Following recent work on Hindsight Experience Replay (Andrychowicz et al 2017), the authors extend the idea to policy gradient methods.	O	O	Review	195
They formally describe the goal-conditioned policy gradient setup and derive the extensions of the classical policy gradient estimators.	O	O	Review	195
Their key insight to deriving a computationally efficient estimator is that for many situations, only a small number of goals will be "active" in a single trajectory.	O	O	Review	195
Then, they conduct extensive experiments on a range of problems and show that their approach leads to improvements in sample efficiency for goal-conditioned tasks.	O	O	Review	195
[line_break_token][line_break_token]Although the technical novelty of the paper is not high (many of the estimators follow straightforwardly from previous results, however, the goal subsampling idea is a nice contribution), the paper is well written, the topic is of great interest, and the experiments are extensive and insightful.	B-Review	B-1	Review	195
I expect that this will serve as a nice reference paper in the future, and launching point for future work.	I-Review	I-1	Review	195
[line_break_token][line_break_token]The only major issue I have is that there is no comparison to HER.	B-Review	B-2	Review	195
I think it would greatly strengthen the paper to have a comparison with HER.	I-Review	I-2	Review	195
I don't think it diminishes their contributions if HER outperforms HPG, so I hope the authors can add that.	I-Review	I-2	Review	195
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]In Sec 6.1, it seems surprising that GCPG+B underperforms GCPG.	B-Review	B-3	Review	195
I understand that HPG+B may underperform HPG, but usually for PG methods a baseline helps.	I-Review	I-3	Review	195
Do you understand what's going on here?	I-Review	I-3	Review	195
[line_break_token][line_break_token]In Sec 6.2, it would be helpful to plot the average return of the optimal policy for comparison (otherwise, it's hard to know if the performance is good or bad).	B-Review	B-4	Review	195
Also, do you have any explanations for why HPG does poorly on the four rooms?	I-Review	I-4	Review	195
[line_break_token][line_break_token]====[line_break_token][line_break_token]Raising my score after the authors responded to my questions and added the HER results.	O	O	Review	195
Thank you very much for the time that you have dedicated to evaluate our work.	O	O	Reply	195
We are glad that you believe that our paper is well written and of great interest, that our experiments are extensive and insightful, and that our contribution has the potential to become a reference and starting point for future work.	O	O	Reply	195
[line_break_token][line_break_token]You are absolutely correct in noting that the fact that only active goals need to be considered is crucial to the feasibility of the proposed estimators.	B-Reply	B-1	Reply	195
This result is very specific to this application of importance sampling, which also leads to other remarkable properties (as discussed in Section 5).	I-Reply	I-1	Reply	195
However, we disagree with the claim that the technical novelty of our paper is not high.	I-Reply	I-1	Reply	195
Firstly, our technical approach to hindsight is radically different from previous work.	I-Reply	I-1	Reply	195
Secondly, the exact formulation of the hindsight policy gradient, its relationships with value functions, and the feasibility of the corresponding estimators are only clear in hindsight.	I-Reply	I-1	Reply	195
Finally, although apparently simple by analogy, several results require proofs that are elementary but involved (for an example, see Theorem 4.2).	I-Reply	I-1	Reply	195
[line_break_token][line_break_token]It is indeed very interesting that including a value function baseline seems more harmful than helpful according to our experiments.	B-Reply	B-3	Reply	195
After careful investigation, we have concluded that the value function baseline is often poorly fit by the time that the policy exhibits desirable behavior, which is probably due to the fact that the value function baseline is not trained using hindsight.	I-Reply	I-3	Reply	195
This is particularly evident in the bit flipping environments, the most extreme examples of sparse-reward environments that we consider, where both HPG+B and GCPG+B exhibit unstable behavior (although GCPG+B only ever reaches a good performance for k=8 and a batch of size 16).	I-Reply	I-3	Reply	195
Although our preliminary experiments in using hindsight to fit a value function baseline have been successful, this may be accomplished in several ways, and requires a careful study of its own.	I-Reply	I-3	Reply	195
[line_break_token][line_break_token]We believe that the poor performance of every technique in the four rooms environment could be addressed by well-known policy gradient tricks (e.g., entropy bonuses, reward scaling, learning rate annealing, simple statistical baselines), which we have avoided in order to reduce confounding factors in our experiments.	B-Reply	B-4	Reply	195
The stark state information and the layout that offers a single door between adjacent rooms make this environment surprisingly difficult, but it is probably within reach of agents trained with either HPG or GCPG.	I-Reply	I-4	Reply	195
Indeed, plotting the average return of the optimal policy would be helpful for inspecting results.	I-Reply	I-4	Reply	195
We can easily include that in the final version of the paper.	I-Reply	I-4	Reply	195
[line_break_token][line_break_token]We completely understand your interest in a direct comparison with hindsight experience replay, although we are glad that you agree that our contribution would not be diminished if hindsight experience replay were more sample efficient at this stage.	B-Reply	B-2	Reply	195
Because this comparison was a common request among reviewers, we are currently working on it.	I-Reply	I-2	Reply	195
We will provide an updated version of the paper including the corresponding results before the end of the rebuttal period (ideally by 21/11).	I-Reply	I-2	Reply	195
[line_break_token][line_break_token]Nonetheless, we would like to briefly explain why we did not include such a comparison in the current version of the paper.	I-Reply	I-2	Reply	195
Firstly, hindsight experience replay is an approach that can be applied to any reinforcement learning technique that relies on experience replay.	I-Reply	I-2	Reply	195
Besides the choices required to implement hindsight experience replay itself (such as the goal sampling strategy and number of hindsight transitions per observed transition), each of these techniques potentially has several important hyperparameters.	I-Reply	I-2	Reply	195
Instead of comparing HPG to one of these techniques, we preferred to focus on a rigorous comparison with GCPG, its most natural counterpart.	I-Reply	I-2	Reply	195
The similarities between both methods allow for a highly systematic comparison that minimizes confounding factors.	I-Reply	I-2	Reply	195
Secondly, note that we have not used tricks that are known to increase the performance of policy gradient methods, once again in order to avoid introducing confounding factors.	I-Reply	I-2	Reply	195
Because hindsight experience replay is directly applicable to state-of-the-art techniques, this would lead to an unbalanced comparison.	I-Reply	I-2	Reply	195
Finally, it should be clear that our work can probably benefit from being extended to state-of-the-art policy gradient approaches.	I-Reply	I-2	Reply	195
However, once again, such extensions are likely to introduce confounding factors that we would prefer to avoid in our fundamental work.	I-Reply	I-2	Reply	195
[line_break_token][line_break_token]We hope that these clarifications and the additional experimental content to be released before the rebuttal deadline will allow you to reconsider the rating given to our submission	O	O	Reply	195

This paper presents a VAE architecture that separates a fixed content representation and time varying features of an image, that can be used to learn a representation of image transformations in a temporal setting.	O	O	Review	20590
[line_break_token][line_break_token]The paper is well written and the ideas presented are interesting, but in my opinion not novel enough or thoroughly demonstrated to justify acceptance:[line_break_token][line_break_token]- there is a very relevant work that is not mentioned by the authors and that can be seen as a generalization of the model presented in this paper: "Disentangled Sequential Autoencoder" by Li and Mandt (ICML 2018), which introduces a model that is also disentangling a content and a temporal representation of sequential data.	B-Review	B-1	Review	20590
This is basically the more general model introduced by the authors of this submission in the beginning of section 2, without all the assumptions made in the rest of section 2.	I-Review	I-1	Review	20590
A comparison with this related work would help assess the differences in terms of modelling power and in performances.	I-Review	I-1	Review	20590
[line_break_token][line_break_token]- The assumptions made in this work are fairly strong for most interesting applications, in particular the fact that the content cannot change across time steps.	B-Review	B-2	Review	20590
[line_break_token][line_break_token]- To me, the issue with the novelty of this model would not be a big problem if the authors focused more on showing its usefulness in different applications (e.g. medical domain or RL as mentioned in the conclusions).	B-Review	B-3	Review	20590
However, the authors only demonstrate the TEVAE on relatively simple experiments that are only tailored to simple image transformations.	I-Review	I-3	Review	20590
[line_break_token]	O	O	Review	20590
hanks for the review and the reference which we will cite and discuss in the paper.	B-Reply	B-1	Reply	20590
Indeed the underlying generative model we start up with is the same as (1) in the reference.	I-Reply	I-1	Reply	20590
However, the main purpose of the paper is that we argue against modeling z_t directly and instead propose our generative model (1) which focuses on the differences between the time-steps.	I-Reply	I-1	Reply	20590
You are right that our model has stronger assumptions insofar that we do not model constant features directly ( c in our paper or f in the reference) and therefore need to assume that c/f and z_t can be correctly estimated from the previous image.	I-Reply	I-1	Reply	20590
[line_break_token][line_break_token]In our paper, we focused on tasks that are simple enough to illustrate the differences in modelling of z_t and \dot{z_t}. We are confident that we could apply it to experiment 4.1 in the reference, which would amount to learning the actions without learning the appearance.	I-Reply	I-1	Reply	20590
However, this task, while looking more fancy, would be easier, because the action-space is discrete(the frame number in the animation) and there is no difficult topology to learn - a flat topology would suffice.	I-Reply	I-1	Reply	20590
In this case, modeling z_t and \dot{z}_t would be equivalent.	I-Reply	I-1	Reply	20590
The experiment 4.3 also sounds very interesting and would require an extension of the model to encode transitions p(\dot{z}_{t+1}|\dot{z}_t, x_t) for the forward-prediction task (to model the elastic collisions).	I-Reply	I-1	Reply	20590
Still, the \dot{z} space would probably be simpler compared to what we consider in our experiments, since movement of the ball is just learning position/velocity, which is a flat space.	I-Reply	I-1	Reply	20590
[line_break_token][line_break_token]In our experiments on MNIST, focusing on scaling and rotation reveals that it is difficult for a VAE to learn an encoding that is compatible with the normal prior and can not be described as disentangled.	I-Reply	I-1	Reply	20590
This is very important, because even if models in Figure 5 e/f/ would produce better visual results, sampling z_t or \dot{z}_t from the prior would not lead to good samples since the true learned encoding lies on a curved manifold.	I-Reply	I-1	Reply	20590
Also, since the manifold changes depending on object symmetry(and involves a twist in 2d space), recent approaches like manifold-based priors are not easy to adapt to this.	I-Reply	I-1	Reply	20590
When enforcing a flat manifold that is consistent with the prior (figure h/l) we obtain that the model fails at reconstructing roughly half of the rotation-space, except when learning a model where the encoder has enough information to perform the parallel transport of the tangent space (Figure g/k).	I-Reply	I-1	Reply	20590
So we claim that the model in Figure g/k is the only one that actually solves the task.	I-Reply	I-1	Reply	20590
[line_break_token][line_break_token]I think the most important result is the carracing task where the z-model fails to learn the translation direction.	I-Reply	I-1	Reply	20590
This is kind of obvious because here it is impossible to disentangle "content" from "position" (without observing x_t there is no valid coordinate system to define position on and movement is the relative shift of all content in the image).	I-Reply	I-1	Reply	20590
The only way to define translation using z_t coordinates would be to treat all "constant/slow changing" features c/f as changing variables z and define translation based on this high level image description of the whole content.	I-Reply	I-1	Reply	20590
This is probably what the encoder in the \dot{z}-model does.	I-Reply	I-1	Reply	20590
[line_break_token][line_break_token]Regarding content: while this is true for the registration model, this is not true for a general NN approach.	B-Reply	B-2	Reply	20590
It is just very difficult to find a proper architecture for that.	I-Reply	I-2	Reply	20590
since changing content is a varying variable, it would be modeled via z_t/\dot{z}_t.	I-Reply	I-2	Reply	20590
E.g. in a video game the only truely constant feature would be "which level am I in".	I-Reply	I-2	Reply	20590
 In our paper, we had to change the loss-function on the carracing task to ignore the borders, otherwise we would have needed a much larger feature space to model all content in the image(or at least the borders).	I-Reply	I-2	Reply	20590
[line_break_token][line_break_token]Final words:[line_break_token]I agree with your review that our model has its limits.	I-Reply	I-2	Reply	20590
We don't model higher order time-dependencies (which is a simple extension that is only relevant for n-step (n&gt;1) prediction tasks) and we don't model c. This is not a simple extension because (c, \dot{z}_t) is not a complete description of the state and we would also need to model z_t somehow.	O	O	Reply	20590
[line_break_token][line_break_token]In the end, ICLR is about learning representations and we learn a representation for \dot{z} that is meaningful and minimal.	B-Reply	B-3	Reply	20590
One might debate whether this is enough or not, but this might be standpoint specific.	I-Reply	I-3	Reply	20590
We definitely have not answered all questions (e.g. how to get a neural network in the MNIST task to learn the flat manifold as in Figure 5c), but we think there are a lot of tasks out there were our current results are important(e.g.	I-Reply	I-3	Reply	20590
modeling progression of diseases)	I-Reply	I-3	Reply	20590

Pros: This seems like very competent and important work in an under-served area: Doing the mapping (or "entity linking") of chemical names to their standardized systematic forms.	O	O	Review	1519
It's not my area, but I was frankly surprised when the paper said there was only one relevant prior piece of work, but having searched for a few minutes on Google Scholar, I'm at least inclined to believe that the authors are (approximately) right on that one. (	O	O	Review	1519
This stands in stark contradistinction to the large quantity of biomedical entity recognition and linking work.)	O	O	Review	1519
So, it's valuable to have work in this area, and the approach and application are sensible.	O	O	Review	1519
In one sense, this gives the work significance and originality (as to domain).	O	O	Review	1519
The paper is also clearly written, and certainly sufficiently accessible to an ML reader.	O	O	Review	1519
[line_break_token][line_break_token]Cons: Unfortunately, though, I just don't think this qualifies for acceptance at ICLR.	B-Review	B-1	Review	1519
It's application of known techniques, and lacks any ML novelty or sufficient ML interest.	I-Review	I-1	Review	1519
It would only be appropriate for an "ML applications" track, which ICLR does not have.	I-Review	I-1	Review	1519
And while its performance is _way_ better than that of the only previous work on the topic that they know, accuracy of mapping non-systematic chemical terms (54.04%) is still low enough that this technique doesn't seem ready for prime time.	I-Review	I-1	Review	1519
[line_break_token][line_break_token]Other comments: In table 5, you show that a prior pipeline stage of spelling correction is definitely useful in your system (table 5).	B-Review	B-2	Review	1519
And yet, given the power of deep learning seq2seq transductions, and the potential to use them for spelling correction, one might wonder whether this prior step of spelling correction is really necessary.	I-Review	I-2	Review	1519
It might be interesting to explore further where it helps and whether the gains of spelling correction might be obtainable in other ways such as using data augmentation (such as spelling error insertion) in the seq2seq training data.	I-Review	I-2	Review	1519
The Golebiewski bib entry is lacking any information as to where it is published, which seems especially bad for the key citation to prior work of the whole paper.	I-Review	I-2	Review	1519
In general, the bibliography has issues: non-ASCII characters have been lost (you either need to LaTeX-escape them or to load a package like utf8, and capitalization of acronyms, etc.	I-Review	I-2	Review	1519
should be improved with curly braces.	I-Review	I-2	Review	1519
Please refer to our comments to AnonReviewer3 about our contribution and the role of this work.	O	O	Reply	1519
[line_break_token]Here we want to add facts about the performance.	B-Reply	B-1	Reply	1519
According to our industrial partner,  the largest chemical database maybe only contains 2% chemical names appearing in all the chemical literature just because of the name obstacle.	I-Reply	I-1	Reply	1519
So, when an accuracy of about 60% is argued, we'd better look backwards.	I-Reply	I-1	Reply	1519
Only several percents of extraction accuracy has supported all the existing chemical database building for a broad range of practical application, while our system boosts nearly 10 times accuracy improvement compared to previous state-of-the-art.	I-Reply	I-1	Reply	1519
Just imagine how a new world we open for the community of CIP through this work.	I-Reply	I-1	Reply	1519
[line_break_token]Please keep it in mind that even 6% extraction accuracy (ChemHits) can effectively and well serve all CIP work so far	I-Reply	I-1	Reply	1519

Summary[line_break_token]This paper introduced a parameterized image processing technique to improve a robustness of visual recognition systems against noisy input data.	O	O	Review	849
The proposed method is composed of two components; a denoising network that suppresses the noise signals in an image, and gating network that predicts whether to use the original input image or the one produced by the denoising network.	O	O	Review	849
The proposed idea is evaluated on three tasks of object detection, tracking and action recognition.	O	O	Review	849
[line_break_token][line_break_token]Originality and significance:[line_break_token]The originality of the paper is very limited since the paper simply combines the existing image denoising technique with the idea of gating.	B-Review	B-1	Review	849
The practical significance of the work is also limited since the model is trained and evaluated with only synthetically generated noise patterns; it is not surprising that the proposed method (both denoising and gating networks) works under this setting, as the noise is created synthetically under the same setting in both training and testing.	I-Review	I-1	Review	849
To demonstrate the practical usefulness, it would be great if the model is evaluated with the actual source of noises (e.g. noises from input sensors, distortion by image compression, etc).	I-Review	I-1	Review	849
 [line_break_token][line_break_token]Clarity:[line_break_token]I think the title of the paper is misleading; the proposed model is actually not a mixture of preprocessing units, as it combines *a* denoising unit together with identity mapping.	B-Review	B-2	Review	849
The gating network is also not designed to incorporate a mixture of more than two preprocessing units, as it outputs only ‚Äúon/off switches‚Äù instead of weights for K mixture components (K>2).	O	O	Review	849
[line_break_token][line_break_token]Minor comments:[line_break_token]1) the paper argued the importance of lightweight preprocessing but have not provided analysis on computation costs.	B-Review	B-3	Review	849
From the current results, I don‚Äôt see the clear benefit of the proposed method (denoising network) over the average filtering considering the tradeoff between computation vs. performance.	I-Review	I-3	Review	849
[line_break_token]2) In Figure 5, I suggest highlighting the differences among the examples for clarity.	B-Review	B-4	Review	849
[line_break_token]	O	O	Review	849
Thank you for the valuable reviews.	O	O	Reply	849
[line_break_token][line_break_token]Q1 ‚Äì Originality and significance:[line_break_token][line_break_token](Ans) In contrast to many other DL works focused on denoising or image classification on noisy images [1-2], the main contribution of this paper is to enhance the performance of object detection and its related other tasks (multiple object tracking and activity recognition) under ‚Äúboth‚Äù noisy/clean condition with ‚Äúlimited overhead‚Äù in terms of memory/computation (table 5).	B-Reply	B-1	Reply	849
Also, we have discovered that adding average filter and U-net [3] like skip connection are beneficial for denoising.	I-Reply	I-1	Reply	849
[line_break_token]For the practical usefulness, it would be great if we can incorporate those actual noises as a future work.	I-Reply	I-1	Reply	849
Thanks for your feedback.	I-Reply	I-1	Reply	849
[line_break_token][line_break_token][1] P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, P.-A. Manzagol, "Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion", J. Mach.	I-Reply	I-1	Reply	849
Learn.	I-Reply	I-1	Reply	849
Res.,	I-Reply	I-1	Reply	849
vol.	I-Reply	I-1	Reply	849
11, no.	I-Reply	I-1	Reply	849
11, pp.	I-Reply	I-1	Reply	849
3371-3408, 2010.	I-Reply	I-1	Reply	849
[line_break_token][2] S. Diamond, V. Sitzmann, S. Boyd, G. Wetzstein, and F. Heide.	I-Reply	I-1	Reply	849
Dirty pixels: Optimizing image classification architectures for raw sensor data.	I-Reply	I-1	Reply	849
arXiv preprint arXiv:1701.06487, 2017.	I-Reply	I-1	Reply	849
[line_break_token][3] Olaf Ronneberger, Philipp Fischer, and Thomas Brox.	I-Reply	I-1	Reply	849
U-net: Convolutional networks for biomedical image segmentation.	I-Reply	I-1	Reply	849
In MICCAI (3), volume 9351 of Lecture Notes in Computer Science, pp.	I-Reply	I-1	Reply	849
234‚Äì241.	I-Reply	I-1	Reply	849
Springer, 2015.	I-Reply	I-1	Reply	849
[line_break_token][line_break_token]Q2 ‚Äì Clarity:[line_break_token](Ans) We think that the title of the paper is valid.	B-Reply	B-2	Reply	849
It is true, in this paper, we have used identity mapping for the clean and low-resolution images as a preprocessing.	I-Reply	I-2	Reply	849
This was the result from our experiments, not necessarily obvious one.	I-Reply	I-2	Reply	849
There could be better preprocessing for low-resolution images that we haven‚Äôt explored.	I-Reply	I-2	Reply	849
[line_break_token][line_break_token]Q3 - lightweight preprocessing[line_break_token](Ans) Please see the table 5.	B-Reply	B-3	Reply	849
Also, it is obvious that average filter requires less computation than the denoise net since denoise net includes average filter as a part (Please see the section 3.2 Pre-processing for the noisy images).	I-Reply	I-3	Reply	849
[line_break_token][line_break_token]Q4 - Figure 5:[line_break_token](Ans) We have changed the figure.	B-Reply	B-4	Reply	849

This paper presents an empirical study on the effect of pruning to the model performance on each class and example, which leads to a novel finding that it has disparate effects to each sample.	O	O	Review	20451
Specifically, the authors have found out that examples that are affected the most by pruning are more difficult to classify even for the non-pruned network, due to low image quality, mislabeling, or being atypical from the class prototype, and performed a further human study to analyze the source of difficulty.	O	O	Review	20451
Moreover, the authors performed an additional experiment, which shows that the sparse models are brittle against natural adversarial examples.	O	O	Review	20451
[line_break_token][line_break_token]Pros[line_break_token]- The paper provides a novel insight on the effect of pruning at the class and the example level, which could lead to a more effective pruning approach that exploit this findings.	O	O	Review	20451
[line_break_token][line_break_token]Cons[line_break_token][line_break_token]- The paper only provides a novel finding but not the solution on how to tackle this problem, and thus the paper looks incomplete.	B-Review	B-1	Review	20451
After section 3.3, I was expecting to see some approaches to tackle this problem but the paper abruptly ended.	I-Review	I-1	Review	20451
[line_break_token][line_break_token]- The effect of pruning could largely differ from one method to another, but the authors do not experimentally compare the effects of different pruning methods.	B-Review	B-2	Review	20451
Also, it is highly likely that the findings discussed in the paper may be only true for input-independent pruning approaches, and may not generalize to input-dependent pruning method.	I-Review	I-2	Review	20451
The authors need to perform extensive study of both input-dependent and input-independent pruning approaches to validate their points.	I-Review	I-2	Review	20451
[line_break_token][line_break_token]In sum, the paper provides a novel insight on how pruning affects the performance at the example level, but does not provide a solution, and the current set of experiments is insufficient to validate that the empirical findings that the authors report generalize to other types of pruning approaches, such as input-dependent pruning.	B-Review	B-1	Review	20451
Thus I believe that the paper is not ready for publication yet, and vote for rejecting this paper in its current form.	O	O	Review	20451
[line_break_token]	O	O	Review	20451
e thank R1 for their feedback, and acknowledge that we do not propose a new method to solve the non-uniform impact of model pruning on different classes and images.	B-Reply	B-1	Reply	20451
We believe our contribution is none the less of value to the ICLR community, because to our knowledge we are the first work to propose a formal framework for measuring the per-class and image impact of pruning deep neural networks.	I-Reply	I-1	Reply	20451
We consider an unexplored and timely question given the widespread use of pruning as a compression technique in many sensitive domains.	I-Reply	I-1	Reply	20451
[line_break_token][line_break_token]Our conclusion, that a small subset of classes and images bear the brunt of pruning, has wide ranging implications for the use of pruned models in sensitive domains.	I-Reply	I-1	Reply	20451
The introduction of pruning may be at odds with fairness objectives to treat certain protected attributes uniformly and/or AI safety objectives to preserve human welfare when predictions by guaranteeing a certain level of recall for certain classes.	I-Reply	I-1	Reply	20451
[line_break_token][line_break_token]Our contribution illustrates that top-1 accuracy alone tells a painfully incomplete picture, and that for these sensitive domains additional measures of model generalization are certainly needed.	I-Reply	I-1	Reply	20451
We propose such formal measures of generalization difference in this manuscript.	I-Reply	I-1	Reply	20451
We will update our manuscript to make this motivation and the scope of our contributions more clear.	I-Reply	I-1	Reply	20451
[line_break_token][line_break_token]"The effect of pruning could largely differ from one method to another, but the authors do not experimentally compare the effects of different pruning methods."	O	O	Reply	20451
[line_break_token][line_break_token]R1 is correct that the results that we report (while consistent across datasets) are only for a single pruning method.	B-Reply	B-2	Reply	20451
We were restricted in our choice of pruning method by the need to pre-specify the final level of sparsity to allow for clean comparison across trained models.	I-Reply	I-2	Reply	20451
We also note that magnitude pruning is a widely used (open source and integrated into the tensorflow library) and considered to be state of art (Gale et al 2019).	I-Reply	I-2	Reply	20451
 [line_break_token][line_break_token]We agree that a consideration of additional methods would be of value, and have committed to open sourcing our code so that we are not the bottleneck for further reproducibility.	I-Reply	I-2	Reply	20451
We note that our methodology is pruning method agnostic, and can easily be extended to other method.	I-Reply	I-2	Reply	20451
[line_break_token][line_break_token]We wanted to seek clarification on what R1 means by input-independent pruning approaches?	I-Reply	I-2	Reply	20451
Can R1 reference an open source implementation of such an approach or prior work to help clarify the use of this terminology	I-Reply	I-2	Reply	20451

The paper propose a new quantization-friendly network training algorithm called GQ (or DQ) net.	O	O	Review	620
I addresses the existing issues in the common paradigm, where a floating-point network is trained first, followed by a second-phase training step for the quantized version.	O	O	Review	620
It is a well-written paper.	O	O	Review	620
Concepts were clearly explained and easy to follow.	O	O	Review	620
Below I present my comments about some details in the paper that were not entirely clear for me.	O	O	Review	620
[line_break_token][line_break_token]- The two loss terms conflict each other.	B-Review	B-1	Review	620
If the training algorithm focuses too much on the first term, it will make the network less friendly to the quantization process.	I-Review	I-1	Review	620
On the other hand, the second one is going to enforce too much emphasis on the accuracy from the quantized network.	I-Review	I-1	Review	620
It is natural to involve some hyperparameter search to find the balance between the two blending parameters.	I-Review	I-1	Review	620
The paper suggests a strategy as to how to handle this issue, but it is not comprehensive, and rather controversial.	I-Review	I-1	Review	620
I think the paper will benefit from a more in-depth discussion and analysis on this regularization issue.	I-Review	I-1	Review	620
[line_break_token][line_break_token]- The schedule for the loss term blending parameters looks drastic to me.	B-Review	B-2	Review	620
It‚Äôs more like ‚Äútrain the floating point net first, and then train the quantized one, and then revisit the floating point one, and so on.	I-Review	I-2	Review	620
‚Äù I know I simplified, because the floating point network never stops getting updated as it‚Äôs \omega_f is always 1.	I-Review	I-2	Review	620
However, it seems to me that this drastic scheduling strategy sounds like very similar to the traditional approach that trains the floating point network first and then finetune the quantized one, except for the fact that this proposed algorithm repeats this process a few times.	I-Review	I-2	Review	620
Hence, I think the authors‚Äô argument about the supremacy of the proposed method to the two-step finetuning approach is not clearly supported.	I-Review	I-2	Review	620
[line_break_token][line_break_token]- The exponentially decaying learning rate scheduling looks like the one from ResNet.	B-Review	B-3	Review	620
I‚Äôm wondering if it should be the best, especially with the drastic introduction and omission of the second loss.	I-Review	I-3	Review	620
[line_break_token][line_break_token]- In the ablation studies, it seems that some of the suggested training options are conflicting each other and the clear winner seems to be the multi-domain BN.	B-Review	B-4	Review	620
I cannot conclude anything from this analysis as to which one is more important than the other one, except for the Alt{W,\theta} case.	I-Review	I-4	Review	620
[line_break_token][line_break_token]Some minor things:[line_break_token][line_break_token]- What‚Äôs the name of the proposed network?	B-Review	B-5	Review	620
Is it GQ or DQ?	I-Review	I-5	Review	620
[line_break_token] 	B-Review	B-1	Review	620
 appreciate the authors' responses that clarified some of my questions.	O	O	Reply	620
The responses elaborated the arguments made in the original draft, while they do not fully resolve the fundamental issues.	B-Reply	B-1	Reply	620
For example, the I wouldn't say the gradient from the first loss term is more accurate, as it's using full precision, which is "different" from the test environment where reduced precision has to be used.	I-Reply	I-1	Reply	620
They also suggest a few potential solutions, while the revised version doesn't really contain those ideas.	I-Reply	I-1	Reply	620

*Summary*[line_break_token]This paper describes DiffSim, a differentiable programming system for learning with physical simulation.	O	O	Review	10067
The system (built on the Taichi system) allows users to specify a forward simulation in a Python-like syntax, after which the program is compiled and iteratively run in both forward-mode and gradients computed for system parameters and controllers, as desired.	O	O	Review	10067
A variety of simple simulations are included, demonstrating that the automatically generated CUDA code runs as fast as hand-written CUDA code (and noticeably faster than TensorFlow or PyTorch implementations), while requiring far fewer lines of code.	O	O	Review	10067
The final section details two issues--time of  impact errors due to discrete time intervals and gradient explosions with long time horizons--and some potential solutions.	O	O	Review	10067
[line_break_token][line_break_token]*Rating*[line_break_token]The paper is interesting and easy to read.	O	O	Review	10067
While some part of the underlying functionality of DiffSim is directly derived from previous work (Taichi), the paper does describe a non-trivial contribution.	O	O	Review	10067
[line_break_token][line_break_token]I lack the background to comment constructively about expectations for these simulations or the fidelity of the methods in this paper.	B-Review	B-1	Review	10067
What evidence can you offer regarding the physical fidelity achievable and how that relates to issues of scalability, gradient behavior, size of time steps, code complexity, etc.?	I-Review	I-1	Review	10067
For a sense of context, what might be needed to simulate a 7 DoF robotic arm and learn a controller that would reasonably transfer to a real robot?	I-Review	I-1	Review	10067
[line_break_token][line_break_token]Overall, I'm optimistic about this paper, and would tend to vote for acceptance.	O	O	Review	10067
[line_break_token][line_break_token]*Notes*[line_break_token]pg3: define k (spring stiffness?)	B-Review	B-2	Review	10067
[line_break_token]pg4: what is the value of 'mass' for this simulation?	I-Review	I-2	Review	10067
[line_break_token]Fig 8: what is the x-axis in the two right plots?	I-Review	I-2	Review	10067
initial height?	I-Review	I-2	Review	10067
[line_break_token]Fig 10: right plot title should probably be "Gradient Explosion with Damping"	I-Review	I-2	Review	10067
ear Reviewer 3,[line_break_token][line_break_token]Thank you for the positive feedback.	O	O	Reply	10067
The question about simulation fidelity is very interesting.	B-Reply	B-1	Reply	10067
DiffSim is as expressive as traditional languages such as C++/Fortran in building physical simulators, so it can achieve the fidelity level of previously build simulators.	I-Reply	I-1	Reply	10067
In order to simulate a 7-DoF robotic arm, a differentiable rigid body simulator written in DiffSim should be used to train the controller, but transferring the controller to a real robot would face a sim2real gap, just as physical simulators written in any other language.	I-Reply	I-1	Reply	10067
DiffSim does not directly address this gap, but it does significantly reduce code complexity and would allow researchers to develop more realistic simulators with the same amount of work.	I-Reply	I-1	Reply	10067
Similarly, DiffSim does not resolve the numerical accuracy issue caused by a finite time step size, but it does improve the program performance to allow users to run simulations with smaller time step sizes and higher spatial resolution and thereby smaller discretization errors.	I-Reply	I-1	Reply	10067
[line_break_token][line_break_token]We have also fixed the minor issues in the revision:[line_break_token]   -   (Page 3) k is spring stiffness.	B-Reply	B-2	Reply	10067
[line_break_token]   -   (Page 4) We used mass = 1 throughout the mass-spring simulation.	I-Reply	I-2	Reply	10067
[line_break_token]   -   (Fig.	I-Reply	I-2	Reply	10067
8) The x-axes are initial height.	I-Reply	I-2	Reply	10067
[line_break_token]   -   (Fig.	I-Reply	I-2	Reply	10067
10) Thanks for pointing out the typo in ‚ÄúGradient Explosion with Damping‚Äù.	I-Reply	I-2	Reply	10067
As suggested by reviewer 2, we have removed the discussion on gradient explosion.	I-Reply	I-2	Reply	10067
[line_break_token][line_break_token]Please also find the detailed paper change log in our general response to all reviewers.	O	O	Reply	10067
Thank you again for your time and feedback.	O	O	Reply	10067
[line_break_token][line_break_token]Best,[line_break_token]Author	O	O	Reply	10067

The paper introduces a method for online adaptation of a model that is expected to adapt to changes in the environment the model models.	O	O	Review	376
The method is based on a mixture model, where new models are spawned using a Chinese restaurant process, and where each newly spawned model starts with weights that have been trained using meta-learning to quickly adapt to new dynamics.	O	O	Review	376
The method is demonstrated on model-based RL for a few simple benchmarks.	O	O	Review	376
[line_break_token][line_break_token]The proposed method is well justified, clearly presented, and the experimental results are convincing.	O	O	Review	376
The paper is generally clear and well written.	O	O	Review	376
The method is clearly most useful for situations where the environment suddenly changes, which is relevant in some real-world problems.	O	O	Review	376
As a drawback, using a mixture model (that also grows with time) for such modelling can be considered quite heavy in some situations.	B-Review	B-1	Review	376
Nevertheless, the idea of combining a spawning process with meta-learned priors is neat, and clearly works well.	O	O	Review	376
[line_break_token][line_break_token]Minor comments:[line_break_token]- Algorithm 1: is the inequality correct, and is T* supposed to be an argmin instead of argmax?	B-Review	B-2	Review	376
Thank you for your review.	O	O	Reply	376
We have corrected the typo in both places of Algorithm 1: it should indeed have been the opposite inequality sign, and argmin instead of argmax.	B-Reply	B-2	Reply	376
[line_break_token][line_break_token]We definitely agree with your comment that a mixture model that grows with time can sometimes be considered quite heavyweight.	B-Reply	B-1	Reply	376
This is precisely where we plan to focus the efforts of our future work, by introducing a refreshing scheme where an offline retraining step can periodically condense the mixture model into fewer components (perhaps in a batch-mode training setting, so not all past data needs to be saved).	I-Reply	I-1	Reply	376
We are also interested in goals such as making this mixture only as big as the agent ‚Äúneeds‚Äù it to be, allowing for better and more compressed sharing and organization of seen data.	I-Reply	I-1	Reply	376
The performance of this current method makes us hopeful and excited to work toward such future work in this area	I-Reply	I-1	Reply	376

This paper jointly trains a sentiment classifier with a sentiment and domain-aware embedding[line_break_token]model, using both labeled and unlabeled data.	O	O	Review	1317
When sentiment label is observed, this model is trained[line_break_token]with the usual cross entropy and maximum likelihood objectives; for unlabeled data, it uses pseudo[line_break_token]labels produced by the sentiment classifier with variational Bayes objective.	O	O	Review	1317
This idea is not novel but the authors report that there is no previous work that jointly trains sentiment aware embeddings with a sentiment classifier specifically, and makes use of an unlabeled corpus to improve both.	B-Review	B-1	Review	1317
However, there are general and broader methods such as 'Toward Controlled Generation of Text' by Hu et al that apply semi-supervised techniques for generation (not classification) with specific constraints (sentiment, domain, etc).	B-Review	B-2	Review	1317
There are other recent methods such as 'Improving Language Understanding by Generative Pre-Training' by Redford et al that use the idea of generative pre-training with discriminative fine-tuning that are task-agnostic and achieve very good performance - how does the paper compare to this approach?	B-Review	B-3	Review	1317
[line_break_token]The experiments and analysis is very well written in the paper.	O	O	Review	1317
Table 4 also shows very interesting, somewhat surprising results in the paper.	O	O	Review	1317
The authors say that they will release the code and data for this technique which will be useful for the sentiment analysis research community.	O	O	Review	1317
 [line_break_token]	B-Review	B-1	Review	1317
Thanks for the informative comment.	O	O	Reply	1317
Hu et al‚Äôs ICML2017 paper is especially a very interesting read.	B-Reply	B-2	Reply	1317
It is not directly comparable to this paper because, as the reviewer already pointed out, Hu et al‚Äôs is about (sentence) generation but this paper is about (document) classification.	I-Reply	I-2	Reply	1317
Nevertheless, let‚Äôs have a deep discussion about these two papers.	I-Reply	I-2	Reply	1317
[line_break_token][line_break_token]First, Hu et al‚Äôs is insightful in that it models different semantic attributes as independent factors which control generation; our paper shares a very similar spirit by learning a disentangled sentiment part and a domain specific part for word embeddings.	I-Reply	I-2	Reply	1317
When the data is unlabeled, both papers use discriminators to produce pseudo-labels for training the generative model.	I-Reply	I-2	Reply	1317
[line_break_token][line_break_token]But then, Hu et al‚Äôs model propagates gradients of the discriminator directly back to the generator, using softmax annealing to circumvent the discreteness of text data; this technique is unnecessary in our setting, because the classifier in our model uses word embeddings (rather than words themselves) as input, and the embeddings are shared between classifier and the generative model.	B-Reply	B-3	Reply	1317
In other words, Hu et al‚Äôs approach uses the discriminator to train the generator, whereas in our model the two are jointly trained.	I-Reply	I-3	Reply	1317
[line_break_token][line_break_token]On the other hand, Hu et al achieve semi-supervised learning of the discriminator by synthesizing data samples from the generator, whereas we use a variational Bayes objective on unlabeled data.	B-Reply	B-4	Reply	1317
Synthesized data only work if one has a good generator; we know that LSTM is a good generator for short sentences, but things are less clear for other types of objects, such as lengthy documents.	I-Reply	I-4	Reply	1317
Therefore, I would not say which one is more general and broader method; both Hu et al‚Äôs and our work are meaningful extensions/applications of Kingma‚Äôs variational Bayes framework.	I-Reply	I-4	Reply	1317
[line_break_token][line_break_token]From a broader perspective, there is no doubt that combining generative and discriminative models is a promising methodology toward semi-supervised learning, and we are interested in this direction because there are plenty of potential applications in Natural Language Processing.	B-Reply	B-3	Reply	1317
For example, one could combine parser and sentence generator, by parsing the generated sentences back to semantic structures to check if intended meanings are conveyed.	I-Reply	I-3	Reply	1317
This idea dates back to old days such as in Duan and White (ACL2014), and is still very active such as in Konstas et al (ACL2017).	I-Reply	I-3	Reply	1317
Domain adaptation of sentiment classifiers is just another, simple but important application task, and there is novelty in applying variational Bayes methods here.	I-Reply	I-3	Reply	1317
We believe the knowledge obtained here will be helpful to other tasks as well.	I-Reply	I-3	Reply	1317
We will modify Related Works to discuss this broader point, including Hu et al and Redford et al as is also suggested by AnonReviewer1.	I-Reply	I-3	Reply	1317
[line_break_token][line_break_token]As for Redford et al‚Äôs in-progress work, we believe it belongs to the realm of pretraining unsupervised language models in order to enhance a wide range of classification tasks.	I-Reply	I-3	Reply	1317
We have already compared with one of its state-of-the-art, ELMo, and shown that we can outperform ELMo in this task, with much smaller unlabeled data.	I-Reply	I-3	Reply	1317
The big difference here, is that the representation learned by our generative model is aware of task-specific latent labels (i.e. sentiment), thus it is more task-oriented; in contrast, representations learned by pretraining unsupervised language models are task-agnostic.	I-Reply	I-3	Reply	1317
Our ablation tests clearly show that more task-oriented representations can improve performance on that task	I-Reply	I-3	Reply	1317

The paper proposes to learn representations by using Krein inner products which are generalizations of standard inner products in Hilbert spaces.	O	O	Review	1486
[line_break_token]A Krein inner product can be formulated as the difference between two inner products, each in a Hilbert space.	O	O	Review	1486
[line_break_token]Although the paper mentions three main contributions, the contributions of the papers are mainly:[line_break_token]- 1.	O	O	Review	1486
using Krein distances instead of Hilbert distances to compare examples[line_break_token]- 2.	O	O	Review	1486
better empirical performance on some datasets[line_break_token][line_break_token]The paper is clear in general, and maybe provides too many details on standard linear algebra (about 3 pages to explain the eigendecomposition of symmetric matrices).	O	O	Review	1486
[line_break_token]My main concern is about novelty.	O	O	Review	1486
The proposed method has already been published in the literature but never been called "representation in a Krein space" (see Novelty point).	O	O	Review	1486
[line_break_token][line_break_token]1.	O	O	Review	1486
Motivation:[line_break_token][line_break_token]It is already known in the literature that Hilbert spaces are limited for certain tasks, non-Euclidean distances have then been used to compare examples.	O	O	Review	1486
[line_break_token]For instance, based on the work of [A], some works have proposed to learn deep representations exploiting hyperbolic distances to represent data with hierarchical structure [B].[line_break_token]The motivation of the superiority of Krein representations is not clear in the paper.	O	O	Review	1486
In what specific contexts is it better to use Krein spaces?	O	O	Review	1486
[line_break_token][line_break_token]2.	O	O	Review	1486
Novelty:[line_break_token][line_break_token]The authors take the example of Mahalanobis-like distance metric learning where a distance function parameterized by a symmetric matrix usually constrained to be positive semi-definite (PSD) is learned.	O	O	Review	1486
The paper argues that constraining the matrix to be PSD limits the expressiveness of the model as the negative spectrum is also meaningful.	O	O	Review	1486
[line_break_token]If the PSD constraint is removed, the problem simply corresponds to learning a symmetric matrix.	O	O	Review	1486
Indeed, by definition, symmetric matrices have real eigenvalues which can be either non-negative or negative.	O	O	Review	1486
The PSD constraint enforces the eigenvalues to be non-negative.	O	O	Review	1486
If the PSD constraint is removed, then the symmetric matrix can be indefinite, which corresponds to the proposed representation in Krein space.	O	O	Review	1486
[line_break_token][line_break_token]Some papers have already proposed to remove the PSD constraint (e.g. [C], Section 2.3) when learning a distance parameterized by a symmetric matrix, which corresponds to the proposed model.	O	O	Review	1486
However, they did not sell the relaxation of the PSD constraint as a contribution.	O	O	Review	1486
[line_break_token][line_break_token]3.	O	O	Review	1486
Experiments:[line_break_token][line_break_token]The experimental section is weak as it provides a simple experiment on a toy dataset, and quantitative results on 4 datasets only for one optimization problem and one specific network architecture.	O	O	Review	1486
[line_break_token]Since the theoretical aspect of the paper is weak, I would expect more comparisons by replacing standard deep metric learning formulations (that use the squared Euclidean distance) with the proposed Krein distance.	O	O	Review	1486
For instance, the submission cites (Oh Song et al), and (Schroff et al) as deep metric learning approaches.	O	O	Review	1486
How would the proposed Krein distance perform in the contexts considered in those references?	O	O	Review	1486
[line_break_token][line_break_token]Demonstrating that the Krein distance also outperforms the squared Euclidean distance in that case would strengthen the experimental aspect of the paper.	O	O	Review	1486
[line_break_token][line_break_token][line_break_token]In conclusion, the theoretical and experimental aspects of the paper are weak.	O	O	Review	1486
[line_break_token][line_break_token][line_break_token][A] Gromov, Hyperbolic groups, 1987[line_break_token][B] Ganea et al, Hyperbolic Neural Networks, NIPS 2018[line_break_token][C] Guillaumin et al Is that you?	O	O	Review	1486
Metric learning approaches for face identification, ICCV 2009	O	O	Review	1486
We thank the reviewers for investing time and effort to provide us with constructive feedback.	O	O	Reply	1486
We take on board the reviewer comments to improve our future work	O	O	Reply	1486

This paper presents a rotation-equivariant model for use with point-clouds.	O	O	Review	336
 Capsule networks with activation and rotation pose estimate in the form of a quaternion are applied to local patches of 3D points, and combined up through progressively more coarser receptive fields.	O	O	Review	336
 Rotation equivariance is obtained by looking for agreement between input point frames (or capsules), by iteratively clustering using the quaternion mean.	O	O	Review	336
 The method is evaluated on ModelNet40, obtaining much improved results in the case where rotation orientation is arbitrary.	O	O	Review	336
[line_break_token][line_break_token]Unfortunately, I found too many important parts of the method difficult to understand, enumerated below, and am also not very clear on the details of how they fit together.	B-Review	B-6	Review	336
 At a high level, the approach of aggregating pose agreement with quaternion averages makes intuitive sense, the quaternion average step itself is described well, and the experimental results seem to corroborate this (results on NR/AR condition are very good, and also near identical to NR/NR condition, a major verification of the method).	I-Review	I-6	Review	336
 However, the rest of the pieces of the method still leave me guessing too much.	I-Review	I-6	Review	336
[line_break_token][line_break_token]*  It isn't clear what computes the activations alpha.	B-Review	B-1	Review	336
 I don't see a description for how to compute activations alpha that are the input to Alg.	I-Review	I-1	Review	336
1, unless these are simply the activations of the previous layer's capsules, and constant for the initial point frames?	I-Review	I-1	Review	336
[line_break_token][line_break_token]*  Likewise, the transform t() could use more description.	B-Review	B-2	Review	336
 Sec 3.2 says it is R3-&gt;R4, indicating that the input to t() is a single point.	O	O	Review	336
 Does this mean that the mere presence of a point in a location R3 (relative to a mostly-canonicalized pose) counts as a vote for a rotation pose?	B-Review	B-2	Review	336
 And if so, how does does this work?	I-Review	I-2	Review	336
 Or does the regressor actually take multiple points as input?	I-Review	I-2	Review	336
 According to the picture in Fig.	I-Review	I-2	Review	336
1, it looks like it takes all points in the local patch as input.	I-Review	I-2	Review	336
[line_break_token][line_break_token]*  Algorithm 1 outer for loop for i doesn't seem quite right.	B-Review	B-3	Review	336
 It suggests that the body is performed either independently or in sequence for each i.  I believe what may actually be intended, is that all i are used at once in parallel, so that the v_ij votes assignment is found for *all* i in order to use in finding the cluster mean for each j.  That is, "v_i,j = Q_i * t_i,j for all i", rather than having the outermost loop over i.  Is this correct?	I-Review	I-3	Review	336
[line_break_token][line_break_token]*  Much space is dedicated to background explanations of quaternions, geodescic distance, etc.	B-Review	B-4	Review	336
 Given my difficulty in understanding much of the system, it seems like some of could be shortened or put into the appendix, and more of the main text devoted to more detailed explanations of each component in the system (e.g. alpha and t), and how the capsule agreement step (QE DR) makes use of these.	I-Review	I-4	Review	336
[line_break_token][line_break_token][line_break_token]Also, some more detailed comments/suggestions:[line_break_token][line_break_token]* Alg.1:  output alpha^hat_K, seems K should be M here?	O	O	Review	336
[line_break_token]* Table 1:  "Right hand side denotes symmetric objects" seems it actually shoudl be in the caption for Table 2.	B-Review	B-5	Review	336
[line_break_token]	O	O	Review	336
e thank the reviewer for the specific comments and acknowledging the improved results we achieve in the paper.	O	O	Reply	336
Please find our responses below.	O	O	Reply	336
[line_break_token][line_break_token]1. ‚	O	O	Reply	336
ÄúThe activation‚Äù: It is true that the update of alpha is only included in the algorithm as it is a standard result from previous works [Sabour et al 2017a, Lenssen et al 2018]. The input to Alg 1.	B-Reply	B-1	Reply	336
are the alphas of the previous layer and we set the initial activations to 1.	I-Reply	I-1	Reply	336
We have now clearly indicated that in the last paragraph of Sec.3.2.	I-Reply	I-1	Reply	336
[line_break_token][line_break_token]2. ‚	O	O	Reply	336
ÄúThe transform t()‚Äù: We have significantly increased our explanation and reworked the formalization of the transform network in the paper.	B-Reply	B-2	Reply	336
The t() network does not directly compute the vote.	I-Reply	I-2	Reply	336
It is merely producing the transformation, on which the input pose is applied to produce the vote: v = q t().	I-Reply	I-2	Reply	336
It is the continuous analogue to the approach in the original capsule networks by Sabour et al There, those transformations lie in a discrete kernel window and are directly optimized like weights for convolution.	I-Reply	I-2	Reply	336
 Here, we train a continuous kernel function instead, given that input capsules are attached to points that lie in continuous space and not on a fixed grid.	I-Reply	I-2	Reply	336
The function t() is shared for all input points and produces transformations for all combinations of input capsules from the respective point and output capsules, which we clarified in the first paragraph of Sec.3.2.	I-Reply	I-2	Reply	336
Additionally, we added specific details of the architecture with pseudocode in Alg.3.	I-Reply	I-2	Reply	336
[line_break_token][line_break_token]3.‚ÄùLoop in Alg.1‚Äù: Thank you for making us aware of this error.	B-Reply	B-3	Reply	336
We fixed the algorithm in the updated version.	I-Reply	I-3	Reply	336
[line_break_token][line_break_token]4.‚ÄùLimited space for explanation‚Äù: We have now shortened the background section to give room for further explanations.	B-Reply	B-4	Reply	336
The paper is also slightly longer.	I-Reply	I-4	Reply	336
As mentioned above, we have added more explanation of the network architecture in Sec.3.2 (added alpha and t), Sec.4 and appendix(Alg.3).	I-Reply	I-4	Reply	336
In Alg.3, we explain the details of the QE-net with pseudocode, included the ‚Äút(.)‚Äù and how the DR is used after we got the transformations.	I-Reply	I-4	Reply	336
[line_break_token][line_break_token]5.‚Äù more detailed comments‚Äù:  Thanks for those corrections.	B-Reply	B-5	Reply	336
We have now incorporated them.	I-Reply	I-5	Reply	336

This paper tackles the problem of navigating scenes to find objects which are potentially not included in the training phase.	O	O	Review	295
To find an unseen object from a scene, the proposed model incorporates an external knowledge graph as an augmented input of the actor-critic model.	O	O	Review	295
To construct a knowledge graph, entities in a scene are identified by ResNet and then the link structure between entities are extracted from VIsual Genome dataset.	O	O	Review	295
Through the ablation study, it is shown that using the knowledge graph helps to track and identify unseen objects during training.	O	O	Review	295
[line_break_token][line_break_token]- The original knowledge graph (KG) has relation labels (such as next to, on in figure 3) between different objects, however, GCN does not take into account the relations between objects.	B-Review	B-1	Review	295
Only co-occurrence patterns will be encoded into the KG constructed from an image.	I-Review	I-1	Review	295
There are more complex graph convolutional models modelling relations between nodes such as [1]. Have you considered adding explicit relations between entities?	I-Review	I-1	Review	295
will it increase the navigation performance?	I-Review	I-1	Review	295
if not why?	I-Review	I-1	Review	295
[line_break_token]- It is unclear how many objects are used to construct a KG from an image.	B-Review	B-2	Review	295
For example, are top-k objects identified by ResNet used to construct a KG?	I-Review	I-2	Review	295
[line_break_token]- Description of the reward is a bit unclear as well, especially when the model is trained without stop action.	B-Review	B-3	Review	295
From the text, the agents receive a positive reward when it is close to the target (within a certain number of steps).	I-Review	I-3	Review	295
Does this mean that the agent gets a positive reward on every step near the target while it's not in the final state?	I-Review	I-3	Review	295
[line_break_token]- This might be a trivial question, but I couldn't find it from the text.	B-Review	B-4	Review	295
Can you find all object from AI2-THOR in the categories of ImageNet and of Visual Genome?	I-Review	I-4	Review	295
is there any information loss while constructing a KG from the classification result?	I-Review	I-4	Review	295
What is the average number of nodes of a KG?	B-Review	B-5	Review	295
and is there any correlation between the size of KG and the result?	I-Review	I-5	Review	295
[line_break_token]- Why are the performances of the models is unstable with Bedroom dataset (in terms of variance)?	B-Review	B-6	Review	295
[line_break_token]- The input feature of GCN is a combination of word feature and image feature.	B-Review	B-7	Review	295
It is clear that there is a corresponding word embedding for each of the identified objects, but it is unclear what is the corresponding image feature.	I-Review	I-7	Review	295
If two objects are identified in the same frame, do input features of these two objects share the same image features from Resnet?	I-Review	I-7	Review	295
[line_break_token][line_break_token][1] Schlichtkrull, Michael, et al "Modeling relational data with graph convolutional networks."	O	O	Review	295
European Semantic Web Conference.	O	O	Review	295
Springer, Cham, 2018.	O	O	Review	295
[line_break_token]	O	O	Review	295
Thank you for the valuable comments and clarifying questions.	O	O	Reply	295
Please find the responses to your questions and comments below.	O	O	Reply	295
[line_break_token][line_break_token]- Have you considered adding explicit relations between entities?	O	O	Reply	295
will it increase the navigation performance?	O	O	Reply	295
if not why?	O	O	Reply	295
[line_break_token][line_break_token]Answer: Yes, we used the explicit relations but it did not improve the results (we briefly mention that towards the end of Section 5.2).	B-Reply	B-1	Reply	295
That is probably due to overfitting since we have few examples for each type of relation.	I-Reply	I-1	Reply	295
[line_break_token][line_break_token]- It is unclear how many objects are used to construct a KG from an image.	O	O	Reply	295
For example, are top-k objects identified by ResNet used to construct a KG?	O	O	Reply	295
[line_break_token][line_break_token]Answer: The number of nodes is fixed and it is not image dependent.	B-Reply	B-2	Reply	295
We are considering 53 objects of THOR so our graph has 53 nodes (Section 5.1).	I-Reply	I-2	Reply	295
[line_break_token][line_break_token]- The agents receive a positive reward when it is close to the target (within a certain number of steps).	O	O	Reply	295
Does this mean that the agent gets a positive reward on every step near the target while it's not in the final state?	O	O	Reply	295
[line_break_token][line_break_token]Answer: In the scenario that we use the termination action, the agent should say ‚Äústop‚Äù when it observes the target object to get the reward.	B-Reply	B-3	Reply	295
Otherwise, it will not receive the reward.	I-Reply	I-3	Reply	295
In the scenario that we do not have the termination action, the agent might receive the positive reward at multiple points since we reward the agent if the target is within the cone of visibility and within 1 meter from the agent.	I-Reply	I-3	Reply	295
Once it receives the reward the episode is finished.	I-Reply	I-3	Reply	295
[line_break_token][line_break_token]- Can you find all object from AI2-THOR in the categories of ImageNet and of Visual Genome?	O	O	Reply	295
is there any information loss while constructing a KG from the classification result?	O	O	Reply	295
[line_break_token][line_break_token]Answer: About half of the object categories are not in ImageNet.	B-Reply	B-4	Reply	295
However, all of them appear in Visual Genome.	I-Reply	I-4	Reply	295
[line_break_token][line_break_token]- What is the average number of nodes of a KG?	O	O	Reply	295
and is there any correlation between the size of KG and the result?	O	O	Reply	295
[line_break_token][line_break_token]Answer: We use 53 nodes.	B-Reply	B-5	Reply	295
In Table 3 of the original submission (Table 4 of the revised version), we show how the performance degrades as we remove nodes and relations from the graph.	I-Reply	I-5	Reply	295
[line_break_token][line_break_token]- Why are the performances of the models is unstable with Bedroom dataset (in terms of variance)?	O	O	Reply	295
[line_break_token][line_break_token]Answer: One run got stuck in a bad local minima and that caused a large variance.	B-Reply	B-6	Reply	295
We have multiple runs with different random initialization.	I-Reply	I-6	Reply	295
[line_break_token][line_break_token]- It is unclear what is the corresponding image feature.	O	O	Reply	295
If two objects are identified in the same frame, do input features of these two objects share the same image features from Resnet?	O	O	Reply	295
[line_break_token][line_break_token]Answer: Yes, that is right.	B-Reply	B-7	Reply	295
We use image-level features (as opposed to object-level features).	I-Reply	I-7	Reply	295
Some of our object categories are novel and unseen so we cannot train supervised detectors for them.	I-Reply	I-7	Reply	295

This paper proposes to detect inputs that are from a slightly shifted distribution (eg images of houses in CA instead of KY) or from a very shifted distribution (eg imagenet images) by fitting a density model to the last layer h(x) of an MLP trained with squared error, and using the likelhiood score p(h(x)) as a metric.	O	O	Review	20356
This is a reasonable idea.	O	O	Review	20356
However, it is not novel eg Aigrain'19 did essentially the same thing for classification models. (	B-Review	B-1	Review	20356
The difference between classification and regression is a trivial change to the loss function, and does not change the fundamental idea.)	I-Review	I-1	Review	20356
[line_break_token][line_break_token]In addition to lack of novelty, the experimental methodology is very weak.	B-Review	B-2	Review	20356
First, the toy 2d example is too trivial to be informative, since there is essentiallly no overlap between the two distributions of features, p(x) and q(x) - even a density model on input space could detect this.	I-Review	I-2	Review	20356
More importantly, the results on the two image datasets are suspect.	I-Review	I-2	Review	20356
First, it seems that using the predictive variance sigma(x) as the reliability metric (the "var" method) - which is totally standard approach known as 'heteroskedastic regression'. -	I-Review	I-2	Review	20356
works very well in several cases.	I-Review	I-2	Review	20356
I suspect when it fails it is due to  implementation problems (eg trying to predict sigma instead of log(sigma)).	I-Review	I-2	Review	20356
Also ensembles are known to be very robust to distribtution shift (see eg Ovadia'19), so  I am surprised at their poor performance.	I-Review	I-2	Review	20356
Another problem is that the datasets used are not standard, so it is impossible to compare to other papers.	B-Review	B-3	Review	20356
Finally, no error bars are reported, so it is hard to know if any of the results are statistically significant.	B-Review	B-4	Review	20356
[line_break_token][line_break_token][line_break_token][line_break_token]J. Aigrain and M. Detyniecki, ‚ÄúDetecting Adversarial Examples and Other Misclassifications in Neural Networks by Introspection,‚Äù in ICML Workshop on Uncertainty and Robustness in Deep Learning, 2019 [Online]. Available: <a href="http://arxiv.org/abs/1905.09186" target="_blank" rel="nofollow">http://arxiv.org/abs/1905.09186</a>[line_break_token][line_break_token][line_break_token]Y. Ovadia et al ‚ÄúCan You Trust Your Model‚Äôs Uncertainty?	O	O	Review	20356
Evaluating Predictive Uncertainty Under Dataset Shift,‚Äù arXiv [stat.	O	O	Review	20356
ML], 06-Jun-2019 [Online]. Available: <a href="http://arxiv.org/abs/1906.02530" target="_blank" rel="nofollow">http://arxiv.org/abs/1906.02530</a>[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Review	20356
.R.T. novelty: Thank you for making us aware of Aigrain et al‚Äôs work.	B-Reply	B-1	Reply	20356
However, we strongly disagree that our proposed method is ‚Äúessentially the same thing.	I-Reply	I-1	Reply	20356
‚Äù Aigrain et al‚Äôs method requires 1) generating adversarial inputs and artificial OOD inputs and 2) trains a neural network (a supervised method) on the logits to identify OOD inputs.	I-Reply	I-1	Reply	20356
Our method on the other hand 1) does not require any OOD inputs at training time (real or artificial) and 2) models the distribution of in-distribution features with a simple Gaussian Mixture Model.	I-Reply	I-1	Reply	20356
We believe that this makes our method substantially different and a novel contribution.	I-Reply	I-1	Reply	20356
[line_break_token][line_break_token]W.R.T. the performance of heteroskedastic regression and ensembles: you note that these baseline methods ‚Äúwork very well in several cases.	B-Reply	B-2	Reply	20356
‚Äù Our experiments indeed confirm this: the ‚Äúvar‚Äù (heteroskedastic) model and the ensemble both achieve an AUROC of &gt;90% on most of our experiments, making these methods strong baselines and not ‚Äúpoor‚Äù performers.	O	O	Reply	20356
At the same time, we do not find it surprising that our proposed method outperforms them.	B-Reply	B-2	Reply	20356
The predicted variance from a heteroskedastic model (which we did in fact parameterize logarithmically) is a reduction of the feature space down to a single dimension.	I-Reply	I-2	Reply	20356
Likewise, an ensemble reduces predictions down to a handful of dimensions (one for each model in the ensemble).	I-Reply	I-2	Reply	20356
These reductions would be prone to the curse of dimensionality argument that we outline in Section 3.	I-Reply	I-2	Reply	20356
Our proposed method on the other hand uses all &gt;1000 dimensions of the feature space to determine if inputs are OOD.	O	O	Reply	20356
[line_break_token][line_break_token]W.R.T the datasets: We chose to focus on image datasets which are the most common datasets for OOD and domain adaptation datasets.	B-Reply	B-3	Reply	20356
This is likely because it is easy to generate images which are ‚Äúout of distribution‚Äù (i.e. use images from an unrelated dataset), whereas it would be more difficult to generate OOD data for e.g. tabular datasets.	I-Reply	I-3	Reply	20356
[line_break_token][line_break_token]We introduced new datasets because we were not aware of any image datasets used for regression.	I-Reply	I-3	Reply	20356
We view this as a contribution in its own right, as future regression-OOD research can utilize these datasets/baselines for evaluation.	I-Reply	I-3	Reply	20356
[line_break_token][line_break_token]W.R.T. error bars: we will update our results table with multiple runs of our experiments	O	O	Reply	20356

[line_break_token][line_break_token]First, I would like to note that the claim that SGD with momentum is a special case of Adam with large epsilon is technically wrong because Adam also includes the bias-corrected momentum estimates which SGD with momentum does not consider.	O	O	Review	20084
It might seem like a small difference, however it is a form of learning rate schedule which most users of Adam are not aware of.	O	O	Review	20084
In practice, however, Adam with large epsilon can approximate SGD with momentum.	O	O	Review	20084
Just don't claim the equivalent since it is not there.	O	O	Review	20084
[line_break_token][line_break_token]I have some difficulties understanding the contribution of the paper.	B-Review	B-1	Review	20084
For example [line_break_token]"When tuning all available metaparameters under a realistic protocol at scales common in deep learning,[line_break_token]we find that more general update rules never underperform their special cases."	I-Review	I-1	Review	20084
[line_break_token]In practice you do adjust hyperparameter search spaces to fit your conclusions, e.g., "We found that searching over (epsilon, alpha0/epsilon) was more efficient than searching over (epsilon, alpha)."	B-Review	B-2	Review	20084
Again, this alone invalidates your experimental setup since you biased it in order to fit your conclusion: "was more efficient" was found after running some prior experiments.	I-Review	I-2	Review	20084
[line_break_token]Another situation where your experimental setup is unfairly tuned is when you used different hyperparameter ranges for similar hyperparameter, e.g. see D.2 for ResNet-32 on CIFAR-10 where 6 orders of magnitute difference was used for the initial learning of Momentum and 3 orders of magnitude difference for the initial learning rate of Adam.	B-Review	B-3	Review	20084
Similarly, there is a difference of 10x for ImageNet experiments.	I-Review	I-3	Review	20084
[line_break_token][line_break_token]The paper suggests that 16 experiments is enough to produce good results.	B-Review	B-4	Review	20084
First, one should not forget the  special arrangements (see above) done for hyperparameter search space.	I-Review	I-4	Review	20084
Second, for any person working in black-box optimization it is clear that 16 experiments is next to nothing.	I-Review	I-4	Review	20084
It should give you something good in 1D, possibly in 2D if your search range is narrow.	I-Review	I-4	Review	20084
This is absolutely nothing in larger dimensions (providing that your benchmark in not super trivial and your hyperparameter search space is not absolutely boring when you already narrowed it around the optimum).	I-Review	I-4	Review	20084
After 16 evaluations you get pretty bad settings for most algorithms.	I-Review	I-4	Review	20084
[line_break_token][line_break_token]Update: [line_break_token][line_break_token]The paper uses a naive hyperparameter optimizer and runs it for a very small budget.	O	O	Review	20084
The latter likely affects the conclusion of the paper that different training algorithms perform similarly.	O	O	Review	20084
The authors seem to accept it by mentioning that this is the case for their tuning protocol/budget.	O	O	Review	20084
[line_break_token][line_break_token]If we would like to compare different training algorithms, we should optimize them on a set of problems using 2-3 state-of-the-art hyperparameter optimizers.	B-Review	B-5	Review	20084
Then, we should study how the best seen solutions so far and their robustness  change as a function of the computation budget (the maximum budget should be large enough).	I-Review	I-5	Review	20084
Then, one would see that the results are not that different for small budgets (a boring result) and somewhat different for larger budgets.	I-Review	I-5	Review	20084
Showing only the boring part seems more misleading than useful.	I-Review	I-5	Review	20084
[line_break_token][line_break_token]Update#2:[line_break_token]As I mentioned in my review, Adam with large epsilon is not equivalent to momentum SGD but only approximates the latter.	B-Review	B-6	Review	20084
This is because the original Adam has a bias correction term and even if the same *global* learning rate schedule is used both for Adam with large epsilon and momentum SGD, they are not equivalent.	I-Review	I-6	Review	20084
In order to obtain the exact equivalence, one would need to either[line_break_token]1) drop the bias correction term of Adam and thus modify the algorithm in order to satisfy the claimed equivalence[line_break_token]or [line_break_token]2) set a particular learning rate *for each batch pass* of Adam to simulate the effect of the bias correction term, this leads to a large number of hyperparameters - as many as the number of batch passes, this is intractable (the setup of the authors does not optimize such batch-wise hyperparameters, they are defined by a global scheduler as a function of batch/epoch index).	I-Review	I-6	Review	20084
 [line_break_token]If you avoid these modifications, then you can't claim the equivalence but only an approximation.	I-Review	I-6	Review	20084
If you don't have the equivalence of the two approaches and so momentum SGD is not a particular case of Adam, then the following sentence from the abstract is false: " As tuning effort grows without bound, more general optimizers should never underperform the ones they can approximate (i.e., Adam should never perform worse than momentum)".	I-Review	I-6	Review	20084
Again, strictly speaking, it is false that "Adam should never perform worse than momentum" because momentum SGD is not a particular case of the original Adam *unless* you drop the bias correction term or simulate it with tons of hyperparameters, one learning rate value per batch pass.	I-Review	I-6	Review	20084
Any global learning rate schedule *used for both* algorithms will not solve the issue because the bias correction term will remain.	I-Review	I-6	Review	20084
If you don't modify the learning rate schedule of Adam but only of momentum SGD, then you basically adjust your SGD by moving some part of Adam in it to claim the equivalence of the two, such actions can make pretty much every second algorithm equivalent to another.	I-Review	I-6	Review	20084
[line_break_token][line_break_token]My main concern is described in the first Update.	O	O	Review	20084
It is trivial that a more general optimizer is capable to perform at least as good as its particular case.	B-Review	B-5	Review	20084
What is not trivial is to clarify the interplay of computational budgets spent on hyperparameter tuning vs number of hyperparameters vs performance over time.	I-Review	I-5	Review	20084
o facilitate discussion, we have responded to the three paragraphs of review 1 in separate threads.	O	O	Reply	20084
The 2nd paragraph seems to contain the reviewer‚Äôs primary concerns, so we focus on that first.	O	O	Reply	20084
Our latest revision should resolve the other issues mentioned by the review.	O	O	Reply	20084
[line_break_token][line_break_token]- - - Summary - - - [line_break_token][line_break_token]1.	O	O	Reply	20084
We do not think the concerns raised in the 2nd paragraph are reasonable, nor is it reasonable to accuse us of acting in bad faith after we exceeded the standards of transparency and care in the literature (e.g. by reporting preliminary search spaces as well as final ones).	B-Reply	B-1	Reply	20084
[line_break_token][line_break_token]2.	O	O	Reply	20084
The reviewer was concerned that search spaces with nominally larger learning rate ranges for SGD and Momentum might be unfair relative to Adam, even though Adam faces a higher dimensional search problem.	B-Reply	B-3	Reply	20084
[line_break_token]‚óè Although part of the point of our work is that we don't think any search spaces are completely fair, we do not think our original search spaces were unreasonable or biased our conclusions.	I-Reply	I-3	Reply	20084
Nevertheless, we ran additional experiments on CIFAR10 designed to, if anything, give non-adaptive optimizers an advantage and confirmed that using the "same" ranges wouldn't change our conclusions.	I-Reply	I-3	Reply	20084
[line_break_token][line_break_token]3.	O	O	Reply	20084
The reviewer was concerned that because we decided to search (epsilon, alpha0/epsilon) instead of searching (epsilon, alpha), we somehow unfairly penalized the non-adaptive optimizers because the former parameterization of the search space is more efficient for Adam in our experience.	B-Reply	B-2	Reply	20084
[line_break_token]‚óè Our choice here is akin to log-transforming 1-momentum when tuning Momentum or log transforming learning rate.	I-Reply	I-2	Reply	20084
Only the adaptive optimizers *have* an epsilon parameter that needs to be searched, so this cannot be unfair to SGD or Momentum since they already benefit from not having to tune the hyperparameter at all.	I-Reply	I-2	Reply	20084
[line_break_token][line_break_token]- - - Full response - - - [line_break_token][line_break_token]One of the central points of our paper is that any empirical comparison of optimizers depends on the tuning protocol.	B-Reply	B-4	Reply	20084
No protocol we are aware of can guarantee fairness between optimizers with incommensurate search spaces -- and yet, empirical optimizer comparisons are crucial for developing new optimizers and guiding practitioners training neural networks.	I-Reply	I-4	Reply	20084
To our knowledge, no other study has highlighted how these comparisons are sensitive to the tuning protocol and which hyperparameters are tuned.	I-Reply	I-4	Reply	20084
Regarding our own results, we make clear in Section 5 that we should only expect our detailed findings to hold for similar workloads under similar protocols.	I-Reply	I-4	Reply	20084
[line_break_token][line_break_token]Although it is always difficult to guarantee fairness when tuning over optimizers with incommensurate search spaces, this is still true for protocols that attempt to use the "same" search space for Adam and Momentum (Adam‚Äôs learning rate parameter is more closely related to (learning rate)/(1 - momentum), so the optimal ranges are almost always different between the two optimizers).	I-Reply	I-4	Reply	20084
Why should practitioners tie one hand behind their backs and only search a set of alpha values when tuning Adam that are the same as the set of learning rate values they search when tuning SGD?	I-Reply	I-4	Reply	20084
Given the importance of tuning protocols, practitioners must decide which protocol most closely captures their own when deciding which optimizer comparison is most relevant to them.	I-Reply	I-4	Reply	20084
Since our protocol produces results that exceed the performance from other optimizer comparisons in most cases (see Figures 3 and 4), we expect that readers will prefer using something similar to our tuning protocol.	I-Reply	I-4	Reply	20084
[line_break_token][line_break_token]In light of reviewer 1‚Äôs concerns about our CIFAR-10 experiments, and to further support our claim that all optimizers were well tuned, we ran additional experiments with ResNet-32 on CIFAR-10.	I-Reply	I-4	Reply	20084
We ran an experiment with SGD, Momentum, and Nesterov with a search space where all learning rate and momentum ranges had the same width as the ranges for Adam's similar hyperparameters (ignoring that they are not necessarily the same units).	I-Reply	I-4	Reply	20084
We centered these new ranges on the best points from the original search, making the new comparison, if anything, unfair to the adaptive methods.	I-Reply	I-4	Reply	20084
Although further narrowing the search space about the best validation error reduces the mean validation error, our conclusions do not change from what was reported in the paper.	I-Reply	I-4	Reply	20084
Taking the process yet further, we doubled the trial budget for all optimizers and re-ran these equal-width-search-space experiments.	I-Reply	I-4	Reply	20084
Again, although the best validation error improved slightly for all optimizers, test error did not change much, and we see no clear evidence that the inclusion relationships are violated.	I-Reply	I-4	Reply	20084
See imgur.com/a/j38e1HP.	I-Reply	I-4	Reply	20084
[line_break_token][line_break_token]Ultimately, it is extremely difficult to judge whether one of two incommensurate search spaces provides some sort of advantage -- again, a key point in our paper -- but we firmly believe our results are robust and that our protocol did not unrealistically bias our conclusions in favor of any one optimizer over another	I-Reply	I-4	Reply	20084

This paper presents a JavaScript framework including WebCL components for training and deploying deep neural networks.	O	O	Review	398
The authors show that it is possible to reach competitive speeds with this technology, even higher speed than a compiled application with ViennaCL on AMD GPUs.	O	O	Review	398
While remaining a little more than factor three slower than compiled high performance software on NVIDIA GPUs, it offers compelling possibilities for easily deployable training and application settings for deep learning.	O	O	Review	398
[line_break_token][line_break_token]My main points of criticism are:[line_break_token]1.	O	O	Review	398
In Tab.	B-Review	B-1	Review	398
4 different batch sizes are used.	I-Review	I-1	Review	398
Even if this is due to technical limits for the Javascript library, it would only be fair to use the smaller batch sizes for the other frameworks as well (on the GPUs probably in favor of the presented framework).	I-Review	I-1	Review	398
[line_break_token][line_break_token]2.	O	O	Review	398
In Fig.	B-Review	B-2	Review	398
6, why not include more information in the graphs?	I-Review	I-2	Review	398
Especially, as stated in the question, why not include the node.js values?	I-Review	I-2	Review	398
While I do see the possible application with one server and many "low performance" clients, the setting of having a few dedicated high performance servers is quite likely.	I-Review	I-2	Review	398
Even if not, these are good values to compare with.	I-Review	I-2	Review	398
For the sake of consistency, please include in both subfigures Firefox, Chrome, node.js.	I-Review	I-2	Review	398
[line_break_token][line_break_token]Apart from these points, well-written, understandable and conclusive.	O	O	Review	398
Thank you for the review.	O	O	Reply	398
[line_break_token]In Table 4 (speed comparison between our system and Caffe using single computer), we measured the speed with same batch size for all software and updated the table.	B-Reply	B-1	Reply	398
[line_break_token]In Figure 6 (speed of distributed computing), we experimented with the situation in which node.js is the computing client as well as Firefox and updated the chart	B-Reply	B-2	Reply	398

This paper is about a self-supervised video representation with a multi-modal learning process that the authors then use for performance on a variety of tasks.	O	O	Review	20381
The main contribution of the paper is a successful effort to incorporate BERT-like models into vision tasks.	O	O	Review	20381
As is detailed in the related work, the field has been inching towards this but without as much success as this paper has.	O	O	Review	20381
[line_break_token][line_break_token]My main criticism of the paper is that it feels like there is everything and a bag of chips happening; It's exceptionally hard to tease apart what is the main contribution to its success.	B-Review	B-1	Review	20381
I mostly came away from the paper thinking that it was good to see an existence proof of successfully incorporating the result, but not having really understood anything more wrt why or how this works.	I-Review	I-1	Review	20381
Other than it being a good idea to have a bigger model and more varied types of gradients, it's unclear what this model does that distinguishes it from other approaches.	I-Review	I-1	Review	20381
[line_break_token][line_break_token]On a more specific critique level, why use COIN?	B-Review	B-2	Review	20381
And why compare on a frame accuracy metric?	I-Review	I-2	Review	20381
The comparison to Ding &amp; Xu seems a bit odd given that they don't assume access to annotations but rather to video transcripts.	O	O	Review	20381
There are other datasets that you could make use of here that are more applicable, like Thumos14 or ActivityNet.	B-Review	B-2	Review	20381
I understand that this is a small section, but arguably the paper would be stronger if more time was spent on the main result than on this sidebar.	I-Review	I-2	Review	20381
[line_break_token][line_break_token]Overall, I'm giving it a weak accept because I do think that the community should be aware of this paper's result.	O	O	Review	20381
hank you for your positive feedback!	O	O	Reply	20381
[line_break_token][line_break_token]In the following we summarize our main contributions: [line_break_token]1.	O	O	Reply	20381
CBT objective for self-supervised visual representation learning.	B-Reply	B-1	Reply	20381
We study the impact of the CBT objective, which uses long temporal information as self-supervision, in Table 1.	I-Reply	I-1	Reply	20381
We observe that CBT outperforms alternative training objectives based on local spatial (3DRotNet) and temporal (Shuffle&amp;Learn) objectives significantly, when they were pre-trained on the same Kinetics data with the same backbone ConvNet (Table 1 left).	O	O	Reply	20381
Our CBT method also outperforms the state of the art (Table 1 right).	B-Reply	B-1	Reply	20381
[line_break_token][line_break_token]2.	O	O	Reply	20381
CBT and cross-modal objectives for temporal representation learning.	B-Reply	B-1	Reply	20381
In Table 2 (left) and Table 4 (left) we compare our method with VideoBERT, which applies vector quantization on visual features.	I-Reply	I-1	Reply	20381
We found CBT outperforms VideoBERT significantly.	I-Reply	I-1	Reply	20381
In Table 3 (left), we observe that the cross-modal objective further improves the performance on action anticipation tasks.	I-Reply	I-1	Reply	20381
[line_break_token][line_break_token]Choice of datasets:[line_break_token][line_break_token]The action segmentation accuracy metric, along with the baselines we compare with, were quoted from Table 3 of the COIN dataset paper.	B-Reply	B-2	Reply	20381
We note that their fully-supervised baseline (Tang et al 2019) performed worse than the weakly-supervised baseline (Ding &amp; Xu 2018).	O	O	Reply	20381
We will make the supervision type clear in the final version.	B-Reply	B-2	Reply	20381
[line_break_token]Besides the COIN dataset, we do provide ActivityNet evaluations in Table 2&amp;3, along with other benchmarks such as HMDB (Table 1), UCF (Table 1), Breakfast (Table 2&amp;3) and YouCook (Table 4).	O	O	Reply	20381
This range of datasets helps us understand the performance of CBT in diverse visual domains.	B-Reply	B-2	Reply	20381

# Summary[line_break_token][line_break_token]This submission proposes a method to combine the benefits of model-based RL and Imitation Learning (IL) for navigation tasks.	O	O	Review	1381
The key idea is to i) learn a prior over trajectory distributions from a fixed dataset of demonstrations, and ii) use this learned dynamical model for path planning via probabilistic inference.	O	O	Review	1381
Reaching target waypoints is done by maximizing the trajectory likelihood conditioned on the planning goal.	O	O	Review	1381
The prior is learned using R2P2 on LIDAR features and past positions.	O	O	Review	1381
Experiments using the CARLA driving simulator show that this method can outperform standard control, IL, and model-based RL baselines, while flexibly incorporating test-time goals and costs thanks to its probabilistic formulation.	O	O	Review	1381
[line_break_token][line_break_token][line_break_token]# Strengths[line_break_token][line_break_token]The method is an elegant way to get the best of both worlds in RL and IL, leveraging the recent R2P2 work to estimate a powerful sequential model used for planning via probabilistic inference.	O	O	Review	1381
The flexibility of the method in considering test-time cost maps and user-defined goals (e.g. to avoid potholes) is appealing, especially since it does not require on-policy data collection.	O	O	Review	1381
[line_break_token][line_break_token]The proposed planning-as-inference method can in theory handle the multi-modality present in human demonstrations by using a probabilistic model of the observed behaviors as prior over undirected expert trajectories.	O	O	Review	1381
[line_break_token][line_break_token]The approach seem to outperform both model-based and imitation learning baselines on a simplified version of the CARLA benchmark, including on interesting fine-grained metrics (e.g., comfort based).	O	O	Review	1381
[line_break_token][line_break_token][line_break_token]# Weaknesses[line_break_token][line_break_token]The main weakness of this submission lies in its experimental evaluation, especially the absence of any dynamic objects in the tested environment ("static world CARLA", section 1).	B-Review	B-1	Review	1381
It is unclear how this approach would generalize beyond just staying on the road.	I-Review	I-1	Review	1381
How would it handle traffic lights, pedestrians, other drivers, weather variations, and more complex driving tasks than waypoint following by traversing mostly free space?	I-Review	I-1	Review	1381
How does the prior generalize to more complex behaviors (e.g, by using more contextual information \phi)?	I-Review	I-1	Review	1381
How robust is the method to noise in the demonstrations, i.e. non-expert or suboptimal behavior?	I-Review	I-1	Review	1381
It seems that estimating the generative prior on human behavior might suffer from the same issues as behavior cloning, e.g., the sample inefficiency due to the combinatorial explosion of causal factors explaining complex human behaviors.	I-Review	I-1	Review	1381
It might be in fact even harder to estimate that generative model than use a direct discriminative approach (e.g., a modular pipeline), at the cost of reduced flexibility at test time of course.	I-Review	I-1	Review	1381
The currently reported sample efficiency (7000 training samples) and near perfect success rate seem to suggest that this (non-standard) version of the CARLA benchmark is too simple (no weather variations, no dynamic obstacles).	I-Review	I-1	Review	1381
Comparison to the state of the art (beyond the baselines implemented here) on the original CARLA benchmark seems needed (especially in the "Nav.	I-Review	I-1	Review	1381
dynamic" task).	I-Review	I-1	Review	1381
[line_break_token][line_break_token]The method is only described very succinctly in section 2.	B-Review	B-2	Review	1381
I do not believe there are enough details (especially around the learning algorithm, hyper-parameters, and other important technical elements) for reproducibility at this stage.	I-Review	I-2	Review	1381
Section 2.1 is also quite dense for people not familiar with the R2P2 paper.	I-Review	I-2	Review	1381
As the main contribution of the paper is to leverage that model for planning and control, it would be great to maybe discuss a bit deeper.	I-Review	I-2	Review	1381
Finally, the input modalities are not clear, especially for the baselines: the proposed method is using LIDAR and localization whereas the IL baseline seems to use vision (while the others just use the trajectory).	I-Review	I-2	Review	1381
This makes the fairness of the comparison really unclear (LIDAR is a much stronger signal for just staying on the road).	I-Review	I-2	Review	1381
[line_break_token][line_break_token]Minor remarks:[line_break_token]- Why use a proportional controller as a baseline instead of the standard PID one?	B-Review	B-3	Review	1381
[line_break_token]- Section 2.3 seems like it's missing the extension of equation 2 to the multi-goal case?	B-Review	B-4	Review	1381
[line_break_token]- Typos in section 3 ("trail-and-error"), section 4 ("autonmous", "knowledge to")[line_break_token][line_break_token][line_break_token]# Recommendation[line_break_token][line_break_token]Although the theoretical benefits of the method are well-motivated and clear (off-policy learning, probabilistic model, flexibility at test time), the experimental evaluation (custom simple CARLA test, unclear comparison to baselines) and lack of details impeding reproducibility seems to suggest that this submission needs a bit more work.	B-Review	B-5	Review	1381
First, adding more details as suggested above and clarifying the experimental protocol seem like a must, but can be easily addressed by an update to the text.	O	O	Review	1381
Second, it would be ideal to evaluate the approach on the standard CARLA benchmark in order to compare fairly to the prior art.	O	O	Review	1381
This is much more involved.	O	O	Review	1381
[line_break_token][line_break_token]I personally like the approach, so although I think it is marginally below the acceptance threshold in its current form, I reserve my judgement for the time being and look forward to the authors' reply.	O	O	Review	1381
[line_break_token][line_break_token][line_break_token]# Update[line_break_token][line_break_token]The submission has been drastically rewritten (the diff is massive) and I think it is in much better shape, answering some of my concerns around reproducibility and generalization.	O	O	Review	1381
Furthermore, it reinforces the strengths of the approach (esp.	O	O	Review	1381
around its flexibility).	O	O	Review	1381
[line_break_token][line_break_token]I am willing to recommend acceptance, but I have some further questions (hence I have only updated my score to a 6 for now).	O	O	Review	1381
They are mostly related to the comparison with IL (important to validate the claim in the paper that the proposed approach is quantitatively better than both existing IL and RL methods).	O	O	Review	1381
See discussion below for details.	O	O	Review	1381
Thank you for your helpful feedback.	O	O	Reply	1381
[line_break_token][line_break_token]Q1: ‚ÄúUnclear how this approach would generalize beyond just staying on the road‚Äù[line_break_token]We agree that there are more sophisticated settings that could be used to test different generalization aspects of our method.	B-Reply	B-1	Reply	1381
In theory, expert behaviors could be modelled in such settings by including the relevant information in the context, as noted by the reviewer.	I-Reply	I-1	Reply	1381
However, we designed our original experiments to reduce the number of uncontrolled variables, in order to clearly isolate the benefits of our approach.	I-Reply	I-1	Reply	1381
In order to test other generalization capabilities, we have since conducted additional experiments in several settings: obstacles in the road that were unseen in the demonstrations (i.e. simulated potholes), and noise in the waypoints provided to the controller, which could occur in a real-world setting due to noisy localization.	I-Reply	I-1	Reply	1381
In the pothole experiment, we found that our model was able to navigate around simulated potholes by including them in the cost map, and compared it to our model that was not provided with a cost map of the potholes.	I-Reply	I-1	Reply	1381
This navigation demands the model generalize its planning to situations not observed in the training data, specifically, when the car must partially enter the opposing lane in order to avoid the obstacle.	I-Reply	I-1	Reply	1381
In the noisy waypoint experiment, we tested two different types of noise: high bias, low variance noise, and low bias, high variance noise.	I-Reply	I-1	Reply	1381
In the high variance setting, ‚Äúdecoy‚Äù waypoints are added to the set of possible waypoints.	I-Reply	I-1	Reply	1381
The decoys are obtained by significantly perturbing the original waypoints with Gaussian noise, sigma=8 meters.	I-Reply	I-1	Reply	1381
Successful navigation in this setting required the model‚Äôs ability to score its plans by  likeliest under the estimated expert‚Äôs distribution of behavior.	I-Reply	I-1	Reply	1381
In the high bias setting, all waypoints were provided on the wrong side of the road, which is modelled with a small amount of observation noise.	I-Reply	I-1	Reply	1381
We found that these waypoints were still sufficient to communicate high-level navigation directions, and that the model usually produced plans on the correct side of the road (where all expert demonstrations occurred).	I-Reply	I-1	Reply	1381
Please see the updated results for quantitative (Tables 2, 3) and qualitative comparisons (Figures 7, 8).	I-Reply	I-1	Reply	1381
[line_break_token][line_break_token]Q2: ‚ÄúComparison to the state of the art (beyond the baselines implemented here) seems needed‚Äù[line_break_token]A2: Our problem motivation is, instead, that of completely offline learning, but state-of-the-art CARLA results require trial-and-error based data collection online (Codevilla, et al 2018).	I-Reply	I-1	Reply	1381
Additionally, navigation performance isn‚Äôt the sole goal of our method; we also show that our model has flexibility to different test-time queries that require behavior not seen in the training data.	I-Reply	I-1	Reply	1381
However, we have since implemented the ‚Äúbranched‚Äù architecture of Codevilla, et al 2018, and trained it with the same inputs and data used to train our method.	I-Reply	I-1	Reply	1381
 We found this approach to slightly outperform the original IL baseline we included in our paper, but underperform the MBRL comparison and our proposed method.	I-Reply	I-1	Reply	1381
Please see the updated results for our quantitative comparison (Table 1).	I-Reply	I-1	Reply	1381
[line_break_token][line_break_token]Q3: ‚ÄúThe method is only described very succinctly in section 2‚Äù[line_break_token]We have included many more details about the method and the implementation in our updated version.	B-Reply	B-2	Reply	1381
Please see Section 2, and Section 2.2 in particular.	I-Reply	I-2	Reply	1381
[line_break_token][line_break_token]Q4: ‚Äúthe input modalities are not clear, especially for the baselines‚Äù[line_break_token]The input modalities are identical for all methods: they all receive the same waypoints, and observe the same LIDAR and past trajectory.	I-Reply	I-2	Reply	1381
We clarified this in the updated paper.	I-Reply	I-2	Reply	1381
[line_break_token][line_break_token]Q5: ‚ÄúWhy use a proportional controller as a baseline instead of the standard PID one?	O	O	Reply	1381
[line_break_token]We tested added I+D terms, replacing the P-controller with a PID controller, and found no significant change -- the PID controller fundamentally cannot handle faraway waypoints.	B-Reply	B-3	Reply	1381
[line_break_token][line_break_token]Q6: ‚ÄúSection 2.3 seems like it's missing the extension of equation 2 to the multi-goal case?‚Äù[line_break_token]We have generalized the mathematical explanation, from which all of our inference procedures can be derived.	B-Reply	B-4	Reply	1381
This includes the multigoal case, in Section 2.1 in the updated version.	I-Reply	I-4	Reply	1381
Additionally, we‚Äôve included a qualitative demonstration of planning to sequential multi-goals (Figure 3).	I-Reply	I-4	Reply	1381

This paper tries to improve exploration performed by alphazero in a game of tic-tac-toe using MCTS.	O	O	Review	10220
The paper proposes to use master game tree (which is MCTS as well) to control the generation of episodes when solving a game using MCTS.	O	O	Review	10220
[line_break_token]This is a clear case of less than half-baked paper.	B-Review	B-1	Review	10220
The paper does not cite any previous research (no references) and is poorly written.	I-Review	I-1	Review	10220
I believe this is sufficient ground for not recommending accept.	I-Review	I-1	Review	10220
I would suggest the authors to re-submit when the paper is complete, maybe, start with related work and references.	I-Review	I-1	Review	10220
hank you deeply for your reviewing my paper.	O	O	Reply	10220
[line_break_token]I didn't know how to use .bib file, then I had no choice but to remove all references.	B-Reply	B-1	Reply	10220
[line_break_token]I would like to improve my paper writing skills and to do more research on this topic	I-Reply	I-1	Reply	10220

The paper proposes new bounds on the misclassification error.	O	O	Review	348
The bounds lead to training classifiers with an adaptive loss function, and the algorithm operates in successive steps: the parameters are trained by minimizing the log-loss weighted by the probability of the observed class as given by the parameters of the previous steps.	O	O	Review	348
The bound improves on standard log-likelihood when outliers/underfitting prevents the learning algorithm to properly optimize the true classification error.	O	O	Review	348
Experiments are performed to confirm the therotical intuition and motivation.	O	O	Review	348
They show different cases where the new algorithm leads to improved classification error because underfitting occurs when using standard log-loss, and other cases where the new bounds do not lead to any improvement because the log-loss is sufficient to fit the dataset.	O	O	Review	348
[line_break_token][line_break_token]The paper also discusses the relationship between the proposed idea and reinforcement learning, as well as with classifiers that have an "uncertain" label.	O	O	Review	348
[line_break_token][line_break_token]While the paper is easy to read and well-written overall, in a second read I found it difficult to fully understand because two problems are somewhat mixed together (here considering only binary classification for simplicity): [line_break_token](a) the optimization of the classification error of a *randomized* classifier, which predicts 1 with probability P(1|x, theta), and [line_break_token](b) the optimization of the deterministic classifier, which predicts sign(P(1|x, theta) - 0.5), in a way that is robust to outliers/underfitting.	B-Review	B-1	Review	348
[line_break_token][line_break_token]The reason why I am confused is that "The standard approach to supervised classification", as is mentioned in the abstract, is to use deterministic classifiers at test time, and the log-loss (up to constants) is an upper bound on the classification error of the deterministic classifier.	B-Review	B-3	Review	348
However, the bounds discussed in the paper only concern the randomized classifier.	I-Review	I-3	Review	348
[line_break_token][line_break_token]=== question:[line_break_token]In the experiments, what kind of classifier is used?	B-Review	B-4	Review	348
The randomized one (as would the sentence in the first page suggest "Assuming the class is chosen according to p(y|X, Œ∏)"), or the more standard deterministic classifier argmax_y P(y|x, theta) ?	I-Review	I-4	Review	348
[line_break_token][line_break_token]As far as I can see, there are two cases: either (i) the paper deals with learning randomized classifiers, in which case it should compare the performances with the deterministic counterparts that people use in practice, or (ii) the paper makes sense as soon as we accept that the optimization of criterion (a) is a good surrogate for (b).	B-Review	B-5	Review	348
In both cases,  I think the write-up should be made clearer (because in case (ii) the algorithm does not minimize an upper bound on the classification error, and in case (i) what is done does not correspond to what is usually done in binary classification).	I-Review	I-5	Review	348
[line_break_token][line_break_token]=== comments:[line_break_token]- The section "allowing uncertainty in the decision" may be improved by adding some references, e.g. Bartlett & Wegkamp (2008) "Classification with a Reject Option using a Hinge Loss" or Sayedi et al (2010) "Trading off Mistakes and Don‚Äôt Know Predictions".	O	O	Review	348
[line_break_token][line_break_token]- there seems to be a "-" sign missing in the P(1|x, theta) in L(theta, lambda) in Section 3.	B-Review	B-7	Review	348
[line_break_token][line_break_token]- The idea presented in the paper is interesting and original.	B-Review	B-8	Review	348
While I give a relatively low score for now, I am willing to increase this score if the clarifications are made.	I-Review	I-8	Review	348
[line_break_token][line_break_token]Final comments:[line_break_token]I think the paper is clear enough in its current form, even though there should still be improvement in the justification of why and to what extent the error of the randomized classifier is a good surrogate for the error of the true classifier.	B-Review	B-9	Review	348
While the "smoothed" version of the 0/1 loss is an acceptable explanation in the standard classification setup, it is less clear in the section dealing with an additional "uncertain" label.	I-Review	I-9	Review	348
I increase my score from 5 to 6.	O	O	Review	348
Thank you for your review and comments.	O	O	Reply	348
I apologize if some parts were unclear and will modify the paper accordingly.	O	O	Reply	348
[line_break_token][line_break_token]- In the experiments, the deterministic classifier is used.	O	O	Reply	348
Interestingly, in the iterative scheme, the randomized classifier converges to the deterministic one, something which is not true in general.	O	O	Reply	348
[line_break_token][line_break_token]You are right that, in the deterministic case (the one studied), the algorithm does not minimize an upper bound on the classification error but rather an upper bound on a smooth version of that error (replacing the step function with a sigmoid).	B-Reply	B-1	Reply	348
I will make this clearer.	I-Reply	I-1	Reply	348
[line_break_token][line_break_token]I will also read your additional references and update the paper accordingly.	O	O	Reply	348
[line_break_token][line_break_token]I hope this clarifies any misunderstandings you might have had	O	O	Reply	348

Summary: [line_break_token]Training RNNs on long-sequences is a challenging task as gradients tend to explode or vanish.	O	O	Review	1477
One way to mitigate this problem to some extent is to use semi-supervised learning in which objective function consists of unsupervised and supervised loss functions.	O	O	Review	1477
Even though the contribution of unsupervised loss function can be controlled by a coefficient in the objective function, the unsupervised loss term can cause important information about the supervised task to be degraded or erased.	O	O	Review	1477
This paper proposed a method to mitigate the problem of training of RNNs on long sequences by coordinating supervised and unsupervised loss functions.	O	O	Review	1477
More specifically, they use two RNNs in which RNNs have a shared feature space for both supervised and unsupervised tasks and allow one of RNN to have a private space dedicated for the supervised task.	O	O	Review	1477
[line_break_token][line_break_token]Strengths:[line_break_token]+ The idea of dividing the hidden states into two parts is interesting as it helps the model to control the effect of unsupervised loss on main supervised task.	O	O	Review	1477
[line_break_token]+ Shared and private spaces visualization are very informative.	O	O	Review	1477
[line_break_token]+ This model shows better results on MNIST and CIFAR-10 in compared with previous methods.	O	O	Review	1477
[line_break_token]Weaknesses:[line_break_token]- Paper writing is good until section 3.1.	B-Review	B-1	Review	1477
This section is very confusing.	I-Review	I-1	Review	1477
I read it multiple times until understood what is happening.	I-Review	I-1	Review	1477
Lots of details are missing in sections 3.2 about how this model forces to not mix up the gradients for shared and private hidden units.	I-Review	I-1	Review	1477
[line_break_token]- There are quite similarities between Trinh et al 2018 and this paper.	B-Review	B-2	Review	1477
The only main difference is dividing the hidden state into shared and private ones.	I-Review	I-2	Review	1477
[line_break_token]- Is there any reason why StanfordDogs and DBpedia are not used in this paper?	B-Review	B-3	Review	1477
Given the close relationship between Trinh et al 2018 and this paper, it would have been better to have some results for these sets.	I-Review	I-3	Review	1477
[line_break_token]- The paper claims that their model trains and evaluates faster.	B-Review	B-4	Review	1477
Rather than an argument about fewer parameters for auxiliary tasks, I don't see any justification.	I-Review	I-4	Review	1477
Fewer parameters don't necessarily lead to faster training or test time.	I-Review	I-4	Review	1477
[line_break_token][line_break_token]Comments and Questions[line_break_token]- Is vanilla RNN used for the experiments?	B-Review	B-5	Review	1477
GRU is mentioned but my understanding is that it is only used for auxiliary loss.	I-Review	I-5	Review	1477
[line_break_token]- There should be some detail about model architectures and training e.g. hidden units size, learning rate, dropout if any, etc.	B-Review	B-6	Review	1477
[line_break_token]- It mentions that the model uses different time-scale updating operations of distinct RNNs with different representational spaces, I don't see how.	B-Review	B-7	Review	1477
Can you elaborate?	I-Review	I-7	Review	1477
[line_break_token]	O	O	Review	1477
We thank the reviewer for taking the time to read our paper in detail, and for providing such extensive comments.	O	O	Reply	1477
We respond to each of the reviewer‚Äôs points below:[line_break_token][line_break_token]> Is there any reason why StanfordDogs and DBpedia are not used in this paper?	O	O	Reply	1477
Given the close relationship between Trinh et al 2018 and this paper, it would have been better to have some results for these sets.	O	O	Reply	1477
[line_break_token][line_break_token]Due to some difficulties of preprocessing, we instead use IMDB dataset.	B-Reply	B-3	Reply	1477
However, we test the baseline methods on the new dataset.	I-Reply	I-3	Reply	1477
[line_break_token][line_break_token]> Is vanilla RNN used for the experiments?	O	O	Reply	1477
GRU is mentioned but my understanding is that it is only used for auxiliary loss.	O	O	Reply	1477
[line_break_token][line_break_token]We should have made it more clear: all RNNs used in experiments are GRUs.	B-Reply	B-5	Reply	1477
[line_break_token][line_break_token]> There should be some detail about model architectures and training e.g. hidden units size, learning rate, dropout if any, etc.	O	O	Reply	1477
[line_break_token][line_break_token]We will include them in the future version.	B-Reply	B-6	Reply	1477

[line_break_token]In this paper, the authors proposed an interesting algorithm for learning the l1-SVM and the Fourier represented kernel together.	O	O	Review	309
The model extends kernel alignment with random feature dual representation and incorporates it into l1-SVM optimization problem.	O	O	Review	309
They proposed algorithms based on online learning in which the Langevin dynamics is utilized to handle the nonconvexity.	O	O	Review	309
Under some conditions about the quality of the solution to the nonconvex optimization, they provide the convergence and the sample complexity.	O	O	Review	309
Empirically, they show the performances are better than random feature and the LKRF.	O	O	Review	309
[line_break_token][line_break_token]I like the way they handle the nonconvexity component of the model.	O	O	Review	309
However, there are several issues need to be addressed.	O	O	Review	309
[line_break_token][line_break_token]1, In Eq. (	B-Review	B-1	Review	309
6), although due to the convex-concave either min-max or max-min are equivalent, such claim should be explained explicitly.	I-Review	I-1	Review	309
[line_break_token][line_break_token]2, In the paper, there is an assumption about the peak of random feature "it is a natural assumption on realistic data that the largest peaks are close to the origin".	B-Review	B-2	Review	309
I was wondering where this assumption is used?	I-Review	I-2	Review	309
Could you please provide more justification for such assumption?	I-Review	I-2	Review	309
[line_break_token][line_break_token]3, Although the proof of the algorithm relies on the online learning regret bound, the algorithm itself requires visit all the data in each update, and thus, it is not suitable for online learning.	B-Review	B-3	Review	309
Please clarify this in the paper explicitly.	I-Review	I-3	Review	309
[line_break_token][line_break_token]4, The experiment is weak.	B-Review	B-4	Review	309
The algorithm is closely related to boosting and MKL, while there is no such comparison.	I-Review	I-4	Review	309
Meanwhile, Since the proposed algorithm requires extra optimization w.r.t.	I-Review	I-4	Review	309
random feature, it is more convincing to include the empirical runtime comparison.	I-Review	I-4	Review	309
[line_break_token][line_break_token]Suggestion: it will be better if the author discusses some other model besides l1-SVM with such kernel learning.	B-Review	B-5	Review	309
[line_break_token]	O	O	Review	309
[line_break_token]@1: We mention the minimax theorem in the proof, in the appendix.	B-Reply	B-1	Reply	309
We can add a brief clarification in the main paper.	I-Reply	I-1	Reply	309
[line_break_token][line_break_token]@2: The only assumption (for the theorems to hold) is that Algorithm 1 finds an eps-approximate global maximum.	B-Reply	B-2	Reply	309
Our discussion on band-limitedness of real-world data is simply to argue that this non-convex problem is plausibly easy on realistic optimization landscapes: low-frequency features (on the same scale as the RBF bandwidth parameter; see Appendix A.1) are informative.	I-Reply	I-2	Reply	309
[line_break_token][line_break_token]@3: That‚Äôs correct, just as in boosting.	B-Reply	B-3	Reply	309
We are happy to find a way to further emphasize the distinction, to reduce confusion.	I-Reply	I-3	Reply	309
[line_break_token][line_break_token]@4:[line_break_token]- As mentioned in the paper, MKL methods take >100 times longer on datasets as large as CIFAR-10.	O	O	Reply	309
[line_break_token]- Unlike the selling point of methods such as LKRF and Quasi-Monte Carlo, our method has much greater expressivity (thus evidently saturates at a much higher accuracy).	B-Reply	B-4	Reply	309
Hence, the value of a quantitative wall clock time comparison is unclear.	I-Reply	I-4	Reply	309
We believe that the existing discussion (primal like RF; parallelizable; reasonable wall clock time in practice) suffices to address qualitative questions on efficiency as compared to other paradigms.	I-Reply	I-4	Reply	309
[line_break_token]- Is there a specific boosting method the reviewer believes to be related enough, so as to require an end-to-end comparison?	I-Reply	I-4	Reply	309
We found that it‚Äôs unclear how to choose an ensemble in boosting for fair comparison with learning an optimal translation-invariant kernel (an infinite-dimensional continuous family).	I-Reply	I-4	Reply	309
As far as we know, though our theoretical analysis bears a strong relationship to boosting, the end-to-end methodology is somewhat dissimilar.	I-Reply	I-4	Reply	309
[line_break_token][line_break_token]@Suggestion: We agree that considering state-of-the-art settings and applications is an important and interesting direction (as we note in the conclusion).	B-Reply	B-5	Reply	309
As we mentioned in another review, any convex kernel machine admitting a dual could fit in our min-max formulation, while the min-max SVM objective captures the structure of learning a kernel for any such kernel machine.	I-Reply	I-5	Reply	309

This paper proposes a so called self-supervised method for learning from time series data in healthcare setting.	O	O	Review	106
Specifically, here self-supervision is achieved via designing auxiliary tasks based on data's internal structure to create more labeled auxiliary training tasks.	O	O	Review	106
[line_break_token][line_break_token]From both perspectives of methods and applications, the proposed model has very limited novelty.	B-Review	B-1	Review	106
It is just one application of multitask learning.	I-Review	I-1	Review	106
Also very similar idea has been implemented by [1]. In [1], the authors learn multi-level embedding to make disease/risk prediction, where the embedding was jointly trained by performing auxiliary prediction tasks that rely on this inherent EHR structure.	I-Review	I-1	Review	106
The authors need to state what is the novelty of the proposed method compared with [1].[line_break_token][line_break_token]In addition, the performance evaluation missed many baselines.	B-Review	B-2	Review	106
Table 1 seems more like a ablation study rather than a performance comparison.	I-Review	I-2	Review	106
You need to compare with all state-of-the-art models in computational phenotyping in order to show the performance advantage brought by the proposed mode design.	I-Review	I-2	Review	106
[line_break_token][line_break_token][1] Edward Choi, Cao Xiao, Walter Stewart, Jimeng Sun, MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare,  NeuRIPS, 2018[line_break_token][line_break_token] 	O	O	Review	106
hank you for your thorough review.	O	O	Reply	106
[line_break_token][line_break_token]In response to your concerns:[line_break_token][line_break_token]- Novelty of the proposed method compared with [1]:[line_break_token]Limited self-supervision uses a multitask framework that, critically, requires no external labels to improve accuracy on a single task.	B-Reply	B-1	Reply	106
Most applications of multitask learning require additional ‚Äòexternal‚Äô labels, but our method is applicable even in situations where such labels aren‚Äôt available, hence its novelty.	I-Reply	I-1	Reply	106
[line_break_token][line_break_token]Although [1] also proposes a limited self-supervised framework, their method is applicable only in the EHR setting, since it requires additional labels from diagnosis and treatment codes.	I-Reply	I-1	Reply	106
Still, we agree this is related, and have updated Section 2 to include a discussion of it.	I-Reply	I-1	Reply	106
The relative novelty of our work is to examine limited self-supervision on general time-series tasks with a variety of different auxiliary tasks.	I-Reply	I-1	Reply	106
In particular, we examine the relative merits of different auxiliary tasks, propose a novel auxiliary task (PLAE), and show the importance of including multiple forms of auxiliary supervision.	I-Reply	I-1	Reply	106
[line_break_token][line_break_token]- Insufficient baselines:[line_break_token]Our main goal was not to obtain state-of-the-art results on computational phenotyping tasks, but to investigate the utility of a limited self-supervision framework to sequence classification.	B-Reply	B-2	Reply	106
To this end we compared to a fully supervised network (our baseline), and ran experiments investigating different types of auxiliary tasks.	I-Reply	I-2	Reply	106
In order to present this frameworks applicability to a broader array of datasets, we have added an analysis of 7 datasets from the UCR repository (see Section A3 in the supplement).	I-Reply	I-2	Reply	106
We showed that the addition of self-supervised auxiliary tasks offered sizable improvements over our baseline architecture on most datasets.	I-Reply	I-2	Reply	106
Although we achieved state-of-the-art level performance on only one dataset,  we find the consistent improvement in performance over the baseline indicates the general promise of this approach.	I-Reply	I-2	Reply	106
[line_break_token]	O	O	Reply	106

This paper proposes a method to impose linear inequality constraints on neural network activations.	O	O	Review	20628
The method is implemented at initialization (by converting the H-representation to the V-representation) and during training (by modifying the network architecture).	O	O	Review	20628
Experiments on two setups (projection and VAE+projection on a checkerboard pattern on MNIST) demonstrate a 2-orders of magnitude speed-up with respect to test-time projection (computed with OSQP).	O	O	Review	20628
[line_break_token][line_break_token]The contributions claimed are:[line_break_token]* Novel technique to impose inequality constraints on neural network activations.	O	O	Review	20628
[line_break_token]* Significant speed-up w.r.t.	O	O	Review	20628
other techniques (at test time).	O	O	Review	20628
[line_break_token][line_break_token]Overall, the approach is well motivated, and well-placed in the literature.	O	O	Review	20628
However, the experimental analysis does not support all the claims made by the authors as it focuses on a single dataset (i.e., MNIST) and single constraint (i.e., checkerboard pattern).	O	O	Review	20628
Additionally, while the authors argue that there is no manual trade-off between constraint satisfaction and data representation, the experiment in Fig.	O	O	Review	20628
3 appears to show that there is some manual trade-off (using box delay).	O	O	Review	20628
As such, I am currently inclined to give a "weak reject" score.	O	O	Review	20628
[line_break_token][line_break_token]The method is clear and the idea of using softmax to get a convex combination of the vertices of the V-representation to guarantee constraint satisfaction is reasonable.	O	O	Review	20628
[line_break_token][line_break_token]1) The softmax used to satisfy the constraints is preceded by a batch normalization layer.	B-Review	B-1	Review	20628
I would expect batch normalization to interfere with the ability to saturate the softmax activation and thus prevent the network from reaching optimality.	I-Review	I-1	Review	20628
Could the authors provide experiments that justify the use of the batch normalization layer?	I-Review	I-1	Review	20628
[line_break_token][line_break_token]2) An important factor that is unexplored in this manuscript is the softmax temperature.	B-Review	B-2	Review	20628
A good scheduling of that temperature could help the optimization.	I-Review	I-2	Review	20628
Have authors tried different temperature values?	I-Review	I-2	Review	20628
[line_break_token][line_break_token]3) The use of softmax and the integration of the constraints as a network layer seem to create some difficulty during training (even with the rather simple checkerboard pattern used in the experiment).	O	O	Review	20628
The loss appears to reach some plateau (9% from optimal) and, thus, there appears to be some trade-off between reconstruction and projection.	O	O	Review	20628
The authors should provide more experiments to explain that trade-off.	B-Review	B-3	Review	20628
That trade-off is also visible on Fig.	I-Review	I-3	Review	20628
5 (the zero has a significantly different shape).	I-Review	I-3	Review	20628
[line_break_token][line_break_token]4) The method is solely compared to test time projection.	B-Review	B-4	Review	20628
Could the authors implement other techniques (if feasible)?	I-Review	I-4	Review	20628
e.g., OptNet.	I-Review	I-4	Review	20628
Overall, it would helpful to add more setups and different types of constraints (other than a last-layer projection; e.g., monotonicity).	I-Review	I-4	Review	20628
e agree that generally speaking a comparison with more methods is desirable.	B-Reply	B-4	Reply	20628
However, as pointed out in the paper, the methods mentioned in the related work section don‚Äôt scale well and hence a comparison with our method is futile.	I-Reply	I-4	Reply	20628
Once the V-representation is computed prior to training, the subsequent training and inference phases have no significant overhead, whereas the other methods solve a sub-optimization problem at training time.	I-Reply	I-4	Reply	20628
[line_break_token][line_break_token]While the softmax is indeed a sensible choice for general linear inequalities, the homogeneous case presented in this paper in fact does not use a softmax.	B-Reply	B-2	Reply	20628
Since the feasible set for homogeneous linear inequalities is a polyhedral cone, all we need is a function that maps to positive values, which we can then use as conic combination parameters.	I-Reply	I-2	Reply	20628
We use the absolute value function for that purpose.	I-Reply	I-2	Reply	20628
[line_break_token][line_break_token]You are right about pointing out that there is an implicit trade-off between constraint satisfaction and data representation in the box delay experiments (Sec.	B-Reply	B-3	Reply	20628
4.1).	I-Reply	I-3	Reply	20628
We will remove the statement in a final version	I-Reply	I-3	Reply	20628

***Score updated to weak accept after the rebuttal.***	O	O	Review	643
[line_break_token][line_break_token]Straight-Through is a popular, yet not theoretically well-understood, biased gradient estimator for Bernoulli random variables.	O	O	Review	643
The low variance of this estimator makes it a highly useful tool for training large-scale models with binary latents.	O	O	Review	643
However, the bias of this estimator may cause divergence in training, which is a significant practical issue.	O	O	Review	643
The paper develops a Fourier analysis of the Straight-Through estimator and provides an expression for the bias of the estimator in terms of the Fourier coefficients of the considered function.	O	O	Review	643
Motivated by this expression, the paper proposes two modifications of Straight-Through which may reduce the bias of the estimator, at the cost of the variance.	O	O	Review	643
The experimental results show advantage of this improved estimator over Gumbel-Softmax and DARN estimator.	O	O	Review	643
[line_break_token][line_break_token]While I really like the premise of the paper, I feel that it needs a significant amount of additional work.	B-Review	B-9	Review	643
The text is currently fairly hard to read.	I-Review	I-9	Review	643
The theoretical part of the paper does not quantify the variance of the estimator.	I-Review	I-9	Review	643
The experiments are a bit unfinished and do not include ablations of the proposed modifications of Straight-Through.	I-Review	I-9	Review	643
Most importantly, I think that in the current form the theoretical and the empirical parts of the papers are not well-connected.	I-Review	I-9	Review	643
Because of this, I believe that the paper should currently be rejected, but I encourage the authors to continue this line of work.	I-Review	I-9	Review	643
[line_break_token][line_break_token]Pros:[line_break_token]1.	O	O	Review	643
Theoretical analysis and empirical improvement of the Straight-Through estimator is an important avenue of work.	O	O	Review	643
[line_break_token]2.	O	O	Review	643
The paper makes a solid contribution of deriving the Fourier expansion of the Straight-Through estimator bias.	O	O	Review	643
[line_break_token]3.	O	O	Review	643
Based on this expansion, the paper proposes an algorithm with reduced bias.	O	O	Review	643
The algorithm is simple to implement, practical and appears to work slightly better than DARN.	O	O	Review	643
[line_break_token][line_break_token]Cons:[line_break_token]1.	O	O	Review	643
The key weakness of the theoretical part of the paper is that it focuses on the bias of the estimator, but does not quantify the variance, especially after the modifications.	B-Review	B-1	Review	643
If reducing the bias was the only goal, one could use unbiased (but high-variance) estimators such as REINFORCE or VIMCO.	I-Review	I-1	Review	643
[line_break_token]2.	O	O	Review	643
The final algorithm appears to be the DARN estimator combined with relaxation by uniform noise (‚ÄúBernoulli splitting uniform‚Äù) and scaling.	B-Review	B-2	Review	643
The paper does not have an ablation showing how the uniform noise and scaling perform on their own.	I-Review	I-2	Review	643
[line_break_token]3.	O	O	Review	643
There are a few incorrect statements that I‚Äôve noticed.	B-Review	B-3	Review	643
[line_break_token]* ‚ÄúAs a side contribution, we show that the gradient estimator employed with DARN (Gregor et al 2013), originally proposed for autoregressive models, is a strong baseline for gradient estimation.	I-Review	I-3	Review	643
‚Äù - MuProp paper compared to this estimator under the name 1/2-estimator[line_break_token]* In Lemma 1 the ‚ÄúREINFORCE gradient‚Äù is just the exact gradient of the expectation, not a stochastic REINFORCE gradient.	I-Review	I-3	Review	643
[line_break_token]* ‚Äú To the best of our knowledge, FouST is the first gradient estimate algorithm that can train very deep stochastic neural networks with Boolean latent variables.	I-Review	I-3	Review	643
‚Äù This paper uses up to 11 latent variable layers, while [1] has trained models with &gt;20 latent variable layers (although their ‚Äúlayers‚Äù have just one unit).	O	O	Review	643
[line_break_token]4.	B-Review	B-6	Review	643
The derivation of ‚ÄúBernoulli splitting uniform‚Äù trick is confusing and contains a lot of typos.	B-Review	B-4	Review	643
For instance, the text before eqn. (	I-Review	I-4	Review	643
14) implies that the distribution of u_i is U[-1, 1], which cannot be right and does not correspond to Algorithm 1.	I-Review	I-4	Review	643
The statement that this trick does not lead to a relaxation is odd, since the function is being evaluated at non-discrete points.	I-Review	I-4	Review	643
[line_break_token]5.	O	O	Review	643
There are generally many typos and some poor formatting in the math.	B-Review	B-5	Review	643
For example, in eqn. (	I-Review	I-5	Review	643
6) the coefficients are off by one: it should be c0 + c1 z1 + c2 z2^2 + ‚Ä¶ .	I-Review	I-5	Review	643
The equations (10) and (11) are poorly formatted.	I-Review	I-5	Review	643
The notation \partial_z1 f(u_1, u_2) in eqn. (	I-Review	I-5	Review	643
14) is strange.	I-Review	I-5	Review	643
In many places p^{i-&gt;¬Ω} is denoted as p^{1-&gt;¬Ω}.[line_break_token]5.	O	O	Review	643
I don‚Äôt think I understood the idea of representation scaling (Section 4.4).	B-Review	B-6	Review	643
The eqn. (	I-Review	I-6	Review	643
16) would suggest that the scaling should optimally be set to zero, which is just saying that the gradient is unbiased when the model does not use the latents.	I-Review	I-6	Review	643
There is no other practical guidance on choosing this coefficient.	I-Review	I-6	Review	643
Furthermore, one can always absorb the global scaling factor into the succeeding weights layer of the model, so this trick can probably be replaced by a modification of the weights initialization.	I-Review	I-6	Review	643
[line_break_token]6.	O	O	Review	643
The experiments are missing a comparison to the Straight-Through Gumbel-Softmax estimator, introduced in the original Gumbel-Softmax paper.	B-Review	B-7	Review	643
This is a popular biased estimator for Bernoulli latents, e.g. used in [1] [2]. Another interesting comparison would be [3] which proposes a lower-bias version of Gumbel-Softmax.	I-Review	I-7	Review	643
[line_break_token]7.	O	O	Review	643
Figure 2 is missing the line for REBAR, even though this line is referred to on Page 8.	B-Review	B-8	Review	643
Figure 2 and Figure 4 are both labeled as training ELBOs, despite the plots being different.	I-Review	I-8	Review	643
[line_break_token][line_break_token][1] Andreas Veit, Serge Belongie ‚ÄúConvolutional Networks with Adaptive Inference Graphs‚Äù ECCV 2018[line_break_token][2] Patrick Chen, Si Si, Sanjiv Kumar, Yang Li, Cho-Jui Hsieh ‚ÄúLearning to Screen for Fast Softmax Inference on Large Vocabulary Neural Networks‚Äù ICLR 2019 <a href="https://openreview.net/forum?id=ByeMB3Act7" target="_blank" rel="nofollow">https://openreview.net/forum?id=ByeMB3Act7</a>[line_break_token][3] Evgeny Andriyash, Arash Vahdat, Bill Macready ‚ÄúImproved Gradient-Based Optimization Over Discrete Distributions‚Äù <a href="https://arxiv.org/abs/1810.00116" target="_blank" rel="nofollow">https://arxiv.org/abs/1810.00116</a>	O	O	Review	643
 would like to thank the authors for their detailed reply to my review.	O	O	Reply	643
The paper can certainly be improved, but, with the added ablations and clarifications, I feel that it would find its audience at ICLR.	O	O	Reply	643
Hence, I am increasing my score to weak accept.	O	O	Reply	643
However, I encourage the authors to work more on the text to increase the paper's impact.	O	O	Reply	643
[line_break_token][line_break_token]Comments on the response:[line_break_token][line_break_token]&gt; As opposed to classical high-variance estimators such as REINFORCE, (high) variance is not essential to our estimator.	O	O	Reply	643
[line_break_token][line_break_token]This claim is false in general.	B-Reply	B-1	Reply	643
One can easily construct a function for which the REINFORCE gradient will have exactly zero variance, while the estimator you propose will have a non-zero variance.	I-Reply	I-1	Reply	643
Consider univariate case and set f(z) = 1 / g_REINFORCE(z).	I-Reply	I-1	Reply	643
Hence, you either have to prove that the method has lower variance, or demonstrate that the variance is empirically lower in the experiments.	I-Reply	I-1	Reply	643
[line_break_token][line_break_token]&gt; uniform sampling is the only extra source of variance[line_break_token][line_break_token]This is also not true in general, as importance sampling can also increase the variance of the estimator if the proposal distribution is not optimal.	O	O	Reply	643
[line_break_token][line_break_token]&gt; This is a valid concern and we have added ablation experiments to the paper (see appendix D.2, page 14).	O	O	Reply	643
[line_break_token][line_break_token]Thank you, this ablation is very informative!	B-Reply	B-2	Reply	643
[line_break_token][line_break_token]&gt; DARN estimator[line_break_token]&gt; ‚ÄúFouST is the first gradient estimate algorithm that can train very deep stochastic neural networks with Boolean latent variables‚Äù[line_break_token][line_break_token]I agree with the revised/toned down version of your statements.	B-Reply	B-3	Reply	643
[line_break_token][line_break_token]&gt; The statement that this does not lead to a relaxation (of the sort in Gumbel-Softmax) refers to the fact that we still have a hard binary decision.	O	O	Reply	643
[line_break_token][line_break_token]I still disagree: your method is clearly a relaxation since it evaluates the function at non-discrete points.	B-Reply	B-4	Reply	643
What you are saying is that one can recover the hard sample from the relaxed sample.	I-Reply	I-4	Reply	643
It is a good property, yet the networks can certainly exploit the extra noise injected by your method.	I-Reply	I-4	Reply	643
This is especially misleading because you state in the introduction that ‚ÄúWe resort to the term Boolean instead of binary to emphasize that we work directly on the Boolean space {‚àí1, +1}, without any continuous relaxations or quantizations.	I-Reply	I-4	Reply	643
‚Äù[line_break_token][line_break_token]Related question to the authors: do you compute the ELBO in Table 1 and Figures 2-3 with Boolean samples?	I-Reply	I-4	Reply	643
It is possible that the models are exploiting the extra Uniform noise.	I-Reply	I-4	Reply	643
[line_break_token][line_break_token]&gt;      a. There is no typo in equation 6.	O	O	Reply	643
It gives the expression for the Fourier coefficient in terms of the Taylor coefficients rather than the Taylor expansion of f.[line_break_token]&gt;      d. The p^{1-&gt;¬Ω} is used in section 4.3 in the illustration of a bivariate function.	O	O	Reply	643
Here we take the gradient relative to the first variable and i is 1.	O	O	Reply	643
[line_break_token][line_break_token]Agreed, there are indeed no typos there.	B-Reply	B-5	Reply	643
Thanks for the clarification.	I-Reply	I-5	Reply	643
[line_break_token]  [line_break_token]&gt; we have added comparisons to Straight-Through Gumbel in the updated paper (see figure 2 on page 8).	B-Reply	B-7	Reply	643
Our results support the ones from the original paper that Gumbel-Straight Through performs worse in terms of the optimization objective than Gumbel Soft-max.	I-Reply	I-7	Reply	643
[line_break_token]&gt; REBAR[line_break_token][line_break_token]Thank you for adding this comparison and the clarifications	O	O	Reply	643

The authors present a quantum algorithm for approximating the forward pass and gradient computation of a classical convolutional neural network layer with pooling and a bounded rectifier activation.	O	O	Review	20383
This algorithm has complexity bounds that would open up (for instance) the possibility of exponentially large filter banks, and the authors show through a simple, classical simulation approach that the resulting network is also likely to be trainable.	O	O	Review	20383
[line_break_token][line_break_token]Feedback:[line_break_token][line_break_token]A few typos/formatting issues:[line_break_token]- The title accidentally includes "Conference Submissions"[line_break_token]- The in-text citation format frequently has the parentheses in the wrong place; this is surprisingly distracting!	B-Review	B-1	Review	20383
[line_break_token][line_break_token]Preliminaries:[line_break_token]- Maybe explain what the ith vector in the standard basis is in terms of |0&gt; and |1&gt;?	O	O	Review	20383
I assume the answer is along the lines of |000&gt;, |001&gt;, |010&gt;, etc.?	O	O	Review	20383
[line_break_token][line_break_token]Main results:[line_break_token]- The sentence "a speedup compared to the classical CNN for both the forward pass and for training using backpropagation in certain cases" is ambiguous; does "in certain cases" qualify only training speed or also forward pass speed?	B-Review	B-6	Review	20383
[line_break_token][line_break_token]- There's a clear separation of background (which is concise and well explained) and contributions, but maybe it would be worth connecting the introduced algorithm more closely to existing work in non-convolutional quantum neural networks?	B-Review	B-7	Review	20383
[line_break_token][line_break_token]- Can you briefly justify (or cite) the claim that "most of the non linear functions in the machine learning literature can be implemented using small sized boolean circuits"?	B-Review	B-5	Review	20383
[line_break_token][line_break_token]- I'm a little confused about the discussion of quantum importance sampling on page 4.	B-Review	B-3	Review	20383
Could you give some intuition for the relationship between eta and the fraction of output values that are on average flushed to zero (is this 1 minus sigma?),	I-Review	I-3	Review	20383
and perhaps connect this to the literature about activation pruning and sparse NNs?	I-Review	I-3	Review	20383
[line_break_token][line_break_token]- Maybe define what you mean by "tomography" for ML folks without the quantum background?	B-Review	B-9	Review	20383
[line_break_token][line_break_token]- I'm convinced by the simulations, even though I shouldn't really be convinced by anything on MNIST... It just seems like the perturbations you're applying are all things that modern neural networks take in stride.	B-Review	B-10	Review	20383
[line_break_token][line_break_token]- The discussion of using a sigma-based classical sampling rather than the eta-based quantum importance sampling mentions a "Section C.1.15" which does not exist (I think you mean the end of Section C.1.5).	B-Review	B-4	Review	20383
[line_break_token][line_break_token]- Re: "We will use this analogy in the numerical simulations (Section 6) to estimate, for a particular QCNN architecture and a particular dataset of images, which values of œÉ are enough to allow the neural network to learn."	B-Review	B-11	Review	20383
My understanding is that you're getting empirical estimates of which values of sigma are enough; it would be valuable to convert those to estimates of which values of eta would be enough (given quantum networks of the size used in the classical simulation experiment, or given larger networks).	I-Review	I-11	Review	20383
[line_break_token][line_break_token]- The sampling procedure based on sigma might be inefficient in your PyTorch implementation, but it's certainly something that GPUs are fairly well suited to computing.	B-Review	B-2	Review	20383
There might be other PyTorch operators that would help here (perhaps Bernoulli sampling?)	I-Review	I-2	Review	20383
or if nothing else you could write a small custom CUDA kernel.	I-Review	I-2	Review	20383
e thank the reviewer for the appreciation of the paper and insightful comments.	O	O	Reply	20383
[line_break_token][line_break_token]- The reviewer is right concerning the meaning of the quantum state being the vector in the standard basis.	B-Reply	B-8	Reply	20383
If accepted, we will make the effort of introducing basic concepts of quantum computing to allow a clearer understanding of our work to the audience.	I-Reply	I-8	Reply	20383
As well, we will introduce more intuitively the concept of quantum tomography, namely the family of procedures that allow to retrieve a classical description of a quantum state by repeated measurements (and infer the values of the quantum amplitudes from the resulting distribution).	B-Reply	B-9	Reply	20383
[line_break_token][line_break_token]- Our work in quantum deep learning is indeed related to previous works in quantum neural network cited in our paper, in particular the fully connected quantum neural network of Allcock et al (2018).	B-Reply	B-7	Reply	20383
Their layer method is similar to ours and indeed could be explained in the appendix.	I-Reply	I-7	Reply	20383
 [line_break_token][line_break_token]- The speedup ¬´&nbsp;in certain cases&nbsp;¬ª concerns indeed both the forward pass and the whole training.	O	O	Reply	20383
We will change this sentence and be more explicit.	B-Reply	B-6	Reply	20383
[line_break_token][line_break_token]- Applying a non linearity (as ReLu activation function) in a quantum circuit is a difficult challenge.	B-Reply	B-5	Reply	20383
In our solution, once the value is encoded as a bit string in a quantum register, we can apply a non linearity on it.	I-Reply	I-5	Reply	20383
The circuit that modifies the value accordingly depends on the non linearity considered.	I-Reply	I-5	Reply	20383
For ReLu or other positive simple rules (piecewise linear functions, indicator functions), one could imagine a simple circuit involving few gates to act on the bit strings.	I-Reply	I-5	Reply	20383
Most importantly, the size of such circuits will have a constant depth that doesn‚Äôt depend on the algorithm parameters.	I-Reply	I-5	Reply	20383
In our sentence, ¬´&nbsp;boolean&nbsp;¬ª refers to a classical and explicit series of gates.	O	O	Reply	20383
Note however that implementing more complex non linearities such as tanh could imply a taylor decomposition of the function in order to approximate it with a small number of gates.	B-Reply	B-5	Reply	20383
This explains our choice of the ReLu function.	I-Reply	I-5	Reply	20383
[line_break_token][line_break_token]- Our ¬´&nbsp;quantum importance sampling&nbsp;¬ª can be parametrized in two manners: that relates to the precision of the tomography, or that corresponds to the ratio of elements sampled (the others being set to zero).	O	O	Reply	20383
The relation between the two approaches is given in Appendix, Section C.1.5, namely we have where is the size of the output image.	B-Reply	B-4	Reply	20383
We agree that the explanations could be clearer and we will make the effort to present it better.	I-Reply	I-4	Reply	20383
In our opinion, the Sigma perspective is more intuitive when considering image processing (as shown in Figure 1), and more explainable than Eta which implicitly depends on the size.	I-Reply	I-4	Reply	20383
[line_break_token][line_break_token]- This particular sampling described above is purely a quantum effect and has no known classical usage or reason to be.	I-Reply	I-4	Reply	20383
In a way, it can be seen to a non deterministic activation function.	I-Reply	I-4	Reply	20383
It is reducing the number of non zero values in the layers themselves, and not (directly) in the weights of the kernels.	I-Reply	I-4	Reply	20383
Therefore it might, or not, be related to pruning, drop out or sparse NN.	I-Reply	I-4	Reply	20383
We appreciate this comment and will research on that analogy.	I-Reply	I-4	Reply	20383
[line_break_token][line_break_token]- We thank the reviewer for the advice concerning the PyTorch implementation.	O	O	Reply	20383
We will certainly use this to perform further simulations on different and larger datasets.	B-Reply	B-2	Reply	20383
This could help us save a lot of time.	I-Reply	I-2	Reply	20383
[line_break_token][line_break_token]- All remarks concerning typos and formatting will be taken into account in the final version.	B-Reply	B-1	Reply	20383

The paper presents some new approaches for communication efficient Federated Learning (FL) that allows for training of large models on heterogeneous edge devices.	O	O	Review	1274
In FL, heterogeneous edge devices have access to potentially non-iid samples of data points and try to jointly learn a model by averaging their local models at a parameter server (the cloud).	O	O	Review	1274
As the bandwidth of the up/downlink-link may be limited communication overheads may become the bottleneck during FL.	O	O	Review	1274
Moreover, due to the heterogeneity of the hardware, large models may be hard to train on small devices.	O	O	Review	1274
Due to that, there are several recent approaches that aim to minimize communication via methods of quantization, which also aim to allow for smaller models via methods of compression and model quantization.	O	O	Review	1274
[line_break_token][line_break_token]In this paper, the authors suggest a combination of two methods to reduce communication and allow for large model training by 1) using a lossy compressed model when that is communicated from the cloud to the edge devices, and 2) subsampling the gradients, a form of dropout, at the edge device side that allows for an overall smaller model update.	O	O	Review	1274
The novelty of either of those techniques is quite limited as individually they have been suggested before, but the combination of both of them is interesting.	O	O	Review	1274
[line_break_token][line_break_token]The paper is overall well written, however there are two aspects that make the contribution lacking in novelty.	B-Review	B-1	Review	1274
First of all, the presented methods are a combination of existing techniques, that although interesting to combine together, are neither theoretically analyzed nor extensively tested.	I-Review	I-1	Review	1274
The model/update quantization technique has been used in the past extensively [eg 1-3]. Then, the ‚Äúfederated dropout‚Äù can be seen as a ‚Äúcoordinate descent‚Äù type of a technique, i.e., randomly zeroing out gradient elements per iteration.	I-Review	I-1	Review	1274
[line_break_token][line_break_token]Since this is a more experimental paper, the setup tested is quite limited in its comparisons.	B-Review	B-2	Review	1274
For example, one would expect to see extensive comparisons with methods for quantizing gradients, eg QSGD, or Terngrad, and combinations of that with DeepCompression.	I-Review	I-2	Review	1274
Although the authors do make an effort to experiment with a different set of hyperparameters (dropout probability, quantization levels, etc), a comparison with state of the art methods is lacking.	I-Review	I-2	Review	1274
[line_break_token][line_break_token]Overall, although the combination of the presented ideas has some merit, the lack of extensive experiments that would compare it with the state of the art is not convincing, and the overall effectiveness of this method is unclear at this point.	B-Review	B-3	Review	1274
[line_break_token][line_break_token][1] <a href="https://arxiv.org/pdf/1510.00149.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1510.00149.pdf</a>[line_break_token][2] <a href="https://arxiv.org/pdf/1803.03383.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1803.03383.pdf</a>[line_break_token][4] <a href="https://arxiv.org/pdf/1610.05492.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1610.05492.pdf</a>	O	O	Review	1274
We thank the reviewer for their thorough review and for highlighting that the paper is well written.	O	O	Reply	1274
However, we think the review does not fully recognize the challenges of FL, and consequently misunderstands the nature (and therefore novelty) of our techniques.	O	O	Reply	1274
Please see a detailed explanation below.	O	O	Reply	1274
[line_break_token][line_break_token]The first point we want to address is the (reported lack of) novelty of the following two contributions:[line_break_token]1) The lossy compression of the model sent from server to clients (the review points to other related works).	B-Reply	B-1	Reply	1274
[line_break_token]2) Federated Dropout, which the review mentions can be seen as a ‚Äú‚Äòcoordinate descent‚Äô type of a technique‚Äù.	I-Reply	I-1	Reply	1274
[line_break_token][line_break_token]Let us address the two in turn:[line_break_token]1) We are not aware of previous work (and please correct us if we have missed something) that compresses the *state of a model* being trained when such compression has to be done repeatedly throughout the iterative training procedure and in a data-independent fashion.	I-Reply	I-1	Reply	1274
Techniques such as DeepCompression modify the whole training procedure, are data dependent, and produce one final compact model (i.e. compression is performed once).	I-Reply	I-1	Reply	1274
As such, not only do they become infeasible in the setting of FL (no data is available on the server), but they are not directly comparable with our method.	I-Reply	I-1	Reply	1274
Note that we do call this out in the last paragraph of Section 2 in the original submission, and highlight it could be *compatible* with the overall objective of FL.	I-Reply	I-1	Reply	1274
A proper exploration of such an idea, however, would likely deserve a complete paper.	I-Reply	I-1	Reply	1274
[line_break_token]Furthermore, the idea of using Kashin‚Äôs representation can be of independent interest.	I-Reply	I-1	Reply	1274
We are not aware of any example of this idea being practically used in Machine Learning and, in the Appendix, we show its relationship to some recent theoretical results.	I-Reply	I-1	Reply	1274
[line_break_token][line_break_token]2) Claiming that Federated Dropout can be seen as coordinate descent, or that it can be reduced to subsampling gradients, is incorrect.	I-Reply	I-1	Reply	1274
In each client, we are not computing partial derivatives of the global model, but the full gradients of a smaller, and different, model.	I-Reply	I-1	Reply	1274
Furthermore, several SGD steps are taken for each local model.	I-Reply	I-1	Reply	1274
The facts that (a) by design of the procedure, we can then map these updates to the larger global model, and that (b) performing training this way leads to savings both in communication and local computation, are our key insights.	I-Reply	I-1	Reply	1274
We are not aware of this conceptual idea being addressed in previous literature.	I-Reply	I-1	Reply	1274
Finally, we do (optionally) use subsampling to further compress the final learned updates (together with basis transform and quantization), but this is complementary to (and not equivalent to) Federated Dropout.	I-Reply	I-1	Reply	1274
[line_break_token][line_break_token]In summary, we believe that not only is the combination of our techniques interesting (as the reviewer points out), but that each individual technique does indeed bring novel ideas that address challenges where there is no state of the art at all.	I-Reply	I-1	Reply	1274

The paper introduces a model trained for video prediction hierarchically: a series of significant frames called ‚Äúkeyframes‚Äù in the paper are first predicted and then intermediate frames between keyframes couples are generated.	O	O	Review	523
The training criterion is maximum likelihood with a variational approximation.	O	O	Review	523
Experiments are performed on 3 different video datasets and the evaluation is performed for 3 tasks: keyframe detection, frame prediction and planning in robot videos.	O	O	Review	523
[line_break_token]The idea of generating an abstraction or a summary of a video via a sequence of important frames is attractive and could probably be used in different contexts.	O	O	Review	523
The proposed model is new and the authors introduce some clever ideas in order to train it.	O	O	Review	523
The evaluation work is important and the authors propose different settings for this evaluation.	O	O	Review	523
[line_break_token]The paper also present weaknesses.	O	O	Review	523
First the motivation for keyframes generation should be better developed: the model does not perform better than baselines for video frames prediction so that keyframes generation should be motivated by other applications.	B-Review	B-1	Review	523
Planning as proposed by the authors could be one, but in this case it should be more developed.	I-Review	I-1	Review	523
The main weakness is however the technical presentation which is painful to follow.	B-Review	B-2	Review	523
When it is possible to get a general picture of what is done, it is quite difficult to figure out exactly how the model works.	I-Review	I-2	Review	523
A global rewriting and maybe a better focus are required for publication.	I-Review	I-2	Review	523
The probabilistic model (section 3.1) is relatively clear, even if it could be improved.	I-Review	I-2	Review	523
It seems that the generation of a keyframe and the prediction of the corresponding time (tau^n)  are independent (eq.	I-Review	I-2	Review	523
3).	I-Review	I-2	Review	523
This could be commented.	I-Review	I-2	Review	523
Also it seems that in eq.	I-Review	I-2	Review	523
3 the log(K|z..) term should be inside an expectation.	I-Review	I-2	Review	523
Section 4 was difficult to decipher for me.	I-Review	I-2	Review	523
My understanding is that instead of sampling from a multinomial during training, you bypass this non differentiable operation by using what you call ‚Äúsoft targets‚Äù thus obtaining a differentiable objective (eq.	I-Review	I-2	Review	523
4).	I-Review	I-2	Review	523
Is that true?	I-Review	I-2	Review	523
In any case, the procedure should be made a lot clearer.	I-Review	I-2	Review	523
The ‚Äúintermediate frame‚Äù passage also remained confuse for me.	I-Review	I-2	Review	523
[line_break_token]Considering the experiments, the authors make an important effort in order to evaluate different aspects of their model.	B-Review	B-3	Review	523
In a fisrt step, they evaluate the ability of the model to generate significant keyframes using a detection setting.	I-Review	I-3	Review	523
 It is not clear how they define ground truth frames for this evaluation.	I-Review	I-3	Review	523
Those ground truth frames are defined as the frames where the movement in the image changes, which is easy on the Brownian movement dataset but what about the others?	I-Review	I-3	Review	523
Also the baselines used in this comparison are weak.	I-Review	I-3	Review	523
In the paper of Denton, they suggest some way to detect surprise and apparently this is not what you used.	I-Review	I-3	Review	523
This should be justified/ commented.	O	O	Review	523
For keyframe modeling the proposed model behaves similarly to the baselines and even performs worse than the simpler ‚Äújumpy‚Äù model.	B-Review	B-4	Review	523
Concerni g the paragraph about the selection of the number of predicted keyframes, it is not clear what is the reference (ground truth) number of target keyframes.	I-Review	I-4	Review	523
[line_break_token] The planning experiments are interesting, but difficult to follow at least from the main text.	O	O	Review	523
[line_break_token]Overall, I think that there are several interesting ideas and realizations.	O	O	Review	523
They should be better put in perspective and explained.	O	O	Review	523
[line_break_token][line_break_token]----- post rebuttal -----------[line_break_token][line_break_token]Thanks for the detailed answer.	O	O	Review	523
The paper is largely improved both for the style and the comparisons.	O	O	Review	523
But still requires further improvements.	O	O	Review	523
I will keep my score.	O	O	Review	523
[line_break_token]	O	O	Review	523
e thank the reviewer for the helpful comments and suggestions.	O	O	Reply	523
We have made several changes to the presentation of the technical section as well as the description of the experiments and results to address the reviewer's concerns (updates in red).	O	O	Reply	523
We have also added comparisons to alternative ‚Äúsurprise‚Äù baselines as well as experiments on keyframe modeling.	O	O	Reply	523
We hope the responses below address the reviewer‚Äôs concerns and we are happy to make additional changes if those are required.	O	O	Reply	523
[line_break_token][line_break_token]== Motivation should be better developed ==[line_break_token]We thank the reviewer for pointing out a possible confusion about the motivation of the paper.	B-Reply	B-1	Reply	523
We tried to highlight in the original submission that the goal of this work is not to improve video prediction quality but instead to discover meaningful temporal structure in sequences.	I-Reply	I-1	Reply	523
As the reviewer notes, one possible application for the temporal structure discovered by our model is predicting subgoals for efficient long-horizon planning, and we now expanded the introduction to discuss this.	I-Reply	I-1	Reply	523
We note that planning is known to be a challenging task [1-4] and we show that our model is able to outperform strong baselines using the learned temporal abstraction.	I-Reply	I-1	Reply	523
[line_break_token][line_break_token]== Keyframe detection baseline weak, use Denton&amp;Fergus‚Äô18 ==[line_break_token] We thank the reviewer for proposing this alternative comparison.	B-Reply	B-3	Reply	523
In the original submission we used a measure of surprise based on the KL divergence (see Sec.	I-Reply	I-3	Reply	523
6.3, details in appendix, Sec.	I-Reply	I-3	Reply	523
F).	I-Reply	I-3	Reply	523
To support the strength of this baseline we have now added two baseline evaluations using alternative definitions of surprise.	I-Reply	I-3	Reply	523
The first uses the method of Denton&amp;Fergus‚Äô18 that the reviewer proposed.	O	O	Reply	523
The second uses the lower bound on the log-likelihood -log(p) instead of just the KL divergence to measure surprise.	B-Reply	B-3	Reply	523
In Tab 3,4, we find that the KL-based baseline reported in the submission consistently performs on par with these alternative formulations, and that our method outperforms all baselines.	I-Reply	I-3	Reply	523
[line_break_token][line_break_token]== No performance gain on keyframe modeling ==[line_break_token]We understand that the reviewer is referring to the results evaluating image sequence prediction quality (as opposed to keyframe prediction quality).	B-Reply	B-4	Reply	523
It is true that our method does not improve performance on video modeling, but we emphasize that it is able to perform on par with recent work (Denton&amp;Fergus‚Äô18) while additionally discovering the keyframe structure of the sequence.	O	O	Reply	523
Please refer to our answer to the first question about motivation.	B-Reply	B-4	Reply	523
We additionally performed an experiment showing that our model‚Äôs ability to model keyframes (i.e. the most important frames) is superior to the baseline methods that do not discover temporal structure in Tab.	I-Reply	I-4	Reply	523
6.	B-Reply	B-3	Reply	523
We further clarified the emphasis of the paper with an additional sentence in Sec 6.2.	B-Reply	B-4	Reply	523
[line_break_token][line_break_token]== Soft targets for obtaining differentiable objective?	O	O	Reply	523
==[line_break_token] This interpretation is correct: we introduce the relaxed formulation to bypass the sampling step from p(tau|z,I_co) and make the formulation fully differentiable.	B-Reply	B-2	Reply	523
The original submission stated this in Sec.	I-Reply	I-2	Reply	523
4.	I-Reply	I-2	Reply	523
We thank the reviewer for pointing out the need for further clarifications.	I-Reply	I-2	Reply	523
We restructured Sec.	I-Reply	I-2	Reply	523
4 to more clearly motivate and derive the soft relaxation objective.	I-Reply	I-2	Reply	523
We additionally improved Fig.	I-Reply	I-2	Reply	523
3 to better illustrate the procedure.	I-Reply	I-2	Reply	523
[line_break_token][line_break_token]	O	O	Reply	523

The authors formulate the credit assignment method as minimizing the divergence between policy function and a learned prior distribution.	O	O	Review	627
Then they apply f-divergence optimization to avoid the model collapse in this framework.	O	O	Review	627
Empirical experiments are conducted on the program synthesis benchmark with sparse rewards.	O	O	Review	627
[line_break_token][line_break_token]The main contribution of this paper is applying f-divergence optimization on the program synthesis task for credit assignment.	O	O	Review	627
[line_break_token][line_break_token]+ One of my concerns is that the experiment section is in a limited domain to argue it is a broad algorithm for credit assignment.	B-Review	B-1	Review	627
The paper will be stronger if the comparison is applied in a distant domain like goal-based robot learning etc.	I-Review	I-1	Review	627
With some experiments on a different domain, the paper will be more convincing.	I-Review	I-1	Review	627
[line_break_token][line_break_token]+ The improvement/margin in program synthesis task needed to be explained well, is the margin significant enough?	B-Review	B-2	Review	627
 [line_break_token][line_break_token]+ The paper could discuss more on related papers on program synthesis in the related work section as the main experiment is in this work.	B-Review	B-3	Review	627
[line_break_token][line_break_token]+ The authors claim that the two-buffer estimation is better and lead to better gradient estimation, but it is not demonstrated empirically or theoretically.	B-Review	B-4	Review	627
It could be better if the ablation study is conducted in the experiment.	I-Review	I-4	Review	627
Or the author could provide a theoretical analysis of why equation (13) is better.	I-Review	I-4	Review	627
Moreover, the investigation of different choices of and is necessary.	I-Review	I-4	Review	627
 [line_break_token][line_break_token]+ Another study needed is the investigation of different divergences; the work will be stronger if a KL divergence version is compared.	B-Review	B-5	Review	627
Otherwise, it is not clear how much the f-divergence will contribute to the performance.	I-Review	I-5	Review	627
[line_break_token]	O	O	Review	627
hank you for your time and detailed feedback.	O	O	Reply	627
[line_break_token]We are glad to hear you found this work interesting and valuable, and understand your concerns.	O	O	Reply	627
We are confident that, following the points of clarification highlighted by you, we can resolve any ambiguities in the paper, and thank you for helping make the paper stronger as a result.	O	O	Reply	627
[line_break_token]We answer most of the said pints below.	O	O	Reply	627
It would be very helpful to hear your thoughts on our responses so that we can make the appropriate modifications to the paper.	O	O	Reply	627
[line_break_token]We hope that you will be willing to consider revising your assessment in light of the clarifications.	O	O	Reply	627
[line_break_token][line_break_token][line_break_token]1.	O	O	Reply	627
Evaluation of the proposed method on other domains[line_break_token][line_break_token]      We would like to point out GACA can be useful in other challenging tasks such as combinational optimization and structured prediction where credit assignment from binary feedback remains a major challenge.	B-Reply	B-1	Reply	627
We want emphasize that one of the main purposes of this paper is to introduce the method of guided adaptive credit assignment.	I-Reply	I-1	Reply	627
As such, the purpose of this paper is not to beat every single benchmark but to show the benefit of this framework.	I-Reply	I-1	Reply	627
In particular, we demonstrate the effectiveness of GACA on two challenging program synthesis benchmarks, to our best knowledge, this work is the current state-of-the-art method that uses only binary supervision and outperforms previous methods by a large margin.	I-Reply	I-1	Reply	627
We leave the investigation of our method on other domains for future work.	I-Reply	I-1	Reply	627
[line_break_token][line_break_token][line_break_token]2.	O	O	Reply	627
Results explanation/significance[line_break_token][line_break_token][line_break_token]    GACA outperforms recent state-of-the-art methods MeRL, BoRL, and MAPO by a large margin, on a variety of tasks‚Äîincluding the challenging WikiSQL and WikiTable,  as shown in Table 1, 2, 3.	B-Reply	B-2	Reply	627
To our best knowledge, GACA is by far the state-of-the-art method on these benchmarks using only binary feedback.	I-Reply	I-2	Reply	627
GACA is easy to implement and is a generalization of various credit assignment methods(MAPO MML, EML, RAML, and REINFORCE), we want to emphasize that GACA is general and can be further improved by combining it with techniques in other methods to further boost performance, such as meta-learning proposed in MeRL.	I-Reply	I-2	Reply	627
[line_break_token][line_break_token][line_break_token][line_break_token]3.	I-Reply	I-2	Reply	627
More related work on program synthesis[line_break_token][line_break_token][line_break_token]    We have included several program synthesis papers in related work.	B-Reply	B-3	Reply	627
[line_break_token][line_break_token][line_break_token][line_break_token]4.	O	O	Reply	627
Why use two-buffer estimation in Eq.	O	O	Reply	627
13[line_break_token][line_break_token][line_break_token]    Because GACA enables reusing all the past trajectories while previous methods only use high-reward trajectories, two-buffer estimation naturally arises here as a result of using stratified sampling to obtain unbiased and low variance gradient.	B-Reply	B-4	Reply	627
w_b and w_c are calculated via stratified sampling, refer to Eq(13) for details.	I-Reply	I-4	Reply	627
[line_break_token][line_break_token][line_break_token]5.	O	O	Reply	627
What‚Äôs the performance of GACA if f-divergence is replaced with KL-divergence?	O	O	Reply	627
[line_break_token][line_break_token][line_break_token]    If KL-divergence is used, then GACA reduces to GACA w/o AG which means GACA without adaptive gradient estimation.	B-Reply	B-5	Reply	627
From experimental results(e.g.	I-Reply	I-5	Reply	627
Table 1), we can see that GACA w/o AG greatly outperforms baselines on both benchmarks	I-Reply	I-5	Reply	627

The paper presents a generalization of the Adagrad type methods using a min-max formulation and then presents two alternate algorithms to solve this formulation.	O	O	Review	1188
[line_break_token][line_break_token]It is unclear to me that much extra generalization has been achieved over the original AdaGrad paper.	B-Review	B-1	Review	1188
That paper simply presents the choice of hyperparameters as an optimal solution to a proximal primal dual formulation.	I-Review	I-1	Review	1188
The formulation presented here appears to be another form of the proximal mapping formulation, and so it is unclear what the advance here is.	I-Review	I-1	Review	1188
The AdaGrad paper used a particular Bregman divergence, and different divergences yield slightly different methods, as is observed here by the authors when they use different divergence measures.	I-Review	I-1	Review	1188
[line_break_token][line_break_token]The Bregman divergences do make sense from a primal pual proximal formulation point of view, but why do you use a discrepancy function in your min-max formulation that comes from the \phi - divergence family?	B-Review	B-2	Review	1188
Why not consider an L_p normalization of the discrepancy?	I-Review	I-2	Review	1188
[line_break_token][line_break_token]The difference between formulations (5) and (6) is not clearly specified.	B-Review	B-3	Review	1188
Did you mean to drop the constraints that \beta \in \cal{B}_t ?	I-Review	I-3	Review	1188
Otherwise, why is (6) , which looks to be a re-write of (5), unconstrained and hence separable?	I-Review	I-3	Review	1188
[line_break_token][line_break_token]The authors claim that the method is free of parameter choices, but the initial \beta_0 seems to be a crucial parameter here since it forms both a target and a lower bound for subsequent \beta_t's.	B-Review	B-4	Review	1188
How is this parameter chosen and what effect does it have on convergence?	I-Review	I-4	Review	1188
From the results (Figs in Sec 5), this choice does significantly impact the final test loss obtained.	I-Review	I-4	Review	1188
[line_break_token]    [line_break_token]I could not find a proof for Thm 6 in the appendix.	B-Review	B-5	Review	1188
Did I over look it or is there a typo?	I-Review	I-5	Review	1188
1) Our main contribution (or focus) of this paper is to propose a framework for adjusting learning rate adaptively.	B-Reply	B-1	Reply	1188
We offer a novel viewpoint different from previous main approaches like line search and approximate second-order methods (BBstep, Adagrad, etc.).	I-Reply	I-1	Reply	1188
[line_break_token]2) Compared with Bregman divergence, \phi-divergence naturally imposes nonnegative constraint about \beta and \eta_t, which is necessary for learning rates, while the L_p normalization still can‚Äôt guarantee nonnegative condition for learning rate.	B-Reply	B-2	Reply	1188
[line_break_token]3) Equation (6) is equivalent to (5).	B-Reply	B-3	Reply	1188
We just want to rewrite (5) to a more clear scheme.	I-Reply	I-3	Reply	1188
[line_break_token]4) In the classical gradient descent algorithm formulated as x_{t+1} = x_t - g_t / \beta, for small \beta, more precisely for \beta < 2 / L, the algorithm has no guarantee for convergence.	O	O	Reply	1188
Our framework gives a upper bound for runtime (O(1 / \varepsilon)) or regret (O(\sqrt(T))) for arbitrary \beta_0.	B-Reply	B-4	Reply	1188
Moreover, like Adagrad or gradient descent, algorithms derived from our framework also can be suggested a best initial learning rate for optimization ( based on our regret bounds).	I-Reply	I-4	Reply	1188
[line_break_token]5) The proof of Theorem 6 can be found in the proofs of Theorems 21, 22, and 23	O	O	Reply	1188

(This delayed review is based on the deadline version of the paper.)	O	O	Review	374
[line_break_token][line_break_token]This paper proposes to learn by RL a reset policy at the same time that we learn the forward policy, and use the learned reset Q-function to predict and avoid actions that would prevent reset ‚Äî an indication that they are "unsafe" in some sense.	O	O	Review	374
[line_break_token][line_break_token]This idea (both parts) is interesting and potentially very useful, particularly in physical domains where reset is expensive and exploration is risky.	O	O	Review	374
While I'm sure the community can benefit from ideas of this kind, it really needs clearer presentations of such ideas.	B-Review	B-10	Review	374
I can appreciate the very intuitive and colloquial style of the paper, however the discussion of the core idea would benefit from some rigor and formal definitions.	I-Review	I-10	Review	374
[line_break_token][line_break_token]Examples of intuitive language that could be hiding the necessary complexities of a more formal treatment:[line_break_token][line_break_token]1.	O	O	Review	374
In the penultimate paragraph of Section 1, actions are described as "reversible", while a stochastic environment may be lacking such a notion altogether (i.e. there's no clear inverse if state transitions are not deterministic functions).	B-Review	B-1	Review	374
[line_break_token][line_break_token]2.	O	O	Review	374
It's not clear whether the authors suggest that the ability to reset is a good notion of safety, or just a proxy to such a notion.	B-Review	B-2	Review	374
This should be made more explicit, making it clearer what this proxy misses: states where the learned reset policy fails (whether due to limited controllability or errors in the policy), that are nonetheless safe.	I-Review	I-2	Review	374
[line_break_token][line_break_token]3.	O	O	Review	374
In the last paragraph of Section 3, a reset policy is defined as reaching p_0 from *any* state.	B-Review	B-3	Review	374
This is a very strong requirement, which isn't even satisfiable in most domains, and indeed the reset policies learned in the rest of the paper don't satisfy it.	I-Review	I-3	Review	374
[line_break_token][line_break_token]4.	B-Review	B-5	Review	374
What are p_0 and r_r in the experiments?	B-Review	B-4	Review	374
What is the relation between S_{reset} and p_0?	I-Review	I-4	Review	374
Is there a discount factor?	I-Review	I-4	Review	374
[line_break_token][line_break_token]5.	O	O	Review	374
In the first paragraph of Section 4.1, states are described as "irreversible" or "irrecoverable".	B-Review	B-5	Review	374
Again, in a stochastic environment a more nuanced notion is needed, as there may be policies that take a long time to reset from some states, but do so eventually.	I-Review	I-5	Review	374
[line_break_token][line_break_token]6.	O	O	Review	374
A definition of a "hard" reset would make the paper clearer.	B-Review	B-6	Review	374
[line_break_token][line_break_token]7.	O	O	Review	374
After (1), states are described as "allowed".	B-Review	B-7	Review	374
Again, preventing actions that are likely to hinder reset cannot completely prevent any given state in a stochastic environment.	I-Review	I-7	Review	374
It also seems that (2) describes states where some allowed action can be taken, rather than states reachable by some allowed action.	I-Review	I-7	Review	374
For both reasons, Algorithm 1 does not prevent reaching states outside S*, so what is the point of that definition?	I-Review	I-7	Review	374
[line_break_token][line_break_token]8.	O	O	Review	374
The paper is not explicit about the learning dynamics of the reset policy.	B-Review	B-8	Review	374
It should include a figure showing the learning curve of this policy (or some other visualization), and explain how the reset policy can ever gain experience and learn to reset from states that it initially avoids as unsafe.	I-Review	I-8	Review	374
[line_break_token][line_break_token]9.	O	O	Review	374
Algorithm 1 is unclear on how a failed reset is identified, and what happens in such case ‚Äî do we run another forward episode?	B-Review	B-9	Review	374
Another reset episode?	I-Review	I-9	Review	374
Thank you for the comments!	O	O	Reply	374
It seems that all the concerns have to do with the writing in the paper and are straightforward to fix.	O	O	Reply	374
We have addressed all the concerns raised about the paper in this review.	O	O	Reply	374
Given that all issues have been addressed, we would appreciate if the reviewer could take another look at the paper.	O	O	Reply	374
[line_break_token][line_break_token]1.	B-Reply	B-9	Reply	374
We have clarified our definition of reversible action in Section 1 paragraph 4.	B-Reply	B-1	Reply	374
For deterministic MDPs, we say an action is reversible if it leads to a state from which there exists a reset policy that can return to a state with high density under the initial state distribution.	I-Reply	I-1	Reply	374
For stochastic MDPs, we say an action is reversible if the probability that an oracle reset policy that can reset from the next state is greater than some safety threshold.	I-Reply	I-1	Reply	374
Note that definition for deterministic MDPs is a special case of the definition for stochastic MDPs.	I-Reply	I-1	Reply	374
[line_break_token][line_break_token]2.	B-Reply	B-4	Reply	374
The ability of an oracle reset policy to reset is a good notion of safety.	B-Reply	B-2	Reply	374
In our algorithm, we approximate this notion of safety, assuming that whether our learned reset policy can reset in N episodes is a good proxy for whether an oracle reset policy can reset.	I-Reply	I-2	Reply	374
We have clarified Section 1 paragraph 4 to make this distinction clear.	I-Reply	I-2	Reply	374
We also added Appendix B to discuss handling errors in Q value estimation.	I-Reply	I-2	Reply	374
In this section, we describe how Leave No Trace copes with overestimates and underestimates of Q values.	I-Reply	I-2	Reply	374
[line_break_token][line_break_token]3.	O	O	Reply	374
We have corrected this technical error in Section 3 paragraph 2 by redefining the reset policy as being able to reach p_0 from any state reached by the forward policy.	B-Reply	B-3	Reply	374
That our learned reset policy only learns to reset from states reached by the forward policy is indeed a limitation of our method.	I-Reply	I-3	Reply	374
However, note that early aborts help the forward policy avoid visiting states from which the reset policy is unable to reach p_0.	I-Reply	I-3	Reply	374
[line_break_token][line_break_token]4.	B-Reply	B-1	Reply	374
For the continuous control environments, the initial state distribution p_0 is uniform distribution centered at a ‚Äústart pose.	B-Reply	B-4	Reply	374
‚Äù  We use a discount factor \gamma = 0.99.	I-Reply	I-4	Reply	374
Both details have been noted in Appendix F.3 paragraph 2.	I-Reply	I-4	Reply	374
The reset reward r_r is a hand-crafted approximation to p_0.	I-Reply	I-4	Reply	374
For example, in the Ball in Cup environment, r_r is proportional to the negative L2 distance from the ball to the origin (below the cup).	I-Reply	I-4	Reply	374
For cliff cheetah, r_r includes one term that is proportional to the distance of the cheetah to the origin, and another term indicating whether the cheetah is standing.	I-Reply	I-4	Reply	374
S_{reset} is the set of states where r_r(s) is greater than 0.7 (Appendix C.3 paragraph 2)[line_break_token][line_break_token]5.	O	O	Reply	374
We have clarified Section 4.1 paragraph 1 to explain how our proposed algorithm handles both cases: states from which it is impossible to reset and states from which resetting would take prohibitively many steps.	B-Reply	B-5	Reply	374
In both cases, the cumulative discounted reward (and hence the value function) will be low.	I-Reply	I-5	Reply	374
By performing an early abort when the value function is low, we avoid both cases.	I-Reply	I-5	Reply	374
[line_break_token][line_break_token]6.	O	O	Reply	374
We added a definition of ‚Äúhard reset‚Äù to Section 4.2 paragraph 1: A hard reset is an action that resamples that state from the initial state distribution.	B-Reply	B-6	Reply	374
Hard resets are available to an external agent (e.g. a human) but not the learned agent.	I-Reply	I-6	Reply	374
[line_break_token][line_break_token]7.	O	O	Reply	374
We acknowledge that the proposed algorithm does not guarantee that we never visit unsafe states.	B-Reply	B-7	Reply	374
In Appendix A, we have added a proof that Leave No Trace would only visit states that are safe in expectation if it had access to the true Q values.	I-Reply	I-7	Reply	374
Appendix A.3 discusses the approximations we make in practice that can cause Leave No Trace to visit unsafe states.	I-Reply	I-7	Reply	374
Finally, Appendix B discusses how Leave No Trace handles errors incurred by over/under-estimates of Q values.	I-Reply	I-7	Reply	374
[line_break_token][line_break_token]8.	O	O	Reply	374
Newly added Appendix D visualizes the training dynamics by plotting the number of time steps in each episode before an early abort.	B-Reply	B-8	Reply	374
Initially, early aborts occur near the initial state distribution, so the forward episode lengths are quite short.	I-Reply	I-8	Reply	374
As the reset policy improves, early aborts occur further from the initial state, as indicated by longer forward episode lengths.	I-Reply	I-8	Reply	374
Newly added Appendix B discusses how Leave No Trace handles errors incurred by over/under-estimates of Q values.	I-Reply	I-8	Reply	374
It describes how Leave No Trace learns that an ‚Äúunsafe‚Äù state is actually safe.	I-Reply	I-8	Reply	374
[line_break_token][line_break_token]9.	B-Reply	B-4	Reply	374
We detect failed resets in line 12 of Algorithm 1.	B-Reply	B-9	Reply	374
We have added a comment to help clarify this.	I-Reply	I-9	Reply	374
When a failed reset is detected, a hard reset occurs (line 13)	I-Reply	I-9	Reply	374

In this manuscript, the authors borrow the idea of "optimism" from the online learning literature and apply it to two frequently used methods for neural network training (AMSGrad and ADAM).	O	O	Review	1058
More or less, replicating the theory known in the literature, they give a regret analysis.	O	O	Review	1058
The manuscript ends with a comparison of the optimistic methods against their plain counterparts on a set of test problems.	O	O	Review	1058
[line_break_token][line_break_token]This is a well-written paper filling a gap in the literature.	O	O	Review	1058
Through the contribution does not seem significant, the results do support that such extensions should be out there.	O	O	Review	1058
In addition to a few typos, some clarification on several points could be quite useful:[line_break_token][line_break_token]1) It is not clear why the authors use this particular extrapolation algorithm?	B-Review	B-1	Review	1058
[line_break_token][line_break_token]2) If we have the past r+1 gradients, can we put them into use for scaling the next direction like in quasi-Newton methods?	B-Review	B-2	Review	1058
[line_break_token][line_break_token]3) The following part of the sentence is not clear: "... the gradient vectors at a specific time span is assumed to be captured by (5)."	B-Review	B-3	Review	1058
[line_break_token][line_break_token]4) \nabla is missing at the end of the line right after equation (6).	B-Review	B-4	Review	1058
[line_break_token][line_break_token]5) The second line after Lemma 2 should be "... it does not matter how..." (The word 'not' is missing.)	B-Review	B-5	Review	1058
[line_break_token]	O	O	Review	1058
Thank you for the comments and identifying the typos.	O	O	Reply	1058
We have fixed them.	O	O	Reply	1058
Please find as follows our response.	O	O	Reply	1058
[line_break_token]We've updated the new version accordingly.	O	O	Reply	1058
[line_break_token][line_break_token]== The extrapolation algorithm == [line_break_token]We choose the particular algorithm by (Scieur et al 2016) because it has good empirical performance[line_break_token]in practice. (	B-Reply	B-1	Reply	1058
Scieur et al 2016) shows that using the last few updates of an optimization algorithm,[line_break_token]the method can predict a point that is much closer to the optimum than the last update of the optimization algorithm.	I-Reply	I-1	Reply	1058
[line_break_token][line_break_token]== Scaling the next direction ==[line_break_token]This may be a good idea.	B-Reply	B-2	Reply	1058
We leave it as a future work.	I-Reply	I-2	Reply	1058
[line_break_token][line_break_token]== "... the gradient vectors at a specific time span is assumed to be captured by (5)."	O	O	Reply	1058
==[line_break_token]We elaborate it in the new version accordingly.	B-Reply	B-3	Reply	1058
[line_break_token]We want to have a good prediction of by using the past few gradients.	I-Reply	I-3	Reply	1058
[line_break_token]If the past few gradients can be modeled by the equation approximately, then[line_break_token]the method should predict the gradient well	I-Reply	I-3	Reply	1058

The authors propose to apply generative adversarial imitation learning to multi player Markov games.	O	O	Review	66
[line_break_token][line_break_token]My opinion is that the studied cases are the most simple cases in multi-agent problems.	B-Review	B-1	Review	66
Rewards are either the same for every agents (collaborative) or opposite (zero-sum) or agents are totally independent.	I-Review	I-1	Review	66
Therefore there is little challenge for imitation learning as in the two first cases, there is only one reward function to learn and in the third, each agent can be imitated independently from the others.	I-Review	I-1	Review	66
[line_break_token][line_break_token]As the authors say, the computation of the advantage function assumes that other agents are just part of the environment which makes the problem much simpler.	O	O	Review	66
[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Review	66
Thank you for your comment!	O	O	Reply	66
To clarify some of your concerns:[line_break_token][line_break_token]- One challenge to inverse reinforcement learning is the ill-defined nature of the problem.	B-Reply	B-1	Reply	66
Even in single agent settings there are multiple solutions to the IRL problem (for example, set zero reward everywhere).	I-Reply	I-1	Reply	66
This is even worse in the multi-agent case because there could be several Nash equilibria.	I-Reply	I-1	Reply	66
If we do not make any assumptions to simplify the problem, it is highly possible to learn many rewards that explain the demonstrated behavior.	I-Reply	I-1	Reply	66
If we merely learn a new set of policies from any set of rewards, we may land into another Nash equilibrium that do not reflect the expert policies	I-Reply	I-1	Reply	66

The authors present HPG, which applies the hindsight formulation already applied to off-policy RL algorithms (hindsight experience replay, HER, Andrychowicz et al 2017) to policy gradients.	O	O	Review	195
[line_break_token]Because the idea is not new, and formulating HPG from PG is so straightforward (simply tie the dynamical model over goals), the work seems incremental.	O	O	Review	195
Also, going off policy in PG is known to be quite unstable, and so I'm not sure that simply using the well known approach of normalized importance weights is in practice enough to make this a widely useful algorithm for hindsight RL.	O	O	Review	195
[line_break_token][line_break_token][line_break_token]Evaluation      3/5 How does HPG compare to HER?	B-Review	B-1	Review	195
The only common experiment appears to be bit-flipping, which it appears (looking back at the HER paper, no reference to HER performance in this paper) to signifcantly underperform HER.	I-Review	I-1	Review	195
In general I think that the justification for proposing HPG and possible advantages over HER need to be discussed: why should we generalize what is considered an on-policy algorithm like PG to handle hindsight, when HER seems ideally suited for such scenarios?	I-Review	I-1	Review	195
Why not design an experiment that showcases the advantages of HPG over HER?	I-Review	I-1	Review	195
[line_break_token]Clarity              4/5 Generally well explained.	O	O	Review	195
[line_break_token]Significance    3/5 The importance of HPG relative to off-policy variants of hindsight is not clear.	B-Review	B-2	Review	195
Are normalized importance weights, a well established variance reduction technique, enough to make HPG highly effective?	I-Review	I-2	Review	195
Do we really want to be running separate policies for all goals?	I-Review	I-2	Review	195
With the practical need to do goal sub-sampling, is HPG really a strong algorithm (e.g. compared to HER)?	I-Review	I-2	Review	195
Why does HPG degrade later in training sometimes when a baseline is added?	I-Review	I-2	Review	195
This is strange, and warrants further investigation.	I-Review	I-2	Review	195
[line_break_token]Originality     2/5 More straightforward extension of previous work based on current presentation.	B-Review	B-3	Review	195
[line_break_token][line_break_token]Overall I feel that HPG is a more straightforward extention of previous work, and is not (yet at least) adequately justified in the paper (i.e. over HER).	O	O	Review	195
Furthermore, the experiments seem very preliminary, and the paper needs further maturation (i.e. more discussion about and experimental comparision with previous work, stronger experiments and justification).	B-Review	B-4	Review	195
[line_break_token]Rating          5/10 Weak Reject[line_break_token]Confidence      4/5[line_break_token][line_break_token]Updated Review: [line_break_token][line_break_token]The authors have updated the appendix with new results, comparing against HER, and provided detailed responses to all of my concerns: thank you authors.	O	O	Review	195
[line_break_token][line_break_token]While not all of my concerns have been addressed (see below), the new results and discussion that have been added to the paper make me much more comfortable with recommending acceptance.	O	O	Review	195
The formuation, while straightforward and not without limitations, has been shown in preliminary experiments to be effective.	O	O	Review	195
While many important details (e.g. robust baselines and ultimate performance) still need to be worked out, HPG is almost certainly going to end up being a widely used addition to the RL toolbox.	O	O	Review	195
Good paper, recommend acceptance.	O	O	Review	195
[line_break_token][line_break_token]Evaluation/Clarity/Originality/Significance: 3.5/4/3/4[line_break_token][line_break_token]Remaining concerns: [line_break_token]- The poor performance of the baselines may indeed be due to lack of hindsight, but this should really be debugged and addressed by the final version of the paper.	B-Review	B-5	Review	195
[line_break_token]- Results throughout the paper are shown for only the first 100 evaluation steps.	B-Review	B-6	Review	195
In many of the figures the baselines are still improving and are highly competitive... some extended results should be included in the final version of the paper (at least in the appendix).	I-Review	I-6	Review	195
[line_break_token]- As pointed out, it is difficult to compare the HER results directly, and it is fair to initially avoid confounding factors, but Polyak-averaging and temporal difference target clipping are important optimization tricks.	B-Review	B-7	Review	195
I think it would strengthen the paper to optimize both the PG and DQN based methods and provide additional results to get a better idea of where things stand on these and/or possibly a more complicated set of tasks.	I-Review	I-7	Review	195
[line_break_token][line_break_token][line_break_token]	O	O	Review	195
Thank you very much for the time that you have dedicated to evaluate our work.	O	O	Reply	195
We are glad that you found our ideas generally well explained.	O	O	Reply	195
[line_break_token][line_break_token]Regarding your summary of our contribution, although we agree that hindsight is not an original idea in reinforcement learning, it was introduced only recently and has attracted significant interest, as evidenced by the fact that the work of Andrychowicz et al (2017) has received more than one hundred citations in less than two years, when it first appeared as a technical report.	B-Reply	B-2	Reply	195
[line_break_token][line_break_token]While we agree that tying the dynamics model over goals is straightforward, that is just one of many steps required to derive our approach, which has importance sampling at its core.	I-Reply	I-2	Reply	195
Importance sampling is indeed the natural choice to enable using off-policy data in policy gradients.	I-Reply	I-2	Reply	195
Nonetheless, the exact formulation of the hindsight policy gradient, its relationships with value functions, and the feasibility of the corresponding estimators are only clear in hindsight.	I-Reply	I-2	Reply	195
For instance, note that we are able to derive an estimator that can be effectively computed for environments of interest even though it seems to require an expectation over all possible goals.	I-Reply	I-2	Reply	195
Although apparently simple by analogy, several results require proofs that are elementary but involved (for an example, see Theorem 4.2).	I-Reply	I-2	Reply	195
Our technical approach to hindsight is radically different from previous work, which is why we strongly disagree with the claim that our work is incremental.	I-Reply	I-2	Reply	195
[line_break_token][line_break_token]The reviewer is correct in noting that employing importance sampling to compute gradients can in general be unstable, which motivates the empirical study presented in Section 6 and the supplementary empirical study of likelihood ratios presented in Appendix E.3.6.	I-Reply	I-2	Reply	195
We believe that our experiments on a diverse selection of sparse-reward environments conclusively answer the question of whether weighted importance sampling is effective.	I-Reply	I-2	Reply	195
In addition to such substantial empirical evidence, it is crucial to note that we apply importance sampling in a very specific setting, leading to estimators that have remarkable properties that differentiate them from previous estimators for off-policy learning.	I-Reply	I-2	Reply	195
We mention several of these properties in Section 5, in the paragraph before the last.	I-Reply	I-2	Reply	195
[line_break_token][line_break_token]On a related subject, we vehemently disagree with the claim that our experiments are preliminary.	B-Reply	B-4	Reply	195
Note that Reviewer #2 refers to our experiments as extensive and Reviewer #4 believes that our experiments are well designed and that our analysis is thorough and rigorous.	I-Reply	I-4	Reply	195
[line_break_token][line_break_token]We completely understand your interest in a direct comparison with hindsight experience replay.	B-Reply	B-8	Reply	195
Because this comparison was a common request among reviewers, we are currently working on it.	I-Reply	I-8	Reply	195
We will provide an updated version of the paper including the corresponding results before the end of the rebuttal period (ideally by 21/11).	I-Reply	I-8	Reply	195
[line_break_token][line_break_token]Nonetheless, we would like to briefly explain why we did not include such a comparison in the current version of the paper.	I-Reply	I-8	Reply	195
Firstly, hindsight experience replay is an approach that can be applied to any reinforcement learning technique that relies on experience replay.	I-Reply	I-8	Reply	195
Besides the choices required to implement hindsight experience replay itself (such as the goal sampling strategy and number of hindsight transitions per observed transition), each of these techniques potentially has several important hyperparameters.	I-Reply	I-8	Reply	195
Instead of comparing HPG to one of these techniques, we preferred to focus on a rigorous comparison with GCPG, its most natural counterpart.	I-Reply	I-8	Reply	195
The similarities between both methods allow for a highly systematic comparison that minimizes confounding factors.	I-Reply	I-8	Reply	195
Secondly, note that we have not used tricks that are known to increase the performance of policy gradient methods (e.g., entropy bonuses, reward scaling, learning rate annealing, simple statistical baselines), once again in order to avoid introducing confounding factors.	I-Reply	I-8	Reply	195
Because hindsight experience replay is directly applicable to state-of-the-art techniques, this would lead to an unbalanced comparison.	I-Reply	I-8	Reply	195
Finally, it should be clear that our work can probably benefit from being extended to state-of-the-art policy gradient approaches.	I-Reply	I-8	Reply	195
However, once again, such extensions are likely to introduce confounding factors that we would prefer to avoid in our fundamental work.	I-Reply	I-8	Reply	195
[line_break_token][line_break_token](Part 1/2	O	O	Reply	195

This paper proposes a GCN variant that addresses a limitation of the original model, where embedding is propagated in only a few hops.	O	O	Review	267
The architectural difference may be explained in the following: GCN interleaves the individual node feature transformation and the single-hop propagation, whereas the proposed architecture first transforms the node features, followed by a propagation with an (in)finite number of hops.	O	O	Review	267
The propagation in the proposed method follows personalized PageRank, where in addition to following direct links, there is a nonzero probably jumping to a target node.	O	O	Review	267
[line_break_token][line_break_token]I find the idea interesting.	O	O	Review	267
The experiments are comprehensive, covering important points including data split, training set size, number of hops, teleport probability, and ablation study.	O	O	Review	267
Two interesting take-home messages are that (1) GCN-like propagation without teleportation leads to degrading performance as the number of hops increases, whereas propagation with teleportation leads to converging performance; and (2) the best-performing teleport probability generally falls within a narrow range.	O	O	Review	267
[line_break_token][line_break_token]Question: The current propagation approach uses the normalized adjacency matrix proposed by GCN, which is, strictly speaking, not the transition matrix used by PageRank.	B-Review	B-1	Review	267
What prevents from using the transition matrix?	I-Review	I-1	Review	267
Note that this matrix naturally handles directed graphs.	I-Review	I-1	Review	267
[line_break_token]	O	O	Review	267
Thank you for your review and feedback!	O	O	Reply	267
[line_break_token][line_break_token]You are right, nothing prevents the model from using the standard transition matrix.	B-Reply	B-1	Reply	267
During model development, however, we have found that the added self-loops of the GCN-matrix are beneficial to performance.	I-Reply	I-1	Reply	267
The symmetrical normalization actually doesn't make any difference in the limit k->infinity.	O	O	Reply	267
However, we found this style of normalization to be beneficial for the finite-step approximation.	B-Reply	B-1	Reply	267

This paper proposes an end-to-end trainable attention module, which takes as input the 2D feature vector map and outputs a 2D matrix of scores for each map.	O	O	Review	331
The goal is to make the learned attention maps highlight the regions of interest while suppressing background clutter.	O	O	Review	331
Experiments conducted on image classification and weakly supervised segmentation show the effectiveness of the proposed method.	O	O	Review	331
[line_break_token][line_break_token]Strength of this paper:[line_break_token]1) Most previous work are all implemented as post-hoc additions to fully trained networks while this work is end-to-end trainable.	O	O	Review	331
Not only the newly added weights for attention will be learned, so are the original weights in the network.	O	O	Review	331
[line_break_token]2) The generalization ability shown in Table 3 is very good, outperforming other existing network by a large margin.	O	O	Review	331
[line_break_token]3) Visualizations shown in the paper are convincing.	O	O	Review	331
[line_break_token][line_break_token]Some weakness:[line_break_token]1) Some of the notations are unclear in this paper, vector should be bold, hard to differentiate vector and scalar.	B-Review	B-1	Review	331
[line_break_token]2) In equation (2), l_i and g should have different dimensionality, how does addition work?	B-Review	B-2	Review	331
Same as equation (3)[line_break_token]3) The choice of layers to add attention modules is unclear to me.	B-Review	B-3	Review	331
The authors just pick three layers from VGG to add attention, why picking those 3 layers?	I-Review	I-3	Review	331
Is it better to add attention to lower layers or higher layers?	I-Review	I-3	Review	331
Why is it the case that having more layers with attention achieves worse performance?	I-Review	I-3	Review	331
[line_break_token]	O	O	Review	331
We thank the reviewer for the comments.	O	O	Reply	331
[line_break_token][line_break_token]1) notation: We have updated the paper, in particular Section 3, to represent the vectors in bold to differentiate them from scalars.	B-Reply	B-1	Reply	331
[line_break_token][line_break_token]2) potential for differing dimensionalities of l_i and g: There is some discussion of this in the second paragraph of Sec.	B-Reply	B-2	Reply	331
3.1.	I-Reply	I-2	Reply	331
We propose the use of one fully connected layer for each CNN layer s, which projects the local feature vectors of s to the dimensionality of g. These linear parameters are learned along with all other network parameters during end-to-end training.	I-Reply	I-2	Reply	331
There is an implementation detail, though, which we had neglected to mention: in order to limit the network parameters at the classification stage, we actually project g to the lower-dimensional space of the local features l_i.	I-Reply	I-2	Reply	331
A note of clarification on this has been added to the first paragraph of Sec.	I-Reply	I-2	Reply	331
4.	I-Reply	I-2	Reply	331
[line_break_token][line_break_token]3) selection of layers for attention: A brief discussion on the choice of adding attention to higher layers as opposed to the lower ones was included in Sec.	B-Reply	B-3	Reply	331
3.3.	I-Reply	I-3	Reply	331
We have now augmented this discussion, in place, with further clarification on the specific layers that we choose for estimating the attention.	I-Reply	I-3	Reply	331
[line_break_token]For l_i and g to be comparable using the proposed compatibility functions, they should be mapped to a common high-dimensional space.	I-Reply	I-3	Reply	331
In other words, the effective filters operating over image patches in the layers s must represent relatively ‚Äòmature‚Äô features that are captured in g for the classification goal.	I-Reply	I-3	Reply	331
We thus expect to see the greatest benefit in deploying attention relatively late in the pipeline to provide for the learning of these features in l_i.	I-Reply	I-3	Reply	331
In fact, att2 architectures often outperform their att3 counterparts, as can be seen in Tables 1 and 2.	I-Reply	I-3	Reply	331
[line_break_token]Further, different kinds of class details are more easily accessible at different scales.	I-Reply	I-3	Reply	331
Thus, in order to facilitate the learning of diverse and complementary attention-weighted features, we propose the use of attention over different spatial resolutions.	I-Reply	I-3	Reply	331
The combination of the two factors stated above results in our deploying the attention units after the convolutional blocks that are late in the pipeline, but before their corresponding max-pooling operations, i.e. before a reduction in the spatial resolution	I-Reply	I-3	Reply	331

This paper proposes a learning strategy to precondition gradients for meta-learning.	O	O	Review	20272
I really enjoyed reading the paper though I admit that I couldn't fully grasp all the details yet (paper is dense).	O	O	Review	20272
My comments below are mostly to improve the readability of the paper for readers like me (knowing a thing or two in optimization and meta-learning)[line_break_token][line_break_token][line_break_token][line_break_token]1- The authors emphasize on the method being trajectory-agnostic.	B-Review	B-1	Review	20272
Can you explain why this is very important?	I-Review	I-1	Review	20272
What methods are not trajectory-agnostic?	I-Review	I-1	Review	20272
[line_break_token][line_break_token]2 - Also in various places, the authors claim the method does not suffer from vanishing/exploding gradients and credit-assignment problem.	B-Review	B-2	Review	20272
This needs to be properly verified (and explained as I do not see the connections clearly)[line_break_token][line_break_token]3- Some claims are based on the Omniglot experiments (eg.,	B-Review	B-3	Review	20272
the effect of the stop-gradient).	I-Review	I-3	Review	20272
It would be good if this can be done on Mini-imagenet instead.	I-Review	I-3	Review	20272
[line_break_token][line_break_token]4- I am not sure I understand the stop-gradient operator, can you be more explicit there?	B-Review	B-4	Review	20272
[line_break_token][line_break_token]5- I read the conversation regarding linear units on openreview and I disagree with your statement.	B-Review	B-5	Review	20272
A cascade of linear layers does not necessarily match one linear layer unless some constraints on the rank of layers are envisaged, a bottleneck in the middle ruin everything.	I-Review	I-5	Review	20272
[line_break_token]	O	O	Review	20272
ear R1, [line_break_token][line_break_token]Thank you for your thorough review and constructive feedback, we will incorporate these when updating the manuscript to make it as accessible as possible!	O	O	Reply	20272
[line_break_token][line_break_token]1 - This is a great point, it is indeed important and we will make sure to emphasise this in the revised manuscript.	B-Reply	B-1	Reply	20272
A meta-learner that is *not* trajectory agnostic has a meta-objective that is a function of the entire trajectory, and hence needs to backpropagate through the entire trajectory, such as MAML-based meta-learners.	I-Reply	I-1	Reply	20272
This limits their scalability and makes meta-optimization challenging (see Eq.	I-Reply	I-1	Reply	20272
1 and following discussion).	I-Reply	I-1	Reply	20272
In contrast, WarpGrad is a trajectory-agnostic meta-learner.	I-Reply	I-1	Reply	20272
We use trajectories to form an empirical distribution from which we sample individual steps that we optimise independently.	I-Reply	I-1	Reply	20272
Because the objective is point-wise, we avoid backpropagation through the trajectory, which is what makes WarpGrad competitive even for very long trajectories: the meta-objective scales with at most linear complexity in trajectory length and does not suffer numerical instability as trajectories become long.	I-Reply	I-1	Reply	20272
[line_break_token][line_break_token]2 - Thank you for the constructive feedback as this too is a central aspect of WarpGrad.	B-Reply	B-2	Reply	20272
To clarify the connection, MAML backpropages through the adaptation trajectory, which is essentially an RNN-like backpropagation through time operation.	I-Reply	I-2	Reply	20272
Hence it suffers from the same exploding/vanishing gradients and credit assignment problems that RNNs struggle with, which has been observed empirically [e.g. 1]. More specifically, because the MAML meta-gradient is a product of Hessian matrices, high or low curvature during task adaptation has a multiplicative effect on the meta-gradient (the product of many values much greater or much lower than 1 will cause gradients to explode or vanish, respectively).	I-Reply	I-2	Reply	20272
In contrast, WarpGrad avoids these specific issues by design as it does not backpropagate through adaptation trajectories and instead learns to optimize each gradient step individually.	I-Reply	I-2	Reply	20272
[line_break_token][line_break_token]3 - While we appreciate the sentiment, tieredImageNet, miniImagenet and Omniglot are structurally similar benchmarks in that they are image classification tasks over homogenous image domains (natural images and hand-drawn characters, respectively).	B-Reply	B-3	Reply	20272
Hence the added benefit of running the same ablations on miniImagenet would be limited and given space as well as time constraints we have refrained from doing so.	I-Reply	I-3	Reply	20272
In terms of the first-order approximation (Eq.	I-Reply	I-3	Reply	20272
12), our claim is that it is a useful approximation over longer adaptation processes, as in the Omniglot and RL experiment, where first-order effects tend to dominate.	I-Reply	I-3	Reply	20272
Hence we evaluate this approximation on these experiments.	I-Reply	I-3	Reply	20272
[line_break_token][line_break_token]4 - A stop-gradient operator is an operation that prevents gradients from flowing through a variable during backpropagation.	B-Reply	B-4	Reply	20272
We use it in Eq.	I-Reply	I-4	Reply	20272
12 to make the same approximation as in the first-order approximation of MAML [2], where the stop-gradient operator prevents the meta-gradient from backpropagating through the inner task adaptation step.	I-Reply	I-4	Reply	20272
That way, the meta-gradient avoids computing second-order derivatives (that is, it renders the meta-gradient Hessian-free).	I-Reply	I-4	Reply	20272
[line_break_token][line_break_token]5 - As R1 correctly points out, we are making an implicit full-rank assumption.	B-Reply	B-5	Reply	20272
The public comment was concerned with potentially unfair comparisons in the case that warp layers increase model capacity.	I-Reply	I-5	Reply	20272
Our reply was directed towards this concern.	I-Reply	I-5	Reply	20272
While linear layers cannot add capacity, they can reduce it.	I-Reply	I-5	Reply	20272
This would not make comparisons to baselines unfair, though potentially unfavorable (hence our results are erring on the side of caution) for WarpGrad.	I-Reply	I-5	Reply	20272
Note that all baselines are tuned for model capacity through conv-layer filter sizes.	I-Reply	I-5	Reply	20272
[line_break_token][line_break_token][1] Finn et al Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.	O	O	Reply	20272
2017.	O	O	Reply	20272
[line_break_token][2] Antoniou et al How to train your MAML.	O	O	Reply	20272
2019	O	O	Reply	20272

*Edit: original score was a weak reject (3), updating to a weak accept (6) in light of revisions.*	O	O	Review	274
[line_break_token][line_break_token]This work implements a hierarchical control scheme for a high-dimensional control problem (locomotion using a humanoid body).	O	O	Review	274
 The hierarchy consists of a high-level module that plans in an abstract space of "intention", and the intention variables serve as inputs, along with state, to a low-level controller that actually executes the movements.	O	O	Review	274
 The premise is that a lower-level controller should be usable for multiple tasks, and should be able to be commanded by a lower-dimensional intention input.	O	O	Review	274
 I find the basic ideas presented clear, the literature reviewed reasonably well, and the motivation and setting to be very interesting.	O	O	Review	274
 The video summary is valuable.	O	O	Review	274
[line_break_token][line_break_token]My main concerns have to do with presentation, but I think they are relatively significant concerns.	B-Review	B-1	Review	274
 As the draft currently stands, I would, somewhat regrettably, be inclined to reject the submission (marginally).	I-Review	I-1	Review	274
 I think revisions could seriously improve this paper and incline me towards acceptance.	O	O	Review	274
[line_break_token][line_break_token]Algorithm 1 indicates that the learning of the low-level controller will be done jointly with the learning of the latent model and planning using the high-level, learned intention space.	B-Review	B-2	Review	274
 In the experiment, it is indicated that the low-level controller is pretrained.	I-Review	I-2	Review	274
 This points to a couple issues that are not clear in the draft:[line_break_token](1) Presumably this pretraining is necessary and things do not work without it.	I-Review	I-2	Review	274
 Indeed, it is hard to imagine that the movements will be well grounded to human motion capture movements without this pretraining.	I-Review	I-2	Review	274
 Does the algorithm work as written or is pretraining a fundamentally essential step?	I-Review	I-2	Review	274
 There are no settings, even toy settings, where the algorithm as written is shown to be effective.	I-Review	I-2	Review	274
[line_break_token](2) The authors should be clearer how they conduct the pretraining which involves learning the low-level controller.	I-Review	I-2	Review	274
 [line_break_token](3) I'm not clear how updating the low-level controller is effective in the algorithm.	I-Review	I-2	Review	274
 While I understand why it makes sense to plan in the intention space of the pre-trained controller, and I understand why learning a model is a core part of planning, it would seem like fine-tuning the low-level controller could make the movements deviate considerably from the initial movement space and maybe even eliminate the ability of the low-level policy to express movements that are not used early in training.	I-Review	I-2	Review	274
So essentially, while the planning in the low-D space makes sense and the learning of the model makes sense, the low-level controller update seems possibly to not make sense, and there aren't experiments showing that step helps.	I-Review	I-2	Review	274
[line_break_token][line_break_token]Is it just a coincidence that the intention space (h) is one-of-three and the low-d state space (z) is 3-dimensional as well?	B-Review	B-3	Review	274
 Or are these both selected with sort of going straight vs turning left or right in mind?	I-Review	I-3	Review	274
[line_break_token][line_break_token]The experiment section is generally very unclear, though details are made a little clearer from the video.	B-Review	B-4	Review	274
 In the paper, there are a few points that need to be clearer: [line_break_token](1) "ref", "plan", and  "true" are not well defined and it is unclear what these distances in Table 1 refer to precisely.	I-Review	I-4	Review	274
 Clearly introduce what each of these refers to.	I-Review	I-4	Review	274
 The authors simply say that there are imitation tasks but do not walk through what these terms refer to.	I-Review	I-4	Review	274
[line_break_token](2) In 4.1, the different structures are not adequately introduced.	I-Review	I-4	Review	274
 The pointers to the figure 2 diagrams are essential, but there is no pointer for zaz', the pointers are only in the table (not in the text), there are grammar issues in the text and the text could be verbally clearer about the variants.	I-Review	I-4	Review	274
[line_break_token](3) shs' setting is a bit unclear.	I-Review	I-4	Review	274
Basically, clarify briefly how planning is performed in this case.	I-Review	I-4	Review	274
  Is a forward model still trained, but the model opperates with the full state space?	I-Review	I-4	Review	274
 If so, presumably the forward model is much worse and then the planning approach is correspondingly bad, hence the poor rollouts?	I-Review	I-4	Review	274
[line_break_token](4) 4.2 is I think obviously inadequately described in the text and I can only assume was the result of rushing for the deadline?	I-Review	I-4	Review	274
 The second experiment is essentially not presented in the text all aside from a still image.	I-Review	I-4	Review	274
 [line_break_token](5) And for all of the experiments that rely on planning with a particle filter, details such as how reliable the filter is in generating useful control, how many samples are required, and possibly elements of compute speed would make much clearer how well the approach actually works.	I-Review	I-4	Review	274
 Does the choice of planner matter at all?	I-Review	I-4	Review	274
 A common, albeit relatively weak, baseline planning approach is CEM...would CEM work here?	I-Review	I-4	Review	274
 I'd like to understand if the choice of particle filter is the author's default choice, which is fine if so, or if there is a positive assertion being made that the particle filter is particularly valuable.	I-Review	I-4	Review	274
[line_break_token][line_break_token]I hope the authors will generally improve the exposition in the experiment section (4) during the revisions.	B-Review	B-5	Review	274
[line_break_token][line_break_token]Overall, I find the paper well motivated in framing the problem (i.e. using model-based approaches to control the latent space of a low-level controller).	O	O	Review	274
 I also appreciate the scale of the problem (humanoid control is challenging, so this is not a toy problem).	O	O	Review	274
 I find the results a bit unclear, perhaps due to hurriedness in writing, so I find them a bit difficult to fully appreciate.	B-Review	B-6	Review	274
 Nevertheless, the core contribution that I take away from this work is that there is a value to learning the low-dimensional state representation (z, via the LVM), relative to planning using a forward model on the full state (?...	I-Review	I-6	Review	274
I'm still unclear on the presentation of this result, due to unclear exposition).	I-Review	I-6	Review	274
Slightly more broadly, this is a good demonstration of using a planner jointly with a learned high-level command/intention representation, for a high-dimensional problem.	I-Review	I-6	Review	274
[line_break_token][line_break_token]If I've understood this correctly, I'd be reasonably interested in this result.	I-Review	I-6	Review	274
If the authors can both clarify the core results and communicate that the choices made in the algorithm are well thought through, I would be happy to adjust my score.	I-Review	I-6	Review	274
[line_break_token][line_break_token][line_break_token]Relatively minor:[line_break_token][line_break_token]Abstract says 90-dimensional humanoid system, but later it is stated "34 degrees of freedom,[line_break_token]197 state features, and 36 action parameters".	B-Review	B-7	Review	274
Where the 90 dimensions comes from is unclear.	I-Review	I-7	Review	274
 Often people refer to number of actuators or DoFs.	I-Review	I-7	Review	274
 Please adjust this or be more explicit.	I-Review	I-7	Review	274
[line_break_token][line_break_token]In equation 9, f() is not very clearly specified.	I-Review	I-7	Review	274
Is f() a nonlinear function (e.g. a neural network) or is it a linear function?	I-Review	I-7	Review	274
It seems like it might as well be a linear function, since the authors propose to learn a latent dynamics model that is nonlinearly related to the state.	I-Review	I-7	Review	274
[line_break_token][line_break_token]Typos in Fig 3 caption.	I-Review	I-7	Review	274
[line_break_token]	O	O	Review	274
s of the revision visible at the present moment, I remain not entirely happy with the presentation of the experiments, but these concerns are now essentially just issues related to what I believe to be clear writing.	B-Reply	B-4	Reply	274
 I encourage a few more read-throughs by the authors with an eye towards editing for clarity.	I-Reply	I-4	Reply	274
 In particular, I still think the authors don't clearly define their setting succinctly at the beginning of the "Experiment" section.	I-Reply	I-4	Reply	274
 And in the subsections of that section, they should open by very briefly defining the tasks.	I-Reply	I-4	Reply	274
 The appendices provide additional information, but they should be more explicitly referenced, with an indication of what they contain.	I-Reply	I-4	Reply	274
[line_break_token][line_break_token]The above comments notwithdstanding, the authors have made meaningful revisions, and the content required to fully interpret the results is now present.	B-Reply	B-8	Reply	274
 I think this work is both interesting and contains valuable contributions.	I-Reply	I-8	Reply	274
 So I will update my score to a weak accept (6).	I-Reply	I-8	Reply	274
 Ultimately, the novel contributions of this work involve the ability to perform planning using the low-dimensional space to reuse the humanoid motor skills, and these contributions warrant acceptance to the conference.	I-Reply	I-8	Reply	274
 This is a challenging problem, so this work does provide a somewhat satisfying demonstration.	I-Reply	I-8	Reply	274
 The ablation experiments make the work valuable to build upon.	O	O	Reply	274

This paper investigates the question of identifying concise equations from data to understand the functional relations.	O	O	Review	20495
In particular, a set of base functions are given in hand and the goal is to obtain the right composition of these functions which fits the target function.	O	O	Review	20495
The main contribution of the paper is to introduce a selection layer, which enhances sparse connections in the network.	O	O	Review	20495
Several experiments are conducted to show the effectiveness of the method.	O	O	Review	20495
[line_break_token][line_break_token]My main concern of the paper is about the novelty and the lack of comparison of existing methods.	B-Review	B-1	Review	20495
The framework of finding functional relations is set up in [1,2], the main contribution of the paper is a refine architecture with the introduction of the selection layer.	I-Review	I-1	Review	20495
However, this selection layer is nothing but incorporating a softmax function.	I-Review	I-1	Review	20495
The idea of combining softmax functions in the hidden layers is not novel neither, which could be found in [3,4]. As a result, I find the contribution of the paper very limited, which could be summarized as applying an existing technique on a specific problem.	I-Review	I-1	Review	20495
Moreover, in the experimental section, there is a lack of comparison with existing methods such as EQL[1,2] and I consider it a major omission.	B-Review	B-2	Review	20495
[line_break_token][line_break_token]Overall, due to the novelty concern and the lack of comparison, I do not support publication of the paper.	B-Review	B-1	Review	20495
[line_break_token][line_break_token][1] Sahoo et al  Learning Equations for Extrapolation and Control[line_break_token][2] Martius et al Extrapolation and learning equations[line_break_token][3] Graves et al  Neural turing machines[line_break_token][4] Graves et al  Hybrid computing using a neural network with dynamic external memory	O	O	Review	20495
e thank you for your valuable comments.	O	O	Reply	20495
[line_break_token][line_break_token]As you said we combine function block activation with selection layer drawn from softmax layer with temperature.	B-Reply	B-1	Reply	20495
Actually, we tried many different ways including the softmax layer, for example, we tried a power method as NTM [3] does, we also used a probabilistic method like gumbel softmax, and tried RL to learn the path.	I-Reply	I-1	Reply	20495
Among them, softmax with low temperture and softmax with learning temperature give the best performances in our experiments.	I-Reply	I-1	Reply	20495
[line_break_token]Furthermore, we find out that we have to restrict l1 norm of W (the matrix before going through softmax), otherwise the network often falls deep into a local minimum.	I-Reply	I-1	Reply	20495
Also we use curriculum learning since above restriction can be the obstacle after the network finds a right order.	I-Reply	I-1	Reply	20495
So we reduces the regression constant during the training task and this helps network to find out the right ordering to obtain the function composition.	I-Reply	I-1	Reply	20495
[line_break_token][line_break_token]As for your comments on the experiments, we will try to compare our methods with existing ones such as EQL since those networks also target finding a right equation including extrapolation.	B-Reply	B-2	Reply	20495
We will try to make an experiment comparing with EQLs not only focusing on the error but also on the resulting objective function form.	I-Reply	I-2	Reply	20495
Thank you again for the comments.	I-Reply	I-2	Reply	20495
[line_break_token][line_break_token][1] Sahoo et al  Learning Equations for Extrapolation and Control[line_break_token][2] Martius et al Extrapolation and learning equations[line_break_token][3] Graves et al  Neural turing machines[line_break_token][4] Graves et al  Hybrid computing using a neural network with dynamic external memor	O	O	Reply	20495

This paper investigates a so-called "compressive transformer" approach.	O	O	Review	467
The idea is to compress distant past memories into a coarse-grained representation while keeping a fine-grained representation for close past memories.	O	O	Review	467
 A variety of compression techniques and training strategies have been investigated in the paper and verified using tasks from multiple domains including language modeling, speech synthesis and reinforcement learning.	O	O	Review	467
Particularly, the authors propose a new benchmark PG-19 for long-term sequence modeling.	O	O	Review	467
 [line_break_token][line_break_token]Overall, I found the work interesting and experiments are thorough and strong.	O	O	Review	467
  It is always great to see a new benchmark released to the community.	O	O	Review	467
 That being said, I have concerns regarding the paper.	O	O	Review	467
 The authors put huge amount of effort into the experiments but only describe the proposed technique in a very rough and abstract way, lacking necessary technical details to formulate the technique.	B-Review	B-1	Review	467
What is the mathematical formulation of the problem?	I-Review	I-1	Review	467
 How exactly the compression is carried out on various network architectures is not clear after reading the paper.	I-Review	I-1	Review	467
 Also, I guess many readers including me do not have a perfect understanding of Fig.	I-Review	I-1	Review	467
1 although it shows something intuitively. (	I-Review	I-1	Review	467
What is the difference between different colors?	I-Review	I-1	Review	467
What is the difference between sequence, memory, and compressed memory?	I-Review	I-1	Review	467
 What do the arrows mean?	I-Review	I-1	Review	467
There is no explanation whatsoever either in the figure or in the caption).	I-Review	I-1	Review	467
 This is the major concern I have regarding the paper.	I-Review	I-1	Review	467
 Despite of the strong experimental presentation, lacking the technical details has significantly hurt the quality of the paper.	I-Review	I-1	Review	467
 [line_break_token][line_break_token]P.S.  Thanks for the rebuttal.	O	O	Review	467
 I have lifted my score.	O	O	Review	467
e completely agree that the model could be described more explicitly. *	B-Reply	B-1	Reply	467
We are updating the paper with more mathematical details and an algorithm box to make things more explicit*. We originally wrote this paper to convey the key components of the model for those familiar with TransformerXLs, with the idea that all of the fine details are better represented in the code --- however we realize this was not the best strategy.	I-Reply	I-1	Reply	467
We will still open-source the code so people can use the model and be certain of every detail, but we are completely re-writing the model section with the inclusion of an algorithm box.	I-Reply	I-1	Reply	467
As pseudo-code here, the compression mechanism is really just passing memories that would otherwise be forgotten through a conv1d compression network:[line_break_token][line_break_token]compression_rate &lt;- 3[line_break_token]old_memory  &lt;- memory[:-seq_size]  # the memories to be forgotten[line_break_token]compression_fn &lt;- conv_1d(kernel_size=compression_rate, stride=compression_rate)[line_break_token]new_cm &lt;- compression_fn(old_memory )  # new compressed memories[line_break_token][line_break_token]Then for attention, before in the TransformerXL one would compute[line_break_token]attention(seq, [memory, seq])[line_break_token]whereas here we compute[line_break_token]attention(seq, [compressed_memory, memory, seq])[line_break_token][line_break_token]Before in the TransformerXL one would update memory by concatenating the sequence and truncating the oldest memories (to keep the memory fixed-size):[line_break_token]memory &lt;- concat_and_truncate(memory, sequence)[line_break_token][line_break_token]where 'concat_and_truncate' refers to:[line_break_token]def concat_and_truncate(old_state, new_state):[line_break_token]    new_state_size &lt;- new_state.shape[1]  # time dimension[line_break_token]    return concat([old_state, new_state])[new_state_size:]  [line_break_token][line_break_token]Now we update both the memory and compressed_memory:[line_break_token]memory &lt;- concat_and_truncate(memory, sequence)[line_break_token]compressed_memory &lt;- concat_and_truncate(compressed_memory, new_cm)[line_break_token][line_break_token]In Figure 1 we kept the sequence and memory the same colour, as these hidden activations represent information for a single time-step in the transformer.	O	O	Reply	467
We use an arrow to indicate that we map a set of memories to a smaller set of compressed memories.	B-Reply	B-1	Reply	467
We chose a different colour for the compressed memories (and made the ticks more frequent) to indicate that these represent information over multiple time-steps.	I-Reply	I-1	Reply	467
We are updating the figure and caption with more details such that this is clearer.	I-Reply	I-1	Reply	467
[line_break_token][line_break_token]If there is anything else that is unclear, feel free to give us feedback!	O	O	Reply	467

In this work the authors point out an issue related to graph neural networks.	O	O	Review	97
Specifically, if two nodes, that may be far apart in the graph, may be represented as (almost) the same vector.	O	O	Review	97
This is simply because when no features/labels are associated with nodes, and the local structure around those two nodes is very similar then the local aggregation of information will result in a similar representation.	O	O	Review	97
 Therefore the authors introduce an embedding first of the graph in the Euclidean space using DeepWalk and then use this embedding in combination with the design of a CNN.	O	O	Review	97
The authors propose a pooling method that outperforms several state-of-the-art pooling techniques on real data.	O	O	Review	97
Overall, the empirical results are supportive of the fact that the proposed method can help improve the performance of GNNs.	O	O	Review	97
[line_break_token][line_break_token]Overall I found the results of this paper to be weak, but nonetheless the paper is well-written and contains some interesting ideas.	B-Review	B-1	Review	97
Hence my rating.	O	O	Review	97
Some questions follow.	O	O	Review	97
[line_break_token][line_break_token]- While the authors call this as an "issue" it is more like a feature of these methods.	B-Review	B-5	Review	97
 For instance, in "RolX: Structural Role Extraction &amp; Mining in Large Graphs" by Henderson et al this "issue" could turn out to be an interesting feature of the GNNs in the sense that these nodes may have a similar (structural) role.	O	O	Review	97
 It would be nice to have a short discussion related to this line of research in social networks' analysis.	B-Review	B-5	Review	97
[line_break_token]-  Some components of the CNN (e.g., node sampling) could be done using  well-developed tools for sampling matrices from numerical linear algebra, or by introducing some randomness when sampling a node as in kmeans++.	B-Review	B-2	Review	97
[line_break_token]- Graph downsampling appears to be an expensive operation.	B-Review	B-3	Review	97
Can you please comment on the running times?	I-Review	I-3	Review	97
The issue of scalability is not discussed, and the reader cannot easily infer to what sizes this method can scale up to.	I-Review	I-3	Review	97
[line_break_token]- Using other graph tasks, that are classical but also more challenging (e.g., learning 2-connected components of a graph just to mention something that comes up) would be interesting to see in Section 5.2.	B-Review	B-6	Review	97
[line_break_token]-  It would have been interesting to see the effect of the embedding step on the accuracy on the real data.	B-Review	B-4	Review	97
E.g., using node2vec or standard spectral embeddings.	I-Review	I-4	Review	97
[line_break_token][line_break_token][line_break_token][Edit: The authors have replied to my comments, and the other reviewers' comments in great detail.	O	O	Review	97
Therefore I upgrade my score.]	O	O	Review	97
e thank the reviewer for the comments.	O	O	Reply	97
[line_break_token][line_break_token]1- ‚ÄúOverall I found the results of this paper to be weak‚Äù:[line_break_token][line_break_token]Table 1 and Table 2  indicate that the improvements in the results are significant for both real and synthetic data.	B-Reply	B-1	Reply	97
[line_break_token][line_break_token]2- ‚ÄúSome components of the CNN (e.g., node sampling) could be done using  well-developed tools for sampling matrices from numerical linear algebra, or by introducing some randomness when sampling a node as in kmeans++‚Äù: [line_break_token][line_break_token]Thanks for this suggestion.	O	O	Reply	97
We are well aware of column/row sampling techniques and we considered several sampling methods as our candidates including the one used in K-means++ and SRS [arXiv:1705.03566]. The farthest data point sampling method used in our pooling method (which is very similar to the sampling techniques used in K-means ++) ensures that the sampled embedding vectors cover the spatial distribution of all the embedding vectors and this is all we expect the sampling method to do.	B-Reply	B-2	Reply	97
[line_break_token][line_break_token]3- ‚ÄúGraph downsampling appears to be an expensive operation.	O	O	Reply	97
‚Äù[line_break_token]The complexity of the sampling method is linear with the number of sampled embedding vectors (O(m*n*de) where m is the number of sampled vectors and de is the dimension of the embedding vectors).	B-Reply	B-3	Reply	97
In addition, different from node classification, in the graph classification task, we mostly do not have large graphs (mostly less than 100 nodes).	I-Reply	I-3	Reply	97
In the revised paper, we described the computation complexity of the node sampling method.	I-Reply	I-3	Reply	97
[line_break_token][line_break_token]4- ‚ÄúIt would have been interesting to see the effect of the embedding step on the accuracy on the real data.	O	O	Reply	97
E.g., using node2vec or standard spectral embeddings.	O	O	Reply	97
‚Äù[line_break_token][line_break_token]ŸëIn our initial experiments, we used other embedding methods such as [arXiv:1710.02971] but the results were not much different.	B-Reply	B-4	Reply	97
In the final version, we will report the results with several different embedding methods.	I-Reply	I-4	Reply	97
[line_break_token][line_break_token]5- ‚ÄúWhile the authors call this as an "issue" it is more like a feature of these methods.	O	O	Reply	97
 For instance, in "RolX: Structural Role Extraction &amp; Mining in Large Graphs" by Henderson et al this "issue" could turn out to be an interesting feature of the GNNs in the sense that these nodes may have a similar (structural) role.	O	O	Reply	97
‚Äù[line_break_token][line_break_token]It depends on the application that we deal with.	B-Reply	B-5	Reply	97
In the graph classification problem , we clearly showed that it is not a desirable feature and this feature can make the GNN unable to extract discriminative features.	I-Reply	I-5	Reply	97
[line_break_token]Moreover, our approach addresses another problem of GNNs raised by (Xu et al (ICLR 2019)): GNNs can map even different local structures to same feature vectors.	I-Reply	I-5	Reply	97
[line_break_token]Since we include the information about the location of the nodes, we help the GNN to distinguish both similar and different local structures.	I-Reply	I-5	Reply	97
[line_break_token]We cited ‚ÄúRolX: Structural Role Extraction &amp; Mining in Large Graphs‚Äù and clarified that the point that in some applications mapping node with similar local structures to similar feature vectors can be desirable.	O	O	Reply	97
[line_break_token][line_break_token]We would like to reiterate that our paper is the first work which address this problem and the presented results (Table 1 and Table2) clearly show how effective is the presented solution.	B-Reply	B-5	Reply	97

This paper studies the implicit regularization phenomenon.	O	O	Review	20255
More precisely, given separable data the authors ask whether homogenous functions (including neural networks) trained by gradient flow/descent converge to the max-margin solution.	O	O	Review	20255
 The authors show that the limit points of gradient descent are KKT points of a constrained optimization problem.	O	O	Review	20255
[line_break_token][line_break_token]-I think that the topic is important and the authors clearly made some interesting insights.	O	O	Review	20255
[line_break_token]-The main results of this paper (Theorem 4.1 and Theorem 4.4) require that assumption (A4) is satisfied.	B-Review	B-2	Review	20255
Assumption (A4) essentially means, that gradient flow/descent is able to reach weights, such that every data x_n is classified correctly.	I-Review	I-2	Review	20255
To me this seems to be a quit restrictive assumption as due to the nonconvexity of the neural net there is a priori no reason to assume that such a point is reached.	I-Review	I-2	Review	20255
In this sense, the paper only studies the latter part of the training process.	I-Review	I-2	Review	20255
[line_break_token][line_break_token]I feel that Assumption (A4) clearly weakens the strength of the main results.	I-Review	I-2	Review	20255
However, because the topic studied by the paper is interesting and the authors have obtained some interesting insights, I decided to rate the paper as a weak accept.	O	O	Review	20255
[line_break_token][line_break_token]Typos:[line_break_token]-p.	B-Review	B-1	Review	20255
4: "Very Recently"[line_break_token]-p.	I-Review	I-1	Review	20255
7 and p. 9: "homogenuous" (instead of "homogeneous")[line_break_token][line_break_token]----------[line_break_token][line_break_token]I want to thank the authors for their response.	O	O	Review	20255
However, I will stand by me evaluation and will not change it.	O	O	Review	20255
[line_break_token]I agree though that assumption (A4) is indeed reasonable, although of course very strong.	O	O	Review	20255
 [line_break_token]	B-Review	B-1	Review	20255
hanks for your reviews and for pointing out the typos!	B-Reply	B-1	Reply	20255
[line_break_token][line_break_token]We admit that (A4) may not hold for all neural networks and all datasets.	B-Reply	B-2	Reply	20255
Indeed, the loss of a neural network is highly non-convex and (A4) seems to be a quite strong assumption.	I-Reply	I-2	Reply	20255
However, it is known that sufficiently overparameterized neural networks can fit the training set through (stochastic) gradient descent.	I-Reply	I-2	Reply	20255
As we discussed in the introduction of our paper, state-of-the-art neural networks are typically overparameterized, and they can perfectly fit not only normal data but also randomly labeled data easily in image classification tasks (Zhang et al 2017).	I-Reply	I-2	Reply	20255
Theoretically, (Allen-Zhu et al 2019; Du et al 2018; Zou et al 2018) showed that gradient descent can achieve 100% training accuracy if the width is large enough.	I-Reply	I-2	Reply	20255
Given the evidence from both theory and practice, we believe (A4) is a reasonable assumption (at least for many DL tasks)	I-Reply	I-2	Reply	20255

(Please find my response to the rebuttal and updated version in a comment below)[line_break_token]The paper analyses latent-variable modeling from a rate-distortion point-of-view in a novel and interesting fashion, highlighting important fundamental connections.	O	O	Review	555
In particular, the paper presents a novel theorem (inspired by how the rate-distortion function is computed) that gives a lower bound on the negative log likelihood.	O	O	Review	555
This lower bound allows to quantify by how much a latent-variable model could be improved by either modifying the prior or the likelihood function.	O	O	Review	555
The latter is important, since the paper shows a duality between improving one while keeping the other fixed and vice versa.	O	O	Review	555
Finally, the paper derives a practical implementation/approximation (founded on solid theoretical analysis) of quantifying the improvement potential of a latent-variable model.	O	O	Review	555
These, so called ‚Äúglossy statistics‚Äù are quantitatively analyzed in a set of experiments with different variational autoencoder architectures (various likelihood models and priors) on a number of datasets.	O	O	Review	555
[line_break_token][line_break_token]The main contribution of this paper is to provide novel proofs and theoretical analysis that connect latent-variable modeling with rate-distortion on a very fundamental level.	O	O	Review	555
While similar attempts have been reported in the recent literature (perhaps a bit more focused on the empirical aspects), the analysis and results in the paper follow a very fundamental treatment of rate-distortion theory and in particular of computation of the rate-distortion function.	O	O	Review	555
The central idea underlying rate-distortion, i.e. lossy compression by discarding irrelevant information, seems very suitable as a guiding principle for representation learning.	O	O	Review	555
In particular, learning representations that generalize well is essentially another instance of a lossy compression problem.	O	O	Review	555
The paper thus addresses an important and timely topic which should be of broad interest to the representation learning community.	O	O	Review	555
The paper is well written and mathematically rigorous.	O	O	Review	555
I have checked most parts of the proofs, though there still is a chance that I missed something.	O	O	Review	555
I am not entirely convinced by the practical impact of the experimental section of the paper (though the experiments are beyond toy-level and I do not doubt the results), but I also believe that this is not the main contribution of the paper, which is rather laying the mathematical groundwork for future work.	O	O	Review	555
I vote and argue for accepting the paper for presentation at the conference.	O	O	Review	555
My criticism below is aimed at giving some pointers for potentially improving the paper.	O	O	Review	555
[line_break_token][line_break_token]1) As the paper acknowledges, there is a risk of overfitting when improving likelihood functions under fixed priors (and vice versa).	B-Review	B-1	Review	555
While the glossy statistics certainly allow making approximate statements of whether the model can be improved further or not, there is no ‚Äúthreshold value‚Äù or other guideline that would indicate a modeling expert that they are entering an over-fitting regime if the model-class is further enriched.	I-Review	I-1	Review	555
Therefore, I am not sure about the practical impact of the experiments: the glossy statistics seem to be indicative of the margin for improvements in the negative log-likelihood - but whether all of these improvements are really desirable is unclear.	I-Review	I-1	Review	555
To test this, one might resort to tasks other than generative modeling, such that models that overfit can easily be ‚Äúspotted‚Äù (by degrading test-set performance).	I-Review	I-1	Review	555
[line_break_token][line_break_token]2) Rate-Distortion can be ‚Äúmade more robust‚Äù against overfitting by different choices of \alpha (essentially limiting channel capacity).	B-Review	B-2	Review	555
Maybe I am missing something, but shouldn‚Äôt the \alpha carry over into the computation of the ratios for c(z)?	I-Review	I-2	Review	555
Was it just assumed to be 1?	I-Review	I-2	Review	555
The same question for Theorem 2 and the equation just above Theorem 2 - does the alpha drop (is it absorbed into the likelihood) or was it set to one?	I-Review	I-2	Review	555
It might be interesting to see how the glossy statistics behave if \alpha is considered a hyper-parameter of the model, e.g. under ‚Äúlow capacity‚Äù do the glossy statistics ‚Äúflatten out‚Äù very early?	I-Review	I-2	Review	555
[line_break_token][line_break_token]3) I would have been excited to see how the glossy statistics evolve during training of a model - it would be interesting to show that the statistics initially predict a large margin of improvement that reduces and slowly flattens out as training converges.	B-Review	B-3	Review	555
[line_break_token][line_break_token]4) In the paragraph after Eq.	B-Review	B-4	Review	555
14: the argument hinges on the possibility of having an invertible (and continuously differentiable) g(z).	I-Review	I-4	Review	555
To me it is not straightforward that a neural network would necessarily implement such a function (particularly the invertibility might be problematic).	I-Review	I-4	Review	555
Is this just a technical condition required for the formal statement, or do you think that this issue could become problematic in practice as well such that the duality between improving prior and likelihood does not hold any longer?	I-Review	I-4	Review	555
[line_break_token][line_break_token]Minor:[line_break_token]5) I think the Alemi et al reference (first reference) has been published under a different name (Fixing a Broken ELBO) at this years‚Äô ICML.	O	O	Review	555
[line_break_token][line_break_token]6) Consider calling the quantity l(x|z) below Eq.	B-Review	B-5	Review	555
1 ‚Äúthe likelihood of the latent variable given the data‚Äù (since the data is given, even though the data is not in the conditional, which is why it is a likelihood function).	I-Review	I-5	Review	555
[line_break_token][line_break_token]7) Rather than using ‚Äúthe KL divergence between‚Äù, use ‚Äúthe KL divergence from ‚Ä¶ to‚Äù which nicely reflects its asymmetry.	I-Review	I-5	Review	555
[line_break_token][line_break_token]8) Page 4, last Equation: square brackets for E_X missing[line_break_token]	I-Review	I-5	Review	555
1) On overfitting - In the experimental setup, we let the training of the models proceed until the log likelihood on a validation data set shows no sign of improvement for a given number of epochs, and then revert back to the best model found during the training.	B-Reply	B-1	Reply	555
We then calculate the glossy statistics based on such best model.	I-Reply	I-1	Reply	555
If the glossy statistics indicate that it is becoming harder to improve the model, then we have "the best of both worlds" - a model that is not overfitting that is also becoming harder to improve.	I-Reply	I-1	Reply	555
If the glossy statistics suggest that it is still possible to improve the model, then we agree that it is possible that the improvement is undesirable as it could lead to overfitting.	I-Reply	I-1	Reply	555
Still, we believe that the glossy statistics do tell something interesting to the statistician in this case.	I-Reply	I-1	Reply	555
We believe that a good statistician should be able to spot when it is that her model is likely to overfit, based on experience (observing how a model overfits when the model allows too much freedom), and should be able to interpret the glossy statistics in this case.	I-Reply	I-1	Reply	555
[line_break_token][line_break_token]We note that in the experiments, we always posted the best model obtained during training in the sense of the procedure involving the validation data set described above (this is, we believe that the models we are posting results for are not overfit).	I-Reply	I-1	Reply	555
We also believe that the experiments show usefulness of the lgossy statistics.	I-Reply	I-1	Reply	555
[line_break_token][line_break_token]We have updated the text of the paper to clarify the procedure involving the validation data set.	O	O	Reply	555
[line_break_token][line_break_token]2) For the log likelihood expression to be a true log likelihood, we need to set, otherwise the statistics and the lower bound are referring to an expression where the likelihood function is raised to the power of.	B-Reply	B-2	Reply	555
Since this is a paper devoted to generative models, we chose to simplify to when we presented the main results - we have now clarified this in the text.	I-Reply	I-2	Reply	555
Rate-distortion theory of course applies to the entire distortion regime which means it gives results for as well (and there is a corresponding variation for in that case).	I-Reply	I-2	Reply	555
We believe the reviewer is correct in his intuition that by using a different, the training can be made more robust against overfitting, in fact in our experiments (not currently in the paper as submitted) we saw small anecdotal evidence that by setting an that is close to, but not exactly 1, the resulting model had a slightly improved test data performance.	I-Reply	I-2	Reply	555
We did not believe the results to be significant enough to be presented as research results at this point.	I-Reply	I-2	Reply	555
We note that even if we train with, the correct way to interpret the results is to then take the resulting model and plug it into our lower bound and glossy statistics with, so that we can obtain a statement for the straight generative model problem.	I-Reply	I-2	Reply	555
[line_break_token][line_break_token]3) We have now added in the appendix what the reviewer is asking for.	B-Reply	B-3	Reply	555
The effect being sought is indeed present.	I-Reply	I-3	Reply	555
[line_break_token][line_break_token]4) We have now eliminated the restriction for the mapping to be invertible and continuously differentiable.	B-Reply	B-4	Reply	555
The result holds under general conditions - we only require to be a measurable function.	I-Reply	I-4	Reply	555
In our initial submission we didn't have enough time to convince ourselves that this was true, but now our Appendix contains a proof of this fact.	I-Reply	I-4	Reply	555
However, we point out if the starting distribution is discrete, or has some discrete portions (as it is obviously the case when the alphabet \mathcal{Z} is finite), it isn't clear that such a mapping can be found.	I-Reply	I-4	Reply	555
We do give examples in the paper of common settings where this mapping is guaranteed to exist.	I-Reply	I-4	Reply	555
[line_break_token][line_break_token]5-8) All suggestions taken	O	O	Reply	555

This paper introduces a model that blends ideas from generative topic models with those from recurrent neural network language models.	O	O	Review	275
The authors evaluate the proposed approach on a document level classification benchmark as well as a language modeling benchmark and it seems to work well.	O	O	Review	275
There is also some analysis as to topics learned by the model and its ability to generate text.	O	O	Review	275
Overall the paper is clearly written and with the code promised by the authors others should be able to re-implement the approach.	O	O	Review	275
I have 2 potentially major questions I would ask the authors to address:[line_break_token][line_break_token]1 - LDA topic models make an exchangability (bag of words) assumption.	B-Review	B-1	Review	275
The discussion of the generative story for TopicRNN should explicitly discuss whether this assumption is also made.	I-Review	I-1	Review	275
On the surface it appears it is since y_t is sampled using only the document topic vector and h_t but we know that in practice h_t comes from a recurrent model that observes y_t-1.	I-Review	I-1	Review	275
Not clear how this clean exposition of the generative model relates to what is actually done.	I-Review	I-1	Review	275
In the Generating sequential text section it‚Äôs clear the topic model can‚Äôt generate words without using y_1 - t-1 but this seems inconsistent with the generative model specification.	I-Review	I-1	Review	275
This needs to be shown in the paper and made clear to have a complete paper.	I-Review	I-1	Review	275
[line_break_token][line_break_token][line_break_token]2 -  The topic model only allows for linear interactions of the topic vector theta.	B-Review	B-2	Review	275
It seems like this might be required to keep the generative model tractable but seems like a very poor assumption.	I-Review	I-2	Review	275
We would expect the topic representation to have rich interactions with a language model to create nonlinear adjustments to word probabilities for a document.	I-Review	I-2	Review	275
Please add discussion as to why this modeling choice exists and if possible how future work could modify that assumption (or explain why it‚Äôs not such a bad assumption as one might imagine)[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]Figure 2 colors very difficult to distinguish.	O	O	Review	275
Thanks for your questions.&nbsp;[line_break_token][line_break_token]1.	O	O	Reply	275
We believe there was a misunderstanding of our proposed model.&nbsp;Unlike LDA, TopicRNN is a sequential model&nbsp;(as expressed in the generative process in the middle of page 4) and as such does not make the exchangeability assumption.&nbsp;[line_break_token]The inference network that produces the topic vector \theta used as bias takes as input Xc which is a bag of words representation of the document.&nbsp;Xc excludes stop words just as done in topic modeling.	O	O	Reply	275
This is where exchangeability is needed and maybe where the confusion is coming from.	B-Reply	B-1	Reply	275
But this is the inference network for \theta, not the actual generative model.	I-Reply	I-1	Reply	275
[line_break_token]&nbsp;[line_break_token]2.	O	O	Reply	275
There are three main reasons behind our choice of using the topic vector as bias instead of passing it into the hidden states of the RNN.&nbsp;[line_break_token][line_break_token]a) First, this enables us to have a clear separation of the contributions of global semantics and those of local dynamics.	B-Reply	B-2	Reply	275
The global semantics come from the topics which are meaningful when stop words are excluded.&nbsp;However, these stop words are needed for the local dynamics of the language model.	O	O	Reply	275
We hence achieve this separation of global vs local via a binary decision model for the stop words.	B-Reply	B-2	Reply	275
It is unclear how to achieve this if we pass the topics to the hidden states of the RNN.	I-Reply	I-2	Reply	275
This is because the hidden states of the RNN&nbsp;will account for all words (including stop words) whereas topics exclude stop words.&nbsp;Passing the topics through the hidden states of the RNN violates this.	O	O	Reply	275
[line_break_token][line_break_token]b) Second, we show empirical evidence that our approach does better than&nbsp;previous ways of integrating topic models into RNNs.&nbsp;This modeling choice also allows discovering interpretable topics within a single model.&nbsp;[line_break_token][line_break_token]c) Finally, this modeling choice allows easier end-to-end training of the model.&nbsp;And we argue that although we do not have the topics directly&nbsp;going into the hidden states, they will affect the whole trained model, including the hidden states&nbsp;due to our end-to-end training approach (unlike the previous work that use pre-trained topic models).	O	O	Reply	275
[line_break_token][line_break_token]We added this note on page 4 of the manuscript	O	O	Reply	275

This paper is built on a simple but profound observation: Frey's bits-back coding algorithm can be implemented much more elegantly when replacing arithmetic coding (AC) with asymmetric numerical systems (ANS), a much more recent development not known at the time, simply due to the fact that it encodes symbols in a stack-like fashion rather than queue-like.	O	O	Review	578
[line_break_token][line_break_token]This simple observation makes for an elegantly written paper, with promising results on MNIST.	O	O	Review	578
I truly enjoyed reading it, and I'm convinced that it will spark some very interesting further work in the field of compression with latent-variable models.	O	O	Review	578
[line_break_token][line_break_token]Having said that, I would like to point out some possible limitations of the proposed approach, which I hope the authors will be able to address/clarify:[line_break_token][line_break_token]1.	O	O	Review	578
At the beginning of section 2.1, the authors define the symbols as chained conditionals prod_n p(s_n | s_1 ... s_n-1), which is generally permissible in AC as well as ANS, as long as the decoding order is taken into account.	B-Review	B-1	Review	578
That is, in AC, the symbols need to be encoded starting with the first symbol in the chain (s_1), while in ANS, the symbols must be encoded starting with the last symbol in the chain, because the decoding order is inverted.	I-Review	I-1	Review	578
[line_break_token][line_break_token]In their description of BB-ANS, the authors omit the discussion of conditional chains.	I-Review	I-1	Review	578
It is unclear to me if a conditioning of the symbols is feasible in BB-ANS due to the necessity to maintain a strict decoding order.	I-Review	I-1	Review	578
It would be very helpful if the authors could clarify this, and update the paper accordingly, because this could present a serious limitation.	I-Review	I-1	Review	578
For instance, the authors simply extrapolate the performance of their method to PixelVAE; however, this model is autoregressive, so a conditioning of symbols seems necessary.	I-Review	I-1	Review	578
Similarly, in appendix A, the authors mention the work of Minnen et al (2018), where the same situation would apply, albeit one probabilistic level higher (on encoding/decoding the latents with an autoregressive prior).	I-Review	I-1	Review	578
[line_break_token][line_break_token]2.	I-Review	I-1	Review	578
Furthermore, in both cases (PixelVAE and Minnen et al), the symbols (s) and latents (y) are defined as jointly conditioned on each other (i.e., computing the posterior on one element of y requires knowledge of all elements of s, and computing the likelihood on one element of s requires knowledge of all elements of y).	B-Review	B-2	Review	578
This seems to imply that all operations pertaining to one data vector (i.e. to one image) would have to be done in a monolithic fashion, i.e.: first sample all elements of y from the stack, then encode all elements of s, and then encode all elements of y. Hence, if the goal is to compress only one image, the algorithm would never get to the point of reusing the "bits back", and the overhead of BB-ANS would be prohibitive.	I-Review	I-2	Review	578
It seems that in the MNIST experiments, the authors avoid this problem by always encoding a large number of images at a time, such that the overhead is amortized.	I-Review	I-2	Review	578
[line_break_token][line_break_token]3.	O	O	Review	578
Similarly, although the compression of continuous-valued variables up to arbitrary precision is an exciting development and I do not wish to undermine the importance of this finding, it should be noted that the finer the quantization gets, the larger the potential overhead of the coding scheme will grow.	B-Review	B-3	Review	578
In practice, this would make it necessary to encode more and more images together, in order to still benefit from the method.	I-Review	I-3	Review	578
This would be a good point to make in the discussion.	I-Review	I-3	Review	578
[line_break_token][line_break_token]4.	O	O	Review	578
The authors state in the appendix that learned compression methods like Ball√© et al (2018) and Minnen et al (2018) could be improved by using BB-ANS.	B-Review	B-4	Review	578
The potential gain of BB-ANS for these models seems rather small, though, as the entropy of y must be larger or equal to the entropy of y conditioned on s: H[y] >= H[y|s], the latter of which should represent the potential coding gain.	O	O	Review	578
Ball√© et al (2018), however, found that the bits used to encode the hierarchical prior (i.e. H[y]) is only a small fraction of the total bitrate, thus upper bounding the potential gains for this type of model.	B-Review	B-4	Review	578
[line_break_token][line_break_token]Overall, I think this is a well-written, important and elegant paper, and I would like to see it accepted at this conference.	O	O	Review	578
If the authors can satisfactorily address some of the above potential limitations, it might turn out to be even better.	O	O	Review	578
[line_break_token]	O	O	Review	578
> 2.	O	O	Reply	578
Furthermore, in both cases (PixelVAE and Minnen et al), the symbols (s) and latents (y) are defined as jointly conditioned on each other (i.e., computing the posterior on one element of y requires knowledge of all elements of s, and computing the likelihood on one element of s requires knowledge of all elements of y).	O	O	Reply	578
This seems to imply that all operations pertaining to one data vector (i.e. to one image) would have to be done in a monolithic fashion, i.e.: first sample all elements of y from the stack, then encode all elements of s, and then encode all elements of y. Hence, if the goal is to compress only one image, the algorithm would never get to the point of reusing the "bits back", and the overhead of BB-ANS would be prohibitive.	O	O	Reply	578
It seems that in the MNIST experiments, the authors avoid this problem by always encoding a large number of images at a time, such that the overhead is amortized.	O	O	Reply	578
[line_break_token][line_break_token]2. (	O	O	Reply	578
RESPONSE) The point you make here is correct.	B-Reply	B-2	Reply	578
When there is no 'other information' to communicate, and only a single sample, or a very small number of i.i.d.	I-Reply	I-2	Reply	578
samples are to be compressed, our method is sub-optimal, and we should certainly have highlighted this limitation in our paper.	I-Reply	I-2	Reply	578
We have extended the first paragraph of Section 2.5 of our paper, emphasizing this point .	I-Reply	I-2	Reply	578
We have also renamed Section 2.5 to "Issues affecting the efficiency of BB-ANS".	I-Reply	I-2	Reply	578
[line_break_token][line_break_token]Nevertheless, we believe there are common use cases where a large enough number of (roughly) i.i.d.	I-Reply	I-2	Reply	578
samples need to be coded, one example being a person's photo library, stored on their computer or smartphone.	I-Reply	I-2	Reply	578
It is also possible that file meta-data could be used as a source of extra information.	I-Reply	I-2	Reply	578
We have yet to investigate whether there is sufficient information in typical real world meta-data to resolve this issue.	I-Reply	I-2	Reply	578
[line_break_token][line_break_token][line_break_token][line_break_token]> 3.	O	O	Reply	578
Similarly, although the compression of continuous-valued variables up to arbitrary precision is an exciting development and I do not wish to undermine the importance of this finding, it should be noted that the finer the quantization gets, the larger the potential overhead of the coding scheme will grow.	O	O	Reply	578
In practice, this would make it necessary to encode more and more images together, in order to still benefit from the method.	O	O	Reply	578
This would be a good point to make in the discussion.	O	O	Reply	578
[line_break_token][line_break_token]3. (	O	O	Reply	578
RESPONSE) This is a good point, which is definitely worth mentioning.	B-Reply	B-3	Reply	578
We have added an extra paragraph discussing this point, near the end of Section 2.5.1.	I-Reply	I-3	Reply	578
We also mention that we found that increasing the precision past around 16 bits yielded no measurable gains in compression rate.	I-Reply	I-3	Reply	578
We think this is because the models we used (like most machine learning implementations) operated at 32 bit floating point precision.	I-Reply	I-3	Reply	578
[line_break_token][line_break_token][line_break_token][line_break_token]> 4.	O	O	Reply	578
The authors state in the appendix that learned compression methods like Ball√© et al (2018) and Minnen et al (2018) could be improved by using BB-ANS.	O	O	Reply	578
The potential gain of BB-ANS for these models seems rather small, though, as the entropy of y must be larger or equal to the entropy of y conditioned on s: H[y] >= H[y|s], the latter of which should represent the potential coding gain.	O	O	Reply	578
Ball√© et al (2018), however, found that the bits used to encode the hierarchical prior (i.e. H[y]) is only a small fraction of the total bitrate, thus upper bounding the potential gains for this type of model.	O	O	Reply	578
[line_break_token][line_break_token]4. (	O	O	Reply	578
RESPONSE) Thanks a lot for pointing that out.	O	O	Reply	578
The paragraph in question here is not central to our paper.	B-Reply	B-4	Reply	578
However we feel that in spite of the limited gains in compression rate from BB-ANS in the case of the two papers mentioned, it's still worth us including this paragraph, particularly because it's quite possible that in future work similar to the two papers mentioned the gain from getting the bits back could be more significant.	I-Reply	I-4	Reply	578
We've reworded the paragraph, incorporating the bound which you mention.	I-Reply	I-4	Reply	578
[line_break_token][line_break_token]References[line_break_token]---------------[line_break_token][1] Johnson, M., Duvenaud, D., Wiltschko, A., Datta, S. and Adams, R. (2016).	O	O	Reply	578
Composing graphical models with neural networks for structured representations and fast inference.	O	O	Reply	578
In Advances in Neural Information Processing Systems (NIPS)	O	O	Reply	578

This work targets learning flow fields for two-dimensional Rayleigh-Benard convections inspired by hybrid RANS-LES turbulence models.	O	O	Review	496
[line_break_token][line_break_token]Internally, the approach employs three U-nets which are each trained to predict a 32 dimensional feature space from three variants of filtered velocity fields.	O	O	Review	496
These three feature spaces are (probably) concatenated and translated to an output velocity via a fourth U-net.	O	O	Review	496
While the overall architecture is intuitive, details are missing in the text.	O	O	Review	496
[line_break_token][line_break_token]I also assume that the network outputs w for timestep t+1, which is the sole input for the next evaluation of the network?	B-Review	B-1	Review	496
A regular flow solver is not used in conjunction with this network, but the results (i.e. sequences) shown are purely inferred by the network? (	I-Review	I-1	Review	496
I guess G2 uses multiple frames - what is used for T here, btw.?)	I-Review	I-1	Review	496
[line_break_token][line_break_token]These details, plus specifics of each layer should be written out (e.g. in the appendix), together with operations such as the merging of the three encoder outputs to make the work reproduicble.	B-Review	B-2	Review	496
I hope the authors can also clarify these points in the rebuttal.	I-Review	I-2	Review	496
[line_break_token][line_break_token]For a future version, I'd also recommend to rephrase equations (2) and (3).	B-Review	B-3	Review	496
The split into w, w-bar and w-tilde is not compatible with figure 2.	I-Review	I-3	Review	496
The figure uses the split from equations (6,7), so it would be good to make this clear via the notation.	I-Review	I-3	Review	496
[line_break_token][line_break_token]As training data, the model uses single RBC data set produced with a lattice boltzmann method.	O	O	Review	496
It's a pity only a single case is shown, as the method claims to learn a general turbulence model.	B-Review	B-5	Review	496
Do the authors have a second data set on which they could demonstrate the method?	I-Review	I-5	Review	496
This would show help to show generality of the approach.	I-Review	I-5	Review	496
[line_break_token][line_break_token]The RBC test case is used to train a nice range of different methods, from a simple ResNet to approaches from previous work, and the results are evaluated with a good range of turbulence metrics.	O	O	Review	496
These evaluations show nice improvements, e.g., the RMSEs over time in figure 4 are consistently lower.	O	O	Review	496
Unfortunately, it's not made clear which data is evaluated - is this a single training case, or e.g. averaged for the whole test set?	B-Review	B-4	Review	496
Likewise for figure 6 and 7.	O	O	Review	496
[line_break_token][line_break_token]Very minor, but I'd recommend to rephrase the last sentence of the fluid animation discussion.	B-Review	B-6	Review	496
Those works are part of computer science, which arguably also counts as science.	I-Review	I-6	Review	496
[line_break_token][line_break_token]Overall, I found the split into temporally and spatially filtered components of the flow field is an interesting one, and it's nice to see how well this seems to work.	O	O	Review	496
The paper certainly does not aim for new insight for deep learning methods in general, but provides an interesting application for turbulent flows that is evaluated with a nice amount of detail.	O	O	Review	496
If the authors can address the unclear points mentioned above, and maybe include a second test case that is evaluated on a subset of the different models, I think this paper could be included in the ICLR program.	B-Review	B-4	Review	496
[line_break_token]	O	O	Review	496
hanks so much for your detailed comments.	O	O	Reply	496
[line_break_token][line_break_token]&gt;&gt;&gt; I also assume that the network outputs w for timestep t+1, which is the sole input for the next evaluation of the network?	O	O	Reply	496
A regular flow solver is not used in conjunction with this network, but the results (i.e. sequences) shown are purely inferred by the network? (	O	O	Reply	496
I guess G2 uses multiple frames - what is used for T here, btw.?)	O	O	Reply	496
[line_break_token]Answer: Yes, for all CNN based models included in our paper, we make predictions in an autoregressive manner.	B-Reply	B-1	Reply	496
Suppose V is the Velocity field, N is the number of input frames and T is the timestamp for the last input frame.	I-Reply	I-1	Reply	496
The models took N initial frames V(T-N+1,..,T) as input to make the first prediction for the next step(T+1), then we feed the prediction at (T+1) back to the input V(T-N+2,..,T+1) to make predictions for time step T+2, and repeat for 60 times.	I-Reply	I-1	Reply	496
 \bar{w} is a weighted average, T here is the moving average window size.	I-Reply	I-1	Reply	496
[line_break_token][line_break_token]&gt;&gt;&gt; These details, plus specifics of each layer should be written out (e.g. in the appendix), together with operations such as the merging of the three encoder outputs to make the work reproducible.	O	O	Reply	496
I hope the authors can also clarify these points in the rebuttal.	O	O	Reply	496
[line_break_token]Answer:  The detailed numbers of each layer are shown in Figure 2.	B-Reply	B-2	Reply	496
The merging of the three encoder outputs is simply summation.	I-Reply	I-2	Reply	496
We will open source our implementation in the final version.	I-Reply	I-2	Reply	496
[line_break_token][line_break_token]&gt;&gt;&gt; For a future version, I'd also recommend to rephrase equations (2) and (3).	O	O	Reply	496
The split into w, w-bar and w-tilde is not compatible with figure 2.	O	O	Reply	496
The figure uses the split from equations (6,7), so it would be good to make this clear via the notation.	O	O	Reply	496
[line_break_token]Answer: Thanks for pointing it out.	B-Reply	B-3	Reply	496
We modified those two equations in the updated version.	I-Reply	I-3	Reply	496
[line_break_token][line_break_token]&gt;&gt;&gt; Unfortunately, it's not made clear which data is evaluated - is this a single training case, or e.g. averaged for the whole test set?	O	O	Reply	496
Likewise for figure 6 and 7.	O	O	Reply	496
[line_break_token]Answer: All evaluation metrics are averaged over the whole test set.	B-Reply	B-4	Reply	496

&gt; What is the specific question/problem tackled by the paper?	O	O	Review	378
[line_break_token]This paper tackles a restricted multi-task setting where the task is known.	B-Review	B-1	Review	378
The main contribution is a new architecture for training a task conditional model.	I-Review	I-1	Review	378
The new architecture is reminiscent of an encoder-decoder-classifier with ladder (latent) connections, the decoder is conditioned on task ID.	I-Review	I-1	Review	378
The claim is this is a type of modulation, it is unclear.	I-Review	I-1	Review	378
Results on three multi-task datasets show that the proposed method is slightly better than compared methods and single task learning.	I-Review	I-1	Review	378
There is no theory or loss function to analyze.	I-Review	I-1	Review	378
[line_break_token][line_break_token]&gt; Is the approach well motivated, including being well-placed in the literature?	O	O	Review	378
[line_break_token]In my opinion, this is lacking.	B-Review	B-2	Review	378
The assumption that task ID is known is fairly severe.	I-Review	I-2	Review	378
Unfortunately the prior works cited also have this restriction, whereas few papers under the topic of continual learning have removed this limitation.	I-Review	I-2	Review	378
This assumption/drawback needs to be clearly mentioned in the paper and discussed if it is realistic?	I-Review	I-2	Review	378
A related shortcoming is that the training data simultaneously comes from all the tasks, whereas prior work has looked at the more interesting setup where tasks arrive sequentially and incrementally.	I-Review	I-2	Review	378
[line_break_token]- Reference [1] seems relevant and should be cited as it shows context dependent gating of tasks / modulation as well.	I-Review	I-2	Review	378
Other missing references e.g. learning without forgetting (LwF) [2] and [3]. [line_break_token]- There is not a clear explanation to think that this is modulation since the result is only passed through a residual connection.	I-Review	I-2	Review	378
More importantly there is no discussion on these important issues.	I-Review	I-2	Review	378
I found the writing to be brief and sketched.	I-Review	I-2	Review	378
[line_break_token]- in the introduction, it would be good to define multi-task learning with the assumption made clear.	I-Review	I-2	Review	378
It would be good to introduce what you mean by TD and BU clearly[line_break_token]- Another drawback is assuming the tasks being encoded as integers, whereas there might be a continuous task space with interpolation, or hierarchical task structure.	I-Review	I-2	Review	378
[line_break_token]- "However, all of these works modulate the recognition network[line_break_token]channel-wise, using the same modulation vector for all the spatial dimension of the feature-maps." -	I-Review	I-2	Review	378
why is this not enough?	I-Review	I-2	Review	378
A nontrivial explanation or discussion is needed.	I-Review	I-2	Review	378
Simply extending to W(t, y, x, ch) would increase performance by a little.	I-Review	I-2	Review	378
[line_break_token]- how is the proposed model different from a conditional model like a task conditional classifier?	I-Review	I-2	Review	378
Also in experiments.	I-Review	I-2	Review	378
[line_break_token]- How is the proposed model different from an encoder-decoder?	I-Review	I-2	Review	378
The impact of "modulation" is not clear.	I-Review	I-2	Review	378
[line_break_token]- "We can scale the number of tasks with no additional layers." -	I-Review	I-2	Review	378
task conditional classifier can also scale in this way to the number of tasks.	I-Review	I-2	Review	378
This claim is not valid.	I-Review	I-2	Review	378
[line_break_token]- Page 3: "uncorrelated gradients from the different tasks" - need not be uncorrelated, but still can be interfering[line_break_token]- next about Kendall (2018) and Sener (2018) - need to compare and contrast to them.	I-Review	I-2	Review	378
[line_break_token]- Last para on page 3 seems not relevant.	I-Review	I-2	Review	378
[line_break_token]- Modulation equations: this seems specific to CNNs.	I-Review	I-2	Review	378
How would you extend this technique to beyond CNNs to recurrent units or even simpler MLPs?	I-Review	I-2	Review	378
Modulation as a technique has been successfully applied in these architectures as well.	I-Review	I-2	Review	378
[line_break_token]- "added to the input tensor X through a residual connection" - this is not clear at all.	I-Review	I-2	Review	378
Are the residual connections not shown in Fig 1(d)?	I-Review	I-2	Review	378
[line_break_token]- "it to be unfeasible due to their large dimensions" - can you explain please?	I-Review	I-2	Review	378
later you say "To avoid the unfeasible computation burden of directly optimizing W"[line_break_token]- Fig 1d, would be good to mark the modulation arrows in a different color[line_break_token][line_break_token]&gt; Does the paper support the claims?	B-Review	B-3	Review	378
This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.	I-Review	I-3	Review	378
[line_break_token]Having said that, I like the experimental section even in the restricted setup.	I-Review	I-3	Review	378
But a lot of details are missing.	I-Review	I-3	Review	378
It is not surprising that there is slight increase in performance over channel modulation due to the increase expressivity.	I-Review	I-3	Review	378
[line_break_token]- table 1: why is there degradation in the LL task across all methods?	I-Review	I-3	Review	378
the introduction of an additional task seems to bring the performance back up.	I-Review	I-3	Review	378
It seems to be a weakness of your method.	I-Review	I-3	Review	378
Please improve the discussion.	I-Review	I-3	Review	378
I'm inclined to think that the tasks are not uncorrelated, as claimed by the authors.	I-Review	I-3	Review	378
[line_break_token]- table 1: how did you arrive at the number of parameters like 1.12x?	I-Review	I-3	Review	378
Doesn't the separate BU and TD nets mean you have at least 2x parameters compared to single task?	I-Review	I-3	Review	378
It seems the larger number of params in single task is mainly coming from the hidden layers?	I-Review	I-3	Review	378
[line_break_token]- table 1: it would be fair for the comparison methods to have equal number of parameters as the proposed method.	I-Review	I-3	Review	378
[line_break_token]- Missing experimental comparison to Kendall et al 2018[line_break_token]- Missing details about reproduction of results from Sener (2018)[line_break_token]- An important baseline would be to show image sensitive full tensor modulation without the new architecture.	I-Review	I-3	Review	378
Similar to XdG.[line_break_token]- Another baseline should be a task-conditional classifier that takes task as input along with the image.	I-Review	I-3	Review	378
[line_break_token]- ablation study: what are the auxiliary losses?	I-Review	I-3	Review	378
I could not find any details.	I-Review	I-3	Review	378
[line_break_token]- The third experiment with CUB seems to use a different loss function that the other methods.	I-Review	I-3	Review	378
This is somewhat hard to evaluate.	I-Review	I-3	Review	378
[line_break_token]- number of parameters are not reported for the CUB experiment[line_break_token]- "where only a single pixel is labeled as foreground, blurred by a Gaussian kernel" needs more details about the smoothing[line_break_token]- In the CUB experiment, due to lateral connections, the top-down result 224x224 image is not the only input to the BU2 classifier, the interpretability argument is weak.	I-Review	I-3	Review	378
[line_break_token]- Why did you choose these 4 questions from CLEVR?	I-Review	I-3	Review	378
There are many interesting types of questions that can be handled.	I-Review	I-3	Review	378
[line_break_token][line_break_token]	O	O	Review	378
irst of all, thanks for the thoughtful review.	O	O	Reply	378
[line_break_token][line_break_token]Regarding your general concern about the scope of the paper (known task-ID is a severe condition, continual learning is more interesting).	O	O	Reply	378
[line_break_token]We agree that there are other realistic setting but we also follow an interesting, realistic and an active line of research.	B-Reply	B-2	Reply	378
References [1], [2], [3], [4] all uses a setting similar to ours (modulation networks with a known task-ID).	I-Reply	I-2	Reply	378
Reference [4] is interesting in this aspect as it applies channel-wise modulation networks with a given task-ID to continual learning applications.	I-Reply	I-2	Reply	378
We, on the other hand, continue this line of research by extending channel-wise modulation tensor-modulation ...[line_break_token][line_break_token][1]  A Modulation Module for Multi-task Learning with Applications in Image Retrieval, ECCV 2018[line_break_token][2]  Attentive Single-Tasking of Multiple Tasks, CVPR 2019[line_break_token][3] Many Task Learning with Task Routing, arxiv preprint[line_break_token][4] Superposition of many models into one, arxiv preprint[line_break_token][line_break_token]Request - you gave several reference numbers in the review, but the references were not listed.	O	O	Reply	378
can you add them?	O	O	Reply	378
[line_break_token][line_break_token]We next go through specific comments:[line_break_token][line_break_token]A major remark was to justify and quantify our main technical contribution (adding 1.	B-Reply	B-2	Reply	378
spatial-wise and 2, image-aware modulation to the existed channel-wise modulation architectures.	I-Reply	I-2	Reply	378
We motivated our contribution in the introduction (page 2, paragraph 2) and now added to specifically quantify the contribution of each of our additions, summarized in table 2a, section 4.3.2.	I-Reply	I-2	Reply	378
[line_break_token][line_break_token]We rewrote section 3 (Approach) to better explain our modulation scheme.	I-Reply	I-2	Reply	378
We treat it as a modulation because adding the residual connections change x*w to x*(w+1).	I-Reply	I-2	Reply	378
Following your question, we have also explained why a naive extension of [1] is infeasible (briefly, the number of parameters to optimize is to large and depend on H, W and the number of tasks - it cannot be applied to large images and is not scalable with the number of tasks).	I-Reply	I-2	Reply	378
[line_break_token][line_break_token]We added an appendix with a calculation of the number of parameters.	I-Reply	I-2	Reply	378
Briefly, for K tasks ‚Äì a single task networks use one separate network for each task (K times the number of parameters found in a single base network), Multi-branched architectures add several branches on a common backbone (one backbone + the number of parameters within a branch times K), our architecture uses only one branch and our TD usually has much less parameters than the BU backbone (because if a convolutional stage uses a series of convolutions like (256-&gt;512, 512-&gt;512) we use (512-&gt;256, 256-&gt;256)).	O	O	Reply	378
[line_break_token][line_break_token]We reproduced the results of Sener(2018) from their official github code.	B-Reply	B-2	Reply	378
      [line_break_token][line_break_token]Regarding the reduced performance on the LL digit:[line_break_token]Several M-MNIST images are demonstrated in figure 2 in the article.	B-Reply	B-3	Reply	378
The digits are i.i.d.	I-Reply	I-3	Reply	378
between images and between tasks (uncorrelated).	I-Reply	I-3	Reply	378
We believe that the degradation of the LL task accuracy is because the specific overlap areas of this task/location carry useful information for the classification process.	I-Reply	I-3	Reply	378
[line_break_token][line_break_token]We have updated the article and uploaded a revised version based on the reviews	O	O	Reply	378

This paper presents learning a spatio-temporal embedding for video instance segmentation.	O	O	Review	431
With spatio-temporal embedding loss, it is claimed to generate temporally consistent video instance segmentation.	O	O	Review	431
The authors show that the proposed method performs nicely on tracking and segmentation task, even when there are occlusions.	O	O	Review	431
[line_break_token][line_break_token]Overall, this paper is well-written.	B-Review	B-1	Review	431
Section 3 clearly explains the loss functions.	I-Review	I-1	Review	431
The main idea is not very complex, but generally makes sense.	I-Review	I-1	Review	431
The authors mention that scenes are assumed to be mostly rigid, and appearance change is mostly due to the camera motion.	I-Review	I-1	Review	431
I would like to see more argument about this, as there are cases if this is obviously not true; for instance, human changes pose significantly.	I-Review	I-1	Review	431
If we limit the range of discussion to some narrow domain, such as self-driving, this might be more valid, but we may want to see some discussion about validity of this assumption.	I-Review	I-1	Review	431
[line_break_token][line_break_token]Some modules are not full explained in detail.	B-Review	B-2	Review	431
For example, what is the background mask network?	I-Review	I-2	Review	431
Which model was used, and how was it trained?	I-Review	I-2	Review	431
[line_break_token][line_break_token]In experiment, the proposed method shows nice score on MOTSA and sMOTSA, but all other metrics, it is on the worse side.	B-Review	B-3	Review	431
The authors are encouraged to discuss more about the metrics and experimental results with the other metrics as well.	I-Review	I-3	Review	431
Other than these, the experiment was well-designed and conducted.	I-Review	I-3	Review	431
any thanks for the feedback.	O	O	Reply	431
Here‚Äôs our answer to the concerns you have raised:[line_break_token][line_break_token]1. ‚	O	O	Reply	431
ÄúThe authors mention that scenes are assumed to be mostly rigid, and appearance change is mostly due to the camera motion.	O	O	Reply	431
I would like to see more argument about this, as there are cases if this is obviously not true; for instance, human changes pose significantly.	O	O	Reply	431
If we limit the range of discussion to some narrow domain, such as self-driving, this might be more valid, but we may want to see some discussion about validity of this assumption.	O	O	Reply	431
‚Äù[line_break_token][line_break_token]Our model learns depth in a self-supervised way using a photometric reconstruction loss, which operates under the assumption of a moving camera and a static scene.	B-Reply	B-1	Reply	431
When this hypothesis does not hold true, for example when the camera is stationary or some scene objects are in motion, performance can rapidly deteriorate.	I-Reply	I-1	Reply	431
During test time, objects that are typically seen in motion during training are then assigned an infinite depth value.	I-Reply	I-1	Reply	431
To overcome this problem, we simply mask during training the pixels that do not change appearance from frame to frame (details in Appendix A.1).	I-Reply	I-1	Reply	431
Since these pixels are often associated with objects moving at the same velocity as the camera, or to scenarios when the camera stops moving, this masking approach effectively removes the pixels that violates the rigid scene assumption.	I-Reply	I-1	Reply	431
[line_break_token][line_break_token]During inference however, our model is able to correctly predict the depth maps of moving objects: see some examples here <a href="https://drive.google.com/open?id=1u-kGxQEWIoC6FguUiXFHyxUcOiG2iIIf" target="_blank" rel="nofollow">https://drive.google.com/open?id=1u-kGxQEWIoC6FguUiXFHyxUcOiG2iIIf</a> [line_break_token][line_break_token]2. "	O	O	Reply	431
Some modules are not full explained in detail.	O	O	Reply	431
For example, what is the background mask network?	O	O	Reply	431
Which model was used, and how was it trained?"	O	O	Reply	431
[line_break_token][line_break_token]The background mask network is described in Appendix A.1: it is a ResNet network with a U-net structure and was trained on KITTI.	B-Reply	B-2	Reply	431
[line_break_token][line_break_token]3. "	O	O	Reply	431
In experiment, the proposed method shows nice score on MOTSA and sMOTSA, but all other metrics, it is on the worse side.	O	O	Reply	431
The authors are encouraged to discuss more about the metrics and experimental results with the other metrics as well."	O	O	Reply	431
[line_break_token][line_break_token]Please refer to the general response (point 3)	B-Reply	B-3	Reply	431

This work is motivated by the widely recognized issue of over-parameterization in modern neural nets, and proposes a clever template sharing design to reduce the model size.	O	O	Review	538
The design is sound, and the experiments are valid and thorough.	O	O	Review	538
The writing is clear and fluent.	O	O	Review	538
[line_break_token][line_break_token]The reviewer is not entirely sure of the originality of this work.	O	O	Review	538
According to the sparse 'related work' section, the contribution is novel, but I will leave it to the consensus of others who are more versed in this regard.	O	O	Review	538
[line_break_token][line_break_token]The part that I find most interesting is the fact that template sharing helps with the optimization without even reducing the number of parameters, as illustrated in CIFAR from Table 1.	O	O	Review	538
The trade-off of accuracy and parameter-efficiency is overall well-studied in CIFAR and ImageNet, although results on ImageNet is not as impressive.	O	O	Review	538
[line_break_token][line_break_token]Regarding the coefficient alpha, I'm not sure how cosine similarity is computed.	B-Review	B-1	Review	538
I have the impression that each layer has its own alpha, which is a scalar.	I-Review	I-1	Review	538
How is cosine similarity computed on scalars?	I-Review	I-1	Review	538
[line_break_token][line_break_token]In the experiments, there's no mentioning of the regularization terms for alpha, which makes me think it is perhaps not important?	B-Review	B-2	Review	538
What is the generic setup?	I-Review	I-2	Review	538
[line_break_token][line_break_token]In summary, I find this work interesting, and with sufficient experiments to backup its claim.	O	O	Review	538
On the other hand, I'm not entirely sure of its novelty/originality, leaving this part open to others.	B-Review	B-3	Review	538
With respect to novelty, we do not believe there is any existing work that utilizes a parameter sharing scheme toward the objective we accomplish here: training a deep network and then folding it into a recurrent form.	B-Reply	B-3	Reply	538
 Please also see our detailed reply to AnonReviewer2.	I-Reply	I-3	Reply	538
[line_break_token][line_break_token]1- Regarding the coefficient alpha, I'm not sure how cosine similarity is computed.	O	O	Reply	538
I have the impression that each layer has its own alpha, which is a scalar.	O	O	Reply	538
How is cosine similarity computed on scalars?	O	O	Reply	538
[line_break_token][line_break_token]Each layer i has its own alpha parameter, denoted by alpha^(i) in the manuscript (refer to equation 1 on page 3), but each alpha is a k-dimensional vector, where k is the number of templates to which that layer has access.	B-Reply	B-1	Reply	538
For the SWRN-L-w-k models we use in the experiments, the same k denotes the number of templates each layer can use, so the dimensionality of each alpha ranges from 1 (in this case it‚Äôs just a scalar) to 6 in our experiments.	I-Reply	I-1	Reply	538
[line_break_token][line_break_token]We made alpha bold in the current version of the manuscript to clarify that it is a vector (except when k=1).	O	O	Reply	538
[line_break_token][line_break_token]2 - In the experiments, there's no mentioning of the regularization terms for alpha, which makes me think it is perhaps not important?	O	O	Reply	538
What is the generic setup?	O	O	Reply	538
[line_break_token][line_break_token]We tried applying L2 regularization to the alpha parameters in our initial experiments, but observed a performance drop, so all reported experiments have no regularization on the alphas.	B-Reply	B-2	Reply	538
[line_break_token][line_break_token]As for the recurrence regularizer described in the end of Section 3.2, where we regularize the Layer Similarity Matrix, it was only used for the experiments in Section 4.4 -- more specifically, the ‚ÄúSCNN, lambda_R = 0.01‚Äù model depicted in Figure 5.	I-Reply	I-2	Reply	538
It was not used for any other experiments, meaning that the observed patterns (e.g. the Layer Similarity Matrices in Figure 4) emerge naturally during optimization, where neither the alphas nor the LSMs had any regularization	I-Reply	I-2	Reply	538

*Summary*[line_break_token]This paper leverages the piecewise linearity of predictions in ReLU neural networks to encode and learn piecewise constant predictors akin to oblique decision trees (trees with splits made on linear combinations of features instead of axis-aligned splits).	O	O	Review	10028
The core observation is that the Jacobian of a ReLU network is piecewise constant w.r.t to the input.	O	O	Review	10028
This Jacobian is chosen to encode the hard splits of a decision tree.	O	O	Review	10028
The paper establishes an exact equivalence between decision trees and a slightly modified form of the locally constant networks (LCN).	O	O	Review	10028
The LCN used for experiments is slightly relaxed to allow for training, including "annealing" from a the softplus nonlinearity to ReLU during training, adding one or more output layers to perform the final prediction, and training with connection dropout.	O	O	Review	10028
Experiments show LCN models outperform existing methods for oblique decision trees, but ensembles are often matched or outperformed by random forests.	O	O	Review	10028
[line_break_token][line_break_token]*Rating*[line_break_token]Perhaps the greatest attribute of decision trees is utter simplicity. (	O	O	Review	10028
The second best attribute the out-of-the-box competitive accuracy of tree ensembles on a wide variety of problems.)	O	O	Review	10028
An argument to be made for this paper is that it leverages the machinery of learning DNNs to learn more powerful, oblique tree-like models.	O	O	Review	10028
The counterpoint is that despite the added complication, it's still often beaten by ensembles of CART trees.	O	O	Review	10028
Overall, the idea is clever, the presentation could be improved slightly, and the experiments raise existential questions for this kind of work.	O	O	Review	10028
My current rating is weak reject.	O	O	Review	10028
[line_break_token][line_break_token](1) It's difficult to know how LCNs should be compared to traditional decision trees, with accuracy, number of parameters, prediction speed, and training time/parallelism as viable components.	B-Review	B-1	Review	10028
The paper focuses almost exclusively on accuracy, while cross-validating over model sizes and other hyperparameters.	I-Review	I-1	Review	10028
This is a reasonable choice, though a discussion of model size and prediction speed would be welcome.	I-Review	I-1	Review	10028
I do have two significant questions about the experiments:[line_break_token][line_break_token](2) It seems unfair that LCN has access to one or more hidden layers between the splits and the final output, denoted g_\phi.	B-Review	B-2	Review	10028
Would competing decision tree models improve with such a layer learned and appended to the final tree?	I-Review	I-2	Review	10028
Would LCN suffer from using a tabular representation like the others?	I-Review	I-2	Review	10028
[line_break_token][line_break_token](3) Despite the assertion that these are datasets that necessitate tree-like predictors, the LLN method outperforms LCN and the trees on 4/5 datasets and is competitive with ensemble methods.	B-Review	B-3	Review	10028
While not explicitly stated, am I correct that LLN is essentially a traditional ReLU-network?	I-Review	I-3	Review	10028
If high accuracy is the goal, then why should I go to the trouble of training LCN when a traditional DNN is better.	I-Review	I-3	Review	10028
And if a tree is needed, then LCNs should be evaluated on more than just accuracy.	I-Review	I-3	Review	10028
[line_break_token][line_break_token](4) LCNs seem to present a less bulky alternative to e.g. Deep Neural Decision Trees (<a href="https://arxiv.org/abs/1806.06988)," target="_blank" rel="nofollow">https://arxiv.org/abs/1806.06988),</a> but that work should be cited and discussed[line_break_token][line_break_token](5) The proof sketch in Section 3.6 of the equivalence between the "standard architecture" and decision trees is difficult to understand and not convincing. (	B-Review	B-5	Review	10028
On second reading I noticed the subtle vector "\mathbf 0" indicating that all entries of "\grad_x a^i_1" are zero.	I-Review	I-5	Review	10028
Some further exposition and enumeration of steps would clear up confusion.)	I-Review	I-5	Review	10028
[line_break_token][line_break_token](6) Overall the presentation is reasonable, other than the notes below.	B-Review	B-6	Review	10028
I did find myself searching back over the (dense) notation section and following sections looking for definitions of variables and terms used later.	I-Review	I-6	Review	10028
Consider better formatting (e.g. more definitions in standalone equations), strategic pruning of some material to make it less dense, and repeating some definitions in line (e.g. see below for "p7:... remind the reader").	I-Review	I-6	Review	10028
[line_break_token][line_break_token]*Notes*[line_break_token](Spelling typos throughout; most are noted below)[line_break_token]p3: clarify in 3.1/3.3 that L is the number of outputs[line_break_token]p4: "interpred"[line_break_token]p5: "aother"[line_break_token]p5: Theorem 2 proof: note that the T/T' notation is capturing left/right splits[line_break_token]p5: "netwoworks"[line_break_token]p5: "Remark 5 is important for learning shallow...": should "shallow" be "narrow" instead?	I-Review	I-6	Review	10028
[line_break_token]p7: in the first paragraph, remind the reader of the definitions of √µ^M and J_x √£^M[line_break_token]p7: "Here we provide a sketch of [the] proof"[line_break_token]p7: "unconstraint" should be "unconstrained"[line_break_token]p7: "...can construct a [sufficiently expressive] network g_\theta"[line_break_token]p7: "simlify"[line_break_token]p9: Table 2: instead of "2nd row", ..., use "1st section", ...; also consider noting which methods are introduced in this paper[line_break_token]p9: Figure 2: text is too small[line_break_token]	I-Review	I-6	Review	10028
2) In short, we have the following ordering of expressiveness *given a fixed depth*: oblique decision trees &gt; canonical (tabular) LCNs &gt;= standard LCNs.	O	O	Reply	10028
[line_break_token][line_break_token]Note that each activation pattern of f yield a *constant* Jacobian, so we can write the Jacobian as Jacobian(o(x)), where o is the activation pattern of x. [line_break_token][line_break_token]Then, standard LCNs can be written as the mapping: [line_break_token]        g_\phi(Jacobian(o(x))).	B-Reply	B-2	Reply	10028
[line_break_token]In contrast, canonical (tabular) LCNs yield the mapping:[line_break_token][tab_token]g(o(x)).	I-Reply	I-2	Reply	10028
[line_break_token]Hence, the tabular case cannot be less powerful than using embeddings (Jacobians), since we can always set the table as g(  ) = g_\phi(Jacobian(  )).	I-Reply	I-2	Reply	10028
[line_break_token][line_break_token]By the proof of Theorem 3, we can again transform such tabular LCN to a decision tree with the same depth, so the canonical LCNs are not more powerful than oblique decision trees.	I-Reply	I-2	Reply	10028
Furthermore, due to how the locally linear regions of f can be partitioned, canonical LCNs are strictly less powerful than oblique decision trees given a fixed depth M as proved in Sec.	I-Reply	I-2	Reply	10028
3.5.	I-Reply	I-2	Reply	10028
[line_break_token][line_break_token]Hence, we obtain the claimed ordering.	I-Reply	I-2	Reply	10028
In fact, by Theorem 8 (updated, originally given as a sketch of proof), we can even prove standard LCNs = canonical LCNs.	I-Reply	I-2	Reply	10028
[line_break_token][line_break_token][line_break_token](3) Yes, LLNs are ReLU networks.	B-Reply	B-3	Reply	10028
The point of including LLN is to compare it with ALCN, since both are continuous functions and thus much more powerful than tree methods.	I-Reply	I-3	Reply	10028
We show that ALCN often outperforms LLN.	I-Reply	I-3	Reply	10028
[line_break_token][line_break_token]If high accuracy is the only goal, currently random forests work well for these chemical/tabular data, outperforming neural networks with ReLU activations by a large margin.	I-Reply	I-3	Reply	10028
However, please see our general response above for why LCN still provides new insights in this setting.	I-Reply	I-3	Reply	10028
[line_break_token][line_break_token]If a tree model is needed, clearly LCNs are much better than traditional oblique decision trees: we can often get 10% absolute improvements in testing AUC.	I-Reply	I-3	Reply	10028
Since LCN can always be explicitly converted to an oblique decision tree, the only difference *in testing time* between oblique decision trees and LCNs is the accuracy.	I-Reply	I-3	Reply	10028
Other factors are discussed in (1).	I-Reply	I-3	Reply	10028
[line_break_token][line_break_token](4) Thank you for the reference.	O	O	Reply	10028
It seems a relevant paper that also uses deep networks to learn decision trees.	B-Reply	B-4	Reply	10028
The paper focused on axis-parallel decisions (traditional decision trees), while we work on oblique decisions.	I-Reply	I-4	Reply	10028
We will cite and discuss the paper in the camera-ready version.	I-Reply	I-4	Reply	10028
[line_break_token][line_break_token](5) Thank you for the feedback.	B-Reply	B-5	Reply	10028
The sketch of the proof is now replaced by a formal theorem with proof in Appendix A.2.	I-Reply	I-5	Reply	10028
[line_break_token][line_break_token](6) and *Notes*: Thank you for the comments.	B-Reply	B-6	Reply	10028
The typos have been addressed, and we will improve the other presentation issues in later revision.	I-Reply	I-6	Reply	10028
[line_break_token][line_break_token]Re "Remark 5 is important for learning shallow..." Thank you for pointing this out.	I-Reply	I-6	Reply	10028
Here we meant that given a fixed number of neurons, the one neuron per layer setting is the most powerful architecture.	I-Reply	I-6	Reply	10028
[line_break_token][line_break_token]Minor technical clarification: we ‚Äúanneal‚Äù LCNs during training, but the LCNs used in testing time are indeed piece-wise constant (not relaxed).	I-Reply	I-6	Reply	10028
Adding any number of layers mapping from the Jacobian to the prediction does not affect the piece-wise constant nature.	I-Reply	I-6	Reply	10028

This paper presents an improved formulation of CNN, aiming to separate geometric transformation from inherent features.	O	O	Review	473
The network can estimate the transformation of filters given the input images.	O	O	Review	473
[line_break_token][line_break_token]This work is based on a solid technical foundation and is motivated by a plausible rationale.	O	O	Review	473
Yet, the value of this work in practice is subject to questions:[line_break_token][line_break_token](1) It relies on the assumption that the input image is subject to a transformation on a certain Lie group (locally).	B-Review	B-1	Review	473
Do such transformations constitute real challenges in practice?	I-Review	I-1	Review	473
State-of-the-art CNNs, e.g. ResNet, are already quite resilient to such local deformations.	I-Review	I-1	Review	473
What such components would add to the state of the art?	I-Review	I-1	Review	473
Limited experiments on Cifar-10 does not seem to provide a very strong argument.	I-Review	I-1	Review	473
[line_break_token][line_break_token](2) The computational cost is not discussed.	B-Review	B-2	Review	473
Thank you very much for your comments and questions.	O	O	Reply	473
[line_break_token][line_break_token]The main goal of the Cifar10 experiments was to show, that one can replace the pixel-basis with a frame that has additional desirable properties like the steerability without decreasing performance.	O	O	Reply	473
Additionally, we were able to show that steerable frames can consistently increase the performance of SOTA networks given they are suitable for natural image data.	O	O	Reply	473
Note that we have added SOTA Densenet models to table 2, in which we were able to improve performance by substituting the pixel-basis with frames as well as in the Resnet models, substantiating the generality of our observations.	O	O	Reply	473
[line_break_token][line_break_token](1) Do such transformations constitute real challenges in practice?	O	O	Reply	473
What such components would add to the state of the art?	O	O	Reply	473
[line_break_token][line_break_token]Being able to replace the pixel-basis by steerable frames leads us to our proposed Dynamic Steerable Frame Networks (DSFNs), a method that continuously transforms filters conditioned on the input.	B-Reply	B-1	Reply	473
DSFNs are locally adaptive, interpretable and data-efficient.	I-Reply	I-1	Reply	473
We compare our DSFNs to other adaptive methods.	I-Reply	I-1	Reply	473
In this domain Dynamic Filter Networks (DFNs) and Spatial Transformer Networks (STNs) constitute the state of the art.	I-Reply	I-1	Reply	473
[line_break_token][line_break_token]Dynamic Filter Networks learn location varying filters in an unconstrained manner and generate any type of filter kernel for each location in the input, this approach is very data-inefficient as it has many unconstrained parameters and the transformations have no clear geometrical meaning.	I-Reply	I-1	Reply	473
Spatial Transformer Networks transform the whole feature stack globally under predefined geometrical parameters.	I-Reply	I-1	Reply	473
The method regularizes the additional parameters introduced by it effectively and achieves global transformation invariance.	I-Reply	I-1	Reply	473
[line_break_token][line_break_token]STNs are not locally adaptive, thus they fail in many cases where it is not beneficial to transform the image globally as it would destroy discriminative information (deformable objects, many objects, dynamic movements) or where global registration is anyway performed as a standard preprocessing step (medical imaging data).	I-Reply	I-1	Reply	473
The hand-gesture experiment is an example of a whole range of tasks where STNs fail, as they are not suitable for moving deformable objects.	I-Reply	I-1	Reply	473
[line_break_token][line_break_token]DFNs are black boxes and not data-efficient.	I-Reply	I-1	Reply	473
They introduce many unconstrained parameters and are thus not suited for limited-data scenarios.	I-Reply	I-1	Reply	473
At the same time, it is not possible to check if the model converges or does something meaningful.	I-Reply	I-1	Reply	473
Such a behavior is undesirable when data is limited and interpretability is key, like in medical imaging.	I-Reply	I-1	Reply	473
Further, they fail to generate very fine-grained local adaption as can be achieved with a well-regularized DSFN, illustrated with the edge-detection experiment.	I-Reply	I-1	Reply	473
This makes them inferior for tasks like segmentation, even in unlimited data scenarios.	I-Reply	I-1	Reply	473
[line_break_token][line_break_token]Our proposed DSFNs transform filters locally in a continuous manner.	I-Reply	I-1	Reply	473
This allows the model to precisely adapt filters to local features in the image.	I-Reply	I-1	Reply	473
It can do so in a data-efficient manner.	I-Reply	I-1	Reply	473
One learned filter can be applied to all its transformations, alleviating the necessity to learn one filter for each orientation or each different scale, effectively representing infinitely many geometrical variants of the same filter.	I-Reply	I-1	Reply	473
[line_break_token][line_break_token]In both experiments, our proposed method substantially outperform DFNs and STNs and we are able to explain why this is the case.	I-Reply	I-1	Reply	473
In conclusion, our proposed Dynamic Steerable Frame Networks are able to fill the gap between adaptive state-of-the-art Dynamic Filter Networks and Spatial Transformer Networks.	I-Reply	I-1	Reply	473
[line_break_token][line_break_token](2) The computational cost is not discussed.	O	O	Reply	473
[line_break_token][line_break_token]Frame-based CNNs have the same runtime as vanilla CNNs.	B-Reply	B-2	Reply	473
The Dynamic Steerable Frame Networks have the same runtime as vanilla Dynamic Filter Networks.	I-Reply	I-2	Reply	473
Besides that, there is a whole body of research on how to speed up convolution with analytic frame functions, with strategies like recursive filtering, showing promise to potentially decrease runtime.	I-Reply	I-2	Reply	473
[line_break_token][line_break_token]Thank you once again for your review, we have updated the manuscript to include our answers.	O	O	Reply	473
[line_break_token][line_break_token]Let us know if this answers your questions	O	O	Reply	473

This paper proposes semi-structured neural filter composed of structured Gaussian filters and the usual structure-agnostic free-form filters found in neural networks.	O	O	Review	20295
They are optimized using end-to-end training.	O	O	Review	20295
Effectively, this lead to increased receptive field size and shape with just few additional parameters.	O	O	Review	20295
Further, this module is architecture agnostic and can also be integrated with any dynamic inference models.	O	O	Review	20295
Specifically, when applied on deformable convolutional filters, the deformation at each input can be structured using gaussian filters.	O	O	Review	20295
Empirical experiments suggest that when integrated with state-of-the-art semantic segmentation architectures, the absolute accuracy on Cityscapes improves by 2%.	O	O	Review	20295
Large improvement in seen on naive / sub-optimal architectures for segmentation.	O	O	Review	20295
[line_break_token][line_break_token]Given that this is first work which demonstrates the efficient composition of classic structured filters with neural layer filters, I believe that research community will benefit to good extent if this paper is accepted.	O	O	Review	20295
[line_break_token][line_break_token]Clarification:[line_break_token]1.	O	O	Review	20295
I note that single gaussian is shared across different free-form filters.	B-Review	B-1	Review	20295
Is same gaussian also shared across input channels ?	I-Review	I-1	Review	20295
[line_break_token]2.	O	O	Review	20295
For dynamic inference, what is the sampling resolution used ?	B-Review	B-2	Review	20295
How is it related to diagonal elements of covariance ?	I-Review	I-2	Review	20295
2\sigma ?	I-Review	I-2	Review	20295
[line_break_token]3.	O	O	Review	20295
In case of blurring and resampling, does the model learn another filter for sampling ?	B-Review	B-3	Review	20295
To me, sampling seems similar to dynamic inference operation but with static parameters.	I-Review	I-3	Review	20295
[line_break_token]4.	O	O	Review	20295
As noted in paper, blurring is fundamental hwen dilating.	B-Review	B-4	Review	20295
Does DRN-A and DLA-34 models used for comparison in Table 1 includes blurring prior to dilation ?	I-Review	I-4	Review	20295
[line_break_token][line_break_token]Additional experiment:[line_break_token]1.	O	O	Review	20295
Does improved receptive field size and shape also lead to improvement in other downstream tasks such as classification, object detection, depth estimation etc. ?	B-Review	B-5	Review	20295
[line_break_token]2.	O	O	Review	20295
Table 4 shows that the networks with reduced depth when integrated with composed filters can perform as well as large networks.	B-Review	B-6	Review	20295
Does this holds true when extended to above tasks ?	I-Review	I-6	Review	20295
[line_break_token]3.	O	O	Review	20295
I note that in all the presented results, the composed filters are only included at the last few layers.	B-Review	B-7	Review	20295
How the results prunes out when included at the lower as well as at the intermediate layers ?	I-Review	I-7	Review	20295
Please include a plot of accuracy vs depth (at which it is included).	I-Review	I-7	Review	20295
[line_break_token]4.	O	O	Review	20295
I am glad to note that Gaussian deformable models performs as good as free-form deformable models with largely reduced parameters.	B-Review	B-8	Review	20295
Can you please add total network parameters comparison in Table 5 ?	I-Review	I-8	Review	20295
Further, are these also included only at the top few layers ?	I-Review	I-8	Review	20295
[line_break_token]5.	O	O	Review	20295
In Table 1, DLA-34 + DoG ?	B-Review	B-9	Review	20295
hank you for your feedback, and the precise clarification questions, which we address point-by-point:[line_break_token][line_break_token]&gt;  single gaussian is shared across different free-form filters.	O	O	Reply	20295
Is same gaussian also shared across input channels ?	O	O	Reply	20295
[line_break_token][line_break_token]The Gaussian is shared across all input and output channels of a layer.	B-Reply	B-1	Reply	20295
In effect, this lets a layer learn/adapt a shared scale for all of its filters.	I-Reply	I-1	Reply	20295
Not sharing the Gaussians, for channel-wise scaling, is an extension for future work.	I-Reply	I-1	Reply	20295
[line_break_token][line_break_token]&gt; For dynamic inference, what is the sampling resolution used ?	O	O	Reply	20295
[line_break_token][line_break_token]We experimented with setting the sampling rate to 2*sigma, as we did for static filtering, but found a constant sampling rate (as shown in Figure 6) to suffice in our experiments.	B-Reply	B-2	Reply	20295
That said, we expect that more extreme ranges of scale would require setting the resolution as a function of sigma, or else the sampling could be too sparse.	I-Reply	I-2	Reply	20295
[line_break_token][line_break_token]&gt; In case of blurring and resampling, does the model learn another filter for sampling ?	O	O	Reply	20295
To me, sampling seems similar to dynamic inference operation but with static parameters.	O	O	Reply	20295
[line_break_token]This is exactly right.	B-Reply	B-3	Reply	20295
The sampling coordinates and the blurring filter are determined by the same covariance.	I-Reply	I-3	Reply	20295
This is analogous to smoothing and decimation when forming a pyramid: only smoothing would merely blur, but gaussian filtering then resampling/dilating the following filter instead changes scale.	I-Reply	I-3	Reply	20295
[line_break_token][line_break_token]&gt; blurring is fundamental when dilating.	O	O	Reply	20295
Does DRN-A and DLA-34 models used for comparison in Table 1 includes blurring prior to dilation ?	O	O	Reply	20295
[line_break_token][line_break_token]Yes, but results with these architectures were not sensitive to this, since the dilation rates (2, 4) are not so large.	B-Reply	B-4	Reply	20295
The effect of blur was stronger for ASPP and CCL (Table 3) with larger rates (6, 12, 18)	I-Reply	I-4	Reply	20295

[ EDIT: Thanks for the response.	O	O	Review	20450
I still believe the paper is not ready for publication, so I'll keep my rating unchanged.	O	O	Review	20450
But as I said before, this is a really interesting research direction and I hope the authors will continue this work to collect more results and re-submit it. ]	O	O	Review	20450
[line_break_token][line_break_token]The paper proposes learning a policy for selecting a pivoting rule to apply at each iteration of the Simplex algorithm for linear programming.	O	O	Review	20450
Several pivoting rules have been proposed in the optimization literature, and different rules work better than others on different instances.	O	O	Review	20450
By learning a policy that switches among the existing rules at each step of the Simplex algorithm, it may be possible to construct a pivoting rule that outperforms existing ones.	O	O	Review	20450
The paper considers learning to switch between the Dantzig rule and the steepest edge rule as an RL problem.	O	O	Review	20450
Results on 5-city TSP instances show that the learned policy can outperform both rules on a test set with respect to number of iterations.	O	O	Review	20450
[line_break_token][line_break_token]Pros:[line_break_token]- The problem is very interesting and definitely should be explored further.	O	O	Review	20450
Learning could potentially help combine rules in an instance distribution-specific manner to construct better pivoting rules.	O	O	Review	20450
[line_break_token]- The paper made a reasonable attempt to provide sufficient background to understand the problem.	O	O	Review	20450
[line_break_token][line_break_token]Cons:[line_break_token]- The results on the 5-city synthetic TSP instances are not sufficient.	B-Review	B-5	Review	20450
While I understand the motivation for considering small problems to measure the best possible strategy‚Äôs performance and to learn on Q* values, I‚Äôm not convinced that the insights from such small synthetic problems would necessarily transfer to larger LPs for which the solve time is large enough to be able to afford the overhead of neural network inference to try to reduce it.	I-Review	I-5	Review	20450
The learning challenges will likely be very different, and the tradeoff between the inference cost of the neural network and the savings from reducing iterations will also likely be different.	I-Review	I-5	Review	20450
Scaling up and neural network inference cost are briefly mentioned in the conclusion, but I believe those are the main challenges.	I-Review	I-5	Review	20450
[line_break_token]- Presentation of the results need to be improved significantly.	B-Review	B-3	Review	20450
Figures 2 and 3 need to be annotated properly and explained more clearly so that they are easy to understand.	I-Review	I-3	Review	20450
[line_break_token][line_break_token]Additional comments:[line_break_token]- Although I‚Äôm recommending rejection, the problem is interesting and I hope the authors will continue working on it to develop the ideas further and collect results on larger scale problems.	B-Review	B-4	Review	20450
[line_break_token]- For permutation invariance and ability to handle variable-sized inputs, a graph neural network would be a better architecture (see, e.g., Gasse et al NeurIPS‚Äô19).	B-Review	B-1	Review	20450
[line_break_token]- It would be helpful to give further details on how the best possible strategy is computed, perhaps as part of an appendix.	B-Review	B-7	Review	20450
[line_break_token]- Another baseline to compare against is the performance of an oracle that makes the best possible choice of the pivoting rule per problem instance.	B-Review	B-2	Review	20450
This will indicate how well a fixed choice per instance can work if that choice is made as well as possible, compared to switching among choices at each iteration.	I-Review	I-2	Review	20450
[line_break_token]- ‚ÄúTo our knowledge, this is one of the first studies to report improvements via learning for combinatorial algorithms.	B-Review	B-6	Review	20450
‚Äù This sentence needs to be clarified because a literal interpretation of it is not true, as shown by, e.g., Bengio et al <a href="https://arxiv.org/abs/1811.06128."	O	O	Review	20450
target="_blank" rel="nofollow">https://arxiv.org/abs/1811.06128.</a>	O	O	Review	20450
e thank the reviewer for the helpful comments and suggestions.	O	O	Reply	20450
[line_break_token][line_break_token]We added a general response to the scalability concerns.	B-Reply	B-4	Reply	20450
[line_break_token][line_break_token]We are thankful for the graph neural network suggestion.	B-Reply	B-1	Reply	20450
We will implement different architectures in the future to compare performance, including the graph neural network.	I-Reply	I-1	Reply	20450
[line_break_token][line_break_token]We will create a new section that will analyze the learned pivoting rule to gain insights on how the neural network decides one rule over the other.	B-Reply	B-2	Reply	20450
[line_break_token][line_break_token]We will revise our figures to improve their clarification	B-Reply	B-3	Reply	20450

The paper proposes a method for selecting a subset of a large dataset to reduce the computational costs of deep neural netwoks.	O	O	Review	556
The main idea is to train a proxy model, a smaller version of the full neural network, to choose important data points for active learning or core-set selection.	O	O	Review	556
Experiments on standard classification tasks demonstrate that this approach can yield substantial computational savings with only a small drop in accuracy.	O	O	Review	556
 [line_break_token][line_break_token]This paper is well-written and was easy to follow, with a clear motivation.	O	O	Review	556
The paper does good job of demonstrating that the proposed algorithm is effective through a comprehensive set of experiments.	O	O	Review	556
Overall, I favor acceptance and would be willing to increase my score if the following are addressed:[line_break_token][line_break_token]1) Training for a smaller number of epochs was mentioned as a possibility to save computation.	B-Review	B-1	Review	556
In the experiments, this was only done for one of the settings.	I-Review	I-1	Review	556
Is this because models trained for fewer epochs are ineffective for data selection?	I-Review	I-1	Review	556
[line_break_token]Looking at Fig.	I-Review	I-1	Review	556
5b, it seems like the error drops significantly around 14 min before plateauing.	I-Review	I-1	Review	556
In practice, for a new dataset, it could be difficult (or impossible) to know when to stop training a proxy a priori so that it achieves good performance relative to a larger model.	I-Review	I-1	Review	556
It could be interesting to look at the effectiveness of a proxy at various points during training to see if the benefits are sensitive to the training time.	I-Review	I-1	Review	556
[line_break_token][line_break_token]2) For the active learning experiments, how many data points were added to the training set in each round?	B-Review	B-2	Review	556
I could not find this number in the paper.	I-Review	I-2	Review	556
Also, how many rounds of data selection were there?	I-Review	I-2	Review	556
[line_break_token][line_break_token]3) Is there an explanation why in Fig.	B-Review	B-3	Review	556
2b and Fig.	I-Review	I-3	Review	556
7c, the resnet20 proxy performs better than the larger (and more accurate) models?	I-Review	I-3	Review	556
In particular, it even outperforms the 'oracle' baseline, which I find surprising.	I-Review	I-3	Review	556
[line_break_token][line_break_token]4) On a similar note, in Fig.	B-Review	B-4	Review	556
7, for small subsets (30%), the random baseline outperforms all of the SVP settings.	I-Review	I-4	Review	556
Why is SVP ineffective in this case?	I-Review	I-4	Review	556
[line_break_token][line_break_token]Minor comments/suggestions:[line_break_token]- In the abstract: "improvement in data selection runtime" Is this "data selection runtime" different from the total runtime?	B-Review	B-5	Review	556
If not, it could be clearer to simply state it as the "total runtime (including the time to repeatedly train and select points)".	I-Review	I-5	Review	556
I was unsure if this was a different measure.	I-Review	I-5	Review	556
[line_break_token][line_break_token]- Did the authors try further reducing the model capacity?	I-Review	I-5	Review	556
With the success of the smaller models, it seems natural to try pushing further in this direction.	I-Review	I-5	Review	556
[line_break_token][line_break_token]- Since one of the findings was that models with similar architectures were effective as proxies but not models with different ones, perhaps there could be even higher correlation if the proxies were initialized with the exact same weights as a subset of the full model.	I-Review	I-5	Review	556
[line_break_token][line_break_token]- The writing in Table 1 (and the ones in the appendix) is a bit small.	I-Review	I-5	Review	556
[line_break_token][line_break_token]	O	O	Review	556
hank you for your time and thoughtful feedback!	O	O	Reply	556
 We ran additional experiments to explore the effectiveness of training for fewer epochs in a variety of settings.	B-Reply	B-1	Reply	556
We also created more plots to explain how the rankings from proxies compared to the larger target model.	I-Reply	I-1	Reply	556
These results show that the underlying selection method plays an essential role in the effectiveness of SVP.	I-Reply	I-1	Reply	556
Notably, the rankings from forgetting events are much more stable because the model‚Äôs uncertainty is effectively averaged throughout training rather than a single snapshot at the end, like entropy or greedy k-centers.	I-Reply	I-1	Reply	556
Based on your questions and the points you raised, the paper more clearly presents the underlying dynamics that affect performance.	I-Reply	I-1	Reply	556
[line_break_token][line_break_token]Below we have provided a detailed response to each of your questions.	O	O	Reply	556

Review of ‚ÄúPrincipled Weight Initialization for Hypernetworks‚Äù[line_break_token][line_break_token]There has been a lot of existing work on neural network initialization, and much of this work has made large impact in making deep learning models easier to train in practice.	O	O	Review	196
There has also been a line of work on indirect encoding of neural works (i.e. HyperNEAT work of Stanley, and more recent Hypernetworks proposed by Ha et al) which showed promising results of training very large networks (in the case of Stanley), or have network weights that can adapt to the training data (in the case of Hypernetworks), and these approaches have been shown to be useful in applications such as meta-learning or few-shot learning (i.e. [1]).	O	O	Review	196
However, as far as I know, there hasn't been any work that looks at a principled way of initializing the weights of a weight-generating network, which this work tries to explore.	O	O	Review	196
[line_break_token][line_break_token]Making the observation (and claim) that traditional init methods don't init hypernetworks properly, they propose a few techniques to initialize hypernetworks ("Hyperfan"-family), which are justified in a similar way as original classical init techniques (i.e. preserving variance like in Xavier init), and they demonstrate that their method works well for feed forward networks on MNIST, CIFAR-10 tasks compared to traditional classical init methods, as well for a continual learning task.	O	O	Review	196
[line_break_token][line_break_token]I liked the paper as they identified a problem that hasn't been studied, and proposed a reasonable method to solve it.	O	O	Review	196
Their method may be able to make Hypernetworks accessible to many more researchers and practitioners, the way classifical init techniques have made neural net training more accessible.	O	O	Review	196
[line_break_token][line_break_token]There are a few things that could improve the paper (and get an improvement score from me).	O	O	Review	196
The authors don't have to do all of these, but just a few suggestions:[line_break_token][line_break_token]1) The experiments, to my understanding, are all feed forward networks.	B-Review	B-1	Review	196
How about RNNs or LSTMs?	I-Review	I-1	Review	196
[line_break_token][line_break_token]2) Are there any (interesting) tasks that use Hypernetworks that are not trainable with existing methods, but made trainable using this proposed scheme?	B-Review	B-2	Review	196
[line_break_token][line_break_token]3) Would this method also work with HyperNEAT [2] or Compressed Network Search [3]? (	B-Review	B-3	Review	196
probably should cite that line of work too).	I-Review	I-3	Review	196
In [3], a research group at IDSIA used DCT compression to compress millions of weights into a few dozen parameters, so would be interesting if the approach will work on similar "learn-from-pixels" RL experiments.	I-Review	I-3	Review	196
[line_break_token][line_break_token]I'm assigning a score of 6 (it's currently like a "really good" workshop paper, but a normal conf paper IMO), but I like this paper and would like to see the authors make an attempt to improve it, so I can improve the score to see it get accepted with a higher certainty.	O	O	Review	196
[line_break_token][line_break_token]Good luck!	O	O	Review	196
[line_break_token][line_break_token][1] i.e. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6519722/" target="_blank" rel="nofollow">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6519722/</a> <a href="https://arxiv.org/pdf/1710.03641.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1710.03641.pdf</a> <a href="https://arxiv.org/pdf/1703.03400.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1703.03400.pdf</a>[line_break_token][line_break_token][2] <a href="http://eplex.cs.ucf.edu/hyperNEATpage/" target="_blank" rel="nofollow">http://eplex.cs.ucf.edu/hyperNEATpage/</a>[line_break_token][line_break_token][3] <a href="http://people.idsia.ch/~juergen/compressednetworksearch.html" target="_blank" rel="nofollow">http://people.idsia.ch/~juergen/compressednetworksearch.html</a>[line_break_token][line_break_token]*** Revised Score ***[line_break_token][line_break_token]Nov20: Upon reading the other reviews, and looking at the changes to the paper with the extra citations, I'm improving the score to 8. (	O	O	Review	196
For the record, if this was a 1-10 scale, I would have liked my score to be a 7).	O	O	Review	196
e would like to thank the reviewer for his thoughtful feedback on our work.	O	O	Reply	196
[line_break_token][line_break_token]Regarding the reviewer‚Äôs questions:[line_break_token][line_break_token]1) Variance analysis does not extend to RNNs and LSTMs even in the classical setting without the use of hypernetworks.	B-Reply	B-1	Reply	196
We believe this is an important open problem that deserves attention and we leave it for future work.	I-Reply	I-1	Reply	196
[line_break_token][line_break_token]2) Hypernetworks are a natural choice for enabling Bayesian neural networks, because they can be used to simulate an expressive prior distribution.	B-Reply	B-2	Reply	196
This is useful for improving model calibration, providing uncertainty estimation, and doing approximate Bayesian inference or regularization. [	I-Reply	I-2	Reply	196
1] demonstrated a method to build a Bayesian network using a hypernet, but they mentioned having to use a heuristic method to initialize the weights of their hypernetwork in order to prevent losses from diverging.	I-Reply	I-2	Reply	196
[line_break_token][line_break_token][1]‚Äôs implementation was unfortunately not publicly available so we could not try our approach on their exact settings.	I-Reply	I-2	Reply	196
We introduced a similar experiment in Section 5.4 that differed with [1]‚Äôs in terms of residual connections in the mainnet.	I-Reply	I-2	Reply	196
 While all initializations led to trainable networks in this case, our proposed initialization gave superior performance compared to the default initialization in PyTorch.	I-Reply	I-2	Reply	196
We are confident that an extension of our approach to hypernetworks with residual mainnets should be able to resolve [1]‚Äôs initializations issues.	I-Reply	I-2	Reply	196
This work is an important stepping stone towards this direction.	I-Reply	I-2	Reply	196
[line_break_token][line_break_token]3) Non-hypernetwork methods like HyperNEAT or Compressed Network Search that generate the weights of some target network would probably also do well to consider if their generated weights might result in exploding activations.	B-Reply	B-3	Reply	196
Because most of this line of work was done before the advent of deep learning, the networks considered were most likely not deep enough to have caused an issue.	I-Reply	I-3	Reply	196
We hope that our paper will drive new progress in this line of research as well.	I-Reply	I-3	Reply	196
We have cited the papers mentioned, thanks for pointing them out.	I-Reply	I-3	Reply	196
[line_break_token][line_break_token][1] Hypernetwork-based Implicit Posterior Estimation and Model Averaging of Convolutional Neural Networks.	O	O	Reply	196
Ukai et al ACML 2018.	O	O	Reply	196

This paper revisits the way RL algorithms are typically evaluated on the ALE benchmark, advocating for several key changes that contribute to more robust and reliable comparisons between algorithms.	O	O	Review	10159
It also brings the following additional contributions: (1) a new measure of comparison to human performance based on actual human world records (which shows that RL algorithms are not as ¬´ super-human ¬ª as is generally believed), and (2) an evaluation (based on the proposed guidelines) of Rainbow as well as a Rainbow-IQN variant (replacing the C51 component of Rainbow with Implicit Quantile Networks), showing that the latter brings a significant improvement upon the original Rainbow algorithm.	O	O	Review	10159
[line_break_token][line_break_token]Overall I am leaning towards acceptance as I believe that such papers encouraging better benchmarking practice on Atari are definitely needed.	O	O	Review	10159
Even if the technical contribution is limited, this paper could have a positive impact on the field by providing a clearer picture of the current state of deep RL algorithms on Atari (assuming that other researchers start following these recommendations -- and if that is not the case at least it will highlight issues with the way evaluation is currently done).	O	O	Review	10159
[line_break_token][line_break_token]I do have a few concerns / questions though:[line_break_token][line_break_token]1.	O	O	Review	10159
[tab_token]I am not convinced by the recommendation to use performance during training for evaluation purpose.	B-Review	B-1	Review	10159
In Machado et al (2018) it is argued that ¬´ this better aligns the performance metric with the goal of continual learning ¬ª, but most deep RL algorithms trained on Atari games have not been intended to be used in a continual learning setting.	I-Review	I-1	Review	10159
It definitely has the advantage of being simple, but it seems to me that it can cause some issues, like making it difficult to compare different exploration techniques for off-policy learning (the exploration may cause poor behavior during training even if it helps the agent learn a better greedy policy), and more generally not being representative of the common practical use case where the goal is to obtain the best agent possible to use in production (with no further learning).	I-Review	I-1	Review	10159
Finally, it could make results even harder to reproduce due to the potential high variance of an agent‚Äôs performance at a fixed # of timesteps (vs. considering the max performance it can reach over the whole period).	I-Review	I-1	Review	10159
As a result, I am currently reluctant to see the proposed performance measure become the standard evaluation metric on ALE, and I would appreciate some additional justification from the authors on this point.	I-Review	I-1	Review	10159
[line_break_token][line_break_token]2.	O	O	Review	10159
[tab_token]Why not suggest to remove reward clipping in the recommendations?	B-Review	B-2	Review	10159
As mentioned in Section 6, reward clipping can prevent RL algorithms from properly playing some games, and thus in my opinion should be removed if the goal is to reach the highest score possible on all games.	I-Review	I-2	Review	10159
It seems to me that the choice of clipping the reward should be part of the algorithm (if it is not able to handle the high variety of ¬´ raw ¬ª rewards) and not of the benchmark environment, thus enabling further advancements towards algorithms that are robust to a wide range of rewards.	I-Review	I-2	Review	10159
[line_break_token][line_break_token]3.	O	O	Review	10159
[tab_token]Why bother to keep the mean performance when, as mentioned, it is highly sensitive to outliers compared to the median?	B-Review	B-3	Review	10159
[line_break_token][line_break_token][line_break_token]Additional remarks:[line_break_token]‚Ä¢[tab_token]I might have missed it but I do not see the link to the source code.	B-Review	B-4	Review	10159
Am I correct to assume it will be released, to help with reproducibility?	I-Review	I-4	Review	10159
[line_break_token]‚Ä¢[tab_token]It is not clear, when reading the paper, that the distributed version of Rainbow is actually constrained to mimic a single agent sequential algorithm in the experiments.	B-Review	B-5	Review	10159
I would suggest to remove mentions of the distributed version in the main text to avoid confusion, and mention it only in the Appendix section where it is used.	I-Review	I-5	Review	10159
[line_break_token]‚Ä¢[tab_token]The ¬´ infinite reward loop ¬ª point at the end of Section 6 does not seem relevant in the list of reasons why Deep RL algorithms are far from the best human performance, since with infinite playtime and an infinite reward loop, the algorithm should be guaranteed to outperform humans.	B-Review	B-6	Review	10159
[line_break_token]‚Ä¢[tab_token]I would have appreciated an evaluation of Rainbow-IQN with the current most commonly used evaluation schemes (e.g. the one used in the original Rainbow paper), for comparison purpose (even if such an evaluation has flaws, it is often the only performance measure available for existing deep RL algorithms)[line_break_token][line_break_token]Review update: thank you for the response, I am currently keeping my "Weak accept" rating because I agree it is important to highlight and (try to) fix the problems with the way algorithms are currently evaluated on ALE, in spite of the limited technical contributions (and the fact that I remained unconvinced regarding #1)	B-Review	B-1	Review	10159
hank you for your comments and feedback.	O	O	Reply	10159
We will try to answer to all your questions and remarks in the following.	O	O	Reply	10159
[line_break_token][line_break_token]1) Concerning the recommendation of reporting performance during training, we will base our argument on Machado et al paper where they specifically speak about "Evaluation after learning" and "Evaluation of the best policy" (page 8).	B-Reply	B-1	Reply	10159
First we think that evaluating the best policy after learning hides both the data efficiency and the stability of the algorithm.	I-Reply	I-1	Reply	10159
Indeed most paper actually do not mention when the best results were encountered.	I-Reply	I-1	Reply	10159
Finally as stated in Machado et al we think that "the best score achieved across training is a statistically biased estimate of an agent‚Äôs best performance".	I-Reply	I-1	Reply	10159
However, it could be interesting to report training performance along with a re-evaluation of the best model encountered while training.	I-Reply	I-1	Reply	10159
[line_break_token][line_break_token]2) We think that finding algorithms capable of managing high variety of rewards is still an open problem and most of algorithms are yet not suited to this.	B-Reply	B-2	Reply	10159
And as you mentioned clipping reward is an algorithmic choice, so we estimate it is out of scope of the recommendations of SABER.	I-Reply	I-2	Reply	10159
We think games on which reward clipping actually leads to sub-optimal policy are an important margin of improvement for algorithms trying to handle highly variable rewards.	I-Reply	I-2	Reply	10159
[line_break_token][line_break_token]3) We kept mean performance as most of previous works were reporting both median and mean.	B-Reply	B-3	Reply	10159
However, we think this is of limited interest and that is why all our graphics just plot the median normalized score.	I-Reply	I-3	Reply	10159
[line_break_token][line_break_token]Additional remarks:[line_break_token]‚Ä¢[tab_token]The source code is currently available here: <a href="https://anonymous.4open.science/r/728e379d-4d38-49e2-9dd8-bf2fb4bd4844/" target="_blank" rel="nofollow">https://anonymous.4open.science/r/728e379d-4d38-49e2-9dd8-bf2fb4bd4844/</a>[line_break_token]‚Ä¢[tab_token]We mentioned our distributed version of Rainbow as we think this give a good value on our source code even if like you mentioned we constrained it to mimic a single agent version in our experiments.	B-Reply	B-5	Reply	10159
[line_break_token]‚Ä¢[tab_token]We have reformulate this "Infinite reward loop" section in the revision we just submitted.	B-Reply	B-6	Reply	10159
The idea we wanted to highlight there was that agents are often stuck in a loop which in many cases is a sub-optimal behavior (in fact most of Atari games incorporate a timeout when not moving along the game and Elevator Action was the only one we found with an infinite reward loop).	I-Reply	I-6	Reply	10159
[line_break_token]‚Ä¢[tab_token]Unfortunately, we did not have time nor computational resources to run Rainbow-IQN following commonly used evaluation schemes	O	O	Reply	10159

Summary: This well written paper presents an effective way to remove outliers for deep generative models, provided examples are ranked along their centrality.	O	O	Review	10005
One question I have is how exactly this centrality is measured[line_break_token][line_break_token]The word ‚Äòcurriculum‚Äô has become a terminology used to describe a wide variety of totally different algorithms.	B-Review	B-2	Review	10005
While the authors provide an excellent introduction to this diversity and clearly differentiate their own flavor of ‚Äòcluster curriculum‚Äô, I am wondering if they would not have been better off by describing the proposed approach in terms of outlier removal, especially has it has very little in common with the original idea of curriculum, which is a learning progression designed by the teacher.	B-Review	B-1	Review	10005
[line_break_token][line_break_token]Nevertheless, the paper is very clearly written and reads well in the present form.	O	O	Review	10005
I am especially impressed about the clarity of the rather technical part on percolation.	O	O	Review	10005
[line_break_token][line_break_token]In terms of outlier removal, this could be interpreted as the following constructive algorithm:[line_break_token]‚Ä¢[tab_token]Examples are ranked along their centrality measure [line_break_token]‚Ä¢[tab_token]One identify the critical point in percolation for a starting point where too many examples are removed[line_break_token]‚Ä¢[tab_token]More examples are added until a minimum is found on validation data[line_break_token]This process can be made faster as:[line_break_token]‚Ä¢[tab_token]The optimum can happen very soon after the critical point[line_break_token]‚Ä¢[tab_token]Otherwise, an active set algorithm can be used to control the size of the training set.	B-Review	B-1	Review	10005
[line_break_token][line_break_token]While my recent expertise has been more NLP than Vision, I think this algorithm is original, and could have a significant impact as it can be extended beyond GANs.	O	O	Review	10005
The technical presentation is excellent.	O	O	Review	10005
[line_break_token][line_break_token]One puzzling issue is the computation of the centrality measure: all I could find in Appendix A1.	B-Review	B-2	Review	10005
and A.3 is that it is directly measured on the raw image (RGB pixels?)	I-Review	I-2	Review	10005
by taking some distance, which I assume is Euclidean?	I-Review	I-2	Review	10005
My experience in image classification suggests such a distance is meaningless, so I may be missing something.	I-Review	I-2	Review	10005
I looked for a Github pointer, but none was provided.	I-Review	I-2	Review	10005
[line_break_token][line_break_token]The English is OK, but there are missing words and strange constructions:[line_break_token]‚Ä¢[tab_token]Page 1:  ‚ÄúDeep generative models HAVE piqueD researchers‚Äô interest in the past decade‚Äù[line_break_token]‚Ä¢[tab_token]Page 4: ‚ÄúThe training of many loops will lead to time-consuming (MISSING WORD)‚Äù[line_break_token][line_break_token]In particular, the usage of ‚Äúthe‚Äù, for instance in pages:[line_break_token]‚Ä¢[tab_token]7 ‚ÄúTherefore, a fast learning strategy can be derived from THE percolation process.	B-Review	B-3	Review	10005
‚Äù[line_break_token]‚Ä¢[tab_token]7 ‚ÄúTraining may begin from the curriculum‚Äù[line_break_token]‚Ä¢[tab_token]8 ‚ÄúCluster curriculum is proposed for robust training of generative models.	I-Review	I-3	Review	10005
‚Äù[line_break_token]	I-Review	I-3	Review	10005
Q1:  ‚ÄúI am wondering if they would not have been better off by describing the proposed approach in terms of outlier removal.	O	O	Reply	10005
‚Äù[line_break_token]A1: Indeed, outlier removal is more clear and easier to understand.	B-Reply	B-1	Reply	10005
But we use ‚Äúclustering‚Äù to emphasize the dynamic process when using cluster curriculum for training generative models.	I-Reply	I-1	Reply	10005
[line_break_token][line_break_token]Q2:  ‚ÄúOne puzzling issue is the computation of the centrality measure.	O	O	Reply	10005
‚Äù[line_break_token]A2: We used ResNet34 to extract 512-dimensional features for each image.	B-Reply	B-2	Reply	10005
 The pre-trained model on ImageNet is available at[line_break_token][line_break_token]ResNet34[line_break_token]<a href="https://github.com/qubvel/classification_models" target="_blank" rel="nofollow">https://github.com/qubvel/classification_models</a>[line_break_token][line_break_token]Then the graph is constructed by Algorithm 3 presented in the following NeurIPS paper[line_break_token][line_break_token]Cyclizing Clusters via Zeta Function of a Graph[line_break_token]<a href="https://papers.nips.cc/paper/3412-cyclizing-clusters-via-zeta-function-of-a-graph" target="_blank" rel="nofollow">https://papers.nips.cc/paper/3412-cyclizing-clusters-via-zeta-function-of-a-graph</a>[line_break_token][line_break_token]In this paper, the authors validated the effectiveness of using graphs for clustering complex data.	O	O	Reply	10005
We will make this clear in the revised version.	B-Reply	B-2	Reply	10005
[line_break_token][line_break_token]We will polish our paper according to your advice on writing.	B-Reply	B-3	Reply	10005
Thank you for your careful review and insightful comments on our work.	I-Reply	I-3	Reply	10005
We appreciate them very much.	I-Reply	I-3	Reply	10005

This paper proposes MaskGAN, a GAN-based generative model of text based on[line_break_token]the idea of recovery from masked text.	O	O	Review	299
[line_break_token]For this purpose, authors employed a reinceforcement learning approach to[line_break_token]optize a prediction from masked text.	O	O	Review	299
Moreover, authors argue that the [line_break_token]quality of generated texts is not appropriately measured by perplexities,[line_break_token]thus using another criterion of a diversity of generated n-grams as well as[line_break_token]qualitative evaluations by examples and by humans.	O	O	Review	299
[line_break_token][line_break_token]While basically the approach seems plausible, the issue is that the result is[line_break_token]not compared to ordinary LSTM-based baselines.	B-Review	B-1	Review	299
While it is better than a [line_break_token]conterpart of MLE (MaskedMLE), whether the result is qualitatively better than[line_break_token]ordinary LSTM is still in question.	I-Review	I-1	Review	299
[line_break_token][line_break_token]In fact, this is already appearent both from the model architectures and the[line_break_token]generated examples: because the model aims to fill-in blanks from the text[line_break_token]around (up to that time), generated texts are generally locally valid but not[line_break_token]always valid globally.	O	O	Review	299
This issue is also pointed out by authors in Appendix[line_break_token]A.2.	O	O	Review	299
[line_break_token]While the idea of using mask is interesting and important, I think if this[line_break_token]idea could be implemented in another way, because it resembles Gibbs sampling[line_break_token]where each token is sampled from its sorrounding context, while its objective[line_break_token]is still global, sentence-wise.	B-Review	B-2	Review	299
As argued in Section 1, the ability of [line_break_token]obtaining signals token-wise looks beneficial at first, but it will actually[line_break_token]break a global validity of syntax and other sentence-wise phenoma.	I-Review	I-2	Review	299
[line_break_token][line_break_token]Based on the arguments above, I think this paper is valuable at least[line_break_token]conceptually, but doubt if it is actually usable in place of ordinary LSTM[line_break_token](or RNN)-based generation.	B-Review	B-3	Review	299
[line_break_token]More arguments are desirable for the advantage of this paper, i.e. quantitative[line_break_token]evaluation of diversity of generated text as opposed to LSTM-based methods.	I-Review	I-3	Review	299
[line_break_token][line_break_token]*Based on the rebuttals and thorough experimental results, I modified the global rating.	O	O	Review	299
Thank you for your review and comments!	O	O	Reply	299
[line_break_token][line_break_token]We reiterate your two primary concerns as the following:[line_break_token]1.	O	O	Reply	299
 A standard LSTM-baseline of a non-masked task should be included.	O	O	Reply	299
[line_break_token]2.	O	O	Reply	299
The MaskGAN algorithm is enforcing only local consistency within text, but does not aid with global consistency.	O	O	Reply	299
 [line_break_token][line_break_token]*Standard Baselines*[line_break_token]To address your first concern, we added a thorough human evaluation of a language model (LM) LSTM baseline.	B-Reply	B-1	Reply	299
 We use the samples produced from our Variational Dropout-LSTM language model and evaluate the resulting sample quality for both the PTB and IMDB datasets using Amazon Mechanical Turk.	I-Reply	I-1	Reply	299
 You can see these results updated in our paper in Table 7 and Table 8.	I-Reply	I-1	Reply	299
 We demonstrate that the MaskGAN training algorithm results in improvements over both the language model and the MaskMLE benchmarks on all three metrics: grammaticality, topicality and overall quality.	I-Reply	I-1	Reply	299
In particular, MaskGAN samples are preferred over LM LSTM baseline samples, 58.0% vs 15.7% of the time for IMDB reviews.	I-Reply	I-1	Reply	299
[line_break_token][line_break_token]*Local vs. Global Consistency*[line_break_token]In regards to your comment on Gibbs sampling, we do agree that this would likely be a valid and helpful technique for inference.	B-Reply	B-2	Reply	299
 In our paper, we in-fill our samples autoregressively from left to right, as is conventional in language modeling.	I-Reply	I-2	Reply	299
 (This approach allows for fast unconditional generation as with the LM baseline and is what our human evaluation is targeted at).	I-Reply	I-2	Reply	299
 This autoregressive process relies on the attention module of our decoder in order to provide full context during the sampling process.	I-Reply	I-2	Reply	299
 For instance, when the decoder is producing the probability distribution over token x_t, it is attending over the future context to create this distribution.	I-Reply	I-2	Reply	299
 If the subject of the sentence is known to be a female leader and the model is generating a pronoun, the model has the ability to attend to the future context and select the correct gender-matched pronoun.	I-Reply	I-2	Reply	299
 If the model fails to do this, a well-trained discriminator will ascribe a low reward to this pronoun selection which in turn will generate useful gradients through the attention mechanism.	I-Reply	I-2	Reply	299
 We have observed this behaviour during preliminary experiments.	I-Reply	I-2	Reply	299
 We argue that global consistency is built into this architecture but to solve the boundary problems in appendix C.2, allowing the autoregressive model decide when to stop instead of forcing it to output a fix number of words may resolve some of the syntactic issues.	I-Reply	I-2	Reply	299
[line_break_token][line_break_token]We also expand table 6 to show the diversity of the generated samples compared to a standard LM-LSTM	B-Reply	B-3	Reply	299

This paper investigates stopping criteria for training of RBMs by contrastive[line_break_token]divergence (CD).	O	O	Review	53
Traditional reconstruction error is compared to a ratio of[line_break_token]probabilities, namely the probabilities of the training data divided by the[line_break_token]probabilities of an equal number of sampled points (with two variants of the[line_break_token]sampling strategy).	O	O	Review	53
By dividing probabilities, the partition function cancels[line_break_token]out, which makes computations tractable.	O	O	Review	53
Experiments on two toy datasets show[line_break_token]that the two proposed variants are overall more useful than reconstruction[line_break_token]error to identify the point of maximum likelihood on training data, even though[line_break_token]they do not work on all cases investigated here.	O	O	Review	53
[line_break_token][line_break_token]The problem of early stopping of RBM training is definitely a relevant one,[line_break_token]since the intractability of the partition function prevents properly monitoring[line_break_token]the likelihood.	O	O	Review	53
The approach suggested here, however, lacks in both theoretical[line_break_token]motivation and empirical evaluation, thus in my opinion is not quite ready for[line_break_token]publication.	B-Review	B-10	Review	53
[line_break_token][line_break_token]On the theoretical side, the proposed criterion (eq.	B-Review	B-1	Review	53
8) is only heuristicallymotivated.	I-Review	I-1	Review	53
Note in particular that a model might be able to reach an arbitraryhigh value of this criterion if P(y_i) -> 0 for some y_i, regardless or howbadly it may perform on the training x_i's.	O	O	Review	53
I'm also not sure why one would[line_break_token]necessarily take N y_i's: why not generalize it to M y_i's, using Pi_i[line_break_token]P(y_i)^(N/M), so as to be able to choose the sample size based on available[line_break_token]computational resources?	B-Review	B-2	Review	53
Finally, I am not convinced by the choice of y_i's:[line_break_token]first, the sampling rules (random h or '1 - h_i') are not well motivated (there[line_break_token]is no guarantee that we will not sample training points), second, since they[line_break_token]are defined from the model parameters they lead to a set of y_i's that evolves[line_break_token]during training (thus the criterion may be unstable), third the y_i's are[line_break_token]expectations and there is no explanation on whether it makes sense for binary[line_break_token]RBMs.	B-Review	B-3	Review	53
[line_break_token][line_break_token]On the empirical side, my first concern is that experiments are performed[line_break_token]on low-dimensional toy datasets, and there is nothing to tell us that [line_break_token]behavior observed on such datasets will actually translate into higher[line_break_token]dimensional tasks.	B-Review	B-6	Review	53
In particular, sampling-based methods tend to behave rather[line_break_token]nicely in low dimension, but may break horribly as the dimension increases...[line_break_token]Thus it would have been good to add experiments in high dimension, for instance[line_break_token]using AIS to estimate the partition function.	B-Review	B-7	Review	53
My second concern is that only[line_break_token]training errors are reported: although they are definitely interesting to[line_break_token]monitor, someone using reconstruction error as a stopping criterion will always[line_break_token]use a validation set for this, and will hope to stop at a point where validation[line_break_token]log-likelihood is maximized.	B-Review	B-8	Review	53
The comparisons in the paper are thus, for the[line_break_token]most part, uninformative, since they only use the training data.	O	O	Review	53
[line_break_token][line_break_token]A few more minor points:[line_break_token]- Eq.	B-Review	B-9	Review	53
5 is missing some characters[line_break_token]- The number of hidden units is not mentioned in the experiments[line_break_token]- Plots show 'reconstruction error' as something that is better when it increases,[line_break_token]  which is counter-intuitive for an error[line_break_token]- Something potentially worth discussing is that RBMs are often used for[line_break_token]  pre-training purpose in deep networks, and it is not clear that better[line_break_token]  likelihood => better pre-training (if there is work on this topic, it should[line_break_token]  be cited, as it is important to motivate this direction of research)[line_break_token]- Another application worth mentioning to this kind of technique is model[line_break_token]  selection (which RBM is best?)	O	O	Review	53
=> the proposed criterion may require a bit[line_break_token]  of tweaking to answer this kind of question (common y_i's are needed)	O	O	Review	53
> On the theoretical side, the proposed criterion (eq.	O	O	Reply	53
8) is only [line_break_token] > heuristically motivated.	O	O	Reply	53
Note[line_break_token] > in particular that a model might be able to reach an arbitrary high [line_break_token]value of this criterion if[line_break_token] > P(y_i) -> 0 for some y_i, regardless or how badly it may perform on [line_break_token]the training x_i's.	O	O	Reply	53
[line_break_token][line_break_token]In our mind we implicitely assume CD_1 is leading to the right place [line_break_token]starting from[line_break_token]weights initialized at random.	B-Reply	B-1	Reply	53
if that does not hold, it would lead to [line_break_token]trouble no matter[line_break_token]what the stopping criteria you use.	I-Reply	I-1	Reply	53
[line_break_token]under our assumptions, the situation you point out should not happen, [line_break_token]hopefully.	I-Reply	I-1	Reply	53
[line_break_token]Our experiments seem to back up our line of reasoning, although we agree [line_break_token]the criteria should[line_break_token]be contrasted against other problems :)[line_break_token][line_break_token] > I'm also not sure why one would[line_break_token] > necessarily take N y_i's: why not generalize it to M y_i's, using Pi_i[line_break_token] > P(y_i)^(N/M), so as to be able to choose the sample size based on [line_break_token]available[line_break_token] > computational resources?	O	O	Reply	53
[line_break_token][line_break_token]We don't say that N_i should be equal to M_i: we just use the proposed [line_break_token]estimator,[line_break_token]but of course it could happen that enhanced versions of it leads to [line_break_token]better results.	B-Reply	B-2	Reply	53
[line_break_token]Still, we are confident the proposed criteria works well.	I-Reply	I-2	Reply	53
[line_break_token][line_break_token] > Finally, I am not convinced by the choice of y_i's:[line_break_token] > first, the sampling rules (random h or '1 - h_i') are not well [line_break_token]motivated (there[line_break_token] > is no guarantee that we will not sample training points)[line_break_token][line_break_token]Our belief is that at the very beginning of the training process the [line_break_token]proposed[line_break_token]sampling does lead to states that are far away from the training set, [line_break_token]just because[line_break_token]the RBM has been initialized to random weights and bias, which are [line_break_token]*very* different[line_break_token]from the ones one will get at the optimal point of the learning stage.	O	O	Reply	53
[line_break_token]of course the criteria gets worse when you surpass that point.	B-Reply	B-3	Reply	53
But that [line_break_token]is precisely our main message:[line_break_token]this does not happen while the system is learning and weights are still [line_break_token]non-optimal.	I-Reply	I-3	Reply	53
[line_break_token][line_break_token] > second, since they are defined from the model parameters they lead to [line_break_token]a set of[line_break_token] > y_i's that evolves during training (thus the criterion may be unstable)[line_break_token][line_break_token]We agree that on general grounds, any procedure that changes with model [line_break_token]parameters could be[line_break_token]dynamically unstable, even standard CD_k could suffer from this problem.	B-Reply	B-4	Reply	53
[line_break_token]However we have not seen anything like that in the problems analyzed.	I-Reply	I-4	Reply	53
[line_break_token]In the present case, the size of the spaces studied, despite large, are [line_break_token]small enough[line_break_token]to compute the likelihood and to exhaustively explore all possible [line_break_token]states.	I-Reply	I-4	Reply	53
While[line_break_token]doing so, we have not encountered any of the problems mentioned here.	I-Reply	I-4	Reply	53
[line_break_token][line_break_token] > third the y_i's are[line_break_token] > expectations and there is no explanation on whether it makes sense [line_break_token]for binary[line_break_token] > RBMs.	O	O	Reply	53
[line_break_token][line_break_token]We have seen that using average values reduces noise.	B-Reply	B-5	Reply	53
That makes the [line_break_token]algorithm more stable,[line_break_token]although not using expectations leads to the same statistical solutions.	I-Reply	I-5	Reply	53
[line_break_token][line_break_token] > On the empirical side, my first concern is that experiments are performed[line_break_token] > on low-dimensional toy datasets, and there is nothing to tell us that[line_break_token] > behavior observed on such datasets will actually translate into higher[line_break_token] > dimensional tasks.	O	O	Reply	53
In particular, sampling-based methods tend to [line_break_token]behave rather[line_break_token] > nicely in low dimension, but may break horribly as the dimension [line_break_token]increases...[line_break_token][line_break_token]We are aware that we have to do a more exhaustive study on the scaling [line_break_token]properties[line_break_token]of the method, and we are currently working on that.	B-Reply	B-6	Reply	53
However, we know [line_break_token]stochastic sampling techniques[line_break_token]are best suited for large scale problems.	I-Reply	I-6	Reply	53
In fcat, when the [line_break_token]dimensionality of the space increases,[line_break_token]stochastic methods are essentially the only ones that provide reliable [line_break_token]results on a general[line_break_token]ground.	I-Reply	I-6	Reply	53
For instance, in numerical simulations of quantum many-body [line_break_token]systems of strongly[line_break_token]interacting partcicles, Monte Carlo methods are known to be the only [line_break_token]ones that are able to provide[line_break_token]exact statistical solutions to the Schrodinger equation.	I-Reply	I-6	Reply	53
We are [line_break_token]confident the same applies in the[line_break_token]present case.	I-Reply	I-6	Reply	53
[line_break_token][line_break_token] > Thus it would have been good to add experiments in high dimension,[line_break_token] >  for instanceusing AIS to estimate the partition function.	O	O	Reply	53
[line_break_token][line_break_token]We agree that it is interesting to explore the scalability with the [line_break_token]system size.	B-Reply	B-7	Reply	53
However[line_break_token]in order to check against exact results (computation of the likelihood) [line_break_token]one is restricted[line_break_token]to medium or small spaces.	I-Reply	I-7	Reply	53
Furthermore we are also aware that AIS may [line_break_token]also fail[line_break_token]in some cases (we already mention that in our paper and refer to [line_break_token]reference Schult et al 2010).	O	O	Reply	53
[line_break_token][line_break_token] > My second concern is that only[line_break_token] > training errors are reported: although they are definitely interesting to[line_break_token] > monitor, someone using reconstruction error as a stopping criterion [line_break_token]will always[line_break_token] > use a validation set for this, and will hope to stop at a point where [line_break_token]validation[line_break_token] > log-likelihood is maximized.	O	O	Reply	53
The comparisons in the paper are thus, [line_break_token]for the[line_break_token] > most part, uninformative, since they only use the training data.	O	O	Reply	53
[line_break_token][line_break_token]In general we agree that using part of the examples as a training set [line_break_token]and the rest as a[line_break_token]validation set is a good way to proceed.	B-Reply	B-8	Reply	53
However in the studied data [line_break_token]sets that separation[line_break_token]would lead to significant information loss that may lead to  wrong results[line_break_token](for instance in the bars and stripes problem one'd better show the [line_break_token]network all[line_break_token]possible instances).	I-Reply	I-8	Reply	53
[line_break_token][line_break_token] > A few more minor points:[line_break_token] > - Eq.	O	O	Reply	53
5 is missing some characters[line_break_token] > - The number of hidden units is not mentioned in the experiments[line_break_token] > - Plots show 'reconstruction error' as something that is better when [line_break_token]it increases,[line_break_token] > which is counter-intuitive for an error[line_break_token] > - Something potentially worth discussing is that RBMs are often used for[line_break_token] > pre-training purpose in deep networks, and it is not clear that better[line_break_token] > likelihood => better pre-training (if there is work on this topic, it [line_break_token]should[line_break_token] > be cited, as it is important to motivate this direction of research)[line_break_token] > - Another application worth mentioning to this kind of technique is model[line_break_token] > selection (which RBM is best?)	O	O	Reply	53
=> the proposed criterion may require [line_break_token]a bit[line_break_token] > of tweaking to answer this kind of question (common y_i's are needed)[line_break_token][line_break_token]We thank for these suggestions, and will try to accomodate them in the [line_break_token]next revision	O	O	Reply	53

[line_break_token]The paper applies conditional GAN to the HRED model [Serban et al 2016] for dialogue response generation, showing improvements in terms of informativeness and diversity compared to HRED and VHRED [Serban et al 2017].[line_break_token][line_break_token]The paper is technically solid and relatively easy to follow and the results are good, but comparisons with previous work (descriptive and experimental) are rather weak.	O	O	Review	1284
[line_break_token][line_break_token]- Related work is incomplete: The paper specifically argues for the use of GAN to improve diversity in dialogue response generation, but this is not the first paper to do so. [	B-Review	B-1	Review	1284
Xu et al 2017] presents a GAN-like setup that targets exactly the same goal, but that work is not cited in the paper.	I-Review	I-1	Review	1284
Same for [Zhang et al 2018], but the latter work is rather recent (it still should probably be cited).	I-Review	I-1	Review	1284
[line_break_token][line_break_token]- Evaluation: There is no evaluation against Xu et al which targets the same goal.	B-Review	B-2	Review	1284
The authors didn‚Äôt even compare their methods against baselines used in other GAN works for diverse response generation (e.g., MMI [Xu et al; Zhang et al], Li et al‚Äôs GAN approach [Xu et al]), which makes it difficult to draw comparisons between these related methods.	I-Review	I-2	Review	1284
As opposed to these other works, the paper doesn‚Äôt offer any human evaluation.	I-Review	I-2	Review	1284
[line_break_token][line_break_token]- It would have been nice to include an LSTM or GRU baseline, as these models are still often used in practice and the VHRED paper suggests [Serban et al 2016; Table 1] that LSTM holds up quite well against HRED (if we extrapolate the results of VHRED vs. LSTM and VHRED vs. HRED).	B-Review	B-3	Review	1284
The ablation of GAN and HRED would help us understand which of the two is more important.	I-Review	I-3	Review	1284
[line_break_token][line_break_token]In sum, the work is relatively solid, but considering how much has already been done on generating diverse responses (including 3 other papers also using GAN), I don‚Äôt think this paper is too influential.	B-Review	B-10	Review	1284
Its main weakness is the evaluation (particularly the lack of human evaluation.)	B-Review	B-11	Review	1284
[line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]- Introduction: ‚Äúdiversity promoting training objective but their model is for single turn conversations‚Äù.	B-Review	B-4	Review	1284
[line_break_token]If these were ‚Äúsingle turns‚Äù, they wouldn‚Äôt really be called conversations; that objective has been used with 3+ turn conversations.	I-Review	I-4	Review	1284
It can actually be applied to multi-turn dialogue as with any autoegressive generative models.	I-Review	I-4	Review	1284
For example, it has been exploited that way as a baseline for multi-turn dialogue [Li et al 2016](‚ÄúDeep Reinforcement Learning for Dialogue Generation‚Äú).	I-Review	I-4	Review	1284
Note it is not a ‚Äútraining objective‚Äù, but only an objective function at inference time, which is a more valid reason to criticize that paper.	I-Review	I-4	Review	1284
[line_break_token][line_break_token]- ‚ÄúWe use greedy decoding (MLE) on the first part of the objective.	B-Review	B-5	Review	1284
‚Äù Doesn‚Äôt that hurt diversity because of MLE?	I-Review	I-5	Review	1284
what about using sampling instead (maybe with temperature)?	I-Review	I-5	Review	1284
[line_break_token][line_break_token]- Algorithm 1: the P_theta_G don‚Äôt seem to match the text of section 2.	B-Review	B-6	Review	1284
h_i is in sometimes written in bold and sometimes not (see also Eq 12 for comparison.)	I-Review	I-6	Review	1284
[line_break_token][line_break_token]- End of section 2.1: There are multiple Li et al; specify which one.	B-Review	B-7	Review	1284
[line_break_token][line_break_token]- End of section 2.2 and 2.4: extra closing parenthesis after N(0, ‚Ä¶))[line_break_token][line_break_token]- Figures are too small to read the subscripts.	B-Review	B-8	Review	1284
[line_break_token][line_break_token][Xu et al 2017]: Zhen Xu, Bingquan Liu, Baoxun Wang, Sun Chengjie, Xiaolong Wang, Zhuoran Wang, and Chao Qi.	O	O	Review	1284
Neural response generation via gan with an approximate embedding layer.	O	O	Review	1284
EMNLP 2017.	O	O	Review	1284
[line_break_token][line_break_token][Zhang et al 2018]: Zhang, Yizhe & Galley, Michel & Gao, Jianfeng & Gan, Zhe & Li, Xiujun & Brockett, Chris & Dolan, Bill. (	O	O	Review	1284
2018).	O	O	Review	1284
Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization.	O	O	Review	1284
Thank you for your review.	O	O	Reply	1284
We will soon post a more detailed explanation and new results with human evaluation but we want to quickly address some of the other concerns raised in your review.	O	O	Reply	1284
[line_break_token][line_break_token]Thank you for pointing out those additional three papers that we missed in our discussion of the previous works.	O	O	Reply	1284
We will give a detailed explanation of how our work relates to them in the final version.	O	O	Reply	1284
[line_break_token][line_break_token]--Uniqueness and Influence[line_break_token]As you have also pointed out, we believe that our work is very unique.	B-Reply	B-10	Reply	1284
We also believe that it will be very influential for future work in this area in that we specifically investigate an end-to-end adversarial learning framework  for multi-turn dialogue.	I-Reply	I-10	Reply	1284
First, most of the works on adversarial dialogue response generation in the literature use ses2seq generator which has limited capacity for multi-turn dialogue history encoding.	I-Reply	I-10	Reply	1284
 It is computationally not feasible to always re-encode the entire conversation history at each turn.	I-Reply	I-10	Reply	1284
Hence, the need for the HRED generator.	I-Reply	I-10	Reply	1284
[line_break_token]Also, in our adversarial framework, our discriminator is also multi-turn and compliments the generator at each turn.	I-Reply	I-10	Reply	1284
Hence, the shared dialogue history encoding which is also unique to out work.	I-Reply	I-10	Reply	1284
[line_break_token]Furthermore, to achieve end-to-end differentiation, we also share the word embedding between the generator and discriminator.	I-Reply	I-10	Reply	1284
As at the time of this work,  we were not aware of the approximate embedding layer in Xu et al 2017 and Zhang et al 2018.	I-Reply	I-10	Reply	1284
However, during our study (in 2017) we took a similar approach by replacing the one-hot decoder output by the softmax probability output (with no temperature) but still with shared word embedding.	I-Reply	I-10	Reply	1284
We however did not see any appreciable improvement in the model performance despite the huge computational burden due to the large vocabulary size.	I-Reply	I-10	Reply	1284
So we decided to stick with the one-hot output and only share the word embedding.	I-Reply	I-10	Reply	1284
The shared embedding still allows us to achieve end-to-end differentiability.	I-Reply	I-10	Reply	1284
This contribution is also unique to our work.	I-Reply	I-10	Reply	1284
[line_break_token]Finally, the adversarial response scoring by our jointly trained discriminator is calibrated based on adversarial training, whereas the scores from MMI-antiLM and MMI-bidi [Li et al (2016)] are not.	I-Reply	I-10	Reply	1284
Additional learning is still required during inference to properly calibrate them.	I-Reply	I-10	Reply	1284
[line_break_token][line_break_token]--‚ÄúWe use greedy decoding (MLE) on the first part of the objective.	O	O	Reply	1284
‚Äù Doesn‚Äôt that hurt diversity because of MLE?	O	O	Reply	1284
what about using sampling instead (maybe with temperature)?	O	O	Reply	1284
[line_break_token]It is true that MLE sampling would ordinarily hurt diversity but with noise injection, we are able to perturb the output distribution.	B-Reply	B-5	Reply	1284
In fact, the exploration factor, alpha helps us to control the diversity (much smoother than categorical sampling).	I-Reply	I-5	Reply	1284
We noted in our experiment that increasing alpha actually increases the likelihood of high scoring by the discriminator.	I-Reply	I-5	Reply	1284
This makes us to believe that the generator has mapped high probability samples to high probability noise samples which the discriminator in turn mapped to low discriminator score.	I-Reply	I-5	Reply	1284
This shows that the rearer the noise samples, the more diverse the generator samples and the higher the discriminator score.	I-Reply	I-5	Reply	1284
We however, also note that very high alpha values results to low discriminator scores.	I-Reply	I-5	Reply	1284
Looking at these responses shows that they are less grammatical even though they are obviously diverse.	I-Reply	I-5	Reply	1284
Hence the decision to limit the range of alpha values.	I-Reply	I-5	Reply	1284
            [line_break_token][line_break_token]--Typos[line_break_token]We appreciate your pointing out some minor typos.	B-Reply	B-8	Reply	1284
All those are now fixed and will be included in the final version.	I-Reply	I-8	Reply	1284
[line_break_token][line_break_token]--Additional Evaluation[line_break_token]We have crowdsourced the human evaluation and we will be reporting the results here soon.	B-Reply	B-11	Reply	1284
[line_break_token]-- Additional Previous Work[line_break_token]The three additional references provided shall be added to our citation and discussed under the previous work section.	B-Reply	B-1	Reply	1284
[line_break_token][line_break_token]Let us know if you have additional questions while we collate and analyze the human evaluation results.	O	O	Reply	1284

This paper re-organized the high dimensional 1-D raw waveform as 2-D matrix.	O	O	Review	286
This method simulated the autoregressive flow.	O	O	Review	286
Log-likelihood could be calculated in parallel.	O	O	Review	286
Autoregressive flow was only run on row dimension.	O	O	Review	286
The number of required parameters was desirable to synthesize high-fidelity speech with the speed faster than real time.	O	O	Review	286
Although this method could not achieve top one in ranking in every measurements, the resulting performance was still obtained with the best average results.	O	O	Review	286
[line_break_token][line_break_token]In general, this paper is clearly written, well organized and easy to follow.	O	O	Review	286
The authors carried out sufficient experiments and analyses, and proposed some rules of thumb to build a good model.	O	O	Review	286
On one hand, we may catch the contributions.	O	O	Review	286
But, on the other hand, the contributions were not clearly explained.	O	O	Review	286
The results were averaged but were not clearly explained.	O	O	Review	286
[line_break_token][line_break_token]The authors suggested to specify a bigger receptive field than the squeezed height.	O	O	Review	286
The property of getting better performance using deeper wavenet was "not" clearly explained and investigated.	O	O	Review	286
In the experiments, a small number of generative steps was considered.	O	O	Review	286
This is because short sequence based on autoregressive model was used.	O	O	Review	286
[line_break_token][line_break_token]This paper mentioned that using convolution queue could improve the synthesis speed.	B-Review	B-1	Review	286
But, the synthesis speed has been fast enough because it is almost 15 times faster than real time.	I-Review	I-1	Review	286
In practical applications, 100x faster is almost the same as 15x faster for humans.	I-Review	I-1	Review	286
But, the task isn‚Äôt interacted with human.	I-Review	I-1	Review	286
It is suggested to focuse on reducing the number of parameters or enhancing the log likelihood.	I-Review	I-1	Review	286
any thanks for your review; the feedback is helpful to improve our paper.	O	O	Reply	286
[line_break_token][line_break_token]** After the submission, we have made two improvements: 1) We find that the split &amp; reverse operations for stacking multiple flows are more effective than reverse-only operations (see details in Section 3.4 in our revision).	O	O	Reply	286
Our small-footprint WaveFlow now obtains larger test likelihood (see Table 3 in the revision) and improved speech fidelity (see Table 5 in the revision).	B-Reply	B-1	Reply	286
  2) We implement convolution queue (Paine et al 2016), which brings additional 3x to 5x speedup for WaveFlow models.	I-Reply	I-1	Reply	286
 As a result, our small-footprint WaveFlow (5.91M parameters) can now generate 22.05kHz high-fidelity speech (MOS: 4.32) more than 40x faster than real-time (faster than WaveGlow), which provides a promising neural vocoder.	I-Reply	I-1	Reply	286
We also recommend setting h = 16 for neural vocoding task, because it provides better speech fidelity and its synthesis speed is only marginally slower than h = 8 with the help of convolution queue. **	O	O	Reply	286
[line_break_token][line_break_token]We will address your comments in the following.	O	O	Reply	286
[line_break_token][line_break_token]- ‚ÄúOn one hand, we may catch the contributions.	O	O	Reply	286
But, on the other hand, the contributions were not clearly explained.	O	O	Reply	286
The results were averaged but were not clearly explained.	O	O	Reply	286
‚Äù[line_break_token]* We can summarize our contributions in two points: [line_break_token](1) We propose a novel and unified framework for constructing likelihood-based generative models for raw audio, which includes previous approaches (WaveNet and WaveGlow) as special cases.	O	O	Reply	286
We demonstrate the trade-off between memory footprint, generation speed and audio fidelity within the framework.	O	O	Reply	286
[line_break_token](2) The resulting small WaveFlow is a compelling neural vocoder.	O	O	Reply	286
In comparison with WaveGlow, it requires much fewer parameters (5.91M vs. 87.88M) to generate high fidelity speech (MOS: 4.32 vs. 4.34).	O	O	Reply	286
Its synthesis speed is also slightly faster (42.60x vs. 34.69x).	O	O	Reply	286
 In comparison with WaveNet, WaveFlow models are significantly faster at synthesis.	O	O	Reply	286
[line_break_token][line_break_token]- ‚ÄúThe property of getting better performance using deeper wavenet was "not" clearly explained and investigated.	O	O	Reply	286
‚Äù [line_break_token]* We only test 30-layer WaveNet in the paper.	O	O	Reply	286
We think this question was perhaps raised for flow-based models.	O	O	Reply	286
In Table 4, we investigate WaveFlow with 6x8 = 48 and 8x8 = 64 layers (e.g., row-(l) vs. row-(m)), and WaveGlow with 6x8 = 48 and 12x8 = 96 layers (e.g., row-(e) vs. row-(f)), respectively.	O	O	Reply	286
The models stacked with larger number of flows (i.e., deeper layers) consistently provide better likelihood.	O	O	Reply	286
This property is also well known in normalizing flow literature (e.g., [1]).	O	O	Reply	286
We have added details in Section 5.1.	O	O	Reply	286
[line_break_token][line_break_token][1] Rezende and Mohamed.	O	O	Reply	286
Variational inference with normalizing flows.	O	O	Reply	286
ICML, 2015.	O	O	Reply	286
[line_break_token][line_break_token]- ‚ÄúThis paper mentioned that using convolution queue could improve the synthesis speed.	O	O	Reply	286
But, the synthesis speed has been fast enough because it is almost 15 times faster than real time.	O	O	Reply	286
In practical applications, 100x faster is almost the same as 15x faster for humans.	O	O	Reply	286
But, the task isn‚Äôt interacted with human.	O	O	Reply	286
It is suggested to focus on reducing the number of parameters or enhancing the log likelihood.	O	O	Reply	286
‚Äù[line_break_token]* From human perceptual perspective, 15x faster and 40x faster (our new result)  than real-time has minor difference.	O	O	Reply	286
However, the convolution queue removes redundant calculation at synthesis, which will also improve system throughput in practical applications.	O	O	Reply	286
We do agree on that reducing parameters or enhancing the log likelihood is very important for flow-based models.	O	O	Reply	286
The previously mentioned split &amp; reverse operation is a new endeavor after the submission.	O	O	Reply	286
Note that, there is still significant likelihood gap that has so far existed between autoregressive models and flow-based models [2]. Our proposed model can close the gap with larger squeezing factor h (e.g., h = 64 in Table 4), or increased model size.	O	O	Reply	286
[line_break_token][line_break_token][2] Ho et al Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design.	O	O	Reply	286
ICML 2019	O	O	Reply	286

[line_break_token][line_break_token]This paper claims to propose an extension of the Transformer architecture specialized for the mobile environment (under 500M Mult-Adds).	O	O	Review	438
[line_break_token]The authors propose their method called "Long-Short Range Attention (LSRA)," which separates the self-attention layers into two different purposes, where some heads focus on the local context modeling while the others capture the long-distance relationship.	O	O	Review	438
[line_break_token]They also demonstrate consistent improvement over the transformer on multiple datasets under the mobile setting.	O	O	Review	438
[line_break_token]It also surpasses the recently developed comparative method called "Evolved Transformer" that requires a far costly architecture search under the mobile setting.	O	O	Review	438
[line_break_token] [line_break_token]This paper is basically well written and easy to follow what they have done.	O	O	Review	438
[line_break_token]The experimental results look good.	O	O	Review	438
[line_break_token] [line_break_token]However, I have several concerns that I listed as follows.	O	O	Review	438
[line_break_token] [line_break_token]1,[line_break_token]I am not sure whether my understanding is correct or not, but it seems that the proposed method, LSRA, is not a method specialized for mobile computation.	B-Review	B-1	Review	438
[line_break_token]In fact, in the paper, they say, "To tackle the problem, instead of having one module for "general" information, we propose a more specialized architecture, Long-Short Range Attention (LSRA), that captures the global and local information separately."	I-Review	I-1	Review	438
[line_break_token] [line_break_token]There is no explicit discussion that LSRA is somehow tackling the mobile setting.	I-Review	I-1	Review	438
[line_break_token]There is a large mismatch (gap) between the main claim and what they have done.	I-Review	I-1	Review	438
[line_break_token]In other words, LSRA can be simply applied to standard-setting (non-mobile setting).	I-Review	I-1	Review	438
Is there any reason that the proposed method cannot be applied to the standard-setting?	I-Review	I-1	Review	438
[line_break_token]If my understanding is correct, the paper must be revised and appropriately reorganized to clear this gap.	I-Review	I-1	Review	438
[line_break_token] [line_break_token]2,[line_break_token]I am not convinced of the condition of the so-called "mobile setting (and also extremely efficient constraint)."	B-Review	B-2	Review	438
[line_break_token]Please provide a clear justification for it.	I-Review	I-2	Review	438
[line_break_token] [line_break_token]	B-Review	B-1	Review	438
hank you very much for your constructive comments.	O	O	Reply	438
[line_break_token][line_break_token]1.	O	O	Reply	438
Specialization for mobile setting[line_break_token]As mentioned in Section 4, the original multi-head self-attention captures ‚Äòglobal‚Äô and ‚Äòlocal‚Äô information in a single module.	B-Reply	B-1	Reply	438
This unified design is not efficient especially when the computation budget is very limited (i.e., under the mobile setting).	I-Reply	I-1	Reply	438
We need to make the module more specialized so that it can capture the context in a more efficient way.	I-Reply	I-1	Reply	438
To this end, we proposed LSRA that captures the short-range information by convolution and the long-range information by attention.	I-Reply	I-1	Reply	438
As shown in Figures 4 and 5, our LSRA achieves more improvements when the computation constraint is tighter.	I-Reply	I-1	Reply	438
This is because the redundancy of the unified design is more severe under the mobile setting.	I-Reply	I-1	Reply	438
[line_break_token][line_break_token]We also conducted experiments under the standard setting on the WMT En-Fr dataset.	I-Reply	I-1	Reply	438
Our Mobile Transformer still outperforms the vanilla Transformer under the standard setting:[line_break_token]Base Transformer:                   40.0 BLEU @ 1336M Mult-Adds[line_break_token]Mobile Transformer (Ours):   40.6 BLEU @ 1328M Mult-Adds[line_break_token][line_break_token]2.	O	O	Reply	438
Clarification of mobile settings[line_break_token]We defined our mobile setting based on the real-world requirements for mobile applications and the conventions in the computer vision community.	B-Reply	B-2	Reply	438
Please refer to our general response for more information.	I-Reply	I-2	Reply	438
We revised our paper accordingly in Section 5.	I-Reply	I-2	Reply	438
[line_break_token][line_break_token]We have also listed all other changes in our general response above.	I-Reply	I-2	Reply	438
Please don‚Äôt hesitate to let us know for any additional comments on the paper	I-Reply	I-2	Reply	438

This submission explores whether the formulation of attention proposed in "Using Fast Weights to Attend to the Recent Past" paper is applicable to LSTM.	O	O	Review	174
The associative memory bit is applied to the proposed input (often denoted by "j") before it's gated ("i") and added to the gated state ("f*c_{t-1}").	O	O	Review	174
[line_break_token][line_break_token]The experiments are done on a simple associative retrieval task and a new, harder variant of the same.	O	O	Review	174
The results indicate that the fast weight LSTM improves on both the plain LSTM and the fast weight RNN.	O	O	Review	174
It is unclear how trustworthy these results are since the experimental setup (especially hyperparameter tuning) is not described in much detail.	B-Review	B-1	Review	174
[line_break_token][line_break_token]The proposed model is simple, the experiments are a good start, but even for a workshop paper, I feel more convincing ones are necessary.	O	O	Review	174
Dear Reviewer 3,[line_break_token][line_break_token]Thank you for taking the time to review our work.	O	O	Reply	174
[line_break_token][line_break_token]We believe there is a misunderstanding related to our description of the experimental setup since we have exhaustively described the setup in the paper.	B-Reply	B-1	Reply	174
We indeed did a systematic grid search to optimize hyperparameters, to which the entire Appendix is dedicated.	I-Reply	I-1	Reply	174
Additionally, as mentioned in the paper, with the intended release of the code, our results will be transparent and reproducible, significantly mitigating any uncertainty.	I-Reply	I-1	Reply	174
[line_break_token][line_break_token]We believe our results, despite simplicity due to usage of toy examples, are categorical in that they demonstrated a task which two existing models utterly failed to learn, but can be almost perfectly solved when the two mechanisms were combined.	I-Reply	I-1	Reply	174
 This has never been reported before.	I-Reply	I-1	Reply	174
 [line_break_token][line_break_token]Regard	O	O	Reply	174

This paper describes a BERT-based pre-training for source code related task.	O	O	Review	374
By pre-training on BERT-like models on source code and finetuning on a set of 5 tasks, the authors show good performance improvements over non-pretrained models.	O	O	Review	374
The authors make a series of ablation studies showing that pre-training is indeed useful.	O	O	Review	374
[line_break_token][line_break_token]Overall, I find this work relevant and interesting, albeit somewhat unsurprising.	O	O	Review	374
Nevertheless, I see no reason to reject this paper.	O	O	Review	374
To make my "weak accept" to a "strong accept" I would like to see experiments on more tasks, preferably more complex tasks.	B-Review	B-1	Review	374
For example, such tasks could include (a) variable naming (b) method naming (c) docstring prediction/summarization (d) language modeling/autocompletion.	I-Review	I-1	Review	374
I believe it's unclear to the reader if pre-training is also helpful for any of those tasks too and adding such experiments would significantly strengthen the paper.	I-Review	I-1	Review	374
[line_break_token][line_break_token]Some clarifications comments/questions to the authors:[line_break_token][line_break_token]* I would insist that the authors rename the "Variable Misuse" task to "Variable Misuse Localization".	B-Review	B-2	Review	374
To my understanding the current model points to the misused variable (if any), but does not attempt to suggest a fix.	I-Review	I-2	Review	374
This tackles only a part of the task discussed in Vasic et al (2019), Allamanis et al (2018) and this might confuse readers who want to compare with those works.	I-Review	I-2	Review	374
[line_break_token][line_break_token]* For the Function-Docstring Mismatch task (Section 3.4):[line_break_token]    * It's unclear to me which dataset is used.	B-Review	B-3	Review	374
Is it the Py150 dataset or the Barone &amp; Sennrich (2017)?	O	O	Review	374
[line_break_token]    * I believe that the citations [a], [b] would be appropriate here.	B-Review	B-3	Review	374
[line_break_token][line_break_token]* Overall, for the all the tasks except from "Exception Type", there is a replicability issue: Since the authors manually mutate the code (e.g. introduce a variable misuse, swap an operand), for anyone to compare directly, they would need access to the mutated samples.	B-Review	B-5	Review	374
I would strongly encourage the authors to provide more details on how they create mutated samples and (eventually) the source code that achieves that.	I-Review	I-5	Review	374
[line_break_token][line_break_token]* For the Variable Misuse, Wrong Binary Operator, Swapped Operand tasks.	B-Review	B-4	Review	374
There are a few things that need to be clarified:[line_break_token]   * How long is each code snippet?	I-Review	I-4	Review	374
One would expect that the longer the code snippet the harder the task.	I-Review	I-4	Review	374
Do the authors pass a whole function?	I-Review	I-4	Review	374
[line_break_token]   * What is the proportion of positive/negative examples in each task?	I-Review	I-4	Review	374
[line_break_token][line_break_token][line_break_token][line_break_token][a] Cambronero, Jose, et al "When Deep Learning Met Code Search."	O	O	Review	374
arXiv preprint arXiv:1905.03813 (2019).	O	O	Review	374
[line_break_token][b] Louis, Annie, et al "Deep learning to detect redundant method comments."	O	O	Review	374
arXiv preprint arXiv:1806.04616 (2018).	O	O	Review	374
e thank the reviewer for the helpful comments and suggestions.	O	O	Reply	374
[line_break_token][line_break_token]&gt;&gt; Addition of more complex task[line_break_token][line_break_token]We have now added a more complex task (Section 4.7), that of joint classification, localization and repair of variable misuse errors as proposed in Vasic et al (2019).	B-Reply	B-1	Reply	374
This requires learning two pointers for localization and repair of variable misuse bugs, and is an extension of the variable misuse classification task we have already considered.	I-Reply	I-1	Reply	374
[line_break_token][line_break_token]We had considered the variable and method naming tasks as candidate finetuning tasks.	I-Reply	I-1	Reply	374
The masked language modeling (MLM) pre-training task works by masking/replacing tokens (Section 3.5) and training the network to predict them.	I-Reply	I-1	Reply	374
Variable and method naming tasks would be very similar to MLM (wherein we mask the names and ask the network to predict the masked tokens) and hence, we decided not to include them in this submission.	I-Reply	I-1	Reply	374
[line_break_token][line_break_token]Since CuBERT produces only a pre-trained encoder, the docstring prediction and language modeling/autocomplete tasks would require learning a decoder from scratch.	I-Reply	I-1	Reply	374
A recent work on transfer learning (‚ÄúExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer‚Äù, <a href="https://arxiv.org/abs/1910.10683)" target="_blank" rel="nofollow">https://arxiv.org/abs/1910.10683)</a> recasts the BERT pre-training objective into a text-to-text setting, wherein both Transformer encoder and decoder are pre-trained.	O	O	Reply	374
We consider this reformulation of BERT to be a great future avenue to enable direct finetuning for generative tasks like docstring prediction and autocompletion.	B-Reply	B-1	Reply	374
[line_break_token][line_break_token]&gt;&gt; Renaming the Variable Misuse task[line_break_token][line_break_token]The task we had described was a classification task where the model needs to identify if any of the variables in a function body is misused.	B-Reply	B-2	Reply	374
To avoid any misunderstanding, we have now renamed it to ‚ÄúVariable Misuse Classification‚Äù.	I-Reply	I-2	Reply	374
To also match the full task from Vasic et al (2019), we now also have the ‚ÄúVariable Misuse Localization and Repair‚Äù task (Section 4.7).	I-Reply	I-2	Reply	374
[line_break_token][line_break_token]&gt;&gt; Dataset for the Function-Docstring Mismatch task and related references[line_break_token][line_break_token]The Py150 dataset is used in this task (and all other fine-tuning tasks).	B-Reply	B-3	Reply	374
We have updated the writeup to make this clear.	I-Reply	I-3	Reply	374
Thank you for the references, we have discussed them in the writeup now.	I-Reply	I-3	Reply	374
[line_break_token][line_break_token]&gt;&gt; Details on reproducibility[line_break_token][line_break_token]We have added an appendix (Appendix A) with the details of the dataset generation for the finetuning tasks, including a discussion of the careful use of pseudorandomness to ensure reproducible dataset generation.	B-Reply	B-5	Reply	374
In addition, we plan to release the datasets for public use.	I-Reply	I-5	Reply	374
[line_break_token][line_break_token]&gt;&gt; Details on data generation and proportion of positive/negative examples[line_break_token][line_break_token]We have included these details in Appendix A in the revised version.	B-Reply	B-4	Reply	374

This paper presents DeepAGREL, a framework for biologically plausible deep learning that is modified to use reinforcement learning as a training mechanism.	O	O	Review	20048
This framework is shown to perform similarly to error-backpropagation on a set of architectures.	O	O	Review	20048
The idea relies on feedback mechanism that can resemble local connections between real neurons.	O	O	Review	20048
[line_break_token][line_break_token]This paper is an interesting approach to provide a reinforcement learning paradigm for training deep networks, it is well written and the experiments are convincing, although more explanation about why these specific architectures were tested would be more convincing.	B-Review	B-1	Review	20048
I also think the assumptions about feedback connections in real neurons should be visited and more neuroscientific evidence from the literature should be included in the paper.	B-Review	B-2	Review	20048
Do we expect feedback to happen at each level of a neuron-neuron interaction and between each pair of connected neurons?	I-Review	I-2	Review	20048
Is there a possibility that feedback is more general to sets of neurons, or skips entire layers of neurons?	I-Review	I-2	Review	20048
I think more neuroscience background would help this paper (and others on the topic).	I-Review	I-2	Review	20048
Nonetheless, I think the paper does offer an interesting proposal of a more biologically plausible form of deep learning.	I-Review	I-2	Review	20048
[line_break_token]	O	O	Review	20048
e selected the same architectures as in [Amit2018] as they were tested on another rule with biologically plausible components, we added this as a reference in the text.	B-Reply	B-1	Reply	20048
[line_break_token]Regarding feedback connections, for reasons of space, we point to the elaborate review paper by Roelfsema and Holtmaat (2018); we also added a reference to the very recent Richards et al (2019) paper.	B-Reply	B-2	Reply	20048
The point about the specificity of forward and backward connections however deserves more study.	I-Reply	I-2	Reply	20048
We would argue that given reciprocal learning and weight decay, as argued by Akrout et al (2019), specificity will emerge.	I-Reply	I-2	Reply	20048
We added this point (and citation) to the discussion.	I-Reply	I-2	Reply	20048
[line_break_token][line_break_token]Richards, Blake A., et al "A deep learning framework for neuroscience.	O	O	Reply	20048
"&nbsp;Nature neuroscience&nbsp;22.11 (2019): 1761-1770.	O	O	Reply	20048
[line_break_token]Akrout, M. M., Wilson, C., Humphreys, P., Lillicrap, T., &amp; Tweed, D. (2019).	O	O	Reply	20048
Deep learning without weight transport	O	O	Reply	20048

(emergency review)[line_break_token][line_break_token]This paper demonstrates that a left-to-right language model suffers a high entropy rate when generating a long-term sequence of words.	O	O	Review	325
Then the authors claim that this is because of entropy rate amplification, which could be mitigated by 'calibration'.	O	O	Review	325
With local entropy rate calibration, a language model could achieve lower perplexity generating shorter and concise sequences of words.	O	O	Review	325
[line_break_token][line_break_token]The proposed technique (local entropy rate calibration) is straightforward to implement, and empirically shown to be effective.	O	O	Review	325
This would be easily applied to the decoder in many seq2seq models, expected to improve various language generation tasks.	O	O	Review	325
However, other language models that use bi-directional connections (BERT, RoBERTa, ALBERT) or GAN based language generation models are omitted, and I think these models should be considered to make this work have more impact.	B-Review	B-1	Review	325
[line_break_token][line_break_token]	O	O	Review	325
hanks for the encouraging review.	O	O	Reply	325
[line_break_token][line_break_token]@Bidirectional models: The trouble with applying our methods to these non-autoregressive language models is that there isn‚Äôt a single probabilistic model to improve.	B-Reply	B-1	Reply	325
For example, under different masking patterns, there is no guarantee that BERT outputs conditional probabilities consistent with a single distribution over sequences.	I-Reply	I-1	Reply	325
Indeed, it remains an open line of research to extract probabilistic models from these non-autoregressively-factorized models (see, e.g. [1]).	I-Reply	I-1	Reply	325
We've revised the manuscript with a few citations and a small note about these.	I-Reply	I-1	Reply	325
[line_break_token][line_break_token][1] BERT has a mouth, and it must speak: BERT as a markov random field language model.	O	O	Reply	325
Wang &amp; Cho ‚Äò19	O	O	Reply	325

This this exciting submission presents a new proof of Leshno's version of the universal approximation property (UAP) for neural networks  -- one of the foundational pillars of our understanding of neural networks.	O	O	Review	221
The new proof provides new insights into the universal approximation property.	O	O	Review	221
I consider these the main contribution of the paper.	O	O	Review	221
Specifically, the authors[line_break_token]- provide an upper bound on the required width for the neural network[line_break_token]- show that the approximation property still holds even if strong further requirements are imposed on the weights of the first or last layer.	O	O	Review	221
[line_break_token][line_break_token]I rate this submission a weak accept.	O	O	Review	221
It‚Äôs a very good paper.	O	O	Review	221
The work makes useful contributions that should and will be of interest to many in the field.	O	O	Review	221
The paper is generally well-written.	O	O	Review	221
[line_break_token][line_break_token][line_break_token]Some remarks:[line_break_token][line_break_token]- Being somewhat long, the ‚ÄúProof of Theorem 3.1‚Äù would be a much better read if the authors prefixed it  with an outline of the strategy that the proof takes.	B-Review	B-1	Review	221
[line_break_token][line_break_token]- The authors point out that the lack of dependence of Theorem 3.1 on epsilon is surprising, and cite Lin‚Äôs work from 2017 who previously found such an independence.	B-Review	B-2	Review	221
Lin‚Äôs derivation of the epsilon-independent UAP is much more intuitive than that of this submission, in which the epsilon independence really pops out somewhat magically and for me only made sense when I read the paper again.	I-Review	I-2	Review	221
I would encourage the authors to add to Lin‚Äôs paper‚Äôs citation sentence that this paper motivates the epsilon independence well.	I-Review	I-2	Review	221
Alternatively, the authors could add a few sentences to their paper to provide intuition on how the epsilon-independence comes about in their line of argument.	I-Review	I-2	Review	221
[line_break_token]	O	O	Review	221
hank you very much for appreciating our work!	O	O	Reply	221
[line_break_token][line_break_token]Following your suggestion, we have prefixed the "Proof of Theorem 3.1" with an "Outline of strategy for proving Theorem 3.1".	B-Reply	B-1	Reply	221
We hope that the new outline helps improve clarity, and hopefully captures the underlying intuition of our proof.	B-Reply	B-2	Reply	221
In particular, we have highlighted (at least an important part of) the underlying intuition for why our upper bound is independent of epsilon	I-Reply	I-2	Reply	221

Traditional open-domain QA systems typically have two steps: passage retrieval and aggregating answers extracted from the retrieved passages.	O	O	Review	254
 This paper essentially follows the same paradigm, but leverages the state-of-the-art reading comprehension models for answer extraction, and develops the neural network models for the aggregating component.	O	O	Review	254
 Although the idea seems incremental, the experimental results do seem solid.	B-Review	B-1	Review	254
 The paper is generally easy to follow, but in several places the presentation can be further improved.	B-Review	B-7	Review	254
[line_break_token][line_break_token]Detailed comments/questions:[line_break_token]  1.	O	O	Review	254
In Sec.	B-Review	B-2	Review	254
2.2, the justification for adding H^{aq} and \bar{H}^{aq} is to downweigh the impact of stop word matching.	I-Review	I-2	Review	254
 I feel this is a somewhat indirect and less effective design, if avoiding stop words is really the reason.	I-Review	I-2	Review	254
 A standard preprocessing step may be better.	I-Review	I-2	Review	254
[line_break_token]  2.	O	O	Review	254
In Sec.	B-Review	B-2	Review	254
2.3, it seems that the final score is just the sum of three individual normalized scores.	B-Review	B-3	Review	254
It's not truly a "weighted" combination, where the weights are typically assumed to be tuned.	I-Review	I-3	Review	254
[line_break_token]  3.	O	O	Review	254
Figure 3: Connecting the dots in the two subfigures on the right does not make sense.	B-Review	B-4	Review	254
 Bar charts should be used instead.	I-Review	I-4	Review	254
[line_break_token]  4.	O	O	Review	254
The end of Sec.	B-Review	B-5	Review	254
4.2: I feel it's a bad example, as the passage does not really support the answer.	I-Review	I-5	Review	254
The fact that "Sesame Street" got picked is probably just because it's more famous.	I-Review	I-5	Review	254
[line_break_token]  5.	O	O	Review	254
It'd be interesting to see how traditional IR answer aggregation methods perform, such as simple classifiers or heuristics by word matching (or weighted by TFIDF) and counting.	B-Review	B-6	Review	254
 This will demonstrates the true advantages of leveraging modern NN models.	I-Review	I-6	Review	254
[line_break_token][line_break_token]Pros:[line_break_token]  1.	O	O	Review	254
Updating a traditional open-domain QA approach with neural models[line_break_token]  2.	O	O	Review	254
Experiments demonstrate solid positive results[line_break_token][line_break_token]Cons:[line_break_token]  1.	O	O	Review	254
The idea seems incremental[line_break_token]  2.	B-Review	B-1	Review	254
Presentation could be improved[line_break_token]	B-Review	B-7	Review	254
Thank you for your feedback and thorough review.	O	O	Reply	254
We have revised the paper to address the issues you raised  and fixed the presentation issues.	O	O	Reply	254
[line_break_token][line_break_token]ABOUT THE NOVELTY: [line_break_token][line_break_token]Although traditional QA systems also have the answer re-ranking component, this paper focuses on a novel problem of ``text evidence aggregation'': Here the problem is essentially modeling the relationship between the question and multiple passages (i.e., text evidence), where different passages could enhance or complement each other.	B-Reply	B-1	Reply	254
For example,  the proposed neural re-ranker models the complementary scenario, i.e., whether the union of different passages could cover different facts in a question, thus the attention-based model is a natural fit.	I-Reply	I-1	Reply	254
[line_break_token][line_break_token]In contrast, previous answer re-ranking research did not address the above problem: (1) traditional QA systems like (Ferrucci et al 2010) used similar passage retrieval approach with answer candidates added to the queries.	I-Reply	I-1	Reply	254
However they usually consider each passage individually for extracting features of answers, whereas we utilize the information of union/co-occurrence of multiple passages by composing them with neural networks. (	I-Reply	I-1	Reply	254
2) KB-QA systems (Bast and Haussmann, 2015; Yih et al 2015; Xu et al 2016) sometimes use text evidence to help answer re-ranking, where the features are also extracted on the pair of a question and a single-passage but ignored the union information among multiple passages.	I-Reply	I-1	Reply	254
[line_break_token][line_break_token]We have added the above discussion to our paper (Page 11).	O	O	Reply	254
[line_break_token][line_break_token]RESPONSE TO THE DETAILED QUESTIONS:[line_break_token][line_break_token]Q1: In Sec.	O	O	Reply	254
2.2, the justification for adding H^{aq} and \bar{H}^{aq} is to downweigh the impact of stop word matching.	O	O	Reply	254
 I feel this is a somewhat indirect and less effective design, if avoiding stop words is really the reason.	O	O	Reply	254
 A standard preprocessing step may be better.	O	O	Reply	254
[line_break_token] [line_break_token]A1: We follow the model design in (Wang and Jiang 2017).	B-Reply	B-2	Reply	254
The reason for adding H^{aq} and \bar{H}^{aq} is not only to downweigh the stop word matching, but also to take into consideration the semantic information at each position.	I-Reply	I-2	Reply	254
Therefore, the sentence-level matching model (Eq. (	I-Reply	I-2	Reply	254
5) in the next paragraph) could potentially learn to distinguish the effects of the element-wise comparison vectors with the original lexical information.	I-Reply	I-2	Reply	254
We‚Äôve clarified this on Page 5.	I-Reply	I-2	Reply	254
[line_break_token] [line_break_token]Q2: In Sec.	O	O	Reply	254
2.3, it seems that the final score is just the sum of three individual normalized scores.	O	O	Reply	254
It's not truly a "weighted" combination, where the weights are typically assumed to be tuned.	O	O	Reply	254
[line_break_token][line_break_token]A2: We did tune the assigned weights for the three types of normalized scores on the dev set.	B-Reply	B-3	Reply	254
The tuned version gives some improvement on dev and results in slightly better test scores, compared to simply summing up the three scores.	I-Reply	I-3	Reply	254
[line_break_token] [line_break_token]Q3: Figure 3: Connecting the dots in the two subfigures on the right does not make sense.	O	O	Reply	254
 Bar charts should be used instead.	O	O	Reply	254
[line_break_token] [line_break_token]A3: We have changed the subfigures to bar charts in the updated version.	B-Reply	B-4	Reply	254
[line_break_token] [line_break_token]Q4: The end of Sec.	O	O	Reply	254
4.2: I feel it's a bad example, as the passage does not really support the answer.	O	O	Reply	254
The fact that "Sesame Street" got picked is probably just because it's more famous.	O	O	Reply	254
[line_break_token] [line_break_token]A4: We agree that the passages in Table 6 do not provide full evidence to the question (unlike the example in Figure 1b where the passages fully support all the facts in the question).	B-Reply	B-5	Reply	254
However, the ‚ÄúSesame Street‚Äù got picked not because it is more famous, but because it has supporting evidence in the form of the  "award-winning" and "children's TV show" facts, while the candidate "Great Dane" only covers "1969".	I-Reply	I-5	Reply	254
[line_break_token][line_break_token]We selected this example in order to show another common case of realistic problems in Open-Domain QA, where the question is complex and the top-K retrieved passages cannot provide full evidence.	I-Reply	I-5	Reply	254
In this case, our model is able to select the candidate with evidence covering more facts in the question (i.e. the candidate that is more likely to be approximately correct).	I-Reply	I-5	Reply	254
[line_break_token][line_break_token] [line_break_token]Q5: It'd be interesting to see how traditional IR answer aggregation methods perform, such as simple classifiers or heuristics by word matching (or weighted by TFIDF) and counting.	O	O	Reply	254
 This will demonstrate the true advantages of leveraging modern NN models.	O	O	Reply	254
[line_break_token] [line_break_token]A5: Thank you for the valuable advice!	B-Reply	B-6	Reply	254
We‚Äôve added a baseline method with BM25 value to rerank the answers based on the aggregated passages, together with the analysis about it in the current version.	I-Reply	I-6	Reply	254
In summary, the BM25 model improved the F1 scores but sometimes caused a decrease in the EM scores.	I-Reply	I-6	Reply	254
 This is mainly for two reasons: (1) BM25 relies on bag-of-word representation, so context information is not taken into consideration.	I-Reply	I-6	Reply	254
Also it does not model the phrase similarities. (	I-Reply	I-6	Reply	254
2) shorter answers are preferred by BM25.	I-Reply	I-6	Reply	254
For example when answer candidate A is a subsequence of B, then according to our way of collecting pseudo passages, the pseudo passage of A is always a superset of the pseudo passage of B. Therefore F1 scores are often improved while EM declines.	I-Reply	I-6	Reply	254

This is an excellent analysis paper of a very interesting phenomenon in deep neural networks.	O	O	Review	178
[line_break_token][line_break_token]Quality, Clarity, Originality:[line_break_token]As far as I know, the paper explores a very relevant and original question -- studying how the learning process of different examples in the dataset varies.	O	O	Review	178
In particular, the authors study whether some examples are harder to learn than others (examples that are forgotten and relearned multiple times through learning.)	O	O	Review	178
We can imagine that such examples are "support vectors" for neural networks, helping define the decision boundary.	O	O	Review	178
[line_break_token][line_break_token]The paper is very clear and the experiments are of very high quality.	O	O	Review	178
I particularly appreciated the effort of the authors to use architectures that achieve close to SOTA on all datasets to ensure conclusions are valid in this setting.	O	O	Review	178
I also thought the multiple repetitions and analysing rank correlation over different random seeds was a good additional test.	O	O	Review	178
[line_break_token][line_break_token]Significance[line_break_token]This paper has some very interesting and significant takeaways.	O	O	Review	178
[line_break_token]Some of the other experiments I thought were particularly insightful were the effect  on test error of removing examples that aren't forgotten to examples that are forgotten more.	O	O	Review	178
In summary, the "harder" examples are more crucial to define the right decision boundaries.	O	O	Review	178
I also liked the experiment with noisy labels, showing that this results in networks forgetting faster.	O	O	Review	178
[line_break_token][line_break_token]My one suggestion would be to try this experiment with noisy *data* instead of noisy labels, as we are especially curious about the effect of the data (as opposed to a different labelling task.)	B-Review	B-1	Review	178
[line_break_token][line_break_token]I encourage the authors to followup with a larger scaled version of their experiments.	B-Review	B-2	Review	178
It's possible that for a harder task like Imagenet, a combination of "easy" and "hard" examples might be needed to enable learning and define good decision boundaries.	I-Review	I-2	Review	178
[line_break_token][line_break_token]I argue strongly for this paper to be accepted to ICLR, I think it will be of great interest to the community.	O	O	Review	178
Thank you for your review and suggestions.	O	O	Reply	178
[line_break_token][line_break_token]We performed two additional experiments in CIFAR-10 and have presented the results in the updated supplementary.	B-Reply	B-2	Reply	178
We are happy to include any parts that the reviewer finds helpful in the main paper.	I-Reply	I-2	Reply	178
[line_break_token][line_break_token]1.	I-Reply	I-2	Reply	178
We corrupt all training images with additive Gaussian noise with mean 0 and increasing standard deviation (std 0.5, 1, 2, 10), and track the forgetting events during training as usual.	I-Reply	I-2	Reply	178
Note that we add the noise after a channel-wise standard normalization step of the training images (zero mean, unit variance).	I-Reply	I-2	Reply	178
Therefore, noise with standard deviation of 2 has twice the standard deviation of the unperturbed training data.	I-Reply	I-2	Reply	178
[line_break_token][line_break_token]We present the results in Figure 11 in Appendix 10.	I-Reply	I-2	Reply	178
 We observe that adding increasing amount of noise decreases the amount of unforgettable examples and increases the amount of examples in the second mode of the forgetting distribution.	I-Reply	I-2	Reply	178
[line_break_token][line_break_token]2.	O	O	Reply	178
We follow the label noise experiments presented in Figure 3, and augment only random 20% of the training data with additive Gaussian noise (mean 0, std 10).	B-Reply	B-1	Reply	178
We present the results of comparing the forgetting distribution of the 20% of examples before and after pixel noise was added in Figure 12 (Left) in Appendix 10.	I-Reply	I-1	Reply	178
We observe that the forgetting distribution under pixel noise resembles the one under label noise.	I-Reply	I-1	Reply	178
It is a very interesting observation that we plan to investigate in the future.	I-Reply	I-1	Reply	178
[line_break_token][line_break_token]We agree that it is important to follow-up with a dataset like Imagenet and will pursue this direction in our future work	O	O	Reply	178

This paper proposes a model for point processes using normalizing flows.	O	O	Review	707
The conditional distributions of next inter-arrival times are modeled as normalizing flows with base distributions conditioned on the history.	O	O	Review	707
Continuous-time flow based on neural ODE was employed.	O	O	Review	707
[line_break_token][line_break_token]Overall I find this paper incremental.	B-Review	B-1	Review	707
There have been several works using deep generative models to temporal data, and the proposed method is a simple combination of well-established existing works without problem-specific adaptation.	I-Review	I-1	Review	707
[line_break_token][line_break_token]I don‚Äôt get the point of using VAE in the likelihood estimation.	B-Review	B-2	Review	707
The model (PPF-D) already defines a flexible conditional distribution.	I-Review	I-2	Review	707
The only reason I can imagine to introduce VAE type model is when the dimension of the latent variables (which should be strictly the same as the observed variable) is too large to model directly.	I-Review	I-2	Review	707
In such case one may choose to optimize a lower bound computed from the variational distribution defined over the lower-dimensional latent spaces.	I-Review	I-2	Review	707
Hence in case of temporal point processes where the dimension is one, I see no point of doing VAE.	I-Review	I-2	Review	707
The authors stated that VAE based model (PPF-P) performs better than ordinary flow model (PPF-D) because PPF-P has more flexible base distribution.	I-Review	I-2	Review	707
My guess is that PPF-P has one more stochastic layer so the architecture itself is more expressive than PPF-D. PPF-D with more complex structure (e.g., more layers in base distribution parameter network) may result in a similar performance.	I-Review	I-2	Review	707
[line_break_token][line_break_token]The authors stated in coclusion section that ‚ÄúThe proposed PPF can be optimized by maximizing the exact likelihood‚Äù, which is not true for PPF-P optimizing the lower bound.	I-Review	I-2	Review	707
hank you for your time and review.	O	O	Reply	707
We would like to clarify main concerns and raised questions.	O	O	Reply	707
 [line_break_token][line_break_token]C1.	O	O	Reply	707
Overall I find this paper incremental.	O	O	Reply	707
There have been several works using deep generative models to temporal data, and the proposed method is a simple combination of well-established existing works without problem-specific adaptation.	O	O	Reply	707
[line_break_token][line_break_token]R1.	O	O	Reply	707
We would like to clarify our contribution and the importance of employing each technique in modeling point process distributions.	B-Reply	B-1	Reply	707
[line_break_token]In this paper, we proposed a new perspective on modelling point process distributions which directly estimates the density of conditional point process distribution by utilizing normalizing flow.	I-Reply	I-1	Reply	707
The main advantage of this method in comparison to the intensity-based methods is that we are able to model arbitrary complex point process distributions without making any parametric assumption on the functional form of the distribution while being able to evaluate the likelihood.	I-Reply	I-1	Reply	707
[line_break_token]In order to make our model more expressive and flexible, we proposed to have base-distributions with probabilistic parameters by utilizing variational auto-encoder paradigm.	I-Reply	I-1	Reply	707
When using flow techniques for density estimation, the expressiveness of the model is not only limited by the complexity of normalizing flow transformations, but also by the class of base-distributions.	I-Reply	I-1	Reply	707
In our proposed framework, the fact that flow transformations are shared across time-steps and the true underlying distribution across time-steps might vary a lot, makes our model more sensitive to the choice of base distribution family.	I-Reply	I-1	Reply	707
We believe that, If we choose to model base distributions with Gaussian distribution with deterministic parameters, the bijective transformation might not be able to estimate underlying distributions well, especially when the the ground-truth target distributions vary a lot across time-steps of all the sequences.	I-Reply	I-1	Reply	707
 We further support our claim by proving Proposition 1 in Appendix A which, intuitively speaking, says more flexible base-distribution yields more expressive model.	I-Reply	I-1	Reply	707
[line_break_token]In order to address this shortcoming, we proposed more flexible base distributions where the parameters are probabilistically modeled using variational auto-encoder framework.	I-Reply	I-1	Reply	707
The flexibility comes from the fact that by marginalizing over the latent space of VAE , the base distribution could be highly flexible.	I-Reply	I-1	Reply	707
The base distribution of follows different Gaussian distributions conditioned on different samples of.	I-Reply	I-1	Reply	707
[line_break_token][line_break_token]To demonstrate the power of our proposed probabilistically modeled base-distribution , we designed a synthetic experiment as follows:[line_break_token][line_break_token]-     We construct a dataset of sequences, where in each sequence, the underlying distribution at each time-step varies from a unimodal Gaussian distribution (at odd time steps) to a bimodal Gaussian distribution (at even time steps).	B-Reply	B-2	Reply	707
[line_break_token]-    We chose one mode (N(4,1)) to be the same between even and odd time steps.	I-Reply	I-2	Reply	707
[line_break_token]-     The motivation for this experiment is as follows.	I-Reply	I-2	Reply	707
For PPF-D, by modelling the base distribution with the deterministic parameters , in our example there is no one-to-one transformation that can map two Gaussian base distributions exactly into a uni-modal and a multi-modal distribution respectively at the same time.	I-Reply	I-2	Reply	707
In other words, if a singular one-to-one mapping can map a Gaussian distribution to the mixture of Gaussian distribution in our example, the inverse mapping of either component of the mixture of Gaussians can not be a Gaussian.	I-Reply	I-2	Reply	707
Please see  Preposition 1 and its proof that are provided in Appendix A. [line_break_token]-     On the contrary, PPF-P, with a more flexible base-distribution, should be able to better estimate the true distribution.	I-Reply	I-2	Reply	707
[line_break_token]-     We visualized  samples generated by both PPF-P and PPF-D for an even and odd time-step.	I-Reply	I-2	Reply	707
The results illustrate when the true underlying distribution is mixture of Gaussians, PPF-D covers both components of the kernels but most of the samples are concentrated in an area of low probability, somewhere in between the means of components of mixture distribution.	I-Reply	I-2	Reply	707
In contrast, the results show that PPF-P, with a more flexible base-distribution is much better in estimating the true underlying distribution.	I-Reply	I-2	Reply	707
 Most of the data sampled from PPF-P model lie in the high-probability region.	I-Reply	I-2	Reply	707
[line_break_token]-    We reported the log-likelihood of test data for both PPF-P and PPF-D and also reported the difference of log-likelihood under the true distribution and log-likelihood under the learned models (LL score).	I-Reply	I-2	Reply	707
 The better estimation of PPF-P is confirmed by having a higher log-likelihood and a lower LL score in comparison to PPF-D. [line_break_token][line_break_token]Please see Appendix A for experimental results and more details on this example.	O	O	Reply	707
[line_break_token]	O	O	Reply	707

The authors present an in-depth study of discretizing / quantizing the input as a defense against adversarial examples.	O	O	Review	456
The idea is that the threshold effects of discretization make it harder to find adversarial examples that only make small alterations of the image, but also that it introduces more non-linearities, which might increase robustness.	O	O	Review	456
In addition, discretization has little negative impact on the performance on clean data.	O	O	Review	456
The authors also propose a version of single-step or multi-step attacks against models that use discretized inputs, and present extensive experiments on MNIST, CIFAR-10, CIFAR-100 and SVHN, against standard baselines and, on MNIST and CIFAR-10, against a version of quantization in which the values are represented by a small number of bits.	O	O	Review	456
[line_break_token][line_break_token]The merits of the paper is that the study is rather comprehensive: a large number of datasets were used, two types of discretization were tried, and the authors propose an attack mechanism better that seems reasonable considering the defense they consider.	O	O	Review	456
The two main claims of the paper, namely that discretization doesn't hurt performance on natural test examples and that better robustness (in the author's experimental setup) is achieved through the discretized encoding, are properly backed up by the experiments.	O	O	Review	456
[line_break_token][line_break_token]Yet, the applicability of the method in practice is still to be demonstrated.	B-Review	B-1	Review	456
The threshold effects might imply that small perturbations of the input (in the l_infty sense) will not have a large effect on their discritized version, but it may also go the other way: an opponent might be able to greatly change the discretized input without drastically changing the input.	I-Review	I-1	Review	456
Figure 8 in the appendix is a bit worrysome on that point, as the performance of the discretized version drops rapidly to 0 when the opponents gets a bit stronger.	I-Review	I-1	Review	456
Did the authors observe the same kind of bahavior on other datasets?	I-Review	I-1	Review	456
What would the authors propose to mitigate this issue?	I-Review	I-1	Review	456
To what extend the good results that are exhibited in the paper are valid over the wide range of opponent's strengths?	I-Review	I-1	Review	456
[line_break_token][line_break_token]minor comment:[line_break_token]- the experiments on CIFAR-100 in Appendix E are carried out by mixing adversarial / clean examples while training, whereas those on SVHN in Appendix F use adversarial examples only.	B-Review	B-2	Review	456
[line_break_token]	O	O	Review	456
Thank you for your feedback!	O	O	Reply	456
[line_break_token][line_break_token]> ...the performance of the discretized version drops rapidly to 0 when the opponents gets a bit stronger.	O	O	Reply	456
[line_break_token][line_break_token]We observe this behavior on the datasets we tested on, which were MNIST and CIFAR. (	B-Reply	B-1	Reply	456
CIFAR does not drop all the way to 0, but does drop sharply.)	I-Reply	I-1	Reply	456
We believe that this is an expected result, stemming from the intuition that the relationship between the input and the loss is highly nonlinear.	I-Reply	I-1	Reply	456
When presented with an input which it has never been exposed to (i.e. a pixel has been moved into a bucket that is beyond the adversarial training threshold), the effect on the loss is highly random.	I-Reply	I-1	Reply	456
Many of these perturbed inputs will increase the loss, and it is therefore easy to find an adversarial example.	I-Reply	I-1	Reply	456
[line_break_token][line_break_token]Controlling for the wide range of opponent‚Äôs strengths is an important issue, one which is endemic to adversarial defenses in general.	I-Reply	I-1	Reply	456
The ‚Äústandard setting‚Äù for the adversarial example problem (in which we constrain the L-infinity norm of the perturbed image to an epsilon ball around the original image) was designed to ensure that any adversarially-perturbed image is still recognizable as its original image by a human.	I-Reply	I-1	Reply	456
However, this artificial constraint excludes many other potential attacks that also result in human-recognizable images.	I-Reply	I-1	Reply	456
State-of-the art defenses in the standard setting can still be easily defeated by non-standard attacks; for recent examples of this, see ICLR submission ‚ÄúAdversarial Spheres‚Äù (appendix A), as well as ‚ÄúAdversarial Patch‚Äù by Brown et.	I-Reply	I-1	Reply	456
al (<a href="https://arxiv.org/abs/1712.09665)."	O	O	Reply	456
target="_blank" rel="nofollow">https://arxiv.org/abs/1712.09665).</a>[line_break_token][line_break_token]With this in mind, we believe that the fact that the performance of thermometer-encoded models degrades more quickly than that of vanilla models beyond the training epsilon is a weakness, but no worse in practice than other defenses.	O	O	Reply	456
A ‚Äúlarger epsilon‚Äù attack is just one special case of a ‚Äúnon-standard‚Äù attack; there are an enormous number of other non-standard attacks, some of which are more effective against vanilla models, some of which are more effective against thermometer encodings, and some of which are devastating to both.	B-Reply	B-1	Reply	456
If we permit non-standard attacks, a fair comparison would show that all current approaches are easily breakable.	I-Reply	I-1	Reply	456
There is nothing special about the ‚Äúlarger epsilon‚Äù attack that makes a vulnerability to this non-standard attack in particular more problematic than vulnerabilities to other non-standard attacks, in practice.	I-Reply	I-1	Reply	456
[line_break_token][line_break_token]Additionally, on the CIFAR dataset, we found that even though discretized inputs are impacted much more severely by examples perturbed by more than the training threshold, the discretized models are sufficiently strong to begin with that they still outperform real-valued models even after this vulnerability has been exploited. (	I-Reply	I-1	Reply	456
See updated Figure 8b.)	I-Reply	I-1	Reply	456
CIFAR is more reflective of real-world datasets, so even with this weakness, thermometer-encoded models may outperform real-valued models in practice.	I-Reply	I-1	Reply	456
[line_break_token][line_break_token]Based on your feedback, we updated our submission to include this discussion in Appendix G, and added Figure 8b showing the CIFAR results.	I-Reply	I-1	Reply	456
Also, we discovered a bug which caused the unquantized attack in Figure 8 to be too weak; essentially, we were using a fixed step size of 0.01 for 40 steps which caused the perturbation to never hit the boundary for epsilon > 0.4.	O	O	Reply	456
We have updated the figure to reflect the correct values. (	B-Reply	B-1	Reply	456
The fixed results are qualitatively equivalent, so this change does not affect the conclusions.)	I-Reply	I-1	Reply	456

The paper proposed a problem that most prior methods overlooked the underlying dependency of classes on domains, namely p (y|d) \= p(y).	O	O	Review	1011
  Figure 1 is used to illustrate this issue.	O	O	Review	1011
[line_break_token][line_break_token]If the conditional probability of source domain and target domain is not equal (i.e., p(y|x_S) \= p(y|x_T)  ), the optimal invariance can lead the same generalization problem.	O	O	Review	1011
  Unfortunately, a lot of works has been done [1,2] in matching domain classifier or conditional probability.	O	O	Review	1011
 It is desirable to discuss the difference between these two problems and compared with the missing references in experiments.	B-Review	B-1	Review	1011
[line_break_token][line_break_token]It is also suggested to conduct the analysis of why the datasets satisfy the assumption of the dependence of class and domains.	O	O	Review	1011
[line_break_token][line_break_token]Reference:[line_break_token][1] Flexible Transfer Learning under Support and Model Shift, NIPS 2014.	O	O	Review	1011
[line_break_token][2]Conditional Adversarial Domain Adaptation, NIPS 2018	O	O	Review	1011
Thank you for your critical feedback.	O	O	Reply	1011
[line_break_token]We hope to clarify and address your concerns and questions.	O	O	Reply	1011
[line_break_token]We respond in detail to each comment below.	O	O	Reply	1011
[line_break_token][line_break_token][line_break_token]### Reply to ‚Äúit is desirable to discuss the difference between these two problems‚Äù[line_break_token][line_break_token]In our understanding, your main concern is the novelty of our problem setting, i.e., ‚Äúis domain generalization under domain-class dependency (p(y|d) \neq p(y)) is different from domain adaptation under p(y|x_S) \neq p(y|x_T) ?‚	B-Reply	B-1	Reply	1011
Äù[line_break_token]We acknowledge that we lack the discussion about the difference between these two (though they are indeed considerably different problems), so we have added the below discussion to the paper and emphasized the novelty of our problem setting.	I-Reply	I-1	Reply	1011
[line_break_token][line_break_token]Firstly, the paper addresses {\em domain generalization}, not domain adaptation, as noted in abstract, Sec.1, etc.	I-Reply	I-1	Reply	1011
[line_break_token]These two have different assumptions and purposes.	I-Reply	I-1	Reply	1011
[line_break_token]Concretely, domain adaptation methods require either labeled or unlabeled data from the target domain at training time.	I-Reply	I-1	Reply	1011
[line_break_token]In contrast, domain generalization methods do not require any data from target domains during training but instead, require labeled data from several source domains.	I-Reply	I-1	Reply	1011
[line_break_token]Then the methods collectively exploit them so that the trained system can handle new domains without any adaptation step.	I-Reply	I-1	Reply	1011
[line_break_token][line_break_token]Due to the difference, domain adaptation methods are not always applicable to domain generalization.	I-Reply	I-1	Reply	1011
[line_break_token]For example, Wang+2014, which you suggested for us, transform unlabeled target data so that they can correct distributional shift, but in domain generalization, target data are unavailable.	I-Reply	I-1	Reply	1011
[line_break_token]Also, please note that we care about the shifts within source domains, because domain generalization methods are agnostic on the target domain.	I-Reply	I-1	Reply	1011
[line_break_token]So we think p(y|x_S) \neq p(y|x_T) should be rewritten as p(y|x, d) \neq p(y|x) (we call it conditional probability shift) in domain generalization, so that clarify we focus on the shift within source domains (not between S and T).	I-Reply	I-1	Reply	1011
[line_break_token][line_break_token]Secondly, conditional probability shift (p(y|x, d) \neq p(y|x)), which is often caused by the causal structure y -> x, is not a sufficient condition for p(y|d) \neq p(y).	O	O	Reply	1011
[line_break_token]While conditional probability shift was previously addressed by Li+2018 in domain generalization context, domain-class dependency has been overlooked.	B-Reply	B-1	Reply	1011
[line_break_token]The relation between these two problems is illustrated in Figure 1 in our updated paper.	I-Reply	I-1	Reply	1011
[line_break_token][line_break_token]Thirdly and most importantly, in domain generalization, conditional probability shift does not cause the trade-off problem as long as the domain-class dependency does not exist.	I-Reply	I-1	Reply	1011
[line_break_token]In other words, p(y|x, d) \neq p(y|x) is not a root cause of the trade-off problem, but domain-class dependency is, so it is essential to consider and address domain-class dependency problem.	I-Reply	I-1	Reply	1011
[line_break_token]Again the relation between these two problems is illustrated in Figure 1 in our updated paper.	I-Reply	I-1	Reply	1011

The authors proposed a new method to learn streaming online updates for neural networks with meta-learning and applied it to multi-task reinforcement learning.	O	O	Review	376
Model-agnostic meta-learning is used to learn the initial weight and task distribution is learned with the Chinese restaurant process.	O	O	Review	376
It sounds like an interesting idea and practical for RL.	O	O	Review	376
Extensive experiments show the effectiveness of the proposed method.	O	O	Review	376
[line_break_token][line_break_token]The authors said that online updating the meta-learner did not improve the results, which is a bit surprised.	B-Review	B-1	Review	376
Also how many data are meta-trained is not clearly described in the paper.	B-Review	B-2	Review	376
Maybe the authors can compare the results with less data for meta-training.	B-Review	B-3	Review	376
[line_break_token]	O	O	Review	376
Thank you for your review.	O	O	Reply	376
We added an appendix to the paper that addresses your question, and we have also added this information (as well as illustrative videos) to the project website.	O	O	Reply	376
To illustrate results with less meta-training data, we have evaluated the test-time performance of models from various meta-training iterations, showing that performance does indeed improve with more meta-training data.	B-Reply	B-3	Reply	376
To clarify, this statement of performance improving with meta-training data is different from the statement in the text regarding online updating the meta-learner not improving results.	I-Reply	I-3	Reply	376
We meant that incorporating the EM weight updates during meta-training did not improve results, but we did not mean that additional meta-learning was harmful.	I-Reply	I-3	Reply	376
We added text at the end of section 5 in the updated paper to reduce the potential for confusion.	I-Reply	I-3	Reply	376
[line_break_token][line_break_token]Regarding the amount of data used, the number of datapoints used during metatraining on each of the agents in our experiments is 382,000: This is 12 iterations of alternating model training plus on-policy rollouts, where each iteration collects data from 16 different environment settings, and each setting consists of 2000 datapoints.	B-Reply	B-2	Reply	376
At a simulator timestep of 0.02sec/step, this sample complexity converts to around only 2 hours of real-world data	I-Reply	I-2	Reply	376

This paper studies the issue of truncated backpropagation for meta-optimization.	O	O	Review	289
Backpropagation through an optimization process requires unrolling the optimization, which due to computational and memory constraints, is typically restricted or truncated to a smaller number of unrolled steps than we would like.	O	O	Review	289
[line_break_token][line_break_token]This paper highlights this problem as a fundamental issue limiting meta-optimization approaches.	O	O	Review	289
The authors perform a number of experiments on a toy problem (stochastic quadratics) which is amenable to some theoretical analysis as well as a small fully connected network trained on MNIST.	O	O	Review	289
 [line_break_token][line_break_token](side note: I was assigned this paper quite late in the review process, and have not carefully gone through the derivations--specifically Theorems 1 and 2).	O	O	Review	289
[line_break_token][line_break_token]The paper is generally clear and well written.	O	O	Review	289
[line_break_token][line_break_token]Major comments[line_break_token]-------------------------[line_break_token]I was a bit confused why 1000 SGD+mom steps pre-training steps were needed.	B-Review	B-1	Review	289
As far as I can tell, pre-training is not typically done in the other meta-optimization literature?	I-Review	I-1	Review	289
The authors suggest this is needed because "the dynamics of training are different at the very start compared to later stages", which is a bit vague.	I-Review	I-1	Review	289
Perhaps the authors can expand upon  this point?	I-Review	I-1	Review	289
[line_break_token][line_break_token]The conclusion suggests that the difference in greedy vs. fully optimized schedule is due to the curvature (poor scaling) of the objective--but Fig 2.	B-Review	B-2	Review	289
and earlier discussion talked about the noise in the objective as introducing the bias (e.g. from earlier in the paper, "The noise in the problem adds uncertainty to the objective, resulting in failures of greedy schedule").	I-Review	I-2	Review	289
Which is the real issue, noise or curvature?	I-Review	I-2	Review	289
Would running the problem on quadratics with different condition numbers be insightful?	I-Review	I-2	Review	289
[line_break_token][line_break_token]Minor comments[line_break_token]-------------------------[line_break_token]The stochastic gradient equation in Sec 2.2.2 is missing a subscript: "h_i" instead of "h"[line_break_token][line_break_token]It would be nice to include the loss curve for a fixed learning rate and momentum for the noisy quadratic in Figure 2, just to get a sense of how that compares with the greedy and optimized curves.	B-Review	B-3	Review	289
[line_break_token][line_break_token]It looks like there was an upper bound constraint placed on the optimized learning rate in Figure 2--is that correct?	B-Review	B-5	Review	289
I couldn't find a mention of the constraint in the paper. (	I-Review	I-5	Review	289
the optimized learning rate remains at 0.2 for the first ~60 steps)?	I-Review	I-5	Review	289
[line_break_token][line_break_token]Figure 2 (and elsewhere): I would change 'optimal' to 'optimized' to distinguish it from an optimal curve that might result from an analytic derivation. '	B-Review	B-6	Review	289
Optimized' makes it more clear that the curve was obtained using an optimization process.	I-Review	I-6	Review	289
[line_break_token][line_break_token]Figure 2: can you change the line style or thickness so that we can see both the red and blue curves for the deterministic case?	B-Review	B-7	Review	289
I assume the red curve is hiding beneath the blue one--but it would be good to see this explicitly.	I-Review	I-7	Review	289
[line_break_token][line_break_token]Figure 4 is fantastic--it succinctly and clearly demonstrates the problem of truncated unrolls.	B-Review	B-8	Review	289
I would add a note in the caption to make it clear that the SMD trajectories are the red curves, e.g.: "SMD trajectories (red) during meta-optimization of initial effective ...".	I-Review	I-8	Review	289
I would also change the caption to use "meta-training losses" instead of "training losses" (I believe those numbers are for the meta-loss, correct?).	I-Review	I-8	Review	289
Finally, I would add a colorbar to indicate numerical values for the different grayscale values.	I-Review	I-8	Review	289
[line_break_token][line_break_token]Some recent references that warrant a mention in the text:[line_break_token]- both of these learn optimizers using longer numbers of unrolled steps:[line_break_token]Learning gradient descent: better generalization and longer horizons, Lv et al, ICML 2017[line_break_token]Learned optimizers that scale and generalize, Wichrowska et al, ICML 2017[line_break_token]- another application of unrolled optimization:[line_break_token]Unrolled generative adversarial networks, Metz et al, ICLR 2017[line_break_token][line_break_token]In the text discussing Figure 4 (middle of pg.	B-Review	B-9	Review	289
8) , "which is obtained by using..." should be "which are obtained by using..."[line_break_token][line_break_token]In the conclusion, "optimal for deterministic objective" should be "deterministic objectives"	B-Review	B-11	Review	289
Q1: Why 1000 SGD+mom steps pre-training steps were needed?	O	O	Reply	289
[line_break_token]We want to choose a setting that our observation is less sensitive to which part of training.	B-Reply	B-1	Reply	289
If we always start looking ahead at zeroth step, then there is a higher chance that the optimal hyperparameter is only fitted to the beginning; whereas if we start at some pre-trained steps, e.g. 1000, then the optimal hyperparameter is more likely to generalize to, say 500 or 5000 steps.	I-Reply	I-1	Reply	289
[line_break_token][line_break_token]Q2: Which is the real issue, noise or curvature?	O	O	Reply	289
[line_break_token]The problem will arise if you have both noise in the objective and different curvature directions.	B-Reply	B-2	Reply	289
We showed that in a deterministic problem, the greedy optimal learning rate and momentum is optimal as it is essentially doing conjugate gradient, regardless of how many different curvature directions you have.	I-Reply	I-2	Reply	289
We also showed in theorem 3 that the greedy learning rate is optimal if the curvature is spherical.	I-Reply	I-2	Reply	289
 On the other hand, if there‚Äôs noise in the objective, and there are many different curvature directions the problem will arise.	I-Reply	I-2	Reply	289
This is because, the noise in the objective forbids one to completely get rid of the loss on a particular direction.	I-Reply	I-2	Reply	289
Hence, one should always first remove the loss on low curvature directions and then move onto high curvature directions.	I-Reply	I-2	Reply	289
But short-horizon objective encourages the opposite because high curvature directions gives most rapid decrease in loss.	I-Reply	I-2	Reply	289
Therefore, both noise in the objective and different curvature directions cause the problem.	I-Reply	I-2	Reply	289
[line_break_token][line_break_token]Q3: Figure 2: 1.	O	O	Reply	289
Show fixed learning rate.	O	O	Reply	289
2.	O	O	Reply	289
Thickness of the red curve.	O	O	Reply	289
3.	O	O	Reply	289
Upper bound.	O	O	Reply	289
[line_break_token]Figure 2 is edited as reviewer suggests.	B-Reply	B-7	Reply	289
Also the reviewer is correct that we upper bounded the learning rate to avoid the loss on any curvature direction becoming larger than its initial value, so as to assure the quadratic assumption.	I-Reply	I-7	Reply	289
We added the description in the revised version.	I-Reply	I-7	Reply	289
[line_break_token][line_break_token]Q4: Figure 4: 1.	O	O	Reply	289
Add a color bar to indicate numerical values for the different grayscale values.	O	O	Reply	289
[line_break_token]Thanks for the suggestion.	B-Reply	B-8	Reply	289
We will add it in the next version of our paper.	I-Reply	I-8	Reply	289
[line_break_token][line_break_token]Q5: Citations:[line_break_token]We added those citations reviewer mentioned.	B-Reply	B-9	Reply	289

This paper studies the problem of part segmentation in objects represented as a point cloud.	O	O	Review	130
The main novelty is in the fact that the proposed method uses a bottom-up iterative merging framework inspired by perceptual grouping and finds that it transfers better to unseen categories.	B-Review	B-7	Review	130
In zero-shot transfer experiments, the proposed method performs better than all four other baselines compared; but is worse than Mo et al (2019) in known categories.	B-Review	B-1	Review	130
[line_break_token][line_break_token]The paper hypothesizes that top-down approaches do not generalizes well to new categories because they end up overfitting to the global context.	O	O	Review	130
While this is reasonable, I find that the experiments are not sufficient to validate this claim (please see questions below).	B-Review	B-6	Review	130
Evaluation on unseen object categories is an underexplored topic, and the paper is generally well written.	I-Review	I-6	Review	130
I think the submission can be an above-threshold paper if the questions are addressed.	I-Review	I-6	Review	130
[line_break_token][line_break_token]- I‚Äôd like to see some evidence for the claim that classic segmentation methods "can perform much better for unseen object classes" (last paragraph of page 1), and see how the proposed method compares to those baselines.	B-Review	B-2	Review	130
[line_break_token][line_break_token]- If my understanding of Table 3 is correct, "PartNet-InsSeg" (Mo et al 2019) is a top-down approach yet it performs better than SGPN which is a bottom-up grouping method (as summarized on page 7) in novel categories.	B-Review	B-3	Review	130
If so, can it be explained in a way that is consistent with the paper's findings?	I-Review	I-3	Review	130
[line_break_token][line_break_token]- Table 4 shows some ablation study in an attempt to justify the proposed design, but I think it should be more thorough.	B-Review	B-4	Review	130
e.g. it is not immediately obvious why the authors did not included a baseline that consists only of the rectification module with a termination threshold (seems like the most basic design that doesn't have the large-part bias or explicitly require a termination module).	I-Review	I-4	Review	130
[line_break_token][line_break_token][line_break_token][line_break_token]Typos:[line_break_token][line_break_token]psilon-greedy   (page 6 paragraph 2)[line_break_token]backpropogation  (page 6 under training losses)[line_break_token]In consequences (page 5 under termination network)[line_break_token]epilson  (page 5, under network training)	B-Review	B-5	Review	130
e thank Reviewer #2 for the feedback and suggestions.	O	O	Reply	130
The suggestions are helpful, and we are open to further discussions.	O	O	Reply	130
[line_break_token][line_break_token]From the comments, we infer that Reviewer #2 assumes our claim to be that top-down approaches perform worse than bottom-up approaches in terms of generalization abilities.	B-Reply	B-7	Reply	130
This is not exactly our view.	I-Reply	I-7	Reply	130
Here, we precisely lay out our argument: Using features with the global context may hurt part segmentation performance in unseen categories.	I-Reply	I-7	Reply	130
In most top-down pipelines and some bottom-up pipelines, the features extracted for each point to be fed to the classifier would include the global context.	I-Reply	I-7	Reply	130
This point will be further discussed when addressing specific concerns.	I-Reply	I-7	Reply	130
[line_break_token][line_break_token][line_break_token][Regarding ‚ÄúPartNet-InsSeg‚Äù outperforms ‚ÄúSGPN‚Äù in novel categories][line_break_token]Both ‚ÄúPartNet-InsSeg‚Äù (top-down) and the ‚ÄúSGPN‚Äù (bottom-up) involve global context to learn point features and make decisions, thus give inferior segmentation results on unseen categories.	B-Reply	B-3	Reply	130
This is consistent with our conclusions.	I-Reply	I-3	Reply	130
We are happy to make this point crystally clear in the revised version.	I-Reply	I-3	Reply	130
[line_break_token][line_break_token][line_break_token][line_break_token][Regarding the performance of the tradition segmentation methods and the proposed method][line_break_token]WCseg is one of the most feasible traditional segmentation methods, whose results are provided in Table 1.	B-Reply	B-2	Reply	130
Compared to the learning-based methods, It champions 6 out of 21 unseen categories.	I-Reply	I-2	Reply	130
Also, we have added more qualitative results to Appendix C.3, which demonstrates the performance of both the traditional segmentation method and the proposed method.	I-Reply	I-2	Reply	130
[line_break_token][line_break_token][line_break_token][line_break_token][Regarding the ablation studies][line_break_token]Thanks for pointing this out, and we made the ablation studies more thorough in revision, including the effects of involving more context on both seen and unseen categories, more components analysis, and qualitative results of the rectification module.	B-Reply	B-4	Reply	130
 Please refer to Appendix B for details.	I-Reply	I-4	Reply	130
[line_break_token][line_break_token]Since the policy scores sum to one overall pairs of sub-parts, there is no explicit signal from the policy network whether the pair should be grouped.	I-Reply	I-4	Reply	130
 We therefore introduce the termination module to verify whether we should group the pair of sub-parts, selected based on the score from the policy module.	I-Reply	I-4	Reply	130
We noticed that the name of ‚Äútermination module‚Äù may have confused reviewers, so we would rename it as ‚Äúverification module‚Äù.	I-Reply	I-4	Reply	130
Also, there is indeed a cascaded structure where the termination module will focus on the samples selected by the policy module.	I-Reply	I-4	Reply	130
This serves as a kind of hard example mining and complements the policy module, which needs to recognize so many samples.	I-Reply	I-4	Reply	130
We will make the related descriptions clearer in revision.	I-Reply	I-4	Reply	130
[line_break_token][line_break_token][line_break_token][line_break_token][Regarding the proposed method performs worse than Mo et al (2019) in seen categories][line_break_token]With involved limited context only for seen categories, our proposed method further improves the performance in seen categories.	B-Reply	B-1	Reply	130
Please refer to Table 1,6 for new results and Appendix B.1 for details.	I-Reply	I-1	Reply	130

To achieve the state-of-the-art on the CLEVR and the variations of this, the authors propose a method to use object-based visual representations and a differentiable quasi-symbolic executor.	O	O	Review	129
Since the semantic parser for a question input is not differentiable, they use REINFORCE algorithm and a technique to reduce its variance.	O	O	Review	129
[line_break_token][line_break_token]Quality: [line_break_token]The issue of invalid evaluation should be addressed.	B-Review	B-1	Review	129
CLEVR dataset has train, validation, and test sets.	I-Review	I-1	Review	129
Since the various hyper-parameters are determined with the validation set, the comparison of state-of-the-art should be done using test set.	I-Review	I-1	Review	129
As the authors mentioned, REINFORCE algorithm may introduce high variance, this notion is critical to report valid results.	I-Review	I-1	Review	129
However, the authors only report on the validation set in Table 2 including the main results, Table 4.	I-Review	I-1	Review	129
For Table 5, they only specify train and test splits.	I-Review	I-1	Review	129
Therefore, I firmly recommend the authors to report on the test set for the fair comparison with the other competitive models, and please describe how to determine the hyperparameters in all experimental settings.	I-Review	I-1	Review	129
[line_break_token]   [line_break_token]Clarity:[line_break_token]As mentioned above, please specify the experimental details regarding setting hyperparameters.	B-Review	B-2	Review	129
[line_break_token]In Experiments section, the authors used less than 10% of CLEVR training images.	I-Review	I-2	Review	129
How about to use 100% of the training examples?	I-Review	I-2	Review	129
How about to use the same amount of training examples in the competitive models?	I-Review	I-2	Review	129
The report is incomplete to see the differential evident from the efficient usage of training examples.	I-Review	I-2	Review	129
[line_break_token][line_break_token]Originality and significance:[line_break_token]The authors argue that object-based visual representation and symbolic reasoning are the contributions of this work (excluding the recent work, NS-VQA < 1 month).	O	O	Review	129
However, bottom-up and top-down attention work [1] shows that attention networks using object-based visual representation significantly improve VQA and image captioning performances.	B-Review	B-3	Review	129
If the object-based visual representation alone is the primary source of improvement, it severely weakens the argument of the neuro-symbolic concept learner.	I-Review	I-3	Review	129
Since, considering the trend of gains, the contribution of the proposing method seems to be incremental, this concern is inevitable.	I-Review	I-3	Review	129
To defend this critic, the additional experiment to see the improvement of the other attentional model (e.g, TbD, MAC) using object-based visual representations, without any other annotations, is needed.	I-Review	I-3	Review	129
[line_break_token][line_break_token]Pros:[line_break_token]- To confirm the effective learning of visual concepts, words, and semantic parsing of sentences, they insightfully exploit the nature of the CLEVR dataset for visual reasoning diagnosis.	O	O	Review	129
[line_break_token][line_break_token]Cons:[line_break_token]- Invalid evaluation to report only on the validation set, not test set.	B-Review	B-1	Review	129
[line_break_token]- The unclear significance of the proposed method combining object-based visual representations and symbolic reasoning[line_break_token]- In the original CLEVR dataset paper, the authors said "we stress that accuracy on CLEVR is not an end goal in itself" and "..CLEVR should be used in conjunction with other VQA datasets in order to study the reasoning abilities of general VQA systems."	B-Review	B-3	Review	129
Based on this suggestion, can this work generalize to real-world settings?	B-Review	B-4	Review	129
This paper lacks to discuss its limitation and future direction toward the general problem settings.	I-Review	I-4	Review	129
[line_break_token][line_break_token]Minor comments:[line_break_token]In 4.3, please fix the typos, "born" -> "brown" and "convlutional" -> "convolutional".	O	O	Review	129
[line_break_token][line_break_token][line_break_token][1] Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., & Zhang, L. (2018).	O	O	Review	129
Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering.	O	O	Review	129
IEEE Computer Vision and Pattern Recognition (CVPR'18).	O	O	Review	129
Thank you very much for the constructive comments.	O	O	Reply	129
[line_break_token][line_break_token]1.	O	O	Reply	129
Train/test split[line_break_token]Our evaluation is valid and fair, because all previous papers have also reported results only on the validation set, and we follow the tradition in this paper.	B-Reply	B-1	Reply	129
They did this because there are no ground-truth labels or evaluation servers provided for the CLEVR test split.	I-Reply	I-1	Reply	129
Evaluation on the test split is therefore impossible.	I-Reply	I-1	Reply	129
We agree that it‚Äôs important to ensure all evaluation valid, and we‚Äôll include this clarification into the revision.	I-Reply	I-1	Reply	129
[line_break_token][line_break_token]2.	O	O	Reply	129
Object-based representations and baselines[line_break_token]Thanks for the suggestion.	B-Reply	B-3	Reply	129
We‚Äôll cite and discuss the paper that used object-based visual representation.	I-Reply	I-3	Reply	129
We will also add additional experiments that incorporate object-based representations into TbD/MAC: Instead of the image feature extracted from a ResNet, we change the input visual feature to the reasoning neural architecture to be an object-based representation as in [1]. Please let us know if you have any suggestion regarding the comparison.	I-Reply	I-3	Reply	129
[line_break_token][line_break_token]We also want to clarify that the object-based representation alone is not the main contribution of the paper.	I-Reply	I-3	Reply	129
Instead, our key contribution is the integration of object-based representations and symbolic reasoning.	I-Reply	I-3	Reply	129
Such combination helps us disentangle visual concept learning and language understanding, and has three advantages over alternatives, as explored in the paper:[line_break_token][line_break_token]1) Executing symbolic programs on object-based representations naturally facilitates complex reasoning that includes quantities (counting), comparisons, and relations.	I-Reply	I-3	Reply	129
It also brings combinatorial generalization by design (Sec.	I-Reply	I-3	Reply	129
4.4): for example, trained on scenes with <= 6 objects, our model (but not the baselines) can also perform counting on scenes with 10 objects.	O	O	Reply	129
[line_break_token][line_break_token]2) It fully disentangles the visual concept learning and reasoning: once the visual concepts are learned, they can be systematically evaluated (Sec.	B-Reply	B-3	Reply	129
4.1) and deployed in any visual-semantic applications (such as image caption retrieval, as shown in Sec.	I-Reply	I-3	Reply	129
4.5).	I-Reply	I-3	Reply	129
In contrast, earlier methods like IEP, TbD, and MAC learn visual concepts and reasoning in an entangled manner and cannot be easily adapted to new problem domains (e.g., show in Table 6, VQA baselines are only able to infer the result on a partial set of the image-caption data).	I-Reply	I-3	Reply	129
[line_break_token][line_break_token]3) Symbolic execution over the object space brings full transparency.	I-Reply	I-3	Reply	129
One can easily trace back the error answer and even detect adversarial (ambiguous or wrong) questions (please refer to Appendix.	I-Reply	I-3	Reply	129
E for some examples).	I-Reply	I-3	Reply	129
[line_break_token][line_break_token]3.	O	O	Reply	129
Limitation and future work[line_break_token]We‚Äôd like to clarify that we are not targeting at a specific application such as VQA; instead, we want to build a system that learns accurate (Sec.	B-Reply	B-4	Reply	129
4.1), interpretable (Sec.	I-Reply	I-4	Reply	129
4.2), and transferrable (Sec.	I-Reply	I-4	Reply	129
4.5) concepts from natural supervision: images and question-answer pairs.	I-Reply	I-4	Reply	129
To achieve this, we propose a novel framework that 1) disentangles the learning of both, but 2) bridges them with a reasoning module and 3) lets them bootstrap the learning of each other.	I-Reply	I-4	Reply	129
[line_break_token][line_break_token]Toward concept learning from realistic images and complex language, the current model design suggest multiple research directions.	I-Reply	I-4	Reply	129
First, our model relies on object-based representations; constructing 3D object-based representations for realistic scenes (or videos) needs further exploration [1,2]. Second, our model assumes a domain-specific language for a formal description of semantics.	I-Reply	I-4	Reply	129
The integration of formal semantics into the processing of complex natural language would be meaningful future work [3,4]. We hope our paper could motivate future research in visual concept learning, language learning, and compositionality.	I-Reply	I-4	Reply	129

This paper presents a novel layer-wise optimization approach for learning CNN with piecewise linear nonlinearities.	O	O	Review	269
 The proposed approach trains piecewise linear CNNs layer by layer and reduces the sub-problem into latent structured SVM, which has been well-studied in the literature.	O	O	Review	269
In addition, the paper presents improvements of the BCFW algorithm used in the inner procedure.	O	O	Review	269
Overall, this paper is interesting.	O	O	Review	269
However, unfortunately, the experiment is not convincing.	O	O	Review	269
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]- To my best knowledge, the proposed approach is novel, and the authors provide nice theoretical analysis.	O	O	Review	269
[line_break_token]- The paper is well-written and easy to follow.	O	O	Review	269
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]- Although the proposed approach can be applied in general structured prediction problem, the experiments only conduct on a simple multi-class classification task.	B-Review	B-1	Review	269
This makes this work less compelling.	I-Review	I-1	Review	269
[line_break_token][tab_token][line_break_token]- The test accuracy performance on CIFAR-10 reported in the paper doesn't look right.	B-Review	B-2	Review	269
The accuracy of the best model reported in this paper is 70.2% while existing work often reports 90+%.	I-Review	I-2	Review	269
For example, <a href="https://arxiv.org/pdf/1412.6806.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1412.6806.pdf</a> showed an accuracy of 91% without data augmentation.	O	O	Review	269
Also, CIFAR-10 is a relatively small dataset, [line_break_token][line_break_token]Other comments:[line_break_token][line_break_token]- If I understand correctly, BCFW only guarantees monotonically increasing in the dual objective and does not have guarantees on the primal objective.	B-Review	B-3	Review	269
Especially, in practice, the inner optimization process often stops pretty early (i.e., stops when duality gap is still large).	I-Review	I-3	Review	269
Therefore, when putting them together, the CCCP procedure may not monotonically decrease as the inner procedure is only solved approximately.	I-Review	I-3	Review	269
The authors should add this note when they discuss the properties of their algorithm.	I-Review	I-3	Review	269
[line_break_token]	O	O	Review	269
We thank the reviewer for his comments, which we discuss below:[line_break_token][line_break_token]Comment: ‚ÄúAlthough the proposed approach can be applied in general structured prediction problem, the experiments only conduct on a simple multi-class classification task.	O	O	Reply	269
‚Äù[line_break_token][line_break_token]Response: In principle the architectures used on ImageNet (such as VGG-16, ResNets etc.)	B-Reply	B-1	Reply	269
can be treated like the models used in our experiments, and we expect to obtain similar results on these.	I-Reply	I-1	Reply	269
In addition to the current results, we are currently evaluating our method on CIFAR-100 and ImageNet, which are more challenging multi-class classification tasks.	I-Reply	I-1	Reply	269
We do take note that it would be interesting to test the method on structured prediction tasks as well.	I-Reply	I-1	Reply	269
[line_break_token][line_break_token][line_break_token]Comment: ‚ÄúThe test accuracy performance on CIFAR-10 reported in the paper doesn't look right.	O	O	Reply	269
The accuracy of the best model reported in this paper is 70.2% while existing work often reports 90+%.‚Äù[line_break_token][line_break_token]Response: The best score of 70% is obtained with a network which does not use batch normalization, which makes an important difference.	B-Reply	B-2	Reply	269
The results with batch-normalization in the revised version of the paper reach around 78% testing accuracy.	I-Reply	I-2	Reply	269
Taking into account the reviewer‚Äôs comments, we are currently running experiments with deeper architectures to improve this score.	I-Reply	I-2	Reply	269
[line_break_token][line_break_token][line_break_token]Comment: ‚ÄúIf I understand correctly, BCFW only guarantees monotonically increasing in the dual objective and does not have guarantees on the primal objective.	O	O	Reply	269
In practice, the inner optimization process often stops pretty early (i.e., stops when duality gap is still large).	O	O	Reply	269
Therefore, when putting them together, the CCCP procedure may not monotonically decrease as the inner procedure is only solved approximately.	O	O	Reply	269
The authors should add this note when they discuss the properties of their algorithm.	O	O	Reply	269
‚Äù[line_break_token][line_break_token]Response: The reviewer is correct that during the inner optimization, only the dual objective is guaranteed a monotonic improvement.	B-Reply	B-3	Reply	269
In practice, we do run BCFW with a sufficient number of iterations to yield a very small duality gap.	I-Reply	I-3	Reply	269
Therefore the method provides a monotonic decrease in practice.	I-Reply	I-3	Reply	269
To illustrate this, we have plotted the training objective and the dual gap for an experiment presented in the paper (Adadelta with batch-norm + LW-SVM, Figure 3 in the revised paper): <a href="https://drive.google.com/file/d/0BxXMf_vDT8vCSFQwOWl0aldzeWs/view?usp=sharing" target="_blank" rel="nofollow">https://drive.google.com/file/d/0BxXMf_vDT8vCSFQwOWl0aldzeWs/view?usp=sharing</a> (one data point at the end of each inner iteration of the CCCP).	O	O	Reply	269
We will add a note about these points in the future revision of the paper	B-Reply	B-3	Reply	269

Some minor points / comments / questions:[line_break_token]- "As Neural Networks cannot directly model multiplicative interactions of their inputs": Why not?	B-Review	B-1	Review	87
Isn't that a standard gating mechanism?	I-Review	I-1	Review	87
[line_break_token]- "model parameters were instead obtained using the Normal Equation": That is unclear to me.	B-Review	B-2	Review	87
What is the "Normal Equation"?	I-Review	I-2	Review	87
In the next line, there is "X", but you never define what "X" is.	I-Review	I-2	Review	87
The same for "R" and "C".	O	O	Review	87
[line_break_token]- The section about the arithmetic unit is very much too short.	B-Review	B-3	Review	87
I don't really understand how it works.	I-Review	I-3	Review	87
E.g. how do you perform the loop with repeated additions?	I-Review	I-3	Review	87
How do you decide when to stop?	I-Review	I-3	Review	87
That could work for integer values, but how does that work for float values?	I-Review	I-3	Review	87
And how do you define it in a way that it is differentiable?	I-Review	I-3	Review	87
Or is the arithmetic unit not differentiable w.r.t.	I-Review	I-3	Review	87
its inputs?	I-Review	I-3	Review	87
[line_break_token]- The question about differentiability should also be answered for all the other variables / intermediate values.	B-Review	B-4	Review	87
[line_break_token]- The PC, I guess that is the address of the ARM code?	B-Review	B-5	Review	87
I guess your branch instructions are conditional jumps, which will conditionally set the PC?	I-Review	I-5	Review	87
How do you do that?	I-Review	I-5	Review	87
Esp.,	I-Review	I-5	Review	87
how can that be differentiable?	I-Review	I-5	Review	87
Or is it not differentiable?	I-Review	I-5	Review	87
If it is not differentiable, how can you do training of the controller?	I-Review	I-5	Review	87
[line_break_token]- You also don't really explain how you train the controller.	B-Review	B-6	Review	87
[line_break_token][line_break_token]Cons:[line_break_token]- Some parts are unclear, very much too short.	B-Review	B-7	Review	87
[line_break_token]- Experiment section very much too short.	B-Review	B-8	Review	87
[line_break_token][line_break_token]Pros:[line_break_token]- Very nice idea and work.	O	O	Review	87
[line_break_token]- Open source implementation.	O	O	Review	87
[line_break_token][line_break_token]I really like the idea and the direction of this work but I think it needs some more improvements.	O	O	Review	87
[line_break_token]	O	O	Review	87
Thank you for the review!	O	O	Reply	87
[line_break_token][line_break_token]A large portion of the feedback stems from the fact that the sections detailing each architectural element are too short.	O	O	Reply	87
Unfortunately so, given the stringent 3 page limit, it was impossible to fit in any more detail, and hopefully our responses are adequately able to address your questions.	O	O	Reply	87
[line_break_token] [line_break_token]1.	B-Reply	B-4	Reply	87
Since Feed-Forward Neural Networks compute a linear combination of their inputs (W1*x1 + W2*x2) followed by a nonlinearity, they cannot directly model multiplicative interactions.	B-Reply	B-1	Reply	87
As an alternative, we chose to model multiplication as repeated addition, but we do agree that we could alternatively create an arbitrary computational graph with multiplication as a gate (with errors flowing back as a gradient switch) for this task.	I-Reply	I-1	Reply	87
[line_break_token][line_break_token]2.	B-Reply	B-3	Reply	87
Normal equation is an analytical procedure used to obtain optimal parameters for a linear problem.	B-Reply	B-2	Reply	87
If we define Y = W.X, we can find the optimal weight W by (X^-1)*Y. We used the pseudoinverse and found the parameter W. Here X contains our input samples (Each sample having the 2 operands) and Y is the expected result.	I-Reply	I-2	Reply	87
Following Neural Programmer [1], we perform all 3 operations (Addition, subtraction and multiplication) and take the weighted sum based on the confidence predicted by the neural network where R is the vector with the result of all three operations and C is confidence vector.	I-Reply	I-2	Reply	87
Taking a distribution over the three results allows the AU to learn which operation needs to be performed, and predict the confidence scores accordingly.	O	O	Reply	87
[line_break_token][line_break_token]3.	O	O	Reply	87
The arithmetic unit also predicts a stopping value at each timestep.	B-Reply	B-3	Reply	87
We stop when this value is 0.	I-Reply	I-3	Reply	87
In this use case, we were able to model multiplication as repeated addition, as ARM does not support floating point numbers.	I-Reply	I-3	Reply	87
However this would still work as long as the multiplier (Number of time steps) is a whole number.	I-Reply	I-3	Reply	87
The AU itself was a feed-forward Neural Network, trained using the normal equations as described in 2.	I-Reply	I-3	Reply	87
However, we could alternatively keep "add", "sub" and "mul" as primitive  operations, as is done in Neural Programmer [1]. [line_break_token][line_break_token]4.	O	O	Reply	87
Similar to ARM, we have one register which acts as the PC.	B-Reply	B-4	Reply	87
The controller reads the value of this register at each timestep and the corresponding instruction.	I-Reply	I-4	Reply	87
It uses that as the encoding and updates the PC after every instruction.	I-Reply	I-4	Reply	87
The reading and writing to PC happens exactly like the other registers as described in Neural Turing Machine [2].[line_break_token][line_break_token]5.	O	O	Reply	87
Our Controller is a One-Many LSTM.	B-Reply	B-5	Reply	87
It uses the encoding to generate the list of steps to execute.	I-Reply	I-5	Reply	87
The controller outputs 2 distributions at every time-step.	I-Reply	I-5	Reply	87
One over all the smaller operations to perform and another over the operands.	I-Reply	I-5	Reply	87
We trained the controller using Back-Propagation with the stack-trace generated for every instruction.	I-Reply	I-5	Reply	87
The training is similar to the procedure followed by the Neural Program Interpreter [3]. We also introduced random noise in the gradient to make the training procedure more robust [4].[line_break_token][line_break_token]We are glad that you appreciated our idea and our work, and are mindful of the improvements that need to be made.	O	O	Reply	87
Being an active area of research, we are taking steps in this direction.	O	O	Reply	87
Some improvements that we have made over the months include using our system to execute recursive algorithms such as finding the factorial of the number, using our memory as a stack, with one of the registers acting as the stack pointer, and deploying the same architecture to generalize beyond ARM to MIPS as well (another RISC architecture.)	O	O	Reply	87
Since Workshop papers favor late breaking developments and works in progress, we sought to develop on this nascent field of research by getting invaluable feedback through reviews, such as the one you have given, alongside fruitful discussions at the workshop.	O	O	Reply	87
Unfortunately, due to lack of space we were unable to have an extensive results section within the paper, but we have made the full stack trace as well as the values of the registers and relevant memory locations at each timestep available on our GitHub website <a href="https://neu0.github.io" target="_blank" rel="nofollow">https://neu0.github.io</a>[line_break_token][line_break_token][line_break_token][1] Le, Q.V., Neelakantan, A., & Sutskever, I. (2015).	O	O	Reply	87
Neural Programmer: Inducing Latent Programs with Gradient Descent.	O	O	Reply	87
CoRR, abs/1511.04834.	O	O	Reply	87
[line_break_token][line_break_token][2] Danihelka, I., Graves, A., & Wayne, G. (2014).	O	O	Reply	87
Neural Turing Machines.	O	O	Reply	87
CoRR, abs/1410.5401.	O	O	Reply	87
[line_break_token][line_break_token][3] Freitas, N.D., & Reed, S.E. (2015).	O	O	Reply	87
Neural Programmer-Interpreters.	O	O	Reply	87
CoRR, abs/1511.06279.	O	O	Reply	87
[line_break_token][line_break_token][4] Kaiser, L., Kurach, K., Le, Q.V., Martens, J., Neelakantan, A., Sutskever, I., & Vilnis, L. (2015).	O	O	Reply	87
Adding Gradient Noise Improves Learning for Very Deep Networks.	O	O	Reply	87
CoRR, abs/1511.06807	O	O	Reply	87

The authors propose a novel joint optimisation framework that attempts to optimally trade-off between accuracy and fairness objectives, since in its general formal counterfactual fairness is at odds with classical accuracy objective.	O	O	Review	723
To this end, the authors propose optimising a Pareto front of the fairness-accuracy trade-off space and show that their resulting method outperforms an adversarial approach in finding non-dominated pairs.	O	O	Review	723
[line_break_token][line_break_token]As main contributions, the paper provides:[line_break_token]* A Pareto objective formulation of the accuracy fairness trade-off[line_break_token]* A new causal fairness objective based on the existing Weighted Average Treatment Effect (WATE) and Average Treatment Effect for the Overlap Population (ATO)[line_break_token][line_break_token]Overall, I think the paper makes an interesting contribution to the field of fairness and that the resulting method seems quite attractive for a real-world practitioners.	O	O	Review	723
However, I found the writing / notation imprecise at times and the experimental section too small (lacking an extensive set of baselines, and only on two datasets).	O	O	Review	723
For these reasons, I give it a Weak Accept.	O	O	Review	723
[line_break_token][line_break_token]Some feedback on notation / writing:[line_break_token]* Typo on page 2, the loss L should be defined on X x Y and not Y x Y[line_break_token]* In page 5, h is being used without being introduced first [line_break_token]* the justification for using ATO in the internal layers of the network is a bit insufficient[line_break_token][line_break_token]In terms of suggestions, I think the experimental section needs to be extended and that the various modelling choices need to be explored and/or be further justified.	B-Review	B-1	Review	723
e thank the reviewer for their careful reading and feedback.	B-Reply	B-1	Reply	723
We have combed through our original submission to fix imprecision in writing and notation, including the specific points raised above. (	I-Reply	I-1	Reply	723
Actually, regarding the loss, this is not a typo but really what we mean‚Ä¶).	I-Reply	I-1	Reply	723
[line_break_token][line_break_token]We have also added better explanation of why we penalise the average treatment effect for the overlap population (ATO) in the internal layers.	B-Reply	B-2	Reply	723
Basically, we believe that the best safeguard against unfairness in a neural net classifier is to constrain the network to learn fair intermediate representations.	I-Reply	I-2	Reply	723
This is because internal representations of neural networks are commonly assumed to contain useful information and may be subsequently employed in transfer learning.	I-Reply	I-2	Reply	723
Therefore it would be important to constrain internal layers of the neural network to be fair as well.	I-Reply	I-2	Reply	723
Our experimental results include a setup where all intermediate layers are penalised and a setup where only the next-to-last layer is penalised.	I-Reply	I-2	Reply	723
The former makes the training more difficult although the estimated Pareto front is still reasonable.	I-Reply	I-2	Reply	723
We will investigate in future work how to train this setup in a better way.	I-Reply	I-2	Reply	723
Nonetheless in both setups it is interesting that only constraining intermediate representations to be fair is sufficient to obtain fairness on the final prediction.	I-Reply	I-2	Reply	723
 [line_break_token][line_break_token]We acknowledge the limitations of our current experimental section.	B-Reply	B-3	Reply	723
We recently became aware of the AI Fairness 360 Tool, a Python package that includes a convenient interface to seven popular datasets in the fairness literature.	I-Reply	I-3	Reply	723
In the original submission we analysed two of the datasets contained therein ‚Äî the Adult Census Income and the ProPublica Recidivism dataset.	I-Reply	I-3	Reply	723
Unfortunately there is not enough time during this discussion phase to run our proposed methodology on the other five datasets provided in AI Fairness 360, but we will do this for the final version of the paper.	I-Reply	I-3	Reply	723
[line_break_token][line_break_token]In the meantime, we were able to add some additional visualisation (Figures 2-4) in the experimental section which shows the visual effect of dialling between 0 and 1.	I-Reply	I-3	Reply	723
Namely, for several values of the penalty parameter, we plot the distribution of the final prediction broken down by true class membership and sensitive attribute.	I-Reply	I-3	Reply	723
In addition to reporting the ATO measure of fairness, we also indicate other non-causal fairness metrics including Equalised Odds, Equal Opportunity, and Demographic Parity.	I-Reply	I-3	Reply	723

This paper proposes a representation learning algorithm for RL based on the Information Bottleneck (IB) principle.	O	O	Review	20635
This formulation leads to the observed state X being mapped to a latent variable Z ~ P(Z | X), in such a way that the standard loss function in actor-critic RL methods is augmented with a term minimizing the mutual information between X and Z (which can be seen as a form of regularization).	O	O	Review	20635
This results in a loss that is difficult to optimize directly in the general case: the authors thus propose to approximate it through a variational bound, using Stein variational gradient descent (SVGD) for optimization, which is based on sampling multiple Z_i‚Äôs for a given state X, so as to compute an approximate gradient for the parameters of the function mapping X to Z. Experiments show that when augmenting the A2C algorithm with this technique, (1) the mutual information I(X, Z) decreases more quickly (better ¬´ compression ¬ª of the information), and (2) better sample efficiency is observed on 5 Atari games (with also encouraging results with PPO on 3 Atari games).	O	O	Review	20635
[line_break_token][line_break_token]In spite of the interesting theoretical contributions, I have to recommend rejection as the current empirical evaluation of the proposed approach is extremely limited, making it difficult to assess its benefits over more straightforward algorithms.	O	O	Review	20635
[line_break_token][line_break_token]On the positive side, the authors derive a sensible approach to IB representation learning in RL, and provide solutions to the optimization challenges it leads to.	O	O	Review	20635
I did not have time to check all the maths in the Appendix (I only went through the derivations in A.1 and A.2), but they seem to make sense overall (though it is unclear to me if the new algorithm proposed in A.5 is a practical one, so I am not taking it into account in this evaluation).	O	O	Review	20635
[line_break_token][line_break_token]The key negative point is definitely the weak empirical evaluation.	O	O	Review	20635
The main results are from a limited sample of 5 Atari games, when the full Atari benchmark has 10x more games and is known to exhibit high variance among games when comparing RL algorithms (the additional results from the Appendix on 3 additional games also show situations where the proposed method does not seem to help much, confirming that larger scale experiments are needed for a proper evaluation).	B-Review	B-1	Review	20635
In addition it seems like each algorithm is run only once (instead of using multiple seeds) and only over ~200K timesteps, which is three orders of magnitude lower than results typically reported on Atari.	B-Review	B-2	Review	20635
Another issue is that there is no comparison to other representation learning techniques (like those mentioned in the related work section, or the recent "Unsupervised State Representation Learning in Atari"), nor to a natural and more straightforward variant of the proposed method where Z would simply be sampled from a (learned) Gaussian distribution Z ~ N(mu(X), var(X)), which at first sight seems like an easier-to-optimize objective (using the reparameterization trick)‚Ä¶ I may be wrong, but then this should probably be explained in the paper (I realize that the proposed approach is more general, but then it should be shown how this extra flexibility can lead to improved results).	B-Review	B-3	Review	20635
Finally, the impact on runtime performance is not analyzed: how much slower do A2C / PPO become when optimizing the mutual information term with SVGD?	I-Review	I-3	Review	20635
Overall it is really unclear that better RL results can be obtained through this technique.	I-Review	I-3	Review	20635
[line_break_token][line_break_token]Another important issue is that I found the paper rather difficult to follow, due to some inconsistent / unclear notations or equations.	B-Review	B-4	Review	20635
Here are the main ones I noted:[line_break_token]‚Ä¢[tab_token]The discount factor is not accounted for in the derivation of the objectives in eq.	I-Review	I-4	Review	20635
1-2 (I know this is often the case in practice, but the reason for dropping it should at least be mentioned)[line_break_token]‚Ä¢[tab_token]The jump from V^pi(X) to V^pi(Z) at the end of Section 3 is explained too succintly.	I-Review	I-4	Review	20635
It suggests that V^pi(Z) must be constant (equal to V^pi(X)) over all values of Z that may be sampled from X, which as far as I can tell is not the case in the rest of the paper.	I-Review	I-4	Review	20635
It is also unclear whether pi depends on Z or X. And the notation J(Z) makes it look like J does not depend on X, but it seems like it does because even if pi depends only on Z, by its definition V^pi(Z) actually still depends on X (this also leads to weird equations like eq.	I-Review	I-4	Review	20635
33 where X does not appear in the right-hand side).	I-Review	I-4	Review	20635
Overall this is rather confusing.	I-Review	I-4	Review	20635
[line_break_token]‚Ä¢[tab_token]The ¬´ for every X ¬ª at the top of p. 4 does not make sense to me, due to the term I(X, Z) in eq.	I-Review	I-4	Review	20635
3 where X is a random variable and thus does not take a specific value.	I-Review	I-4	Review	20635
[line_break_token]‚Ä¢[tab_token]The paragraph below eq.	I-Review	I-4	Review	20635
4 is a bit confusing.	I-Review	I-4	Review	20635
It looks like it amounts to saying that Y is a Gaussian around V(Z)?	I-Review	I-4	Review	20635
[line_break_token]‚Ä¢[tab_token]Eq.	I-Review	I-4	Review	20635
5 suggests that R depends on Z, but shouldn‚Äôt it depend on X?	I-Review	I-4	Review	20635
If it depended on Z, then wouldn‚Äôt it influence the optimization since by modifying P(Z|X) we can control the distribution on Z and thus the distribution on R?	I-Review	I-4	Review	20635
[line_break_token]‚Ä¢[tab_token]In eq.	I-Review	I-4	Review	20635
10 it is unclear whether L1 and L2 contain the expectation, also L2 is defined as a function of both theta and phi but seems to depend only on theta[line_break_token]‚Ä¢[tab_token]Below eq.	I-Review	I-4	Review	20635
15 it is said that ¬´ P is the distribution of Z ¬ª but P does not appear in eq.	I-Review	I-4	Review	20635
15[line_break_token]‚Ä¢[tab_token]In eq.	I-Review	I-4	Review	20635
16 should the phi on the left hand side be phi* as in eq.	I-Review	I-4	Review	20635
15?	I-Review	I-4	Review	20635
[line_break_token]‚Ä¢[tab_token]Below eq.	I-Review	I-4	Review	20635
16 it is said ¬´ Notice that C has been omitted ¬ª, but it is unclear whether it was not included to alleviate notations or because it disappears naturally in the mathematical derivation of eq.	I-Review	I-4	Review	20635
16[line_break_token]‚Ä¢[tab_token]The motivation for introducing zeta below eq.	I-Review	I-4	Review	20635
17 is unclear, especially since it seems to play an important role considering that zeta = 0.005 &lt;&lt; 1 is used in the experiments (with no explanation as to how this specific value was selected)[line_break_token]‚Ä¢[tab_token]\hat{L}(Z_i, theta, phi) (between eq.	O	O	Review	20635
17 and 18) does not seem to be defined[line_break_token]‚Ä¢[tab_token]What is the motivation for using the Gaussian U(Z) as described in Section 5?	B-Review	B-4	Review	20635
In particular I find it weird that it depends on X_i, while U(Z) is supposed to replace the marginal P(Z) and not the conditional P(Z | X)[line_break_token][line_break_token]Minor points:[line_break_token]‚Ä¢[tab_token]In the definition of Y_t = R_t = sum_i=0^n-2 ‚Ä¶ above eq.	I-Review	I-4	Review	20635
4, I think the sum should be up to n-1 for an n-step return[line_break_token]‚Ä¢[tab_token]Eq.	I-Review	I-4	Review	20635
4 uses R_t on the right hand term instead of Y_t which looks weird[line_break_token]‚Ä¢[tab_token]Theorem 1 states ¬´ Assume that for any epsilon &gt; 0, ‚Ä¶ ¬ª: ¬´ for any ¬ª should probably be ¬´ there exists ¬ª, since if the inequality was true for any epsilon, it would imply both mutual informations are equal (also the formulation of the theorem does not make it clear that the last inequality is the main result)[line_break_token]‚Ä¢[tab_token]Footnote 1 p. 4: I(X, Y) should be I(X, Z)[line_break_token]‚Ä¢[tab_token]In eq.	O	O	Review	20635
15 the phi below the argmax should be in bold[line_break_token]‚Ä¢[tab_token]Please add a reference that the reader can refer to in order to understand where eq.	B-Review	B-4	Review	20635
20 is coming from[line_break_token]‚Ä¢[tab_token]¬´ Apparently ¬ª is used in a couple of places but should probably be replaced with another word[line_break_token]‚Ä¢[tab_token]When U is uniform, how do you choose its support?	I-Review	I-4	Review	20635
[line_break_token]‚Ä¢[tab_token]After ¬´ median of pairwise distances between the particles ¬ª, I think i=1 should be j=1[line_break_token]‚Ä¢[tab_token]It is unclear to me what ¬´ A2C with noise is ¬ª: it is said that the same phi(X, epsilon) is used ¬´ as A2C with our framework ¬ª, but is it the same phi as A2C with uniform SVIB or A2C with Gaussian SVIB?	I-Review	I-4	Review	20635
And whichever it is, how does it differ from the one it is equal to?	I-Review	I-4	Review	20635
[line_break_token]‚Ä¢[tab_token]¬´ we add 21 to all four curves in order to make exponential moving average ¬ª: I do not understand that sentence[line_break_token]‚Ä¢[tab_token]¬´ we set the number of samples as 26 for the sake of computation efficiency ¬ª: I fail to see how going from 32 to 26 is going to make a major difference in computational efficiency[line_break_token][line_break_token]Update: thank you for your response, but in the absence of a revised version addressing my concerns (as well as those from the other reviewers), I cannot increase my rating	O	O	Review	20635
hanks for your detailed reviews!	O	O	Reply	20635
Due to recent bussiness, we are not able to respond all the concerns.	O	O	Reply	20635
Yet we will augment our paper both on experiments and notations based on your detailed and careful advice.	O	O	Reply	20635
Again many thanks to your careful reading.	O	O	Reply	20635
Here are responses to some main concerns.	O	O	Reply	20635
[line_break_token][line_break_token]1.About seeds[line_break_token]Due to the limitations of compution resources and time, we are only able to run 1 seed for each game before submission.	B-Reply	B-2	Reply	20635
Yet these days we are working on adding multi-seeds experiments(3 seeds specifically), now we have the results that our algorithm performs better than original A2C in five games(Pong, Assault, BeamRider, Qbert, AirRaid), more games are running now.	I-Reply	I-2	Reply	20635
[line_break_token]2.About timesteps[line_break_token]We are not sure about if we are wrong: Since our batchsize is 64, our total frames ought to be 200k * 64 * 4 = 51,200,000 frames.	I-Reply	I-2	Reply	20635
This is the same setting as openai-baselines.	I-Reply	I-2	Reply	20635
Emmm, do you think these timesteps are still not enough for evaluation?	I-Reply	I-2	Reply	20635
[line_break_token]3.About assuming representation variable Z as Gaussian.	O	O	Reply	20635
[line_break_token]The reason why we didn't take this into consideration at first is because that in the original paper of MINE, using MINE to optimize the information bottleneck in supervised learning has already outperformed the variational bottleneck(assuming Z as a Gaussian).	B-Reply	B-3	Reply	20635
Yet in reinforcement learning(Atari games), MINE did not even converge in our experiments.	I-Reply	I-3	Reply	20635
You can see appendix A.5 for detailed descriptions.	I-Reply	I-3	Reply	20635
So we suspect that directly using variational bottleneck might even hurt the performance.	I-Reply	I-3	Reply	20635
But you are definitely right, we should add the experiments to verify the performance of variational bottleneck in reinforcement learning.	I-Reply	I-3	Reply	20635
[line_break_token][line_break_token]We are really grateful that you can give us the directions to augment our experiments.	B-Reply	B-4	Reply	20635
Your advice of notation is also valuable.	I-Reply	I-4	Reply	20635
After we finish the current bussiness, we will make a more rigorous correction on the notations	I-Reply	I-4	Reply	20635

The paper proposed a scheme to detect the presence of anomalous inputs, such as samples designed adversarially for deep learning tasks, that is based on a "subset scanning" approach to detect anomalous activations in the deep learning network.	O	O	Review	20641
The paper is considering a very interesting problem and provides the suitable application of an approach previously developed for pattern detection.	O	O	Review	20641
The approach is motivated by p-value statistics of the activation patterns in the deep learning network under the "null hypothesis" of a non-anomalous input.	O	O	Review	20641
[line_break_token][line_break_token]My rating is "weak reject" because the explanation of the subset scanning approach is not clear.	B-Review	B-1	Review	20641
The paper describes two functionals F and G that are defined over subsets of the data and activations.	I-Review	I-1	Review	20641
Section 2.2 mentions a method that maximizes F over data and activation subsets by maximizing F over the data subsets under a fixed activation subset and vice versa, and iterating over these two.	I-Review	I-1	Review	20641
The section also discusses the function G that measures the priority of an image, but does not describe how the priority is known to provide an optimal solution for the former optimization over F. Another function with the same name is defined to measure the priority of an activation node, and again it is not clear why this will provide an optimal solution for the latter optimization.	I-Review	I-1	Review	20641
It would have been helpful to establish (or at least instantiate) the optimality results for this approach; only a citation is provided.	I-Review	I-1	Review	20641
[line_break_token][line_break_token]The applicability of the approach is limited to the requirement that multiple adversarial samples be present for accurate detection.	B-Review	B-2	Review	20641
It would appear that other approaches to anomaly detection do not require this condition, particularly if they are designed to operate on individual samples.	I-Review	I-2	Review	20641
Furthermore, the requirement for the "same system" to design the anomalous samples limits the applicability of the anomaly detection approach to cases like the single adversarial design detection setting studied here.	I-Review	I-2	Review	20641
[line_break_token][line_break_token]Some questions for the authors:[line_break_token]Is there a reason why the figures (Fig.	B-Review	B-3	Review	20641
2) show results only for a single class?	I-Review	I-3	Review	20641
[line_break_token]Is there a reason why no other anomaly detection algorithms for the activation patterns were used in comparisons?	B-Review	B-4	Review	20641
How about other adversarial noise detection algorithms?	I-Review	I-4	Review	20641
[line_break_token]Is there intuition behind the difference in performance when all target classes vs. a single target class is used?	B-Review	B-5	Review	20641
Does this mean that a multi-class adversary generation would be too diverse for the proposed approach to detect it effectively?	I-Review	I-5	Review	20641
[line_break_token][line_break_token]Minor comments[line_break_token]"Weird together" - is too informal, and it's not clear why this phrasing is needed.	B-Review	B-6	Review	20641
Consider replacing or explaining.	I-Review	I-6	Review	20641
[line_break_token]Typos "anomlaous" multiple times.	I-Review	I-6	Review	20641
hank you for taking the time to review our work!	O	O	Reply	20641
[line_break_token][line_break_token]Allow us to take some more page-space here in the comments with a longer prose form of the optimality of each individual maximization step.	B-Reply	B-1	Reply	20641
 (The convergence of these individual steps to a global maximum is addressed in a larger, top-level comment).	I-Reply	I-1	Reply	20641
[line_break_token][line_break_token]Recall the function G as a priority function which ranks elements under consideration.	I-Reply	I-1	Reply	20641
 When optimizing over images for a fixed set of nodes the elements are the images.	I-Reply	I-1	Reply	20641
 The priority function is the number of node activations created by the image that are less than a threshold level alpha; the higher number of these nodes, the higher priority of the image.	I-Reply	I-1	Reply	20641
 [line_break_token][line_break_token]Now, lets consider the subset of images formed exactly by the 1st, 2nd, and 4th highest priority images.	I-Reply	I-1	Reply	20641
 (Note the 3rd priority image is missing).	I-Reply	I-1	Reply	20641
 The LTSS property allows us to guarantee that this subset (1st, 2nd, and 4th) is suboptimal.	I-Reply	I-1	Reply	20641
 This is because the score of this subset can be improved by either a) removing the 4th priority image form the subset or b) adding the 3rd priority image to the subset.	I-Reply	I-1	Reply	20641
 In other words,[line_break_token][line_break_token]F(1,2,4) &lt;= F(1,2) OR F(1,2,3,4)   (where 1,2,3,4 are the priority rankings of images provided by G).	O	O	Reply	20641
[line_break_token][line_break_token]Therefore we know there are at most LINEARLY many subsets of images to consider and those subsets all have the form of the top-k priority images for some k between 1 and n.  Any subset not meeting this form does not need to be considered.	B-Reply	B-1	Reply	20641
 This drastic reduction of the search space allows us to score only the necessary subsets while guaranteeing that the highest scoring one will be one of them.	I-Reply	I-1	Reply	20641
 [line_break_token][line_break_token](Another version of this same logic can be summarized as:   If the kth highest priority image is a part of the highest scoring subset then we know all images with a higher priority than the kth must also be included.)	I-Reply	I-1	Reply	20641
[line_break_token][line_break_token]Proving that the scoring functions used in this current work satisfy the LTSS property is more involved and is shown on page 1541 here, <a href="http://www.jmlr.org/papers/volume14/mcfowland13a/mcfowland13a.pdf."	O	O	Reply	20641
target="_blank" rel="nofollow">http://www.jmlr.org/papers/volume14/mcfowland13a/mcfowland13a.pdf.</a>  It comes down to the non-parametric scan statistics being monotonically increasing with the number of p-values less than a threshold alpha.	O	O	Reply	20641
[line_break_token][line_break_token]re: Multiple samples being required.	B-Reply	B-2	Reply	20641
[line_break_token] The philosophy of subset scanning is that it is important to leverage a larger, group structure to identify a pattern that may not be noticeable in individual elements.	I-Reply	I-2	Reply	20641
 In the adversarial noise detection scenario, this boils down to caring more about detecting a coordinated attack on the system as compared to a more random (chaotic neutral) actor who may be motivated to alter a single image to a random new class (a single, un-targeted attack).	I-Reply	I-2	Reply	20641
[line_break_token][line_break_token]However, we do not completely ignore the individual image detection power of the method.	I-Reply	I-2	Reply	20641
 These are reported in the first column on the large table of results and can be thought of as an effective floor for detection power when moving into group scanning.	I-Reply	I-2	Reply	20641
 [line_break_token][line_break_token]Adversarial noise is not the only scenario where multiple examples of a similar anomalous pattern may be present.	I-Reply	I-2	Reply	20641
 We've also considered the 'new class label' problem where a network may have been trained on cats and dogs, but now houses are becoming more frequent in the data stream.	I-Reply	I-2	Reply	20641
 Detecting a single house may be difficult, but detecting a dozen houses (among hundred+ cats and dogs) is more reasonable.	I-Reply	I-2	Reply	20641
 This type of formulation also has implications for detecting data-drift over time as well.	I-Reply	I-2	Reply	20641
 In these settings a single one-off anomalous example is not enough to declare a larger shift in the data being processed.	I-Reply	I-2	Reply	20641
 [line_break_token][line_break_token][line_break_token]Class 0 was simply chosen because it was the first class.	B-Reply	B-3	Reply	20641
 Those images are more intended to demonstrate to readers how we calculated AUC's coming from the scores generated by tests sets containing ALL clean images compared to the scores generated by evaluating tests sets that contain some group of noised images.	I-Reply	I-3	Reply	20641
[line_break_token][line_break_token]We've added a top-level comment under this review for why many comparisons across networks, noise types, detection algorithms, data sets, etc.	B-Reply	B-4	Reply	20641
were left out.	I-Reply	I-4	Reply	20641
 The short summary is we believe the idea of detecting out-of-distribution samples by leveraging a common anomalous pattern that is present across those samples is more relevant to the larger body of work then another SOTA claim (which at the current rate of arxiv submissions is fleeting at best).	I-Reply	I-4	Reply	20641
 [line_break_token][line_break_token]The lower detection power when noised examples in the test set are coming from different classes is a noteworthy result.	B-Reply	B-5	Reply	20641
 This suggests that the power of detecting from a single class is truly leveraging a persistent pattern.	I-Reply	I-5	Reply	20641
 It is not simply doing a good job on individually anomalous images and then cleverly combining them.	I-Reply	I-5	Reply	20641
 If it was doing that, then detection power should also be high when the images had different targets	I-Reply	I-5	Reply	20641

The paper investigates methods to train neural networks so the final network has sparse weights, both in convolutional layers and in fully connected layers.	O	O	Review	20401
In particular, the paper focuses on modifying the training so that the network is first trained without sparsification for a certain number of epochs, then trained to be increasingly sparse, and then fine-tuned with a fixed sparsity pattern at the end.	O	O	Review	20401
[line_break_token][line_break_token]While I find the overall approach of the paper interesting, currently the experiments are not systematic enough to derive clear insights from the paper.	O	O	Review	20401
Hence I unfortunately recommend rejecting the paper at this point.	O	O	Review	20401
I hope the authors find time to conduct more systematic experiments for a future version of the paper.	B-Review	B-10	Review	20401
[line_break_token][line_break_token]Concretely, the following would be interesting experiments / questions:[line_break_token][line_break_token]- How effective is the proposed training method on architectures other than ResNets?	B-Review	B-1	Review	20401
[line_break_token][line_break_token]- What happens if the "pruning era" is made longer, started substantially earlier, or started substantially later?	B-Review	B-2	Review	20401
Currently it is not clear if the epoch 30 - 50 pruning era is (approximately) optimal and how much performance varies with begin and end of the pruning era.	I-Review	I-2	Review	20401
[line_break_token][line_break_token]- Due to the small variation between some of the methods, it would be good to investigate how robust the ordering is when the experiment is re-ran with different random seeds etc.	B-Review	B-3	Review	20401
[line_break_token][line_break_token][line_break_token]In addition, I have the following suggestions:[line_break_token][line_break_token]- The authors may want to remove or enhance the adversarial robustness evaluation.	B-Review	B-4	Review	20401
Currently the authors only evaluate robustness against FGSM, but it is well known that iterative attacks such as PGD are more effective.	I-Review	I-4	Review	20401
[line_break_token][line_break_token]- Instead of "intra-epoch pruning" or "intra", the name "combined" may be more clear for the combined method.	B-Review	B-5	Review	20401
[line_break_token][line_break_token]- In the description of the experimental setup, it could be good to specify what GPUs were used (since this lead to the smaller batch size).	B-Review	B-6	Review	20401
[line_break_token][line_break_token]- It could be helpful for the reader to discuss how predictive results on Tiny-ImageNet are for results on ImageNet.	B-Review	B-7	Review	20401
[line_break_token][line_break_token]- In Table 2, it would be good to add context by comparing to prior work with sparsity level 60% and some of the compression-focused methods from Table 4.	B-Review	B-8	Review	20401
[line_break_token][line_break_token]- In the comparison to Mao et al (2017), it could be good to clarify that they also work with ResNet models on ImageNet.	B-Review	B-9	Review	20401
[line_break_token]	O	O	Review	20401
1) Our argument for only using one architecture is that Resnet networks are the benchmark for MLPerf and the hardest/longest networks to train.	B-Reply	B-1	Reply	20401
All other recent work on CNNs use Resnet, on Imagenet and some smaller datasets, as well.	I-Reply	I-1	Reply	20401
However, to address this concern we will add experiments on VGG.	I-Reply	I-1	Reply	20401
[line_break_token] [line_break_token](2) The main goal of this approach is to restrict the pruning era to reduce complexity especially on accelerators.	B-Reply	B-2	Reply	20401
We also aimed to reach a fixed sparsity mask as early as possible.	I-Reply	I-2	Reply	20401
Keeping the above goal in mind, we did perform sensitivity analysis (shown in Table 1) keeping the final convergence accuracy as high as possible.	I-Reply	I-2	Reply	20401
We demonstrated that shrinking the pruning era damages the accuracy.	I-Reply	I-2	Reply	20401
On top of that we moved the pruning era 10 epochs earlier or later in training and studied wider pruning schedules.	I-Reply	I-2	Reply	20401
[line_break_token] [line_break_token](3) This is a good suggestion; however, what prevented us from doing this is that these experiments we demonstrated each take several days of training per data point.	B-Reply	B-3	Reply	20401
To just perform the sensitivity analysis on the width of the pruning era it took us several months.	I-Reply	I-3	Reply	20401
We can definitely perform these analysis for smaller networks and datasets.	I-Reply	I-3	Reply	20401
[line_break_token] [line_break_token](4) Thanks for the suggestion regarding adversarial attacks.	B-Reply	B-4	Reply	20401
We will investigate PGD.	I-Reply	I-4	Reply	20401
However, we believe that finding that structured sparse training is robust for FGSM is still valuable as other work show.	I-Reply	I-4	Reply	20401
[line_break_token] [line_break_token](5) Thanks we will fix the name of intra-epoch pruning to combined method to improve clarity.	B-Reply	B-5	Reply	20401
[line_break_token] [line_break_token](6) We used RTX2080 instances.	B-Reply	B-6	Reply	20401
We will add that to the paper.	I-Reply	I-6	Reply	20401
[line_break_token] [line_break_token](7) Very valid point regarding the productivity of the Tiny-Imagenet results.	B-Reply	B-7	Reply	20401
We will add this.	I-Reply	I-7	Reply	20401
[line_break_token] [line_break_token](8) Regarding Table2, compression focused methods take around 180 epochs of training if aiming for levels of accuracy that reported.	B-Reply	B-8	Reply	20401
If not, they have much worse accuracy numbers without providing structured sparsity and without the potential of computation savings during training.	I-Reply	I-8	Reply	20401
So, we chose to only compare with sparse training methods.	I-Reply	I-8	Reply	20401
[line_break_token] [line_break_token](9) Thanks, we will clarify that Mao et al (2017) worked with Resnet/Imagenet.	B-Reply	B-9	Reply	20401

This paper derives a formula for finding the minimum and maximum clipping values for uniform quantization which minimize the square error resulting from quantization, for either a Laplace or Gaussian distribution over pre-quantized value.	O	O	Review	683
This seems like too small a contribution to warrant a paper.	O	O	Review	683
I wasn't convinced that appropriate baselines were used in experiments.	O	O	Review	683
There were a number of statements that I believed to be technically slightly incorrect.	O	O	Review	683
There were also some small language problems (though these didn't hinder understanding).	O	O	Review	683
[line_break_token][line_break_token]more specific comments:[line_break_token][line_break_token]abstract:[line_break_token]"derive exact expressions" -- these expressions aren't exact.	B-Review	B-1	Review	683
they turn out to be based on a piecewise zeroth order Taylor approximation to the density.	I-Review	I-1	Review	683
[line_break_token][line_break_token]main paper:[line_break_token]"allow fit bigger networks into" -> "allow bigger network to fit into"[line_break_token]"that we are need" -> "that need"[line_break_token]"introduces an additional" -> "introduces additional"[line_break_token]clippig -> clipping[line_break_token][line_break_token]it's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.	B-Review	B-3	Review	683
[line_break_token][line_break_token]"distributions of tensors" -> "distribution of tensor elements"[line_break_token]this comment also applies in a number of other places, where the writing refers to the marginal distribution of values taken on by entries in a tensor as the distribution over the tensor.	O	O	Review	683
note that a distribution over tensors is a joint distribution over all entries in a tensor.	B-Review	B-4	Review	683
e.g. it would capture things like eigenvalues, entry-entry covariance, rather than just marginal statistics.	I-Review	I-4	Review	683
[line_break_token][line_break_token]"than they could have by working individually" -> "than could have been achieved by each individually"[line_break_token][line_break_token]Why the focus on small activation bit depth?	B-Review	B-6	Review	683
I would imagine weight bit-depth was more important than activation bit depth.	I-Review	I-6	Review	683
Especially since you're using ?	I-Review	I-6	Review	683
32-bit?	I-Review	I-6	Review	683
precision in the weight/activations multiplications, so activations are computed at a high bit depth anyways.	I-Review	I-6	Review	683
[line_break_token][line_break_token]Table 1: Give absolute accuracies too!	B-Review	B-7	Review	683
Improvement relative to what baseline?	I-Review	I-7	Review	683
[line_break_token][line_break_token]sec 2:[line_break_token]sufficeint -> sufficient[line_break_token]\citep often used when it should instead be \citet.	O	O	Review	683
[line_break_token]"As contrast" -> "In contrast"[line_break_token][line_break_token]section 3:[line_break_token]uniformity -> uniformly[line_break_token][line_break_token]I don't believe the notion of p-value is being used correctly here w.r.t.	B-Review	B-10	Review	683
the Kolmogorov-Smirnov test.	I-Review	I-10	Review	683
[line_break_token][line_break_token]Figure 1: The mean square error should never go to 0.	B-Review	B-11	Review	683
This suggests something is wrong.	I-Review	I-11	Review	683
If it's just a scaling issue, consider a semilogy plot.	I-Review	I-11	Review	683
[line_break_token][line_break_token]Figure 2: I'm unclear what baseline (no clipping) refers to in terms of clipping values.	B-Review	B-12	Review	683
For uniform quantization there needs to be some min and max value.	I-Review	I-12	Review	683
The paper indeed provides a formula for optimal quantization when the distribution of tensor elements is either laplace or gauss.	O	O	Reply	683
The paper also shows the relevance of these derivations to a very attractive use-case i.e., the conversion of full precision network to low precision network without time-consuming re-training or the availability of the full datasets.	O	O	Reply	683
Our approach is shown to have significant advantages over previous approaches (as summarized in Table 1).	O	O	Reply	683
[line_break_token] [line_break_token]Response to more specific comments:[line_break_token]Language problems: We have incorporated all typos and paraphrasing suggestions[line_break_token][line_break_token]1.‚Äúit's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.	O	O	Reply	683
‚Äù  The connection between quantization error and classification accuracy has been investigated through the preservation of the direction of the quantized tensor.	B-Reply	B-3	Reply	683
See for example here:[line_break_token]         a.[tab_token]<a href="https://arxiv.org/pdf/1805.11046.pdf#page=9&zoom=100,0,96" target="_blank" rel="nofollow">https://arxiv.org/pdf/1805.11046.pdf#page=9&zoom=100,0,96</a> (section 5.1)[line_break_token]         b.[tab_token]<a href="https://arxiv.org/pdf/1705.07199.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.07199.pdf</a> (section 3.1)[line_break_token]We have added a detailed explanation about the connection between power of the quantization error and accuracy drop (see paragraph #5 in the introduction).	O	O	Reply	683
[line_break_token][line_break_token]2.‚ÄúGive absolute accuracies too!	O	O	Reply	683
Improvement relative to what baseline?‚Äù We now provide the baselines we use in our experiments (see Table 1).	B-Reply	B-7	Reply	683
 [line_break_token][line_break_token]3. ‚	O	O	Reply	683
ÄúThe mean square error should never go to 0.	O	O	Reply	683
This suggests something is wrong.	O	O	Reply	683
If it's just a scaling issue, consider a semilogy plot.	O	O	Reply	683
‚Äù: This was indeed a scale issue only.	B-Reply	B-11	Reply	683
It is not relevant anymore (the figure was removed and replaced by the synthetic experiments showing that analysis and simulations are in a good agreement).	I-Reply	I-11	Reply	683
[line_break_token][line_break_token]4.	O	O	Reply	683
[tab_token]‚ÄúI'm unclear what baseline (no clipping) refers to in terms of clipping values.	O	O	Reply	683
For uniform quantization there needs to be some min and max‚Äù: we improved the explanation of this issue in the introduction (see beginning of paragraph 9), where we explain that the traditional method that avoids clipping uniformly quantize the values between the largest and smallest tensor elements.	B-Reply	B-12	Reply	683

The current paper proposes using Graph Convolutional Networks (GCN) to explicitly represent and use relational data in dialog modeling, as well an attention mechanism for combining information from multiple sources (dialog history, knowledge base, current utterance).	O	O	Review	1359
The work assumes that the knowledge base associated with the dialog task has en entity-to-entity-relationship format and can be naturally expressed as a graph.	O	O	Review	1359
The dependency tree of dialog utterances can also be expressed as a graph, and the dialog history as a set of graphs.	O	O	Review	1359
To utilize this structure, the proposed method uses GCNs whose lowest layer embeddings are initialized with the entity embeddings or via outputs of standard RNN-like models.	O	O	Review	1359
The main claim is that the proposed model outperforms the current state-of-the-art on a goal-oriented dialog task.	O	O	Review	1359
[line_break_token][line_break_token]The idea of explicitly modeling the relational structure via GCNs is interesting.	B-Review	B-1	Review	1359
However, the use of GCNs independently per sentence and per knowledge-base is a bit disappointing, since it does not couple these sources of information in a structured way.	I-Review	I-1	Review	1359
Instead, from my current understanding, the approach merely obtains better representations for each of these sources of information, in the same way it is done in the related language tasks.	I-Review	I-1	Review	1359
For instance, have you considered passing information across the trees in the history as well?	I-Review	I-1	Review	1359
Or aligning the parsed query elements with the KB elements?	I-Review	I-1	Review	1359
[line_break_token][line_break_token]The results are very good.	B-Review	B-2	Review	1359
That said, a source of concern is that the model is only evaluated as a whole, without showing which modification brought the improvements.	I-Review	I-2	Review	1359
The comparison between using/not using RNNs to initiate the first GCN layer is promising, but why not compare to using only RNN also?	I-Review	I-2	Review	1359
Why not compare the various encoders within an established framework (e.g. without the newly introduced attention mechanism)?	I-Review	I-2	Review	1359
Finally, the attention mechanism, stated as a contribution, is not motivated well.	I-Review	I-2	Review	1359
[line_break_token][line_break_token]Clarity:[line_break_token]The notation is described well, but it's not terribly intuitive (the query embedding is denoted by c, the history embedding by a, etc.),	B-Review	B-3	Review	1359
making section 4.4.	I-Review	I-3	Review	1359
hard to follow.	I-Review	I-3	Review	1359
A figure would have made things easier to follow, esp.	I-Review	I-3	Review	1359
due to the complexity of the model.	I-Review	I-3	Review	1359
A clearer parallel with previous methods would also improve the paper: is the proposed approach adding GCN on top of an established pipeline?	I-Review	I-3	Review	1359
Why not?	I-Review	I-3	Review	1359
[line_break_token][line_break_token]More discussion on code-mixed language, e.g. in section 4.6, would also improve clarity a bit (make the paper more self-contained).	B-Review	B-4	Review	1359
While the concept is clear from the context, it would be helpful to describe the level of structure in the mixed language.	I-Review	I-4	Review	1359
For instance, can dependency trees not be obtained code-mixed languages?	I-Review	I-4	Review	1359
Is there any research in this direction? (	I-Review	I-4	Review	1359
or is the concept very new?)	I-Review	I-4	Review	1359
Maybe I am just missing the background here, but it seems helpful in order to asses how appropriate the selected heuristic (based on the co-occurence matrix) is.	I-Review	I-4	Review	1359
[line_break_token][line_break_token]Relevant Reference:[line_break_token]Learning Graphical State Transitions, Johnson, ICLR 2017 also uses graph representations in question answering, though in a somewhat different setting.	B-Review	B-5	Review	1359
[line_break_token][line_break_token]Typos:[line_break_token]Section 4: "a model with following components"[line_break_token]Section 5: "the various hyperparameters that we conisdered"	B-Review	B-6	Review	1359
We would like to thank you for some great suggestions on strengthening the paper.	O	O	Reply	1359
We must confess that while we had some of these on our to-do list, there were a few that we hadn't actually thought of.	O	O	Reply	1359
We have now been able to add these experiments and we believe it has definitely helped us improve the quality of the paper.	O	O	Reply	1359
Below we give a pointwise update about the new experiments.	O	O	Reply	1359
[line_break_token][line_break_token]1)Passing information across the KB tree and query/history tree by aligning query/history elements with the KB elements: We were able to implement this and did a thorough hyperparameter tuning across all languages.	B-Reply	B-1	Reply	1359
We have included these results in the paper (RNN+CROSS-GCN-SeA in Tables 1, 2) but the short summary is that there was not much change in the BLEU, ROUGE and per response accuracy and only a marginal improvement in the Entity F1-score for En-DSTC2 and Ta-DSTC2.	I-Reply	I-1	Reply	1359
We had expected the entity F1-score to improve significantly across all languages since we are explicitly linking entities in the KB with entities in the query/history but unfortunately this was not the case.	I-Reply	I-1	Reply	1359
Initial analysis suggests that given that the task is relatively simple, even the base model, which does not explicitly pass information across the trees, is still able to capture the relevant information.	I-Reply	I-1	Reply	1359
[line_break_token][line_break_token]2)Ablation tests including comparisons with basic RNN based models and basic attention models: This was a bad miss on our part but now we have been able to do a thorough ablation study with the following experiments where we try to evaluate the (i) need for GCNs (ii) need for our sequential attention mechanism and (iii) need for combining RNNs with GCN:[line_break_token][line_break_token]a)RNN with attention (the basic seq2seq+attention model of Bahdanau et al 2015)[line_break_token]b)GCN with Bahdanau attention [does not use RNN or our sequential attention][line_break_token]c)RNN+GCN with Bahdanau attention [does not use our sequential attention][line_break_token]d)RNN with our sequential attention [does not use GCNs][line_break_token]e)RNN+GCN with our sequential attention [Our Final Model][line_break_token][line_break_token]We have included these results for all languages in the updated version of the paper (see Table 8 in Appendix D and ‚ÄúAblations‚Äù part of Section 6) and the main observations are summarized below:[line_break_token][line_break_token]i)GCNs do not outperform RNNs independently: In general, the performance of GCN-Bahdanau attention < RNN-Bahdanau attention[line_break_token]ii)Our sequential attention outperforms Bahdanau attention:  In general, the performance of GCN-Bahdanau attention < GCN-our_seq_attention, RNN-Bahdanau attention < RNN-our_seq_attention and RNN+GCN-Bahdanau attention < RNN+GCN-our_seq_attention.	O	O	Reply	1359
However, note that RNN-Bahdanau attention < RNN-our_seq_attention holds for BLEU and all ROUGE metrics but not for Entity F1 and exact match accuracy.	O	O	Reply	1359
We are analyzing this further and will hopefully be able to add some insights in the final version of the paper.	B-Reply	B-2	Reply	1359
[line_break_token]iii)Combining GCNs with RNNs helps: In general, RNN-our_seq_attention < RNN+GCN-our_seq_attention[line_break_token][line_break_token]Overall, the best results are always obtained by our final model which combines RNN, GCN and sequential attention.	O	O	Reply	1359
Also, the code for our model and these ablation studies will be made publicly available.	B-Reply	B-2	Reply	1359
[line_break_token][line_break_token]3)Motivation behind attention: The motivation behind using a sequential attention mechanism was as follows: The current utterance which we refer to as query sets the stage for what comes next (the response).	I-Reply	I-2	Reply	1359
Hence we use this query to attend to only important parts in the history (essentially, the history can be long and we just want to focus on things which are relevant for the last utterance).	I-Reply	I-2	Reply	1359
Once, we have identified relevant portions of the history and computed an attention weighted representation for the history we are now ready to identify the important concepts from the KB.	I-Reply	I-2	Reply	1359
To achieve this effect we use the sequential attention mechanism.	I-Reply	I-2	Reply	1359
[line_break_token][line_break_token]4)GCN on top of an established pipeline: experiment c in point 2 above.	B-Reply	B-3	Reply	1359
[line_break_token][line_break_token]5)Better notations and figures: Indeed, in hindsight, we agree that some of our choices were not very intuitive.	I-Reply	I-3	Reply	1359
We have added 2 diagrams which hopefully makes things clear.	I-Reply	I-3	Reply	1359
It would be great if you can give us a feedback on the diagrams.	I-Reply	I-3	Reply	1359
[line_break_token][line_break_token]6)Clarity on code-mixing: The statistics about the level of code mixing, level of structure, etc are mentioned in the original paper (Banerjee et al 2018) which introduced the dataset.	B-Reply	B-4	Reply	1359
As suggested, to make the paper self-contained we have added the important statistics in this paper and some examples of code mixed conversations from the dataset (Appendix A).	I-Reply	I-4	Reply	1359
Note that there is a lot of work on processing code mixed text (for example, POS tagging of code mixed text, sentiment analysis of code mixed text, information retrieval using code mixed queries, etc).	I-Reply	I-4	Reply	1359
However, there is not much work on code mixed dialogues because this dataset was only released recently (COLING 2018).	I-Reply	I-4	Reply	1359
To the best of our knowledge, there is no work on building parsers for code mixed languages which produce parse trees.	I-Reply	I-4	Reply	1359
[line_break_token][line_break_token]7)We have fixed the typos and added the relevant reference	O	O	Reply	1359

This paper presents a joint learning framework for document ranking and query suggestion.	O	O	Review	495
It introduces the session embeddings to capture the connections between queries in a session, and potential impact of previous queries in a session to the document ranking of the current query.	O	O	Review	495
I like the idea in general.	O	O	Review	495
[line_break_token][line_break_token]However, I have a few comments as follows:[line_break_token][line_break_token]- Multi-task Match Tensor model, which is important in the experiments (best results), is only briefly introduced in Section 3.4.	B-Review	B-1	Review	495
It is not very clear how to extend from match tensor model to a multi-task match tensor model.	I-Review	I-1	Review	495
This makes me feel like this paper is not self-contained.	I-Review	I-1	Review	495
The setting for this model is not introduced either in Section 4.2.	I-Review	I-1	Review	495
[line_break_token][line_break_token]- Section 3 is written mostly about what has been done but not why doing this.	B-Review	B-2	Review	495
More intuition should be added to better explain the idea.	I-Review	I-2	Review	495
[line_break_token][line_break_token]- I like the analysis about testing the impact of the different model components in Section 4.4, especially analyzing the impact of the session.	B-Review	B-3	Review	495
It would be nice to have some real examples to see the impact of session embeddings on document ranking.	I-Review	I-3	Review	495
One more related question is how the clicked documents of a previous query in the same session influence the document ranking of this current query?	I-Review	I-3	Review	495
Would that be feasible to consider in this proposed framework?	I-Review	I-3	Review	495
[line_break_token][line_break_token]- Session seems to play an important role in this multi task learning framework.	B-Review	B-4	Review	495
This paper used the fixed 30 minute window of idle time to define a session.	I-Review	I-4	Review	495
It would be nice to know how sensitive this model is to the definition / segmentation of sessions.	I-Review	I-4	Review	495
[line_break_token]	O	O	Review	495
We thank the reviewer for recognizing our contribution to multi-task learning and giving suggestions to improve the writing.	O	O	Reply	495
We have revised our paper accordingly and respond to the major concerns here.	O	O	Reply	495
[line_break_token][line_break_token]1.	O	O	Reply	495
We have added a figure of the Multi-task Match-Tensor model in the appendix (see figure 4 in the revised version of the paper).	B-Reply	B-1	Reply	495
We adapt multi-task learning in Match-Tensor model by adding the session encoder and the query decoder and keeping the other part of the model as it is.	I-Reply	I-1	Reply	495
More details of this procedure are explained in the revised paper Section 3.4.	I-Reply	I-1	Reply	495
[line_break_token][line_break_token]2.	B-Reply	B-3	Reply	495
We have revised the section 3 of our paper by adding more details about the motivation and design of every component in our proposed framework.	B-Reply	B-2	Reply	495
[line_break_token][line_break_token]3.	B-Reply	B-1	Reply	495
We did the experiment to verify the impact of session embeddings on document ranking and result is reported in Table 4 of our revised paper.	B-Reply	B-3	Reply	495
The row labeled with ‚ÄúM-NRF‚Äù resembles the model without considering the session embeddings in document ranking, where we observed a 2.8% drop in MAP.	I-Reply	I-3	Reply	495
As the session encoder is designed to capture the search context carried till the current query, it provides an important signal for ranking documents under the current/reformulated queries.	I-Reply	I-3	Reply	495
 It would be great if we could summarize what kind of queries/sessions benefit from this session recursion (i.e., where does that 2.8% drop in MAP come from).	I-Reply	I-3	Reply	495
[line_break_token][line_break_token]In our current model, we do not model the click sequence, and multiple clicks under the same query are assumed to be governed by the same query and session representation.	I-Reply	I-3	Reply	495
As a result, the session recursion is not directly/immediately influenced by the click sequence.	I-Reply	I-3	Reply	495
However, we do appreciate the great suggestion, and we believe adding another layer of session recursion at click sequence level would enable us to better capture this influence.	I-Reply	I-3	Reply	495
And we will list this as a top priority in our future work.	I-Reply	I-3	Reply	495
[line_break_token][line_break_token]4.	B-Reply	B-1	Reply	495
We appreciate the suggestion.	B-Reply	B-4	Reply	495
We followed the most commonly used threshold to define the session in IR literature.	I-Reply	I-4	Reply	495
In our future work, we will study the sensitivity of the segmentation of sessions	I-Reply	I-4	Reply	495

This paper develop a path-based encoding scheme to featurize the neural architectures that are used to train the neural network model, and design a NAS algorithm that performs Bayesian optimization using a neural network model.	O	O	Review	699
The experiments show the priority of the proposed method.	O	O	Review	699
[line_break_token][line_break_token]In general, this paper is easy to follow, but the contribution is limited.	B-Review	B-1	Review	699
The author did not give a clear explanation of why does this method work.	I-Review	I-1	Review	699
There are several problems that exist in the paper:[line_break_token][line_break_token]1.	I-Review	I-1	Review	699
[tab_token]The paper introduced a path-based encoding scheme, which seems have nothing different from enumerating all possible paths.	I-Review	I-1	Review	699
Any additional operations should be clarified in the paper.	I-Review	I-1	Review	699
[line_break_token]2.	O	O	Review	699
[tab_token]The method retains new architectures with high UCB value.	B-Review	B-2	Review	699
However, the author did not prove that a higher UCB value leads to a better architecture.	I-Review	I-2	Review	699
Eq.(1) trained several different networks to predict the accuracy.	I-Review	I-2	Review	699
However, when using early stop stragegy, the intermediate accuracy is not convincing, and the new architecture selected based on UCB may not perform well when training with full epochs.	I-Review	I-2	Review	699
If early stop is not used, there is no need  to predict the accuracy with different networks.	I-Review	I-2	Review	699
[line_break_token]3.	O	O	Review	699
[tab_token]In my opinion, Algorithm 1 is a simplified traditional Evolutionary Algorithm, which only have mutation operation and do not have selection and crossover operation, and has limited novelty.	B-Review	B-3	Review	699
[line_break_token][line_break_token]	O	O	Review	699
hank you for your comments.	O	O	Reply	699
We discuss them below.	O	O	Reply	699
[line_break_token][line_break_token]1.	O	O	Reply	699
Yes, the path-based encoding scheme is enumerating all possible paths, with no additional operations.	B-Reply	B-1	Reply	699
As we show in Table 1 and Figures 2 and 4, using a path-based encoding is extremely effective for predicting the accuracy of neural architectures.	I-Reply	I-1	Reply	699
[line_break_token][line_break_token]2.	O	O	Reply	699
We do not optimize UCB to choose an architecture.	B-Reply	B-2	Reply	699
We are optimizing the validation accuracy and only use UCB as an acquisition function to choose subsequent queries.	I-Reply	I-2	Reply	699
This is the standard formulation for Bayesian optimization.	I-Reply	I-2	Reply	699
In Bayesian optimization literature, UCB is a well-known acquisition function that has been used for efficient global optimization.	I-Reply	I-2	Reply	699
In the NASBench experiments, there is no early stopping at all.	I-Reply	I-2	Reply	699
Every architecture is trained for 108 epochs.	I-Reply	I-2	Reply	699
In the DARTS experiments, every architecture is trained to 50 epochs (due to the large cost of training).	I-Reply	I-2	Reply	699
Then at the very end of our algorithm, we take the architecture with the best validation accuracy and train it to 600 epochs.	I-Reply	I-2	Reply	699
This method works well in practice.	I-Reply	I-2	Reply	699
[line_break_token][line_break_token]3.	O	O	Reply	699
Our method is completely different from an evolutionary algorithm.	B-Reply	B-3	Reply	699
Our algorithm follows a standard Bayesian optimization procedure, which is a different class of strategies.	I-Reply	I-3	Reply	699
In fact, we compared our algorithm to an evolutionary algorithm in Figure 2, and our algorithm performs much better.	I-Reply	I-3	Reply	699
The only similarity is that we use a mutation function to optimize the acquisition function.	I-Reply	I-3	Reply	699
Note that in the ablation study (Figure 3), we removed the mutation function (using random sampling instead), and our algorithm still significantly outperforms the evolutionary algorithm.	I-Reply	I-3	Reply	699
There is no overlap between the two algorithms other than the mutation function.	I-Reply	I-3	Reply	699
For example, our algorithm predicts the performance of unseen neural architectures, and there is no part of an evolutionary algorithm that makes predictions	I-Reply	I-3	Reply	699

This work proposes to use visualization of gradients to further understand the importance of features (i.e. pixels) for visual classification.	O	O	Review	601
Overall, this presented visualizations are interesting, however, the approach is very ad hoc.	B-Review	B-1	Review	601
The authors do not explain why visualizing regular gradients isn't correlated with the importance of features relevant to the given visual category and proceed to the interior gradient approach.	I-Review	I-1	Review	601
[line_break_token][line_break_token]One particular question with regular gradients at features that form the spatial support of the visual class.	B-Review	B-2	Review	601
Is it the case that the gradients of the features that are confident of the prediction remain low, while those with high uncertainty will have strong gradients?	I-Review	I-2	Review	601
[line_break_token][line_break_token]With regards to the interior gradients, it is unclear how the scaling parameter \alpha affects the feature importance and how it is related to attention.	B-Review	B-3	Review	601
[line_break_token][line_break_token]Finally, does this model use batch normalization?	B-Review	B-4	Review	601
We thank the reviewer for the review.	O	O	Reply	601
[line_break_token] [line_break_token]Regarding ‚Äúauthors do not explain why visualizing regular gradients isn't correlated with the importance of features relevant‚Äù.	O	O	Reply	601
[line_break_token][line_break_token]We do think we discuss this.	B-Reply	B-1	Reply	601
Notice that Section 2.1 (‚ÄúGradients do not reflect feature importance‚Äù) gives examples of gradients not reflecting feature importance, and Section 2.2 (‚ÄúSaturation‚Äù) discusses why to an extent.	I-Reply	I-1	Reply	601
[line_break_token][line_break_token]The thesis proposed by the reviewer ‚ÄúIs it the case that the gradients of the features that are confident of the prediction remain low, while those with high uncertainty will have strong gradients‚Äù seems plausible empirically.	O	O	Reply	601
For instance, see this GIF for the label ‚Äúdrilling platform‚Äù obtained by combining the visualizations of interior gradients at various scaling intensities <a href="https://github.com/ankurtaly/Attributions/blob/master/Visualizations/Gifs/6717aba6a10b230f.gif)."	O	O	Reply	601
target="_blank" rel="nofollow">https://github.com/ankurtaly/Attributions/blob/master/Visualizations/Gifs/6717aba6a10b230f.gif).</a> Gradients at lower intensities seem to emphasize prominent features while those at higher intensities emphasize less important ones (peripheral?).	O	O	Reply	601
Notice also that ablating the gradient at the image often does not change the prediction, another data point toward the thesis that they are unimportant (see Section 2.1 for an example).	B-Reply	B-2	Reply	601
 [line_break_token][line_break_token]One exercise is we plan to carry out is to find the set of neurons that contribute to the gradient (and via Proposition 1 to the final prediction), at lower values of the scaling parameter (alpha)---these gradients look to us like they capture meaningful features and therefore the neurons through which they flow seem critical.	B-Reply	B-3	Reply	601
We could check whether these critical neurons remain saturated at higher alpha, including for alpha=1.	I-Reply	I-3	Reply	601
This exercise serves to connect the apparent variation in the interior gradients as alpha increases to the operation of important neurons within the network.	I-Reply	I-3	Reply	601

Summary:[line_break_token][line_break_token]The paper proposes an autoencoder-based initialization for RNNs with linear memory.	O	O	Review	20276
The proposed initialization is aimed at helping to maintain longer-term memory and instability during training such as  exploding gradients (due to linearity).	O	O	Review	20276
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]1.	O	O	Review	20276
The paper is well written, the motivation and methods are clearly described.	O	O	Review	20276
[line_break_token][line_break_token]Cons.	O	O	Review	20276
[line_break_token][line_break_token]1.	O	O	Review	20276
The authors claimed the proposed method could help with exploding gradient  in training the linear memories.	B-Review	B-1	Review	20276
It would be helpful to include some experiments indicating that this was the case (for the baseline) and that this method does indeed help with this problem.	I-Review	I-1	Review	20276
[line_break_token][line_break_token]2.	O	O	Review	20276
The experiments on the copy task only showed results for length upto 500, which almost all baseline models are able to solve.	B-Review	B-2	Review	20276
I am not too sure how the proposed initialization helps in this case.	I-Review	I-2	Review	20276
[line_break_token][line_break_token]3.	O	O	Review	20276
TIMNIT is a relatively small speech recognition dataset.	B-Review	B-3	Review	20276
The task/ dataset does not require long-term memorization.	I-Review	I-3	Review	20276
It is nice to see that the initialization helps in this case.	I-Review	I-3	Review	20276
However, it is still a little how this experiment corresponds to the messsage that the authors are attempting to deliver at the end of the introduction.	I-Review	I-3	Review	20276
[line_break_token][line_break_token]4.	O	O	Review	20276
In general, it seems that the experiments could be more carefully designed to reflect the contributions of the proposed method.	B-Review	B-1	Review	20276
Some suggestions for future edits are, more analysis on gradients, maybe more experiments on the stability of training such as gradients could help.	I-Review	I-1	Review	20276
[line_break_token][line_break_token]Minor:[line_break_token][line_break_token]1.	O	O	Review	20276
There are some confusions, on P2 "we can construct a simple linear recurrent model which uses the autoencoder to encode the input sequences within a single vector", I think the authors meant encode the input sequences into a sequence of vectors?	B-Review	B-5	Review	20276
Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence).	I-Review	I-5	Review	20276
[line_break_token][line_break_token]2.	O	O	Review	20276
Although the copy task was used in ((Arjovsky et al 2015), I believe the original task was proposed in the following paper and hence this citation should properly be the correct one to cite here,[line_break_token][line_break_token]Hochreiter, Sepp and Schmidhuber, J√ºrgen.	B-Review	B-4	Review	20276
Long short-term memory.	I-Review	I-4	Review	20276
Neural computation, 9(8):[line_break_token]1735‚Äì1780, 1997.	I-Review	I-4	Review	20276
[line_break_token][line_break_token]	O	O	Review	20276
&gt;&gt;&gt; 1.	O	O	Reply	20276
The authors claimed the proposed method could help with exploding gradient  in training the linear memories.	O	O	Reply	20276
It would be helpful to include some experiments indicating that this was the case (for the baseline) and that this method does indeed help with this problem.	O	O	Reply	20276
[line_break_token]&gt;&gt;&gt; 4.	O	O	Reply	20276
In general, it seems that the experiments could be more carefully designed to reflect the contributions of the proposed method.	O	O	Reply	20276
Some suggestions for future edits are, more analysis on gradients, maybe more experiments on the stability of training such as gradients could help.	O	O	Reply	20276
[line_break_token][line_break_token]We agree that this are interesting experiments.	B-Reply	B-1	Reply	20276
We believe that it is especially useful to study the effect on the gradient and training stability when combined with the truncated backpropagation (e.g. as done in the LSTM paper).	I-Reply	I-1	Reply	20276
Unfortunately, we still do not have the final results on these experiments.	I-Reply	I-1	Reply	20276
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; 2.	O	O	Reply	20276
The experiments on the copy task only showed results for length upto 500, which almost all baseline models are able to solve.	O	O	Reply	20276
I am not too sure how the proposed initialization helps in this case.	O	O	Reply	20276
[line_break_token] [line_break_token]We used the experiments on the copy tasks to show that the LMN architecture learns the copy task with a saturating nonlinearity (tanh).	B-Reply	B-2	Reply	20276
As far as we know, this is the only architecture that can do it, while most of the other models use variations of ReLUs.	I-Reply	I-2	Reply	20276
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; 1.	O	O	Reply	20276
There are some confusions, on P2 "we can construct a simple linear recurrent model which uses the autoencoder to encode the input sequences within a single vector", I think the authors meant encode the input sequences into a sequence of vectors?	O	O	Reply	20276
Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence).	O	O	Reply	20276
[line_break_token] [line_break_token]The state vector of the LAES m^t can be used to reconstruct the entire input sequence x^1, ‚Ä¶ x^t.	B-Reply	B-5	Reply	20276
Therefore, each vector m^t encodes the entire subsequence x^1, ‚Ä¶, x^t.	I-Reply	I-5	Reply	20276
We will update the paper to make this point clearer.	I-Reply	I-5	Reply	20276
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; 2.	O	O	Reply	20276
Although the copy task was used in ((Arjovsky et al 2015), I believe the original task was proposed in the following paper and hence this citation should properly be the correct one to cite here[line_break_token] [line_break_token]Thank you for noticing this, we will add the reference.	B-Reply	B-4	Reply	20276

*Summary of paper*[line_break_token]This paper investigates the use of random perturbations applied to a robotic policy to learn a local gradient useful for policy optimization.	O	O	Review	10250
The method aims to learn a policy directly on a real physical robotic system, bypassing both simulation models and model-free RL.	O	O	Review	10250
Training pairs are gathered by perturbations of a starting policy, and the "gradient" is captured in a probabilistic model learned from the training data.	O	O	Review	10250
The paper includes experiments on a custom 3-DOF robotic platform.	O	O	Review	10250
[line_break_token][line_break_token]*Decision*[line_break_token]I vote for rejecting this paper.	O	O	Review	10250
While the idea is interesting, the paper lacks precision in key areas and the method is not placed in context among related work.	B-Review	B-1	Review	10250
Further, it fails to communicate key ideas (particularly in the experiments) to a non-robotics reader.	I-Review	I-1	Review	10250
Without sufficient clarity and background, it is not suited to a general machine learning conference.	I-Review	I-1	Review	10250
[line_break_token][line_break_token]- Lemma 3, which attempts to justify the use of voxelization, and its proof are both imprecise and inadequate.	I-Review	I-1	Review	10250
To improve precision, please define "error causes by voxelization" in mathematical terms, e.g. ||c_i - x_i||. Also, while the statement of the lemma un-intuitively implies that larger voxels introduce smaller errors, the proof seems to say that larger errors will result for smaller gradients if larger voxels are used.	I-Review	I-1	Review	10250
[line_break_token]- Related work: How does this work relate to random search/evolutionary computation?	B-Review	B-2	Review	10250
How does it compare to performing those methods or a model-free RL method directly on the robot?	I-Review	I-2	Review	10250
How does it compare to learning using an inaccurate model for robot dynamics?	I-Review	I-2	Review	10250
Presumably there are numerous methods that have been tried in this area, so further context is needed.	I-Review	I-2	Review	10250
[line_break_token]- The evaluation is unclear, at least to a non-expert in robotics.	B-Review	B-3	Review	10250
A lack of quantitative evaluation further exacerbates this issue: nearly all experiments, even those with associated plots, are characterized qualitatively and without reference the performance of related methods.	I-Review	I-3	Review	10250
[line_break_token][line_break_token]- In addition to addressing the limitations above, I would encourage the authors to consider the use of experiments in simulation to thoroughly and quantitatively investigate the convergence/bias/variance of the gradient model w.r.t. #	B-Review	B-4	Review	10250
DoF of the robot, length of the trajectory, voxelization, # sampled trajectories, perturbation sampling method, and robot reliability/reproducibility[line_break_token][line_break_token]*Additional feedback*[line_break_token]- spelling errors throughout; please check thoroughly[line_break_token]- the captions/labels/etc.	B-Review	B-5	Review	10250
in most figures is far too small to read in a printed copy of the paper[line_break_token]- What is the intuition for the "empirical distribution p_e(T|\pi) = ..." on page 2?	B-Review	B-7	Review	10250
Is it counting the exact matches between the trajectory T and the M observed trajectories? (	I-Review	I-7	Review	10250
This may be more clear in the context of voxelization introduced later.)	I-Review	I-7	Review	10250
[line_break_token]- Figure 3: what are the units for \gamma?	B-Review	B-8	Review	10250
what is the time step?	I-Review	I-8	Review	10250
[line_break_token]- many of the figures are out of order w.r.t.	B-Review	B-9	Review	10250
their introduction in the text	I-Review	I-9	Review	10250
e thank the respected reviewer and try to answer the comments in the following.	O	O	Reply	10250
[line_break_token][line_break_token]Regarding the use of simulation:[line_break_token]Even though working with a simulator was much easier than building a physical robot and experimenting on it, we intentionally went for a real robot since the results of the simulator were not reliable.	B-Reply	B-4	Reply	10250
For example, the separation between spatial and temporal noise was not known for us prior to running experiments on the real robot.	I-Reply	I-4	Reply	10250
Real challenges of the problem are not visible before doing real experiments on real robots.	I-Reply	I-4	Reply	10250
[line_break_token][line_break_token]Regarding the empirical distribution on page 2:[line_break_token]It the sum of delta functions located on some trajectories in the dataset	O	O	Reply	10250

This paper introduces the General Language Understanding Evaluation (GLUE) benchmark and platform, which aims to evaluate representations of language with an emphasis on generalizability.	O	O	Review	523
This is a timely contribution and GLUE will be an impactful resource for the NLP community.	O	O	Review	523
This is mitigated, perhaps, somewhat by the recent release of decaNLP.	O	O	Review	523
But, as discussed the authors, this has a different focus (re-framing all tasks as QQ) and further does not feature the practical tools released here (leaderboard, error analysis) that will help drive progress.	O	O	Review	523
[line_break_token][line_break_token]Some comments below.	O	O	Review	523
[line_break_token][line_break_token]- The inclusion of the small diagnostic dataset was a nice addition and it would be nice if future corpora included similar.	B-Review	B-1	Review	523
[line_break_token][line_break_token]- Implicit in this and related efforts is the assumption that parameter sharing ought to be possible and fruitful across even quite diverse tasks.	B-Review	B-2	Review	523
While I do not object to this, it would be nice if the authors could make an explicit case here as to why should we believe this to be the case.	I-Review	I-2	Review	523
[line_break_token][line_break_token]- The proposed platform is touted as one of the main contributions here, but not pointed to -- I assume for anonymity preserving reasons, but still would have been nice for this to be made explicit.	B-Review	B-3	Review	523
[line_break_token][line_break_token]- I would consider pushing Table 5 (Appendix) into the main text.	B-Review	B-4	Review	523
[line_break_token]	O	O	Review	523
Thank you for your review!	O	O	Reply	523
[line_break_token][line_break_token]We agree that the diagnostic data is a key contribution of our work.	B-Reply	B-1	Reply	523
We wanted to not only have an application-driven measure of progress, but also a targeted measure of performance on specific natural language phenomena that we would expect a general-purpose NLU model to handle well.	I-Reply	I-1	Reply	523
[line_break_token][line_break_token]Regarding parameter sharing, our intent was to include tasks with very little training data such that automated systems could not do well learning on just those tasks‚Äô data.	B-Reply	B-2	Reply	523
Competitive systems, then, would need to include some form of knowledge-sharing from outside data.	I-Reply	I-2	Reply	523
 In only requiring model predictions to evaluate on test, we wanted to avoid restricting future research to any particular paradigm of knowledge sharing.	I-Reply	I-2	Reply	523
We use multi-task learning and parameter sharing because it is a straightforward baseline with lots of precedent (GenSen, Collobert and Weston, etc.),	I-Reply	I-2	Reply	523
so we thought it necessary to include.	I-Reply	I-2	Reply	523
[line_break_token][line_break_token]Could you please clarify how a small *test* set would encourage few-shot learning?	I-Reply	I-2	Reply	523
To the best of our knowledge, few-shot learning is when you have a small *training* set for the target task.	I-Reply	I-2	Reply	523
[line_break_token][line_break_token]Re: table 5, we agree!	B-Reply	B-4	Reply	523
We‚Äôll post an updated version of the paper shortly.	I-Reply	I-4	Reply	523

[line_break_token][Summary][line_break_token]This paper studies the relationship between gradient clipping in stochastic gradient descent and robustness to label noise.	O	O	Review	10101
Theoretical results show that gradient clipping in general is not robust to symmetric label noise.	O	O	Review	10101
The paper then proposes a variant of gradient clipping (cl-clipping) that induces label noise robustness.	O	O	Review	10101
Experiments support these claims on synthetic datasets and typical classification benchmarks.	O	O	Review	10101
[line_break_token][line_break_token][Decision][line_break_token]The first contribution, that gradient clipping does not induce robustness to label noise, is an important negative result given the prominence of gradient clipping and datasets with noisy labels.	O	O	Review	10101
The second contribution, cl-clipping, amounts to minimizing a non-convex loss with saturating regions but, as far as I know, these properties are necessary for robustness to label noise.	B-Review	B-1	Review	10101
Theoretical results are limited to SGD with mini-batch size 1 but the insights carry over to larger mini-batches in the experiments.	I-Review	I-1	Review	10101
Overall, I recommend acceptance.	O	O	Review	10101
[line_break_token][line_break_token][Comments][line_break_token]The parameter tau controls robustness, and a higher noise level requires a higher tau.	B-Review	B-1	Review	10101
There is little discussion on how this parameter is chosen in the experiments.	I-Review	I-1	Review	10101
On the synthetic dataset, the Huberized loss uses tau=1 and the partially Huberized loss uses tau=2.	I-Review	I-1	Review	10101
How are these values chosen?	I-Review	I-1	Review	10101
Did the authors observe a U-shaped curve when sweeping over tau?	I-Review	I-1	Review	10101
On the real-world datasets, tau is fixed for each method across different noise levels.	I-Review	I-1	Review	10101
Does this mean that a single value of tau worked best regardless of the noise level, or was it tuned for a particular noise level?	I-Review	I-1	Review	10101
[line_break_token][line_break_token]Proposition 4 shows that symmetric noise breaks down the clipping method in Eq (7) which can be seen as a special case of gradient clipping.	B-Review	B-2	Review	10101
I might be missing something here, but it is not obvious to me that, when the norm of x is constant across the samples, Eq (7) is equal to gradient clipping.	I-Review	I-2	Review	10101
[line_break_token]	O	O	Review	10101
hanks for the feedback!	O	O	Reply	10101
[line_break_token][line_break_token]We have updated the draft to include a discussion on the choice of œÑ in Section 5.	B-Reply	B-1	Reply	10101
This is a tuning parameter that can be set by the user, similar to the q parameter from generalised cross-entropy, or noise estimates in loss-correction techniques.	I-Reply	I-1	Reply	10101
[line_break_token][line_break_token]In our experiments, we chose œÑ so as to maximise accuracy on a set of (noisy) validation samples for the setting of noise rate œ± = 0.6.	I-Reply	I-1	Reply	10101
We did not tune œÑ for each noise rate, since this value of œÑ worked well for lower noise rates as well.	I-Reply	I-1	Reply	10101
Of course, there is no conceptual issue with tuning œÑ for each value of œ±, although there is a slight computational cost.	I-Reply	I-1	Reply	10101
[line_break_token][line_break_token]For the range of œÑ, we found that values of œÑ = { 2, 10 } ‚Äî which correspond to clipping at probability values less than 0.5 and 0.1 respectively ‚Äî generally gave good performance for the datasets considered.	I-Reply	I-1	Reply	10101
In general, one can certainly expand this range, again with a slight computational cost.	I-Reply	I-1	Reply	10101
[line_break_token][line_break_token]We indeed observe a U-shaped curve in general.	I-Reply	I-1	Reply	10101
Note also that as œÑ gets closer to 1, we essentially reduce to the original loss (e.g., log-loss).	I-Reply	I-1	Reply	10101
As œÑ gets larger, we essentially reduce to the linear loss.	I-Reply	I-1	Reply	10101
As shown in Table 2, intermediate values of œÑ yield better performance than either extreme under label noise.	I-Reply	I-1	Reply	10101
We have made a comment on this following the discussion of how œÑ is chosen.	I-Reply	I-1	Reply	10101
[line_break_token][line_break_token]Proposition 4 indeed concerns loss-based gradient clipping, i.e., Equation 7.	B-Reply	B-2	Reply	10101
Per the discussion following Lemma 1, this is not exactly the same as gradient clipping in general.	I-Reply	I-2	Reply	10101
However, note that for linear models, the term ‚àámŒ∏(x, y) = ||x||2, so if this is constant then Equations 6 and 7 will coincide.	I-Reply	I-2	Reply	10101
We have added some clarifying text after Equation 7	I-Reply	I-2	Reply	10101

This paper presents an approach to multi-modal imitation learning by using a variational auto-encoder to embed demonstrated trajectories into a structured latent space that captures the multi-modal structure.	O	O	Review	863
This is done through a stochastic neural network with a bi-directional LSTM and mean pooling architecture that predicts the mean and log-variance of the latent state.	O	O	Review	863
This is followed by a state and action/policy decoder (both LSTMs) that recursively generate trajectories from latent space samples.	O	O	Review	863
The entire model is trained by optimising the ELBO on a set of pre-specified expert demonstrations.	O	O	Review	863
At test time, samples are generated from the latent space and recursively decoded to generate state and action trajectories.	O	O	Review	863
The method is tested on three low-dimensional continuous control tasks and is able to learn structured latent spaces capturing the modes in the training data as well as generating good trajectory reconstructions.	O	O	Review	863
[line_break_token][line_break_token]Learning from multi-modal demonstration data is an important sub-area in imitation learning.	B-Review	B-1	Review	863
As the paper pointed out, there has been a lot of recent work in this area.	I-Review	I-1	Review	863
A lot of the ideas in this paper are similar to those proposed in prior work -- the network for embedding the trajectory is similar to the ones from Wang et al & Co-Reyes et al with the major difference being in the structure of the action decoder (and what inputs to encoder).	O	O	Review	863
Also, prior work has dealt with problems that are high-dimensional (Wang et al) and has shown results when operating directly on visual data (InfoGAIL).	B-Review	B-1	Review	863
Comparatively, the results in this paper are on toy problems.	I-Review	I-1	Review	863
[line_break_token][line_break_token]As there is no direct comparison to prior work provided in the paper, it is hard to quantify how much better the proposed approach is in comparison to prior work.	B-Review	B-2	Review	863
For example, the "2D Circle Example" was taken from the InfoGAIL paper.	I-Review	I-2	Review	863
It would have been good to use that as a baseline example to compare those two methods and highlight the advantages of the proposed approach -- did it require less data?	I-Review	I-2	Review	863
fewer environment interactions?	I-Review	I-2	Review	863
etc.	I-Review	I-2	Review	863
[line_break_token][line_break_token]The results on the Zombie Attack Scenario seem poor.	B-Review	B-3	Review	863
Specifically, in the avoid scenario, the approach seems to fail almost half the time.	I-Review	I-3	Review	863
It would be good if the authors spend more time on this -- again, a comparison to prior work would establish some baselines and give us a good idea of the expected performance on this scenario.	I-Review	I-3	Review	863
The videos show a single representative example for the "Attack" and "Avoid" scenarios.	I-Review	I-3	Review	863
More examples including failures need to be included so that the distribution of results can be captured.	I-Review	I-3	Review	863
[line_break_token][line_break_token]There is little in terms of generalisation or ablation studies in the paper.	B-Review	B-4	Review	863
For example, in the Zombie Attack Scenario one could generate data with different zombie behaviours and measure performance on held out behaviours.	I-Review	I-4	Review	863
Similarly, as an ablation, the authors could look at directly predicting actions instead of states & actions (states could be generated through a pre-trained dynamics model).	O	O	Review	863
[line_break_token][line_break_token]Figure 6.	B-Review	B-5	Review	863
is hard to parse and could be explained better.	I-Review	I-5	Review	863
No details are provided on the network architecture (number/size of the LSTM/fully connected layers), number of demonstrations used, training algorithm, hyper-parameters etc.	I-Review	I-5	Review	863
[line_break_token][line_break_token]Few typos in the paper: [line_break_token]  Page 6 - between the animation links 'avoiding' 'region'[line_break_token]  Fig 7 caption - the zombie but are not in attacking range -> but the zombies are not in the attacking range,[line_break_token][line_break_token]Relevant citations that can be added:[line_break_token]1) Hausman, K., Chebotar, Y., Schaal, S., Sukhatme, G., & Lim, J. J. (2017).	O	O	Review	863
Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets.	B-Review	B-7	Review	863
In Advances in Neural Information Processing Systems (pp.	I-Review	I-7	Review	863
1235-1245).	I-Review	I-7	Review	863
[line_break_token]2) Tamar, A., Rohanimanesh, K., Chow, Y., Vigorito, C., Goodrich, B., Kahane, M., & Pridmore, D. (2018).	O	O	Review	863
Imitation Learning from Visual Data with Multiple Intentions.	B-Review	B-7	Review	863
[line_break_token][line_break_token]Overall, I find the paper to be incremental and lacking good experimental results and comparisons.	O	O	Review	863
The strengths of the paper are not clear and need to be explained and evaluated well.	O	O	Review	863
Substantial work is needed to significantly improve the paper before it can be accepted.	O	O	Review	863
Our model differs from Wang et al in the sense that our VAE is on the trajectory level, which enables it to better identify the latent variable that differentiates different behaviors from the whole trajectory.	B-Reply	B-1	Reply	863
 Co-Reyes et al  also uses a trajectory-level VAE, but our work differs from theirs in that our model is fully probabilistic and consistent.	I-Reply	I-1	Reply	863
Therefore no extra penalty term is needed as in Co-Reyes et al to force the state decoder to be consistent with the action decoder.	I-Reply	I-1	Reply	863
[line_break_token][line_break_token]Thank you for the suggestions for the ablation studies.	B-Reply	B-4	Reply	863
We will conduct a comprehensive analysis on the impact of the state decoder/policy decoder.	I-Reply	I-4	Reply	863
[line_break_token][line_break_token]We will fix the typos, add the references and clarify experiment setup in a revision.	B-Reply	B-6	Reply	863

This paper presented a dialog response generation method using adversarial learning framework.	O	O	Review	1284
[line_break_token]The generator is based on previously proposed hierarchical recurrent encoder-decoder network (HRED), and the discriminator is a bidirectional RNN.	O	O	Review	1284
[line_break_token]Noise samples are introduced in generator for response generation.	O	O	Review	1284
[line_break_token]They evaluated their approach on two datasets and showed mostly better results than the other systems.	O	O	Review	1284
[line_break_token][line_break_token]The novelty of the paper is limited.	B-Review	B-1	Review	1284
[line_break_token]Modeling longer dialog history (beyond the current turn) is not new, this has been used in different tasks such as dialect act classification, intent classification and slot filling, response generation, etc.	I-Review	I-1	Review	1284
[line_break_token]The generator is based on previous HRED.	I-Review	I-1	Review	1284
[line_break_token]Adding noise to generate responses is somewhat new, but that doesn‚Äôt seem to be well motivated or justified.	I-Review	I-1	Review	1284
[line_break_token]Why adding Gaussian noise improves the diversity or informativeness of the responses is not explained.	I-Review	I-1	Review	1284
[line_break_token]The idea of discriminator has been widely used recently for language generation related tasks.	I-Review	I-1	Review	1284
 What is new here?	I-Review	I-1	Review	1284
Is it the word-based metric?	I-Review	I-1	Review	1284
Sharing the context and word information with generator?	I-Review	I-1	Review	1284
 It would be helpful if the authors can clarify their contribution.	I-Review	I-1	Review	1284
[line_break_token]  [line_break_token]Regarding using MLE to first generate multiple hypotheses in generator, how is the quality of the n-best responses?	B-Review	B-2	Review	1284
[line_break_token]Is there a way to measure the goodness of the responses in some kind of reranking framework, not necessarily discriminator?	I-Review	I-2	Review	1284
[line_break_token][line_break_token]The results in the table showed the proposed method outperforms the others in terms of those objective metrics.	B-Review	B-3	Review	1284
I feel some subjective evaluations are needed to strengthen the paper.	I-Review	I-3	Review	1284
[line_break_token]From the samples responses in the table, it doesn‚Äôt look like the new method generates very good responses.	I-Review	I-3	Review	1284
[line_break_token][line_break_token][line_break_token]Detailed comments: [line_break_token]- Sec 2, before 2.1, last paragraph, ‚ÄúWith the GAN objective, we can match the noise distribution, P(Z_i) to the distribution of the ground truth response, P(X_i+1|X_i).	B-Review	B-4	Review	1284
 This needs clarification.	I-Review	I-4	Review	1284
[line_break_token]- Figure 1: caption, ‚Äúleft‚Äù and ‚Äúright‚Äù are misplaced.	B-Review	B-5	Review	1284
[line_break_token]- sec 2.1, last paragraph, without Z_i, the net could still learn a mapping from X_i to Y_i, but would produce deterministic outputs.	B-Review	B-6	Review	1284
 I think the authors mean that the system generates a probability distribution P(Y_i|X), the output is the most likely one from that.	I-Review	I-6	Review	1284
However, if the output is a distribution, the system can also do some sampling and not necessarily output the top one.	I-Review	I-6	Review	1284
 This is not that different from adding noise in the history ‚Äî if that‚Äôs based on some distribution, then it may still be deterministic.	I-Review	I-6	Review	1284
[line_break_token]	O	O	Review	1284
Thank you for your review.	O	O	Reply	1284
We will soon post a more detailed explanation and new results with human evaluation but we want to quickly address some of the other concerns raised in your review.	O	O	Reply	1284
[line_break_token][line_break_token]Novelty and Significance:[line_break_token][line_break_token]Our work employs a similar approach as the VHRED which applies variational approach to improve the HRED.	B-Reply	B-1	Reply	1284
One could argue that HRED and variational bayes already exists independently, but VHRED shows the impact of variational training on the HRED generator.	I-Reply	I-1	Reply	1284
In the same vein, we also examine the impact of adversarial training on the HRED generator since both the variational and adversarial approaches are very competitive for training generative models.	I-Reply	I-1	Reply	1284
That's why we compare hredGAN, VHRED and HRED in our evaluation.	I-Reply	I-1	Reply	1284
In summary, our work shows that our proposed adversarial training performs better than the variational training in VHRED.	I-Reply	I-1	Reply	1284
[line_break_token][line_break_token]Our other contributions relate more with the actualization of the adversarial training.	I-Reply	I-1	Reply	1284
To achieve an end-to-end gradient flow from the discriminator to the generator, we share the word embedding and context information between the generator and discriminator as you have rightly mentioned.	I-Reply	I-1	Reply	1284
The alternative would be either using a policy gradient method (REINFORCE) or passing the softmax output instead of the argmax output to the discriminator, both of which did not perform better than the embedding sharing in our experiments.	I-Reply	I-1	Reply	1284
  On the choice of the discriminator, we found the aggregated word-level metric to be much better than the utterance-level metric so we propose a word-level metric as you have rightly mentioned.	I-Reply	I-1	Reply	1284
[line_break_token][line_break_token]Detailed Comments:[line_break_token]We have corrected the misplaced caption in Fig.	B-Reply	B-5	Reply	1284
1.	I-Reply	I-5	Reply	1284
[line_break_token][line_break_token]Your explanation of "sec 2.1, last paragraph" is spot on.	B-Reply	B-6	Reply	1284
We opted to sample a latent and much smoother noise distribution, P(Z_i) while keeping the output as the most likely from P(Y_i|X, Z_i) instead of sampling P(Y_i|X) discretely.	I-Reply	I-6	Reply	1284
Whereas the discrete sampling of  P(Y_i|X) does not work well in practice due the large vocabulary size, our latent sampling, P(Y_i|X, Z_i)P(Z_i) allows us to control the diversity of the output from the variation of the noise sample via the parameter \alpha.	I-Reply	I-6	Reply	1284
Therefore, we are able to generate a much more coherent samples than possible with discrete sampling of P(Y_i|X).	I-Reply	I-6	Reply	1284
[line_break_token][line_break_token]Let us know if you have additional questions as we collate and analyze the human evaluation results.	O	O	Reply	1284
We will be posting the new results in the next few days	O	O	Reply	1284

This work proposes a new method of stabilizing GAN training and encouraging the generator to cover the data distribution better (i.e. less mode dropping).	O	O	Review	147
 As I understand it they do so by gradually annealing the data distribution so that it initially has high entropy and gradually move towards the true distribution.	O	O	Review	147
[line_break_token][line_break_token]While this approach is potentially promising, the paper in its current form lacks and discussion of its relation to other approaches to stabilizing GANs.	B-Review	B-1	Review	147
I think this method needs to be placed in context to be better understood.	I-Review	I-1	Review	147
[line_break_token][line_break_token]Finally, I have one question: in algorithm 1, the generator network is written as a function of beta, but as I understand it only the data distribution is annealed, not the generator distribution?	B-Review	B-2	Review	147
Please explain.	I-Review	I-2	Review	147
Thank you for your comments.	O	O	Reply	147
We added the discussion section to the paper clarifying our formulation in relation to other related works that have addressed stabilization of GAN training.	B-Reply	B-1	Reply	147
[line_break_token][line_break_token]Regarding the question:  Both and depend on beta implicitly, since the generator and the discriminator are trained while the data distribution is being annealed.	B-Reply	B-2	Reply	147
The notation in Algorithm 1 emphasizes this implicit dependence	I-Reply	I-2	Reply	147

This paper proposes a unified architecture in the context of multi-task learning where they demonstrate that training four tasks (with a variety of modalities like image, text, and videos) together results in about three times compressed model, while maintaining the performance similar to their respective individually trained models.	O	O	Review	20541
The major components of this archtiecutre are (1) peripheral networks: used to encode the domain specific input into feature representations. (	O	O	Review	20541
2) central neural processor: a fully attention based encoder-decoder model similar to the Transformer networks which encodes the spatio-temporal information.	O	O	Review	20541
Further, this paper suggests that their unified architecture enables to perform decent on unseen tasks during its training.	O	O	Review	20541
In this paper they test such scenarios on video captioning and video question answering.	O	O	Review	20541
[line_break_token][line_break_token]Overall, the paper is clear to read and thorough in its experiments, with the caveat that its missing many multi-task paper references and the ideas are not much novel.	O	O	Review	20541
However, I would say the setup is well engineered.	O	O	Review	20541
[line_break_token][line_break_token]Arguments:[line_break_token][line_break_token]1) There are many works in multi-task learning after Luong et al 2016, please refer them in the related work section (this section is very short!)	B-Review	B-1	Review	20541
and discuss on the differences of your model w.r.t.	I-Review	I-1	Review	20541
previous work (this is completely missing in the paper).	I-Review	I-1	Review	20541
I am pointing to some references below.	I-Review	I-1	Review	20541
[line_break_token][line_break_token]2) Statistical significance tests are missing to show that MULT-3 or MULT-4 are able to ‚Äúmaintain‚Äù the performance w.r.t.	B-Review	B-2	Review	20541
IND.	I-Review	I-2	Review	20541
[line_break_token][line_break_token][line_break_token][1] Latent Multi-task Architecture Learning, Ruder et al 2019[line_break_token][2] A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks, Hashimoto et al 2017[line_break_token][3] Multi-Task Video Captioning with Video and Entailment Generation, Pasunuru &amp; Bansal, 2017[line_break_token]	O	O	Review	20541
e thank the reviewer for encouraging feedback and comments.	O	O	Reply	20541
As suggested, we will add a  discussion on multi-tasking literature in the final version of the paper.	B-Reply	B-1	Reply	20541
 We are in the process of hyper-parameter optimization as pointed by Reviewer#1 and will perform the detailed statistical significance tests for comparison of MULT-3 and MULT-4 with IND.	B-Reply	B-2	Reply	20541
We will add these results as well to the final version of the paper.	I-Reply	I-2	Reply	20541
[line_break_token]	O	O	Reply	20541

Summary:[line_break_token]The authors analyze the bias in the straight-through gradient estimator using the framework of harmonic analysis of boolean functions.	O	O	Review	643
Based on this analysis, they propose three methods to reduce the bias of the straight-through estimator, resulting in a less-biased estimator that is the same computational complexity as the original.	O	O	Review	643
They evaluate this estimator on a series of generative modeling tasks where they demonstrate improvements over existing methods, including the ability to train a very deep stochastic network.	O	O	Review	643
[line_break_token][line_break_token]I enjoyed this paper -- the exposition is clear, the ideas are (to my knowledge) novel and make sense, and the experimental evaluation is thorough and convincing.	O	O	Review	643
I recommend an accept.	O	O	Review	643
[line_break_token][line_break_token]I skimmed through the proofs in the appendix so cannot with absolute confidence vouch for their correctness.	O	O	Review	643
[line_break_token][line_break_token]One small piece of feedback: I found the most confusing part of the paper was the section on the 'bernoulli splitting trick'.	B-Review	B-1	Review	643
It might be helpful to pull some of the appendix material into this section to make it a little less sparse.	I-Review	I-1	Review	643
[line_break_token]	O	O	Review	643
e thank the reviewer for the encouraging review and for appreciating the novelty and thoroughness of the experiments.	O	O	Reply	643
With regard to the suggestion of clarifications in section 4.3, we have incorporated this in the updated version (section 4.3, page 5).	B-Reply	B-1	Reply	643
We hope to have made the matter clearer	I-Reply	I-1	Reply	643

[line_break_token]Summary:[line_break_token][line_break_token]The paper proposes to use the same language model to learn multiple tasks and also to generate pseudo-samples for these tasks which could be used for rehearsal while learning new tasks.	O	O	Review	253
The authors demonstrate that this idea works well compared to other SOTA lifelong learning methods for learning various NLP tasks using a single model.	O	O	Review	253
[line_break_token][line_break_token][line_break_token]My comments:[line_break_token][line_break_token]1.	O	O	Review	253
Please change the title!	B-Review	B-1	Review	253
Language modeling is NOT all you need for lifelong language learning.	I-Review	I-1	Review	253
Also, not every NLP task is a QA task.	I-Review	I-1	Review	253
I do not want more papers to over-trivialize NLP by following Bryan McCann and Socher, 2018.	I-Review	I-1	Review	253
I will not increase my scores until the title is changed.	I-Review	I-1	Review	253
[line_break_token]2.	B-Review	B-11	Review	253
A relevant model architecture based method is Sodhani et al 2018 (Towards Training Recurrent Neural Networks for Lifelong Learning) who use Net2Net to do zero-shot expansion of the model parameters.	B-Review	B-2	Review	253
[line_break_token]3.	B-Review	B-3	Review	253
Section 3.2 - you mention that any pseudo-example which does not have only one ANS token is discarded.	I-Review	I-3	Review	253
Can you comment on how much discarding is needed to generate the required number of pseudo-samples?	I-Review	I-3	Review	253
[line_break_token]4.	O	O	Review	253
Why is it that every task was trained only for 9 epochs?	B-Review	B-4	Review	253
[line_break_token]5.	O	O	Review	253
On page 5, you mention k=20.	B-Review	B-5	Review	253
What is k?	I-Review	I-5	Review	253
Where is this introduced?	I-Review	I-5	Review	253
[line_break_token]6.	O	O	Review	253
On page 5, you mention that MTL is used to determine whether forgetting is caused by a lack of model capacity.	B-Review	B-6	Review	253
I am not sure if it is correct.	I-Review	I-6	Review	253
Can you explain?	I-Review	I-6	Review	253
[line_break_token]7.	O	O	Review	253
Why not compare the approach with models like GEM?	B-Review	B-7	Review	253
Keeping very few examples is ok.	I-Review	I-7	Review	253
Even though you don‚Äôt beat GEM, it is good to see the comparison.	I-Review	I-7	Review	253
[line_break_token]8.	B-Review	B-1	Review	253
Page 7: Is there any reason why you choose to go from large to small tasks?	B-Review	B-8	Review	253
I feel like this is a favorable order.	I-Review	I-8	Review	253
I would like to see how the model performs if you do the reverse order.	I-Review	I-8	Review	253
[line_break_token]9.	O	O	Review	253
Please remove the last line.	B-Review	B-9	Review	253
[line_break_token]10.	O	O	Review	253
I assume that the authors will release the code upon acceptance of the paper.	B-Review	B-10	Review	253
[line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]1.	B-Review	B-11	Review	253
Page 2, 4th contribution: check the spelling for ‚Äúpseudo-samples‚Äù[line_break_token]2.	I-Review	I-11	Review	253
Page 2, 5th last line: ‚ÄúAfter a completing a task‚Äù - fix it.	I-Review	I-11	Review	253
[line_break_token]3.	B-Review	B-3	Review	253
Table 1: I think the description is not correct.	B-Review	B-11	Review	253
1fEM is for wikiSQL, not WOZ.	I-Review	I-11	Review	253
Also, it is better if you can describe these metrics in detail in the appendix.	I-Review	I-11	Review	253
[line_break_token][line_break_token]==================================[line_break_token][line_break_token]After rebuttal:[line_break_token][line_break_token]I am happy with the authors' response and name change.	O	O	Review	253
I am increasing my score.	O	O	Review	253
[line_break_token]	O	O	Review	253
e thank the reviewer for the review, comments, and constructive feedback.	O	O	Reply	253
We provide answers to the comments below.	O	O	Reply	253
[line_break_token][line_break_token]Q1: Please change the title!	O	O	Reply	253
[line_break_token][line_break_token]A1: We understand our title over-trivialized NLP tasks, so we changed it to: "LAMOL: LAnguage MOdeling for Lifelong Language Learning".	B-Reply	B-1	Reply	253
We change the title in the revised PDF but we can't change the title on OpenReview for now.	I-Reply	I-1	Reply	253
We also rephrase the paper to show that we merely use the datasets and metrics from decaNLP.	I-Reply	I-1	Reply	253
[line_break_token][line_break_token]Q2: A relevant model architecture based method is Sodhani et al 2018.	O	O	Reply	253
[line_break_token][line_break_token]A2: Thank you for your reminder.	B-Reply	B-2	Reply	253
We added the following paragraph to Section 2.2:[line_break_token]Training Recurrent Neural Networks for Lifelong Learning (Sodhani et al 2018) unifies Gradient episodic memory (Lopez-Paz et al 2017) and Net2Net  (Chen et al 2015a).	I-Reply	I-2	Reply	253
Using the curriculum-based setting, the model learns the tasks in easy-to-hard order.	I-Reply	I-2	Reply	253
The model alleviates the forgetting problem by GEM method, and if it fails to learn the current task and has not been expanded yet, the model will expand to a larger model by the Net2Net approach.	I-Reply	I-2	Reply	253
[line_break_token][line_break_token]Q3: Can you comment on how much discarding is needed to generate the required number of pseudo-samples?	O	O	Reply	253
[line_break_token][line_break_token]A3: After 9 epochs of training for each task, the discarding happens for only 0.5% to 1% of all generated examples.	B-Reply	B-3	Reply	253
[line_break_token]We added this information to Section 3.2 the last line of the first paragraph.	I-Reply	I-3	Reply	253
[line_break_token][line_break_token]Q4: Why is it that every task was trained only for 9 epochs?	O	O	Reply	253
[line_break_token][line_break_token]A4: There are two reasons.	B-Reply	B-4	Reply	253
First, we want to compare our method to multitasking in a fair manner, so the total update steps on each example in each task should be exactly the same.	I-Reply	I-4	Reply	253
If we train multitask for epochs, then in LLL, we should train each task for the same number of epochs.	I-Reply	I-4	Reply	253
Secondly, we find that epochs were enough for every task we chose to converge to a satisfying performance, as shown in Table 2, the single task performance.	I-Reply	I-4	Reply	253
Some tasks may have slightly higher performance if trained for more epochs, but we only have limited computational resource so we think is a good balance.	I-Reply	I-4	Reply	253
[line_break_token][line_break_token]Q5: What is k?	O	O	Reply	253
Where is it introduced?	O	O	Reply	253
[line_break_token][line_break_token]A5: It is the of the top sampling, introduced in Section 3.2.	B-Reply	B-5	Reply	253
We made it clearer in Section 4.2 paragraph 2: In all experiments, in top sampling and for weight of the LM loss.	I-Reply	I-5	Reply	253
[line_break_token][line_break_token]Q6: On page 5, you mention that MTL is used to determine whether forgetting is caused by a lack of model capacity.	O	O	Reply	253
Can you explain?	O	O	Reply	253
[line_break_token][line_break_token]A6: In many papers (for example: Learning without Forgetting), the performance of MTL is viewed as an upper bound of the performance of lifelong learning because MTL has access to old data while lifelong learning can only access current data.*	B-Reply	B-6	Reply	253
Therefore, we assumed if we could not get acceptable performance on MTL, we don‚Äôt even need to consider the model‚Äôs capability in lifelong learning.	I-Reply	I-6	Reply	253
[line_break_token][line_break_token]* Sometimes other methods of training multiple tasks may have better overall performance than MTL.	I-Reply	I-6	Reply	253
This is because (1) training all tasks together can make optimization much harder and (2) if there are unbalanced datasets, multitasking may ignore smaller datasets during training; however when we are averaging the final scores of all tasks, the weight of every task is the same.	I-Reply	I-6	Reply	253
[line_break_token][line_break_token]Q7: Why not compare the approach with models like GEM?	O	O	Reply	253
[line_break_token][line_break_token]A7: We added the comparison to GEM in Section 5.2 for the SST, QA-SRL, and WOZ tasks.	B-Reply	B-7	Reply	253
The results are updated in the paper in Table 3 (<a href="https://drive.google.com/file/d/15S0qtl7TeR_a4dTvuYEa6qrWY-c8qp9f/view?usp=sharing)" target="_blank" rel="nofollow">https://drive.google.com/file/d/15S0qtl7TeR_a4dTvuYEa6qrWY-c8qp9f/view?usp=sharing)</a>[line_break_token]and Figure 5 in Appendix B (<a href="https://drive.google.com/file/d/1NE3r_wlvsKQ-IW4mC1Awa9-o-YiLVpME/view?usp=sharing)."	O	O	Reply	253
target="_blank" rel="nofollow">https://drive.google.com/file/d/1NE3r_wlvsKQ-IW4mC1Awa9-o-YiLVpME/view?usp=sharing).</a>[line_break_token]The performance of GEM is only slightly better than fine-tuned, which is similar to that of EWC and MAS.	O	O	Reply	253
[line_break_token]We do not run GEM on larger datasets because it is too time-consuming to solve the Quadratic Programming.	B-Reply	B-7	Reply	253
[line_break_token][line_break_token]Q8: Is there any reason why you choose to go from large to small tasks?	O	O	Reply	253
How about other orders?	O	O	Reply	253
[line_break_token][line_break_token]A8: On the five DecaNLP tasks, with a limited computational resource, we decided to explore this order at first.	B-Reply	B-8	Reply	253
On the three small tasks SST, QA-SRL, and WOZ, we compared all 6 orders as shown in Table 3.	I-Reply	I-8	Reply	253
[line_break_token]Now, we also completed the reversed order (WOZ ‚Üí QA-SRL ‚Üí SST ‚Üí WikiSQL ‚Üí SQuAD) experiments using following methods: (1) Fine-tuned, (2) MAS, (3), (4), (5), (6), (7), and (8).	I-Reply	I-8	Reply	253
Again, because it is too time-consuming for solving the Quadratic Programming, we did not run GEM.	I-Reply	I-8	Reply	253
[line_break_token]The results are shown in Appendix C (<a href="https://drive.google.com/file/d/1Y9ACQIAMH8tXFrS-ezLjmAIo1gHDvYDl/view?usp=sharing)."	O	O	Reply	253
target="_blank" rel="nofollow">https://drive.google.com/file/d/1Y9ACQIAMH8tXFrS-ezLjmAIo1gHDvYDl/view?usp=sharing).</a>[line_break_token]We can clearly see that our method performs much better than Fine-tuned and MAS.	O	O	Reply	253
In this case, even performs better than multitasking, possibly due to the reason stated in the annotation in A6.	B-Reply	B-8	Reply	253
[line_break_token][line_break_token]---- to be continued ----	O	O	Reply	253

The authors propose a method for lossless image compression based on using[line_break_token]fully convolutional VAE models.	O	O	Review	474
These models are shown to generalize well when[line_break_token]they are trained on small images (e.g. 32x32 and 64x64) and then applied to[line_break_token]much larger images.	O	O	Review	474
The method is based on a fully vectorized implementation of[line_break_token]bits back with asymetric numeral systems coding which is much faster than[line_break_token]previous non-vertorized implementations.	O	O	Review	474
An improvement with respect to similar[line_break_token]methods is to use a dynamic discretization of the latent variables which avoids[line_break_token]having to callibrate a static discretization (as in previous methods).	O	O	Review	474
[line_break_token]Finally, the authors initialize the bis back process with information about a[line_break_token]few initial images which are coded using a different codec.	O	O	Review	474
 The experiments[line_break_token]performed illustrate the gains of the method in terms of compression ratio and[line_break_token]speed.	O	O	Review	474
[line_break_token][line_break_token]Clarity:[line_break_token][line_break_token]The paper is extremelly well writen and it is very easy to read.	O	O	Review	474
The athors[line_break_token]indicate that they will release open-source code to implement all their[line_break_token]results, which is very wellcome to improve reproducibility.	O	O	Review	474
However, I have to[line_break_token]say that the part describing the vectorized implementation of their method was[line_break_token]rather confusing and the paper could benefit a lot from clarifying this part.	B-Review	B-1	Review	474
[line_break_token][line_break_token]Quality:[line_break_token][line_break_token]The experiments performed are sound and illustrate the gains produced by their[line_break_token]method (although they do not achieve state of the art results).	O	O	Review	474
In particular,[line_break_token]the experiments show the speed up gain by the proposed vectorization and the gains[line_break_token]produced by the dynamic discretization.	O	O	Review	474
The experiments also show how the methods[line_break_token]trained on smaller images generalize well to larger images.	O	O	Review	474
[line_break_token][line_break_token]Novelty:[line_break_token][line_break_token]The proposed approach is novel up to my knowledge.	O	O	Review	474
Although the methodological[line_break_token]innovations are not that advanced, the vectorization in the specific[line_break_token]application considered is novel, as well as the dynamic discretization.	O	O	Review	474
[line_break_token][line_break_token]Significance:[line_break_token][line_break_token]The proposed contributions are significant in my opinion.	B-Review	B-2	Review	474
The vectorization[line_break_token]approach can be very useful in practice and the dynamic discretization can also[line_break_token]be useful as shown by the experiments.	I-Review	I-2	Review	474
One criticism could be that the authors[line_break_token]do not achieve state of the art results, but I consider this a minor thing.	I-Review	I-2	Review	474
hank you for your review.	O	O	Reply	474
We address the following point:[line_break_token][line_break_token]&gt; However, I have to say that the part describing the vectorized implementation of their method was rather confusing and the paper could benefit a lot from clarifying this part.	O	O	Reply	474
[line_break_token][line_break_token]It‚Äôs difficult to give a proper description of this without going into a lot more detail about ANS implementation.	B-Reply	B-1	Reply	474
To aid readers who are confused and/or curious, we‚Äôve added a recommendation, in the second paragraph of Section 3.2, to refer to our code and to Giesen (2015) for more detail	I-Reply	I-1	Reply	474

This paper presents a novel method to extract cross-modal text-visual embeddings on the HowTo 100M corpus.	O	O	Review	20381
The core idea is to extend previous work on clip-level embeddings (e.g. the max-margin ranking loss proposed for HowTo 100M) to a transformer architecture which takes into account the entire context of a video, which should lead to better learned representations and improved performance in downstream tasks.	O	O	Review	20381
In addition, the max-margin loss is replaced by noise contrastive estimation.	O	O	Review	20381
[line_break_token][line_break_token]The paper is well written and explains the main problem well, however I do have a few questions:[line_break_token]- I do not understand the sentence "However, for images and videos, the inputs are real-valued vectors." (	B-Review	B-1	Review	20381
Section 3.2) - Transformers are being used for speech recognition or speech translation - the input features are not the problem.	I-Review	I-1	Review	20381
The outputs are assumed to be discrete (in the original formulation)[line_break_token]- Why not directly compare your approach to the approach presented in (Miech, 2019c) - it would be interesting to see a direct comparison, but as far as I can tell, there is no overlap in tasks?	B-Review	B-2	Review	20381
[line_break_token]- What is the influence of adding punctuation to the ASR output, how good is it, and how good is the underlying ASR?	B-Review	B-3	Review	20381
Why did you not use the original text annotations provided by HowTo 100M, but run the audio through Google ASR (again?)	I-Review	I-3	Review	20381
It would be good to know how good the ASR is, and if adding in punctuation post-hoc works well, and how this influences your use with a pre-trained BERT model.	I-Review	I-3	Review	20381
My guess is that the BERT model will be happy as long as it sees a "."	I-Review	I-3	Review	20381
at the end?	I-Review	I-3	Review	20381
[line_break_token]- Also, would it be possible to compare the results of your work with some of the work in (Miech, 2019c) - it almost seems that your work avoids comparing your results to this previous work.	B-Review	B-4	Review	20381
[line_break_token]	O	O	Review	20381
hank you for your positive feedback.	O	O	Reply	20381
[line_break_token][line_break_token]Comparison to HowTo100M:[line_break_token][line_break_token]Although we use the HowTo100M dataset for pre-training, there are key differences to (Miech, 2019c):[line_break_token]1.	B-Reply	B-5	Reply	20381
Miech et al improve text-video embedding by training on HowTo100M and show the gain by transferring it to the text to video retrieval task.	I-Reply	I-5	Reply	20381
In comparison, CBT focuses on learning generic visual and temporal features, with or without using text-video correspondences.	I-Reply	I-5	Reply	20381
We show that CBT can be transferred to various downstream tasks, such as classification, anticipation, segmentation and captioning.	I-Reply	I-5	Reply	20381
[line_break_token]2.	O	O	Reply	20381
Miech et al assume the visual features to be pre-trained and fixed, while CBT can be applied for self-supervised visual representation learning, as shown in Table 1.	B-Reply	B-5	Reply	20381
[line_break_token][line_break_token]Direct comparison to (Miech2019c):[line_break_token]We evaluate our cross-modal model pre-trained on HowTo100M with the same preprocessing as in (Miech2019c), i.e. with short clips.	B-Reply	B-2	Reply	20381
We evaluate on the MSR-VTT clip retrieval benchmark (zero-shot settings) and can observe that we outperform their approach, see below.	I-Reply	I-2	Reply	20381
We will add this results to the final version of the paper if accepted.	I-Reply	I-2	Reply	20381
[line_break_token]HowTo100M (table 6):    R@1: 7.5   R@5: 21.2   R@10: 29.6   median R: 38[line_break_token]Ours:                                 R@1: 8.3   R@5: 23.3   R@10: 33.2   median R: 30[line_break_token][line_break_token]‚ÄúThe inputs are real-valued vectors‚Äù:[line_break_token]Thank you for pointing this out, we will clarify in the final version.	B-Reply	B-1	Reply	20381
[line_break_token][line_break_token]Influence of ASR and punctuation:[line_break_token]The video clips and speech released by HowTo100M were preprocessed and broken into short segments.	B-Reply	B-3	Reply	20381
To learn long-term temporal features with the transformer, our approach requires longer input clips.	I-Reply	I-3	Reply	20381
Hence, we re-extract the ASR with the same algorithm as HowTo100M and run punctuation to get longer semantic coherent text segments (sentences).	I-Reply	I-3	Reply	20381
Furthermore, we concatenate several consecutive sentences to obtain even longer sequences of video-ASR training data.	I-Reply	I-3	Reply	20381

In this paper, the authors tackle the problem of multi-modal image-to-image translation by pre-training a style-based encoder.	O	O	Review	79
The style-based encoder is trained with a triplet loss that encourages similarity between images with similar styles and dissimilarity between images with different styles.	O	O	Review	79
The output of the encoder is a style embedding that helps differentiates different modes of image synthesis.	O	O	Review	79
 When training the generator for image synthesis, the input combines an image in the source and a style embedding, and the loss is essentially the sum of image conditional GAN loss and perceptual loss.	O	O	Review	79
Additionally, the authors propose a mapping function to sample styles from a unit Gaussian distribution.	O	O	Review	79
[line_break_token][line_break_token]I think the idea of pre-training a style-based encoder is straightforward.	O	O	Review	79
I am mainly concerned about the performance of the presented approach.	O	O	Review	79
First, there are no many visual comparisons in the paper.	B-Review	B-1	Review	79
The only visual comparison is in Figure 8, but results are only limited to faces.	I-Review	I-1	Review	79
The visual results in Figure 5 do not look appealing to me.	I-Review	I-1	Review	79
The change in the style mainly comes from the global change in color: no much change in the texture or local color.	B-Review	B-2	Review	79
The "night2day" results look poor to me.	I-Review	I-2	Review	79
 I am concerned about the diversity of the styles learned in the model.	I-Review	I-2	Review	79
[line_break_token][line_break_token]On the other hand, I am convinced that the proposed model is better than BicycleGAN, and the approach is somehow novel.	B-Review	B-3	Review	79
The user study in Table 5 suggests that the proposed method is somehow better than BicyleGAN in visual quality on one task.	I-Review	I-3	Review	79
My overall rating is borderline.	I-Review	I-3	Review	79
[line_break_token][line_break_token]Minor comments:[line_break_token]- In the first sentence of Section 3.2, I do not think "one-to-one correspondence" is the right description.	B-Review	B-4	Review	79
The encoder is not expected to be invertible.	I-Review	I-4	Review	79
[line_break_token]- In Equation (3), "e_i" is a little bit misleading.	I-Review	I-4	Review	79
It does not mean the i-th element in {"e_j"}. You may want to replace "e_i" with "s_i" to avoid confusion.	I-Review	I-4	Review	79
[line_break_token]- The explanation of ours v1, v2, v3, v4 is not clear.	I-Review	I-4	Review	79
It is also difficult to find its definition.	I-Review	I-4	Review	79
hank you for reviewing our paper!	O	O	Reply	79
Please find responses to your points/questions below:[line_break_token][line_break_token]Visual comparisons: Figure 2 in the paper shows qualitative comparisons, not just figure 8.	B-Reply	B-1	Reply	79
Also, Table 5 shows results of a user study which compared the quality of 50 different outputs of our method against the BicycleGAN-based baselines.	I-Reply	I-1	Reply	79
[line_break_token][line_break_token]Diversity comes from global change in color: we would like to highlight that there is plenty of evidence in the paper that the diversity doesn‚Äôt come from just the global color change.	B-Reply	B-2	Reply	79
For example:[line_break_token]- Figure 5 (style sampling):[line_break_token]    - Space needle: results show clear weather changes, such as cloudy vs sunny, change in cloud patterns and even sampling foggy weather which was present in some images in the training set.	I-Reply	I-2	Reply	79
[line_break_token]    - Maps dataset: the existence and/or density of bushes clearly varies between different sampled styles.	I-Reply	I-2	Reply	79
[line_break_token]    - Edges2handbags: the texture of the bag varies clearly between smooth and rough leather (better seen in zoom).	I-Reply	I-2	Reply	79
[line_break_token]- Figure 4 (style interpolation):[line_break_token]    - The smooth change from cloudy to sunny weather including the change in lighting and cloud patterns.	I-Reply	I-2	Reply	79
[line_break_token]- Figure 3 (style transfer):[line_break_token]    - Space needle: the output style clearly copies the weather condition.	I-Reply	I-2	Reply	79
We show sunset, sunny, foggy and cloudy weather.	I-Reply	I-2	Reply	79
[line_break_token]    - Night2day: variation in lighting conditions can be clearly seen including transferring whether the surface is sunlit or not, as well as different cloud patterns and clear skies.	I-Reply	I-2	Reply	79
[line_break_token]    - Edges2handbags: the output texture varies (most clear in the third image with the dark pink color).	I-Reply	I-2	Reply	79
Figure best seen in zoom.	I-Reply	I-2	Reply	79
[line_break_token]- Figure 2 (qualitative comparison):[line_break_token]    - Our approach matches the GT texture better than the baselines (most obvious in the left column - first and third rows) ‚Äî figure best seen in zoom.	I-Reply	I-2	Reply	79
[line_break_token]Also, we quantitatively measure the output diversity in both style transfer and style sampling setups in Table 5.	I-Reply	I-2	Reply	79
[line_break_token][line_break_token]Quality of results:[line_break_token]We recommend looking at the figures in zoom to better appreciate the quality.	B-Reply	B-3	Reply	79
The night2day and labels2facades datasets are particularly smaller than the other datasets, as night2day has only 100 unique scenes in the training set, while the labels2facades trainset contains only a few hundred images.	I-Reply	I-3	Reply	79
We observed that our models overfits the training set if we trained with full capacity like the larger datasets.	I-Reply	I-3	Reply	79
While we used the same hyper-parameters for all datasets, the change we made for training on the night2day and labels2facades datasets is to use a smaller model (i.e reduce the number of convolution filters), and train for shorter (i.e early stopping).	I-Reply	I-3	Reply	79
[line_break_token][line_break_token]Minor comments: thank you for the suggestions.	B-Reply	B-4	Reply	79
We will adopt the suggested changes, and include a clear definition for the different versions of our method, and we will submit a revised version of our paper by Friday.	I-Reply	I-4	Reply	79

The goal of this work is to best understand the performance and benchmarking of continual learning algorithms when applied to sequential data processing problems like language or sequence data sets.	O	O	Review	20335
The contributions of the paper are 3 fold - new benchmarks for CL with sequential data for RNN processing, new architecture introduced for more effective processing and a thorough empirical evaluation.	O	O	Review	20335
[line_break_token][line_break_token]Introduction: [line_break_token]I think a little more insight into why the sequential data processing CL scenario is any different than the vision scenario would be quite helpful.	B-Review	B-1	Review	20335
Specifically, it would be quite impactful to tell us more about what the additional challenges with RNNs for CL vs feedforward for CL are in the intro.	I-Review	I-1	Review	20335
[line_break_token][line_break_token]The paper is written as if the benchmark is the main contribution and the architecture improvement is just a delta on top of this, but it gets confusing when the methods section starts off with just directly stating the new architecture.	B-Review	B-2	Review	20335
[line_break_token][line_break_token]The algorithm seems like a straightforward combination of recurrent progressive nets and gated autoencoders for CL.	B-Review	B-3	Review	20335
Can the authors provide more justification if that is the contribution or there is more to the insight than has been previously suggested in prior work?	I-Review	I-3	Review	20335
[line_break_token][line_break_token]Figure 1 has a very uninformative caption.	B-Review	B-4	Review	20335
It also doesn‚Äôt show how modules feed into one another properly.	I-Review	I-4	Review	20335
[line_break_token][line_break_token]The motivation for why one needs GIM after one already has A-LSTM or A-LMN is not very clear?	B-Review	B-5	Review	20335
[line_break_token][line_break_token]Overall the contribution does seem a bit incremental based on prior work and the description lacks enough detail to properly indicate why this is a very important contribution?	B-Review	B-6	Review	20335
[line_break_token][line_break_token]Experiments:[line_break_token]What does it mean to be application agnostic but restricted to particular datasets and losses?	B-Review	B-7	Review	20335
This doesn‚Äôt quite parse to me.	I-Review	I-7	Review	20335
[line_break_token][line_break_token]The description of the tasks is very informal and hard to follow.	B-Review	B-8	Review	20335
It‚Äôs not clear what exactly the tasks and datasets look like [line_break_token][line_break_token]‚Äúusing morehidden units can bridge this gap‚Äù -&gt; why not just do it?	O	O	Review	20335
Its a benchmark after all.	B-Review	B-8	Review	20335
[line_break_token][line_break_token]Overall the task descriptions should be in a separate section where the setup is described in a lot of detail and motivated properly.	B-Review	B-9	Review	20335
[line_break_token][line_break_token]The results in the experiments section are very hard to parse.	B-Review	B-10	Review	20335
The captions need much more detail for eg Table 2.	I-Review	I-10	Review	20335
[line_break_token][line_break_token]Could we also possibly have more baselines from continual learning?	B-Review	B-11	Review	20335
For instance EWC (Kirkpatrick) or generative replay might be competitive baselines.	I-Review	I-11	Review	20335
[line_break_token][line_break_token]Overall I think that the GIM and A-LMN and A-LSTM methods are reasonable although somewhat incremental.	B-Review	B-12	Review	20335
But the proposed benchmarks are pretty unclear and the results are a bit hard to really interpret well.	I-Review	I-12	Review	20335
It would also be important to run comparisons with more baselines and to provide more ablation/analysis experiments to really see the benefit of GIM/A-LMN or A-LSTM.	I-Review	I-12	Review	20335
I also think that the task descriptions should be much earlier in the paper and desribed in much more rigorous detail.	I-Review	I-12	Review	20335
[line_break_token]	O	O	Review	20335
he main difference between the sequential data processing scenario and the vision scenario is related to the fact that sequential processing requires the use of a memory that embeds the history of past inputs.	B-Reply	B-1	Reply	20335
Such memories have to be appropriately learned and preserved, making the sequential processing tasks clearly different than the vision tasks.	I-Reply	I-1	Reply	20335
When it comes to CL, drifts in the input distribution could affect the hidden memory of RNNs.	I-Reply	I-1	Reply	20335
Additional works will be needed in order to clarify this phenomenon.	I-Reply	I-1	Reply	20335
We will clarify this point in the Introduction.	I-Reply	I-1	Reply	20335
[line_break_token][line_break_token]The main concern of this work was to provide a set of common benchmarks for CL in sequential domains that are independent of domain-specific applications (e.g. NLP) against which existing and future models can compare their performances.	B-Reply	B-2	Reply	20335
We will better describe the experimental settings, reserving a specific section to the description of the tasks and datasets.	I-Reply	I-2	Reply	20335
Since they are the main contribution of this work, we agree that they should be better highlighted.	I-Reply	I-2	Reply	20335
[line_break_token]In addition, we extend the progressive approach and the gating autoencoder to the recurrent domain.	I-Reply	I-2	Reply	20335
At the best of our knowledge, no previous work proposed these two extensions for recurrent neural networks, nor they combine both into one end-to-end model.	I-Reply	I-2	Reply	20335
[line_break_token][line_break_token]The reason why the Augmented models need the autoencoders (e.g. from A-LSTM to GIM-LSTM) is that without the autoencoders is not possible to avoid the use of task labels at inference time.	B-Reply	B-5	Reply	20335
GIM architectures can detect the correct module for inference, while Augmented modules alone only allow the transfer of useful, learned features from one module to the others.	I-Reply	I-5	Reply	20335
[line_break_token][line_break_token]The experimental protocol is task-agnostic in the sense that we do not restrict the choice of datasets to a particular application (e.g. NLP), but instead, we proposed a set of general datasets (Copy and SSMNIST) that do not require any domain-specific technique.	B-Reply	B-7	Reply	20335
Using this benchmarks, we can evaluate CL models while eliminating the idiosyncrasies of specific application domains.	I-Reply	I-7	Reply	20335
[line_break_token][line_break_token]In future versions, we will extend standard CL techniques to the RNN scenario and we will compare their performances against both naive RNNs and GIM.	B-Reply	B-1	Reply	20335
[line_break_token]We will also provide ablation studies highlighting the effects that autoencoders and inter-modules connections have on the overall performance of GIM	B-Reply	B-12	Reply	20335

This paper proposes a new variational recurrent model for learning sequences.	O	O	Review	1081
Comparing to existing work, instead of having latent variables that are dependent on the neighbors, this paper proposes to use independent latent variables with observations that are generated from multiple latent variables.	O	O	Review	1081
[line_break_token]The paper further combined the proposed method with multiple existing ideas, such as the shared/prviate representation from VAE-CCAE, adding the hierarchical structure, and prior updating.	O	O	Review	1081
[line_break_token][line_break_token]Pros:[line_break_token]The proposed method seems technical correct and reasonable.	O	O	Review	1081
[line_break_token]There are many extensions which are potentially useful for many applications [line_break_token]There are many experimental results showing promising performance.	O	O	Review	1081
[line_break_token][line_break_token]Cons:[line_break_token]The framework is very incremental.	B-Review	B-1	Review	1081
It is novel but limited.	I-Review	I-1	Review	1081
[line_break_token]The paper claim that the main point to use the simpler variations distribution is to speed up the inference.	B-Review	B-2	Review	1081
But no speed comparisons are shown in the experiments section.	I-Review	I-2	Review	1081
[line_break_token]The evaluation shows that prior updating (one extension) seems contributes to the biggest performance gain, not the main proposed method.	B-Review	B-3	Review	1081
[line_break_token][line_break_token]	O	O	Review	1081
Thank you for pointing out the missing speed comparison.	B-Reply	B-1	Reply	1081
 RecRep is roughly twice faster in our implementation than StocCon when using batch size 4.	I-Reply	I-1	Reply	1081
 We will include this in a revision.	I-Reply	I-1	Reply	1081
 Regarding the degree of novelty, our main contribution is a practical approach to representation learning for sequences that improves performance on multiple downstream tasks.	I-Reply	I-1	Reply	1081
 While prior work has largely focused on measuring the quality of recurrent models for generation, we focus on making them useful for representation learning	I-Reply	I-1	Reply	1081

This work proposed a mask based approach for instance-level unsupervised content transfer, which is an extension of the disentanglement work in (Press et al 2019) and the attention guided translation (Chen et al 2018, Mejjati et al 2018).	O	O	Review	10071
Unlike the disentanglement work, the introduced mask allows the adaptation to focus on the relevant content which substantially reduce the complexity of the generation.	O	O	Review	10071
On the other hand, the proposed method extends the attention guided translation from the domain level to the instance level which allows more specific and diverse translations.	O	O	Review	10071
Experiments on benchmark data shows both improved qualitative and quantitative results comparing to existing methods.	O	O	Review	10071
It is really nice that the authors also considered the situation of generalization to out of domain images.	O	O	Review	10071
[line_break_token][line_break_token]However, I would encourage the authors to spend more discussion on the "Method" and "Ablation Analysis" sections to give a better illustration.	B-Review	B-1	Review	10071
First is the choice of the L2 norm in all the reconstruction losses, which is different from L1 norm used in both (Press et al 2019) and (Mejjati et al 2018).	I-Review	I-1	Review	10071
What is the advantage of using L2 instead of L1 norm here?	I-Review	I-1	Review	10071
Does it work better with the mask generation?	I-Review	I-1	Review	10071
Second, the domain confusion loss.	I-Review	I-1	Review	10071
The presence of both equation (3) and (4) are quite confusing and the domain confusion loss (3) seems different from traditional ones.	I-Review	I-1	Review	10071
In Table 7, it shows that the learned mask is empty without any of the losses (3), (5), (7).	I-Review	I-1	Review	10071
But only loss (7) is directly related to the mask generation.	I-Review	I-1	Review	10071
How does the loss (3) or (5) impact the mask learning?	I-Review	I-1	Review	10071
It is also unclear why the losses introduced in (8) would encourage the mask to be minimal despite the quantitative results shown in Table 7.	I-Review	I-1	Review	10071
Actually, I am very curious about the performance of the loss introduced in (Press et al 2019) on top of the network introduced in Figure 2.	I-Review	I-1	Review	10071
[line_break_token][line_break_token]Other comments:[line_break_token]- It would be nice to see the out of domain transfer in the "attribute" domain.	B-Review	B-2	Review	10071
Ideally, the network should be able to detect "difference" in the image from domain B and apply it to the image from domain A. For example, the model is trained on faces without and with glasses, but applied to faces without and with facial hair.	I-Review	I-2	Review	10071
Indeed, the introduction of mask alleviates the decoder to learn the attribute itself, and provides the ability to locate the place of difference.	I-Review	I-2	Review	10071
[line_break_token]- Please unify the citation style: there are both Press et al (2019) and (Press et al 2019) used.	B-Review	B-3	Review	10071
[line_break_token]- In Section 2 under "Mask Based Approaches", the authors argued that the existing attention guided translation "does not allow for the adaptation of the image information in the masked area".	B-Review	B-4	Review	10071
I do not think this is the case.	I-Review	I-4	Review	10071
The existing work also introduced adaptation of the image information in the masked area.	I-Review	I-4	Review	10071
For example, the equation (1) in (Mejjati et al 2018).	I-Review	I-4	Review	10071
[line_break_token]- How is the binarized mask generated in inference?	B-Review	B-5	Review	10071
Specifically, how to determine the threshold?	I-Review	I-5	Review	10071
[line_break_token]- In Section 4.1, the authors argued that "without L_{Cycle} the masks produced include larger portions of the face".	B-Review	B-6	Review	10071
But this actually produces the second smallest mask in Table 7.	I-Review	I-6	Review	10071
[line_break_token]- What is the "L2 reg" in Table 7?	B-Review	B-7	Review	10071
[line_break_token]- It would be good to show the sensitivity of the lambdas in the overall loss.	B-Review	B-8	Review	10071
ith regards to the sensitivity of the lambda coefficients in our loss, the values of the coefficients were set early on in the development process in a way that reflects the relative importance we attributed to each component and the observed trade-offs.	B-Reply	B-8	Reply	10071
For example, if the mask obtained was too large we would increase (Eq.	I-Reply	I-8	Reply	10071
8).	I-Reply	I-8	Reply	10071
As illustrated in Fig.	I-Reply	I-8	Reply	10071
39, our network is not overly sensitive to the choice of these values.	I-Reply	I-8	Reply	10071
For example, for (Eq.	I-Reply	I-8	Reply	10071
8) loss each value in the range 0.4-1.0 results in a similar output and for (Eq.	I-Reply	I-8	Reply	10071
5) each value in the range 3.0-7.0 results in a similar output	I-Reply	I-8	Reply	10071

The authors propose a framework for combining value function factorization and communication learning in a multi-agent setting by introducing two regularizers, one for maximizing mutual information between decentralized Q functions and communication messages and the other for minimizing the entropy of messages between agents.	O	O	Review	719
The authors also discuss a method for dropping non-informative messages.	O	O	Review	719
They illustrate their approach on sensor and hallway tasks and evaluate their method on the decentralized StarCraft II benchmark.	O	O	Review	719
The paper addresses an interesting problem, and the authors show that their approach gives good performance compared to alternative approaches even when a large percentage of communication is cut off between the agents.	O	O	Review	719
[line_break_token][line_break_token]Questions/Comments:[line_break_token]- Implementation details (e.g., hyper-parameters, model size) are missing from the paper.	B-Review	B-1	Review	719
[line_break_token]- The results are average over only 3 seeds, is this enough to compare different algorithms?	B-Review	B-2	Review	719
[line_break_token]- How should beta should be determined?	B-Review	B-3	Review	719
[line_break_token]- The authors present results when 80% of messages are cut off.	B-Review	B-4	Review	719
What is the performance of the model when all communication is cut off for comparison?	I-Review	I-4	Review	719
[line_break_token]- How does the approach work in competitive environments?	B-Review	B-5	Review	719
[line_break_token]- The experimental results section is not well organized.	B-Review	B-6	Review	719
The authors mention five question on page 6, but it is not very clear with examples/set of experiments address which question.	I-Review	I-6	Review	719
[line_break_token]- There are many spelling/grammar errors in the paper.	B-Review	B-7	Review	719
hanks for your comments.	O	O	Reply	719
Here we provide explanations to clarify your questions.	O	O	Reply	719
In addition, please feel free to refer to our response to reviewer #1, which summarizes novelties of our paper.	O	O	Reply	719
[line_break_token] [line_break_token]Q: Implementation details (e.g., hyper-parameters, model size) are missing from the paper.	O	O	Reply	719
[line_break_token]A: These details were described in Appendix B of our original submission because of the space limitation.	B-Reply	B-1	Reply	719
[line_break_token] [line_break_token]Q: The results are average over only 3 seeds, is this enough to compare different algorithms?	O	O	Reply	719
[line_break_token]A: We have run all the SC2 experiments with more random seeds and found that the variances of learning curves are similar and the performance comparison results do not change.	B-Reply	B-2	Reply	719
We have shown learning curves averaged over 5 different random seeds in Fig.	I-Reply	I-2	Reply	719
7, 8, and 10 in the updated version of our paper.	I-Reply	I-2	Reply	719
                                                                                                                                                         [line_break_token]                                                                                                                                  [line_break_token]Q: How beta should be determined?	O	O	Reply	719
[line_break_token]A: is used to trade off communication costs and communication effects.	B-Reply	B-3	Reply	719
We have studied how affects the message embedding on the task sensor, as shown in Fig.3 on page 6.	I-Reply	I-3	Reply	719
We also find that the performance of our method is robust across all the tested environments when.	I-Reply	I-3	Reply	719
Therefore, we recommend that a in this region being tried first on new tasks and some fine-tuning may improve the performance further.	I-Reply	I-3	Reply	719
[line_break_token] [line_break_token]Q: The authors present results when 80% of the messages are cut off.	O	O	Reply	719
What is the performance of the model when all communication is cut off for comparison?	O	O	Reply	719
[line_break_token]A: We have shown the performance comparison when all communication is cut off, which is illustrated by Fig.	B-Reply	B-4	Reply	719
10 on page 16 of our original submission.	I-Reply	I-4	Reply	719
[line_break_token] [line_break_token]Q: How does the approach work in competitive environments?	O	O	Reply	719
[line_break_token]A: Our approach is designed for a team of agents to learn to effectively collaborate and coordinate.	B-Reply	B-5	Reply	719
These cooperative scenarios are common in the field of MARL [Foerster et al AAAI 2018, Rashid et al ICML 2018]. Of course, such a team of agents can compete against another opponent team in competitive settings.	I-Reply	I-5	Reply	719
[line_break_token] [line_break_token]In mixed cooperative-competitive tasks, our method is readily combined with IC3Net [Singh et al ICLR 2019], learning gates to cut off messages sent to the opponents.	I-Reply	I-5	Reply	719
It will be the same as how TarMAC [Das et al ICML 2019] is adapted to mixed environments.	I-Reply	I-5	Reply	719
However, this setting is not the focus of this paper, and we will explore it in the future.	I-Reply	I-5	Reply	719
[line_break_token] [line_break_token]Q: The experimental results section is not well organized.	O	O	Reply	719
The authors mention five questions on page 6, but it is not very clear which examples/set of experiments address which question.	O	O	Reply	719
[line_break_token]A: Performance comparison and visualization results of didactic experiments can clarify all the questions.	B-Reply	B-6	Reply	719
Our SC2 experiments further prove that the miscoordination problem of full decomposition methods is quite common and that our method can outperform QMIX and a state-of-the-art attentional communication algorithm.	I-Reply	I-6	Reply	719
[line_break_token] [line_break_token]We hope that our clarifications can address your questions.	O	O	Reply	719
Please let us know if you have any other questions.	O	O	Reply	719
[line_break_token] [line_break_token][Foerster et al AAAI 2018] Foerster, J.N., Farquhar, G., Afouras, T., Nardelli, N. and Whiteson, S., 2018, April.	O	O	Reply	719
Counterfactual multi-agent policy gradients.	O	O	Reply	719
In Thirty-Second AAAI Conference on Artificial Intelligence.	O	O	Reply	719
[line_break_token][line_break_token][Rashid et al ICML 2019] Rashid, T., Samvelyan, M., Witt, C.S., Farquhar, G., Foerster, J. and Whiteson, S., 2018, July.	O	O	Reply	719
QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning.	O	O	Reply	719
In International Conference on Machine Learning (pp.	O	O	Reply	719
4292-4301).	O	O	Reply	719
[line_break_token] [line_break_token][Singh et al ICLR 2019] Singh, A., Jain, T. and Sukhbaatar, S., 2019.	O	O	Reply	719
Learning when to communicate at scale in multiagent cooperative and competitive tasks.	O	O	Reply	719
In International Conference on Learning Representations.	O	O	Reply	719
[line_break_token] [line_break_token][Das et al ICML 2019] Das, A., Gervet, T., Romoff, J., Batra, D., Parikh, D., Rabbat, M. and Pineau, J., 2019, May. TarMAC: Targeted Multi-Agent Communication.	O	O	Reply	719
In International Conference on Machine Learning (pp.	O	O	Reply	719
1538-1546)	O	O	Reply	719

This paper extends the work of TT-RRN [Khrulkov et al 2018] to further analyze the connection between RNN and TT decomposition by incorporating generalized nonlinearity, i.e., RELU, into the network architectures.	O	O	Review	510
Specifically, the authors theoretically study the influence of generalized nonlinearity on the expressivity power of TTD-based RNN, both theoretical result and empirical validation show that generalized TTD-based RNN is more superior to CP-based shallow network in terms of depth efficiency.	O	O	Review	510
[line_break_token]Pros:[line_break_token]1.	O	O	Review	510
This work is theoretically solid and extend the analysis of TT-RNN to the case of generalized nonlinearity, i.e. ReLU.	O	O	Review	510
[line_break_token][line_break_token]2.	O	O	Review	510
The paper is well written and organized.	O	O	Review	510
[line_break_token] [line_break_token]Cons:[line_break_token]1.	O	O	Review	510
The contribution and novelty of this paper is incremental and somehow limited, since the analysis TT-RNN based on the product nonlinearity already exists, which make the contribution of this paper decreased.	B-Review	B-1	Review	510
[line_break_token][line_break_token]2.	O	O	Review	510
The analysis is mainly on the particular case of rectifier nonlinearity.	B-Review	B-2	Review	510
I wonder if the nonlinearities other than the RELU hold the similar properties?	I-Review	I-2	Review	510
The proof or discussion on the general nonlinearities is missing.	I-Review	I-2	Review	510
[line_break_token][line_break_token]Other comments:[line_break_token]1.	O	O	Review	510
The authors said that the replacement of standard outer product with its generalized version leads to the loss of conformity between tensor networks and weight tensors, the author should clarify this in a bit more details.	B-Review	B-3	Review	510
[line_break_token][line_break_token]2.	O	O	Review	510
The theoretical analysis relies on grid tensor and restricts the inputs on template vectors.	B-Review	B-4	Review	510
It is not explained why to use and how to choose the those template vectors in practice?	I-Review	I-4	Review	510
[line_break_token][line_break_token]3.	O	O	Review	510
A small typo: In Figure 2, ‚Äòm' should be ‚ÄòM'	B-Review	B-5	Review	510
Thank you for your comments!	O	O	Reply	510
Please, see the answers to your questions below.	O	O	Reply	510
[line_break_token][line_break_token]1.	O	O	Reply	510
The detailed proof we provide in the paper indeed refers to the ReLU nonlinearity only.	B-Reply	B-2	Reply	510
Due to the constructive nature of our proof, it is not easily generalized to the arbitrary associative and commutative binary operator, and we highly doubt that it will work in general.	I-Reply	I-2	Reply	510
However, even without solid theoretical justification, we can implement generalized tensor networks with various nonlinearities and compare them empirically, which we do in Section B of the appendix.	I-Reply	I-2	Reply	510
As we can see, the right choice of nonlinearity for particular dataset may lead to boost in the performance and it will be interesting direction of research to analyze them more rigorously from both theoretical and practical viewpoints.	I-Reply	I-2	Reply	510
[line_break_token][line_break_token]2.	B-Reply	B-3	Reply	510
Before introducing the concept of generalized tensor networks, we had full correspondence between the score functions of scalar product form (equation 2) and the score functions of tensor decomposition form (equations 6 and 8).	I-Reply	I-3	Reply	510
It ensures that tensor networks are universal function approximators and allows us to focus on another important properties, such as expressivity.	I-Reply	I-3	Reply	510
However, after replacing the outer product with different operator and declaring the expressions from equations 14 and 16 to be the score functions, we can no longer state that they can be represented in a form of equation 2.	I-Reply	I-3	Reply	510
Specifically, we can no longer guarantee the existence of corresponding weight tensor W (and, thus, universality), the existence of which was trivial in the case of standard tensor networks with multiplicative nonlinearity.	I-Reply	I-3	Reply	510
[line_break_token][line_break_token]3.	O	O	Reply	510
The use of template vectors is motivated by the discussion in [1]. In order to be able to achieve zero classification error for the model under analysis, the data has to satisfy two assumptions: label has to be completely determined by the instance, and the input vectors may be quantized into one of the M templates.	B-Reply	B-4	Reply	510
The assumption that natural images possess these properties is based on various empirical studies.	I-Reply	I-4	Reply	510
For example, it was shown in [2] that small image patches of sizes 2x2, 4x4, 8x8, 16x16, and so on, can be effectively modeled by a GMM of size 64.	I-Reply	I-4	Reply	510
We believe that similar properties also hold for sequential data appearing in NLP tasks, however, this assumption requires further investigation.	I-Reply	I-4	Reply	510
[line_break_token][line_break_token][1] N. Cohen, O. Sharir, A. Shashua.	O	O	Reply	510
On the expressive Power of Deep Learning: A Tensor Analysis.	O	O	Reply	510
In Conference on Learning Theory, pp.	O	O	Reply	510
698 - 728, 2016.	O	O	Reply	510
[line_break_token][2] D. Zoran, Y. Weiss.	O	O	Reply	510
Natural images, Gaussian Mixtures and Dead Leaves.	O	O	Reply	510
In Advances in Neural Information Processing Systems, pp.	O	O	Reply	510
1745 - 1753, 2012	O	O	Reply	510

The authors improve a retriever-reader architecture for open-domain QA by iteratively retrieving passages and tuning the retriever with reinforcement learning.	O	O	Review	327
They first learn vector representations of both the question and context, and then iteratively change the vector representation of the question to improve results.	O	O	Review	327
I think this is a very interesting idea and the paper is generally well written.	O	O	Review	327
[line_break_token][line_break_token]I find some of the description of the models, methods and training is lacking detail.	B-Review	B-1	Review	327
For example, their should be more detail on how REINFORCE was implemented; e.g. was a baseline used?	I-Review	I-1	Review	327
[line_break_token][line_break_token]I am not sure about the claim that their method is agnostic to the choice of machine reader, given that the model needs access to internal states of the reader and their limited results on BiDAF.	B-Review	B-2	Review	327
[line_break_token][line_break_token]The presentation of the results left a few open questions for me:[line_break_token][line_break_token]  - It is not clear to me which retrieval method was used for each of the baselines in Table 2.	B-Review	B-3	Review	327
[line_break_token]  - Why does Table 2 not contain the numbers obtained by the DrQA model (both using the retrieval method from the DrQA method and their method without reinforcement learning)?	B-Review	B-4	Review	327
That would make their improvements clear.	I-Review	I-4	Review	327
[line_break_token]  - Moreover, for TriviaQA their results and the cited baselines seem to all perform well below to current top models for the task (cf.	O	O	Review	327
<a href="https://competitions.codalab.org/competitions/17208#results)."	O	O	Review	327
target="_blank" rel="nofollow">https://competitions.codalab.org/competitions/17208#results).</a>[line_break_token]  - I would also like to see a better analysis of how the number of steps helped increase F1 for different models and datasets.	B-Review	B-6	Review	327
The presentation should include a table with number of steps and F1 for different step numbers they tried. (	I-Review	I-6	Review	327
Figure 2 is lacking here.)	I-Review	I-6	Review	327
[line_break_token]  - In the text, the authors claim that their result shows that natural language is inferior to 'rich embedding spaces'.	B-Review	B-7	Review	327
They base this on a comparison with the AQA model.	I-Review	I-7	Review	327
There are two problems with this claim: 1) The two approaches 'reformulate' for different purposes, retrieval and machine reading, so they are not directly comparable.	I-Review	I-7	Review	327
2) Both approaches use a 'black box' machine reading model, but the authors use DrQA as the base model while AQA uses BiDAF.	I-Review	I-7	Review	327
Indeed, since the authors have an implementation of their model that uses BiDAF, an additional comparison based on matched machine reading models would be interesting.	I-Review	I-7	Review	327
[line_break_token]- Generally, it would be great to see more detailed results for their BiDAF-based model as well.	B-Review	B-8	Review	327
[line_break_token]	O	O	Review	327
We sincerely thank you for your insightful comments and we‚Äôre glad that you found our approach interesting.	O	O	Reply	327
Based on your comments, we have significantly improved the writing of the paper with more details and have added more evaluation.	O	O	Reply	327
Below we address your concerns point-by-point.	O	O	Reply	327
[line_break_token][line_break_token]- I find some of the description of the models, methods and training is lacking detail.	O	O	Reply	327
For example, their should be more detail on how REINFORCE was implemented; e.g. was a baseline used?	O	O	Reply	327
[line_break_token][line_break_token]We have significantly updated the model section of our paper to include more details about methods and training (Sec 2 & 3).	O	O	Reply	327
To answer your specific question about use of variance reduction baseline with REINFORCE -- In question answering settings, it has been noted by previous work such as  Shen et al (2017) that common variance reduction techniques don‚Äôt work well.	B-Reply	B-1	Reply	327
We also tried experimenting with a commonly used baseline - the average reward in a mini-batch, but found that it significantly degrades the final performance.	I-Reply	I-1	Reply	327
[line_break_token][line_break_token]I am not sure about the claim that their method is agnostic to the choice of machine reader, given that the model needs access to internal states of the reader and their limited results on BiDAF.	O	O	Reply	327
[line_break_token][line_break_token]We agree with you and based on your comments we have made this absolutely clear in the paper.	B-Reply	B-2	Reply	327
Our method needs access to the internal token level representation of the reader model in order to construct the current state.	I-Reply	I-2	Reply	327
The current API of machine reading models only return the span boundaries of the answer, but for our method, it needs to return the internal state as well.	I-Reply	I-2	Reply	327
What we wanted to convey is, our model does not depend/need any neural architecture re-designing to an existing reader model.	I-Reply	I-2	Reply	327
To show the same, we experimented and showed improvements with two popular and widely used reader architectures - DrQA and BiDAF.	I-Reply	I-2	Reply	327
[line_break_token]Regarding results of BiDAF -- During submission we ran out of time and hence we could not tune the BiDAF model.	I-Reply	I-2	Reply	327
But now the results of BiDAF have improved a lot and as can be seen from (Table 2, row 9), the results of BiDAF are comparable to that of DrQA.	I-Reply	I-2	Reply	327
[line_break_token][line_break_token]It is not clear to me which retrieval method was used for each of the baselines in Table 2.	O	O	Reply	327
[line_break_token][line_break_token]We report the best performance for each of our baseline that is publicly available.	B-Reply	B-3	Reply	327
Most of the results for the baseline (except DS-QA) are taken as reported in the R^3 paper.	I-Reply	I-3	Reply	327
We briefly describe the retrieval method used by the baselines below:[line_break_token](a) R^3 and DS-QA, like us, has a trained retriever module.	I-Reply	I-3	Reply	327
R^3 retriever is based on the Match-LSTM model and DS-QA is based on DrQA model (more details in the respective papers).	I-Reply	I-3	Reply	327
However, their retrievers compute query dependent para representation and hence don‚Äôt scale as we experimentally demonstrate in Fig 2.	I-Reply	I-3	Reply	327
[line_break_token](b) AQA, GA and BiDAF lack an explicit retriever module.	I-Reply	I-3	Reply	327
They concatenate all paragraphs in the context and feed it to their respective machine reading module.	I-Reply	I-3	Reply	327
Since the reader has to find the answer from possible very large context (because of concatenation), these models have lower performance as can be seen from Table 2.	I-Reply	I-3	Reply	327
[line_break_token][line_break_token]Why does Table 2 not contain the numbers obtained by the DrQA model (both using the retrieval method from the DrQA method and their method without reinforcement learning)?	O	O	Reply	327
That would make their improvements clear.	O	O	Reply	327
[line_break_token][line_break_token]Thanks for suggesting this experiment!	B-Reply	B-4	Reply	327
We ran the experiment and results are in (Table 2, row 7).	I-Reply	I-4	Reply	327
We trained a DrQA baseline model and the results indeed suggest that multi-step reasoning give uniform boost in performance across all datasets	I-Reply	I-4	Reply	327

The authors present a framework for testing a set of structured hypotheses about environment dynamics by learning an exploratory policy using Reinforcement Learning and a evaluator through supervised learning.	O	O	Review	706
They propose a formulation that decomposes environment hypotheses into sets of pre-conditions, required actions, and post-conditions.	O	O	Review	706
They then exploit this decomposition to (a) decouple the problem into both RL and supervised learning, and (b) provide localised pre-training to make the problem more tractable.	O	O	Review	706
[line_break_token][line_break_token]Overall, I really wanted to like this paper.	O	O	Review	706
The problem is interesting, and it certainly provides a great venue for interesting and impactful research in RL, language-conditioned decision making, structured / symbolic learning, and so on.	O	O	Review	706
However, I've found it relatively difficult to understand good parts of the methods and part of the experimental section, due to missing or misleading details.	O	O	Review	706
[line_break_token][line_break_token]In particular:[line_break_token][line_break_token]1.	O	O	Review	706
the justification for splitting the problem in a _exploratory_ / verification policy and a predictor is sound in principle, however it's unclear to me whether the problem is after all that intractable.	B-Review	B-1	Review	706
In the experiment section a "RL Baseline" is mentioned in principle, however (1) it is unclear whether it was pre-trained similarly to the proposed methods, and (2) if the policy has learnt enough about the problems that its poking methodology provides enough signal to the predictor, I would expect the same policy to be able to learn the same function given enough memory and training steps.	B-Review	B-2	Review	706
[line_break_token][line_break_token]2.	O	O	Review	706
I'm confused by the way the authors decomposed the action space for the policy and the predictor in section 3.1.	B-Review	B-3	Review	706
Does the policy use ans_T and ans_F at any point during training?	I-Review	I-3	Review	706
Does the actor effectively decide (i.e. by choosing "ans") when to query the prediction network?	I-Review	I-3	Review	706
[line_break_token][line_break_token]3.	I-Review	I-3	Review	706
The way the authors split the templates is confusing to me.	B-Review	B-5	Review	706
Up to section 3.3.1 (and - really - until I read the appendix...), the writing sort of led me to assume that (1) the "(pre-condition, action sequence) -&gt; post-condition" split was a fairly standard manner of compose a hypothesis, and that (2) the templates were mostly symbolic.	O	O	Review	706
However after reading the appendix, I found the imposed structure to be fairly arbitrary, and the usage of natural language overkill and not necessarily well justified.	O	O	Review	706
Ideally, I would like to see some comparisons between this type of hypothesis and other decompositions used in previous literature, since it seems like the method exploits this particular structure quite heavily and I don't quite understand how it generalises to other tasks.	B-Review	B-4	Review	706
[line_break_token][line_break_token]4.	O	O	Review	706
The environments seem to be all fairly similar, both in terms of overall complexity, size, and features.	B-Review	B-7	Review	706
It would have been better to also present problems with fairly different settings (e.g. much different - sparser and/or denser - types of reward function), rather than evaluating multiple times on effectively the same grid-world.	I-Review	I-7	Review	706
I was though encouraged to see that one of the environment seemed to require slightly different setting in the pre-training reward setup, however the authors didn't follow up with some analysis on why there was such a difference.	I-Review	I-7	Review	706
[line_break_token][line_break_token]5.	O	O	Review	706
I'm confused by how the pre-training is done.	B-Review	B-6	Review	706
I understand that R_{pre} is used by itself in one environment, but I couldn't figure out whether it's both reward functions at the same time that are used in the rest of them, or just R_{ppost}. Looking at the scale of the (average?)	I-Review	I-6	Review	706
reward, the former seems to be the case, but it would be good to be certain about such things.	I-Review	I-6	Review	706
[line_break_token][line_break_token]6.	O	O	Review	706
The final accuracy of all the experiments are shown using the max of top-5, however appendix D shows quite a significant variance for the methods.	B-Review	B-8	Review	706
Thus I'm not sure the analysis and final considerations are reasonable.	I-Review	I-8	Review	706
What happens if the methods are trained on more seeds?	I-Review	I-8	Review	706
[line_break_token][line_break_token]6. [	O	O	Review	706
nit] the title is somewhat misleading: in the introduction, a scientist is defined as being both a proposer and a verifier of hypotheses, which is a reasonable, however the authors fundamentally propose to solve only arguably the more straightforward of the two problems.	B-Review	B-9	Review	706
A less _flashy_ title would go a long way towards providing reasonable expectations for the reader.	I-Review	I-9	Review	706
[line_break_token][line_break_token][line_break_token]To improve this paper, I would like to see:[line_break_token][line_break_token]- Better clarity on how the hypothesis setup stands to previous literature.	B-Review	B-4	Review	706
[line_break_token]- The difference in performance on each environment with different pre-training reward function (only one in show in the paper right now)[line_break_token]- At least one more environments with significantly different dynamics, or an explanation of how the existing settings differ in qualitative terms.	B-Review	B-10	Review	706
[line_break_token]- A baseline employing some form of memory (such as heavy usage of frame stacking or recurrency), to attempt at figuring out whether it's really not reasonable to learn the whole problem simply using RL, with ablation of pre-training (which I suspect might make a significant difference).	B-Review	B-2	Review	706
[line_break_token][line_break_token]At this point, I cannot recommend the article for acceptance, but I'd be willing to change my rating if the authors were to address some of the above points.	O	O	Review	706
hank you for your helpful comments and suggestions.	O	O	Reply	706
We have updated the paper and made some general comments above.	O	O	Reply	706
We will now answer your specific concerns and suggestions.	O	O	Reply	706
[line_break_token][line_break_token]‚ÄúThe environments seem to be all fairly similar‚Ä¶would have been better to also present problems with fairly different settings (e.g. much different - sparser and/or denser - types of reward function)‚Äù: [line_break_token]We agree and have now included new experiments that explore different forms of pre-training (something that was possible to do in the rebuttal period), which adds to the diversity of experiments presented.	B-Reply	B-7	Reply	706
More generally, we are working to demonstrate our approach on a broader set of environments, which we hope to include in a future update of the paper.	I-Reply	I-7	Reply	706
[line_break_token][line_break_token]‚Äúa "RL Baseline" is mentioned in principle, however (1) it is unclear whether it was pre-trained similarly to the proposed methods‚Äù: [line_break_token]Pre-training was not used for the RL baseline, but the deep network structure and fine-tuning procedures were the same as our approach.	B-Reply	B-1	Reply	706
[line_break_token][line_break_token]‚Ä¶ ‚ÄúI would expect the same policy to be able to learn the same function given enough memory and training steps.	O	O	Reply	706
‚Äù: [line_break_token]‚ÄúA baseline employing some form of memory (such as heavy usage of frame stacking or recurrency), to attempt at figuring out whether it's really not reasonable to learn the whole problem simply using RL‚Äù[line_break_token]Our revised paper includes new experiments that ran the RL baseline for longer (Appendix H), and another experiment that gave the RL baseline more ‚Äúmemory‚Äù (Appendix I).	B-Reply	B-2	Reply	706
These show that the extra training did not help, except for the pushblock task where some limited performance was achieved, although still not as much as our methods.	I-Reply	I-2	Reply	706
See those appendices for figures and more analysis.	I-Reply	I-2	Reply	706
[line_break_token][line_break_token]For clarity, all methods already keep a state memory.	I-Reply	I-2	Reply	706
In all original experiments, the policy and hypothesis predictor get the last N=5 states.	I-Reply	I-2	Reply	706
In Appendix I we show that increasing N furtehr does not improve performance.	I-Reply	I-2	Reply	706
[line_break_token][line_break_token]Also, as mentioned to R1, and as we show in Appendix G: when we have an oracle hypothesis verification predictor, the RL baseline with its stacked observations can pretty easily solve the problem.	I-Reply	I-2	Reply	706
So we don‚Äôt believe that the use of memory stacking to sidestep the partial observability is the main difficulty of this problem.	I-Reply	I-2	Reply	706
[line_break_token][line_break_token]‚ÄúI'm confused by the way the authors decomposed the action space for the policy and the predictor in section 3.1.	O	O	Reply	706
Does the policy use ans_T and ans_F at any point during training?	O	O	Reply	706
Does the actor effectively decide (i.e. by choosing "ans") when to query the prediction network?‚Äù[line_break_token]We apologize for the confusion.	B-Reply	B-3	Reply	706
The policy does not use ans_T and ans_F, it has a single ans action which then lets the actor query the prediction network.	I-Reply	I-3	Reply	706
We will make this more clear on revision.	I-Reply	I-3	Reply	706
[line_break_token][line_break_token]‚ÄúBetter clarity on how the hypothesis setup stands to previous literature‚Äù... [line_break_token]‚ÄúIdeally, I would like to see some comparisons between this type of hypothesis and other decompositions used in previous literature, since it seems like the method exploits this particular structure quite heavily‚Äù: [line_break_token]As far as we are aware, ours is the first attempt to decompose a hypothesis in this fashion for the purposes of facilitating ML based approach, thus there is no previous literature with which a comparison can be made.	B-Reply	B-4	Reply	706
However, if R2 knows of any relevant works we would be most interested.	I-Reply	I-4	Reply	706
[line_break_token][line_break_token]As requested by R3, we have added new experiments to the paper that explores different forms of decomposition, by adjusting the type of intrinsic motivation used.	I-Reply	I-4	Reply	706
These experiments that the original form of factorization chosen is more effective than other types.	I-Reply	I-4	Reply	706
See Appendix F for figures and details.	I-Reply	I-4	Reply	706
[line_break_token][line_break_token]‚Äúthe usage of natural language overkill and not necessarily well justified‚Äù: [line_break_token]We agree that for the experiments reported, we could have used simpler symbolic representations.	B-Reply	B-5	Reply	706
 It is not clear that these would actually be more convenient, and they would be less general.	I-Reply	I-5	Reply	706
 More importantly, we choose templated language because we believe it is scalable in the sense that it allows extension to more complicated and richer hypotheses.	I-Reply	I-5	Reply	706
 In our view the combinatorial nature of the hypotheses is an important feature of our framing.	I-Reply	I-5	Reply	706
 [line_break_token][line_break_token]‚Äúconfused by how the pre-training is done‚Äù: [line_break_token]Apologies for the confusion.	B-Reply	B-6	Reply	706
We will make this clearer in the next revision.	I-Reply	I-6	Reply	706
When we use both pre and prepost reward functions (which we do on pushblock and crafting) they are added.	I-Reply	I-6	Reply	706
Your interpretation here was indeed correct	I-Reply	I-6	Reply	706

This paper proposed the concept of "property signatures" , which are learned to represent programs.	O	O	Review	88
The property signatures are essentially some key attributes that one may summarize from a given set of input-output pairs, which the target function has.	O	O	Review	88
Then a program can be generated by evaluating these property signatures vectors (which is simply a bag-of-word representation with only 0 or 1 as each element).	O	O	Review	88
Much discussions have been given to discuss why and how these properties may be useful and very little real experiments are conducted quantitatively compared with existing works.	O	O	Review	88
Although this paper is quite interesting, I think this paper is in its very early stage and there are a lot of serious concerns I have for using this approach to synthesize the real complex programs.	O	O	Review	88
[line_break_token][line_break_token]1) First of all, the notion of property signatures are easy to understand and is very natural.	B-Review	B-1	Review	88
Just like human beings, when we write a program, we first think about the possible attributes of this program may have given a set of input-output pairs for both correctness and completeness.	I-Review	I-1	Review	88
However, this is also the hard part of this idea.	I-Review	I-1	Review	88
Potentially it could have an exponential number of possible properties as the program goes more complex and complex.	I-Review	I-1	Review	88
It will quickly become computationally intractable problem.	I-Review	I-1	Review	88
[line_break_token][line_break_token]2) When I read the middle of paper, I would eager to know how authors can effectively find a good set of properties of a target program from a given input-output pairs.	B-Review	B-2	Review	88
However, when I eventually reached the Section 4, I was kindly disappointed since I did not see any effective and principle way to get them.	I-Review	I-2	Review	88
All I saw are "randomly sample and generate".	I-Review	I-2	Review	88
This may be Ok for a very simple program given a set of simple input-output pairs.	I-Review	I-2	Review	88
But it is definitely not feasible for any complex function, not to mention project.	I-Review	I-2	Review	88
I think this is the key for the proposed idea since how to construct a good set of property signatures is crucial to treat them as the inputs for any program synthesis task later.	I-Review	I-2	Review	88
[line_break_token][line_break_token]3) There are very little baselines to compare against even though authors listed "substantial prior work on program synthesis".	B-Review	B-3	Review	88
I understand the existing works may have their limitation in both what they can do and how well they can do.	I-Review	I-3	Review	88
But it is still important to compare with directly on the same set of benchmarks.	I-Review	I-3	Review	88
Otherwise, it is hard to be convincing that this approach is indeed superior compared to existing ones.	I-Review	I-3	Review	88
i and thanks again,[line_break_token][line_break_token]We've run a new experiment that we believe largely addresses your 3rd point.	B-Reply	B-3	Reply	88
[line_break_token]We wonder if, in light of this new experiment and our previous response (which addresses your 1st and 2nd points),[line_break_token]you might consider increasing your score slightly?	B-Reply	B-1	Reply	88
[line_break_token]In light of the other two reviews, a score of 1 seems perhaps a bit harsher than is warranted?	O	O	Reply	88
[line_break_token][line_break_token]Please let us know if there are any other questions we can answer.	O	O	Reply	88

The paper investigates to what degree Convolutional Neural Networks (CNNs) learn to encode positional information.	O	O	Review	20531
[line_break_token]Rather interesting finding is the not only they do encode this information, but that it is to a large degree function of the padding commonly used in the CNN architectures.	O	O	Review	20531
[line_break_token][line_break_token]The problem the paper is looking at is well motivated, the experiments are nicely designed and it includes comprehensive ablation study.	O	O	Review	20531
[line_break_token]Previous and related work seems to be well referenced.	O	O	Review	20531
[line_break_token]The main idea of introducing the PosENet to predict the gradient map is neat, and allows for interesting experiments (e.g. what layers most strongly encode the positional information).	O	O	Review	20531
[line_break_token][line_break_token]I really enjoyed the paper, the overall quality is high and does not seem to be rushed (no obvious typos or mistakes in the figures/tables).	O	O	Review	20531
[line_break_token]I believe this should be an accept.	O	O	Review	20531
[line_break_token][line_break_token]Q:[line_break_token]I can understand why you removed the pooling layers, but did you try to run some of your experiments with these as well?	B-Review	B-1	Review	20531
How were the numbers effected?	I-Review	I-1	Review	20531
e really appreciate your review and  we‚Äôre glad to hear you are pleased with the paper!	O	O	Reply	20531
[line_break_token][line_break_token]Please let us further clarify the implementation details.	B-Reply	B-1	Reply	20531
We did not remove any pooling layers except the last average pooling layer in the ResNet, which was designed to compress the output in order to feed to a Fully Connected (FC) layer.	I-Reply	I-1	Reply	20531
The pooling layers within each network (convolutional part, sometimes called backbone) have been retained because the weight was trained based on that structure design.	I-Reply	I-1	Reply	20531
It is commonplace to replace the FC layers with conv layers as in most dense labeling tasks.	I-Reply	I-1	Reply	20531

TLDR: split node embeddings into medatadata and graph structure, force them to be orthogonal.	O	O	Review	80
[line_break_token][line_break_token]The paper proposes to split node embeddings in a graph into two parts:[line_break_token]1.	O	O	Review	80
graph structure embeddings: Es[line_break_token]2.	O	O	Review	80
known node metadata embeddings: Em[line_break_token]To prevent Es from containing information about Em, the authors propose a scheme which puts Es into the Nullspace of Em through repeated SVD factorizations.	O	O	Review	80
This prevents linear classifiers that operate on Es to reliably predict information in Em.	O	O	Review	80
[line_break_token][line_break_token]The weakness of the paper stems from the proposed definition of debiasing.	B-Review	B-1	Review	80
Just like two random variables can be dependent, but have a linear correlation coefficient of 0, in the proposed method the two embeddings may be linearly unrelated, but have a strong non-linear relationship.	I-Review	I-1	Review	80
[line_break_token][line_break_token]This is an important caveat that should be highlighted in the papers' abstract, not burried deep on p4, under Theorem 2.	I-Review	I-1	Review	80
[line_break_token][line_break_token]In fact, looking at Fig 3c information about party affiliation follows a XOR-like pattern in the PCA space.	B-Review	B-3	Review	80
This means that a linear classifier will fail (indeed the linear SVM in Table 1 fails), but a non-linear one should work OK.	I-Review	I-3	Review	80
Thus, contrary to the abstract, the proposed method doesn't remove the effect of arbitrary covariates, but removes a LINEAR dependence.	I-Review	I-3	Review	80
[line_break_token][line_break_token]Thus the paper proposes to solve an important problem and proposes a partial solution, but overstates the results in the abstract and hides the true efficiency of the method.	I-Review	I-3	Review	80
[line_break_token][line_break_token]Action items ot correct the paper:[line_break_token]- be more honest about the true result.	B-Review	B-4	Review	80
Decorrelation does not imply independence.	I-Review	I-4	Review	80
[line_break_token]- redo Table 1 with strong non-linear classifiers such a Gaussian SVM or Random Forest to show how much is not filtered out by your linear decorrelation method[line_break_token][line_break_token]Finally, contrast with the adversarial information removal [1] and  the information bottleneck [2], both of which also promise to remove non-linear dependencies.	B-Review	B-2	Review	80
It may happen that the you method works better, even though it only guarantees no linear dependencies.	I-Review	I-2	Review	80
[line_break_token][line_break_token][1] <a href="https://arxiv.org/abs/1505.07818" target="_blank" rel="nofollow">https://arxiv.org/abs/1505.07818</a>[line_break_token][2] D. Moyer, S. Gao, R. Brekelmans, A. Galstyan, and G. Ver Steeg, ‚ÄúInvariant Representations without Adversarial Training,‚Äù in Advances in Neural Information Processing Systems 31, 2018[line_break_token][line_break_token]	O	O	Review	80
ortunately, we were able to implement an attribute adversary into our GloVe model using the framework in [1]. All references to adversarial learning work you gave (and others mentioned by other reviewers) are extremely relevant, and aim to solve closely related problems.	B-Reply	B-2	Reply	80
We discuss them in our related work section.	I-Reply	I-2	Reply	80
However, none of the associated models apply directly to our problem, unless one makes significant modifications (verging on novel work).	I-Reply	I-2	Reply	80
Therefore we decided to directly adapt a fundamental adversarial learner (from [1]) to our GloVe trainer.	I-Reply	I-2	Reply	80
To our knowledge, this is actually a novel (though naive and preliminary) incorporation of adversarial learning in unsupervised GNNs.	I-Reply	I-2	Reply	80
While by no means a mature and complete approach to the problem, we believe it helps shed light on how a comparable adversarial approach would work as an alternative to MONET.	I-Reply	I-2	Reply	80
The option to use the adversarial loss will be available in the code we are open sourcing as a reference implementation of the ideas discussed in the paper.	I-Reply	I-2	Reply	80
[line_break_token][line_break_token]Since our last update we have added a paragraph about the connection to adversarial networks in our Methods section (S 3.4).	I-Reply	I-2	Reply	80
We now describe our adversarial baseline in the beginning of the experiments section and more fully in the Appendix.	I-Reply	I-2	Reply	80
Note that the shilling experiment involves real-valued attributes, which requires a different type of adversarial network than that needed for the political blogs experiment.	I-Reply	I-2	Reply	80
We consider the development of multiple adversaries in our unsupervised setting beyond the scope of this paper, so we use the adversary baseline only for the first experiment.	I-Reply	I-2	Reply	80
[line_break_token][line_break_token][line_break_token][1] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio.	O	O	Reply	80
Generative adversarial nets.	O	O	Reply	80
In Advances in neural information processing systems, pages 2672‚Äì2680, 2014	O	O	Reply	80

In this work, the authors propose to transfer knowledge from a teacher model to a smaller student model with two variations:[line_break_token]1) knowledge is transferred by matching the feature vector before the softmax [line_break_token]2) the teacher is trained with an additional regularization term to make the feature vectors more dense within the same class.	O	O	Review	101
[line_break_token][line_break_token]This is a solid piece work that should be accepted.	O	O	Review	101
One question:[line_break_token]- Does the TF-baseline refer to student model trained with traditional cross-entropy knowledge transfer?	B-Review	B-1	Review	101
or the feature vector transfer?	I-Review	I-1	Review	101
If the latter, can you please have additional baseline numbers for student models trained with (standard) cross-entropy loss transfer?	I-Review	I-1	Review	101
[line_break_token][line_break_token]Minor comments:[line_break_token]- Citations: Should really cite Bucila et al 2006 for knowledge distillation and LeCun et al 1990 (Optimal Brain Damange) for model compression, as these predate some of the more recent work (Hinton 2015, Han 2016, Jaderberg 2014, etc.)	B-Review	B-2	Review	101
[line_break_token][line_break_token]- "Mimic learning": probably best just to stick to "knowledge distillation"	B-Review	B-3	Review	101
Thank you for your comment.	O	O	Reply	101
[line_break_token][line_break_token]Regarding your question, TF-baseline refers to student model trained with feature vector transfer.	B-Reply	B-1	Reply	101
We couldn't get the error rate go down below 9% by training a student model with traditional cross-entropy transfer (stated in your comment).	I-Reply	I-1	Reply	101
This is expected as previous works (Srivastava et al (2015) and Chen et al (2016)) indicated that the cross-entropy transfer strategy did not outperform baseline networks trained from scratch where baseline networks are sufficiently deep neural networks with strong regularizers such as batch-norm.	I-Reply	I-1	Reply	101
[line_break_token][line_break_token]We'll add suggested citations as well	B-Reply	B-2	Reply	101

This paper has studied the efficiency and stability of computing the Wasserstein metric through its dual formulation under weight clipping, gradient penalty, c-transform and (c- œµ)-transform.	O	O	Review	20554
The results show that (c- œµ)-transform and c-transform give more estimation of the Wasserstein distances than the gradient penalty and weight clipping methods in the given experiments, but the gradient penalty method produces more compelling samples in the generative setting.	O	O	Review	20554
[line_break_token][line_break_token]The paper is well written and the experiment section is extensive.	O	O	Review	20554
However, it is more like an extended experiment report to me which is very valuable but lacks sufficient technical novelty expected at ICLR.	B-Review	B-1	Review	20554
[line_break_token][line_break_token]Another comment is that when the authors mentioned "... are compared to ground truth values d_ground computed by POT", there needs more explanations on what that library actually does to compute the Wasserstein distance to make the paper self-contained, e.g. what exact algorithms it uses as there are also dozens of different algorithms implemented in that library.	B-Review	B-2	Review	20554
[line_break_token][line_break_token]In Section 3.1, the authors state that "it tends to converge within couple of iterations of the symmetric Sinkhorn-Knopp algorithm.	B-Review	B-3	Review	20554
For efficiency, we approximate these terms with one Sinkhorn-Knopp iteration".	I-Review	I-3	Review	20554
What is the extent of sacrifice in accuracy due to this approximation?	I-Review	I-3	Review	20554
The authors should provide more evidences to justify the approximation.	I-Review	I-3	Review	20554
hank you for pointing out where we could improve.	O	O	Reply	20554
Below, we will address those comments, for which the explanations will also be added to the paper.	O	O	Reply	20554
Furthermore, we give arguments to why we view the contribution as a fit for ICLR.	O	O	Reply	20554
[line_break_token][line_break_token]We utilize POT‚Äôs ot.emd method to compute the ordinary optimal transport quantity, which is implemented using the method in [1]. We apologize for not explaining which method is used in the entropic case, where the ot.sinkhorn method is utilized with the ‚Äòsinkhorn‚Äô option.	B-Reply	B-2	Reply	20554
[line_break_token][line_break_token]The sacrifice due to only applying one Sinkhorn-Knopp iteration for the unbiasing terms is slight, as can be seen from the resulting errors with respect to the ground truth in the experiments.	B-Reply	B-3	Reply	20554
[line_break_token][line_break_token][line_break_token]We view the main contributions of this paper to be the study of the approximation and estimation (stability) of the WGAN methods, which unfortunately has not been considered to its rightful extend in the literature yet.	B-Reply	B-1	Reply	20554
On the technical side, we are the first to consider the smooth c-transform in the WGAN setting, although it relates closely to [2], where the primal formulation of entropic optimal transport is considered.	I-Reply	I-1	Reply	20554
We are happy to hear that you consider the experimentation extensive.	I-Reply	I-1	Reply	20554
On top of new methodological contributions, it is important to also consider comparative studies to guide the development of new methodologies.	I-Reply	I-1	Reply	20554
For example, it is important to consider which functional classes the discriminator should belong to, which reflects on the representation part of ICLR.	I-Reply	I-1	Reply	20554
From our experiments, it seems that, when evaluating optimal transport quantities in the general setting (independent of generation), the-transform provides a meaningful class.	I-Reply	I-1	Reply	20554
In the generative setting the task gets more complicated due to the minimax nature of the game.	I-Reply	I-1	Reply	20554
[line_break_token][line_break_token][1] Bonneel, N., Van De Panne, M., Paris, S., &amp; Heidrich, W. (2011, December).	O	O	Reply	20554
Displacement interpolation using Lagrangian mass transport.	O	O	Reply	20554
In&nbsp;ACM Transactions on Graphics (TOG)&nbsp;(Vol.	O	O	Reply	20554
30, No.	O	O	Reply	20554
6, p. 158).	O	O	Reply	20554
ACM.	O	O	Reply	20554
[line_break_token][line_break_token][2] Genevay, A., Peyre, G. &amp; Cuturi, M.. (2018).	O	O	Reply	20554
Learning Generative Models with Sinkhorn Divergences.	O	O	Reply	20554
Proceedings of the Twenty-F	O	O	Reply	20554

This paper introduced a linear interpolation method that could be applied to the latent space of a generative model.	O	O	Review	464
 With their method, interpolating instances generated by those generative models all maintain high quality in terms of the realism index they proposed.	O	O	Review	464
[line_break_token][line_break_token]This paper first introduced the quantity realism index, which is a measure of how well a generated instance in the latent space is fitted to the ground truth manifold of the data space.	O	O	Review	464
The definition of realism index is the probability measure of the sublevel set of some f (f:latent -&gt; R+) function threshold by the f(z) for some z. f(z) could be the density function of feature in the latent space.	O	O	Review	464
[line_break_token][line_break_token]There are two types of realism index which has analytic form introduced in this paper.	O	O	Review	464
The one based on normal density.	O	O	Review	464
Another is based on Frechet inception distance.	O	O	Review	464
If the density of latent feature is normal, normal density based index is used and it could be approximated with a analytic form; while if the density is not accessible, then f is the gaussian density of certain transformation of features in the latent space.	O	O	Review	464
[line_break_token][line_break_token]If an arbitrary f is used, a kernel density estimator is used to estimate the density of log(f).	O	O	Review	464
After the realism index is introduced, the optimal interpolation  is the one has the highest cumulative realism index along the interpolation curve.	O	O	Review	464
[line_break_token][line_break_token]To optimize, a linear interpolation is used as initialization.	O	O	Review	464
All the intermediate results are updated iteratively.	O	O	Review	464
[line_break_token][line_break_token]Results show better interpolation than linear ones.	B-Review	B-1	Review	464
But not many baselines are available.	I-Review	I-1	Review	464
[line_break_token][line_break_token]Overall, I think the problem is very interesting and important.	O	O	Review	464
The results seem reasonable although only beating an obviously flawed baseline.	O	O	Review	464
[line_break_token][line_break_token]Typo in Equation (3): w-&gt;s?	O	O	Review	464
[line_break_token][line_break_token]-----------------[line_break_token][line_break_token]After reading rebuttal and other reviews, I agree that quantitative results is crucially missing especially when the proposed method involves proposing an optimization method to find the best geodesic.	B-Review	B-3	Review	464
I think the authors should find a reasonable model that can at least show the proposed geodesic is better than a linear interpolation in the accumulated realism score.	I-Review	I-3	Review	464
Also some quantitative evaluation of the proposed optimization scheme will be very helpful.	I-Review	I-3	Review	464
hank you for reviewing our work!	O	O	Reply	464
We believe that Equation (3) is correct, although the notation used there was not explained clearly enough.	B-Reply	B-2	Reply	464
The letter ‚Äúw‚Äù in this Equation is only used to define the set over which we are integrating.	I-Reply	I-2	Reply	464
We are grateful to the reviewer for pointing out this issue, and we will update the paper to address it	I-Reply	B-2	Reply	464

This paper proposes applying random convolutions to the observation space to improve the ability of deep RL agents to generalize to unseen environments.	O	O	Review	790
To encourage the learning of invariant features, the authors further include a loss term to align features of perturbed and unperturbed observations.	O	O	Review	790
Thorough experiments on multiple generalization benchmarks show that this method outperforms many previously used regularization and data augmentation techniques.	O	O	Review	790
[line_break_token][line_break_token]Although the proposed method is simple, it represents a useful contribution.	B-Review	B-5	Review	790
The need to generalize across low level transformations in the observation space features prominently in several environments, including DeepMind Lab and CoinRun.	O	O	Review	790
The clear need for agents to be invariant to these low level transformations well motivates the proposed approach, as does the failure of many existing methods to provide this invariance.	O	O	Review	790
[line_break_token][line_break_token]The authors could more explicitly discuss the main drawbacks of this approach.	B-Review	B-1	Review	790
As with any data augmentation, there is an assumption that the applied transformation generally won‚Äôt destroy information pertinent to the task.	I-Review	I-1	Review	790
While this is true for the MDPs investigated here, it is easy to imagine slight variants of these MDPs for which this approach would fail.	I-Review	I-1	Review	790
If an optimal policy must condition on color or texture information from observations, then using these random convolutions would render training impossible.	I-Review	I-1	Review	790
Encountering such MDPs is not farfetched, so this weakness seems worth acknowledging.	I-Review	I-1	Review	790
[line_break_token][line_break_token]In Figure 5 it would be useful to visualize performance of an agent trained directly on these unseen environments, as this presumably serves as an upper bound for the zero-shot performance of ‚ÄúPPO + ours‚Äù.	B-Review	B-2	Review	790
How close does ‚ÄúPPO + ours‚Äù come to closing this gap?	I-Review	I-2	Review	790
Without any context on the reward scale, it‚Äôs hard to infer how well this method is generalizing, beyond seeing that it beats some (possibly weak) baselines.	I-Review	I-2	Review	790
Admittedly some closely related curves can be found in Appendix Figures 9 and 14, though they‚Äôre a bit out of the way.	I-Review	I-2	Review	790
[line_break_token][line_break_token]Section 3.1 mentions that using alpha = 0 complicates training.	B-Review	B-3	Review	790
It is somewhat surprising that using alpha &gt; 0 is necessary or significant and yet the value used (alpha = .1) is relatively small.	O	O	Review	790
Any further comments on this choice?	B-Review	B-3	Review	790
[line_break_token][line_break_token]I appreciate the discussion in Appendix F. It‚Äôs natural to wonder about alternative injection sites for the random network, and it‚Äôs good to see how the proposed method compares to these alternatives.	B-Review	B-4	Review	790
[line_break_token]	O	O	Review	790
e appreciate your valuable comments, efforts and times on our paper.	O	O	Reply	790
As you and R3 mentioned, we introduce a simple, yet powerful solution for generalization in deep RL, and show that it achieves significant performance gains in comparison to many known regularization and data augmentation techniques in various environments.	B-Reply	B-5	Reply	790
Our responses to all your questions are provided below.	O	O	Reply	790
Revised parts in the new draft are colored by red (in particular, we updated Section 3, 4 and 5, Appendix A, L, M, and N, and Figure 5, 7, 16, and 17).	O	O	Reply	790
[line_break_token][line_break_token]Q1.	O	O	Reply	790
Handling potential failure case of our methods[line_break_token][line_break_token]A1.	O	O	Reply	790
Thank you for the suggestion to acknowledge the failure cases of our method.	B-Reply	B-1	Reply	790
As you pointed out, some color (or texture)-conditioned RL tasks can be difficult for our methods to work.	I-Reply	I-1	Reply	790
For example, consider an extreme seek-avoid object gathering setup, where the agent must learn to collect good objects and avoid bad objects which have the same shape but different colors.	I-Reply	I-1	Reply	790
However, we remark that our method would not always fail for such tasks if other environmental factors (e.g., the shape of objects in Collect Good Objects in DeepMind Lab [1]) are available to distinguish them.	I-Reply	I-1	Reply	790
As shown in Appendix M of the revised draft, our method can perform well on the modified CoinRun environment with good and bad coins by capturing the other factors such as the location of coins to perform this task.	I-Reply	I-1	Reply	790
As another example, consider color-matching tasks such as the keys doors puzzle in DeepMind Lab [1] where the agent must collect colored keys to open matching doors.	I-Reply	I-1	Reply	790
Even though this task is color-conditioned, a policy trained with our method can perform well because the same colored objects will have the same color value even after randomization, i.e., our randomization method still maintains the structure of input observation.	I-Reply	I-1	Reply	790
Finally, we remark that our method can handle such corner cases by adjusting the fraction of clean samples during training  on page 4, in the paragraph "Details of the random networks.").	I-Reply	I-1	Reply	790
In summary, we believe that the proposed method covers a broad scope of generalization across low-level transformations in the observation space features as you mentioned.	I-Reply	I-1	Reply	790
We added related discussions in Section 5 and Appendix M of the revised draft.	I-Reply	I-1	Reply	790
[line_break_token][line_break_token]Q2. ‚	O	O	Reply	790
ÄúOptimal‚Äù performance (i.e. upper bound) [line_break_token][line_break_token]A2.	O	O	Reply	790
Following your suggestion, we included the performance of an agent trained directly on unseen environments to Figure 5 and 7of the revised draft.	B-Reply	B-2	Reply	790
In summary, our method approaches this hypothetical upper bound performance.	I-Reply	I-2	Reply	790
[line_break_token][line_break_token]Q3.	O	O	Reply	790
The choice of[line_break_token][line_break_token]A3.	O	O	Reply	790
We would like to clarify that the chosen fraction of clean samples is set empirically based on controlled experiments.	B-Reply	B-3	Reply	790
To support this, we added controlled experimental results by varying the fraction of clean samples in Figure 17(d) of the revised draft.	I-Reply	I-3	Reply	790
[line_break_token][line_break_token][1] Charles Beattie et al Deepmind lab.	O	O	Reply	790
arXiv preprint arXiv:1612.03801, 2016.	O	O	Reply	790

Paper summary: This paper proposes a new normalization technique specially designed for settings with small mini-batch sizes (where previous methods like BatchNorm are known to suffer).	O	O	Review	20594
The approach aggregates mean/variance statistics from previous iterations, weighted based on the Taylor expansion, to get a better estimate of population statistics.	O	O	Review	20594
The authors evaluate their approach on ImageNet classification, and object detection and instance segmentation on the COCO dataset.	O	O	Review	20594
[line_break_token][line_break_token][line_break_token][line_break_token]The paper is clearly written and explores an interesting idea---aggregating mini-batch statistics across iterations.	O	O	Review	20594
That being said, I am not convinced by the utility of the proposed approach since it doesn‚Äôt offer over significant benefits over prior approaches designed for the small mini-batch setting (e.g., Group Normalization)---either in terms of empirical performance, implementation complexity, or lower computational/memory requirements.	O	O	Review	20594
[line_break_token][line_break_token]Specific comments/questions:[line_break_token][line_break_token]1.	O	O	Review	20594
Why do the authors not include the Kalman Normalization baseline in the paper?	B-Review	B-1	Review	20594
Based on my understanding, it is also designed for the low-sample regime (and the original paper also conducts experiments on ImageNet/COCO).	I-Review	I-1	Review	20594
Also the BRN baseline is included in Table 3 for ImageNet but is missing from the COCO experiments.	I-Review	I-1	Review	20594
It is important to thoroughly compare to other normalization techniques specifically designed for this regime to clearly highlight relative benefits of the proposed approach.	I-Review	I-1	Review	20594
[line_break_token][line_break_token]2.	O	O	Review	20594
The authors mention that they average performance across 5 trials but omit confidence intervals in their Figures/Tables.	B-Review	B-2	Review	20594
Since the difference in performance between the different approaches compared is small, I think confidence intervals should be reported to see whether improvements are within statistical error margins.	I-Review	I-2	Review	20594
In fact, for CIFAR-10 based on Table 7 in the Appendix, performance of batch renormalization, group normalization and CBN is essentially the same.	I-Review	I-2	Review	20594
[line_break_token][line_break_token]3.	O	O	Review	20594
In Table 3, how many iterations was the BRN aggregation performed over?	B-Review	B-3	Review	20594
Was it also chosen to ensure effective number of samples was not less than 16 (like CBN).	I-Review	I-3	Review	20594
What do Figures 3 and 4 look like for BRN?	I-Review	I-3	Review	20594
[line_break_token][line_break_token]4.	O	O	Review	20594
One thing I find interesting (the authors do not discuss this specifically) about Figure 5 in the Appendix is that both for CIFAR and COCO (the two datasets for which plots are provided), CBN helps as long as it is used before the final learning rate drop.	B-Review	B-4	Review	20594
Specifically, choosing a burn-in period as large as 120 for CIFAR and 8 for COCO is fine (in fact, probably the best) as long as you turn on CBN before the final learning rate drop.	I-Review	I-4	Review	20594
This makes me curious whether BN in the low-sample regime only suffers in terms of generalization performance in the final stages of training (compared to low-sample alternatives like GN/CBN, etc).	I-Review	I-4	Review	20594
[line_break_token][line_break_token][line_break_token][line_break_token]The authors should include other recent benchmarks (Kalman normalization and BRN in the omitted Tables) and error bars to make the change in performance clearer.	B-Review	B-5	Review	20594
It would also be interesting to see whether (and probably make the paper stronger if) alternatives like GN/KN benefit from being combined with the proposed scheme to aggregate statistics over time.	I-Review	I-5	Review	20594
[line_break_token][line_break_token]Overall, while the proposed approach is novel, its performance is comparable to prior approaches, with the disadvantage of an additional computational/memory footprint.	B-Review	B-6	Review	20594
Thus, I am not yet convinced about how useful/interesting this approach would be to the community.	I-Review	I-6	Review	20594
[line_break_token]	O	O	Review	20594
e thank the reviewer for the careful reviews and constructive suggestions.	O	O	Reply	20594
We feel we can well address the concerns of R#1, and hope R#1 give a second thought about the paper.	O	O	Reply	20594
[line_break_token][line_break_token]1.	O	O	Reply	20594
We present our experimental results with BRN as follows:[line_break_token]|         Method         | ImageNet-Top1(%) | COCO-mAP_bbox |[line_break_token]|-------------------------|---------------------------|-------------------------|[line_break_token]| BN-bs16/syncBN |               70.2             |             37.7             |[line_break_token]| BN-bs1                  |               65.1             |             36.3             |[line_break_token]| BRN                       |               67.9             |             37.5             |[line_break_token]| GN                         |               69.0             |             37.8             |[line_break_token]| CBN                       |               69.8             |             37.7             |[line_break_token]For KN, we tried our best to re-implement it and also asked the author for help, but failed to reproduce the result without a response from the author.	B-Reply	B-1	Reply	20594
[line_break_token][line_break_token]2.	O	O	Reply	20594
As mentioned in the paper, the variance between different trials is negligible for both ImageNet and COCO.	B-Reply	B-2	Reply	20594
For CIFAR-10, we show the error bar in Table 7 of the Appendix.	I-Reply	I-2	Reply	20594
[line_break_token][line_break_token]3.	O	O	Reply	20594
For BRN, the statistics are updated in a "moving" policy.	B-Reply	B-3	Reply	20594
So there is no parameter similar to ‚Äúaggregation iteration‚Äù.	I-Reply	I-3	Reply	20594
[line_break_token][line_break_token]4.	O	O	Reply	20594
Many thanks to the reviewer for sharing this interesting perspective.	B-Reply	B-4	Reply	20594
To perform this further exploration, we design a new ablation experiment to remove other influences: we first train the model on COCO with standard BN and a small batch size, then switch BN to syncBN (the learning rate will be divided by 10 at epoch-9 and epoch-11).	I-Reply	I-4	Reply	20594
We present the experimental results as follows:[line_break_token]| Resume Epoch | Epoch-8  | Epoch-9  | Epoch-10 | Epoch-11 |[line_break_token]|----------------------|-------------|-------------|---------------|--------------|[line_break_token]| mAP_bbox         |     37.7    |     37.7     |      37.6      |      37.3     |[line_break_token][line_break_token]Interestingly, as mentioned by the reviewer, BN in the low-sample regime only hurts the generalization performance in the final stage after the learning rate drops.	I-Reply	I-4	Reply	20594
We leave this as a direction for future study.	I-Reply	I-4	Reply	20594
[line_break_token][line_break_token]The major concern on ‚Äúhow useful/interesting this approach would be to the community‚Äù is addressed in the comment to all reviewers, please check it.	B-Reply	B-6	Reply	20594
Thanks!	I-Reply	I-6	Reply	20594
[line_break_token][line_break_token]We hope that your concerns are addressed.	O	O	Reply	20594

Cons[line_break_token][line_break_token]1.	O	O	Review	484
[tab_token]It‚Äôs unclear why LABC produces lower scores than ‚Äònormal‚Äô training on ‚Äònormal‚Äô testing.	B-Review	B-2	Review	484
[line_break_token]2.	O	O	Review	484
[tab_token]The text says nothing I can find to explain why in Fig 5 the ‚Äòentity‚Äô vectors have all 0s except in one dimension, which seems to make the problem considerably easier.	B-Review	B-5	Review	484
[line_break_token]3.	B-Review	B-1	Review	484
[tab_token]In a sense, there is no cross-domain adaptation required in the symbolic task: min is min, whether it operates on dimension k of the source vectors or dimension j of the target vectors.	B-Review	B-3	Review	484
On the other hand, dimensions are processed independently in the model, as far as I can tell, so there‚Äôs no free transfer of learning min on dimension k to knowing min on dimension j. It would be good to comment on this issue.	I-Review	I-3	Review	484
[line_break_token]4.	O	O	Review	484
[tab_token]There seem to be obvious analogies (so to speak) to GANs, and it is very curious that this is not mentioned anywhere that I can see.	B-Review	B-1	Review	484
This is particularly glaring in Sec.	I-Review	I-1	Review	484
5.3.	I-Review	I-1	Review	484
[line_break_token]5.	I-Review	I-1	Review	484
[tab_token]The quantitative results are scattered throughout the prose; it would be challenging, but worthwhile, to gather them into an actual table.	B-Review	B-4	Review	484
[line_break_token][line_break_token]Pros[line_break_token][line_break_token]6.	O	O	Review	484
[tab_token]The basic idea (‚ÄúWe should aspire to select as negative examples those examples that are plausible considering the most abstract principles that describe the data‚Äù, p. 14) is very intuitive, common-sensical, bordering on obvious.	O	O	Review	484
But it is not at all obvious that the idea has as much power as is demonstrated in the experiments.	O	O	Review	484
The transfer to novel domain combinations, novel domains, and novel values of dimensions is impressive and surprising.	O	O	Review	484
[line_break_token]7.	O	O	Review	484
[tab_token]The result that the proposed training, designed to promote generalization on analogy tasks, also seems to promote improved sensory processing is interesting.	O	O	Review	484
Whether it really instantiates the parallel connection argued for by the High-Level Perception view from psychology/philosophy is debatable, but that is itself an interesting connection that the authors should be praised for identifying.	O	O	Review	484
[line_break_token]8.	O	O	Review	484
[tab_token]In general, the connection to the cognitive literature is creative and tantalizing and provides good scientific grounding for the work.	O	O	Review	484
[line_break_token]9.	O	O	Review	484
[tab_token]The linking to the flexibility of word meanings in the final paragraph pushes the limit of the plausibility of connection to broader cognitive issues, but I‚Äôm inclined to indulge the authors for at least bringing up this important and relevant issue.	O	O	Review	484
 [line_break_token]	B-Review	B-1	Review	484
Dear Reviewer Three,[line_break_token][line_break_token]Thank you for your review and very helpful comments.. We note that your principal concerns involved the clarity of exposition of our symbolic experiments and results, our failure to reference GANs and a query (also raised by Reviewer 1) about testing models that were trained using LABC in the 'normal' training condition.	O	O	Reply	484
To address these concerns, we have: [line_break_token][line_break_token]1.	O	O	Reply	484
Added a discussion of the connection between learning by contrasting and GANs in section 5.3 [line_break_token]Clarified the symbolic analogy domain by comprehensively re-writing parts of Section 5 and synthesizing the results in Table 3 (see also our previous response).	B-Reply	B-1	Reply	484
[line_break_token][line_break_token]2.	O	O	Reply	484
Conducted a comparison (see Table 1) that demonstrates clearly the advantage of training with LABC in cases where we do not know in advance whether test questions will involve semantically (and perceptually)-plausible incorrect answers or merely perceptually-plausible answers.	B-Reply	B-2	Reply	484
See also our response to Reviewer 1 in relation to this.	I-Reply	I-2	Reply	484
[line_break_token][line_break_token]3.	B-Reply	B-4	Reply	484
Added a schematic Figure 1, and re-written Section 3.1 to clarify how analogy problems can be constructed with candidate answers that require the problems to be understood at different degrees of abstract relational structure.	I-Reply	I-4	Reply	484
[line_break_token]Added Table 2 (new data) and Table 3 (previously found in main text) to collect quantitative results easier to digest for the reader.	I-Reply	I-4	Reply	484
[line_break_token][line_break_token]We also draw your attention to the new finding reported in Table 1 that the LABC effect seems to hold for a wide range of well-known visual reasoning neural network architectures, and also the new appendix 7 showing a selection of correct and incorrect test answers given by a model trained with LABC, which gives the reader a better sense of the scope and difficulty of the dataset.	B-Reply	B-2	Reply	484
[line_break_token][line_break_token]Thanks to your input, we have been able to substantially improve the paper, and hope that you can reevaluate it in light of these extra contributions.	O	O	Reply	484

Summary:[line_break_token]The paper describes a noisy channel approach for document-level translation, which does not rely on parallel documents to train.	O	O	Review	20288
The approach relies on a sentence-level translation model (from target-to-source languages) and a document level language model (on target language), each is trained separately.	O	O	Review	20288
For decoding, the paper relies on another proposal model (i.e., a sentence level translation model from source to target) and performs beam-search weighted by a linear combination of the scores of all three models.	O	O	Review	20288
Experiments show strong results on two standard translation benchmarks.	O	O	Review	20288
[line_break_token][line_break_token]Comments:[line_break_token]-  The proposed approach is strongly based on the neural noisy channel model of Yu et al 2017 but mainly extends it to context aware translation.	B-Review	B-1	Review	20288
While the paper is referenced, I believe more emphasis should be put on the differences of the proposed approach[line_break_token]-  It seems that the Document Transformer uses parallel-documents to train, so I am wondering if you can still claim that your approach does not require parallel documents.	B-Review	B-2	Review	20288
[line_break_token]-  In general, I think the paper is well written and results are compelling.	O	O	Review	20288
[line_break_token]	O	O	Review	20288
hank you for your review.	O	O	Reply	20288
[line_break_token][line_break_token]Regarding the differences to Yu et al 2017.	B-Reply	B-1	Reply	20288
While both papers indeed use a noisy channel decomposition, the novelty in this paper is the theoretical justification for training a model using only parallel sentences and monolingual documents, and then using it to infer document translations (an important task!).	I-Reply	I-1	Reply	20288
This asymmetry in available data is exactly the situation that exists in the world today, and our model, which addresses it directly and elegantly, will undoubtedly be of general interest.	I-Reply	I-1	Reply	20288
Moreover, while the Yu et al 2017 model could be used on documents by concatenating their sentences to form a single long sequence, this would not let us use the conditional sentence independence assumptions that gives our model the flexibility to use just parallel sentences.	I-Reply	I-1	Reply	20288
Secondarily, the Yu et al inference algorithm is specialized to their channel model, and it has a quadratic (in the length of the sentence) complexity, which would be prohibitive for sequences longer than a single sentence; in practice our inference technique is much faster.	I-Reply	I-1	Reply	20288
We will clarify these differences in the paper.	I-Reply	I-1	Reply	20288
[line_break_token][line_break_token]Regarding whether our approach really needs parallel documents.	B-Reply	B-2	Reply	20288
First, there are two models in this paper- the joint translation model and proposal model we use to do inference.	I-Reply	I-2	Reply	20288
The joint translation model is only ever trained using parallel sentences.	I-Reply	I-2	Reply	20288
For inference, we use a proposal model that approximates the posterior, and we compare two variants: one that is trained using just parallel sentences (effectively, we assume independence between translations given the source document) and one that is trained with document context (see Table 2).	I-Reply	I-2	Reply	20288
As predicted, a proposal model that more closely matches the true posterior (i.e., the one with document context) is more effective than one that is less accurate (no document context), but the crucial result is that in both cases, document information has a positive impact on the performance of the system.	I-Reply	I-2	Reply	20288
The secondary result is that search is a hard problem, and while usable approximations exist, this is an important open question.	I-Reply	I-2	Reply	20288
We will clarify this	I-Reply	I-2	Reply	20288

I have read the author response, thank you for responding.	O	O	Review	20695
[line_break_token][line_break_token]Original review:[line_break_token]This paper presents the extraction of a bibliographic database of Chinese technical papers.	O	O	Review	20695
 This database could potentially be a valuable resource for the community.	O	O	Review	20695
 However, the paper is mis-targeted to the ICLR conference, as it does not discuss learning representations or using deep learning (the 36-page appendix does include some material on knowledge graph embedding, but this is not covered in the main body of the paper).	B-Review	B-1	Review	20695
 Also, for important tasks like name deduplication, the paper does not discuss or compare against techniques from previous work, and instead proposes a small set of heuristics, which is a sensible approach for building a resource but will not be of interest to the ICLR audience.	B-Review	B-2	Review	20695
[line_break_token][line_break_token]The paper refers to their resource as a knowledge graph, but I would say it is more accurate to call it a bibliographic database (it consists primarily of paper titles, authors, and keywords).	B-Review	B-3	Review	20695
 This is very different from the broader KBs and KGs discussed in the related work.	I-Review	I-3	Review	20695
 YAGO, Freebase, Cyc, and so on capture a much wider variety of semantic relationships and entity types.	I-Review	I-3	Review	20695
 I think re-positioning this submission as being aimed at building a bibliographic database, rather than a Knowledge Graph, would help ensure it reaches the right audience.	I-Review	I-3	Review	20695
 Also, targeting a different venue like a digital libraries conference and making a strong case that this set of bibliographic data offers advantages in coverage or accuracy over other comparable resources, if any, would help.	I-Review	I-3	Review	20695
[line_break_token][line_break_token]Finally, one of the most valuable features of a bibliographic database is the citation graph, it would be exciting if TechKG could be extended to include citation information.	B-Review	B-4	Review	20695
[line_break_token][line_break_token]Minor:[line_break_token]Section 2, most of these citations should not be shortcites but should be regular full cites.	B-Review	B-5	Review	20695
 For example in the first paragraph, Miller (1995) should be (Miller, 1995).	O	O	Review	20695
[line_break_token]	O	O	Review	20695
e would like to thank the reviewer for the thorough and valuable feedback for the manuscript.	O	O	Reply	20695
But we want to clarify some misunderstandings of our paper.	O	O	Reply	20695
[line_break_token][line_break_token]1.We claim in our paper that TechKG is a new Chinese KG and it can be used as a dataset for many diverse AI-related applications.	B-Reply	B-1	Reply	20695
In our primpary experiments in the appendix part, we use three completely different applications to show  the adaptability of TechKG.	I-Reply	I-1	Reply	20695
All of these applications are related to deep learning.	I-Reply	I-1	Reply	20695
Especially, the "knowledge graph embedding" application is directly related to representation learning.	I-Reply	I-1	Reply	20695
So we think that our paper matches the scope of ICLR well.	I-Reply	I-1	Reply	20695
[line_break_token][line_break_token]2. "	O	O	Reply	20695
name deduplication" is not an important task in TechKG, instead, it is just one of the important characteristics in TechKG (section 4, page 5).	B-Reply	B-2	Reply	20695
Totally, there are three important characteristics that make TechKG be a more challenging dataset for many applications.	I-Reply	I-2	Reply	20695
For example, in the "knowledge graph embedding" application, the ConvE model, one of the state-of-the-art method, achieves very poor results.	I-Reply	I-2	Reply	20695
We analyzed the reason in page14.	I-Reply	I-2	Reply	20695
[line_break_token][line_break_token]3.	O	O	Reply	20695
The comment that "This is very different from the broader KBs and KGs discussed in the related work. "	B-Reply	B-3	Reply	20695
is right.	I-Reply	I-3	Reply	20695
In Table 8 (page 8) of our paper, we compare the differences between different KGs.	I-Reply	I-3	Reply	20695
TechKG is a very different KG compared with current existing KGs mainly due to the following two reason.	I-Reply	I-3	Reply	20695
First, TechKG is technology-oriented KG, while other KGs are general purpose.	I-Reply	I-3	Reply	20695
Second, TechKG takes technical papers as data source, while most of other KGs take Wikipedia as datasource.	I-Reply	I-3	Reply	20695
Because of these two reasons, both the semantic relationships and the entity types are proper in TechKG.	I-Reply	I-3	Reply	20695
[line_break_token][line_break_token]4.	B-Reply	B-2	Reply	20695
TechKG is a completely different KGs and it provides a new choice for lots of applications: the AI-related applications are diverse, thus there should be diverse datasets.	B-Reply	B-4	Reply	20695
Besides, a lot of new characteristics hierent in TechKG raise new challenges for many existing methods. (	I-Reply	I-4	Reply	20695
page 10, "conclusion" section	I-Reply	I-4	Reply	20695

This paper provides new generalization bounds for deep neural networks using the PAC-Bayesian framework.	O	O	Review	367
Recent efforts along these lines have proved bounds that [line_break_token]either apply to a classifier drawn from a distribution or to a compressed form of the trained classifier.	O	O	Review	367
In contrast, the paper uses PAC Bayesian bounds to [line_break_token]provide generalization bounds for the original trained network.	O	O	Review	367
At this same time, the goal is to provide bounds that do not scale exponentially in the depth of the[line_break_token]network and depend on more nuanced parameters such as the noise-stability of the network.	B-Review	B-1	Review	367
In order to do that the paper formalizes properties that a classifier must [line_break_token]satisfy on the training data.	I-Review	I-1	Review	367
While these are a little difficult to understand in general, in the context of ReLU networks these boil down to bounding the l2-norms[line_break_token]of the Jacobian and the hidden layer outputs on each data point.	I-Review	I-1	Review	367
Additionally, the paper also requires the pre-activations to be sufficiently large, which as the authors [line_break_token]acknowledge, is an unrealistic assumption that is not true in practice.	B-Review	B-2	Review	367
Despite that, the paper makes an important contribution towards our current understanding of [line_break_token]generalization of deep nets.	I-Review	I-2	Review	367
It would have been helpful if the authors had a more detailed discussion on how their assumptions relate to the specific assumptions in the papers[line_break_token]of Arora et al and Neyshabur et al This would help when comparing the results of the paper with existing ones.	B-Review	B-3	Review	367
Dear Reviewer,[line_break_token][line_break_token]Thanks for your positive feedback!	O	O	Reply	367
[line_break_token][line_break_token]We have uploaded a revised version with Appendix G where we have added a one-page discussion relating our noise-resilience conditions and the conditions in prior work.	B-Reply	B-1	Reply	367
We hope this provides you better context to understand our assumptions.	O	O	Reply	367
Happy to provide more details if needed.	O	O	Reply	367
[line_break_token]	O	O	Reply	367

- Does the paper present substantively new ideas or explore an under explored or highly novel[line_break_token]question?	O	O	Review	1381
[line_break_token][line_break_token]Yes, the paper combines two frameworks (Imitation Learning and Model Base[line_break_token]Reinforcement Learning) to incorporate target information while fitting to	O	O	Review	1381
Thank you for your helpful feedback.	O	O	Reply	1381
[line_break_token][line_break_token]Q1: ‚ÄúThe authors do not address the problem of IL when the stochasticity in the environment and/or model results in trajectories outside of expert‚Äôs distribution.	O	O	Reply	1381
‚Äù[line_break_token]A1: In our original submission, we evaluated our model‚Äôs ability to control the agent in a held out test scene (Town02).	O	O	Reply	1381
This demonstrated our model‚Äôs ability to generalize its behavior beyond the behaviors observed in the data.	O	O	Reply	1381
As further evidence of generalization, we performed additional experiments designed to force the model to produce trajectories outside of the distribution of observed trajectories.	O	O	Reply	1381
In one, we added simulated potholes to the scene, which we modelled with a cost map.	O	O	Reply	1381
This forced our planning to produce trajectories that avoid the potholes.	O	O	Reply	1381
We found that the model could still complete most of its episodes, while avoiding most potholes, despite the fact that the agent was forced into situations not seen in the training data.	O	O	Reply	1381
Please see the revised paper for these results.	O	O	Reply	1381
[line_break_token][line_break_token]Q2: ‚Äúthe experiments only compare the proposed algorithm to its components, namely proportional controller, IL only controller and Model Basel RL only controller.	O	O	Reply	1381
‚Äù [line_break_token]A2: We agree that relevant comparison is important.	O	O	Reply	1381
Our current IL comparison is not an ablation of our method, but rather a comparison to prior offline IL work.	O	O	Reply	1381
It most closely resembles the method of Codevilla, et al "End-to-end driving via conditional imitation learning."	O	O	Reply	1381
ICRA, 2018.	O	O	Reply	1381
However, this prior method uses categorical command prediction, "turn left/turn right/go straight", for a learned lower-level controller, whereas our variant of this method regresses setpoints provided to a PID controller.	O	O	Reply	1381
We did not make the connection clear in the original paper, which we will fix.	O	O	Reply	1381
[line_break_token]We also conducted additional experiments against the state-of-the-art with the ‚Äúbranched‚Äù network of Codevilla, et al 2018, which we include in our revised comparison.	O	O	Reply	1381
We found this approach to slightly outperform the original IL baseline we included in our paper, but still underperform the MBRL method and our proposed method.	O	O	Reply	1381
Please see the updated paper for our quantitative comparison.	O	O	Reply	1381
[line_break_token][line_break_token]Q3: ‚Äúthe paper does not provide any detail on the training procedure (Network architecture, cost function, etc), which makes results hard to reproduce‚Äù[line_break_token]A3: In our updated version, we have simplified our explanation and expanded on additional details, including network architecture, cost function, etc.	O	O	Reply	1381
Please see Section 2.2 in the updated paper	O	O	Reply	1381

The paper proposes to learn a custom translation or rotation invariant kernel in the Fourier representation to maximize the margin of SVM.	O	O	Review	309
Instead of using Monte Carlo approximation as in the traditional random features literature, the main point of the paper is to learn these Fourier features in a min-max sense.	O	O	Review	309
This perspective leads to some interesting theoretical results and some new interpretation.	O	O	Review	309
Synthetic and some simple real-world experiments demonstrate the effectiveness of the algorithm compared to random features given the fix number of bases.	O	O	Review	309
[line_break_token][line_break_token]I like the idea of trying to formulate the feature learning problem as a two-player min-max game and its connection to boosting.	O	O	Review	309
As for the related work, it seems the authors have missed some very relevant pieces of work in learning these Fourier features through gradient descent [1, 2]. It would be interesting to compare these algorithms as well.	B-Review	B-1	Review	309
[line_break_token][line_break_token][1] Zichao Yang, Marcin Moczulski, Misha Denil, Nando de Freitas, Alex Smola, Le Song, Ziyu Wang.	O	O	Review	309
Deep Fried Convnets.	O	O	Review	309
ICCV 2015.	O	O	Review	309
[line_break_token][2] Zichao Yang, Alexander J. Smola, Le Song, Andrew Gordon Wilson.	O	O	Review	309
A la Carte ‚Äî Learning Fast Kernels.	O	O	Review	309
AISTATS 2015.	O	O	Review	309
Similar to our work, paper [2] also considers learning the Fourier spectrum of a shift-invariant kernel, where the spectrum is parameterized as a mixture of (a fixed number of) Gaussians or a piecewise linear function, which can definitely fit in our min-max formulation.	B-Reply	B-2	Reply	309
However, in comparison, our end-to-end method is more general since it doesn‚Äôt rely on any specific parameterization.	I-Reply	I-2	Reply	309
Paper [1] is also interesting and relevant since it draws connections between spectrally learned kernel machines and deep neural networks.	I-Reply	I-2	Reply	309
As we mention in the conclusion, it is an exciting future direction to build our method into a deep neural network.	I-Reply	I-2	Reply	309
We thank the reviewer for pointing out these references, and we‚Äôll add them to the related work section.	B-Reply	B-1	Reply	309

This paper presents a novel application of machine learning using Graph NN's on ASTs to identify incorrect variable usage and predict variable names in context.	O	O	Review	250
It is evaluated on a corpus of 29M SLOC, which is a substantial strength of the paper.	O	O	Review	250
[line_break_token][line_break_token]The paper is to be commended for the following aspects:[line_break_token]1) Detailed description of GGNNs and their comparison to LSTMs[line_break_token]2) The inclusion of ablation studies to strengthen the analysis of the proposed technique[line_break_token]3) Validation on real-world software data[line_break_token]4) The performance of the technique is reasonable enough to actually be used.	O	O	Review	250
[line_break_token][line_break_token]In reviewing the paper the following questions come to mind:[line_break_token]1) Is the false positive rate too high to be practical?	B-Review	B-1	Review	250
 How should this be tuned so developers would want to use the tool?	I-Review	I-1	Review	250
[line_break_token]2) How does the approach generalize to other languages? (	B-Review	B-2	Review	250
Presumably well, but something to consider for future work.)	I-Review	I-2	Review	250
[line_break_token][line_break_token]Despite these questions, though, this paper is a nice addition to deep learning applications on software data and I believe it should be accepted.	O	O	Review	250
[line_break_token][line_break_token]	O	O	Review	250
Thank you for reviewing our work so kindly.	O	O	Reply	250
Please note that the evaluation in our submission only covers 2.9M SLOC (not 29M), even though we have performed additional experiments with similar results on the Roslyn project (~2M SLOC).	O	O	Reply	250
[line_break_token][line_break_token]Regarding your first question: We have just updated our submission to also include ROC and PR curves for our main model in the appendix, which show that for a false positive rate of 10%, our model achieves a true positive rate of 73% on the SeenTestProj dataset and 69% on UnseenTestProj.	B-Reply	B-1	Reply	250
We expect our system to be most useful in a code review setting, where locations in which the model disagrees with the ground truth are highlighted for a reviewer.	I-Reply	I-1	Reply	250
The PR curve indicates that setting a high certainty threshold for such highlighting should yield relatively few false positives.	I-Reply	I-1	Reply	250
[line_break_token][line_break_token]Regarding your second question: We have not tested our model on other languages so far.	B-Reply	B-2	Reply	250
However, we expect similar performance on other strongly typed languages such as Java.	I-Reply	I-2	Reply	250
An interesting research question will be to explore how the model could be adapted to gradually typed (e.g. TypeScript) or untyped (e.g. JavaScript or Python) languages.	I-Reply	I-2	Reply	250

Summary:[line_break_token]This paper tackles the problem of context modelling within recurrent neural networks (RNNs).	O	O	Review	20578
The authors propose an interdependent gating mechanism that enriches the coupling between inputs and hidden states.	O	O	Review	20578
For an input x_0 and hidden state h_0; h_0 gates x_0 to create x_1; x_1 then gates h_0 to create h_1; this cyclical gating operation is applied for several rounds and it's output is fed into a recurrent neural network.	O	O	Review	20578
For the next time-step, this process is repeated, with h_0 as the final h obtained after the final round of gating in the previous time-step.	O	O	Review	20578
This results in the RNN processing a more contextualized version of the input tokens x.[line_break_token][line_break_token]Main Contributions:[line_break_token]1.	O	O	Review	20578
A simple pre-processing step that contextualizes inputs for recurrent neural networks and significantly improves performance.	O	O	Review	20578
[line_break_token]2.	O	O	Review	20578
An extensive evaluation of the proposed technique against previous works and on all relevant datasets.	O	O	Review	20578
[line_break_token][line_break_token]Pros:[line_break_token]The paper is very well-written and clear.	O	O	Review	20578
It motivates and explores the questions and issues surrounding this topic very well.	O	O	Review	20578
[line_break_token][line_break_token]Cons:[line_break_token]It would be good to see how this performance translates to other RNN architectures such as GRUs.	B-Review	B-1	Review	20578
[line_break_token][line_break_token][line_break_token]Final notes:[line_break_token]This paper raises many interesting question:[line_break_token]- What is the really going on with the gating mechanism?	B-Review	B-2	Review	20578
[line_break_token]The authors explore this question but the jury is still out on exactly what is going on here.	I-Review	I-2	Review	20578
[line_break_token]- "Mogrification" as a general preprocessing step: could it also improve performance for transformer models?	B-Review	B-3	Review	20578
[line_break_token]- Are there better ways to preprocess and gate the RNN inputs?	B-Review	B-4	Review	20578
[line_break_token][line_break_token]--------[line_break_token][line_break_token]Review Decision:[line_break_token]It is clear, well motivated, well written and represents a concrete contribution to the language modelling literature.	O	O	Review	20578
Furthermore, most claims made are substantiated via thorough experimentation.	O	O	Review	20578
Lastly, this work demonstrates that rather than relying on data and model scaling to improve performance; there is alot left to be done in tackling language modelling on smaller scale datasets.	B-Review	B-5	Review	20578
e thank Reviewer #3 for their comments.	O	O	Reply	20578
[line_break_token][line_break_token]- "Mogrification" as a general preprocessing step: could it also[line_break_token]  improve performance for transformer models?	O	O	Reply	20578
[line_break_token][line_break_token]Possibly, but it would be quite surprising, as attention might very[line_break_token]well be able to express similar transformations.	B-Reply	B-3	Reply	20578
[line_break_token][line_break_token]As to whether there better ways to preprocess and gate the RNN inputs,[line_break_token]we are sure that the answer is yes.	I-Reply	I-3	Reply	20578
More generally, we believe that[line_break_token]our neural models lack the necessary biases perform well in a[line_break_token]data-efficient manner.	I-Reply	I-3	Reply	20578
Large datasets can alleviate the problem, but[line_break_token]may not be able to solve it.	I-Reply	I-3	Reply	20578

Summary:[line_break_token][line_break_token]The authors propose a method to make exploration in really sparse reward tasks more efficient.	O	O	Review	340
They propose a method called Workflow Guided Exploration (WGE) which is learnt from demonstrations but is environment agnostic.	O	O	Review	340
Episodes are generated by first turning demonstrations to a workflow lattice.	O	O	Review	340
This lattice encodes actions which are in some sense similar to those in the demonstration.	O	O	Review	340
By rolling out episodes which are randomly sampled from this set of similar actions for each encountered state, it is claimed that other methods like Behavor Cloning + RL (BC-then-RL) can be outperformed in terms of number of sample complexity since high reward episodes can be sampled with much higher probability.	O	O	Review	340
[line_break_token][line_break_token]A novel NN architecture (DOMNet) is also presented which can embed structured documents like HTML webpages.	O	O	Review	340
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]- The paper is well-written and relevant literature is cited and discussed.	O	O	Review	340
[line_break_token]- My main concern is that while imitation learning and inverse reinforcement learning are mentioned and discussed in related work section as classes of algorithms for incorporating prior information there is no baseline experiment using either of these methods.	B-Review	B-2	Review	340
Note that the work of Ross and Bagnell, 2010, 2011 (cited in the paper) establish theoretically that Behavior Cloning does not work in such situations due to the non-iid data generation process in such sequential decision-making settings (the mistakes grow quadratically in the length of the horizon).	I-Review	I-2	Review	340
Their proposed algorithm DAgger fixes this (the mistakes by the policy are linear in the horizon length) by using an iterative procedure where the learnt policy from the previous iteration is executed and expert demonstrations on the visited states are recorded, the new data thus generated is added to the previous data and a new policy retrained.	I-Review	I-2	Review	340
Dagger and related methods like Aggrevate provide sample-efficient ways of exploring the environment near where the initial demonstrations were given.	I-Review	I-2	Review	340
WGE is aiming to do the same: explore near demonstration states.	I-Review	I-2	Review	340
[line_break_token]- The problem with putting in the replay buffer only episodes which yield high reward is that extrapolation will inevitably lead the learnt policy towards parts of the state space where there is actually low reward but since no support is present the policy makes such mistakes.	B-Review	B-3	Review	340
[line_break_token]- Therefore would be good to have Dagger or a similar imitation learning algorithm be used as a baseline in the experiments.	B-Review	B-2	Review	340
[line_break_token]- Similar concerns with IRL methods not being used as baselines.	B-Review	B-1	Review	340
[line_break_token][line_break_token]Update: Review score updated after discussion with authors below.	O	O	Review	340
[line_break_token]	O	O	Review	340
We would like to thank the reviewer for the feedback!	O	O	Reply	340
[line_break_token][line_break_token]The reviewer suggested further comparisons with inverse reinforcement learning (IRL) and DAgger-based methods (e.g., DAgger, AggreVaTe).	O	O	Reply	340
In our paper revision, we will address the critical differences between our setting and the settings of these methods, which are summarized below:[line_break_token][line_break_token]- In IRL, the system does not receive rewards from the environment and instead extracts a reward function from demonstrations.	B-Reply	B-1	Reply	340
In our setting, the system already observes the true reward from the environment, so applying IRL would be redundant.	I-Reply	I-1	Reply	340
Furthermore, IRL would struggle to learn a good reward function from such a small number of demonstrations (e.g., 3-10), which we have in our setting.	I-Reply	I-1	Reply	340
[line_break_token][line_break_token]- DAgger-based methods require access to an expert policy, which is iteratively queried to augment the training data.	B-Reply	B-2	Reply	340
In our setting, the system gets a small number of demonstrations and can interact with the environment, but does not have access to an expert policy, so these methods cannot be directly applied.	I-Reply	I-2	Reply	340
In addition, while DAgger-based methods do indeed provide an alternative way to explore around a neighborhood of the demonstrations, their goal is different from ours: DAgger addresses compounding errors, while our work addresses finding sparse reward.	I-Reply	I-2	Reply	340
[line_break_token][line_break_token]Finally, we want to clarify the concern that only high reward episodes are placed in the buffer.	B-Reply	B-3	Reply	340
The neural policy updates both off-policy from the buffer and on-policy during roll-outs.	I-Reply	I-3	Reply	340
If the neural policy begins to make mistakes, it will be penalized by receiving low reward during the on-policy rollouts, which will correct these mistakes	I-Reply	I-3	Reply	340

This papers show the effects of under-fitting in a neural network as the size of a single neural network layer increases.	O	O	Review	27
The overall model is composed of SIFT extraction, k-mean, and this single hidden layer neural network.	O	O	Review	27
The paper suggest that this under-fitting problem is due to optimization problems with stochastic gradient descent.	O	O	Review	27
[line_break_token][line_break_token]Pros[line_break_token]For a certain configurations of network architecture the paper shows under-fitting remains as the number of hidden units increases.	O	O	Review	27
[line_break_token][line_break_token]Cons[line_break_token]This paper makes many big assumptions:[line_break_token]1) that the training set of millions of images is labelled correctly.	B-Review	B-1	Review	27
[line_break_token]2) training on sift features followed by kmeans retains enough information from the images in the training set to allow for proper learning to proceed.	I-Review	I-1	Review	27
[line_break_token]3) a single hidden layer network is capable of completely fitting (or over-fitting) Imagenet.	I-Review	I-1	Review	27
[line_break_token][line_break_token]While the idea seems novel, it does appear to be a little rushed.	B-Review	B-2	Review	27
Perhaps more experimentation with larger models and directly on the input image would reveal more.	I-Review	I-2	Review	27
The 3 assumptions can be thought of has 3 conditions that are necessary for the model to be able to fit ImageNet.	B-Reply	B-1	Reply	27
In traditional experiments this would be true, however, in this case we are only monitoring *training* error.	I-Reply	I-1	Reply	27
To learn the training set, only one assumption is necessary: no training image has an exact duplicate with a different label.	I-Reply	I-1	Reply	27
In this case, the model can at least learn a KNN-like function that gives 0 error.	I-Reply	I-1	Reply	27
[line_break_token][line_break_token]As for more experiments, we are planning experiments starting from the raw images	B-Reply	B-2	Reply	27

This paper proposes a method, R3L, for exploration in reinforcement learning.	O	O	Review	10010
R3L performs an exploration procedure before policy optimization.	O	O	Review	10010
In R3L exploration, it considers the task as a planning problem, and applies RRT to find feasible solutions (trajectories).	O	O	Review	10010
Then it applies a warm start procedure for policy optimization, where the feasible solutions found by RRT are used to initialize the policy by supervised learning.	O	O	Review	10010
The paper provides theoretical guarantees of R3L exploration finding feasible solutions.	O	O	Review	10010
Empirically, the algorithmic contribution is demonstrated by comparing with information theoretical exploration methods in benchmark control domains.	O	O	Review	10010
[line_break_token][line_break_token]The paper makes two strong assumptions, which are made to guarantee RRT can be successfully applied in the task.	B-Review	B-1	Review	10010
However, it is unlikely that these two assumptions can hold in RL problems we consider in general, where the learning agent only have access to the transition data gathered by interactions with the environment.	I-Review	I-1	Review	10010
This makes the proposed R3L algorithm not a general method for exploration in RL.	I-Review	I-1	Review	10010
Due to this reason I think this paper should be rejected.	I-Review	I-1	Review	10010
[line_break_token][line_break_token]The first assumption is that random states can be uniformly sampled from the MDP state space.	B-Review	B-2	Review	10010
The author further argue that sampling a random state is typically equivalent to trivially sampling a hyper-rectangle.	I-Review	I-2	Review	10010
But isn't this a domain-dependent property?	I-Review	I-2	Review	10010
For example, how to sample a random state in Atari games and decide if it is valid?	I-Review	I-2	Review	10010
By the method proposed in the paper, one need to sample a random image, then apply a function to decide if the image is valid in the game.	I-Review	I-2	Review	10010
How to get such a function?	I-Review	I-2	Review	10010
The second assumption is that the environment state can be set to an arbitrary state.	B-Review	B-3	Review	10010
This basically assumes the learning agent is available to the transition function, so that a new state can be added to the current search tree.	I-Review	I-3	Review	10010
But again, this assumption might not be appropriate in the general RL framework.	I-Review	I-3	Review	10010
[line_break_token][line_break_token]For the theoretical contribution, the paper shows that RRT is complete with high probability, which is a standard result of RRT.	B-Review	B-4	Review	10010
In experiments, R3L is compared with VIME.	I-Review	I-4	Review	10010
But is this a fair comparison since R3L assumes to have a generative model?	I-Review	I-4	Review	10010
The tested domains are picked such that RRT can be directly applied.	I-Review	I-4	Review	10010
Can R3L be applied in domains like mujoco or Atari games?	I-Review	I-4	Review	10010
[line_break_token][line_break_token]The main idea of this paper is to deal with exploration using planning algorithms.	O	O	Review	10010
But once a generative model of the environment is given, the exploration problem will be very different with the exploration considered in RL.	B-Review	B-5	Review	10010
I would like to improve my score if the author can demonstrate the efficiency of R3L with a learned generative model.	I-Review	I-5	Review	10010
[line_break_token][line_break_token]Minor issues:[line_break_token][line_break_token]1.	O	O	Review	10010
Can you give more details about how pi_l is learned in Algorithm 1?	B-Review	B-6	Review	10010
In line 9 an action is generated using pi_l(s_near, s_rand-s_near).	I-Review	I-6	Review	10010
But in line 11, the action is again updated by ({s_near, s_rand-s_near}, a), which is very confusing.	I-Review	I-6	Review	10010
[line_break_token][line_break_token]2.	O	O	Review	10010
The notations for state and valid state are very confusing.	B-Review	B-7	Review	10010
In 3.1, the transition and reward functions are defined on S. But later in the paper, S contains states that are not valid.	I-Review	I-7	Review	10010
What's the transitions and rewards on invalid states?	I-Review	I-7	Review	10010
[line_break_token]	O	O	Review	10010
e would like to thank Reviewer 4 for the thorough review and helpful suggestions.	O	O	Reply	10010
[line_break_token][line_break_token]Reviewer 4 has raised some concerns about the assumptions.	B-Reply	B-1	Reply	10010
First, it is important to note that these assumptions only pertain to the demonstration generation (planning) phase, not the RL phase.	I-Reply	I-1	Reply	10010
We will clarify this in the text.	I-Reply	I-1	Reply	10010
[line_break_token][line_break_token]Regarding Assumption 1, we stress that the random states sampled from do not need to be valid, as stated in the paper following Assumption 1.	B-Reply	B-2	Reply	10010
is not added to the tree.	I-Reply	I-2	Reply	10010
Hence, there is no need for a function that will test states for validity.	I-Reply	I-2	Reply	10010
Sampling a (not necessarily valid) state from is indeed domain specific, as Reviewer 4 notes.	I-Reply	I-2	Reply	10010
Nonetheless, it reduces to sampling a hyper-rectangle in all common RL benchmark tasks (OpenAI Gym, MuJoCo, Atari Learning Environment, DMControl), since all of these tasks define the state space as a hyper-rectangle.	I-Reply	I-2	Reply	10010
[line_break_token][line_break_token]We have changed Assumption 2 to make it milder and more accurate.	B-Reply	B-3	Reply	10010
It now reads: "The environment state can be set to a previously visited state".	I-Reply	I-3	Reply	10010
In simulation, setting the environment to a specific state can be implemented as a variable assignment.	I-Reply	I-3	Reply	10010
As such, this step does not involve a transition from the current state to the target state, and does not require access to the transition dynamics, and does not involve a generative model.	I-Reply	I-3	Reply	10010
As discussed in Section 6, policies learned in simulated environments can be transferred to real world tasks using sim-to-real techniques, which is left as future work.	I-Reply	I-3	Reply	10010
We will clarify the connection between simulation and Assumption 2 in the main text.	I-Reply	I-3	Reply	10010
[line_break_token][line_break_token]As noted above, is not added to the tree. (	I-Reply	I-3	Reply	10010
almost always different from) is generated by executing action in state.	I-Reply	I-3	Reply	10010
Assumption 2 is used to set the state to for this purpose.	I-Reply	I-3	Reply	10010
Action attempts to reach but is not guaranteed to succeed.	I-Reply	I-3	Reply	10010
This is a classic RL transition, which does not require knowing transition dynamics, and enforces that is a valid state.	I-Reply	I-3	Reply	10010
[line_break_token][line_break_token]Regarding the theoretical contribution, our results extend RRT planning guarantees to the setting of MDPs, where the goal might be specified not as a subset of the state space but in terms of the return (cf.	B-Reply	B-4	Reply	10010
Theorem 2).	I-Reply	I-4	Reply	10010
Further, Theorem 3 is not a standard result in RRTs or in RL.	I-Reply	I-4	Reply	10010
[line_break_token][line_break_token]As to mujoco and Atari environments, we note that three of the domains considered in the paper (Reacher, Fetch Reach and Hand Reach) are mujoco domains.	I-Reply	I-4	Reply	10010
[line_break_token]R3L is most suitable to fully observable, continuous control, sparse-reward problems.	B-Reply	B-5	Reply	10010
R3L should be applicable as-is to Atari problems, but will not necessarily be as efficient as methods tailored for discrete state and action spaces, or for image data.	I-Reply	I-5	Reply	10010
Extending R3L to make it practical on high-dimensional tasks is mentioned as future work in Section 6.	I-Reply	I-5	Reply	10010
We will clarify that this includes Atari/image data problems.	I-Reply	I-5	Reply	10010
[line_break_token][line_break_token]Concerning the minor issues:[line_break_token]  * The local policy is defined as, mapping a state and a goal state to an action.	B-Reply	B-6	Reply	10010
line 11 does not update, but rather the policy model.	I-Reply	I-6	Reply	10010
The action is used as supervision for this update.	I-Reply	I-6	Reply	10010
[line_break_token]  * An invalid state is e.g. a robotic arm being inside a wall.	B-Reply	B-7	Reply	10010
Such a state is implausible, but in practice most MDPs include it in their definition of the state space.	I-Reply	I-7	Reply	10010
Since this paper is in the sparse reward setting, the reward for such a state would be should it somehow be encountered.	I-Reply	I-7	Reply	10010
The transition dynamics in that state would depend on the MDP.	I-Reply	I-7	Reply	10010
In the example of the robotic arm getting stuck inside a wall, this would be an absorbing state, as no action can change the pose of the arm.	I-Reply	I-7	Reply	10010

[line_break_token][line_break_token]This paper describes a general purpose differentiable molecular dynamics physics package, JAX MD.	O	O	Review	698
It shows several instances, where it simplifies the research process and enables new avenues of work.	O	O	Review	698
[line_break_token][line_break_token]The Github link is provided for reproducible research and future development.	O	O	Review	698
It should be encouraged.	O	O	Review	698
[line_break_token][line_break_token]I am sure whether this paper fit the ICLR or not, or how deep learning community can benefit from it.	B-Review	B-2	Review	698
[line_break_token][line_break_token]The writing does not feel academic enough sometime.	B-Review	B-1	Review	698
For example,  "Please let us know if there are features that you would find interesting.	I-Review	I-1	Review	698
We are always seeking contributions!"	I-Review	I-1	Review	698
Please consider the rephrase it.	I-Review	I-1	Review	698
hank you for taking the time to review our work and we appreciate your advice about the writing.	B-Reply	B-1	Reply	698
We will fix the sentence you noted and generally make the writing more formal.	I-Reply	I-1	Reply	698
[line_break_token][line_break_token]We would like to discuss the applicability of this work to the ML community.	B-Reply	B-2	Reply	698
While it is true that JAX MD will be of use to Physicists, we note that there has been significant research among ML practitioners that would be aided by JAX MD.	I-Reply	I-2	Reply	698
In particular, we note the following (non-exhaustive) list of papers [1-7] that were published recently in Machine Learning Conferences.	I-Reply	I-2	Reply	698
In each case, these papers leverage physical simulation; however, they were hindred since the simulations used were not integrated with deep learning libraries.	I-Reply	I-2	Reply	698
This is precisely the gap that JAX MD hopes to fill.	I-Reply	I-2	Reply	698
We would like to draw particular attention to [1], ‚ÄúLearning Protein Structure with a Differentiable Simulator‚Äù that could have been implemented out-of-the-box using JAX MD and received an oral at ICLR last year.	I-Reply	I-2	Reply	698
[line_break_token][line_break_token]Apart from this, we believe (though there has been less work in this direction so far) that physical systems are an ideal environment to explore meta-optimization since the inner-loop is much better understood than neural networks in deep learning.	I-Reply	I-2	Reply	698
[line_break_token][line_break_token][1] Learning Protein Structure with a Differentiable Simulator[line_break_token]Ingraham et al; ICLR 2019[line_break_token][line_break_token][2] Interaction Networks for Learning about Objects, Relations and Physics[line_break_token]Battaglia et al; NeurIPS 2016[line_break_token][line_break_token][3] Visual Interaction Networks: Learning a Physics Simulator from Video[line_break_token]Watters et al; NeurIPS 2017[line_break_token][line_break_token][4] SchNet: A continuous-filter convolutional neural network for modeling quantum interactions[line_break_token]Sch√ºtt et al; NeurIPS 2017[line_break_token][line_break_token][5] Learning Invariant Representations of Molecules for Atomization Energy Prediction[line_break_token]Montavon et al; NeurIPS 2012[line_break_token][line_break_token][6] A Compositional Object-Based Approach to Learning Physical Dynamics[line_break_token]Chang et al; ICLR 2017[line_break_token][line_break_token][7] End-to-End Differentiable Physics for Learning and Control[line_break_token]Belbute-Peres et al; NeurIPS 2018	O	O	Reply	698

This paper introduces the idea of energy based model to the traditional classifier, and proposes a new framework to improve the performances of the model in multiple aspects.	O	O	Review	20145
The idea of reinterpreting the traditional classifier is very interesting, and the experiments show some good results of the proposed method.	O	O	Review	20145
 [line_break_token][line_break_token]Here are my main concerns of the current paper:[line_break_token]1.	O	O	Review	20145
The training procedure seems to be very sensitive, and the SGLD may take a long time at each iteration to converge.	B-Review	B-1	Review	20145
This may be a big limitation of the proposed method.	I-Review	I-1	Review	20145
[line_break_token]2.	O	O	Review	20145
According to equation (8), the proposed method is having a trade-off between classification and generation, and this seems to be the key to improve the performance of the model in generation by sacrificing some classification accuracy.	B-Review	B-2	Review	20145
I think author should emphasize this instead of energy based model.	I-Review	I-2	Review	20145
[line_break_token]3.	O	O	Review	20145
The presentation is not very clear in section 5.	B-Review	B-3	Review	20145
What is the task of calibration, and what is the definition of ECE?	I-Review	I-3	Review	20145
[line_break_token]4.	O	O	Review	20145
The robustness guarantee seems too good to be true.	B-Review	B-4	Review	20145
Although the authors claim that they allow the attacker to have access to the gradient  of SGLD, the SGLD will add noise during the forward process, this will obfuscate the gradient.	I-Review	I-4	Review	20145
In this sense, I don‚Äôt think the proposed method will have the strong robustness as they claimed.	I-Review	I-4	Review	20145
[line_break_token][line_break_token]----------------[line_break_token]Post-Rebuttal Comments:[line_break_token]Thanks for addressing my concerns.	O	O	Review	20145
Although I think the proposed method is not comprehensive to check obfuscated gradients, I do think the current version is a good fit for ICLR, and I decide to increase my score.	B-Review	B-4	Review	20145
PART 1 OF 2)[line_break_token][line_break_token]We thank you for your time reviewing our work.	O	O	Reply	20145
We will address your concerns in order and we have updated the manuscript accordingly.	O	O	Reply	20145
We hope these changes will encourage you to change your score:[line_break_token][line_break_token]1) Your concerns on the sensitivity and speed of SGLD training of EBMs.	O	O	Reply	20145
[line_break_token][line_break_token]Regarding your concern about sensitivity: [line_break_token][line_break_token]While we agree that SGLD training of EBMs can be sensitive to hyper-parameter settings, we note that throughout our work we used the exact same hyper-parameters for every model and every dataset.	B-Reply	B-1	Reply	20145
We also found these settings transferred well to datasets such as MNIST which we did not present in our paper.	I-Reply	I-1	Reply	20145
Further, we found these same settings worked well across a variety of model architectures such as MLPs, non-resnet convnets, and resnets.	I-Reply	I-1	Reply	20145
This was stated in Appendix  G.2 of our paper, but we have added it to the main body of our paper for clarity.	I-Reply	I-1	Reply	20145
This hyper-parameter transferability behavior has also been reported in prior work on EBM training such as [1, 2].[line_break_token][line_break_token]Regarding your other concern about the convergence time: [line_break_token][line_break_token]In our work we put a great deal of focus into being able to train as quickly as possible with minimal hardware requirements.	I-Reply	I-1	Reply	20145
We have been able to train EBMs with far fewer SGLD steps per training iteration than in previous work and found that at these settings stable training can still take place.	I-Reply	I-1	Reply	20145
All of our models were trained on a single GPU and each training run took hours.	I-Reply	I-1	Reply	20145
While this is slower than training a standard classifier on these datasets, our training speed falls comfortably in the range of other popular classes of generative models such as flows [3] and GANs [4].[line_break_token][line_break_token]We admit that we did not put enough emphasis on these two facts in our original draft and we have added this information in section 5.	I-Reply	I-1	Reply	20145
We hope this clarifies your concerns regarding training sensitivity and run-time.	I-Reply	I-1	Reply	20145
 [line_break_token][line_break_token]Overall we feel that training and sampling are the biggest challenges when working with EBMs.	I-Reply	I-1	Reply	20145
Developing improved methods for this is important further work but we also feel it is outside of the scope of our current work.	I-Reply	I-1	Reply	20145
The main point of our work was to demonstrate that despite the challenges which currently exist in training EBMs, they can be used to achieve a very interesting and diverse set of results on problems which other classes of generative models have not been able to achieve at this scale.	I-Reply	I-1	Reply	20145
These results provide a strong motivation for more work in the space of EBM training methods.	I-Reply	I-1	Reply	20145
[line_break_token][line_break_token][line_break_token]2) We are slightly unsure of what you mean with this point.	B-Reply	B-2	Reply	20145
We train our model using the factorized likelihood of Equation (8).	I-Reply	I-2	Reply	20145
As we explain in the following sentence, this was done to reduce bias in our training procedure, not because there is a need to weight these terms differently.	I-Reply	I-2	Reply	20145
We are aware that this is common practice in other hybrid-models [4, 5], but we do not do this in our model.	I-Reply	I-2	Reply	20145
Each term in this objective is weighted equally.	I-Reply	I-2	Reply	20145
While different results could possibly be achieved if we did weight each term in (8) we feel that our model's ability to weight the terms equally and still perform well at both tasks is actually a benefit of our approach over competing methods.	I-Reply	I-2	Reply	20145
We hope this clarifies your concerns.	I-Reply	I-2	Reply	20145
[line_break_token][line_break_token](CONTINUED BELOW)[line_break_token][line_break_token][1] "Implicit Generation and Generalization in Energy-Based Models"  Yilun Du, Igor Mordatch.	O	O	Reply	20145
<a href="https://arxiv.org/abs/1903.08689" target="_blank" rel="nofollow">https://arxiv.org/abs/1903.08689</a>[line_break_token][2] "On the Anatomy of MCMC-based Maximum Likelihood Learning of Energy-Based Models"  Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, Ying Nian Wu.	O	O	Reply	20145
<a href="https://arxiv.org/abs/1903.12370" target="_blank" rel="nofollow">https://arxiv.org/abs/1903.12370</a>[line_break_token][3] "Large Scale GAN Training for High Fidelity Natural Image Synthesis"  Andrew Brock, Jess Donahue, Karen Simonyan.	O	O	Reply	20145
<a href="https://arxiv.org/abs/1809.11096" target="_blank" rel="nofollow">https://arxiv.org/abs/1809.11096</a>[line_break_token][4] "Glow: Generative Flow with Invertible 1x1 Convolutions"  Diederik P. Kingma, Prafulla Dhariwal.	O	O	Reply	20145
<a href="https://arxiv.org/abs/1807.03039" target="_blank" rel="nofollow">https://arxiv.org/abs/1807.03039</a>[line_break_token][5] "Residual Flows for Invertible Generative Modeling"  Ricky T. Q. Chen, Jens Behrmann, David Duvenaud, J√∂rn-Henrik Jacobsen.	O	O	Reply	20145
<a href="https://arxiv.org/abs/1906.02735" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.02735</a>[line_break_token][6] "On Calibration of Modern Neural Networks"  Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q. Weinberger.	O	O	Reply	20145
<a href="https://arxiv.org/abs/1706.04599" target="_blank" rel="nofollow">https://arxiv.org/abs/1706.04599</a>[line_break_token]	O	O	Reply	20145

Review: This paper focuses on generating adversarial perturbation in semantic space.	O	O	Review	349
The main contribution of this paper is to propose a general method to generate semantic adversarial examples by using advances in differential rendering and inverse graphics.	O	O	Review	349
[line_break_token][line_break_token]Pros:[line_break_token]1.	O	O	Review	349
Generally, the presentation is clear and easy to follow.	O	O	Review	349
[line_break_token]2.	O	O	Review	349
A general way to transform any pixel-attack algorithm to its ‚Äúsemantic version‚Äù is novel.	O	O	Review	349
[line_break_token][line_break_token]Cons:[line_break_token]1.	O	O	Review	349
There are already a lot of ways to make adversarial examples even semantic adversarial examples.	B-Review	B-1	Review	349
It‚Äôs not enough to just propose a new way to make adversarial examples.	I-Review	I-1	Review	349
I think this paper would be more compelling if proposed SAEs have some special property (e.g, easy to take effect in the real world or stronger robustness against defense strategy).	I-Review	I-1	Review	349
[line_break_token]2.	O	O	Review	349
In section 5.3, the authors show that data augmentation using SAEs increase the robustness to SAEs, but pixel perturbation AEs do not.	B-Review	B-2	Review	349
This result is of little value.	I-Review	I-2	Review	349
It is obvious that data augmentation using SAEs can increase more robustness to SAEs or pixel-perturbation AEs can increase more robustness to pixel-perturbation AEs.	I-Review	I-2	Review	349
The authors are suggested to compare changes in general robustness caused by two types of data augmentations.	I-Review	I-2	Review	349
For example, compare minimum adversarial distortion.	I-Review	I-2	Review	349
e thank the reviewer for his/her valuable feedback.	O	O	Reply	349
Below, we respond to some of the questions raised by the reviewer.	O	O	Reply	349
[line_break_token][line_break_token]1.	O	O	Reply	349
Motivation + Novelty: While we believe that pixel perturbations are hard to realize in the physical world, the SAEs we generate are much easier to realize.	B-Reply	B-1	Reply	349
Thanks to your feedback, we re-iterate this point several times through the paper to make it clearer to the reader.	I-Reply	I-1	Reply	349
We also compare and contrast our approach of generating SAEs with prior works in the space (see the text in blue in the related work section); the generality of our approach coupled with the ability to easily transform existing pixel perturbation attacks to attacks capable of generating SAEs is novel and has not been studied before.	I-Reply	I-1	Reply	349
[line_break_token]2.	O	O	Reply	349
Results: We have moved the results regarding the impact of SA-training on PP and vice-versa to the appendix (now Appendix A1) to make for clearer reading.	B-Reply	B-2	Reply	349
[line_break_token]3.	O	O	Reply	349
Adversarial Distortion: We believe that measuring the distortion caused by the adversary is a challenging proposition in the context of SAEs; in the case of pixel perturbations, adversarial distortion is measured using p-norms, which serve as a proxy for visual perception.	B-Reply	B-2	Reply	349
However, there exists no function that accurately captures changes in semantics, and ties it to visual perception.	I-Reply	I-2	Reply	349
Should such a function exist, we will be able to easily add it to our optimization framework, and produce SAEs with lesser computational overhead.	I-Reply	I-2	Reply	349
We thank the reviewer for pointing this out; we have clarified this in the paper (added as a footnote on page 4), and pose discovering such a function as an open question to researchers in the community.	I-Reply	I-2	Reply	349

This paper studied the problem of the encoded position information in convolution neural networks.	O	O	Review	20531
The hypothesis is that CNN can implicitly learn to encode the position information.	O	O	Review	20531
The author tests the hypothesis with lots of experiments to show how and where the position information is encoded.	O	O	Review	20531
[line_break_token][line_break_token]Clarity:[line_break_token]This paper is interesting for me.	O	O	Review	20531
It tries to understand the encoded position information that is easily ignored by researchers.	O	O	Review	20531
I like adequate experiments with learned position information and position illustrations.	O	O	Review	20531
[line_break_token][line_break_token]Experiments:[line_break_token]1.	O	O	Review	20531
The paper mainly discussed the zero-padding and found it is the source of position information.	B-Review	B-1	Review	20531
How about other padding modes like constant-padding, reflection-padding, and replication-padding?	I-Review	I-1	Review	20531
[line_break_token][line_break_token]2.	O	O	Review	20531
The partial convolution-based padding method [1] (padded regions are masked out) shows that its recognition accuracy is higher than the traditional zero-padding approach.	B-Review	B-2	Review	20531
Can you help investigate where the position information comes from for this case?	I-Review	I-2	Review	20531
[line_break_token][line_break_token][1] Partial Convolution based Padding, <a href="https://arxiv.org/pdf/1811.11718.pdf."	O	O	Review	20531
target="_blank" rel="nofollow">https://arxiv.org/pdf/1811.11718.pdf.</a>[line_break_token][line_break_token][line_break_token]Some of my concerns are well addressed by the author thus I upgrade my score.	O	O	Review	20531
[line_break_token]	O	O	Review	20531
any thanks for your review and we appreciate your insightful feedback.	O	O	Reply	20531
[line_break_token][line_break_token]In our paper we discussed the implicit effect of the widely used zero-padding mechanism in CNNs.	B-Reply	B-1	Reply	20531
We believe the strong position information is encoded by the value transition near the boundary, zero to non-zero values.	I-Reply	I-1	Reply	20531
Intuitively, we believe other padding strategies, e.g. reflection or replication padding, are not able to deliver this clear position information.	I-Reply	I-1	Reply	20531
[line_break_token][line_break_token]We compared the effect of Circular padding implemented in Pytorch with the commonly used zero-padding on the Horizontal (H) setting using VGG16, First row of Table 1 (VGG).	I-Reply	I-1	Reply	20531
The training loss of zero-padding starts from 0.045 and drops to 0.03 in the end.	I-Reply	I-1	Reply	20531
While the loss for circular-padding begins at 0.065 and ends at 0.056, much higher than zero-padding.	I-Reply	I-1	Reply	20531
The results of circular-padding on the PASCAL-S dataset are (SPC 0.381, MAE 0.224).	I-Reply	I-1	Reply	20531
Note that this result is similar to the setting of VGG w/o padding, Table 4 (VGG w/o padding on H).	I-Reply	I-1	Reply	20531
This further validates our hypothesis that the position information is delivered by the value transition of zero-padding.	I-Reply	I-1	Reply	20531
[line_break_token][line_break_token]For the conv-padding paper, according to Equations (4) and (5), their method essentially still applies zero-padding, which means the position information should be encoded.	B-Reply	B-2	Reply	20531
Their method is actually weighing the output of the convolution based on how many zeros are padded, r(i, j).	I-Reply	I-2	Reply	20531

The authors propose a way to visualize which areas of an image provide mostly influence a certain DNN response mostly.	O	O	Review	283
They apply some very elegant and convincing improvements to the basic method by Robnik-Sikonja and Konononko from 2008 to DNNs, thus improving it's analysis and making it usable for images and DNNs.	O	O	Review	283
[line_break_token][line_break_token]The authors provide a very thorough analysis of their methods and show very convincing examples (which they however handpicked.	O	O	Review	283
It would be very nice to have maybe at least one figure showing the analysis on e.g. 24 random picks from ImageNet).	O	O	Review	283
[line_break_token]One thing I would like to see is how their method compares to some other methods they mention in the introduction (like gradient-based ones or deconvolution based ones).	B-Review	B-1	Review	283
[line_break_token][line_break_token]They paper is very clearly written, all necessary details are given and the paper is very nice to read.	O	O	Review	283
[line_break_token][line_break_token]Alltogether: The problem of understanding how DNNs function and how they draw their conclusions is discussed a lot.	O	O	Review	283
The author's method provides a clear contribution that can lead to further progress in this field (E.g. I like figure 8 showing how AlexNet, GoogLeNet and VGG differ in where they collect evidence from).	O	O	Review	283
I can think of several potential applications of the method and therefore consider it of high significance.	O	O	Review	283
[line_break_token][line_break_token]Update: The authors did a great job of adopting all of my suggestions.	O	O	Review	283
Therefore I improve the rating from 8 to 9.	O	O	Review	283
Thank you very much for your review.	O	O	Reply	283
We understand that for the reader it would make a convincing point to see results on random picks, and therefore ran additional experiments on 34 randomly selected ImageNet images.	B-Reply	B-1	Reply	283
We also added the results of the method from Simonyan et al (2013) for direct comparison.	I-Reply	I-1	Reply	283
Please see <a href="https://www.dropbox.com/s/0eoe1krqg4m6gv8/results_random_legend.png" target="_blank" rel="nofollow">https://www.dropbox.com/s/0eoe1krqg4m6gv8/results_random_legend.png</a> for the results (we will add them to the appendix of the paper in a revised version).	O	O	Reply	283
[line_break_token][line_break_token]Further, we made our code publicly available, see <a href="https://github.com/lmzintgraf/DeepVis-PredDiff" target="_blank" rel="nofollow">https://github.com/lmzintgraf/DeepVis-PredDiff</a>	O	O	Reply	283

In the paper, the authors propose a novel optimization method for training deep learning models.	O	O	Review	20682
The idea is from the LARS and AdamW. The authors then test the proposed method on multiple experiments, results showing that the proposed method works better than other compared methods.	O	O	Review	20682
 The following are my concerns:[line_break_token][line_break_token]1) No convergence guarantee in the paper.	B-Review	B-1	Review	20682
There are too many papers claiming faster convergence these days, proof of convergence guarantee is always preferred.	I-Review	I-1	Review	20682
[line_break_token]2) The proposed method is straightforward and easy to understand.	B-Review	B-2	Review	20682
It is just a combination of AdamW and LARS.	I-Review	I-2	Review	20682
I am worried about the novelty of this paper.	I-Review	I-2	Review	20682
[line_break_token]3) In the experiments, why the compared methods are usually different.	B-Review	B-3	Review	20682
For example, compared methods are Adam, SGD, and NovoGrad in table 4 and compared methods are Adam, AdamW, and NovoGrad in table 6.	I-Review	I-3	Review	20682
 Why not compare all these methods?	I-Review	I-3	Review	20682
[line_break_token]4) When the batch size varies,  is it required to tune beta_2 accordingly?	B-Review	B-4	Review	20682
I didn't find it clearly mentioned in the paper, could authors explain how to set it?	I-Review	I-4	Review	20682
[line_break_token]5)  I am confusing that NovoGrad method works much better than Adam or AdamW in Table 6 with no weight decay, more explanations are required.	B-Review	B-5	Review	20682
[line_break_token]6) It is unclear why NovoGrad is better than LARS.	B-Review	B-6	Review	20682
LARS normalizes learning rate through |w|_2/|g|_2.	I-Review	I-6	Review	20682
The authors should explain why normalizes using layerwise |g|_2 is better.	I-Review	I-6	Review	20682
[line_break_token][line_break_token]Although the idea is straightforward, the proposed method may be helpful for the community.	O	O	Review	20682
  I will consider increasing the score if authors can address my concerns.	O	O	Review	20682
hank you for the review.	O	O	Reply	20682
Clearly we could  do better comparison of NovoGrad with LARS and explain why removed scaling of normalized gradients by.	B-Reply	B-1	Reply	20682
[line_break_token] [line_break_token]Q1:"There is no convergence guarantee in the paper.	O	O	Reply	20682
There are too many papers claiming faster convergence these days, proof of convergence guarantee is always preferred."	O	O	Reply	20682
[line_break_token]A1: The proofs of convergence for the majority of optimizers (e.g. Adam, AdaFactor, LARS etc) are given for convex / quasi-convex case only, and usually these proofs closely follow the original proof from Adagrad paper [1].  The proof for Stochastic Normalized GD was also given only in  quasi-convex setting (Hazan et al , 2014 [2]).	B-Reply	B-1	Reply	20682
This proof can be extended in straight-forward  way for NovoGrad.	I-Reply	I-1	Reply	20682
The convexity / quasi-convexity assumptions that don't hold for deep networks.	I-Reply	I-1	Reply	20682
[line_break_token]The convergence proof for deep networks with more  than 2 layers is open problem.	I-Reply	I-1	Reply	20682
As far as I know, even for vanilla gradient descent  the convergence proof for deep networks was  proposed only for  deep linear networks in Aurora et al , 2018 [3].  We are working to extend their proof for Normalized Gradients type algorithms.	I-Reply	I-1	Reply	20682
[line_break_token][line_break_token]Q2: "The proposed method is just a combination of AdamW and LARS.	O	O	Reply	20682
I am worried about the novelty of this paper."	O	O	Reply	20682
[line_break_token]A2:   NovoGrad comparison  to  LARS:[line_break_token]1.	O	O	Reply	20682
LARS uses norm of layer gradient for normalization.	B-Reply	B-2	Reply	20682
NovoGrad uses the norm of  second moments for the layer.	I-Reply	I-2	Reply	20682
So if we set, the norm of second moment will become just norm of gradient.	I-Reply	I-2	Reply	20682
So NovoGrad is more general comparing to LARS.	I-Reply	I-2	Reply	20682
[line_break_token]2.	O	O	Reply	20682
After normalization, LARS rescales the update proportional to the norm of layer weight.	B-Reply	B-2	Reply	20682
NovoGrad doesn't .	I-Reply	I-2	Reply	20682
The reasons why we removed this rescaling are explained in the A6 below.	I-Reply	I-2	Reply	20682
[line_break_token]NovoGrad comparison  to  AdamW:[line_break_token]The main difference between AdamW and NovoGrad is that NovoGrad normalize gradients before it compute first moment, while AdamW first computes the first moment, and then normalize it by second moment.	I-Reply	I-2	Reply	20682
This change in order makes NovoGrad more robust to the "gradients outlier", while AdamW keeps remembering very high gradient for long period.	I-Reply	I-2	Reply	20682
[line_break_token][line_break_token]Q3: "Why the compared methods are usually different.	O	O	Reply	20682
For example, compared methods are Adam, SGD, and NovoGrad in table 4 and compared methods are Adam, AdamW, and NovoGrad in table 6.	O	O	Reply	20682
 Why not compare all these methods?"	O	O	Reply	20682
[line_break_token]A: The choice of baseline algorithms for each particular problem was based on the best performing optimizers from the literature.	B-Reply	B-3	Reply	20682
We tried to solve several tasks with ‚Äúnon-traditional‚Äù optimizers but did not succeed.	I-Reply	I-3	Reply	20682
For example, we could not make Adam converge on ResNet-50 to reasonable accuracy and we could not make SGD converge on Transformer NMT.	I-Reply	I-3	Reply	20682
[line_break_token][line_break_token]Q4: "When the batch size varies,  is it required to tune accordingly?"	O	O	Reply	20682
[line_break_token]A: No.	B-Reply	B-4	Reply	20682
We didn‚Äôt use tuning for different batch sizes.	I-Reply	I-4	Reply	20682
The default suggested value is which we used in the majority of our experiments (ASR, LM, NMT).	I-Reply	I-4	Reply	20682
ResNet-50 experiments were conducted with  the earlier version of the code with=0.98[line_break_token][line_break_token]Q5:"Why NovoGrad method works much better than Adam or AdamW in Table 6 with no weight decay?"	O	O	Reply	20682
[line_break_token]A: For language modeling with Transformer-XL, we used only Dropout for regularization, following the original paper [4]. We experimented with weight decay too, but did not manage to get better results for both NovoGrad and Adam (the scores of AdamW are comparable to those of Adam).	B-Reply	B-5	Reply	20682
[line_break_token][line_break_token]Q6: "Why NovoGrad is better than LARS.	O	O	Reply	20682
LARS normalizes learning rate through.	O	O	Reply	20682
The authors should explain why normalizes using layer-wise is better."	O	O	Reply	20682
[line_break_token]A: The main weakness of LARS is its behavior in the regions with either too small or too large weights.	B-Reply	B-6	Reply	20682
If weights are near 0, then scaling by will make update very small, and it will take too long to leave this region.	I-Reply	I-6	Reply	20682
If weights are large, then the update (which is proportional to the weights norm) can be too large, which might cause instability.	I-Reply	I-6	Reply	20682
NovoGrad does not have this weakness.	I-Reply	I-6	Reply	20682
This is major reason why we removed scaling of normalized gradients by in NovoGrad.	I-Reply	I-6	Reply	20682
[line_break_token][line_break_token]References:[line_break_token][1] J. Duchi, E. Hazan, Y. Signer.	O	O	Reply	20682
Adaptive subgradient methods for online learning and stochastic optimization, 2011.	O	O	Reply	20682
[line_break_token][2] E. Hazan, K. Levy, S. Shalev-Shwartz.	O	O	Reply	20682
Beyond Convexity: Stochastic Quasi-Convex Optimization, 2014[line_break_token][3] S. Arora, N. Cohen, N. Golowich, W.Hu.	O	O	Reply	20682
A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks, 2018.	O	O	Reply	20682
[line_break_token][4] Z. Dai, Z. Yang, Y. Yang, J. Carbonell, Q. Le, R. Salakhutdinov.	O	O	Reply	20682
Transformer-XL: language models beyond a fixed-length context, 2019.	O	O	Reply	20682
[line_break_token]	O	O	Reply	20682

The paper claims that a combination of policy gradients calculate by different RL algorithms would provide better objective values.	O	O	Review	1226
Main focus of the work is to devise and adaptive combination scheme for policy gradient estimators.	O	O	Review	1226
Authors claim that by using the statistical shrinkage estimators combining different gradients that have different bias-variance trade-off would provide better mean-square error than each of those individual gradient estimators.	O	O	Review	1226
The key observations made by the authors are that gradients computed by on-policy methods would provide nearly unbiased estimators with very high variance while the gradients obtained by the off-policy methods in particular model based approaches would provide highly biased estimators with low variance.	O	O	Review	1226
Proposed statistical tool to combine gradients is James-Steim shrinkage estimator.	O	O	Review	1226
JS estimator provides strong theoretical guarantees for Gaussian cases but some practical  heuristics tor more complex non-Gaussian cases.	O	O	Review	1226
Authors do not discuss  whether the JS estimator actually suitable for this task given the fact that strong assumptions of the underlying statistical approach is violated.	B-Review	B-1	Review	1226
They also do not go into any discussion about theoretical guarantees nor they provide any exposures or intuitions about that.	B-Review	B-2	Review	1226
The scope of the experiments is very limited.	B-Review	B-3	Review	1226
Given the fact that there is no theory behind the claims and the lack of strong evidence I believe this paper does not cut the requirements for publication.	B-Review	B-4	Review	1226
[line_break_token][line_break_token]To improve please add significantly more empirical evidence, provide more discussion about theoretical ground work and discussion about the suitability of the JS estimators when its required assumptions are not satisfied.	B-Review	B-5	Review	1226
We would like to thank reviewer's valuable comments.	O	O	Reply	1226
As for theoretical gurantees,  JS estimator was originally motivated for normal distributions for which nice inequalities can be established to guarantee the decrease of MSE.	B-Reply	B-2	Reply	1226
 However, it is easily applicable to more general cases and provides a simple yet powerful strategy for addressing the {very challenge of bias-variance trade-off} that is crucial in many components of RL.	I-Reply	I-2	Reply	1226
The goal of this work is to fill this gap between RL and JS literature.	I-Reply	I-2	Reply	1226
Note that the decrease of MSE in our experiments is already a direct evidence of the effectiveness of JS in RL.	I-Reply	I-2	Reply	1226
 In the future we will try to use recent extended efficient shrinkage estimators in parametric models (hansen, 2016), which relaxes the normal distribution to general asymptotic distributions.	I-Reply	I-2	Reply	1226
[line_break_token][line_break_token]Hansen, Bruce E. Efficient shrinkage in parametric models.	O	O	Reply	1226
Journal of Econometrics, 190(1):115‚Äì132, 2016.	O	O	Reply	1226

This paper gives theoretical and empirical results for a gradient clipping variant of Adam they call ACClip.	O	O	Review	20132
 While the theoretical analysis is rather  sophisticated and nontrivial, I personally do not believe that analyses of this form are of any value in guiding practice.	B-Review	B-1	Review	20132
 But that is a long discussion that is not specific to this paper.	I-Review	I-1	Review	20132
 The bottom line is that for me it is mainly the experimental results that matter.	I-Review	I-1	Review	20132
[line_break_token][line_break_token]The experimental results are not compelling.	B-Review	B-2	Review	20132
 It is now clear that careful hyperparameter search is critical to drawing experimental conclusions about optimizers.	I-Review	I-2	Review	20132
 This paper simply states the hyperparameters used with no discussion of hyperparameter search.	I-Review	I-2	Review	20132
I strongly believe that any claim about optimizers needs to be backed up by experiments with very careful hyper-parameter optimization.	I-Review	I-2	Review	20132
[line_break_token][line_break_token]Postscript:  I have modified this review in response to the authors.	O	O	Review	20132
 I remain unconvinced that the theory is providing anything more than an intuitive hypothesis that Adam is importance when the variance is large.	B-Review	B-1	Review	20132
 Since Adam and RMSprop are explicitly damping variance in the gradients, this intuition is reasonable even before we prove any theorems.	I-Review	I-1	Review	20132
 I still believe the theorems do not add really add anything to the intuition and it is the experiments that matter.	I-Review	I-1	Review	20132
e thank the reviewer for the comments and feedback.	O	O	Reply	20132
We address the reviewer‚Äôs questions as follows:[line_break_token][line_break_token]1‚Äúanalyses of this form are of no value in guiding practice;  it is mainly the experimental results that matter‚Äù:[line_break_token][line_break_token]The discrepancy between convergence analysis and empirical result is the main motivation of our work.	B-Reply	B-1	Reply	20132
Particularly, we show that under a more realistic assumption that noise is heavy tailed, theory can guide practice.	I-Reply	I-1	Reply	20132
[line_break_token][line_break_token]We would like to emphasize that the central goal of the paper is to address the important practical question: Why Adam outperforms SGD in Attention models?	I-Reply	I-1	Reply	20132
It is indeed puzzling why training these models necessitates the use of adaptive optimization techniques like Adam in comparison to computer vision models like ResNet where SGD + Momentum gives the best performance.	I-Reply	I-1	Reply	20132
[line_break_token][line_break_token]In this paper, we hypothesize that heavy-tail noise is one root cause of this difference and provide strong theoretical (see Table 1 and corresponding theorems) and empirical evidence for this hypothesis.	I-Reply	I-1	Reply	20132
These results show that under heavy tail noise of stochastic gradients (or high variance in general) , the performance of SGD deteriorates significantly (see Assumption 1 and Section A of Appendix).	I-Reply	I-1	Reply	20132
While we believe that the convergence rates are interesting and important, even from a practical standpoint, our theoretical results provide qualitative insights into why SGD fails to perform well in the aforementioned settings.	I-Reply	I-1	Reply	20132
 Our analysis provides guidelines for the development of optimization techniques for attention models (indeed, ACClip follows as a direct consequence of this analysis).	I-Reply	I-1	Reply	20132
[line_break_token][line_break_token][line_break_token][line_break_token]2. ‚	O	O	Reply	20132
ÄúThere is no mention of RoBERTa and her descendents.	O	O	Reply	20132
‚Äù: [line_break_token][line_break_token]Since RoBERTa is a different training procedure (more data, more iterations, larger batch) of the same BERT model, we believe that ACClip should perform similarly well in these models.	B-Reply	B-2	Reply	20132
We will be happy to run more experiments and include them in the final version if this is the point of concern.	I-Reply	I-2	Reply	20132
[line_break_token][line_break_token]We indeed extensively tuned the hyperparameters to get the best result for each optimizer and will include the details in the next version.	I-Reply	I-2	Reply	20132
We thank the reviewer for pointing out our oversight.	I-Reply	I-2	Reply	20132
In particular, we found that the set of ADAM hyperparameters used in the original BERT [Devlin et al] paper works the best.	I-Reply	I-2	Reply	20132
Hence we use the same params as in [Devlin et al] and achieved slightly better baseline performance.	I-Reply	I-2	Reply	20132
[line_break_token][line_break_token]It will indeed be great if GLUE leader board members can examine the paper and try our optimization technique.	I-Reply	I-2	Reply	20132
We will be happy to help them in this process.	I-Reply	I-2	Reply	20132
That said, we would like to emphasize that the primary focus of the paper is not to achieve SOTA results for attention models but rather understand the optimization challenges in training attention models and provide guidelines for development of optimization techniques specially catered to these settings.	I-Reply	I-2	Reply	20132

Pros:[line_break_token]1.	O	O	Review	211
This work presents a novel construction of the popularly-used attention modules.	O	O	Review	211
It points out the problems lied in existing design that attention vectors are only computed based on parametric functions, instead of considering the interactions among each attention step and output variables.	O	O	Review	211
To achieve that, the authors re-write the joint distribution as a product of tractable terms at each timestamp and fully exploit the dependencies among attention and output variables across the sequence.	O	O	Review	211
The motivation is clear, and the proposed strategy is original and to the point.	O	O	Review	211
This makes the work relative solid and interesting for a publication.	O	O	Review	211
Furthermore, the authors propose 3 different formulation for prior attention, making the work even stronger.	O	O	Review	211
[line_break_token]2.	O	O	Review	211
The technical content looks good, with each formula written clearly and with sufficient deductive steps.	O	O	Review	211
Figure 1 provides clear illustration on the comparison with traditional attentions and shows the advantage of the proposed model.	O	O	Review	211
[line_break_token]3.	B-Review	B-2	Review	211
Extensive experiments are conducted including 5 machine translation tasks as well as another morphological inflection task.	O	O	Review	211
These results make the statement more convincing.	O	O	Review	211
The authors also conducted further experiments to analyze the effectiveness, including attention entropy evaluation.	O	O	Review	211
[line_break_token][line_break_token]Cons:[line_break_token]1.	O	O	Review	211
The rich information contained in the paper is not very well-organized.	B-Review	B-1	Review	211
It takes some time to digest, due to some unclear or missing statements.	I-Review	I-1	Review	211
Specifically, the computation for prior attention should be ordered in a subsection with a section name.	I-Review	I-1	Review	211
The 3 different formulations should be first summarized and started with the same core formula as (4).	I-Review	I-1	Review	211
In this way, it will become more clear of where does eq(6) come from or used for.	I-Review	I-1	Review	211
Currently, this part is confusing.	I-Review	I-1	Review	211
[line_break_token]2.	O	O	Review	211
Many substitutions of variables take place without detailed explanation, e.g., y_{<t} with s_t, a with x_{a} in (11) etc.	O	O	Review	211
Could you explain before making these substitutions?	B-Review	B-2	Review	211
[line_break_token]3.	I-Review	I-2	Review	211
As mentioned, the PAM actually computes hard attentions.	B-Review	B-3	Review	211
It should be better to make the statement more clear by explicitly explaining eq(11) on how it assembles hard attention computation.	I-Review	I-3	Review	211
[line_break_token][line_break_token]QA:[line_break_token]1.	O	O	Review	211
In the equation above (3) that computes prior(a_t), can you explain how P(a_{t-1}|y_{<t}) approximates P(a_{<t}|y_{<t})?	O	O	Review	211
What's the assumption?	B-Review	B-4	Review	211
[line_break_token]2.	O	O	Review	211
How is eq(5) computed using first order Taylor expansion?	B-Review	B-5	Review	211
How to make Postr inside the probability?	I-Review	I-5	Review	211
And where does x_a' come from?	I-Review	I-5	Review	211
[line_break_token]3.	B-Review	B-2	Review	211
Transferring from P(y) on top of page 3 to eq(11), how do you substitute y_{<t}, a_t with s_t, x_j?	O	O	Review	211
Is there a typo for x_j?	B-Review	B-6	Review	211
[line_break_token]4.	O	O	Review	211
Can you explain how is the baseline Prior-Joint constructed?	B-Review	B-7	Review	211
Specifically, how to compute prior using soft attention without postr?	I-Review	I-7	Review	211
We thank the reviewer for their feedback.	O	O	Reply	211
[line_break_token]We have rewritten the derivation of our factorization and made the assumptions clearer in Section 2.2 .	B-Reply	B-8	Reply	211
[line_break_token]Section 2.2.1 has also been revised describing the different variants and their intuition, deriving them all from Eqn 4.	I-Reply	I-8	Reply	211
[line_break_token]We have also fixed some notational discrepancies as pointed out by the reviewer for which we are thankful.	I-Reply	I-8	Reply	211
[line_break_token][line_break_token]QA[line_break_token]1)[line_break_token]We have rewritten that section, but the simplification comes about because of the Markovian assumption that P(a_t|a_{<t}) = P(a_t|a_{t-1}).	O	O	Reply	211
 This makes \sum_{a_{t-1}} P(a_t|a_{<t})P(a_{<t}|y_{<t})  =  \sum_{a_{t-1}} P(a_t|a_{<t}) P(a_{t-1}|y_{<t}).	O	O	Reply	211
[line_break_token][line_break_token][line_break_token]2)[line_break_token]The Taylor trick was used by [1] to simplify the expectation computation.	B-Reply	B-5	Reply	211
Essentially if the average value of a function is computed at different points, one can compute the Taylor expansion of the function at average of the points leaving only second order terms.	I-Reply	I-5	Reply	211
[line_break_token][line_break_token]\Sigma f(x_i) = \Sigma f( xm + x_i - xm) = \Sigma [ f(xm) + f‚Äô(xm)(x_i - xm) + second order terms ] = \Sigma f(xm) + df(xm)\Sigma(x_i - xm) + second order =  \Sigma f(xm) + df(xm)*0 + second order \approx \Sigma f(xm)[line_break_token][line_break_token]3)[line_break_token]s_t is the decoder state after feeding in output y_{t-1} and attention at step {t-1}. Like in standard seq2seq literature, we rely on the decoding RNN state to capture the dependence on history of output tokens.	B-Reply	B-6	Reply	211
Under the assumption that y_t depends directly on attention 'a' at t and previous tokens, we use the decoder state s_t and the encoder state x_{a}. Indeed as pointed 'j' was a typo.	I-Reply	I-6	Reply	211
[line_break_token][line_break_token]4)[line_break_token]The main difference between the prior-joint and postr-joint model is which attention gets propagated further down.	B-Reply	B-7	Reply	211
The prior-joint model behaves analogously to the standard soft-attention in ignoring any interaction between output and attention.	I-Reply	I-7	Reply	211
In fact, it is a version of an IBM model 1.	I-Reply	I-7	Reply	211
We have expanded on this in Section3 paragraph 7 and Section4 paragraph 1[line_break_token][line_break_token][1] Xu et al; Show, attend and tell: Neural image caption generation with visual attention , 2015	O	O	Reply	211

This paper proposes to train a Universal Phonetic Model for building speech recognition for new languages without any training data.	O	O	Review	790
It suggests to use X-SAMPA to map phones from all the languages into a single phonetic space.	O	O	Review	790
The prediction models are designed to first predict the phonetic features and then the phones depending on the target language.	O	O	Review	790
[line_break_token]Overall , the paper is quite clear written.	O	O	Review	790
[line_break_token]- Strengthens:[line_break_token]+ It observed overall improvements for all the target languages.	O	O	Review	790
[line_break_token][line_break_token]- Weaknesses:[line_break_token]+ The idea and the proposed model are not novel.	B-Review	B-1	Review	790
[line_break_token]+ All the baseline systems have relative high phone error rates.	B-Review	B-2	Review	790
[line_break_token]+ The authors claimed to have a universal phonetic model but actually the model was trained only with English data.	B-Review	B-3	Review	790
Therefore, experimental setup could be improved.	I-Review	I-3	Review	790
In my opinion, it makes more sense to define a bunch of resource-rich languages as source and then train a real universal phonetic model.	I-Review	I-3	Review	790
[line_break_token]+ Overall, this paper lacks an analysis what are exactly improved and why the improvements for some target languages are larger than for the others.	B-Review	B-4	Review	790
[line_break_token] 	B-Review	B-1	Review	790
Thank you for your valuable comments !	O	O	Reply	790
[line_break_token][line_break_token]We think that the term ‚ÄúUniversal Phonetic Model‚Äù might have confused the reviewer.	B-Reply	B-3	Reply	790
We are sorry about that.	I-Reply	I-3	Reply	790
The problem that we want to address is the task of zero-shot learning for speech recognition, which consist of learning an acoustic model without any resources for a given target language.	I-Reply	I-3	Reply	790
We call our model ‚ÄúUniversal Phonetic Model‚Äù, because it has the ability to predict any phoneme, even the ones that are not present during training (therefore it covers a ‚Äúuniversal‚Äù set).	I-Reply	I-3	Reply	790
We achieve this by decomposing the phone label into its phone attributes.	I-Reply	I-3	Reply	790
[line_break_token][line_break_token]One of the weakness that has been pointed out is that the idea and model is not novel.	B-Reply	B-1	Reply	790
However, we did not find any works that attempt the same problem with a similar model.	I-Reply	I-1	Reply	790
It is possible we are unaware of related work, it would be helpful if the reviewer can give some references so that we can investigate further.	I-Reply	I-1	Reply	790
Most of the work on zero-shot in speech community that we found only identified ‚Äúsimilar‚Äù speech concepts or sounds, but could not ground them to phone labels making it hard to do speech recognition.	I-Reply	I-1	Reply	790
Similarly, the idea of decomposing sounds into articulatory features is old, but our work presents the first approach that actually decomposes sounds into ‚Äúuniversal‚Äù articulatory features and recognizes speech in unseen languages using such representations.	I-Reply	I-1	Reply	790
[line_break_token][line_break_token]As we mentioned to AnonReviewer1, we agree that our baseline model has too high a phone error rate to be usable in practice.	B-Reply	B-2	Reply	790
Unfortunately this is what the current CTC acoustic models provide for the task of zero-shot speech recognition.	I-Reply	I-2	Reply	790
Both the baseline and UPM models had practical and competitive phoneme error rate in the test data of the 3 english datasets that were used during training.	I-Reply	I-2	Reply	790
However, we do believe that some of the performance reduction when using this model cross-lingually and cross-domain could because our input features are not robust against acoustic domain mismatch.	I-Reply	I-2	Reply	790
We are currently re-running the experiments with a new set of input features proposed in [1], and first results indicate that we can get even better improvements in the same settings, and on top of a much improved baseline.	I-Reply	I-2	Reply	790
We believe this is due to the stronger (noise robust and domain invariant) overall baseline allowing for a better sharing of the linguistically informative information across languages, and we are working towards applying this idea to all the experiments including baseline, so that an updated version of the paper will again be consistent.	I-Reply	I-2	Reply	790
[line_break_token][line_break_token][line_break_token]We do agree that a better universal phoneme recognizer can be built by training on even more languages.	B-Reply	B-4	Reply	790
But we believe that our experiments show that problem we want to address here, specifically the ability to predict unseen phonemes, in a zero-shot speech recognition scenario, can be tackled with the proposed method.	I-Reply	I-4	Reply	790
Using more training languages would reduce appearance of unknown phonemes, but there will still almost always be at least a few unseen phones, which we show our model is effective in reducing..[line_break_token][line_break_token][1] S.Dalmia, X. Li, F. Metze and AW Black, ‚ÄúDomain Robust Feature Extraction for Rapid Low Resource ASR Development‚Äù, in Proc SLT 2018, <a href="https://arxiv.org/pdf/1807.10984.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1807.10984.pdf</a>	O	O	Reply	790

To improve the robustness of neural networks under various conditions, this paper proposes a new regularizer defined on the graph of the training examples, which penalizes the large similarities between representations belonging to different classes, thus increase the stability of the transformations defined by each layer of the network.	O	O	Review	890
[line_break_token][line_break_token]The paper is overall well written, and the idea involving the Laplacian of the similarity graph is interesting.	O	O	Review	890
I have reviewed this paper before.	O	O	Review	890
Compared to the previous version, this paper made a good improvement in its experimental results, by adding two different robustness settings in section 4.1 and section 4.3, and also include DeepFool as a strong attack method for testing adversarial robustness.	O	O	Review	890
[line_break_token][line_break_token]However, my main concern about the paper is still about its significance.	O	O	Review	890
[line_break_token]1.	O	O	Review	890
It is still not clear why would this regularization help robustness especially when considering adversarial examples.	B-Review	B-1	Review	890
Example 1 seems not obvious to me why maintaining the boundary margin (rather than expanding or shrinking) is preferred.	I-Review	I-1	Review	890
As stated in the second paragraph in section 3.4, ‚Äúlower value of \sigma^\ell(s) are indicative of better separation between classes‚Äù, what is the reason of not directly penalizing this value, rather than requesting a ‚Äústability‚Äù property on this value?	I-Review	I-1	Review	890
How is this stability related to the robustness?	I-Review	I-1	Review	890
This would request a deeper analysis and more empirical proofs in the paper.	I-Review	I-1	Review	890
[line_break_token]2.	O	O	Review	890
Experimental results still seem not convincing to me.	B-Review	B-2	Review	890
On one hand, based on the reported result, I am not very convincing that the proposed method outperforms Parseval, especially when considering the inconsistent behaviour of ‚ÄúProposed + Parseval‚Äù.	I-Review	I-2	Review	890
On the other hand, for adversarial robustness, the authors should have compared to the method of adversarial training as well.	I-Review	I-2	Review	890
Beyond that, the authors should also be careful of the gradient masking effect of the proposed method.	I-Review	I-2	Review	890
I am not sure if there is some other obvious benchmarks should be included for the other two robustness settings.	I-Review	I-2	Review	890
[line_break_token][line_break_token]Other comments:[line_break_token]1.	O	O	Review	890
Descriptions in the last 3 paragraphs in section 3.2 are not very clear.	B-Review	B-3	Review	890
It always took me a while to figure it out every time I read the paper.	I-Review	I-3	Review	890
It would be very helpful if the computation process and the discussions can be separated here, maybe with a pseudo-code for computing the regularizer.	I-Review	I-3	Review	890
[line_break_token]2.	O	O	Review	890
On the other hand, while the proposed regularizer can be interpreted in a perspective of the Laplacian of the similarity graph, the third part in Equation (4), that expresses the smoothness as the sum of similarities between different classes, seems more intuitive to me.	B-Review	B-4	Review	890
Emphasizing in this interpretation may also help convey the message.	I-Review	I-4	Review	890
We would like to thank the reviewer for their comments and suggestions.	O	O	Reply	890
We greatly appreciate that they acknowledged the paper improved since the last submission.	O	O	Reply	890
[line_break_token][line_break_token]Regularization and robustness:[line_break_token]To answer the first point, we added a discussion in the supplementary material (see also answer to reviewer 1).	B-Reply	B-1	Reply	890
In particular, a regularizer that aims at minimizing the quantity would result in dilation in space between examples of distinct classes.	I-Reply	I-1	Reply	890
The expected consequence of this would be to transform small variations in the input to large variations in the output, which is the opposite of the desired robustness behavior.	I-Reply	I-1	Reply	890
Also, the boundary region would likely fall into a ``stretched'' part of the space, resulting in sharp transitions between classes.	I-Reply	I-1	Reply	890
As shown in [Zhang et al 2017], this is not a desirable property as far as the generalization is concerned.	I-Reply	I-1	Reply	890
We also added experiments to show the connection between the proposed regularizer and the boundary region.	I-Reply	I-1	Reply	890
In Figure~11 of the supplementary material, we draw the average network function decision along segments between two input examples in distinct classes.	I-Reply	I-1	Reply	890
As is shown in this figure, the proposed regularizer results in a boundary closer to the middle of the segment, thus yielding better robustness along this axis.	I-Reply	I-1	Reply	890
[line_break_token][line_break_token]Experimental results: To better address the significance concerns, we have multiple experiments in the supplementary material to stress the abilities of the proposed method.	B-Reply	B-2	Reply	890
We tested against another dataset (CIFAR-100) and with new architecture/hyperparameters (WideResnet and standard data augmentation), and in those experiments proposed regularizer was always the most robust (sometimes in combination with Parseval).	I-Reply	I-2	Reply	890
Concerning adversarial training, we have tested the proposed regularizer in combination with methods from both [Kurakin 2017,Madry 2018], and the results show that the proposed regularizer is able to increase robustness even when used in combination with adversarial training.	I-Reply	I-2	Reply	890
[line_break_token][line_break_token]Gradient Masking: Experiments with Gaussian noise can be seen as evidence that the robustness of our proposed method is not due only to gradient masking (since Gaussian noise is added without knowledge of the gradients).	I-Reply	I-2	Reply	890
We also added black box tests, where the attacks are generated on a network trained using a distinct method from the one it is used upon, to the supplementary material.	I-Reply	I-2	Reply	890
We obtained that for all sources, the most robust target network was the one that combined the proposed regularizer with Parseval, proving that the obtained results are not solely due to gradient masking, but to the increased robustness due to the use of the regularizer.	I-Reply	I-2	Reply	890
[line_break_token][line_break_token]Pseudo-code: In regards to pseudo-code, we will be adding one to the additional material and we are willing to share the code as soon as the review process is over, as we think that is the easiest way to explain the method and increase reproducibility.	B-Reply	B-3	Reply	890
About presentation, we added a paragraph after Equation (4) to ease readability: ``In this paper we are particularly interested in smoothness of the label signals.	I-Reply	I-3	Reply	890
We call \emph{label signal} associated with class a binary ) vector whose nonzero coordinates are the ones corresponding to input vectors of class.	I-Reply	I-3	Reply	890
In other words, is in class.	I-Reply	I-3	Reply	890
Using Equation~(4), we obtain that the smoothness of the label signal is the sum of similarities between examples in distinct classes.	I-Reply	I-3	Reply	890
Thus a smoothness of 0 means that examples in distinct classes have 0 similarity.''.	I-Reply	I-3	Reply	890
[line_break_token][line_break_token]References:[line_break_token][Kurakin 2017] Kurakin, Alexey, Ian Goodfellow, and Samy Bengio. "	O	O	Reply	890
Adversarial machine learning at scale."	O	O	Reply	890
ICLR 2017.	O	O	Reply	890
[line_break_token][Zhang 2018] Zhang, Hongyi, et al "mixup: Beyond empirical risk minimization."	O	O	Reply	890
ICLR 2018.	O	O	Reply	890
[line_break_token][Madry 2018] Madry, Aleksander, et al "Towards deep learning models resistant to adversarial attacks."	O	O	Reply	890
ICLR 2018.	O	O	Reply	890

The authors propose a model for Click-Through Rate Prediction using a model consisting of an embedding layer, a Transformer stack, a Factorization Machine, and a DNN.	O	O	Review	70
[line_break_token][line_break_token]I have several major concerns about the submission:[line_break_token]2.	O	O	Review	70
Relevance: This work is extremely application specific, the application is not relevant to this community.	B-Review	B-1	Review	70
[line_break_token]1.	O	O	Review	70
Clarity and writing: The contributions which are relevant to the ICLR community are not explained well and the paper needs copy-editing for English grammar[line_break_token]4.	B-Review	B-2	Review	70
Novelty: While seemingly showing good results on some benchmarks, the model is a mix of many components and it's not clear which components actually improve performance and would be worth further study.	B-Review	B-3	Review	70
[line_break_token][line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]Applying the DNN directly on top of the embeddings, and having a parallel stack of Encoder-FM, is not well explained.	B-Review	B-4	Review	70
What does it mean that "DNN aims at bit-wise level" if the DNN receives the same embedding features as the encoder, which supposedly "learn[s] at vector wise level"?	I-Review	I-4	Review	70
[line_break_token][line_break_token]References to datasets are missing[line_break_token][line_break_token]Ablation study is limited, and has surprising results.	B-Review	B-5	Review	70
E.g. even completely removing self-attention barely makes a dent in how well the method compares to other published work, moving it from rank 1 to rank 2.	B-Review	B-6	Review	70
Otherwise only small tweaks with even more minor effects are made.	I-Review	I-6	Review	70
What about removing e.g. the FM, other major components?	I-Review	I-6	Review	70
[line_break_token][line_break_token]The biggest architectural innovations here are the bi-linear attention mechanism and max-pooling self attention.	B-Review	B-7	Review	70
They are hard to interpret in this context.	I-Review	I-7	Review	70
It's not clear how they would perform in a simpler architecture (e.g. vanilla BERT or Transformer) and in the context of a more standard benchmark.	I-Review	I-7	Review	70
That study would have a lot more relevance to this community than the present one.	I-Review	I-7	Review	70
[line_break_token]	O	O	Review	70
e thank the reviewer for the feedback and address the concerns in detail below[line_break_token]1.	O	O	Reply	70
[tab_token]Relevance to ICLR[line_break_token]Thanks, our paper aims to use the encoder to gain better field feature representation for CTR task, which is relevant to learning representations.	B-Reply	B-1	Reply	70
[line_break_token]2.	O	O	Reply	70
[tab_token]The meaning of ‚ÄúDNN learns at bit-wise level.	O	O	Reply	70
‚Äù[line_break_token]The statement ‚ÄúDNN learns at bit-wise level‚Äù means that DNN learns the feature representation by the linear and non-linear transformation of neurons.	B-Reply	B-4	Reply	70
The FM learns the inner product of two features, which is a vector-wise level.	I-Reply	I-4	Reply	70
[line_break_token]3.	O	O	Reply	70
[tab_token]Major component study.	O	O	Reply	70
[line_break_token]Thanks, we have added the ablation study for the main component.	B-Reply	B-6	Reply	70
We have removed the FM, DNN to analyze the contribution of FM and DNN in our work.	I-Reply	I-6	Reply	70
The results show that the AUC of ‚ÄúDeepEnFM w/o DNN‚Äù is 0.8037 on criteo dataset, which is higher than AutoInt, which demonstrates the effectiveness of our encoder with bilinear and max-pooling method.	I-Reply	I-6	Reply	70
Surprisingly, the AUC of  ‚ÄúDeepEnFM w/o FM‚Äù is 0.8059 on criteo dataset, which is very close to the full model(0.8077).	I-Reply	I-6	Reply	70
The gap to the full model demonstrates the effect of each component	I-Reply	I-6	Reply	70

**Summary of the paper: [line_break_token]The paper proposes an IL method named support-guided adversarial IL (SAIL), which is based on generative adversarial IL (GAIL) (Ho and Ermon, 2016) and random expert distillation (RED) (Wang et al 2019).	O	O	Review	704
The key idea of SAIL is to construct a reward function by multiplying reward functions learned by GAIL and RED.	O	O	Review	704
This multiplication yields two benefits; 1) it handles the issue of biased reward in GAIL, since state-action pairs outside the expert‚Äôs support are assigned low reward values.	O	O	Review	704
2) SAIL‚Äôs reward is more reliable than RED‚Äôs reward for state-action pairs inside the expert‚Äôs support.	O	O	Review	704
The authors show that SAIL is at least as fast as than GAIL in terms of the sample complexity.	O	O	Review	704
Experiments on continuous control benchmarks show that SAIL is overall more stable than GAIL.	O	O	Review	704
[line_break_token][line_break_token]**Rating: [line_break_token]The paper proposes a simple but effective combination of existing methods.	O	O	Review	704
The proposed method is well motivated and performs well on benchmarks.	O	O	Review	704
Still, the paper has some issues regarding justification, clarity, and evaluation, which should be addressed (see below).	O	O	Review	704
I vote for weak acceptance.	O	O	Review	704
[line_break_token][line_break_token]**Major comments/questions: [line_break_token]- No guarantee of the optimality of the learned policy.	B-Review	B-1	Review	704
[line_break_token]Can it be guaranteed that SAIL learns the expert policy? (	I-Review	I-1	Review	704
assuming the expert policy is realizable).	I-Review	I-1	Review	704
Propositions 1 and 2 show the convergence of the support estimation, but these results are not related to the optimality of a policy learned with the reward function.	I-Review	I-1	Review	704
This is an important point for justifying SAIL, since SAIL does not perform distribution matching to learn the expert policy, and it also does not perform IRL to learn the reward function.	I-Review	I-1	Review	704
Therefore, SAIL lacks the optimality guarantee from both distribution matching and IRL perspectives.	I-Review	I-1	Review	704
Please address and clarify this point.	I-Review	I-1	Review	704
[line_break_token][line_break_token]- Clarity in the theoretical analysis.	I-Review	I-1	Review	704
[line_break_token]In the theoretical analysis, the paper assumes a rate of GAIL for support estimation.	I-Review	I-1	Review	704
This is quite confusing, since GAIL performs distribution matching and does not estimate the support.	I-Review	I-1	Review	704
Also, given that r_gail = -log D(s,a), the reward‚Äôs upper-bound (R_gail) is infinity and the bound in Eq. (	I-Review	I-1	Review	704
9) is not informative.	I-Review	I-1	Review	704
[line_break_token][line_break_token]- The reward r_red is constant at the optimal.	B-Review	B-3	Review	704
[line_break_token]Eq. (	B-Review	B-1	Review	704
2) and Eq. (	B-Review	B-3	Review	704
3) imply that, for state-action pairs from the expert‚Äôs state-action distribution, r_red is constant at the optimal.	I-Review	I-3	Review	704
Specifically, the optimal solution of Eq. (	I-Review	I-3	Review	704
2) is \hat{\theta} = \theta, which yields to a constant value of r_red(s,a) in Eq. (	I-Review	I-3	Review	704
3).	I-Review	I-3	Review	704
In this scenario, SAIL is equivalent to GAIL for the expert state-action distribution.	I-Review	I-3	Review	704
This means that Eq. (	I-Review	I-3	Review	704
2) should not be optimized until optimal, and some early stopping criteria are required.	I-Review	I-3	Review	704
Does this scenario (constant value of r_red) occur in the experiments?	I-Review	I-3	Review	704
[line_break_token][line_break_token]- IRL baseline methods.	B-Review	B-4	Review	704
[line_break_token]The paper should compare SAIL to methods which aim to handle the bias in reward function, e.g., DAC (Kostrikov et al 2019).	I-Review	I-4	Review	704
While DAC requires the time limit, this time limit is known in the benchmark tasks.	I-Review	I-4	Review	704
Also, IRL methods such as AIRL (Fu et al 2018) should be compared, since IRL methods are better than GAIL at handling bias in reward function (Kostrikov et al 2019).	I-Review	I-4	Review	704
[line_break_token][line_break_token]**Minor comments/questions: [line_break_token]- Typos: "offline RL algorithms" should be "off-policy RL algorithms".	B-Review	B-5	Review	704
Line 5 of Algorithm 1 should perform gradient ascent instead of gradient descent.	I-Review	I-5	Review	704
An expectation over state-action distribution of expert is missing from Eq. (	I-Review	I-5	Review	704
2).	I-Review	I-5	Review	704
[line_break_token][line_break_token]- What are the bold numbers in table 1 and 2 indicating?	B-Review	B-2	Review	704
Why does the Hopper task have two bold numbers, but the other tasks have only one?	I-Review	I-2	Review	704
[line_break_token][line_break_token]--After author response--[line_break_token]I have read the author response and other reviews.	O	O	Review	704
I thank the authors for including additional experiments.	O	O	Review	704
However, the authors' arguments regarding optimality do not fully address my comments (see below).	O	O	Review	704
I will keep the vote of weak acceptance.	O	O	Review	704
 [line_break_token][line_break_token]The authors argue that "In this asymptotic case, SAIL is equivalent to performing distribution matching via GAIL with the additional *constraint* that candidate distributions need to have the same support of the expert distribution".	O	O	Review	704
However, the support of the expert distribution may coincide with the entire state-action space, which makes the additional constraint uninformative in the asymptotic case.	B-Review	B-1	Review	704
Specifically, the expert distribution coincides with the state-action space when the expert policy has an infinite support (e.g., the expert policy is Gaussian).	I-Review	I-1	Review	704
Assuming the asymptotic case, the support estimation in RED will give an indicator function over an entire state-action space, and the support constraint in SAIL is always satisfied.	I-Review	I-1	Review	704
In other words, SAIL is exactly equivalent to GAIL in this case.	I-Review	I-1	Review	704
For these reasons, the authors' arguments regarding optimality do not fully address my comments.	I-Review	I-1	Review	704
I think additional assumptions are required, e.g., the expert policy needs to have a finite support or be deterministic.	I-Review	I-1	Review	704
 [line_break_token][line_break_token][line_break_token]	I-Review	I-1	Review	704
e thank the reviewer for the constructive feedback.	O	O	Reply	704
[line_break_token][line_break_token]- Clarification on method justification &amp; theoretical analysis[line_break_token]As the reviewer pointed out, distribution matching does not necessarily imply support estimation (it depends on the metric used for the distribution matching).	B-Reply	B-1	Reply	704
However, following the intuition in motivating this work, restricting the distribution matching problem to the support of the target distribution (the expert) might help the overall learning.	I-Reply	I-1	Reply	704
 In this sense, the results in Prop.	I-Reply	I-1	Reply	704
1 and 2 show that, even if GAIL were to perform a very slow support estimation (or no support estimation at all), the distribution matching process would be constrained onto the expert‚Äôs support, thanks to RED.	I-Reply	I-1	Reply	704
[line_break_token][line_break_token]In the asymptotic setting, RED converges to an indicator function on the support of the expert policy: r_red(s, a) =1 if (s, a) belongs to the support of the expert policy, and 0 otherwise.	I-Reply	I-1	Reply	704
[line_break_token][line_break_token]Therefore, In this asymptotic case, SAIL is equivalent to performing distribution matching via GAIL with the additional *constraint* that candidate distributions need to have the same support of the expert distribution.	I-Reply	I-1	Reply	704
Since we are restricting candidate estimators to the support of the target distribution, distribution matching methods (e.g. GAIL) can still be adopted.	I-Reply	I-1	Reply	704
[line_break_token][line_break_token]- Clarification on why optimizing Eq.	O	O	Reply	704
2 doesn‚Äôt recover the \theta and thus render the red reward a constant[line_break_token]The technique of random network distillation was first proposed in (Burda et al 2018), which states that empirically, standard training would converge to a local minimum other than the randomly initialized \theta.	B-Reply	B-3	Reply	704
We have similar observations in our experiment, and thus no special treatment (e.g. early stopping) is used.	I-Reply	I-3	Reply	704
[line_break_token][line_break_token]- Clarification on additional comparison[line_break_token]We have included a comparison with the absorbing state (AS) technique (Kostrikov et al 2019) in Table 5 from Appendix.	B-Reply	B-4	Reply	704
We also run SAIL combined with AS, since the two methods are not mutually exclusive.	I-Reply	I-4	Reply	704
[line_break_token][line_break_token]The results are:[line_break_token]Default env[line_break_token]GAIL 258.30¬±28.98 | GAIL+AS  271.46¬±11.90 | SAIL 262.97¬±18.11 | SAIL+AS 270.33¬±15.86[line_break_token]Modified env (renamed as ‚ÄúGoal-terminal‚Äù env in the appendix)[line_break_token]GAIL -7.16¬±31.64 | GAIL+AS 110.22¬±119.25 | SAIL 252.07¬±67.22 | SAIL+AS 258.30¬±20.75[line_break_token][line_break_token]AS improves GAIL significantly in both environments.	I-Reply	I-4	Reply	704
In particular, in the default environment, GAIL+AS has performance comparable to (or slightly better than) SAIL.	I-Reply	I-4	Reply	704
[line_break_token][line_break_token]However, we also observe that: 1) SAIL+AS either outperforms (or is comparable to) GAIL+AS, showing that the proposed approach is generally more favorable than GAIL.	I-Reply	I-4	Reply	704
Also, SAIL+AS has much smaller variance than standard SAIL.	I-Reply	I-4	Reply	704
2) In the modified environment, GAIL+AS is unable  to reach the expert‚Äôs performance and suffers from a high variance, even when it improves significantly upon GAIL.	I-Reply	I-4	Reply	704
On the contrary, SAIL and SAIL+AS are on-par with the expert.	I-Reply	I-4	Reply	704
[line_break_token][line_break_token]To better study the effect of SAIL, we further modified LunarLander to contain no terminal states at all.	I-Reply	I-4	Reply	704
We refer to this setting as NoTerm.	I-Reply	I-4	Reply	704
Here each episode ends only after a fixed time limit (1000 steps).	I-Reply	I-4	Reply	704
In this environment, the absorbing state (AS) method is not applicable.	I-Reply	I-4	Reply	704
We obtain the following returns (updated Table 1 in the paper): [line_break_token][line_break_token]GAIL 169.73¬±80.84 | SAIL 256.83¬±20.99[line_break_token][line_break_token]showing that SAIL is significantly more robust than GAIL also in this setting.	I-Reply	I-4	Reply	704
[line_break_token][line_break_token]In summary, the results on all variants of LunarLander suggests that AS and SAIL both mitigate the implicit reward bias.	I-Reply	I-4	Reply	704
[line_break_token][line_break_token]- On minor points[line_break_token]We thank the reviewer for pointing out the typos, they have been fixed.	B-Reply	B-5	Reply	704
[line_break_token]The bold font highlights the best performance of each row for ease of reading.	B-Reply	B-2	Reply	704
Hopper had 2 because we considered them comparable.	I-Reply	I-2	Reply	704
We have updated the paper to remove the additional highlighting.	I-Reply	I-2	Reply	704
[line_break_token]	O	O	Reply	704

This paper proposes to replace the traditional KL term of VAE with the KL between two conditional distributions, which is to equip the model with the ability to address multimodal data.	O	O	Review	1491
Moreover, the paper also extend the model to add an additional network to predict the label from the reconstructed image to enhance the decoder with supervised information.	B-Review	B-2	Review	1491
[line_break_token][line_break_token]In general, the model is contrived and the  novelty of the paper is incremental.	O	O	Review	1491
Is Eq.	O	O	Review	1491
2 the ELBO of the new model?	O	O	Review	1491
If so, the authors should provide the derivation of the ELBO.	O	O	Review	1491
If not, can you prove the objective is the correct one to be optimized?	O	O	Review	1491
[line_break_token]Moreover, the model is just an trivial extension of VAE and all key techniques are borrowed from existing work (Chen et al 2016).	O	O	Review	1491
[line_break_token][line_break_token]The experiments are only conducted on MNIST and Fashion-MNIST, which is not sufficient.	B-Review	B-1	Review	1491
CIFAT10 should be at least added, and other more challenging benchmarks should also be considered to make the model more solid.	I-Review	I-1	Review	1491
[line_break_token]	O	O	Review	1491
"The experiments are only conducted on MNIST and Fashion-MNIST, which is not sufficient.	O	O	Reply	1491
CIFAT10 should be at least added, and other more challenging benchmarks should also be considered to make the model more solid."	O	O	Reply	1491
[line_break_token][line_break_token]We accept that it is desirable to include additional data sets (something we are currently working on, but that takes time).	B-Reply	B-1	Reply	1491
 Clearly if we were, for example, proposing a new classifier then results on MNIST would clearly be inadequate.	I-Reply	I-1	Reply	1491
 However, for exploring the semantics of latent spaces, MNIST and Fashion-MNIST provide an adequate proof of principle in our judgement.	I-Reply	I-1	Reply	1491
 We cannot see why the latent space embedding would be very different if we used a data set that is visually more complex.	I-Reply	I-1	Reply	1491
 It is unclear to us that the CIFAR-10 data set is the best next step as many of the classes in CIFAR10 seem unrelated (ship and horse) so the learnt semantic embedding is likely to be uninteresting.	I-Reply	I-1	Reply	1491
 CIFAR-100 seems more appropriate, but the relative sparseness of the data makes it big step beyond the MNIST data sets we used.	I-Reply	I-1	Reply	1491
Moving to such a dataset also would require significant changes to the architecture of the encoder and decoder (they would both likely have to be convolutional to achieve good performance), and it is not obvious that this actually adds much to the main point of our paper (which is to demonstrate that our model learns meaningful latent spaces).	I-Reply	I-1	Reply	1491
[line_break_token][line_break_token]To conclude we would once again like to thank the reviewer for their time.	I-Reply	I-1	Reply	1491
In the revised version of the paper, we have addressed the points made by the other reviewers, and hopefully the exposition of the novelty should be even more clear in the revision.	I-Reply	I-1	Reply	1491
We would be happy to respond to any further questions that might arise.	I-Reply	I-1	Reply	1491

The authors propose a new CNN architecture and show results on object and speech recognition.	O	O	Review	293
In particular, they propose a multi-scale CNN module that processes feature maps at various scales.	O	O	Review	293
They show compelling results on IN and a reduction of compute complexity[line_break_token][line_break_token]Pros:[line_break_token](+) The paper is well written[line_break_token](+) The method is elegant and reproducible[line_break_token](+) Results are compelling and experimentation is thorough[line_break_token]Cons:[line_break_token](-) Transfer to other visual tasks, beyond IN, is missing[line_break_token](-) Memory requirements are not mentioned, besides FLOPs, speed and parameters[line_break_token][line_break_token]Overall, the proposed approach is elegant and clear.	B-Review	B-1	Review	293
The impact of the multi-scale module is evident, in terms of FLOPs and performance.	O	O	Review	293
While their approach performs a little worse than NASNet, both in terms of FLOP efficiency and top1-error, it is simpler and easier to train.	O	O	Review	293
I'd like for the authors to also discuss memory requirements for training and testing the network.	B-Review	B-2	Review	293
[line_break_token][line_break_token]Finally, various papers have appeared over the recent years showing improvements over baselines on ImageNet.	B-Review	B-1	Review	293
However, most of these papers are not impactful, because they do not show any impact to other visual tasks, such as detection.	I-Review	I-1	Review	293
On the contrary, methods that do transfer get adopted very fast.	I-Review	I-1	Review	293
I would be much more convinced of this approach, if the authors showed similar performance gains (both in terms of complexity and metrics) for COCO detection.	I-Review	I-1	Review	293
[line_break_token]	O	O	Review	293
We thank the reviewer for the constructive comments.	O	O	Reply	293
[line_break_token][line_break_token]- Transfer capability of bLNet:[line_break_token]We used bLNet as a backbone network for feature extraction in the Faster RCNN + FPN detector.	B-Reply	B-1	Reply	293
[line_break_token]The detection results on PASCAL VOC and COCO datasets are included in Table 10 in Appendix A6.	I-Reply	I-1	Reply	293
[line_break_token]Our bLNet achieves comparable or better accuracy than the baseline detectors while reducing FLOPs by about 1.5 times.	I-Reply	I-1	Reply	293
[line_break_token]Please refer to Table 10 in Appendix A6 for more detail.	I-Reply	I-1	Reply	293
[line_break_token][line_break_token]- Memory requirements of bLNet:[line_break_token]We benchmarked the GPU memory consumption in runtime at both the training and test phases for all the models evaluated in Fig.	B-Reply	B-2	Reply	293
3.	I-Reply	I-2	Reply	293
[line_break_token]The results are shown in Fig.	I-Reply	I-2	Reply	293
5 in Appendix A7.	I-Reply	I-2	Reply	293
The batch size was set to 8, which is the largest number allowed for NASNet on a P100 GPU card (16 GiB memory).	I-Reply	I-2	Reply	293
The image size for any model in this benchmark experiment is the same as that used in the experiment reported in Fig.	I-Reply	I-2	Reply	293
3.	I-Reply	I-2	Reply	293
For bLNet, the input image size is 224x224 in training and 256x256 in test.	I-Reply	I-2	Reply	293
[line_break_token][line_break_token]From Fig.	I-Reply	I-2	Reply	293
5, we can see that bLNet is the most memory-efficient for training among all the approaches.	I-Reply	I-2	Reply	293
[line_break_token]In test, bL-ResNeXt consumes more memory than inception-resnet-v2 and inception-v4 at the same accuracy, [line_break_token]but bL-SEResNeXt outperforms all the approaches.	I-Reply	I-2	Reply	293
Note that NASNet and PNASNet are not memory friendly.	I-Reply	I-2	Reply	293
[line_break_token]This is largely because they are trained on a larger image size (331x331) and these models are composed of many layers.	I-Reply	I-2	Reply	293

This paper first introduces a method for quantifying to what extent a dataset split exhibits compound (or, alternatively, atom) divergence, where in particular atoms refer to basic structures used by examples in the datasets, and compounds result from compositional rule application to these atoms.	O	O	Review	494
The paper then proposes to evaluate learners on datasets with maximal compound divergence (but minimal atom divergence) between the train and test portions, as a way of testing whether a model exhibits compositional generalization, and suggests a greedy algorithm for forming datasets with this property.	O	O	Review	494
In particular, the authors introduce a large automatically generated semantic parsing dataset, which allows for the construction of datasets with these train/test split divergence properties.	O	O	Review	494
Finally, the authors evaluate three sequence-to-sequence style semantic parsers on the constructed datasets, and they find that they all generalize very poorly on datasets with maximal compound divergence, and that furthermore the compound divergence appears to be anticorrelated with accuracy.	O	O	Review	494
[line_break_token][line_break_token]This is an interesting and ambitious paper tackling an important problem.	O	O	Review	494
It is worth noting that the claim that it is the compound divergence that controls the difficulty of generalization (rather than something else, like length) is a substantive one, and the authors do provide evidence of this.	O	O	Review	494
At the same time, I think the authors could possibly do more to show that the trend in the plots in Figure 2 can't be explained by something else: for example, the authors could show that the length ratios remain constant as the compound divergence is varied.	B-Review	B-2	Review	494
 I think it is also not necessarily clear how easily the notion of differing compound distributions generalizes to other types of tasks.	B-Review	B-3	Review	494
[line_break_token][line_break_token]Presentation-wise, much of the paper is clear and well written, though I think the discussion of weighted frequency distributions of compounds (top of page 3) could be clarified further, and in particular an example subgraph of a rule application DAG should be highlighted here.	B-Review	B-1	Review	494
hank you for reading our paper in depth and for the interesting comments and observations.	O	O	Reply	494
[line_break_token][line_break_token]Addressing the specific comments in order:[line_break_token][line_break_token]On (other) explanations for the trend between compound divergence and accuracy which we observe in Figure 2 ("show that the length ratios remain constant as the compound divergence is varied"): We did some further specific analysis to show that length variation (as measured by the length ratios) is not a better explanation for the drop in accuracy.	B-Reply	B-2	Reply	494
We added a paragraph discussing this to the paper in Section 5.2 now.	I-Reply	I-2	Reply	494
Also, we had already observed in Table 3 and the discussion that we did not expect the lengths to stay perfectly constant between train and test splits.	I-Reply	I-2	Reply	494
Note, however, that the splitting algorithm could be extended in a way that would try to achieve maximum compound divergence while keeping both the atom divergence close to zero and the length distribution constant between the splits.	I-Reply	I-2	Reply	494
Here, we focus on the compound divergence as a single measure of compositionality challenge. (	I-Reply	I-2	Reply	494
Compare also the discussion in Section 4: "Interestingly, the MCD splits still correlate with the aspects of compositional generalization that are targeted by the other experiments in this table.	I-Reply	I-2	Reply	494
As shown in the four right columns of Table 3, for each MCD split, the train set V contains on average shorter examples than the test set W (measured by the ratio of average lengths), and [...].	I-Reply	I-2	Reply	494
However, these correlations are less pronounced than for the experiments that specifically target these aspects, and they vary significantly across the different MCD splits.")	I-Reply	I-2	Reply	494
[line_break_token][line_break_token]On using the idea of varying compound divergence for other tasks ("not necessarily clear how easily the notion of differing compound distributions generalizes to other types of tasks"): We agree that this is an interesting direction for future work.	B-Reply	B-3	Reply	494
For example, we believe that a similar approach may be applicable to visual tasks for which the compounds can be programmatically analyzed, e.g. visual question answering tasks like CLEVR.	I-Reply	I-3	Reply	494
We mention this now explicitly in Section 7.	I-Reply	I-3	Reply	494
The same way that splits based on lengths or patterns have been used for natural language compositionality analysis, vision tasks have used specific splits for analysis of compositionality e.g. based on color or pairs of objects in images. (	I-Reply	I-3	Reply	494
We discuss this in Section 6 to some degree.)	I-Reply	I-3	Reply	494
Therefore it seems a reasonable expectation to us that the DBCA approach would also transfer to such tasks.	I-Reply	I-3	Reply	494
[line_break_token][line_break_token]Regarding the "discussion of weighted frequency distributions of compounds": Thank you for your suggestion to clarify this section.	O	O	Reply	494
[line_break_token][line_break_token]We have reworded the relevant paragraph to make it more precise.	B-Reply	B-1	Reply	494
We have also added illustrative examples of subgraphs in Appendix L.4, together with a more detailed explanation of the weight calculation.	I-Reply	I-1	Reply	494
We hope that the more precise presentation and the discussion in the appendix help to clarify this point.	I-Reply	I-1	Reply	494

To my knowledge, this paper is probably the first one to apply few-shot learning concept into high-level computer vision tasks.	O	O	Review	978
In this paper's sense, segmentation.	O	O	Review	978
It proposes a general framework to few from the very few sample, extract a latent representation z, and apply it to do segmentation on a query.	O	O	Review	978
Cases of semantic, interactive and video segmentation are applied.	O	O	Review	978
Experiments are very thorough.	O	O	Review	978
[line_break_token][line_break_token]We see too many variants of few-shot learning papers on mini-imagenet or omniglot.	O	O	Review	978
For the reason of applying to high-level segmentation, the paper already deserves an acceptance for the first work.	O	O	Review	978
I believe this work would inspire many follow-ups in related domain (especially for high-level vision tasks)[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]- what is interactive segmentation?	B-Review	B-1	Review	978
I looked through the related work, it just mentioned some previous work without defining or describing it.	I-Review	I-1	Review	978
[line_break_token][line_break_token]- z is the network output of g?	B-Review	B-2	Review	978
is there any constraint on z?	I-Review	I-2	Review	978
Like Gaussian distributions like what z is like in VAE models.	I-Review	I-2	Review	978
[line_break_token][line_break_token]	O	O	Review	978
Thank you for the review and your enthusiasm for applying few-shot learning to richer visual tasks like segmentation!	O	O	Reply	978
We provide a few clarifications and address the questions listed in your review.	O	O	Reply	978
Given our response here, we would appreciate it if you could comment further regarding[line_break_token][line_break_token]- novelty with respect to the one existing few-shot segmentation method we cite[line_break_token]- clarity of our figure summarizing interactive segmentation and the other segmentation tasks we address (Figure 2)[line_break_token][line_break_token]We agree that few-shot learning need not be limited to image classification and should address higher-level tasks such as different types of segmentation as we show in this work.	B-Reply	B-3	Reply	978
We hope that our work inspires more progress on few-shot learning for structured output tasks for which labels are even more costly and scarce than image-level supervision.	I-Reply	I-3	Reply	978
[line_break_token][line_break_token]Our work is not the first to consider few-shot learning for structured output, but we do significantly generalize the problem scope and extend the approach.	I-Reply	I-3	Reply	978
Shaban et al (2017) consider one-shot semantic segmentation.	I-Reply	I-3	Reply	978
We consider a wider range of tasks (instance, semantic, and video object segmentation), experiment with varying shot and way (from one-shot to 1000+ shot and 2-20 way) beyond the prior 1-5 shot and fixed 2-way of Shaban et al and propose a novel late fusion architecture (that is faster to update during inference).	I-Reply	I-3	Reply	978
[line_break_token][line_break_token]> what is interactive segmentation?	O	O	Reply	978
[line_break_token][line_break_token]Interactive segmentation is the task of inferring dense segmentation masks from sparse pixel-wise labels within the same image (see middle panel of Figure 2 and our references Kass et al 1998, Boykov and Jolly 2001, and Xu et al 2016).	B-Reply	B-1	Reply	978
Guided segmentation is our extension to interactive segmentation that can propagate pixel labels across images and not just within images.	I-Reply	I-1	Reply	978
Guided segmentation is necessary to (1) cumulatively incorporate labels across inputs to keep improving the segmentation and (2) increase data efficiency by not requiring annotations on every input.	I-Reply	I-1	Reply	978
[line_break_token][line_break_token]> is there any constraint on z?	O	O	Reply	978
Like Gaussian distributions like what z is like in VAE models[line_break_token][line_break_token]z is the latent task encoding extracted by the guide branch g (see Figure 1 and Sections 4 & 4.1).	O	O	Reply	978
We do not enforce a distribution over z, although this is a possible extension of our work for regularization or sampling diverse segmentations.	B-Reply	B-2	Reply	978
We are revising the text to make it clear that there is no constraint on the value of z.	I-Reply	I-2	Reply	978

A method is proposed, which learns to reason on physical interactions of different objects (solids like cuboids, tetrahedrons etc.).	O	O	Review	309
Traditionally in related work the goal is to predict/forecast future observations, correctly predicting (and thus learning) physics.	O	O	Review	309
This is also the case in this paper, but the authors explicitly state that the target is to evaluate the learned model on downstream tasks requiring a physical understanding of the modelled environment.	O	O	Review	309
[line_break_token][line_break_token]The main contribution here lies in the fact that no supervision is used for object properties.	O	O	Review	309
Instead, a mask predictor is trained without supervision, directly connected to the rest of the model, ie.	O	O	Review	309
to the physics predictor and the output renderer.	O	O	Review	309
The method involves a planning phase, were different objects are dropped on the scene in the right order, targeting bottom objects first and top objects later.	O	O	Review	309
The premise here is that predicting the right order of the planning actions requires understanding the physics of the underlying scene.	O	O	Review	309
[line_break_token][line_break_token]I particularly appreciated the fact, that object instance renderers are combined with a global renderer, which puts individual images together using predicted heatmaps for each object.	O	O	Review	309
With a particular parametrization, these heatmaps could be related to depth maps allowing correct depth ordering, but depth information has not been explicitly provided during training.	O	O	Review	309
[line_break_token][line_break_token]Important issues:[line_break_token][line_break_token]One of the biggest concerns is the presentation of the planning algorithm, and more importantly, a proper formalization of what is calculated, and thus a proper justification of this part.	B-Review	B-1	Review	309
The whole algorithm is very vaguely described in a series of 4 items on page 4.	I-Review	I-1	Review	309
It is intuitively almost clear how these steps are performed, but the exact details are vague.	I-Review	I-1	Review	309
At several steps, calculated entities are ‚Äúcompared‚Äù to other entities, but it is never said what this comparison really results in.	I-Review	I-1	Review	309
The procedure is reminiscent of particle filtering, in that states (here: actions) are sampled from a distribution and then evaluated through a likelihood function, resulting in resampling.	I-Review	I-1	Review	309
However, whereas in particle filtering there is clear probabilistic formalization of all key quantities, in this paper we only have a couple of phrases which describe sampling and ‚Äúcomparisons‚Äù in a vague manner.	I-Review	I-1	Review	309
[line_break_token][line_break_token]Since the procedure performs planning by predicting a sequence of actions whose output at the end can be evaluated, thus translated into a reward, I would have also liked a discussion (or at least a remark) why reinforcement learning has not been considered here.	B-Review	B-2	Review	309
[line_break_token][line_break_token]I am also concerned by an overclaim of the paper.	B-Review	B-3	Review	309
As opposed to what the paper states in various places, the authors really only evaluate the model on video prediction and not on other downstream tasks.	I-Review	I-3	Review	309
A single downstream task is very briefly mentioned in the experimental section, but it is only very vaguely described, it is unclear what experiments have been performed and there is no evaluation whatsoever.	I-Review	I-3	Review	309
[line_break_token][line_break_token]Open questions:[line_break_token][line_break_token]Why is the proposed method better than one of the oracles?	B-Review	B-4	Review	309
[line_break_token][line_break_token]Minor remarks:[line_break_token][line_break_token]It is unclear what we see in image 4, as there is only a single image for each case (=row) and method (=column).	B-Review	B-5	Review	309
[line_break_token][line_break_token]The paper is not fully self-contained.	B-Review	B-6	Review	309
Several important aspects are only referred to by citing work, e.g. CEM sampling and perceptual loss.	I-Review	I-6	Review	309
These are concepts which are easy to explain and which do not take much space.	I-Review	I-6	Review	309
They should be added to the paper.	I-Review	I-6	Review	309
[line_break_token][line_break_token]A threshold is mentioned in the evaluation section.	B-Review	B-7	Review	309
A plot should be given showing the criterion as a function of this threshold, as is standard in, for instance, pose estimation literature.	I-Review	I-7	Review	309
[line_break_token][line_break_token]I encourage the authors to use the technical terms ‚Äúunary terms‚Äù and ‚Äúbinary terms‚Äù in the equation in section 2.2.	B-Review	B-8	Review	309
This is the way how the community referred to interactions in graphical models for relational reasoning long before deep learning showed up on the horizon, let‚Äôs be consistent with the past.	I-Review	I-8	Review	309
[line_break_token][line_break_token]I do not think that the physics module can be reasonable be called a ‚Äúphysics simulator‚Äù as has been done throughout the paper.	B-Review	B-9	Review	309
It does not simulate physics, it predicts physics after learning, which is not a simulation.	I-Review	I-9	Review	309
[line_break_token][line_break_token]A cube has not been confused with a rectangle, as mentioned in the paper, but with a rectangular cuboid.	B-Review	B-10	Review	309
A rectangle is a 2D shape, a rectangular cuboid is a 3D polyhedron.	I-Review	I-10	Review	309
[line_break_token]	O	O	Review	309
Thank you for your feedback and suggestions.	O	O	Reply	309
We have updated the paper to make the planning algorithm clearer, give short descriptions of CEM and perceptual losses, and incorporate your terminology suggestions (‚Äòrectangular cuboid‚Äô, ‚Äòunary‚Äô, ‚Äòbinary‚Äô, etc).	B-Reply	B-1	Reply	309
At the request of other reviewers, we have also tested our approach on a physical Sawyer robot.	I-Reply	I-1	Reply	309
The following video gives a qualitative result analogous to Figure 4: [line_break_token]goo.gl/151BT1[line_break_token]These results will be included in the paper in a second revision this week.	I-Reply	I-1	Reply	309
Below, we give more details about the current changes.	I-Reply	I-1	Reply	309
[line_break_token][line_break_token]-- Evaluation on downstream tasks [line_break_token]Downstream task results were in the original submission (all Figures after 3 and Table 1); we have updated the paper to better differentiate between image prediction results in isolation and the use of our model‚Äôs predictions in a planning procedure to build towers.	B-Reply	B-3	Reply	309
[line_break_token][line_break_token]Figure 4 shows qualitative results on this building task, and Table 1 gives quantitative results.	I-Reply	I-3	Reply	309
Figures 5 and 6 give some analysis of the procedure by which our model selects actions.	I-Reply	I-3	Reply	309
Figure 7 briefly shows how our model can be adapted to other physics-based tasks: stacking to maximize height, and building a tower to make a particular block stable.	I-Reply	I-3	Reply	309
[line_break_token][line_break_token]-- Planning algorithm[line_break_token]We have added a more precise algorithmic description on page 4 to make the tower-building procedure clearer (Algorithm 1: Planning Procedure).	B-Reply	B-1	Reply	309
[line_break_token][line_break_token]-- Oracle models[line_break_token]We have added a sentence to the Table 1 caption to explain why O2P2 outperforms Oracle (pixels).	B-Reply	B-4	Reply	309
The Oracle (pixels) model has access to the true physics simulator which generated the data, but not an object-factorized cost function.	I-Reply	I-4	Reply	309
Instead, it uses pixel-wise L2 over the entire image (Section 3.2).	I-Reply	I-4	Reply	309
The top row of Figure 4 is illustrative here: the first action taken by Oracle (pixels) was to drop the blue rectangular cuboid in the bottom left to account for both of the blue cubes in the target.	I-Reply	I-4	Reply	309
Our model, despite having a worse physics predictor, performs better by virtue of its object factorization.	I-Reply	I-4	Reply	309
 [line_break_token][line_break_token]-- Figure 4 clarification[line_break_token]We have updated the caption of Figure 4 and changed some text in the graphic.	B-Reply	B-12	Reply	309
Figure 4 shows qualitative results on the tower building task described above.	I-Reply	I-12	Reply	309
We show four goal images (outlined in green), and the towers built by each of five methods.	I-Reply	I-12	Reply	309
This figure has a few utilities:[line_break_token]    1.	I-Reply	I-12	Reply	309
It illustrates what our model‚Äôs representations capture well for planning and what they do not.	I-Reply	I-12	Reply	309
For example, most mistakes made by our model concern object colors.	I-Reply	I-12	Reply	309
This suggests that object positions are more prominently represented by our model‚Äôs representations than color.	I-Reply	I-12	Reply	309
[line_break_token]    2.	I-Reply	I-12	Reply	309
It shows why an object-factorization is still useful even if one has access to the ‚Äútrue‚Äù physics simulator (as discussed in the previous question).	I-Reply	I-12	Reply	309
[line_break_token]    3.	I-Reply	I-12	Reply	309
It shows that the types of towers being built in the downstream task are not represented in the training set of the perception, graphics, and physics modules (depicted in Figure 3, where we show reconstruction and prediction results).	I-Reply	I-12	Reply	309
The object-factorized predictions allow our model to generalize out of distribution more effectively than an object-agnostic video prediction model (Table 1).	I-Reply	I-12	Reply	309
[line_break_token][line_break_token]-- Reinforcement learning baseline[line_break_token]We have found that a PPO agent works poorly on this task, possibly due to the high dimensionality of the observation space (raw images).	B-Reply	B-13	Reply	309
We will continue to try to get this baseline to work for the next revision, and would be happy to try out any other RL algorithms that the reviewer might suggest.	I-Reply	I-13	Reply	309

This paper uses reinforcement learning for automated theorem proving.	O	O	Review	20324
The proposed method aims to generalize the short proofs to longer proofs with similar structure.	O	O	Review	20324
Experiments were run to compare the performance of curriculum learning with the ones without curriculum.	O	O	Review	20324
[line_break_token][line_break_token]Overall the paper attempts to explain clearly the original contribution of the proposed approach, which is using curriculum learning in RL based proof guidance.	O	O	Review	20324
However,  I am not convinced about the how compelling the results are in support of the claim.	B-Review	B-1	Review	20324
The main arguments to bolster my decision are as follows.	O	O	Review	20324
[line_break_token][line_break_token]I am familiar with RL and curriculum learning but not so much with connection tableau calculus.	B-Review	B-1	Review	20324
The description given in the paper seems to be insufficient and confusing for readers with limited knowledge in this area.	I-Review	I-1	Review	20324
A step-by-step explanation with a toy example might have done the job nicely.	I-Review	I-1	Review	20324
Without such a clear understanding of the calculus, it gets hard to appreciate the merits of the results.	I-Review	I-1	Review	20324
[line_break_token][line_break_token]Some claims of the paper are not clearly validated by the reported experimental results.	B-Review	B-2	Review	20324
For example:[line_break_token]- in Table 8, curriculum learning is worse in some cases and better in others.	I-Review	I-2	Review	20324
What to conclude from such a report?	I-Review	I-2	Review	20324
[line_break_token]- in experiment 3, curriculum learning tends to find shorter proofs.	B-Review	B-4	Review	20324
Isn't that contrary to the focus of the paper?	I-Review	I-4	Review	20324
[line_break_token]- in Table 3, curriculum learning performs lot worse than the other method.	B-Review	B-5	Review	20324
What is to be inferred from such a report?	I-Review	I-5	Review	20324
[line_break_token][line_break_token]It would be nice if there was a clear explanation of the role of curriculum in the learning algorithm.	B-Review	B-3	Review	20324
For example, in Algorithm 1, how is Line 8 helping in overall objective of learning longer proofs?	I-Review	I-3	Review	20324
If one advances curriculum, one takes lesser number of proof steps according to stored proofs.	I-Review	I-3	Review	20324
How does that help in the learning?	I-Review	I-3	Review	20324
Does it imply 'less memorizing' with advancement of curriculum?	I-Review	I-3	Review	20324
ear Reviewer,[line_break_token]Thank you for your comments.	O	O	Reply	20324
[line_break_token][line_break_token]It is a challenging task to provide a proper introduction to the connection calculus in such a short paper.	B-Reply	B-1	Reply	20324
However, we did our best to provide illustration on the project webpage <a href="http://bit.ly/site_atpcurr" target="_blank" rel="nofollow">http://bit.ly/site_atpcurr</a> .	O	O	Reply	20324
Here you can find some screencasts and logs that cover few selected problems and include all details of the reasoning.	B-Reply	B-1	Reply	20324
[line_break_token][line_break_token]The primary role of our curriculum is to provide more training signal to the learner, as well as to allow a priori knowledge to the system through proofs (please see the answer given to Rewiever #3).	B-Reply	B-2	Reply	20324
Figure 5 in Appendix B illustrates that curriculum learning indeed yields more reward during training.	I-Reply	I-2	Reply	20324
The upside is that this makes training faster and more stable.	I-Reply	I-2	Reply	20324
However, the downside of better is training is the risk of overfitting.	I-Reply	I-2	Reply	20324
We can see our curriculum as a tradeoff between faster training and higher chance of overfitting.	I-Reply	I-2	Reply	20324
As described in Appendix A, Failure Modes, Stage 3 is very sensitive to overfitting as different proofs of the same problem can yield very different generalization, this is why curriculum can be detrimental.	I-Reply	I-2	Reply	20324
[line_break_token][line_break_token]RL methods are oftenly biased towards shorter solutions: even if no reward discounting is applied, exploration is more likely to find shorter solutions than longer ones.	B-Reply	B-4	Reply	20324
This is true with and without curriculum.	I-Reply	I-4	Reply	20324
What curriculum learning does is to speed up learning once a proof was found.	I-Reply	I-4	Reply	20324
So it is beneficial if used on some "good" proofs and detrimental if used on "bad" proofs.	I-Reply	I-4	Reply	20324
Table 3 shows an example of each scenario (Stage 2 and 3).	I-Reply	I-4	Reply	20324
Assessing the quality of proofs (with respect to generalization) is, we believe, an important research question.	I-Reply	I-4	Reply	20324
[line_break_token][line_break_token]While our project targets to learn to solve hard problems that require long proofs, given a particular problem, we have no incentive to prefer longer proofs of that problem.	I-Reply	I-4	Reply	20324
Our only concern during training is to learn how to generalize to other problems.	I-Reply	I-4	Reply	20324
[line_break_token][line_break_token]The advancement of curriculum is meant to ensure that the system is continuously faced with a "reasonably" hard problem.	B-Reply	B-5	Reply	20324
Once it becomes easy to finish the proof from a particular state, we make things harder by moving the starting state backwards.	I-Reply	I-5	Reply	20324
It is only after we have gone through the full curriculum that the system has been exposed to all the states of the proof.	I-Reply	I-5	Reply	20324
[line_break_token][line_break_token]The reason why we believe our setting is useful for learning long proofs is that we are capable of performing very long rollouts during training time, without facing an exponentially diminishing chance of getting some reward.	B-Reply	B-3	Reply	20324
The system thus trains on long sequences of proof steps	I-Reply	I-3	Reply	20324

Summary: This paper proposes a policy optimization framework for Bayesian RL (BPO).	O	O	Review	419
BPO is based on a Bayesian model-based RL formulation.	O	O	Review	419
Using a Bayesian approach, it is expected to have better trade-off between exploration and exploitation in RL, and be able to deal with model uncertainty as well.	O	O	Review	419
Experiments are done on multiple domains consisting both POMDP planning tasks and RL.	O	O	Review	419
[line_break_token][line_break_token]In general, the paper is well written.	O	O	Review	419
Related work are thoroughly discussed.	O	O	Review	419
In my opinion, the proposed idea is a solid combination of existing techniques: Monte-Carlo sampling (step 3), Bayes belief update, and policy gradient in POMDP (G(PO)MDP).	O	O	Review	419
However, this combination is still worth trying and has been shown to scale to larger problems through the use of deep learning.	O	O	Review	419
[line_break_token][line_break_token]I have some following major concerns about the paper:[line_break_token][line_break_token]- Root sampling (step 3 in Algorithm 1) would result in sampled models that are fixed in every simulation.	B-Review	B-1	Review	419
In a pure nature of Bayes RL, after each update at new observation (step 11: belief update), the model distribution already changes.	I-Review	I-1	Review	419
Thus how does this Algorithm can guarantee an optimal solution for BAMDP?	I-Review	I-1	Review	419
can the authors have more discussions on this point?	I-Review	I-1	Review	419
Does this explain why TRPO (using a mean model) can perform comparably to BPO in Ant?	I-Review	I-1	Review	419
[line_break_token][line_break_token]- Belief representation is based on a Bayes filter which requires discretization.	B-Review	B-2	Review	419
Finely discretized belief would increase the complexity and computation dramatically with the dimension of the latent space.	I-Review	I-2	Review	419
This would result in very slow SIMULATE steps, especially for a long-horizon problem, let alone further computation for BatchPolicyOptimization.	I-Review	I-2	Review	419
[line_break_token][line_break_token]- I wonder how TRPO using RNN would perform in this case, instead of using a wrong starting model (an average model)?	B-Review	B-3	Review	419
Thank you for your feedback.	O	O	Reply	419
In addition to the clarification on belief representation (Section 4) and the newly added section on Bayes filter (Section 5), we would like to answer some of the concerns you have raised.	O	O	Reply	419
[line_break_token][line_break_token]Root sampling results in sampled models that are fixed in every simulation: [line_break_token]This is indeed the correct realization of the BAMDP framework, where the underlying model is fixed but unknown.	B-Reply	B-1	Reply	419
Our algorithm addresses this by fixing the sampled model for the whole episode.	I-Reply	I-1	Reply	419
Since the true model is hidden from the agent, it maintains a belief over the possible models.	I-Reply	I-1	Reply	419
After each belief update, the agent‚Äôs belief over the model changes, but the actual underlying model remains the same.	I-Reply	I-1	Reply	419
A Bayes-optimal agent learns to act such that the uncertainty in the belief distribution reduces to the degree necessary for maximal long-term reward.	I-Reply	I-1	Reply	419
[line_break_token][line_break_token]TRPO on Ant performs well on certain cases but poorly on corner cases.	I-Reply	I-1	Reply	419
The reason why BPO seems to have only marginal gain in this case is due to the particular four-legged nature of Ant, which allows a mean-model agent to walk reasonably under small geometric variation.	I-Reply	I-1	Reply	419
The visualization of a corner case is added in Figure 4.	I-Reply	I-1	Reply	419
[line_break_token][line_break_token][line_break_token]Computational complexity of discretization: [line_break_token]We agree that increasing the belief discretization level increases the time required to perform posterior updates at each timestep.	B-Reply	B-2	Reply	419
Ultimately, this is an implementation detail of the black-box Bayes filter.	I-Reply	I-2	Reply	419
However, we have empirically found that fine discretization of the continuous latent state space may be unnecessary: BPO produces high-performing agents even with a coarse discretization.	I-Reply	I-2	Reply	419
For MuJuCo problems, we outperform the other baselines with only 25 bins to discretize the latent parameter space.	I-Reply	I-2	Reply	419
For the Chain problem, the discretization with 10 bins is as good as or slightly better than 1e2 or 1e3 bins.	I-Reply	I-2	Reply	419
This implies two things: 1) our algorithm is robust to approximate beliefs, and 2) the agent only needs the belief to be sufficiently accurate to inform its actions.	I-Reply	I-2	Reply	419
Due to these properties, we believe that more computationally-efficient approximate Bayes filters can be used without significantly degrading performance.	I-Reply	I-2	Reply	419
[line_break_token][line_break_token][line_break_token]RNN: [line_break_token]As you suggest, a recurrent policy could learn to act with respect to a history of observations.	B-Reply	B-3	Reply	419
In our case, the history of observation is encoded by the belief, so TRPO in the belief space has as much information as an RNN.	I-Reply	I-3	Reply	419
The use of RNN for jointly training the Bayes filter and the policy could certainly be effective, as proposed in (Karkus et al 2017).	I-Reply	I-3	Reply	419

This work presents an extension of Lazaridou et al 2017 (another ICLR submission) to communication between agents with sequence of symbols.	O	O	Review	81
Due to the complexity of the problem (generating a sequence of symbols rather than a single symbol), the authors switch from using 1-hot symbols (and thus RL) to using Gumbel-softmax distribution, thus allowing for training the agents in an end-to-end fashion by backprop.	B-Review	B-2	Review	81
Similar to Lazaridou et al they attempt grounding the communication protocol to natural language (at this point it's not entirely clear to me whether the authors trained the sender on caption generation or the receiver on caption retrieval).	B-Review	B-3	Review	81
Interestingly, when this happens, the induced communication protocol reflects properties of natural language  (as measured by the omission score) while at the same time decreasing the agents' communication performance (from 95% to 52%).	O	O	Review	81
[line_break_token][line_break_token]The fact that a very similar paper has already been accepted in the same venue takes away some of the novelty points.	B-Review	B-1	Review	81
Moreover, the fact that the communicative success with the grounding task decreases so much hints that the proposed way of grounding is not an effective one (also from the text it's not crustal clear how is the grounding achieved as the KL is measured  between the probability of the messages as produced by the sender and some unspecified p_w(m) distribution).	B-Review	B-4	Review	81
Perhaps, the authors need to look into the strength of the regularizer as it seems to be taking over.	I-Review	I-4	Review	81
 The analysis of the appendix is really interesting, as well as the point about hierarchical coding.	O	O	Review	81
[line_break_token][line_break_token]Overall, this is a very intriguing line of research and, as the authors point in the conclusions, many open questions remain.	B-Review	B-6	Review	81
That being said, the current work does feel a bit rushed; many parts are not clear (specifically details regarding the grounding part) and the proposed grounding approach doesn't seem to be effective in terms of communication.	I-Review	I-6	Review	81
[line_break_token][line_break_token]pros:[line_break_token]- extending the rather limited setup of Lazaridou et al to sequences of symbols, resembling more natural language[line_break_token]- to the best of my knowledge, the use of Gumbel-distribution for text generation is novel[line_break_token][line_break_token]cons:[line_break_token]- lack of clarity, especially in the section about grounding[line_break_token]- proposed grounding method is not effective with regards to communicative success[line_break_token]- rather limited novelty (given the emphasis of the ICLR workshop) as work is direct extension of previous work[line_break_token][line_break_token]	B-Review	B-7	Review	81
Thank you very much for your review and feedback.	O	O	Reply	81
 We would like to comment on a couple of your remarks and clarify points which we think were misunderstood.	O	O	Reply	81
[line_break_token][line_break_token]> The fact that a very similar paper has already been accepted in the same venue takes away some of the novelty points.	O	O	Reply	81
[line_break_token][line_break_token]Indeed, the setup is inspired by Lazaridou et al 2017.	B-Reply	B-1	Reply	81
 Though conceptually it seems natural to go from symbols to sequences of symbols, in practice, it is not straightforward to make such an approach scalable and efficient.	I-Reply	I-1	Reply	81
 In fact, though several neural network approaches have been proposed for inducing protocols consisting of single symbols (including Lazaridou et al; see the paper for reference), we believe we are the first to generalize the set-up to sequences of symbols and also to show that using sequences results in more efficient communication than using single symbols.	I-Reply	I-1	Reply	81
Also, apart from the setting, our method and that of Lazaridou et al are very different.	I-Reply	I-1	Reply	81
[line_break_token][line_break_token][line_break_token]> the authors switch from using 1-hot symbols (and thus RL) to using Gumbel-softmax distribution[line_break_token][line_break_token]We would like to emphasize that in the proposed method one-hot symbols are still used during training and testing phases.	B-Reply	B-2	Reply	81
During training and testing, symbols in messages are generated from Categorical distribution (Gumbel-argmax).	I-Reply	I-2	Reply	81
The fact that we have used neither continuous messages nor RL is another aspect which differentiates us from previous work on multi-agent protocol induction.	I-Reply	I-2	Reply	81
[line_break_token][line_break_token]> (at this point it's not entirely clear to me whether the authors trained the sender on caption generation or the receiver on caption retrieval)[line_break_token][line_break_token]Indeed, this kind of grounding is possible, but, in the proposed approach, we neither trained the Sender for the caption generation task nor trained the Receiver for caption retrieval.	B-Reply	B-3	Reply	81
Our grounding process consists of imposing a prior on the communication protocol q(m|t).	I-Reply	I-3	Reply	81
Minimizing the Kullback-Leibler divergence from the natural language to the learned protocol KL[q(m|t)||p_NL(m)] favors generated messages to have a high probability according to the distribution p_NL(m) (natural language) but at the same time should have high entropy.	I-Reply	I-3	Reply	81
[line_break_token][line_break_token]In other words, though the word ‚Äòred‚Äô may not refer to ‚Äòred‚Äô in the protocol, the goal was to ensure that statistical properties of the protocol are similar to these of the natural language, and see what effect it would have on the communicative success.	I-Reply	I-3	Reply	81
  In hindsight, maybe we should not have referred to it as ‚Äògrounding‚Äô, as we now realized it is potentially misleading.	I-Reply	I-3	Reply	81
[line_break_token][line_break_token]> Moreover, the fact that the communicative success with the grounding task decreases so much hints that the proposed way of grounding is not an effective one ... Perhaps, the authors need to look into the strength of the regularizer as it seems to be taking over.	O	O	Reply	81
[line_break_token][line_break_token]In our case, we tested a hypothesis whether favoring ‚Äúnaturalness‚Äù of the protocol makes it more efficient.	B-Reply	B-4	Reply	81
It turns out the answer is no.	I-Reply	I-4	Reply	81
Also, we tested, whether agents would start using, e.g., nouns as nouns, adjectives as adjectives, without us imposing stricter forms of supervision (e.g. training the Sender for caption generation).	I-Reply	I-4	Reply	81
[line_break_token][line_break_token]It worth mentioning that Imaginet establishes an upper bound for any communication protocol that looks like a language from the MSCOCO dataset.	I-Reply	I-4	Reply	81
Any protocol that will obey the proposed KL constraint (will look like MSCOCO language) will have worse performance than the Imaginet model or equal.	I-Reply	I-4	Reply	81
Proposed model has comparable performance to the upper bound (Imaginet).	I-Reply	I-4	Reply	81
[line_break_token][line_break_token]By decreasing the impact of the KL regularizer, the communication protocol will less resemble natural language, and that contradicts the goal of the grounding process.	I-Reply	I-4	Reply	81
Also, one should bear in mind that MSCOCO descriptions were not generated for the referential game, that is why they can be not very discriminative.	I-Reply	I-4	Reply	81
[line_break_token][line_break_token][line_break_token]> ... the KL is measured  between the probability of the messages as produced by the sender and some unspecified p_w(m) distribution)[line_break_token][line_break_token]As we mentioned in the extended abstract,  we used an estimated language model p_œâ(m).	B-Reply	B-5	Reply	81
We implemented p_œâ(m) as an LSTM language model.	I-Reply	I-5	Reply	81
We used image captions of randomly selected (50%) images from the training set to estimate parameters of the language model.	I-Reply	I-5	Reply	81
It is worth mentioning that these images were not used for training the Sender and the Receiver.	I-Reply	I-5	Reply	81
Unfortunately, given the 3-page constraint on the extended abstract, we could not describe all the details of the set-up.	I-Reply	I-5	Reply	81
[line_break_token]	O	O	Reply	81

This paper presents a method for generating 3D objects.	O	O	Review	682
They train a VAE to generate voxel occupancy grids.	O	O	Review	682
Then, they allow a user to generate novel shapes using the learned model by combining latent codes from existing examples.	O	O	Review	682
[line_break_token][line_break_token]Pros:[line_break_token]- The idea of linking affordances to 3D object generation is interesting, and relevant to the machine learning and computer vision communities.	O	O	Review	682
[line_break_token][line_break_token]- They propose to evaluate the quality of the shape based on a physical simulation (Section 4.4.3), which is an interesting idea.	O	O	Review	682
[line_break_token][line_break_token]Cons:[line_break_token]- This paper is not well written.	B-Review	B-1	Review	682
The method is described in too much detail, and the extra length (10 pages) is unnecessary.	I-Review	I-1	Review	682
Cross entropy, VAEs, and many of the CNN details can usually just be cited, instead of being described to the reader.	I-Review	I-1	Review	682
[line_break_token][line_break_token]- The paper uses suggestive terminology, like "functional essence" and "functional arithmetic" for concepts that are fairly mundane (see Lipton and Steinhardt, 2018 for an extended discussion of this issue).	B-Review	B-2	Review	682
For example, the "functional essence" of a class is essentially an average of the VAE latent vectors (Section 3.3.1).	I-Review	I-2	Review	682
The paper claims, without sufficient explanation, that this is computation is motivated by the idea that "form follows function".	B-Review	B-3	Review	682
[line_break_token][line_break_token]- The results are not very impressive.	B-Review	B-4	Review	682
There is no rigorous evaluation.	I-Review	I-4	Review	682
They propose several nice metrics to use (eg.	I-Review	I-4	Review	682
affordance simulation), but the results they present for each metric are quite limited.	I-Review	I-4	Review	682
The qualitative results are also not particularly compelling.	I-Review	I-4	Review	682
[line_break_token][line_break_token]- The paper should more thoroughly evaluate the importance weighting that is described in Section 3.3.2.	B-Review	B-5	Review	682
[line_break_token][line_break_token] - The technical approach (combining VAE vectors to make new shapes) is not particularly novel[[line_break_token][line_break_token]Overall:[line_break_token][line_break_token]The paper should not be accepted in its current form, both due to the confusing writing, and the lack of careful evaluation.	B-Review	B-6	Review	682
[line_break_token]	O	O	Review	682
Thank you for the time you took to review our paper.	O	O	Reply	682
[line_break_token]We appreciate the reviewer's insight in summarising our paper and addressing the main points.	O	O	Reply	682
[line_break_token][line_break_token]Following your remarks, we have reorganised the article, extruding and placing the part about the neural network architecture into an appendix.	B-Reply	B-1	Reply	682
[line_break_token][line_break_token]Regarding the first concern on the structure of the paper, the initial purpose of describing the details of the architecture was to make the paper self-sufficient.	I-Reply	I-1	Reply	682
However, according with the feedback we received from the community, we agree with the reviewer that some details are verbose.	I-Reply	I-1	Reply	682
The part on the neural network architecture was removed from the main body of the paper, and left for an optional appendix.	I-Reply	I-1	Reply	682
[line_break_token][line_break_token]Regarding the second concern on the employed terminology, we re-read the paper by Lipton and Steinhardt, and renamed the term "functional essence" into "functional form" of an object.	B-Reply	B-2	Reply	682
[line_break_token]We preferred this term, as it denotes the purpose of this operation.	I-Reply	I-2	Reply	682
[line_break_token]We also did not name it "averaging of latent vectors" because there  may be multiple methods for extracting this "functional form" (one is presented by us, another one from [2] is cited).	I-Reply	I-2	Reply	682
[line_break_token]We thus preferred to use the term "functional form extraction" for a family of algorithms performing this task.	I-Reply	I-2	Reply	682
[line_break_token][line_break_token]The term "functional arithmetic" makes use of the analogy with the term "shape arithmetic" [1]. Following this parallel, we manipulate latent vectors corresponding to _functionalities_ (as opposed to _shapes_ in the cited reference).	I-Reply	I-2	Reply	682
Thus, we argue to maintain this term.	I-Reply	I-2	Reply	682
[line_break_token][line_break_token]Regarding the computations being motivated by the idea "form follows function":[line_break_token]We follow the principle form follows function, and assume that the form of an object is correlated to its function.	B-Reply	B-3	Reply	682
Moreover, since we extract shape features from a dataset of objects designed by humans for humans, it is reasonable to assume that the employed shapes are close to optimal for performing their intended function.	I-Reply	I-3	Reply	682
We included this mention in the paper.	I-Reply	I-3	Reply	682
[line_break_token][line_break_token]Regarding the third concern on the results:[line_break_token]We would like to point out that (to the best of our knowledge) there are no alternative methods for shape generation conditioned on desired functionalities.	B-Reply	B-4	Reply	682
[line_break_token]Hence, it would be misleading to state that they are not at the level of the state-of-the-art.	I-Reply	I-4	Reply	682
[line_break_token][line_break_token]As this research is based on exploring new concepts, detailed quality of the reconstructions is not the major contribution of our work.	I-Reply	I-4	Reply	682
Rather, we try to formulate a new problem for generating shapes based on functionalities.	I-Reply	I-4	Reply	682
For instance, the generated bathtub-workdesk does provide the desired functionalities, but its aesthetics should improve with further research.	I-Reply	I-4	Reply	682
[line_break_token][line_break_token]Regarding the evaluation of the importance weighting described in Section 3.3.2, we added images of the combination of toilet and bathtub functional forms, to show the interpolation spectrum (see Fig.	B-Reply	B-5	Reply	682
11 in the Appendix).	I-Reply	I-5	Reply	682
[line_break_token]We admit that a rigorous evaluation would have required an evaluation of all the shapes generated using different combination parameters, in order to choose the parameters that consistently provide best results.	I-Reply	I-5	Reply	682
This will become meaningful once we will have a bigger set of affordance/functionality tests.	I-Reply	I-5	Reply	682
[line_break_token]For the moment, we decided to view this multitude of solutions as design proposals, leaving the final choice for the human designer.	I-Reply	I-5	Reply	682
[line_break_token]Hopefully, these new additions brought the paper closer to the desired rigour standard.	I-Reply	I-5	Reply	682
[line_break_token][line_break_token]Regarding the remaining concerns:[line_break_token]Indeed, the employed architecture is not conceptually novel (it is still a 3D autoencoder).	B-Reply	B-6	Reply	682
However, the same paper by Lipton and Steinhardt [3] mentioned above also states that "empirical advances often come about [...] through clever problem formulations [...] or by applying existing methods to interesting new tasks."	I-Reply	I-6	Reply	682
We consider the formulation of the problem of shape design conditioned on desired functionalities/affordances valuable in itself.	I-Reply	I-6	Reply	682
[line_break_token][line_break_token]To summarise, we used the advice from the reviewers and revised accordingly the paper (changes are highlighted in yellow).	O	O	Reply	682
We hope that the quality of the writing has improved.	O	O	Reply	682
[line_break_token][line_break_token]Thank you again for the time invested into this review.	O	O	Reply	682
[line_break_token][line_break_token]References:[line_break_token][1] Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum.	O	O	Reply	682
Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling.	O	O	Reply	682
[line_break_token]In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.),	O	O	Reply	682
Advances in Neural Information Processing Systems 29, pp.	O	O	Reply	682
82‚Äì90.	O	O	Reply	682
Curran Associates, Inc., 2016.	O	O	Reply	682
[line_break_token][line_break_token][2] Larsen, Anders Boesen Lindbo, et al "Autoencoding beyond pixels using a learned similarity metric."	O	O	Reply	682
arXiv preprint arXiv:1512.09300 (2015).	O	O	Reply	682
[line_break_token][line_break_token][3] Lipton, Zachary C., and Jacob Steinhardt. "	O	O	Reply	682
Troubling trends in machine learning scholarship."	O	O	Reply	682
arXiv preprint arXiv:1807.03341 (2018)	O	O	Reply	682

The authors apply linear time subset scanning to find groups of anomalous inputs and network activations.	O	O	Review	20641
They further use this method to detect effects of the same adversarial perturbation algorithm over a set of images.	O	O	Review	20641
[line_break_token]Major comments:[line_break_token]Overall this is quite interesting work, and seems like a promising method to detect groups of anomalies.	O	O	Review	20641
However, this work is not complete without comparison to existing methods, the lack of which makes it impossible to evaluate its usefulness.	B-Review	B-1	Review	20641
See [1,2].[line_break_token][line_break_token]Minor questions/comments:[line_break_token]The results seem to be applied to ReLU activation networks and anomalous signals are described as having higher activation that the background or the clean images.	B-Review	B-2	Review	20641
Could you clear up whether this method works for all activations or just ReLU networks?	I-Review	I-2	Review	20641
[line_break_token]I‚Äôm envisioning a case where the anomalous images are all anomalous because they are all very similar.	B-Review	B-3	Review	20641
If I put 100 of the same (or very similar images) would this be something that this method could detect?	I-Review	I-3	Review	20641
[line_break_token]Your results seem to suggest that adversarial perturbation methods produce adversarial images with activations that are more extreme than natural images.	B-Review	B-4	Review	20641
This doesn‚Äôt seem immediately obvious to me and I would be interested in further exploration of this direction.	I-Review	I-4	Review	20641
[line_break_token]A value of \epsilon=0.02 was used in experiments for BIM.	B-Review	B-5	Review	20641
While I agree that smaller values of \epsilon are harder to detect it would be useful to have an evaluation of performance over smaller values of \epsilon even if these did not perform as well.	I-Review	I-5	Review	20641
[line_break_token][1] Xiong, L., P ÃÅoczos, B., Schneider, J., Connolly, A., VanderPlas, J.: Hierarchical probabilistic models for group anomaly detection.	O	O	Review	20641
In: AISTATS 2011 (2011)[line_break_token][2] Chalapathy R., Toth E., Chawla S. (2019) Group Anomaly Detection Using Deep Generative Models.	O	O	Review	20641
In: ECML PKDD 2018.	O	O	Review	20641
Lecture Notes in Computer Science, vol 11051.	O	O	Review	20641
Springer, Cham	O	O	Review	20641
hank you for bringing this piece to our attention.	B-Reply	B-1	Reply	20641
 Chalapathy R., Toth E., Chawla S. (2019) Group Anomaly Detection Using Deep Generative Models.	I-Reply	I-1	Reply	20641
  A quick review does seem to show a similar philosophy in the goal of detecting patterns that persist across multiple images/inputs.	I-Reply	I-1	Reply	20641
  Future work will consider this in direct comparisons due to their ability to also scale to groups.	I-Reply	I-1	Reply	20641
 [line_break_token][line_break_token]ReLu is actually trickier than sigmoid and tanh in this regard and that is because it is difficult for an activation to be anomalously 'low' due to the large prevalence of '0' activations.	B-Reply	B-2	Reply	20641
 Therefore we only considered anomalously 'high' activations.	I-Reply	I-2	Reply	20641
 (The difference is simply defining a left or right tailed pvalues).	I-Reply	I-2	Reply	20641
  With sigmoid and tanh it is possible to define anomalous in either direction (i.e. 2 tailed pvalues).	I-Reply	I-2	Reply	20641
 However, we felt that relu seems to be the most common activation function and did not want give the impression that a user's  model would have to be retrained before being 'scannable'.	I-Reply	I-2	Reply	20641
 [line_break_token][line_break_token]We briefly considered scanning over 'pre-relu' activations which does have a notion of some activations being more negative than others.	I-Reply	I-2	Reply	20641
 This did not help detection performance.	I-Reply	I-2	Reply	20641
 We suspect its because in terms of propagating information through the network, a severely negative activation (pre-relu) is no different than a barely negative one (post-relu).	I-Reply	I-2	Reply	20641
 In short, scanning for larger than expected values on post-relu activations was the best balance for direct explanations of the overall process.	I-Reply	I-2	Reply	20641
 [line_break_token][line_break_token]Excellent question on performance whether an anomalous pattern would be detected by a dominant class of the same image type (and all clean examples).	B-Reply	B-3	Reply	20641
 We did not consider that.	I-Reply	I-3	Reply	20641
 Our clean images in the test sets were always constructed with a uniform sampling from the larger group of images.	I-Reply	I-3	Reply	20641
 This means that each class would've been equally represented.	I-Reply	I-3	Reply	20641
 We suspect the correct way to explore this would be through evaluating the role that alpha_max plays.	I-Reply	I-3	Reply	20641
 We currently have an agnostic role of alpha_max by leaving it at 0.5.	I-Reply	I-3	Reply	20641
 By decreasing this value we would be giving preference to a smaller number of nodes that produce more extreme (smaller pvalue) activations.	I-Reply	I-3	Reply	20641
  This parameterization would likely downplay the role of the scenario you described.	I-Reply	I-3	Reply	20641
 In fact, we currently estimate that an alpha_max value of 0.5 is too high.	I-Reply	I-3	Reply	20641
 A smaller value may potentially decrease recall, but drastically increase precision.	I-Reply	I-3	Reply	20641
 This type of question is easily addressed if we wish to go into supervised detection.	I-Reply	I-3	Reply	20641
 However, at that point the more interesting question is which layers provide the best detection power.	I-Reply	I-3	Reply	20641
[line_break_token][line_break_token]Re: Noised examples producing more extreme activations than clean ones.	B-Reply	B-4	Reply	20641
 Other work in this space <a href="https://arxiv.org/pdf/1810.08676.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1810.08676.pdf</a> considers detection power over multiple layers of a smaller, simpler network.	O	O	Reply	20641
  Detection power varies across layers and, critically to your point, in some layers the noised examples produced much more 'boring' activations than clean ones.	B-Reply	B-4	Reply	20641
 This is noted by a AUC value &lt;&lt; 0.5.	O	O	Reply	20641
 The authors of that piece propose that adversarial noise is running 'interference' by removing the signal normally present in clean images.	B-Reply	B-4	Reply	20641
Once that signal is removed, a new label assignment can be made trivially.	I-Reply	I-4	Reply	20641
   The current work under review only considers the final convolution layer for scanning.	I-Reply	I-4	Reply	20641
  It is possible that other layers provide higher detection results, or as shown in the arxiv piece, some layers may appear 'hollow' for noised images.	I-Reply	I-4	Reply	20641

The paper studies a phenomenon of unusual memorisation in deep overparametrized neural networks.	O	O	Review	20462
[line_break_token]Authors observe that, if an auto-encoder overfits to machine precision on a number of images, they can be reliably decoded from random noise and that it is even possible to memorise this way a sequence of images.	O	O	Review	20462
[line_break_token]Essentially, images from such a training set become attractors for the mapping defined by the auto-encoder.	O	O	Review	20462
[line_break_token]The impact of network size, nonlinearity and initialization is studied and, quite surprisingly, very unusual trigonometric non-linearities performed the best.	O	O	Review	20462
[line_break_token][line_break_token]I find the studied phenomenon rather interesting and the analysis well-performed, but I am not sure how practically important is this work.	B-Review	B-2	Review	20462
[line_break_token]First, I would argue that to call the overfit auto-encoder a function associative memory, it must be able to retrieve stored images not just from random noise, but from a somehow distorted or partially known version.	I-Review	I-2	Review	20462
[line_break_token]Otherwise we are just left with a ridiculously large network that can only recall a handful of images we could store in the raw format using much less numbers.	I-Review	I-2	Review	20462
[line_break_token]Second, training until convergence takes prohibitively long time.	B-Review	B-3	Review	20462
[line_break_token][line_break_token]I would be also interested to at least an interesting discussion, if not an answer, to the question of why and how exactly trained images become attractors.	I-Review	I-3	Review	20462
[line_break_token][line_break_token]In terms of novelty, it feels like Zhang et al, 2019 already studied a very similar phenomenon and the submitted paper does not add much to understanding of memorisation in neural networks.	B-Review	B-1	Review	20462
However, memorization of sequences was indeed a surprise.	I-Review	I-1	Review	20462
[line_break_token][line_break_token]Overall, I do not have a strong opinion on rejecting the paper, it just feels like more work in this direction will make the paper significantly better.	O	O	Review	20462
e thank the reviewer for the comments and  emphasizing that the phenomenon we identify is interesting and that our analysis is well performed.	O	O	Reply	20462
 [line_break_token][line_break_token]Regarding the comparison to Zhang et al, 2019:  We would like to point out that the first arXiv version of our paper precedes the first version of Zhang, et al Just like our paper, Zhang, et al has only been presented in a workshop, which does not count as a refereed publication.	B-Reply	B-1	Reply	20462
 Furthermore, a version of Zhang, et al is concurrently under review in this same venue.	I-Reply	I-1	Reply	20462
  Therefore, we strongly feel that our paper should be reviewed on its own merits and not compared against Zhang, et al[line_break_token][line_break_token]In terms of the importance of this result, our method is the first for training a model to store and recover high dimensional inputs up to numerical precision.	B-Reply	B-2	Reply	20462
Moreover, there is considerable interest in understanding the similarities and differences in artificial neural networks and biological neural networks.	I-Reply	I-2	Reply	20462
Our results point to a biologically plausible mechanism for memory retrieval (while the biological plausibility of the training process still remains an open question).	I-Reply	I-2	Reply	20462
Namely, we show that iterating a trained autoencoder allows retrieving stored images.	I-Reply	I-2	Reply	20462
 Our results also suggest an interesting hypothesis for biological neural networks, which we are currently following up on with neuroscientists.	I-Reply	I-2	Reply	20462
We demonstrated that it is ‚Äúeasier‚Äù for an artificial neural network to store sequences of images instead of individual images, or more precisely, smaller networks can be used to store sequences of images as compared to the same number of single images.	I-Reply	I-2	Reply	20462
Similar phenomena may be observed in biological neural networks.	I-Reply	I-2	Reply	20462
 [line_break_token][line_break_token]Moreover, a question of considerable interest in machine learning is the identification of the inductive bias of neural networks.	B-Reply	B-3	Reply	20462
In the overparameterized setting, a neural network can achieve zero training error.	I-Reply	I-3	Reply	20462
There are many different functions that can achieve zero training error.	I-Reply	I-3	Reply	20462
What are the functions learned by a neural network, i.e. what is its inductive bias?	I-Reply	I-3	Reply	20462
Our study identifies a novel form of inductive bias of deep networks that persists across different architectures: deeper networks tend to store training examples as attractors.	I-Reply	I-3	Reply	20462
This means that deep networks learn functions that are contractive at the training examples, a form of self-regularization.	I-Reply	I-3	Reply	20462
[line_break_token][line_break_token]By the definition of an attractor, iterating the network on points within an open set around an attractor will converge to the attractor.	I-Reply	I-3	Reply	20462
 Hence, the model does represent associative memory as small perturbations to an attractor (i.e. a point within this open set) will converge to the attractor upon iterating the network.	I-Reply	I-3	Reply	20462
 Importantly, this condition is a mathematical guarantee for associative memory.	I-Reply	I-3	Reply	20462
 Hence, the networks learned do implement associative memory mechanisms with mathematically verifiable conditions on which training examples are attractors.	I-Reply	I-3	Reply	20462
 We will add some experiments to highlight this in the revision.	I-Reply	I-3	Reply	20462

I have read the authors response.	O	O	Review	20247
In the response the authors clarified the contributions of this paper.	O	O	Review	20247
I agree with the authors that the analysis of gradient descent-ascent is a difficult problem, and the optimization results given in this paper is a contribution of importance.	O	O	Review	20247
Because of this I have improved my score.	O	O	Review	20247
[line_break_token][line_break_token]However, I do not agree with the authors that studying quadratic discriminators instead of more complicated ones should be considered as a contribution instead of drawback.	B-Review	B-1	Review	20247
In my opinion, as long as the focus is on WGAN, results involving standard neural networks are still more desired compared with the results in this submission.	I-Review	I-1	Review	20247
For example, similar results for a neural network discriminator might be even more impactful, because the optimization problem is even more difficult.	I-Review	I-1	Review	20247
Therefore I still consider the simple discriminator and generator as a weak point of this paper.	I-Review	I-1	Review	20247
[line_break_token][line_break_token][line_break_token]======================================================================================================[line_break_token][line_break_token]This paper studies the training of WGANs with stochastic gradient descent.	O	O	Review	20247
The authors show that for one-layer generator network and quadratic discriminator, if the target distribution is modeled by a teacher network same as the generator, then stochastic gradient descent-ascent can learn this target distribution in polynomial time.	O	O	Review	20247
The authors also provide sample complexity results.	O	O	Review	20247
[line_break_token][line_break_token]The paper is well-written and the theoretical analysis seems to be valid and complete.	O	O	Review	20247
However, I think the WGANs studied in this paper are simplified too much that the analysis can no longer capture the true nature of WGAN training.	B-Review	B-2	Review	20247
[line_break_token][line_break_token]First, the paper only studies linear and quadratic discriminators.	B-Review	B-3	Review	20247
This is not very consistent with the original intuition of WGAN, which is to use the worst Lipschitz continuous neural network to approximate the worst function in the set of all Lipschitz continuous functions in the definition of Wasserstein distance.	I-Review	I-3	Review	20247
When the discriminator is as simple as linear or quadratic functions, there is pretty much no ‚ÄúWasserstein‚Äù in the optimization problem.	I-Review	I-3	Review	20247
[line_break_token][line_break_token]Moreover, the claim that SGD learns one-layer networks can be very misleading.	B-Review	B-4	Review	20247
In fact what is a ‚Äúone-layer‚Äù neural network?	I-Review	I-4	Review	20247
[line_break_token]- if the authors meant ‚Äútwo-layer network‚Äù or ‚Äúsingle hidden layer network‚Äù, then this is not true.	I-Review	I-4	Review	20247
Because as far as I can tell, the model is much more difficult than the model.	I-Review	I-4	Review	20247
The former is a standard single hidden layer network which is non-convex, while the latter is essentially a linear model especially when \phi is known.	I-Review	I-4	Review	20247
[line_break_token]- if the authors meant ‚Äúa linear model with elementwise monotonic transform‚Äù, then I would like to suggest that a more appropriate name should be used to avoid unnecessary confusion.	I-Review	I-4	Review	20247
[line_break_token][line_break_token]As previously mentioned, the discriminators are too simple to approximate the Wasserstein distance, and therefore in general it should not be possible to guarantee recovery of the true data distribution.	B-Review	B-5	Review	20247
However, in this paper it is still shown that certain true distributions can be learned.	I-Review	I-5	Review	20247
This is due to the extremely simplified true model.	I-Review	I-5	Review	20247
In fact, even if the activation function is unknown, it seems that one can still learn well (for example, by Kendall‚Äôs tau).	I-Review	I-5	Review	20247
[line_break_token]	O	O	Review	20247
hank you for your reviews.	O	O	Reply	20247
Unfortunately there is a significant misunderstanding of our contributions.	O	O	Reply	20247
We will try to clarify some concerns here and hope it will justify our contributions more clearly.	O	O	Reply	20247
[line_break_token][line_break_token]We want to emphasize our contributions first.	O	O	Reply	20247
[line_break_token]1.	O	O	Reply	20247
To begin with, the global convergence of gradient descent-ascent in the GAN setting has not been extensively studied.	B-Reply	B-1	Reply	20247
We provide the to show for.	I-Reply	I-1	Reply	20247
The difficulty in analyzing gradient descent-ascent is twofold: the generator dynamics and discriminator dynamics.	I-Reply	I-1	Reply	20247
On the discriminator side, our choice of quadratic discriminator not only simplifies the dynamics but also has sufficient discriminating power (we will justify it  below).	I-Reply	I-1	Reply	20247
On the generator side, its minimization problem is non-convex, and therefore our convergence result to global equilibria is highly non-trivial.	I-Reply	I-1	Reply	20247
Our primary contribution in gradient descent-ascent analysis is to choose a proper discriminator set and to understand the generator dynamics.	I-Reply	I-1	Reply	20247
[line_break_token][line_break_token]2.	O	O	Reply	20247
For the generator class we are considering, we proved the quadratic discriminator both and (see point 3 below).	B-Reply	B-1	Reply	20247
Had we chosen to use a more complex discriminator, even if the maximization step were tractable, this would increase the sample complexity, potentially to a non-parametric rate (Feizi et al 2017; Bai et al 2018).	I-Reply	I-1	Reply	20247
[line_break_token][line_break_token]3.	O	O	Reply	20247
Our sample analysis also matches the upper bound of on dependence of the error provided in (Wu et al 2019).	B-Reply	B-1	Reply	20247
This is also a side proof that with WGAN we could via.	I-Reply	I-1	Reply	20247
[line_break_token][line_break_token]Next we justify our choice of discriminator class.	O	O	Reply	20247
[line_break_token]We want to emphasize that our goal is to show that SGD learns the ground truth generating distribution, with minimal requirements for the discriminator class.	B-Reply	B-3	Reply	20247
[line_break_token][line_break_token]Our choice of discriminator class, quadratic discriminators, already to learn the family of distributions parametrized by our generator class.	I-Reply	I-3	Reply	20247
As shown in Theorem 3, the quadratic discriminator class is sufficient to learn the optimal generator.	I-Reply	I-3	Reply	20247
In fact using a larger discriminator family will only make the learning harder by increasing the sample complexity; see (Feizi et al 2017; Bai et al 2018) for a discussion of the importance of appropriately constraining the discriminator class to attain parametric sample complexity.	I-Reply	I-3	Reply	20247
Our choice of small discriminator class is a strength, not a weakness.	I-Reply	I-3	Reply	20247
[line_break_token][line_break_token]When more complex discriminators are necessary (on studying more complicated generators for future work), we believe the discriminator dynamics can be analyzed using recent developments in the training of neural networks for classification problems (e.g. NTK results).	I-Reply	I-3	Reply	20247
However, this is not the focus of our paper since we are learning to recover one-layer generator, which does not need a complex discriminator.	I-Reply	I-3	Reply	20247
[line_break_token][line_break_token]Finally we clarify some other points you‚Äôve raised.	O	O	Reply	20247
[line_break_token]Q: ‚Äúwhat is one-layer generator‚Äù &amp; ‚Äúit can be learned easily‚Äù[line_break_token]A: By one-layer generator we mean the second case as you have suggested.	B-Reply	B-4	Reply	20247
This terminology is also used in some prior work, for instance in (Wu et al 2019).	I-Reply	I-4	Reply	20247
As we have emphasized, our goal is not just to learn the one-layer generator by any method, but to understand the dynamics of gradient descent-ascent with WGAN on learning the distribution.	I-Reply	I-4	Reply	20247
We also demonstrate the near optimal sample complexity when learning with WGAN.	I-Reply	I-4	Reply	20247
Even though the generator is a simple formulation, this work still provides the first result on successful learning a non-linear generator with WGAN setting.	I-Reply	I-4	Reply	20247
[line_break_token][line_break_token]Reference:[line_break_token](Feizi et al 2017) Feizi, S., Farnia, F., Ginart, T., &amp; Tse, D. (2017).	O	O	Reply	20247
Understanding GANs: the LQG setting.	O	O	Reply	20247
arXiv preprint arXiv:1710.10793.	O	O	Reply	20247
[line_break_token](Bai et al 2018) Bai, Y., Ma, T., &amp; Risteski, A. (2018).	O	O	Reply	20247
Approximability of discriminators implies diversity in GANs.	O	O	Reply	20247
arXiv preprint arXiv:1806.10586.	O	O	Reply	20247
[line_break_token](Wu et al 2019) Wu, S., Dimakis, A. G., &amp; Sanghavi, S, ‚ÄúLearning Distributions Generated by One-Layer ReLU Networks‚Äù, NeurIPS 2019	O	O	Reply	20247

This paper addresses the issue of interpretability of GAN generation through an alternative approach to the introduction of variability.	O	O	Review	736
To seed the generation, instead of providing a random input vector (typically sampled from a standard Gaussian distribution), the authors instead modify the generator architecture so as to allow for randomization in the routing: each layer is replaced by a bucket consisting of several blocks, and in forward propagation only through randomly chosen blocks.	O	O	Review	736
In this case, the input vector is chosen to be a constant - the only source of randomization[line_break_token]provided to the generator is in the choice of blocks through which to propagate.	O	O	Review	736
The explanability derives from the tendency of blocks to associate with a common interpretation after training.	O	O	Review	736
Their use of blocks necessitates the introduction of a block diversity loss, to discourage mode collapse.	O	O	Review	736
The scheme is referred to as RPGAN, for "Random Path GAN".	O	O	Review	736
[line_break_token][line_break_token]The main strengths of the paper:[line_break_token][line_break_token](1) Their proposed approach is highly flexible.	O	O	Review	736
In principle, any underlying GAN architecture can be adapted by assigning each layer to a distinct bucket, and then replicating the layer across the blocks.	O	O	Review	736
[line_break_token][line_break_token](2) Experimental results do show that different block sequences are associated with common image characteristics after training, especially for the initial and final layers.	O	O	Review	736
[line_break_token][line_break_token](3) The use of non-standard ways of introducing stochasticity to GAN generation is an interesting idea in itself.	O	O	Review	736
[line_break_token][line_break_token]The main weaknesses:[line_break_token][line_break_token](1) Although the authors provide experimental examples showing images associated with various paths through the architecture, is not clear how interpretations can be associated with these paths.	B-Review	B-1	Review	736
In the examples presented, there seems to be a tendency for greater interpretability at the initial and final layers, with the explanation given for the intermediate layers being less convincing.	I-Review	I-1	Review	736
[line_break_token][line_break_token](2) The number of experimental examples is low, yet the authors draw rather firm conclusions (end of Section 4.1) regarding interpretability across layers.	B-Review	B-2	Review	736
I am not sure that their conclusions adequately capture what is going on here, nor am I convinced that they generalize to other situations.	I-Review	I-2	Review	736
[line_break_token][line_break_token](3) The number of buckets limits the numbers of explanations.	B-Review	B-3	Review	736
Essentially, the method has the same difficulties as in clustering, where specifying too many or too few groups can profoundly influence the nature and quality of the result.	I-Review	I-3	Review	736
Although the authors do discuss an approach by which the number of buckets can be incrementally increased (thereby allowing for variation in the number of explanations generated), the experimental evidence is insufficient.	I-Review	I-3	Review	736
[line_break_token][line_break_token](4) Presumably, the replication of a layer across the blocks assigned to its bucket would require more training data and/or greater training times.	B-Review	B-4	Review	736
What is the relationship in both time and quality between the original GAN network and its RPGAN versions?	I-Review	I-4	Review	736
[line_break_token][line_break_token](5) There are many presentational problems with this paper, in grammar, vocabulary and terminology, sentence structure, etc.	B-Review	B-5	Review	736
[line_break_token][line_break_token]Overall, in its current state (not least due to presentational issues) the paper appears to be below the acceptance threshold.	O	O	Review	736
[line_break_token]	O	O	Review	736
hank you for your time and comments; we address the items from your weaknesses list below.	O	O	Reply	736
[line_break_token][line_break_token]1) [is not clear how interpretations can be associated with these paths.]	O	O	Reply	736
[line_break_token]To avoid possible confusion: the interpretations are associated with buckets, not with paths.	B-Reply	B-1	Reply	736
Varying active blocks in each bucket we get an understanding of what factors of variations are captured by this bucket.	I-Reply	I-1	Reply	736
For instance, in Figure 3, using different blocks in the fourth bucket results in images with the same content but of different colors, which indicates that the fourth bucket is ‚Äúresponsible for‚Äù coloring.	I-Reply	I-1	Reply	736
As another example, varying blocks in the first bucket shows that this bucket mostly determines an object location on the image.	I-Reply	I-1	Reply	736
[line_break_token][line_break_token](2) [I am not convinced that the conclusions generalize to other situations.]	O	O	Reply	736
[line_break_token]We do not claim that the layers‚Äô roles identified in the section 4.1 are the same for all datasets and generator architectures.	B-Reply	B-2	Reply	736
Moreover, Figure 6 (left) of the original submission demonstrates that on MNIST, the first bucket is responsible for image semantics, while on CIFAR10 semantics is determined by the intermediate buckets.	I-Reply	I-2	Reply	736
[line_break_token]However, we argue that the RPGAN tool is general: it allows to analyze the roles of different generator layers on any datasets.	I-Reply	I-2	Reply	736
As an addition, we accomplish the RPGAN results with a number of experiments on other domains, model architectures and learning strategies.	I-Reply	I-2	Reply	736
Namely, we show that the concept works for DCGAN-like generators trained as Wasserstein-GP GANs on colored MNIST, CIFAR10 and CelebA datasets (see Figures 8, 19, 21).	I-Reply	I-2	Reply	736
[line_break_token][line_break_token](3) [The number of buckets limits the numbers of explanations.]	O	O	Reply	736
[line_break_token]To avoid confusion between \textit{buckets} and \textit{blocks}: each bucket corresponds to the particular generator layer, while different blocks denote different replications of this layer inside the bucket.	B-Reply	B-3	Reply	736
The number of buckets hence equals to the number of layers in the generator.	I-Reply	I-3	Reply	736
The number of blocks in all our experiments equals 10-40, e.g., see Figure 7.	I-Reply	I-3	Reply	736
In all our experiments, a few dozens of images are enough to understand the factors of variations, corresponding to the particular buckets.	I-Reply	I-3	Reply	736
[line_break_token][line_break_token](4)[What is the relationship in both time and quality between the original GAN network and its RPGAN versions?]	O	O	Reply	736
[line_break_token]In all our experiments, we use completely the same training protocols for both RPGAN and the original GAN.	B-Reply	B-4	Reply	736
Both models are always trained on the same data, with the same number of steps for generator/discriminator, etc, see the beginning of Section 4.	I-Reply	I-4	Reply	736
In terms of wall-clock time, there were no differences in training time for both models on our hardware and the implementations from the code <a href="https://github.com/rpgan-ICLR2020/RPGAN."	O	O	Reply	736
target="_blank" rel="nofollow">https://github.com/rpgan-ICLR2020/RPGAN.</a>[line_break_token][line_break_token](5) In a new revision, we have largely rewritten the text and expect it to be easier to follow.	B-Reply	B-5	Reply	736

This paper shows that we can relate the solution of specific autoencoder to the data generating distribution.	O	O	Review	10
Specifically solving for general reconstruction function with regularizer that is the L2 penalty of reconstruction contraction relates the reconstruction function derivative of the data probability log likelihood.	O	O	Review	10
This is in the limit of small regularization.	O	O	Review	10
The paper also shows that in the limit of small penalty this autoencoder is equivalent to denoising autoencoder with small noise.	O	O	Review	10
[line_break_token][line_break_token]Section 3.2.3: You get similar attractive behavior using almost any autoencoder with limited capacity.	B-Review	B-1	Review	10
The point of your work is that with the specific form of regularization - square norm of contraction of r - the r(x)-x relates to derivative of log probability (proof seem to require it - it would be interesting to know what can be said about other regularizers).	I-Review	I-1	Review	10
It would be good to compare these plots with other regularizers and show that getting log(p) for contractive one is somehow advantageous.	I-Review	I-1	Review	10
Otherwise this section doesn't support this paper in any way.	I-Review	I-1	Review	10
[line_break_token][line_break_token]As authors point out, it would be good to know something not in the limit of penalty going to zero.	B-Review	B-2	Review	10
At least have some numerical experiments, for example in 1d or 2d.	I-Review	I-2	Review	10
[line_break_token][line_break_token]Figure 4. - '	B-Review	B-3	Review	10
Top plots are for one model and bottom plots for another' - what are the two models?	I-Review	I-3	Review	10
It would be good to specify this in the figure, e.g. denosing autoencoders with different initial conditions and parameter settings.	I-Review	I-3	Review	10
[line_break_token][line_break_token]Section 3.2.5 is important and should be written a little more clearly.	B-Review	B-4	Review	10
[line_break_token][line_break_token]I would suggest deriving (13) in the appendix directly from (11) without having the reader recall or read about Euler-Lagrange equations, and it might actually turn out to be simpler.	B-Review	B-5	Review	10
Differentiating the first term with r(x) gives r(x)-x.	I-Review	I-5	Review	10
For the second term one moves the derivative to the other size using integration by parts (and droping the boundary term) and then just applying it to the product p(x)dr/dx resulting in (13).	I-Review	I-5	Review	10
[line_break_token][line_break_token]Minor - twice you say in the appending that the proof is in the appendinx (e.g. after statement of theorem 1)[line_break_token][line_break_token]The second last sentence in the abstract is uncomfortable to read.	B-Review	B-7	Review	10
[line_break_token][line_break_token]This is probably not important, but can we assume that r given by (11) actually has a taylor expansion in lambda? (	B-Review	B-9	Review	10
probably, but in the spirit of prooving things).	I-Review	I-9	Review	10
[line_break_token][line_break_token]You don't actually derive formulas the second moments in the appendix like you do for the first moment, you mean they can similarly be derived?	B-Review	B-6	Review	10
> It would be good to compare these plots with other regularizers and show that getting log(p) for contractive one is somehow advantageous.	O	O	Reply	10
[line_break_token][line_break_token]We have worked on the denoising/contracting auto-encoders with squared error because we were able to prove our results with them, but we believe that other regularized auto-encoders (even those with discrete inputs) also estimate something related to the score, i.e., the direction in input space in which probability increases the most.	B-Reply	B-1	Reply	10
The intuition behind that statement can be obtained by studying figure 2: the estimation of this direction arises out of the conflict between reconstructing training examples well and making the auto-encoder as constant (regularized) as possible.	I-Reply	I-1	Reply	10
[line_break_token][line_break_token]Other regularizers (e.g. cross-entropy) as well as the challenging case of discrete data are in the back of our minds and we would very much like to extend mathematical results to these settings as well.	I-Reply	I-1	Reply	10
[line_break_token]We have added a brief discussion in the conclusion about how we believe these results could be extended to models with discrete inputs, following the tracks of ratio matching (Hyvarinen 2007).	I-Reply	I-1	Reply	10
[line_break_token][line_break_token]We have also added (in new sec.	I-Reply	I-1	Reply	10
3.2.3) a brief discussion of how these new results (on r(x)-x estimating the score) contradict previous interpretations of the reconstruction error of auto-encoders (Ranzato & Hinton NIPS 2007) as being akin to an energy function.	O	O	Reply	10
Indeed whereas both interpretations agree on having a low reconstruction error at training examples, the score interpretation suggests (and we see it experimentally) other (median) regions that are local maxima of density, where the reconstruction error is also low.	B-Reply	B-1	Reply	10
[line_break_token][line_break_token]> it would be good to know something not in the limit of penalty going to zero[line_break_token][line_break_token]We agree.	B-Reply	B-2	Reply	10
We did a few artificial data experiments.	I-Reply	I-2	Reply	10
In fact, we ran the experiment shown in section 3.2.2 using values of lambda ranging from 10^-6 to 10^2 to observe the behavior of the optimal solutions when the penalty factor varies smoothly.	I-Reply	I-2	Reply	10
The optimal solution degrades progressively into something comparable to what is shown in Figure 2.	I-Reply	I-2	Reply	10
It becomes a series of increasing plateaus matching the density peaks.	I-Reply	I-2	Reply	10
Regions of lesser density are used to 'catch up' with the fact that the reconstruction function r(x) should be relatively close to x.[line_break_token][line_break_token][line_break_token]> Figure 4. - '	O	O	Reply	10
Top plots are for one model and bottom plots for another' - what are the two models?	O	O	Reply	10
It would be good to specify this in the figure, e.g. denosing autoencoders with different initial conditions and parameter settings.	O	O	Reply	10
[line_break_token][line_break_token]We have addressed this concern that many of the reviewers had.	B-Reply	B-3	Reply	10
The whole section 3.2.3 has been edited and we decided to remove two of the plots which may have introduced confusion.	I-Reply	I-3	Reply	10
Reviewers seem to focus on the difference between the two models and wanted to know why the outcomes were different.	I-Reply	I-3	Reply	10
They were only different because of the non-convexity of the problem and the dependance on initial conditions (along with the random noise used for training).	I-Reply	I-3	Reply	10
At the end of the day, the point is that the vector field points in the direction of the energy gradient, and that is illustrated nicely by the two plots left (far and close distance).	I-Reply	I-3	Reply	10
[line_break_token][line_break_token]> Section 3.2.5 is important and should be written a little more clearly.	O	O	Reply	10
[line_break_token][line_break_token]We have reworked that section (now identified as 3.2.6), to emphasize the main point: whereas Vincent 2011 showed that denoising auto-encoders with a particular form estimated the score, our results extend this to a very large family of estimators (including the non-parametric case).	B-Reply	B-4	Reply	10
The section also shows how to interpret Vincent's results so as to show that any auto-encoder whose reconstruction function is a derivative of an energy function can be shown to estimate a score.	I-Reply	I-4	Reply	10
Instead, the rest of our paper shows that we achieve an estimator of the score even without that strong constraint on the form of the auto-encoder.	I-Reply	I-4	Reply	10
[line_break_token][line_break_token]> I would suggest deriving (13) in the appendix directly from (11) without having the reader recall or read about Euler-Lagrange equations[line_break_token][line_break_token]We must admit to not having understood the hints that you have given us.	B-Reply	B-5	Reply	10
If indeed there was such a way to, as you say, spare the reader the headaches of Euler-Lagrange, we agree that it would be an interesting approach.	I-Reply	I-5	Reply	10
[line_break_token][line_break_token]> You don't actually derive formulas the second moments in the appendix like you do for the first moment, you mean they can similarly be derived?	O	O	Reply	10
[line_break_token][line_break_token]Yes, an asymptotic expansion can be derived in a similar way for the second moment.	B-Reply	B-6	Reply	10
That derivation is 2 to 3 times longer and is not very useful in the context of this paper.	I-Reply	I-6	Reply	10
[line_break_token][line_break_token]Please also have a look at a new short section (now identified as 3.2.5) that we just added in	I-Reply	I-6	Reply	10

Brief summary of the paper:[line_break_token]This paper studies data-parallel SGD that K processors work together to minimize an objective function.	O	O	Review	376
Each processor computes a stochastic gradient and broadcasts to other peers.	O	O	Review	376
In this distributed system, there is a trade-off between the *communication cost* from sharing the stochastic gradient and the *variance* from gradient quantization.	O	O	Review	376
This paper is a follow-up of Alistarh et al&nbsp;(2017).	O	O	Review	376
It proposes a non-uniform (logarithmic) quantization scheme (NUQSGD).	O	O	Review	376
This paper provides theoretical analysis of the variance and communication cost of NUQSGD.	O	O	Review	376
Then the paper analyzes the convergence rate of NUQSGD for convex and smooth objective function.	O	O	Review	376
At the end, this paper empirically evaluates NUQSGD for image classification problem.	O	O	Review	376
[line_break_token][line_break_token][line_break_token]Originality and significance:[line_break_token]This paper follows up on the parallel SGD framework proposed by Alistarh et al&nbsp;(2017), where the authors proposed QSGD using a uniform quantization.	O	O	Review	376
This paper proposes NUQSGD using a non-uniform quantization method.	O	O	Review	376
The quantization of the stochastic gradient amplifies the stochastic variance, which influences the rate of convergence of SGD.	O	O	Review	376
Thus, on one hand, it is important to design a quantization method to improve the variance, for the sake of convergence rate.	O	O	Review	376
On the other hand, it is also important to decrease the communication cost.	O	O	Review	376
NUQSGD does not provide significant improvements in terms of the variance and communication cost.	B-Review	B-1	Review	376
[line_break_token][line_break_token]Theorem 2 and Theorem 3: QSGD has a variance of min {d/s^2, \sqrt{d}/s} and NUQSGD has a variance of min{O(d/2^{-2s}), O(\sqrt{d/2^{-2s}})}. QSGD has communication cost of \tilde O(s(s+\sqrt{d})) and NUQSGD has communication cost of \tilde O(2^{2s}\sqrt{d} ).	O	O	Review	376
Compared to QSGD, we can see that NUQSGD improves the dependence on s for the variance term, but it has a worse (exponential) dependence on s for the communication cost.	O	O	Review	376
Usually s is a small number and it serves as a hyper-parameter to be tuned.	O	O	Review	376
We would expect NUQSGD to improve the dependence on the dimension d, which is more significant.	B-Review	B-2	Review	376
However, NUQSGD has the same dependence on d as QSGD in terms of both variance and communication cost.	I-Review	I-2	Review	376
[line_break_token][line_break_token]Experiments: Figure 3 compares NUQSGD with other parallel SGD algorithms and vanilla SGD.	O	O	Review	376
Figure 3 shows how fast the training loss decreases with respect to iterations.	O	O	Review	376
It would be great to add learning curves with the ‚Äòtime‚Äô being the x-axis as well.	B-Review	B-3	Review	376
Also, I would suggest the authors to record the time needed to proceed one iteration for each parallel algorithm to compare the communication cost.	I-Review	I-3	Review	376
[line_break_token][line_break_token]Quality and clarity:[line_break_token]This paper is well-written.	O	O	Review	376
[line_break_token][line_break_token][line_break_token]	O	O	Review	376
hanks for your feedback.	O	O	Reply	376
Below is our specific feedback to your review.	O	O	Reply	376
We have also posted a general response (see our top-level comment) to all reviewers addressing high level points.	O	O	Reply	376
[line_break_token][line_break_token]&gt;NUQSGD does not provide significant improvements in terms of the variance and communication cost.	O	O	Reply	376
[line_break_token][line_break_token]The goal of the paper was to close the gap between QSGD and QSGDinf.	B-Reply	B-1	Reply	376
QSGD provides theoretical guarantees but is empirically worse than QSGDinf.	I-Reply	I-1	Reply	376
QSGDinf has no theoretical guarantees.	I-Reply	I-1	Reply	376
NUQSGD matches the empirical performance of QSGDinf and has slightly stronger asymptotic guarantees than QSGD, and so we don't see the fact that the improvement is "minor" as undermining the significance.	I-Reply	I-1	Reply	376
In practice, it's much better than QSGD.	I-Reply	I-1	Reply	376
[line_break_token][line_break_token]&gt;We would expect NUQSGD to improve the dependence on the dimension d, which is more significant[line_break_token][line_break_token]We have proven that, for any given set of levels, there exists a distribution of points with dimension d such that the variance is in Omega(sqrt{d}), and so our bound is tight in d. We will include this proof in the updated version (forthcoming).	B-Reply	B-2	Reply	376
[line_break_token][line_break_token]&gt;It would be great to add learning curves with the ‚Äòtime‚Äô being the x-axis as well.	O	O	Reply	376
Also, I would suggest the authors to record the time needed to proceed one iteration for each parallel algorithm to compare the communication cost.	O	O	Reply	376
[line_break_token][line_break_token]Regarding simulation-based learning curves with respect to time, if different compression schemes are run on the same gpu, there will be no difference between any quantization method.	B-Reply	B-3	Reply	376
This does not hold for error-corrected methods though, since they require additional storage for the error.	I-Reply	I-3	Reply	376
We will add convergence-versus-time bounds to the updated version.	I-Reply	I-3	Reply	376
In addition, we will record the time needed to proceed one iteration for each parallel algorithm.	I-Reply	I-3	Reply	376

The paper proposes a multi-document extractive machine reading model and algorithm.	O	O	Review	327
The model is composed of 3 distinct parts.	O	O	Review	327
First, the document retriever and the document reader that are states of the art modules.	O	O	Review	327
Then, the paper proposes to use a "multi-step-reasoner" which learns to reformulate the question into its latent space wrt its current value and the "state" of the machine reader.	O	O	Review	327
[line_break_token][line_break_token]In the general sense, the architecture can be seen as a specific case of a memory network.	B-Review	B-1	Review	327
Indeed, the multi-reasoner step can be seen as the controller update step of a memory network type of inference.	I-Review	I-1	Review	327
The retriever is the attention module and the reader as the final step between the controller state and the answer prediction.	I-Review	I-1	Review	327
[line_break_token][line_break_token]The authors claim the method is generic, however, the footnote in section 2.3 mentioned explicitly that the so-called state of the reader assumes the presence of a multi-rnn passage encoding.	B-Review	B-2	Review	327
Furthermore, this section 2.3 gives very little detailed about the "reinforcement learning" algorithms used to train the reasoning module.	I-Review	I-2	Review	327
[line_break_token][line_break_token]Finally, the experimental section, while giving encouraging results on several datasets could also have been used on QAngoroo dataset to assess the multi-hop capabilities of the approach.	B-Review	B-3	Review	327
Furthermore, very little details are provided regarding the reformulation mechanism and its possible interpretability.	B-Review	B-4	Review	327
We thank you for your helpful reviews.	O	O	Reply	327
We have significantly updated the writing of the paper to hopefully address all confusion and we‚Äôve also updated the results section of the paper for better comparison.	B-Reply	B-5	Reply	327
In a nutshell, we have added a section on retriever performance demonstrating the scalability of our approach (sec 4.1).	I-Reply	I-5	Reply	327
We have improved results for our experiments with BiDAF reader and we have also added new results on the open-domain version of the SQuAD dataset.	I-Reply	I-5	Reply	327
[line_break_token][line_break_token]> In the general sense, the architecture can be seen as a specific case of a memory network.	O	O	Reply	327
 Indeed, the multi-reasoner step can be seen as the controller update step of a memory network type of inference.	O	O	Reply	327
The retriever is the attention module and the reader as the final step between the controller state and the answer prediction.	O	O	Reply	327
[line_break_token][line_break_token]We agree with you and think its a valid way of viewing our framework.	B-Reply	B-1	Reply	327
We have updated and cited memory networks in our paper (Sec 4) .	I-Reply	I-1	Reply	327
However, we would like to point out that most memory network architectures are based on soft-attention, but in our case the retriever actually makes a ‚Äúhard selection‚Äù of the top-k paragraphs and hence for the same reason, we have to train it via reinforcement learning.	I-Reply	I-1	Reply	327
[line_break_token][line_break_token]> The authors claim the method is generic, however, the footnote in section 2.3 mentioned explicitly that the so-called state of the reader assumes the presence of a multi-rnn passage encoding.	O	O	Reply	327
Furthermore, this section 2.3 gives very little detailed about the "reinforcement learning" algorithms used to train the reasoning module.	O	O	Reply	327
[line_break_token][line_break_token]We agree with you and based on your comments we have made this absolutely clear in the paper.	B-Reply	B-2	Reply	327
Our method needs access to the internal token level representation of the reader model in order to construct the current state.	I-Reply	I-2	Reply	327
The current API of machine reading models only return the span boundaries of the answer, but for our method, it needs to return the internal state as well.	I-Reply	I-2	Reply	327
What we wanted to convey is, our model does not depend/need any neural architecture re-designing to an existing reader model.	I-Reply	I-2	Reply	327
To show the same, we experimented and showed improvements with two popular and widely used reader architectures - DrQA and BiDAF.	I-Reply	I-2	Reply	327
[line_break_token]Regarding results of BiDAF -- During submission we ran out of time and hence we could not tune the BiDAF model.	I-Reply	I-2	Reply	327
But now the results of BiDAF have improved a lot and as can be seen from (Table 2, row 9), the results of BiDAF are comparable to that of DrQA.	I-Reply	I-2	Reply	327
[line_break_token]We have also significantly updated the model section of our paper to include more details about methods and training (Sec 2 & 3) with details about our policy gradient methods and training procedure.	O	O	Reply	327
[line_break_token][line_break_token]> Finally, the experimental section, while giving encouraging results on several datasets could also have been used on QAngaroo dataset to assess the multi-hop capabilities of the approach.	O	O	Reply	327
[line_break_token][line_break_token]We did not consider QAngaroo for the following reasons -- (a) The question in QAngaroo are based on knowledge base relations and are not natural language questions.	B-Reply	B-3	Reply	327
This makes the dataset a little synthetic in nature and we were unsure if our query reformulation strategy would work in this synthetic setting. (	I-Reply	I-3	Reply	327
b) In this paper, we have tried to focus on datasets for open domain settings where the number of paragraphs per query is large (upto millions).	I-Reply	I-3	Reply	327
QAngaroo on the other hand is quite small in that respect (avg of 13.7 paragraphs per question).	I-Reply	I-3	Reply	327
We were unsure, that in this small setting, if we would see significant gains by doing query reformulation.	I-Reply	I-3	Reply	327
[line_break_token][line_break_token]We have shown the effectiveness of our model in 4 large scale datasets including new results on SQuAD-open since submission.	I-Reply	I-3	Reply	327
We sincerely hope, we will not be penalized for not showing the effectiveness of our model on enough number of datasets.	I-Reply	I-3	Reply	327
[line_break_token][line_break_token]> Furthermore, very little details are provided regarding the reformulation mechanism and its possible interpretability.	O	O	Reply	327
[line_break_token][line_break_token]We have significantly updated this section of the paper.	B-Reply	B-4	Reply	327
We have added a whole new section (Sec 5.3) with detailed analysis of the effect of query reformulation.	I-Reply	I-4	Reply	327
In Table 4, we quantitatively measure if the iterative interaction between the retriever and reader is able to retrieve better context for the reader.	I-Reply	I-4	Reply	327
[line_break_token]	O	O	Reply	327

The paper presents a maximally expressive parameter-sharing scheme for hypergraphs, and in general when modeling the high order interactions between elements of a set.	O	O	Review	488
This setting is further generalized to multiple sets.	O	O	Review	488
The paper shows that the number of free parameters in invariant and equivariant layers corresponds to the different partitioning of the index-set of input and output tensors.	O	O	Review	488
Experimental results suggest that the proposed layer can outperform existing methods in supervised learning with graphs.	O	O	Review	488
[line_break_token][line_break_token]The paper presents a comprehensive generalization of a recently proposed model for interaction across sets, to the setting where some of these sets are identical.	O	O	Review	488
This is particularly useful and important due to its applications to graphs and hyper-graphs, as demonstrated in experiments.	O	O	Review	488
[line_break_token][line_break_token]Overall, I enjoyed reading the paper.	O	O	Review	488
My only concern is the experiments:[line_break_token][line_break_token]1) Some of the benchmark datasets for the proposed task as well as some well-known methods (see Battaglia et al‚Äô18 and references in there) are missing.	B-Review	B-2	Review	488
[line_break_token][line_break_token]2) Applying the model of Hartford et al‚Äô18 to problems where interacting sets are identical is similar to applying convolution layer to a feature vector that is not equivariant to translation. (	B-Review	B-1	Review	488
In both cases the equivariance group of data is a strict subgroup of the equivariance of the layer.)	I-Review	I-1	Review	488
 Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?	I-Review	I-1	Review	488
[line_break_token]	O	O	Review	488
We thank the reviewer for the positive comments.	O	O	Reply	488
Below we address the main concerns.	O	O	Reply	488
[line_break_token][line_break_token]Q: ‚ÄùApplying the model of Hartford et al to problems where interacting sets are identical is similar to applying convolution layer to a feature vector that is not equivariant to translation... Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?‚Äù[line_break_token][line_break_token]A: Our goal in performing the synthetic experiments was to quantify the expressive power that is  gained by adding our basis elements to [Hartford et al 18]. We felt it is an informative experiment since [Hartford et al 18] also discuss applying their model in the jointly exchangeable setting (page 3, second column, top paragraph).	B-Reply	B-1	Reply	488
[line_break_token]Having said that, we agree with the reviewer that [Hartford et al 18] probably cannot handle such tasks by construction.	I-Reply	I-1	Reply	488
As we mentioned in our response to Reviewer1 we will change the wording of this section to better reflect that this is *not* a failure of Hartford et al but merely a setting outside their scope due to a different assumption on the symmetry group of the data.	I-Reply	I-1	Reply	488
 [line_break_token]If the reviewers feel strongly about this experiment, we are open to replace it with a discussion.	I-Reply	I-1	Reply	488
 [line_break_token][line_break_token]--------------------------------------------------------------------------------------------------------------------------------[line_break_token]Q: ‚ÄúSome of the benchmark datasets for the proposed task as well as some well-known methods (see Battaglia et al‚Äô18 and references in there) are missing‚Äù.	O	O	Reply	488
[line_break_token][line_break_token]A: We did our best to survey and compare to the most related works on the dataset collection introduced in [Yanardag & Vishwanathan 2015]. These datasets contain graphs from multiple origins, where some of them consist of highly varying graph sizes (within the same dataset).	O	O	Reply	488
In any case we will make the code available as soon as possible.	B-Reply	B-2	Reply	488
   [line_break_token]--------------------------------------------------------------------------------------------------------------------------------	O	O	Reply	488

The main significance of this paper is to propose the task of generating the lead section of Wikipedia articles by viewing it as a multi-document summarization problem.	O	O	Review	298
Linked articles as well as the results of an external web search query are used as input documents, from which the Wikipedia lead section must be generated.	O	O	Review	298
Further preprocessing of the input articles is required, using simple heuristics to extract the most relevant sections to feed to a neural abstractive summarizer.	O	O	Review	298
A number of variants of attention mechanisms are compared, including the transofer-decoder, and a variant with memory-compressed attention in order to handle longer sequences.	O	O	Review	298
The outputs are evaluated by ROUGE-L and test perplexity.	O	O	Review	298
There is also a A-B testing setup by human evaluators to show that ROUGE-L rankings correspond to human preferences of systems, at least for large ROUGE differences.	O	O	Review	298
[line_break_token][line_break_token]This paper is quite original and clearly written.	B-Review	B-1	Review	298
The main strength is in the task setup with the dataset and the proposed input sources for generating Wikipedia articles.	I-Review	I-1	Review	298
The main weakness is that I would have liked to see more analysis and comparisons in the evaluation.	I-Review	I-1	Review	298
[line_break_token][line_break_token]Evaluation:[line_break_token]Currently, only neural abstractive methods are compared.	B-Review	B-2	Review	298
I would have liked to see the ROUGE performance of some current unsupervised multi-document extractive summarization methods, as well as some simple multi-document selection algorithms such as SumBasic.	I-Review	I-2	Review	298
Do redundancy cues which work for multi-document news summarization still work for this task?	I-Review	I-2	Review	298
[line_break_token][line_break_token]Extractiveness analysis:[line_break_token]I would also have liked to see more analysis of how extractive the Wikipedia articles actually are, as well as how extractive the system outputs are.	B-Review	B-3	Review	298
Does higher extractiveness correspond to higher or lower system ROUGE scores?	I-Review	I-3	Review	298
This would help us understand the difficulty of the problem, and how much abstractive methods could be expected to help.	I-Review	I-3	Review	298
[line_break_token][line_break_token]A further analysis which would be nice to do (though I have less clear ideas how to do it), would be to have some way to figure out which article types or which section types are amenable to this setup, and which are not.	B-Review	B-4	Review	298
[line_break_token][line_break_token]I have some concern that extraction could do very well if you happen to find a related article in another website which contains encyclopedia-like or definition-like entries (e.g., Baidu, Wiktionary) which is not caught by clone detection.	B-Review	B-5	Review	298
In this case, the problem could become less interesting, as no real analysis is required to do well here.	I-Review	I-5	Review	298
[line_break_token][line_break_token]Overall, I quite like this line of work, but I think the paper would be a lot stronger and more convincing with some additional work.	O	O	Review	298
[line_break_token][line_break_token]----[line_break_token]After reading the authors' response and the updated submission, I am satisfied that my concerns above have been adequately addressed in the new version of the paper.	O	O	Review	298
This is a very nice contribution.	O	O	Review	298
[line_break_token]	O	O	Review	298
Thank you for the detailed review with actionable feedback.	O	O	Reply	298
We found common feedback from the three reviewers to augment the evaluation section of the paper and believe we have significantly improved it.	O	O	Reply	298
In particular, please see responses below in-line where we address all of your feedback.	O	O	Reply	298
[line_break_token][line_break_token]‚ÄúThis paper is quite original and clearly written.	O	O	Reply	298
The main strength is in the task setup with the dataset and the proposed input sources for generating Wikipedia articles. ‚	O	O	Reply	298
Äú[line_break_token][line_break_token]- In addition to the task setup, we believe we‚Äôve demonstrated how to do very long (much longer than previously attempted) text-to-text sequence transduction and introduced a new model architecture to do it.	B-Reply	B-1	Reply	298
We believe this is of great interest to the ICLR community.	I-Reply	I-1	Reply	298
[line_break_token][line_break_token]‚ÄúCurrently, only neural abstractive methods are compared.	O	O	Reply	298
I would have liked to see the ROUGE performance of some current unsupervised multi-document extractive summarization methods, as well as some simple multi-document selection algorithms such as SumBasic.	O	O	Reply	298
Do redundancy cues which work for multi-document news summarization still work for this task?‚Äù[line_break_token][line_break_token]- We implemented SumBasic and TextRank (along with tf-idf) to evaluate extractive methods on their own and evaluated them on this task.	B-Reply	B-2	Reply	298
I believe we show convincingly in the results (e.g. extractive bar-plot) that the abstractive stage indeed adds a lot to the extractive output in terms of ROUGE and human evaluation of linguistic quality and that redundancy cues are not enough.	I-Reply	I-2	Reply	298
[line_break_token][line_break_token]‚ÄúI would also have liked to see more analysis of how extractive the Wikipedia articles actually are, as well as how extractive the system outputs are.	O	O	Reply	298
Does higher extractiveness correspond to higher or lower system ROUGE scores?	O	O	Reply	298
This would help us understand the difficulty of the problem, and how much abstractive methods could be expected to help.	O	O	Reply	298
‚Äù[line_break_token][line_break_token]- In Section 2.1 we computed the proportion of unigrams/words in the output co-occurring in the input for our task and for the Gigaword and CNN/DailyMail datasets and showed that by this measure WikiSum is much less extractive.	B-Reply	B-3	Reply	298
In particular, the presence of wiki-clones in the input would give a score of 100%, whereas we report 59.2%.	I-Reply	I-3	Reply	298
[line_break_token][line_break_token]‚ÄúA further analysis which would be nice to do (though I have less clear ideas how to do it), would be to have some way to figure out which article types or which section types are amenable to this setup, and which are not.	O	O	Reply	298
‚Äù[line_break_token][line_break_token]- We added a comparison in the paper with Sauper & Barzilay on two Wiki categories.	O	O	Reply	298
It turns out we do worse on Diseases compared to Actors.	B-Reply	B-4	Reply	298
We think this is because we use a single model for all categories and the training data is heavily biased toward people.	I-Reply	I-4	Reply	298
[line_break_token][line_break_token]‚ÄúI have some concern that extraction could do very well if you happen to find a related article in another website which contains encyclopedia-like or definition-like entries (e.g., Baidu, Wiktionary) which is not caught by clone detection.	O	O	Reply	298
In this case, the problem could become less interesting, as no real analysis is required to do well here.	O	O	Reply	298
‚Äù[line_break_token]- We hope our added analysis in Section 2.1 mentioned above should address this concern.	B-Reply	B-5	Reply	298

This paper introduces a mutual information term into the training objective of message passing graph neural networks.	O	O	Review	10058
 The additional term favors the preservation on information in a mapping from an input edge feature vector e_{i,j} to a weight matrix f(e_{i,j}) used in computing messages across the edge from node i to node j.  A variational lower bound on the mutual information is used in training.	O	O	Review	10058
 Impressive empirical results are given for chemical property prediction and relation prediction in knowledge graphs.	O	O	Review	10058
 I have no real complaints other than I might recommend citing the original work on infomax:[line_break_token][line_break_token]"Self Organization in a Perceptual Network", Ralph Linsker, 1988.	B-Review	B-1	Review	10058
[line_break_token][line_break_token]Postscript:  I have been swayed by the complaints of reviewer 1 and reduced my score to weak reject.	O	O	Review	10058
e appreciate your positive feedback and thank you for pointing out the original paper on infomax ([Linsker 1998]) which explains the importance of applying the infomax principle for designing neural networks.	B-Reply	B-1	Reply	10058
We have cited the paper and discussed it in Section 3.1.	I-Reply	I-1	Reply	10058
[line_break_token][line_break_token][Linsker 1998] Linsker, Ralph. "	O	O	Reply	10058
Self-organization in a perceptual network."	O	O	Reply	10058
Computer 21.3 (1988): 105-117.	O	O	Reply	10058

The paper provides an unsupervised domain adaptation approach[line_break_token]in the context of deep learning.	O	O	Review	453
The motivation is clear, related work[line_break_token]sufficient and experimental settings and results convincing.	O	O	Review	453
[line_break_token]I have only very minor comments:[line_break_token]- I would prefer to get the paper additionally linked to a few more[line_break_token]  transfer learning techniques out of the deep learning domain[line_break_token]  which is important as well[line_break_token]- do you really need to call it (multi) flow network .... - a flow network[line_break_token]  is a well established concept in algorithmics and refers to a graph problem[line_break_token]  ... to avoid name clashes ...[line_break_token]- in the references you have provided back links to the pages where the references[line_break_token]  are used - this is handy but also confusing and a bit unusual - I think it was not part [line_break_token]  of the standard template[line_break_token]- please avoid using arxiv references but replace them by reviewed material.	B-Review	B-1	Review	453
In parts[line_break_token]  I am willing to accept such kind of gray literature provided by well known authors but[line_break_token]  this should not become a standard habit[line_break_token]- I am happy to see that the code will be published - I hope this is really done, because[line_break_token]  from the material it maybe hard to reconstruct the method	B-Review	B-5	Review	453
hank you for your insights.	O	O	Reply	453
Here are our responses:[line_break_token][line_break_token]&gt;- I would prefer to get the paper additionally linked to a few more transfer[line_break_token]&gt;learning techniques out of the deep learning domain which is important as well[line_break_token][line_break_token]We focused our literature review on deep learning because our work proposes an[line_break_token]approach for deep architectures.	B-Reply	B-1	Reply	453
For the sake of completeness, we will[line_break_token]nonetheless include the following papers:[line_break_token][line_break_token]- Boosting for Transfer Learning [Dai07][line_break_token]- Covariate Shift by Kernel Mean Matching [Gretton09][line_break_token]- Domain adaptation via transfer component analysis [Pan10][line_break_token]- Unsupervised Visual Domain Adaptation Using Subspace Alignment [Fernando13][line_break_token]- Deep CORAL: Correlation Alignment for Deep Domain Adaptation [Sun16][line_break_token]- A DIRT-T approach to unsupervised domain adaptation [Shu18][line_break_token][line_break_token]&gt;- do you really need to call it (multi) flow network .... - a flow network is[line_break_token]&gt;a well established concept in algorithmics and refers to a graph problem ...[line_break_token]&gt;to avoid name clashes ...[line_break_token][line_break_token]We propose to rename our approach as Domain-Adaptive Multibranch Networks.	B-Reply	B-2	Reply	453
[line_break_token][line_break_token]&gt;- in the references you have provided back links to the pages where the[line_break_token]&gt;references are used - this is handy but also confusing and a bit unusual - I[line_break_token]&gt;think it was not part of the standard template[line_break_token][line_break_token]We will abide by the template and remove the back links.	B-Reply	B-3	Reply	453
[line_break_token][line_break_token]&gt;- please avoid using arxiv references but replace them by reviewed material.	O	O	Reply	453
[line_break_token]&gt;In parts I am willing to accept such kind of gray literature provided by well[line_break_token]&gt;known authors but this should not become a standard habit[line_break_token][line_break_token]We have replaced the arxiv references with reviewed ones when available.	B-Reply	B-4	Reply	453
[line_break_token][line_break_token]&gt;- I am happy to see that the code will be published - I hope this is really[line_break_token]&gt;done, because from the material it maybe hard to reconstruct the method[line_break_token][line_break_token]Our code is currently stored in a private github repository, which will be set as public once the blind review period ends.	B-Reply	B-5	Reply	453
[line_break_token][line_break_token]We have updated the manuscript to reflect the above changes.	O	O	Reply	453
[line_break_token][line_break_token]Thank you for your input	O	O	Reply	453

Pros: [line_break_token]- Introduction of a nice filter banks and its implementation[line_break_token]- Good numerical results[line_break_token]- Refinement of the representation via back propagation, and a demonstration that it speeds up learning[line_break_token][line_break_token]Cons:[line_break_token]- The algorithms (section 3.1) are not necessary, and they even affect the presentation of the paper.	B-Review	B-1	Review	378
However, a source code would be great!	I-Review	I-1	Review	378
[line_break_token]- The link with a scattering transform is not clear[line_break_token]- Sometimes (as mentionned in some of my comments), the writing could be improved.	B-Review	B-2	Review	378
[line_break_token][line_break_token]From a personal point of view, I also believe the negative points I mention can be easily removed.	O	O	Review	378
The current available revised version contains the code and link to GitHub, the writing is improved, and we added SPEECH TIMIT experimentation showing improvement on vowel recognition using proposed FCT	B-Reply	B-5	Reply	378

[line_break_token]I have mixed feelings about this paper.	O	O	Review	1628
On one hand, it‚Äôs a thorough and well-written experimental paper, something which is really important but is also clearly underappreciated in the machine learning community.	O	O	Review	1628
On the other, it was not really obvious to me why some of objectives tested here are interesting: LM objectives like ELMo have seen a lot of uptake in the NLP community (and this is definitely an NLP paper), but most of the others‚Äîlike skip-thought, MT, and autoencoders‚Äîhave not.	B-Review	B-1	Review	1628
So the basic research question doesn‚Äôt seem like an especially burning one.	I-Review	I-1	Review	1628
The trends in Fig.	O	O	Review	1628
2 show that these alternatives underperform an LM objective, which suggests that the NLP community can keep using that objective without worry‚Äîand everything else in the figure seems as we would expect.	O	O	Review	1628
[line_break_token][line_break_token]In short, I think the paper is a well-done study on a hypothesis of perhaps minor interest.	O	O	Review	1628
The results are sensible but confirm what we already strongly suspected, and they seem unlikely to strongly influence other research, since they confirm that everyone has been the right thing all along.	B-Review	B-2	Review	1628
I‚Äôm not entirely sure what I learned from this.	I-Review	I-2	Review	1628
[line_break_token][line_break_token]To me, the most interesting experiment is the final one in Section 6.	O	O	Review	1628
This experiment seems like it could be the germ for a far more interesting paper getting at how these pretraining objectives help with downstream tasks.	O	O	Review	1628
As it stands, it feels like an interesting nugget tacked on to an otherwise complete (and much less interesting) paper.	O	O	Review	1628
[line_break_token][line_break_token]Presentational comments:[line_break_token][line_break_token]Fig.1: really nitpicky, but the typography of the POS tags and CCG categories is all wrong.	B-Review	B-3	Review	1628
These aren‚Äôt mathematical symbols!	I-Review	I-3	Review	1628
[line_break_token][line_break_token]Fig 2.	B-Review	B-4	Review	1628
Slightly confused why these are broken up into two separate plots.	I-Review	I-4	Review	1628
[line_break_token][line_break_token]Fig 4.	B-Review	B-5	Review	1628
is hard to read due to the lurid colors and patterns, which require a lot of cross-referencing with the legend.	I-Review	I-5	Review	1628
I wonder if this would be better as simply a table.	I-Review	I-5	Review	1628
I also found it very confusing at first since the y-axes are out of sync between the two figures‚Äîinitially it looked as if the legend was overlaid on a set of bars in the left figure that had the same baseline as the right figure.	I-Review	I-5	Review	1628
[line_break_token]	O	O	Review	1628
Our contribution is a thorough examination of several different pretraining tasks, controlling for the domain, amount of data, and training procedure.	B-Reply	B-2	Reply	1628
When CoVe was released at NIPS last year, it achieved SoTA numbers on several prominent NLP tasks.	I-Reply	I-2	Reply	1628
Although ELMo compares to CoVe in their paper and outperforms CoVe, since CoVe was trained on WMT English-German and ELMo was trained on the One Billion Word Benchmark, it was unclear if the performance gain of ELMo was primarily due to the increased amount of training data.	I-Reply	I-2	Reply	1628
Moreover, without a direct comparison we can‚Äôt even be sure that language modeling is better because ELMo could have just been more carefully tuned.	I-Reply	I-2	Reply	1628
Our finding that language modeling, an unsupervised task, outperformed translation models trained on the *same* data is still surprising because the translation models are given the source sentence in a different language and thus have strictly more information than language models.	I-Reply	I-2	Reply	1628
We also agree that the results of our analysis of the randomly-initialized encoder in Section 6 are surprising, and could form the basis for a larger study.	I-Reply	I-2	Reply	1628
[line_break_token][line_break_token]Fig 1: You are right.	B-Reply	B-3	Reply	1628
We just fixed the typography in our most recent revision.	I-Reply	I-3	Reply	1628
[line_break_token][line_break_token]Fig 2: The upper plot is for POS tagging and the bottom for CCG supertagging.	B-Reply	B-4	Reply	1628
Each of those plots are then split into three columns corresponding to different amounts of classifier training data.	I-Reply	I-4	Reply	1628
Each column has two plots because when we tried plotting all ten lines into one figure it was difficult to read, so we split up the models into two groups: models with attention (plus BiLMs) and models without attention (plus forward LM).	I-Reply	I-4	Reply	1628
We welcome further suggestions for improving our presentation.	I-Reply	I-4	Reply	1628
[line_break_token][line_break_token]Fig 4: We included the patterns and bright colors in order to make it easier for the visually impaired to read	B-Reply	B-5	Reply	1628

UPDATE:[line_break_token]I looked at the arxiv version of the paper.	O	O	Review	594
It is much longer and appears more rigorous.	O	O	Review	594
Fig 3 there is indeed more insightful.	O	O	Review	594
[line_break_token]However, I am reviewing the submission and my overall assessment does not change.	O	O	Review	594
This is not a minor incremental contribution, and if you want to compress it into a conference submission of this type, I would recommend choosing message you want to convey, and focus on that.	O	O	Review	594
As you say, "...ICLR submission focus on the ParMAC algorithm...", I would focus on this properly - and remove or move to appendix all extensions and theoretical remarks, and have an extra page on explaining the algorithm.	O	O	Review	594
Additionally, make sure to clearly explain the relation of the arxiv paper, in particular that the submission was a compressed version.	O	O	Review	594
[line_break_token][line_break_token]ORIGINAL REVIEW:[line_break_token]The submission proposes ParMAC, based on MAC (Method of Auxiliary Coordinates), formulating a distributed variant of the idea.	O	O	Review	594
[line_break_token][line_break_token]Related Work: In the part on convex ERM and methods, I would recommend citing general communication efficient frameworks, COCOA (Ma et al) and AIDE (Reddi et al).	O	O	Review	594
I believe these works are most related to the practical objectives authors of this paper set, while number of the papers cited are less relevant.	O	O	Review	594
[line_break_token][line_break_token]Section 2, explaining MAC, is quite clearly written, but I do not find part on MAC and EM particularly useful.	B-Review	B-1	Review	594
[line_break_token][line_break_token]Section 3 is much less clearly written.	B-Review	B-2	Review	594
I have trouble following notation, particularly in the speedups part, as different symbols were introduced at different places.	I-Review	I-2	Review	594
Perhaps a quick summary or paragraph on notation in the introduction would be helpful.	I-Review	I-2	Review	594
In paragraph 2, you write as if reader knew how data/anything is distributed, but this was not mentioned yet; it is specified later.	I-Review	I-2	Review	594
It is not clear what is meant by "submodel".	I-Review	I-2	Review	594
Perhaps a more precise example pointing back to eqs (1) & (2) would be useful.	O	O	Review	594
As far as I understand from what is written, there are P independent sets of submodels, that traverse the machines in circular fashion.	B-Review	B-2	Review	594
I don't understand how are they initialized (identically?),	I-Review	I-2	Review	594
and more importantly I don't understand what would be a single output of the algorithm (averaging?	I-Review	I-2	Review	594
does not seem to make sense).	I-Review	I-2	Review	594
Since this is not addressed, I suppose I get it wrong, leaving me to guess what was actually meant.	I-Review	I-2	Review	594
[line_break_token]The fact that I am not able to understand what is actually happening, I see as major issue.	O	O	Review	594
[line_break_token][line_break_token]I don't like the later paragraphs on extensions, model for speedup, convergence and topologies.	B-Review	B-3	Review	594
I don't understand whether these are novel contributions or not, as the authors refer to other work for details.	I-Review	I-3	Review	594
If these are novel, the explanation is not sufficient, particularly speedup part, which contains undefined quantities, e.g. T(P) (or I can't find it).	I-Review	I-3	Review	594
If this is not novel, It does not provide enough explanation to understand anything more, compared with a its version compressed to 1/4 of its size and referring to the other work.	I-Review	I-3	Review	594
The statement that we can recover the original convergence guarantees seems strong and I don't see why it should be trivial to show (but author point to other work which I did not look at).	I-Review	I-3	Review	594
In topologies part, claiming that something does "true SGD", without explaining what is "true SGD" seems very strange.	I-Review	I-3	Review	594
Other statements in this section seem also very vague and unjustified/unexplained.	I-Review	I-3	Review	594
[line_break_token][line_break_token]Experimental section seems to suggest that the method is interesting for binary autoencoders, but I don't see how would I conclude anything about any other models.	B-Review	B-4	Review	594
ParMAC is also not compared to alternative methods, only with itself, focusing on scaling properties.	I-Review	I-4	Review	594
[line_break_token][line_break_token]Conclusion contains statements that are too strong or misleading based on what I saw.	B-Review	B-5	Review	594
In particular, "we analysed its parallel speedup and convergence" seems ungrounded.	I-Review	I-5	Review	594
Further, the claim "The convergence properties of MAC remain essentially unaltered in ParMAC" is unsupported, regardless of the meaning of "essentially unchanged".	I-Review	I-5	Review	594
[line_break_token][line_break_token]In summary, the method seems relevant for particular model class, binary autoencoders, but clarity of presentation is insufficient - I wouldn't be able to recreate the algorithm used in experiments - and the paper contains a number of questionable claims.	O	O	Review	594
Regarding clarity of presentation, we regret you didn't find the paper sufficiently clear and thank you for your suggestions.	O	O	Reply	594
We tried to make it approachable and point to the longer arXiv version as needed.	O	O	Reply	594
But, given the MAC and ParMAC frameworks are very different from the standard practice (backpropagation, SGD, GPUs, etc.),	O	O	Reply	594
this is bound to be a denser than usual paper.	O	O	Reply	594
We do find the analogy of MAC and EM very helpful in order to explain how ParMAC works based on our experience in describing this work to people who are familiar with EM (this would include most machine learning researchers).	O	O	Reply	594
In particular, it should help understand the notion of "submodels" and "coordinates" (since what these exactly are depends on the model used).	O	O	Reply	594
[line_break_token][line_break_token]We try to answer your specific questions, as follows.	O	O	Reply	594
[line_break_token][line_break_token]- Firstly, the notion of submodels only applies during a W step.	B-Reply	B-2	Reply	594
In the Z step, we have a single model, the binary autoencoder.	I-Reply	I-2	Reply	594
In the W step, this single model splits into submodels because the objective function additively separates given Z.[line_break_token][line_break_token]- There are M (not P) independent submodels and P processors.	I-Reply	I-2	Reply	594
Each submodel indeed traverses the machines in circular fashion (in the W step).	I-Reply	I-2	Reply	594
[line_break_token][line_break_token]- Crucially, each submodel is trained on different data (different input dimensions or different output dimensions), so different submodels will differ at the end of the W step.	I-Reply	I-2	Reply	594
Specifically, each encoder l has the same input vector x but a different output bit z_l; and each decoder d has the same input vector z but a different output dimension x_d (see pseudocode in fig.	I-Reply	I-2	Reply	594
1).	I-Reply	I-2	Reply	594
[line_break_token]  In the analogy with EM, each Gaussian (= submodel) trains on different data: the training points, and the posterior probabilities (= auxiliary coordinates), which are different for each Gaussian.	I-Reply	I-2	Reply	594
[line_break_token][line_break_token]- Initialisation of each submodel: from PCA.	I-Reply	I-2	Reply	594
But, since different submodels train on different data, they will differ anyway.	I-Reply	I-2	Reply	594
Besides, in the binary autoencoder), each submodel is a convex problem (encoder = a binary SVM, decoder = a linear regressor).	I-Reply	I-2	Reply	594
[line_break_token][line_break_token]- "what would be a single output of the algorithm?":	I-Reply	I-2	Reply	594
we don't understand what you mean, but hopefully the above explanation has cleared this up.	I-Reply	I-2	Reply	594
There is one overall model (the binary autoencoder), it's just that during the W step it splits into M independently trained submodels (L encoders, D decoders), given the training data and auxiliary coordinates.	I-Reply	I-2	Reply	594
[line_break_token]  Perhaps fig.	I-Reply	I-2	Reply	594
3 in the arXiv paper (which works best as an animation) may help you understand better the training of the independent submodels in the W step.	I-Reply	I-2	Reply	594
[line_break_token][line_break_token]- "later paragraphs on extensions, model for speedup, >convergence and topologies": all those parts are novel contributions indeed and are more fully explained in the arXiv paper.	O	O	Reply	594
Unfortunately we can't fit all the details in a conference paper.	B-Reply	B-3	Reply	594
We think it is better to have the ICLR submission focus on the ParMAC algorithm, which is the most important part, and point to the longer paper for these other things.	I-Reply	I-3	Reply	594
[line_break_token]  We did omit the definition of T(P): T(P) = TW(P) + TZ(P).	I-Reply	I-3	Reply	594
[line_break_token]  "True SGD" means SGD as it would run in a single machine.	I-Reply	I-3	Reply	594
[line_break_token]  The statement that we can recover the original convergence guarantees follows by realising that the critical condition we need to ensure for MAC to converge is "to reduce the gradient of the penalised function below a tolerance for each value of \mu" (arXiv p. 19).	I-Reply	I-3	Reply	594
Proposition 1 in Bertsekas/Tsisiklis00 guarantees this for SGD even for nonconvex functions.	I-Reply	I-3	Reply	594
Essentially, if you run the W steps (= SGD on each submodel) for sufficiently many epochs, you follow the path over \mu closely enough, and you converge in the limit.	I-Reply	I-3	Reply	594
For full details, see section 6 in the arXiv paper.	I-Reply	I-3	Reply	594
[line_break_token][line_break_token]Regarding the choice of the binary autoencoder for the experiments, see our "response to reviewers".	O	O	Reply	594
[line_break_token][line_break_token]The ICLR submission (together with the arXiv paper) does contain a detailed theoretical analysis of the speedup.	O	O	Reply	594
The arXiv paper does describe the convergence properties.	O	O	Reply	594
We provide the full C/MPI code in our website to recreate the experiments in either a shared- or a distributed-memory system.	O	O	Reply	594

This paper proposed a pre-trainable generic representation for visual-linguistic tasks call VL-BERT.	O	O	Review	281
VL-BERT extend BERT by changing the input from subsequent sentence to image regions and modify the caption words has the additional visual feature embedding.	O	O	Review	281
The authors pre-train the VL-BERT on the conceptual caption dataset and Wikipedia and book corpus dataset, empirical results show that the VL-BERT achieve the SOTA performance on the VCR, VQA and refer expression tasks.	O	O	Review	281
[line_break_token][line_break_token]As the authors mentioned in Table 5, pre-training the visolinguistic representation for vision and language tasks is very popular recently, and 5~6 similar works have appeared recently.	O	O	Review	281
One of the nice features I found on this work is it's joint train with text-only corpus and faster RCNN weight.	O	O	Review	281
While ViLBERT designs for easier extendable for other modalities, VLBERT is more focus on the representation learning on the vision and language, since the caption input also combines with the visual feature embedding.	O	O	Review	281
[line_break_token][line_break_token]Overall the paper is well written and performs extensive experiments/ablations.	O	O	Review	281
There is some specific point that is not clear to me or needs further clarifications from the authors.	O	O	Review	281
[line_break_token][line_break_token]1: The authors mentioned the improvement over tuning the visual parameters, I wonder what is the details on that?	B-Review	B-1	Review	281
is the region proposal network's weight fixed?	I-Review	I-1	Review	281
if not, how to avoid the shift on the proposal layer?	I-Review	I-1	Review	281
Is the model still has the visual genome target or objective?	I-Review	I-1	Review	281
Which layer is fixed/updated?	I-Review	I-1	Review	281
and what is the optimizer and learning rate scheduler?	I-Review	I-1	Review	281
[line_break_token][line_break_token]2: I notice there is a change in the textual input which take visual feature embeddings.	B-Review	B-2	Review	281
I wonder what is the performance without these features?	I-Review	I-2	Review	281
What is the visual feature input for textual corpus?	I-Review	I-2	Review	281
[line_break_token][line_break_token]3: For the Masked RoI classification with Linguistic Clues, what if there are overlapped regions?	B-Review	B-3	Review	281
what if the detection label from faster rcnn is incorrect?	I-Review	I-3	Review	281
will this introduce any noise?	I-Review	I-3	Review	281
[line_break_token][line_break_token]4: For VCR tasks, it seems the VL-BERT_base w/o pre-training is performed similar compare to the with pre-training (only 0.7% lower on val of Q-&gt;A) I wonder what is the reason of this?	O	O	Review	281
Is this show the pre-training is not important for the VCR tasks?	B-Review	B-4	Review	281
[line_break_token][line_break_token]5: The VCR tasks also have the object bounding box correspondence, is VL-BERT take any of this supervision for input?	B-Review	B-5	Review	281
If not, how does the VL-BERT learn the correspondence?	I-Review	I-5	Review	281
[line_break_token][line_break_token]6: For refer expression tasks, the VL-BERT_base is actually worse than ViLBERT on the detected regions.	B-Review	B-6	Review	281
It's not a fair comparison since other models use bert-base model.	I-Review	I-6	Review	281
[line_break_token][line_break_token]Overall, I think this paper is well written and has solid experiment results.	O	O	Review	281
It will be great if the authors can further clarify the above questions.	O	O	Review	281
e thank the reviewer for the careful reviews and constructive suggestions.	O	O	Reply	281
We clarify the questions as follows.	O	O	Reply	281
[line_break_token][line_break_token]Q#1: Details on tuning the visual parameters.	O	O	Reply	281
[line_break_token][line_break_token]A#1: As described in Section 3.2 and Fig.	B-Reply	B-1	Reply	281
1, in VL-BERT, only the object detection branch (i.e., Fast R-CNN) in Faster R-CNN is exploited to extract visual feature embeddings for each RoI. The region proposal network is not involved in training/inference of VL-BERT.	I-Reply	I-1	Reply	281
The optimizer and learning rate mentioned in experiments are shared for all the parameters in VL-BERT and Fast R-CNN.	I-Reply	I-1	Reply	281
[line_break_token][line_break_token]Indeed, such a training scheme would cause shift on the proposal layer in Faster R-CNN.	I-Reply	I-1	Reply	281
Here we extract the RoIs on the training/test samples by a separate pre-trained Faster R-CNN.	I-Reply	I-1	Reply	281
The shift may well be alleviated by joint training on object detection tasks.	I-Reply	I-1	Reply	281
[line_break_token][line_break_token]Q#2: ``What is the visual feature input for textual corpus?‚Äù ``I wonder what is the performance without these features?‚Äù[line_break_token][line_break_token]A#2: The visual feature input for textual corpus is a learnable embedding shared for all words.	B-Reply	B-2	Reply	281
We did not try experimenting without such features.	I-Reply	I-2	Reply	281
We shall clarify in revision.	I-Reply	I-2	Reply	281
[line_break_token][line_break_token]Q#3: What if there are overlapped regions in task Masked RoI classification with Linguistic Clues?	O	O	Reply	281
What if the detection label from the pre-trained Faster R-CNN is incorrect?	O	O	Reply	281
[line_break_token][line_break_token]A#3: The pixels laid in the masked RoI are set as zeros, regardless of whether the pixels also belong to other RoIs.	B-Reply	B-3	Reply	281
Thus, for the pixels covered by overlapping RoIs, they are also simply set as zeros.	I-Reply	I-3	Reply	281
The detection labels on Conceptual Captions can be incorrect, since they are just pseudo labels generated by a pre-trained Faster R-CNN.	I-Reply	I-3	Reply	281
Because there are no ground-truth detection annotations on Conceptual Captions, we cannot validate the effect for the time being.	I-Reply	I-3	Reply	281
[line_break_token][line_break_token]Q#4: Is the pre-training not important for the VCR tasks?	O	O	Reply	281
[line_break_token][line_break_token]A#4: We believe this is because the pre-training task on Conceptual Captions is for image captioning, where no commonsense reasoning is involved, which is vital for the VCR task.	B-Reply	B-4	Reply	281
[line_break_token][line_break_token]Q#5: Does VL-BERT use object bounding box correspondence annotations for VCR dataset?	O	O	Reply	281
[line_break_token][line_break_token]A#5: No, we did not use the bounding box correspondence annotations for VCR dataset, for the coherence in the design of VL-BERT.	B-Reply	B-5	Reply	281
We also tried exploiting the annotated bounding box correspondence in VCR, but there is little difference in accuracy.	I-Reply	I-5	Reply	281
We feel VL-BERT might already learned to encode such correspondence.	I-Reply	I-5	Reply	281
[line_break_token][line_break_token]Q#6: VL-BERT is actually worse than ViLBERT on refer expression tasks[line_break_token][line_break_token]A#6: Yes, VL-BERT is slightly shy of ViLBERT on RefCOCO+.	B-Reply	B-6	Reply	281
Meanwhile, VL-BERT and ViLBERT are concurrent works.	I-Reply	I-6	Reply	281
We feel there is no problem that VL-BERT does not surpass ViLBERT on every benchmark.	I-Reply	I-6	Reply	281

This paper proposes to learn implicit generative models by a feature matching objective which forces the generator to produce samples that match the means of the data distribution in some fixed feature space, focusing on image generation and feature spaces given by pre-trained image classifiers.	O	O	Review	1390
[line_break_token][line_break_token]On the positive side, the paper is well-written and easy to follow, the experiments are clearly described, and the evaluation shows the method can achieve good results on a few datasets.	O	O	Review	1390
The method is nice in that, unlike GANs and the stability issues that come with them, it minimizes a single loss and requires only a single module, the generator.	O	O	Review	1390
[line_break_token][line_break_token]On the other hand, the general applicability of the method is unclear, the novelty is somewhat limited, and the evaluation is missing a few important baselines.	O	O	Review	1390
In detail:[line_break_token][line_break_token]1) The proposed objective was used as a GAN auxiliary objective in [Salimans et al 2016] and further explored in [Warde-Farley & Bengio, 2017]. The novel bit here is that the proposed objective doesn‚Äôt include the standard GAN term (so no need for an adversarially-optimized discriminator), and the feature extractor is a fixed pre-trained classifier or encoder from an auto-encoder (rather than a discriminator).	O	O	Review	1390
[line_break_token][line_break_token]2) The method only forces the generator‚Äôs sample distribution to match the first moment (the mean) of the data distribution.	B-Review	B-2	Review	1390
While the paper shows that this can result in a generator that produces reasonably good samples in practice, it seems like this may have happened due to a ‚Äúlucky‚Äù artifact of the chosen pre-trained feature extractors.	I-Review	I-2	Review	1390
For example, a degenerate generator that produces a single image whose features exactly match the mean would be a global optimum under this objective, equally good as a generator that exactly matches the data distribution.	I-Review	I-2	Review	1390
Perhaps no such image exists for the chosen pre-trained classifiers, but it‚Äôs nonetheless concerning that the objective does nothing to prevent this type of behavior in the general case. (	I-Review	I-2	Review	1390
This is similar to the mode collapse problem that often occurs with GAN training in practice, but at least a GAN generator is required to exactly match the full data distribution to achieve the global optimum of that objective.)	I-Review	I-2	Review	1390
[line_break_token][line_break_token]3) It‚Äôs unclear why the proposed ADAM-based Moving Average (AMA) updates are appropriate for estimate the mean features of the data distribution.	B-Review	B-3	Review	1390
Namely, unlike EMA updates, it‚Äôs not clear that this is an unbiased estimator (I suspect it‚Äôs not); i.e. that the expectation of the resulting estimates is actually the true mean of the dataset features.	I-Review	I-3	Review	1390
 It‚Äôs therefore not clear whether the stated objective is actually what‚Äôs being optimized when these AMA updates are used.	I-Review	I-3	Review	1390
[line_break_token][line_break_token]4) Related to (3), an important baseline which is not discussed is the true fixed mean of the dataset distribution.	B-Review	B-4	Review	1390
In Sec.	I-Review	I-4	Review	1390
2.4 (on AMA) it‚Äôs claimed that ‚Äúone would need large mini-batches for generating a good estimate of the mean features...this can easily result in memory issues‚Äù, but this is not true: one could trivially compute the full exact dataset mean of these fixed features by accumulating a sum over the dataset (e.g., one image a time, with minibatch size 1) and then dividing the result by the number of images in the dataset.	I-Review	I-4	Review	1390
Without this baseline, I can‚Äôt rule out that the method only works due to its reliance on the stochasticity of the dataset mean estimates to avoid the behavior described in (2), or even the fact that the estimates are biased due to the use of ADAM as described in (3).	I-Review	I-4	Review	1390
[line_break_token][line_break_token]5) The best results in Table 3 rely on initializing G with the weights of a decoder pretrained for autoencoding.	B-Review	B-5	Review	1390
However, the performance of the decoder itself with no additional training from the GFMN objective is not reported, so it‚Äôs possible that most of the result relies on *autoencoder* training rather than feature matching to get a good generator.	I-Review	I-5	Review	1390
This explanation seems especially plausible due to the fact that the learning rate is set to a miniscule value (5*10^-6 for ADAM, 1-2 orders of magnitude smaller than typical values).	I-Review	I-5	Review	1390
Without the generator pretraining, the next best CIFAR result is an Inception Score of 7.67, lower than the unsupervised result from [Warde-Farley & Bengio, 2017] of 7.72.	O	O	Review	1390
[line_break_token][line_break_token]6) It is misleading to call the results based on ImageNet-pretrained models ‚Äúunconditional‚Äù -- there is plenty of overlap in the supervision provided by the labeled images of the much larger ImageNet to CIFAR and other datasets explored here.	B-Review	B-6	Review	1390
This is especially true given that the reported metrics (Inception Score and FID) are themselves based on ImageNet-pretrained classifiers.	I-Review	I-6	Review	1390
If the results were instead compared to prior work on conditional generation (e.g. ProGAN (Karras et al 2017), which reports CIFAR IS of 8.56), there would be a clear gap between these results and the state of the art.	I-Review	I-6	Review	1390
[line_break_token][line_break_token]Overall, the current version of the paper needs additional experiments and clarifying discussion to address these issues.	O	O	Review	1390
[line_break_token][line_break_token]=======================================[line_break_token][line_break_token]REVISION[line_break_token][line_break_token]Based on the authors' responses, I withdraw points 3-5 from my original review.	O	O	Review	1390
Thanks to the authors for the additional experiments.	O	O	Review	1390
On (3), I indeed misunderstood where the moving average was being applied; thanks for the correction.	O	O	Review	1390
On (4), the additional experiment using the global mean features for real data convinces me that the method does not rely on the stochasticity of the estimates. (	O	O	Review	1390
Though, given that the global mean works just as well, it seems like it would be more efficient and arguably cleaner to simply have that be the main method.	O	O	Review	1390
But this isn't a major issue.)	O	O	Review	1390
On (5), I misread the learning rate specified for "using the autoencoder features" as being the learning rate for autoencoder *pretraining*; thanks for the correction.	O	O	Review	1390
The added results in Appendix 11 do show that the pretrained decoder on its own does not produce good samples.	O	O	Review	1390
[line_break_token][line_break_token]My biggest remaining concerns are with points (2) and (6) from my original review.	O	O	Review	1390
[line_break_token][line_break_token]On (2), I did realize that features from multiple layers are used, but this doesn't theoretically prevent the generator from achieving the global minimum of the objective by producing a single image whose features are the mean of the features in the dataset.	B-Review	B-7	Review	1390
That being said, the paper shows that this doesn't tend to happen in practice with existing classifiers, which is an interesting empirical contribution. (	I-Review	I-7	Review	1390
It would be nice to also see ablation studies on this point, showing the results of training against features from single layers across the network.)	I-Review	I-7	Review	1390
[line_break_token][line_break_token]On (6), I'm still unconvinced that making use of ImageNet classifiers isn't providing something like a conditional training signal, and that using such classifiers isn't a bit of an "unfair advantage" vs. other methods when the metrics themselves are based on an ImageNet classifier.	B-Review	B-8	Review	1390
I realize that ImageNet and CIFAR have different label sets, but most if not all of the CIFAR classes are nonetheless represented -- in a finer-grained way -- in ImageNet.	I-Review	I-8	Review	1390
If ImageNet and CIFAR were really completely unrelated, an ImageNet classifier could not be used as an evaluation metric for CIFAR generators. (	I-Review	I-8	Review	1390
And yes, I saw the CelebA results, but for this dataset there's no quantitative comparison with prior work, and qualitatively, if the results are as good as or better than the 3 year old DCGAN results, I can't tell.)	I-Review	I-8	Review	1390
[line_break_token][line_break_token]On the other hand, given that the approach relies on these classifiers, I don't have a good suggestion for how to control for this and make the comparison with prior work completely fair.	B-Review	B-9	Review	1390
Still, it would be nice to see acknowledgment and discussion of this caveat in a future revision of the paper.	I-Review	I-9	Review	1390
[line_break_token][line_break_token]Overall, given that most of my concerns have been addressed with additional experiments and clarification, and that the paper is well-written and has some interesting results from its relatively simple approach, I've raised my rating to above acceptance threshold.	O	O	Review	1390
[line_break_token]We would like to thank the reviewer for the questions and comments.	O	O	Reply	1390
[line_break_token]In order to better address your concerns, we have uploaded a new version of the paper that contains three new appendices: A.11, A.12 and A.13.	O	O	Reply	1390
Please see below our detailed reply for your questions/comments.	O	O	Reply	1390
We believe that the new added appendices and the clarifications given in our reply will address all the concerns and misconceptions of the reviewer.	O	O	Reply	1390
 [line_break_token][line_break_token]1) About the loss function and novelty:[line_break_token][line_break_token]AUTHORS:  Regarding the objective function, please note that, in the paper, we never mentioned that our loss function is novel, nor that we were the first to perform feature matching.	B-Reply	B-1	Reply	1390
As you mentioned, one of the key novelties is on avoiding the min/max game by using a pretrained feature extractor, which sets our work completely apart from [Salimans et al 2016] and [Warde-Farley & Bengio, 2017]. In addition, notice that differently from [Salimans et al 2016] and [Warde-Farley & Bengio, 2017] we perform feature matching using all the layers of the network and this is extremely important for the good performance of the method (as you can see in Table 2).	O	O	Reply	1390
[line_break_token][line_break_token]The research community in generative models has spent the last few years trying to figure out methods to make GANs training more stable.	B-Reply	B-1	Reply	1390
Here we offer an alternative novel method that is competitive with GANs while moving away completely from the problematic min/max game.	I-Reply	I-1	Reply	1390
Hence, it is safe to say that the paper presents a relevant novel contribution for the research community in generative models.	I-Reply	I-1	Reply	1390
[line_break_token][line_break_token]2)  Muli-scale features (on multiple layers of the CNN)  prevent degeneracy of the generator : [line_break_token][line_break_token]AUTHORS:  Please note that our loss does not perform matching using a single feature map, it uses many layers to do feature matching, and this is crucial to prevent such degeneracy.	B-Reply	B-2	Reply	1390
As we are matching effectively on f_1... f_m where m are are features extracted on different layers, we are getting matching on different scales of the generated image.	I-Reply	I-2	Reply	1390
Hence the claim of the reviewer that nothing prevents degeneracy in the objective is not true, and this is not an artifact of the features, it is due to the multi-scale nature of the features!	I-Reply	I-2	Reply	1390
 This multi-feature matching on multiple scales regularizes the learning of the generator.	I-Reply	I-2	Reply	1390
We quote here [1]: " representations obtained across the layers of a CNN increasingly capture the statistical properties of natural images, producing impressive texture synthesis results".	I-Reply	I-2	Reply	1390
  [line_break_token][line_break_token]Note that this multi-features matching has been exploited also in end to end style transfer, or super-resolution [1], but it is novel in generative modeling context .	I-Reply	I-2	Reply	1390
In [1] for instance, the authors show that by matching CNN layers of a pretrained network  one can do super-resolution, we push these observation further by showing that those multi scale features are sufficient statistics also for generation.	I-Reply	I-2	Reply	1390
 Moreover  our empirical results on generation from those deep priors from pretrained features complements theoretical results in [2], that gives theoretical guarantees  for signal recovery from features of deep networks in inverse problems.	I-Reply	I-2	Reply	1390
[line_break_token][line_break_token][1] Bruna et al Super-Resolution with Deep Convolutional Sufficient Statistics.	O	O	Reply	1390
ICLR 2016, <a href="https://arxiv.org/pdf/1511.05666.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1511.05666.pdf</a>[line_break_token][2]Global Guarantees for enforcing deep generative priors by empirical risk minimization, Hand et al[line_break_token]<a href="https://arxiv.org/pdf/1705.07576.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.07576.pdf</a>	O	O	Reply	1390

The paper is an extension of the matching networks by Vinyals et al in NIPS2016.	O	O	Review	414
Instead of using all the examples in the support set during test, the method represents each class by the mean of its learned embeddings.	O	O	Review	414
The training procedure and experimental setting are very similar to the original matching networks.	B-Review	B-1	Review	414
I am not completely sure about its advantages over the original matching networks.	I-Review	I-1	Review	414
It seems to me when dealing with 1-shot case, these two methods are identical since there is only one example seen in this class, so the mean of the embedding is the embedding itself.	B-Review	B-2	Review	414
When dealing with 5-shot case, original matching networks compute the weighted average of all examples, but it is at most 5x cost.	I-Review	I-2	Review	414
The experimental results reported for prototypical nets are only slightly better than matching networks.	B-Review	B-3	Review	414
I  think it is a simple, straightforward,  novel extension, but I am not fully convinced its advantages.	I-Review	I-3	Review	414
We thank Reviewer 2 for reviewing our paper.	O	O	Reply	414
This review‚Äôs main criticism is that our approach is too similar to the matching networks model proposed by Vinyals et al 2016.	O	O	Reply	414
We will update the related work section of our paper to clarify the relationship between prototypical networks and matching nets.	O	O	Reply	414
In the meantime, we would like to take this opportunity to elaborate upon some of the benefits of our approach relative to matching networks: better computational efficiency, a simpler form for the classifier, and a straightforward extension to the zero-shot setting.	O	O	Reply	414
[line_break_token][line_break_token]First and foremost, prototypical networks are computationally more efficient than matching networks.	B-Reply	B-1	Reply	414
If there are K classes, each with N support examples, then computing distances for a query point will take O(K) time for prototypical networks vs. O(KN) for matching networks.	I-Reply	I-1	Reply	414
This is indeed a 5x speedup for the 5-shot scenario, which though not enormous is also not insignificant.	I-Reply	I-1	Reply	414
Even slightly larger scales such as N=10 or N=100 would lead to useful performance gains.	I-Reply	I-1	Reply	414
We see favorable applications of our approach to tasks such as document tagging where it is important to quickly label new documents without needing to compute distances to multiple support examples per tag.	I-Reply	I-1	Reply	414
[line_break_token][line_break_token]Second is the simpler expression of our classifier (see Section 3.2 of our paper) compared to the non-parametric form of matching networks.	B-Reply	B-2	Reply	414
Not only does this require less storage (O(K) vs. O(KN)) but it also sets the stage for future work that explores the prediction of alternate classifiers beyond the linear ones we investigate here.	I-Reply	I-2	Reply	414
[line_break_token][line_break_token]Finally, our approach affords a straightforward extension to the zero-shot setting that matching networks do not.	B-Reply	B-3	Reply	414
The matching networks approach is fundamentally about embedding support examples whereas prototypical networks focuses on learning an embedded representation for each class.	I-Reply	I-3	Reply	414
For the few-shot scenario we chose our representation to be the mean of embedded points, while for the zero-shot scenario we utilized the embedded metadata.	I-Reply	I-3	Reply	414
Such a generalization of the matching networks approach to zero-shot classification does not exist	I-Reply	I-3	Reply	414

This paper sets to understand whether pretraining word embeddings for[line_break_token]programming language code by using NLP-like language models has an[line_break_token]impact on extreme code summarization task (i.e., generate/predict the[line_break_token]name of a function based on its body).	O	O	Review	913
[line_break_token][line_break_token]I think the paper asks some important questions, however the execution[line_break_token]of the research and the results presented are not convincing.	O	O	Review	913
[line_break_token][line_break_token]I think the area is relevant and the research questions are worth[line_break_token]pursuing; however the work as it is presented in the paper needs[line_break_token]improvement to be accepted for publication.	O	O	Review	913
[line_break_token][line_break_token]Pros:[line_break_token]* The study of language models for programming language code[line_break_token]* Pretraining is performed for 3 different languages (C, Java, Python) - target task is in Python[line_break_token][line_break_token]Cons:[line_break_token]* Strange claims of speedup and performance improvement[line_break_token]* Inconclusive results[line_break_token][line_break_token]Some suggestions for improvement:[line_break_token][line_break_token]* The section on language models pretraining is very sparse, more[line_break_token]  details are needed.	B-Review	B-1	Review	913
[line_break_token][line_break_token]* The claims of speedup and improvement are strange.	B-Review	B-2	Review	913
Speedup refers to[line_break_token]  the training speed, I suppose.	I-Review	I-2	Review	913
The performance of the downstream[line_break_token]  task is never discussed.	I-Review	I-2	Review	913
Only the validation loss is shown and all[line_break_token]  the performance "improvement" is discussed on these graphs, which I[line_break_token]  found strange.	I-Review	I-2	Review	913
Also, the graphs have their y-axes starting at[line_break_token]  non-zero values.	I-Review	I-2	Review	913
I personally prefer graphs that start at zero and[line_break_token]  if there is a need to "zoom-in" find a way to "zoom-in" to the part[line_break_token]  of the graph that is important.	I-Review	I-2	Review	913
[line_break_token][line_break_token]* In general the paper writing and reporting on the experiments sounds[line_break_token]  ad-hoc and not well thought-out.	B-Review	B-3	Review	913
[line_break_token][line_break_token]* I don't agree with many of the explanations in the paper.	B-Review	B-4	Review	913
For[line_break_token]  example (page 6), it's not true that the extreme summarization task[line_break_token]  does not require much of the syntactic information (there are[line_break_token]  submission at the current ICLR'19 that show exactly the opposite,[line_break_token]  encoding based on syntactic information is useful).	I-Review	I-4	Review	913
The model[line_break_token]  studied in the paper does NOT use any syntactic information, it[line_break_token]  treats the code like a sequence of tokens.	I-Review	I-4	Review	913
[line_break_token][line_break_token]* The last question in Section 6 is not a Yes/No question, the answer[line_break_token]  is phrased as a Yes/No question.	B-Review	B-5	Review	913
[line_break_token][line_break_token]I encourage the authors to pursue the research questions, however in a[line_break_token]more systematic and with better methodology.	O	O	Review	913
Thank you for the comments and feedback.	O	O	Reply	913
[line_break_token][tab_token][line_break_token]1.	O	O	Reply	913
We have added details about the size of the datasets for the language modeling.	B-Reply	B-1	Reply	913
More details about the model are available in the papers by Merity et al which is referenced in our paper.	I-Reply	I-1	Reply	913
[line_break_token][tab_token][line_break_token]2.	O	O	Reply	913
You are correct in that speedup refers to the increase in training speed.	B-Reply	B-2	Reply	913
This is detailed in the results section where we mention how speedup, S, is calculated as the number of epochs taken by the random embeddings to reach its best validation loss, N\_r, divided by the number of epochs taken by a non-random embedding to reach that same validation loss, N\_e.	I-Reply	I-2	Reply	913
[line_break_token][tab_token][line_break_token]3.	O	O	Reply	913
The downstream task in this experiment is the extreme summarization task.	B-Reply	B-2	Reply	913
We have clarified this in the abstract \& introduction.	O	O	Reply	913
[line_break_token][tab_token][line_break_token]4.	O	O	Reply	913
The performance improvement is for the test loss (using the parameters achieved from the lowest validation loss).	B-Reply	B-2	Reply	913
The paper previously incorrectly stated that improvement was calculated via the validation loss and this has now been corrected.	I-Reply	I-2	Reply	913
We have also added a table of results for the rank 1 F1 scores and made sure to explicitly mention the performance improvements (both for F1 scores and test loss) in the results section.	I-Reply	I-2	Reply	913
[line_break_token][tab_token][line_break_token]5.	O	O	Reply	913
We agree that syntactic information is useful and you are correct in that the model is not explicitly fed the syntactic information.	B-Reply	B-4	Reply	913
However, the model does implicitly use syntactic information as the syntax does exist within the sequence of tokens.	I-Reply	I-4	Reply	913
Furthermore, as per AnonReviewer1's comments, we have added results obtained from using embeddings trained on a natural language (English), and have shown they achieve comparable results to each of the programming languages used.	I-Reply	I-4	Reply	913
As all 4 of these embeddings achieve similar results - with the main difference between them being the syntax - we would argue that this supports the view that the syntax is less important - although admittedly still useful - than the semantic information provided by sensible variable names for this task.	I-Reply	I-4	Reply	913
We do think the usefulness of syntactic information for the extreme summarization task is an interesting area of research and requires further investigation, but we believe it is outside the scope of this work.	I-Reply	I-4	Reply	913
[line_break_token][tab_token][line_break_token]6.	O	O	Reply	913
Thank you for spotting the error with RQ6, this has now been corrected.	B-Reply	B-5	Reply	913

[line_break_token]CONTRIBUTIONS:[line_break_token][line_break_token]C1.	O	O	Review	197
Cross-linguistic token overlap.	O	O	Review	197
Fake-English: English, but with the Unicode codes of English characters all shifted by a large constant so that there is no overlap between Fake-English characters and those of actual languages, but the language-internal structure remains that of English.	O	O	Review	197
[line_break_token][line_break_token]C2.	O	O	Review	197
A bilingually-trained BERT, pretrained on languages L and L‚Äô, is then trained on a downstream task in L then tested on that task in L‚Äô.	O	O	Review	197
The task is Cross-Lingual NLI (XNLI) or Cross-Lingual NER.	O	O	Review	197
L‚Äô is Spanish, Hindi, or Russian.	O	O	Review	197
L is English or Fake-English.	O	O	Review	197
Comparing the success at test when L = English vs. when L = Fake-English, it is shown that eliminating all token overlap between L and L‚Äô has a small effect (less than 1.5% on XNLI, less than about 3.5% on NER). (	O	O	Review	197
Table 1)[line_break_token][line_break_token]C3.	O	O	Review	197
Several architectural parameters of BERT are varied holding the others roughly constant (same tasks as C2, with L = Fake-English).	O	O	Review	197
This shows that depth (Table 2) and level of tokenization matter (Table 7), while little effect results from varying the number of attention heads (Table 3), number of parameters (Table 4), whether the next sentence prediction task is used for training (Table 5), or whether the language of an input is explicitly given (Table 6).	O	O	Review	197
[line_break_token][line_break_token]C4.	O	O	Review	197
Testing cross-language entailment on XNLI by B-BERT shows that there is a large reduction in performance when the hypothesis and premises sentences are from different languages.	O	O	Review	197
[line_break_token][line_break_token]RATING: Weak reject[line_break_token][line_break_token]REASONS FOR RATING (SUMMARY).	O	O	Review	197
Aside from the invention of Fake-English, which as far as I know is original and a clever approach to assessing the importance of token overlap in cross-language transfer, the other contributions are reporting results of mechanical changes.	O	O	Review	197
The paper‚Äôs contributions are useful, but do not reach a level of generality, originality, or depth justifying presentation at ICLR.	B-Review	B-1	Review	197
[line_break_token][line_break_token]Although it did not factor into my rating, I would like to point out that saying ‚Äòstructural similarity is important‚Äô and saying ‚Äòword-piece overlap is not important‚Äô is saying exactly the same thing twice, since the gain not attributable to word-piece overlap, by their definition, equals the gain due to ‚Äòstructural similarity‚Äô, which is a concept otherwise undefined and unmeasurable.	B-Review	B-2	Review	197
e sincerely thank the reviewer for reviewing our paper.	O	O	Reply	197
[line_break_token]&gt; **Lack of generality, originality or depth**[line_break_token][line_break_token](1) First, we would like to point out that this paper is the first to propose an experimental design that proves that word-pieces overlap do not contribute to the transferability of M-BERT.	B-Reply	B-2	Reply	197
This was done by inventing the notion of Fake-English, with a distinct word-piece space.	I-Reply	I-2	Reply	197
Moreover, we believe that the methodology we propose in this paper is general enough to support additional insights, and will be followed up by other authors, and therefore this in itself is a significant contribution.	I-Reply	I-2	Reply	197
[line_break_token][line_break_token](2) Second, while the design of our architectural experiments may not be sophisticated, we are the first to perform this set of experiments systematically, and identify the aspects of the architecture that are important for transferability, as well as those that are not.	B-Reply	B-1	Reply	197
We believe that this, too, is an important contribution to understanding M-BERT.	I-Reply	I-1	Reply	197
Further, we have added a few more results on the number of parameters to understand the threshold, and also showed that we can get comparable performance with only a small number of parameters and attention heads, even in multilingual case (four language BERT).	I-Reply	I-1	Reply	197
Please refer to appendix section ‚ÄúFURTHER DISCUSSIONS ON ARCHITECTURE‚Äù[line_break_token][line_break_token](3) Third, our results are the first to show clearly that the transferability of M-BERT depend on some aspect of structural similarity between the languages, and has nothing to do with lexical similarity.	I-Reply	I-1	Reply	197
While we have not isolated yet which aspects of structural similarity contribute to transferability, and how much, this is already an important contribution, please refer to the appendix section ‚ÄúFURTHER  DISCUSSIONS ON STRUCTURAL SIMILARITY‚Äù, for some of our initial experiments that break this down a bit more.	I-Reply	I-1	Reply	197
[line_break_token][line_break_token](4) Our final observation of the drastic drop in performance when the premise and hypothesis are in different languages (Table 8) might suggest that BERT is simply learning the word matching instead of learning the actual entailment.	I-Reply	I-1	Reply	197
This observation definitely needs special attention to understand what BERT learns from entailment supervision.	I-Reply	I-1	Reply	197
[line_break_token][line_break_token][line_break_token]General comment:[line_break_token]Also, please take a look at the general comments for more on structural similarity and the number of parameters experiment.	O	O	Reply	197

The authors propose and evaluate using SPN's to generate embeddings of input and output variables, and using MPN to decode output embeddings to output variables.	O	O	Review	513
The advantage of predicting label embeddings is to decouple dependencies in the predicted space.	O	O	Review	513
The authors show experimentally that using SPN based embeddings is better than those produced by RBM's.	O	O	Review	513
[line_break_token][line_break_token]This paper is fairly dense and a bit hard to read.	O	O	Review	513
After the discussion, the main contributions of the authors are:[line_break_token][line_break_token]1.	O	O	Review	513
They propose the scheme of learning SPN's over Y and then using MPN's to decode the output, or just SPNs to embed X.[line_break_token]2.	O	O	Review	513
They propose how to decode MPN's with partial data.	O	O	Review	513
[line_break_token]3.	O	O	Review	513
They perform some analysis of when their scheme will lead to perfect encoding/decodings.	O	O	Review	513
[line_break_token]4.	O	O	Review	513
They run many, many experiments comparing various ways of using their proposed method to make predictions on multi-label classification datasets.	O	O	Review	513
[line_break_token][line_break_token]My main concerns with this paper are as follows:[line_break_token][line_break_token]- The point of this paper is about using generative models for representation learning.	O	O	Review	513
In their experiments, the main task is discriminative; e.g. predict multiple Y from X. The only discriminative baseline is a L2 regularized logistic regression, which does not have any structure on the output; it'd be nice to see how a discriminative structured prediction method would do, such as CRF or belief propagation.	O	O	Review	513
[line_break_token][line_break_token]- The many experiments suggest that their encoder/decoder scheme is working better than the alternatives; can you please give more details on the relative computation complexity of each method?	O	O	Review	513
[line_break_token][line_break_token]- One thing I'm still having trouble understanding is *why* this method works better than MADE and the other alternatives.	O	O	Review	513
Is it learning a better model of the distribution of Y?	O	O	Review	513
Is it better at separating out correlations in the output into individual nodes?	O	O	Review	513
 Does it have larger representations?	O	O	Review	513
[line_break_token][line_break_token]- I think the experiments are overkill and if anything, they way they are presented detract from the paper.	O	O	Review	513
There's already far too many numbers and graphs presented to be easy to understand.	O	O	Review	513
 If I have to dig through hundreds of numbers to figure out if your claim is correct, the paper is not clear enough.	O	O	Review	513
And, I said this before in my comments, please do not refer to Q1, Q2, etc. --	O	O	Review	513
these shortcuts let you make the paper more dense with fewer words but at the cost of readability.	O	O	Review	513
[line_break_token][line_break_token]I *think* I convinced myself that your method works...I would love to see a table that shows, for each condition: (A) a baseline X->Y, (B) one *average* result across datasets for your method, and (C) one *average* result from a reasonable best competitor method.	O	O	Review	513
Please show for both the exact match and hamming losses, as that will demonstrate the gap between independent linear prediction and structured prediction.	O	O	Review	513
That would still be plenty of numbers but would make it much easier for the reader to verify your claims and you can put everything else in the Appendix.	O	O	Review	513
 E.g. something like:[line_break_token][line_break_token]Input | Predicted Output | Decoder | Hamming | Exact Match[line_break_token]----[line_break_token]X | P(Y) | CRF | xx.xx | xx.xx   (this is your baseline)[line_break_token]SPN E_X | P(Y) | n/a | xx.xx | xx.xx [line_break_token]X | SPN E_Y | MPN | xx.xx | xx.xx  (given X, predict E_Y, then decode it with an MPN)[line_break_token][line_break_token]Does a presentation like that make sense?	O	O	Review	513
It's just really hard and time-consuming for me as a reviewer to verify your results, the way you've laid them out currently.	O	O	Review	513
[line_break_token][line_break_token][line_break_token]	O	O	Review	513
--------------------------[line_break_token]Dear reviewer, thanks for your time and suggestions.	O	O	Reply	513
[line_break_token]We will try to answer your questions more in detail, hoping to improve the paper towards a full acceptance.	O	O	Reply	513
[line_break_token][line_break_token][line_break_token]> The point of this paper is about using generative models for	O	O	Reply	513

This paper studies the effects of using function of ngram statistics as feature to generate attention score per word.	O	O	Review	20092
The attention score is then used as weights to aggregate document embedding by doing a weighted average on word embedding.	O	O	Review	20092
The output is finally fed into a ridge regressor to do the final predictions on target labels.	O	O	Review	20092
[line_break_token][line_break_token]Main comments:[line_break_token]This paper has a clear motivation and decent experimental results (though some concern on baseline models, see below).	B-Review	B-1	Review	20092
The introduction of using distributional signature to derive attention scores seems interesting and a novel contribution.	I-Review	I-1	Review	20092
However I was not able to fully understand the intuition behind the benefit of doing attention mechanism on top of ngram statistics (see my question below as well).	I-Review	I-1	Review	20092
[line_break_token]Also the reference/baseline models used in the experiment might not be strong enough.	B-Review	B-2	Review	20092
If you could compare your model with some latest algorithms proposed in the few-shot-learning communities, that would be more convincing as well.	I-Review	I-2	Review	20092
[line_break_token]To list a few:[line_break_token]* P-MAML: [Zhang et al 2019][line_break_token]* Induction-Network-Routing: [Geng et al 2019][line_break_token]* ROBUSTTC-FSL [Yu et al 2018][line_break_token][line_break_token]I am leaning to give a "weak reject" based on my current knowledge and understanding of the paper.	O	O	Review	20092
But I will be willing to revisit the decision after we get feedback from the author(s).	O	O	Review	20092
[line_break_token][line_break_token]In particular, I would be glad if the author could clarify the questions below.	O	O	Review	20092
[line_break_token][line_break_token]* From table 1, it seems Method IDF+RR is a competitive model.	B-Review	B-3	Review	20092
IIUC, the statistics of s(.)	I-Review	I-3	Review	20092
is highly correlated with IDF which also indicates general word importance in corpus.	I-Review	I-3	Review	20092
My questions are that, [line_break_token]1) regarding ablation test "OUR w/o biLSTM", how is calculated in this case (without biLSTM)?	I-Review	I-3	Review	20092
[line_break_token]2) since each word is represented based on two statistical number (map function by t(.)	B-Review	B-4	Review	20092
and s(.)),	I-Review	I-4	Review	20092
can you give any intuitive explanation that why getting attention score from that makes sense?	I-Review	I-4	Review	20092
[line_break_token]3) do you have any experiments using the distributional signature as a common feature in standard text classification problems?	B-Review	B-5	Review	20092
In other words, is this method only (significantly) beneficial to few-short-learning?	I-Review	I-5	Review	20092
If it is also useful in general text classification task, it would be a good "plus" here.	I-Review	I-5	Review	20092
[line_break_token][line_break_token]* From table 2, can you explain why CNN+RR benefits a lot from the BERT embedding?	B-Review	B-6	Review	20092
Actually it gets more percentage of improvement than the model "OUR".	I-Review	I-6	Review	20092
[line_break_token][line_break_token]* For all the usages of pre-trained embedding (fasttext or BERT), are you further finetuning the embedding parameters during your training?	B-Review	B-7	Review	20092
Or you freeze the embedding parameters?	I-Review	I-7	Review	20092
[line_break_token][line_break_token][Zhang et al 2019] Ningyu Zhang et al Improving Few-shot Text Classification via Pretrained Language Representations.	O	O	Review	20092
arXiv preprint arXiv: 1908.08788[line_break_token][Geng et al 2019] Ruiying Geng, Binhua Li, Yongbin Li, Yuxiao Ye, Ping Jian, and Jian Sun.	O	O	Review	20092
2019.	O	O	Review	20092
Few-shot text classification with induction network.	O	O	Review	20092
arXiv preprint arXiv:1902.10482.	O	O	Review	20092
[line_break_token] [Yu et al 2018] Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng, Gerald Tesauro, Haoyu Wang,[line_break_token]and Bowen Zhou.	O	O	Review	20092
2018.	O	O	Review	20092
Diverse few-shot text classification with multiple metrics.	O	O	Review	20092
arXiv preprint arXiv:1805.07513	O	O	Review	20092
hank you for the detailed comments and suggestions!	O	O	Reply	20092
[line_break_token][line_break_token]The main idea of the paper is that if we want to learn transferable knowledge, methods that memorize word identities will fail when the word distribution shifts.	B-Reply	B-1	Reply	20092
By learning meta-knowledge on top of n-gram statistics, class-specific words will still be important (and common stop words unimportant), even if the actual words themselves change. (	I-Reply	I-1	Reply	20092
More specific example regarding our two statistics below.)	I-Reply	I-1	Reply	20092
[line_break_token][line_break_token]Additional Experiments: Based on the suggestions, we have compared our work to P-MAML and Induction Network Routing.	B-Reply	B-2	Reply	20092
Detailed results are located in Appendix A.5.	I-Reply	I-2	Reply	20092
[line_break_token] [line_break_token]On average, our method outperforms P-MAML by 18.5% on 1-shot and 19.3% on 5-shot, and Induction Networks by 21.1% on 1-shot and 32.4% on 5-shot (Table 4).	I-Reply	I-2	Reply	20092
While both P-MAML and Induction Networks are able to overfit the meta-train data easily, they are unable to generalize when faced with lexical mismatch (Figure 9).	I-Reply	I-2	Reply	20092
[line_break_token][line_break_token]Furthermore, we show that we can improve Induction Networks by replacing its lexically-aware encoder with our attention-weighted representation learned from distributional signatures  (Appendix A.9).	I-Reply	I-2	Reply	20092
On average, distributional signatures increase Induction Networks accuracy by 14.3% on 1-shot and 25.1% on 5-shot.	I-Reply	I-2	Reply	20092
[line_break_token][line_break_token]RobustTC-FSL is not directly applicable to our setting since it considers a fixed set of tasks during meta-training (e.g. binary sentiment classification across 23 Amazon domains) and utilizes their cross-task transferability.	I-Reply	I-2	Reply	20092
[line_break_token][line_break_token]Questions:[line_break_token]* s(.)	B-Reply	B-3	Reply	20092
and IDF both indicate general word importance.	I-Reply	I-3	Reply	20092
We experimented with both during our development stage and found that they perform similarly when used in our attention generator (idf 77.8 vs s(.)	I-Reply	I-3	Reply	20092
78.0 for 5 shot classifications averaged across 6 datasets).	I-Reply	I-3	Reply	20092
We choose the current formulation as it is more interpretable in context of robustness against word-substitution perturbation.	I-Reply	I-3	Reply	20092
[line_break_token][line_break_token]1) We apply an MLP on top of the [s(); t()] at each position, where ; denotes concatenation.	I-Reply	I-3	Reply	20092
After that we applied softmax over the output of the MLP.	I-Reply	I-3	Reply	20092
This MLP has 2 inputs, 50 hidden units (ReLU activation) and 1 output.	I-Reply	I-3	Reply	20092
[line_break_token][line_break_token]2) One indicates word importance for general classification (estimated from source pool) and the other indicates how important the feature is for this particular task (a rough estimate).	O	O	Reply	20092
[line_break_token][line_break_token]For example, suppose we have lots of data from political and sports news, and we want to expand into arts news.	B-Reply	B-4	Reply	20092
General word importance (learned from politics and sports) can tell us that words like ‚Äúthe‚Äù and ‚Äúwe‚Äù are not useful, so we learn to ignore them.	I-Reply	I-4	Reply	20092
However, politics and sports news also have no use for arts-specific words, like ‚Äúpainting‚Äù or ‚Äúperformance.	I-Reply	I-4	Reply	20092
‚Äù Thus, we require task-specific word importance (learned from few arts examples) to refine our understanding of useful words.	I-Reply	I-4	Reply	20092
[line_break_token][line_break_token]3) The general idea of ‚Äúdistributional signatures‚Äù is not new.	B-Reply	B-5	Reply	20092
Prior to the age of deep learning, linear SVM + TF-IDF was considered a strong baseline to beat, and more recently, Arora 2016 showed that SIF-weighted representations (statistics used for s(.)	I-Reply	I-5	Reply	20092
in our model) do outperform LSTMs/CNNs on some (standard) tasks.	I-Reply	I-5	Reply	20092
In our setting, we noted that the idea may also be helpful for few-shot classification, as these statistics are more transferable across tasks.	I-Reply	I-5	Reply	20092
For general classification tasks with lots of annotation, the representation power of distribution signatures may be limited (though this is slightly beyond the scope of our paper).	I-Reply	I-5	Reply	20092
[line_break_token][line_break_token]* BERT is contextual, so the embedding of one word represents not only itself, but also its surroundings.	B-Reply	B-6	Reply	20092
Correspondingly, if a CNN downweights an important word from an unseen class, its adjacent words still contain information about that word.	I-Reply	I-6	Reply	20092
This means that it is less ‚Äúcostly‚Äù to ignore important words from unseen classes, as a result of overfitting on seen classes.	I-Reply	I-6	Reply	20092
For OUR, this means that we don‚Äôt have to be as precise about picking out each important word.	I-Reply	I-6	Reply	20092
[line_break_token][line_break_token]* Since the vocabulary of meta-train classes and meta-test classes may be very different, we freeze the pre-trained embeddings (Fasttext or BERT) during meta training.	B-Reply	B-7	Reply	20092
This is to avoid disrupting the inherent geometry of word embeddings, as finetuning will cause these embeddings to lose the relationship between meta-train vocabulary (seen during finetuning) and meta-test vocabulary (not seen, and thus not optimized for).	I-Reply	I-7	Reply	20092
Empirically, we show that freezing word embeddings outperforms finetuning (Table 6).	I-Reply	I-7	Reply	20092
[line_break_token][line_break_token]We hope we have adequately addressed your concerns.	O	O	Reply	20092
Please let us know if you have any more questions.	O	O	Reply	20092
Thank you!	O	O	Reply	20092

This paper puts forward a new schema for language modeling, especially for relationship between two parts far apart.	O	O	Review	969
[line_break_token][line_break_token]The experimental results on WikiText-103 are good, improving the STOA PPL by 9.0.	O	O	Review	969
On the other three datasets, however, there's little or no gain.	O	O	Review	969
The speed comparison should be carried out over more LM models, as Al-Rfou is not the fastest.	O	O	Review	969
[line_break_token][line_break_token]The writing is not very clear, especially around equations.	O	O	Review	969
[line_break_token][line_break_token]Overall the contribution of this paper is marginally incremental:[line_break_token]1.	O	O	Review	969
The major proposed idea is just to add one no-grad previous segment into the prediction for next segment.	O	O	Review	969
This is similar to Residual network idea but more simplified.	O	O	Review	969
[line_break_token]2.	O	O	Review	969
Using relative positional encoding is not a new idea, e.g. <a href="https://arxiv.org/pdf/1803.02155.pdf."	O	O	Review	969
target="_blank" rel="nofollow">https://arxiv.org/pdf/1803.02155.pdf.</a>[line_break_token]3.	O	O	Review	969
Reusing previous level/segment computation with gradient fixed is also not a big innovation.	O	O	Review	969
[line_break_token][line_break_token]typo:[line_break_token]1.	O	O	Review	969
end of page 3, and "W." denotes".	O	O	Review	969
[line_break_token]2.	O	O	Review	969
The speed experiment should be put in the main text.	O	O	Review	969
Dear reviewer, we believe we have addressed your concerns in the rebuttal (see the General Response above and the comments below).	O	O	Reply	969
Especially, we have further improved over state-of-the-art results ever since.	O	O	Reply	969
Do you have an updated assessment or other concerns of our paper?	O	O	Reply	969
Thank you	O	O	Reply	969

The paper introduces a new intrinsic reward for MARL, representing the causal influence of an agent‚Äôs action on another agent counterfactually.	O	O	Review	670
The authors show this causal influence reward is related to maximising the mutual information between the agents‚Äô actions.	O	O	Review	670
The behaviour of agents using this reward is tested in a set of social dilemmas, where it leads to increased cooperation and communication protocols, especially if given an explicit communication channel.	O	O	Review	670
As opposed to related work, the authors also equip the agents with an internal Model of Other Agents that predicts the actions of other agents and simulates counterfactuals.	O	O	Review	670
This allows the method to run in a decentralized fashion and without access to other agents‚Äô reward functions.	O	O	Review	670
[line_break_token][line_break_token]The paper proposes a very interesting approach.	O	O	Review	670
I‚Äôm not a MARL expert, so I focused more on the the causal aspects.	O	O	Review	670
The paper seems generally well-organized and well-written, although I‚Äôm a bit confused about the some of the causal modelling decisions and assumptions.	O	O	Review	670
This confusion and  some potential errors, which I describe in detail below, are the reason for my borderline decision, despite liking the paper otherwise.	O	O	Review	670
[line_break_token] [line_break_token]First, I‚Äôm a bit confused about the utility of the Section 2.1 model (Figure 1), mostly because of the temporal and multiple agents aspects that seem to be dealt with (‚Äúmore‚Äù) correctly in the MOA model.	B-Review	B-1	Review	670
Specifically in Figure 1, one would need to assume that there is only one agent A influencing agent B at the same time (and agent B does not influence anything else).	I-Review	I-1	Review	670
For example, there is no other agent C which actions also influence agent B, and no agent D that is influenced by agent B, otherwise the backdoor-criterion would not work, unless you add also the action of agent C to the conditioning set (or its state).	I-Review	I-1	Review	670
Importantly, adding the actions of all agents, also a potential agent D that is downstream of B would be incorrect.	I-Review	I-1	Review	670
So in this model there is some kind of same time interaction and there seems to be the need for a causal graph that is known a priori.	I-Review	I-1	Review	670
These problems should disappear if one assumes that only the time t-1 actions can influence the time t actions, as in the MOA model.	I-Review	I-1	Review	670
I assume the idea of the Figure 1 model was to show a relationship with mutual information, but for me specifically it was quite confusing.	I-Review	I-1	Review	670
[line_break_token][line_break_token]I was much less confused by the MOA causal graph represented in Figure 4, although I suspect there are quite some interactions missing (for example s_t^A causes u_t^A similarly to the green background?	B-Review	B-2	Review	670
s_t causes s_{t+1} (which btw in this case should probably be split in two nodes, one s_{t+1} and one s_{t+1}^B?).	I-Review	I-2	Review	670
Possibly one could also add the previous time step for agent B (with u_{t+1}^B influenced by u_t^B I would assume?).	I-Review	I-2	Review	670
As far as I can see there is no need to condition on a_t^B in this case to see the influence of a_t^A on a_{t+1}^B, u_t^A and s_t^A should be enough?	I-Review	I-2	Review	670
[line_break_token][line_break_token]Minor details:[line_break_token]Is there possibly a log missing in Eq.	B-Review	B-3	Review	670
2?	I-Review	I-3	Review	670
[line_break_token]	O	O	Review	670
Thanks for your feedback - we are glad that you found the paper interesting, and we hope to be able to clear up any confusion surrounding the causal modeling.	O	O	Reply	670
[line_break_token][line_break_token]You are correct that the first method of implementing the causal influence reward described in section 2.1 has the important limitation that agents cannot mutually influence each other.	B-Reply	B-1	Reply	670
However, we believe we have handled the conditioning correctly to satisfy the back door criterion, by imposing a sequential ordering on agents‚Äô actions.	I-Reply	I-1	Reply	670
We allow only a fixed number of agents to be influencers, and the rest are influencees.	I-Reply	I-1	Reply	670
Only an influencer gets the causal influence reward, and only an influencee can be influenced.	I-Reply	I-1	Reply	670
At each timestep, the influencers choose their actions first, and these actions are then given as input to the influencees.	I-Reply	I-1	Reply	670
Let‚Äôs say that agent A and B are influencers, and C is an influencee.	I-Reply	I-1	Reply	670
Then C receives both a^A_t and a^B_t as input.	I-Reply	I-1	Reply	670
When computing the causal influence of A on C, we also add a^B_t to the conditioning set, as you describe.	I-Reply	I-1	Reply	670
However, we do not condition on actions downstream of C, as you mention.	I-Reply	I-1	Reply	670
You are correct that in this model the causal graph does need to be known a priori, and in that sense it is more limited.	I-Reply	I-1	Reply	670
We only introduced this initial model as a proof-of-concept, and retained it in the paper because it is associated with some of the interesting qualitative results we present in Section 4.1.	I-Reply	I-1	Reply	670
We will modify the paper to include a more detailed description of the sequential nature of agents‚Äô actions in order to reduce confusion in the future.	I-Reply	I-1	Reply	670
However, you are correct that the MOA approach is likely to be more effective in practice, and we would like to emphasize the success of this approach, and the communication results in Section 4.2, as more important contributions.	I-Reply	I-1	Reply	670
[line_break_token][line_break_token]You are right that we are missing an arrow from s_t -> s_{t+1}, and the partially observed states s^B_{t+1} in Figure 4; we will add these to the Figure and update it in the next revision.	O	O	Reply	670
You are also correct that we do not need to condition on a_t^B, but we do allow the model to use a_t^B when making its predictions about a_{t+1}^B, so we have shown this as shaded in the Figure.	B-Reply	B-2	Reply	670
 [line_break_token][line_break_token]We don‚Äôt believe there is a missing log in equation 2; the log is absorbed into the KL term.	B-Reply	B-3	Reply	670

The paper proposes simple modifications to GAN architecture for unsupervised conditional image generation.	O	O	Review	1116
The authors achieve this by making the distribution of noise z dependent on variable y that can depend on the label distribution when available.	O	O	Review	1116
This involves learning to predict the input noise z as well as y from the generated image.	O	O	Review	1116
The qualitative results shown for unsupervised conditional image generations using the approach are convincing.	O	O	Review	1116
[line_break_token][line_break_token]Pros:[line_break_token][tab_token]- The paper is well written and easy to follow.	O	O	Review	1116
[line_break_token][tab_token]- The simple modification to the noise distribution leads to good results on unsupervised conditional image generation.	O	O	Review	1116
[line_break_token][tab_token]- Minimizes loss terms exactly instead of lower bound as is commonly done in other similar unsupervised approaches.	O	O	Review	1116
[line_break_token][tab_token]- Theoretical justifications for the approach are convincing.	O	O	Review	1116
[line_break_token][line_break_token]Cons:[line_break_token][tab_token]- The paper can be strengthened by including ablation studies on the loss term for the z reconstruction.	B-Review	B-1	Review	1116
[line_break_token][tab_token]- How will InfoGAN and VEEGAN compare with similar loss terms for the z reconstruction added to their objective?	B-Review	B-2	Review	1116
[line_break_token][tab_token]- It will be useful to show FID and other similar scores to better evaluate the learned generative model.	B-Review	B-3	Review	1116
Including mode counting, experiments will strengthen the paper.	I-Review	I-3	Review	1116
[line_break_token][tab_token]- ACGAN can suffer from the issue of generating images where it is easy to infer y [1]. This leads to mode collapse within each category/class.	B-Review	B-4	Review	1116
Will the proposed approach suffer from similar issues?	I-Review	I-4	Review	1116
[line_break_token][line_break_token][1] Shu, Rui, Hung Bui, and Stefano Ermon. "	O	O	Review	1116
AC-GAN Learns a Biased Distribution."	O	O	Review	1116
We thank the reviewer for the constructive feedback and comments.	O	O	Reply	1116
Below are our responses for the concerns raised.	O	O	Reply	1116
We are happy to answer further questions, if any.	O	O	Reply	1116
[line_break_token][line_break_token]Q1.	O	O	Reply	1116
The paper can be strengthened by including ablation studies on the loss term for the z reconstruction.	O	O	Reply	1116
[line_break_token][line_break_token]Ans: Thank you for this suggestion.	B-Reply	B-1	Reply	1116
We have now included the ablation studies in the experimental section.	I-Reply	I-1	Reply	1116
The following are the observations - [line_break_token][line_break_token]Our model involves two reconstruction stages for the latent space  and).	I-Reply	I-1	Reply	1116
To study the effect of individual components of the model, we perform the following ablation studies -  (a) training a NEMGAN without the network, (b) training a NEMGAN without the network, (c) training a conventional GAN with noise engineering.	I-Reply	I-1	Reply	1116
Experiment (a) and (b) are conducted on the MNIST dataset and the output images are shown in Fig 9.	I-Reply	I-1	Reply	1116
It can be seen that the absence of the KL-loss ) results in the mixing of classes within each mode and the absence of norm-loss ) results in lack of variety within each mode.	I-Reply	I-1	Reply	1116
For example, 1's with serifs are not generated in absence of.	I-Reply	I-1	Reply	1116
Results for the experiment (c) is depicted in the Appendix E which suggests that a conventional GAN with latent space engineering cannot separate out the modes.	I-Reply	I-1	Reply	1116
These experiments suggests that the inclusion of the norm-based reconstruction term encourages the model to avoid the intra-class mode collapse unlike in the case of supervised conditional GANs [1]. [line_break_token][line_break_token]Q2.	O	O	Reply	1116
How will InfoGAN and VEEGAN compare with similar loss terms for the z reconstruction added to their objective?	O	O	Reply	1116
[line_break_token][line_break_token]Ans: The original VEEGAN has a latent space reconstruction term in it by construction.	B-Reply	B-2	Reply	1116
We included the z reconstruction term in the official implementation of the InfoGAN and found that it is unable to produce the MNIST images.	I-Reply	I-2	Reply	1116
We believe that this might be because of the fact that the Q network, which is used to maximize the mutual information, is made a part of the discriminator.	I-Reply	I-2	Reply	1116
Thus, performing a joint task of maximizing mutual information between the categorical code and the generated images as well as reconstructing the noise term is not feasible.	I-Reply	I-2	Reply	1116
That is perhaps the reason authors of InfoGAN terms ‚Äòz‚Äô as the irreducible noise.	I-Reply	I-2	Reply	1116
On the contrary, our architecture has the discriminator and the latent reconstructor decoupled from each other which is the reason our method performs multiple tasks such as conditional generation, data inference etc.	I-Reply	I-2	Reply	1116
[line_break_token][line_break_token]Q3.	O	O	Reply	1116
It will be useful to show FID and other similar scores to better evaluate the learned generative model.	O	O	Reply	1116
Including mode counting, experiments will strengthen the paper.	O	O	Reply	1116
[line_break_token][line_break_token]Ans: Thank you again for this suggestion.	B-Reply	B-3	Reply	1116
We have included the FID values in Table 2 and 3 of the current version of the paper and compared with the existing methods.	I-Reply	I-3	Reply	1116
We have also included the mode counting experiments on standard stacked MNIST data and a toy 8 component GMM data in Appendix D. Mode counting results are summarized in Table 1 of the current version of the paper and it is found that NEMGAN captures the most number of modes.	I-Reply	I-3	Reply	1116
[line_break_token][line_break_token]Q4.	O	O	Reply	1116
ACGAN can suffer from the issue of generating images where it is easy to infer y [1]. This leads to mode collapse within each category/class.	O	O	Reply	1116
Will the proposed approach suffer from similar issues?	O	O	Reply	1116
[line_break_token][line_break_token]Ans: This is precisely the reason we broke down the z-reconstruction loss into two parts - KL and norm-based.	B-Reply	B-4	Reply	1116
The below paragraph (from Sec.	I-Reply	I-4	Reply	1116
2 of the paper) summarizes the idea - [line_break_token][line_break_token]Using proposition 1 and 2, one can make the data generating distribution to be bimodal, however, produced modes might be degenerated in a sense that's  reduce to singletons (mode collapse).	I-Reply	I-4	Reply	1116
 To avoid this degenerative case, we propose to decompose   as a composite of two mappings and.	I-Reply	I-4	Reply	1116
Minimizing a norm distance between the samples of and prevents degenerative modes in.	I-Reply	I-4	Reply	1116
This is because enforces a unique reconstruction of every sample of which in turn ensures that a unique sample of is generated by a unique sample of.	I-Reply	I-4	Reply	1116
The function can be seen as an activity regularizer that would force every unique noise sample within each mode to map to a unique samples in the inversion and the generated spaces.	I-Reply	I-4	Reply	1116
[line_break_token][line_break_token]These ideas are reconciled with the ablation experiments (Sec.	I-Reply	I-4	Reply	1116
4.4) where the inclusion of norm-based loss is seen to avoid the intraclass mode collapse.	I-Reply	I-4	Reply	1116
This point has been brought out in the current version of the paper.	I-Reply	I-4	Reply	1116
[line_break_token][line_break_token][1] Shu, Rui, Hung Bui, and Stefano Ermon. "	O	O	Reply	1116
AC-GAN Learns a Biased Distribution.	O	O	Reply	1116

Paper's Claims[line_break_token][line_break_token]The paper introduces a new unsupervised abstractive summarization approach called TED, using a Transformer encoder and decoder.	O	O	Review	346
Their main contributions are as follows:[line_break_token]1) Pretraining the encoder and decoder on news articles using the first beginning as the target summary.	O	O	Review	346
[line_break_token]2) Fine-tune on other datasets using so-called theme modeling, and separately a denoising loss.	O	O	Review	346
[line_break_token]3) TED's performance is claimed to significantly improve over GPT-2 while not being too far from the best unsupervised extractive summarization results.	O	O	Review	346
[line_break_token][line_break_token]Decision[line_break_token][line_break_token]Edit: After revisions and discussions, I recommend we accept this paper.	O	O	Review	346
[line_break_token][line_break_token]I am leaning towards accepting this paper mostly because of the contribution #1 above.	O	O	Review	346
Unsupervised learning using large quantities of text that have the property of being typically written in a style that synthesizes information in the first 1-3 sentences is a powerful idea.	O	O	Review	346
That the performance is improved compared to other unsupervised abstractive summarization confirms the importance of this approach.	O	O	Review	346
[line_break_token][line_break_token]However the importance of and justification for the fine-tuning steps are comparatively much more limited in my opinion.	O	O	Review	346
Also, some important details about the preprocessing for pre-training appear to be missing and they could be quite important.	O	O	Review	346
[line_break_token][line_break_token]Detailed arguments for decision[line_break_token][line_break_token]I view this effort as aiming to reproduce the BERT approach in the context of abstractive summarization, which is a good idea.	O	O	Review	346
The most clever contribution is in leveraging un-labeled text using the first few sentences as the target summary for pretraining.	O	O	Review	346
The results of just this part are already beating previous approaches, while not requiring any in-domain data, which is quite powerful.	O	O	Review	346
[line_break_token][line_break_token]However, some relatively important details regarding the methodology are omitted or only glossed over and it would greatly contribute to making this work more reproducible if the details were included (see my detailed notes below, notably regarding section 2.2).	B-Review	B-1	Review	346
[line_break_token][line_break_token]On the fine-tuning steps, I have several worries.	B-Review	B-2	Review	346
First, why not fine-tune using supervised learning, as would be the analog to the BERT approach?	I-Review	I-2	Review	346
Instead the authors go out of their way to do in-domain unsupervised learning, which provides a boost, yes, but still doesn't compare positively to extractive and/or supervised methods.	I-Review	I-2	Review	346
Second, why not perform the theme modeling and denoising also -- or rather only -- on the unlabelled pretraining data?	I-Review	I-2	Review	346
Why should it be done on the in-domain fine-tuning data instead (while not using the most valuable piece of in-domain information, namely the example summaries)?	I-Review	I-2	Review	346
After all, it's a fully unsupervised approach and it can actually be performed on any text at all, whether a summary for it exists or not.	I-Review	I-2	Review	346
[line_break_token][line_break_token]Again regarding the unsupervised approach, and to push the BERT analogy further, I'm wondering why not initialize the pretraining model with a BERT-style trained model?	B-Review	B-3	Review	346
After all we could imagine building a system that adds more and more in-domain characteristics sequentially: first pretrain a BERT model, then fine-tune to summarization using what this paper calls pretraining, and then finally fine-tune again to a specific summarization domain.	I-Review	I-3	Review	346
[line_break_token][line_break_token]So, to conclude, I find that this paper goes in the right direction and introduces important ideas for pretraining and fine tuning unsupervised abstractive summarization models, but that some decisions about how to use the various ideas (theme and denoising but no supervised learning, in-domain vs during pretraining) have not been explored enough.	O	O	Review	346
[line_break_token][line_break_token]Extra notes[line_break_token][line_break_token]page 2, second line: pretrainleverages (typo)[line_break_token]section 2.1: fix first sentence to make it an actual sentence.	B-Review	B-4	Review	346
[line_break_token]section 2.2: "we obtain three years of online new articles ... via a search engine" please be more specific about your methodology.	B-Review	B-6	Review	346
[line_break_token]section 2.2: You should double check more throughly that there is no data leakage in test.	B-Review	B-7	Review	346
There could be articles about the same exact events, years apart, for example.	I-Review	I-7	Review	346
I doubt that this would be a big effect, but there are easily ways to find highly similar articles between the pretraining data and test data to make sure.	I-Review	I-7	Review	346
[line_break_token]section 2.2: "Next we conduct following data cleaning" fix (typo?).	B-Review	B-8	Review	346
Also that sentence probably belongs to the next paragraph.	I-Review	I-8	Review	346
[line_break_token]section 2.2: Why did you pick the values that you did for the preprocessing heuristics (such as between 10-150 words, 150-1200 words, 3 sentences and not 2 or 1 or 4, the ratio 0.65, etc.)?	B-Review	B-9	Review	346
Were other values tried?	I-Review	I-9	Review	346
[line_break_token]section 2.2: You mention you end up with 21.4M articles.	B-Review	B-10	Review	346
How many were there to start with?	I-Review	I-10	Review	346
What's the filtering ratio?	I-Review	I-10	Review	346
[line_break_token]section 2.2: You mention that you pick the model with the best ROUGE-L score on the validation set.	B-Review	B-11	Review	346
How many models were there?	I-Review	I-11	Review	346
What was different between them?	I-Review	I-11	Review	346
[line_break_token]section 2.2, OOV Problem: the information in this whole subsection would fit better in 2.1 where 'tokens' are left generic without specifying which type of token you're considering.	B-Review	B-12	Review	346
[line_break_token]Figure 1: I find the upper part of this figure very confusing.	B-Review	B-13	Review	346
Why are there arrows going from the encoder/decoder to a summary, to theme loss, to article and back to encoder/decoder?	I-Review	I-13	Review	346
It's important that the summary is never seen by the theme loss otherwise it's not unsupervised anymore, and I also don't see why the arrow would go through article *after* theme loss.	I-Review	I-13	Review	346
I assume there must have been a mistake, please fix.	I-Review	I-13	Review	346
[line_break_token]section 2.4: "the sequence is slightly shuffled by applying a permutation /sigma such that ..." The formula given here tells me that all token indices are shuffled with another token within a window k. That seems like a lot of moving around, and also depending on the implementation a token from the beginning could possibly end up at the very tail of the sentence by being picked iteratively again and again, thus falling outside the permutation distance k. Please provide more details on how this is done and a justification for why it was decided to do it this way.	B-Review	B-14	Review	346
[line_break_token]Section 3.1: I'd like to know how long (preferably number of words, or at least number of wordpiece tokens) the summaries generated are.	B-Review	B-15	Review	346
What determines how long they are, is it a fixed size, or the model decides to stop on his own (or when hitting some limit), or something else?	I-Review	I-15	Review	346
[line_break_token]section 4.2: Do you have any idea why your unsupervised approach yields more novel n-grams than a the supervised model you compare against?	B-Review	B-5	Review	346
This can be good as much as it can be bad, in that it could be going off-track.	I-Review	I-5	Review	346
Yes humans have high novelty, but high novelty in itself isn't necessarily good.	I-Review	I-5	Review	346
I don't find the argument that have more novel ngrams is intrinsically, necessarily good, compelling.	I-Review	I-5	Review	346
If I'm wrong, then it would be nice to have better explanation in the paper.	I-Review	I-5	Review	346
[line_break_token][line_break_token][line_break_token]	O	O	Review	346
egarding the extra notes (with the same order as in ‚ÄúExtra notes‚Äù):[line_break_token][line_break_token](1) (2) Sorry about the typos.	B-Reply	B-4	Reply	346
We have fixed them.	I-Reply	I-4	Reply	346
[line_break_token](3) The search engine indexes major online news domain, for instance, New York Times and Bloomberg.	B-Reply	B-6	Reply	346
Then we collect the parsed articles within the 2016-2019 time range as the raw data.	I-Reply	I-6	Reply	346
[line_break_token](4)  We understand your concern about data leakage.	B-Reply	B-7	Reply	346
We went through the three test sets and did not find significantly overlapped articles as in the pretraining.	I-Reply	I-7	Reply	346
[line_break_token](5) Thanks for pointing it out.	B-Reply	B-8	Reply	346
We have revised it.	I-Reply	I-8	Reply	346
[line_break_token](6) Some explanations for the heuristic values selections:[line_break_token][line_break_token]150 and 1,200 words: Articles with very long content are filtered them mainly to reduce memory consumption.	B-Reply	B-9	Reply	346
Short articles are filtered since the information might be too condensed and not suitable for summarization pretraining.	I-Reply	I-9	Reply	346
[line_break_token][line_break_token]10 and 150 words: Some leading sentences are extremely short, e.g. one or two words phrases.	I-Reply	I-9	Reply	346
Those are filtered since they have too little information to be reasonable summaries.	I-Reply	I-9	Reply	346
Longer leading sentences are removed to reduce the pretraining time.	I-Reply	I-9	Reply	346
[line_break_token][line_break_token]0.65: The overlap ratio is an indicator of the amount of information that the leading sentences maintain.	I-Reply	I-9	Reply	346
For instance,  in CNN/DM dataset, the median of the overlapping ratio of non-stopping words between golden summary and the article is 0.87, and the ratio between the first 3 sentences and the rest of the article is 0.77 (median).	I-Reply	I-9	Reply	346
Setting the number at 0.65 makes the final training set size fit with the available computation resources and ensures that the leading sentences contain enough information.	I-Reply	I-9	Reply	346
[line_break_token][line_break_token]We mean to have demanding filtering criteria since we want high-quality pretraining data.	I-Reply	I-9	Reply	346
We didn‚Äôt try other settings since pretraining is a time-consuming process.	I-Reply	I-9	Reply	346
[line_break_token][line_break_token](7) We start with about 407 million articles.	B-Reply	B-10	Reply	346
The filtering ratio is about 95%.	I-Reply	I-10	Reply	346
We‚Äôve also added this information to the paper.	I-Reply	I-10	Reply	346
[line_break_token][line_break_token](8) We train one model for 10 epochs.	B-Reply	B-11	Reply	346
After each epoch, the model is evaluated on validation data.	I-Reply	I-11	Reply	346
We pick the check points with the highest ROUGE L.[line_break_token][line_break_token](9) About OOV.	B-Reply	B-12	Reply	346
It is a good idea.	I-Reply	I-12	Reply	346
We have edited and moved the paragraph to section 2.1[line_break_token][line_break_token](10)  About Figure 1.	B-Reply	B-13	Reply	346
Sorry about the confusion.	I-Reply	I-13	Reply	346
The ‚Äúsummary‚Äù refers to the generated summary from the transformer encoders/decoders, not the groundtruths summaries.	I-Reply	I-13	Reply	346
The process follows that the article is input to the transformer encoder/decoders and a summary is generated.	I-Reply	I-13	Reply	346
Then we compute the theme loss using the generated summary and the article.	I-Reply	I-13	Reply	346
We‚Äôve changed the text label ‚Äúsummary‚Äù in figure to ‚Äúgenerated summary‚Äù to avoid the confusion.	I-Reply	I-13	Reply	346
[line_break_token][line_break_token](11) About sequence shuffling.	B-Reply	B-14	Reply	346
Here is how we generate the permutations (the variable perm) of the indices using numpy.	I-Reply	I-14	Reply	346
Assume the length of the sequence is L, and the window size is k.[line_break_token]ids = np.arange(L)[line_break_token]noise =  np.random.uniform(0, k, size = L)[line_break_token]tmp = ids + noise[line_break_token]perm = tmp.argsort()[line_break_token]For tokens in the beginning, e.g. the first token, since there are at most k -1 elements smaller than tmp[0] in tmp, so the first token is at most shuffled to the kth position.	I-Reply	I-14	Reply	346
[line_break_token][line_break_token]The motivation of shuffling is as follows.	I-Reply	I-14	Reply	346
The information is to extract and summarize is scattered across an article.	I-Reply	I-14	Reply	346
By applying this shuffling noise, we want our model to learn to recognize and reorganize the information.	I-Reply	I-14	Reply	346
[line_break_token][line_break_token](12) The generation has a hard limit, which is decided on the validation dataset.	B-Reply	B-15	Reply	346
For instance, the maximum generation length for CNN/DM dataset is 175.	I-Reply	I-15	Reply	346
Also, in beam search, if the generated token is &lt;EOS&gt;, i.e. the end of sentence, then the generation is terminated immediately for the current sequence.	O	O	Reply	346
[line_break_token][line_break_token](13) Since TED is an abstractive model, this experiment is to show that TED has the ability to summarize using words/phrases not in the original article, which is typical in human-edited summaries.	B-Reply	B-5	Reply	346
Explanations why TED has more novel grams could be TED has seen more data during the pretraining phase than PGNet (which is only trained using in-domain data).	I-Reply	I-5	Reply	346
Also PGNet uses RNN while TED leverages transformer.	I-Reply	I-5	Reply	346
The more powerful modeling ability of transformer can also help.	I-Reply	I-5	Reply	346
Also the major evaluation metrics is the ROUGE, on which TED shows competitive performances	I-Reply	I-5	Reply	346

-- Paper summary --[line_break_token][line_break_token]The primary goal of this paper is to investigate the suitability of BNNs for carrying out post-calibration on trained deep learning models.	O	O	Review	1223
The results are compared to equivalent models calibrated using temperature scaling, and the pr	O	O	Review	1223
I thank the authors for their detailed response to all reviewer comments and providing additional explanations about their method.	O	O	Reply	1223
Unfortunately, I tend to agree with other reviewers that the contribution isn‚Äôt significant enough in isolation, and requires a broader and more extensive experimental evaluation in order to make up for the lack of theoretical innovation.	O	O	Reply	1223
[line_break_token]Consequently, my score remains unchanged.	O	O	Reply	1223

The paper proposed a RNN with skip-connection (external memory) to past hidden states, this is a slightly different version of the TARDIS network.	O	O	Review	1104
The authors experimented on PTB and a temporal action detection method.	O	O	Review	1104
[line_break_token][line_break_token]Novelty:[line_break_token][line_break_token]I dont see a lot of novelty to the method.	B-Review	B-1	Review	1104
The authors proposed a method very similar to TARDIS, the difference seems to be that MMARNN does not use extra usage vectors for reading from previous memory, but this is not a fundamental difference between MMARNN and Tardis.	I-Review	I-1	Review	1104
[line_break_token][line_break_token]Shortcomings of the paper:[line_break_token][line_break_token]1.	O	O	Review	1104
The experiments seem rather weak.	B-Review	B-2	Review	1104
The authors experimented on PTB and temporal action detection method.	I-Review	I-2	Review	1104
It is not clear why authors experimented with PTB, this is not a task with long-term dependencies, I do not see how this task (compared to many other tasks) can benefit from using external memory (especially when only 1 past hidden state is used[line_break_token][line_break_token]2.	O	O	Review	1104
The model uses a single past hidden state, it is not clear to me why this is better than using  a weighted sum of a few past hidden states, as many tasks requires long-term dependencies from multiple steps in the past.	B-Review	B-3	Review	1104
The authors should cite "Sparse attentive backtracking" (<a href="https://arxiv.org/abs/1809.03702)" target="_blank" rel="nofollow">https://arxiv.org/abs/1809.03702)</a> at NIPS 2018.	O	O	Review	1104
SAB is very related in that it also propagate gradients to a few hidden states in the memory.	B-Review	B-3	Review	1104
The difference is that SAB used a few hidden states from the past/ memory instead of one; another difference is that it propagates gradients locally to the selected hidden states/ memory slots.	I-Review	I-3	Review	1104
[line_break_token][line_break_token]3.	O	O	Review	1104
The paper only demonstrated experimental results on PTB and temporal action prediction.	B-Review	B-4	Review	1104
I think it would make the paper a lot stronger if the authors experimented with a variety of  different tasks.	I-Review	I-4	Review	1104
Tasks that requires long term dependencies can really demonstrate the strength of the model (copy and adding tasks).	I-Review	I-4	Review	1104
[line_break_token][line_break_token]4.	O	O	Review	1104
If the authors could run the model on copy and adding tasks, I would be curious to see if the model is picking the "correct" timestep in the memory / past.	B-Review	B-5	Review	1104
[line_break_token][line_break_token]post rebuttal: I feel that the authors have addressed some of my concerns, in particular, in terms of additional experimental results.	O	O	Review	1104
I have raised the score to reflect this changes.	O	O	Review	1104
[line_break_token]	O	O	Review	1104
Thank you for your valuable comment.	O	O	Reply	1104
We apologize for not clearly stating our difference against TARDIS and causing some misunderstanding regarding the novelty.	O	O	Reply	1104
We have accordingly revised our paper and can address your concerns as follows:[line_break_token][line_break_token]Q1:Novelty:I don't see a lot of novelty to the method.	O	O	Reply	1104
The authors proposed a method very similar to TARDIS, the difference seems to be that MMARNN does not use extra usage vectors for reading from previous memory, but this is not a fundamental difference between MARNN and Tardis.	O	O	Reply	1104
[line_break_token][line_break_token]We have discussed 5 important differences regarding the cell computation and addressing mechanism , supported by experimental evidences we added.	B-Reply	B-1	Reply	1104
Please refer to appendix B for a thorough comparison.	I-Reply	I-1	Reply	1104
[line_break_token][line_break_token]Q2: The experiments seem rather weak.	O	O	Reply	1104
The authors experimented on PTB and temporal action detection method.	O	O	Reply	1104
It is not clear why authors experimented with PTB, this is not a task with long-term dependencies, I do not see how this task (compared to many other tasks) can benefit from using external memory (especially when only 1 past hidden state is used.	O	O	Reply	1104
[line_break_token][line_break_token]We apologize for not clearly stating the motivation of our dataset choice of PTB and THUMOS 14.	B-Reply	B-2	Reply	1104
As we state in the introduction, we aim at building a bridge between simple RNN and complex memory models.	I-Reply	I-2	Reply	1104
We primarily intend to focus on augmenting RNN's performance on real-world tasks with a light-weight external memory, but not focus on coming up with more functional and complex memory mechanism.	I-Reply	I-2	Reply	1104
 We choose PTB and THUMOS 14 tasks  because they are real-world tasks where we can examine if our memory network can be helpful.	I-Reply	I-2	Reply	1104
 In our network, each r_t , although only 1 past hidden state, is a summary of historical hidden states with skip connection selected by auto-addressing mechanism.	I-Reply	I-2	Reply	1104
The ARMIN(renamed from MARNN) cell learns to recurrently integrate the summary of historical information from r_t into h_t at every time-step, which favors a paradigm of deep transition, as is shown by the success of  deep-transition RNNs on PTB task.	I-Reply	I-2	Reply	1104
 We believe this  can explain why we choose PTB and why the ARMIN success on PTB.	I-Reply	I-2	Reply	1104
[line_break_token] [line_break_token]Q3: The model uses a single past hidden state, it is not clear to me why this is better than using  a weighted sum of a few past hidden states, as many tasks requires long-term dependencies from multiple steps in the past.	O	O	Reply	1104
The authors should cite "Sparse attentive backtracking" (<a href="https://arxiv.org/abs/1809.03702)" target="_blank" rel="nofollow">https://arxiv.org/abs/1809.03702)</a> at NIPS 2018.	O	O	Reply	1104
SAB is very related in that it also propagate gradients to a few hidden states in the memory.	O	O	Reply	1104
The difference is that SAB used a few hidden states from the past/ memory instead of one; another difference is that it propagates gradients locally to the selected hidden states/ memory slots.	O	O	Reply	1104
[line_break_token][line_break_token]Thank you for pointing out this paper, and we have cited and introduced the SAB in our paper.	B-Reply	B-3	Reply	1104
As we state in Q1, each r_t is a summary of historical hidden states with skip connection selected by auto-addressing mechanism(we train the selecting process by backpropagation), so there is no fundamental difference from using  a weighted sum of a few past hidden states.	I-Reply	I-3	Reply	1104
 Another reason is that the gumbel-softmax can only sample 1-hot vector, so we think a more fundamental comparison between ARMIN and SAB should be : is the 1-hot sampling of gumbel-softmax better or multiple selecting of ReLU and softmax addressing mechanism in SAB is better?	I-Reply	I-3	Reply	1104
Due to time constraints, we leave this for future work.	I-Reply	I-3	Reply	1104
[line_break_token][line_break_token]Q3&4.	O	O	Reply	1104
The paper only demonstrated experimental results on PTB and temporal action prediction.	O	O	Reply	1104
I think it would make the paper a lot stronger if the authors experimented with a variety of  different tasks.	O	O	Reply	1104
Tasks that requires long term dependencies can really demonstrate the strength of the model (copy and adding tasks).	O	O	Reply	1104
If the authors could run the model on copy and adding tasks, I would be curious to see if the model is picking the "correct" timestep in the memory / past.	O	O	Reply	1104
[line_break_token][line_break_token]We have added a set of algorithmic tasks introduced by the NTM paper, including copy, repeat copy, associative recall and priority sort.	B-Reply	B-4	Reply	1104
We think these tasks do require exact long-term dependency, and we demonstrate the efficiency of our network on these tasks.	I-Reply	I-4	Reply	1104
Specifically, our network can converge 3~4 time faster in terms wall clock time than NTM on most of the tasks.	I-Reply	I-4	Reply	1104
We also adds enwik8 char-level lm tasks.	I-Reply	I-4	Reply	1104
We are currently doing experiment on pMNIST, but can't report in time as the training is very slow.	I-Reply	I-4	Reply	1104
We will report the results in later revision of our paper.	I-Reply	I-4	Reply	1104
[line_break_token][line_break_token]We hope these answers can address your concerns, thanks!	O	O	Reply	1104
[line_break_token]	O	O	Reply	1104

The authors propose Graph VRNN.	O	O	Review	521
The proposed method models the interaction of multiple agents by deploying a VRNN for each agent.	O	O	Review	521
The interaction among the agents is modeled by the graph interaction update on the hidden states of the VRNNs.	O	O	Review	521
The model predicts the true state (e.g., location) of the agent via supervised auto-regressive learning.	O	O	Review	521
The proposed model can improve this estimation from partially-observed visual observations.	O	O	Review	521
In the experiment, the authors apply the proposed method to Basketball and Soccer data to model the positions of the players.	O	O	Review	521
[line_break_token][line_break_token]The paper is clearly written.	O	O	Review	521
However, Section 3.2 needs to be elaborated more because using graph interaction update in VRNN is one of the main contributions.	O	O	Review	521
[line_break_token][line_break_token]I see two main weaknesses.	O	O	Review	521
The first is that the states are learned by supervised learning where obtaining the state label (i.e., the agent locations) is very expensive.	B-Review	B-1	Review	521
Indeed, the authors had to develop their own soccer game to obtain these labels.	I-Review	I-1	Review	521
The second weakness is the weak/inconsistent experiment results.	B-Review	B-2	Review	521
It seems not clear whether having the graph structure or stochastic modeling is really helping or not.	I-Review	I-2	Review	521
For example, for basketball experiment, Graph-RNN works poorly.	I-Review	I-2	Review	521
And, for soccer, Graph-VRNN works just as good as Graph-RNN.	I-Review	I-2	Review	521
The authors explained that this is due to the simplicity of the player behavior (not much stochastic), but the result in Table 2 shows good performance for Graph-VRNN for future prediction task.	I-Review	I-2	Review	521
All these make it difficult to buy the claimed argument.	I-Review	I-2	Review	521
It is also a limitation that the model requires to know and fix the number of agents.	I-Review	I-2	Review	521
[line_break_token][line_break_token]As minor comments, [line_break_token][line_break_token]- in Table 1.	B-Review	B-3	Review	521
Graph-RNN works better for soccer t=4, but not indicated in bold.	I-Review	I-3	Review	521
[line_break_token]- Having a single RNN baseline will be helpful to compare with Graph-RNN.	B-Review	B-4	Review	521
[line_break_token]- It is confusing to call s_t a belief state because it is observed not latent.	B-Review	B-5	Review	521
[line_break_token]- In the qualitative results, I think it can be compared to the heatmap of true distribution.	B-Review	B-6	Review	521
[line_break_token][line_break_token]I think the following papers needs to be discussed as related works.	B-Review	B-7	Review	521
[line_break_token]- <a href="https://arxiv.org/pdf/1806.01242.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1806.01242.pdf</a> [line_break_token]- <a href="https://arxiv.org/pdf/1802.03006.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.03006.pdf</a>[line_break_token][line_break_token]	O	O	Review	521
Thank you for your detailed feedback!	O	O	Reply	521
We have uploaded a revision to address your concerns:[line_break_token][line_break_token](1) Weak/inconsistent results:[line_break_token]We found that joint training of visual encoder and (V)RNN/Graph-(V)RNN lead to suboptimal performance for all methods, which has been addressed by our modified visual encoder and pre-training mechanism.	B-Reply	B-2	Reply	521
We can see from Table 1, 2 and 3 that graph structure consistently helps for both datasets and both tasks.	I-Reply	I-2	Reply	521
We also observe that stochastic modeling is more useful for Graph-RNN than vanilla RNN.	I-Reply	I-2	Reply	521
[line_break_token][line_break_token](2) Missing related work:[line_break_token]We have added the references in the related work section.	B-Reply	B-7	Reply	521
[line_break_token][line_break_token](3) RNN baseline:[line_break_token]We have added this baseline, we find that Graph-RNN outperforms single RNN in both current state estimation and future state prediction tasks.	B-Reply	B-4	Reply	521
[line_break_token][line_break_token](4) Comparison with true distribution:[line_break_token]This is a great idea.	B-Reply	B-6	Reply	521
We are looking into the possibility to conduct such comparison for soccer world.	I-Reply	I-6	Reply	521
Unfortunately we cannot do it for basketball since the true distribution is unknown	I-Reply	I-6	Reply	521

Apologies for the late review.	O	O	Review	640
[line_break_token][line_break_token]This submission proposes method for class-conditional generative image modeling using auxiliary classifiers.	O	O	Review	640
Compared to normal GANs the generator also receives a randomly sampled class label c from the class distribution.	O	O	Review	640
The discriminator has two outputs and two corresponding objectives: determine whether a sample is real or generated, and independently to predict the (real or sampled) class label corresponding to the sample.	O	O	Review	640
[line_break_token][line_break_token]Figure 2.	O	O	Review	640
nicely illustrates related methods - this particular method bears similarities to InfoGANs and Semi-supervised GANs.	O	O	Review	640
Compared to infogans, this method also encourages correspondence between the latent c and the real class labels for the real examples (whereas infogans are presented as fully unsupervised).	O	O	Review	640
[line_break_token][line_break_token]The authors attempt at evaluating the method quantitatively by looking at the discriminability and diversity of samples.	O	O	Review	640
It is found - not surprisingly - that higher resolution improves discriminability (because more information is present).	O	O	Review	640
[line_break_token][line_break_token]Discriminability: Figure 3 doesn‚Äôt have legends so it is a bit hard to understand what is going on.	O	O	Review	640
Furthermore, my understanding is that when evaluating discriminability the authors downsample and then bicubically upsample the image, which is much more like a blurring, very different from retraining all the models to work on low resolution in the first place.	O	O	Review	640
[line_break_token][line_break_token]Diversity: The authors try to quantitatively evaluate diversity of samples by measuring the average MS-SSIM between randomly selected pairs of points within each class.	B-Review	B-1	Review	640
I think this method is significantly flawed and limited, for reasons mentioned in (Theis et al, 2015, A note on the evaluation‚Ä¶).	I-Review	I-1	Review	640
In its behaviour, MS-SSIM is not that dissimilar from Euclidean distance - although it is nonlinear and is bounded between -1 and 1.	I-Review	I-1	Review	640
Evaluating diversity/entropy of samples in high dimensions is very hard, especially if the distributions involved are non-trivial for example concentrated around manifolds.	B-Review	B-2	Review	640
Consider for example a generative model which randomly samples just two images.	I-Review	I-2	Review	640
Assuming that the MSSSIM between these two images is -1, this generative model can easily achieve an average MSSSIM score of 0, implying a conclusion that this model has more diversity than the training data itself.	I-Review	I-2	Review	640
Conversely, SSIM is designed not to be sensitive to contrast and average pixel intensity, so if a model is diverse in this sense, that will be ignored by this measure.	B-Review	B-3	Review	640
[line_break_token][line_break_token]Overall, the paper proposes a new way to incorporate class labels into training GAN-type models.	O	O	Review	640
As far as I know the particular algorithm is novel, but I consider it incremental compared to what has been done before.	O	O	Review	640
I think the proposed evaluation metrics are flawed, especially when evaluating the diversity of the samples for the aforementioned reasons.	O	O	Review	640
Thank you for the review.	O	O	Reply	640
We have used ">" for quotes in the below response.	O	O	Reply	640
[line_break_token][line_break_token]As mentioned in the global response, we believe that the review misstates several key points in our paper.	O	O	Reply	640
 We have revised our paper for clarity and we respond to each point in detail below.	O	O	Reply	640
[line_break_token][line_break_token]======================[line_break_token]VARIABILITY AND MS-SSIM[line_break_token]======================[line_break_token][line_break_token]1. ‚	O	O	Reply	640
ÄúThe authors try to quantitatively evaluate diversity of samples by measuring the average MS-SSIM between randomly selected pairs of points within each class.	O	O	Reply	640
I think this method is significantly flawed and limited, for reasons mentioned in (Theis et al, 2015, A note on the evaluation‚Ä¶).	O	O	Reply	640
In its behaviour, MS-SSIM is not that dissimilar from Euclidean distance - although it is nonlinear and is bounded between -1 and 1.‚Äù[line_break_token][line_break_token]The main claim of Theis et al (2015) is that log-likelihood might not correspond to sample quality in a generative model.	B-Reply	B-1	Reply	640
Furthermore, training a model based on one objective will not guarantee good performance under another objective.	I-Reply	I-1	Reply	640
We view these points as orthogonal to our evaluation framework.	I-Reply	I-1	Reply	640
If the reviewer views this differently, we would be interested to hear their perspective.	I-Reply	I-1	Reply	640
That said, Theis et al (2015) provide an explicit motivation for us to build an evaluation method that is independent of the training objective.	I-Reply	I-1	Reply	640
[line_break_token][line_break_token]2.	O	O	Reply	640
In regards to the statement that ‚ÄòMS-SSIM is not that dissimilar from Euclidean distance‚Äô, we strongly disagree.	O	O	Reply	640
We believe that this statement is not supported by the literature.	O	O	Reply	640
[line_break_token][line_break_token]To start with, SSIM is a highly nonlinear metric that has been constructed to reflect human perceptual judgements [*].	O	O	Reply	640
The original SSIM paper as well as follow up works on MS-SSIM have demonstrated that SSIM-based metrics provide substantially improved quantitative estimates of human perceptual judgements compared to simple Euclidean distance measures (and many other quantitative measures of perceptual similarity) [1, 2, 3; and references therein].[line_break_token][line_break_token]A simple intuition for why SSIM is perceptually superior to Euclidean distance can be gained through looking at examples.	O	O	Reply	640
The SSIM web page (<a href="http://www.cns.nyu.edu/~lcv/ssim/" target="_blank" rel="nofollow">http://www.cns.nyu.edu/~lcv/ssim/</a> ) shows that images which are drastically different perceptually can have the same MSE and quite different SSIM scores.	O	O	Reply	640
[line_break_token][line_break_token][1] Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "	O	O	Reply	640
Multiscale structural similarity for image quality assessment."	O	O	Reply	640
[line_break_token][2] Z. Wang, A. C. Bovik, H. R. Sheikh and E. P. Simoncelli, "Image quality assessment: From error visibility to structural similarity"[line_break_token][3] Kede Ma, Qingbo Wu, Zhou Wang, Zhengfang Duanmu, Hongwei Yong, Hongliang Li, and Lei Zhang.	O	O	Reply	640
Group mad competition - a new methodology to compare objective image quality models.	O	O	Reply	640
[line_break_token][*] Note that our MS-SSIM implementation ranges from [0, 1] and not from [-1, 1]. All values on our graphs should be interpreted accordingly.	O	O	Reply	640
[line_break_token] [line_break_token]3. ‚	O	O	Reply	640
ÄúEvaluating diversity/entropy of samples in high dimensions is very hard, especially if the distributions involved are non-trivial for example concentrated around manifolds.	O	O	Reply	640
Consider for example a generative model which randomly samples just two images.	O	O	Reply	640
Assuming that the MSSSIM between these two images is -1, this generative model can easily achieve an average MSSSIM score of 0, implying a conclusion that this model has more diversity than the training data itself.	O	O	Reply	640
‚Äù[line_break_token][line_break_token]We claim that this example is seriously flawed, for the following reasons:[line_break_token][line_break_token]a. The range of MS-SSIM is [0, 1] (see above), so the average would be 0.5, which corresponds to half as much diversity as in the least diverse ImageNet class.	B-Reply	B-2	Reply	640
[line_break_token]b. This type of memorization would manifest as high variance of the mean MS-SSIM, but we report lower variance for samples than for training data (In other words, we explicitly account for this in the metric itself).	I-Reply	I-2	Reply	640
One could also compute higher moments or look at a histogram of pairwise MS-SSIM values, etc.	I-Reply	I-2	Reply	640
[line_break_token]c. We have also ruled out memorization explicitly by examining both latent space interpolations and nearest neighbors (both by L1 and MS-SSIM).	I-Reply	I-2	Reply	640
[line_break_token]d. We have provided 10,000 sample images, which do not show this type of memorization.	I-Reply	I-2	Reply	640
[line_break_token]e. It‚Äôs not even clear how well other existing methods of measuring diversity would perform in this case.	I-Reply	I-2	Reply	640
[line_break_token][line_break_token]4.	O	O	Reply	640
The reviewer suggests that in an ideal world we would compute the entropy of the generator distribution.	O	O	Reply	640
We argue that -- even if this were feasible -- we would still want to use perceptually calibrated metrics such as MS-SSIM.	O	O	Reply	640
Namely, we might want to ignore variability due to contrast or pixel intensity in favor of diversity of image content.	O	O	Reply	640
[line_break_token][line_break_token]5. ‚	O	O	Reply	640
ÄúConversely, SSIM is designed not to be sensitive to contrast and average pixel intensity, so if a model is diverse in this sense, that will be ignored by this measure.	O	O	Reply	640
‚Äù[line_break_token][line_break_token]We think that this is a good thing (see above).	O	O	Reply	640
[line_break_token]This is a sense in which Euclidean distance measures are very different than MS-SSIM, which directly contradicts the reviewer‚Äôs earlier point.	B-Reply	B-3	Reply	640
[line_break_token][line_break_token]=============[line_break_token]DISCRIMINABILITY[line_break_token]===============[line_break_token][line_break_token]1. ‚	O	O	Reply	640
ÄúDiscriminability: Figure 3 doesn‚Äôt have legends so it is a bit hard to understand what is going on.	O	O	Reply	640
Furthermore, my understanding is that when evaluating discriminability the authors downsample and then bicubically upsample the image, which is much more like a blurring, very different from retraining all the models to work on low resolution in the first place.	O	O	Reply	640
‚Äù[line_break_token][line_break_token]We feel that there was a large misunderstanding about our methods, so we present a quick summary of what was done to measure discriminability:[line_break_token][line_break_token]Our goal in this analysis was to measure how much of the output resolution is actually used by the image synthesis model.	O	O	Reply	640
In other words, does a 128x128 model just produce 32x32 images that are naively resized to 128x128?	O	O	Reply	640
This is the goal of the ‚Äòblurring‚Äô analysis and a question that has not been addressed in the literature.	O	O	Reply	640
If a sample were a naive resizing, a blurring would not reduce its discriminability.	O	O	Reply	640
[line_break_token][line_break_token]For each image analyzed, and for each resolution in [16, 32, 64, 128, 256], we iteratively resized the sample from its original size (using bilinear interpolation) to the resolution in question.	O	O	Reply	640
We then passed the image to a pretrained Inception model, which resizes all inputs to 299x299 before processing.	O	O	Reply	640
We took note of whether Inception correctly classified the input, and then we reported these results in the lower left hand corner of figure 3.	O	O	Reply	640
We have revised the manuscript to better describe these methods.	O	O	Reply	640
[line_break_token][line_break_token]2. ‚	O	O	Reply	640
ÄúIt is found - not surprisingly - that higher resolution improves discriminability (because more information is present).‚Äù[line_break_token][line_break_token]If the reviewer means that simply increasing the resolution should result in higher discriminability: We did explicitly test for this by upsampling images to confirm that simply upsampling would not increase discriminability.	O	O	Reply	640
See Figure 3 and Section 4.1.	O	O	Reply	640
[line_break_token][line_break_token]If the reviewer means that it is unsurprising that the model is successfully making use of its available output resolution: Naive resizing is not an idle concern.	O	O	Reply	640
We tested another model that actually failed to meaningfully increase discriminability score from 64x64 to 128x128.	O	O	Reply	640
[line_break_token][line_break_token]3."[the authors do not retrain] all the models to work on low resolution in the first place".	O	O	Reply	640
[line_break_token][line_break_token]We did retrain models at a lower output resolution.	O	O	Reply	640
We found that samples from these models are about half as discriminable at the 128x128 resolution as samples from the 128x128 model.	O	O	Reply	640
The results of this experiment correspond to the blue curve in the lower left of Figure 3.	O	O	Reply	640
This procedure was also described in section 4.1.	O	O	Reply	640

This paper studies the problem of visual representation learning from 2.5D video streams by exploring the 2D-3D geometry structures in the 3D visual world.	O	O	Review	571
Building upon the previous work GRNN (Tung et al 2019), this paper introduced a novel view-contrast objective applied to its internal 2D and 3D feature space.	O	O	Review	571
To facilitate the 3D view-contrast learning, this paper proposed a novel 2D-3D inverse graphics networks with a 2D-to-3D un-projection encoder, a 2D encoder, a 3D bottlenecked RNNs, an ego-motion stabilization module, and a 3D-to-2D projection module.	O	O	Review	571
Compared to previous work (Tung et al 2019), view-contrastive inverse graphics networks decode in the feature space rather than RGB space.	O	O	Review	571
Experimental evaluations are conducted using CARLA simulator (sim) and KITTI dataset (real).	O	O	Review	571
Results demonstrate the strengths of the proposed view-contrastive framework in feature learning, 3D moving object detection, and 3D motion estimation.	O	O	Review	571
[line_break_token][line_break_token]Overall, this paper studies an important problem in computer vision with a novel solution using unsupervised feature learning.	O	O	Review	571
While the technical novelty is clear, reviewer has several questions regarding the implementation and experimental details.	O	O	Review	571
[line_break_token][line_break_token](1) For 3D box detection on KITTI (see Table 1), the comparisons to state-of-the-art models are currently missing.	B-Review	B-1	Review	571
While the benefit of unsupervised feature learning has been demonstrated, it would be more convincing to compare against the following papers (at least with a paragraph of discussion).	I-Review	I-1	Review	571
[line_break_token][line_break_token](2) The 3D-to-2D projection module seems very expensive.	B-Review	B-2	Review	571
Can you possibly report the training and inference time compared to baselines?	I-Review	I-2	Review	571
Also, the design of the projection module is a bit counter-intuitive as it has 8x8 convolutions.	I-Review	I-2	Review	571
In principle, such projection should be learning-free or with only 1x1 convolutions (aggregation along depth channel).	I-Review	I-2	Review	571
It would be good to consider such ablation studies in the final version.	I-Review	I-2	Review	571
[line_break_token][line_break_token]-- Multi-view Supervision for Single-view Reconstruction via Differentiable Ray Consistency.	O	O	Review	571
Tulsiani et al In CVPR 2017.	O	O	Review	571
[line_break_token]-- Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision.	O	O	Review	571
Yan et al In NIPS 2016.	O	O	Review	571
[line_break_token]-- MarrNet: 3D Shape Reconstruction via 2.5D Sketches.	O	O	Review	571
Wu et al In NIPS 2017.	O	O	Review	571
[line_break_token][line_break_token](3) It seems that the proposed method assumes slow moving background across consecutive frames.	B-Review	B-3	Review	571
In principle, the view-contrastive objective should mask out new pixels in frame T+1.	I-Review	I-3	Review	571
Also, because the view-contrastive loss is applied at feature-level, reviewer would like to know performance on detecting small objects.	I-Review	I-3	Review	571
[line_break_token][line_break_token](4) As the latent map update module uses an RNN, it would be good to consider consistency beyond 2 frames (given mask is applied to view-contrastive objective).	B-Review	B-4	Review	571
Curriculum learning could be helpful for further improvements.	I-Review	I-4	Review	571
[line_break_token][line_break_token]-- Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis.	O	O	Review	571
Yang et al In NIPS 2015.	O	O	Review	571
[line_break_token][line_break_token](5) How does the proposed method perform when applied to indoor environments?	B-Review	B-5	Review	571
[line_break_token][line_break_token](6) Additional ablation study to consider: what if 2D/3D contrastive loss is turned off?	B-Review	B-6	Review	571
[line_break_token][line_break_token]	O	O	Review	571
ear reviewer,[line_break_token][line_break_token]Thank you for your detailed analysis.	O	O	Reply	571
[line_break_token][line_break_token]-- For 3D box detection on KITTI (see Table 1), the comparisons to state-of-the-art models are currently missing.	O	O	Reply	571
While the benefit of unsupervised feature learning has been demonstrated, it would be more convincing to compare against the following papers.	O	O	Reply	571
[line_break_token][line_break_token]The state-of-the-art for KITTI is at approximately 0.8 mAP at the 0.5 IOU threshold, which exceeds our 0.6 mAP score.	B-Reply	B-1	Reply	571
The main reason for this is resolution.	I-Reply	I-1	Reply	571
The SOTA models in KITTI achieve extremely high resolution outputs, by sacrificing the ‚Äúvertical‚Äù dimension of their latent representation: they build a ‚Äúbird‚Äôs eye view‚Äù of the scene, and do 2D convolutions in that space.	I-Reply	I-1	Reply	571
Our approach aims to be more general, and treats all three axes equally; we therefore use 3D convolutions throughout our model.	I-Reply	I-1	Reply	571
Nonetheless, we are actively trying to bridge this resolution gap, via efficient implementations of sparse 3D convolutions: by avoiding wasteful computation on the ‚Äúempty air‚Äù part of the scene, we are able to nearly double our resolution.	I-Reply	I-1	Reply	571
Competing with SOTA on KITTI also requires careful augmentation of the pointclouds, via object-centric and scene-centric jittering and non-rigid transforms, to expand the training distribution to cover test statistics.	I-Reply	I-1	Reply	571
We are doing this also, and hope to have results soon, but please note that higher resolution and augmented data lead to slower training, so it will take several days for each model to train.	I-Reply	I-1	Reply	571
With luck, we will add these results into the paper by Friday.	I-Reply	I-1	Reply	571
[line_break_token][line_break_token][line_break_token]-- The 3D-to-2D projection module seems very expensive.	O	O	Reply	571
Can you possibly report the training and inference time compared to baselines?	O	O	Reply	571
Also, the design of the projection module is a bit counter-intuitive as it has 8x8 convolutions.	O	O	Reply	571
In principle, such projection should be learning-free or with only 1x1 convolutions (aggregation along depth channel).	O	O	Reply	571
It would be good to consider such ablation studies in the final version.	O	O	Reply	571
[line_break_token][line_break_token]Thank you for writing this.	B-Reply	B-2	Reply	571
Our description should have been better.	I-Reply	I-2	Reply	571
Our 3D-to-2D architecture is actually quite cheap. (	I-Reply	I-2	Reply	571
There are no 8x8 convolutions.)	I-Reply	I-2	Reply	571
[line_break_token]- The module starts with a perspective transform, which puts viewing rays along the depth axis of a tensor.	I-Reply	I-2	Reply	571
[line_break_token]- Then there is a max pooling operation with a 1x8x1 kernel and 1x8x1 stride, where the 8 is along the depth axis; this quickly and coarsely aggregates along the ray axis, as you suggest.	I-Reply	I-2	Reply	571
[line_break_token]- Following this aggregation, there is a 3D convolution with kernel size 3x3x3.	I-Reply	I-2	Reply	571
[line_break_token]- Then there is a reshape, putting the depth dimension together with channels.	I-Reply	I-2	Reply	571
[line_break_token]- Finally there are two 2D convolution layers, with a 3x3 kernel then a 1x1 kernel.	I-Reply	I-2	Reply	571
[line_break_token]We have updated the text to clarify this.	I-Reply	I-2	Reply	571
[line_break_token][line_break_token]Regarding the related works you pointed out: Tulsiani et al does not actually have an image renderer: that work only has a 2D-to-3D mapping, and then uses losses to encourage the 3D representation to be consistent with the 2.5D data (RGB-D images).	I-Reply	I-2	Reply	571
Wu et al is similar to Tulsiani et al: they have no renderer and apply losses directly in 3D voxelspace, except they assume an orthographic camera instead of a perspective one.	I-Reply	I-2	Reply	571
Our work‚Äôs ‚Äúperspective transform‚Äù step is very similar to the first step in Yan et al except they follow this by a single depthwise maxpool and output the result; this has no capacity for occlusion-reasoning and cannot be effective when the scene includes a background.	I-Reply	I-2	Reply	571
The Yang et al model uses a 1D (vector) latent space uses fully-connected layers for the transformations; our model‚Äôs 3D latent space allows for explicit geometric transformations.	I-Reply	I-2	Reply	571
Another related work is DeepVoxels (Sitzmann et al), which has a softmax on the ray axis, followed by a dot product.	I-Reply	I-2	Reply	571
We tried this, and found it did not work better than our CNN-based renderer.	I-Reply	I-2	Reply	571
We will add this result into the paper, as you suggest.	I-Reply	I-2	Reply	571
[line_break_token][line_break_token][line_break_token]-- It seems that the proposed method assumes slow moving background across consecutive frames.	O	O	Reply	571
[line_break_token][line_break_token]This is a great observation.	B-Reply	B-3	Reply	571
We do not explicitly assume a slow-moving background, but the egomotion module (with its coarse-to-fine cross correlations) has a limited effective range.	I-Reply	I-3	Reply	571
In particular, we use 3 scales in this module (0.25, 0.5, 1.0), and the correlations have a maximum displacement of 3 voxels; this means a limit of approximately 5 meters displacement between timesteps.	I-Reply	I-3	Reply	571
The rotation limit is approximately 8 degrees.	I-Reply	I-3	Reply	571
We chose these limits based on the statistics of camera motion in the KITTI dataset.	I-Reply	I-3	Reply	571
You are right that if the camera motion becomes unexpectedly extreme at test time, we will not be able to ‚Äúcancel it out‚Äù as desired, since our egomotion estimation will fail.	I-Reply	I-3	Reply	571
[line_break_token] [line_break_token][line_break_token](We continue in the next comment, due to the OpenReview character count limit.	O	O	Reply	571

This paper proposes a method for generalized image recognition based on random forest, that use directly the features extracted by the backbone, that assign pseudo-labels to the data.	O	O	Review	253
The learning is performed with a triplet loss adapted for better generalization.	O	O	Review	253
[line_break_token]Decision: weak reject[line_break_token]Motivation: the method is incremental and presented in general in a clear way and easy to follow, the authors present a simple but interesting trick to make the triplet loss more effective on a random forest in the case of generalization to a new unlabeled dataset.	B-Review	B-8	Review	253
This method looks incremental to me because it is addressing the problem of pseudo-labelling for learning on a new dataset and instead of using confidence measures uses a random forest to assign labels.	I-Review	I-8	Review	253
[line_break_token]The experimental section of the paper is a bit confusing because is not clear if the results presented are with comparable network (e.g. ResNet18) like the cited state-of-the-art papers, from further readings I am confident the autors compared fairly with similar architectures.	B-Review	B-1	Review	253
Authors should perhaps stress they compare with state-of-the-art in fair condition to avoid confusion as in my case.	I-Review	I-1	Review	253
How much is the overhead of building the random forest for each iteration of the learning (algorithm 1), a more detailed analysis on this is useful for understanding the method.	B-Review	B-2	Review	253
Could this method be used to train a network from scratch on an unlabeled data or on data with noisy labels?	I-Review	I-2	Review	253
How did the authors choose the T decision trees, is there any ablation study, general practice or euristics behind the choice of 1,10,50?	B-Review	B-3	Review	253
The comparison with state-of-the-art Tab 3 and Tab 4 shows that for some datasets other techniques are better, did the authors draw some conclusions from that?	B-Review	B-7	Review	253
Comparing Tab 3 and 4 with Tab 5/6/7/8/9 looks like this method can work but only in the case of much bigger network like ResNet50 and DenseNet 161 which can limit its use for high resources (computing power) cases.	B-Review	B-4	Review	253
[line_break_token]Replicability: I think with improvements in the experimental section the method results can be replicated.	B-Review	B-6	Review	253
At the moment it lack many details like learning rates, epoch of training and other useful information that are useful.	I-Review	I-6	Review	253
[line_break_token]Minor: there are two lines out of the 9 page limit	B-Review	B-5	Review	253
e thank Reviewer 3 for the helpful comments.	O	O	Reply	253
We answer to the comments of Reviewer 3.	O	O	Reply	253
[line_break_token][line_break_token]1.	B-Reply	B-3	Reply	253
Backbone networks[line_break_token]We compare the proposed algorithm with the state-of-the-art methods using the same backbone network such as ResNet-18 (Table 3), AlexNet (Table 4), ResNet-50 (Table 5, 6, 8 and 9), ResNet-152 (Table 7) and DenseNet-161 (Table 9).	B-Reply	B-1	Reply	253
[line_break_token][line_break_token]In Table 9, we use two backbone networks (ResNet-50 and DenseNet-161) for comparisons.	I-Reply	I-1	Reply	253
Since pairwise confusion (PC) [1] report results from both backbone networks, we compare the proposed method with PC on both for fair comparisons.	I-Reply	I-1	Reply	253
[line_break_token][line_break_token]We also revised the paper to clarify the backbone networks on page 6 and abstract.	I-Reply	I-1	Reply	253
[line_break_token] [line_break_token][1] Abhimanyu Dubey, Otkrist Gupta, Pei Guo, Ramesh Raskar, Ryan Farrell, and Nikhil Naik.	O	O	Reply	253
Pairwise confusion for fine-grained visual classification.	O	O	Reply	253
In European Conference on Computer Vision, pp.	O	O	Reply	253
70‚Äì86, 2018.	O	O	Reply	253
[line_break_token][line_break_token]2.	B-Reply	B-4	Reply	253
Overhead of each iteration[line_break_token]We measured the overhead of training time for random forests.	B-Reply	B-2	Reply	253
[line_break_token][line_break_token]As stated in answer 3, we use 300 epochs and random forests are trained at every 3 epochs for reducing the overhead.	I-Reply	I-2	Reply	253
[line_break_token][line_break_token]The time for training a random forest is about 15 seconds (MIT Indoor dataset with ResNet-50), which results in only 15sec X 300 epochs / 3 = 25 minute overhead in the whole learning process.	I-Reply	I-2	Reply	253
[line_break_token][line_break_token]3.	B-Reply	B-4	Reply	253
The number of trees[line_break_token]We compare the performance of random forests constructed on canonical, strengthened, and generalized feature space with T=1,10 and 50 in Table 1.	B-Reply	B-3	Reply	253
As shown in [2] there is little change in performance above 64 trees for a random forest,  we measure the performance change from 1 to 50 in a way similar to [2]. Table 1 shows the ablation study of the performance with regard to the number of trees.	I-Reply	I-3	Reply	253
[line_break_token][line_break_token][2] Oshiro Thais Mayumi, Perez Pedro Santoro, Baranauskas Jos¬¥e Augusto, How many trees in a random forest?.	O	O	Reply	253
In International workshop on machine learning and data mining in pattern recognition, pp.	O	O	Reply	253
154‚Äì168, 2012[line_break_token][line_break_token]4.	O	O	Reply	253
Some results in Table 3 and 4[line_break_token]There are some cases that the proposed GCFN does not outperform the state-of-the-art methods.	B-Reply	B-7	Reply	253
However, the GCFN outperforms them in terms of average accuracy for each dataset, which shows the effectiveness of GCFN.	I-Reply	I-7	Reply	253
It is more important to analyze the overall average performance of all cases to validate the generalization ability rather than one or two cases.	I-Reply	I-7	Reply	253
[line_break_token][line_break_token]5.	B-Reply	B-4	Reply	253
Validation on small networks[line_break_token]We perform some additional experiments on the AlexNet [1] which is relatively small and fast networks compared to ResNet-50 and DenseNet-161.	I-Reply	I-4	Reply	253
[line_break_token][line_break_token]We compare the random forests on canonical features as the baseline with the proposed GCFN on the DTD, MIT Indoor and Scene-15 datasets.	I-Reply	I-4	Reply	253
[line_break_token][line_break_token]The results also confirm that GCFN also performs well with relatively small networks.	I-Reply	I-4	Reply	253
[line_break_token]                            DTD                      MIT Indoor                  Scene-15              [line_break_token]                  T=1   T=10  T= 50    T=1  T=10  T= 50       T=1   T=10  T= 50 [line_break_token]Base          44.9   60.4  62.8       39.9  59.2   62.0         79.9  88.5   88.9   [line_break_token]GCFN        55.0   63.1  64.2       51.6  62.1   63.1         84.7  88.7   89.5  [line_break_token][line_break_token][1] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.	O	O	Reply	253
Imagenet classification with deep convolutional neural networks.	O	O	Reply	253
In Neural Information Processing Systems, 2012[line_break_token][line_break_token]6.	O	O	Reply	253
Implementation details [line_break_token]We add the implementation details about the learning rate, batch size, number of epochs, and training process in Page 12 of the paper as below.	B-Reply	B-6	Reply	253
[line_break_token][line_break_token]We use 300 epochs with 5*10^(-3) learning rate, weigh decay with 9*10^(-4) for the network training.	I-Reply	I-6	Reply	253
Random forests are created at every 3 epochs to reduce the overhead.	I-Reply	I-6	Reply	253
Once we build a random forest, the neural networks are updated for 3 epochs based on the split result of the random forest.	I-Reply	I-6	Reply	253
The training time overhead due to the random forests is 15 seconds for MIT Indoor dataset with ResNet-50, which results in only 25 minute overhead in the whole learning process.	I-Reply	I-6	Reply	253
For the fast training, we use 50 trees with the split function of `F' for the network update.	I-Reply	I-6	Reply	253
[line_break_token][line_break_token]7.	O	O	Reply	253
Page limit  [line_break_token]We fix the page limit issue by moving some parts to the appendix.	B-Reply	B-5	Reply	253

This paper proposes generating feature representations for set elements using weighted multiset automata.	O	O	Review	20284
Experiments show that this leads to better generalization performance in some tasks.	O	O	Review	20284
[line_break_token][line_break_token]I am leaning to reject this paper.	O	O	Review	20284
The proposed algorithm for generating features seems relevant and correct, but there are shortcomings in the presentation and the experiments are not entirely convincing.	B-Review	B-4	Review	20284
[line_break_token][line_break_token]In particular, the paper begins by introducing weighted multiset automata quite clearly, but it fails to explain how exactly these automata would be used to generate set representations.	B-Review	B-1	Review	20284
I assumed that the set would be represented as the state of the automaton after processing a string (where each element of the set is a symbol from the alphabet in the string) but in section 4 the different states of the automaton while processing a string are used instead.	I-Review	I-1	Review	20284
If this paper proposes a new way of learning representations for sets, I would like to see a general recipe for the application of this idea.	I-Review	I-1	Review	20284
[line_break_token][line_break_token]Reading the paper it is not entirely clear what theoretical results are novel and which proofs are restatements of existing proofs.	B-Review	B-2	Review	20284
It would be useful to guide the reader a bit more clearly here.	I-Review	I-2	Review	20284
[line_break_token][line_break_token]The second statement in section 4.1 is not clear to me: In what sense is the diagonal with alternating complex conjugate entries fully general?	B-Review	B-3	Review	20284
[line_break_token][line_break_token]The experimental results are difficult to interpret.	B-Review	B-4	Review	20284
Since there are no confidence intervals it is impossible to draw conclusions from table 1.	I-Review	I-4	Review	20284
I am also not entirely convinced by figure 2.	B-Review	B-7	Review	20284
The "unit digit of a sum" task seems slightly artificially constructed to be suitable for a network which uses complex numbers.	I-Review	I-7	Review	20284
Although this is not a bad thing, it doesn't necessarily validate that complex weighted automata have better representational power.	I-Review	I-7	Review	20284
If that was the case, wouldn't we expect better results for other tasks that don't explicitly have a cyclic nature?	I-Review	I-7	Review	20284
[line_break_token][line_break_token]The main questions I would like to see answered (and adjusted in the paper) for me to accept this paper would be:[line_break_token][line_break_token]* What is the general recipe for applying this technique to get representations of a multiset?	B-Review	B-5	Review	20284
[line_break_token]* How do the experimental results validate the increased representational power of complex-weighted diagonal automata?	B-Review	B-6	Review	20284
hank you for taking the time to read and review our paper.	O	O	Reply	20284
 We appreciate your feedback and below address questions you expressed.	O	O	Reply	20284
[line_break_token][line_break_token]&gt; What is the general recipe for applying this technique to get representations of a multiset?	O	O	Reply	20284
[line_break_token][line_break_token]Sorry that this wasn't clear.	B-Reply	B-5	Reply	20284
The automaton is nondeterministic, so at each time step it could be in any state.	I-Reply	I-5	Reply	20284
The vector fw(w) of forward weights could be thought of as like a distribution over the state that the machine is in after reading w, except that the values don't have to be probabilities.	I-Reply	I-5	Reply	20284
This vector fw(w) is what we propose as the "general recipe" to represent multiset w.[line_break_token][line_break_token]&gt; It is not entirely clear what theoretical results are novel and which proofs are restatements of existing proofs.	O	O	Reply	20284
[line_break_token][line_break_token]Again, sorry for not making this clear.	B-Reply	B-2	Reply	20284
Proposition 1 and Lemma 4 are not novel.	I-Reply	I-2	Reply	20284
To our knowledge, Propositions 2 and 3 are novel, as are the results in the appendices.	I-Reply	I-2	Reply	20284
[line_break_token][line_break_token]&gt; In what sense is the diagonal with alternating complex conjugate entries fully general?	O	O	Reply	20284
[line_break_token][line_break_token]To be fully general, we should have put in front of each and in front of each; apologies for this error.	B-Reply	B-3	Reply	20284
With that correction in place, the form at the top of page 5 is general in the sense that any real-weighted multiset automaton is close to a complex-weighted diagonal automaton (Prop 3), and because the original automaton had real weights, the diagonal entries that are complex must come in conjugate pairs.	I-Reply	I-3	Reply	20284
Those that are real can be duplicated to form conjugate pairs.	I-Reply	I-3	Reply	20284
Thus, any real-weighted multiset automaton is close to one that can be put into the form shown.	I-Reply	I-3	Reply	20284
We will try to make this clearer in a future version of the paper.	I-Reply	I-3	Reply	20284
[line_break_token][line_break_token]&gt; Since there are no confidence intervals it is impossible to draw conclusions from table 1.	O	O	Reply	20284
[line_break_token][line_break_token]We've run bootstrap resampling to compare the other lines against the first line (the original position encodings).	B-Reply	B-4	Reply	20284
Roughly, significance is at about 0.4 BLEU.	I-Reply	I-4	Reply	20284
In the last line (learned per-position), all differences are significant except for Urdu-English.	I-Reply	I-4	Reply	20284
This confirms our conclusion that learned per-position encodings are worse, but the rest are all about the same.	I-Reply	I-4	Reply	20284
[line_break_token][line_break_token]&gt; The "units digit of a sum" task seems slightly artificially constructed to be suitable for a network which uses complex numbers.	O	O	Reply	20284
Although this is not a bad thing, it doesn't necessarily validate that complex weighted automata have better representational power.	O	O	Reply	20284
If that was the case, wouldn't we expect better results for other tasks that don't explicitly have a cyclic nature?	O	O	Reply	20284
[line_break_token][line_break_token]The sum task demonstrates that DeepSets and our method are able to outperform LSTM and GRU models on multiset structured input, specifically being able to generalize results to multisets which are larger than were seen at training time.	B-Reply	B-7	Reply	20284
 The units-digit-of-sum task is meant to be a simple extension of the sum task to demonstrate that our method can not only represent the same types of data as the DeepSets method, but also represent other behavior such as cycles.	I-Reply	I-7	Reply	20284
 We have not run other tasks which don't explicitly have a cyclic nature for which DeepSets obtains less than 100% accuracy	I-Reply	I-7	Reply	20284

This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty).	O	O	Review	188
The experiments are conducted in MuJoCo, with a set of experiments being from the state of the joints/links (5.2/5.3) and a set of experiments on the pixels (5.4).	O	O	Review	188
They exhibit transfer from arms with different number of links, and from a torque-driven arm to a tendon-driven arm.	O	O	Review	188
[line_break_token][line_break_token]One limitation of the paper is that the authors suppose that time alignment is trivial, because the tasks are all episodic and in the same domain.	B-Review	B-1	Review	188
Time alignment is one form of domain adaptation / transfer that is not dealt with in the paper, that could be dealt with through subsampling, dynamic time warping, or learning a matching function (e.g. neural network).	I-Review	I-1	Review	188
[line_break_token][line_break_token]General remarks: The approach is compared to CCA, which is a relevant baseline.	O	O	Review	188
However, as the paper is purely experimental, another baseline (worse than CCA) would be to just have the random projections for "f" and "g" (the embedding functions on the two domains), to check that the bad performance of the "no transfer" version of the model is due to over-specialisation of these embeddings.	B-Review	B-2	Review	188
I would also add (for information) that the problem of learning invariant feature spaces is also linked to metric learning (e.g. [Xing et al 2002]).	I-Review	I-2	Review	188
More generally, no parallel is drawn with multi-task learning in ML.	I-Review	I-2	Review	188
In the case of knowledge transfer (4.1.1), it may make sense to anneal \alpha.	I-Review	I-2	Review	188
[line_break_token][line_break_token]The experiments feel a bit rushed.	B-Review	B-3	Review	188
In particular, the performance of the baseline being always 0 (no transfer at all) is uninformative, at least a much bigger sample budget should be tested.	I-Review	I-3	Review	188
Also, why does Figure 7.b contain no "CCA" nor "direct mapping" results?	I-Review	I-3	Review	188
Another concern that I have with the experiments: (if/how) did the author control for the fact that the embeddings were trained with more iterations in the case of doing transfer?	I-Review	I-3	Review	188
[line_break_token][line_break_token]Overall, the study of transfer is most welcomed in RL.	O	O	Review	188
The experiments in this paper are interesting enough for publication, but the paper could have been more thorough.	O	O	Review	188
Thank you for your review.	O	O	Reply	188
We agree that assuming a trivial time alignment is somewhat unsatisfying, and to address this we have formulated an alternating optimization to learn the alignment jointly with the embeddings, described in Section 3.3.2.	B-Reply	B-1	Reply	188
The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space, as described in Section 3.3.2.	I-Reply	I-1	Reply	188
Results using this method can be found in Figure 5, Figure 7a.	I-Reply	I-1	Reply	188
Using this approach usually works better than just assuming timestep correspondences, or as well in the case of well aligned data.	I-Reply	I-1	Reply	188
[line_break_token][line_break_token]As per the suggestion of comparing with random projections, we have added a comparison using random projections as feature embeddings.	B-Reply	B-2	Reply	188
As shown in Figures 5 and 7a, this method achieves a low level of performance in between the CCA method and no transfer.	I-Reply	I-2	Reply	188
Also, as pointed out in the review we do indeed anneal \alpha over the course of learning in all our experiments.	I-Reply	I-2	Reply	188
[line_break_token][line_break_token]As shown in Table 1, we have run the ‚ÄúNo Transfer‚Äù method for 75 iterations (seeing 3 times more samples).	B-Reply	B-3	Reply	188
A likely reason the no transfer baseline doesn‚Äôt work even with this greater sample budget is that the exploration is insufficiently coherent for any reward to be obtained at all, leading to the behavior seen.	I-Reply	I-3	Reply	188
[line_break_token][line_break_token]Finally, we have added a connection to metric learning in the last paragraph of Section 2, as well as a paragraph on multitask learning (the third paragraph in Section 2).	I-Reply	I-3	Reply	188
[line_break_token][line_break_token]Figure 7b does not yet contain the comparisons with CCA and direct mapping because we have been adding these comparisons over the course of the response period.	I-Reply	I-3	Reply	188
This figure will contain all comparisons for the final version.	I-Reply	I-3	Reply	188
Thanks!	O	O	Reply	188

This paper proposes a method for link prediction on Knowledge Bases.	O	O	Review	451
The method contains 2 main innovations: (1) an iterative inference process that allows the model to refine its predictions and (2) a shared memory component.	O	O	Review	451
Thanks to these 2 elements, the model introduced in the paper achieved remarkable results on two benchmarks.	O	O	Review	451
[line_break_token][line_break_token][line_break_token]The paper is fairly written.	O	O	Review	451
The model is interesting and the experimental results are strikingly good.	O	O	Review	451
Still, I only rate for a weak accept for the following reasons.	O	O	Review	451
[line_break_token][line_break_token]* The main problem with this paper is that there is little explanation of how and why the two new elements aforementioned are leading to such better results.	B-Review	B-1	Review	451
For instance:[line_break_token]  - What are the performance without the shared memory?	I-Review	I-1	Review	451
And when its size is grown?	I-Review	I-1	Review	451
[line_break_token]  - How does the performance is impacted when one varies Tmax from 1 to 5 (which the chosen value for the experiments I assume)?	B-Review	B-2	Review	451
This gives an indications of how often the termination gate works.	I-Review	I-2	Review	451
[line_break_token]  - It would also be interesting to give the proportion of examples for which the inference is terminated before hitting Tmax.	B-Review	B-3	Review	451
[line_break_token]  - What is the proportion of examples for which the prediction changed along several inference iterations?	B-Review	B-4	Review	451
[line_break_token][line_break_token]* A value of \lambda set to 10 (Section 2) seems to indicate a low temperature for the softmax.	B-Review	B-5	Review	451
Is the attention finally attending mostly at a single cell?	I-Review	I-5	Review	451
How do the softmax activations change with the type of relationships?	I-Review	I-5	Review	451
the entity type?	I-Review	I-5	Review	451
[line_break_token][line_break_token]* FB15k and WN18 are quite old overused benchmarks now.	B-Review	B-6	Review	451
It would be interesting to test on larger conditions.	I-Review	I-6	Review	451
Thanks for your insightful review.	O	O	Reply	451
To address your comments, we added Table 2 and a corresponding paragraph to analyze the performance with different termination steps (T_max = 1, 2, 5, 8) and memory sizes (|M| = 32, 64, 128, 256, 4096).	B-Reply	B-2	Reply	451
In the T_max = 1 cases, it is the case where IRNs do not use the shared memory.	I-Reply	I-2	Reply	451
We found the number of times IRNs access the shared memory is critical for the performance, so IRNs cannot achieve the same level of performance without using shared memory.	I-Reply	I-2	Reply	451
[line_break_token]Regarding the attention over memory cells, we have found some interesting behaviors of the shared memory by counting the most active relations of each memory cell.	B-Reply	B-1	Reply	451
For example, in one particular memory cell, we observe its most active relations from a cluster around ‚Äúfamily/spouse based‚Äù relations.	I-Reply	I-1	Reply	451
We will update some findings in the discussion and we will test the current model on more challenge tasks, i.e., knowledge base QA, machine reading, and conversation bot in the future.	I-Reply	I-1	Reply	451

The paper claims to propose a computationally efficient algorithm for training deep CNNs by making assumptions about the distribution of data.	O	O	Review	1084
The authors argue that (i) they don't make very simplistic assumptions about the data generating distribution as some other papers do, and (ii) their algorithm resembles the actual methods that are used for training deep models and shows some surprising properties of SGD.	O	O	Review	1084
[line_break_token][line_break_token]Throughout the paper, the authors make a number of assumptions which seem arbitrary at times; not much justifications are provided.	B-Review	B-11	Review	1084
The authors claim that their assumptions are not as simplistic as assuming e.g., the inputs are sampled from Gaussian distribution.	I-Review	I-11	Review	1084
Unfortunately this is highly unclear: while the "assumptions" themselves are complex, the combination of those assumptions may make the problem solution trivial.	I-Review	I-11	Review	1084
While proving a lower bound to address this issue may be hard, at least the authors should try to illuminate more why the solution is not trivial (e.g., why a linear classifier doesn't work, etc.)	I-Review	I-11	Review	1084
[line_break_token][line_break_token]Despite the claims, I find the proposed algorithm very far from the usual SGD-based training methods; this is not a problem per se but I don't think that the result illuminates on the effectiveness of SGD (as the authors suggest).	B-Review	B-12	Review	1084
The proposed algorithm is a greedy layer-wise method that in each level does a clustering and also trains a "linear" CNN with SGD.	I-Review	I-12	Review	1084
So the hardness of end-to-end training of a deep network does not show up.	I-Review	I-12	Review	1084
Furthermore, it is not clear for training a linear CNN the SGD is even needed.	I-Review	I-12	Review	1084
[line_break_token][line_break_token]I suggest that the authors name each of the assumptions and clearly say which ones are assumed for which result.	O	O	Review	1084
Here are some of the assumptions that the authors talk about.	O	O	Review	1084
[line_break_token][line_break_token]1_ The data is generated by the following recursive procedure: First a small "high-level image" is generated from a distribution, G_0.	B-Review	B-1	Review	1084
The "pixels" of this high-level image are supposed to encode semantic classes, e.g., sky or ground.	I-Review	I-1	Review	1084
In the next step, each of these high-level pixels are turned into a small (lower-level) image.	I-Review	I-1	Review	1084
Therefore, we will have a more refined image after the second step. (	I-Review	I-1	Review	1084
each semantic class (e.g., sky) has a corresponding distribution that generates the smaller lower-level image (e.g., uniform over 4 possible types of skies)).	I-Review	I-1	Review	1084
This procedure continues recursively until we have the final image.	I-Review	I-1	Review	1084
[line_break_token][line_break_token]2_ G_0 is "linearly separable".	B-Review	B-2	Review	1084
[line_break_token][line_break_token]3_ Semantic classes defined in the model are different enough from each other[line_break_token][line_break_token]4_ {F_c} corresponding to semantic classes are linearly independent [line_break_token][line_break_token]5_ Patch Orthonormality (apparently not assumed everywhere) [line_break_token][line_break_token][line_break_token]it appears that if one assumes all of 1-5, then the problem becomes trivial (linearly separable).	B-Review	B-3	Review	1084
The authors then say that we don't want to make assumption 5 for this reason; still, the problem solution may be trivial (authors should at least intuitively justify why it isn't )[line_break_token][line_break_token]Here are some more uses of the word "assumption".	O	O	Review	1084
[line_break_token][line_break_token]6_ "For simplicity of analysis, we assume only the first layer of the network is trained".	B-Review	B-6	Review	1084
[line_break_token][line_break_token]7_ "We assume the algorithm [KMEANS++] returns a mapping [...] such that [...]" [line_break_token][line_break_token]The experiments do not seem conclusive.	B-Review	B-7	Review	1084
Only a few experiments have been done.	B-Review	B-8	Review	1084
I think the acquired results for CIFAR-10 are below the usual ones using CNNs, and the effects of various hyper-parameters may have interfered.	I-Review	I-8	Review	1084
[line_break_token][line_break_token]--[line_break_token]After reading the authors' response, I still think the way that the contributions are depicted (e.g., a justifying the effectiveness of SGD) are inaccurate/unsupported.	B-Review	B-9	Review	1084
[line_break_token][line_break_token]Furthermore, although the authors' suggest that they have tested a linear classifier and observed that the data is not linearly separable, more explanations/intuitions are needed about the assumptions that are made throughout the paper.	B-Review	B-10	Review	1084
Thank you for the response.	O	O	Reply	1084
[line_break_token]We will give here a few notes of clarification about the assumptions, and we can add these to the final revision of the paper.	O	O	Reply	1084
We hope that these comments provide the intuitions and explanations that are missing.	O	O	Reply	1084
[line_break_token][line_break_token]Assumption 1: The linear separability of the latent distribution captures the fact that the observed images are generated from a latent distribution that is "simple" to learn.	B-Reply	B-2	Reply	1084
[line_break_token][line_break_token]Assumption 2: We assume that sets of patches that belong to different semantic classes are disjoint - this is just another way of writing that the there exists a partition of the set of patches, where each subset in the partition is identified with a semantic class.	B-Reply	B-3	Reply	1084
The assumption that these subsets have the same size is just for simplification of the notations in the analysis.	I-Reply	I-3	Reply	1084
[line_break_token][line_break_token]Assumption 3: We require that the frequency matrices of patches from different semantic classes are linearly independent in pairs - i.e, that two frequency matrices of different semantic classes are not linearly dependent (similar up to scaling by a positive scalar).	B-Reply	B-4	Reply	1084
This is a way to make sure that the semantic classes defined in the model are different from each other, as otherwise one could define many different models that generate the same output distribution.	I-Reply	I-4	Reply	1084
The empirical experiments that were added in Figure 3 show that this requirement holds for a model with random parameters.	I-Reply	I-4	Reply	1084
[line_break_token][line_break_token]Assumption 4: The assumption about the orthonormality of the patches is given only in section 4, as a technical step that is not needed in the later analysis of the full algorithm	O	O	Reply	1084

In my opinion, the paper contains very interesting novel ideas.	B-Review	B-1	Review	501
[line_break_token]However, some parts needs a future clarification and the state-of-the-art must be improved.	I-Review	I-1	Review	501
[line_break_token][line_break_token]- First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified.	I-Review	I-1	Review	501
For instance, I believe you can create a unique section with title " Choice of Proposal density " and then schematically describe each proposal from the simplest to the more sophisticated one.	I-Review	I-1	Review	501
[line_break_token][line_break_token]- At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.	B-Review	B-2	Review	501
[line_break_token][line_break_token]- Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates where, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way.	B-Review	B-3	Review	501
This is more general that your scheme but very related.	I-Review	I-3	Review	501
Please see[line_break_token][line_break_token]Qin, Z.S., Liu, J.S., 2001.	I-Review	I-3	Review	501
Multi-point Metropolis method with application to hybrid Monte Carlo.	I-Review	I-3	Review	501
Journal of Computational Physics 172, 827‚Äì840.	I-Review	I-3	Review	501
[line_break_token][line_break_token]L. Martino, V. P. Del Olmo, J. Read, "A multi-point Metropolis scheme with generic weight functions", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.	I-Review	I-3	Review	501
[line_break_token][line_break_token]L. Martino, "A Review of Multiple Try MCMC algorithms for Signal Processing", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.	I-Review	I-3	Review	501
[line_break_token][line_break_token]- Related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed.	B-Review	B-4	Review	501
If I have properly understood, you also adapt a mixture via variational inference.	I-Review	I-4	Review	501
Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,[line_break_token][line_break_token]P. Giordani and R. Kohn, ‚ÄúAdaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,‚Äù Journal of Computational and Graphical Statistics, vol.	O	O	Review	501
19, no.	O	O	Review	501
2, pp.	O	O	Review	501
243‚Äì259, September 2010.	O	O	Review	501
[line_break_token][line_break_token]Tran, M.-N., M. K. Pitt, and R. Kohn.	O	O	Review	501
Adaptive Metropolis‚ÄìHastings sampling using reversible dependent mixture proposals.	O	O	Review	501
Statistics and Computing, 26, 1‚Äì21, 2014.	O	O	Review	501
[line_break_token][line_break_token]D. Luengo, L. Martino, "Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.	O	O	Review	501
[line_break_token][line_break_token]Roberts, G. O. and J. S. Rosenthal (2009).	O	O	Review	501
Examples of adaptive MCMC.	O	O	Review	501
Journal of Computational and Graphical Statistics 18, 349‚Äì367.	O	O	Review	501
[line_break_token][line_break_token][line_break_token]	O	O	Review	501
Thank you for your review and well considered comments.	O	O	Reply	501
[line_break_token][line_break_token]> Review: In my opinion, the paper contains very interesting novel ideas.	O	O	Reply	501
[line_break_token]> However, some parts needs a future clarification and the state-of-the-art must be improved.	O	O	Reply	501
[line_break_token][line_break_token][line_break_token]> First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified.	O	O	Reply	501
For instance, I believe you can create a unique section with title " Choice of Proposal density " and then schematically describe each proposal from the simplest to the more sophisticated one.	O	O	Reply	501
[line_break_token][line_break_token]Thanks for the feedback.	B-Reply	B-1	Reply	501
As we edit the paper to include other changes we'll bear this in mind.	I-Reply	I-1	Reply	501
We'd hoped this was what we had done already but will try to make it clearer.	I-Reply	I-1	Reply	501
[line_break_token][line_break_token]> At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.	O	O	Reply	501
[line_break_token][line_break_token]We believe that this was made clear in sections 2.3.1 and 2.3.2.	B-Reply	B-2	Reply	501
In particular the discussion immediately following equation (9) tries to make this point.	I-Reply	I-2	Reply	501
However, we can add a further sentence emphasising this at the start of section 2 as well.	I-Reply	I-2	Reply	501
[line_break_token][line_break_token]> Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates were, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way.	O	O	Reply	501
This is more general that your scheme but very related.	O	O	Reply	501
Please see[line_break_token][line_break_token]> Qin, Z.S., Liu, J.S., 2001.	O	O	Reply	501
Multi-point Metropolis method with application to hybrid Monte Carlo.	O	O	Reply	501
Journal of Computational Physics 172, 827‚Äì840.	O	O	Reply	501
[line_break_token][line_break_token]> L. Martino, V. P. Del Olmo, J. Read, "A multi-point Metropolis scheme with generic weight functions", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.	O	O	Reply	501
[line_break_token][line_break_token]>L. Martino, "A Review of Multiple Try MCMC algorithms for Signal Processing", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.	O	O	Reply	501
[line_break_token][line_break_token]Thanks for the pointers to these papers.	B-Reply	B-3	Reply	501
We are aware of Multiple Try Metropolis (MTM) but many of the references you provided below were new to us.	I-Reply	I-3	Reply	501
Whilst we acknowledge that MTM is a powerful tool in the MCMC arsenal, we felt that it was quite different to our method and really offers an orthogonal direction for improvement.	I-Reply	I-3	Reply	501
We don't attempt a thorough review of the state-of-the-art in MCMC, which we feel is beyond the scope here, but instead try to focus our discussion on other neural adaptive samplers such as L2HMC and A-NICE-MCMC.	I-Reply	I-3	Reply	501
[line_break_token][line_break_token][line_break_token]> related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed.	O	O	Reply	501
If I have properly understood, you also adapt a mixture via variational inference.	O	O	Reply	501
Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,[line_break_token][line_break_token]Thanks for the pointers to these papers.	B-Reply	B-3	Reply	501
These were mostly new to us and do seem very related.	B-Reply	B-4	Reply	501
After reading the papers more closely we will try to include them in our references.	I-Reply	I-4	Reply	501
[line_break_token][line_break_token]>P. Giordani and R. Kohn, ‚ÄúAdaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,‚Äù Journal of Computational and Graphical Statistics, vol.	O	O	Reply	501
19, no.	O	O	Reply	501
2, pp.	O	O	Reply	501
243‚Äì259, September 2010.	O	O	Reply	501
[line_break_token][line_break_token]>Tran, M.-N., M. K. Pitt, and R. Kohn.	O	O	Reply	501
Adaptive Metropolis‚ÄìHastings sampling using reversible dependent mixture proposals.	O	O	Reply	501
Statistics and Computing, 26, 1‚Äì21, 2014.	O	O	Reply	501
[line_break_token][line_break_token]>D. Luengo, L. Martino, "Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.	O	O	Reply	501
[line_break_token][line_break_token]>Roberts, G. O. and J. S. Rosenthal (2009).	O	O	Reply	501
Examples of adaptive MCMC.	O	O	Reply	501
Journal of Computational and Graphical Statistics 18, 349‚Äì36	O	O	Reply	501

This paper proposes a feature-wise transformation layer to augment the image features, which is a new regularization of neural networks and leads to better generalization ability of the features.	O	O	Review	498
And the proposed method performs well in the few-shot classification problem.	O	O	Review	498
Furthermore, the paper develops a learning-to-learn model in the cross-domain setting to choose optimal hyper-parameters of the feature-wise transformation layers.	O	O	Review	498
Which leads to consistent improvement in the cross-domain leave-one-out setting.	O	O	Review	498
[line_break_token][line_break_token]Although I vote weak accept for this paper, I still have several concerns:[line_break_token]* In equation, how to calculate the gradient of w.r.t in the condition that the is calculated after removing the feature-wise transformation layers from the model?	B-Review	B-1	Review	498
In my understanding, The is not related to after the removal of the feature-wise transformation layers.	I-Review	I-1	Review	498
[line_break_token]* In Section 4.2, why not choose the Prototypical networks?	B-Review	B-2	Review	498
According to the results in (Chen et al 2019a), it performs much better in the mini-ImageNet to CUB setting.	I-Review	I-2	Review	498
[line_break_token]* In Section 4.3, what's the initial value of and?	B-Review	B-3	Review	498
Is the initial value sensitive to the performance?	I-Review	I-3	Review	498
[line_break_token]* In Section 4.2, actually, you can learn the and automatically even in a single domain.	B-Review	B-4	Review	498
For example, use a different batch to update and.	I-Review	I-4	Review	498
What's the performance under this setting?	I-Review	I-4	Review	498
[line_break_token]* There is no direct comparison to the state-of-the-art methods.	B-Review	B-5	Review	498
[line_break_token][line_break_token]Overall, the paper is well written and the figures are well illustrated.	O	O	Review	498
The experiments show the effectiveness of the proposed feature-wise transformation layers and the learning-to-learning approach.	O	O	Review	498
But the above concerns should be addressed.	O	O	Review	498
‚Äî‚Äî---[line_break_token]&gt;&gt;&gt; Comments: There is no direct comparison to the state-of-the-art methods.	O	O	Reply	498
[line_break_token][line_break_token]&gt; Response: We include the results of several state-of-the-art methods [Qiao et al 2018; Oreshkin et al 2018; Lifchitz et al 2019; Lee et al 2019; Rusu et al 2019] on the mini-ImageNet dataset in Table 7 in the appendix.	B-Reply	B-5	Reply	498
Our conclusion is that training the metric-based framework with 1) pre-trained feature encoder, and 2) the proposed feature-wise transformation layers can demonstrate competitive performance.	I-Reply	I-5	Reply	498
For instance, the GNN approach trained with our pre-determined feature-wise transformation layers shows 66% 1-shot and 81% 5-shot classification accuracies on the mini-ImageNet dataset, which is comparable to the state-of-the-art MetaOptNet [Lee et al 2019] (with the accuracy of 64% 1-shot and 80% 5-shot).	I-Reply	I-5	Reply	498
[line_break_token][line_break_token]For the cross-domain setting, we report the performance of MetaOptNet [Lee et al 2019]. We use the model trained on the mini-ImageNet dataset provided by the authors (<a href="https://github.com/kjunelee/MetaOptNet)" target="_blank" rel="nofollow">https://github.com/kjunelee/MetaOptNet)</a> for the evaluation on other datasets.	O	O	Reply	498
As shown in the table below, while MetaOptNet [Lee et al 2019]  achieves state-of-the-art performance on the mini-ImageNet dataset, this approach also suffers from the domain shifts in the cross-domain setting.	B-Reply	B-5	Reply	498
Training the GNN framework with pre-trained feature encoder and feature-wise transformation layers performs favorably against the MetaOptNet method  [Lee et al 2019] under the cross-domain setting.	I-Reply	I-5	Reply	498
[line_break_token][line_break_token]5-way 5-shot performance of models trained on the mini-ImageNet dataset:[line_break_token]                                          CUB                       Cars                     Places                  Plantae[line_break_token][Lee et al 2019] |  54.67 ¬± 0.56%  |  45.90 ¬± 0.49%  |  65.83 ¬± 0.57%  |  46.48 ¬± 0.52%  |[line_break_token]GNN                      |  62.25 ¬± 0.65%  |  44.28 ¬± 0.63%  |  70.84 ¬± 0.65%  |  52.53 ¬± 0.59%  |[line_break_token]GNN + FT             |  66.98 ¬± 0.68%  |  44.90 ¬± 0.64%  |  73.94 ¬± 0.67%  |  53.85 ¬± 0.62%  |[line_break_token][line_break_token]S. Qiao et al Few-Shot Image Recognition by Predicting Parameters From Activations, CVPR 2018.	O	O	Reply	498
[line_break_token][line_break_token]B. Oreshkin et al TADAM: Task Dependent Adaptive Metric for Improved Few-Shot Learning, NeurIPS 2018.	O	O	Reply	498
[line_break_token][line_break_token]Y. Lifchitz et al Dense Classification and Implanting for Few-Shot Learning, CVPR 2019.	O	O	Reply	498
[line_break_token][line_break_token]K. Lee et al Meta-Learning with Differentiable Convex Optimization, CVPR 2019.	O	O	Reply	498
[line_break_token][line_break_token]A. Rusu et al Meta-Learning with Latent Embedding Optimization, ICLR 2019	O	O	Reply	498

Summary:[line_break_token]The paper presents a novel method for answering ‚ÄúHow many ‚Ä¶?‚Äù questions in the VQA datasets.	O	O	Review	458
Unlike previously proposed approaches, the proposed method uses an iterative sequential decision process for counting the relevant entity.	O	O	Review	458
The proposed model makes discrete choices about what to count at each time step.	O	O	Review	458
Another qualitative difference compared to existing approaches is that the proposed method returns bounding boxes for the counted object.	O	O	Review	458
The training and evaluation of the proposed model and baselines is done on a subset of the existing VQA dataset that consists of ‚ÄúHow many ‚Ä¶?‚Äù questions.	O	O	Review	458
The experimental results show that the proposed model outperforms the baselines discussed in the paper.	O	O	Review	458
[line_break_token][line_break_token]Strengths:[line_break_token]1.	O	O	Review	458
[tab_token]The idea of sequential counting is novel and interesting.	O	O	Review	458
[line_break_token]2.	O	O	Review	458
[tab_token]The analysis of model performance by grouping the questions as per frequency with which the counting object appeared in the training data is insightful.	O	O	Review	458
[line_break_token] [line_break_token]Weaknesses:[line_break_token]1.	O	O	Review	458
[tab_token]The proposed dataset consists of 17,714 QA pairs in the dev set, whereas only 5,000 QA pairs in the test set.	B-Review	B-1	Review	458
Such a 3.5:1 split of dev and test seems unconventional.	I-Review	I-1	Review	458
Also, the size of the test set seems pretty small given the diversity of the questions in the VQA dataset.	I-Review	I-1	Review	458
[line_break_token]2.	O	O	Review	458
[tab_token]The paper lacks quantitative comparison with existing models for counting such as with Chattopadhyay et al This would require the authors to report the accuracies of existing models by training and evaluating on the same subset as that used for the proposed model.	B-Review	B-2	Review	458
Absence of such a comparison makes it difficult to judge how well the proposed model is performing compared to existing models.	I-Review	I-2	Review	458
[line_break_token]3.	B-Review	B-1	Review	458
[tab_token]The paper lacks analysis on how much of performance improvement is due to visual genome data augmentation and pre-training?	B-Review	B-3	Review	458
When comparing with existing models (as suggested in above), this analysis should be done, so as to identify the improvements coming from the proposed model alone.	I-Review	I-3	Review	458
[line_break_token]4.	O	O	Review	458
[tab_token]The paper does not report the variation in model performance when changing the weights of the various terms involved in the loss function (equations 15 and 16).	B-Review	B-4	Review	458
[line_break_token]5.	O	O	Review	458
[tab_token]Regarding Chattopadhyay et al the paper says that ‚ÄúHowever, their analysis was limited to the specific subset of examples where their approach was applicable.	B-Review	B-2	Review	458
‚Äù It would be good it authors could elaborate on this a bit more.	I-Review	I-2	Review	458
[line_break_token]6.	O	O	Review	458
[tab_token]The relation prediction part of the vision module in the proposed model seems quite similar to the Relation Networks, but the paper does not mention Relation Networks.	B-Review	B-5	Review	458
It would be good to cite the Relation Networks paper and state clearly if the motivation is drawn from Relation Networks.	I-Review	I-5	Review	458
[line_break_token]7.	O	O	Review	458
[tab_token]It is not clear what are the 6 common relationships that are being considered in equation 1.	B-Review	B-5	Review	458
Could authors please specify these?	I-Review	I-5	Review	458
[line_break_token]8.	O	O	Review	458
[tab_token]In equation 1, if only 6 relationships are being considered, then why does f^R map to R^7 instead of R^6?	B-Review	B-5	Review	458
[line_break_token]9.	O	O	Review	458
[tab_token]In equations 4 and 5, it is not clarified what each symbol represents, making it difficult to understand.	B-Review	B-6	Review	458
[line_break_token]10.	O	O	Review	458
[tab_token]What is R in equation 15?	B-Review	B-6	Review	458
Is it reward?	I-Review	I-6	Review	458
[line_break_token][line_break_token]Overall:[line_break_token]The paper proposes a novel and interesting idea for solving counting questions in the Visual Question Answering tasks.	O	O	Review	458
However, the writing of the paper needs to be improved to make is easier to follow.	O	O	Review	458
The experimental set-up ‚Äì the size of the test dataset seems too small.	B-Review	B-1	Review	458
And lastly, the paper needs to add comparisons with existing models on the same datasets as used for the proposed model.	B-Review	B-2	Review	458
So, the paper seems to be not ready for the publication yet.	O	O	Review	458
We would like to thank the reviewer for their thoughtful and constructive feedback.	O	O	Reply	458
Before addressing the reviewer‚Äôs concerns, we should mention that since the original submission, we have observed superior performance (for all the models we consider) when using the visual features released with the original UpDown paper (those used by Anderson et al).	B-Reply	B-7	Reply	458
We believe this choice simplifies our work by focusing our contribution on the counting module and, by using publicly available visual features, facilitates future comparison.	I-Reply	I-7	Reply	458
[line_break_token][line_break_token][line_break_token]Regarding comment 1: To examine the robustness of the test metrics, we re-computed the accuracy for the development and test splits after diverting 6500 randomly chosen QA pairs from dev to test (giving the adjusted dev/test splits 11k QA pairs each).	B-Reply	B-1	Reply	458
We did this for the 8 IRLC models from the hyperparameter sweep whose penalty weights surrounded the optimum.	I-Reply	I-1	Reply	458
On the original dev/test splits, those models have average accuracies of 56.21 & 57.06.	O	O	Reply	458
In the adjusted split, the average accuracies are 56.18 & 56.64.	O	O	Reply	458
This analysis suggests that the smaller test size does introduce some noise into the accuracy measurement, but the effect of that noise is small compared to the scale of the performance differences between SoftCount, UpDown and IRLC.	B-Reply	B-1	Reply	458
[line_break_token][line_break_token]Regarding comments 2, 3 and 5: The reviewer points out that we did not sufficiently place our work in the context of Chattopadhyay et al We agree and have attempted to correct that mistake in our revised submission (changes appear in Related Works and Models [page 4] sections).	B-Reply	B-2	Reply	458
[line_break_token]To further clarify our reasoning here, there are three main reasons we do not compare to their work.	O	O	Reply	458
[line_break_token]1) Our work and theirs both examine counting, but we use counting as a lens for exploring interpretability in visual question answering.	B-Reply	B-2	Reply	458
This led to considerably different architectures as considered between our works.	I-Reply	I-2	Reply	458
[line_break_token]2) Our work examines generalization for unseen or few-shot classes.	I-Reply	I-2	Reply	458
Since the question is a sentence, not a single word, there are a number of cases where the effective class is a combination of noun and adjective or position (eg.	I-Reply	I-2	Reply	458
black birds, people sitting on the bench).	I-Reply	I-2	Reply	458
Chattopadhyay et al only handles counting a fixed set of object classes and lacks the flexibility required for question answering.	I-Reply	I-2	Reply	458
[line_break_token]3) The reviewer has suggested that we train and evaluate a model based on their proposals (i.e. ‚Äúseq-sub‚Äù); however, to do so would make it very difficult to control for the quality/structure of visual features and the mechanism of visual-linguistic fusion.	I-Reply	I-2	Reply	458
Additionally, the seq-sub architecture is not amenable to question answering or supervision from VQA data alone.	I-Reply	I-2	Reply	458
[line_break_token]All in all, we believe that the issues described above makes quantitatively comparing our work to that of Chattopadhyay et al overly complicated and we hope the reviewer will agree with our assessment.	I-Reply	I-2	Reply	458
[line_break_token][line_break_token]As part of incorporating the new visual features, we have revised the model section describing the vision module.	B-Reply	B-5	Reply	458
This revision has resulted in the removal of the confusing text that the reviewer mentioned in comments 6-8.	I-Reply	I-5	Reply	458
[line_break_token][line_break_token]Following this change, we cannot readily assess how details of pre-training affect ultimate performance, as recommended in comment 3.	B-Reply	B-3	Reply	458
However, we have included an experiment to demonstrate the effect of data augmentation with Visual Genome (Appendix Section C in revised submission).	I-Reply	I-3	Reply	458
We observe that removing the Visual Genome data reduces accuracy by 2.7% on average and increases RMSE by 0.12 on average and that IRLC is most robust to the decrease in training data.	I-Reply	I-3	Reply	458
[line_break_token][line_break_token]In addition, we have incorporated the experiment suggested in comment 4 (Appendix Section C in revised submission).	B-Reply	B-4	Reply	458
The results demonstrate the range of weight settings in which the penalties improve performance.	I-Reply	I-4	Reply	458
[line_break_token][line_break_token]We have also clarified the model descriptions referred to in comments 9 and 10.	B-Reply	B-6	Reply	458
[line_break_token][line_break_token][tab_token][tab_token][tab_token][tab_token][tab_token][line_break_token]Anderson et al Bottom-Up and Top-Down Attention for Image Captioning and VQA.	O	O	Reply	458
In CVPR, 2017.	O	O	Reply	458
[line_break_token][line_break_token]Chattopadhyay et al Counting Everyday Objects in Everyday Scenes.	O	O	Reply	458
In CVPR, 2017.	O	O	Reply	458

This paper proposes to combine the distributed and symbolic execution for natural language queries.	O	O	Review	100
Based on the finding that the symbolic executor's column selection generally aligns with the field attention of the distributed enquirer, the authors incorporate the symbolic executor to the loss of the distributed enquirer by augmenting a field attention cross entropy loss into the original loss.	O	O	Review	100
This information is also used in pre-train the policy for the REINFORCE algorithm.	O	O	Review	100
The experiments show by combining the distributed and symbolic execution this way, the model achieve better performance.	O	O	Review	100
[line_break_token][line_break_token]I like the idea of incorporating the symbolic executor model into the neural model via attention.	B-Review	B-1	Review	100
Similar ideas have been proposed in other papers too (for example <a href="https://arxiv.org/pdf/1511.04586.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1511.04586.pdf</a> -- section 2.6) It would be nice if the authors can refer more to the related works.	O	O	Review	100
Thank you.	O	O	Reply	100
[line_break_token][line_break_token]Special thanks to the recommendation of the paper (<a href="https://arxiv.org/pdf/1511.04586.pdf)," target="_blank" rel="nofollow">https://arxiv.org/pdf/1511.04586.pdf),</a> where the authors train neural attention with IBM Model 4.	O	O	Reply	100
Our main idea works in an opposite way: we first make use of fully differentiable neural networks to learn meaningful (although imperfect) intermediate execution steps, and then guide an external symbolic system, which is more natural in our semantic parsing scenario.	B-Reply	B-1	Reply	100
[line_break_token][line_break_token]We revised the paper with discussion at the end of Section 1.	O	O	Reply	100
Due to page limitation, we had included more discussion in our extended version (Section 4 in <a href="https://arxiv.org/pdf/1612.02741.pdf);" target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.02741.pdf);</a> the suggested paper will also be discussed next time we update the arXiv version (i.e., in mini-batch fashion).	O	O	Reply	100

Summary:-[line_break_token]The authors investigates downsampling as one method by which autoencoding CNNs may memorize data.	O	O	Review	821
The theoretical motivation provided concentrates on linear CNNs.	O	O	Review	821
They show that downsampling linear CNNs tent to learn a point-map of the training data, even though (under certain initializations) they are capable of learning identity maps.	O	O	Review	821
However, non-downsampling linear CNNs learn identity maps.	O	O	Review	821
Given enough data however, the authors claim that the downsampling CNN will learn the identity map.	O	O	Review	821
[line_break_token][line_break_token]Strengths:-[line_break_token]+ Authors present a good exploration of how linear CNNs memorize data when they do downsampling.	O	O	Review	821
[line_break_token]+ A theoretical prediction of the amount of training data needed to counteract data memorization for downsampling linear CNNs is provided, "Our conjecture also implies that when training a linear downsampling CNN on images of size 3 ¬∑ 224 ¬∑ 224, which corresponds to the input image size for VGG and ResNet (He et al (2016), Simonyan & Zisserman (2015)), the number of linearly independent training examples needs to be at least 3 ¬∑ 224 ¬∑ 224 = 153, 228 before the network can learn the identity function."	O	O	Review	821
[line_break_token][line_break_token]Weaknesses:-[line_break_token]+ Not enough theoretical proof is provided to support the hypothesis.	B-Review	B-1	Review	821
Which would be fine but some key experiments are missing to make the paper empirically rigorous.	I-Review	I-1	Review	821
[line_break_token]++ Would be good to see experiments that illustrate the predication that a certain amount of data would allow for learning identity maps, both for linear and non-linear CNNs.	B-Review	B-2	Review	821
[line_break_token]++ In the non-linear CNN setting, I'd like to see the same early-stopping experiment done for linear CNNs whose results are in Fig.	B-Review	B-3	Review	821
3.	I-Review	I-3	Review	821
I don't see any obvious theoretical reason why that result form Fig.	I-Review	I-3	Review	821
3 must extend to the non-linear setting.	I-Review	I-3	Review	821
[line_break_token]+ Initializations are pointed to as effecting the type of function the network learns.	B-Review	B-4	Review	821
The authors give an example of a hand-designed initialization that allows a downsampling linear CNN to learn the identity map but they don't explain how they arrived at this initialization, or its properties that make it a good initialization.	I-Review	I-4	Review	821
In general however, I think it's alright to assign exploration of effect of initialization to future work, since it seems like a non-trivial task.	I-Review	I-4	Review	821
[line_break_token]+ It is mentioned that "the results are not observed for linear networks when using Kaiming initialization," which I read to mean the downsampling linear CNNs with Kaiming initialization learn the identity map, not point-map.	B-Review	B-5	Review	821
If this is true, it seems like a vital point and should be included in discussions of future work.	I-Review	I-5	Review	821
[line_break_token][line_break_token]Recommendation:  I think this could be a better short paper.	B-Review	B-6	Review	821
There are some interesting contributions, but maybe not enough for a full length paper.	I-Review	I-6	Review	821
For a full length paper, some further exploration of _why_ downsampling leads to (if indeed there is a causality) data memorization is needed.	I-Review	I-6	Review	821
[line_break_token][line_break_token]Minor stuff:-[line_break_token]Citation "Gunasekar et al" is missing year (conclusions section)	B-Review	B-7	Review	821
In the following we provide a point-by-point response to the remarks concerning weaknesses :[line_break_token][line_break_token]In response to the first two points:  "+ Not enough theoretical proof is provided to support the hypothesis.	O	O	Reply	821
Which would be fine but some key experiments are missing to make the paper empirically rigorous. " "	O	O	Reply	821
++ Would be good to see experiments that illustrate the predication that a certain amount of data would allow for learning identity maps, both for linear and non-linear CNNs. "	O	O	Reply	821
[line_break_token][line_break_token]For linear downsampling networks, this experiment is shown in the proof of our proposition, namely we see that for 4 linearly independent training examples the network from Figure 4a learns the identity function exactly.	B-Reply	B-1	Reply	821
 Depending on the nonlinearity it may be impossible for non-linear CNNs to learn the identity map (for example a single layer with a ReLU activation can never learn the full identity function as it will always zero out the negative values), which is why our conjecture is made only for linear downsampling networks.	I-Reply	I-1	Reply	821
  [line_break_token][line_break_token]In response to "++ In the non-linear CNN setting, I'd like to see the same early-stopping experiment done for linear CNNs whose results are in Fig.	O	O	Reply	821
3.	B-Reply	B-3	Reply	821
I don't see any obvious theoretical reason why that result form Fig.	O	O	Reply	821
3 must extend to the non-linear setting. "	O	O	Reply	821
[line_break_token][line_break_token]We have run these experiments and they are identical to those for linear networks in Figure 3.	B-Reply	B-3	Reply	821
 For example, even after running for 100 iterations, downsampling non-linear networks learn the point map while non-downsampling non-linear networks learn a mapping more similar to the identity function.	I-Reply	I-3	Reply	821
 [line_break_token][line_break_token]With regard to  "+ Initializations are pointed to as effecting the type of function the network learns.	O	O	Reply	821
The authors give an example of a hand-designed initialization that allows a downsampling linear CNN to learn the identity map but they don't explain how they arrived at this initialization, or its properties that make it a good initialization.	O	O	Reply	821
In general however, I think it's alright to assign exploration of effect of initialization to future work, since it seems like a non-trivial task."	O	O	Reply	821
[line_break_token][line_break_token]In regard to the initialization of the identity map, we provide a full description of the initialization in Appendix A.  To provide more intuition around how we arrived at this initialization: the manual initialization is meant to preserve all pixels of the input image through the layers so that they can be rearranged by the final layer to get the identity function.	B-Reply	B-4	Reply	821
 [line_break_token][line_break_token]Lastly, in response to "+ It is mentioned that "the results are not observed for linear networks when using Kaiming initialization," which I read to mean the downsampling linear CNNs with Kaiming initialization learn the identity map, not point-map.	O	O	Reply	821
If this is true, it seems like a vital point and should be included in discussions of future work."	O	O	Reply	821
[line_break_token][line_break_token]We thank the reviewer for pointing out this possible misinterpretation.	B-Reply	B-5	Reply	821
When we say that the results are not observed for linear networks when using the Kaiming initialization, we meant to say that under the Kaiming initialization, the downsampling linear CNN learns neither the point map nor the identity map.	I-Reply	I-5	Reply	821
 [line_break_token][line_break_token][line_break_token]"Recommendation: I think this could be a better short paper.	O	O	Reply	821
There are some interesting contributions, but maybe not enough for a full length paper.	O	O	Reply	821
For a full length paper, some further exploration of _why_ downsampling leads to (if indeed there is a causality) data memorization is needed."	O	O	Reply	821
[line_break_token][line_break_token]Thanks, we will consider this in our future submission.	B-Reply	B-6	Reply	821
[line_break_token][line_break_token]"Minor stuff:- Citation "Gunasekar et al" is missing year (conclusions section)"[line_break_token][line_break_token]Agreed, thanks.	B-Reply	B-7	Reply	821

Summary: This work proposes a new transformer architecture for tasks that involve a query sequence and multiple candidate sequences.	O	O	Review	20674
The proposed architecture, called poly-encoder, strikes a balance between a dual encoder which independently encodes the query and candidate and combines representations at the top, and a more expressive architecture which does full joint attention over the concatenated query and candidate sequences.	O	O	Review	20674
Experiments on utterance retrieval tasks for dialog and an information retrieval task show that poly-encoders strike a good trade-off between the inference speed of the dual encoder model and the performance of the full attention model.	O	O	Review	20674
[line_break_token][line_break_token]Pros:[line_break_token]- Strong results compared to baselines on multiple dialog and retrieval tasks.	O	O	Review	20674
[line_break_token]- Detailed discussion of hyperparameter choices and good ablations.	O	O	Review	20674
[line_break_token]- Paper is well written and easy to follow.	O	O	Review	20674
[line_break_token][line_break_token]Cons:[line_break_token]- Limited novelty of methods.	B-Review	B-1	Review	20674
Ideas similar to the model variants discussed in this work have been considered in other work (Eg: [1]).	I-Review	I-1	Review	20674
It is also known that in-domain pre-training (i.e, pre-training on data close to the downstream task‚Äôs data distribution) helps (Eg: [2]).	B-Review	B-6	Review	20674
So this work can be considered as an application of existing ideas to dialog tasks.	I-Review	I-6	Review	20674
[line_break_token]- In terms of impact, utterance retrieval has fairly limited applicability in dialog.	B-Review	B-2	Review	20674
The dialog tasks considered in this work have a maximum of 100 candidate utterances, whereas in practice, the space of possible responses is much larger.	B-Review	B-3	Review	20674
While retrieval models are useful, I am skeptical about the practical value of the improvements shown in the paper (especially the improvements over bi-encoder, which is already a decent model).	B-Review	B-4	Review	20674
[line_break_token][line_break_token]Suggestions:[line_break_token]One way to get around the inefficiency of the cross-encoder architecture is to first use an inexpensive scoring mechanism such as TFIDF or bi-encoder to identify a small number of promising candidates from all the possible candidates.	B-Review	B-5	Review	20674
We can then use the cross-encoder to do more precise scoring of only the promising candidates.	I-Review	I-5	Review	20674
I am curious where a pipelined model such as this compares against the variants discussed in the paper in terms of speed and performance.	I-Review	I-5	Review	20674
[line_break_token][line_break_token]While the paper presents strong results on several dialog utterance retrieval tasks, the methods presented have limited novelty and impact.	B-Review	B-1	Review	20674
I am hence leaning towards borderline.	O	O	Review	20674
[line_break_token][line_break_token]References[line_break_token][line_break_token][1] Logeswaran Lajanugen, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob Devlin, and Honglak Lee.	O	O	Review	20674
2019.	O	O	Review	20674
Zero-Shot Entity Linking by Reading Entity Descriptions.	O	O	Review	20674
In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics.	O	O	Review	20674
[line_break_token][2] Jeremy Howard and Sebastian Ruder.	O	O	Review	20674
2018.	O	O	Review	20674
Universal language model fine-tuning for text classification.	O	O	Review	20674
In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics.	O	O	Review	20674
[line_break_token][line_break_token]Edit: I have read the author response.	O	O	Review	20674
Based on the rebuttal, I am more convinced about the practical impact of the approach.	O	O	Review	20674
I am raising my score and recommending accept.	O	O	Review	20674
hank you for your review.	O	O	Reply	20674
[line_break_token][line_break_token]Re: "utterance retrieval has fairly limited applicability in dialog"[line_break_token][line_break_token]Firstly, there are whole competitions run by dialogue researchers evaluating retrieval systems, e.g. DSTC7 Track 1 last year, and again this year in DSTC8, implying researchers in the field feel it is very important.	B-Reply	B-2	Reply	20674
Secondly, on a number of dialogue tasks, direct human evaluation comparing SOTA generative models with SOTA retrieval models ends up with retrieval models winning, see e.g. <a href="https://openreview.net/forum?id=r1l73iRqKm" target="_blank" rel="nofollow">https://openreview.net/forum?id=r1l73iRqKm</a> from last ICLR.	O	O	Reply	20674
[line_break_token][line_break_token][line_break_token]Re: "The dialog tasks considered in this work have a maximum of 100 candidate utterances, whereas in practice, the space of possible responses is much larger."	O	O	Reply	20674
[line_break_token][line_break_token]The tasks do really involve 100,000+ candidates (all utterances from the training set, see Table 1) but the evaluation metrics used in previous work involve using a subset of those per evaluated example, presumably because methods such as cross-encoder are too slow to evaluate otherwise.	B-Reply	B-3	Reply	20674
Poly-encoder can handle these sizes as evidenced in Table 5, which is of course the actual goal.	I-Reply	I-3	Reply	20674
Note the IR task evaluation did use 10,000 candidates also (Table 4), where the methods worked very well.	I-Reply	I-3	Reply	20674
This point seems to be more a criticism of standard evaluation practice, which we follow,  than our method.	I-Reply	I-3	Reply	20674
[line_break_token][line_break_token][line_break_token]Re: "I am skeptical about the practical value of the improvements shown in the paper (especially the improvements over bi-encoder, which is already a decent model)."	O	O	Reply	20674
[line_break_token][line_break_token]The anonymity constraint of ICLR makes this response harder than it should be for us to reply to -- in fact, this approach has become our standard method going forward that we use in real situations, and hence we do emphasize it has strong practical value.	B-Reply	B-4	Reply	20674
The method is practical because it is elegant &amp; simple, fast and gives great results, as evidenced by the evaluation metrics (Table 4) and inference speed (Table 5).	O	O	Reply	20674
For us, it‚Äôs one of those papers where you do actually end up using the method, which definitely isn‚Äôt every time!	B-Reply	B-4	Reply	20674
[line_break_token][line_break_token][line_break_token]Re: "One way to get around the inefficiency of the cross-encoder architecture is to first use an inexpensive scoring mechanism such as TFIDF or bi-encoder to identify a small number of promising candidates from all the possible candidates.	O	O	Reply	20674
We can then use the cross-encoder to do more precise scoring of only the promising candidates.	O	O	Reply	20674
I am curious where a pipelined model such as this compares against the variants discussed in the paper in terms of speed and performance."	O	O	Reply	20674
[line_break_token][line_break_token]Building hybrids, pipelines and ensembles is often useful, but in this case looks tricky.	B-Reply	B-5	Reply	20674
For example, if we cut down the number of candidates from 100k to 1k with a bi-encoder, then switched to a cross-encoder, we would still need 20 seconds (on CPU) to rank with the cross-encoder (see Table 5).	I-Reply	I-5	Reply	20674
In this paper, we only compare single, related architectures against each other (bi, cross, poly).	I-Reply	I-5	Reply	20674
[line_break_token][line_break_token][line_break_token]Re: "Ideas similar to the model variants discussed in this work have been considered in other work (Eg: [1])."	O	O	Reply	20674
[line_break_token][line_break_token]Firstly, our work actually predates that work (an earlier version of this submission was uploaded to a non-archival venue).	B-Reply	B-1	Reply	20674
In any case, their brief description of architectures is not completely clear to us in terms of overlap, but apparently what they tried did not work as they conclude ‚ÄúThe significant gap between Full-Transformer and the other variants shows the importance of allowing fine-grained comparisons between the two inputs via the cross attention mechanism embedded in the Transformer‚Äù.	I-Reply	I-1	Reply	20674
This is quite a different conclusion to ours, where we developed Poly-encoders which have almost the same performance as cross-encoders, but with huge speed-ups.	I-Reply	I-1	Reply	20674
[line_break_token][line_break_token][line_break_token]Re: "It is also known that in-domain pre-training (i.e, pre-training on data close to the downstream task‚Äôs data distribution) helps (Eg: [2]).	O	O	Reply	20674
So this work can be considered as an application of existing ideas to dialog tasks."	O	O	Reply	20674
[line_break_token][line_break_token]We agree that it is long-known that multi-tasking similar tasks is more useful than dissimilar tasks, as cited in our paper, and indeed our work is another example of this.	B-Reply	B-6	Reply	20674
As we understand [2], which is also on a different topic as you say, doesn‚Äôt actually compare two types of pre-training to show this helps though, it only compares ‚Äúusing no pre-training with pre-training on WikiText-103‚Äù (and then fine-tunes on the data of interest).	I-Reply	I-6	Reply	20674
 We also note that WikiText 103 experiments are not on the same scale as ours -- our pre-training on Reddit is more than 100x larger and compares to modern BERT pre-training.	I-Reply	I-6	Reply	20674
 We believe our result is important because much recent work is ignoring related-domain pre-training and using BERT-based (and variant) models etc.	I-Reply	I-6	Reply	20674
and scaling to larger &amp; larger data without considering this crucial point of related-domain pre-training.	O	O	Reply	20674
 Our work provides clear empirical results that this is important even at massive scale.	B-Reply	B-6	Reply	20674
 (We will however add this cite, thanks.	I-Reply	I-6	Reply	20674

This paper introduces Distribution Matching Prototypical Network (DMPN) for Unsupervised Domain Adaptation (UDA).	O	O	Review	20179
The proposed method explicitly models the feature distribution as a Gaussian mixture model in both source and target domains.	O	O	Review	20179
Then the method aligns the target distribution with the source distribution by minimizing losses, which are called Gaussian Component Mean Matching (GCMM) and Pseudo Distribution Matching (PDM).	O	O	Review	20179
[line_break_token][line_break_token]This paper should be rejected because (1) the novelty of the main idea is marginal, and (2) the performance gain over the baseline methods is also marginal.	B-Review	B-1	Review	20179
[line_break_token][line_break_token]Pan et al already proposed the idea of transferring the knowledge from the source to the target using the prototype of each class.	B-Review	B-3	Review	20179
It is required to explain why explicit modeling performs better than implicit modeling of prototypes by theory or practice.	B-Review	B-4	Review	20179
[line_break_token][line_break_token]In table 2, the proposed method seems better than TPN, but in the appendix, by comparing then in each category, the proposed method wins six categories, whereas TPN also wins six categories.	B-Review	B-5	Review	20179
Therefore, it is hard to say the proposed DMPN is more effective than another method.	I-Review	I-5	Review	20179
[line_break_token][line_break_token]Each prototype is modeled using a mean and a covariance matrix.	B-Review	B-6	Review	20179
Why the authors don't use the estimated covariance matrix to measure the distance in eq.5?	I-Review	I-6	Review	20179
[line_break_token][line_break_token]Because the proposed method uses pseudo-labeling for the target domain, it seems that the weights to determine unreliable examples are crucial.	B-Review	B-7	Review	20179
The paper should show the sensitivity of ways to determine the weights.	I-Review	I-7	Review	20179
What happens if values of 0.1 and 0.9 are changed in (pi-0.1)/0.9 on page 6?	I-Review	I-7	Review	20179
hanks for reviewing our paper.	O	O	Reply	20179
You rejected our paper based on two reasons: "This paper should be rejected because (1) the novelty of the main idea is marginal, and (2) the performance gain over the baseline methods is also marginal.".	O	O	Reply	20179
We know it is difficult to argue about the novelty part, as different people have different tastes, however we want to have a try.	O	O	Reply	20179
[line_break_token][line_break_token]As a researcher in the area of domain adaptation, you and us all agree on the importance of this area and have read a lot of great works and come across tons of ideas in this area.	B-Reply	B-1	Reply	20179
But in all of these works and ideas, as far as we are concerned, none of them thought about modeling the feature distribution for domain adaptation though it facilitates us to better measure the distribution discrepancy across domains.	I-Reply	I-1	Reply	20179
This is the gap in the area of domain adaptation we are trying to fill with this work.	I-Reply	I-1	Reply	20179
You mentioned "the novelty of the main idea is marginal", so we want to ask which work do you have in mind that generates our idea as a marginal when you claim that?	I-Reply	I-1	Reply	20179
If you have, please provide us the example.	I-Reply	I-1	Reply	20179
Thanks very much.	I-Reply	I-1	Reply	20179
[line_break_token][line_break_token]You mentioned "Pan et al[1] already proposed the idea of transferring the knowledge from the source to the target using the prototype of each class.",	B-Reply	B-3	Reply	20179
however, we want to clarify again that our work is not about applying prototypical network for domain adaptation, the main idea in our work is to model the feature distribution for domain adaptation, which is a new methodology for domain adaptation.	I-Reply	I-3	Reply	20179
Thus, inspired from Wan et al's [2] work, we model the feature distribution as Gaussian Mixture.	I-Reply	I-3	Reply	20179
In the Related Works section, we cite Snell et al's [3] paper, showing that learning prototypical network is equivalent to modeling feature distribution as exponential density.	I-Reply	I-3	Reply	20179
This statement shows the only connection between our work and Pan et al's.	I-Reply	I-3	Reply	20179
However, the equivalence expressed in the statement is only true for training a model in a single domain.	I-Reply	I-3	Reply	20179
Our work is way different from Pan et al's work in the setting of domain adaptation.	I-Reply	I-3	Reply	20179
[line_break_token]First, we base on different ideas.	I-Reply	I-3	Reply	20179
While Pan et al propose a novel idea to remold Prototypical Network (PN) for domain adaptation, as stated in their paper, our work is based on the idea that almost all existing domain adaptation methods are minimizing the feature distribution discrepancy for effective knowledge transfer from source domain to target domain, however none of them explicitly models the feature distribution though intuitively it facilitates the measuring of distribution discrepancy, thus minimizing the measurement reduces the discrepancy.	I-Reply	I-3	Reply	20179
[line_break_token]Second, the two works propose different distribution discrepancy loss functions.	I-Reply	I-3	Reply	20179
While Pan et al proposes multi-granular distribution discrepancy loss functions at both class-level and sample-level.	I-Reply	I-3	Reply	20179
Our work proposes two novel distribution discrepancy loss function based on probability, one is Gaussian Component Mean Matching and one is Pseudo Distribution Matching.	I-Reply	I-3	Reply	20179
The two distribution discrepancy loss functions work at different aspects and complement each other, where GCMM brings the two distribution closer, PDM shapes the two distribution alike.	I-Reply	I-3	Reply	20179
The two distribution discrepancy loss functions also work at different levels.	I-Reply	I-3	Reply	20179
GCMM reduces domain discrepancy at class level, while PDM reduces domain discrepancy at sample level.	I-Reply	I-3	Reply	20179
We all know that discrepancy loss functions play the central role in a domain adaptation method and devising new domain discrepancy loss functions for domain adaptation is an active research area [4,5,6]. Thus, researchers in the area of domain adaptation would not ignore the two novel discrepancy loss functions we put forward.	I-Reply	I-3	Reply	20179
Furthermore, the idea that modeling the feature distribution enables us to propose new distribution discrepancy loss functions inspires further exploration in this direction to device more novel distribution discrepancy measures.	I-Reply	I-3	Reply	20179
[line_break_token][line_break_token]You further mentioned "It is required to explain why explicit modeling performs better than implicit modeling of prototypes by theory or practice.".	B-Reply	B-4	Reply	20179
As we are exploring the direction of modeling feature distribution for domain adaptation, we do not have much theory to back it up currently.	I-Reply	I-4	Reply	20179
Indeed, modeling the feature distribution as Gaussian Mixture enables us to propose two novel domain discrepancy loss functions.	I-Reply	I-4	Reply	20179
One is Gaussian Component Mean Matching (GCMM) and one is Pseudo Distribution Matching (PDM).	I-Reply	I-4	Reply	20179
For GCMM, Pan et al have proposed a similar one, which they called general purpose domain adaptation, but theirs is more complicated and does not inherit a probability interpretation.	I-Reply	I-4	Reply	20179

This paper proposes an RL training procedure that maintains an ensemble of k policies and periodically pushes all the policies to be closer to the best performing one.	O	O	Review	252
The formulation, experiments and analysis are very clear and show a mild improvement over using the same underlying RL algorithm without the imitation part.	O	O	Review	252
The idea is close to many other proposed in the literature, but to my knowledge it is the first time this exact procedure is studied in detail.	O	O	Review	252
[line_break_token][line_break_token]The first piece of their approach is an off-policy RL algorithm.	O	O	Review	252
In their case, they use SAC.	O	O	Review	252
The second piece is adding an ensemble of policies (3 in their case), and randomly selecting one of them every time a rollout is collected, and using the collected rollout to update all the policies.	O	O	Review	252
This effectively implies 3 times more overall gradient updates compared to SAC.	O	O	Review	252
They call this ablation SAC-ensemble.	O	O	Review	252
Interestingly they only use the most recently collected trajectories to update all policies, and despite storing the rollouts in a replay buffer, they seem to only use the stored transitions for the imitation part described below.	B-Review	B-1	Review	252
Some of their experimental results uses extra gradient steps, although it‚Äôs not clear if those gradient steps are also only on the last rollout collected, or on transitions sampled from the replay buffer as it is typical in off-policy RL methods.	B-Review	B-2	Review	252
In general, I think the work could improve with more details about how much the policy training could improve by increasing the number of gradient steps on the full replay buffer.	I-Review	I-2	Review	252
[line_break_token][line_break_token]The final piece of their method is selecting the best performing policy (or ‚Äúteacher‚Äù) of the ensemble based on the recent experience, and update all other policies by executing some gradient steps on the KL divergence between them and the current ‚Äúteacher‚Äù.	O	O	Review	252
They also try an experiment where the ‚Äúteacher‚Äù is selected randomly, and it does surprisingly well in my opinion (specially realizing that the ‚ÄúHalfCheetah‚Äù experiments seem to not have all seeds run to convergence, please report the full results).	B-Review	B-4	Review	252
I suspect that most of the benefit of their method comes from randomly perturbing the parameters of the policies in the ensemble.	B-Review	B-3	Review	252
More thorough and careful experimentation needs to be carried out to investigate this direction.	I-Review	I-3	Review	252
This is in fact not very surprising given the results of Evolutionary Strategy methods, or Population-based training (even if usually used for hyper-parameters adaptation).	I-Review	I-3	Review	252
[line_break_token][line_break_token]Furthermore, the authors only run the environments for 1M steps, whereas in previous works some environments are shown to get higher return after more training steps.	B-Review	B-5	Review	252
I would also encourage the authors to report the results in all the standard MuJoCo benchmarks for the ablations (even if it‚Äôs in the appendix) to better asses their claims.	I-Review	I-5	Review	252
[line_break_token][line_break_token]Overall, this is a very well presented work, although it lacks some novelty and a few more thorough experiments to fully understand the improvements they show.	B-Review	B-6	Review	252
I think this idea is worth sharing with the community, and I recommend a weak accept.	O	O	Review	252
irst, we would like to thank the reviewer for the time and effort given to the review, and for his/her valuable comments.	O	O	Reply	252
We will address various points that the reviewer mentioned here.	O	O	Reply	252
[line_break_token][line_break_token]-‚ÄúInterestingly they only use the most recently collected trajectories to update all policies, and despite storing the rollouts in a replay buffer, they seem to only use the stored transitions for the imitation part described below.	O	O	Reply	252
‚Äù[line_break_token]-‚ÄúSome of their experimental results uses extra gradient steps, although it‚Äôs not clear if those gradient steps are also only on the last rollout collected, or on transitions sampled from the replay buffer as it is typical in off-policy RL methods‚Äù.	O	O	Reply	252
[line_break_token][line_break_token]In fact, we indeed do what the reviewer notes that we should do, i.e., we use ‚Äútransitions sampled from the replay buffer as it is typical in off-policy RL methods‚Äù, for all of our experiments, as the original SAC algorithm does.	B-Reply	B-1	Reply	252
Perhaps this misunderstanding stems from our pseudocode (Algorithm 1), which was written to be general.	I-Reply	I-1	Reply	252
Though we allude to the use of experience replay for policy training in Section 4.2, we realize that the pseudocode is misleading to make one think that our policy is only trained by the most recent rollouts.	I-Reply	I-1	Reply	252
We have rewritten our pseudocode to accurately reflect our experiments and the SAC algorithm.	I-Reply	I-1	Reply	252
[line_break_token][line_break_token][line_break_token]-‚ÄúI suspect that most of the benefit of their method comes from randomly perturbing the parameters of the policies in the ensemble.	O	O	Reply	252
More thorough and careful experimentation needs to be carried out to investigate this direction.	O	O	Reply	252
‚Äù[line_break_token][line_break_token]First, we would like to clarify that our results demonstrate that selecting the best agent to be the teacher has some benefit over choosing a random teacher.	B-Reply	B-3	Reply	252
Perhaps we misunderstood, but we interpreted the reviewer‚Äôs mention of the ‚Äúrandom perturbation‚Äù to mean the change in parameters after performing distillation with a random teacher.	I-Reply	I-3	Reply	252
 We agree that this question is worth investigating, and we will address these in subsequent experiments in the future.	I-Reply	I-3	Reply	252
[line_break_token][line_break_token]Our hypothesis (which we have updated in the draft), outlined in Section 5.4, is that the reason that distillation from a random teacher performs quite well is because reducing the KL divergence between policies in the ensemble makes each policy better at learning from off-policy data generated from other members of the ensemble, by reducing the extrapolation error that comes from off-policy data distributions [11]. Thus, the distillation improves the quality of the off-policy RL updates, leading to better-than-expected performance for the agents.	I-Reply	I-3	Reply	252
[line_break_token][line_break_token]We intend to investigate this improvement by measuring the extrapolation error [11] (stemming from learning from off-policy data) before and after distillation to measure this effect.	I-Reply	I-3	Reply	252
We can do so with the method used by Fujimoto et al [11], where they measured the extrapolation error for DDPG, an off-policy actor-critic method applied to Mujoco tasks.	I-Reply	I-3	Reply	252
We will also run additional ablations where we withhold some agents in the ensemble from distillation or distill from all members of the ensemble to a single agent.	I-Reply	I-3	Reply	252
[line_break_token][line_break_token]We would like to re-emphasize that these additional investigations are not fundamental to our core claims and results in the paper.	I-Reply	I-3	Reply	252
These experiments are interesting supplementary experiments that better explain the reasons behind our performance improvements upon Ensemble-SAC.	I-Reply	I-3	Reply	252
However, they will not change our core result which is that Ensemble-SAC augmented with CIKD gives improves performance across several Mujoco tasks.	I-Reply	I-3	Reply	252
[line_break_token][line_break_token]-‚Äúspecially realizing that the ‚ÄúHalfCheetah‚Äù experiments seem to not have all seeds run to convergence, please report the full results‚Äù[line_break_token]-‚ÄúFurthermore, the authors only run the environments for 1M steps, whereas in previous works some environments are shown to get higher return after more training steps.	O	O	Reply	252
‚Äù [line_break_token][line_break_token]We intend to run experiments for longer training times and on all standard Mujoco tasks.	B-Reply	B-4	Reply	252
Due to limited resources, we have prioritized (for the rebuttal) running experiments for longer training times.	I-Reply	I-4	Reply	252
These experiments for longer training times are currently underway and we will post them to the rebuttal as soon as possible.	I-Reply	I-4	Reply	252
We will also run experiments on more Mujoco tasks, though it is not likely that we will be able to complete them within the rebuttal period.	I-Reply	I-4	Reply	252

The paper describes a "layer" that aims at producing embeddings for discrete objects by using fewer parameters than classical embeddings layers.	O	O	Review	281
Indeed, the model proposes, instead of learning an embedding matrix of size VxN, to learn a matrix of embeddings of anchors (AxN) and a transformation matrix (VxA) such that the embedding of any object can be found by multiplying A with T. On top of that, they propose different regularization techniques to improve the quality of the learned embeddings, and particularly a proximal gradient method over a L1 normalization on T to reduce the number of parameters.	O	O	Review	281
They propose also different ways to initialize A and also a method for incorporating a priori information (e.g knowledge) into the model.	O	O	Review	281
 They evaluate this model on different tasks: text classification and language modeling and show that they can achieve good performance while using fewer parameters than Sota methods.	O	O	Review	281
[line_break_token][line_break_token]First of all, the paper is well written, and the description is very detailed and understandable.	O	O	Review	281
It was a pleasure to read such a paper!	O	O	Review	281
 [line_break_token][line_break_token]One point which is unclear is the interest of using such a method, and more precisely in which cases, this method can be useful.	B-Review	B-1	Review	281
Indeed, the overall number of parameters of ANT is AxN + VxA (N being the size of the embeddings, A the number of anchors and V the size of the vocabulary) while classical methods are VxN parameters.	I-Review	I-1	Review	281
Said otherwise, we need to have V&lt;N to really have less parameters to train in the model -- knowing that classical embeddings spaces size is usually between 256 and 1024, it means that we have to target a task where the number of anchors is quite low.	O	O	Review	281
I agree that the sparsity term on T is here to encourage to decrease the number of parameters but first, the same sparsity could be applied on the original VxN embedding matrix, and also, even if, at the end, the T matrix is sparse, during learning one has to maintain a large matrix in memory.	B-Review	B-1	Review	281
 I would like the authors to discuss more on this point which is crucial?	I-Review	I-1	Review	281
Particularly, I am not sure to understand what the #Emb value is in the table (AxN + AxV or just AxN), and how to compare the models. (	I-Review	I-1	Review	281
There is a discussion in Section 3, but the argumentation does not explain why having so many parameters at train time is not a problem).	O	O	Review	281
 Also, since this is the crucial point in the paper, I would be interested in having a discussion about the use of neural models compression techniques after learning that could also "do the job" (even if they are not trained end-to-end).	B-Review	B-2	Review	281
[line_break_token][line_break_token]One other remark concerns the different "components" added into the model (e.g sparsity, orthogonality, Relu...).	B-Review	B-3	Review	281
It is difficult to measure the interest of each of them, and I would recommend the authors to provide an ablation study to make the effect of the different choices more understandable by the reader.	I-Review	I-3	Review	281
[line_break_token][line_break_token]The notion of anchors also is misleading since it gives the impression that the A matrix will store embeddings for particular objects, while there is no constraint of that type.	B-Review	B-4	Review	281
Each line of the A matrix is an embedding, but this embedding is not associated with one of the objects seen at train time (no direct mapping from anchors to words in the vocabulary).	I-Review	I-4	Review	281
This has to be made more clear at the beginning of the paper.	I-Review	I-4	Review	281
[line_break_token][line_break_token]Concerning the initialization of A by K-means, it assumes that the space of objects has a particular metric.	B-Review	B-5	Review	281
The authors say that this metric can come from a pretrained embedding space, but in that case, the problem in the number of parameters (which is the main justification of this work) is invalid (i.e if you already have an embedding matrix, then just let us fine-tune it).	I-Review	I-5	Review	281
Could you clarify ?	I-Review	I-5	Review	281
[line_break_token][line_break_token]The fact that the method would allow incorporating knowledge is certainly the most interesting point.	O	O	Review	281
The way it is done has to be better explained (I do not understand why positive pairs are taken into account by not enforcing sparsity on T at this particular point, the way negative pairs are handled seem more natural)[line_break_token][line_break_token]The paper is interesting and proposes a new simple model that could be used to keep good performance while reducing the number of parameters of the final model.	O	O	Review	281
Discussions have to be added to discuss the relevance of the approach since it still needs a large number of parameters at train time, and the role of each component could be studied more in depth.	B-Review	B-3	Review	281
hank you for your detailed comments and suggestions for improvements.	O	O	Reply	281
We answer your questions and provide more experimental comparisons with baselines below.	O	O	Reply	281
[line_break_token][line_break_token][R3 usefulness] Our methods are implemented using a dense matrix for the anchor embeddings A and a **sparse matrix** for the transformations T. Although, naively deep learning frameworks do not fully support backprop on such sparse matrix (basically change of non-zero locations in the sparse matrix is not supported) and we had do some engineering around it.	B-Reply	B-1	Reply	281
In particular, for T we store only the non-zero positions and their values in a sparse format that allow efficient row slicing (adjacency list or CSOO format).	I-Reply	I-1	Reply	281
The memory usage during training, storage, and evaluation are proportional to the size of A and the number of non-zero entries in T: size(A) + nnz(T).	I-Reply	I-1	Reply	281
Time complexity is hard to analyse, but empirically the runtime for training does increase by 1.6 times on WikiText-103 language modeling task, but its mostly due to our unoptimized engineering.	I-Reply	I-1	Reply	281
However, during inference time we see negligible difference because now native sparse ops for the T matrix can be utilized.	I-Reply	I-1	Reply	281
 We do not require that V &lt; N for our method to work, au contraire typically V &gt;&gt; N. In our experiments, we find that T is indeed very sparse, allowing us to obtain 10-100x compression of the embedding matrix, which in our opinion is a good trade-off.	O	O	Reply	281
We have added these details to subsection 3.4 in the paper.	B-Reply	B-1	Reply	281
We also outlined several tips to further speedup training in Appendix C and ways to incorporate our method with existing speedup techniques like softmax sampling or noise-contrastive estimation.	I-Reply	I-1	Reply	281
[line_break_token][line_break_token]Simply applying l1 sparsity to the entire V x N embedding matrix can be seen as a special case of our method where we use **no** anchors.	I-Reply	I-1	Reply	281
This is undesirable since 1) each object is also modeled independently without information sharing between objects (from a statistical perspective, no strength in parameter sharing), and 2) there are no underlying anchors to induce the remaining representations.	I-Reply	I-1	Reply	281
[line_break_token][line_break_token][R3 compression techniques] For the purposes of comparison, we selected a method based on hashing [3] as a post-processing step after training the embedding matrix.	B-Reply	B-2	Reply	281
Specifically, we call Post-SH baseline where we take the trained embedding matrix from a language model trained on PTB or WikiText-103, compress the matrix using the method from [3] (k-means to obtain the anchors + sparse representation the remaining points as in Alg 1 of [3]), and use the reconstructed matrix for evaluation.	I-Reply	I-2	Reply	281
As performance was not good, we tried to improve the method.	I-Reply	I-2	Reply	281
In particular, we use k-SVD [4] to solve for a sparse representation instead of using ad-hoc projection methods (eq 8-9) from [3] and report it as an additional baseline which we call Post-SH+k-SVD.	I-Reply	I-2	Reply	281
Comparing to these post-processing methods we demonstrate that end-to-end joint training of sparse embedding matrices is beneficial over post-processing compression.	I-Reply	I-2	Reply	281
[line_break_token][line_break_token]We present these results as follows:[line_break_token]Using AWD-LSTM on PTB language modeling:[line_break_token][line_break_token][tab_token][tab_token][tab_token]        #anchors[tab_token]perplexity[tab_token]#params (M)[line_break_token]Post-SH [tab_token][tab_token]        1,000[tab_token][tab_token]118.8[tab_token][tab_token]0.60[line_break_token]Post-SH[tab_token][tab_token]        500 [tab_token][tab_token]        166.8[tab_token][tab_token]0.30[line_break_token]Post-SH+k-SVD[tab_token]1,000 [tab_token][tab_token]78.0 [tab_token][tab_token]0.60[line_break_token]Post-SH+k-SVD[tab_token]500 [tab_token][tab_token]        103.5 [tab_token][tab_token]0.30[line_break_token]ANT (ours)[tab_token][tab_token]1000[tab_token][tab_token]72.0[tab_token][tab_token]        0.44[line_break_token]ANT (ours)[tab_token][tab_token]500[tab_token][tab_token]        74.0[tab_token][tab_token]        0.26[line_break_token][line_break_token]Using AWD-LSTM on WikiText-103 language modeling:[line_break_token][line_break_token][tab_token][tab_token][tab_token]        #anchors[tab_token]perplexity[tab_token]#params (M)[line_break_token]Post-SH [tab_token][tab_token]        1,000[tab_token][tab_token]764.7[tab_token][tab_token]5.7[line_break_token]Post-SH[tab_token][tab_token]        500 [tab_token][tab_token]        926.8[tab_token][tab_token]2.9[line_break_token]Post-SH+k-SVD[tab_token]1,000 [tab_token][tab_token]73.7 [tab_token][tab_token]5.7[line_break_token]Post-SH+k-SVD[tab_token]500 [tab_token][tab_token]        148.3 [tab_token][tab_token]2.9[line_break_token]ANT (ours)[tab_token][tab_token]1000 [tab_token][tab_token]39.7 [tab_token][tab_token]3.1[line_break_token]ANT (ours) [tab_token][tab_token]500 [tab_token][tab_token]        54.2 [tab_token][tab_token]0.4[line_break_token][line_break_token]We have also updated Tables 2 and 3 in the paper accordingly with these new baselines.	I-Reply	I-2	Reply	281
[line_break_token][line_break_token]These empirical results show that joint end-to-end training of the sparse embedding matrices is beneficial over post-processing compression, where errors may accumulate in both downstream tasks as well as embedding reconstruction.	I-Reply	I-2	Reply	281
We observe that the performance improvement of ANT over post-processing compression methods is larger on WikiText-103 as compared to PTB, demonstrating that our end-to-end sparse embedding method is particularly suitable for tasks with large vocabularies.	I-Reply	I-2	Reply	281
We emphasize that we are the first to incorporate these ideas of anchor points and sparse transformations into modern neural models for discrete objects	I-Reply	I-2	Reply	281

What is the task?	O	O	Review	469
[line_break_token]Knowledge distillation of BERT[line_break_token][line_break_token]What has been done before?	O	O	Review	469
[line_break_token]Unlike prior works such as Distilled BiLSTMSOFT (Tang et al 2019), BERT-PKD (Sun et al 2019) and DistilBERT, this work[line_break_token][line_break_token]i) Do knowledge distillation at pre training stage also in addition to fine tuning stage.	O	O	Review	469
[line_break_token]ii) Student learns from all - embedding layers, attention matrices, hidden states, and final prediction layers.	O	O	Review	469
[line_break_token][line_break_token]In BERT-PKD, student learns from the [CLS]  hidden states of the teacher.	O	O	Review	469
[line_break_token][line_break_token]What are the main contributions of the paper?	O	O	Review	469
[line_break_token]Novel Transformer distillation method that is specially designed for knowledge distillation of the Transformer-based models.	O	O	Review	469
[line_break_token]Novel two-stage learning framework which performs Transformer distillation at both the pre-training and task-specific learning stages[line_break_token]Resulting TinyBERT being 7.5x smaller and 9.4x faster on inference and significantly outperforms other state-of-the-art baselines on BERT distillation.	O	O	Review	469
[line_break_token][line_break_token]What are the key techniques used to tackle this task?	O	O	Review	469
[line_break_token]Novel Transformer distillation method that is specially designed for knowledge distillation of the Transformer-based models.	O	O	Review	469
[line_break_token]Novel two-stage learning framework which performs Transformer distillation at both the pre-training and task-specific learning stages[line_break_token][line_break_token]What are the main results?	O	O	Review	469
Are they significant?	O	O	Review	469
[line_break_token]Resulting TinyBERT being 7.5x smaller and 9.4x faster on inference and significantly outperforms other state-of-the-art baselines on BERT distillation with only ‚àº28% parameters and ‚àº31% inference time of them.	O	O	Review	469
[line_break_token][line_break_token]Results show that three key procedures: TD (Task-specific Distillation), GD (General Distillation) and DA (Data Augmentation) are crucial for the proposed KD method.	O	O	Review	469
[line_break_token][line_break_token]Proposed distillation objectives - Transformer-layer distillation (attention matrices and hidden states), embedding-layer distillation and prediction layer distillation  are crucial for the proposed KD method.	O	O	Review	469
[line_break_token][line_break_token]Weaknesses[line_break_token]experimental results were not easily comparable to prior work so it is hard to say if claims are well-supported experimental results[line_break_token][line_break_token]Questions[line_break_token]Did authors try other values of lambda[line_break_token]	B-Review	B-1	Review	469
hank you for the helpful comments!	O	O	Reply	469
[line_break_token][line_break_token]Q1: Experimental results are not easily comparable to prior work.	O	O	Reply	469
[line_break_token][line_break_token]A1:[line_break_token]*** Comparison results as shown in Table 2, Table 3 and Table4 ***[line_break_token]The comparison results as shown in the Table 2 are all evaluated on the test set of the official GLUE tasks.	B-Reply	B-1	Reply	469
As shown in the Table 3, our TinyBERT, baselines BERT-PKD and DistilBERT, all have the same number of layers (M=4), and our TinyBERT has a relatively challenging setting with smaller hidden size (d‚Äô=312 vs d‚Äô=768) and feedforward/filter size (d‚Äô_i=1200 vs d‚Äô_i=3072).	I-Reply	I-1	Reply	469
If we increase the hidden size and feedforward/filter size of TinyBERT, it can obtain better performances, which is validated in our experiments in the Table 4 (wider TinyBERT variants achieve better results).	I-Reply	I-1	Reply	469
[line_break_token][line_break_token]In the Table 4, we also directly compared the performances of TinyBERT, BERT-PKD and DistilBERT with the same architecture settings (M=6; d‚Äô=768; d‚Äôi=3072), and TinyBERT has significantly better performances.	I-Reply	I-1	Reply	469
[line_break_token][line_break_token]***More complete comparisons with the same student architecture ***[line_break_token]For complete and direct comparisons with prior works, we here also present the results of TinyBERT (M=6; d‚Äô=768; d‚Äô_i=3072) with the same architectures as used in the original BERT-PKD (Sun et al 2019) and DistilBERT [1] papers.	I-Reply	I-1	Reply	469
[line_break_token][line_break_token]Since in the original papers, the BERT-PKD is evaluated on the TEST set, and the DistilBERT is evaluated on the DEV set.	I-Reply	I-1	Reply	469
Thus, for a clear illustration, we present the results in the following two tables, separately, and the results have been added to the Appendix E of our paper.	I-Reply	I-1	Reply	469
[line_break_token][line_break_token]Table: the comparisons between TinyBERT and BERT-PKD, and the results are evaluated on the test set of official GLUE tasks.	I-Reply	I-1	Reply	469
[line_break_token]-------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token][tab_token][tab_token][tab_token][tab_token]                                SST-2         MRPC           QQP        MNLI-m    MNLI-mm    QNLI        RTE [line_break_token]                                                                (67k)          (3.7k)          (364k)        (393k)         (393k)       (105k)      (2.5k)[line_break_token]                                                                 acc           f1/acc          f1/acc          acc               acc             acc          acc[line_break_token]-------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token]BERT_6-PKD (Sun et al 2019)           92.0        85.0/79.9     70.7/88.9      81.5              81.0           89.0         65.5[line_break_token](M=6; d‚Äô=768;d‚Äô_i=3072)                                                                                                                               [line_break_token]------------------------------------------------------------------------------------------------------------------------------------------------------- [line_break_token]TinyBERT                                               93.1        87.3/82.6     71.6/89.1      84.6             83.2            90.4         66.0 [line_break_token](M=6; d‚Äô=768;d‚Äô_i=3072)                                                                                                                             [line_break_token]--------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token][line_break_token][line_break_token]Table: the comparisons between TinyBERT with DistilBERT, and the results are evaluated on the dev set of GLUE tasks.	I-Reply	I-1	Reply	469
Mcc refers to Matthews correlation and pear/spea refer to pearson/spearman.	I-Reply	I-1	Reply	469
[line_break_token]---------------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token][tab_token][tab_token][tab_token][tab_token]                 CoLA     MNLI     MNLI-mm      MRPC         QNLI        QQP         RTE      SST-2        STS-B [line_break_token]                                                 mcc        acc            acc              f1/acc          acc         f1/acc        acc        acc       pear/spea [line_break_token]--------------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token]DistilBERT [1]                        42.5        81.6            81.1         88.3/82.4       85.5     87.7/90.6     60.0      92.7       84.5/85.0[line_break_token](M=6; d‚Äô=768;d‚Äô_i=3072)[line_break_token]--------------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token]TinyBERT                               54.0        84.5            84.5         90.6/86.3       91.1     88.0/91.1     70.4      93.0       90.1/89.6[line_break_token](M=6; d‚Äô=768;d‚Äô_i=3072)[line_break_token]-------------------------------------------------------------------------------------------------------------------------------------------------------------	I-Reply	I-1	Reply	469

Although this paper seems to only combine existing techniques in community detection and node embedding into a co-train process.	O	O	Review	580
The idea is simple and easy understood and the paper is well-written.	O	O	Review	580
Theoretical analysis is provided for the approximation error for the sampling strategy.	O	O	Review	580
However, major concerns are:[line_break_token][line_break_token]1.	O	O	Review	580
Experimental results show that co-training node embedding and community detection can improve the performance for node classification.	B-Review	B-1	Review	580
The improvements may result from the assumption that papers with the same class label are associated with the same community in the citation graph.	I-Review	I-1	Review	580
However, in the dataset, there are many cases that there are not dense connections among the same labeled papers.	I-Review	I-1	Review	580
The authors should check the correlation between the detected communities and the original paper labels.	I-Review	I-1	Review	580
[line_break_token][line_break_token]2.	O	O	Review	580
No comparison with other community-preserving node embedding methods, such as "Community Preserving Network Embedding" in AAAI17[line_break_token][line_break_token]3.	O	O	Review	580
Since this paper aims to combine community detection and node embedding process, a set of baseline should be considered.	B-Review	B-3	Review	580
For example, if considering the downstream node classification of node embedding as an evaluation task, then how about the performance of the following two-step method.	I-Review	I-3	Review	580
We can first detect communities based on the node features then do graph node embedding by considering the communities' membership and node features together (e.g. simply concatenating both community membership features and node features).	I-Review	I-3	Review	580
[line_break_token][line_break_token]4.	O	O	Review	580
Efficiency and scalability evaluations are needed.	B-Review	B-4	Review	580
Spectral clustering has a scalability issue when meeting big graphs.	I-Review	I-4	Review	580
Since the spectral process is also applied in the proposed method, efficiency and scalability evaluations are encouraged to provide, especially for big graphs which are not covered in the selected datasets in this paper.	I-Review	I-4	Review	580
[line_break_token][line_break_token]5.	B-Review	B-5	Review	580
In Sec 5.3 and Fig 2, it's mentioned that trends of the three datasets are different.	I-Review	I-5	Review	580
For the increasing trend, how about the performance for an extreme case where all nodes are considered in one batch.	I-Review	I-5	Review	580
On the other hand, adding more nodes in one minibatch could provide more information, but why there exists a decreasing trend?	I-Review	I-5	Review	580
Though the authors provide a reason in Sec 5.3, it's better to analyze the reason directly from the datasets.	I-Review	I-5	Review	580
e would like to thank the reviewer for these constructive comments.	O	O	Reply	580
[line_break_token]1.	O	O	Reply	580
The assumption that each class label is associated with a community is not entirely correct.	B-Reply	B-1	Reply	580
First, there is no 1-to-1 mapping between a class label and a community.	I-Reply	I-1	Reply	580
The 1-to-1 mapping relies on an assumption that the number of communities and the number of classes should be the same.	I-Reply	I-1	Reply	580
There are cases that there are more communities than classes which makes n-to-1 mapping between communities and class labels.	I-Reply	I-1	Reply	580
For instance, several small unconnected communities form a class label.	I-Reply	I-1	Reply	580
[line_break_token]Second, the node embeddings can be considered as unnormalized probabilities of assigning nodes to communities.	I-Reply	I-1	Reply	580
Since the classifier is built on the node embeddings, there could be cases that all the nodes that have 60% chance to be in community C1 and 40% chance to be in community C2 to be classified to label L1 while another node with different probability assignments is assigned to another label.	I-Reply	I-1	Reply	580
[line_break_token]The assumption only makes sense when there are clear separation between communities in the graph and each community is associated with a label.	I-Reply	I-1	Reply	580
[line_break_token][line_break_token]2.	O	O	Reply	580
It is worth noting that the technique in [1] (which is called M-NMF) is an extended version of one baseline (NMF) that we have compared in the paper.	B-Reply	B-2	Reply	580
However, we have added a comparison with the mentioned paper for completeness.	I-Reply	I-2	Reply	580
Please see Table 2 in the updated paper.	I-Reply	I-2	Reply	580
Still, our proposed method is able to outperform M-NMF significantly on all datasets.	I-Reply	I-2	Reply	580
[line_break_token][line_break_token]3.	O	O	Reply	580
In this paper, we do not aim to combine community detection and node embedding process.	B-Reply	B-3	Reply	580
We aim to learn node embeddings by detecting community.	I-Reply	I-3	Reply	580
In the baseline proposed by the reviewer, it requires concatenation between community membership and node features, which requires knowing the community structure before learning the node embeddings.	I-Reply	I-3	Reply	580
Our experiment confirms that our approach outperforms the baseline.	I-Reply	I-3	Reply	580
For instance, in the Cora dataset, DMC achieves 0.839 while this baseline's accuracy is 0.749.	I-Reply	I-3	Reply	580
[line_break_token][line_break_token]4.	O	O	Reply	580
It is worth noting that our proposed method (DMC) does not use spectral process.	B-Reply	B-4	Reply	580
In our paper, we discuss spectral method as it provides an analytical solution to minimize the mincut loss.	I-Reply	I-4	Reply	580
This means spectral method can serve as a baseline to compare our results obtained using neural networks with DMC.	I-Reply	I-4	Reply	580
[line_break_token][line_break_token]5.	O	O	Reply	580
It is expected that adding more nodes in a minibatch provide more information, which provides better performance.	B-Reply	B-5	Reply	580
After analysing the dataset, we found out another reason for the decreasing trend for the Pubmed dataset that the node features are extremely useful for node classification.	I-Reply	I-5	Reply	580
Adding more structure information (by adding nodes to the minibatch) would add noise, which decreases the classification accuracy.	I-Reply	I-5	Reply	580
On the other hand, for other datasets, we obtain an increasing trend as expected.	I-Reply	I-5	Reply	580
[line_break_token][line_break_token][line_break_token][1] Wang, Xiao, et al "Community preserving network embedding."	O	O	Reply	580
Thirty-First AAAI Conference on Artificial Intelligence.	O	O	Reply	580
2017	O	O	Reply	580

This paper proposes a neural architecture for segmental language modeling[line_break_token]that enables unsupervised word discoveries.	O	O	Review	1433
The architecture employes a [line_break_token]two-stage architecture that a word might be a type, or a sequence of characters[line_break_token]of its spellings.	O	O	Review	1433
[line_break_token]This idea is basically similar to Nested Pitman-Yor language models [line_break_token](Mochihashi et al 2009) and two-stage language models (Goldwater et al 2011),[line_break_token]but the authors seem not to notice these previous work.	B-Review	B-1	Review	1433
[line_break_token]Experimental results show some improvements on naive baselines, but clearly [line_break_token]below the state-of-the-art in unsupervised word segmentation.	B-Review	B-2	Review	1433
[line_break_token][line_break_token]As noted above, the crucial drawback of this paper is that the authors are[line_break_token]completely unaware of latest achievements on unsupervised word segmentation[line_break_token]and discovery, rather than old, simplistic baselines such as Goldwater+ (2009,[line_break_token]idea is based on Goldwater+ ACL 2006) or Berg-Kirkpatrick (2010).	B-Review	B-3	Review	1433
[line_break_token]The idea of using characters and words is already exploited in Mochihashi+[line_break_token](ACL 2009) in a nonparametric Bayesian framework; it has a better F1 than this[line_break_token]work by a large margin.	B-Review	B-4	Review	1433
Moreover, it is recently extended (Uchiumi+ TACL [line_break_token]2015) to also include latent word categories as well as segmentations to yield [line_break_token]the state-of-the-art accuracies on F1=81.6 on PKU corpus, as compared to 73.1 [line_break_token]in this paper.	I-Review	I-4	Review	1433
[line_break_token]Note that they employ a prior distribution on segment lengths as a (mixture of) [line_break_token]Poisson distributions or negative binomials whose parameters are [line_break_token]automatically learned during inference, as compared to a post-hoc regularization[line_break_token]used in this paper.	B-Review	B-5	Review	1433
[line_break_token][line_break_token]In a Bayesian framework, interpolations between words and characters are[line_break_token]theoretically derived and quite carefully learned, and regularizations are[line_break_token]automatically adjusted.	B-Review	B-6	Review	1433
While neural architectures have some potentials [line_break_token]to improve over them, current heuristic architectures that have lower [line_break_token]performance does not have any advantage over these methods, [line_break_token]both theoretically and empicially.	I-Review	I-6	Review	1433
[line_break_token]	O	O	Review	1433
This work presents a recurrent neural network language model that obtains better predictive distributions (perplexity) than an LSTM while also discovering the words that exist in language.	B-Reply	B-3	Reply	1433
The review above misconstrues the aim of this paper as simply producing the best segmentation accuracy, which the papers cited achieve by tuning for segmentation performance on held out data and sacrificing predictive accuracy.	I-Reply	I-3	Reply	1433
While we agree with the reviewer that there has been much excellent work done on nonparametric Bayesian segmentation (and two key ideas from that modeling tradition directly inspired this work!),	I-Reply	I-3	Reply	1433
no such model has been shown to achieve perplexities close to those of an RNN.	I-Reply	I-3	Reply	1433
However no previous RNN has been shown to discover plausible word segmentations.	I-Reply	I-3	Reply	1433
Our model achieves both.	I-Reply	I-3	Reply	1433
In doing so we argue that word segmentation is not a task that should be studied in isolation from the rest of the language learning but that the flexibility of neural models means they can approach other aspects (e.g., grounding in different modalities or tasks, learning large scale syntactic regularities) more naturally than would be practical with current Bayesian techniques.	I-Reply	I-3	Reply	1433
[line_break_token][line_break_token]Below we elaborate on several more technical objections to this review:[line_break_token][line_break_token]First, our decision to focus on DP/HDP models rather than the extensions referred to in the review (specifically PYP/HPYPs, nested PYPs, integrating out hyperparameters, etc.)	I-Reply	I-3	Reply	1433
was not due to ignorance, but rather that we were incorporating a two core ideas from Bayesian nonparametric word segmentation/language modeling into neural networks and we chose the simplest possible Bayesian model that made our points.	I-Reply	I-3	Reply	1433
These are: (1) that a lexicon that memorizes word chunks is useful for inducing good segmentations; (2) that capacity control is important when you have a lexicon like this.	I-Reply	I-3	Reply	1433
We do agree that nested PYPs, which learn to model character sequences (although not across word boundaries), deserve discussion and we will update the paper accordingly (again we emphasize that this is an oversight, not something that changes the meaningfulness of our results).	I-Reply	I-3	Reply	1433
Thus, the DP/HDP models otherwise perfectly illustrates the points they needed to illustrate, and the newer variations do not offer any additional insight into how to fix the problems that RNNs have with discovering words.	I-Reply	I-3	Reply	1433
[line_break_token][line_break_token]Second, our results are not precisely comparable since Bayesian unsupervised learning has traditionally been evaluated in a setup which does not distinguish between a train and test set, or which uses observations from both when performing posterior inference.	I-Reply	I-3	Reply	1433
As we demonstrated, in Bayesian models, selecting hyperparameters empirically (ie, based on held-out likelihood) results in less effective structure discovery than setting the hyperparameters subjectively (however, since some standard datasets did not have a train/test split until this paper, we expect that in many cases, these models were chosen based on reported segmentation accuracies!).	I-Reply	I-3	Reply	1433
We certainly appreciate the insights that have been enabled by using both methodologies, but our perspective is that relying on held-out likelihood for model selection is eminently defensible methodology.	I-Reply	I-3	Reply	1433
However, held-out likelihood is indeed a radically different development/training/evaluation methodology for working on segmentation that is a better fit for neural models (and, we think, Bayesian models as well) than what came before, and it does make the results incomparable.	I-Reply	I-3	Reply	1433
Finally, another source of incompatibility is that the Uchiumi et al (2015) length distribution correction relies on hand-engineered features.	I-Reply	I-3	Reply	1433
We expected these were selected to improve reported segmentation accuracy (rather than validation likelihood), and as an ICLR paper, we are exploring how well we can do with learning representations, rather than engineering them.	I-Reply	I-3	Reply	1433
[line_break_token][line_break_token]Third, the goal of this paper was to show that it is possible to align the goals of good segment discovery with good held-out models of language (after all, humans are good at both!).	I-Reply	I-3	Reply	1433
In their zeal to argue that our segmentation accuracy lags behind that of the best Bayesian models (which we questioned in the previous paragraph), the reviewers ignore the crucial fact that the most basic RNNs outperform the best hierarchical Bayesian language models by far in terms of predicting held-out data.	I-Reply	I-3	Reply	1433
Surprisingly, although posterior predictive checking is a standard tool for assessing Bayesian models, none of the existing Bayesian segmentation papers seem to have used this methodology, and so we had to include our own likelihood experiments (Table 4) to demonstrate this disparity.	I-Reply	I-3	Reply	1433
These results show clearly that while Bayesian models are perhaps slightly better than our models in terms of segmentation accuracy, they are far less good than RNNs in terms of predictive accuracy.	I-Reply	I-3	Reply	1433
On the other hand, our RNNs are good at both	I-Reply	I-3	Reply	1433

The paper introduces a neural translation model that automatically discovers phrases.	O	O	Review	6
 This idea is very interesting and tries to marry phrase-based statistical machine translation with neural methods in a principled way.	O	O	Review	6
However, the clarity of the paper could be improved.	O	O	Review	6
[line_break_token][line_break_token]The local reordering layer has the ability to swap inputs, however, how do you ensure that it actually does swap inputs rather than ignoring some inputs and duplicating others?	B-Review	B-1	Review	6
[line_break_token][line_break_token]Are all segments translated independently, or do you carry over the hidden state of the decoder RNN between segments?	B-Review	B-2	Review	6
In Figure 1 both a BRNN and SWAN layer are shown, is there another RNN in the SWAN layer, or does the BRNN emit the final outputs after the segments have been determined?	B-Review	B-3	Review	6
Thank you for your valuable comments.	O	O	Reply	6
 We address the comments and questions below:[line_break_token]1.	O	O	Reply	6
The local reordering layer has the ability to swap inputs, however, how do you ensure that it actually does swap inputs rather than ignoring some inputs and duplicating others?	O	O	Reply	6
[line_break_token]<Response>: We do not have a guarantee that the layer forces to swap inputs as it is data driven.	B-Reply	B-1	Reply	6
In Appendix A, we show an example translating from "can you translate it ?"	I-Reply	I-1	Reply	6
to  "k√∂nnen es √ºbersetzen?"	I-Reply	I-1	Reply	6
to show that some input information is swapped.	I-Reply	I-1	Reply	6
 Note that the example needs to be reordered from "translate it" to "es √ºbersetzen".	I-Reply	I-1	Reply	6
 Each row of Figure 3 represents a window of size 7 that is centered at a source sentence word.	I-Reply	I-1	Reply	6
We can observe that the gates mostly focus on the central word since the first part of the sentence only requires monotonic alignment.	I-Reply	I-1	Reply	6
Interestingly, the model outputs "$" (empty) when the model has the word "translate" in the center of the window.	I-Reply	I-1	Reply	6
 Then, the model outputs "es" when the model encounters "it".	I-Reply	I-1	Reply	6
 Finally, in the last window (top row), the model not only has a large gate value to the center input "?",	I-Reply	I-1	Reply	6
but the model also has a relatively large gate value to the word "translate" in order to output the translation "√ºbersetzen ?".	I-Reply	I-1	Reply	6
 This shows an example of the reordering effect achieved by using the gating mechanism of the reordering layer.	I-Reply	I-1	Reply	6
[line_break_token] [line_break_token]2.	B-Reply	B-2	Reply	6
Are all segments translated independently, or do you carry over the hidden state of the decoder RNN between segments?	O	O	Reply	6
[line_break_token]<Response>: Yes, all the segments are translated independently.	B-Reply	B-2	Reply	6
We do not carry over the hidden states between segments.	I-Reply	I-2	Reply	6
Hence, the decoding can be parallelized.	I-Reply	I-2	Reply	6
We are highlighting this part in the second to last paragraph of Section 2.2.	I-Reply	I-2	Reply	6
[line_break_token] [line_break_token]3.	O	O	Reply	6
In Figure 1 both a BRNN and a SWAN layer are shown, is there another RNN in the SWAN layer, or does the BRNN emit the final outputs after the segments have been determined?	O	O	Reply	6
[line_break_token]<Response>: In Figure 1, the reordering layer and BRNN can be considered as the encoder of an input sequence.	B-Reply	B-3	Reply	6
The SWAN is the decoder, which contains another unidirectional RNN for p(a_t|x_t) in Eq. (	I-Reply	I-3	Reply	6
1).	I-Reply	I-3	Reply	6
The BRNN emits x_t to SWAN.	I-Reply	I-3	Reply	6
We added some clarification in defining x_t to address it	I-Reply	I-3	Reply	6

This paper presents a method for blind source separation relying on randomly initialized networks to decompose an input audio spectrogram into two components.	O	O	Review	10035
[line_break_token]The networks are designed to promote temporal contiguity of spectral energy in the estimated signals, which are modulated (in time) by estimated masks.	O	O	Review	10035
[line_break_token]The proposed method is evaluated on a collection of 150 random mixes of sounds, and performs favorably relative to some standard baseline methods (RPCA, NMF, KAM).	O	O	Review	10035
[line_break_token][line_break_token]This seems like a promising line of work, but at this point I think the weaknesses of the paper outweigh its strengths (as detailed below).	O	O	Review	10035
 Some of these points may be addressed during discussion, but I currently lean toward reject.	O	O	Review	10035
[line_break_token][line_break_token][line_break_token]Strengths of the paper:[line_break_token][line_break_token]- The ideas are interesting, and appear to perform well on a simulated and real(ish) data.	O	O	Review	10035
[line_break_token][line_break_token]- The authors investigate several variations and applications of source separation, including interactive editing, co-separation, and texture synthesis.	O	O	Review	10035
[line_break_token][line_break_token]- A small (qualitative) ablation study is included to clarify the importance of different components of the loss function.	O	O	Review	10035
[line_break_token][line_break_token][line_break_token]Weaknesses of the paper:[line_break_token][line_break_token]- Much of the presentation is vague or opaque.	B-Review	B-1	Review	10035
 There is little detail provided about the specific architectural parameters of the model, and the diagram (figure 1) does not appear to match the equations.	I-Review	I-1	Review	10035
 Specifically, it's unclear whether S_1^* is a function of S_mixture or not.	I-Review	I-1	Review	10035
[line_break_token][line_break_token]- The quantitative evaluation focuses entirely on one (new) dataset with unclear characteristics.	B-Review	B-2	Review	10035
 No details are provided about the evaluation protocol, and in particular, the tuning of hyperparameters for the various methods under comparison.	I-Review	I-2	Review	10035
 Aggregate statistics are included (mean?	I-Review	I-2	Review	10035
SDR, etc), but no notion of variance or error bars are included.	I-Review	I-2	Review	10035
 It's not ultimately clear how fair this evaluation is.	I-Review	I-2	Review	10035
 There should at minimum be a comparison on a standard source separation or speech enhancement dataset, in addition to the new set presented here.	I-Review	I-2	Review	10035
[line_break_token][line_break_token]- Most of the spectrogram figures appear to be upside-down, which is confusing.	B-Review	B-3	Review	10035
 The details of the audio processing are omitted: STFT parameters are stated, but not the sampling rate.	I-Review	I-3	Review	10035
[line_break_token][line_break_token]- There are numerous typos ("grounth", "spectrogram stokes", etc), indicative of the authors not running a spell-checker on their submission.	B-Review	B-4	Review	10035
[line_break_token][line_break_token][line_break_token]Questions for the authors:[line_break_token][line_break_token]- The model itself consists of several competing loss functions, but it seems like they may have a trivial, optimal solution at S1 = S_mix (M_1 = 1) and S_2 = 0 (M_2 = 0 or 1).	B-Review	B-5	Review	10035
 As far as I can tell, this solution would trivially minimize each term of equation 9.	I-Review	I-5	Review	10035
 (If S_1* does not depend on S_mixture, this may be less of an issue, but the trivial solution may still exist when the driving noise is of sufficiently high dimension and the optimization is run long enough.)	I-Review	I-5	Review	10035
 Am I misunderstanding the algorithm, or is there some deeper reason why this solution would not be preferred?	I-Review	I-5	Review	10035
[line_break_token]	O	O	Review	10035
hank the reviewer for recognizing our work and providing constructive comments.	O	O	Reply	10035
We try to address the concerns brought up below.	O	O	Reply	10035
[line_break_token][line_break_token]A1: Since U-net is commonly used in previous works (Ulyanov et al 2018; Gandelsman et al 2019), we only give the reference in the paper for making the paper be concise and leaving pages for delivering methods and several exciting applications.	B-Reply	B-1	Reply	10035
But now, to make it more clear to readers, we have illustrated the network in the updated appendix (please see Section A.1 and Figure 10).	I-Reply	I-1	Reply	10035
[line_break_token][line_break_token]Figure 1 is consistent with Equation 1 in the paper.	I-Reply	I-1	Reply	10035
As shown in the Figure and formulated in the Equation, we decompose a sound mixture to individual sounds with corresponding mask modulations.	I-Reply	I-1	Reply	10035
To achieve the decomposition, unlike all existing sound separation networks that use sound mixtures as separation network inputs, our DAP model learn individual audio source generator network and mask generator network for each audio source with randomly sampled noise as inputs.	I-Reply	I-1	Reply	10035
Therefore, S_{mixture} is not a function input and it will serve as the groundtruth signal for learning as in Equation 2.	I-Reply	I-1	Reply	10035
[line_break_token][line_break_token]A2: We have indeed faced the problem in our evaluation to find an existing dataset for validating our method whether can learn to handle various audio sources.	B-Reply	B-2	Reply	10035
However, we learn that most existing datasets only contain either music or speech sounds.	I-Reply	I-2	Reply	10035
To evaluate the generalizability of our deep audio prior network, we build a dataset containing 150 sound mixtures covering a large range of sound categories appeared in our daily life.	I-Reply	I-2	Reply	10035
[line_break_token][line_break_token]For evaluation, we adopt the commonly used mir_eval library <a href="https://github.com/craffel/mir_eval" target="_blank" rel="nofollow">https://github.com/craffel/mir_eval</a> to compute SDR and SIR scores and LSD is implemented by us.	O	O	Reply	10035
For the compared methods, we carefully tuned their parameters for fair comparisons.	B-Reply	B-2	Reply	10035
However, the conventional matrix decomposition and kernel regression-based blind separation methods have limited capacity to well model rich and diverse audio patterns as shown in Figure 3 and also results in our anonymous Github repository.	I-Reply	I-2	Reply	10035
[line_break_token][line_break_token]Since averaged scores of SDR, SIR, and LSD are commonly used metrics in previous literature, we also adopt the practice in our paper.	I-Reply	I-2	Reply	10035
For additional comparison, we have compared our method with recent speech enhancement methods: DNP and SEGAN on a noisy speech, where the clean speech is from the used dataset in the SEGAN paper.	I-Reply	I-2	Reply	10035
[line_break_token][line_break_token]To further address the concerns, we would like to show additional results on our dataset using a new metric and test our method on an existing standard sound separation dataset containing music and speech sounds.	I-Reply	I-2	Reply	10035
We have included the additional experimental results in the Appendix of the paper (please see Section A.2.)	I-Reply	I-2	Reply	10035
[line_break_token][line_break_token]To further clarify the numerical results, except from the mean SDR, mean SIR, and mean LSD, which are sensitive to over large or over small values (variance also has the same issue), we count the better result ratio based on the three metrics.	I-Reply	I-2	Reply	10035
The ratio will count our DAP is better than the compared the method on how many testing samples.	I-Reply	I-2	Reply	10035
For example, compared to the NMF in terms of SDR, the ratio is 0.753, which shows that our method is better than the NMF on 75.3% testing samples.	I-Reply	I-2	Reply	10035
In terms of SDR, SIR and LSD, compared to NMF, RPCA, and KAM, the ratio results are (0.753, 0.66, 0.56)@SDR, (0.767, 0.627, 0.667)@SIR, and (0.714, 0.58, 0.714)@LSD, respectively.	I-Reply	I-2	Reply	10035
The results further show the superiority and robustness of our method.	I-Reply	I-2	Reply	10035
[line_break_token][line_break_token]To further validate our method, we compare with other methods on a sound separation benchmark (Vincent et al, 2007), which has 20 testing samples and each sample has 3 clean sounds.	I-Reply	I-2	Reply	10035
In our testing, we take the first two sounds from each sample to compose sound mixtures.	I-Reply	I-2	Reply	10035
The (SDR, SIR, LSD) results for NMF, RPCA, KAM, and DAP are (-3.36, -0.93, 0.56), (-4.49, -1.00, 0.57), (-2.16, -0.32, 2.19), and (-1.37, 0.82, 0.48).	I-Reply	I-2	Reply	10035
We can see that our method outperforms the three compared methods in terms of SDR, SIR, and LSD.	I-Reply	I-2	Reply	10035
Note that it is smaller and better for LSD.	I-Reply	I-2	Reply	10035
[line_break_token][line_break_token]E. Vincent, R. Gribonval and M.D. Plumbley, Oracle estimators for the benchmarking of source separation algorithms, Signal Processing 87(8), p. 1933-1950, 2007.	O	O	Reply	10035
[line_break_token][line_break_token]	O	O	Reply	10035

The authors introduce MelNet, an autoregressive model of Mel-frequency scaled spectrograms.	O	O	Review	591
They convert audio into high resolution spectrograms to reduce the audio artifacts introduced by inverting spectrograms (here they use gradient-based inversion over Griffin-Lim).	O	O	Review	591
To improve modeling of long term dependencies, they perform multi-scale splitting of the spectrograms and maximize the likelihood at each scale (avoiding dominance of noise at higher resolutions).	O	O	Review	591
They condition generation at finer scales from coarser scales, enabling sampling through an ancestral process.	O	O	Review	591
The authors also highlight the difference between temporal and frequency dimensions, creating different conditioning stacks for the past in time vs. the "past" in frequency (lower frequencies), and mixing conditioning between the two stacks through layers of the network.	O	O	Review	591
Multilayer RNNs are used throughout the network and external conditioning is incorporated at the input.	O	O	Review	591
[line_break_token][line_break_token]The challenge the authors are attempting to address is modeling of audio structure on both long and short timescales.	O	O	Review	591
As the authors demonstrate with strong baselines, WaveNet models, while superior on fine-scale fidelity, fail to capture dynamics more than a couple hundred milliseconds.	O	O	Review	591
The experiments demonstrate improvements on state-of-the-art for unconditional generation on text-to-speech datasets (generating coherent words and phrases) and the MAESTRO piano dataset (generating sections with consistent dynamics/timing/motifs).	O	O	Review	591
The continuations of primed examples in both domains are particularly impressive qualitatively, as they maintain much of the character of the priming sample.	O	O	Review	591
Ablation experiments qualitatively demonstrate the importance of multi-scale modeling for unconditional generation.	O	O	Review	591
Human listener studies support the claims made from qualitative evaluation of long term structure.	O	O	Review	591
[line_break_token][line_break_token]This paper should be accepted because it represents a non-trivial adaptation of autoregressive modeling to handle multi-scale structure in audio.	O	O	Review	591
The baselines comparisons and strong, and experiments validate the claims of the paper.	O	O	Review	591
[line_break_token][line_break_token]That said, several things could be done to improve the clarity and significance of the paper.	O	O	Review	591
[line_break_token][line_break_token]* While the network architecture is described in detail and some figures, the full network structure itself is non-trivial and still somewhat opaque from the plain text description.	B-Review	B-1	Review	591
A schematic diagram of the full network architecture, even in the appendix, could help clarify how many layers are present connecting each component of the model, which would improve reproducibility.	I-Review	I-1	Review	591
[line_break_token][line_break_token]* The paper is a bit thin on metrics.	B-Review	B-2	Review	591
Human listening studies compare long-term structure, but not short-scale fidelity.	I-Review	I-2	Review	591
For TTS, there are clear artifacts from the spectrogram inversion process.	I-Review	I-2	Review	591
Mean opinion scores on conditional samples could help to quantify the importance of each element of the network for audio quality.	I-Review	I-2	Review	591
For instance, how does MOS compare between Griffin-Lim MelNet, Gradient Inversion MelNet, and WaveNet?	I-Review	I-2	Review	591
How does MelNet compare to Linear scaled spectrograms?	I-Review	I-2	Review	591
[line_break_token][line_break_token]* Generating MelSpectrograms to model long-term structure is a fairly established technique, most notably employed by all of the Tacotron variants (<a href="https://google.github.io/tacotron/)."	O	O	Review	591
target="_blank" rel="nofollow">https://google.github.io/tacotron/).</a> These models are perhaps a more appropriate comparison for MelNet in many ways, and opt for spectrogram inversion by smaller WaveRNN models.	O	O	Review	591
One of the claims of the paper is that it is important to model the fine-scale structure of spectrograms, but it is not clear if that really is the case.	B-Review	B-3	Review	591
A proper comparison to Tacotron models (where spectrograms are generated at the same resolution / the same inversion methods are used) would help clarify the importance of end-2-end training, vs. the learned inversion approach.	I-Review	I-3	Review	591
[line_break_token][line_break_token]	O	O	Review	591
hank you for the comments and suggestions.	O	O	Reply	591
[line_break_token][line_break_token]&gt; While the network architecture is described in detail and some figures, the full network structure itself is non-trivial and still somewhat opaque from the plain text description.	O	O	Reply	591
A schematic diagram of the full network architecture, even in the appendix, could help clarify how many layers are present connecting each component of the model, which would improve reproducibility.	O	O	Reply	591
[line_break_token][line_break_token]We spent a fair amount of time discussing how to show the architecture schematically, but ultimately did not come up with anything particularly satisfying.	B-Reply	B-1	Reply	591
 Most of the intricacy lies in the implementation of the multi-dimensional recurrence and the connectivity between the time and frequency stacks, so we focused on including equations and figures which provide clarity in these areas.	I-Reply	I-1	Reply	591
[line_break_token][line_break_token][line_break_token]&gt; The paper is a bit thin on metrics.	O	O	Reply	591
Human listening studies compare long-term structure, but not short-scale fidelity.	O	O	Reply	591
For TTS, there are clear artifacts from the spectrogram inversion process.	O	O	Reply	591
Mean opinion scores on conditional samples could help to quantify the importance of each element of the network for audio quality.	O	O	Reply	591
For instance, how does MOS compare between Griffin-Lim MelNet, Gradient Inversion MelNet, and WaveNet?	O	O	Reply	591
How does MelNet compare to Linear scaled spectrograms?	O	O	Reply	591
[line_break_token][line_break_token]We generally agree with your comments here.	B-Reply	B-2	Reply	591
 As we don‚Äôt provide any experiments regarding short-term fidelity, we made sure to restrict our claims to state that the benefit of MelNet relates to its ability to capture long-range structure.	I-Reply	I-2	Reply	591
 In cases where audio fidelity is paramount, time-domain models could be used to invert spectrograms generated by MelNet.	I-Reply	I-2	Reply	591
[line_break_token][line_break_token][line_break_token]&gt;  Generating MelSpectrograms to model long-term structure is a fairly established technique, most notably employed by all of the Tacotron variants (<a href="https://google.github.io/tacotron/)."	O	O	Reply	591
target="_blank" rel="nofollow">https://google.github.io/tacotron/).</a> These models are perhaps a more appropriate comparison for MelNet in many ways, and opt for spectrogram inversion by smaller WaveRNN models.	O	O	Reply	591
One of the claims of the paper is that it is important to model the fine-scale structure of spectrograms, but it is not clear if that really is the case.	O	O	Reply	591
A proper comparison to Tacotron models (where spectrograms are generated at the same resolution / the same inversion methods are used) would help clarify the importance of end-2-end training, vs. the learned inversion approach.	O	O	Reply	591
[line_break_token][line_break_token]The main distinction between MelNet and models such as Tacotron is that MelNet utilizes a much more flexible probabilistic model that allows it to be applied to unconditional generation tasks such as music generation.	B-Reply	B-3	Reply	591
 The experiments in this paper are restricted to unconditional audio generation, so direct comparison with models such as Tacotron would not be possible.	I-Reply	I-3	Reply	591
 We‚Äôve revised the paper to include a discussion of existing TTS models.	I-Reply	I-3	Reply	591

This paper propose a new approach to dialogue modeling by introducing two[line_break_token]innovations over an established dialogue model: the HRED (Hierarchical[line_break_token]Recurrent Encoder-Decoder) network.	O	O	Review	1284
The innovations are: (1) adding a GAN[line_break_token]objective to the standard MLE objective of the HRED model; and (2)[line_break_token]modifying the HRED model to include an attention mechanism over the local[line_break_token]conditioning information (i.e. the "call" before the present "response").	O	O	Review	1284
 [line_break_token][line_break_token]Writing: The writing was mostly ok, though there were some issues early in[line_break_token]Section 2.	B-Review	B-1	Review	1284
The authors rather awkwardly transition from a mathematical[line_break_token]formalism that included the two halves of the dialogue as X (call) and Y[line_break_token](response), to a formalism that only considers a single sequence X. [line_break_token][line_break_token]Novelty and Impact:  The proposed approach explicitly combines an established[line_break_token]model with two components that are themselves well-established.	B-Review	B-2	Review	1284
[line_break_token]It's fair to say that the novelty is relatively weak.	I-Review	I-2	Review	1284
The model development[line_break_token]is sensible, but reasonably straightforward.	I-Review	I-2	Review	1284
It isn't clear to me that a[line_break_token]careful reader of the literature in this area (particularly the GAN for[line_break_token]text literature) will learn that much from this paper.	I-Review	I-2	Review	1284
[line_break_token][line_break_token]Experiments: Overall the empirical evaluation shows fairly convincingly[line_break_token]that the proposed model is effective.	B-Review	B-3	Review	1284
I do wonder why would the hredGAN[line_break_token]model outperform the hred model on perplexity.	I-Review	I-3	Review	1284
The hred model is[line_break_token]directly optimizing MLE which is directly related to the perplexity[line_break_token]measure, while the hredGAN include an additional objective that should[line_break_token](perhaps) sacrifice likelihood.	I-Review	I-3	Review	1284
This puzzling result was not discussed and[line_break_token]really should be.	I-Review	I-3	Review	1284
[line_break_token][line_break_token]The generated responses, given in table 3 -- while showing some improvement[line_break_token]over hred and Vhred (esp.	B-Review	B-4	Review	1284
in terms of response length and specificity) --[line_break_token]do not fit the context particularly well.	I-Review	I-4	Review	1284
This really just shows we still[line_break_token]have some way to go before this challenging task is solved.	I-Review	I-4	Review	1284
[line_break_token][line_break_token]It would be useful if the authors could run an ablation study to help[line_break_token]resolve the relative contributions of the two innovations (GAN and[line_break_token]attention) to the improvements in results.	B-Review	B-5	Review	1284
Perhaps the improvement in[line_break_token]perplexity (discussed above) is do to the use of attention.	I-Review	I-5	Review	1284
[line_break_token][line_break_token]Detailed comments / questions[line_break_token][line_break_token]- In the paragraph between Eqns 2 and 3, the authors seem to suggest that[line_break_token]  teacher forcing is an added heuristic -- however this is just the[line_break_token]  correct evaluation of the MLE objective.	B-Review	B-6	Review	1284
[line_break_token][line_break_token]- In discussing the combined MLE-GAN objective in Eqn.	B-Review	B-7	Review	1284
8 Does the MLE[line_break_token]  objective use teacher forcing?	I-Review	I-7	Review	1284
Some earlier text (discussed above) leads[line_break_token]  me to suspect that it does not.	I-Review	I-7	Review	1284
[line_break_token]	O	O	Review	1284
Thank you for your review.	O	O	Reply	1284
[line_break_token][line_break_token]-- The authors rather awkwardly transition from a mathematical formalism that included the two halves of the dialogue as X (call) and Y (response), to a formalism that only considers a single sequence X.[line_break_token]We try to depict the original problem by Eq.(2) which is difficult to learn or train and substitute with a well known approximation (teacher forcing) in Eq.(3).	B-Reply	B-1	Reply	1284
This a well established trick for training machine translation and dialogue response generation.	I-Reply	I-1	Reply	1284
[line_break_token][line_break_token]--The model development is sensible, but reasonably straightforward.	O	O	Reply	1284
[line_break_token]While HRED and GAN are will established concept, it is not trivial to combine due to the lack of end-to-end differentiability between the HRED generator and the GAN discriminator.	B-Reply	B-2	Reply	1284
Also, the questions of where to inject noise and how to apply discrimination also arise.	I-Reply	I-2	Reply	1284
Our paper addresses these problems by [line_break_token](i) proposing shared encoder and word embedding between the generator and the discriminator.	I-Reply	I-2	Reply	1284
Existing works with seq2seq generator either use policy gradient (Li at.	I-Reply	I-2	Reply	1284
Al, 2016) with no end-to-end differentiability or approximate embedding layer (Xu et al 2017, Zhang et al 2018) which is memory and computationally intensive with large vocabulary size.	I-Reply	I-2	Reply	1284
 [line_break_token](ii) exploring noise injection at the word and utterance levels and discrimination at word level with RNN and at the utterance with CNN         [line_break_token][line_break_token]-- I do wonder why would the hredGAN model outperform the hred model on perplexity.	I-Reply	I-2	Reply	1284
Perhaps the improvement in perplexity (discussed above) is do to the use of attention.	O	O	Reply	1284
[line_break_token]We agree with your observation but due to space limitations, we only discussed this in the Ablation experiments in the Appendix.	B-Reply	B-3	Reply	1284
Indeed, the presence of attention in the model is responsible for the low perplexity but it didn‚Äôt address the lack of diversity until we introduced GAN.	I-Reply	I-3	Reply	1284
We will include the complete results for HRED+Attention in the ablation section for comparison in the final version.	I-Reply	I-3	Reply	1284
[line_break_token][line_break_token]-- In the paragraph between Eqns 2 and 3, the authors seem to suggest that teacher forcing is an added heuristic [line_break_token]We agree with the reviewer that teacher forcing is the actual evaluation of MLE objective.	B-Reply	B-6	Reply	1284
However, the problem of dialogue response generation is indeed autoregressive and not teacher forcing  (Please see Lamb et.	I-Reply	I-6	Reply	1284
al 2016 for details).	I-Reply	I-6	Reply	1284
During inference, Eq. (	I-Reply	I-6	Reply	1284
2) is used while Eq.(3) is used as a tractable and accurate approximation during training.	I-Reply	I-6	Reply	1284
This discrepancy, known as exposure bias has been the subject of several dialogue modeling papers (including Lamb et.	I-Reply	I-6	Reply	1284
al 2016 and references there in).	I-Reply	I-6	Reply	1284
[line_break_token]-- In discussing the combined MLE-GAN objective in Eqn.	O	O	Reply	1284
8 Does the MLE objective use teacher forcing?	O	O	Reply	1284
[line_break_token]Yes, the MLE objective uses teacher forcing as can be seen in Eq.(7).	B-Reply	B-7	Reply	1284
  [line_break_token][line_break_token]Let us know if you have additional questions while we collate and analyze the human evaluation as well as the HRED+Attention results.	O	O	Reply	1284

In many ways this work is well presented.	B-Review	B-1	Review	20282
However, I have major concerns regarding the novelty of the proposed method and the theoretical rationale for the key design choices.	I-Review	I-1	Review	20282
Although the authors do cite and discuss (Rosenbaum et al 2019), what is very much not clear to me is how the Gumbel-Matrix Routing proposed in this work differs from past work using the Gumbel Softmax within routing networks.	I-Review	I-1	Review	20282
It seems like past work even focused on using only the task for routing, so it is not clear to me how the approach here is really novel in comparison.	I-Review	I-1	Review	20282
Even if there is some distinction I am missing, the high level idea is clearly not that new.	I-Review	I-1	Review	20282
Additionally, there is not much theoretical discussion about what the Gumbel Softmax adds to routing networks.	I-Review	I-1	Review	20282
[line_break_token][line_break_token]The bias/variance tradeoff of Gumbel Softmax / RELAX / REINFORCE was already highlighted in (Rosenbaum et al 2019).	B-Review	B-2	Review	20282
Can the performance of the model on the settings tested be attributed to this tradeoff?	I-Review	I-2	Review	20282
If so, would a RELAX model perform even better?	I-Review	I-2	Review	20282
Moreover, there is not much discussion of important implications of using the Gumbel Softmax trick in the context of routing.	I-Review	I-2	Review	20282
First, as the authors acknowledge, but don't really elaborate on, using the Gumbel Softmax means we must backprop through every possible routing choice in each layer.	I-Review	I-2	Review	20282
As a result, the Gumbel approach results in a large scaling of computation with the number of modules, limiting the applicability to more ambitious settings.	I-Review	I-2	Review	20282
Moreover, while a clear motivation of this work is eliminating interference between tasks, it is not really explained how Gumbel Softmax does this and how it compares to hard routing decisions in this respect.	I-Review	I-2	Review	20282
During backprop, the computation it very similar to mixtures of experts models, and should contain more interference than hard routing.	I-Review	I-2	Review	20282
Can you explicitly show that the shape of the Gumbel distribution results in less interference between modules during learning than the standard mixtures of experts softmax approach?	I-Review	I-2	Review	20282
[line_break_token][line_break_token]Furthermore, (Rosenbaum et al 2019) found that a number of RL based models outperform Gumbel Softmax when routing on multi-task settings of CIFAR-100 and the Stanford Corpus of Implicatives.	B-Review	B-3	Review	20282
The authors do not provide any explanation for why this approach did not succeed in their settings.	I-Review	I-3	Review	20282
This also leads me to doubt how impressive the results presented here are as there is really not any apples to apples comparison with the same architecture and different routing decisions.	I-Review	I-3	Review	20282
In Tables 1 and 2 the best baseline is full sharing.	I-Review	I-3	Review	20282
This indicates to me that the performance difference with other cited baselines has to do with different architecture choices and not changes in the routing policy itself.	I-Review	I-3	Review	20282
The experiments can be much improved by discussing why past approaches to Gumbel based routing have failed and by thoroughly comparing to other methods for just the routing decisions with the same base architecture as done in prior work.	I-Review	I-3	Review	20282
 Unfortunately, in its current form, there is not enough context provided for the community to understand the implications of the proposed approach in the submitted draft even though it achieves good performance.	I-Review	I-3	Review	20282
e thank the reviewer for the valuable comments.	O	O	Reply	20282
Our responses to specific comments are provided below.	O	O	Reply	20282
[line_break_token][line_break_token]1) Novelty of our method[line_break_token][line_break_token]We agree that the Gumbel trick and the Gumbel-Softmax routing method is not new.	B-Reply	B-1	Reply	20282
In this work, we propose a new method for multi-task learning and not a new routing method.	I-Reply	I-1	Reply	20282
[line_break_token][line_break_token]While Gumbel-based routing has been already applied to multi-task learning, we claim that our formulation (in its full form) is novel for the following reasons:[line_break_token]- We learn flexible parameter sharing among tasks by learning binary allocation matrices indicating how each component is allocated to each task.	I-Reply	I-1	Reply	20282
This is in contrast to previous works, which typically consider routing with a sequence of decisions ‚Äúwhere to route‚Äù.	I-Reply	I-1	Reply	20282
We argue that our formulation is more natural for multi-task learning, as it provides an explicit way to control parameter sharing between tasks (depending on their relatedness).	I-Reply	I-1	Reply	20282
Right now we condition on the task id, but in the future we envision conditioning on task embeddings, which can better capture the relatedness of the tasks.	I-Reply	I-1	Reply	20282
[line_break_token]- Moreover, we also introduced ways to regularize our method such as the budget penalty (see Section 4.4) that promotes sparsity of the allocation solution.	I-Reply	I-1	Reply	20282
[line_break_token][line_break_token]Since the proposed method is a new method for multi-task learning (and not a new routing method), we argue that evaluating different routing solvers (such as REINFORCE or RELAX) goes beyond the scope of this work.	I-Reply	I-1	Reply	20282
However, it is a very interesting direction and it will definitely be the focus of our future work.	I-Reply	I-1	Reply	20282
As per reviewer‚Äôs suggestion, this may further improve the results.	I-Reply	I-1	Reply	20282
[line_break_token][line_break_token]2) Hard vs soft routing decisions[line_break_token][line_break_token]Please note that our method does use hard decisions, since we use the Straight-Through variant of the Gumbel-Softmax trick (the original Gumbel-Softmax paper introduces both the soft variant, and the Straight-Through variant).	B-Reply	B-2	Reply	20282
If a connection is sampled to be inactive, the corresponding component will not contribute to the output and therefore will not get gradients.	I-Reply	I-2	Reply	20282
It will only be used to compute the gradient for the per-connection routing probability.	I-Reply	I-2	Reply	20282
[line_break_token][line_break_token]3) Comparing apples to apples[line_break_token][line_break_token]We believe that the Omniglot experiment is an apples-to-apples comparison, since we re-used the same architecture that achieved the previous SotA (‚ÄúDiversity and Depth in Per-Example Routing Models‚Äù, ICLR 2019).	B-Reply	B-3	Reply	20282
We made sure that we reproduced all the details by contacting the authors of that prior work; we also used the same regularization strategies and the same optimizer.	I-Reply	I-3	Reply	20282
The only difference is the routing method.	I-Reply	I-3	Reply	20282
[line_break_token][line_break_token]4) Scalability[line_break_token][line_break_token]It is indeed the case that due to the use of Gumbel-Softmax, the backward pass needs to activate all of the components of the model.	I-Reply	I-3	Reply	20282
Hence, the training phase of our method is more expensive than for other sparse baselines (such as the sparsely-gated mixture-of-experts).	I-Reply	I-3	Reply	20282
[line_break_token]However, it is important to note that inference phase of our method is pretty scalable, since it uses hard decisions (and the budget penalty promotes even sparser solutions).	I-Reply	I-3	Reply	20282
Therefore, we argue that our method is practical for many multi-task learning applications	I-Reply	I-3	Reply	20282

[line_break_token]This paper trains low-precision network with quantized weights and quantized activation.	O	O	Review	437
The main idea is to split the scale and quantized values.	O	O	Review	437
Both scales and weights are updated with backprop and SGD.	O	O	Review	437
The paper presents excellent experimental results on ImageNet.	O	O	Review	437
[line_break_token][line_break_token]The paper is generally well written and easy to follow.	O	O	Review	437
However, there does exist quite some grammar errors, especially in abstract, which could be improved.	B-Review	B-1	Review	437
[line_break_token][line_break_token]Moreover, I would like the authors to clarify some technical details.	B-Review	B-2	Review	437
Are the scales s, so called step size in the paper, for every weight, every convolutional kernel, or very layer?	I-Review	I-2	Review	437
How do you deal with BatchNorm?	I-Review	I-2	Review	437
[line_break_token][line_break_token]What is the main benefits of the proposed quantization method in general?	B-Review	B-3	Review	437
Is it for fast inference, fast training, or just memory compression?	I-Review	I-3	Review	437
Do the authors see the real benefits in practice besides claiming the accuracy does not drop?	I-Review	I-3	Review	437
[line_break_token][line_break_token]I would suggest the authors discuss and compare with XNOR network in detail.	B-Review	B-4	Review	437
The proposed method looks similar.	I-Review	I-4	Review	437
[line_break_token][line_break_token]I am wondering how the baseline methods are tuned.	B-Review	B-5	Review	437
There are quite a few ‚Äútricks‚Äù like learning rate scheduler and weight decay, which I do consider them as contributions of the paper.	I-Review	I-5	Review	437
But would baseline methods also benefit from more hyper-parameter tuning?	I-Review	I-5	Review	437
[line_break_token][line_break_token]Minor issue, I donot get the explanation of eq (4), and it looks rather unnecessary.	B-Review	B-6	Review	437
It sounds to me starting from a trained network and then train 90 epochs is a rather long time.	I-Review	I-6	Review	437
Could the authors convince me this is a standard setting by providing some reference?	I-Review	I-6	Review	437
[line_break_token][line_break_token][line_break_token]================ after rebuttal=========================[line_break_token]Thank the authors for reply.	O	O	Review	437
My rating does not change.	O	O	Review	437
The proposed does look similar to XNOR, and the only difference seems to be how the scales are updated.	B-Review	B-4	Review	437
Since there is only one scale per layer, I will be quite surprised if the proposed method can be much better than XNOR.	I-Review	I-4	Review	437
Moreover, since BatchNorm is not quantized and it is everywhere in a ResNet-like architecture, it surprises me how much the scale helps.	I-Review	I-4	Review	437
Finally, I am worried about practical benefits towards the authors' claim because the networks are not fully quantized.	I-Review	I-4	Review	437
[line_break_token]	O	O	Review	437
We have carefully read through the manuscript to look for and fix grammatical issues.	B-Reply	B-1	Reply	437
 If the reviewer points out any specific issues that remain, we will be happy to fix them to improve the manuscript.	I-Reply	I-1	Reply	437
[line_break_token][line_break_token]There is one step size for each layer of weights (that is, for each weight tensor) and one step size for each layer of activations.	B-Reply	B-2	Reply	437
 This is noted in section 2.1 with the line "each layer of weights and each layer of activations has a distinct step size".	I-Reply	I-2	Reply	437
 BatchNorm is handled using full precision operations.	I-Reply	I-2	Reply	437
 We have updated the text in section 2.3 to clarify this point.	I-Reply	I-2	Reply	437
[line_break_token][line_break_token]The proposed method offers 2 main benefits.	B-Reply	B-3	Reply	437
 First, it allows for a reduction in model size, facilitating the deployment deep networks operating on the edge (for example, in mobile phones).	I-Reply	I-3	Reply	437
 Second, it points to the value of developing next generation inference hardware optimized for low precision operations to improve throughput and energy efficiency, while reducing latency.	I-Reply	I-3	Reply	437
 As we also note in our response to Review #2, we believe it is the correct first step to demonstrate the ability of deep networks to achieve high accuracy at these extremely low precisions before inference chips optimized for these precisions is commercially available.	I-Reply	I-3	Reply	437
 As such hardware becomes available, we look forward to benchmarking these low precision networks against full precision alternatives.	I-Reply	I-3	Reply	437
 [line_break_token][line_break_token]We now highlight the importance of XNOR in the introduction by noting it provided the first demonstration of tuned quantization.	B-Reply	B-4	Reply	437
 XNOR differs from our approach in that the former employs a quantizer tuned based on data statistics, in approach later taken by techniques such as TWN, Dorefa, FAQ, and Half-wave gaussian quantization, while the latter learns the quantization through backpropagation, which is noted in the introduction.	I-Reply	I-4	Reply	437
[line_break_token][line_break_token]Providing a comparison between various quantization methods using exactly the same weight decay or learning rate schedule is difficult, as there is no standardization across prior papers on settings.	B-Reply	B-5	Reply	437
 Properly re-implementing and re-running methods from prior papers can be challenging if even trivial details (for example, initial values) are missing from the original publications, and even if done properly, it is possible that different weight decay values or schedulers are optimal for different methods.	I-Reply	I-5	Reply	437
 However, we have sought to address this as best we can by showing our results at different weight decay values and showing the simple power of 2 search that was employed to find the weight decays chosen (Table 2).	I-Reply	I-5	Reply	437
 Notably, our approach still out performs the next best method even when using a weight decay of 10^-4, which is fairly standard for a full precision ResNet-18.	I-Reply	I-5	Reply	437
 We also ran an experiment using a more traditional step-based weight decay (Section 3.5), and found that again our approach still out performs that next best method (with only 90 epochs of fine-tuning, compared to a total of 360 epochs of fine-tuning for the next best method).	I-Reply	I-5	Reply	437
[line_break_token][line_break_token]If of interest, Table 3 explores the value of the gradient adjustment derived from Equation 4, and shows that it is important for achieving high accuracy.	B-Reply	B-6	Reply	437
[line_break_token][line_break_token]Relatively long fine-tuning in the quantized space after initializing from a full precision trained network is fairly common when targeting networks with less than 8-bits of precision, and in fact the 90 epochs we employ is on the short side.	I-Reply	I-6	Reply	437
 For example  Choi et al ("Learning low precision deep neural networks through regularization") fine-tuned for 100 epochs, McKinstry et al ("Discovering low-precision networks close to full- precision networks for efficient embedded inference") fine-tuned for 110 epochs, Baskin et al ("Nice: Noise injection and clamping estimation for neural network quantization") fine-tuned for 120 epochs, and Jung et al ("Joint training of low-precision neural network with quantization interval parameters") used a progressive quantization approach that amounted to a total of 360 additional epochs of fine-tuning for 2-bit models	I-Reply	I-6	Reply	437

The paper proposes to make a clear connection between the InfoNCE learning objective (which is a lower bound of the mutual information) and multiple language models like BERT and XLN.	O	O	Review	20150
Then based on the observation that classical LM can be seen as instances of InfoNCE, they propose a new (InfoWord) model relying on the same principles, but taking inspiration from other models also based on InfoNCE.	O	O	Review	20150
Mainly, the proposed model  differs both in the nature of the a and b variables used in InfoNCE, and also on the fact that it uses negative sampling instead of softmax.	O	O	Review	20150
Experiments are made on two tasks and compared to a classical BERT model, and on the BERT-NCE model that is a BERT variant proposed by the authors which is somehow in-between BERT and InfoWord.	O	O	Review	20150
They show that their approach works quite well.	O	O	Review	20150
[line_break_token][line_break_token]I have a very mitigated opinion on the paper.	B-Review	B-1	Review	20150
I) First, I really like the idea of trying to unify different models under the same learning principles, and then show that these models can be seen as specific instances of generic principles.	I-Review	I-1	Review	20150
But the way it is presented and explained lacks of clarity: for instance in Section 2, some notations are not well defined (e.g what is f?) .	I-Review	I-1	Review	20150
Moreover, the way classical models are casted under the InfoNCE principle is badly written: it assumes that readers have a very good knowledge of the models, and the paper does not show well the mapping between the loss function of each model and the InfoNCE criterion.	I-Review	I-1	Review	20150
It gives technical details that could (in my opinion) get ignored, and I would clearly prefer to catch the main differences between the different models that being flooded by technical details.	I-Review	I-1	Review	20150
So, my suggestion would be to improve the writing of this section to make the message stronger and relevant for a larger audience.	I-Review	I-1	Review	20150
II) The Infoword model can be seen as a simple instance of word masking based models, and as an extension of deep infomax for sequences (it would be certainly nice to describe a little bit what Deep InfoMax is to facilitate the reading).	I-Review	I-1	Review	20150
 Here again, the article moves from technical details (e.g "hidden state of the first token (assumed to be a special start of sentence symbol ") without providing formal definitions.	I-Review	I-1	Review	20150
Having a first loss function after paragraph 4 could help to understand the principle of this model (before restricting the model to n-grams).	I-Review	I-1	Review	20150
 Moreover, the equation J_DIM seems to be wrong since it contains g_\omega twice while I think (but maybe I am wrong) that it has also to be defined by g_\psi.	I-Review	I-1	Review	20150
J_MLM is also not clear since x_i is never defined (I assume it is x_{i:i}).	I-Review	I-1	Review	20150
At last,  after unifying multiple models under one common learning objective, the authors propose to mix two different losses which is strange (the effect of the second term is slightly studied in the experimental section) without allowing us to understand why it is important to have this second loss function and why the first one is not sufficient enough.	I-Review	I-1	Review	20150
At last, I am pretty sure to not be able to reproduce the model described in the paper (adding a section on that in the supplementary material would help), and many concrete aspects are described too fast (like the way to sample negative pairs).	I-Review	I-1	Review	20150
[line_break_token][line_break_token]Concerning the experimental section, experiments are convincing and show that the model is able to achieve a performance which is close to classical models.	O	O	Review	20150
In my opinion, tis section has to be interpreted as  a proof that the proposed unified vision is a good way to easily define new and efficient models.	O	O	Review	20150
[line_break_token][line_break_token]To summarize, the unification under the InfoNCE principle is interesting,  but the way the paper is written makes it very difficult to follow, and the description of the proposed model is unclear (making the experiments difficult to reproduce) and lacks of a better discussion about the interest of mixing multiple loss.	B-Review	B-2	Review	20150
[line_break_token][line_break_token][line_break_token]	O	O	Review	20150
hank you for your thoughtful review.	O	O	Reply	20150
[line_break_token][line_break_token]We have updated the paper based on your comments to improve clarity and reproducibility.	B-Reply	B-1	Reply	20150
We list a summary of our main changes below:[line_break_token]- In order to make it easier for readers to understand the differences between different models and how they are related to InfoNCE, we have added a summary in Table 1.	I-Reply	I-1	Reply	20150
[line_break_token]- We have improved notations by adding explicit definitions before they are used in Section 2 and Section 4, and added a short description of Deep InfoMax in Section 4.	I-Reply	I-1	Reply	20150
[line_break_token]- We have included model and training hyperparameter details in Section 5.1 and Appendix B.[line_break_token]- We added a motivation for mixing two different terms in the objective function.	I-Reply	I-1	Reply	20150
Our DIM is primarily designed to improve sentence and span representations.	I-Reply	I-1	Reply	20150
We combine it with MLM which is designed for learning (contextual) word representations, since our overall goal is to create better representations for both the sentence and each word in the sentence.	I-Reply	I-1	Reply	20150
We also note that Deep InfoMax for learning image representations mixes multiple terms in their objective function.	I-Reply	I-1	Reply	20150
We only take one of the terms from the full objective function and mix it with MLM.	I-Reply	I-1	Reply	20150
[line_break_token][line_break_token]Regarding equation I_{DIM}, it is supposed to contain two g_{\omega} and no g_{\psi} as we use one network for encoding both the sentence and n-grams.	I-Reply	I-1	Reply	20150
This is not a typo.	I-Reply	I-1	Reply	20150

This paper is well written, and the quality of the figures is good.	O	O	Review	631
In this paper, the authors propose an invariant-covariant idea, which should be dated back at least to the bilinear models.	O	O	Review	631
The general direction is important and should be pursued further.	O	O	Review	631
[line_break_token][line_break_token]However, the literature is not well addressed.	B-Review	B-1	Review	631
Eslami et al 2018 have been cited, but some very important and related earlier works like: [line_break_token][1] Kulkarni et al 2015, Deep Convolutional Inverse Graphics Network[line_break_token][2] Cheung et al 2015, Discovering Hidden Factors of Variation in Deep Networks[line_break_token]were not discussed at all.	I-Review	I-1	Review	631
The authors should certainly make an effort to discuss the connections and new developments beyond these works.	I-Review	I-1	Review	631
At the end of section 1, the authors argue that the covariant vector could be more general, but in fact, these earlier works can achieve further equivalence, which is much stronger than the proposed covariance.	I-Review	I-1	Review	631
[line_break_token][line_break_token]There is also an effort to compare this work to Sabour et al 2017 and the general capsule idea.	B-Review	B-2	Review	631
I would like to point out, the capsule concept is a much more fine-grained what & where separation rather than a coarse-grained class & pose separation in one shot.	O	O	Review	631
In a hierarchical representation, what & where can appear at any level as one class can consist of several parts each with a geometrical configuration space.	O	O	Review	631
So the comparison of this work to the generic capsule network is only superficial if the authors can not make the proposed architecture into a hierarchical separation.	B-Review	B-2	Review	631
Besides different capsule network papers, I found another potentially useful reference on a fine-grained separation:[line_break_token][3]Goroshin et al Learning to Linearize Under Uncertainty[line_break_token][line_break_token]In the paper, it is argued several times that the latent vector r_y contains a rich set of global properties of class y, rather than just its label and the aim is that it can learn what the elements of the class manifold have in common.	O	O	Review	631
But this point is not supported well since we can always make a label and this latent vector r_y equivalent by a template.	B-Review	B-3	Review	631
I think this point could be meaningful if we look at r_y's for different y, where each of the dimension may have some semantic meaning.	I-Review	I-3	Review	631
Additional interpretation is certainly needed.	I-Review	I-3	Review	631
[line_break_token][line_break_token]Under equation (3), "Note that v is inferred from r_y" should be "inferred from both r_y and x", which is pretty clear from the fig 5.	B-Review	B-4	Review	631
Related to this, I could imagine some encoder can extract the 'style' directly from x, but here both r_y and x are used.	I-Review	I-4	Review	631
I couldn't find any guarantee that v only contains the 'style' information based on the architecture with even this additional complication, could the authors comment on this?	I-Review	I-4	Review	631
[line_break_token][line_break_token]Equation (5) is not really a marginalization and further equation (6) may not be a lower bound anymore.	B-Review	B-5	Review	631
This is probably a relatively minor thing and a little extra care is probably enough.	I-Review	I-5	Review	631
[line_break_token][line_break_token]The numbers in table 2 seems a little outdated.	B-Review	B-6	Review	631
[line_break_token][line_break_token]To conclude, I like the general direction of separating the identity and configurations.	O	O	Review	631
The natural signals have hierarchical structures and the class manifold concept is not general enough to describe the regularities and provide a transparent representation.	B-Review	B-2	Review	631
Rather, it's a good starting point.	B-Review	B-1	Review	631
If the authors could carefully address the related prior works and help us understand the unique and original contributions of this work, this paper could be considered for publication.	I-Review	I-1	Review	631
We appreciate deeply the reviewer's detailed feedback.	O	O	Reply	631
The reviewer made a number of useful suggestions to improve this submission, of which we felt that the most prominent theme was improving our discussion and comparison to the literature.	O	O	Reply	631
We discuss this first.	O	O	Reply	631
[line_break_token][line_break_token]Overall, we have included 9 new references to the literature along with discussion in Section 1, which has been significantly modified.	B-Reply	B-1	Reply	631
In particular, we discuss the two important references [1] and [2] provided by the reviewer.	I-Reply	I-1	Reply	631
Indeed these two references are able to separate more structure into their latent variables (for data sets that contain structured labels for different variations of the data) using a 'clamping' technique during training to force particular latent components to be disentangled (as in [1]), or by predicting the labels and using a cross-covariance term in the objective function of their deterministic autoencoder (as in [2]).	I-Reply	I-1	Reply	631
Similarly, we discuss InfoGAN (Chen et al, 2016), which achieves disentanglement by adding a mutual-information maximisation term between the meaningful latent and the model generations.	I-Reply	I-1	Reply	631
We consider the simplicity of our probabilistic model, trained with log-likelihood maximisation (no additional objective function hyperparameters), augmented only with a complementary batch of same-class data for each training data point, to be attractive in comparison to these other approaches.	I-Reply	I-1	Reply	631
[line_break_token][line_break_token]However, there are other significant differences.	I-Reply	I-1	Reply	631
One major difference is that our invariant representation takes as input multiple data points that come from the same class, but are different from the reconstructed data point.	I-Reply	I-1	Reply	631
Thus, our invariant representation directly learns to encode the information common to the overall class, but not the individual data point.	I-Reply	I-1	Reply	631
This is why there is no need for clamping or cross-covariance / mutual information penalty terms in our objective function: there is no way for the invariant representation to store data-point specific information due to the information flow through it.	I-Reply	I-1	Reply	631
In further contrast to some of the other approaches in the literature, we deliberately use a deterministic latent for the class-invariant information, and a stochastic latent for the smooth 'style' information (an idea employed by Zhu et al (2014), for their binary neurons).	I-Reply	I-1	Reply	631
This modelling choice is why we do not need to force the equivariant latent to not contain any class-level information (which is clear from our results) because it is available and easier to access from the deterministic latent.	I-Reply	I-1	Reply	631
This last point was a question raised by the reviewer which we have addressed with an added discussion after Equation 3 in Section 2.	I-Reply	I-1	Reply	631
[line_break_token][line_break_token]..	O	O	Reply	631

#Summary[line_break_token][line_break_token]This paper proposes a generalised self-training framework to build a Graph Neural Network to label graphs.	O	O	Review	330
 Of importance is the dynamic nature of the self-training.	O	O	Review	330
The authors do not change the GCN but extend the self-training portion as per the prior GCN paper by introducing Dynamic Self-Training that keeps a confidence score of labels predicted for unlabelled nodes.	O	O	Review	330
[line_break_token][line_break_token]# Comments[line_break_token][line_break_token]This is a very interesting paper in terms of looking at the effects of changing the self-training framework to better utilise the underlying structure.	O	O	Review	330
As such we can exploit information from other nodes that are yet to be labelled.	O	O	Review	330
[line_break_token][line_break_token]1.	O	O	Review	330
As the self-training is going on, are there different computational costs or are they about the same?	B-Review	B-1	Review	330
[line_break_token]2.	O	O	Review	330
For CiteSeer 20 and 50, why does \beta = 0.45 switch from the other experiments?	B-Review	B-2	Review	330
[line_break_token]3.	O	O	Review	330
Will such self-training be useful for general NN self-training procedures[line_break_token]4.	O	O	Review	330
If we had soft-labelling or uncertainty on which label each node has, how would the dynamic self-training be changed?	B-Review	B-4	Review	330
[line_break_token][line_break_token]#Other notes[line_break_token]Please remove the [line_break_token][line_break_token]An appendix[line_break_token]You may include other additional sections here	B-Review	B-5	Review	330
e thank the reviewer for the constructive comments.	O	O	Reply	330
[line_break_token][line_break_token]1. "	O	O	Reply	330
As the self-training is going on, are there different computational costs or are they about the same?"	O	O	Reply	330
[line_break_token]The computational costs is only slightly increased.	B-Reply	B-1	Reply	330
The reason is that the computational cost of the original GCN model is dominated by previous layers, where the entire graph is included.	I-Reply	I-1	Reply	330
So even if all nodes become pseudo labels, the size of the entire network is increased by at most a factor of 2, and the number of parameters remains the same.	I-Reply	I-1	Reply	330
Therefore, the computational costs will increase by at most a small constant in theory.	I-Reply	I-1	Reply	330
We have also verified this empirically.	I-Reply	I-1	Reply	330
We record the training time of GCN and GAT before and after applying our framework.	I-Reply	I-1	Reply	330
In the experiments, the training size is 20 per class, the number of epochs is 200, and the time is the average time (in seconds) of 25 runs.	I-Reply	I-1	Reply	330
[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]Cora       [line_break_token]           GCN        2.6[line_break_token]         DSGCN     6.3[line_break_token]           [line_break_token]           GAT        4.7[line_break_token]         DSGAT     8.7[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]    Citeseer[line_break_token]          GCN         3.0[line_break_token]         DSGCN     9.7[line_break_token][line_break_token]         GAT           5.2[line_break_token]        DSGAT      11.9[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token]2. "	O	O	Reply	330
For CiteSeer 20 and 50, why does \beta = 0.45 switch from the other experiments?"	O	O	Reply	330
[line_break_token]We didn‚Äôt use \beta = 0.45 for CiteSeer 20 and 50.	B-Reply	B-2	Reply	330
As explicitly explained in the paper, we use a threshold of 0.6 when the number of labels per class is below 3 and set the threshold to 0.75 for label rate above 3 but below 10.	I-Reply	I-2	Reply	330
Otherwise, the threshold is 0.9 by default.	I-Reply	I-2	Reply	330
In Figure 1, \beta=0.45 here is used for comparison with other thresholds on various label rate.	I-Reply	I-2	Reply	330
We are sorry for any ambiguity in the paper.	I-Reply	I-2	Reply	330
[line_break_token][line_break_token][line_break_token]3. "	O	O	Reply	330
Will such self-training be useful for general NN self-training procedures"[line_break_token]We believe our self-training method will be useful for general NN training, although we think it is most effective for GNN models.	B-Reply	B-3	Reply	330
We have tested our self-training methods on other GNNs, e.g., GraphSage, GAT, SGC, and some preliminary results are as follows.	I-Reply	I-3	Reply	330
[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                                                  Cora[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                              5            10              20             50         [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]GraphSage       69.3         75.3          79.2          82.5[line_break_token]DSGraphSage  72.5         78.4          81.0          84.0[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]GAT                    71.1         76.0          79.6          83.4[line_break_token]DSGAT               71.9         77.1          81.0          83.6[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]SGC                    63.5         72.5         75.9          78.9[line_break_token]DSSGC               65.0         73.4         76.2          78.9    [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                                             Citeseer[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                               5             10           20             50         [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]GraphSage        59.7        65.4         68.8          72.1[line_break_token]DSGraphSage   60.6        66.3         69.5          72.6[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]GAT                     54.9        60.8         68.2          71.5[line_break_token]DSGAT                58.3        67.0         70.8          73.5[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]SGC                     55.5        63.7         69.0           72.6[line_break_token]DSSGC                59.6        65.0         69.7           73.4        [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token][line_break_token]4. "	O	O	Reply	330
If we had soft-labelling or uncertainty on which label each node has, how would the dynamic self-training be changed?"	O	O	Reply	330
[line_break_token]In general, we can treat all original labels as ‚Äúpseudo labels‚Äù as well.	B-Reply	B-4	Reply	330
We just need a mechanism to determine the initial confidence of these labels and then all labels in the training set can be treated equally.	I-Reply	I-4	Reply	330

In this paper, the authors proposed methodologies to identify mislabeled training examples.	O	O	Review	20355
Specifically, the authors proposed to examine the training loss of each example to identify examples with high training losses.	O	O	Review	20355
To mitigate the randomness in the training loss, the authors proposed an AUL (area under the loss) metric, which is less noisy that directly examining the loss.	O	O	Review	20355
The authors proposed to use Gaussian mixture to approximate the AUL distribution, and then estimate the probability of mislabeling.	O	O	Review	20355
The authors proposed to downweight training examples with high likelihood of being mislabeled.	O	O	Review	20355
The proposal is examined in numerical studies.	O	O	Review	20355
[line_break_token][line_break_token]While I agree the method has a good potential to be significant, in its current form, I have several concerns that prevent me from recommending acceptance.	O	O	Review	20355
[line_break_token]1.	O	O	Review	20355
How can we be sure that examples with large training loss are mislabeled examples, rather than examples that are inherently difficult to classify?	B-Review	B-1	Review	20355
For example, if the dataset consists of 99% bright images and 1% dark images, then it could be possible that dark image training examples have a higher loss.	I-Review	I-1	Review	20355
This question becomes more relevant when the model does not have sufficient complexity, or does not have the correct form of complexity.	I-Review	I-1	Review	20355
[line_break_token]2.	O	O	Review	20355
If we cannot distinguish mislabeled examples with examples that are hard to classify, then it seems to me that a simple downweighting based on AUL could potential lead to the opposite outcome.	B-Review	B-2	Review	20355
Intuitively, we should upweight those difficult to classify examples to improve generalizability.	I-Review	I-2	Review	20355
[line_break_token]3.	O	O	Review	20355
It is somewhat surprising to me that the AUL distribution is a nicely looking bimodal shape.	B-Review	B-3	Review	20355
Could it be due to the fact that the wrong labels are randomly generated with equal probabilities from other classes?	I-Review	I-3	Review	20355
What it we have a different error distribution, e.g., the label has p probability of being correct, and (1-p) probability of being k, where k is a constant?	I-Review	I-3	Review	20355
[line_break_token]4.	O	O	Review	20355
Given the above concerns, I feel the numerical studies are insufficient.	B-Review	B-4	Review	20355
The authors may consider 1) including more noise distributions, 2) presenting the AUL distributions to check whether they are truly bimodal, and 3) trying more datasets and more model architectures.	I-Review	I-4	Review	20355
hank you for your review.	O	O	Reply	20355
We hope that we are able to clarify some misunderstanding and address your comments.	O	O	Reply	20355
[line_break_token][line_break_token]W.R.T. ‚Äúhard‚Äù clean examples: From our observations, it appears that ‚Äúhard‚Äù examples have higher AUL than most clean examples, but lower AUL than mislabeled examples. (	B-Reply	B-1	Reply	20355
Intuitively, this makes sense, because truly mislabeled examples will be the hardest for the network to generalize to.)	I-Reply	I-1	Reply	20355
Therefore, hard samples will be downweighted some, but not as much as noisy examples.	I-Reply	I-1	Reply	20355
We would note that curriculum learning (e.g. Bengio et al, ICML 2019; Hacohen and Weinshall, ICML 2019) similarly down-weights (rather than up-weights) difficult examples until the end of training.	I-Reply	I-1	Reply	20355
To some extent AUL-based downweighting will have a similar effect: the network will not reduce the loss of difficult examples until the high-weight easy examples have sufficiently low loss.	I-Reply	I-1	Reply	20355
[line_break_token][line_break_token]W.R.T. other noise models: Please refer to our ‚Äúpair flip‚Äù experiments in Figure 7 and Table 1.	B-Reply	B-2	Reply	20355
These experiments are exactly the noise model you propose (p probability of being correct, and (1-p) probability of being k).	I-Reply	I-2	Reply	20355
We note that our proposed method is adept at estimating and correcting for label error in this setting as well.	I-Reply	I-2	Reply	20355
[line_break_token][line_break_token]W.R.T. presenting AUL distributions: we observed the bimodal behavior for both CIFAR10 and CIFAR100 on all experiments that we performed - regardless of noise model, noise percentage, or network architecture.	B-Reply	B-3	Reply	20355
We will update the paper with additional plots that demonstrate this bimodality.	I-Reply	I-3	Reply	20355
[line_break_token][line_break_token]W.R.T. real-world datasets: To demonstrate our method‚Äôs applicability on real-world (non-image) datasets, we trained a model on a Machine Translation dataset (IWSLT14 German-to-English dataset).	B-Reply	B-4	Reply	20355
AUL determines that roughly 25 training samples have an incorrect target (the English sentence in the translation pair).	I-Reply	I-4	Reply	20355
Typically, these targets are not English and therefore are mislabeled.	I-Reply	I-4	Reply	20355
For example:[line_break_token][line_break_token]SOURCE: vielen dank .	I-Reply	I-4	Reply	20355
[line_break_token]TARGET: merci beaucoup .	I-Reply	I-4	Reply	20355
[line_break_token][line_break_token]SOURCE: google glass : aroi mann 9 : mmm , aroi .	I-Reply	I-4	Reply	20355
[line_break_token]TARGET: google glass : ‡∏≠‡∏£ ‡πà ‡∏≠‡∏¢man 9 : mmm , ‡∏≠‡∏£ ‡πà ‡∏≠‡∏¢	I-Reply	I-4	Reply	20355

&lt;Paper summary&gt;[line_break_token]The authors proposed Distribution Matching Prototypical Network (DMPN) for unsupervised domain adaptation.	O	O	Review	20179
DMPN extracts features from the input data and models them as Gaussian mixture distributions.	O	O	Review	20179
By explicitly modeling the distributions that the features follow, the discrepancy between the distribution of source data and that of target data can be easily evaluated.	O	O	Review	20179
DMPN is trained by jointly minimizing two kinds of loss, which are classification loss on the source data and domain discrepancy loss that is calculated via the explicit models.	O	O	Review	20179
Experimental results on two popular benchmark datasets validate the advantage of DMPN over other state-of-the-art methods.	O	O	Review	20179
[line_break_token][line_break_token]&lt;Review summary&gt;[line_break_token]The proposed method seems simple but empirically performs well.	O	O	Review	20179
The paper is well written and easy to follow, so we can maybe easily implement it.	O	O	Review	20179
However, I have several concerns mainly about the details and theories of the proposed method, which makes my score a bit lower than the border line.	O	O	Review	20179
Given clarifications in an author response, I would be willing to increase the score.	O	O	Review	20179
[line_break_token][line_break_token]&lt;Details&gt;[line_break_token]* Strength[line_break_token] + The motivation of using ProtoNet for domain adaptation seems reasonable.	O	O	Review	20179
[line_break_token] + The proposed method performs well in the experiments.	O	O	Review	20179
[line_break_token] + The paper, especially the experiment section, is well written and easy to follow.	O	O	Review	20179
[line_break_token][line_break_token][line_break_token]* Weakness and concerns[line_break_token] - Several points on the proposed loss (GCMM and PDM) are not sufficiently discussed.	B-Review	B-1	Review	20179
[line_break_token]  -- Why do we need two kinds of loss?	B-Review	B-2	Review	20179
These losses seem to play almost same role.	I-Review	I-2	Review	20179
Since PDM loss corresponds to target-side log likelihood regularization term (Eq. (	I-Review	I-2	Review	20179
3)), I wonder if we really need GCMM loss.	I-Review	I-2	Review	20179
[line_break_token]  -- Since the authors explicitly model the feature distributions by Gaussian mixtures (GMs), it might be possible to calculate a standard divergence between source and target data distributions by using the parameters of GMs.	B-Review	B-3	Review	20179
Compared with such a straightforward approach, the proposed method seems to be ad-hoc and is not theoretically validated.	I-Review	I-3	Review	20179
What term of divergence (or distance) does it minimize?	I-Review	I-3	Review	20179
[line_break_token]  -- When a certain class does not appear in pseudo-labeled target data, how can we calculate GCMM loss? (	B-Review	B-4	Review	20179
specifically, \mu^{et}_c)[line_break_token]  -- Are Eq. (	B-Review	B-5	Review	20179
3) and Eq. (	I-Review	I-5	Review	20179
6) correct?	I-Review	I-5	Review	20179
These are defined as total loss, not average, over each domain.	I-Review	I-5	Review	20179
It means that the scale of the coefficients for these terms changes according to the number of training data, but the sensitivity analysis in Fig.	I-Review	I-5	Review	20179
2 does not show such effect.	I-Review	I-5	Review	20179
[line_break_token]  -- Since the proposed losses heavily depend on the pseudo labels on the target data, it should be important to carefully set a proper threshold for the confidence.	B-Review	B-6	Review	20179
Is the proposed method sensitive against the change of this threshold?	I-Review	I-6	Review	20179
If so, how can we tune it?	I-Review	I-6	Review	20179
[line_break_token]  -- How can we know p(c) in advance?	B-Review	B-7	Review	20179
[line_break_token][line_break_token] - The theory shown in 3.5 is not sufficiently validated.	B-Review	B-8	Review	20179
[line_break_token]  -- The authors state ````we minimize the first term through minimizing the domain discrepancy losses," but it is not sufficiently supported, because the relationship between the proposed losses and H-delta-H divergence is not clear.	B-Review	B-9	Review	20179
[line_break_token][line_break_token] - I am concerned about whether the proposed method works well with harder datasets such as Office-Home dataset, because each class data are modeled by a simple Gaussian distribution in the proposed method.	B-Review	B-10	Review	20179
[line_break_token][line_break_token][line_break_token]* Minor concerns that do not have an impact on the score[line_break_token] - Using both f^s_i and F(x^s_i; \theta) is confusing.	O	O	Review	20179
[line_break_token] - Typo in Eq. (	B-Review	B-11	Review	20179
7): PMD -&gt; PDM[line_break_token]	O	O	Review	20179
hanks for reviewing our paper and your appreciation of our idea.	O	O	Reply	20179
Here we answer your concerns and clarify some of the weak points you mentioned:[line_break_token][line_break_token]1).	O	O	Reply	20179
These two losses actually serve with different purposes when we design them.	B-Reply	B-2	Reply	20179
The GCMM loss brings the two distribution closer via minimizing the corresponding Gaussian Component means of the source and target data.	I-Reply	I-2	Reply	20179
And the PDM loss shapes the target feature distribution similar as the source feature distribution via minimizing the likelihood of generating the target feature from the source feature distribution.	I-Reply	I-2	Reply	20179
In this sense, they complement each other, to match the target feature distribution to be exactly like the source feature distribution.	I-Reply	I-2	Reply	20179
Furthermore, these two losses also reduce distribution discrepancy at different levels, GCMM reduces distribution discrepancy at the class-level and PDM reduces distribution discrepancy at the sample-level, thus in this sense, they also complete each other for domain adaptation.	I-Reply	I-2	Reply	20179
[line_break_token][line_break_token]2).	O	O	Reply	20179
We want to clarify here.	B-Reply	B-3	Reply	20179
Our method does not learn the distribution parameters for the target data.	I-Reply	I-3	Reply	20179
We learn the distribution parameters of the source data.	I-Reply	I-3	Reply	20179
We use the empirically calculated distribution parameter estimator of the source and target data to minimize the distribution discrepancy loss function.	I-Reply	I-3	Reply	20179
Thus, we cannot "calculate a standard divergence between source and target data distributions by using the parameters of GMs."	I-Reply	I-3	Reply	20179
For the GCMM loss, our method minimizes the euclidean distance between the corresponding Gaussian Component means of the source and target data for each class.	I-Reply	I-3	Reply	20179
PDM loss minimizes the likelihood of generating the target feature with the source feature distribution.	I-Reply	I-3	Reply	20179
[line_break_token][line_break_token]3).	O	O	Reply	20179
We will ignore data from that class in the batch in that training iteration.	B-Reply	B-4	Reply	20179
As training data are sampled randomly in each iteration, and in the end, all data updates the model.	I-Reply	I-4	Reply	20179
[line_break_token][line_break_token]4).	O	O	Reply	20179
Yes, you are correct.	B-Reply	B-5	Reply	20179
We forgot to average the term when writing the paper.	I-Reply	I-5	Reply	20179
We have corrected it in the revised paper.	I-Reply	I-5	Reply	20179
Thanks for pointing this out.	I-Reply	I-5	Reply	20179
[line_break_token][line_break_token]5).	O	O	Reply	20179
We have added a sensitivity experiment on the confidence threshold.	B-Reply	B-6	Reply	20179
The results are in the appendix of the revised paper.	I-Reply	I-6	Reply	20179
Here is the summary:[line_break_token][line_break_token]confidence-threshold: 0.6, 0.7, 0.8, 0.9[line_break_token]Mean-accuracy: 81.3, 81.4, 81.4, 81.5[line_break_token][line_break_token]The results show that our method is also robust against confidence threshold.	I-Reply	I-6	Reply	20179
[line_break_token]For our proposed probability based weighting mechanism, as there is no hyper-parameter in there, so there is no need to provide sensitivity analysis on it.	I-Reply	I-6	Reply	20179
[line_break_token][line_break_token]6).	O	O	Reply	20179
We know p(c) in the source domain, as it has labels.	B-Reply	B-7	Reply	20179
We do not know p(c) in the target domain, but we can estimate it.	I-Reply	I-7	Reply	20179
In this paper, we assume p(c) is uniform, as we focus on co-variate shift in this paper.	I-Reply	I-7	Reply	20179
Our work can be easily augmented to work for label shift too, once we estimate the target label distribution.	I-Reply	I-7	Reply	20179
However, we leave this as future work.	I-Reply	I-7	Reply	20179
[line_break_token][line_break_token]7).	O	O	Reply	20179
The H-delta-H divergence is small when the two distribution discrepancy is small.	B-Reply	B-9	Reply	20179
As GCMM loss brings the two distribution closer, and PDM loss shapes the two distribution to be alike, the source and target feature distribution discrepancy will be smaller.	I-Reply	I-9	Reply	20179
Thus H-delta-H becomes smaller as we minimize GCMM loss and PDM loss.	I-Reply	I-9	Reply	20179
We have updated the paper on this part to make it clearer.	I-Reply	I-9	Reply	20179
Thanks for indicating this.	I-Reply	I-9	Reply	20179
[line_break_token][line_break_token]8).	O	O	Reply	20179
We have added an experiment on the Office-Home dataset in the appendix of our paper.	B-Reply	B-10	Reply	20179
Our paper performs the best in all the transfer tasks in Office-Home compared to state-of-the-art UDA methods, showing that it also works for this more challenging dataset.	I-Reply	I-10	Reply	20179
[line_break_token][line_break_token]9).	O	O	Reply	20179
Thanks for pointing out some of our typos, we have made the changes in our revised paper	B-Reply	B-11	Reply	20179

This paper proposes an algorithm for supervising networks for image classification and reconstruction with the object's hierarchical categories in mind.	O	O	Review	216
The claimed benefits are the improved generalizability and interpretability.	O	O	Review	216
The paper reports per-category-level analysis on the semantic image reconstruction task and retrieval on seen and unseen object categories.	O	O	Review	216
[line_break_token][line_break_token]I am currently leaning towards weak accept because I find the paper's claim and technical details generally convincing and simultaneously extracting low-level and high-level features trained using the hierarchical levels of categories is novel.	O	O	Review	216
Generalization to unseen categories tends to be a good proxy for real world performance and directly learning the high level categories is a useful idea for doing so.	O	O	Review	216
[line_break_token][line_break_token]Although I am leaning towards weak accept, I think this paper is close to borderline because the findings do not seem experimentally well validated.	B-Review	B-1	Review	216
It would be more interesting to see Table 3 on multiple unseen categories instead of one special case per dataset.	I-Review	I-1	Review	216
Another idea for experiments is doing cross-dataset evaluations where different datasets may have different leaf categories but shared high level ones.	B-Review	B-2	Review	216
I think it may also be interesting to compare with a non-hierarchical retrieval model and then obtain their high-level prediction accuracy using the corresponding parent level categories.	B-Review	B-3	Review	216
[line_break_token][line_break_token]The paper generally needs polishing.	B-Review	B-4	Review	216
Minor typos I found:[line_break_token][line_break_token]Page 5: classificaiton, classifers[line_break_token]Page 6: intuitional-&gt;intuitive[line_break_token]Page 7: an significant[line_break_token]Page 8: leraning[line_break_token]Page 1: human[line_break_token]Figure 3: arbitary	O	O	Review	216
e thank you for your valuable comments and suggestions.	O	O	Reply	216
We have followed your suggestions and conducted experiments which would make our work more interesting.	O	O	Reply	216
[line_break_token]1).	O	O	Reply	216
Table.3 evaluated on multiple unseen categories.	B-Reply	B-1	Reply	216
[line_break_token]During rebuttal, we tried our best to collect and preprocess more unseen categories in each dataset.	I-Reply	I-1	Reply	216
Specifically, we observed all 40 attributes on CelebA and finally used the bald and gray hair which are unseen leaf-level hair colors.	I-Reply	I-1	Reply	216
We further investigated the 205 categories of ShapeNet and preprocessed 3D models for kinds of new tables and sofas which are regarded as the unseen leaf-level categories for ShapeNet-C. Finally, objects with other poses for ShapeNet-P are also considered in this experiment.	I-Reply	I-1	Reply	216
Typical examples of these unseen categories are shown in Fig.11 in the Appendix.	I-Reply	I-1	Reply	216
[line_break_token]The new test results are updated in Tab.3 in the revision.	I-Reply	I-1	Reply	216
We find that the performance of super-categories decreased to some extent due to more categories added.	I-Reply	I-1	Reply	216
Overall, our method still has considerable generalization ability for unseen but similar objects.	I-Reply	I-1	Reply	216
[line_break_token][line_break_token]2).	O	O	Reply	216
Cross dataset evaluations.	B-Reply	B-2	Reply	216
[line_break_token]Thanks for this interesting and valuable comments.	I-Reply	I-2	Reply	216
We preprocessed a facial expressions dataset called RAF (Li et al CVPR 2017) and a fine-grained cars dataset called CompCars (Yang et al CVPR2015).	I-Reply	I-2	Reply	216
These two datasets are quite challenging compared we have used for training our model and have different leaf-level annotations.	I-Reply	I-2	Reply	216
Similar to the evaluation of our method for unseen categories but within the same dataset, we also test the performance of hierarchical prediction and semantic translation.	I-Reply	I-2	Reply	216
Detailed results can be found in Sec.	I-Reply	I-2	Reply	216
A.4.	I-Reply	I-2	Reply	216
[line_break_token]It is found that the performance would become relatively poor due to the large domain shift.	I-Reply	I-2	Reply	216
Even so, we can still extract and transfer some meaningful information in high-level, e.g. the gender, smiling on Faces, the poses on Cars, which demonstrates the robustness and advantages of hierarchical feature learning compared to the flat ways.	I-Reply	I-2	Reply	216
[line_break_token][line_break_token]3).	O	O	Reply	216
Compare with non-hierarchical retrieval models and obtain their high-level performance using the corresponding parent level categories.	B-Reply	B-3	Reply	216
[line_break_token]In fact, the compared hashing methods in Tab.2 are all non-hierarchical retrieval models and we trained them in each level.	I-Reply	I-3	Reply	216
Training them using the annotations in each level can make them perform best in that level, but a little inefficient.	I-Reply	I-3	Reply	216
Following your advice, we only trained them in the leaf-level and used the learned features to test on high-level using corresponding parent level categories.	I-Reply	I-3	Reply	216
Results are added to Tab.2 (methods with ‚Äú-S‚Äù postfix).	I-Reply	I-3	Reply	216
Besides, we also added pre-trained GANs as baselines for comparison in this experiment.	I-Reply	I-3	Reply	216
We find that using only one model trained in leaf-level is efficient but the mAP drops.	I-Reply	I-3	Reply	216
This also proves both efficient and effective of our HDN for disentangled features.	I-Reply	I-3	Reply	216
[line_break_token][line_break_token]4).	O	O	Reply	216
Typos.	B-Reply	B-4	Reply	216
[line_break_token]We are sorry for these inaccurate expressions which have influenced your reading experience and thank you for your careful reading and good suggestions.	I-Reply	I-4	Reply	216
We have carefully modified corresponding writings one by one in our revision.	I-Reply	I-4	Reply	216
[line_break_token][line_break_token]Ref.	O	O	Reply	216
[line_break_token]Shan Li, Weihong Deng, and JunPing Du.	O	O	Reply	216
Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild.	O	O	Reply	216
In CVPR 2017[line_break_token]Linjie Yang, Ping Luo, Chen Change Loy, and Xiaoou Tang.	O	O	Reply	216
A large-scale car dataset for fine-grained categorization and verification.	O	O	Reply	216
In CVPR 2015	O	O	Reply	216

This paper notes that ensemble distillation (EnD) loses the distributional information from the original ensemble, which prevents users of the distilled model from being able to obtain estimates of its knowledge uncertainty.	O	O	Review	408
It proposes the challenge of distilling the ensemble in a way that preserves information about the ensemble distribution, so that knowledge uncertainty can still be extracted from the distilled model.	O	O	Review	408
It names this task "Ensemble Distribution Distillation (EnD^2)".	O	O	Review	408
It then proposes using Prior Networks (introduced in Malinin &amp; Gales 2018) as a solution, and proceeds to evaluate it with a series of experiments -- first obtaining some intuition from spiral dataset, then more rigorously on benchmark image datasets (CIFAR10/100/TinyImageNet).	O	O	Review	408
[line_break_token][line_break_token]First, it trains ensembles of 10 and 100 NNs on a spiral dataset, distills them using the regular approach (EnD) and Prior Networks (EnD^2), compares their performance, and notes that the Prior Networks approach has comparable performance.	O	O	Review	408
Next, it visualizes over the input space of the spiral dataset the total uncertainty, data uncertainty, and knowledge uncertainty estimates, which are extracted directly from the original ensemble and from the EnD^2 distilled model (Figure 3).	O	O	Review	408
It notes that while the original ensemble is able to correctly estimate the knowledge uncertainty in regions that are far away from the training distribution, the EnD^2 model fails at this task (Figure 3f).	O	O	Review	408
It then proposes to augment the training set with out-of-distribution data, and demonstrates that this improves the estimation of knowledge uncertainty (Figure 3i).	O	O	Review	408
It also proposes a new metric for evaluating the Prediction Rejection Ratio (PRR), uses it to compare how the EnD^2 model compares to the original ensemble and the EnD model.	O	O	Review	408
Finally, it demonstrates using a series of benchmark image classification tasks that the EnD^2 model is able to identify out-of-distribution samples with comparable performance to the original ensemble.	O	O	Review	408
[line_break_token][line_break_token]Decision: Leaning-to-Accept.	O	O	Review	408
Distillation is a well-established technique, and adapting it so that the same NN can perform both predictions and knowledge uncertainty estimates is impactful.	O	O	Review	408
This work proposes using Prior Networks as a way to distill ensembles of NNs in a way that preserves the knowledge uncertainty estimates, and evaluated this claim with a sequence of experiments.	O	O	Review	408
This work also proposes a new evaluation metric (Prediction Rejection Ratio), and can be used to evaluate future models that are able to simultaneously perform prediction and knowledge uncertainty estimation.	O	O	Review	408
However, the way that the paper is organized around the proposal of "Ensemble Distribution Distillation" as a novel machine learning task does not seem very well motivated, as the distribution was solely used to provide uncertainty estimates.	B-Review	B-1	Review	408
[line_break_token][line_break_token]Strengths:[line_break_token]- The visualizations in Figure 3 helped to provide intuition to the reader.	O	O	Review	408
[line_break_token]- Experiments have a clear logical flow.	O	O	Review	408
Spiral experiments provide intuition, motivate out-of-distribution data augmentation, then image data experiments provide evidence for the applicability of the method.	O	O	Review	408
[line_break_token]- Motivates and explains the newly proposed evaluation metric (prediction rejection ratio) in the appendix.	O	O	Review	408
[line_break_token]- The out-of-distribution detection experiments are quite comprehensive.	O	O	Review	408
[line_break_token]- The training procedures are clearly detailed in the appendix.	O	O	Review	408
[line_break_token]- Investigates the appropriateness of the Dirichlet distribution in the appendix.	O	O	Review	408
[line_break_token][line_break_token]Weaknesses:[line_break_token]- The proposal of the novel machine learning task of "Ensemble Distribution Distillation" does not seem very well motivated.	B-Review	B-1	Review	408
In this paper, the distribution distillation was solely used to obtain a knowledge uncertainty estimation.	I-Review	I-1	Review	408
Besides that, what else would the distribution be used for?	I-Review	I-1	Review	408
It was also initially unclear to me what this paper contributes on top of "Predictive Uncertainty Estimation via Prior Networks (Malinin &amp; Gales, 2018)".	O	O	Review	408
A suggestion is to rewrite the summary of contributions to emphasize that the use of Prior Networks to produce a single model that can both perform predictions and provide uncertainty estimates as an extension of ensemble distillation is novel, and that a more comprehensive set of experiments on more difficult image datasets were done in this paper.	B-Review	B-1	Review	408
[line_break_token][line_break_token]Minor comments:[line_break_token]- page 2, expression right before equation 2, and in the first sentence on page 3 is missing closing parentheses.	B-Review	B-2	Review	408
[line_break_token]- page 3, figure 1.	I-Review	I-2	Review	408
It wasn't initially obvious to me that the triangle represents the simplex of the softmax output, and each black dot represents the output of one model of the ensemble.	I-Review	I-2	Review	408
[line_break_token]- page 4, equation 9.	I-Review	I-2	Review	408
Add some space to the right of the equality sign.	I-Review	I-2	Review	408
[line_break_token]- Use backticks`   instead of single quotation mark ' to open quotation marks in LaTeX.[line_break_token][line_break_token][line_break_token]Rebuttal response:[line_break_token]I acknowledge the authors' point about the importance of EnDD in addition to knowledge uncertainty estimation, and maintain my rating.	O	O	Review	408
ear Reviewer III,[line_break_token][line_break_token]The benefit of Ensemble Distribution Distillation is the ability to explicitly emulate a source ensemble and decompose measures of uncertainty.	B-Reply	B-1	Reply	408
This is common practice for tasks such as Bayesian Active Learning (Kirsch 2019), where knowledge uncertainty is commonly used.	I-Reply	I-1	Reply	408
Thus, we believe that the ability to model an ensemble and decompose uncertainties via EnDD is by itself significant.	I-Reply	I-1	Reply	408
However, we speculate that Ensemble Distribution Distillation may have additional benefits by consuming extra degrees of freedom from the model and adding a regularizing effect.	I-Reply	I-1	Reply	408
This may make the model more robust to, for example, adversarial attacks.	I-Reply	I-1	Reply	408
This is supported by the findings in (Malinin &amp; Gales, 2019), where it is shown that it is more difficult to construct adversarial attacks against Prior Network models due to their rich measures of uncertainty.	O	O	Reply	408
However, investigating this is left to future work.	B-Reply	B-1	Reply	408
[line_break_token][line_break_token](Kirsch, 2019) "BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning" (NeurIPS 2019)[line_break_token](Malinin and Gales, 2019) "Reverse KL-divergence training of Prior Networks: Improved Uncertainty and Adversarial Robustness" (NeurIPS 2019)	O	O	Reply	408

The method works by substituting a hidden layer with a denoised version.	B-Review	B-1	Review	1328
[line_break_token]Not only it enable to provide more robust classification results, but also to sense and suggest to the analyst or system when the original example is either adversarial or from a significantly different distribution.	I-Review	I-1	Review	1328
[line_break_token]Improvements in adversarial robustness on three datasets are significant.	I-Review	I-1	Review	1328
[line_break_token][line_break_token]Bibliography is good, the text is clear, with interesting and complete experimentations.	I-Review	I-1	Review	1328
‚ÄúThe method works by substituting a hidden layer with a denoised version.	O	O	Reply	1328
[line_break_token]Not only it enable to provide more robust classification results, but also to sense and suggest to the analyst or system when the original example is either adversarial or from a significantly different distribution.	O	O	Reply	1328
[line_break_token]Improvements in adversarial robustness on three datasets are significant.	O	O	Reply	1328
[line_break_token]Bibliography is good, the text is clear, with interesting and complete experimentations.	O	O	Reply	1328
‚Äù[line_break_token][line_break_token]Thank you for your feedback.	B-Reply	B-1	Reply	1328
We have obtained several new results to address concerns related to gradient obfuscation raised by other reviewers and the public comment.	I-Reply	I-1	Reply	1328

This paper proposes two techniques for fast linear interpolation on CPUs.	O	O	Review	20611
They achieved speedups by reducing 1) fixed overhead cost and 2) per example computation (linear interpolation operation level optimization).	O	O	Review	20611
[line_break_token]Authors consider this problem for small operation models like linear interpolation rather than the models requiring large operations such as ResNet.	O	O	Review	20611
In this case, dispatch overhead cannot be ignored and so they use the MLIR frameworks to optimize trained model into the C++ code (reducing fixed overhead cost).	O	O	Review	20611
This results in 2-3x speed up.	O	O	Review	20611
Secondly, they propose the way to construct auxiliary index-mapping function by considering spacing of the key points rather just using for example evenly spaced index-mapping.	O	O	Review	20611
[line_break_token]They compare proposed method to C++ interpreter implementation on two-layer and deep lattice networks and achieve 5-10x speed improvements.	O	O	Review	20611
[line_break_token][line_break_token]It seems the topic of this paper does not fit ICLR and most machine learning researchers are unlikely to be interested in and even understand this paper.	O	O	Review	20611
This reviewer also does not have enough knowledge and background to judge this paper.	O	O	Review	20611
But my impression is that achieving&nbsp;speed up using existing MLIR framework has no surprising novelty.&nbsp;[line_break_token]Moreover, the experimental results seems quite limited in the sense that they only experiment with trained 2 and 4-layer calibrated lattice models which are kind of small.&nbsp;&nbsp;[line_break_token][line_break_token]It would be better to highlight why the proposed method is meaningful and provide more background knowledge to understand this paper.&nbsp;[line_break_token][line_break_token]This is only consider optimization on CPUs.	B-Review	B-4	Review	20611
What about the case of using GPUs?	I-Review	I-4	Review	20611
[line_break_token][line_break_token]Is branch free assumption for functions ‚ÄòAdjust‚Äô &amp; ‚ÄòT‚Äô is valid? (	O	O	Review	20611
I don‚Äôt have much knowledge on compiler..)	B-Review	B-5	Review	20611
e hope these responses give you more perspective on the novelty and significance.	O	O	Reply	20611
[line_break_token][line_break_token]Re: ‚ÄúBut my impression is that achieving speed up using existing MLIR framework has no surprising novelty. ‚	O	O	Reply	20611
Äú[line_break_token]The key novelty here is that we show that ML models with many small ops (here, linear interpolation ops) are not bottlenecked by their computation, but by the interpreter itself, and we additionally present low-level optimizations and data-handling that enable incredibly fast runtimes on widely available CPUs.	B-Reply	B-1	Reply	20611
 This is in contrast to ML models with large matrix operations (like ResNet or DNN‚Äôs) where the interpreter is a small fraction of total runtime, and have well-studied primitives.	I-Reply	I-1	Reply	20611
[line_break_token][line_break_token][line_break_token]Re: ‚ÄúThis is only consider optimization on CPUs.	O	O	Reply	20611
What about the case of using GPUs?‚Äù[line_break_token]Evaluation runtimes in our experiments are at or below the typical GPU latency of around 10 microseconds, so our CPU implementation would already have finished by the time you moved the data to a GPU.	B-Reply	B-4	Reply	20611
 [line_break_token][line_break_token]Re: ‚ÄúIs branch free assumption for functions ‚ÄòAdjust‚Äô &amp; ‚ÄòT‚Äô is valid? (	O	O	Reply	20611
I don‚Äôt have much knowledge on compiler..)‚Äù[line_break_token]Yes, please see Section 2.1 for details.	B-Reply	B-5	Reply	20611
[line_break_token][line_break_token][line_break_token]Re: ‚Äútrained 2 and 4-layer calibrated lattice models which are kind of small.	O	O	Reply	20611
‚Äù [line_break_token]Yes, the models in the experiments ranged from very small to medium-sized, the largest was the selector model that had 75,000 parameters.	B-Reply	B-2	Reply	20611
 This paper is focused on models with runtimes in the microseconds or nanoseconds.	I-Reply	I-2	Reply	20611
 In production systems such models can run early in a latency-critical pipeline, or many such models may need to be run serially, making speed-ups important.	I-Reply	I-2	Reply	20611

- Are there some labels more important than others, or shouldn‚Äôt we employ taxonomic distances ?	B-Review	B-1	Review	85
[line_break_token]- How make model to decide on number of output labels ?	B-Review	B-2	Review	85
[line_break_token]- It would be nice to have experiments comparing it to the network pretrained on imagenet.	B-Review	B-3	Review	85
'Are there some labels more important than others, or shouldn‚Äôt we employ taxonomic distances' [line_break_token][line_break_token]The standard evaluation protocol described in [25] is used in our work, and we have evaluated different methods by 5 different protocols (which is more comprehensive than [25]).	B-Reply	B-1	Reply	85
The overall precision and overall recall emphasis on frequent tags, and per-class recall and per-class precision emphasis on infrequent tags.	I-Reply	I-1	Reply	85
So we believe the evaluation is thorough.	I-Reply	I-1	Reply	85
The point raised by the reviewer is definitely interesting, however we believe it is orthogonal to this paper.	I-Reply	I-1	Reply	85
[line_break_token][line_break_token][line_break_token]'How make model to decide on number of output labels ?'	O	O	Reply	85
[line_break_token][line_break_token]We follow the standard practice in most previous works [25,14,26] to fix the number of output labels for each image to 3 or 5.	B-Reply	B-2	Reply	85
[line_break_token][line_break_token][line_break_token] 'It would be nice to have experiments comparing it to the network pretrained on imagenet.'	O	O	Reply	85
[line_break_token][line_break_token]We have tested it before and found using pretrained weights can further improve the performance for around 2% for all methods.	B-Reply	B-3	Reply	85
However, our goal is to perform a clear comparison between different loss functions for multilabel annotation, and want to use the simplest experimental setting, so we did not includ the pretrained results	I-Reply	I-3	Reply	85

This paper proposes a method for unsupervised clustering.	O	O	Review	436
Similarly to others unsupervised learning (UL) papers like "Deep Clustering for Unsupervised Learning of Visual Features" by Caron et al they propose an algorithm alternating between a labelling phase and a training phase.	O	O	Review	436
Though, it has interesting differences.	O	O	Review	436
For example, unlike the Caron et al paper, not all the samples get assigned a labels but only the most confident ones.	O	O	Review	436
These samples are determined by the pruning of a graph whose edges are determined by the votes of an ensemble of clustering models.	O	O	Review	436
Then, these pseudo labels are used within a supervised loss which act as a regularizer for the retraining of the clustering models.	O	O	Review	436
[line_break_token][line_break_token]Novelties /contributions/good points:[line_break_token]* Votes from the clustering models to create a graph[line_break_token]* Using a graph to identify the most important samples for pseudo labelling[line_break_token]* Modification of the ladder network to be used as clustering algorithm[line_break_token]* Good amount of experiments and good results[line_break_token][line_break_token]Weaknesses:[line_break_token]* The whole experiment leading to Table 1 in page 2 is unclear for me.	B-Review	B-1	Review	436
I have trouble understanding the experiment settings.	I-Review	I-1	Review	436
Could you please rephrase it.	I-Review	I-1	Review	436
About initial/ final clustering for example and the rest as well.	I-Review	I-1	Review	436
The whole thing puzzles me whereas the experiments section at the end is much more clear.	I-Review	I-1	Review	436
[line_break_token]* Lack of motivation about why using the Ladder method rather than another one.	B-Review	B-2	Review	436
Other recent methods have better results in semi-supervised learning.	I-Review	I-2	Review	436
[line_break_token]* Algorithm 1 seems quite ad-hoc.	B-Review	B-3	Review	436
Do more principled algos exist to solve this problem ?	I-Review	I-3	Review	436
You could write about it and at least explain why it would not be feasible here.	I-Review	I-3	Review	436
The sentence "The intuition is that most of the neighbours of that node will also be connected with each other" is unmotivated: no empirical proof for this ?	I-Review	I-3	Review	436
[line_break_token]* Related work section is too light.	B-Review	B-4	Review	436
It is an important section and should really not be hidden or neglected.	I-Review	I-4	Review	436
[line_break_token]* In the experiments, you could add the "Deep Clustering for Unsupervised Learning of Visual Features"  as baseline as well even if they use it for unsupervised learning as they do clustering as well.	B-Review	B-5	Review	436
[line_break_token]* In the experiments, you use the features extracted from ResNet-50 but what about finetuning this network rather than adding something on top or even better starting from scratch.	B-Review	B-6	Review	436
Because here CIFAR-10 benefits greatly from the ImageNet features.	I-Review	I-6	Review	436
I know that you should reproduce the settings from other papers but it might be good to go a bit beyond.	I-Review	I-6	Review	436
Especially, if the settings of previous papers are a bit faulty.	I-Review	I-6	Review	436
[line_break_token]* Regarding, the impact of number of models in section D of the appendix, there is no saturation at 10 models.	B-Review	B-7	Review	436
So how many models are necessary for saturation of the performance ?	I-Review	I-7	Review	436
[line_break_token]* Minor point: several times, you write "psuedo".	B-Review	B-8	Review	436
[line_break_token][line_break_token]Conclusion: the algorithm is novel and represents a nice contribution.	O	O	Review	436
Though, there are a lot of weaknesses that could be solved.	O	O	Review	436
So, I am putting "Weak accept" for the moment but it could change towards a negative rating depending on the rebuttal.	O	O	Review	436
[line_break_token]	O	O	Review	436
hank you for your comments and the positive review of the paper.	O	O	Reply	436
[line_break_token][line_break_token]* We have updated the paper to clarify these experiments better.	B-Reply	B-1	Reply	436
At a high level, the goal of the experiments in page 2 is to see the effect of generating pseudo labels using existing approaches on the final clustering accuracy using our iteration-based approach.	I-Reply	I-1	Reply	436
These experiments establish two things: 1) We need good quality of initial pseudo labels to get good final clustering accuracy.	I-Reply	I-1	Reply	436
2) None of the existing methods provide high accuracy pseudo labels.	I-Reply	I-1	Reply	436
[line_break_token][line_break_token]* Yes, there are several recent methods for semi-supervised learning that have higher accuracy than ladder networks.	B-Reply	B-2	Reply	436
 For some of these approaches [1,2],  data-augmentation is a core component which assumes some domain knowledge of the dataset.	I-Reply	I-2	Reply	436
Further, many of the data-augmentation techniques are specific to image datasets.	I-Reply	I-2	Reply	436
There are other  methods [3,4] which uses adversarial training to learn latent features.	I-Reply	I-2	Reply	436
However, we found that these methods do not work well if we jointly train them with unsupervised losses.	I-Reply	I-2	Reply	436
Ladder networks does not require any domain-dependent augmentation, works for both image and text datasets, and can be easily jointly trained with supervised and unsupervised losses.	I-Reply	I-2	Reply	436
Thus, we chose to work with Ladder networks though our approach is general enough to work with any semi-supervised method that accommodates training with unsupervised loss terms.	I-Reply	I-2	Reply	436
[line_break_token][line_break_token]* Traditional clustering algorithms focus mainly on clustering the entire data set, not on finding high accuracy clusters of subsets of the data, and thus do not achieve high enough accuracy required for improving final clustering accuracy.	B-Reply	B-3	Reply	436
One principled algorithm is Girvan‚ÄìNewman algorithm [5]  that was proposed for community detection but we found that it was computationally impractical given the size of our datasets.	I-Reply	I-3	Reply	436
[line_break_token]Regarding the intuition that most of the neighbours of that node will be connected with each other, we found this to be empirically true in our experiments.	I-Reply	I-3	Reply	436
For example, on Cifar10, for the threshold of 90% models agreeing on the label, about 81% of the nodes in a cluster were connected to each other.	I-Reply	I-3	Reply	436
If the threshold is at 100%, all nodes in a cluster are connected with each other due to transitivity.	I-Reply	I-3	Reply	436
We have updated the paper with these numbers.	I-Reply	I-3	Reply	436
[line_break_token][line_break_token]*  We have updated the related work section with discussion of several other related papers.	B-Reply	B-4	Reply	436
[line_break_token][line_break_token]* We found that running K means starting with a random initialization to assign pseudo-labels as described in the paper resulted in poor pseudo-label accuracy.	B-Reply	B-5	Reply	436
Further, if we iterate based on these low accuracy pseudo-labels, the model degenerates to assigning most of the samples to the same cluster.	I-Reply	I-5	Reply	436
Thus, we felt that it was unfair to the authors to add these results as a baseline, especially since the authors themselves did not report clustering performance.	I-Reply	I-5	Reply	436
Note that, for the results in section 2, we did not start with a random initialization (we used a ladder network trained with an unsupervised loss to generate the initial pseudo-labels).	I-Reply	I-5	Reply	436
[line_break_token][line_break_token]* We did try some experiments on not using any pre-trained models for features and training convnets from scratch.	B-Reply	B-6	Reply	436
On the cifar10 dataset, using Resnet34 as CNN initialized randomly, our method was able to achieve clustering accuracy of 35.17 ( achieving about 2% improvement over the same model without our framework) .	I-Reply	I-6	Reply	436
In the literature, there are a couple of papers [6 , 7 ] that performs clustering on cifar-10 datasets from scratch, but they use a variety of domain-based data augmentation-based techniques to improve performance and we were not able to reproduce their results.	I-Reply	I-6	Reply	436
Furthermore, they are applicable to only image datasets and do not help with text-based datasets that we also evaluate on.	I-Reply	I-6	Reply	436
[line_break_token][line_break_token]* We ran additional experiments with 15 models in the ensemble and the accuracy remained at 98.5% accuracy on the MNIST dataset.	B-Reply	B-7	Reply	436
This suggests that accuracy saturates after 10 models.	I-Reply	I-7	Reply	436
We have updated the paper with this result.	I-Reply	I-7	Reply	436
[line_break_token][line_break_token]* Thanks for pointing it out, we have fixed it in the revised version of the paper.	B-Reply	B-8	Reply	436
[line_break_token][line_break_token][1] David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin Raffel.	O	O	Reply	436
 Mixmatch: A holistic approach to semi-supervised learning[line_break_token][line_break_token][2]  Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V Le.	O	O	Reply	436
 Unsupervised data augmentation[line_break_token][line_break_token][3] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii.	O	O	Reply	436
Virtual adversarial training: a regularization method for supervised and semi-supervised learning[line_break_token][line_break_token][4] Saki Shinoda, Daniel E Worrall, and Gabriel J Brostow.	O	O	Reply	436
 Virtual adversarial ladder networks for semi-supervised learning[line_break_token][line_break_token][5] Girvan M. and Newman M. E. J., Community structure in social and biological networks[line_break_token][line_break_token][6] Jianlong Chang, Lingfeng Wang, Gaofeng Meng, Shiming Xiang, and Chunhong Pan.	O	O	Reply	436
Deep adaptive image clustering[line_break_token][line_break_token][7] Xu Ji, Jo√£o F Henriques, and Andrea Vedaldi.	O	O	Reply	436
Invariant information clustering for unsupervised image classification and segmentation	O	O	Reply	436

The paper proposed a weakly-supervised wMAN model for moment localization in untrimmed videos.	O	O	Review	10041
Only the video-level annotation is available for training, and the goal is retrieving the video segment described by the sentence.	O	O	Review	10041
The proposed model explored to utilize better context information and captured the relation between video and sentence/word via graph neural networks.	O	O	Review	10041
In particular, instead of modeling the context information between the sentence and each video frame, wMAN tried to learn the representation with multi-level and co-attention, which considers all possible pairs between the word and the frame.	O	O	Review	10041
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.	O	O	Review	10041
[line_break_token][line_break_token]Pros:[line_break_token]- Weakly-supervised method for video moment localization is a reasonable and important direction.	O	O	Review	10041
[line_break_token]- wMAN explicitly utilized multi-level context information between the sentence and the video frame, and used the graph neural network and the message passing to model the representation.	O	O	Review	10041
I think this is a reasonable direction.	O	O	Review	10041
[line_break_token]- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other "oracle" baselines.	O	O	Review	10041
The performance is impressive and could be a better baseline for the future work.	O	O	Review	10041
[line_break_token][line_break_token]Cons:[line_break_token]- wMAN model the relation for all possible pairs of the word and the video frame.	B-Review	B-1	Review	10041
However, if the video is quite long, say 10 minutes, 30 minutes, or even few hours, will the method still be efficient and effective?	I-Review	I-1	Review	10041
[line_break_token]- When building the relation between the word and the frame, is there any emphasis on verb, some particular word, or self-learned attention?	B-Review	B-2	Review	10041
For some particular word, say "people" and "cup", won't it have strong connection with many frames?	I-Review	I-2	Review	10041
But for some of the words, say "hold" and "sits", could it play a more important role?	I-Review	I-2	Review	10041
[line_break_token]- Followed by previous question, in the qualitative results, it seems the boundary parts of the predicted video segments are less accurate.	B-Review	B-3	Review	10041
Is it because some of the words case these false positive results?	I-Review	I-3	Review	10041
What do you think the reason is?	I-Review	I-3	Review	10041
[line_break_token]- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.	B-Review	B-4	Review	10041
For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.	I-Review	I-4	Review	10041
Is there a particular reason about this?	I-Review	I-4	Review	10041
PE seems to be important for wMAN, and the authors provides few sentences analysis about this, but I don't think I fully understand this part.	I-Review	I-4	Review	10041
Another problem is that there is only few qualitative results, and in both these two examples, predicted results cover the GT segments.	I-Review	I-4	Review	10041
Is this always the case for wMAN?	I-Review	I-4	Review	10041
Why?	I-Review	I-4	Review	10041
Some failure cases could also be very helpful.	I-Review	I-4	Review	10041
[line_break_token]- Less technical comments: The paper writing is fine to me, but I don't like the typesetting.	B-Review	B-5	Review	10041
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.	I-Review	I-5	Review	10041
[line_break_token][line_break_token]Overall, I think the paper is marginal above the accept line.	O	O	Review	10041
hank you for your review.	O	O	Reply	10041
We address your concerns below.	O	O	Reply	10041
[line_break_token][line_break_token]- wMAN model the relation for all possible pairs of the word and the video frame.	O	O	Reply	10041
However, if the video is quite long, say 10 minutes, 30 minutes, or even few hours, will the method still be efficient and effective?	O	O	Reply	10041
[line_break_token][line_break_token]Computing effective video representations for long videos efficiently is still an unsolved problem in computer vision.	B-Reply	B-1	Reply	10041
There is a lot of ongoing work in this area.	I-Reply	I-1	Reply	10041
With this said, based on the observed memory requirements of our proposed approach during inference, the efficiency and effectiveness of our method should be scalable to videos lasting a few minutes.	I-Reply	I-1	Reply	10041
As mentioned before, reasoning about videos lasting a few hours efficiently and effectively is still an unsolved research topic.	I-Reply	I-1	Reply	10041
However, with increased computational resources, there is no reason to believe that our method is not scalable to such videos.	I-Reply	I-1	Reply	10041
One possible solution is to reduce the sampling rate of video frame.	I-Reply	I-1	Reply	10041
Another option is to break the video into smaller parts and localize within each part individually.	I-Reply	I-1	Reply	10041
Finding a way to reason about long videos and natural language effectively from a low frame sampling rate in this task provides an interesting avenue for future work.	I-Reply	I-1	Reply	10041
[line_break_token][line_break_token]- When building the relation between the word and the frame, is there any emphasis on verb, some particular word, or self-learned attention?	O	O	Reply	10041
[line_break_token][line_break_token]The motivation behind the frame-by-word interaction mechanism in our approach is that it encourages the model to learn the association between words and action sequences in videos.	B-Reply	B-2	Reply	10041
Words such as ‚Äòhold‚Äô and ‚Äòsits‚Äô definitely play a much more important role in localizing the relevant temporal segment in videos.	I-Reply	I-2	Reply	10041
For example, in Figure 3b, we observe that the top 3 weights assigned to each frame for ‚Äòperson‚Äô and ‚Äòchair‚Äô generally occur in tandem with ‚Äòsits‚Äô and ‚Äòdown‚Äô.	I-Reply	I-2	Reply	10041
This demonstrates that our model learns the association between verbs and entities via self-learned attention.	I-Reply	I-2	Reply	10041
This is consistent with our observations in Figure 3a as well.	I-Reply	I-2	Reply	10041
[line_break_token][line_break_token]- Followed by previous question, in the qualitative results, it seems the boundary parts of the predicted video segments are less accurate.	O	O	Reply	10041
[line_break_token][line_break_token]One possible reason is that we are using non-overlapping segments as proposals on Charades-Sta to facilitate fair comparison with prior work.	B-Reply	B-3	Reply	10041
Given that these proposals have static boundaries, it will cause the boundary parts of the candidate proposals to be less accurate.	I-Reply	I-3	Reply	10041
[line_break_token][line_break_token]- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.	O	O	Reply	10041
[line_break_token][line_break_token]It appears that contextual cues generally help to improve retrieval accuracy on harder settings such as higher IOU thresholds and Recall@1 accuracy.	B-Reply	B-4	Reply	10041
Using just the FBW module leads to better performance only on the lowest IOU threshold and Recall@5 and Recall@10 accuracies.	I-Reply	I-4	Reply	10041
We observe the same consistency in our ablation experiments on DiDeMo as well.	I-Reply	I-4	Reply	10041
We hypothesize that these cues help to make our model more discriminative in harder settings which is arguably more practical for real-world applications such as in video search engines.	I-Reply	I-4	Reply	10041
Finally, the overall performance of wMAN is better than that of the FBW module.	I-Reply	I-4	Reply	10041
If we average the scores, we obtain 57.0% and 58.2% for the FBW module and wMAN respectively.	I-Reply	I-4	Reply	10041
[line_break_token][line_break_token]- Less technical comments [line_break_token][line_break_token]We will update the next version of the paper with the necessary clarifications and modifications.	B-Reply	B-5	Reply	10041
[line_break_token][line_break_token]We hope that we have addressed your concerns satisfactorily.	O	O	Reply	10041
Please let us know if you have any further concerns or questions	O	O	Reply	10041

This paper propose local prior matching to leverage a language model to use unlabeled speech data to improve an ASR system.	O	O	Review	20571
This is a worthy goal.	O	O	Review	20571
The details of the proposal were a bit hard for me to understand.	B-Review	B-1	Review	20571
The proposed method reminded me of "posterior regularization" (K. Ganchev et al 2010), but I could not understand Section 2.2 well enough to draw a direct link.	I-Review	I-1	Review	20571
I encourage the authors to condense 2.2 and make it clearer what, exactly, Local Prior Matching is.	I-Review	I-1	Review	20571
[line_break_token][line_break_token]The paper presents extensive, interesting results.	B-Review	B-2	Review	20571
I do want to point that they seem to be considerably off of the LibriSpeech state of the art, e.g. see K. Irie et al Interspeech 2019.	I-Review	I-2	Review	20571
e thank the reviewer for the thoughtful comments.	O	O	Reply	20571
Below are our itemized responses to address the concerns.	O	O	Reply	20571
[line_break_token][line_break_token][line_break_token]Q1: The details of the proposal were a bit hard for me to understand.	O	O	Reply	20571
The proposed method reminded me of "posterior regularization" (K. Ganchev et al 2010), but I could not understand Section 2.2 well enough to draw a direct link.	O	O	Reply	20571
I encourage the authors to condense 2.2 and make it clearer what, exactly, Local Prior Matching is.	O	O	Reply	20571
[line_break_token][line_break_token]A1: We thank the reviewer for the suggestion on writing.	B-Reply	B-1	Reply	20571
We will clarify Section 2 of the paper.	I-Reply	I-1	Reply	20571
If the reviewer has specific parts in mind that are not clear, we will gladly address them.	I-Reply	I-1	Reply	20571
[line_break_token][line_break_token]In a nutshell, we propose a training objective for unlabeled speech.	I-Reply	I-1	Reply	20571
Our approach is like pseudo-labeling, but instead of using the top-1, we use top-k with beam search, and re-weight this top-k by the LM score.	I-Reply	I-1	Reply	20571
We call it the ‚Äúlocal prior‚Äù because it gives a distribution proportional to the prior (LM), but only in a region close to the ground truth, where p(speech | text) is high.	I-Reply	I-1	Reply	20571
We then train an ASR system using unlabeled speech by matching the ASR model distribution with this target distribution, and hence the proposed training objective is termed ‚Äúlocal prior matching.	I-Reply	I-1	Reply	20571
‚Äù[line_break_token][line_break_token]Both posterior regularization (PR) [1] and our work aim to incorporate implicit supervision, but the methods differ significantly.	I-Reply	I-1	Reply	20571
PR focuses on incorporating domain knowledge (e.g., in POS tagging there must be at least one noun and one verb in the output) through adding *handcrafted* and *linear* constraints to the posterior distribution family.	I-Reply	I-1	Reply	20571
Optimization of PR is done with an EM algorithm.	I-Reply	I-1	Reply	20571
[line_break_token][line_break_token]On the other hand, we propose a Bayesian-based method, where the implicit supervision from the language model corresponds to the prior in the Bayesian framework.	I-Reply	I-1	Reply	20571
Unlike PR, there is no limitation on what models can be used for parameterizing the prior distribution.	I-Reply	I-1	Reply	20571
Hence, we can use a very strong prior model that incorporates all the prior knowledge (e.g., in the POS tagging example, any sequence with no verb and no noun should have extremely low prior probability).	I-Reply	I-1	Reply	20571
One of our main contributions is proposing a tractable and theoretically justified posterior estimator utilizing a strong prior distribution model for sequence transduction tasks.	I-Reply	I-1	Reply	20571
[line_break_token][line_break_token][1] Ganchev, Kuzman, Jennifer Gillenwater, and Ben Taskar. "	O	O	Reply	20571
Posterior regularization for structured latent variable models."	O	O	Reply	20571
Journal of Machine Learning Research 11.Jul (2010): 2001-2049.	O	O	Reply	20571
[line_break_token][line_break_token][line_break_token]Q2: The paper presents extensive, interesting results.	O	O	Reply	20571
I do want to point that they seem to be considerably off of the LibriSpeech state of the art, e.g. see K. Irie et al Interspeech 2019.	O	O	Reply	20571
[line_break_token][line_break_token]A2: We thank the reviewer for pointing out the reference and we are also aware of those work.	B-Reply	B-2	Reply	20571
As described in our paper, we base our model on [2] because it is light-weight and efficient compared to the RNN-based encoders used in [3; 4], while achieving comparable performances.	I-Reply	I-2	Reply	20571
Below we list our baseline model results and those from some very recent literature using seq2seq+attention ASR models trained on LibriSpeech train-clean-100.	I-Reply	I-2	Reply	20571
Our baseline model is on-par with the second place and not far from the best results.	I-Reply	I-2	Reply	20571
[line_break_token][line_break_token]*Baseline Performances (WER)*[line_break_token]Paper  |  test-clean |  test-other  [line_break_token]Ours   |  14.85%     |  39.95%[line_break_token][5]       |  25.2%       |  (not reported)[line_break_token][6]       |  21.0%       |  (not reported)[line_break_token][3]       |  14.7%       |  40.8%[line_break_token][4]       |  12.9%       |  35.5%[line_break_token][line_break_token]We also point out that the reference the reviewer mentioned [4] was concurrent work published just one week before the ICLR submission deadline.	I-Reply	I-2	Reply	20571
Since the focus of our paper is semi-supervised learning and not on achieving the best possible baseline, we feel that the important results are the amount of improvement from the baseline and the gap reduced from using a larger labeled dataset (WER recovery rate, WRR).	I-Reply	I-2	Reply	20571
In that respect, our proposed method demonstrates superior performance compared to the literature as shown below (complete results are in Table 11), while being extremely simple to implement and theoretically well-justified.	I-Reply	I-2	Reply	20571
[line_break_token][line_break_token]*Proposed Method Performances with 360hr of unlabeled speech*[line_break_token]WRR = (WER(sup.	I-Reply	I-2	Reply	20571
100) - WER(proposed)) / (WER(sup.	I-Reply	I-2	Reply	20571
100) - WER(sup.	I-Reply	I-2	Reply	20571
460))[line_break_token]Paper |  test-clean WER  |  test-clean WRR[line_break_token]Ours  |  9.21%           |  82.22%[line_break_token][5]      |  21.5%           |  27.6%[line_break_token][6]      |  17.5%           |  38.0%[line_break_token][line_break_token][line_break_token][2] Hannun, Awni, et al "Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions."	O	O	Reply	20571
Interspeech (2019).	O	O	Reply	20571
[line_break_token][3] L√ºscher, Christoph, et al "RWTH ASR systems for LibriSpeech: Hybrid vs Attention."	O	O	Reply	20571
Interspeech (2019).	O	O	Reply	20571
[line_break_token][4] Irie, Kazuki, et al "On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition."	O	O	Reply	20571
Interspeech (2019).	O	O	Reply	20571
[line_break_token][5] Hori, Takaaki, et al "Cycle-consistency training for end-to-end speech recognition."	O	O	Reply	20571
ICASSP (2019).	O	O	Reply	20571
[line_break_token][6] Baskar, Murali Karthick, et al "Self-supervised Sequence-to-sequence ASR using Unpaired Speech and Text."	O	O	Reply	20571
Interspeech (2019)	O	O	Reply	20571

Results on the VQA task are good for this simple model, the ablation study of table 1 gives some insights as to what is important.	O	O	Review	356
[line_break_token][line_break_token]Missing are some explanations about the language embedding and the importance in deciding embedding dimension and final output dimension, equivalent to deciding the projected dimension in[tab_token]the compact bilinear model.	B-Review	B-1	Review	356
Since the main contribution of the[line_break_token]paper seems to be slightly better performance with fairly large reduction in parameters vs. compact bilinear something should be said about choice of those hyper parameters.	I-Review	I-1	Review	356
If you increase embedded and output dimensions to equalize parameters to the compact bilinear model are further gains possible?	I-Review	I-1	Review	356
 How is the question encoded?	I-Review	I-1	Review	356
Is word order preserved in this encoding, the compact bilinear model compared to in table 1 mentions glove, the proposed model is using this as well?	I-Review	I-1	Review	356
The meaning of visual attention in this model along with the number of glimpses should be tied to the sentence embedding, so now we are looking at particular spatial components when that part of the sentence is encoded, then we stack according to your equation 9?	B-Review	B-2	Review	356
[line_break_token]	O	O	Review	356
Explanation about the question embedding can be found in Appendix A.1.1, and please refer to our recent comment on that.	B-Reply	B-1	Reply	356
The output dimension (the number of candidate answers) and joint embedding size is fixed according to Kim et al (2016b).	I-Reply	I-1	Reply	356
Our preliminary study shows that the choice of the number of joint embedding size is difficult, since the variance of performance is relatively high, but around 1,000 is fairly good.	I-Reply	I-1	Reply	356
[line_break_token][line_break_token]For the multiple-glimpse attention mechanism, we get two different attention probability distributions over 14x14 grids using attention mechanism, and concatenating the two different weighted-sum visual features for each distribution, respectively	B-Reply	B-2	Reply	356

1.	B-Review	B-2	Review	1031
This papers leverages the concept of wavelet transform within a deep architecture to solve the classic problem (especially for wavelet analysis) of change point detection.	B-Review	B-1	Review	1031
The authors do a reasonably comprehensive job of demonstrating the efficacy of the proposed framework using various synthetic and real data sets with both gradual and abrupt changes[line_break_token][line_break_token]2.	O	O	Review	1031
The concept of pyramid network idea is not really new, in the context of CNN it has been established quite well.	B-Review	B-2	Review	1031
The paper should highlight this fact by citing papers such as "Lin, Tsung-Yi, et al "Feature Pyramid Networks for Object Detection."	I-Review	I-2	Review	1031
CVPR.	I-Review	I-2	Review	1031
Vol.	I-Review	I-2	Review	1031
1.	I-Review	I-2	Review	1031
No.	I-Review	I-2	Review	1031
2.	I-Review	I-2	Review	1031
2017."	I-Review	I-2	Review	1031
[line_break_token][line_break_token]3.	O	O	Review	1031
Involving wavelet transforms in deep nets have been done before.	B-Review	B-3	Review	1031
This paper attempts to learn wavelet transform parameters by involving them as trainable layers.	I-Review	I-3	Review	1031
But even this kind of idea is also emerging in the community.	I-Review	I-3	Review	1031
Papers such as "Fujieda, Shin, Kohei Takayama, and Toshiya Hachisuka. "	I-Review	I-3	Review	1031
Wavelet Convolutional Neural Networks."	I-Review	I-3	Review	1031
arXiv preprint arXiv:1805.08620 (2018)" need to be discussed in this context.	I-Review	I-3	Review	1031
[line_break_token][line_break_token]4.	O	O	Review	1031
The biggest issue in my mind is that I feel "Chung et al 2016" is still a very similar framework as the proposed one.	B-Review	B-4	Review	1031
While authors argue that it uses more like CNN architecture and the proposed method may pick up the multi-scale features better, comparison with this seems to be most appropriate.	I-Review	I-4	Review	1031
This will also clearly identify the benefits of the wavelet structure to the filters and multi-resolution analysis approaches.	I-Review	I-4	Review	1031
[line_break_token][line_break_token]5.	B-Review	B-3	Review	1031
RCNN term has been used for CNN+RNN architecture.	B-Review	B-5	Review	1031
This may not be a good terminology to use since RCNN is a very popular term referring to Region based CNN for detection and localization purposes.	I-Review	I-5	Review	1031
[line_break_token][line_break_token]6.	O	O	Review	1031
AUC metric, I believe is the - area under ROC curve, this needs to be spelled out, how it is computed?	B-Review	B-6	Review	1031
at least in the Appendix[line_break_token][line_break_token]xxxxxxxxxxxxxxxxxxx[line_break_token][line_break_token]Appreciate the authors' rebuttal, updated my score.	O	O	Review	1031
We thank the reviewer for their helpful comments and have both updated the paper and planned experiments to further improve it.	O	O	Reply	1031
Specific replies are below.	O	O	Reply	1031
[line_break_token][line_break_token]2-3) The reviewer states that ‚Äúthe concept of pyramid network is not really new‚Äù and that ‚Äúinvolving wavelet transforms in deep nets have been done before‚Äù.	B-Reply	B-2	Reply	1031
We have added both papers to the related work, however there are crucial differences between our approach and the cited works.	I-Reply	I-2	Reply	1031
Both Lin et al and Fujieda et al address multiscale data, though this is in the context of image data with varying scale/resolution.	I-Reply	I-2	Reply	1031
However, these works focus on images, each of which has data at multiple scales.	I-Reply	I-2	Reply	1031
In contrast, we focus on temporal dependencies among multivariate time series, which are not captured by these approaches.	I-Reply	I-2	Reply	1031
For example, Lin et al built feature pyramids for each input image to model different scales, but in our data the change points relate to earlier signals rather than the same moment captured at a different resolution.	I-Reply	I-2	Reply	1031
For example, blood glucose changes in response to factors like exercise or food intake that happened earlier.	I-Reply	I-2	Reply	1031
The wavelet method proposed by Fujieda et al has the same limitations, since that method is designed specifically for capturing spatial dependencies for different scales.	I-Reply	I-2	Reply	1031
[line_break_token][line_break_token][line_break_token]4) The reviewer had some questions about how the paper advances the state of the art over the work of Chung et al (2016).	B-Reply	B-4	Reply	1031
While that work also examines temporal dependencies at different scales, the approach is not designed specifically for CPD.	I-Reply	I-4	Reply	1031
However, this approach is not scale invariant, relies on the hierarchical boundary structure, and has stronger connections between layers in the hierarchy.	I-Reply	I-4	Reply	1031
The available code was used for prediction, but we are now attempting to apply the approach to the datasets in our paper by replacing the RNN framework in our proposed PRNN with the Hierarchical Multiscale Recurrent Neural Network (HMRNN) proposed by Chung et al The comparison results will be added to our paper once the experiments are completed.	I-Reply	I-4	Reply	1031
[line_break_token][line_break_token][line_break_token]5) We have updated the terminology used.	O	O	Reply	1031
[line_break_token]6)AUC: We included detail on the calculation under the implementation details (sec.	B-Reply	B-5	Reply	1031
4.3) of our original submission, but have revised to make this clearer and have expanded the appendix to discuss how AUC is computed for each tolerance level.	I-Reply	I-5	Reply	1031
[line_break_token][line_break_token]To detect changepoints, we apply non-maximum suppression with a sliding window of length and filter the maximum values with a threshold.	I-Reply	I-5	Reply	1031
We evaluate AUC by iterating over this threshold.	I-Reply	I-5	Reply	1031
Since changepoints may not exactly match the true changepoints, we use a tolerance parameter that sets how close a detected change must be to a true change to be considered a correct detection.	I-Reply	I-5	Reply	1031
We match detected changepoints to the closest true changepoint within time ste	I-Reply	I-5	Reply	1031

Generating high-quality sentences/paragraphs is an open research problem that is receiving a lot of attention.	O	O	Review	299
This text generation task is traditionally done using recurrent neural networks.	O	O	Review	299
This paper proposes to generate text using GANs.	O	O	Review	299
GANs are notorious for drawing images of high quality but they have a hard time dealing with text due to its discrete nature.	O	O	Review	299
This paper's approach is to use an actor-critic to train the generator of the GAN and use the usual maximum likelihood with SGD to train the discriminator.	O	O	Review	299
The whole network is trained on the "fill-in-the-blank" task using the sequence-to-sequence architecture for both the generator and the discriminator.	O	O	Review	299
At training time, the generator's encoder computes a context representation using the masked sequence.	O	O	Review	299
This context is conditioned upon to generate missing words.	O	O	Review	299
The discriminator is similar and conditions on the generator's output and the masked sequence to output the probability of a word in the generator's output being fake or real.	O	O	Review	299
With this approach, one can generate text at test time by setting all inputs to blanks.	O	O	Review	299
[line_break_token][line_break_token]Pros and positive remarks: [line_break_token]--I liked the idea behind this paper.	O	O	Review	299
I find it nice how they benefited from context (left context and right context) by solving a "fill-in-the-blank" task at training time and translating this into text generation at test time.	O	O	Review	299
[line_break_token]--The experiments were well carried through and very thorough.	O	O	Review	299
[line_break_token]--I second the decision of passing the masked sequence to the generator's encoder instead of the unmasked sequence.	O	O	Review	299
I first thought that performance would be better when the generator's encoder uses the unmasked sequence.	O	O	Review	299
Passing the masked sequence is the right thing to do to avoid the mismatch between training time and test time.	O	O	Review	299
[line_break_token][line_break_token]Cons and negative remarks:[line_break_token]--There is a lot of pre-training required for the proposed architecture.	B-Review	B-1	Review	299
There is too much pre-training.	I-Review	I-1	Review	299
I find this less elegant.	I-Review	I-1	Review	299
[line_break_token]--There were some unanswered questions:[line_break_token]            (1) was pre-training done for the baseline as well?	B-Review	B-2	Review	299
[line_break_token]            (2) how was the masking done?	B-Review	B-3	Review	299
how did you decide on the words to mask?	I-Review	I-3	Review	299
was this at random?	I-Review	I-3	Review	299
[line_break_token]            (3) it was not made very clear whether the discriminator also conditions on the unmasked sequence.	B-Review	B-4	Review	299
It needs to but [line_break_token]                  that was not explicit in the paper.	I-Review	I-4	Review	299
[line_break_token]--Very minor: although it is similar to the generator, it would have been nice to see the architecture of the discriminator with example input and output as well.	B-Review	B-5	Review	299
[line_break_token][line_break_token][line_break_token]Suggestion: for the IMDB dataset, it would be interesting to see if you generate better sentences by conditioning on the sentiment as well.	B-Review	B-6	Review	299
[line_break_token]	O	O	Review	299
Thank you for your review!	O	O	Reply	299
[line_break_token][line_break_token]*Pretraining*[line_break_token]We found evidence that this architecture could replicate simple data distributions without pretraining and found it could perform reasonably on larger data sets, however, in the interest of computational efficiency, we relied on pretraining procedures, similar to other work in this field.	B-Reply	B-2	Reply	299
All our baselines also included pre-training.	I-Reply	I-2	Reply	299
[line_break_token][line_break_token]To test whether all the pretraining steps were necessary, we experimented with training MaskMLE and MaskGAN on PTB without initializing from a pretrained language model.	I-Reply	I-2	Reply	299
The perplexity of the generated samples were 117 without pretraining and 126 with pretraining, showing that at least for PTB language model pretraining does not appear to be necessary.	I-Reply	I-2	Reply	299
[line_break_token][line_break_token]Models trained from scratch were found to more computationally intense.	I-Reply	I-2	Reply	299
 By building off near state-of-the-art language models, we were able to rapidly iterate over architectures thanks to faster convergence.	I-Reply	I-2	Reply	299
 Additionally, we were working at a word-level representation where our softmax is producing a distribution over O(10K)-tokens.	I-Reply	I-2	Reply	299
 Attempting reinforcement learning methods from scratch on an ‚Äòaction space‚Äô of this magnitude is prone to extreme variance.	I-Reply	I-2	Reply	299
 The likelihood of producing a correct token and receiving a positive reward is exceedingly rare; therefore, the model spends a long time exploring the space with almost always negative rewards.	I-Reply	I-2	Reply	299
 As a related and budding research avenue, one could consider the properties and characteristics of exclusively GAN-trained language models.	I-Reply	I-2	Reply	299
 [line_break_token][line_break_token]*Masking Strategy*[line_break_token]We predominantly evaluated two masking strategies at training time.	B-Reply	B-3	Reply	299
 One was a completely random mask and the other was a contiguous mask, where blocks of adjacent words are masked.	I-Reply	I-3	Reply	299
 Though we were able to train with both strategies, we found that the random mask was more difficult to train.	I-Reply	I-3	Reply	299
 However, and more significantly, the random mask doesn‚Äôt share the primary benefit of GAN autoregressive text generation (termed free-running mode in the literature).	I-Reply	I-3	Reply	299
 One can see this because for a given percentage of words to omit, a Generator given the random mask will fill-in shorter sequences autoregressively than the contiguous mask will.	I-Reply	I-3	Reply	299
 GAN-training allows our training and inference procedure to be the same, in contrast to teacher-forcing in maximum likelihood training.	I-Reply	I-3	Reply	299
 Therefore, we generally found it beneficial to allow the model to produce long sequences, conditioned on what it had produced before, rather than filling in short disjoint sequences or or even single tokens.	I-Reply	I-3	Reply	299

Summary:[line_break_token][line_break_token]The paper provides a description of a new framework for reproducible and efficient RL experiments, as well as benchmarks of many algorithms on popular environments, such as `Atari and Roboschool.	O	O	Review	451
[line_break_token][line_break_token]Pros:[line_break_token]- I agree that reproducibility is an extremely important question for the RL research, and thus such a code library is very beneficial for the community.	O	O	Review	451
[line_break_token]- The library is well designed, and allows for creating extensions rather easily in the future.	O	O	Review	451
[line_break_token]- Benchmarks are quite extensive and instructive.	O	O	Review	451
[line_break_token][line_break_token]Cons:[line_break_token]-  Comparison with the library [1] is missing (see also [2] for description and benchmarks).	B-Review	B-1	Review	451
As both libraries are focused on reproducibility and flexible implementations of algorithms, such a comparison would support authors claims.	I-Review	I-1	Review	451
[line_break_token]- I am not sure that ICLR is the right venue for such paper.	B-Review	B-2	Review	451
Perhaps a more specialized conference of a workshop would be better.	I-Review	I-2	Review	451
[line_break_token]- Anonymity violation[line_break_token][line_break_token]Questions:[line_break_token]- How difficult it is to implement distributional algorithms in your framework?	B-Review	B-3	Review	451
[line_break_token]- What about different exploration strategies? (	B-Review	B-5	Review	451
Boltzmann, epsilon-greedy, parameter noise etc.).	I-Review	I-5	Review	451
I guess it should be quite easy to make it configurable as well[line_break_token][line_break_token][line_break_token][1] <a href="https://github.com/catalyst-team/catalyst" target="_blank" rel="nofollow">https://github.com/catalyst-team/catalyst</a>[line_break_token][2] <a href="https://arxiv.org/pdf/1903.00027.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1903.00027.pdf</a>[line_break_token]	O	O	Review	451
[line_break_token]Thank you for taking the time to review this paper and for your thoughtful comments.	O	O	Reply	451
Please see our responses below.	O	O	Reply	451
[line_break_token][line_break_token]---[line_break_token]‚ÄúComparison with the library [1] is missing‚Ä¶‚Äù[line_break_token]Thanks for bringing this library to our attention.	B-Reply	B-1	Reply	451
We added a comparison in Table 3, and the similarities and differences are summarized below:[line_break_token][line_break_token]Both libraries addresses reproducibility using config/spec files, although SLM Lab uses the git SHA to reference code as opposed to saving source as Catalyst does.	I-Reply	I-1	Reply	451
They both report benchmark results, however SLM Lab is more comprehensive.	I-Reply	I-1	Reply	451
Parallelization in Catalyst can scale to multiple machines, where as parallelization in SLM Lab is focused on the single machine use case.	I-Reply	I-1	Reply	451
SLM Lab also logs to Tensorboard, and provides a more extensive automatic experiment analysis.	I-Reply	I-1	Reply	451
Finally, Catalyst does not appear to provide hyper-parameter search.	I-Reply	I-1	Reply	451
This is a key feature of SLM Lab and is configured in the spec file.	I-Reply	I-1	Reply	451
[line_break_token][line_break_token]---[line_break_token]‚ÄúI am not sure that ICLR is the right venue for such paper...‚Äù[line_break_token]Our paper is as much an empirical contribution as a software contribution.	B-Reply	B-2	Reply	451
It provides what is, to the best of our knowledge, the most comprehensive set of benchmark RL results published to date (including entirely new results for the SAC algorithm), and moreover one which is a fairer comparison between RL algorithms than previous benchmarks due to the SLM Lab design that minimizes implementation differences.	I-Reply	I-2	Reply	451
It also includes a new hybrid parallelization capability applicable to all RL algorithms.	I-Reply	I-2	Reply	451
[line_break_token][line_break_token]Even considering just the software contribution of the SLM Lab library, however, we feel that ICLR is an appropriate venue for this paper.	I-Reply	I-2	Reply	451
 We note that the call for papers specifically lists ‚Äúimplementation issues, parallelization, software platforms, hardware‚Äù as a relevant topic.	I-Reply	I-2	Reply	451
We also note that some of the libraries cited in Table 3 have been published at similar venues, such as ELF at NeurIPS 2017, and RLLib at ICML 2018.	I-Reply	I-2	Reply	451
[line_break_token][line_break_token]---[line_break_token]‚ÄúHow difficult it is to implement distributional algorithms in your framework?‚Äù[line_break_token]This is on the SLM Lab roadmap.	B-Reply	B-4	Reply	451
 It is not difficult, and can be implemented as an extension of the DQN class with a custom network output sampling mechanism and loss computation.	I-Reply	I-4	Reply	451
[line_break_token][line_break_token]---[line_break_token]‚ÄúWhat about different exploration strategies?...‚Äù[line_break_token]Boltzmann and epsilon-greedy exploration strategies are implemented and can be specified in the spec file.	B-Reply	B-5	Reply	451
We have updated the paper to make it clear that this is available.	I-Reply	I-5	Reply	451
[line_break_token][line_break_token]Parameter noise is not currently implemented, but adding it is relatively straightforward, and it is on our future roadmap	I-Reply	I-5	Reply	451

This paper focuses on decoding/generation in neural sequence models (specifically machine translation) in a non-autoregressive manner that instead of generating in a left-to-right manner, focuses on generating sequences by picking a length first ,and then indices to replace in a deterministic or random scheme and, finally using a context sensitive distribution over vocabulary (using BERT-like masked LM scheme)  to pick the word to replace.	O	O	Review	20047
In practice, this procedure of picking indices and words to replace is repeated T number of times and hence the final sequence is obtained by this iterative refinement procedure.	O	O	Review	20047
This is an interesting and important research direction because not only would it result in better and context sensitive greedy/approximate-MAP decoded outputs, but also opens up opportunities for parallelization of the decoding procedure which is difficult to achieve with left-to-right decoders.	O	O	Review	20047
[line_break_token]That said, the results are fairly inconclusive and the practical implementation does leave things desired for a practical decoder.	O	O	Review	20047
As observed by the authors, different deterministic strategies for choosing T results in very different performances among the variants of the proposed approach.	O	O	Review	20047
Besides among the variants, one clear pattern is that uniformly random picking of indices is worse than other schemes (left-to-right, least-to-most, easy-first) which is not unexpected but no conclusive empirical evidence can be found for relative differences between the performances of other 3 schemes.	B-Review	B-3	Review	20047
Moreover, the proposed decoding variants generally perform worse than or at best similarly to standard autoregressive baselines.	I-Review	I-3	Review	20047
As authors note, this is due to the mismatch between the method in which the model was trained and the decoding procedure which is not surprising, but at the same time this does not give insight into the effectiveness of the proposed decoding objective.	I-Review	I-3	Review	20047
The central question is: if the training prefers left-to-right generation then how valuable is it to device  more reasonable but incompatible decoding procedures?	B-Review	B-1	Review	20047
[line_break_token][line_break_token]Also, authors also note that index picking schemes investigated in the paper are heuristic based and a more interesting decoder could be learned if index selection procedure itself was learned with features depending on the previous index selection states, decoded states Y, and other relevant quantities.	B-Review	B-2	Review	20047
They attribute poor performance of the proposed decoder to the nature of index selection approaches investigated in the paper.	I-Review	I-2	Review	20047
I think the paper would be strengthened with results with a more sophisticated learned index selection procedure in addition to the heuristics investigated in this paper.	I-Review	I-2	Review	20047
[line_break_token][line_break_token]Overall, while the idea and motivation behind this work is exciting, the inconclusive results and the approaches for practical implementation leave open significant room for improvement.	O	O	Review	20047
e appreciate that you found our work exciting!	B-Reply	B-3	Reply	20047
We disagree that there is no clear pattern on which decoding strategy to use for linear/constant time decoding scenarios.	I-Reply	I-3	Reply	20047
For linear time case (Table 1), left2right and easy-first decoding strategies outperform both least2most and uniform decodings while left2right having slight performance improvement over easy-first decoding strategy.	I-Reply	I-3	Reply	20047
These results hold across various linear-time decoding hyperparameter settings (beam size, decoding budget (T) and whether using reranking with an autoregressive model).	I-Reply	I-3	Reply	20047
For constant-time decoding results (Table 3) least2most decoding strategy works best when annealing number of generated symbols at each step (L -&gt; 1) while easy-first strategy works best when generating constant L/T number of tokens.	O	O	Reply	20047
In practice if one would to use our method, left2right is recommended for linear-time translation and least2most is recommended for constant-time translation with annealing number of tokens L-&gt;1.	O	O	Reply	20047
[line_break_token][line_break_token]&gt; ‚ÄúThe central question is: if the training prefers left-to-right generation then how valuable is it to device more reasonable but incompatible decoding procedures?‚Äù[line_break_token][line_break_token]We don‚Äôt think it‚Äôs obvious that left2right decoding is the best decoding strategy for all possible decoding settings.	B-Reply	B-1	Reply	20047
For example, from our experiments in the constant time decoding, left2right decoding performs considerably worse than least2most decoding.	I-Reply	I-1	Reply	20047
Furthermore, given the proliferation of and advantages of non-left-to-right pretraining objectives, we argue that it is worthwhile to investigate non-left-to-right decoding strategies.	I-Reply	I-1	Reply	20047
Such strategies have additional potential benefits, such as being easier to parallelize.	I-Reply	I-1	Reply	20047
[line_break_token][line_break_token]&gt; ‚ÄúI think the paper would be strengthened with results with a more sophisticated learned index selection procedure in addition to the heuristics investigated in this paper.	O	O	Reply	20047
‚Äù[line_break_token][line_break_token]We would agree that learning position selecting mechanism would be interesting to investigate, but we think this would be a significant undertaking on its own, as we would need to develop and test ways of providing generation order error signal and methods to learn against that signal	O	O	Reply	20047

This paper proposed a study on audio adversarial examples and conclude the input transformation-based defenses do not work very well on the audio domain, especially for adaptive attacks.	O	O	Review	508
They also point out the importance of temporal dependency in designing defenses which is specific for the audio domain.	O	O	Review	508
This observation is very interesting and inspiring as temporal dependency is an important character that should be paid attention to in the field of audio adversarial examples.	O	O	Review	508
They also design some adaptive attacks to the defense based on temporal dependency but either fail to attack the system or can be detected by the defense.	O	O	Review	508
[line_break_token][line_break_token]Based on the results in Table S7, it seems like being aware of the parameter k when designing attacks are very helpful for reducing the AUC score.	O	O	Review	508
My question is if the attacker uses the random sample K_A to generate the adversarial examples, then how the performance would be.	B-Review	B-1	Review	508
Another limitation of this work is that the proposed defense can differentiate the adversarial examples to some extent, but the ASR is not able to make a right prediction for adversarial examples.	B-Review	B-2	Review	508
In addition, the writing of Section 4 is not very clear and easy to follow.	B-Review	B-3	Review	508
[line_break_token][line_break_token]In all, this paper proposed some interesting findings and point out a very important direction for audio adversarial examples.	O	O	Review	508
If the author can improve the writing in experiments and answer the above questions, I would support for the acceptance.	O	O	Review	508
[line_break_token][line_break_token][line_break_token]	O	O	Review	508
We appreciate your insightful comments and feel sorry about hard following in Section 4.	O	O	Reply	508
Here are some response to questions you concerned and we‚Äôve uploaded new version of our paper with clearer structure.	O	O	Reply	508
[line_break_token][line_break_token]Q: My question is if the attacker uses the random sample K_A to generate the adversarial examples, then how the performance would be.	O	O	Reply	508
[line_break_token]A: Following your comment, we added the corresponding experiments in TableA7 in Appendix when k_A = rand(0.2, 0.8).	B-Reply	B-1	Reply	508
We observe that even k_A is chosen randomly, the results are similar to k_A equals to a fixed number when k_D is also a random number.	I-Reply	I-1	Reply	508
And when k_D is a fixed number, the attack detection results are also good because if k_A is not close to defender‚Äôs k_D, the attack effectiveness will be limited.	I-Reply	I-1	Reply	508
[line_break_token][line_break_token]Q: Another limitation of this work is that the proposed defense can differentiate the adversarial examples to some extent, but the ASR is not able to make a right prediction for adversarial examples[line_break_token]A: Yes, the proposed TD method is a detection instead of defense method, and our goal is to tell the adversarial instances apart from benign.	B-Reply	B-2	Reply	508
In many scenarios, detection is very important.	I-Reply	I-2	Reply	508
For instance, in malware or adversarial audio based attacks, if users can detect adversarial instances and remove or ignore them, it indeed helps to ensure system security.	I-Reply	I-2	Reply	508
[line_break_token][line_break_token]Q: writing in Section 4[line_break_token]A: We apologize that we did not put enough efforts in presenting the experimental results in Section 4.	B-Reply	B-3	Reply	508
Based on the review comments, we have reorganized and revised Section 4 to make the presentation clearer, including adding new tables (Tables 1 & 4) that highlight the overall structure of our attack & defense / detection	O	O	Reply	508

Summary:[line_break_token][line_break_token]The paper focuses on designing a generative framework for 3-D point data clouds.	O	O	Review	120
These point clouds correspond to objects shapes in 3-dimensions.	O	O	Review	120
According to the paper, previous approaches for generating such 3-D point clouds involved autoencoder and GANs used separately.	O	O	Review	120
The authors propose a framework combining both autoencoder and GAN in a single network.	O	O	Review	120
The authors claim that part of the network learns effective latent space embedding for 3-d point clouds corresponding to different objects and thus the entire network is more effective in generating 3-d point cloud.	O	O	Review	120
Experimental results are presented to support the claims for efficient embeddings, and better generation of 3-d point clouds.	O	O	Review	120
[line_break_token][line_break_token]Decision[line_break_token][line_break_token]The paper has some lacking in explanation.	O	O	Review	120
I am particularly interested in the answers to the following questions:[line_break_token]1.	O	O	Review	120
[tab_token]The encoder module (denoted as E in the paper) uses a loss function that apparently does not involve the encoder output (z in the paper).	B-Review	B-1	Review	120
How the module weights can be updated this way is unclear.	I-Review	I-1	Review	120
[line_break_token]2.	O	O	Review	120
[tab_token]G1 is updated twice in each iteration, according to algorithm 1 in paper (once during update of ùúΩG1 and ùúΩG).	B-Review	B-2	Review	120
How the generator G1‚Äôs output manages to converge to output z from encoder E is unclear.	I-Review	I-2	Review	120
[line_break_token]3.	O	O	Review	120
[tab_token]The authors claim that the proposed model has both better performance and efficiency.	B-Review	B-3	Review	120
Although experimental results are provided to support claim for better performance, none have been offered for efficiency claim. (	I-Review	I-3	Review	120
calculation of EMD distance seems to be very expensive computationally)[line_break_token][line_break_token]Feedback[line_break_token][line_break_token]For section 5.5, a quantitative analysis might make the claim for portability of the framework stronger.	B-Review	B-4	Review	120
In paragraph 1 of introduction, disadvantage of 3d point cloud data can be better explained.	I-Review	I-4	Review	120
[line_break_token]	O	O	Review	120
hank you for your review, and we hope that our revisions address your concerns.	O	O	Reply	120
[line_break_token]Q1:[line_break_token]The encoder module (denoted as E in the paper) uses a loss function that apparently does not involve the encoder output (z in the paper).	O	O	Reply	120
How the module weights can be updated this way is unclear[line_break_token][line_break_token]A:[line_break_token]Thanks for reading our paper carefully, and it id indeed a good question.	B-Reply	B-1	Reply	120
We use the loss between and to update the parameter E. Although z did not pass g2, we can still do this through some tricks in the code.	I-Reply	I-1	Reply	120
The purpose of this design is to not only help encoder generate latent code, but also help minimize the distance between representation z and \bar{z} from encoder.	I-Reply	I-1	Reply	120
[line_break_token][line_break_token]Q2: G1 is updated twice in each iteration, according to algorithm 1 in paper (once during update of G1 and G).	O	O	Reply	120
How the generator G1‚Äôs output manages to converge to output z from encoder E is unclear.	O	O	Reply	120
[line_break_token][line_break_token]AÔºö[line_break_token]Thanks.	B-Reply	B-2	Reply	120
The reason why we let G1 be updated twice in one iteration is as follow: the first time we use Lgan(noise \rightarrow z) to only update the G1 parameter, and the purpose of this step is to make the distribution of close to that of z; and then we use loss LG to update total model G including G1, in order to let G1 learn global information and increase the diversity of generator.	I-Reply	I-2	Reply	120
[line_break_token][line_break_token]Q3:[line_break_token]The authors claim that the proposed model has both better performance and efficiency.	O	O	Reply	120
Although experimental results are provided to support claim for better performance, none have been offered for efficiency claim. (	O	O	Reply	120
calculation of EMD distance seems to be very expensive computationally)[line_break_token][line_break_token]A:[line_break_token]Thanks.	B-Reply	B-2	Reply	120
The reason why we claim that our model has better efficiency is that our approach is one-stage, and the previous methods with similar ideas are two-stage.	B-Reply	B-3	Reply	120
The previous approach need to train a model first and then use pre-trained model‚Äôs result to train generator, while our model can be trained end-to-end, which will greatly shorten the training time.	I-Reply	I-3	Reply	120
[line_break_token][line_break_token]Q4:[line_break_token]For section 5.5, a quantitative analysis might make the claim for portability of the framework stronger.	O	O	Reply	120
In paragraph 1 of introduction, disadvantage of 3d point cloud data can be better explained.	O	O	Reply	120
[line_break_token][line_break_token]A:[line_break_token]Thanks for you suggestion.	B-Reply	B-4	Reply	120
We have added the quantitative analysis of the 2D results in section 5.5 and modified the paragraph 1	I-Reply	I-4	Reply	120

This paper proposes active learning with partial feedback, which means at each step, the learner actively chooses both which example to label and which binary question to ask, then learn the multi-class classifier with these partial labels.	O	O	Review	298
Three different sampling strategies are used during active learning.	O	O	Review	298
Experimental results demonstrate that the proposed ALPF strategy outperforms existing baselines on the predicting accuracy under a limited budget.	O	O	Review	298
[line_break_token][line_break_token]This paper is well-written.	O	O	Review	298
The main ideas and claims are clearly expressed.	O	O	Review	298
ALPF combines active learning with learning from partial labels.	O	O	Review	298
This setting is interesting and important, especially when the number of categories is large and share some hierarchical structure.	O	O	Review	298
The experimental results are promising.	O	O	Review	298
My main concern about this work is the lack of theoretical guarantees, which is usually important for active learning paper.	B-Review	B-1	Review	298
it‚Äôs better to provide some analysis on the efficiency of ALPF to further improve the quality of the paper.	I-Review	I-1	Review	298
[line_break_token]I have the following questions for the authors:[line_break_token]+Why vanilla active learning strategy does not work well?	B-Review	B-2	Review	298
Which uncertainty measurement do you use here?	I-Review	I-2	Review	298
[line_break_token]+The performances of this work heavily rely on the taxonomy of labels, while in some cases the taxonomy of labels is not tree structure but a graph, i.e. a label may belong to multiple hyper-labels.	B-Review	B-3	Review	298
Can ALPF still work on these cases?	I-Review	I-3	Review	298
[line_break_token]	O	O	Review	298
We thank the reviewer for their thoughtful feedback and were glad to see that you found our proposed setting to be both interesting and important.	O	O	Reply	298
We would like to respond to your concerns briefly:[line_break_token][line_break_token]First, concerning your questions:[line_break_token]***Re the failure of vanilla active learning***[line_break_token]Since theoretical analysis guaranteeing the performance of active + deep learning has yet to be established, it‚Äôs hard to say *why* vanilla uncertainty-sampling-based active learning doesn‚Äôt work so well when applied on image classification datasets with convolutional neural networks.	B-Reply	B-2	Reply	298
However, we are not the first to find this.	I-Reply	I-2	Reply	298
Take for example the results Active Learning for Convolutional Neural Networks: A Core Set Approach (<a href="https://arxiv.org/pdf/1708.00489.pdf)," target="_blank" rel="nofollow">https://arxiv.org/pdf/1708.00489.pdf),</a> which was published at ICLR 2018, where uncertainty sampling and even the more recent deep Bayesian active learning by disagreement perform no better than random on CIFAR 10 and only marginally better for CIFAR 100.	O	O	Reply	298
In contrast, vanilla AL strategies have demonstrated promise on a number of NLP tasks (e.g. <a href="https://arxiv.org/pdf/1808.05697.pdf)."	O	O	Reply	298
target="_blank" rel="nofollow">https://arxiv.org/pdf/1808.05697.pdf).</a>[line_break_token][line_break_token]***Re the taxonomy of labels***[line_break_token]While tree-structured taxonomies are especially convenient, our methods do not in principle depend specifically on tree structure, requiring only a list of composite labels.	B-Reply	B-3	Reply	298
One can draw a parallel to general formulations of the game twenty questions where the available set of questions needn‚Äôt form tree.	I-Reply	I-3	Reply	298
We thank the reviewer for the suggestion for future work and plan to evaluate our methods on with label ontologies like the MeSH labels (medical subject headings) used to annotate biomedical articles that do not form a strict tree hierarchy (some nodes have multiple parents).	I-Reply	I-3	Reply	298
[line_break_token][line_break_token]Regarding theoretical guarantees, we agree with the reviewer that establishing theoretical guarantees for active learning with partial labels is an especially exciting direction and plan to pursue future work in this direction.	B-Reply	B-1	Reply	298
We note that generally there is a considerable gap between the theory of active learning and the practical methods established to cope with high dimensional data and modern classifiers and hope to close this gap in the future with rigorous analysis.	I-Reply	I-1	Reply	298

This paper compares the use of hand-designed and learned features for the analysis of 3d objects.	O	O	Review	43
The authors use an extensive set of 25 hand-designed features to obtain 92.33% accuracy for the task of agglomerating neuron fragments.	O	O	Review	43
They then explored fully supervised end to end learning of features from raw inputs, but only obtain 85.54% accuracy.	O	O	Review	43
However, because the data is small compared to its dimensionality, unsupervised learning provides some improvement.	O	O	Review	43
Finally, a dynamic pooling method allows them to match the hand-designed features score.	O	O	Review	43
Data augmentation however brings fully supervised and unsupervised approaches on par.	O	O	Review	43
[line_break_token][line_break_token]Novelty and quality: I am not very familiar with the literature in 3d analysis but the introduction suggests that feature learning (fully supervised and unsupervised) has not been used before or is not common.	B-Review	B-1	Review	43
If so, the methods themselves are not novel but their application to this particular field is.	I-Review	I-1	Review	43
It would be good if the authors could state clearly if this has ever been tried before or not.	I-Review	I-1	Review	43
The quality of the work is good and thorough.	O	O	Review	43
[line_break_token][line_break_token]Pros:[line_break_token]- directly comparing hand-designed and learned features is good.	O	O	Review	43
[line_break_token]- learned features are shown to be slightly superior in accuracy.	O	O	Review	43
Thank you for your comments.	O	O	Reply	43
[line_break_token][line_break_token]To our knowledge, this work is indeed the first to use representation learning in the context of 3d shape analysis, and we state this at the end of the introduction	B-Reply	B-1	Reply	43

This paper explores maximally expressive linear layers for jointly exchangeable data and in doing so presents a surprisingly expressive model.	O	O	Review	488
I have given it a strong accept because the paper takes a very well-studied area (convolutions on graphs) and manages to find a far more expressive model (in terms of numbers of parameters) than what was previously known by carefully exploring the implications of the equivariance assumptions implied by graph data.	O	O	Review	488
The result is particularly interesting because the same question was asked about exchangeable matrices (instead of *jointly* exchangeable matrices) by Hartford et al [2018] which lead to a model with 4 bases instead of the 15 bases in this model, so the additional assumption of joint exchangeability (i.e. that any permutations applied to rows of a matrix must also be applied to columns - or equivalently, the indices of the rows and columns of a matrix refer to the same items / nodes) gives far more flexibility but without losing anything with respect to the Hartford et al result (because it can be recovered using a bipartite graph construction - described below).	O	O	Review	488
So we have a case where an additional assumption is both useful (in that it allows for the definition of a more flexible model) and benign (because it doesn't prevent the layer from being used on the data explored in Hartford et al).	O	O	Review	488
[line_break_token][line_break_token]I only have a couple of concerns: [line_break_token]1 - I would have liked to see more discussion about why the two results differ to give readers intuition about where the extra flexibility comes from.	B-Review	B-1	Review	488
The additional parameters of this paper come from having parameters associated with the diagonal (intuitively: self edges get treated differently to other edges) and having parameters for the transpose of the matrix (intuitively: incoming edges are different to outgoing edges).	I-Review	I-1	Review	488
Neither of these assumptions apply in the exchangeable setting (where the matrix may not be square so the diagonal and transpose can't be used).	I-Review	I-1	Review	488
Because these differences aren't explained, the synthetic tasks in the experimental section make this approach look artificially good in comparison to Hartford et al  The tasks are explicitly designed to exploit these additional parameters - so framing the synthetic experiments as, "here are some simple functions for which we would need the additional parameters that we define" makes sense; but arguing that Hartford et al "fail approximating rather simple functions" (page 7) is misleading because the functions are precisely the functions on which you would expect Hartford et al to fail (because it's designed for a different setting).	I-Review	I-1	Review	488
[line_break_token]2 - Those more familiar of the graph convolution literature will be more familiar with GCN [kipf et al 2016] / GraphSAGE [Hamilton et al 2017] / Monti et al [2017] / etc.. Most of these approaches are more restricted version of this work / Hartford et al so we wouldn't expect them to perform any differently from the Hartford et al  baseline on the synthetic dataset, but including them will strengthen the author's argument in favour of the work.	B-Review	B-3	Review	488
I would have also liked to see a comparison to these methods in the the classification results.	B-Review	B-2	Review	488
[line_break_token]3 - Appendix A - the 6 parameters for the symmetric case with zero diagonal reduces to the same 4 parameters from Hartford et al if we constrained the diagonal to be zero in the output as well as the input.	B-Review	B-4	Review	488
This is the case when you map an exchangeable matrix into a jointly exchangeable matrix by representing it as a bipartite graph [0, X; X^T, 0]. So the two results coincide for the exchangeable case.	I-Review	I-4	Review	488
Might be worth pointing this out.	I-Review	I-4	Review	488
[line_break_token]	O	O	Review	488
We thank the reviewer for the detailed review.	O	O	Reply	488
Below we address the main concerns.	O	O	Reply	488
[line_break_token][line_break_token]--------------------------------------------------------------------------------------------------------------------------------[line_break_token]Q:‚Äùso framing the synthetic experiments as, "here are some simple functions for which we would need the additional parameters that we define" makes sense; but arguing that Hartford et al "fail approximating rather simple functions" (page 7) is misleading because the functions are precisely the functions on which you would expect Hartford et al to fail‚Äù[line_break_token][line_break_token]A: We agree with the reviewer and will change our wording accordingly.	B-Reply	B-1	Reply	488
[line_break_token]--------------------------------------------------------------------------------------------------------------------------------[line_break_token]Q:‚ÄùI would have liked to see more discussion about why the two results differ to give readers intuition about where the extra flexibility comes from‚Äù.	O	O	Reply	488
 ‚Äúthe two results coincide for the exchangeable case‚Äù[line_break_token][line_break_token]A: We agree with the reviewer that such a discussion will be helpful to the reader.	B-Reply	B-2	Reply	488
We will add such a discussion (in addition to the short discussion at the end of Appendix 1).	I-Reply	I-2	Reply	488
[line_break_token]--------------------------------------------------------------------------------------------------------------------------------[line_break_token]Q: Comparison to popular graph convolution methods (GCN [kipf et al 2016] / GraphSAGE [Hamilton et al 2017] / Monti et al [2017] / etc.).	O	O	Reply	488
[line_break_token][line_break_token]A: As discussed in our response to Reviewer 2, We will add a theoretical result that shows that our model is at least as powerful in terms of universality as [Kipf & Welling ICLR 2017].	O	O	Reply	488

Background disclaimer: I work in RL research for quite an amount of time, but I do not know much about the domain of distributed systems.	O	O	Review	20006
For this reason, I may not know the details of technical terms, and I might not be the best person to review this work (when compared with the literature in this field).	O	O	Review	20006
Nevertheless, below I try to give my evaluation based on reading the paper.	O	O	Review	20006
[line_break_token][line_break_token]====================[line_break_token]In this work, the authors applied value-based reinforcement learning to learn an optimal policy for global parameter tuning in the parameter server (PS) that trains machine learning models in a distributed way using  stochastic gradient descent.	B-Review	B-1	Review	20006
Example parameters include SGD hyper-parameters (such as learning rate) and system-level parameters.	I-Review	I-1	Review	20006
Immediate cost is to minimize the training time of the SGD algorithm, and i believe the states are the server/worker parameters.	I-Review	I-1	Review	20006
From the RL perspective, the algorithm used here is a standard DQN with discrete actions (choices of parameters).	I-Review	I-1	Review	20006
But in general I am puzzled why the action space is discrete instead of continuous, if the actions are the hyper-parameters.	I-Review	I-1	Review	20006
State transition wise, I am not sure if the states follow an action-dependent MDP transition, and therefore at this point I am not sure if DQN is the best algorithm for this applications (versus bandits/combinatorial bandits).	I-Review	I-1	Review	20006
 While it is impressive to see that RL beats many of the SOTA baselines for parameter tuning, I also find that instead of using data in the real system to do RL training, the paper proposes generating "simulation" data by training a separate DNN.	I-Review	I-1	Review	20006
I wonder how the performance would differ if the RL policy is trained on the batch real data.	I-Review	I-1	Review	20006
[line_break_token][line_break_token]	O	O	Review	20006
n the following, we list your concerns on the Problem I and our detailed responses.	O	O	Reply	20006
[line_break_token][line_break_token]Problem I:[line_break_token]In this work, the authors applied value-based reinforcement learning to learn an optimal policy for global parameter tuning in the parameter server (PS) that trains machine learning models in a distributed way using  stochastic gradient descent.	O	O	Reply	20006
Example parameters include SGD hyper-parameters (such as learning rate) and system-level parameters.	O	O	Reply	20006
Immediate cost is to minimize the training time of the SGD algorithm, and i believe the states are the server/worker parameters.	O	O	Reply	20006
From the RL perspective, the algorithm used here is a standard DQN with discrete actions (choices of parameters).	O	O	Reply	20006
In general I am puzzled why the action space is discrete instead of continuous, if the actions are the hyper-parameters.	O	O	Reply	20006
State transition wise, I am not sure if the states follow an action-dependent MDP transition, and therefore at this point I am not sure if DQN is the best algorithm for this applications (versus bandits/combinatorial bandits).	O	O	Reply	20006
[line_break_token][line_break_token]Response to Problem I:[line_break_token]Thank you for your kind review.	O	O	Reply	20006
First let us clarify the difference of our work with learning hyperparameters, then answer the question on actions and states.	B-Reply	B-1	Reply	20006
[line_break_token][line_break_token]In this paper, we learn an optimal ''synchronization policy'' used for the distributed training of machine learning models with Stochastic Gradient Descent (SGD) in Parameter-Server (PS)-based environment.	I-Reply	I-1	Reply	20006
This setting consists of one (or several) PS maintaining model parameters and receiving updated gradients from workers, and multiple workers pulling model parameters from PS, computing gradients and pushing them back to PS.	I-Reply	I-1	Reply	20006
[line_break_token][line_break_token]The synchronization policy is a mechanism to coordinate the execution progress of all workers in the PS setting.	I-Reply	I-1	Reply	20006
It determines in each step, i.e., whenever a worker pushes its gradient to the PS, whether this worker should continue to run for the next step or wait for sometime for the completion of some other workers.	I-Reply	I-1	Reply	20006
Thus, it is independent of the hyper-parameters of SGD and system parameters.	I-Reply	I-1	Reply	20006
Hence, we are trying to optimize the mechanism of the synchronization policy to save training time but not tuning the global hyperparameters of SGD.	I-Reply	I-1	Reply	20006
 In short, our work falls in the category of "learning how to learn" to train the underlying ML models while hyperparameter tuning falls in the category of "learning which model to learn" to optimize the hyperparameters of the underlying ML models.	I-Reply	I-1	Reply	20006
[line_break_token][line_break_token]To  this end, we formalize the design of a synchronization policy as a reinforcement learning problem (see Figure 1 in Page 5 for an illustration).	I-Reply	I-1	Reply	20006
In this RL problem, for the state we choose  features which characterize the execution progress of SGD training in each step.	I-Reply	I-1	Reply	20006
To ensure the expression power of the state, the state space in our problem is large when compared to more standard RL problem instances.	I-Reply	I-1	Reply	20006
Each state vector may contain dozens to hundreds of features (See the paragraphs in Page 4 entitled with "State" for more details).	I-Reply	I-1	Reply	20006
Therefore, we choose a deep neural network to represent the transition function \pi(S, a) and apply DQN to train the RL policy.	I-Reply	I-1	Reply	20006
The tabular and bandits algorithms are unable to represent the large and complex transition function in this application.	I-Reply	I-1	Reply	20006
[line_break_token][line_break_token]In our RL problem, each action represents a decision for each worker to run or wait at each step.	I-Reply	I-1	Reply	20006
Therefore, the action space is discrete.	I-Reply	I-1	Reply	20006
It contains at most 2^n actions for n workers since for each worker it need to be decided whether to run or wait, respectively.	I-Reply	I-1	Reply	20006
We choose a small but powerful action space containing three valid actions to enable fast training of the RL policy (See the paragraphs in Page 5 entitled with "Action" for more details).	I-Reply	I-1	Reply	20006
We design the state and action in this manner in our RL setting to ensure its generality while keeping training and inference efficiency.	I-Reply	I-1	Reply	20006
[line_break_token][line_break_token]The state clearly follows an action-dependent MDP transition since the next position of execution process is purely determined by the current state (where we are) and the next action (where we go)	I-Reply	I-1	Reply	20006

In this paper, the authors study an interesting problem called open-ended content style recombination, i.e., recombining the style of one image with the content of another image.	O	O	Review	642
In particular, the authors propose a VAE (variational autoencoder) based method (i.e., Style Transfer onto Open-Ended Content, STOC), which is optimized over a VAE reconstruction loss and/or a leakage filtering (LF) loss.	O	O	Review	642
More specifically, there are four variants of STOC, including CC (content classifier), CE (content encoding), PM (predictability minimization, Section 2.1) and LF (leakage filtering, Section 2.2).	O	O	Review	642
The main advantage of STOC is its ability to handle novel content from open domains.	O	O	Review	642
Experimental results on image synthesis and data set augmentation show the effectiveness of the proposed method in comparison with the state-of-the-art methods.	O	O	Review	642
The authors also study the comparative performance of four variants, i.e., CCF, CE, PM and LF.	O	O	Review	642
[line_break_token][line_break_token]Overall, the paper is well presented.	O	O	Review	642
[line_break_token][line_break_token]Some comments/suggestions:[line_break_token][line_break_token](i) The authors are suggested to include an analysis of the time complexity of the proposed method (including the four variants).	B-Review	B-1	Review	642
[line_break_token][line_break_token](ii) The authors are suggested to include more results with different configurations such as that in Table 1 in order to make the results more convincing.	B-Review	B-2	Review	642
[line_break_token]	O	O	Review	642
We thank the reviewer for the thoughtful evaluation and feedback.	O	O	Reply	642
Regarding the investigation of different model configurations, in the Appendix (Figure 8) we vary the coefficients of the various costs in the training objective function on the naturally-evaluated, synthetically-trained (NEST) task.	B-Reply	B-2	Reply	642
We show that each component cost contributes to the model‚Äôs overall performance.	I-Reply	I-2	Reply	642
Regarding time complexity, predictability minimization incorporates a GAN-like adversarial objective, which makes it strictly inferior to STOC in time complexity and--as we show in the paper--in the quality of synthesized images.	B-Reply	B-1	Reply	642
The penalty in the STOC leakage filtering loss is proportional to the number of within- and between-class pairs that are drawn from P^+ and P^- in a minibatch	I-Reply	I-1	Reply	642

This paper introduces a new way of interpreting the VQ-VAE, [line_break_token]and proposes a new training algorithm based on the soft EM clustering.	O	O	Review	1029
[line_break_token][line_break_token]I think the technical aspect of this paper is written concisely.	O	O	Review	1029
[line_break_token]Introducing the interpretation as hard EM seems natural for me, and the extension[line_break_token]to the soft EM training is sound reasonable.	O	O	Review	1029
[line_break_token]Mathematical complication is limited, this is also a plus for many non-expert readers.	O	O	Review	1029
[line_break_token][line_break_token]I'm feeling difficulties in understanding the experimental part.	B-Review	B-1	Review	1029
[line_break_token]To be honest, I think the experimental section is highly unorganized, not a quality for ICLR submission.	I-Review	I-1	Review	1029
[line_break_token]I'm just wondering why this happens, given clean and organized technical sections...[line_break_token][line_break_token]First, I'm confusing what is the main competent in the Table 1.	B-Review	B-2	Review	1029
[line_break_token]In the last paragraph of the page 6, it reads; [line_break_token]"Our implementation of VQ-VAE achieves a significantly better BLEU score and faster decoding speed compared to (10)."	I-Review	I-2	Review	1029
[line_break_token]However, Ref. (	I-Review	I-2	Review	1029
10) is not mentioned in the Table 1.	I-Review	I-2	Review	1029
Which BLEU is the score of Ref. (	I-Review	I-2	Review	1029
10)?	I-Review	I-2	Review	1029
[line_break_token][line_break_token]Second, terms "VQ-VAE", (soft?)"EM" and "our {model, approach}" are used in a confusing manner.	B-Review	B-3	Review	1029
[line_break_token]For example, in Table 1, below the row "Our Results", there are:[line_break_token]- VQ-VAE[line_break_token]- VQ-VAE with EM[line_break_token]- VQ-VAE + distillation[line_break_token]- VQ-VAE with EM + distillation[line_break_token][line_break_token]The "VQ-VAE" is not the proposed model, correct?	I-Review	I-3	Review	1029
[line_break_token]My understanding is that the proposal is a VQ-VAE solved via soft EM, which corresponds to "VQ-VAE with EM".	I-Review	I-3	Review	1029
[line_break_token][line_break_token]Third, a paragraph "Robustness of EM to Hyperparameters" is mis-leading.	B-Review	B-4	Review	1029
[line_break_token]The figure 3 does not show the robustness against a hyperparameter.	I-Review	I-4	Review	1029
[line_break_token]It shows the BLEU against the number of "samples" (in fact, there is no explanation about what the "samples" means).	I-Review	I-4	Review	1029
[line_break_token]I think hyperparameters are model constants such as the learning rate of the SGD, alpha-beta params for Adam, dimension of hidden units, number of layers, etc.	I-Review	I-4	Review	1029
The number of samples are not considered as a model hyperparameter; it's a dataset property.	I-Review	I-4	Review	1029
[line_break_token]The figure 5 shows the reconstructed images of the original VQ-VAE and the proposed VQ-VAE with EM.	B-Review	B-5	Review	1029
[line_break_token]However, there is no explanation which hyperparameter is tested to assess "the robustness to hyperparameters".	I-Review	I-5	Review	1029
[line_break_token][line_break_token]Fourth, there is no experimental report on the image reconstructions (with CIFAR and SVHN) in the main manuscript.	B-Review	B-6	Review	1029
[line_break_token]In fact, there is a short paragraph that mentions about the SVHN results, [line_break_token]but it only refers to the appendix.	I-Review	I-6	Review	1029
[line_break_token]I think appendix is basically used for additional results or proofs, that are not essential for the main message of the paper.	I-Review	I-6	Review	1029
[line_break_token]However, performance in the image reconstruction is one of the main claims written in the abstract, the intro, etc.	I-Review	I-6	Review	1029
[line_break_token]So, the authors should include the image reconstruction results in the main body of the paper.	I-Review	I-6	Review	1029
[line_break_token]Otherwise, claims about the image reconstructions should be removed from the abstract, etc.	I-Review	I-6	Review	1029
[line_break_token][line_break_token][line_break_token]+ Insightful understanding of the VQ-VAE as hard EM clustering[line_break_token]+ Natural and reasonable extension to soft-EM based training of the VQ-VAE[line_break_token]-- Unorganized experiment section.	B-Review	B-1	Review	1029
This simply ruins the quality of the technical part.	I-Review	I-1	Review	1029
[line_break_token][line_break_token][line_break_token]## after feedback[line_break_token][line_break_token]Some of my concerns are addressed the feedback.	O	O	Review	1029
[line_break_token]Considering the interesting technical parts, I raise the score upward, to the positive side.	O	O	Review	1029
We thank the reviewer for reading our paper.	O	O	Reply	1029
Below we address specific points raised by the reviewer:[line_break_token][line_break_token]>[line_break_token]I'm feeling difficulties in understanding the experimental part.	O	O	Reply	1029
[line_break_token]To be honest, I think the experimental section is highly unorganized, not a quality for ICLR submission.	O	O	Reply	1029
[line_break_token]I'm just wondering why this happens, given clean and organized technical sections...[line_break_token]>[line_break_token][line_break_token]We have made an effort to clean up the experimental section part in the updated draft.	B-Reply	B-1	Reply	1029
We would appreciate specific comments to help us make the experimental section more readable and organized.	I-Reply	I-1	Reply	1029
[line_break_token][line_break_token]>[line_break_token]First, I'm confusing what is the main competent in the Table 1.	O	O	Reply	1029
[line_break_token]In the last paragraph of the page 6, it reads; [line_break_token]"Our implementation of VQ-VAE achieves a significantly better BLEU score and faster decoding speed compared to (10)."	O	O	Reply	1029
[line_break_token]However, Ref. (	O	O	Reply	1029
10) is not mentioned in the Table 1.	O	O	Reply	1029
Which BLEU is the score of Ref. (	O	O	Reply	1029
10)?	O	O	Reply	1029
[line_break_token]>[line_break_token][line_break_token]This should be fixed in the updated version.	B-Reply	B-2	Reply	1029
[line_break_token][line_break_token]>[line_break_token]Second, terms "VQ-VAE", (soft?)"EM" and "our {model, approach}" are used in a confusing manner.	O	O	Reply	1029
[line_break_token]For example, in Table 1, below the row "Our Results", there are:[line_break_token]- VQ-VAE[line_break_token]- VQ-VAE with EM[line_break_token]- VQ-VAE + distillation[line_break_token]- VQ-VAE with EM + distillation[line_break_token][line_break_token]The "VQ-VAE" is not the proposed model, correct?	O	O	Reply	1029
[line_break_token]My understanding is that the proposal is a VQ-VAE solved via soft EM, which corresponds to "VQ-VAE with EM".	O	O	Reply	1029
[line_break_token]<[line_break_token][line_break_token]Yes VQ-VAE is not the proposed model, although we report it in "Our Results" because the implementation is different from Kaiser et al in two crucial aspects 1) No attention to source sequences for the discrete latents 2) Product Quantization (PQ) which the authors of Kaiser et al call DVQ is not being used.	B-Reply	B-3	Reply	1029
Hence we also report it in "Our Results".	I-Reply	I-3	Reply	1029
[line_break_token][line_break_token]>[line_break_token]Third, a paragraph "Robustness of EM to Hyperparameters" is mis-leading.	O	O	Reply	1029
[line_break_token]The figure 3 does not show the robustness against a hyperparameter.	O	O	Reply	1029
[line_break_token]It shows the BLEU against the number of "samples" (in fact, there is no explanation about what the "samples" means).	O	O	Reply	1029
[line_break_token]I think hyperparameters are model constants such as the learning rate of the SGD, alpha-beta params for Adam, dimension of hidden units, number of layers, etc.	O	O	Reply	1029
The number of samples are not considered as a model hyperparameter; it's a dataset property.	O	O	Reply	1029
[line_break_token]>[line_break_token][line_break_token]The number of samples used for EM training of VQ-VAE is a hyperparameter, how is it a property of the dataset?	B-Reply	B-4	Reply	1029
You are free to choose any number of samples regardless of the dataset.	I-Reply	I-4	Reply	1029
[line_break_token][line_break_token]>[line_break_token]The figure 5 shows the reconstructed images of the original VQ-VAE and the proposed VQ-VAE with EM.	O	O	Reply	1029
[line_break_token]However, there is no explanation which hyperparameter is tested to assess "the robustness to hyperparameters".	O	O	Reply	1029
[line_break_token]<[line_break_token][line_break_token]Our apologies, this should be robustness to initialization of the codebook.	B-Reply	B-5	Reply	1029
VQ-VAE/K-means is much more sensitive to a good initialization as compared to EM.	I-Reply	I-5	Reply	1029
[line_break_token][line_break_token]>[line_break_token]Fourth, there is no experimental report on the image reconstructions (with CIFAR and SVHN) in the main manuscript.	O	O	Reply	1029
[line_break_token]In fact, there is a short paragraph that mentions about the SVHN results, [line_break_token]but it only refers to the appendix.	O	O	Reply	1029
[line_break_token]I think appendix is basically used for additional results or proofs, that are not essential for the main message of the paper.	O	O	Reply	1029
[line_break_token][line_break_token]However, performance in the image reconstruction is one of the main claims written in the abstract, the intro, etc.	O	O	Reply	1029
[line_break_token]So, the authors should include the image reconstruction results in the main body of the paper.	O	O	Reply	1029
[line_break_token]Otherwise, claims about the image reconstructions should be removed from the abstract, etc.	O	O	Reply	1029
[line_break_token]>[line_break_token][line_break_token]We have removed all image references from the main section and now only report it in the Appendix.	B-Reply	B-6	Reply	1029
We hope this helps improving the quality and clarity of the main paper	I-Reply	I-6	Reply	1029

This paper proposes a new set of heuristics for learning a NN for generalising a set of NNs trained for more specific tasks.	O	O	Review	159
This particular recipe might be reasonable, but the semi-formal flavour is distracting.	B-Review	B-1	Review	159
The issue of model selection (clearly the main issue here) is not addressed.	B-Review	B-2	Review	159
A quite severe issue with this report is that the authors don't report relevant learning results from before (+-) 2009, and empirical comparisons are only given w.r.t.	B-Review	B-3	Review	159
other recent heuristics.	I-Review	I-3	Review	159
This makes it for me not possible to advice publication as is.	O	O	Review	159
We thank the reviewer for time and feedback.	O	O	Reply	159
We think the questions aren‚Äôt precise enough for us to act upon:[line_break_token]1.	O	O	Reply	159
We‚Äôd appreciate if the reviewer can point out the parts that are according to the reviewer‚Äôs opinion `semi-formal‚Äô?	B-Reply	B-1	Reply	159
We are more than happy to revise the text but are currently left guessing, particularly since another reviewer points out that the paper is `well written.	I-Reply	I-1	Reply	159
‚Äô [line_break_token]2.	O	O	Reply	159
We compare to recent baselines, in particular state-of-the-art methods like PNN and PathNet.	B-Reply	B-3	Reply	159
If the reviewer would specify which papers from before 2009 we should compare to, we are very happy to include a statement, assuming that PNN and/or PathNet or their predecessors haven‚Äôt compared to those already.	I-Reply	I-3	Reply	159
[line_break_token]3.	O	O	Reply	159
To the best of our knowledge, the two baselines (PNN and PathNet) we compare with are the state-of-the-art RL transfer frameworks.	B-Reply	B-3	Reply	159

########## UPDATED AFTER AUTHOR RESPONSE ##########[line_break_token][line_break_token]Thanks for the good revision and response that addressed most of my concerns.	O	O	Review	390
I am bumping up my score.	O	O	Review	390
[line_break_token][line_break_token]###############################################[line_break_token][line_break_token][line_break_token]This paper presents a Disentangled Inferred Prior (DIP-VAE) method for learning disentangled features from unlabeled observations following the VAE framework.	O	O	Review	390
The basic idea of DIP-VAE is to enforce the aggregated posterior q(z) = E_x [q(z | x)] to be close to an identity matrix as implied by the commonly chosen standard normal prior p(z).	O	O	Review	390
The authors propose to moment-match q(z) given it is hard to minimize the KL-divergence between q(z) and p(z).	O	O	Review	390
This leads to one additional term to the regular VAE objective (in two parts, on- and off-diagonal).	O	O	Review	390
It has the similar property as beta-VAE (Higgins et al 2017) but without sacrificing the reconstruction quality.	O	O	Review	390
Empirically the authors demonstrate that DIP-VAE can effectively learn disentangled features, perform comparably better than beta-VAE and at the same time retain the reconstruction quality close to regular VAE (beta-VAE with beta = 1).	O	O	Review	390
[line_break_token][line_break_token]The paper is overall well-written with minor issues (listed below).	B-Review	B-9	Review	390
I think the idea of enforcing an aggregated (marginalized) posterior q(z) to be close to the standard normal prior p(z) makes sense, as opposed to enforcing each individual posterior q(z|x) to be close to p(z) as (beta-)VAE objective suggests.	I-Review	I-9	Review	390
I would like to make some connection to some work on understanding VAE objective (Hoffman & Johnson 2016, ELBO surgery: yet another way to carve up the variational evidence lower bound) where they derived something along the same line of an aggregated posterior q(z).	O	O	Review	390
In Hoffman & Johnson, it is shown that KL(q(z) | p(z)) is in fact buried in ELBO, and the inequality gap in Eq (3) is basically a mutual information term between z and n (the index of the data point).	O	O	Review	390
Similar observations have led to the development of VAMP-prior (Tomczak & Welling 2017, VAE with a VampPrior).	O	O	Review	390
Following the derivation in Hoffman & Johnson, DIP-VAE is basically adding a regularization parameter to the KL(q(z) | p(z)) term in standard ELBO.	O	O	Review	390
I think this interpretation is complementary to (and in my opinion, more clear than) the one that‚Äôs described in the paper.	B-Review	B-9	Review	390
[line_break_token][line_break_token]My concerns are mostly regarding the empirical studies: [line_break_token][line_break_token]1.	O	O	Review	390
One of my main concern is on the empirical results in Table 1.	B-Review	B-1	Review	390
The disentanglement metric score for beta-VAE is suspiciously lower than what‚Äôs reported in Higgins et al where they reported a 99.23% disentanglement metric score on 2D shape dataset.	I-Review	I-1	Review	390
I understand the linear classier is different, but still the difference is too large to ignore.	I-Review	I-1	Review	390
Hence my current more neutral review rating.	I-Review	I-1	Review	390
[line_break_token][line_break_token]2.	O	O	Review	390
Regarding the correlational plots (the bottom row of Table 3 and 4), I don‚Äôt think I can see any clear patterns (especially on CelebA).	B-Review	B-2	Review	390
I wonder what‚Äôs the point of including them here and if there is a point, please explain them clearly in the paper.	O	O	Review	390
[line_break_token][line_break_token]3.	B-Review	B-3	Review	390
Figure 2 is also a little confusing to me.	I-Review	I-3	Review	390
If I understand the procedure correctly, a good disentangled feature would imply smaller correlations to other features (i.e., the numbers in Figure 2 should be smaller for better disentangled features).	I-Review	I-3	Review	390
However, looking at Figure 2 and many other plots in the appendix, I don‚Äôt think DIP-VAE has a clear win here.	I-Review	I-3	Review	390
Is my understanding correct?	I-Review	I-3	Review	390
If so, what exactly are you trying to convey in Figure 2?	I-Review	I-3	Review	390
[line_break_token][line_break_token]Minor comments: [line_break_token][line_break_token]1.	O	O	Review	390
In Eq (6) I think there are typos in terms of the definition of Cov_q(z)(z)?	B-Review	B-4	Review	390
It appears as only the second term in Eq (5).	I-Review	I-4	Review	390
[line_break_token][line_break_token]2.	O	O	Review	390
Hyperparameter subsection in section 3: Shouldn‚Äôt \lambda_od be larger if the entanglement is mainly reflected in the off-diagonal entries?	B-Review	B-5	Review	390
Why the opposite?	I-Review	I-5	Review	390
[line_break_token][line_break_token]3.	B-Review	B-3	Review	390
Can you elaborate on how a running estimate of Cov_p(x)(\mu(x)) is maintained (following Eq (6)).	B-Review	B-6	Review	390
It‚Äôs not very clear at the current state of the paper.	I-Review	I-6	Review	390
[line_break_token][line_break_token]4.	O	O	Review	390
Can we have error bars in Table 2?	B-Review	B-7	Review	390
Some of the numbers are possibly hitting the error floor.	I-Review	I-7	Review	390
[line_break_token][line_break_token]5.	O	O	Review	390
Table 5 and 6 are not very necessary, unless there is a clear point.	B-Review	B-8	Review	390
Thank you for the careful reading of the paper and thoughtful comments!	O	O	Reply	390
We were not aware of the work [Hoffman & Johnson 2016, ELBO Surgery] and it looks like the method can also be motivated from that perspective.	O	O	Reply	390
However we are not sure about your note ‚Äúthe inequality gap in Eq (3) is basically a mutual information term between z and n (the index of the data point)‚Äù -- it looks like the gap between KL(q(z|x)||p(z)) and KL(q(z)||p(z)) is the mutual information term between z and n, whereas the Inequality (3) compares KL(q(z|x)||p(z|x)) and KL(q(z)||p(z)).	B-Reply	B-9	Reply	390
[line_break_token][line_break_token][[Disentanglement metric score on \beta-VAE:]][line_break_token]We found out that \beta-VAE for \beta=60 was not trained to convergence which now gives the best metric score for \beta-VAE on 2DShapes data (95.7%).	B-Reply	B-1	Reply	390
We have updated the Table 1 and Figure 1 with new results. [	I-Reply	I-1	Reply	390
Higgins et al, 2017] report 99.23% score on 2D shape which is close to what we get.	I-Reply	I-1	Reply	390
Apart from the linear classifier, the difference could also be due to the evaluation protocol where in [Higgins et al, 2017]  that trained 30 \beta-VAE models with different random seeds and ‚Äúdiscarded the bottom 50% of the thirty resulting scores and reported the remaining results‚Äù (quoting verbatim from [Higgins et al, 2017]).	I-Reply	I-1	Reply	390
We also discovered in this duration that the metric proposed in [Higgins et al, 2017] is not a good indicator of disentanglement seen in the latent traversal plots (ie, decoder‚Äôs output by varying one latent while fixing others).	I-Reply	I-1	Reply	390
We added a short section (Sec 3) on the new metric we propose (referred as Separated Attribute Predictability or SAP score) which is much better aligned with the subjective disentanglement we see in the latent traversals.	I-Reply	I-1	Reply	390
We have also added plots for SAP score vs reconstruction error (Fig 1 and 2).	I-Reply	I-1	Reply	390
[line_break_token][line_break_token][[Correlation plots:]][line_break_token]We agree that these plots were not conveying any insights or quantitative measure for disentanglement.	B-Reply	B-2	Reply	390
We have omitted them in the revised version.	I-Reply	I-2	Reply	390
[line_break_token][line_break_token][[Fig 2 in the submitted version:]][line_break_token]As CelebA dataset has many ground truth attributes which are correlated with each other, it is not possible to infer different dimensions of latents capturing these (at least with the current approaches).	B-Reply	B-3	Reply	390
Through this plot we were trying to show that the top attributes corresponding to a given dimension are semantically more similar for our method compared to the baselines.	I-Reply	I-3	Reply	390
As you rightly noticed this is a subjective question so we have omitted these plots in the revised version.	I-Reply	I-3	Reply	390
[line_break_token][line_break_token][[Cov_{q(z)}[z] in Eq 6:]][line_break_token]The first term in Cov_{q(z)}[z] in Eq 5 is a diagonal matrix (expectation of variance of variational posterior, which is a Gaussian with diagonal covariance) and contributes only to the variances of z~q(z), so in the regularizer we had considered only the second term Cov_{p(x)} [\mu(x)] which is a dense square matrix.	B-Reply	B-4	Reply	390
However we have now included another variant (DIP-VAE-II) where the regularizer uses complete Cov_{q(z)}[z]. This actually provides better results on 2D Shapes data.	I-Reply	I-4	Reply	390
[line_break_token][line_break_token][[Hyperparameters \lambda_od and \lambda_d:]][line_break_token]We have included a discussion on this in the paragraph after Eq 5.	B-Reply	B-5	Reply	390
Essentially, penalizing the off-diagonal entries of Cov_{p(x)} [\mu(x)] also ends up reducing the diagonals of this matrix as off-diagonal are really derived from the diagonals (product of square root of diagonals for each example followed by averaging over examples).	I-Reply	I-5	Reply	390
Hence holding the diagonals to a fixed value was important.	I-Reply	I-5	Reply	390
We found that \lambda_d > \lamda_od was better for decreasing the covariance without impacting the variance.	O	O	Reply	390
[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token][[Running estimate of Cov_p(x)(\mu(x)):]][line_break_token]If the estimate using the current minibatch is B and the previous cumulative estimate is C, we take a combination B + a*C with ‚Äòa‚Äô being the inertia parameter (0.95 or so) and then normalize by (1/1-a).	B-Reply	B-6	Reply	390
C is treated as constant while backpropagating the gradients.	I-Reply	I-6	Reply	390

The authors of this paper analyse feed-forward networks of linear rectifier units (RELUs) in terms of the number of regions in which they act linearly.	O	O	Review	61
 They give an upper bound on the number of regions for networks with a single hidden layer based on known results in geometry, and then show how deeper networks can have a much larger number of regions by constructing examples.	O	O	Review	61
  The constructions form the main novel technical contribution, and they seem non-trivial and interesting.	O	O	Review	61
[line_break_token][line_break_token]Overall I think this is a good and interesting paper.	O	O	Review	61
 It is well written with the notable exception of the proof of theorem 8 and the latter half of the introduction.	O	O	Review	61
 In most spots, the math is precise and accessible (to me anyway), the results nicely broken into lemmas, and the diagrams are very useful for providing intuition.	O	O	Review	61
[line_break_token][line_break_token]These results can be interpreted as separating networks with a single hidden layer from deep networks in terms of the types of functions they can efficiently compute.	O	O	Review	61
 However, number of linear regions is a pretty abstract notion, and it isn't obvious what these results can say about the expressibility by neural nets of functions that we can actually write down.	O	O	Review	61
 Do you know of any natural examples of functions that require a finite but super-exponential number of regions?	O	O	Review	61
 [line_break_token][line_break_token]Unfortunately, region counting can't say anything about the representability of functions defined on such input spaces of the form S^n0 where S is a finite set, since there are only |S|^n0 input values, and |S|^n0 < n^n0 = region upper bound.	O	O	Review	61
[line_break_token][line_break_token][line_break_token]About Theorem 8: [line_break_token][line_break_token]After hours trying to understand the proof of Theorem 8 I gave up.	O	O	Review	61
 However, I was able to use Prop 7, and intuition provided from the diagrams, to prove a slightly different version of Thm 8 myself, and so I think the result is correct, and the proof is probably trying to describe basically the same thing I came up with (except my proof went from the top layer down, instead of the bottom layer up).	O	O	Review	61
 So while I don't doubt the correctness of the statement of Thm 8, but the write-up of the proof of Thm 8 needs to be completely redone to be understandable and intuitive.	O	O	Review	61
 I don't think you need to make it 100% formal (Prop 7 isn't completely formal either, but it's fine as is), but you need to make it possible to understand with a reasonable amount of effort.	O	O	Review	61
[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]Detailed comments:[line_break_token]---[line_break_token][line_break_token]Title: Please pick a different title.	B-Review	B-1	Review	61
 These are feed-forward networks so calling the regions 'inference regions' doesn't make sense.	I-Review	I-1	Review	61
[line_break_token][line_break_token]Abs: Why is it 'computational geometry' and not just 'geometry'?	O	O	Review	61
 What is specifically computational about arrangements of hyperplanes?	O	O	Review	61
[line_break_token][line_break_token]Page 2: Missing from the review of previous results about the power networks is all of the work done on threshold units (see the papers of Wolfgang Maass for example, or the seminal of Hajnal et al proving lower bounds for shallow threshold networks).	B-Review	B-2	Review	61
 Unlike the single paper by Hastad et al cited, none of these require the weights to be non-negative.	I-Review	I-2	Review	61
 Moreover, these results are hardly non-realistic, as neural networks with sigmoids can easily simulate thresholds, and under certain assumptions the reverse simulation can be done approximately and reasonably efficiently too.	O	O	Review	61
[line_break_token][line_break_token]Also missing from this review is recent work of Montufar et al and Martens et al analysing the expressive power of generative models (RBMs).	B-Review	B-2	Review	61
[line_break_token][line_break_token]Beginning of page 3: I have a hard time following this high-level discussion.	B-Review	B-3	Review	61
 I think this doesn't belong in the introduction, as it is too long and convoluted.	I-Review	I-3	Review	61
 Instead, I think you should include such discussion as intuition about your formal constructions *as you give them*.  The way it is written right now, the discussion tries to be intuitive, precise, and comprehensive, and it doesn't really succeed at being any of these.	I-Review	I-3	Review	61
[line_break_token][line_break_token][line_break_token]Page 3: You should formally define what you mean by 'hyperplane' and 'arrangement'.	I-Review	I-3	Review	61
  In particular, a hyperplane is the set of points defined by the equation, not the equation itself.	I-Review	I-3	Review	61
 And if an arrangement is taken to be a set of hyperplanes (as per the usual definition), then the statement in Prop 6 isn't formal (although its meaning is still obvious).	I-Review	I-3	Review	61
 In particular, how does a ball S 'intersect' with a set of hyperplanes?	I-Review	I-3	Review	61
 Do you mean that it intersects with the union of the hyperplanes in the arrangement?	I-Review	I-3	Review	61
 I know these are nit-picky points, but if you should try to be technically precise.	I-Review	I-3	Review	61
[line_break_token][line_break_token]Page 5: There is a missing reference here: 'Zaslavsky's theorem (?,	B-Review	B-4	Review	61
Theorem A)'[line_break_token][line_break_token]Page 5: You should explain the concept of general position precisely.	I-Review	I-4	Review	61
 I don't know what 'generic weights' is supposed to mean, the actual definition has to do with lack of colinearity.	I-Review	I-4	Review	61
 You might want to point out that any choice of hyperplanes can be infinitesimally perturbed so that they end up in general position.	I-Review	I-4	Review	61
[line_break_token][line_break_token]Page 6: 'Relative position' is never formally defined, and it's not immediately obvious what it means.	B-Review	B-5	Review	61
[line_break_token][line_break_token]Page 6: The explanation after the statement of Prop 6 is much clearer.	I-Review	I-5	Review	61
 Perhaps you should just prove this (stronger) statement directly, and not the fairly opaque and abstract statement made in Prop 6.	I-Review	I-5	Review	61
[line_break_token][line_break_token]Figure 3: Why are there 2 dotted circles instead of just 1?	B-Review	B-6	Review	61
[line_break_token][line_break_token]Page 7: 'arrangements 2-dimensional essentialization'?	B-Review	B-7	Review	61
[line_break_token][line_break_token]Page 7: '{0,...,n}, a < b'  ->  '{0,...,n} s.t.	O	O	Review	61
a < b'[line_break_token][line_break_token]Page 7: What do you mean by 'independent groups of n0 units within the n units of a layer'?	B-Review	B-7	Review	61
 How can a unit be 'within' a unit?	I-Review	I-7	Review	61
[line_break_token][line_break_token]Page 7: What do you mean by an 'enumeration' of a 2-dimensional arrangement?	I-Review	I-7	Review	61
 [line_break_token][line_break_token][line_break_token]Page 9:  Below the statement of prop 7, it was suggested that the construction would be top down, where each group in a lower layer 'duplicates' the number of regions constructed by the layer above.	B-Review	B-8	Review	61
 But the construction given here seems to proceed bottom up... at least in the structure of the proof.	I-Review	I-8	Review	61
 This makes it less intuitive.	I-Review	I-8	Review	61
[line_break_token][line_break_token]Page 9:  The proof starts out very confusingly.	I-Review	I-8	Review	61
 I wasn't able to follow the sentence 'Then we find...'.	I-Review	I-8	Review	61
 These 'groups' haven't been formally defined at this stage, only informally alluded to.	I-Review	I-8	Review	61
 [line_break_token][line_break_token]And I have another question:  how is Prop 7 actually used here?	B-Review	B-9	Review	61
 Merely to establish the existence of network where there is n/n0 regions that each only turn on for different groups Ii?	I-Review	I-9	Review	61
 Isn't it trivial to construct such a thing?	I-Review	I-9	Review	61
 i.e. take the input weights to the units in a given group to be all the same, and make sure the square n0xn0 matrix formed by taking the weight vector for each group is full-rank (e.g. the identity matrix)?	I-Review	I-9	Review	61
[line_break_token][line_break_token]I suspect the reason this doesn't work is that the dimensions would collapse to 1 since each unit in a group would behave identically.	B-Review	B-10	Review	61
 However, one could then perturb the final expanded weight matrix to get a general position matrix, so that the subspace associated with each group wouldn't collapse to dimension 1.	I-Review	I-10	Review	61
 Is there anything wrong with this?	I-Review	I-10	Review	61
 [line_break_token][line_break_token][line_break_token]Page 9: Don't say 'decompose' here.	B-Review	B-11	Review	61
 'Decompose' implies you already have weights and are decomposing them into factors.	I-Review	I-11	Review	61
 Instead, what you are doing is defining some weights to be a product of particular matrices.	I-Review	I-11	Review	61
[line_break_token][line_break_token]You should emphasize that it is a common V shared by all the i.  This is easy to miss.	B-Review	B-12	Review	61
[line_break_token][line_break_token][line_break_token]Page 9: What does it mean for a linear map to be 'with Ii-coordinates equal to...'?	B-Review	B-13	Review	61
 The 'Ii-coordinates' are the inputs to this map?	I-Review	I-13	Review	61
 The outputs?	I-Review	I-13	Review	61
[line_break_token][line_break_token]Page 9: What is R_i^(1)?	B-Review	B-14	Review	61
 It is never defined.	I-Review	I-14	Review	61
 Is it different from the version without the superscript?	I-Review	I-14	Review	61
 Is it defined implicitly the first time it is used?	I-Review	I-14	Review	61
 If so, what is a 'region of activation values'?	I-Review	I-14	Review	61
[line_break_token][line_break_token]What is very confusing is that you use x to define this function, when I had the impression that x was for the original inputs only.	B-Review	B-15	Review	61
 This isn't consistent with the h notation you use in figure 1 for example.	I-Review	I-15	Review	61
[line_break_token][line_break_token][line_break_token]Page 9: You say that something 'passed through' rho^2 is the 'input' to the second layer.	B-Review	B-16	Review	61
 This is the input to the rectifier units without their weights (which I'm guessing are contained in rho^2)?	I-Review	I-16	Review	61
 Or is it these units with the 'V' factor part of their weights only, but not the 'U' part?	I-Review	I-16	Review	61
 This is all extremely confusing.	I-Review	I-16	Review	61
 Without careful definitions of your notation it requires a lot more work on the part of the reader to understand what is going on.	I-Review	I-16	Review	61
[line_break_token][line_break_token]Page 9: How can rho_i^(2)(R_i^(1)) be a 'subset' of an subspace that lives in R^(n1)?	B-Review	B-17	Review	61
 rho_i^(2)(R_i^(1)) is going to be a set of vectors living in R^(n0)!	O	O	Review	61
[line_break_token][line_break_token][line_break_token]Page 10:  What do you mean when you say that 'this arrangement is repeated once in each region'?	B-Review	B-18	Review	61
 What does it mean for an arrangement to be 'repeated in a region'?	I-Review	I-18	Review	61
[line_break_token][line_break_token]I feel like the proof becomes mostly a proof-by-diagram as this point.	I-Review	I-18	Review	61
 Maybe you should have started off with this kind of diagram and the intuition of 'duplicating regions', explaining how composing piece-wise linear functions can achieve this kind of thing (which is really the critical point that gets glossed over), and then proceeding to show that you could formally construct each 'piece' required to do this.	I-Review	I-18	Review	61
  And you should have done the construction starting at the top layer going down.	I-Review	I-18	Review	61
[line_break_token][line_break_token]Having reconstructed the proof in a way that I actually understood it, it seemed that one could also proof that one can (prod_{i=1}^{k-1} n_i)/2^{k-1} * sum_i=0^2 (n_k choose i) regions, which in some cases might be a lot larger than the expression you arrived at.	B-Review	B-19	Review	61
  Unlike your Thm 8 does, this version would actually need to use the fact the constructions are 2-dimensional in Prop 7.	I-Review	I-19	Review	61
[line_break_token][line_break_token]Page 11:  The asymptotic analysis is just very routine and uninteresting computations and should be in the appendix.	B-Review	B-20	Review	61
 It breaks the flow of your paper.	I-Review	I-20	Review	61
 I would much prefer to see more detailed commentary about the implications of Thm 8.	I-Review	I-20	Review	61
We appreciate the detailed comments of Reviewer 2699.	O	O	Reply	61
They were very helpful for preparing the present revision of the manuscript.	O	O	Reply	61
In the following we address all comments of the reviewer and give description of the changes made to the manuscript.	O	O	Reply	61
[line_break_token][line_break_token]In response to the general comments we [line_break_token][line_break_token]* Changed the title of the manuscript to ``On the number of response regions of deep feedforward networks with piecewise linear activations''[line_break_token][line_break_token]* Shortened the Introduction (and removed an erroneous example that was given there)[line_break_token][line_break_token]* Completely overworked the proof of the former Theorem 8 (now Theorem 1).	B-Reply	B-1	Reply	61
[line_break_token][line_break_token]* Moved the asymptotic analysis to the appendix[line_break_token][line_break_token]* Included a new section (Section 5) discussing tighter bounds for deep models.	B-Reply	B-4	Reply	61
[line_break_token][line_break_token]In the following we address the detailed comments.	O	O	Reply	61
[line_break_token][line_break_token]* ``Computational geometry'' refers to the study of algorithms using geometry.	B-Reply	B-2	Reply	61
Here, using the word ``computational'' is just a matter of taste.	I-Reply	I-2	Reply	61
Our motivation is that a neural network is a computational system and an algorithm (compute output of unit for, sum the outputs of units, etc.).	I-Reply	I-2	Reply	61
 [line_break_token][line_break_token]* We included a reference to Hajnal's work in the Introduction.	I-Reply	I-2	Reply	61
[line_break_token][line_break_token]* We included pointers to the work of Montufar et al and Martens et al in the Introduction.	I-Reply	I-2	Reply	61
[line_break_token][line_break_token]* We removed the long discussion from the Introduction and decided, instead, to include an example (Example 1) in the vicinity of the main theorem (Theorem 1).	I-Reply	I-2	Reply	61
[line_break_token][line_break_token]* We included several definitions and worked on making our formulations more precise.	I-Reply	I-2	Reply	61
[line_break_token][line_break_token]* We corrected a missing reference to Zaslavsky's work.	I-Reply	I-2	Reply	61
[line_break_token][line_break_token]* We included the formal definition of ``general position'' and comments on infinitesimal perturbations.	I-Reply	I-2	Reply	61
[line_break_token][line_break_token]* We no longer use the expression ``relative position'' For clarity, in the previous manuscript, the definition was as follows: Two arrangements have the same relative position if they are combinatorially equivalent, or more formally, if there is a bijection of their intersection posets, where the intersection poset of an arrangement is the set of all nonempty intersection of its hyperplanes partially ordered by reverse inclusion.	B-Reply	B-5	Reply	61
[line_break_token][line_break_token]* We reformulated the former Proposition 6 in terms of scaling and shifting, moving technical details to the proof, and avoiding the use of the expression ``relative position''.	I-Reply	I-5	Reply	61
[line_break_token][line_break_token]* We corrected the former Figure 3, which now shows just 1 dotted circle instead of 2.	B-Reply	B-6	Reply	61
[line_break_token][line_break_token]* We explained the notion of ``essentialization'' in more detail.	B-Reply	B-7	Reply	61
Proposition 4 describes the combinatorics of-dimensional arrangements with-dimensional essentialization; that is, arrangements of hyperplanes whose intersections with the span of their normal vectors build a-dimensional arrangement (on the span of the normal vectors).	I-Reply	I-7	Reply	61
[line_break_token][line_break_token]* We corrected '.	I-Reply	I-7	Reply	61
[line_break_token][line_break_token]* We improved our formulations, especially about ``independent groups of units'' and ``enumeration'' of the hyperplanes in an arrangement.	O	O	Reply	61
[line_break_token][line_break_token]* We made significant efforts in clarifying how the construction works, bottom to top.	B-Reply	B-3	Reply	61
[line_break_token][line_break_token]* We improved the formulations ``we find'', ``groups'', trying to make the arguments more formal and clearer.	B-Reply	B-8	Reply	61
[line_break_token][line_break_token]* The reviewer asked how Proposition 7 was used in the proof of the theorem.	B-Reply	B-9	Reply	61
Using the same activation weights for a collection of units would cause them to behave identically.	I-Reply	I-9	Reply	61
The entire collection of units would have an output of dimension at most one, which would not be useful for our proof.	I-Reply	I-9	Reply	61
Perturbing the weights to produce a full dimensional matrix would work.	I-Reply	I-9	Reply	61
A high level proof could be formulated in this way.	I-Reply	I-9	Reply	61
We found it important to give an explicit choice of weights for which certain well defined properties hold, instead of relying only on high level arguments, in particular, because this allows us to verify the accuracy of our intuitions.	I-Reply	I-9	Reply	61
[line_break_token][line_break_token]In fact, our construction is stable, in the sense that small perturbations of the specified weights cause only small perturbations of the computed function.	I-Reply	I-9	Reply	61
The resulting perturbed function has at least as many linear regions as the original one.	I-Reply	I-9	Reply	61
[line_break_token] [line_break_token]* The word `decompose' was meant in the opposite way that `compose' is used for compositions of functions,.	B-Reply	B-11	Reply	61
Thanks for the comment, we tried to use more precise expressions.	I-Reply	I-11	Reply	61
[line_break_token][line_break_token]* The reviewer asked [line_break_token]``Page 9: What does it mean for a linear map to be 'with Ii-coordinates equal[line_break_token]to...'?	O	O	Reply	61
 The 'Ii-coordinates' are the inputs to this map?	O	O	Reply	61
The outputs? ''	O	O	Reply	61
[line_break_token][line_break_token]We tried to make this more precise in the revision.	B-Reply	B-13	Reply	61
For clarity, the terminology is the standard one: [line_break_token]A ``coordinate'' of a map is any of the functions for.	I-Reply	I-13	Reply	61
 Given a subset of, the-coordinates of the map are the functions with.	I-Reply	I-13	Reply	61
[line_break_token]For example, if, we can consider the map defined by the-coordinates of, which is the map.	I-Reply	I-13	Reply	61
[line_break_token][line_break_token]* The reviewer asked ``What is?	O	O	Reply	61
It is never defined...''.	O	O	Reply	61
[line_break_token][line_break_token]We worked on better explaining the notation and using it uniformly.	B-Reply	B-14	Reply	61
[line_break_token][line_break_token]* The reviewer wrote ``Page 9: You say that something 'passed through' is the 'input' to the''... [line_break_token][line_break_token]We improved the terminology.	B-Reply	B-16	Reply	61
[line_break_token][line_break_token]* Also ``Page 9: How can be a 'subset' of an subspace that lives...''[line_break_token][line_break_token]We overworked these parts as well.	O	O	Reply	61
[line_break_token][line_break_token]* The reviewer suggested a new construction for proving statements about deep models.	B-Reply	B-18	Reply	61
We do not argue that our construction or our analysis yields the maximal number of regions of linearity.	I-Reply	I-18	Reply	61
It merely demonstrates that deep models are exponentially more efficient than shallow models.	I-Reply	I-18	Reply	61
In the revision we included a new construction of weights of deep rectifier networks (in Section 5), which shows tighter bounds for certain choices of layer widths.	I-Reply	I-18	Reply	61
Other constructions exploiting higher dimensional versions of the former Proposition 7 are worth studying in the future, in order to arrive at yet tighter bounds.	I-Reply	I-18	Reply	61
[line_break_token][line_break_token]* We moved the asymptotic analysis to the appendix.	B-Reply	B-20	Reply	61
In the Discussion we included comments about the number of linear regions computable per parameter	I-Reply	I-20	Reply	61

This paper introduces new benchmarks for measuring the robustness of computer vision models to various image corruptions.	O	O	Review	315
In contrast with the popular notion of ‚Äúadversarial robustness‚Äù, instead of measuring robustness to small, worst-case perturbations this benchmark measures robustness in the average case, where the corruptions are larger and more likely to be encountered at deployment time.	O	O	Review	315
The first benchmark ‚ÄúImagenet-C‚Äù consists of 15 commonly occurring image corruptions, ranging from additive noise, simulated weather corruptions, to digital corruptions arising from compression artifacts.	O	O	Review	315
Each corruption type has several levels of severity and overall corruption score is measured by improved robustness over a baseline model (in this case AlexNet).	O	O	Review	315
The second benchmark ‚ÄúImagenet-P‚Äù measures the consistency of model predictions in a sequence of slightly perturbed image frames.	O	O	Review	315
These image sequences are produced by gradually varying an image corruption (e.g. gradually blurring an image).	O	O	Review	315
The stability of model predictions is measured by changes in the order of the top-5 predictions of the model.	O	O	Review	315
More stable models should not change their prediction to minute distortions in the image.	O	O	Review	315
Extensive experiments are run to benchmark recent architecture developments on this new benchmark.	O	O	Review	315
It‚Äôs found that more recent architectures are more robust on this benchmark, although this gained robustness is largely due to the architectures being more accurate overall.	O	O	Review	315
Some techniques for increasing model robustness are explored, including a recent adversarial defense ‚ÄúAdversarial Logit Pairing‚Äù, this method was shown to greatly increase robustness on the proposed benchmark.	O	O	Review	315
The authors recommend future work benchmark performance on this suite of common corruptions without training on this corruptions directly, and cite prior work which has found that training on one corruption type typically does not generalize to other corruption types.	O	O	Review	315
Thus the benchmark is a method for measuring model performance to ‚Äúunknown‚Äù corruptions which should be expected during test time.	O	O	Review	315
[line_break_token][line_break_token]In my opinion this is an important contribution which could change how we measure the robustness of our models.	O	O	Review	315
Adversarial robustness is a closely related and popular metric but it is extremely difficult to measure and reported values of adversarial robustness are continuously being falsified [1,2,3]. In contrast, this benchmark provides a standardized and computationally tractable benchmark for measuring the robustness of neural networks to image corruptions.	O	O	Review	315
The proposed image corruptions are also more realistic, and better model the types of corruptions computer vision models are likely to encounter during deployment.	O	O	Review	315
I hope that future papers will consider this benchmark when measuring and improving neural network robustness.	B-Review	B-3	Review	315
It remains to be seen how difficult the proposed benchmark will be, but the authors perform experiments on a number of baselines and show that it is non-trivial and interesting.	I-Review	I-3	Review	315
At a minimum, solving this benchmark is a necessary step towards robust vision classifiers.	I-Review	I-3	Review	315
[line_break_token][line_break_token]Although I agree with the author‚Äôs recommendation that future works not train on all of the Imagenet-C corruptions, I think it might be more realistic to allow training on a subset of the corruptions.	B-Review	B-1	Review	315
The reason why I mention this is it‚Äôs unclear whether or not adversarial training should be considered as performing data augmentation on some of these corruptions, it certainly is doing some form of data augmentation.	I-Review	I-1	Review	315
Concurrent work [4] has run experiments on a resnet-50 for Imagenet and found that Gaussian data augmentation with large enough sigma (e.g. sigma = .4 when image pixels are on a [0,1] scale) does improve robustness to pepper noise and Gaussian blurring, with improvements comparable to that of adversarial training.	I-Review	I-1	Review	315
Have the authors tried Gaussian data augmentation to see if it improves robustness to the other corruptions?	I-Review	I-1	Review	315
I think this is an important baseline to compare with adversarial training or ALP.	I-Review	I-1	Review	315
[line_break_token][line_break_token]Few specific comments/typos:[line_break_token][line_break_token]Page 2 ‚Äúl infinity perturbations on small images‚Äù[line_break_token][line_break_token]The (Stone, 1982) reference is interesting, but it‚Äôs not clear to me that their main result has implications for adversarial robustness.	B-Review	B-2	Review	315
Can the authors clarify how to map the L_p norm in function space of ||T_n - T(theta) || to the traditional notion of adversarial robustness?	I-Review	I-2	Review	315
[line_break_token][line_break_token]1.	O	O	Review	315
<a href="https://arxiv.org/pdf/1705.07263.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.07263.pdf</a>[line_break_token]2.	O	O	Review	315
<a href="https://arxiv.org/pdf/1802.00420.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.00420.pdf</a>[line_break_token]3.	O	O	Review	315
<a href="https://arxiv.org/pdf/1607.04311.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1607.04311.pdf</a>[line_break_token]4.	O	O	Review	315
<a href="https://openreview.net/forum?id=S1xoy3CcYX&noteId=BklKxJBF57" target="_blank" rel="nofollow">https://openreview.net/forum?id=S1xoy3CcYX&noteId=BklKxJBF57</a>	O	O	Review	315
Thank you for your interest in this topic and your analysis of our paper.	O	O	Reply	315
[line_break_token][line_break_token]‚ÄúI think it might be more realistic to allow training on a subset of the corruptions.	O	O	Reply	315
‚Äù[line_break_token]Researchers could train on various other corruptions, such as film grain, adversarial noise, HSV noise, uniform noise,[line_break_token]high-pass filtering, median blur, spherical camera distortions, pincushion distortions, out-of-distribution object occlusions, stylized images ( <a href="https://openreview.net/forum?id=Bygh9j09KX" target="_blank" rel="nofollow">https://openreview.net/forum?id=Bygh9j09KX</a> ), lens scratches, image quilting, color quantization, etc.	O	O	Reply	315
We have updated the text to make it clearer that researchers can train on more than just cropped and flipped images, but we still do not want researchers training on the test corruptions.	B-Reply	B-1	Reply	315
In the paper we experimented with uniform noise data augmentation in the stability training experiment and found minor perturbation robustness gains, but not with Gaussian noise with a large standard deviation.	I-Reply	I-1	Reply	315
[line_break_token][line_break_token]Thank you for pointing out that the brief Stone comment requires much more context.	I-Reply	I-1	Reply	315
For that reason we have removed the citation.	I-Reply	I-1	Reply	315
Essentially, if f is a model and f^\hat is an approximation, and if input x is d-dimensional, then if we want | f(x) - f^\hat (x) | < epsilon, then in some scenarios the number of samples necessary is ~ epsilon^{-d}. Other context is on slide 10 of <a href="https://github.com/joanbruna/MathsDL-spring18/blob/master/lectures/lecture1.pdf" target="_blank" rel="nofollow">https://github.com/joanbruna/MathsDL-spring18/blob/master/lectures/lecture1.pdf</a>[line_break_token][line_break_token]‚Äúl infinity perturbations on small images‚Äù[line_break_token]Thanks to your suggestion, we have changed this to ‚Äúperturbations on small images.	B-Reply	B-2	Reply	315
‚Äù We kept the word ‚Äúsmall‚Äù as the images often have side length 32 pixels.	I-Reply	I-2	Reply	315
We removed ‚Äúl_infinity‚Äù since that method has had some success for perturbations which are small in an l_2 sense	I-Reply	I-2	Reply	315

This paper introduces a new method for training a classifier that simultaneously optimizes for a fairness criterion and robustness to data poisoning.	O	O	Review	486
The method is shown to increase measures of fairness and reduce inaccuracy on poisoned data relative to classifiers that only consider accuracy or fairness.	O	O	Review	486
Extensive results are shown for both synthetic and real benchmark data sets.	O	O	Review	486
[line_break_token][line_break_token]I would lean to reject for the following reasons: 1) the problem is not well-motivated.	B-Review	B-1	Review	486
I would like a more clear example of some problem with sensitive attributes in which the data is publicly available and the providers of the data are motivated to falsify it.	I-Review	I-1	Review	486
2) the contribution is very simple and the individual pieces do not seem to be significant contributions.	B-Review	B-2	Review	486
In particular, the use of GANs for fairness is previously done, and the use of the GAN for robustness here seems too simple to be broadly useful 3) the results are less convincing than they might otherwise be because none of the competing methods tested make use of a clean validation set 4) the paper is somewhat unpolished.	B-Review	B-3	Review	486
I find the results difficult to read, although the arrows are helpful, and it is not clear to me whether these results are on a test set or the training set.	B-Review	B-4	Review	486
[line_break_token][line_break_token]Lack of convincing tests for robustness: It is disappointing that FR-GAN does not offer any promises to be robust in general.	B-Review	B-5	Review	486
Despite access to a clean validation set, the classifier is trained only to ignore the type of data poisoning that exists in the training set.	I-Review	I-5	Review	486
If the test set were out of distribution in a different way relative to the training set, I see no reason to believe FR-GAN would protect against this.	I-Review	I-5	Review	486
Furthermore, because it is not stated that these are test set results, I am not certain that they are not training set results, in which case some performance may be due to overfitting.	I-Review	I-5	Review	486
[line_break_token][line_break_token]Minor notes:[line_break_token][line_break_token]It would be nice for comparison if the charts had the same axes throughout.	B-Review	B-6	Review	486
[line_break_token][line_break_token]What are the numbers of nodes used in the hidden layers?	I-Review	I-6	Review	486
hanks for the insightful comments.	O	O	Reply	486
[line_break_token][line_break_token]Q3-1. (	O	O	Reply	486
1) motivation[line_break_token][line_break_token]A3-1.	O	O	Reply	486
[line_break_token]We believe that given that real data would increasingly become both biased and poisoned (this is what we expect in the big data era - see the next paragraph for details), our main contribution of providing an integrated solution for fair and robust training is likely to become important in the near future.	B-Reply	B-1	Reply	486
[line_break_token][line_break_token]We contend that supporting robust training is just as critical as fair training.	I-Reply	I-1	Reply	486
Dataset searching is becoming mainstream as demonstrated by Google Dataset Search (Goods) [1] and its public version for searching scientific datasets [2]. While data lakes within companies may consist of refined datasets, datasets in the public are easy to poison.	I-Reply	I-1	Reply	486
In our experiments, we could easily poison the Adult and COMPAS datasets using simple label flipping techniques.	I-Reply	I-1	Reply	486
And anyone can poison public datasets using attacks in the literature and share them.	I-Reply	I-1	Reply	486
We thus believe that it is essential to address both bias and poisoning as a preventive measure.	I-Reply	I-1	Reply	486
We reflected these points in our revision (Section 1, highlighted in blue).	I-Reply	I-1	Reply	486
[line_break_token][line_break_token][1] Goods: Organizing Google's Datasets, ACM SIGMOD 2017.	O	O	Reply	486
[line_break_token][2] Google Dataset Search: Building a search engine for datasets in an open Web ecosystem, WWW 2019.	O	O	Reply	486
[line_break_token][line_break_token][line_break_token]Q3-2. (	O	O	Reply	486
2) contributions[line_break_token][line_break_token]A3-2.	O	O	Reply	486
[line_break_token]We agree that the fairness part of FR-GAN is similar to Adversarial Debiasing (AD) [3]. However, we strengthen the theoretical results of AD using information theory, and this motivates us to propose a novel robust training discriminator.	B-Reply	B-2	Reply	486
We agree that the key insight of using adversarial training to minimize mutual information between the prediction and sensitive attribute is the same for FR-GAN and AD.	I-Reply	I-2	Reply	486
Although, the end algorithms of FR-GAN and AD are also similar, our paper plays a role in providing systematic methodology not only for various fairness metrics, but also for the design of robust training.	I-Reply	I-2	Reply	486
As far as we know, no other validation-set-based approach (including Ren et al 2018) leverages the idea of adversarial training.	I-Reply	I-2	Reply	486
We reflected these points in our revision (Section 2, highlighted in blue).	I-Reply	I-2	Reply	486
[line_break_token][line_break_token][3] Mitigating Unwanted Biases with Adversarial Learning, AAAI 2018.	O	O	Reply	486
[line_break_token][line_break_token][line_break_token]Q3-3. (	O	O	Reply	486
3) competing methods[line_break_token][line_break_token]A3-3.	O	O	Reply	486
[line_break_token]As Reviewer 2 mentioned, FR-GAN is one of the first works to address both fairness and robustness and that there are few baselines to compare with.	B-Reply	B-3	Reply	486
Hence, we employed one reasonable baseline, which first sanitizes the poisoned data using a well-known sanitization technique and then performs a fair training (see Tables 1 and 2, rows with +LD).	I-Reply	I-3	Reply	486
We clarified these points in our revision (Section 5.1, highlighted in blue).	I-Reply	I-3	Reply	486
[line_break_token][line_break_token][line_break_token]Q3-4. (	O	O	Reply	486
4) writeup[line_break_token][line_break_token]A3-4.	O	O	Reply	486
[line_break_token]All of our results are on a separate test set.	B-Reply	B-4	Reply	486
We clarified this in our revision (Section 5, highlighted in blue) to avoid any confusion.	I-Reply	I-4	Reply	486
[line_break_token][line_break_token][line_break_token]Q3-5.	O	O	Reply	486
Lack of convincing tests for robustness[line_break_token][line_break_token]A3-5.	O	O	Reply	486
[line_break_token]We agree that generalizing to all poisoning attacks is important.	B-Reply	B-5	Reply	486
If we know all possible attacks, we can construct a training set containing these attacks.	I-Reply	I-5	Reply	486
In the more challenging case where we do not know which attacks even exist, there seems to be a fundamental limitation in protecting against the attacks.	I-Reply	I-5	Reply	486
Generalization is a universal problem in machine learning where a model trained on one dataset is not guaranteed to perform well in another dataset with a different distribution.	I-Reply	I-5	Reply	486
Although the generalization is a critical issue to address, we think it is beyond the scope of the current work.	I-Reply	I-5	Reply	486
We reflected these points in our revision (Section 6, highlighted in blue).	I-Reply	I-5	Reply	486
[line_break_token][line_break_token][line_break_token]Q3-6.	O	O	Reply	486
Minor notes[line_break_token][line_break_token]A3-6.	O	O	Reply	486
[line_break_token]We will display the figures with the same axes throughout in our revision.	B-Reply	B-6	Reply	486
We added the information about the number of nodes in the hidden layers in our revision (Appendix A.4, highlighted in blue).	I-Reply	I-6	Reply	486

[line_break_token]Pros:[line_break_token]The paper shows that we could have a better document/sentence embedding by partitioning the word embedding space based on a topic model and summing the embedding within each partition.	O	O	Review	1108
The writing and presentation of the paper are clear.	O	O	Review	1108
The method is simple, intuitive, and the experiments show that this type of method seems to achieve state-of-the-art results on predicting semantic similarity between sentences, especially for longer sentences.	O	O	Review	1108
[line_break_token][line_break_token]Cons:[line_break_token]The main concern is the novelty of this work.	B-Review	B-1	Review	1108
The method is very similar to SCDV (Mekala et al 2017).	I-Review	I-1	Review	1108
The high-level flow figure in appendix H is nearly identical as the Figure 1 and 2 in Mekala et al 2017.	I-Review	I-1	Review	1108
The main difference seems to be that this paper advocates K-SVD (extensively studies in Arora et al 2016) as their topic model and SCDV (Mekala et al 2017) uses GMM.	I-Review	I-1	Review	1108
[line_break_token]However, in the semantic similarity experiments (STS12-16 and Twitter15), the results actually use GMM.	I-Review	I-1	Review	1108
So I suppose the results tell us that we can achieve state-of-the-art performances if you directly combine tricks in SIF (Arora et al 2017) and tricks in SCDV (Mekala et al 2017).	I-Review	I-1	Review	1108
[line_break_token]In the document classification experiment, the improvement looks small and the baselines are not strong enough.	B-Review	B-2	Review	1108
The proposed method should be compared with other strong unsupervised baselines such as ELMo [1] and p-mean [2].[line_break_token][line_break_token]Overall:[line_break_token]The direction this paper explores is promising but the contributions in this paper seem to be incremental.	B-Review	B-3	Review	1108
I suggest the authors to try either of the following extensions to strengthen the future version of this work.	I-Review	I-3	Review	1108
[line_break_token]1.	I-Review	I-3	Review	1108
In addition to documentation classification, show that the embedding is better than the more recent proposed strong baselines like ELMo in various downstream tasks.	I-Review	I-3	Review	1108
[line_break_token]2.	B-Review	B-9	Review	1108
Derive some theories.	B-Review	B-3	Review	1108
One possible direction is that I guess the measuring the document similarity based on proposed embedding could be viewed as an approximation of Wasserstein similarity between the all the words in both documents.	I-Review	I-3	Review	1108
The matching step in Wasserstein is similar to the pooling step in your topic model.	I-Review	I-3	Review	1108
You might be able to say something about how good this approximation is.	I-Review	I-3	Review	1108
Some theoretical work about doing the nearest neighbor search based on vector quantization might be helpful in this direction.	I-Review	I-3	Review	1108
[line_break_token][line_break_token]Minor questions:[line_break_token]1.	O	O	Review	1108
I think another common approach in sparse coding is just to apply L1 penalty to encourage sparsity.	B-Review	B-4	Review	1108
Does this K-SVD optimization better than this L1 penalty approach?	I-Review	I-4	Review	1108
[line_break_token]2.	B-Review	B-9	Review	1108
How does the value k in K-SVD affect the performances?	B-Review	B-5	Review	1108
[line_break_token]3.	B-Review	B-9	Review	1108
In Aorora et al 2016b, they constrain alpha to be non-negative.	B-Review	B-6	Review	1108
Did you do the same thing here?	I-Review	I-6	Review	1108
[line_break_token]4.	B-Review	B-9	Review	1108
How important this topic modeling is?	B-Review	B-7	Review	1108
If you just randomly group words and sum the embedding in the group, is that helpful?	I-Review	I-7	Review	1108
[line_break_token]5.	B-Review	B-9	Review	1108
In Figure 2, I would also like to see another curve of performance gain on the sentences with different lengths using K-SVD rather than GMM.	B-Review	B-8	Review	1108
[line_break_token] [line_break_token]Minor writing suggestions:[line_break_token]1.	B-Review	B-9	Review	1108
In the 4th paragraph of section 3, "shown in equation equation 2", and bit-wise should be element-wise[line_break_token]2.	I-Review	I-9	Review	1108
In the 4th paragraph of section 4, I think the citation after alternating minimization should be Arora et al 2016b and Aharon et al 2006 rather than Arora et al 2016a[line_break_token]3.	I-Review	I-9	Review	1108
In the 2nd paragraph of section 6.1, (Jeffrey Pennington, 2014) should be (Pennington et al 2014).	I-Review	I-9	Review	1108
In addition, the author order in the corresponding Glove citation in the reference section is incorrect.	I-Review	I-9	Review	1108
The correct order should be Jeffrey Pennington, Richard Socher, Christopher D. Manning.	I-Review	I-9	Review	1108
[line_break_token]4.	I-Review	I-9	Review	1108
In the 3rd paragraph of section 6.1, "Furthermore, Sentence"[line_break_token]5.	I-Review	I-9	Review	1108
In the 6th paragraph of section 6.1, I thought skip-thoughts and Sent2Vec are unsupervised methods.	I-Review	I-9	Review	1108
[line_break_token]6.	I-Review	I-9	Review	1108
In Table 2 and 3, it would be easier to read if the table is transposed and use the longer name for each method (e.g., use skip-thought rather than ST)[line_break_token]7.	I-Review	I-9	Review	1108
In Table 2,3,4,5, it would be better to show the dimensions of embedding for each method[line_break_token]8.	I-Review	I-9	Review	1108
Table 10 should also provide F1[line_break_token]9.	I-Review	I-9	Review	1108
Which version of GMM is used in STS experiment?	I-Review	I-9	Review	1108
The one using full or diagonal covariance matrix?	I-Review	I-9	Review	1108
[line_break_token][line_break_token][line_break_token][1] Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018).	O	O	Review	1108
Deep contextualized word representations.	O	O	Review	1108
NAACL[line_break_token][2] R√ºckl√©, A., Eger, S., Peyrard, M., & Gurevych, I. (2018).	O	O	Review	1108
Concatenated p-mean Word Embeddings as Universal Cross-Lingual Sentence Representations.	O	O	Review	1108
arXiv preprint arXiv:1803.01400.	O	O	Review	1108
Apologies for the delay in response.	O	O	Reply	1108
We would like to thank the reviewer for evaluating our manuscript.	O	O	Reply	1108
We have tried to address the reviewer concerns in a proper way and believe that our paper has improved.	O	O	Reply	1108
We would be happy to make further corrections and look forward to hearing from you soon.	O	O	Reply	1108
We respond to the questions and concerns in the following points:[line_break_token][line_break_token]1.	O	O	Reply	1108
We agree that the methods draw inspiration from the SCDV (Mekala et al 2017).	B-Reply	B-1	Reply	1108
However, there are major differences between SCDV (Mekala et al 2017) and this work:[line_break_token][line_break_token]a) SCDV (Mekala et al 2017) uses GMM whereas P-SIF uses k-svd (Arora et al 2016) for topic modelling.	I-Reply	I-1	Reply	1108
It should be noted that we did not apply manual hard thresholding over final documents representation as the method in SCDV did.	I-Reply	I-1	Reply	1108
Because of k-svd we implicitly put the sparsity constraint during clustering.	I-Reply	I-1	Reply	1108
This yields several other benefits such as sparser documents thus reducing space and time complexity.	I-Reply	I-1	Reply	1108
For single sentence datasets (STS 12-16 and Twitter15), we found out that both GMM and k-svd work really well.	I-Reply	I-1	Reply	1108
GMM works slightly better as it is much easier to optimize compared to k-svd.	I-Reply	I-1	Reply	1108
We also noted for these datasets the total number of clusters is small.	I-Reply	I-1	Reply	1108
However, for datasets containing multiple sentences such as 20NewsGroup and Reuters (200-500-word documents), k-svd outperforms GMM a.k.a P-SIF outperforms SCDV.	I-Reply	I-1	Reply	1108
Additionally, using k-svd leads to a fewer number of total clusters and hence fewer dimensions of document vectors for better representations.	I-Reply	I-1	Reply	1108
As a result, the feature formation, training and prediction time are faster.	I-Reply	I-1	Reply	1108
We will add time and space complexity results in the paper as well.	I-Reply	I-1	Reply	1108
[line_break_token][line_break_token]b) We used the SIF weighting and common component removal in P-SIF, whereas SCDV used tf-idf.	I-Reply	I-1	Reply	1108
SIF (Arora et al 2017) has shown the benefit of using such weighting and common component removal.	I-Reply	I-1	Reply	1108
We have successfully generalized SIF (Arora et al 2017) using the ideas from the SCDV paper.	I-Reply	I-1	Reply	1108
Additionally, SCDV used SGNS-initialised word vectors, whereas P-SIF used Doc2VecC-initialised word vectors.	I-Reply	I-1	Reply	1108
Also, in Doc2VecC the averaging is based on sentence representation and training of word vectors is done jointly with corruptions.	I-Reply	I-1	Reply	1108
This kind of training with corruption results in zeroing of common words' word vectors.	I-Reply	I-1	Reply	1108
However, since our approach is about partition based averaging such as zeroing, we can yield more robust document representation.	I-Reply	I-1	Reply	1108
We will add more downstream tasks which were requested by the reviewer as well.	I-Reply	I-1	Reply	1108
It should be noted that we have more thorough experiments on 26 STS similarity and 2 text classification datasets of the SCDV paper (28 in total).	I-Reply	I-1	Reply	1108
[line_break_token][line_break_token]The proposed baselines in document classification are taken from a very recently published paper (2017-2018).	B-Reply	B-2	Reply	1108
As suggested by reviewer we will add more baselines such as the Elmo [1] and p-mean [2] for text classification.	I-Reply	I-2	Reply	1108
We didn't find the baselines for our reported datasets, but we have found the code to run on our datasets.	I-Reply	I-2	Reply	1108
[line_break_token][line_break_token]Minor Questions:[line_break_token]1.	O	O	Reply	1108
Yes, but directly optimising the L1 is an NP-hard objective.	B-Reply	B-4	Reply	1108
So k-svd does an alt-min (Arora et al 2016b and Aharon et al 2006) between clustering and thresholding to achieve the require sparsity.	I-Reply	I-4	Reply	1108
[line_break_token]2.	O	O	Reply	1108
We keep the k small, unlike other normal k-svd applications as we know that in text each word has a very limited number (< 5) of total senses.	O	O	Reply	1108
We use the procedure similar to (Arora et al 2016b) to choose the optimal k. For our experiments, we take k equal to the total_clusters of clusters (K) divided by 10, which is a good approximation.	B-Reply	B-5	Reply	1108
[line_break_token]3.	O	O	Reply	1108
Yes, if we randomly average words in same clusters and analyze the top dominant words in the clusters, we observe words with similar meanings are close to each other.	B-Reply	B-7	Reply	1108
A similar observation was reported by (Mekala et al 2017) and (Arora et al 2016b).	I-Reply	I-7	Reply	1108
[line_break_token]4.	O	O	Reply	1108
We will plot the point.	B-Reply	B-8	Reply	1108
Our institution is that initially for small length documents GMM and K-svd perform equally well (GMM may be slightly better due to easier optimization) but later for long length documents k-svd will easily outperform GMM with a fewer lesser number of clusters as reported in the text classification.	I-Reply	I-8	Reply	1108
[line_break_token]5.	B-Reply	B-3	Reply	1108
We used the full covariance matrix of the GMM in our paper.	B-Reply	B-6	Reply	1108
[line_break_token][line_break_token]We thank the reviewer for providing helpful directions for theoretical derivations [line_break_token]We were having doubts about how to proceed with the theoretical analyzes.	B-Reply	B-3	Reply	1108
The idea of measuring the document similarity based on P-SIF embedding and viewing it as an approximation of Wasserstein similarity between all the words in both documents seem interesting.	I-Reply	I-3	Reply	1108
As stated, the matching step in Wasserstein is indeed similar to the pooling step in our topic model.	I-Reply	I-3	Reply	1108
We will also delve into the theoretical work on doing the nearest neighbour search on vector quantizations.	I-Reply	I-3	Reply	1108
Thanks for your suggestion.	I-Reply	I-3	Reply	1108
We pinned down atleast one relevant paper: <a href="http://proceedings.mlr.press/v37/kusnerb15.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v37/kusnerb15.pdf</a> .	O	O	Reply	1108
[line_break_token][line_break_token]Minor writing corrections[line_break_token]We made the correction suggested in the revised version.	B-Reply	B-9	Reply	1108
We didn't transpose the table due to page limitation	I-Reply	I-9	Reply	1108

This paper proposes two sparsifying methods of computing attention weights, dubbed sparsemax and TVmax, which appear to slightly improve objective and subjective image captioning scores.	O	O	Review	601
   The sparsifying projections are posed as optimization problems, and algorithms for their computation, along with formula for their gradients are given.	O	O	Review	601
 Proof of the optimality of these algorithms relies significantly on prior work, so could not be checked deeply without bringing in additional sources.	O	O	Review	601
 [line_break_token][line_break_token]It is not clear that the motivation for these sparsifying objectives is sound.	B-Review	B-1	Review	601
  The conventional softmax approach to attention weights should be capable of producing attention weights near zero, which would be effectively sparse, especially if the pre-activations, z_i, in equation (1), are allowed to have a large enough range.	I-Review	I-1	Review	601
  It's not clear why weights should need to be zero exactly in the ignored regions, since being near zero should be sufficient to contribute almost nothing to the subsequent weighted sum.	I-Review	I-1	Review	601
   So it is also not clear why the strict sparsity itself, as opposed to the effective sparsity of the softmax, should explain the differences in Figure 1, and in the results.	I-Review	I-1	Review	601
 In particular it is unclear why the strict sparsity should prevent repetition; when looking at the weight distributions in the two cases, a more likely story seems to be that the weight distributions don't repeat as much from one word to the next in the second case, but there is no clear reason to attribute this to sparsity.	I-Review	I-1	Review	601
  The pictures of the attention weights are lacking a color scale, so it is impossible to see how close to zero it comes in the unattended regions, although the gray color values chosen for these regions might be misleading.	I-Review	I-1	Review	601
[line_break_token]The TVmax approach, in addition to sparsity, also constrains the non-zero region to be contiguous.	O	O	Review	601
  To the extent that this improves performance, this presumably introduces an inductive bias that matches the data.	B-Review	B-3	Review	601
  It is unclear why this fails to produce better objective scores than sparsemax, while producing better human ratings.	I-Review	I-3	Review	601
  In any case it is not clear why this should necessarily be a good inductive bias for all images, although it is plausible that it helps in some cases.	I-Review	I-3	Review	601
 [line_break_token]In many neural network problems, what makes a difference has more to do with the optimizability of the gradients, than the specific activations per se, and that might be the case here too, although the paper does not analyze this aspect of the proposed models.	I-Review	I-3	Review	601
  [line_break_token][line_break_token]Overall the paper is flawed by the lack of clarity in the motivation for the proposed methods, and the lack of retrospective analysis and understanding of why the proposed methods should improve results.	B-Review	B-2	Review	601
[line_break_token]	O	O	Review	601
hank you for your detailed comments.	O	O	Reply	601
The main points you raised are related to 1) the motivation for our proposed method and 2) the analysis and understanding of why it improves results.	O	O	Reply	601
We clarify these two points below and we added new analyses to the revised version of the paper to help understanding where the improvements come from.	O	O	Reply	601
[line_break_token][line_break_token]1) Motivation for our proposed method.	O	O	Reply	601
[line_break_token]While softmax may lead to attention weights near zero, prior work [1,2,3,4] shows that it has the tendency of accumulating too much probability mass on a long tail of irrelevant features, which may harm model performance.	B-Reply	B-1	Reply	601
In contrast, sparse attention mechanisms are able to select only a small set of features, with improved attention focus.	I-Reply	I-1	Reply	601
In the refs above, the success of sparse attention has been shown for NLP tasks such as machine translation, textual entailment, summarization, and morphological inflection.	I-Reply	I-1	Reply	601
The main motivation for this work is to test if this hypothesis also holds for a significantly different task, image captioning, where attention is visual.	I-Reply	I-1	Reply	601
Our findings confirm those of Xu et al [5], who obtained better results and improved interpretability with hard attention over softmax.	I-Reply	I-1	Reply	601
However, their approach is not end-to-end differentiable, requiring imitation learning or Monte Carlo policy gradient approximations, while ours is differentiable and can be used as a drop-in replacement for softmax.	I-Reply	I-1	Reply	601
To further induce structural bias on top of sparsity (important when we want to exploit spatial correlations in visual tasks), we proposed TVmax, that promotes selection of contiguous regions.	I-Reply	I-1	Reply	601
We will make these motivations clearer in the final version of the paper.	I-Reply	I-1	Reply	601
[line_break_token][line_break_token]2) Analysis and understanding of why it improves results.	O	O	Reply	601
[line_break_token]Thank you for suggesting a color scale to facilitate the visualization of the attention plots -- we included it in the new version of the paper.	B-Reply	B-2	Reply	601
The sparsity benefits are qualitatively illustrated in Figure 1 and 3: we can observe that when using sparsemax and TVmax the weights given to the relevant regions are much higher than the ones given when using softmax, while the non relevant regions receive zero attention.	I-Reply	I-2	Reply	601
This is corroborated by the human attention evaluation.	I-Reply	I-2	Reply	601
It also confirms our motivation for TVmax that by focusing in contiguous regions, high attention weights can be attributed to compact objects, improving their detection.	I-Reply	I-2	Reply	601
[line_break_token]Moreover, human evaluation scores and automatic REP scores are considerably higher when using TVmax.	I-Reply	I-2	Reply	601
This happens even though TVmax generates longer sentences.	I-Reply	I-2	Reply	601
[line_break_token][line_break_token]We posit that the reasons behind the decrease in the number of repetitions are two-fold:[line_break_token]- By using softmax, some attention (even if small) is given to all regions of the image in every time step, even those that are not relevant for the word being generated (see point 1 above).	I-Reply	I-2	Reply	601
Consequently, the feature vector obtained is more similar between time steps than with sparsemax or TVmax, possibly leading to the generation of the same word repeatedly.	I-Reply	I-2	Reply	601
This is in agreement with your intuition that the smaller number of repetitions is caused by the weight distributions not repeating as much.	I-Reply	I-2	Reply	601
[line_break_token]- Focusing on compact regions of the image leads to the detection of more objects, which can lead to less repetitions.	I-Reply	I-2	Reply	601
[line_break_token][line_break_token]To corroborate the first point, we measured the Jensen-Shannon divergence (JS) between the attention probabilities for each time step of the captions correspondent to the MSCOCO test set images.	I-Reply	I-2	Reply	601
The mean JS values are 0.12, 0.29, and 0.34 for softmax, sparsemax, and TVmax, respectively.	I-Reply	I-2	Reply	601
This confirms our intuition that sparsemax and TVmax lead to less similar attention distributions across time steps and, consequently, to less repetitions.	I-Reply	I-2	Reply	601
We report this statistic in the new version of the paper.	I-Reply	I-2	Reply	601
[line_break_token][line_break_token]Note that this decrease of repetitions is consistent with previous findings in sequence-to-sequence models (machine translation) which has shown that sparsemax has much lower propensity for repetitions than softmax (see ref [1] below, Table 1, which reports consistently better REP scores for several language pairs).	I-Reply	I-2	Reply	601
[line_break_token][line_break_token][1] C. Malaviya, P. Ferreira, and A. Martins.	O	O	Reply	601
Sparse and constrained attention for neural machine translation.	O	O	Reply	601
ACL 2018.	O	O	Reply	601
<a href="https://www.aclweb.org/anthology/P18-2059.pdf" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/P18-2059.pdf</a>[line_break_token][line_break_token][2] A. Martins and R. Astudillo.	O	O	Reply	601
From softmax to sparsemax: A sparse model of attention and multi-label classification.	O	O	Reply	601
ICML 2016.	O	O	Reply	601
<a href="http://proceedings.mlr.press/v48/martins16.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v48/martins16.pdf</a>[line_break_token][line_break_token][3] V. Niculae and M. Blondel.	O	O	Reply	601
A regularized framework for sparse and structured neural attention.	O	O	Reply	601
NeurIPS 2017.	O	O	Reply	601
[line_break_token]<a href="https://papers.nips.cc/paper/6926-a-regularized-framework-for-sparse-and-structured-neural-attention.pdf" target="_blank" rel="nofollow">https://papers.nips.cc/paper/6926-a-regularized-framework-for-sparse-and-structured-neural-attention.pdf</a>[line_break_token][line_break_token][4] B. Peters, V. Niculae, and A. Martins.	O	O	Reply	601
Sparse sequence-to-sequence models.	O	O	Reply	601
ACL 2019.	O	O	Reply	601
[line_break_token]<a href="https://www.aclweb.org/anthology/P19-1146.pdf" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/P19-1146.pdf</a>[line_break_token][line_break_token][5] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, and Y. Bengio.	O	O	Reply	601
Show, attend and tell: Neural image caption generation with visual attention.	O	O	Reply	601
ICML 2015.	O	O	Reply	601
<a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v37/xuc15.pdf</a	O	O	Reply	601

Summary: The paper considers a variational inference strategy for learning neural networks with binary weights.	O	O	Review	640
In particular, the paper proposes using a structured recognition model to parameterise the variational distribution, which couples the weights in different layers/filters in a non-trivial way.	O	O	Review	640
The gradient of the expected likelihood term in the variational lower bound is estimated using the REINFORCE estimator.	O	O	Review	640
This paper adjusts this estimator to use the gradient of the log-likelihood wrt the samples.	O	O	Review	640
Experiments on several image classification tasks are provided.	O	O	Review	640
[line_break_token][line_break_token]evaluation:[line_break_token][line_break_token]pros:[line_break_token]- the idea of the proposed approach is interesting: using variational inference for binary weight neural networks.	O	O	Review	640
While recent work on VI for discrete variables only focused on discrete latent variable models, this work shows how VI can be used for binary neural networks.	O	O	Review	640
[line_break_token] [line_break_token]cons:[line_break_token]- the writing, in my opinion, needs to be improved [see my comments below]. The VI presentation is cluttered and the justification of using the pseudo-reward for reinforce is not clear.	B-Review	B-1	Review	640
[line_break_token]- the experimental results are mixed and it's not clear to me how to interpret them/compare to the baselines -- what is the goal here: computational efficiency, compression or accuracy?	B-Review	B-2	Review	640
[line_break_token][line_break_token]Some specific questions/comments:[line_break_token][line_break_token]+ What is the input of the policy/recognition network?	B-Review	B-3	Review	640
It's not clear from the paper whether this includes the inputs of the current batch or outputs or both?	I-Review	I-3	Review	640
If so, how are variable batch sizes handled?	I-Review	I-3	Review	640
What is the input to this network at test time?	I-Review	I-3	Review	640
In contrast to generative models/VAEs, the weights here are global parameters and it's not clear to me these should be varied for different data batches.	I-Review	I-3	Review	640
[line_break_token][line_break_token]+ related to the question above: how is prediction handled at test time?	B-Review	B-4	Review	640
Say the parameters of the variational distribution over weights are generated using the recognition network, then 100 weights are sampled given these parameters which then give 100 predictions -- should these be then averaged out to get the final prediction?	I-Review	I-4	Review	640
I'm not quite sure I understand why the paper chose to *pick the best one* out of 100 predictions and the justification/criterion for this procedure.	I-Review	I-4	Review	640
 [line_break_token][line_break_token]+ The writing is not very clear at places, and it does not help that the references being merged with the text.	B-Review	B-5	Review	640
I'm also not sure about some of the technical jargons/terms used in the papers:[line_break_token]- reinforcement learning: is this really a reinforcement learning problem?	I-Review	I-5	Review	640
If you tackle this problem from a pure variational perspective, reinforce is used to obtain the gradient of the expected log-likelihood wrt the variational parameters.	I-Review	I-5	Review	640
But instead of using the log likelihood, a learning signal that depends on the gradient of the log-likelihood is used.	I-Review	I-5	Review	640
[line_break_token]- concrete weights -- what are these?	I-Review	I-5	Review	640
I assume they are just binary weights sampled from the variational approximation.	I-Review	I-5	Review	640
[line_break_token]- middle of page 3: p(w|X, Y) = p_\theta(w): this is not precise as p_\theta(w) is only an approximation to the exact posterior, which then allows us to lower bound the log marginal likelihood. "	I-Review	I-5	Review	640
common practice in modern variational approximation": This is the standard way of deriving the lower bound and has been used for many years.	I-Review	I-5	Review	640
[line_break_token][line_break_token]+ the reinforce estimator tends to have high variances since it does not make use of the gradient of the function in the expectation.	B-Review	B-6	Review	640
This paper adjusts the vanilla estimator with a learning signal that involves the gradient.	I-Review	I-6	Review	640
Could you comment on the bias/variance trade-off of the resulting estimator?	I-Review	I-6	Review	640
Much of recent literature on learning discrete variables, as far as I understand, propose ways to not to have to use the vanilla reinforce, for example Concrete, Relax or rebar, albeit the focus on latent variable models.	I-Review	I-6	Review	640
[line_break_token][line_break_token]+ model selection and uncertainty measure: the paper mentions these potential advantages of the proposed approach over deterministic binarisation schemes, but does not fully explore and test these.	B-Review	B-7	Review	640
[line_break_token][line_break_token]	O	O	Review	640
- We thank R2 for pointing out the issue w.r.t.	B-Reply	B-1	Reply	640
the pseudo-reward for reinforce.	I-Reply	I-1	Reply	640
For now, we admit it is ad-hoc.	I-Reply	I-1	Reply	640
We will try to formulate it in a more elegant manner in a future version.	I-Reply	I-1	Reply	640
[line_break_token]- We admit that the proposed method is not better than baselines.	B-Reply	B-2	Reply	640
A	I-Reply	I-2	Reply	640

This paper considers from a high level the problem of learning a latent representation of high dimensional observations with underlying dynamics for control.	O	O	Review	20446
 The authors specifically describe some desiredata for latent representations for LLC algorithms.	O	O	Review	20446
The authors rigorously construct a learning framework that can satisfy the desiredata and then show how this can be tractably instantiated.	O	O	Review	20446
[line_break_token][line_break_token]The paper overall is clear, however there is many equations in 4.2  with heavy subscritping making it sometimes difficult to read.	B-Review	B-1	Review	20446
The authours could attempt to better highlight the more critical parts of their propositins (e.g. eq.	I-Review	I-1	Review	20446
8/9).	I-Review	I-1	Review	20446
[line_break_token][line_break_token]The methodology and insights appear novel and well motivated, however I am not familiar with many of the prior work.	O	O	Review	20446
 The experiments compared to competing methods  show substantial improvement.	O	O	Review	20446
The authors also motivate well why these improvements over the existing methods should occur and provide ablations to validate all the components of the final loss.	O	O	Review	20446
Overall the paper appears very solid and may motivate insights and research  in more complex model based control and planning [line_break_token]	B-Review	B-2	Review	20446
e thank the reviewer for appreciating our work in terms of novelty, theory, and experiments.	O	O	Reply	20446
[line_break_token][line_break_token]We will improve the notations and presentation of the mathematical results, especially in Section 4.2, in the final version of the paper.	B-Reply	B-1	Reply	20446

In this article, the authors propose a generative adversarial network named UWGAN to generate realistic underwater images from the pairs of in-air images and depth images.	O	O	Review	498
Then, a U-Net was leveraged to enhance the results.	O	O	Review	498
[line_break_token]However, the text suffers from too many language problems.	O	O	Review	498
The authors should consult professional proofreading services.	O	O	Review	498
As a courtesy towards referees, the quality of writing needs meticulous attention before a scientific paper should be submitted.	O	O	Review	498
[line_break_token][tab_token]Other comments:[line_break_token]1.	O	O	Review	498
[tab_token]The literature is limited.	B-Review	B-1	Review	498
I found some novel works being done in the field that must be addressed and listed in the background and experiments.	I-Review	I-1	Review	498
[line_break_token]2.	B-Review	B-2	Review	498
[tab_token]The underwater imaging model presented in this paper derives from the Jaffe-McGlamery model, which is a common sense in this field.	I-Review	I-2	Review	498
The authors use a generator to produce underwater images that only implements the common model by a neural network.	I-Review	I-2	Review	498
Moreover, the statement of section 2.2 is not clear.	I-Review	I-2	Review	498
Please rewrite this section.	I-Review	I-2	Review	498
[line_break_token]3.	O	O	Review	498
[tab_token]The authors used U-Net without any improvement to enhance the results generated from UWGAN, which is the integration of existing models.	B-Review	B-3	Review	498
[line_break_token]4.	O	O	Review	498
[tab_token]The authors claimed that their model is better than others, while there is no evidence to indicates that.	B-Review	B-4	Review	498
For example, 1) in (page 5, line 4 from bottom), ‚ÄúIt can be seen that our proposed method has achieved a higher score.	I-Review	I-4	Review	498
‚Äù, can we observe this from the Table 1 and 2?	I-Review	I-4	Review	498
2) ‚ÄúThe method we proposed has the fastest processing speed compared to other methods.	I-Review	I-4	Review	498
Moreover, the method proposed in this paper has the fewest parameters compared to other deep-learning-based methods.	I-Review	I-4	Review	498
‚Äù, it is suggested that a study about the parameters and FLOPs of the involved methods should be given.	I-Review	I-4	Review	498
[line_break_token]5.	B-Review	B-5	Review	498
[tab_token]Please carefully check the references.	I-Review	I-5	Review	498
For example, ‚ÄúHummel R. Image enhancement by histogram transformation[J]. Unknown, 1975.‚Äù lacks the journal name.	I-Review	I-5	Review	498
[line_break_token]6.	O	O	Review	498
[tab_token]High-resolution figures should be given in the manuscript.	B-Review	B-6	Review	498
[line_break_token]	O	O	Review	498
e would like to thank the reviewer for pointing out some problems in our work.	O	O	Reply	498
Please find our response to your questions below.	O	O	Reply	498
We have updated the paper and uploaded a revision on Nov 13.	O	O	Reply	498
[line_break_token][line_break_token]**1) The literature is limited.**	O	O	Reply	498
[line_break_token][line_break_token]**Response:** We have cited and listed some new references in the background.	B-Reply	B-1	Reply	498
In section 4, the method we chose to compare with ours can be roughly divided into three types: model-free algorithms, model-based algorithms, and deep-learning-based algorithms.	I-Reply	I-1	Reply	498
These methods are classical and representative, we can't list too much due to paper length limit.	I-Reply	I-1	Reply	498
[line_break_token][line_break_token]&gt; Anwar S, Li C, Porikli F. Deep underwater image enhancement[J]. arXiv preprint arXiv:1807.03528, 2018.	O	O	Reply	498
[line_break_token]&gt;[line_break_token]&gt; Ancuti C, Ancuti C O, De Vleeschouwer C. D-hazy: A dataset to evaluate quantitatively dehazing algorithms[C]//2016 IEEE International Conference on Image Processing (ICIP).	O	O	Reply	498
IEEE, 2016: 2226-2230.	B-Reply	B-1	Reply	498
[line_break_token]&gt;[line_break_token]&gt; Uplavikar P, Wu Z, Wang Z. All-In-One Underwater Image Enhancement using Domain-Adversarial Learning[J]. arXiv preprint arXiv:1905.13342, 2019.	O	O	Reply	498
[line_break_token]&gt;[line_break_token]&gt; Anwar S, Li C. Diving Deeper into Underwater Image Enhancement: A Survey[J]. arXiv preprint arXiv:1907.07863, 2019.	O	O	Reply	498
[line_break_token]&gt;[line_break_token]&gt; Ding X, Wang Y, Yan Y, et al Jointly Adversarial Network to Wavelength Compensation and Dehazing of Underwater Images[J]. arXiv preprint arXiv:1907.05595, 2019.	O	O	Reply	498
[line_break_token]&gt;[line_break_token]&gt; Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint arXiv:1804.02767, 2018.	O	O	Reply	498
[line_break_token][line_break_token]**2) The underwater imaging model presented in this paper derives from the Jaffe-McGlamery model, which is a common sense in this field.	O	O	Reply	498
The authors use a generator to produce underwater images that only implements the common model by a neural network.	O	O	Reply	498
Moreover, the statement of section 2.2 is not clear.	O	O	Reply	498
Please rewrite this section.**	O	O	Reply	498
[line_break_token][line_break_token]**Response:** We have rewritten section 2.1 and 2.2.	B-Reply	B-2	Reply	498
Inspired by in-air images dehazing algorithms, we improved the underwater imaging model in this paper.	I-Reply	I-2	Reply	498
Then, we employed GAN for generating more realistic underwater-style images based on the improved model (taken both light attenuation and haze effect in real-world underwater images into consideration), which can be found in Sections 2.1 and 2.2 in this paper.	I-Reply	I-2	Reply	498
[line_break_token][line_break_token]**3) The authors used U-Net without any improvement to enhance the results generated from UWGAN, which is the integration of existing models.**	O	O	Reply	498
[line_break_token][line_break_token]**Response:** U-Net is an efficient tool for the proposed pipeline.	B-Reply	B-3	Reply	498
We employed U-Net as an enhancement network structure, but not only that, we studied the effect of different loss functions in U-Net (The detailed content can be found in Page 11, section APPENDIX), which could provide a new idea for further research about loss functions on underwater image enhancement.	I-Reply	I-3	Reply	498
Considering the inference speed and Flops, U-Net is better than other networks and could run on real-time compared to other deep-learning-based methods mentioned in this paper.	I-Reply	I-3	Reply	498
[line_break_token][line_break_token]**4) The authors claimed that their model is better than others, while there is no evidence to indicates that.**	O	O	Reply	498
[line_break_token][line_break_token]**Response:** We have revised some imprecise sentences of the result analysis part in section 4, ‚ÄúTable 1 and Table 2 quantitatively show the scores of sample images in Figure 5 and Figure 6 respectively.	B-Reply	B-4	Reply	498
It can be seen that our proposed method has achieved the highest scores in (a), (c) and (f).	I-Reply	I-4	Reply	498
In addition, the average quantized scores evaluated on RealA, RealB, and RealC datasets are shown in Table 3.	I-Reply	I-4	Reply	498
Our model achieves the best score in terms of color restoration.	I-Reply	I-4	Reply	498
‚Äù Besides, we add FLOPs of deep-learning-based methods in Table 5.	I-Reply	I-4	Reply	498
[line_break_token][line_break_token]**5) Please carefully check the references.**	O	O	Reply	498
[line_break_token][line_break_token]**Response:** We have revised small errors in references.	O	O	Reply	498
[line_break_token][line_break_token]&gt; ‚ÄúHummel R. Image enhancement by histogram transformation[J]. Computer Graphics and Image Processing, 1977, 6(2):184-195.‚Äù[line_break_token][line_break_token]**6) High-resolution figures should be given in the manuscript.**	O	O	Reply	498
[line_break_token][line_break_token]**Response:**  We have improved the resolution of images in this paper.	B-Reply	B-6	Reply	498
It should support higher magnifications	I-Reply	I-6	Reply	498

[line_break_token]I'd like to thank the authors for their detailed response to my questions.	O	O	Review	327
[line_break_token][line_break_token]The paper proposes a support regularized version of sparse coding that takes into account the underlying manifold structure of the data.	O	O	Review	327
For this purpose, the authors augment the classic sparse coding loss with a term that encourages near by points to have similar active set.	O	O	Review	327
Convergence guarantees for the optimization procedure are presented.	O	O	Review	327
Experimental evaluation on clustering and semi-supervised learning shows the benefits of the proposed approach.	O	O	Review	327
[line_break_token][line_break_token]The paper is well written and a nice read.	O	O	Review	327
The most relevant contribution of this work is to including (and optimizing) the regularization function, and not an approximation or surrogate.	O	O	Review	327
The authors derive a a PGD-styple iterative method and present convergence analysis for it.	O	O	Review	327
[line_break_token][line_break_token]Thanks for the clarifications regarding the assumptions used in Section 3.	B-Review	B-1	Review	327
It would be nice to include some of that in the manuscript.	I-Review	I-1	Review	327
[line_break_token][line_break_token]The authors also propose a fast encoding scheme for their proposed method.	O	O	Review	327
[line_break_token]The authors included a new experiment in semi-supervised consists of a very interesting use (of the method and the fast approximation).	B-Review	B-2	Review	327
While this is an interesting addition, I think that using fast encoders is not particularly novel or the main part of the work. "	I-Review	I-2	Review	327
Converting" iterative optimization algorithms into feed-forward nets for accelerating the inference process has been done in the past (several times with quite similar problems).	I-Review	I-2	Review	327
Is natural that this can be done, and not very surprising.	I-Review	I-2	Review	327
Maybe would be interesting to evaluate how important is to have an architecture matching the optimization algorithm, compared to a generic network (though some of this analysis has also been performed in the past).	I-Review	I-2	Review	327
[line_break_token][line_break_token][line_break_token]	O	O	Review	327
Thank you for your comment!	O	O	Reply	327
[line_break_token][line_break_token]We have included the intuition of what implies the condition G_ki >=0  in Section 3.	O	O	Reply	327
Moreover, we have presented the additional experiments in the revised paper on the MNIST and CIFAR-10 data for the clustering and semi-supervised learning tasks, which further demonstrate the effectiveness of SRSC and Deep-SRSC.	B-Reply	B-2	Reply	327

This paper is a survey of unsupervised learning techniques applied to the unsupervised task of descriptor matching.	O	O	Review	33
Various methods such as Gaussian RBMs, sparse RBMs, and mcRBMs were applied to image patches and the resulting feature vectors were used in a matching task.	O	O	Review	33
These methods were compared to standard hand-crafted descriptors such as SIFT, SURF, etc.	O	O	Review	33
[line_break_token][line_break_token]Pros[line_break_token]Provides a survey of descriptors for matching pairs of image patches.	O	O	Review	33
[line_break_token][line_break_token]Cons[line_break_token]It is not clear what the purpose of the paper is.	B-Review	B-2	Review	33
The paper compares several learning algorithms on the task of what essentially seems like clustering image patches to find their correspondences.	I-Review	I-2	Review	33
The ground truth correspondences of the dataset were found by clustering the image patches to find correspondences... In this paper, simple clustering methods were not compared to such as kmeans or sparse coding which are less complicated models than RBMs and are meant for finding correspondences.	B-Review	B-3	Review	33
Additionally, training in a supervised way makes much more sense for finding correspondences.	B-Review	B-5	Review	33
[line_break_token][line_break_token]It is not clear from the paper alone what is considered at match between descriptors?	B-Review	B-6	Review	33
Is it the distance being below a threshold, the pair of descriptors being closer than any other pair of descriptors, etc.?	I-Review	I-6	Review	33
[line_break_token][line_break_token]The preprocessing of the image patches seems different for each method.	B-Review	B-7	Review	33
This could lead to wildly different scales of the input pixels and thus the corresponding representations of the various methods.	I-Review	I-7	Review	33
[line_break_token][line_break_token]In section 3.3 it is mentioned that it is surprising that L1 normalization works better because sparsity hurts classification typically.	B-Review	B-8	Review	33
However, the sparsity in the paper is directly before the distance calculation, and not before being fed as input to a classifier which is a different setup and would thus be expected to behave differently with sparsity.	B-Review	B-9	Review	33
This is the typical setup in which sparsity is found to hurt classification performance because information is being thrown away before the classifier is used.	I-Review	I-9	Review	33
[line_break_token][line_break_token]Novelty and Quality:[line_break_token]This paper is not novel in that it is survey of prior work applied to matching descriptors.	B-Review	B-10	Review	33
It is well written but does not appear to apply to a wide audience as other papers have done a comparison of unsupervised methods in the past, for example:[line_break_token]- A. Coates, H. Lee, and A. Ng.	I-Review	I-10	Review	33
An analysis of single-layer networks in unsupervised feature learning.	I-Review	I-10	Review	33
In Proc.	I-Review	I-10	Review	33
AISTATS, 2011.	I-Review	I-10	Review	33
[line_break_token]- A. Coates and A. Ng.	I-Review	I-10	Review	33
The importance of encoding versus training with sparse coding and vector quanti- zation.	I-Review	I-10	Review	33
In Proc.	I-Review	I-10	Review	33
ICML, 2011.	I-Review	I-10	Review	33
Dear 3338,[line_break_token]Thank you for your feedback.	O	O	Reply	33
In order to give a comprehensive[line_break_token]answer, we quote sentences from your feedback and try to respond[line_break_token]appropriately.	O	O	Reply	33
[line_break_token][line_break_token]> It is not clear what the purpose of the paper is.	O	O	Reply	33
[line_break_token]We suggest that the way unsupervised feature learning[line_break_token]methods are evaluated should be extended: A more direct evalution[line_break_token]of the learnt representations without subsequent supervised algorithms,[line_break_token]and not tied to the task of high-level object classification.	B-Reply	B-2	Reply	33
[line_break_token][line_break_token]> The ground truth correspondences of the dataset were found by [line_break_token]> clustering the image patches to find correspondences.	O	O	Reply	33
[line_break_token]This is not how the description of [R1] with respect to the[line_break_token]Ground Truth Data (section II in [R1]) reads.	B-Reply	B-3	Reply	33
[line_break_token][line_break_token]> In this paper, simple clustering methods were not [line_break_token]> compared to such as kmeans ...[line_break_token]We added a K-Means experiment to the new version of the paper.	B-Reply	B-4	Reply	33
[line_break_token]We run K-Means (with a soft threshold function) [R2] on the dataset,[line_break_token]it performs worse than spGRBM. (	I-Reply	I-4	Reply	33
This is mentioned in the new version[line_break_token]3 of the paper).	I-Reply	I-4	Reply	33
[line_break_token][line_break_token]> Additionally, training in a supervised way makes much more sense[line_break_token]> for finding correspondences.	O	O	Reply	33
[line_break_token]This is not the question that we are asking.	B-Reply	B-5	Reply	33
We deliberately [line_break_token]avoid any supervised training because we want to investigate[line_break_token]purely unsupervised methods.	I-Reply	I-5	Reply	33
We are not trying to achieve any [line_break_token]state-of-the-art results.	I-Reply	I-5	Reply	33
[line_break_token][line_break_token]> It is not clear from the paper alone what is considered at match [line_break_token]> between descriptors[line_break_token]We have added some text that describes how a false positive[line_break_token]rate for a fixed true positive rate is computed.	B-Reply	B-6	Reply	33
[line_break_token][line_break_token]> The preprocessing of the image patches seems different for each [line_break_token]> method.	O	O	Reply	33
This could lead to wildly different scales of the input [line_break_token]> pixels and thus the corresponding representations of the various [line_break_token]> methods.	O	O	Reply	33
[line_break_token]Could you elaborate why this is something to consider [line_break_token]in our setting?	B-Reply	B-7	Reply	33
[line_break_token][line_break_token]> In section 3.3 it is mentioned that it is surprising that L1 [line_break_token]> normalization works better because sparsity hurts classification [line_break_token]> typically.	O	O	Reply	33
[line_break_token]We don't say that 'sparsity hurts classification typically'.	B-Reply	B-8	Reply	33
We say[line_break_token]the exact opposite (that sparse representations are beneficial[line_break_token]for classification) and give a reference to [R3], a paper that you[line_break_token]also reference.	I-Reply	I-8	Reply	33
We say that it is surprising that a sparse representation[line_break_token]('sparse' as produced by spGRBM, not by a normalization scheme) [line_break_token]performs better in a  distance calculation, because the general [line_break_token]understanding is (to our  knowledge) that sparse representations [line_break_token]suffer  more from the curse of dimensionality when considering [line_break_token]distances.	I-Reply	I-8	Reply	33
[line_break_token][line_break_token]> However, the sparsity in the paper is directly before the distance [line_break_token]> calculation, and not before being fed as input to a classifier which [line_break_token]> is a different setup and would thus be expected to behave differently [line_break_token]> with sparsity.	O	O	Reply	33
This is the typical setup in which sparsity is found to [line_break_token]> hurt classification performance because information is being thrown [line_break_token]> away before the classifier is used.	O	O	Reply	33
[line_break_token]We don't understand what is meant here.	B-Reply	B-9	Reply	33
Wasn't the gist of [R3] that[line_break_token]a sparse encoding is key for good classification results?	I-Reply	I-9	Reply	33
However, we[line_break_token]think that the main point that we wanted to convey in the referred part[line_break_token]of the paper was poorly presented.	I-Reply	I-9	Reply	33
We tried[line_break_token]to make the presentation of the analysis part better in the new version[line_break_token](arxiv version 3) of the paper.	I-Reply	I-9	Reply	33
[line_break_token][line_break_token]> ...does not appear to apply to a wide audience as other papers have [line_break_token]> done a comparison of unsupervised methods in the past'[line_break_token]Those comparisions are, as explained in the paper, done always in combination[line_break_token]with a subsequent supervised classification algorithm on a high-level[line_break_token]object classification task.	B-Reply	B-10	Reply	33
We want to avoid exactly this setting.	I-Reply	I-10	Reply	33
We think[line_break_token]that the paper is relevant for researchers working on[line_break_token]unsupervised (feature) learning methods and for researchers working in [line_break_token]Computer Vision.	I-Reply	I-10	Reply	33
[line_break_token][line_break_token]A new version (arxiv version 3) of the paper is uploaded on March 11.	O	O	Reply	33
[line_break_token][line_break_token][R1] M. Brown, G. Hua, and S. Winder.	O	O	Reply	33
Discriminative learning of local image descriptors.	O	O	Reply	33
[line_break_token][R2] A. Coates, H. Lee, and A. Ng.	O	O	Reply	33
An analysis of single-layer networks in unsupervised feature learning.	O	O	Reply	33
[line_break_token][R3] A. Coates and A. Ng.	O	O	Reply	33
The importance of encoding versus training with sparse coding and vector quantization	O	O	Reply	33

[line_break_token]The authors propose CMOW, an extension of the CBOW model that allows the model to capture word order.	O	O	Review	253
Instead of each word being represented as a vector, words are represented by matrices.	O	O	Review	253
They extend the CBOW objective to take into account word order by replacing the averaging of vectors to create the context with matrix multiplication (a non-commutative operation).	O	O	Review	253
This is the first time this model has been applied in a large scale unsupervised setting.	O	O	Review	253
They are able to do this using their objective and an initialization strategy where the matrix embeddings are set to the identity matrix with some Gaussian noise added.	O	O	Review	253
[line_break_token][line_break_token]The results of this paper are its main weakness.	B-Review	B-1	Review	253
I did enjoy reading the paper, and it is nice to see some results using matrices as embeddings and matrix multiplication as a compositional function.	I-Review	I-1	Review	253
They include a nice analysis of how word order is captured by these CMOW embeddings while CBOW embeddings capture the word content, but it doesn't seem to make much of a difference on the downstream tasks where CBOW is better than CMOW and close to the performance of the hybrid combination of CBOW and CMOW.	I-Review	I-1	Review	253
[line_break_token][line_break_token]I think it's clear that their model is able to capture word information to some extent, but other models  (RNNs etc.)	B-Review	B-2	Review	253
can do this as well, that admittedly are more expensive, but also have better performance on downstream tasks.	I-Review	I-2	Review	253
I think a stronger motivation for their method besides an analysis of some phenomena it captures and a slight improvement on some downstream tasks when combined with CBOW is needed though for acceptance.	I-Review	I-2	Review	253
Could it be used in other settings besides these downstream transfer tasks?	I-Review	I-2	Review	253
[line_break_token][line_break_token]PROS:[line_break_token]- introduced an efficient and stable approach for training CMSM models[line_break_token]- Show that their model CMOW is able to capture word order information[line_break_token]- Show that CMOW compliments CBOW and a hybrid model leads to improved results on downstream tasks.	O	O	Review	253
[line_break_token][line_break_token]CONS[line_break_token]- The results on the hybrid model are only slightly better than CBOW.	B-Review	B-1	Review	253
CMOW alone is mostly worse than CBOW.	I-Review	I-1	Review	253
Dear reviewer,[line_break_token][line_break_token]Thanks for your review!	O	O	Reply	253
To my understanding, your main concerns with our paper are:[line_break_token][line_break_token]1. ‚	O	O	Reply	253
ÄúThe improvements of the Hybrid model over CBOW are not large enough‚Äù[line_break_token]2. ‚	O	O	Reply	253
ÄúThere are other, more powerful models (RNNs) that achieve much better results, so there is not enough justification.	O	O	Reply	253
‚Äù[line_break_token][line_break_token]Let me address these issues one at a time:[line_break_token][line_break_token]1.	O	O	Reply	253
[line_break_token]We conducted a study in the field of learning universal sentence embeddings.	B-Reply	B-1	Reply	253
Obviously, an embedding that doesn‚Äôt have a notion of word order should not be considered "universal".	I-Reply	I-1	Reply	253
The goal of our research is thus to push the limits of what simple word aggregation methods are capable of encoding.	I-Reply	I-1	Reply	253
Finding some empirical evidence, Henao et al (2018) hypothesize that the main difference of simple word embedding methods to RNNs may be their inability to capture word order.	I-Reply	I-1	Reply	253
[line_break_token][line_break_token]We successfully propose a way to diminish that difference.	I-Reply	I-1	Reply	253
Our hybrid CBOW-CMOW model is not only able to capture word order information, it scores 8% better on average on the linguistic probing tasks than CBOW.	I-Reply	I-1	Reply	253
Even if we disregard the benefit from BShift, the improvement is still large (~4%).	I-Reply	I-1	Reply	253
From the perspective of learning linguistically informed universal sentence embeddings, this is an important result, especially at a conference that is all about learning representations.	I-Reply	I-1	Reply	253
[line_break_token][line_break_token]It is true that the results on linguistic probing tasks do not transfer to the same extent to the downstream tasks, achieving an average improvement of "only" 1.2%.	I-Reply	I-1	Reply	253
We have added this in the revised version of the paper.	I-Reply	I-1	Reply	253
[line_break_token]We evaluate our models on the SentEval benchmark.	I-Reply	I-1	Reply	253
This framework is the de facto standard for evaluating sentence embeddings, and thus we should evaluate our models this way as well.	I-Reply	I-1	Reply	253
Most tasks in SentEval depend heavily on word content memorization (Conneau et al 2018).	I-Reply	I-1	Reply	253
Thus, the selection of downstream tasks rather disfavors our model, since it improves in every aspect but Word Content memorization.	I-Reply	I-1	Reply	253
[line_break_token]Recently, more doubt has been cast repeatedly whether the selection of tasks in SentEval is sufficient to test the generality of sentence embeddings (‚ÄúAnonymous ICRL Submission‚Äù, 2018), especially their compositionality (Dasgupta et al 2018).	I-Reply	I-1	Reply	253
[line_break_token][line_break_token]In summary, considering the strong results on linguistic probing tasks, and the nature of the SentEval framework, we believe that the results obtained by our hybrid CBOW-CMOW model are already strong evidence that our method produces more general, robust sentence embeddings.	I-Reply	I-1	Reply	253
[line_break_token][line_break_token]2.	O	O	Reply	253
[line_break_token][line_break_token]The research community in sentence embedding learning has paid a lot of attention to baselines based on word embedding aggregation methods (such as the one presented in this paper) that are conceptually simple, e.g., Henao et al (2018), Pagliardini et al (2018), Rueckle et al (2018), including important work presented at ICLR (Wieting et al (2016), Arora et al (2017).	B-Reply	B-2	Reply	253
[line_break_token]The reasoning is two-fold: i) Aggregated word embeddings are computationally inexpensive compared to RNNs (see Hill et al (2016), and the measurements in our work).	I-Reply	I-2	Reply	253
ii) Pushing the limits of conceptually simple encoders helps to identify the benefit introduced by more sophisticated encoders, which has also been a recurring topic of interest ( Adi et al (2016), Conneau et al (2018), Zhu et al (2018), Anonymous (2018) ).	I-Reply	I-2	Reply	253
[line_break_token]Our paper is clearly motivated by reason i), since our method is computationally as inexpensive as CBOW.	I-Reply	I-2	Reply	253
It is also motivated by reason ii): The conceptual difference between CBOW and CMOW boils down to using matrix multiplication instead of addition, followed by simple adaptations to the training procedure.	I-Reply	I-2	Reply	253
Yet, these changes substantially improve the model's ability to learn linguistic properties such as word order, which were formerly left up to more sophisticated RNNs.	I-Reply	I-2	Reply	253
[line_break_token][line_break_token]Adi et al (2016) : Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks, ICLR 2017[line_break_token]Anonymous (2018) : No Training Required: Exploring Random Encoders for Sentence Classification.	O	O	Reply	253
URL: <a href="https://openreview.net/forum?id=BkgPajAcY7" target="_blank" rel="nofollow">https://openreview.net/forum?id=BkgPajAcY7</a> , ICLR 2019 Submission[line_break_token]Arora et al (2017) : A Simple But Tough-to-Beat Baseline for Sentence Embeddings, ICLR 2017[line_break_token]Conneau et al (2018): What you can cram into a single vector, ACL 2018[line_break_token]Henao et al (2018) : Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms, ACL 2018[line_break_token]Hill et al (2016) : Learning Distributed Representations of Sentences from Unlabelled Data, NAACL 2016[line_break_token]Pagliardini et al (2018) : Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features, NAACL 2018[line_break_token]Rueckle et al (2018) : Concatenated Power Mean Word Embeddings as Universal Cross-Lingual Sentence Representations, arXiv:1803.01400[line_break_token]Wieting et al (2016) : Towards Universal Paraphrastic Sentence Embeddings, ICLR 2016[line_break_token]Zhu et al (2018) : Exploring Semantic Properties of Sentence Embedding	O	O	Reply	253

This paper performs a very important service: exploring in a clear and systematic way the performance and trainability characteristics of a set of neural network architectures -- in particular, the basic RNN motifs that have recently been popular.	O	O	Review	233
  [line_break_token][line_break_token]Pros:[line_break_token][line_break_token]* This paper addresses an important question I and many others would have liked to know the answer to but didn't have the computational resources to thoroughly attack it.	O	O	Review	233
  This is a nice use of Google's resources to help the community.	O	O	Review	233
[line_break_token][line_break_token]* The work appears to have been done carefully so that the results can be believed.	O	O	Review	233
[line_break_token][line_break_token]* The basic answer arrived at (that, in the "typical training environment" LSTMs are reliable but basically GRUs are the answer) seems fairly decisive and practically useful.	O	O	Review	233
  Of course the real answer is more complicated than my little summary here, but the subtleties are discussed nicely in the paper.	O	O	Review	233
[line_break_token][line_break_token]* The insistence on a strong distinction between capacity and trainability helps nicely clear up a misconception about the reasons why gated architectures work.	O	O	Review	233
 In sum, they're much more easily trainable but somewhat lower capacity than vanilla RNNs, and in hard tasks, the benefits of better trainability far outweigh the costs of mildly lower capacity.	O	O	Review	233
[line_break_token][line_break_token]* The point about the near-equivalence of capacity at equal numbers of parameters is very useful.	O	O	Review	233
  [line_break_token][line_break_token]* The paper makes it clear the importance of HP tuning, something that has sometimes gotten lost in the vast flow of papers about new architectures.	O	O	Review	233
[line_break_token][line_break_token]* The idea of quantifying the fraction of infeasible parameters (e.g. those that diverge) is nice, because it's a practical problem that everyone working with these networks has but often isn't addressed.	O	O	Review	233
[line_break_token][line_break_token]* The paper text is very clearly written.	O	O	Review	233
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]* The work on the UGRNNs and the +RNNs seems a bit preliminary.	B-Review	B-1	Review	233
 I don't think that the authors have clearly shown that the +RNN should be "recommended" with the same generality as the GRU.	I-Review	I-1	Review	233
  I'd at the least want some better statistics on the significance of differences between +RNN and GRU performances quantifying the results in Figure 4 (8-layer panel).	I-Review	I-1	Review	233
  In a way the high standards for declaring an architecture useful that are set in the paper make the UGRNNs and +RNN contributions seem less important.	I-Review	I-1	Review	233
  I don't really mind having them in the paper though.	I-Review	I-1	Review	233
  I guess the point of this paper is not really to be novel in the first place -- which is totally fine with me, though I don't know what the ICLR area chairs will think.	O	O	Review	233
[line_break_token][line_break_token]* The paper gives short shrift to the details of the HP algorithm itself.	B-Review	B-2	Review	233
 They do say: [line_break_token][line_break_token]     "Our setting of the tuner‚Äôs internal parameters was such that it uses Batched GP Bandits with an expected improvement acquisition function and a   [line_break_token]     Matern 5/2 Kernel with feature scaling and automatic relevance determination performed by optimizing over kernel HPs"  [line_break_token][line_break_token]and give some good references, but I expect that actually trying to replicate this involves a lot of missing details.	B-Review	B-3	Review	233
  [line_break_token][line_break_token]* I found some of the figures a bit hard to read at first, esp.	B-Review	B-4	Review	233
Fig 4, mostly due to the panels being small, having a lot of details, and bad choices for visual cleanliness.	I-Review	I-4	Review	233
  [line_break_token][line_break_token]* The neuroscience reference ("4.7 bits per synapse") seems a little bit of a throw-away to me, because the connection between these results and the experimental neuroscience is very tenuous, or at any rate, not well explained.	B-Review	B-5	Review	233
 I guess it's just in the discussion, but it seems gratuitous.	I-Review	I-5	Review	233
  Maybe it should couched in slightly less strong terms (nothing is really strongly shown to be "in agreement" here between computational architectures and neuroscience, but perhaps they could say something like -- "We wonder if it is anything other than coincidence that our 5 bits result is numerically similar to the 4.7 bits measurement from neuroscience.")	I-Review	I-5	Review	233
[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Review	233
Thank you for your review!	O	O	Reply	233
[line_break_token][line_break_token]Our experiments have demonstrated that the UGRNN performs competitively with gated architectures in terms of trainability (Fig 4) while maintaining capacity comparable to the vanilla RNN.	B-Reply	B-1	Reply	233
In the deepest trainability scenario we tested (8 layer architectures), we show that the +RNN outperforms all other architectures in both tasks, on both of our metrics.	O	O	Reply	233
While we do not report additional statistics on the significance of the differences between architectures on these trainability tasks (this is difficult as we believe that the use of an HP tuner leads to samples that are not i.i.d.),	B-Reply	B-2	Reply	233
we measured how robust our experiments are against random batching and weight initializations by running the same HP sets multiple times and looking at the final losses (Table 1 of appendix).	I-Reply	I-2	Reply	233
We found that the losses don‚Äôt deviate very much across runs, leading us to believe our results generally, and our findings regarding the UGRNN and +RNN.	B-Reply	B-3	Reply	233
 Obviously, the GRU and LSTM are better vetted through extensive study by the entire deep learning community.	O	O	Reply	233
 We have softened our language in the discussion regarding our recommendation of the +RNN, to ‚ÄúOf course further experiments will be required to fully vet the UGRNN and +RNN.	B-Reply	B-4	Reply	233
All things considered, in an uncertain training environment, we would recommend using the GRU or +RNN‚Äù.	I-Reply	I-4	Reply	233
[line_break_token][line_break_token]As you suggested, we have also now done statistical tests on the experiment described in Fig.	B-Reply	B-5	Reply	233
5, which shows evaluation losses for randomly selected HPs for different architectures trained on the parentheses task.	I-Reply	I-5	Reply	233
We ran a Welch‚Äôs t-test and found that for the 1 layer case, the differences between all loss distributions are statistically significant.	I-Reply	I-5	Reply	233
In the 8 layer case, we found that the differences were statistically significant for most architecture pairs, except for the differences between the GRU and UGRNN, LSTM and RNN, and IRNN and RNN.	I-Reply	I-5	Reply	233
 These findings have been summarized in the caption for Fig.	I-Reply	I-5	Reply	233
5.,	I-Reply	I-5	Reply	233
and exact values are reported in the Appendix	I-Reply	I-5	Reply	233

This paper proposes a new adversarial attack method by combining spatial transformations with perturbation-based noises.	O	O	Review	20365
The proposed method uses two networks to generate the parameters of spatial transformation and the perturbation noise.	O	O	Review	20365
The whole architecture is trained by a variant of GAN-loss to make the adversarial examples realistic to humans.	O	O	Review	20365
Experiments on MNIST prove that the proposed attack method can improve the success rate of white-box attacks against several models.	O	O	Review	20365
[line_break_token][line_break_token]Overall, this paper considers an important problem of adversarial robustness of classifiers, and present a new approach to craft adversarial examples.	O	O	Review	20365
The writing is clear.	O	O	Review	20365
However, I have some concerns about this paper.	O	O	Review	20365
[line_break_token][line_break_token]1.	O	O	Review	20365
This paper seems to integrate multiple ideas studied before into a single attack method.	B-Review	B-1	Review	20365
Perturbation-based adversarial examples, spatial transformation-based adversarial examples, generating adversarial examples based on the GAN loss are all studied before.	I-Review	I-1	Review	20365
And the proposed method integrates them together to form a new attack.	I-Review	I-1	Review	20365
[line_break_token][line_break_token]2.	O	O	Review	20365
The experiments are only conducted on MNIST and Fashion MNIST.	B-Review	B-2	Review	20365
More experiments on CIFAR-10 and ImageNet can further prove the effectiveness of the proposed method.	I-Review	I-2	Review	20365
[line_break_token][line_break_token]3.	O	O	Review	20365
More robust defense models should be incorporated in experiments, at least the PGD-based adversarial training model (Madry et al 2018).	B-Review	B-3	Review	20365
ur response is as follows:[line_break_token][line_break_token]1.	O	O	Reply	20365
Please allow us to re-emphasize the main novelty of our method: We focus on generating adversarial examples that look realistic to humans but also attack the classifier well; We achieve this goal by proposing a generator that conducts both spatial distortions and perturbations.	B-Reply	B-1	Reply	20365
Importantly, the proposed generator is fully differentiable so that we can train it to generate spatial distortions and perturbations jointly.	I-Reply	I-1	Reply	20365
In the joint process, spatial distortions and perturbations are ‚Äúaware of‚Äù each other and ‚Äúwork collaboratively‚Äù, so that we are able to use small spatial distortions plus small perturbations to achieve better attack performance.	I-Reply	I-1	Reply	20365
[line_break_token][line_break_token]2.	O	O	Reply	20365
We are conducting experiments on CIFAR and CelebA. We will try our best to report the results in the rebuttal.	B-Reply	B-2	Reply	20365
If the experiments cannot be concluded by the rebuttal deadline, we will report them in the revised paper.	I-Reply	I-2	Reply	20365
[line_break_token][line_break_token]3.	O	O	Reply	20365
We have conducted the experiments of adversarial training + PGD, i.e.,  Adv-Train-PGD.	B-Reply	B-3	Reply	20365
The performance results are shown in the following table.	I-Reply	I-3	Reply	20365
It can be observed that Adv-Train-PGD defends well against perturbation-based methods but is less effective than our proposed approaches.	I-Reply	I-3	Reply	20365
[line_break_token][line_break_token][line_break_token]+---------------+--------------------------------+--------------------------------+--------------------------------+--------------------------------+[line_break_token]|               |         MNIST, Model A         |         MNIST, Model B         |     Fashion MNIST, Model A     |     Fashion MNIST, Model B     |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|               | Adv-Train-FGSM | Adv-Train-PGD | Adv-Train-FGSM | Adv-Train-PGD | Adv-Train-FGSM | Adv-Train-PGD | Adv-Train-FGSM | Adv-Train-PGD |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|   No attack   |     0.9916     |     0.9915    |     0.9757     |     0.9830    |     0.9057     |     0.9060    |     0.8869     |     0.8854    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|      STM      |     0.9481     |     0.4241    |     0.1200     |     0.0413    |     0.1296     |     0.1323    |     0.1112     |     0.1132    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|  SdAdv (ours) |      0.074     |     0.0631    |     0.0744     |      0.08     |     0.1502     |     0.1049    |     0.1420     |     0.1850    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|      FGSM     |     0.9481     |     0.9710    |     0.8753     |     0.8189    |     0.8838     |     0.7499    |     0.8558     |     0.6076    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|      PGD      |     0.0926     |     0.9427    |     0.0147     |     0.7419    |     0.0764     |     0.6619    |     0.0431     |     0.5140    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|      MIM      |     0.1584     |     0.9358    |     0.0373     |     0.7201    |     0.1054     |     0.5987    |     0.0515     |     0.4401    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|     AdvGAN    |     0.9278     |     0.9906    |     0.2868     |     0.8680    |     0.1854     |     0.3762    |     0.1015     |     0.1387    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]| SdpAdv (ours) |      0.033     |     0.0752    |     0.0741     |     0.092     |     0.0444     |     0.1113    |     0.0392     |     0.1081    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+	I-Reply	I-3	Reply	20365

The paper presents a model that learns an embedding/representation for spatial points (POI's).	O	O	Review	600
There are two specific things the representations are trying to encode - location modeling and spatial context modeling and the model tries to do it in multi-scale manner to increase the information/granularity of the learnt representations.	O	O	Review	600
[line_break_token][line_break_token]The experiments are performed on Yelp Data challenge which has 21,830 POI's with 1191 POI types.	O	O	Review	600
In the location context experiments authors show that by going after a smaller grid size we can get much better results compared to other methods while other methods like tile, wrap and rbf have more parameters causing overfitting.	O	O	Review	600
Similarly, on spatial context modeling we see better results.	O	O	Review	600
[line_break_token][line_break_token]Overall, the problem of learning vector representations for spatial points is interesting and useful and this paper has valuable contributions on how to do it.	O	O	Review	600
[line_break_token][line_break_token]One thing I would like to have seen to strengthen the paper further is the application of these representations in other tasks like image classification or recommendation systems or retrieval.	B-Review	B-1	Review	600
The paper currently misses that.	I-Review	I-1	Review	600
[line_break_token][line_break_token]For ex - <a href="https://arxiv.org/abs/1505.03873" target="_blank" rel="nofollow">https://arxiv.org/abs/1505.03873</a> uses location information to improve image classification, similarly can we use the representation learned through this method instead of positional coordinates and show that it helps the final task.	O	O	Review	600
hank you for your valuable suggestion about adding another application of the proposed space representation model.	B-Reply	B-1	Reply	600
We followed your suggestion and applied our Space2Vec to the task of  fine-grained image classification.	I-Reply	I-1	Reply	600
[line_break_token] [line_break_token]The core idea is to use our Space2Vec to capture the spatial prior information of species distribution.	I-Reply	I-1	Reply	600
We follow the exact experiment setup as Mac Aodha et al [1], which had a similar inductive learning set up as our main result: using a location encoder to encode geographic coordinates into location embeddings.	I-Reply	I-1	Reply	600
Mac Aodha et al combined the location encoder with a pretrained InceptionV3 network to do image classification.	I-Reply	I-1	Reply	600
Tang et al [2] leveraged a diverse set of metadata (e.g. hashtags, ACS data), but they discretized latitude and longitude to train embedding for each space block, which is comparable to our tile-based baselines in Table 1 and 2.	I-Reply	I-1	Reply	600
In fact, Mac Aodha et al [1] already included Tang et al [2] as a baseline for fine-grained image classification task.	I-Reply	I-1	Reply	600
We also included Tang et al [2] in Table 3.	I-Reply	I-1	Reply	600
[line_break_token] [line_break_token]We utilized the original code of Mac Aodha et al [1] and replaced their location encoder with our Space2Vec model.	I-Reply	I-1	Reply	600
We picked two fine-grained image classification datasets of significant sizes, BirdSnap‚Ä† (49,829 images spanning 500 species of North American birds) and NABirds‚Ä† (555 categories with a total of 48,562 images) as example datasets which have been used in Mac Aodha et al [1]. Experiment results showed that our grid and theory model can outperform previous models as well as the model of Mac Aodha et al [1] on both datasets.	I-Reply	I-1	Reply	600
For experiment results and details, please refer to Appendix A.6 in our updated paper on openreview.	I-Reply	I-1	Reply	600
[line_break_token] [line_break_token]We believe that this additional task demonstrates the generalizability of our space representation model.	I-Reply	I-1	Reply	600
[line_break_token] [line_break_token]References:[line_break_token]1.	O	O	Reply	600
Mac Aodha, O., Cole, E. and Perona, P., 2019.	O	O	Reply	600
Presence-Only Geographical Priors for Fine-Grained Image Classification.	O	O	Reply	600
arXiv preprint arXiv:1906.05272.	O	O	Reply	600
[line_break_token]2.	B-Reply	B-1	Reply	600
Tang, K., Paluri, M., Fei-Fei, L., Fergus, R. and Bourdev, L., 2015.	O	O	Reply	600
Improving image classification with location context.	O	O	Reply	600
In Proceedings of the IEEE international conference on computer vision (pp.	O	O	Reply	600
1008-1016).	O	O	Reply	600
<a href="https://arxiv.org/abs/1505.03873" target="_blank" rel="nofollow">https://arxiv.org/abs/1505.03873</a>	O	O	Reply	600

[line_break_token]##### Rebuttal Response:[line_break_token]The other reviewers seem to have understood more than me.	O	O	Review	300
Their opinion and the rebuttal did not convince me to update my score.	O	O	Review	300
In my opinion the writing must be adapted to be interesting to the ICLR community and the bigger picture should be highlighted more, as the bigger picture is remains quite unclear at the current state.	B-Review	B-3	Review	300
[line_break_token][line_break_token][line_break_token]##### Review:[line_break_token]Summary: [line_break_token][...][line_break_token][line_break_token][line_break_token]Conclusion:[line_break_token]I have read the paper multiple times and I still have a problem summarizing the paper with my own words.	O	O	Review	300
The contributions summarize the most fundamental works of RL but do not really relate these methods to the proposed approach.	B-Review	B-1	Review	300
Therefore, I am still uncertain about the general motivation and intention of the work as well as the evaluation.	I-Review	I-1	Review	300
Currently I vote for borderline reject as I am familiar with RL &amp; PDE'S but do not understand the motivation and intention.	O	O	Review	300
I am leaning towards rejection as the paper is a resubmission from Neurips and has not been substantially improved.	B-Review	B-1	Review	300
However, I am not certain about my evaluation.	I-Review	I-1	Review	300
I am happy to adapt my vote based on the other reviewers and a clarified and better structured paper, which can be submitted during the rebuttal.	O	O	Review	300
hanks the reviewer for your feedbacks.	O	O	Reply	300
[line_break_token][line_break_token]We have updated the manuscript for the following 3 parts, where all the updates are in the "Complementary Experiments" section (section A) in the Appendix.	B-Reply	B-2	Reply	300
1) We added experiments on comparing our RL-based method and a SL-based method, in appendix A.1.	I-Reply	I-2	Reply	300
2) We add more figures analyzing the performance of our RL policy on smooth regions and near singularities of the PDE solutions in appendix A.2.	I-Reply	I-2	Reply	300
3) We report and compare the inference time of our RL policy and WENO in appendix A.3.	I-Reply	I-2	Reply	300
Currently we put these contents in appendix, but if the paper gets accepted, we would then incorporate them into the main body in the final version.	I-Reply	I-2	Reply	300

This paper uses a collection of methods (with minor improvements) to obtain good prediction performance on ImageNet-subset data.	O	O	Review	1582
I sincerely recommend authors improving the paper's quality by offering more analysis and insights of their method.	O	O	Review	1582
[line_break_token][line_break_token]1.	O	O	Review	1582
Could authors add more experiments on explaining their motivations?	B-Review	B-1	Review	1582
[line_break_token]- The big motivation to their work is "feature representations will become more similar as depth increases leading to easier classification" (in the introduction).	I-Review	I-1	Review	1582
However, this is only supported with results in a small table in Appendix.	I-Review	I-1	Review	1582
C.[line_break_token]- It is better to show results directly based on GCNZ, and then results on SGCN.	B-Review	B-2	Review	1582
[line_break_token]- It seems that the performance in Table 6 and 1 (hop 2) are not consistent.	B-Review	B-3	Review	1582
Are there any reasons for this?	I-Review	I-3	Review	1582
[line_break_token]- Except for accuracy, could author design some other measurement to evaluate the smoothness of the embedding in deeper layers? (	B-Review	B-4	Review	1582
perhaps t-SNE as Wang etal 2018).	I-Review	I-4	Review	1582
[line_break_token]- All the above will make the paper sound more principle and better motivated.	B-Review	B-1	Review	1582
Currently, the motivation is not well justified.	I-Review	I-1	Review	1582
[line_break_token][line_break_token]2. "	O	O	Review	1582
Rethinking" indicates in-depth analysis of existing works, based on Q1, I suggest the author changes their title as well.	B-Review	B-5	Review	1582
[line_break_token][line_break_token]3.	O	O	Review	1582
The connections to ancestors and descendants look tricky.	B-Review	B-6	Review	1582
Are there any insight reasons for connecting and training in this way?	I-Review	I-6	Review	1582
[line_break_token]- Specifically, the connectivity patterns in the graph is very complex.	I-Review	I-6	Review	1582
The authors have also said there can be DAG in the graph, so, why should we connect in this way?	I-Review	I-6	Review	1582
[line_break_token][line_break_token]4.	O	O	Review	1582
Can the proposed method be used on other kinds of data sets except those from the image domain?	B-Review	B-7	Review	1582
[line_break_token][line_break_token]5.	O	O	Review	1582
The motivation in this paper is inconsistent with experiments in Wang et al 2018.	B-Review	B-8	Review	1582
Wang has shown in Section:"how important is the depth of GCN" & Table 4 that the model performance increasing with the depth of layers.	O	O	Review	1582
So, could the authors repeat the same experiments on NELL & NEIL?	O	O	Review	1582
This will make the motivation more convincing.	B-Review	B-8	Review	1582
Dear Reviewer 3.	O	O	Reply	1582
Thank you for your constructive comments.	O	O	Reply	1582
[line_break_token][line_break_token]1.	O	O	Reply	1582
[line_break_token]- Thank you for pointing out that the motivation might not have been clear enough in the original submission.	B-Reply	B-1	Reply	1582
In Appendix C we only include a small study because our conclusion is derived from theoretical analysis.	I-Reply	I-1	Reply	1582
We will update Section 3.2 to include:[line_break_token]The Laplacian smoothing operation in matrix form can be written as, as also noted in Li et al (2018).	I-Reply	I-1	Reply	1582
Substituting the graph Laplacian with its definition the operation simplifies for (looking only at the immediate neighbors) to.	I-Reply	I-1	Reply	1582
This corresponds to the first part of the update rule in Equation~(1) meaning that the complete update rule is thus a smoothing operating followed by a matrix multiplication with the weights, which can be interpreted as a fully connected layer.	I-Reply	I-1	Reply	1582
Thus, repeatedly applying the update rule in Equation~(1) will lead to repeatedly applying Laplacian smoothing, thus diluting the information.	I-Reply	I-1	Reply	1582
[line_break_token][line_break_token]- It is better to show results directly based on GCNZ, and then results on SGCN.	O	O	Reply	1582
[line_break_token]Appendix D shows the transition from GCNZ to SGCN illustrating all the modifications that have been made.	B-Reply	B-2	Reply	1582
[line_break_token][line_break_token]- It seems that the performance in Table 6 and 1 (hop 2) are not consistent.	O	O	Reply	1582
Are there any reasons for this?	O	O	Reply	1582
[line_break_token]Thank you for indicating that this can cause confusion.	B-Reply	B-3	Reply	1582
The results in Table 6 are for the non-finetuned version of SGCN while the results in Table 1 are for the finetuned version of SGCN.	I-Reply	I-3	Reply	1582
We will state this explicitly in the updated version.	I-Reply	I-3	Reply	1582
[line_break_token][line_break_token]3.	B-Reply	B-1	Reply	1582
We designed it so that that it allows all nodes to communicate with each other within two propagation steps.	B-Reply	B-6	Reply	1582
Another advantage of this connection scheme is that it is not very complex as ancestors and descendants are well defined in a DAG due to the direction of the edges.	I-Reply	I-6	Reply	1582
[line_break_token][line_break_token]4.	O	O	Reply	1582
Indeed, the proposed method can be used for other kinds of data sets.	B-Reply	B-7	Reply	1582
The only requirement is that we have a DAG that describes meaningful relations between classes and some form of semantic representation of each class (for example the word embedding).	I-Reply	I-7	Reply	1582
Non-image data could be considered by replacing the pre-trained CNN with a pre-trained fully connected network.	I-Reply	I-7	Reply	1582
[line_break_token][line_break_token]5.	O	O	Reply	1582
Our motivation of focusing on the ImageNet dataset is that it is a commonly used large-scale benchmark dataset for zero-shot learning that, most importantly, is openly available to allow reproducibility.	B-Reply	B-8	Reply	1582
We want to stress that there is a fundamental difference in our experimental setting and the study in Wang et al 2018 as their ablation study does not only modify the number of layers in the network but at the same time the number of neurons per layer.	I-Reply	I-8	Reply	1582
Their 2-layer (one hidden layer) model has 512 neurons, the 4-layer (three hidden layer) one uses a 2048-1024-512 setup and the 6-layer (five hidden layer) setup is 2048-2048-1024-1024-512.	I-Reply	I-8	Reply	1582
In our study in Appendix C we instead keep the number of neurons in the hidden layer constant to avoid the effects that varying the number of nodes introduces	I-Reply	I-8	Reply	1582

This paper is the first (I believe) to establish a simple yet important result that Convnets for NMT encoders can be competitive to RNNs.	O	O	Review	602
The authors present a convincing set of results over many translation tasks and compare with very competitive baselines.	O	O	Review	602
I also appreciate the detailed report on training and generation speed.	O	O	Review	602
I find it's very interesting when position embeddings turn out to be hugely important (beside residual connections); unfortunately, there is little analysis to shed more lights on this aspect and perhaps compare other ways of capturing positions (a wild guess might be to use embeddings that represent some form of relative positions).	B-Review	B-1	Review	602
The only concern I have (similar to the other reviewer) is that this paper perhaps fits better in an NLP conference.	B-Review	B-2	Review	602
[line_break_token][line_break_token]One minor comment: it's slight strange that this well-executed paper doesn't have a single figure on the proposed architecture :) It will also be even better to draw a figure for the biLSTM architecture as well (it does take some effort to understand the last paragraph in Section 2, especially the part on having a linear layer to compute z).	B-Review	B-3	Review	602
We will add figures illustrating our model architecture better; our baseline biLSTM architecture closely follows [Zhou et al, TACL 2016] <a href="https://arxiv.org/pdf/1606.04199v3.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1606.04199v3.pdf</a> who have detailed figures illustrating the model.	O	O	Reply	602
[line_break_token]Position embeddings are important.	B-Reply	B-1	Reply	602
Without them our encoder has no notion of position.	I-Reply	I-1	Reply	602
We investigated position embeddings numbered from the left to right and right to left but found that one direction was enough.	I-Reply	I-1	Reply	602
[line_break_token][line_break_token]Regarding conference fit: we show that RNNs are not necessary to perform encoding in a complex sequence to sequence task and that CNNs are comparable or better.	B-Reply	B-2	Reply	602
Of course, this is of interest to the NLP community but also to the ML community.	I-Reply	I-2	Reply	602
In term of representation learning, the two stack CNN highlight that attention weights and the input representation might benefit from different depth, which can impact other tasks, and other models.	I-Reply	I-2	Reply	602
Our work also highlights  that the success of RNNs in MT cannot be attributed to their unique ability to model long term dependencies.	I-Reply	I-2	Reply	602
We believe that those findings are of great interest to the ML community	I-Reply	I-2	Reply	602

This is an interesting paper that studies the latent variable modeling from an information theoretic perspective.	O	O	Review	555
Specifically, the authors argue that the rate-distortion theory for lossy compression provides a natural toolkit for studying latent variable models, and they propose a lower bound (also a gap function) that could be used to assess the goodness of data fitting given a pair of prior distribution over latent factor and a likelihood function.	O	O	Review	555
Overall the paper is very well-written, clear to follow, and the authors did a great job in not overclaiming their results.	O	O	Review	555
[line_break_token][line_break_token]Several questions follow: [line_break_token]1.	O	O	Review	555
 In Eq. (	B-Review	B-1	Review	555
3), why the R.H.S. is an upper bound of the L.H.S.?	I-Review	I-1	Review	555
Under the assumption of (1) should this be equal?	I-Review	I-1	Review	555
[line_break_token]2.	O	O	Review	555
 In section 2, "must use at use" -> "must use at least".	O	O	Review	555
[line_break_token]3.	B-Review	B-4	Review	555
 Since the mutual information is convex in the conditional distribution Q(Z|X), when considering the Lagrangian, since \alpha is constrained to be positive, should the sign before \alpha be positive instead of negative?	B-Review	B-3	Review	555
[line_break_token]4.	O	O	Review	555
 In section 3.3, "An very common" -> "A very common".	O	O	Review	555
[line_break_token][line_break_token]To me the most interesting result in this paper is in Thm.	O	O	Review	555
1, Eq. (	O	O	Review	555
9), where the authors show that the optimization over the prior in latent variable modeling is exactly equivalent to the optimization of the channel in rate-distortion theory.	O	O	Review	555
Following this line the authors propose a gap function that could be used to assess the goodness of a model.	O	O	Review	555
One drawback of the current framework is that it only links the optimization of the prior, rather than the likelihood function, to rate-distortion theory, while in practice it is usually the other way around.	B-Review	B-5	Review	555
Although the authors argue in section 3.3 that similar conclusion could be achieved for a family of likelihood functions, the analysis is only possible under the very restrictive (in my personal view) assumption that relies on the existence of a smooth and invertible mapping.	I-Review	I-5	Review	555
This assumption usually does not hold in practice, e.g., the ReLU network, and as a result the analysis here is only of theoretical interest.	I-Review	I-5	Review	555
[line_break_token][line_break_token]The experimental validation basically shows the usefulness of the proposed gap function in assessing the goodness of model fitting in latent variable models.	O	O	Review	555
It would be great if there are more direct use of the proposed lower bound, but I appreciate the novelty in this paper on bridging the two subfields.	B-Review	B-6	Review	555
[line_break_token]	O	O	Review	555
[line_break_token]In the paper, we argued that results pertaining to the problem of prior optimization were relevant also to the problem of likelihood function optimization (although for the latter problem only weaker statements are possible).	B-Reply	B-5	Reply	555
In the paper we made an assumption that there existed an invertible mapping that transformed a random variable distributed according to (the "current" prior) to a random variable with distribution (the "better" prior).	I-Reply	I-5	Reply	555
Both reviewers 1 and 3 pointed out this as a limitation in the usefulness of the result.	I-Reply	I-5	Reply	555
[line_break_token][line_break_token]It turns out that the conditions imposed in the original submission were unnecessarily restrictive.	I-Reply	I-5	Reply	555
The result holds under a very general condition - we only need to assume that is a measurable function.	I-Reply	I-5	Reply	555
The claims in the paper have been restated and the proof of this is now included in the Appendix; the proof is a fairly straightforward application of basic concepts in Lebesgue integration.	I-Reply	I-5	Reply	555
However, we point out if the starting distribution is discrete, or has some discrete portions (as it is obviously the case when the alphabet \mathcal{Z} is finite), it isn't clear that such a mapping can be found.	I-Reply	I-5	Reply	555
In the paper, we do give examples of common continuous distributions where such a mapping is guaranteed to exist (multivariate gaussians and product of continuous distributions).	I-Reply	I-5	Reply	555
[line_break_token][line_break_token]We now address the individual comments:[line_break_token][line_break_token]1.	O	O	Reply	555
 In Eq. (	O	O	Reply	555
3), why the R.H.S. is an upper bound of the L.H.S.?	O	O	Reply	555
Under the assumption of (1) should this be equal?	O	O	Reply	555
[line_break_token][line_break_token]We have overloaded the meaning of - whenever it is outside of an optimization expression we imply it to be the "current" model that the statistician is trying to improve, and when inside of an optimization expression we think of as a "free" quantity that one can optimize over.	B-Reply	B-1	Reply	555
We have clarified in the paper the notation overload.	I-Reply	I-1	Reply	555
if the reviewer thinks this is still not clear, then we can consider revising the notation in the entire paper.	I-Reply	I-1	Reply	555
[line_break_token][line_break_token]3.	B-Reply	B-4	Reply	555
 Since the mutual information is convex in the conditional distribution Q(Z|X), when considering the Lagrangian, since \alpha is constrained to be positive, should the sign before \alpha be positive instead of negative?	O	O	Reply	555
[line_break_token][line_break_token]In rate-distortion theory, we want "low rate" (which implies "low" mutual information, which denotes the number of bits used to describe a source sample) and "low distortion".	B-Reply	B-3	Reply	555
The Lagrangian in rate-distortion thus needs to be setup so that minimizing it promotes reducing mutual information and reducing distortion.	I-Reply	I-3	Reply	555
In the case of a generative model, whenever is high, the meaning is that the data is well explained by the latent variable and therefore it corresponds to the notion of "low distortion".	I-Reply	I-3	Reply	555
Conversely, if is very low, then then it means that and are mismatched and thus the distortion is high.	I-Reply	I-3	Reply	555
In the Lagrangian, the logarithm of is what appears, but the logarithm is a strictly increasing function.	I-Reply	I-3	Reply	555
Since, then the correct sign is as written, i.e. I(X;Z) - \alpha \log \ell(x|z).	I-Reply	I-3	Reply	555
[line_break_token][line_break_token][line_break_token]2. &	O	O	Reply	555
4. -	B-Reply	B-4	Reply	555
suggestions taken.	I-Reply	I-4	Reply	555
[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Reply	555

[Contribution summary][line_break_token]Authors propose a new model for the DST task that (1) reduces the inference time complexity with an non-autoregressive decoder, and (2) obtains the competitive DST accuracy (49.04% joint accuracy on MultiWoZ 2.1).	O	O	Review	533
[line_break_token][line_break_token][Comments][line_break_token]- The proposed model is well motivated and well structured.	O	O	Review	533
Empirical results show improvement over other baselines, with the main gain coming from delexicalization, slot gating, fertility output, etc.	O	O	Review	533
[line_break_token][line_break_token]- Some of the details are not entirely provided - e.g. please provide the loss hyper-parameter values (e.g. Eq.23) and optimizer parameters for the training.	B-Review	B-1	Review	533
[line_break_token][line_break_token]- Overall presentation, notations, figures, etc.	B-Review	B-2	Review	533
could improve.	I-Review	I-2	Review	533
[line_break_token][line_break_token]- There have been recent work on DST with new SOTA results (e.g. ‚ÄúTowards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset‚Äù by Rastogi et al) -- please consider comparing the approaches.	B-Review	B-3	Review	533
[line_break_token]	O	O	Review	533
hank you very much for your review.	O	O	Reply	533
Below are our responses:[line_break_token][line_break_token]1.	O	O	Reply	533
About the details of parameter settings, we simply set the loss hyper-parameters and to 1.	B-Reply	B-1	Reply	533
 We set the optimizer parameters for training to,, and.	I-Reply	I-1	Reply	533
[line_break_token][line_break_token]2.	O	O	Reply	533
Thanks for pointing out the presentation issue.	B-Reply	B-2	Reply	533
We made some improvement including standardizing the notations.	I-Reply	I-2	Reply	533
We will further improve the paper presentation in the final version.	I-Reply	I-2	Reply	533
 [line_break_token][line_break_token]3.	O	O	Reply	533
Thanks for pointing out the new paper.	B-Reply	B-3	Reply	533
We note that the paper addresses a different setting and the authors employed a different evaluation metric instead of traditional joint goal accuracy.	I-Reply	I-3	Reply	533
This metric is based on a Fuzzy Matching score on non-categorical slots but traditional metric uses exact word matching instead.	I-Reply	I-3	Reply	533
 We are not sure if this metric is the one reported in the paper.	I-Reply	I-3	Reply	533
We also do not know how the authors decide which slot is categorical or non-categorical in the MultiWOZ benchmark.	I-Reply	I-3	Reply	533
Therefore, it is difficult for us to make a direct comparison of our model performance to this work.	I-Reply	I-3	Reply	533

This paper studies the importance of a neural networks weights and to which extend do they need to be updated.	O	O	Review	20708
Particularly, the authors show that freezing weights which have small gradient in the very beginning of the training only results in a very slight drop in the final accuracy.	O	O	Review	20708
[line_break_token][line_break_token]This paper should be rejected because (1) the paper only provides some empirical results on freezing network network weights, I don't think there are much insights and useful information; (2) To my knowledge, the phenomenon that only a few parameters are important has been observed before by many papers.	B-Review	B-1	Review	20708
[line_break_token][line_break_token]Given that, I vote for a rejection.	O	O	Review	20708
hank you for your feedback.	O	O	Reply	20708
To best of our knowledge, the previous studies have observed the process of freezing complete layers in a neural network unlike our studies that investigates the importance of the individual gradient parameters even in different layers without the need to freeze the complete layer and here lies the uniqueness of our study.	B-Reply	B-1	Reply	20708

*Summary*[line_break_token]The authors perform RNA secondary prediction using deep learning.	O	O	Review	582
The outputs are subject to hard constraints on which nucleotides can be in contact with others.	O	O	Review	582
They unroll a sophisticated optimization algorithm for a relaxation of the task of finding the optimal contact map subject to these constraints.	O	O	Review	582
This work is in a long line of work demonstrating that end-to-end training of models that incorporate application-specific optimization routines as sub-modules is very useful.	O	O	Review	582
In particular, it outperforms an approach where the inputs to this optimization problem come from a network that was trained using a simple loss that ignores the fact that it will feed into this structured optimizer.	O	O	Review	582
The paper also considers an application domain that will be unfamiliar to many ICLR readers interested in deep structured prediction, and may serve as a call to arms for the community engaging with additional problems in this field.	O	O	Review	582
  [line_break_token][line_break_token]*Overall Assessment*[line_break_token]The paper is well written, well executed, and part of a general research thread that ICLR readers care about.	O	O	Review	582
There are a number of technical details, such as the loss function in (8) that will be of general interest.	O	O	Review	582
I advocate for acceptance.	O	O	Review	582
[line_break_token][line_break_token]*Comments*[line_break_token]The actual specification of the output constraints doesn't occur until late in the paper.	B-Review	B-1	Review	582
Before then, the discussion of them is very abstract.	I-Review	I-1	Review	582
Given that the constraints are easy to describe, the exposition would be improved notably if you described the specific constraints earlier on.	I-Review	I-1	Review	582
This would help me understand the problem domain better.	I-Review	I-1	Review	582
[line_break_token][line_break_token]Fyi, the idea of nested structures vs. non-nested structures appears in NLP in terms of projective parsing vs. non-projective parsing.	B-Review	B-2	Review	582
There may be some relevant reading for you to do there.	I-Review	I-2	Review	582
Your specific work (minus the unrolled constraint enforcement) is similar to "Dozat et al 2017.	I-Review	I-2	Review	582
Deep biaffine attention for neural dependency parsing."	I-Review	I-2	Review	582
[line_break_token][line_break_token]The idea of backpropping through some constraint-enforcing process is reminiscent of backpropping through belief propagation.	B-Review	B-3	Review	582
See, for example, Domke's "Learning Graphical Model Parameters with Approximate Marginals Inference."	I-Review	I-3	Review	582
Or Hershey et al "Deep Unfolding: Model-Based Inspiration of Novel Deep Architectures."	I-Review	I-3	Review	582
You should also cite work using unrolled ISTA to learn sparse coding dictionaries.	I-Review	I-3	Review	582
They have terms similar to (5).	I-Review	I-3	Review	582
[line_break_token][line_break_token]What exactly was your motivation for the setup in "Test On ArchiveII Without Re-training?"	B-Review	B-4	Review	582
[line_break_token][line_break_token]How sensitive is performance to the number of optimizer iterations?	B-Review	B-5	Review	582
Does it work to train with a fixed number of unrolled iters, but at test time run the optimizer until convergence?	B-Review	B-6	Review	582
[line_break_token][line_break_token](8) is cool!	O	O	Review	582
[line_break_token]	O	O	Review	582
e would like to thank the reviewer for the overall positive comments, constructive suggestions on paper refinement and references to interesting related works!	O	O	Reply	582
[line_break_token][line_break_token][line_break_token]***Q1.	O	O	Reply	582
 ‚Äú...output constraints doesn't occur until late...‚Äù[line_break_token][line_break_token]Thank you for your suggestion on the flow of our paper!	O	O	Reply	582
In the revised version, we state the RNA secondary structure prediction problem, including the concrete constraints, in a newly added section ‚Äú3 RNA Secondary Structure Prediction Problem‚Äù, which follows the Related Work section.	B-Reply	B-1	Reply	582
[line_break_token][line_break_token][line_break_token]***Q2.	O	O	Reply	582
Related work in NLP[line_break_token][line_break_token]Thank you for referring us to these related works in NLP!	B-Reply	B-2	Reply	582
We also noticed the relation to NLP as we mentioned at the end of the introduction section.	I-Reply	I-2	Reply	582
This indeed motivates us to use transformers and also the trick mentioned in BERT to compute position information by a series of base functions.	I-Reply	I-2	Reply	582
However, it is interesting to know about projective parsing vs. non-projective parsing which we didn‚Äôt notice before!	I-Reply	I-2	Reply	582
We‚Äôve added a paragraph in the related work section to discuss this aspect.	I-Reply	I-2	Reply	582
Thank you for pointing it out, which can help us relate our work to a larger range of problems in ML.	I-Reply	I-2	Reply	582
[line_break_token][line_break_token][line_break_token]***Q3.	O	O	Reply	582
Related work on Graphical Models and ISTA[line_break_token][line_break_token]Thanks!	O	O	Reply	582
We found the ‚Äúdeep unfolding‚Äù work very related and cited it in the revised paper.	B-Reply	B-3	Reply	582
[line_break_token]In our first submission, we‚Äôve cited the unrolled ISTA paper ‚ÄúTheoretical linear convergence of unfolded ISTA and its practical weights and thresholds.	I-Reply	I-3	Reply	582
‚Äù[line_break_token][line_break_token][line_break_token]***Q4.	O	O	Reply	582
Motivation for the setup in "Test On ArchiveII Without Re-training"[line_break_token][line_break_token]One can think of ArchiveII as a separate held-out test dataset.	B-Reply	B-4	Reply	582
E2Efold is only learned from RNAStralign training set, but can directly generalize to ArchiveII, and obtain the best test results.	I-Reply	I-4	Reply	582
[line_break_token][line_break_token]In fact, testing on the ArchiveII dataset is a more challenging test for generalization, because the data distribution in ArchiveII can have a larger difference with the RNAStralign training set.	I-Reply	I-4	Reply	582
To see this, we performed additional statistical hypothesis tests using Maximum Mean Discrepancy (MMD)  [1] and attached the results in Appendix D.2.	I-Reply	I-4	Reply	582
[line_break_token][line_break_token]More specifically, we computed the empirical MMD to evaluate the differences between[line_break_token](a) RNAStralign_train and RNAStralign_test, where the MMD is 0.0025 (*can not reject* null hypothesis of no difference with p-value 0.1)[line_break_token](b) RNAStralign_train and ArchiveII, where the MMD is 0.0296 (*reject* null hypothesis of no difference with p-value &lt; 0.001)[line_break_token]These tests suggest that the difference between RNAStralign training set and ArchiveII is much larger.	O	O	Reply	582
[line_break_token][line_break_token]Therefore, the data distribution in ArchiveII is very different from the RNAStralign training set.	B-Reply	B-4	Reply	582
A good performance on ArchiveII shows a significant generalization power of our model.	I-Reply	I-4	Reply	582
[line_break_token][line_break_token][line_break_token]***Q5.	O	O	Reply	582
the number of optimizer iterations [line_break_token][line_break_token]For the explanation on the choice/effect of the number of optimizer iterations, please kindly refer to our response to this common question posted above.	B-Reply	B-5	Reply	582
[line_break_token][line_break_token][line_break_token]***Q6.	O	O	Reply	582
Does it work to train with a fixed number of unrolled iters, but at test time run the optimizer until convergence?‚Äù[line_break_token][line_break_token]It‚Äôs very interesting that the reviewer asked this question!	B-Reply	B-6	Reply	582
We were also curious about this before and tried it empirically.	I-Reply	I-6	Reply	582
We trained the model on T=20 and used it for T=50 iterations during the test phase.	I-Reply	I-6	Reply	582
However, the performance is not as good as keeping T=20 for the test.	I-Reply	I-6	Reply	582
[line_break_token][line_break_token]We think the reason could be: we choose the discounting factor in equation 9, which is also a default choice in some related works.	I-Reply	I-6	Reply	582
It gives the output at each time step T=t an equal weight.	I-Reply	I-6	Reply	582
With a smaller, the outputs at later steps can gain more weights.	I-Reply	I-6	Reply	582
In this case, it is possible that the trained network will output a progressively closer approximation of the ground truth and further generalize to a larger number of iterations.	I-Reply	I-6	Reply	582
We would investigate this option in the future.	I-Reply	I-6	Reply	582
[line_break_token][line_break_token][line_break_token]***Finally[line_break_token][line_break_token]Yes, we also like the differentiable F1 score!	B-Reply	B-7	Reply	582
Imbalanced data (more negative samples than positive samples) is a common issue in many computational biology problems (e.g. [4,5]) and our proposed method is very simple and effective in this case.	I-Reply	I-7	Reply	582
[line_break_token][line_break_token][line_break_token][1] Gretton, Arthur, et al "A kernel two-sample test."	O	O	Reply	582
JMLR (2012)[line_break_token][4] Zhou, Jian, and Olga G. Troyanskaya. "	O	O	Reply	582
Predicting effects of noncoding variants with deep learning‚Äìbased sequence model."	O	O	Reply	582
Nature methods 12.10 (2015): 931.	O	O	Reply	582
[line_break_token][5] Armenteros, Jos√© Juan Almagro, et al "SignalP 5.0 improves signal peptide predictions using deep neural networks."	O	O	Reply	582
Nature biotechnology 37.4 (2019): 420.	O	O	Reply	582
[line_break_token][line_break_token][line_break_token]Please expect the revised paper posted soon	O	O	Reply	582

Authors provide a novel approach for outlier detection of SIFT feature matchings.	O	O	Review	201
They construct a graph by connecting each SIFT feature to its 5 nearest neighbors initially.	O	O	Review	201
Then optimize a regression loss to find the matching between the 2d keypoints and 3d universal points.	O	O	Review	201
Hence applying cycle-consistency to figure out image matchings.	O	O	Review	201
[line_break_token][line_break_token]Their formulation of the problem as a GNN pruning is brilliant and widens the path for future research in the feature matching field.	O	O	Review	201
They also incorporate epipolar line constraints as a regularizer for their training.	O	O	Review	201
Experiments show effectiveness of adding the epipolar constraints.	O	O	Review	201
[line_break_token][line_break_token]Their experiments show that this is a promising approach, but probably requires further research to achieve state of the art results.	O	O	Review	201
 [line_break_token][line_break_token]I believe this work is a valuable and novel method for pruning the sift feature matches.	O	O	Review	201
It is in an early but acceptable stage.	O	O	Review	201
Adding extra regularizers on F_v (to make it one-hot?)	B-Review	B-1	Review	201
would be a promising first step.	I-Review	I-1	Review	201
Also it has been shown that GNNs performance deteriorates with increased depth.	B-Review	B-2	Review	201
There are recent developments in GNNs that alleviate the oversmoothing problem.	I-Review	I-2	Review	201
Maybe switching to these architectures would enable this work to try 15 pass GNNs.	I-Review	I-2	Review	201
[line_break_token][line_break_token]Question: How do you tune the hyper-parameters? (	B-Review	B-3	Review	201
learning rate, number of layers, etc)[line_break_token][line_break_token]Improvement: In the experiment section explain the specifics of the geometric loss, how camera calibration, etc is calculated.	B-Review	B-4	Review	201
 ‚ÄúAdding extra regularizers on F_v (to make it one-hot?)	O	O	Reply	201
would be a promising first step.	O	O	Reply	201
‚Äù[line_break_token][line_break_token]Indeed this would mean to enforce the image to universe mapping to be a partial permutation.	B-Reply	B-1	Reply	201
We could even add a differential step that rotates the ‚Äúsoft‚Äù image to universe mapping to a partial permutation.	I-Reply	I-1	Reply	201
We preferred to avoid any of those steps in order to keep the soft mapping as a feature representation which we can prune in order to compute hard matches.	I-Reply	I-1	Reply	201
But we agree that we have to investigate how such a loss term (or the rotation step) would affect the final matching outcome and we will definitely add it to our experiments.	I-Reply	I-1	Reply	201
[line_break_token][line_break_token]- ‚ÄúAlso it has been shown that GNNs performance deteriorates with increased depth.	O	O	Reply	201
There are recent developments in GNNs that alleviate the oversmoothing problem.	O	O	Reply	201
Maybe switching to these architectures would enable this work to try 15 pass GNNs.	O	O	Reply	201
‚Äù[line_break_token][line_break_token]This is a good observation, as we indeed noticed that after 12 passes of the GNN their were diminishing returns even with skip connections.	B-Reply	B-2	Reply	201
Looking over such architectures will be important for future work.	I-Reply	I-2	Reply	201
[line_break_token][line_break_token]- ‚ÄúQuestion: How do you tune the hyper-parameters? (	O	O	Reply	201
learning rate, number of layers, etc)‚Äù[line_break_token][line_break_token]For the architecture, we searched over increasing sized networks, starting with 4 layers and going up to 15, searching various numbers of hidden nodes.	B-Reply	B-3	Reply	201
We also explored various extensions such as Graph Convolutional Networks, Graph Attention Networks, and (what we finally decided on) Graph Networks from Deepmind‚Äôs graph network library.	I-Reply	I-3	Reply	201
For other hyperparameters, we searched in log-linear space.	I-Reply	I-3	Reply	201
[line_break_token][line_break_token]- ‚ÄúImprovement: In the experiment section explain the specifics of the geometric loss, how camera calibration, etc is calculated.	O	O	Reply	201
‚Äù[line_break_token][line_break_token]We will add details on the calibration in the paper, and how the geometric loss is computed into the appendix.	B-Reply	B-4	Reply	201

This paper investigates the issue of whether and how to use syntactic dependencies in unsupervised word representation learning models like CBOW or Skip-Gram, with a focus one the issue of bound (word+dependency type, 'She-nsubj') vs. unbound (word alone, 'She') representations for context at training time.	O	O	Review	504
The empirical results are extremely mixed, and no specific novel method consistently outperforms existing methods.	O	O	Review	504
[line_break_token][line_break_token]The paper is systematic and I have no major concerns about its soundness.	O	O	Review	504
However, I don't think that this paper is of broad interest to the ICLR community.	O	O	Review	504
The paper is focused on a fairly narrow detail of representation learning that is entirely specific to NLP, and its results are primarily negative.	O	O	Review	504
A short paper at an ACL conference would be a more reasonable target.	O	O	Review	504
Dear reviewer,[line_break_token]A new version of this paper is uploaded and we are exited to share the results with you.	O	O	Reply	504
[line_break_token]Please see our recent comment for more information.	O	O	Reply	504
Thanks	O	O	Reply	504

This paper proposes a neural architecture search (NAS) algorithm which automatically finds a efficient network architecture, FasterSeg, for real time semantic segmentation.	O	O	Review	20001
In designing a NAS algorithm the author takes cue from recent architectural advances introduced for faster segmentation as well as improved accuracy.	O	O	Review	20001
For instances a) it explores and integrates multi-resolution branches from BiSeNet during NAS b) simultaneously optimizes the loss for accuracy and latency (as done in CAS algorithm) and c) knowledge distillation for semantic segmentation.	O	O	Review	20001
However, the usage of these blocks in FasterSeg has been well refined to integrate with NAS search.	O	O	Review	20001
To be precise, their improved version of latency loss avoids architectural collapse during latency-constrained search and it claims to be the first work to co-search for teacher and student network using NAS.	O	O	Review	20001
Empirical experiments on benchmark dataset suggests that FasterSeg  is more than 30 percent faster with similar accuracy as state-of-the-art real-time segmentation algorithms.	O	O	Review	20001
[line_break_token][line_break_token]This paper weakly leans towards rejection.	O	O	Review	20001
Some of the contributing factors [line_break_token]1) Overall presentation of algorithm leaves one more confused.	B-Review	B-1	Review	20001
Perhaps, the paper is targeted at small set of audience who primarily works on NAS.	I-Review	I-1	Review	20001
More about specific comment in 'Clarification'.	I-Review	I-1	Review	20001
[line_break_token]2) There is not a single concrete contribution.	B-Review	B-2	Review	20001
For example, NAS search in semantic segmentation using cells and downsampling rates was done in Auto-Deeplab.	I-Review	I-2	Review	20001
Further, resource-constrained search for segmentation was introduced in Zhang et al while distillation for segmentation task was proposed by Liu et al [line_break_token]3) No doubt that it achieves improved efficiency.	B-Review	B-3	Review	20001
But at the cost of accuracy.	I-Review	I-3	Review	20001
On Camvid and BDD, the competitive algorithm is 1.7 % better in absolute terms.	I-Review	I-3	Review	20001
On cityscapes it performs on par.	I-Review	I-3	Review	20001
However, the large improvement in accuracy can be attributed to distillation process (Table 3: absolute 2%), without which the overall performance of NAS is suboptimal.	I-Review	I-3	Review	20001
[line_break_token][line_break_token]Clarification:[line_break_token]1.	O	O	Review	20001
It is not clear what is the form of initial network which is pre-trained for 20 epochs ?	B-Review	B-4	Review	20001
My guess is, initial network consists of b=3 branches with L=16 sequential layers and for each cell in a layer, the network pre-trains 5 operators as well as for different expansion ratios.	I-Review	I-4	Review	20001
Is it correct ?	I-Review	I-4	Review	20001
[line_break_token]2.	B-Review	B-14	Review	20001
Can you explain 697 unique paths as well as 10^55 unique combinations ?	B-Review	B-5	Review	20001
[line_break_token]3.	B-Review	B-7	Review	20001
It is noted that by default b=2 is used.	B-Review	B-6	Review	20001
However, in FasterSeg network shown in figure 6, I note three branches s={8,16,32}. Am I missing something ?	I-Review	I-6	Review	20001
Also, how more branches will introduce more latency ?	I-Review	I-6	Review	20001
Branches operate in parallel with max sensitivity s=0.01 and max L=16.	I-Review	I-6	Review	20001
[line_break_token]4.	O	O	Review	20001
Next, as pointed in 3.4 the discrete architecture is obtained by computing \argmax_l over \beta.	B-Review	B-7	Review	20001
In that case, there should only be single connection which branches out from s-&gt;2s.	O	O	Review	20001
In figure 6, I note two branches from 8-&gt;16 (4th and 6th cell).	O	O	Review	20001
[line_break_token]5.	O	O	Review	20001
If the teacher and student network shares the same weight, then what is the need for distillation ?	B-Review	B-8	Review	20001
Only difference I currently note is in the expansion ratio.	I-Review	I-8	Review	20001
May be you want to say same pretrained network ?	I-Review	I-8	Review	20001
[line_break_token]6.	B-Review	B-6	Review	20001
Can you explain with example how \gamma's are updated using backpropagation and lookup-table ?	B-Review	B-9	Review	20001
[line_break_token]7.	O	O	Review	20001
Are you employing STE for Gumbel-Max trick ?	B-Review	B-10	Review	20001
[line_break_token]8.	O	O	Review	20001
The individual terms in eq (3) optimizes for \alpha, \beta and \gamma respectively ?	B-Review	B-11	Review	20001
[line_break_token]9.	O	O	Review	20001
In eq (2), each cell output O is linear combination of different operator ?	B-Review	B-12	Review	20001
[line_break_token]10.	O	O	Review	20001
Once the discrete architecture is obtained, is it retrained on cityscapes from scratch or fine-tuned ?	B-Review	B-13	Review	20001
[line_break_token][line_break_token]Request for ablation:[line_break_token]1.	B-Review	B-14	Review	20001
What is the variation in NAS output with changes in \lambda ?	I-Review	I-14	Review	20001
Precisely, can one tradeoff accuracy for improved latency just by tuning \lambda ?	I-Review	I-14	Review	20001
[line_break_token]2.	I-Review	I-14	Review	20001
What happens if teacher network is also optimised over \gamma ?	I-Review	I-14	Review	20001
The difference between teacher and student will then only be in loss function.	I-Review	I-14	Review	20001
[line_break_token]3.	B-Review	B-7	Review	20001
Currently, discrete architecture is greedily extracted.	B-Review	B-14	Review	20001
This need not be the best.	I-Review	I-14	Review	20001
Instead one can utilize sequential beam search (vitterbi algorithm).	I-Review	I-14	Review	20001
With this it is possible to visualise the accuracy and latency distribution of, say top 100 architecture obtained by NAS.	I-Review	I-14	Review	20001
[line_break_token][line_break_token]Minor comments:[line_break_token]1.	B-Review	B-15	Review	20001
Seachable -&gt; Searchable[line_break_token][line_break_token]Updates:[line_break_token]I read through the reviews of other reviewers as well as the rebuttal posted by authors.	O	O	Review	20001
Overall, I am satisfied with the authors response and hence Improving my scores to Weak Accept.	O	O	Review	20001
hank you for your time and comments.	O	O	Reply	20001
We have revised our paper and we believe our responses and revisions address all your concerns.	O	O	Reply	20001
We would be very grateful if you would please look over our paper again, and consider changing your scores.	O	O	Reply	20001
[line_break_token][line_break_token]Indeed, our paper primarily targets at contributions to the NAS fields.	B-Reply	B-1	Reply	20001
 However, we also expect the work to provide broad reference values to the general audience working on related computer vision problems.	I-Reply	I-1	Reply	20001
We apologize if our paper didn‚Äôt read smoothly to you at the first glance: we have addressed all your specified ‚Äúclarification‚Äù comments and hope our work‚Äôs merit now becomes more clear to you.	I-Reply	I-1	Reply	20001
[line_break_token][line_break_token]We respectfully cannot agree on your comment ‚Äúthere is not a single concrete contribution‚Äù.	B-Reply	B-2	Reply	20001
We apologize if your misunderstanding arose from our lack of writeup clarity or else.	I-Reply	I-2	Reply	20001
Please see our detailed explanations below.	I-Reply	I-2	Reply	20001
[line_break_token][line_break_token]First of all, we are well aware of NAS search works done in semantic segmentation.	I-Reply	I-2	Reply	20001
Meanwhile, in most NAS papers published, designing novel search spaces and improving the search algorithms are considered as the two core contributions to claim: see [1,2,3] for example.	I-Reply	I-2	Reply	20001
They are also what makes FasterSeg substantially different and novel from Auto-DeepLab.	I-Reply	I-2	Reply	20001
 As confirmed by other reviewers, both our multiscale search space, the regularized latency optimization, and the co-searching algorithm are significant contributions.	I-Reply	I-2	Reply	20001
They are for the first time proposed, well-motivated, and supported by our solid ablation studies.	I-Reply	I-2	Reply	20001
Furthermore, we push the performance of real-time segmentation to a new state of the art.	I-Reply	I-2	Reply	20001
[line_break_token][line_break_token]Second, our distillation is not appended as a post-processing to the searched/designed models as done in the mentioned literature.	I-Reply	I-2	Reply	20001
Instead, integrating distillation into the NAS framework (and therefore enabling jointly search multiple networks) is the KEY.	I-Reply	I-2	Reply	20001
This is confirmed by the last two rows in Table 3, where we distill to the pruned teacher net and to our search student net respectively, from the same teacher network.	I-Reply	I-2	Reply	20001
With the same distillation training setting, the pruned teacher is 6% worse than our searched student, indicating that the important reason for our FasterSeg‚Äôs superior performance is in the optimized architecture.	I-Reply	I-2	Reply	20001
[line_break_token][line_break_token]In sum, while we all agree that neither ‚Äú(efficient) NAS for segmentation‚Äù nor ‚Äúdistillation‚Äù is novel now, our methods‚Äô contributions are concretely established, well beyond those.	I-Reply	I-2	Reply	20001
Hopefully, the above answers have resolved your confusion on our novelty.	I-Reply	I-2	Reply	20001
[line_break_token][line_break_token]In the experiments, by further fine-tuning our FasterSeg, we are now able to achieve 71.5% on Cityscapes test set, bypassing all previous works on both mIoU and FPS in Table 4, making CityScape our clear all-win case.	B-Reply	B-3	Reply	20001
In Table 5 and 6, our FasterSeg now achieves 71.1% and 54.9% respectively, reaching the same bar on mIoU as CAS and DRN, while surpassing their latency by over-doubling the FPS.	I-Reply	I-3	Reply	20001
[line_break_token][line_break_token]Notice that, we target at extremely efficient segmentation, for our own specific application needs at very high FPSs (~150 - ~400).	I-Reply	I-3	Reply	20001
Such is considered as "well-motivated" by the other two reviewers.	I-Reply	I-3	Reply	20001
To meet that demanding requirement, our model is clearly the best option available that can still maintain state-of-the-art mIOUs in addition to its unparalleled efficiency.	I-Reply	I-3	Reply	20001
[line_break_token][line_break_token]We note that the other two reviewers concur and appreciate our paper‚Äôs novelty points well.	O	O	Reply	20001
We are more than happy to provide extra clarification and justifications if needed.	O	O	Reply	20001
[line_break_token][line_break_token][1] Bender, Gabriel, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, and Quoc Le. "	O	O	Reply	20001
Understanding and simplifying one-shot architecture search."	O	O	Reply	20001
ICML 2018.	O	O	Reply	20001
[line_break_token][2] Liu, Chenxi, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. "	O	O	Reply	20001
Progressive neural architecture search."	O	O	Reply	20001
ECCV 2018.	O	O	Reply	20001
[line_break_token][3] Cai Han, Ligeng Zhu, and Song Han. "	O	O	Reply	20001
Proxylessnas: Direct neural architecture search on target task and hardware."	O	O	Reply	20001
ICLR 2019	O	O	Reply	20001

The contribution of the paper is the following two findings: 1.	B-Review	B-1	Review	679
Despite the fact that local minima are connected in the loss landscape the functions corresponding to the points on the curve are significantly distinct.	I-Review	I-1	Review	679
2.	I-Review	I-1	Review	679
The points along the training trajectory correspond to similar functions.	I-Review	I-1	Review	679
[line_break_token][line_break_token]Originality and novelty.	B-Review	B-2	Review	679
Both findings do not seem quite new.	I-Review	I-2	Review	679
The first conclusion can be mostly derived from Figure 2 right [1]. Moreover, the difference between functions on the curve in terms of predictions is the main motivation of Fast Geometric Ensembling.	I-Review	I-2	Review	679
The second conclusion is also not quite new and there were several approaches to overcome it e.g. SWA [2]. I appreciate that the authors did a much broader investigation of this phenomena than it was done in previous works.	B-Review	B-3	Review	679
Another drawback is lack of practical implications.	B-Review	B-4	Review	679
It is known that ensembling based on dropout is worse than independent networks, but the main advantage of this and similar approaches is memory efficiency.	I-Review	I-4	Review	679
[line_break_token][line_break_token]The clarity.	O	O	Review	679
The paper is well written, contains all necessary references and is easy to follow.	O	O	Review	679
The provided experimental results and supporting plots are also clear and contain the necessary description.	O	O	Review	679
The only part that I found a bit confusing is radial plots.	O	O	Review	679
I would recommend the authors to add more rigorous description of how they constructed these plots to increase clarity of the paper.	B-Review	B-5	Review	679
Can the authors please also clarify how they derived formulas for the expected fractional difference for f^* and f functions in the section 3.2?	I-Review	I-5	Review	679
[line_break_token][line_break_token]Overall, it is an interesting paper, but the findings are not quite new.	O	O	Review	679
[line_break_token][1]  Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry P Vetrov, and Andrew G Wilson.	O	O	Review	679
Loss surfaces, mode connectivity, and fast ensembling of DNNs.	O	O	Review	679
InNeurIPS, 2018[line_break_token][2] Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson.	O	O	Review	679
Av-eraging weights leads to wider optima and better generalization.arXiv preprint arXiv:1803.05407,2018[line_break_token]	O	O	Review	679
hank you for your review.	O	O	Reply	679
[line_break_token][line_break_token]‚ÄúThe contribution of the paper is the following two findings: 1.	O	O	Reply	679
Despite the fact that local minima are connected in the loss landscape the functions corresponding to the points on the curve are significantly distinct.	O	O	Reply	679
2.	O	O	Reply	679
The points along the training trajectory correspond to similar functions. ‚	O	O	Reply	679
Äú [line_break_token][line_break_token]These comments seem focused on particular subsections (Section 3.3 and Section 3.1) and significantly under-estimates the total contributions of our paper.	B-Reply	B-1	Reply	679
[line_break_token][line_break_token]To the best of our knowledge, we are the first to comprehensively investigate deep ensembles vs Bayesian neural nets from loss landscape perspective.	I-Reply	I-1	Reply	679
We carefully investigated the role of random initialization in deep ensembles, tested the complementary effects of ensembling and subspace methods, and measured diversity of functions.	I-Reply	I-1	Reply	679
Aside from earlier results on CIFAR-10 and ImageNet, we have also added new experiments on CIFAR-100 (see Figure S3 in Appendix C) which are consistent with our earlier results.	I-Reply	I-1	Reply	679
[line_break_token][line_break_token]Please see also the summary of contributions from other reviewers.	I-Reply	I-1	Reply	679
[line_break_token][line_break_token]R1 said ‚ÄúThis paper analyzes ensembling methods in deep learning from the perspective of the loss landscapes.	I-Reply	I-1	Reply	679
The authors empirically show that popular methods for learning Bayesian neural networks produce samples with limited diversity in the function space compared to modes of the loss found using different random initializations ... The paper also demonstrates the complementary benefits of using subspace sampling/weight averaging in combination with deep ensembles and shows that relative benefits of deep ensembles are higher. ‚	I-Reply	I-1	Reply	679
Äú[line_break_token][line_break_token]R2 said ‚ÄúThis paper is trying to answer the question why ensembles of deep neural networks trained with random initialization work so well in practice in improving accuracy ... Overall, the paper is very well written and provides interesting insights into the multi-modal structure of deep neural network loss landscapes.	I-Reply	I-1	Reply	679
‚Äù[line_break_token][line_break_token]--------------[line_break_token][line_break_token]‚ÄúI would recommend the authors to add more rigorous description of how they constructed these plots to increase clarity of the paper.	O	O	Reply	679
Can the authors please also clarify how they derived formulas for the expected fractional difference for f^* and f functions in the section 3.2? ‚	O	O	Reply	679
Äú[line_break_token][line_break_token]We have added the derivation of the two limiting functions in the appendix.	B-Reply	B-5	Reply	679
The upper limit corresponds to the best case for ensembling, where the two functions are uncorrelated.	I-Reply	I-5	Reply	679
The lower limit corresponds to the worst case, where the predictions are obtained by perturbing the outputs of the reference function by different amounts of noise, therefore retaining a large amount of correlation between their predictions.	I-Reply	I-5	Reply	679
We provide the detailed derivation in the appendix our updated version.	I-Reply	I-5	Reply	679
[line_break_token][line_break_token]--------------[line_break_token][line_break_token]‚ÄúThe first conclusion can be mostly derived from Figure 2 right of Garipov et al‚Äù [line_break_token][line_break_token]We do not agree that this conclusion can be reached from that figure as you are suggesting.	B-Reply	B-2	Reply	679
Figure 2 in Garipov et al only plots loss and accuracy, and does not measure function space similarity, between different initializations, or along the tunnel at all.	I-Reply	I-2	Reply	679
Just by looking at accuracy and loss values, there is no way to infer how similar the predictions of the two functions are.	I-Reply	I-2	Reply	679
[line_break_token][line_break_token]--------------[line_break_token][line_break_token]‚ÄúThe second conclusion is also not quite new and there were several approaches to overcome it e.g. SWA [2].‚Äù[line_break_token][line_break_token]We are not sure what exactly you mean.	B-Reply	B-3	Reply	679
Could you clarify your claim?	I-Reply	I-3	Reply	679
[line_break_token]We showed that functions along a trajectory (or subspace thereof) are similar whereas ensembling over random initializations leads to much more diversity; see sections 3.2 for diversity vs accuracy plots and Section 4 where we measure the relative effects of ensembles and subspace sampling methods.	I-Reply	I-3	Reply	679
These results indicate that random initialization provides more diversity than subspace sampling methods.	I-Reply	I-3	Reply	679
[line_break_token][line_break_token]--------------[line_break_token][line_break_token]‚ÄúAnother drawback is lack of practical implications.	O	O	Reply	679
It is known that ensembling based on dropout is worse than independent networks, but the main advantage of this and similar approaches is memory efficiency.	O	O	Reply	679
‚Äù[line_break_token][line_break_token]We‚Äôre happy to add a discussion about different regimes (training time constraints, serving time constraints, memory constraints, etc), but it is beyond the scope of this paper to discuss every possible setting in detail.	B-Reply	B-4	Reply	679
Some of these solutions are well-known in the literature, cf.	I-Reply	I-4	Reply	679
the discussion in (Lakshminarayanan et al 2017) or the take-home messages in (Ovadia et al 2019): for instance, distillation is a popular solution when serving time is the primary constraint.	I-Reply	I-4	Reply	679
Implicit ensembles (e.g. Monte-Carlo dropout) are popular when memory is the main constraint.	I-Reply	I-4	Reply	679
The best method would obviously depend on the specific constraints (as you also point out).	I-Reply	I-4	Reply	679
[line_break_token][line_break_token]The goal of this work is to understand the general question of why ensembles work well and we provide an explanation from the perspective of loss landscapes.	I-Reply	I-4	Reply	679
In future work, we plan to take these insights to develop better algorithms for specific settings	I-Reply	I-4	Reply	679

[line_break_token]This paper studies the accuracy vs model-size trade-off of quantized CNNs under different channel width multipliers.	O	O	Review	20107
The authors demonstrated that while all-to-all convolution works well under low bit settings, depthwise conv needs a different sweet spot.	O	O	Review	20107
The authors then proceed to use the insight to design quantized cnns that have two different schemes for depthwise and normal conv.	O	O	Review	20107
[line_break_token][line_break_token][line_break_token]Strength[line_break_token][line_break_token]The paper is well written and motivated.	O	O	Review	20107
By adding network width to the search space,  using the simple heuristics, the authors provide a better results than previously DRL based search method.	O	O	Review	20107
[line_break_token][line_break_token]Weakness[line_break_token][line_break_token]One of my main concerns is the direct usage of total number of bits as an equivalent measurement between models.	B-Review	B-1	Review	20107
While it is useful to measure the storage cost for weights.	I-Review	I-1	Review	20107
The choices of bit width will likely affect the computing cost in a non-trivial way, depending on the target hardware platform.	I-Review	I-1	Review	20107
It is unclear whether equal model size would mean equal inference latency in practice (most likely they would not be).	I-Review	I-1	Review	20107
Providing empirical implementations of these models will shed light into this question.	I-Review	I-1	Review	20107
[line_break_token][line_break_token]These weakness makes it a borderline paper.	O	O	Review	20107
[line_break_token][line_break_token]Question:[line_break_token][line_break_token]How do you handle batchnorm layer, do you use floating points?	B-Review	B-2	Review	20107
[line_break_token][line_break_token]How many bits did you use for accumulating the results?	B-Review	B-3	Review	20107
[line_break_token][line_break_token]Update after rebuttal:[line_break_token][line_break_token]I have read the authors' response.	O	O	Review	20107
I would like to keep my current review as it is.	O	O	Review	20107
Also note that the authors uses floating pt for batchnorm and 32 bit for accumulation, such additional cost might out-weights the benefit of choosing ultra low bits in the low bits regime, making the study less relevant for practice reasons[line_break_token][line_break_token][line_break_token]	B-Review	B-2	Review	20107
e thank the reviewer for their feedback and for finding our paper well-written and motivated.	O	O	Reply	20107
[line_break_token][line_break_token]Regarding your main concern, we agree that it is non-trivial to see if equal model size reflects compute (in terms of latency and/or energy) since it depends on the application scenario and software/hardware implementation.	B-Reply	B-1	Reply	20107
However, our insights and good results from the model size standpoint set a strong motivation for future study to target a specific application scenario and research on hardware acceleration.	I-Reply	I-1	Reply	20107
We argue that this does not constitute a weakness for our paper since there are scenarios where model sizes is important.	I-Reply	I-1	Reply	20107
From the perspective of information theory and Minimum Description Length (MDL) principle [1,2], our results show that by trading weight precision values with the number of channels, one can achieve a smaller description length for the model with equal accuracy, which is more preferable based on the MDL principle.	I-Reply	I-1	Reply	20107
Moreover, considering edge devices that are deployed for streaming inference scenarios (single image per batch), our analyses in the updated manuscript (Appendix F and Figure 6) show lower memory footprint is needed for the proposed model to achieve equally accurate results compared to the baseline.	I-Reply	I-1	Reply	20107
We argue that for streaming inference applications that run on IoT devices, model size is an important factor due to their limited RAM.	I-Reply	I-1	Reply	20107
[line_break_token][line_break_token]Beyond the above argument for the efficacy of DualPrecision, we would like to re-iterate that our contributions are more than the proposed DualPrecision method.	I-Reply	I-1	Reply	20107
Specifically, the following three contributions are non-trivial, novel, and can be built upon for future study:[line_break_token]-[tab_token]We are the first to show that lower precision weight values outperform higher precision weight values in a Pareto sense (accuracy vs. model size) for networks with standard convolutions.	I-Reply	I-1	Reply	20107
This is intriguing since it implies that scaling up (in terms of model size) along the channel count dimension is more effective for accuracy than the precision value dimension.	I-Reply	I-1	Reply	20107
This finding can lead to follow-up works trying to understand or exploit this phenomenon.	I-Reply	I-1	Reply	20107
[line_break_token][line_break_token]-[tab_token]We are the first to show that the fan-in channel counts per output filter for a convolution layer determine the effectiveness of accuracy improvement along the weight precision dimension and provide both theoretical and empirical reasoning for this.	I-Reply	I-1	Reply	20107
This finding is useful for future works that are interested in optimizing the neural architecture regarding both channel counts and weight precision as we show what might affect the effectiveness of weight precision scaling.	I-Reply	I-1	Reply	20107
[line_break_token][line_break_token]-[tab_token]We are the first to show that with a simple scaling rule, one can achieve a more accurate model (given the same model size) even compared to mixed-precision prior art that uses DRL to search for layer-wise weight precision values.	I-Reply	I-1	Reply	20107
Moreover, the results are validated on the large-scale dataset, i.e., ImageNet.	I-Reply	I-1	Reply	20107
This is a manifestation of our two previous findings.	I-Reply	I-1	Reply	20107
[line_break_token][line_break_token]We hope the reviewer can take into account the above-listed contributions and their potential impacts when making the final recommendation.	I-Reply	I-1	Reply	20107
[line_break_token][line_break_token]Regarding the questions, we use floating-point for batch norm.	B-Reply	B-2	Reply	20107
The accumulation of results is done in 32 bits (We simulate the quantization process in PyTorch according to Figure C.4 in [3]).	I-Reply	I-2	Reply	20107
[line_break_token][line_break_token][1] Blier, L√©onard, and Yann Ollivier. "	O	O	Reply	20107
The description length of deep learning models."	O	O	Reply	20107
NeurIPS 2018.	O	O	Reply	20107
[line_break_token][2] Havasi, Marton, Robert Peharz, and Jos√© Miguel Hern√°ndez-Lobato. "	O	O	Reply	20107
Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters."	O	O	Reply	20107
ICLR 2019.	O	O	Reply	20107
[line_break_token][3] Benoit Jacob, Skirmantas  Kligys,  Bo  Chen,  Menglong  Zhu,  Matthew  Tang,  Andrew  Howard,Hartwig Adam, and Dmitry Kalenichenko.	O	O	Reply	20107
Quantization and training of neural networks for effi-cient integer-arithmetic-only inference.	O	O	Reply	20107
InThe IEEE Conference on Computer Vision and PatternRecognition (CVPR), June 2018	O	O	Reply	20107

The paper studies learning in deep neural networks with hard activation functions, e.g. step functions like sign(x).	O	O	Review	414
Of course, backpropagation is difficult to adapt to such networks, so prior work has considered different approaches.	O	O	Review	414
Arguably the most popular is straight-through estimation (Hinton 2012, Bengio et al 2013), in which the activation functions are simply treated as identity functions during backpropagation.	O	O	Review	414
More recently, a new type of straight-through estimation, saturated STE (Hubara et al 2016) uses 1[|z|<1] as the derivative of sign(z).	O	O	Review	414
[line_break_token][line_break_token]The paper generalizes saturated STE by recognizing that other discrete targets of each activation layer can be chosen.	O	O	Review	414
Deciding on these targets is formulated as a combinatorial optimization problem.	O	O	Review	414
Once the targets are chosen, updating the weights of each layer to minimize the loss on those targets is a convex optimization.	O	O	Review	414
The targets are heuristically updated through the layers, starting out the output using the proposed feasibility target propagation.	O	O	Review	414
At each layer, the targets can be chosen using a variety of search algorithms such as beam search.	O	O	Review	414
[line_break_token][line_break_token]Experiments show that FTP often outperforms saturated STE on CIFAR and ImageNet with sign and quantized activation functions, reaching levels of performance closer to the full-precision activation networks.	O	O	Review	414
[line_break_token][line_break_token]This paper's ideas are very interesting, exploring an alternative training method to backpropagation that supports hard-threshold activation functions.	O	O	Review	414
The experimental results are encouraging, though I have a few questions below that prevent me for now from rating the paper higher.	O	O	Review	414
[line_break_token][line_break_token]Comments and questions:[line_break_token][line_break_token]1) How computationally expensive is FTP?	B-Review	B-1	Review	414
The experiments using ResNet indicate it is not prohibitively expensive, but I am eager for more details.	I-Review	I-1	Review	414
[line_break_token][line_break_token]2) Does (Hubara et al 2016) actually compare their proposed saturated STE with the orignal STE on any tasks?	B-Review	B-2	Review	414
I do not see a comparison.	I-Review	I-2	Review	414
If that is so, should this paper also compare with STE?	I-Review	I-2	Review	414
How do we know if generalizing saturated STE is more worthwhile than generalizing STE?	I-Review	I-2	Review	414
[line_break_token][line_break_token]3) It took me a while to understand the authors' subtle comparison with target propagation, where they say "Our framework can be viewed as an instance of target propagation that uses combinatorial optimization to set discrete targets, whereas previous approaches employed continuous optimization."	B-Review	B-3	Review	414
It seems that the difference is greater than explicitly stated, that prior target propagation used continuous optimization to set *continuous targets*. (One could imagine using continuous optimization to set discrete targets such as a convex relaxation of a constraint satisfaction problem.)	I-Review	I-3	Review	414
Focusing on discrete targets gains the benefits of quantized networks.	I-Review	I-3	Review	414
If I am understanding the novelty correctly, it would strengthen the paper to make this difference clear.	I-Review	I-3	Review	414
[line_break_token][line_break_token]4) On a related note, if feasible target propagation generalizes saturated straight through estimation, is there a connection between (continuous) target propagation and the original type of straight through estimation?	B-Review	B-4	Review	414
[line_break_token][line_break_token]5) In Table 1, the significance of the last two columns is unclear.	B-Review	B-5	Review	414
It seems that ReLU and Saturated ReLU are included to show the performance of networks with full-precision activation functions (which is good).	I-Review	I-5	Review	414
I am unclear though on why they are compared against each other (bolding one or the other) and if there is some correspondence between those two columns and the other pairs, i.e., is ReLU some kind of analog of SSTE and Saturated ReLU corresponds to FTP-SH somehow?	I-Review	I-5	Review	414
Thank you for your review.	O	O	Reply	414
We respond to each of your questions below.	O	O	Reply	414
[line_break_token][line_break_token]1) FTP-SH is no more expensive than backprop (in the same way that SSTE isn‚Äôt either, and SSTE is a special case of FTPROP-MB).	B-Reply	B-1	Reply	414
The only added cost is that the soft hinge loss requires computing an exponential, which is slower than a max (i.e., the cost of computing a sigmoid vs. a ReLU), but this is a minor difference in compute time.	I-Reply	I-1	Reply	414
[line_break_token][line_break_token]2) In the experiments, Hubara et al (2016) does not compare SSTE and STE directly, but in the text of the paper they report that ‚ÄúNot [saturating] the gradient when [the input] is too large significantly worsens performance.	B-Reply	B-2	Reply	414
‚Äù This is also what we found in preliminary experiments, where the unsaturated STE is significantly worse than STE.	I-Reply	I-2	Reply	414
Note, however, that STE is also a special case of our framework where the loss function is just loss(z, t) = -zt, so we generalize that as well (and pretty much any type of STE can be obtained by choosing different losses in our framework).	I-Reply	I-2	Reply	414
[line_break_token][line_break_token]3) Yes, this is a good point and correct.	B-Reply	B-3	Reply	414
We will update the paper to make this fact more clear.	I-Reply	I-3	Reply	414
Thank you.	O	O	Reply	414
[line_break_token][line_break_token]4) It‚Äôs possible, although if so it‚Äôs not an obvious connection, and we haven‚Äôt studied this issue in detail yet.	B-Reply	B-4	Reply	414
[line_break_token][line_break_token]5) Yes, good point.	B-Reply	B-5	Reply	414
This is somewhat confusing, and we will clarify it in the paper and remove the bolding, since the goal isn‚Äôt really to compare them against each other (although it is mildly interesting that saturating the ReLU improves performance in some cases).	I-Reply	I-5	Reply	414
There is no correspondence between those two columns and the other pairs; the formatting of the table is just unclear	I-Reply	I-5	Reply	414

The paper proposes a means of improving the predictions of a "simple" (low-capacity) model.	O	O	Review	20125
The idea is to take the predictions of a "complex" (high-capacity) model, and weight the loss in the simple model based on the ratio of complex to simple models' predictions.	O	O	Review	20125
Intuitively, this seeks to focus on instances which the complex model can fit, but the unweighted simple model cannot.	O	O	Review	20125
Experiments show the proposed method to have some benefits over existing approaches.	O	O	Review	20125
[line_break_token][line_break_token]The application of importance-weighting to the "model distillation" problem is interesting, and the paper gives a reasonable intuition for why this approach might work.	B-Review	B-5	Review	20125
One general comment is that in contrasting their approach to a number of existing approaches, they note that several of them are typically employed with fairly complex simple models (e.g., neural networks).	I-Review	I-5	Review	20125
This may be true, but it was not clear that any of them require this to be the case.	I-Review	I-5	Review	20125
Surely they can also be used with simple models as ones you consider in the paper?	I-Review	I-5	Review	20125
In this case, I would've liked more elucidation as to why the proposed method can be expected to offer superior performance.	I-Review	I-5	Review	20125
[line_break_token][line_break_token]The theoretical justification of the approach is provided by means of Lemmas 3.1 and 3.2, for which I have some comments:[line_break_token]- Lemma 3.1: the notation here is a bit imprecise.	B-Review	B-6	Review	20125
In general, a loss for example (x, y) takes in a true label y and predicted score z(x).	I-Review	I-6	Review	20125
You refer to the loss of a probabilistic prediction p(y | x), but do not refer to the actual label y itself.	I-Review	I-6	Review	20125
From the proof, it is implicit that you are considering y to be binary, and the use of a margin loss.	I-Review	I-6	Review	20125
This is ok, but for the hinge loss one doesn't use a probability estimate p(y | x) as input to the loss, but rather, a real-valued score.	I-Review	I-6	Review	20125
[line_break_token][line_break_token]I think the result itself could be proven by noting that if œÜ is non-increasing and q &lt; p, then œÜ(p)/œÜ(q) &lt;= 1 &lt; p/q.	O	O	Review	20125
[line_break_token][line_break_token]- Lemma 3.2: the result is interesting, but it seems that for practical purposes you are only using the first term, since it is the only quantity that depends on Œ∏. Since max(1, .) &	B-Review	B-7	Review	20125
gt;= 1 and -log pŒ∏(y | x) &gt;= 0, it seems one could trivially bound the LHS by the first term since -log pŒ∏(y | x) &lt;= max(1, .) *	O	O	Review	20125
-log pŒ∏(y | x)?	B-Review	B-7	Review	20125
Would this not suffice for the purposes of justifying your method?	I-Review	I-7	Review	20125
It should also be noted here how the subsequent requirement that the weights be capped (so as to prevent outliers) fits into the analysis.	I-Review	I-7	Review	20125
[line_break_token][line_break_token]In describing the method itself, the authors introduce a notion of Œ¥-graded subsets.	B-Review	B-4	Review	20125
I found this to be a bit difficult to parse, and it was not clear why this notion was needed.	I-Review	I-4	Review	20125
It does not seem to feature in the description of Algorithm 1, nor the subsequent discussion.	I-Review	I-4	Review	20125
On the other hand, I felt that the meaning and need for parameters Œ≤ and Œ≥ ought to have been discussed more prominently upfront.	I-Review	I-4	Review	20125
[line_break_token][line_break_token]The experiments show favourable performance of the proposed method over baselines, including the distillation approach of Hinton.	B-Review	B-1	Review	20125
The datasets are mostly small-scale, but this is in keeping with the goal of the paper, viz.	I-Review	I-1	Review	20125
addressing scenarios where simple models may be desired.	I-Review	I-1	Review	20125
Per earlier comments, I did not have a deep sense of what additional information the proposed method exploits so as to improve performance.	I-Review	I-1	Review	20125
I gather that the weighting including the predictions of the simple model is one difference; it might have been nice to give a sense of what fraction of points this amplifies or suppresses, compared to just using the predictions of the complex model.	B-Review	B-2	Review	20125
[line_break_token][line_break_token]There is a nice illustration in Fig 1 (right) as to the class-labels of the training samples assigned various weights.	I-Review	I-2	Review	20125
This shows that points with low weight tend to have low agreement with their neighbours' labels.	I-Review	I-2	Review	20125
One question is how using a nearest neighbour probability estimate itself (i.e., using this as the "complex" model) would fare.	I-Review	I-2	Review	20125
[line_break_token][line_break_token]Minor comments:[line_break_token]- the title is a bit confusing.	B-Review	B-3	Review	20125
It is not clear what "its" refers to.	I-Review	I-3	Review	20125
You are leveraging the predictions of a complex model to enhance those of a simple model?	I-Review	I-3	Review	20125
[line_break_token]- the text has a number of long sentences that could benefit from rewriting or splitting.	I-Review	I-3	Review	20125
[line_break_token]- proof of Lemma 3.2, use \cdot not *.	I-Review	I-3	Review	20125
[line_break_token]- proof of Lemma 3.2, Œ∏* should use superscript.	I-Review	I-3	Review	20125
[line_break_token]- Fig 1, the caption is overlong.	I-Review	I-3	Review	20125
Most of this should be in the text.	I-Review	I-3	Review	20125
[line_break_token]- Fig 1, use crisper fonts for the text.	I-Review	I-3	Review	20125
hank you very much for the comments.	O	O	Reply	20125
 We below address them and have posted a new version of the paper.	O	O	Reply	20125
[line_break_token][line_break_token]Regarding Lemma 3.2: You are correct about the trivial bound, but the bound would not be as tight without the other term.	B-Reply	B-7	Reply	20125
In any case, please refer to our response about Lemma 3.2 to Reviewer 4.	I-Reply	I-7	Reply	20125
We have modified the result to include the requirement that weights be capped, which also provides further intuition into the algorithm and how to select the cap.	I-Reply	I-7	Reply	20125
[line_break_token][line_break_token]Regarding comparison with existing methods: We added a paragraph discussing relationships between our work and the existing ones that Reviewer 4 pointed out in the related work.	B-Reply	B-5	Reply	20125
[line_break_token][line_break_token]Regarding delta-graded classifiers: Again, please refer to our response to Reviewer 4.	B-Reply	B-4	Reply	20125
The notion of delta-graded classifiers is necessary in order to extract information from a a large class of models and generalizes how Dhurandhar et al (2018) attach probes to different layers of a neural network to generate predictions from various layers of a neural network.	I-Reply	I-4	Reply	20125
As in Dhurandhar et al (2018), using such information proved to be useful here, in comparison to simply using the final prediction of a model (which is labelled ConfWeight in our experiments).	I-Reply	I-4	Reply	20125
We further clarify this in the beginning of Section 3 (Methodology).	I-Reply	I-4	Reply	20125
[line_break_token][line_break_token]Regarding what additional information the proposed method exploits: Indeed, using a weighting that includes the predictions of the simple model is the key difference from all other works, and judging from our experiments, is a significant differentiator from other weighting schemes.	B-Reply	B-1	Reply	20125
[line_break_token][line_break_token]Regarding what fractions of points were suppressed: Figure 1 (left) demonstrates that less than 1% of points were suppressed as being too difficult for the simple model (no points are suppressed by only using the complex model predictions).	B-Reply	B-2	Reply	20125
[line_break_token][line_break_token]Regarding Minor Comments: Please note that, regarding the title, we are leveraging the simple model predictions (along with the complex model predictions) to enhance those of a simple model, so "its" refers to the Simple model.	B-Reply	B-3	Reply	20125
We can remove "its" if it is still not clear.	I-Reply	I-3	Reply	20125
We have made a thorough pass and did some rewriting, fixing long sentences, and improving the overall flow.	I-Reply	I-3	Reply	20125
Most of the caption to Figure 1 has been moved to the text	I-Reply	I-3	Reply	20125

This paper presents AutoGen, which combines a generative variational autoencoder (VAE) with a high-fidelity reconstruction model based on autoencoder.	O	O	Review	772
The motivation behind AutoGen is to address a common problem when training VAEs with powerful encoders (e.g., autoregressive models) that the model simply ignores the latent representation and does not associate latent representation with the generated data in a meaningful way.	O	O	Review	772
A common strategy to (partially) solve this problem is by introducing KL annealing, gradually turning up the KL term in the standard ELBO, which unfortunately means the model is no longer optimizing a valid lower bound on the log-likelihood of the data.	O	O	Review	772
AutoGen provides an alternative solution by adding a reconstructing term to the standard ELBO for VAE to enforce the latent representation striking a balance between generation and reconstruction -- the objective still remains a valid lower bound (albeit not on the data log-likelihood) and has close connection to the standard ELBO.	O	O	Review	772
It also provides alternative interpretations for some other similar techniques, e.g., beta-VAE and KL-annealing.	O	O	Review	772
Experimental results and survey studies demonstrate that AutoGen is able to leverage latent representation more effectively when comparing with VAE without annealing, has better reconstruction overall, but at the same time lose some ability to generate good samples from prior -- this is not too surprising considering the model objective balances between generation and reconstruction.	O	O	Review	772
  [line_break_token][line_break_token]Overall the paper is clearly written with some minor issues listed below.	O	O	Review	772
The paper presents a simple but reasonable adjustment to the standard VAE training and yields an objective that is intuitive and connects nicely to some other similar techniques that scale the KL term.	O	O	Review	772
I have a few concerns about the paper, however, that I hope the authors could better address:[line_break_token][line_break_token]1.	O	O	Review	772
My major concern is that VAE after all is a generative model and its ability to sample from prior is an important property.	B-Review	B-1	Review	772
VAE with annealing, admittedly unprincipled, addresses this issue better than AutoGen, especially on shorter generated sentences.	I-Review	I-1	Review	772
There might be cases where reconstruction is important, but the paper did not demonstrate that (this relates to the point 3 below).	I-Review	I-1	Review	772
In the current state, even though the paper presents a simple and intuitive adjustment to the VAE training objective, it hasn't convinced me that if I want a generative model of language I would try to use AutoGen rather than VAE with annealing.	I-Review	I-1	Review	772
[line_break_token][line_break_token]2.	O	O	Review	772
As mentioned in the paper, VAE with annealing is an unprincipled approach.	B-Review	B-2	Review	772
It would be interesting to see if AutoGen compares favorably over some other principled approaches along the line of better utilizing the latent representation, e.g., Krishnan et al On the challenges of learning with inference networks on sparse, high-dimensional data, 2018.	I-Review	I-2	Review	772
[line_break_token][line_break_token]3.	B-Review	B-7	Review	772
I can understand that because of the objective of AutoGen, it does not make much sense comparing held-out likelihood or ELBO between VAE and AutoGen.	B-Review	B-3	Review	772
However, currently the paper is lacking in terms of quantitative evaluation.	I-Review	I-3	Review	772
An interesting experiment would be to use the latent representation z from both AutoGen and VAE (with/without annealing) for some downstream tasks and see if better reconstruction in this case helps.	I-Review	I-3	Review	772
This would also demonstrate the importance of incorporating a reconstruction term in the objective.	I-Review	I-3	Review	772
[line_break_token][line_break_token]Minor: [line_break_token][line_break_token]1.	O	O	Review	772
Above equation (5): What exactly do you mean by ‚Äúsymmetric‚Äù?	B-Review	B-4	Review	772
[line_break_token][line_break_token]2.	O	O	Review	772
Above equation (9): instead of just 2 -> instead of just 1?	O	O	Review	772
since m represents the number of reconstructions[line_break_token][line_break_token]3.	O	O	Review	772
Also above equation (9): it is worth more elaboration on how to generalize to m reconstructions: it is not L_AutoGen = L_VAE + m * L_SAE (which is what the text seems to suggest), rather it's L_SAE = \int_z p(x|z)^m p(z|x) dz.	B-Review	B-6	Review	772
[line_break_token][line_break_token]4.	O	O	Review	772
Section 3.2, since the model "finds different reconstructions every time from the same input sentence", how robust is the reconstruction to the sampling variations?	B-Review	B-7	Review	772
We appreciate the reviewers detailed comments.	O	O	Reply	772
[line_break_token][line_break_token]Major:[line_break_token][line_break_token]1.	O	O	Reply	772
We agree that there are certainly use cases where generation from the prior is more important than reconstruction.	B-Reply	B-1	Reply	772
In these cases we would recommend using a VAE.	I-Reply	I-1	Reply	772
However there are many use cases where the latent variable is of critical importance (see for example citations in our response to Reviewer 3 above).	I-Reply	I-1	Reply	772
In fact, we would argue that there are relatively few downstream tasks in which you would only want to generate say, text or images from Gaussian noise, with no regard for the latent variable.	I-Reply	I-1	Reply	772
[line_break_token][line_break_token]2.	B-Reply	B-6	Reply	772
The paper by Krishnan et al is certainly interesting, and quite a different approach to the AutoGen model.	B-Reply	B-2	Reply	772
However, they are not using their model to generate sentences, and are taking a bag-of-words approach.	I-Reply	I-2	Reply	772
For this reason, we felt it made more sense to compare our experimental results to that of Bowman et al[line_break_token][line_break_token]3.	O	O	Reply	772
We agree that it would certainly be interesting to see the performance of AutoGen on downstream tasks.	B-Reply	B-3	Reply	772
[line_break_token][line_break_token]Minor:[line_break_token][line_break_token]1.	O	O	Reply	772
We assume that in a stochastic autoencoder, the encoding distribution and decoding distribution should be closely related.	B-Reply	B-4	Reply	772
In fact we assume that this relationship can be captured via Bayes‚Äô Rule, as shown in Equation (5).	I-Reply	I-4	Reply	772
[line_break_token][line_break_token]2.	B-Reply	B-6	Reply	772
Yes, you are correct, this is an error and has been amended in the revised submission.	B-Reply	B-5	Reply	772
There is only 1 reconstruction.	I-Reply	I-5	Reply	772
[line_break_token][line_break_token]3.	O	O	Reply	772
In the case of multiple reconstructions, we agree with your statement that there would be a term of the form  \int_z p(x|z)^m p(z|x) dz.	B-Reply	B-6	Reply	772
However, after applying the assumptions in Equation (5) as before, we get \int_z p(x|z)^(m+1) p(z)/p(x) dz.	I-Reply	I-6	Reply	772
The result then follows as in Section 2.	I-Reply	I-6	Reply	772
I cannot see where we suggest that L_AutoGen = L_VAE + m * L_SAE, however if you can indicate where this is, we will gladly amend it.	I-Reply	I-6	Reply	772
[line_break_token][line_break_token]4.	O	O	Reply	772
We have not done this experiment directly, but agree that this would be interesting to see.	B-Reply	B-7	Reply	772
Note that in Table 5, we demonstrate how interpolating across the latent space can affect the output sentences, and found the interpolations to be smoother.	I-Reply	I-7	Reply	772
From this, we would assume that the Autogen model is more robust to sampling variations than the VAE.	I-Reply	I-7	Reply	772

This is a strong deep learning theory paper, and I recommend to accept.	O	O	Review	20255
[line_break_token][line_break_token]This paper studies the trajectory induced by applying gradient descent/gradient flow for optimizing a homogeneous model with exponential tail loss functions, including logistic and cross-entropy loss in particular.	O	O	Review	20255
This is an important direction in recent theoretical studies on deep learning as we need to understand which global minimizer the training algorithm picks to analyze the generalization behavior.	O	O	Review	20255
[line_break_token][line_break_token]This paper makes a significant contribution to this direction.	O	O	Review	20255
This paper rigorously proves gradient descent / gradient flow can maximize the L2 margin of homogeneous models.	O	O	Review	20255
Existing works mostly focus on linear models or deep linear networks, and comparing with Nascon et al 2019a, the assumptions in this paper are significantly weaker.	O	O	Review	20255
Furthermore, this paper provides convergence rates, which seem to be the first work of this kind for non-linear models.	O	O	Review	20255
[line_break_token][line_break_token]I really like Lemma 5.1.	O	O	Review	20255
This is not only a technical lemma for proving the main theorem.	O	O	Review	20255
Lemma 5.1 itself has a nice geometric interpretation.	O	O	Review	20255
It naturally decomposes the dynamics of the smoothed version into a radial component and a tangential velocity component.	O	O	Review	20255
I believe this lemma can be useful in other settings as well.	O	O	Review	20255
[line_break_token][line_break_token][line_break_token]Comments:[line_break_token]The bibliography should be fixed.	B-Review	B-1	Review	20255
Some papers are already published, so they should not be cited as the arXiv version, and author lists in some papers have "et al"[line_break_token][line_break_token]-----------------------------------------------------[line_break_token]I have read the rebuttal and I maintain my score.	O	O	Review	20255
hanks for your appreciation!	O	O	Reply	20255
We will fix the errors in the bibliography	B-Reply	B-1	Reply	20255

This paper proposes a framework for semantic parsing, which includes a neural generator that synthesizes the logical forms from natural language utterances, and a neural reranker that re-ranks the top predictions generated by beam search decoding using the neural generator.	O	O	Review	20510
While the neural generator is the same as prior work, the main novelty is the reranker design, which is a binary classifier that takes a pair of natural language utterance/logical form, and predicts the similarity between them.	O	O	Review	20510
This reranker could also be pre-trained using auxiliary data sources, e.g., Quora question pairs benchmark for paraphrasing.	O	O	Review	20510
They evaluate their approach on 3 semantic parsing datasets (GEO, ATIS, and OVERNIGHT), and show that their reranker can further improve the performance of the base generator.	O	O	Review	20510
[line_break_token][line_break_token]I think the general motivation of the framework is sound.	O	O	Review	20510
Although the idea of reranking is not new in the semantic parsing community, with the most recent work [1] already shows the promise of this direction, the concrete approach described in this paper is different, seems simple yet effective.	O	O	Review	20510
The most interesting part is to transform the generated logical form into a pseudo-natural language text, so that it becomes a paraphrase of the input natural language utterance in some sense, which enables the re-ranker to be pre-trained with auxiliary data sources, and to use the wordpiece tokenizer that is effective in understanding natural language.	O	O	Review	20510
In their evaluation, they indeed show that this transformation helps improve the performance of the reranker.	O	O	Review	20510
[line_break_token][line_break_token]My main concern of  this paper is about evaluation.	B-Review	B-1	Review	20510
First, although they already evaluate on 3 datasets, all of them are not among the most challenging benchmarks in semantic parsing.	I-Review	I-1	Review	20510
In [1], they also evaluate on Django and Conala, which are 2 benchmarks to translate natural language to Python, and also are more complicated than the benchmarks in this paper.	I-Review	I-1	Review	20510
It would be helpful for the authors to show results on such datasets that the results of baseline neural generators are less satisfactory, which may also make more room for the possible improvement using a re-ranker.	I-Review	I-1	Review	20510
[line_break_token][line_break_token]On the other hand, they also lack a comparison with existing re-ranking approaches.	B-Review	B-2	Review	20510
For example, it will be helpful to compare with [1], given that they also evaluate on GEO and ATIS.	I-Review	I-2	Review	20510
Right now the results are not directly comparable because: (1) the base generators are different; and (2) the beam size used in this paper (10) is larger than the beam size (5) in [1]. It will be helpful if the authors can at least provide results with a smaller beam size, and would be better if they can provide results that are directly comparable to [1].[line_break_token][line_break_token][1] Yin and Neubig, Reranking for Neural Semantic Parsing, ACL 2019.	O	O	Review	20510
[line_break_token][line_break_token]------------[line_break_token]Post-rebuttal comments[line_break_token][line_break_token]I thank the authors for the response.	O	O	Review	20510
However, I don't think my concerns are addressed; e.g., without a comparison with previous re-ranking methods, it is hard to justify their proposed approach, given that other re-ranking methods are also able to improve over an existing well-performed generator.	B-Review	B-2	Review	20510
Therefore, I keep my original assessment.	O	O	Review	20510
[line_break_token]------------	O	O	Review	20510
omment: My main concern of this paper is about evaluation.	O	O	Reply	20510
First, although they already evaluate on 3 datasets, all of them are not among the most challenging benchmarks in semantic parsing.	O	O	Reply	20510
In [1], they also evaluate on Django and Conala, which are 2 benchmarks to translate natural language to Python, and also are more complicated than the benchmarks in this paper.	O	O	Reply	20510
It would be helpful for the authors to show results on such datasets that the results of baseline neural generators are less satisfactory, which may also make more room for the possible improvement using a re-ranker.	O	O	Reply	20510
[line_break_token][line_break_token]Response: We agree with the reviewer that applying our architecture on more benchmark datasets would make this work stronger and we also stated this as a future work.	B-Reply	B-1	Reply	20510
However, we believe that significantly improving the best performing model over three widely used semantic parsing datasets and achieving the state-of-the-art results, along with showing through error analysis how our architecture is systematically helpful is already a very strong and convincing argument of the fact that the introduced reranker model is very effective.	I-Reply	I-1	Reply	20510
[line_break_token][line_break_token]We note that the choice for the datasets we used were not arbitrary.	I-Reply	I-1	Reply	20510
We wanted to test with the best performing generator model because if we were to use a weaker model, then the improvement would be questionable and one could easily argue whether the introduced approach can improve the best model in the literature.	I-Reply	I-1	Reply	20510
Therefore, it was important for us to show that our approach can improve upon already the best performing model in the literature.	I-Reply	I-1	Reply	20510
We chose the overnight dataset because this is a dataset that has 8 various domains with large number of examples and allows for all the three processing methods we proposed to be experimented.	I-Reply	I-1	Reply	20510
We chose the GEO and ATIS datasets because the generator we use was not applied to the overnight dataset, but it was applied to these two datasets.	I-Reply	I-1	Reply	20510
So we wanted to show that we can also improve the performance on these datasets as well.	I-Reply	I-1	Reply	20510
Of course, evaluating on more benchmark datasets (like challenging ones such as Django and Conala) would make our results stronger, however, we believe our set of results are already significant and can show the effectiveness of the reranker model we introduced.	I-Reply	I-1	Reply	20510
[line_break_token][line_break_token]Comment: On the other hand, they also lack a comparison with existing re-ranking approaches.	O	O	Reply	20510
For example, it will be helpful to compare with [1], given that they also evaluate on GEO and ATIS.	O	O	Reply	20510
Right now the results are not directly comparable because: (1) the base generators are different; and (2) the beam size used in this paper (10) is larger than the beam size (5) in [1]. It will be helpful if the authors can at least provide results with a smaller beam size, and would be better if they can provide results that are directly comparable to [1].[line_break_token][line_break_token]Response: We agree with the reviewer that the results are not directly comparable and we would like to emphasize that our approach improves upon the best performing model in the literature, which is a more challenging improvement.	B-Reply	B-2	Reply	20510
We agree with the reviewer that a direct comparison would be better and we will do this comparison in future work	I-Reply	I-2	Reply	20510

The paper describes a mid-level representation for videos that can be faster than existing representations and yields similar performance.	O	O	Review	59
The idea is to train many SVMs to detect predefined action instances on sub-blocks from the video, and then to aggregate the SVM responses into a representation for the whole video.	O	O	Review	59
[line_break_token][line_break_token]This work seems like a fairly straightforward extension of previous similar work that was done on images (Malisiewicz et al), but there are some technical differences like the use of an integral video trick to compute SVM responses fast, which seems nice.	B-Review	B-5	Review	59
[line_break_token][line_break_token]I don't really understand the mining of negative examples for training the exemplar SVMs.	B-Review	B-1	Review	59
Why is it not possible to train the SVM, say with stochastic gradient descent, on all or many negative examples?	I-Review	I-1	Review	59
[line_break_token][line_break_token]The method relies on extra, intermediate labels for training which are not used by bag-of-words.	O	O	Review	59
This makes it hard to judge the performance differences between the two and seems to be unfair towards bag-of-words.	O	O	Review	59
[line_break_token][line_break_token]3.3: Rather than learning to scale svm confidences within a sigmoid, why not train a regularized logistic regression classifier in the first place, instead of the svm?	B-Review	B-2	Review	59
[line_break_token][line_break_token]The feature extraction time is reported as the total on the whole UT-I dataset.	B-Review	B-3	Review	59
It would be much better to report it in frames per second to make it comparable with other datasets without having to dig up the description of this dataset.	I-Review	I-3	Review	59
If I am not mistaken it amounts to approximately 5 frames (with more or less standard resolution) per second?	I-Review	I-3	Review	59
If correct, this means that despite the improvement over action bank, the bottleneck is really feature exctraction not classification.	I-Review	I-3	Review	59
So the speed up due to the linear classifier will be swamped by the feature extraction and is not really that relevant, unless I'm missing something.	O	O	Review	59
[line_break_token][line_break_token]pro:[line_break_token]- Well-written, uses some nice engineering tricks like the integral video for computing SVM responses.	O	O	Review	59
[line_break_token][line_break_token][line_break_token]neg:[line_break_token]- The paper seems like a slightly strange fit for this conference as it describes a vision system rather than investigating the learning of representations.	B-Review	B-4	Review	59
That intermediate labels are useful on this data is well-known (and unsurprising).	I-Review	I-4	Review	59
The paper does propose a faster way to use them, which is probably worthwhile.	I-Review	I-4	Review	59
We thank the reviewer for the thoughtful suggestions.	O	O	Reply	59
We would like to comments on a few points of the review.	O	O	Reply	59
[line_break_token][line_break_token]- We believe that it is quite apparent that our approach is not a straightforward extension of [Malisiewicz et al2011]. This prior work has not been applied to videos, just to object detection in still images.	B-Reply	B-5	Reply	59
A naive application of [Malisiewicz et al2011] to videos is simply not feasible because of the prohibitive cost.	I-Reply	I-5	Reply	59
In our paper we describe how to adapt it to work efficiently on videos so that it can scale to large datasets.	I-Reply	I-5	Reply	59
This is not a trivial contribution, as partly acknowledged by the reviewer.	I-Reply	I-5	Reply	59
[line_break_token][line_break_token]- The mining of hard negatives is a standard strategy in the learning of exemplar SVMs.	B-Reply	B-1	Reply	59
Having said this, the reviewer makes an excellent suggestion in proposing the use of stochastic gradient descent on the entire negative set.	I-Reply	I-1	Reply	59
This is definitely an interesting experiment for future work.	I-Reply	I-1	Reply	59
However, our expectation is that results would be quite similar as those obtained with iterative hard negative mining since only examples violating the margin (i.e., the hard negatives) would contribute to refining the parameters in stochastic gradient descent.	O	O	Reply	59
[line_break_token][line_break_token]- We agree with the reviewer that regularized logistic regression may be a sensible alternative to the two-step learning of the SVMs and the sigmoids.	B-Reply	B-2	Reply	59
Again, we opted for the simple two-step solution as it has been proven to work effectively in several prior systems (e.g., [Malisiewicz et al 2011; Deng et al CVPR 2011, Bergamo and Torresani, CVPR 2012]).	I-Reply	I-2	Reply	59
[line_break_token][line_break_token]- As suggested by the reviewer, we will make sure to report the feature extraction time also in frames per second in order to make this number more easily interpretable.	B-Reply	B-3	Reply	59
We recognize that, despite the significant speedup enabled by our approach, feature extraction remains more costly than recognition.	I-Reply	I-3	Reply	59
However, we note that there are many practical scenarios where a feature extraction time of 5 frames per second (as opposed to the 4 frames per *minute* of Action Bank) would enable application of action recognition in large-scale datasets.	I-Reply	I-3	Reply	59
For example, consider the motivating application of interactive content-based video search where the user may query a system by providing an example sequence in order to find videos containing the same action in the database.	I-Reply	I-3	Reply	59
In such scenario the search index (containing the features) can be built offline while the training of the action classifier and the recognition itself must be done at query time.	I-Reply	I-3	Reply	59
Our system can be directly used in such scenarios, in principle even for YouTube-size datasets, while prior mid-level descriptors are simply too costly to be computed for large databases.	I-Reply	I-3	Reply	59
[line_break_token][line_break_token]- We disagree with the final conclusion of the reviewer that this paper 'describes a vision system rather than investigating the learning of representations.'	B-Reply	B-4	Reply	59
Our entire work centers around the learning of a novel intermediate representation for action recognition.	I-Reply	I-4	Reply	59
While it is true that it shares similarities with prior high-level descriptors (which we discuss in the paper), it should also be acknowledged that our new representation model introduces significant advantages in terms of computational cost and recognition accuracy over the most closely related prior system	I-Reply	I-4	Reply	59

This work builds on a sum(top k) identity to derive a pathwise differentiable sampler of 'unimodal row stochastic' matrices.	O	O	Review	254
The Plackett-Luce family has a tractable density (an improvement over previous works) and is (as developed here) efficient to sample.	O	O	Review	254
[line_break_token][line_break_token][OpenReview did not save my draft, so I now attempt to recover it from memory.]	O	O	Review	254
[line_break_token][line_break_token]Questions:[line_break_token]- How much of the improvement is attributable to the lower dimension of the parameterization? (	B-Review	B-1	Review	254
e.g. all Sinkhorn varients have N^2 params; this has N params) Is there any reduction in gradient variance due to using fewer gumbel samples?	I-Review	I-1	Review	254
[line_break_token]- More details needed on the kNN loss (uniform vs inv distance wt?	B-Review	B-2	Review	254
which one?);	I-Review	I-2	Review	254
and the experiment overall: what k got used in the end?	I-Review	I-2	Review	254
[line_break_token]- The temperature setting is basically a bias-variance tradeoff (see Fig 5).	B-Review	B-3	Review	254
How non-discrete are the permutation-like matrices ultimately used in the experiments?	I-Review	I-3	Review	254
While the gradients are unbiased for the relaxed sort operator, they are still biased if our final model is a true sort.	I-Review	I-3	Review	254
Would be nice to quantify this difference, or at least mention it.	I-Review	I-3	Review	254
[line_break_token][line_break_token]Quality:[line_break_token]Good quality; approach is well-founded and more efficient than extant solutions.	O	O	Review	254
Fairly detailed summaries of experiments in appendices (except kNN).	O	O	Review	254
Neat way to reduce the parameter count from N^2 to N.[line_break_token][line_break_token]I have not thoroughly evaluated the proofs in appendix.	O	O	Review	254
[line_break_token][line_break_token]Clarity:[line_break_token]The approach is presented well, existing techniques are compared in both prose and as baselines.	O	O	Review	254
Appendix provides code for maximal clarity.	O	O	Review	254
[line_break_token][line_break_token]Originality:[line_break_token]First approach I've seen that reduces parameter count for permutation matrices like this.	O	O	Review	254
And with tractable density.	O	O	Review	254
Very neat and original approach.	O	O	Review	254
[line_break_token][line_break_token]Significance:[line_break_token]More scalable than existing approaches (e.g: only need N gumbel samples instead of N^2), yields better results.	O	O	Review	254
[line_break_token][line_break_token]I look forward to seeing this integrated into future work, as envisioned (e.g. beam search)	O	O	Review	254
Thanks for reviewing our paper and the helpful feedback!	O	O	Reply	254
We have addressed your questions below.	O	O	Reply	254
[line_break_token] [line_break_token]Q1.	O	O	Reply	254
How much of the improvement is attributable to the lower dimension of the parameterization? (	O	O	Reply	254
e.g. all Sinkhorn varients have N^2 params; this has N params) Is there any reduction in gradient variance due to using fewer gumbel samples?	O	O	Reply	254
[line_break_token]A1.	O	O	Reply	254
Precise quantification of the gains due to lower dimension of the parameterization alone is hard since the relaxation itself is fundamentally different from the Sinkhorn variants.	B-Reply	B-1	Reply	254
In an attempt to get a handle on these aspects (n^2 vs. n parameters and doubly stochastic vs. unimodal matrices), we analyzed the signal-to-noise (SNR) ratio for the Stochastic Sortnet and Gumbel-Sinkhorn approaches with the same number of Gumbel samples (=5).	I-Reply	I-1	Reply	254
Here, we define SNR as the ratio of the absolute value of the expected gradient estimates and the standard deviation.	I-Reply	I-1	Reply	254
For the experiments in Section 6.1, the SNR ratio averaged across all the parameters is shown in Figure 8.	I-Reply	I-1	Reply	254
We observe a much higher SNR for the proposed approach, in line with the overall gains we see on the underlying task.	I-Reply	I-1	Reply	254
[line_break_token][line_break_token]Q2.	O	O	Reply	254
More details needed on the kNN loss (uniform vs inv distance wt?	O	O	Reply	254
which one?);	O	O	Reply	254
and the experiment overall: what k got used in the end?	O	O	Reply	254
[line_break_token]A2.	O	O	Reply	254
We used a uniformly weighted kNN loss for both the Sortnet approaches, while noting that it is straightforward to extend our framework to use an inverse distance weighting.	B-Reply	B-2	Reply	254
Appendix E.3 includes the formal expressions for the loss functions optimized in our framework.	I-Reply	I-2	Reply	254
Furthermore, we have included new results in Table 5 which show the raw performance of Deterministic and Stochastic Sortnet for all values of k considered.	I-Reply	I-2	Reply	254
[line_break_token][line_break_token]Q3.	O	O	Reply	254
The temperature setting is basically a bias-variance tradeoff (see Fig 5).	O	O	Reply	254
How non-discrete are the permutation-like matrices ultimately used in the experiments?	O	O	Reply	254
[line_break_token]A3.	O	O	Reply	254
That‚Äôs a great suggestion!	B-Reply	B-3	Reply	254
One way to quantify the non-discreteness could be based on the element-wise mean squared difference between the inferred unimodal row stochastic matrix and its projection to a permutation matrix, for  the test set of instances.	I-Reply	I-3	Reply	254
We have included these results for the sorting experiment in Table 4.	I-Reply	I-3	Reply	254
[line_break_token][line_break_token]Please let us know if there are any further questions	O	O	Reply	254

The paper proposes to use low-rank matrix decomposition for embedding compression, with relu in the reconstruction layer to gain non-linearity.	O	O	Review	381
Experiments on machine translation task shows improvement compared with state-of-the-art methods with different compression rates.	O	O	Review	381
[line_break_token][line_break_token]Detailed comments:[line_break_token]1)[tab_token]The technical contribution seems to be a bit limited.	B-Review	B-1	Review	381
Using relu in the reconstruction function looks straightforward and adding reconstruction loss in objective function is also common practice.	I-Review	I-1	Review	381
Also, not much insight is provided on why such approach works better than other baselines.	I-Review	I-1	Review	381
[line_break_token][line_break_token]2)[tab_token]Experiments:[line_break_token]a.[tab_token]It is good to see such simple approach outperforms several more sophisticated baseline methods.	B-Review	B-2	Review	381
Also, ablation study is also performed to show the effect of different components.	I-Review	I-2	Review	381
[line_break_token][line_break_token]b.[tab_token]How does the time complexity and running time of the proposed method compared to the baselines?	I-Review	I-2	Review	381
[line_break_token][line_break_token]c.[tab_token]The paper only evaluates distilled embedding on one task (i.e., machine translation).	I-Review	I-2	Review	381
The experiments would be more convincing if evaluated on more tasks as well.	I-Review	I-2	Review	381
[line_break_token][line_break_token]d.[tab_token]It could be helpful to include some sensitivity analysis on the hyperparameters such as \alpha which controls the weight of reconstruction loss.	I-Review	I-2	Review	381
[line_break_token][line_break_token]In conclusion, this paper seems to be below the bar and I would recommend a ‚Äòweak reject‚Äô for the paper.	O	O	Review	381
[line_break_token]	O	O	Review	381
) We specifically chose RELU so that the model can learn to regularize certain embedding dimensions, which is useful when dealing with a high dimensional embedding space, further, since this will lead to a reduction in reconstruction performance, we introduce the reconstruction loss and hyper-parameter ‚Äòalpha‚Äô, to balance out regularization and reconstruction.	B-Reply	B-1	Reply	381
These were mentioned in the paper but you are right that they were not highlighted well.	I-Reply	I-1	Reply	381
[line_break_token]2) The reason we did not run experimental results for measuring the inference time is that the only accurate method to do it is either on edge device or in a simulated environment.	B-Reply	B-2	Reply	381
Secondly, more than inference speed, running memory reduction is also important that is where the SVD based techniques (including ours) are superior, as there is no need to reconstruct the entire embedding matrix.	I-Reply	I-2	Reply	381
We ran the experiment on inference speed and the results are shown below,[line_break_token]Experimental Setup: We used 1 P100 GPU (12GB), and measured the time for the forward graph on the validation dataset (size 7590), with a batch size of 1024.	I-Reply	I-2	Reply	381
We averaged this time for 30 runs and summarize are results below.	I-Reply	I-2	Reply	381
[line_break_token][line_break_token]|              Model                        | Inference Time (Sec) |[line_break_token]| Distilled Embedding (ours) |           29.23                  |[line_break_token]| SVD                                         |           29.63                   |[line_break_token]| Structured Embedding        |           31.18                  |[line_break_token]| Base Model                           |           27.92                   |[line_break_token]We did not perform experiments on Group Reduce and Tensor Train, but they are likely to perform comparably to SVD and Our Method, or even slower.	I-Reply	I-2	Reply	381

In the paper, the authors proposed to solve the learning problem of adversarial examples from Riemannian geometry viewpoint.	O	O	Review	916
More specifically, the Euclidean metric in Eq.(7) is generated to the Riemannian metric (Eq.(8)).	O	O	Review	916
Later, the authors built the correspondence between the metric tensor and the higher order of Taylor expansions.	O	O	Review	916
 Experiments show the improvement over the state-of-the art methods.	O	O	Review	916
[line_break_token][line_break_token]Some questions:[line_break_token]First of all, the idea of introducing Riemannian geometry is appealing.	B-Review	B-1	Review	916
[line_break_token]In the end, a neural network can be roughly viewed as a chart of certain Riemannian manifold.	I-Review	I-1	Review	916
[line_break_token]The challenging part is how can you say something about the properties of the high dimensional manifold, such as curvature, genus, completeness etc.	I-Review	I-1	Review	916
[line_break_token]Unfortunately, I didn't find very insightful analysis about the underlying structure.	I-Review	I-1	Review	916
[line_break_token]Which means, hypothetically, without introducing Riemannian geometry we can still derive Eq.(14) from Eq.(12), Taylor expansion will do the work.	I-Review	I-1	Review	916
[line_break_token]So more insights about metric tensor G determined manifold structure can be very helpful.	I-Review	I-1	Review	916
[line_break_token] [line_break_token]Second, Lagrange multipliers method is a necessary condition, which means the search directions guided by the constraint may not lead to the optimal solutions.	B-Review	B-2	Review	916
[line_break_token]It would be better if the authors can provide either theoretical or experimental study showing certain level of direction search guarantee.	I-Review	I-2	Review	916
[line_break_token] [line_break_token]Last, the experiment results are good, though it lacks of detailed discussion, for example could you decompose the effect achieved by proposed new Riemannian constraint and neural network architecture?	B-Review	B-3	Review	916
Merely demonstrating the performances does not tell the readers too much.	I-Review	I-3	Review	916
[line_break_token]	O	O	Review	916
To Q1: [line_break_token][line_break_token]Thanks for your comments.	B-Reply	B-1	Reply	916
Our paper offers a new insight to study adversarial examples (from the perspective of Riemannian geometry).	I-Reply	I-1	Reply	916
Our work is the first one that investigates the effect of the norm on adversarial examples.	I-Reply	I-1	Reply	916
We also construct an intrinsic Riemannian space based on the loss function, with a property that the descent direction can be maintained at each training step.	I-Reply	I-1	Reply	916
Our paper offers a new starting point which can inspire new insight to study adversarial examples.	I-Reply	I-1	Reply	916
On the other hand, we agree that it is better to define the physical meaning of manifold properties like the curvature, which could be one of our future work.	I-Reply	I-1	Reply	916
In the future, it is also meaningful to study how to define other metric tensors (like fisher information matrix).	I-Reply	I-1	Reply	916
[line_break_token][line_break_token][line_break_token]To Q2: [line_break_token]We agree that the Lagrange multiplier is just the necessary condition.	B-Reply	B-2	Reply	916
Similar to almost all the optimization associated with neural networks, the global optimum of the loss function could not be guaranteed with the proposed algorithm in the paper.	I-Reply	I-2	Reply	916
 Nonetheless, we manage to find the steepest direction on the defined manifold.	I-Reply	I-2	Reply	916
We prove that each training step would point to the descent direction, which could guarantee a local optimum.	I-Reply	I-2	Reply	916
This proposed algorithm was verified to be effective with very promising empirical results.	I-Reply	I-2	Reply	916
To better visualize the convergence property, we also added the plots of convergence curves in the revision.	I-Reply	I-2	Reply	916
[line_break_token][line_break_token]To Q3: [line_break_token]We actually have already provided the performance of baseline model (CNN model), baseline + l_2 adversarial training, and our proposed method (i.e., baseline + l_2 Riemannian constraint adversarial training).	B-Reply	B-3	Reply	916
Compare with these three methods, we can conclude that our proposed Riemannian constraint can improve the performance of CNN model and appears more appropriate than the adversarial constraint defined in the Euclidean space.	I-Reply	I-3	Reply	916

This paper provides a theoretical justification for the benefit of multi-task deep RL (MTRL) with shared representations.	O	O	Review	20144
By extending prior work (Farahmand (2011) and Maurer et al (2016)), the authors demonstrate that the bound of MTRL can be improved if the cost of learning the shared representation at each AVI iteration can be reduced, which is mitigated as we increase the number of tasks.	O	O	Review	20144
The author also empirically verify their theoretical results in a tabular Q-Fitted Iteration domain and also in challenging RL domains such as Mujoco.	O	O	Review	20144
The results show that MTRL with shared representation can outperform their single task counterparts to some degree.	O	O	Review	20144
[line_break_token][line_break_token]Overall this paper adapts the theory shown in Farahmand (2011) and Maurer et al (2016) to the setting of MTRL and demonstrates the effectiveness of using shared layers, which seems intuitive.	B-Review	B-1	Review	20144
While the theory seems a bit incremental, it‚Äôs the first paper that theoretically validates the benefits of sharing knowledge, which is a contribution to the MTRL field.	I-Review	I-1	Review	20144
I would recommend a weak accept, though I have a few concerns on experimental results, and hope that the authors can clarify them during rebuttal.	O	O	Review	20144
[line_break_token][line_break_token]Specifically, as the authors have noted, there is a wide range of prior works [1,2,3] that have empirically demonstrated the effectiveness of utilizing shared representations in MTRL.	B-Review	B-2	Review	20144
While the authors claim that the goal of the experiments is to show that MTRL with shared layers can outperform its sing task counterparts and thus they ignore other MTRL approaches.	I-Review	I-2	Review	20144
I believe that is not the main argument of the paper.	I-Review	I-2	Review	20144
The authors should provide empirical evidence on the claim that with an increasing number of tasks in MTRL, the error bound should improve and the performance of MTRL should also boost.	I-Review	I-2	Review	20144
Besides, I find the comparison where single-task training is initialized with shared representation a bit confusing.	I-Review	I-2	Review	20144
Training would definitely be improved when it‚Äôs initialized with some related pretrained features.	I-Review	I-2	Review	20144
Maybe the authors should compare this to some other methods such as initializing with single-task representation or even representation learned from training different tasks.	I-Review	I-2	Review	20144
[line_break_token][line_break_token][1] M. Hessel, H. Soyer, L. Espeholt, W. Czarnecki,S. Schmitt, and H. van Hasselt.	O	O	Review	20144
Multi-task deep reinforcement learning with popart.arXiv preprintarXiv:1809.04474, 2018.	O	O	Review	20144
[line_break_token][2] Teh, Y.W., Bapst, V., Czarnecki, W.M., Quan, J., Kirkpatrick, J., Hadsell, R.,Heess, N., Pascanu, R.: Distral: Robust multitask reinforcement learning.	O	O	Review	20144
In: Ad-vances in Neural Information Processing Systems 30: Annual Conference on Neu-ral Information Processing Systems 2017 (2017)[line_break_token][3] Wulfmeier, M., Abdolmaleki, A., Hafner, R., Springenberg, J. T., Neunert, M., Hertweck, T., ... &amp; Riedmiller, M. (2019).	O	O	Review	20144
Regularized Hierarchical Policies for Compositional Transfer in Robotics.	O	O	Review	20144
arXiv preprint arXiv:1906.11228.	O	O	Review	20144
e thank the reviewer for reading the paper and the positive comments about it.	O	O	Reply	20144
In the following, we aim to clarify the reported doubts.	O	O	Reply	20144
[line_break_token][line_break_token]We confirm the opinion of the reviewer that this paper aims at providing theoretical guarantees on the intuitive benefit of sharing representation of multiple tasks in Deep RL.	B-Reply	B-1	Reply	20144
Theorem 3 derives the upper bound of the approximation error averaged over multiple tasks, and Theorem 2 derives the first multi-task AVI bound in literature.	I-Reply	I-1	Reply	20144
Since the bound in Theorem 2 contains the task-averaged approximation error, which is bounded by the upper bound in Theorem 3 that decreases for an increasing number of tasks, the bound in Theorem 2 shows the benefit of multi-task RL w.r.t.	I-Reply	I-1	Reply	20144
learning a single task.	I-Reply	I-1	Reply	20144
More in detail, Theorem 2 proves that learning multiple tasks together helps to converge to the optimal-function faster than the single-task scenario.	I-Reply	I-1	Reply	20144
[line_break_token][line_break_token]Regarding the experiments, we firstly address this doubt of the reviewer: ‚ÄúI believe that is not the main argument of the paper.	B-Reply	B-2	Reply	20144
The authors should provide empirical evidence on the claim that with an increasing number of tasks in MTRL, the error bound should improve and the performance of MTRL should also boost.	I-Reply	I-2	Reply	20144
‚Äù Since this is definitely something useful, we provide this analysis in Figure 1(b) and Figure 1(c).	I-Reply	I-2	Reply	20144
Theorem 2 bounds the norm-1 of the difference between the optimal-function and the-function at each update of the policy; thus, we want to measure the progress of this measure during learning in single-task and multi-task scenarios.	I-Reply	I-2	Reply	20144
Note that, except for very easy tabular problems, it is not easy to compute the optimal-function in RL.	I-Reply	I-2	Reply	20144
Nevertheless, we choose the car-on-hill MDP which is a not trivial problem that still allows us to compute the optimal-function.	I-Reply	I-2	Reply	20144
We solve it using Neural Fitted-Iteration, based on a neural network built accordingly to our proposed architecture.	I-Reply	I-2	Reply	20144
Since a neural network is a parametric regressor, we are not sure about what the reviewer means when it refers to ‚Äútabular‚Äù Fitted-Iteration.	I-Reply	I-2	Reply	20144
In the left plot in Figure 1(b), we consider four different tasks in the car-on-hill MDP.	I-Reply	I-2	Reply	20144
We solve each of these tasks with a single-task network, and all of them together in our multi-task network.	I-Reply	I-2	Reply	20144
Then, we show the progress of the averaged norm-1s of each single task network, and the norm-1 of the multi-task network.	I-Reply	I-2	Reply	20144
The plot shows how the multi-task network is able to get closer to the optimal-function w.r.t.	I-Reply	I-2	Reply	20144
the single task network.	I-Reply	I-2	Reply	20144
Then, Figure 1(c) provides evidence of the benefit of increasing the number of tasks.	I-Reply	I-2	Reply	20144
Note how the approximation of the optimal-function gets progressively better and more stable for an increasing number of tasks.	I-Reply	I-2	Reply	20144
Moreover, the right plot in Figure 1(b) also shows the benefit of multi-task in terms of performance.	I-Reply	I-2	Reply	20144
We think this experiment shows what the reviewer is asking, and we wonder if this is not clear in the paper.	I-Reply	I-2	Reply	20144
Regarding the initialization of the single-task network, we emphasize that the shared representation is learned on all the other tasks, excluding the one used for training the single-task network.	I-Reply	I-2	Reply	20144
This experiment has the purpose of providing another empirical evidence of the meaningfulness of the extracted shared features.	I-Reply	I-2	Reply	20144
We hope to have clarified the reviewer‚Äôs doubts; otherwise, we will be glad to resolve further concerns.	I-Reply	I-2	Reply	20144
[line_break_token][line_break_token]We noted that the last reference provided by the reviewer is not included in our paper; we thank the reviewer for the additional reference and we have added it in the revised version of the paper.	I-Reply	I-2	Reply	20144

This paper carries out several kinds of analysis on the GAT networks of Velickovic (2018), which augment GNN updates with multihead self attention.	O	O	Review	430
Three standard attention types are compared, on several different datasets, and differences between uniform attention and learned attention are reported.	O	O	Review	430
An experiment is carried out where low-attention edges are pruned.	O	O	Review	430
[line_break_token][line_break_token]While understanding the value of attention is important, this paper leaves many questions open.	B-Review	B-1	Review	430
First, since the graphs studied in this paper are, if not generally sparse to begin with at least they only include connections that are meaningful, the sparsification experiment is a bit hard to understand.	I-Review	I-1	Review	430
One particular extension would improve things: adding random edges (can the model learn to prune them out?),	I-Review	I-1	Review	430
but learning sparse attention (see e.g., Maruf et al 2019) rather than thresholding seems to be a reasonable point of comparison.	I-Review	I-1	Review	430
[line_break_token][line_break_token]Overall this paper would be more valuable if a clear and concise recommendation could be given regarding how to use or understand attention; but the lack of a consistent pattern of results makes any obvious narrative hard to support.	B-Review	B-2	Review	430
I would encourage the authors to continue this line of work so that it can be used to provided guidance to those who would like to make more effective use of GNNs.	I-Review	I-2	Review	430
e thank the reviewer for his encouragement and suggestions on future work	O	O	Reply	430

This paper demonstrates some limitations of censoring for privacy with respect to sensitive attributes.	O	O	Review	20482
In particular, the authors show that censoring reduces, but does not eliminate, the ability of a neural network to infer private/sensitive attributes, e.g. to infer race from a model aiming to predict gender.	O	O	Review	20482
Part of the proposed method is a component that performs de-censoring using an auxiliary dataset.	O	O	Review	20482
The authors show that censoring strength often does reduce the ability to infer sensitive attributes, but also affects the ability to perform the main (non-sensitive) task; and in some cases, may actually increase ability to infer sensitive attributes.	O	O	Review	20482
This type of work is important in that privacy is of growing importance, and so is the risk to privacy; this particular work is well carried out.	O	O	Review	20482
[line_break_token][line_break_token]One concern: In Sec.	B-Review	B-1	Review	20482
3.1, there is an assumption of the availability of D_{aux}. How realistic is this assumption?	I-Review	I-1	Review	20482
hanks for the review!	O	O	Reply	20482
[line_break_token]With the growing availability of public datasets, if the adversary knows only the input domain (e.g., face images), today it is relatively easy to find public data with the desired target attribute (e.g., race)	B-Reply	B-1	Reply	20482

The paper is well written and flows very well.	O	O	Review	20486
The idea is straightforward and easy to understand.	O	O	Review	20486
Here are my feedbacks:[line_break_token][line_break_token]--Method--[line_break_token][line_break_token]Methodology-wise, the novelty is somewhat limited.	B-Review	B-5	Review	20486
The main technical contributions are: 1) formulate linear programming to reduce energy costs, and the formulation of linear programming is straightforward.	O	O	Review	20486
2) the claimed main contribution is an application of Rayleigh-Quotient gradient descent to approximate the eigenvalue calculations in the model proposed by Wu et al (2019).	O	O	Review	20486
[line_break_token][line_break_token]I believe computing the eigenvalue shall not be the only way to solve Eq.(3), e.g. using gradient-based method or Lagrange.	B-Review	B-1	Review	20486
My main question is whether computing the global optimum really matters?	I-Review	I-1	Review	20486
Since your method is still essentially an approximation algorithm, which may break the optimality condition here.	I-Review	I-1	Review	20486
From the experimental results, it seems that your approximation is quite close to the analytical solution.	I-Review	I-1	Review	20486
Therefore, it is unclear computing a global optimum really matters here.	I-Review	I-1	Review	20486
[line_break_token][line_break_token]I tried to buy the idea of escaping the saddle point with splitting (it indeed sounds straightforward and reasonable).	B-Review	B-2	Review	20486
It will be great if the author can add some empirical experiments to verify it.	I-Review	I-2	Review	20486
[line_break_token][line_break_token]--Content--[line_break_token]The entire section2 is at reviewing prior works, and I believe you should cut down the content here.	O	O	Review	20486
[line_break_token][line_break_token]--Experiments--[line_break_token]1.	O	O	Review	20486
Diversity of your tests: the author main uses MobileNet in testing their ideas.	B-Review	B-3	Review	20486
It seems that their method starts at MobileNet, then tries to improve it.	I-Review	I-3	Review	20486
I suggest authors adding other recent works, e.g. FBNet, MobileNetV3, into their tests to diversify the types of networks.	I-Review	I-3	Review	20486
[line_break_token][line_break_token]2.	O	O	Review	20486
Results variations: all figures, e.g. fig.3, fig.4, in the paper lack plotting their results variations.	B-Review	B-4	Review	20486
Since the optimization may converge to different local optimum, it is more persuasive to show their performance variations.	I-Review	I-4	Review	20486
[line_break_token][line_break_token]3.	O	O	Review	20486
The final results are not surprising: in table.1 and table.2, as far as I'm aware, the mainstream accuracy for ImageNet under the mobile setting should be 75% top-1.	B-Review	B-5	Review	20486
And the SOTA top-1 accuracy on ImageNet is around 85.5%.	I-Review	I-5	Review	20486
Table.1 and table.2 do somewhat show the effectiveness of your method, but its significance is limited especially considering the limited novelty of methodology.	I-Review	I-5	Review	20486
[line_break_token][line_break_token]Minors:[line_break_token]In Fig.3 k = 6, it seems vanilla splitting is better than accuracy and parameters, except for 0.2 log higher flops.	B-Review	B-6	Review	20486
I don't think this makes a compelling case here.	I-Review	I-6	Review	20486
[line_break_token][line_break_token]In Fig.4, from flops 7 ~ 9, your results are similar to Bn especially accuracy &gt; 0.6.	O	O	Review	20486
When accuracy &lt; 0.6, it is less interesting, and I believe the improvement should be huge.	O	O	Review	20486
[line_break_token][line_break_token]Fig.5, could you please compare the time using MAGMA from NVIDIA?	B-Review	B-8	Review	20486
I had some experiences in implementing the LAPACK and BLAS on GPUs, and it should not be that slow.	I-Review	I-8	Review	20486
[line_break_token][line_break_token]Overall, this paper has some interesting results, which shows the eigenvalue can be approximated by Rayleigh-Quotient gradient descent, and show positive improvement.	O	O	Review	20486
However, the methodological and experimental results can definitely be strengthened.	B-Review	B-9	Review	20486
The author may consider proving that achieving the global optimum on Eq.(3) really matters, then motivate the methodology.	I-Review	I-9	Review	20486
Thank you.	O	O	Review	20486
[line_break_token]	O	O	Review	20486
**I believe computing the eigenvalue shall not be the only way to solve Eq.(3), e.g. using gradient-based method or Lagrange;**  [line_break_token]  [line_break_token]Since Eigen-problem is equivalent to Eq (3) in the zero-step size limit, our algorithm is already in some sense doing gradient descent for Eq (3).	B-Reply	B-1	Reply	20486
Brute-forcefully applying gradient descent can be problematic because the gradient of the two off-springs would cancel with each other and yield zero gradients (because they move along opposite directions).	I-Reply	I-1	Reply	20486
As shown in the theory of the original splitting descent paper, the structural descent is a second-order update.	I-Reply	I-1	Reply	20486
Eigen-formulation avoids this problem because it allows us to analytically derive the gradient, which requires to look at some (partial) second-order terms of the objective function in Eq(3).	I-Reply	I-1	Reply	20486
 [line_break_token][line_break_token]To put it in another way,  if someone tries to derive a gradient descent algorithm for Eq (3), they will end up with something similar or equivalent to our method, after careful mathematical derivation.	I-Reply	I-1	Reply	20486
  [line_break_token][line_break_token]We hope this makes it clear that Eq (3) is not trivial mathematically and theoretical thinking is needed.	I-Reply	I-1	Reply	20486
For example, without deriving the eigen-formulation, we would need to optimize the weights w and size m, which makes the problem complicated.	I-Reply	I-1	Reply	20486
   [line_break_token][line_break_token]Issue of "global vs. local optimality"[line_break_token][line_break_token]Following our comments above, we do not think there is an issue of global vs. local optimality here.	I-Reply	I-1	Reply	20486
We are already doing a type of gradient descent on Eq (3), for which the global optimum happens to be the only stable local optimum thanks to its equivalent to Eigen-problem.	I-Reply	I-1	Reply	20486
[line_break_token][line_break_token]Question: "I tried to buy the idea of escaping the saddle point with splitting (it indeed sounds straightforward and reasonable).	O	O	Reply	20486
It will be great if the author can add some empirical experiments to verify it."	O	O	Reply	20486
[line_break_token][line_break_token]Reply: We believe this question has already been fully answered in the original splitting descent paper.	B-Reply	B-2	Reply	20486
For example, Figure 1 in that paper offers very intuitively and convincing illustrations that might alleviate R#3?s concerns.	I-Reply	I-2	Reply	20486
[line_break_token]Our main focus is on scaling the algorithm to large-scale settings.	I-Reply	I-2	Reply	20486
We only cite and explain their point on this aspect.	I-Reply	I-2	Reply	20486
[line_break_token][line_break_token] [line_break_token]Question: "adding other recent works, e.g. FBNet, MobileNetV3, into their tests to diversify the types of networks."	O	O	Reply	20486
[line_break_token][line_break_token]Reply:  We choose MobileNetV1 and MobileNetV2 as our testbed mainly due to their popularity and nice accuracy-flops tradeoff.	B-Reply	B-3	Reply	20486
And MobileNetV1 and MobileNetV2 together define all basic blocks/layers of many recent works such as FBNet and MobileNetV3.	I-Reply	I-3	Reply	20486
We expect that the results will be similar on FBNet and MobileNetV3.	I-Reply	I-3	Reply	20486
[line_break_token][line_break_token]Question:  "it is more persuasive to show their performance variations."	O	O	Reply	20486
[line_break_token][line_break_token]Reply:  We provide ablation studies in section 5.4 (see Figure 6).	B-Reply	B-4	Reply	20486
[line_break_token][line_break_token]Question:  "The final results are not surprising: in table.1 and table.2, as far as I'm aware, the mainstream accuracy for ImageNet under the mobile setting should be 75% top-1.	O	O	Reply	20486
And the SOTA top-1 accuracy on ImageNet is around 85.5%."	O	O	Reply	20486
[line_break_token][line_break_token]Reply: The main goal of this paper is to provide a way to grow networks that work in practice.	B-Reply	B-5	Reply	20486
Therefore, our method should be compared with existing methods using the same meta-architectures (e.g. same depth, kernel size, resolutions).	I-Reply	I-5	Reply	20486
 To the best of our knowledge, our results are the current SOTA top-1 accuracy on ImageNet using *MobileNetV1* and *MobileNetV2* with similar Flops compared to expert-designed MobileNets and pruning methods.	I-Reply	I-5	Reply	20486
[line_break_token][line_break_token]Question:  "In Fig.3 k = 6, it seems vanilla splitting is better than accuracy and parameters, except for 0.2 log higher flops.	O	O	Reply	20486
I don't think this makes a compelling case here."	O	O	Reply	20486
[line_break_token][line_break_token]In this case, all networks are 1) not very deep; 2) trained on a small CIFAR10 dataset.	B-Reply	B-6	Reply	20486
That said, the differences shouldn't be super significant.	I-Reply	I-6	Reply	20486
However, the results are shown in Figure 3 clearly demonstrate that our method achieves better accuracy-flops trade-off than the vanilla splitting approach.	I-Reply	I-6	Reply	20486
[line_break_token][line_break_token]Question: "In Fig.4, from flops 7 ~ 9, your results are similar to Bn especially accuracy &gt; 0.6.	O	O	Reply	20486
When accuracy &lt; 0.6, it is less interesting, and I believe the improvement should be huge."	O	O	Reply	20486
[line_break_token][line_break_token]Reply: We believe it?s already significant enough to show that our method outperforms pruning methods.	B-Reply	B-7	Reply	20486
Pruning methods have already taken advantage of using knowledge from a pre-trained over-parameterized model, while our method training small models from scratch.	I-Reply	I-7	Reply	20486
[line_break_token][line_break_token]Question: "Fig.5, could you please compare the time using MAGMA from NVIDIA?	O	O	Reply	20486
I had some experiences in implementing the LAPACK and BLAS on GPUs, and it should not be that slow."	O	O	Reply	20486
[line_break_token][line_break_token]Reply:  Thanks for your suggestions.	B-Reply	B-8	Reply	20486
We note that the key bottleneck of the vanilla splitting approach is the requirement of calculating all splitting matrices, which causes a space complexity O(nd^2) (n: number of neurons, d: dimension of each neuron).	I-Reply	I-8	Reply	20486
 This makes it *impossible* to implement the algorithm on GPUs for modern neural networks with thousands of neurons, mainly due to the explosion of GPU memory	I-Reply	I-8	Reply	20486

Overview/Contribution:[line_break_token]====================[line_break_token]The authors present a explanation generation framework that help validate post-hoc explanations when the explanations are generated based on feature selection.	O	O	Review	20170
They claim to demonstrate their method by showing failure modes of exiting explanation generation methods.	O	O	Review	20170
[line_break_token][line_break_token]Overall, the paper is not ready to be accepted to the conference and I describe my rational with the following strengths and weaknesses.	O	O	Review	20170
[line_break_token][line_break_token]Strength:[line_break_token]========[line_break_token]+ Explanations make models more transparent and easy to understand for end users of the decision made by complex models such as deep neural networks [1]. In that respect, having a verification mechanism for post-hoc explanations is interesting and useful.	O	O	Review	20170
[line_break_token]+ The paper is easy to read and follow.	O	O	Review	20170
[line_break_token]Weakness:[line_break_token]===========[line_break_token]- evaluating explanations generated for an opaque model with another opaque model (RCNN) is cyclical.	B-Review	B-1	Review	20170
[line_break_token]- Just like many literature in this nascent space, interpretation (which is measuring the contribution of features or subsets of features towards predicted output) is confused as explanation.	B-Review	B-2	Review	20170
Human level explanations don‚Äôt necessarily depend on the direct interaction or contribution of model derived features.	I-Review	I-2	Review	20170
Rather they describe ‚Äòwhy‚Äô the model come up with the decision produced.	I-Review	I-2	Review	20170
[line_break_token]- Explanation generation is gaining traction in the deep learning community especially for critical applications such as healthcare and security.	B-Review	B-3	Review	20170
However, the authors claim that post-hoc explanations currently are only evaluated for only simple non-neural model.	I-Review	I-3	Review	20170
That is misleading given the recent attention toward generating explanations for various deep learning models.	I-Review	I-3	Review	20170
[line_break_token]- As a generalized pos-hoc explanation generators verification framework, the experiments are seriously lacking and are not well designed to illicit broad applicability.	B-Review	B-4	Review	20170
[line_break_token][line_break_token]1) Bekele, E., Lawson, W. E., Horne, Z., &amp; Khemlani, S. (2018).	O	O	Review	20170
Implementing a Robust Explanatory Bias in a Person Re-identification Network.	O	O	Review	20170
In&nbsp;Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops&nbsp;(pp.	O	O	Review	20170
2165-2172).	O	O	Review	20170
REVIEWER: Evaluating explanations generated for an opaque model with another opaque model (RCNN) is cyclical.	O	O	Reply	20170
[line_break_token]ANSWER: Our general answer should help clarify this.	B-Reply	B-1	Reply	20170
The RCNN is not meant to explain other opaque models, it only explains itself, hence there is no cycle.	I-Reply	I-1	Reply	20170
We only evaluate explainers on the trained RCNNs with their associated pruned datasets for which we provided the guarantees mentioned in the general answer.	I-Reply	I-1	Reply	20170
The RCNN has a degree of transparency that we exploit: it itself, selects the features that it will further exclusively use in the final prediction.	I-Reply	I-1	Reply	20170
Our 2 pruning procedures ensure that, on the instances of the pruned datasets, the RCNN‚Äôs selection faithfully represents the model‚Äôs inner-working: the non-selected tokens are indeed irrelevant and some of the selected tokens are clearly relevant.	I-Reply	I-1	Reply	20170
[line_break_token][line_break_token]R: Authors claim that post-hoc explanations currently are only evaluated for simple non-neural model.	O	O	Reply	20170
[line_break_token]A: We do not claim that explainers are only evaluated on non-neural models.	B-Reply	B-3	Reply	20170
In the related work, we had listed the 4 types of evaluations we identified in the literature, the last 3 of which are based on complex neural models, but they have other downsides.	I-Reply	I-3	Reply	20170
We have updated the paper to ensure that we mention all 4 types of evaluations together in all parts of the paper.	I-Reply	I-3	Reply	20170
[line_break_token][line_break_token]R: More experiments[line_break_token]A: Please see general answer.	B-Reply	B-4	Reply	20170
[line_break_token][line_break_token]R: Referenced human-level explanation paper[line_break_token]A: Thank you for mentioning it, we added it accordingly in the related work.	B-Reply	B-2	Reply	20170

This paper proposes a strategy to generate audio samples from noise with GANs.	O	O	Review	279
The treatment is analogous to image generation with GANs, with the emphasis being the changes to the architecture and representation necessary to make it possible to generate convincing audio that contains an interpretable latent code and is much faster than an autoregressive Wavenet based model ("Neural Audio Synthesis of Musical Notes with WaveNet AutoEncoders" - Engel et al (2017)).	O	O	Review	279
Like the other two related works (WaveGAN - "Adversarial Audio Synthesis" - Donahue et al 2018) and the Wavenet model above, it uses the NSynth dataset for its experiments.	O	O	Review	279
[line_break_token][line_break_token]Much of the discussion is on the representation itself - in that, it is argued that using audio (WaveGAN) and log magnitude/phase spectrograms  (PhaseGAN) produce poorer results as compared with the version with the unrolled phase that they call 'IF' GANs, with high frequency resolution and log scaling to separate scales.	O	O	Review	279
 [line_break_token][line_break_token]The architecture of the network is similar to the recently published paper  (Donahue et al 2018), with convolutions and transpose convolutions adapted for audio.	O	O	Review	279
However, there seem to be two important developments.	O	O	Review	279
The current paper uses progressive growing of GANs (the current state of the art for producing high resolution images), and pitch conditioning (Odena et al, where labels are used to help training dynamics).	O	O	Review	279
[line_break_token][line_break_token]For validation, the paper presents several metrics, with the recently proposed "NDB" metric figuring in the evaluations, which I think is interesting.	O	O	Review	279
The IF-Mel + high frequency resolution model seems to outperform the others in most of the evaluations, with good phase coherence and interpolation between latent codes.	O	O	Review	279
[line_break_token][line_break_token]My thoughts: [line_break_token]Overall, it seems that the paper's contributions are centered around the representation (with "IF-Mel" being the best).	O	O	Review	279
The architecture itself is not very different from commonly used DCGAN variants - the authors say that using PGGAN is desirable, but not critical, and the use of labels from Odena et al [line_break_token][line_break_token]Many of my own experiments with GANs were plagued by instability (especially at higher resolution) and mode collapse problems without special treatment (largely documented, such as adding noise, adjusting learning rates and so forth).	B-Review	B-1	Review	279
To this end, what do the authors see as 'high' resolution vis a vis audio signals?	I-Review	I-1	Review	279
[line_break_token][line_break_token]I am curious if we can adapt these ideas for recurrent generators as might appear in TTS problems.	B-Review	B-2	Review	279
[line_break_token][line_break_token]I rate this paper as an accept since this is one of the few existing works that demonstrate successful audio generation from noise using GANs, and  owing to its novelty in exploring representation for audio.	O	O	Review	279
[line_break_token]	O	O	Review	279
Thank you for your time and expertise in your review, we've addressed the key points below:[line_break_token][line_break_token]> ‚Äú...what do the authors see as 'high' resolution vis a vis audio signals?‚Äù[line_break_token][line_break_token]In the context of these audio datasets, we use ‚Äúhigh‚Äù resolution to refer more to the dimensionality of the signal to model with a single latent vector, rather than the temporal resolution of the audio.	B-Reply	B-1	Reply	279
The spectral ‚Äúimages‚Äù that GANSynth models, have 1024 frequencies, 128 timesteps, and 2 channels, [1024, 128, 2], which is roughly equivalent to a [295, 295, 3] RGB image.	I-Reply	I-1	Reply	279
This puts the task comparable to some of the higher-resolution GANs for images.	I-Reply	I-1	Reply	279
[line_break_token][line_break_token]> ‚ÄúI am curious if we can adapt these ideas for recurrent generators as might appear in TTS problems.	O	O	Reply	279
‚Äú[line_break_token][line_break_token]We agree that would be an interesting development.	B-Reply	B-2	Reply	279
Recurrent generators, and even discriminators, would allow for variable-length sequences and variable-length conditioning as is common in speech synthesis or music generation beyond single notes.	I-Reply	I-2	Reply	279
Our initial experiments at using recurring generators were not very successful, so we opted to adopt a better tested architecture for this study, but this is definitely still an area ripe for exploration.	I-Reply	I-2	Reply	279

Observing shortcomings of BLEU and ROUGE, the paper proposes, JAUNE, a set of criteria for a good evaluation metric.	O	O	Review	577
These criteria include: high correlation with human judgement; being able to distinguish similar but contradicting statements; penalizing grammatical errors, and hard to game.	O	O	Review	577
[line_break_token][line_break_token]The paper, as its current form, is not ready for publishing.	O	O	Review	577
Some suggestions and comments:[line_break_token][line_break_token]- Please carefully check the paper and fix typos and confusing sentences.	B-Review	B-1	Review	577
I was collecting these errors but eventually stopped.	I-Review	I-1	Review	577
Some examples.	I-Review	I-1	Review	577
Sec.	I-Review	I-1	Review	577
2.3: punctuation missing between "RUSE" and "this method", comma missing after "a discrete space"; Sec.	I-Review	I-1	Review	577
4.1.1: "made to ,for example"....[line_break_token][line_break_token]- The motivation of the paper is unclear.	B-Review	B-2	Review	577
Is your criticism only about BLEU and ROUGE, or the state of the arts in NLP evaluation in general?	B-Review	B-3	Review	577
To make JAUNE appealing, one has to argue that the state of the arts in NLP evaluation is ineffective.	I-Review	I-3	Review	577
For this, the paper needs to review a boarder range of metrics beyond just BLUE and ROUGE.	I-Review	I-3	Review	577
[line_break_token][line_break_token]- While the authors suggest a data-driven metric, it reads to me like a model-driven metric (RoBERTAa specifically).	B-Review	B-4	Review	577
Doesn't it systematically bias towards a certain family of metrics?	I-Review	I-4	Review	577
[line_break_token][line_break_token]- Better and more comprehensive experimental results are highly desired.	B-Review	B-5	Review	577
ear Reviewer #1,[line_break_token][line_break_token]1) Thank you for your comments.	O	O	Reply	577
We have checked the paper for typos, confusing sentences and made it easier to read.	B-Reply	B-1	Reply	577
[line_break_token][line_break_token]2) Overall the goals of the paper are to present clear criteria to assess evaluation metrics and show how transformers can be used to assess the quality of candidate translations and summaries.	B-Reply	B-2	Reply	577
[line_break_token][line_break_token]3) Currently, all summaries/translation results use BLEU/ROUGE, hence the focus on these 2 metrics.	B-Reply	B-3	Reply	577
The core idea in the experimental section is that in all dimensions capturing the properties of a "good evaluator", BLEU/ROUGE are outperformed by a Transformer trained to predict semantic similarity between candidate and reference sentences.	I-Reply	I-3	Reply	577
The earlier version of the paper hinted at a more general framework in which Transformers themselves are used as feature extractors for various sentence pairs but we removed this part to reduce confusion.	I-Reply	I-3	Reply	577
[line_break_token][line_break_token]4) We use the term data-driven because the evaluators are general purpose language models fine-tuned on semantic similarity.	B-Reply	B-4	Reply	577
We took RoBERTa-STS as an example but recent, high-performing models such as ALBERT or ALICe are also applicable.	I-Reply	I-4	Reply	577
The constant among those is the training procedure relying on the same data.	I-Reply	I-4	Reply	577
The models are anticipated to evolve which is why we did not want to be specifying just a model.	I-Reply	I-4	Reply	577
[line_break_token][line_break_token]5) We have added 3 more experiments.	B-Reply	B-5	Reply	577
The first 2 complete the evaluation of RoBERTa-STS for the 2 dimensions of the scorecard.	I-Reply	I-5	Reply	577
The last experiments use RoBERTa-STS on 5300+ WMT sentence pairs and show that this model transfers well.	I-Reply	I-5	Reply	577
[line_break_token][line_break_token][line_break_token]	O	O	Reply	577

This paper performs cache side-channel attacks to extract attributes of a victim model, and infer its architecture accordingly.	O	O	Review	1553
In their threat model, the attacker could launch a co-located process on the same host machine, and use the same DL framework as the victim model.	O	O	Review	1553
Their evaluation shows that: (1) their attacks can extract the model attributes pretty well, including the number of different types of layers; (2) using these attributes, they train a decision tree classifier among 13 CNN architectures, and show that they can achieve a nearly perfect classification accuracy.	O	O	Review	1553
They also evaluate some defense strategies against their attacks.	O	O	Review	1553
[line_break_token][line_break_token]Model extraction attack under a black-box setting is an important topic, and I am convinced that their threat model is a good step towards real-world attacks.	O	O	Review	1553
As for the novelty, although Yan et al also evaluate cache side-channel attacks, that paper was released pretty shortly before ICLR deadline, thus I would consider this work as an independent contribution at its submission.	O	O	Review	1553
[line_break_token][line_break_token]I have several questions and comments about this paper:[line_break_token][line_break_token]- One difference of the evaluation setup between this paper and Yan et al is that in Yan et al they are trying to infer more detailed hyper-parameters of the architecture (e.g., the number of neurons, the dimensions of each layer, the connections), but within a family of architectures (i.e., VGG or ResNet).	B-Review	B-1	Review	1553
On the other hand, in this paper, the authors extract higher-level attributes such as the number of different layers and activation functions, and predict the model family (from 5 options) or the concrete model architecture (from 13 options).	I-Review	I-1	Review	1553
While I think inferring the model family type is also an interesting problem, this setup is still a little contrived.	I-Review	I-1	Review	1553
Would the classifier predict the family of a model correctly if it is not included in the training set, say, could it predict ResNet32 as R (ResNet)?	I-Review	I-1	Review	1553
[line_break_token][line_break_token]- In Table 3, it looks like the errors in the captured computation sequences show some patterns.	B-Review	B-2	Review	1553
Are these error types consistent across different runs?	I-Review	I-2	Review	1553
Could you provide some explanation of these errors?	I-Review	I-2	Review	1553
[line_break_token][line_break_token]- In Table 5, my understanding is that we need to compare the avg errors to the numbers in Table 2.	B-Review	B-3	Review	1553
In this case, the errors seem to be even larger than the sum of the attribute values.	I-Review	I-3	Review	1553
Is this observation correct?	I-Review	I-3	Review	1553
If so, could you discuss what attributes are most wrongly captured, and show some examples?	I-Review	I-3	Review	1553
[line_break_token][line_break_token]- It would be beneficial to provide a more detailed comparison between this work and Yan et al e.g., whether the technique proposed in this work could be also extended to infer more fine-grained attributes of a model, and go beyond a classification among a pre-defined set of architectures.	B-Review	B-4	Review	1553
[line_break_token][line_break_token]- The paper needs some editing to fix some typos.	B-Review	B-5	Review	1553
For example, in Table 5, the captions of Time (Baseline) and Time (+TinyNet) should be changed, and it looks confusing at the first glance.	I-Review	I-5	Review	1553
[line_break_token]	O	O	Review	1553
We thank the reviewer for the constructive feedback: the questions and comments can improve and make our contributions more concrete.	O	O	Reply	1553
We will update our paper accordingly to include their points.	O	O	Reply	1553
In the meantime, we would like to provide initial answers to the reviewer‚Äôs questions:[line_break_token][line_break_token](1) Could our classifier predict the family of a model correctly (ex.	O	O	Reply	1553
ResNet32) not in the training data?	O	O	Reply	1553
[line_break_token][line_break_token]No, our classifier could not predict this because it cannot learn how to classify unobserved samples into the families that have similar features (or attributes).	B-Reply	B-1	Reply	1553
Suppose that the samples from ResNet18 or 34 are not in our training set.	I-Reply	I-1	Reply	1553
Since the architecture attributes of ResNet18 or 34 are similar to those of VGG16/19 or MobileNetV1/2, our classifier may predict the unseen samples as some other close family (VGGs or MobileNets).	I-Reply	I-1	Reply	1553
However, we are sure that if we include the ResNet18 or 34 to our training set, our classifier will learn to specify them as ResNets.	I-Reply	I-1	Reply	1553
[line_break_token][line_break_token]The key contribution of our (fingerprinting) experiment is to examine which of the architecture attributes that our attacker can extract are essential to specify network families.	I-Reply	I-1	Reply	1553
We identified that four common attributes (#relus, #merges, #convs, and #poolings) are important to know the family of a victim‚Äôs network.	I-Reply	I-1	Reply	1553
This information can help our attacker to launch large-scale attacks in the transfer learning scenario because our attacker already knows multiple commonly used pre-trained models + architectures that she can train her classifier on.	I-Reply	I-1	Reply	1553
Then, by passively observing the information leakage from cache side-channels, the attacker can specify which actual pre-trained model that the victim uses and synthesize adversarial samples with the pre-trained model that also works for the victim model (as prior work [1] warned).	I-Reply	I-1	Reply	1553
[line_break_token][line_break_token](2) Reconstruction errors observable in Table 3.	O	O	Reply	1553
[line_break_token][line_break_token]In our experiments, we could not find specific error patterns in the extracted attribute sequences.	B-Reply	B-2	Reply	1553
As we can see in Table 3, there are the cases where convolutional layers are missing and/or added and activations are missing and/or added.	I-Reply	I-2	Reply	1553
Also, the locations of missing attributes are different in each run.	I-Reply	I-2	Reply	1553
We attribute these errors to a few primary causes: there is background noise of other processes that our flush+reload cache-based side channel attack may pick up (e.g. other background processes pull something into the cache and evict our target functions between when the victim calls the function and we reload it), or we may experience common errors associated with flush+reload (e.g. a victim may call the function during the time when we reload, causing us to see a cache miss instead of correctly observing a cache hit) [2].[line_break_token][line_break_token](3) Comparison of avg.	O	O	Reply	1553
errors in Table 5 (running decoy process as a defense).	O	O	Reply	1553
[line_break_token][line_break_token]Yes, in Table 5, our experiments indicate that the errors are larger than the sum of the original attribute values (that we can expect from ResNet50).	B-Reply	B-3	Reply	1553
In our experiments in Table 5, we increase the errors associated with the attributes that we aim to obfuscate.	I-Reply	I-3	Reply	1553
For instance, when we run the TinyNet with only one convolutional layer, we observe the #conv attribute is significantly increased.	I-Reply	I-3	Reply	1553
This result is important because, with our defenses, a defender can choose the attributes to obfuscate.	I-Reply	I-3	Reply	1553
By introducing noise into the cache side channel by means of another process, we can make differentiating between functions that are called by our victim and our decoy incredibly difficult and therefore mitigate, and possibly eliminate, any useful information that an attacker can gain by these side channels.	I-Reply	I-3	Reply	1553
Since the defender has control over what noise gets introduced, they can also dynamically and adaptively change what noise is added into the attacker‚Äôs observations, thereby increasing our defenses‚Äô effectiveness and generalizability.	I-Reply	I-3	Reply	1553
[line_break_token][line_break_token](4) Emphasizing our contributions over the concurrent work (Yan et al 2018).	O	O	Reply	1553
[line_break_token][line_break_token]Our key contributions over the concurrent work (Yan et al 2018) are highlighted in the initial response to the reviewer‚Äôs comments below [comment 1]: <a href="https://openreview.net/forum?id=rk4Wf30qKQ&noteId=B1l2z9wgTm" target="_blank" rel="nofollow">https://openreview.net/forum?id=rk4Wf30qKQ&noteId=B1l2z9wgTm</a> / comment 2: <a href="https://openreview.net/forum?id=rk4Wf30qKQ&noteId=Sye8V5wx67]." target="_blank" rel="nofollow">https://openreview.net/forum?id=rk4Wf30qKQ&noteId=Sye8V5wx67].</a> We plan to include the comparison in our related work section.	O	O	Reply	1553
[line_break_token][line_break_token](5) Fixing typos in our paper.	O	O	Reply	1553
[line_break_token][line_break_token]We are working on revising our paper based on the reviewers‚Äô feedback.	B-Reply	B-5	Reply	1553
We will include those fixes in the revised version.	I-Reply	I-5	Reply	1553
[line_break_token][line_break_token][1] Bolun Wang, Yuanshun Yao, Bimal Viswanath, Haitao Zheng, and Ben Y Zhao.	O	O	Reply	1553
With great training comes great vulnerability: Practical attacks against transfer learning.	O	O	Reply	1553
USENIX Security, 2018[line_break_token][2] Yarom, Yuval, and Katrina Falkner. "	O	O	Reply	1553
FLUSH+ RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack."	O	O	Reply	1553
USENIX Security Symposium.	O	O	Reply	1553
Vol.	O	O	Reply	1553
1.	O	O	Reply	1553
2014	O	O	Reply	1553

This paper performs a general analysis of sign-based methods for non-convex optimization.	O	O	Review	10056
They define a new norm-like function depending on the success probabilities.	O	O	Review	10056
Using this new norm-like function and under an assumption, they prove exponentially variance reduction properties in both directions and small mini-batch sizes.	O	O	Review	10056
[line_break_token][line_break_token]I am not convinced about assumption 1, which plays the key role of the proof.	B-Review	B-1	Review	10056
It assumes that success probabilities are always large or equal to 1/2.	I-Review	I-1	Review	10056
[line_break_token][line_break_token]How can we guarantee this property hold for an algorithm?	B-Review	B-2	Review	10056
I suggest the authors provide some real learning examples, under which it will satisfy the condition.	I-Review	I-2	Review	10056
 I may revise my rating according to this.	O	O	Review	10056
[line_break_token]	O	O	Review	10056
e provided 3 different setups, where assumption 1 is satisfied:[line_break_token]1) Unimodal and symmetric noise setup (Lemma 1).	B-Reply	B-1	Reply	10056
As noted in (Bernstein et al 2018), it is backed up by central limit theorem when training neural networks.	I-Reply	I-1	Reply	10056
[line_break_token]2) Strong growth condition with fixed mini-batch size (updated Lemma 2).	I-Reply	I-1	Reply	10056
This setup corresponds to over-parameterized deep network learning, where the model can fit the training data completely.	I-Reply	I-1	Reply	10056
[line_break_token]3) Adaptive mini-batch size setup (Lemma 3), which guarantees converge merely by choosing appropriate mini-batch size.	I-Reply	I-1	Reply	10056
[line_break_token][line_break_token]Note that, while sign matching SPB assumption is quite intuitive in sign based methods, it is not assumed or somehow claimed that it holds automatically for simple problems.	I-Reply	I-1	Reply	10056
Even in one dimensional regression problem SPB assumption might fail, as much as signSGD might fail to converge.	I-Reply	I-1	Reply	10056
Furthermore, the SPB assumption describes the convergence of sign descent methods, which is known to be problematic (see e.g. (Balles &amp; Hennig, 2018), section 6.2 Results)	O	O	Reply	10056

This paper proposes a drop-in module of disentangled patch representation learning for adversarial learning-based domain adaptation.	O	O	Review	687
The main idea is to encourage the source patch level representation to be disentangled, by creating certain intermediate pseudo-ground truths via clustering the label patch histograms using k-means.	O	O	Review	687
This basically creates an alternative, additional view of prediction target of the network outputs.	O	O	Review	687
And similar to global network output alignment by Tsai et al the authors impose an adversarial loss on the additionally introduced view.	O	O	Review	687
[line_break_token][line_break_token]Clarity: The paper is well-written with good clarity.	O	O	Review	687
[line_break_token][line_break_token]Results: This paper has a good experimental validation of proposed module.	O	O	Review	687
[line_break_token][line_break_token]Concerns: [line_break_token]- The idea of using patches in domain adaptation is not completely new.	B-Review	B-1	Review	687
ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes, CVPR 2018 also uses the patch level information to help domain adaptation.	I-Review	I-1	Review	687
Although the ideas are not entirely identical, this paper should at least cite and compare this work.	I-Review	I-1	Review	687
[line_break_token][line_break_token]- The disentangled patch feature learning introduces two additional loss, L_d and L_adv^l, which require three extra parameters, including K in K-means, lambda_d and lambda_adv^l.	B-Review	B-2	Review	687
It will be great if a formal sensitivity analysis on the parameters can be conducted.	I-Review	I-2	Review	687
There are some details missing in the paper too.	I-Review	I-2	Review	687
For example, what is the performance of the VGG source model without adaptation?	I-Review	I-2	Review	687
I am also curious about the learning behavior of the proposed method.	I-Review	I-2	Review	687
Could you show the mIoU v.s.	I-Review	I-2	Review	687
epoch curve for GTA2Cityscapes, or any other benchmarks?	I-Review	I-2	Review	687
[line_break_token][line_break_token]- Although consistently improving over Tsai et al CVPR18, the introduced methods does not show very significant gain in multiple experiments.	B-Review	B-3	Review	687
On SYNTHIA-to-City, only 0.4 mIoU gain is obtained.	I-Review	I-3	Review	687
In addition, while the proposed method is empirically effective, it is largely task-specific and restricted to domain adaptation for scene parsing only.	I-Review	I-3	Review	687
It seems difficult to generalize the same method to other domain adaptation tasks.	I-Review	I-3	Review	687
The limitation on the performance gain and generalizability somehow reduced the contribution from this work to the community.	I-Review	I-3	Review	687
[line_break_token][line_break_token]- A major concern of this work is the lack of citation and direct comparison to multiple previous SOTAs.	B-Review	B-4	Review	687
For example, the paper should compare the end-system performance with several published works such as:[line_break_token]1.	I-Review	I-4	Review	687
Zhang et al Fully convolutional adaptation networks for semantic segmentation, CVPR2018[line_break_token]2.	I-Review	I-4	Review	687
Zhu et al Penalizing top performers: conservative loss for semantic segmentation adaptation, ECCV2018[line_break_token]3.	I-Review	I-4	Review	687
Zou et al Domain adaptation for semantic segmentation via class-balanced self-training, ECCV2018[line_break_token]And according to the results reported by these works, the proposed joint framework in this paper does not seem very competitive in terms of the UDA performance in multiple settings	I-Review	I-4	Review	687
Thanks for the valuable comments.	O	O	Reply	687
For the CVPR‚Äô18 work (ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes), we acknowledge their idea of using spatial-aware adaptation on spatial regions in the image (will cite it in the revised paper).	B-Reply	B-1	Reply	687
However, their idea is more similar to the PatchGan discriminator used in Tsai, et al CVPR‚Äô18 (i.e., spatially global alignment), and is different from the proposed patch-level alignment.	I-Reply	I-1	Reply	687
Our patch alignment focuses on refining small patches (e.g., 32x64) and is location-independent (as described in Figure 1, introduction, and Section 3.3), while the CVPR‚Äô18 works assume fixed local regions with larger patches (e.g., 171x342) that account for the context information.	I-Reply	I-1	Reply	687
In addition, as shown in the ablation study (without reshaped \hat{F} in Table 1), it shows that the proposed location-independent operation helps patch-level alignment.	I-Reply	I-1	Reply	687
[line_break_token][line_break_token]For the number of clusters K, we find that the result varies on the GTA5-to-Cityscapes dataset.	B-Reply	B-2	Reply	687
For example, when K is small (e.g., 20), there would be ambiguities for the patch-level alignment process and the performance drops to 41.6, while it is also more difficult to match patches across domains when K is too large (e.g., 200).	I-Reply	I-2	Reply	687
In practice, we find that within a reasonable range, e.g., K = [30, 80], the IoU is in a range of [42.6%, 43.2%]. For \lambda_d, the goal is to simply perform classification based on clustering, and we find that the results do not differ a lot when choosing \lambda_d from a range of [0.005, 0.02]. For \lambda_adv^l in a range of [0.00005, 0.001], the results are in a range of [42.7%, 43.2%]. We will provide a complete analysis in the revised paper.	I-Reply	I-2	Reply	687
Note that, choosing such hyper-parameters is an open question for domain adaptation tasks.	I-Reply	I-2	Reply	687
We will put this as a future work and we hope that by providing such analysis, it would help the audience better understand the effect of hyper-parameters.	I-Reply	I-2	Reply	687
[line_break_token][line_break_token]Following Tsai, et al CVPR‚Äô18, the source-only performance using VGG is 26.4% and 30.7% on GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes, respectively.	B-Reply	B-3	Reply	687
For the mIoU v.s.	I-Reply	I-3	Reply	687
epoch curve on GTA5-to-Cityscapes, since there is no supervision on the target domain, the performance usually fluctuates as most domain adaptation methods do via adversarial learning.	I-Reply	I-3	Reply	687
In our experiments, the IoUs are [42.6, 42.0, 42.1, 43.2, 42.1] when training for [50, 55, 60, 65, 70] K iterations using a batch size of 1.	I-Reply	I-3	Reply	687
[line_break_token][line_break_token]Although the improvement on SYNTHIA-to-Cityscapes is smaller, we find larger gains on certain categories against Tsai, et al CVPR‚Äô18, such as road (3%), sidewalk (2.2%), and sky (1.5%).	I-Reply	I-3	Reply	687
This is because that the proposed method is designed to overcome domain gaps such as camera pose or field of view via location-independent patch-level alignment.	I-Reply	I-3	Reply	687
Due to this merit of our approach and the ease of integrating our module into any architectures, we believe that it could be beneficial for other tasks (e.g., depth estimation) that also suffer from the similar issues to semantic segmentation.	I-Reply	I-3	Reply	687
[line_break_token][line_break_token]We thank for pointing out related works.	B-Reply	B-4	Reply	687
Different from these methods that mostly focus on the usage of pixel-level domain adaptation (synthesized target images), loss function design, and pseudo label re-training, our work explores a new perspective via patch-level adversarial alignment and the proposed module is general for different architectures or design choices.	I-Reply	I-4	Reply	687
While the performance is competitive compared to these methods, we believe that our contribution is orthogonal to theirs.	I-Reply	I-4	Reply	687
We will add and discuss these papers in the revised paper	I-Reply	I-4	Reply	687

In this paper,  the authors pay attention on the bottleneck in the NAS of its large architecture space which cause low efficiency.	O	O	Review	725
They introduce the multi agent reinforcement learning method to take the neural architecture search as a multi agent reinforcement learning problem.	O	O	Review	725
[line_break_token][line_break_token]Main contribution is :(1) Framing the MAS as a multi agent problem. (	O	O	Review	725
2)Purpose two lightweight implementation. (	O	O	Review	725
3) Presenting 3 new datasets for NAS evaluation to minimize algorithmic over-fitting.	O	O	Review	725
[line_break_token][line_break_token]It seems like that it is the first work to combine multi agent reinforcement learning with NAS, and you have make complete proof about the algorithm's efficiency both mathematically and empirically.	O	O	Review	725
But from the view of multi agent reinforcement learning, there are also some points which make me confused.	B-Review	B-1	Review	725
[line_break_token][line_break_token]The main problem is coordination, and I understand it as the agents in your work aim to get a joint action and the training process of them are independent, but we all know that in multi agent problems, the changing of agent's policy will cause change of the environment, so it will bring the instability, so I want to know that how you deal with the instability or whether the instability influence a lot in your work?	I-Review	I-1	Review	725
Another problem may be not a theoretically problem that I want to know that have you made the guarantee of the consistency of agents' policies when using parallel training (May be the framework in coding process guarantee it ?)	I-Review	I-1	Review	725
or the consistency is unnecessary to talk because it doesn't influence the result?	I-Review	I-1	Review	725
e thank the reviewer for the encouraging and insightful comments.	O	O	Reply	725
We hope the following will address the issues raised.	O	O	Reply	725
[line_break_token][line_break_token]Regarding instability:[line_break_token]Our theoretical guarantees are based on the worst-case scenarios of adversarial losses, which includes potential instabilities in the joint behavior of the agents.	B-Reply	B-1	Reply	725
Indeed, this can be seen as a special form of reward stochasticity, which our algorithm is robust to.	I-Reply	I-1	Reply	725
In practice, we never encounter instabilities during training nor failure in convergence.	I-Reply	I-1	Reply	725
[line_break_token][line_break_token]Regarding, consistency of agents' policies:[line_break_token]If by parallel training the reviewer means training on multiple GPUs, then this is not an issue, as we wait for the full batch step to complete on all GPU cards before computing the reward, i.e. the coordination is synchronized and therefore the agents' policies are consistent.	I-Reply	I-1	Reply	725
Please let us know if we misunderstood the question	I-Reply	I-1	Reply	725

This paper proposes a novel advantage estimate for reinforcement learning based on estimating the extent to which past actions impact the current state.	O	O	Review	169
More precisely, the authors train a classifier to predict the action taken k-steps ago from the state at time t, the state at t-k and the time gap k. The idea is that when it is not possible to accurately predict the action, the action choice had no impact on the current state, and thus should not be assigned credit for the current reward, they refer to this as the "independence property" between current action and future states.	O	O	Review	169
Based on this idea, the authors introduce a "dependency factor", using the ratio P(s_{t+k},a_{t+k}|s_t,a_t)/P(s_{t+k},a_{t+k}|s_t).	O	O	Review	169
They later show that this can be reworked using Bayes theorem into a ratio of the form P(a_t|s_t,s_{t+k})/\pi(a_t|s_t) which is more convenient to estimate.	O	O	Review	169
The authors show mathematically that, when the dependency factor is computed with the true probabilities and use to weight each reward in a trajectory, the result is an unbiased advantage estimator.	O	O	Review	169
Importantly the expectation, in this case, is taken over trajectories sampled according to the policy pi conditioned only on S_t.	O	O	Review	169
This is distinct from the Monte-Carlo estimator which is based only on samples in which A_t, the action whose advantage is being estimated, was selected.	O	O	Review	169
[line_break_token][line_break_token]They go on to say that this estimator will tend to have lower variance than the conventional Monte-Carlo estimator when future rewards are independent of current actions.	O	O	Review	169
However, the variance can actually be higher, due to the importance sampling ratio used, when future rewards are highly dependent on the current action.	O	O	Review	169
They propose a method to combine the two estimators on a per reward while maintaining unbiasedness using a control variate style decomposition.	O	O	Review	169
This introduces a tunable reward decomposition parameter which determines how to allocate each reward between the two estimators.	O	O	Review	169
The authors propose a method to tune this parameter by approximately optimizing an upper bound on the variance of the combined estimator.	O	O	Review	169
[line_break_token][line_break_token]As a final contribution, the authors introduce a temporal-difference method of estimating the action probability P(a_t|s_t,s_{t+k}) required by their method.	O	O	Review	169
[line_break_token][line_break_token]In the experiments, the authors provide empirical evidence that various aspects of their proposed method can work as suggested on simple problems.	O	O	Review	169
They also provide a simple demonstration where their advantage estimator is shown to improve sample efficiency in a control problem.	O	O	Review	169
[line_break_token][line_break_token]This paper suffers from moderate clarity issues, but I lean toward acceptance primarily because I feel that the central idea is a solid contribution.	O	O	Review	169
The idea of improving credit assignment by explicitly estimating how much actions impact future states seems reasonable and interesting.	O	O	Review	169
The temporal difference method introduced for estimating P(a_t|s_t,s_{t+k}) is also interesting and clever.	O	O	Review	169
I'm less confident in the introduced method for trading off between the Monte Carlo and importance sampling estimators.	O	O	Review	169
The experiments seem reasonably well executed and do a fair job of highlighting different aspects of the proposed method.	O	O	Review	169
[line_break_token][line_break_token]The derivation of the combined estimator was very confusing to me.	B-Review	B-1	Review	169
It's strange that the derivation of the variance lower bound includes terms which are drawn from both a state conditional and state-action conditional trajectory.	I-Review	I-1	Review	169
You're effectively summing variances computed with respect to two different measures, but the quantity being bounded is referred to as just the "variance of the advantage estimator".	I-Review	I-1	Review	169
What measure is this variance supposed to be computed with respect to?	I-Review	I-1	Review	169
Especially given that as written the two estimators rely on samples drawn from two different measures.	I-Review	I-1	Review	169
It doesn't help that the advantage estimator whose variance is being constructed is never explicitly defined but just referred to as "advantage estimator derived from equation 3".	I-Review	I-1	Review	169
Nevertheless, if we ignore the details of what exactly it is a lower bound of, the sum of the three variances in equation 5 seems a reasonable surrogate to minimize.	I-Review	I-1	Review	169
[line_break_token][line_break_token]Related to the above point I don't fully understand what the variances shown in table 1 mean in the experiments section.	B-Review	B-2	Review	169
For the IAE estimator for example, is the variance computed based on each sample using three independent trajectories (one for each term) or is it computed from single trajectories?	I-Review	I-2	Review	169
If it's from single trajectories I can't understand how the expression would be computed.	I-Review	I-2	Review	169
[line_break_token][line_break_token]Questions for the authors:[line_break_token]-Could you please explicitly define the "advantage estimator derived from equation 3"?	B-Review	B-1	Review	169
[line_break_token]-Could you please explain precisely how the variance is computed in table 1?	B-Review	B-2	Review	169
[line_break_token][line_break_token]Update:[line_break_token][line_break_token]Having read the other reviews and authors response I will maintain my score of a weak accept, though given more granularity I would raise my score to a 7 after the clarifications.	O	O	Review	169
I appreciate the authors' clarification of the advantage estimator and feel the related changes to the paper are very helpful.	O	O	Review	169
I still feel the central idea of the work is quite strong.	O	O	Review	169
[line_break_token][line_break_token]However, I also feel the control variate part of the work is very loosely specified.	B-Review	B-3	Review	169
In particular, given the use of function approximation in practice instead of actually sampling 3 trajectories the validity of the control variate method applied is questionable.	I-Review	I-3	Review	169
As the authors say "if the random variable in either term has high variance, function approximators will tend to have large error", This may be true initially but the function approximator can already reduce variance over time by learning, so it's not clear how the function approximators and control variate complement each other.	I-Review	I-3	Review	169
This is something I feel would be worthwhile to explore more in future work.	I-Review	I-3	Review	169
[line_break_token][line_break_token]Also, I feel it's worth pointing out that a concurrent paper presenting a very similar idea is scheduled to be presented at NeurIPS 2020, which can be found here: <a href="https://papers.nips.cc/paper/9413-hindsight-credit-assignment."	O	O	Review	169
target="_blank" rel="nofollow">https://papers.nips.cc/paper/9413-hindsight-credit-assignment.</a> I don't feel this in any way undermines the contribution of the work presented here, but merely wanted to make the meta reviewer aware in case it was relevant to their decision.	O	O	Review	169
In fact, I feel this work complements that one in a number of ways, including the presentation of the temporal difference method for learning the action probabilities.	B-Review	B-4	Review	169
hank you so much for your supportive comments.	O	O	Reply	169
In the following sections, we will give response to two questions you have.	O	O	Reply	169
Please let us know if you have any questions in the response.	O	O	Reply	169
[line_break_token] [line_break_token][Define the "advantage estimator derived from equation 3‚Äù][line_break_token] [line_break_token]We are sorry that we didn't clearly define the advantage estimator without function approximations.	B-Reply	B-1	Reply	169
In our updated version of paper, the advantage estimator is defined formally, based on one assumption that we can sample multiple trajectories on the same state.	I-Reply	I-1	Reply	169
If three samples are individually sampled in every expectation term in equation (3), we are able to define an advantage estimator with the variance in the same form as equation (5) in the old version of paper, except that the factor is 1.	I-Reply	I-1	Reply	169
The rest of discussions, which focuses on how to minimize the variance, will not be affected by this change.	I-Reply	I-1	Reply	169
[line_break_token] [line_break_token]If we consider the problem practically, since we cannot sample multiple trajectories from the same state, we must use function approximators to represent some of values in equation (3).	I-Reply	I-1	Reply	169
That doesn't mean it is unnecessary to consider the variance in either of three terms: if the random variable in either term has high variance, function approximators will tend to have large error.	I-Reply	I-1	Reply	169
Thus practically, we think that using the sum of three variances as a surrogate objective will be a reasonable choice.	I-Reply	I-1	Reply	169
[line_break_token] [line_break_token][How variance is computed in table 1][line_break_token] [line_break_token]We are sorry that we didn‚Äôt clearly mention this.	B-Reply	B-2	Reply	169
For all three methods, we estimate the advantage function of the same state-action pair.	I-Reply	I-2	Reply	169
For IAE, we individually sample three trajectories for each estimation of, one starting from and two starting from s, and use these three trajectories to compute the three terms in equation (3).	I-Reply	I-2	Reply	169
We have added these details to the experiment section in the updated version of our paper	I-Reply	I-2	Reply	169

The authors propose a new neural network model, called as Dissimilarity Network, to improve the few-shot learning accuracy.	O	O	Review	295
[line_break_token]Overall the idea is well motivated that by emphasizing the difference among classes, the model can achieve more accurate predictions for classes where only limited data points are available for training.	O	O	Review	295
[line_break_token]However, the paper is not quite well written.	O	O	Review	295
[line_break_token]Firstly, much of the work is built upon previous work including attention mechanisms, episodic training for few-shot learning.	B-Review	B-1	Review	295
Such components are the core of this work because the attention mechanisms implement the class-awareness, and the episodic training facilitates the LSTM structure.	I-Review	I-1	Review	295
Yet these are not well explained and not much context is provided, thus making the paper hard to follow.	I-Review	I-1	Review	295
[line_break_token]Secondly, some terms are fairly overloaded, or not clearly defined.	B-Review	B-2	Review	295
For example, the ‚Äúprior‚Äù as mentioned in both the abstract and the introduction doesn‚Äôt refer to the commonly interpreted term as in the Bayesian settings, but rather as a hand-waiving term to indicate the model design.	I-Review	I-2	Review	295
Also, the terms, ‚Äúscore‚Äù, ‚Äúmetric‚Äù, ‚Äúdissimilarity‚Äù are mentioned in the paper but the paper is not really learning the metric, to my understanding.	I-Review	I-2	Review	295
Thus the details of the paper is quite hard to grasp.	I-Review	I-2	Review	295
[line_break_token]Lastly, the idea of designing the global embedding and the task aware embedding is interesting but shouldn‚Äôt really be restricted to few-shot learning.	B-Review	B-3	Review	295
It would be interesting to test the idea on general classification tasks, for example in a simple cross validation settings.	I-Review	I-3	Review	295
[line_break_token]Thus I think the paper would be stronger if the above are addressed and it‚Äôs not ready for publishing yet in its current form.	O	O	Review	295
[line_break_token][line_break_token]Below are some more detailed comments:[line_break_token]1)[tab_token]In the abstract, the ‚Äúnewly introduced dataset H-CIFAR‚Äù is not precise to me; my understanding is that the paper proposes such an experiment design for testing how well a classifier can predict the labels with hierarchy.	B-Review	B-4	Review	295
The current writing refers to that the authors comprises a completely new dataset with new labels.	I-Review	I-4	Review	295
[line_break_token]2)[tab_token]In the last sentence of the second paragraph in Introduction, the question is asked ‚Äúwhat prior‚Äù should be reasonable.	B-Review	B-6	Review	295
Since the authors didn‚Äôt really add any priors in a Bayesian settings but rather designed an architecture, I suggest to reword something like ‚Äúhow to explicitly encode hierarchies into the model structure‚Äù.	I-Review	I-6	Review	295
[line_break_token]3)[tab_token]In Section 2.1, some more description for ‚Äúepisodic training‚Äù would be nice: why should it be used?	B-Review	B-7	Review	295
How is it used and why it makes sense in the few-shot learning context?	I-Review	I-7	Review	295
[line_break_token]4)[tab_token]In Section 2.2, it would be nice to add the mathematical definition of ‚Äúprototype‚Äù.	B-Review	B-8	Review	295
[line_break_token]5)[tab_token]In Section 2.2.1, it would be nice to define ‚ÄúH‚Äù.	B-Review	B-9	Review	295
[line_break_token]6)[tab_token]In Section 2.2.2, is M required to be fixed given it‚Äôs episodic training?	B-Review	B-10	Review	295
Also it would be nice to add more details about the attention mechanism.	I-Review	I-10	Review	295
[line_break_token]7)[tab_token]In the result section, it would be nice to discuss when the proposed method is doing better than other methods, for example RelationNet, as well as when it‚Äôs worse since different datasets show different results.	B-Review	B-5	Review	295
[line_break_token]	O	O	Review	295
hanks for taking the time to review our paper.	O	O	Reply	295
[line_break_token][line_break_token][line_break_token]Explanation about Components[line_break_token]---[line_break_token]We have updated the manuscript to include more explanation about the methods that we rely upon.	B-Reply	B-1	Reply	295
[line_break_token][line_break_token][line_break_token]Terms &amp; Similarity Learning[line_break_token]---[line_break_token]We have updated the manuscript to use more appropriate terms: inductive bias and similarity learning.	B-Reply	B-2	Reply	295
[line_break_token][line_break_token]Our method adopts the approach of similarity learning.	I-Reply	I-2	Reply	295
Instead of learning a distance or similarity function, we learn a space (embedding) that works well with a fixed similarity-based classifier in that space.	I-Reply	I-2	Reply	295
Specifically, our model learns to construct a space that is optimized to separate data that belong to different classes for a classifier that uses dot-product as its similarity function.	I-Reply	I-2	Reply	295
[line_break_token][line_break_token][line_break_token]Application on General Classification Tasks[line_break_token]---[line_break_token]In the usual classification tasks, the labels are fixed during the training and testing.	B-Reply	B-3	Reply	295
Our approach is advantageous if the labels are changing between task -- as in few-shot classification.	I-Reply	I-3	Reply	295
[line_break_token][line_break_token][line_break_token]Detailed Comments[line_break_token]---[line_break_token]We have updated our manuscript based on the above comments.	B-Reply	B-4	Reply	295
We also updated the name of our harder variant of CIFAR dataset to CIFAR-Hard to avoid confusion -- as CIFAR is already hierarchically labeled.	I-Reply	I-4	Reply	295
For point (1), it‚Äôs true that our new dataset can be seen through the lens of experiment design.	I-Reply	I-4	Reply	295
However, it‚Äôs also true that the dataset is new, in a sense that the dataset comprises of a new set of image label pairs, with the label derived from the original CIFAR.	I-Reply	I-4	Reply	295
[line_break_token][line_break_token][line_break_token]Results &amp; Discussions[line_break_token]---[line_break_token]We have added more discussion about the results in the manuscript.	B-Reply	B-5	Reply	295
Please have a look at the updated manuscript.	I-Reply	I-5	Reply	295

The paper discusses connections between the properties of DNN loss surfaces and the step length SGD algorithms take, a timely topic.	O	O	Review	458
 On the whole, reasonably well done, with some interesting observations.	O	O	Review	458
[line_break_token][line_break_token]It makes several claims, most notably that there is an initial regime where SGD visits increasingly sharp regions of the loss surface, followed by a regime where the loss surface gets smoother.	O	O	Review	458
 Useful to know, and characterized moderately well.	O	O	Review	458
[line_break_token][line_break_token]A weakness is that the generality of that claim is not made clear.	B-Review	B-1	Review	458
 Like many papers in the area, it is an observation, the realm of which is not clarified.	I-Review	I-1	Review	458
 E.g., what properties of the neural network or data does it depend on.	I-Review	I-1	Review	458
 Also not clarified is how this depends on initialization, etc.	I-Review	I-1	Review	458
[line_break_token][line_break_token]The evaluation should be more systematic, as it is hard to tell how general is the claims of the paper as well as how they depend on implementation details.	B-Review	B-2	Review	458
[line_break_token] [line_break_token]The discussion of Hessian directions ignores very relevant work by Yao et al (<a href="https://arxiv.org/abs/1802.08241" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.08241</a> and follow up).	O	O	Review	458
[line_break_token][line_break_token]The first figure in Fig 1 is probably misleading, and probably not worth having, the latter two are what is measured and thus more interesting.	B-Review	B-4	Review	458
[line_break_token][line_break_token]The obvious conclusion from the poor conditioning is that methods designed to addressed poor conditioning, i.e., second order methods, should be considered.	B-Review	B-5	Review	458
 Those should have a complementary dynamics to what is discussed.	I-Review	I-5	Review	458
 This is what is the elephant in the room when you talk about steering towards or away from regions whose curvature matches the SGD step.	I-Review	I-5	Review	458
[line_break_token][line_break_token]I don't know what it means to say "Where applicable, the Hessian is estimated with regularization applied"  Is this to speed up computation, why doesn't this change the loss surface, etc.	B-Review	B-6	Review	458
 If you are not measuring Hessian information precisely, then all the claims of the paper fall apart.	I-Review	I-6	Review	458
[line_break_token][line_break_token]Several times claims like "SGD reaches a region in which the SGD step matches ..."  Of course, the energy surface changes with training time, so it is a little unclear what is being said.	B-Review	B-7	Review	458
[line_break_token][line_break_token]The main method Nudged-SGD sounds like a poor-mans second order method.	B-Review	B-8	Review	458
 Why not describe it as such (in more than a footnote and appendix), rather than introducing a new acronym.	I-Review	I-8	Review	458
 I don't know that I believe the "key design principle" in the appendix for second order methods.	I-Review	I-8	Review	458
 Second order methods rotate and stretch to take a locally-correct step length, and this method sounds like it is doing a poor mans version of that.	I-Review	I-8	Review	458
 There is a good question as to whether the "thresholding" into large and small that NSGD is doing causes it to do something very different, but that isn't really evaluated.	I-Review	I-8	Review	458
[line_break_token][line_break_token]Averaging over two random seeds is not a lot.	B-Review	B-9	Review	458
[line_break_token]	O	O	Review	458
We thank the reviewer for his valuable comments.	O	O	Reply	458
Based on yours and other reviewers‚Äô remarks we run additional experiments using Adam, different initialization schemes  and on data from a sentence classification task.	O	O	Reply	458
We summarized them in <a href="https://goo.gl/yYM1DG," target="_blank" rel="nofollow">https://goo.gl/yYM1DG,</a> and would be happy to add them to the paper.	O	O	Reply	458
We will address now each point in order.	O	O	Reply	458
[line_break_token][line_break_token]* On generality *[line_break_token]On the whole, our experiments were run on CIFAR-10 and PTB as described  in the main text, and CIFAR-100 and Fashion-MNIST as descibed in the Appendix.	B-Reply	B-1	Reply	458
We also experimented with 4 models (Resnet-32, SimpleCNN, VGG, and LSTM).	I-Reply	I-1	Reply	458
We therefore believe that our main results describing how the Hessian behaves along the optimization trajectory were  supported by a reasonable (compared to similar papers in the domain) set of settings.	I-Reply	I-1	Reply	458
Please also note that related results were observed in concurrent ICLR submissions [1], [2] and [3]. In particular [2] shows that indeed a measure of curvature (Fisher Information) closely related to the Hessian grows initially very quickly - which confirms some of our observations in 3.1.	I-Reply	I-1	Reply	458
[line_break_token][line_break_token]Having said that we fully agree that extending the analysis to different initialization and dataset dependence would be desirable.	I-Reply	I-1	Reply	458
We rerun similar analysis to 3.1 using Adam, different initialization (we compared uniform to normal, with different scaling) and on IMDB (a sentence classification task).	I-Reply	I-1	Reply	458
These experiment corroborate our main finings.	I-Reply	I-1	Reply	458
[line_break_token][line_break_token]* Extending results to second order methods *[line_break_token]We fully agree that investigating second order methods would be very interesting.	B-Reply	B-5	Reply	458
Based on your remark as the first step towards this direction we rerun some of the experiments using Adam, see <a href="https://goo.gl/yYM1DG."	O	O	Reply	458
target="_blank" rel="nofollow">https://goo.gl/yYM1DG.</a> On the whole the main focus of the paper is on SGD, and thus a more extensive study perhaps should left for future work.	O	O	Reply	458
[line_break_token][line_break_token]Hessian and regularization.	B-Reply	B-5	Reply	458
We apologize for the unclear formulation.	I-Reply	I-5	Reply	458
We wanted to say, that we used regularization when computing the Hessian (e.g. including L2 terms, or sampling dropout mask) if this was also done for computing the loss  uring optimization.	I-Reply	I-5	Reply	458
In this sense we get a  more *realistic* estimate and this choice has *no bearing on the computation speed*. We will make this more clear in the revised version of the manuscript.	I-Reply	I-5	Reply	458
[line_break_token][line_break_token]What does ‚ÄúSGD matches curvature‚Äù mean.	I-Reply	I-5	Reply	458
Let us clarify what we mean by the phrase that SGD finds a region where its steps matches the curvature.	I-Reply	I-5	Reply	458
Consider projecting SGD step onto the directions corresponding to the largest eigenvalues of the Hessian.	I-Reply	I-5	Reply	458
Our claim is that along these directions the projection is too large to reduce the loss.	I-Reply	I-5	Reply	458
Visually, SGD step crosses the minima in the subspace spanned by the sharpest directions.	I-Reply	I-5	Reply	458
Please also see Fig.1 for an illustration.	I-Reply	I-5	Reply	458
We agree that wording is confusing, and we will formulate this in the revised version.	I-Reply	I-5	Reply	458
[line_break_token][line_break_token]*NSGD as a poor-mans second order *[line_break_token]We agree that NSGD is a second order method in the sense that it uses second order information to adapt the step-size.	B-Reply	B-8	Reply	458
It is different from typical second order methods in that it does not seek to minimize loss along the sharpest directions.	I-Reply	I-8	Reply	458
Instead, NSGD step typically crosses over the minima along the sharpest direction, just like in the case of SGD (in the sense as depicted in Fig.	I-Reply	I-8	Reply	458
1, and as discussed in the last Appendix).	I-Reply	I-8	Reply	458
To further clarify - the goal of this section was to investigate importance of SGD dynamics along the sharpest directions.	I-Reply	I-8	Reply	458
We did not seek to prove NSGD is a better optimizer than other second order methods, which is why we were inadvertently brief in the discussion about how it differs from other second order methods.	I-Reply	I-8	Reply	458
 We will clarify all of this and in particular note that NSGD is a specific form of a second order method.	I-Reply	I-8	Reply	458
[line_break_token][line_break_token]* Other points *[line_break_token]Thank you for pointing us to Yao et al We will add a discussion of Yao et al to ‚ÄòRelated work‚Äô.	B-Reply	B-3	Reply	458
[line_break_token][line_break_token]You mentioned that Fig.	B-Reply	B-4	Reply	458
1 is not useful.	I-Reply	I-4	Reply	458
In general, we would like to keep an intuitive depiction of the main findings.	I-Reply	I-4	Reply	458
Please let us know if you have any suggestions how to improve Fig.	I-Reply	I-4	Reply	458
1.	B-Reply	B-1	Reply	458
[line_break_token]---[line_break_token][line_break_token]Thank you again for your valuable comments, and we will update the manuscript shortly.	O	O	Reply	458
[line_break_token][line_break_token][1] Gradient Descent Happens in a Tiny Subspace, <a href="https://openreview.net/forum?id=ByeTHsAqtX" target="_blank" rel="nofollow">https://openreview.net/forum?id=ByeTHsAqtX</a>[line_break_token][2] Critical Learning Periods, <a href="https://openreview.net/forum?id=BkeStsCcKQ&noteId=BkeStsCcKQ" target="_blank" rel="nofollow">https://openreview.net/forum?id=BkeStsCcKQ&noteId=BkeStsCcKQ</a>[line_break_token][3] A Walk with SGD: How SGD Explores Regions of Deep Network Loss?,	O	O	Reply	458
<a href="https://openreview.net/forum?id=B1l6e3RcF7&noteId=BylzRFgP2Q" target="_blank" rel="nofollow">https://openreview.net/forum?id=B1l6e3RcF7&noteId=BylzRFgP2Q</a>[line_break_token][line_break_token]EDIT: We updated now the manuscript and added a summary of the experiments with a more careful analysis of NSGD results on IMDB.	O	O	Reply	458

The paper is easy to read and the presentation is clear, and I really appreciate this.	O	O	Review	1063
[line_break_token][line_break_token]The authors address the very important topic of feature extraction and state representation learning.	O	O	Review	1063
New results in this area are always valuable and welcome.	O	O	Review	1063
However, my feeling is that the paper falls short in terms of making sufficient new contributions for an ICLR paper.	O	O	Review	1063
[line_break_token][line_break_token]1.	O	O	Review	1063
The authors propose to learn a state representation by either training using a combined loss function, or training several representations using multiple loss functions followed by stacking.	B-Review	B-1	Review	1063
These are standard and well-known techniques in machine learning.	I-Review	I-1	Review	1063
The key contribution one looks for is in terms of new insights on why and when each approach works.	I-Review	I-1	Review	1063
The paper fails to provide much insight in this regard.	I-Review	I-1	Review	1063
Take this simple scenario: Suppose my input image is actually generated by a linear map plus gaussian noise on the true states.	I-Review	I-1	Review	1063
Then I can simply use a PCA as my "auto encoder" and happily learn a high quality state representation close to the ground truth.	I-Review	I-1	Review	1063
We know why this works.	I-Review	I-1	Review	1063
In the real task, the image is a complex non-linear transformation of the true states.	I-Review	I-1	Review	1063
What insights do I gain from this work in terms of how I should tackle this?	I-Review	I-1	Review	1063
[line_break_token][line_break_token]2.	O	O	Review	1063
Section 3 states some desirable characteristics in constructing a state representation.	B-Review	B-2	Review	1063
These are well-known and fundamental aspects of machine learning -- applicable to almost all models that we want to learn.	I-Review	I-2	Review	1063
In this sense, I do not find the section very informative.	I-Review	I-2	Review	1063
[line_break_token][line_break_token]3.	O	O	Review	1063
The empirical results (say, Table 1) seem too noisy to interpret (other than that using the ground truth provides the best performance).	B-Review	B-3	Review	1063
It almost seems to suggest that one should simply use random features (as done in the "extreme learning machine" approach).	I-Review	I-3	Review	1063
Again, not much insight to draw from this.	I-Review	I-3	Review	1063
[line_break_token][line_break_token]4.	O	O	Review	1063
Last comment.	B-Review	B-4	Review	1063
Suppose I have a new robotic goal-directed task and my inputs are camera images.	I-Review	I-4	Review	1063
Does this work tell me something that I don't already know in terms of learning new feature representation that is highly suitable for my task?	I-Review	I-4	Review	1063
[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Review	1063
[line_break_token]Dear reviewer,[line_break_token]Thank you for your remarks!	O	O	Reply	1063
[line_break_token][line_break_token]1.	O	O	Reply	1063
We indeed do not have strong theoretical result on the applicability of our approach, however, we provide some insight about the way of performing efficient state representation learning in the case of goal based tasks.	B-Reply	B-1	Reply	1063
 In particular, we highlight the fact that auto-encoder based approaches and approaches based on action or next state prediction have complementary strengths that need to be combined to achieve good performances.	I-Reply	I-1	Reply	1063
The use of GTC metrics also provides better understanding of what was learned by the SRL methods and we show that this is a good proxy for the final RL performance.	I-Reply	I-1	Reply	1063
[line_break_token][line_break_token]Although the idea of "stacking" models is not new, this is, to the best of our knowledge, the first work proposing stacking for learning a disentangled state representation.	I-Reply	I-1	Reply	1063
[line_break_token][line_break_token][line_break_token]2.	O	O	Reply	1063
We agree the desirable aspects are common sense.	B-Reply	B-2	Reply	1063
We wanted to give more context, as it is still important for us to clarify what we are looking for before proposing any solution.	I-Reply	I-2	Reply	1063
Following your remark, we reduced this section size to give more space for the technical description of our approach.	I-Reply	I-2	Reply	1063
[line_break_token][line_break_token][line_break_token]3.	O	O	Reply	1063
Table 1 should not be used alone.	B-Reply	B-3	Reply	1063
It only gives insights about the "sufficiency" of each method using a large budget (5 Millions steps).	I-Reply	I-3	Reply	1063
One should look at additional tables (with different time-steps budgets) along with the ground truth correlation (GTC, i.e., what was learned, is the representation interpretable?).	I-Reply	I-3	Reply	1063
[line_break_token]Indeed, the evaluation of random features in comparison with other SRL approaches is one of our interesting results and we consider it as a good baseline versus end-to-end learning.	I-Reply	I-3	Reply	1063
Nevertheless, the first contribution of the paper is to advocate for the decoupling of policy learning from feature extraction.	I-Reply	I-3	Reply	1063
We hypothesize that random features should work in environments where visual observations are simple enough, and random features can preserve enough information (cf GTC tables).	I-Reply	I-3	Reply	1063
[line_break_token]Following your remark, we updated the experiment and intro sections to clarify our results.	I-Reply	I-3	Reply	1063
[line_break_token][line_break_token]4.	O	O	Reply	1063
Good question.	B-Reply	B-4	Reply	1063
First, if you adopt reinforcement learning, this work should incite you to use a SRL model instead of learning the policy end to end.	I-Reply	I-4	Reply	1063
Our study will also help you choose the objective function: it is important to combine several objectives; using an inverse model or an auto-encoder alone is usually not sufficient.	I-Reply	I-4	Reply	1063
Finally, it gives you hints on the choice and effects of the different hyper-parameters: what state dimension is required, how many samples are needed, how to evaluate the learned states (using GTC as a proxy for RL performance) or how to choose the weights when combining objectives (and insights on the influence of changing the weights)	I-Reply	I-4	Reply	1063

Summary[line_break_token]The paper describes using the technique of modifying the weights for the outer layers, used in teacher-student network for same task, to transfer learning for different tasks by modifying the loss function and pre-training using target network labels to emphasize the neurons that are considered important for prediction.	O	O	Review	562
The technique seems to be no more/slightly better than the Lsquare SP, but exceeds when used with attention.	O	O	Review	562
[line_break_token][line_break_token]Improvements[line_break_token]- the amount of training time needed to pre-train using the L-square FE and target labels should be mentioned as it seems that for large network, and large data, this can be a factor[line_break_token]- The choice of Resnet, at least one of the more recent networks for object detection (Inception, YOLO etc.)	B-Review	B-1	Review	562
 would be a good add	B-Review	B-2	Review	562
Thank you for your review and encouraging comments.	O	O	Reply	562
We summarize Reviewer 1‚Äôs major concerns as following two questions and we try to respond these two answers accordingly.	O	O	Reply	562
[line_break_token][line_break_token]Q1. ‚	O	O	Reply	562
Äúthe amount of training time needed to pre-train using the L-2 FE and target labels should be mentioned as it seems that for large network, and large data, this can be a factor‚Äù[line_break_token][line_break_token]Response: Thanks for the comment.	O	O	Reply	562
We totally agree that the time-consumption of L2-FE adaption and attention learning should be considered as the overhead of our method.	B-Reply	B-1	Reply	562
Indeed, the time spent by L2-FE adaption and attention learning is no more than 50% of overall training time.	I-Reply	I-1	Reply	562
 For example, DELTA (w/o Attention) requires 139 minutes on Caltech30 task transferring from Resnet-101 pre-trained model, while DELTA (with Attention) consumes 197 minutes (42% more than DELTA w/o Attention which doesn‚Äôt need L2-FE adaption and attention learning).	I-Reply	I-1	Reply	562
Furthermore, L2-SP takes124 minutes and L2 spends 115 minutes on the same task in the same settings.	I-Reply	I-1	Reply	562
It is thus reasonable to conclude the extra time consumption on L2-FE adaption and attention learning does not add a significant overhead to common deep transfer learning practices.	I-Reply	I-1	Reply	562
[line_break_token][line_break_token]When we further breakdown such time overhead, we found that the major overhead is due to the attention learning, where for each filter forward inference is needed to estimate the contribution of such filter to the overall accuracy.	I-Reply	I-1	Reply	562
It should not be a significant performance bottleneck even for a large dataset, as the number of filters needed to evaluate might be fixed with given scratch for transfer learning.	I-Reply	I-1	Reply	562
 Note that one key contribution made in this manuscript is to improve the deep transfer learning via feature-map based regularization through introducing attention mechanism.	I-Reply	I-1	Reply	562
All in all, many thanks for your comments.	I-Reply	I-1	Reply	562
We are revising the manuscript, including the discussion on time consumption, accordingly.	I-Reply	I-1	Reply	562
[line_break_token][line_break_token]Q.2 The choice of Resnet, at least one of the more recent networks for object detection (Inception, YOLO etc.)	O	O	Reply	562
 would be a good add[line_break_token][line_break_token]Response: Thanks for comments.	O	O	Reply	562
We agree to incorporate more results and neural network architectures.	B-Reply	B-2	Reply	562
We are revising the manuscript with supplementary experiments on both new architecture (inception v3) and datasets(CUB-200-2011[1], Food-101[2]).	I-Reply	I-2	Reply	562
The results of above experiments will be reported in our new version.	I-Reply	I-2	Reply	562
[line_break_token][line_break_token][1] C.Wah,S.Branson,P.Welinder,P.Perona,andS.Belongie.	O	O	Reply	562
The caltech-ucsd birds-200-2011 dataset.	O	O	Reply	562
California Institute of Technology, 2011.	O	O	Reply	562
6, 7, 8[line_break_token][2] L. Bossard, M. Guillaumin, and L. Van Gool.	O	O	Reply	562
Food-101‚Äìmining discriminative components with random forests.	O	O	Reply	562
In ECCV, 2014.	O	O	Reply	562
6, 8	O	O	Reply	562

The authors apply neural architecture search techniques to the problem of physics based learning.	O	O	Review	566
It is interesting because it cleverly tackles the challenge of manually designing priors and network architectures.	O	O	Review	566
The results are also impressive as the proposed method surpasses all the considered baselines.	O	O	Review	566
Despite of the above upsides, I have the following questions/concerns.	O	O	Review	566
[line_break_token]1.	B-Review	B-1	Review	566
There is limited technical novelty as the entire method is mainly based on previous work on neural architecture search.	I-Review	I-1	Review	566
Nevertheless, it might be helpful to have some ablation study to show the improvement of the task-specific adaptations presented in the paper, with which I believe this could be a good paper on the application side.	I-Review	I-1	Review	566
[line_break_token]2.	O	O	Review	566
I'm curious about the performance of the baseline methods given the same amount of computation.	B-Review	B-2	Review	566
For example, is it possible to perform intensive hyperparameter tuning for the baselines to also obtain improvement.	I-Review	I-2	Review	566
It seems that the authors did not discuss the computational costs and whether different methods are compared given the same cost.	I-Review	I-2	Review	566
hank you for your detailed review.	O	O	Reply	566
[line_break_token][line_break_token]Q1: Ablation Study (Comparison with NAS without Task-specific Adaptations)[line_break_token]A1: We have added such a comparison.	B-Reply	B-1	Reply	566
The added experiment results in Appendix Section D and Fig.13  justify that our task-specific adaptations significantly boost the performance.	I-Reply	I-1	Reply	566
The details about task-specific adaptations and our novelty in merging NAS with PBL are in reply ‚ÄòGeneral reply about Novelty in merging NAS with PBL‚Äô.	O	O	Reply	566
[line_break_token][line_break_token]Q2: Intensive hyperparameter tuning for the baselines.	O	O	Reply	566
[line_break_token]A1: In our previous submission, we have tuned the hyperparameters for perfecting the baseline performance.	B-Reply	B-2	Reply	566
We now make it clearer by adding illustrations in ‚ÄòTraining details‚Äô, Section 4.3.	I-Reply	I-2	Reply	566
The illustrations are ‚ÄòMoreover, for all baseline approaches we compare in this paper, we fine-tune their hyperparameters in order to make fair comparisons.	I-Reply	I-2	Reply	566
We choose three hyperparameter sets for each scenario and run five times for each method.	I-Reply	I-2	Reply	566
We finally pick out the best result for each method.	I-Reply	I-2	Reply	566
‚Äô   [line_break_token]	O	O	Reply	566

This paper proposes an autoencoder architecture and training procedure for producing high-quality reconstructions and realistic interpolations.	O	O	Review	1001
A "generator" autoencoder is trained to fool a "discriminator" autoencoder.	O	O	Review	1001
The generator tries to minimize its own reconstruction error and minimize the reconstruction error of the discriminator when fed with interpolated latent vectors of real datapoints.	O	O	Review	1001
The discriminator autoencoder has three losses, corresponding to minimizing reconstruction error on real datapoints and maximizing reconstruction error on the generator's output on both real datapoints and interpolated outputs.	O	O	Review	1001
The authors also propose a loss which encourages the distances between real datapoints and their corresponding latent vectors to be similar, as well as a heuristic procedure for stabilizing GAN training.	O	O	Review	1001
Qualitative results are shown on CelebA.[line_break_token][line_break_token]While the results look nice, the paper is not fit for publication in its current form.	O	O	Review	1001
At a high level, the issues include a lack of convincing experimental verification of the method, a generally contradictory and confusing description of the methods, and frequent factual errors or mischaracterizations.	O	O	Review	1001
Here I will try to describe many of the issues I found while reading the paper:[line_break_token]- Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure.	B-Review	B-1	Review	1001
The experimental results are completely qualitative.	I-Review	I-1	Review	1001
No effort is made to provide a quantitative proof of claims such as "the reconstructions are less blurry" or "the interpolations are higher quality"; only a few examples are shown.	I-Review	I-1	Review	1001
The experiments are not even described in the text, and many of the figures are unreferenced.	I-Review	I-1	Review	1001
No ablation studies are done to determine the importance of different loss terms, such as L_dist.	I-Review	I-1	Review	1001
No mention is given to how hyperparameters like alpha should be chosen (and in fact, the value given for it "1^{-4}/2" is nonsense; 1^{-4} is just 1).	I-Review	I-1	Review	1001
No results for a baseline autoencoder (i.e., just optimizing reconstruction loss) are given.	I-Review	I-1	Review	1001
[line_break_token]- At a higher level, no effort is given to argue why interpolation is a useful characteristic to try to encourage.	B-Review	B-2	Review	1001
There are no downstream applications proposed or tested.	I-Review	I-2	Review	1001
Earlier models, such as VAEGAN, also give reasonable reconstructions and good interpolations.	I-Review	I-2	Review	1001
Why is GAIA better?	I-Review	I-2	Review	1001
On what problem would I use GAIA and achieve better results apart from making nice-looking interpolations of people's faces?	I-Review	I-2	Review	1001
[line_break_token]- Definitions are often unclear or contradictory.	I-Review	I-2	Review	1001
For example, the generator autoencoder is alternatingly treating as taking input X and taking input Z. I believe what is meant is that the generator consists of two networks which compute Z = encoder(X) and X = decoder(Z).	I-Review	I-2	Review	1001
Instead, the paper just switches between G(Z) and G(X) wherever convenient.	I-Review	I-2	Review	1001
Similarly, the equation for \delta_Disc is different in Algorithm 1 and in the equation in 2.2.	I-Review	I-2	Review	1001
Interpolation, arguably one of the core parts of the model, is described as "interpolations are Euclidean interpolations between pairs of points in Z, sampled from a Gaussian distribution around the midpoint between Zg1en and Zg2en."	I-Review	I-2	Review	1001
I assume the mean of this Gaussian is the midpoint; what is its covariance?	I-Review	I-2	Review	1001
Etc.	I-Review	I-2	Review	1001
[line_break_token]- All autoencoders are not generative models, and in particular GAIA is not a generative model.	B-Review	B-3	Review	1001
There is no generative process.	I-Review	I-3	Review	1001
It does not estimate a data distribution.	I-Review	I-3	Review	1001
A VAE is a generative model which an autoencoder-like structure, but this does not make all autoencoders generative models.	I-Review	I-3	Review	1001
[line_break_token]- GAIA is described as encouraging "convex latent distributions" and a convex set is defined in the text as "A convex set of points is defined as a set in which the line connecting any pair of points will fall within the rest of the set."	B-Review	B-4	Review	1001
A convex set is not defined in terms of lines; it's defined in terms of convex combinations of points within the set.	I-Review	I-4	Review	1001
In the paper, only lines between points are considered.	I-Review	I-4	Review	1001
Claiming that the latent space is "convex" in the sense of purple blobs in B is not done - you would need to take a convex combination of multiple latent vectors and decode the results.	I-Review	I-4	Review	1001
[line_break_token][line_break_token]This is an incomplete list of the issues with this paper.	O	O	Review	1001
The paper would need significant changes before publication.	O	O	Review	1001
Dear reviewer,[line_break_token][line_break_token]We thank you for your comprehensive list of issues raised with the initial submission of our article.	O	O	Reply	1001
We believe we have exhaustively addressed each issue raised by each reviewer in our revised submission.	O	O	Reply	1001
In response to each reviewer, we have divided each review into a point-by-point list of each issue raised followed by our response, pointing to where that issue was addressed in the text.	O	O	Reply	1001
[line_break_token][line_break_token]We have made several major revisions, listed below, as well as a number of other revisions which are addressed point-by-point in response to reviewers.	O	O	Reply	1001
[line_break_token][line_break_token]Major revisions:[line_break_token]As requested by all three reviewers, we added a set of quantitative and ablation experiments on a low dimensional dataset.	O	O	Reply	1001
These experiments can be seen in Figures 2 and 6, as well as Table 1.	O	O	Reply	1001
[line_break_token]We added an experiments section to the text and rearranged the text for structure.	O	O	Reply	1001
[line_break_token]We rewrote sections of the introduction to better motivate our research.	O	O	Reply	1001
[line_break_token]We added a number of relevant references and extended our discussion of related works.	O	O	Reply	1001
[line_break_token]We edited the entire document for consistent notation both internally and to other related papers.	O	O	Reply	1001
[line_break_token][line_break_token]We thank you for the time and energy put into your excellent reviews of our article and believe that our submission has greatly increased in quality because of your input.	O	O	Reply	1001
[line_break_token][line_break_token]________________________________________[line_break_token]"- Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure.	O	O	Reply	1001
The experimental results are completely qualitative.	O	O	Reply	1001
[line_break_token]-------------------------------------------------------[line_break_token]We added a low dimensional dataset example (Figure 2, Table 1, Figure 6), and a quantitative assessment of the likelihood of interpolations and reconstructions, the correlation between latent structure and structure in high dimensional space, and the KL divergence between data and interpolations, as well as data and reconstructions.	B-Reply	B-1	Reply	1001
We compared a VAE, and AE, and GAIA (both with and without the pairwise-distance loss term).	I-Reply	I-1	Reply	1001
[line_break_token][line_break_token]________________________________________[line_break_token]"No effort is made to provide a quantitative proof of claims such as "the reconstructions are less blurry" or "the interpolations are higher quality"; only a few examples are shown.	O	O	Reply	1001
[line_break_token]-------------------------------------------------------[line_break_token]We edited these section and sentences to not make comparative claims.	B-Reply	B-1	Reply	1001
We now show examples in the appendix of reconstructions on several low dimensional datasets.	I-Reply	I-1	Reply	1001
We can add additional interpolation and attribute vector figures in the appendix as well if the reviewer finds it important.	I-Reply	I-1	Reply	1001
[line_break_token][line_break_token]________________________________________[line_break_token]"The experiments are not even described in the text, and many of the figures are unreferenced.	O	O	Reply	1001
[line_break_token]-------------------------------------------------------[line_break_token]We added an experiments section to the text which now includes subsections for both datasets, describing each measure.	B-Reply	B-1	Reply	1001
[line_break_token][line_break_token]________________________________________[line_break_token]"No ablation studies are done to determine the importance of different loss terms, such as L_dist.	O	O	Reply	1001
No mention is given to how hyperparameters like alpha should be chosen[line_break_token]-------------------------------------------------------[line_break_token]We now perform an ablation study by comparing our autoencoder with adversarial regularization, to an autoencoder of the same architecture without regularization.	B-Reply	B-1	Reply	1001
We also ablate L_dist.	I-Reply	I-1	Reply	1001
[line_break_token]	O	O	Reply	1001

This work proposed a new goodness of fit measure for generative network evaluations, which is based on how well the network can generate the training data.	O	O	Review	10206
The measure is zero if the network could perfectly recover the training data, and would represent how far it is from generating the training set in the average manner of the total least square sense, where the one-to-one mapping between the generated data and the training sample is constructed through latent space optimization.	O	O	Review	10206
Using the proposed measure, the authors showed an interesting trend present in the DCGAN training and the impact of the residual connection.	O	O	Review	10206
The authors might want to add some discussion in Section 4.2 regarding why the residual connection is detrimental for covering the support.	O	O	Review	10206
 Increasing the model complexity through larger latent space dimension and learning mixtures is proposed as solutions to improve the measure as well.	O	O	Review	10206
[line_break_token][line_break_token]With all the interesting results presented, I still have the concerns about the sensitivity of the proposed measure:[line_break_token]- It is an average over the training data or the selected sample.	B-Review	B-1	Review	10206
Above Section 4, the authors argued that "\hat{F}(G) &gt; 0 meaning that we do not observe any memorization".	O	O	Review	10206
This seems overly assertive.	B-Review	B-1	Review	10206
Since the measure is an average over the training data, it has difficulty to differentiate between one network which has almost zero value for part of the training data but large values for the rest, and another network with roughly the same \hat{F}(G) value but small values for all training data.	I-Review	I-1	Review	10206
The variance could help, but can not resolve this issue.	I-Review	I-1	Review	10206
This would be more important when the training data contains noise or outliers.	I-Review	I-1	Review	10206
[line_break_token]- It only concerns the generation of the training data, but not the sampled data from the network (at least not directly).	B-Review	B-2	Review	10206
Therefore it has no direct control of the fidelity of the generated samples.	I-Review	I-2	Review	10206
[line_break_token]- As shown by the authors, the proposed measure can be considered as the approximation of the true probability support not covered by the generative models, which also defines a necessary condition to avoid mode collapse.	B-Review	B-3	Review	10206
But what about the other part?	I-Review	I-3	Review	10206
It would have difficulty comparing two models with the same support but different high-density areas.	I-Review	I-3	Review	10206
Indeed, there are existing works which consider both the precision and recall of the generative models [1, 2, 3], and directly work with the generated samples instead of the training data.	I-Review	I-3	Review	10206
These should be discussed and compared with, not just the FID scores which have already been shown to have issues [3]. [line_break_token][line_break_token]Some notations:[line_break_token]- In the last equation on Page 2,  should it be L_{G} instead of L_{D}?	B-Review	B-4	Review	10206
[line_break_token]- In the first equation on Page 3, should the denominator be N_{B} instead of N_{N}?	B-Review	B-5	Review	10206
[line_break_token]- "Optimality" in terms of generative models may depend on the downstream tasks.	B-Review	B-6	Review	10206
I do not think there exists a universal definition of "optimality" for generative models.	I-Review	I-6	Review	10206
[line_break_token][line_break_token][1] M.S.M. Sajjadi, O. Bachem, M. Lucic, O. Bousquet, and S. Gelly.	O	O	Review	10206
Assessing generative models via precision and recall.	O	O	Review	10206
NeurIPS 2018.	O	O	Review	10206
[line_break_token][2] L. Simon, R. Webster, and J. Rabin.	O	O	Review	10206
Revisiting precision and recall definition for generative model evaluation.	O	O	Review	10206
ICML 2019.	O	O	Review	10206
[line_break_token][3] T. Kynkaanniemi, T. Karras, S. Laine, J. Lehtinen, and T. Aila.	O	O	Review	10206
Improved precision and recall metric for assessing generative models.	O	O	Review	10206
Arxiv:1904.06991.	O	O	Review	10206
hank you for the feedback on our paper.	O	O	Reply	10206
We address your concerns as follows:[line_break_token][line_break_token]- It is true that if F&gt;0 then we can still have memorization, because we are taking an average.	O	O	Reply	10206
In practice, this does not happen, as we captured in the histograms of Figure 4 and Figure 8 in the paper.	B-Reply	B-1	Reply	10206
We observe that the distribution of distance is relatively symmetric and unimodal, making the average a very informative measure of memorization.	I-Reply	I-1	Reply	10206
In addition, we are mostly concerned with having complete memorization of the data instead of just partial memorization.	I-Reply	I-1	Reply	10206
For partial memorization scenarios, we agree that variations on our metric (such as minimum distance) could be very useful as well.	I-Reply	I-1	Reply	10206
[line_break_token][line_break_token]- We consider generating the training set as a first step toward understanding important issues like mode collapse.	B-Reply	B-2	Reply	10206
Of course, our measure alone will not be used to directly evaluate the fidelity of generated samples.	I-Reply	I-2	Reply	10206
High fidelity samples are desirable, but if F &gt; 0 for these models, then that means that they are not learning the simplest distribution of all: the empirical distribution.	O	O	Reply	10206
Hence, generative models should have F = 0, which implies that there is no mode collapse with the empirical distribution.	B-Reply	B-2	Reply	10206
[line_break_token][line_break_token]- We are comparing the support of G to the training set only (and not the probability densities), because we are focusing on the simpler, yet necessary, topic of memorization in generative networks.	B-Reply	B-3	Reply	10206
If a generative network cannot learn the training set, then there exists an image x such that the probability of generating x is equal to 0.	I-Reply	I-3	Reply	10206
Thus, a probabilistic distance of x from the distribution of Imag(G) is related to the distance between the image of G and x, which is our approach.	I-Reply	I-3	Reply	10206
[line_break_token][line_break_token]Let us know if you have any further concerns about our paper, and thank you for the helpful feedback	O	O	Reply	10206

This paper tackles the problem of compressing trained convnets with the goal of reducing memory overhead and speeding up the forward pass.	O	O	Review	324
As I understand it, the main contribution of this work is to develop fast convolution routines for sparse conv weights int he case of general sparsity (as compared with structured sparsity).	B-Review	B-1	Review	324
They evaluate their method on both AlexNet and GoogLeNet as well as on various platforms.	O	O	Review	324
The authors make code available online.	O	O	Review	324
The paper is well written and does a good job of putting this work in the context of past model reduction techniques.	O	O	Review	324
[line_break_token][line_break_token]My main request of the authors would be to provide a concise summary of the speedup/memory gains achievable with this new work compared with previously published work.	B-Review	B-2	Review	324
The authors do show the various sparsity level obtained with various methods of pruning but it is unclear to me how to translate the information given in the paper into an understanding of gains relative to other methods.	I-Review	I-2	Review	324
Please note that, in addition to our fast convolution algorithms, another important contribution is the performance model guiding the pruning process that allows pursuing desired speedup and model size reduction without falling into combinatorial number of choices offered by multiple layers.	B-Reply	B-1	Reply	324
Our performance model can also guide other methods discussed in related work as shown by our application to dynamic network surgery (GDNS in Figure 4(a)).	I-Reply	I-1	Reply	324
[line_break_token][line_break_token]Thanks for the suggestion on summarizing inference speedups and model size reductions of related work.	O	O	Reply	324
A quick summary is shown below, which we will also consider including in our paper.	O	O	Reply	324
It is important to note that our work achieves highest speedup without accuracy loss among all the techniques below.	B-Reply	B-2	Reply	324
The speedups shown that are not our own measurements should be taken with a grain of salt because 1) many papers only provide relative speedups to a baseline whose efficiency is suboptimal (e.g. in some cases, the baseline is Caffe running on CPU, which is known to be suboptimal as it is tuned for GPU), and 2) what some papers report as "speedup" is actually FLOP reduction, not actual timing measurements.	I-Reply	I-2	Reply	324
As we did in our paper, for more scientific comparison among different CNN speedup techniques, we recommend using dense matrix multiplication (GEMM) FLOP/s of the evaluated platform as the baseline, because many platforms readily have vendor-provided extensively-optimized GEMM implementations which can be a proxy of highly-optimized dense CNN implementation.	I-Reply	I-2	Reply	324
This also aligns with a long-accepted common practice in the high-performance computing (HPC) community.	I-Reply	I-2	Reply	324
We omit Denton et al 2014, Jaderberg et al 2014, and Lebedev et al 2015 in the summary because they report improvements in a subset of conv and fc layers.	I-Reply	I-2	Reply	324
[line_break_token] [line_break_token]AlexNet[line_break_token]GESL (ours, 0% top-1 accuracy drop):                8.5x smaller model,                      2.5x speedup,                                      4.2x FLOP reduction[line_break_token]DNS (0.5% top-1 accuracy drop):                    17.7x smaller model,                      1.0x speedup (not enough sparsity in conv layers), 2.8x FLOP reduction[line_break_token]SSL (0% top-1 accuracy drop):                       1.01x smaller model (no sparsity in fc), 1.5x speedup,                                      1.3x FLOP reduction[line_break_token]Lebedev and Lempitsky (1.3% top-1 accuracy drop):   2.9x smaller model,                      3.0x speedup? (	I-Reply	I-2	Reply	324
not sure if this is a real speedup or FLOP reduction)[line_break_token]Liu et al (1% top-1 accuracy drop):                1.04x smaller model (no sparsity in fc), 4.4x speedup (not sure if lowering overhead included)[line_break_token]Kim et al (1.7% top-5 accuracy drop):              5.5x smaller model,                      1.8x speedup,                                      2.7x FLOP reduction[line_break_token]Tai et al (0.4% top-5 accuracy drop):              5.0x smaller model,                      1.8x speedup,                                      5.3x FLOP reduction[line_break_token][line_break_token]GoogLeNet[line_break_token]GESL (0.2% top-1 accuracy drop):                    3.3x smaller model,                      2.0x speedups in conv and fc layers,               3.0x FLOP reduction[line_break_token]DNS (our own evaluation, 2.5% top-1 accuracy drop): 1.5x smaller model,                      2.0x speedups in conv and fc layers,               2.6x FLOP reduction[line_break_token]SSL (our own evaluation, 2% top-1 accuracy drop):   2.1x smaller model,                      speedup N/A yet,                                   2.3x FLOP reduction[line_break_token]Kim et al (0.2% top-5 accuracy drop):              1.3x smaller model,                      1.2x speedup,                                      1.3x FLOP reduction[line_break_token]Ioannou et al (0.4% top-1 accuracy drop):          1.7x smaller model,                      speedup N/A,                                       1.4x FLOP reduction[line_break_token]Tai et al (0.4% top-5 accuracy drop):              2.8x smaller model,                      1.2x speedup,                                      2.9x FLOP reductio	I-Reply	I-2	Reply	324

This paper describes a method of training neural networks to be robust to a worse case mixture of a set of predefined example attributes.	O	O	Review	724
This is done with a loss in accuracy in the average case but improvements in the worse case.	O	O	Review	724
The proposed algorithm is relatively simple and convergence rates are also given for this new algorithm.	O	O	Review	724
[line_break_token][line_break_token]Building neural networks that perform well in the face of group-level worse case test-set distributions is a very important problem particularly in areas such as health and safety-critical applications as past work points out.	O	O	Review	724
This paper shows good results in the worse case and additionally shows that the common technique of importance reweighting cannot arrive at the same solution.	O	O	Review	724
The convergence analyses also yield additional insight into this new algorithm.	O	O	Review	724
The paper is well written and relatively easy to understand with good details on the experimental setup.	O	O	Review	724
The algorithm has a downside in that the groups must be known a priori, is it possible for these groups to be learnt?	B-Review	B-1	Review	724
Also, can using a hinge loss also improve robustness to the worse case examples?	B-Review	B-2	Review	724
[line_break_token][line_break_token]However, there are some unanswered questions in the paper.	O	O	Review	724
What is the effect on the training time of this algorithm?	B-Review	B-3	Review	724
Is it just the time for an additional forward prop?	I-Review	I-3	Review	724
What is the effect on the worse-case examples of weight decay on the Bert model?	B-Review	B-4	Review	724
Even though it hurts the average performance does it improve the worse case at all?	I-Review	I-4	Review	724
In the last line of algorithm 1 why is q_G used instead of q_g?	B-Review	B-5	Review	724
[line_break_token][line_break_token]Other comments:[line_break_token]At the bottom of P5: The ordering of 93.4% and 97.1% seem to be reversed.	B-Review	B-6	Review	724
[line_break_token]Above eq.	B-Review	B-7	Review	724
5 , \delta_g seems to be overloaded.	I-Review	I-7	Review	724
In the paragraph, it first refers to the generalization gap and then later to a heuristic.	I-Review	I-7	Review	724
[line_break_token]Table 2: The drop in average accuracy for waterbirds does not seem 'small'.	B-Review	B-8	Review	724
[line_break_token]Bottom of P8: 'background is more unique', it seems this is supposed to mean the background appears less often?	B-Review	B-9	Review	724
[line_break_token][line_break_token]======================================================================================================[line_break_token]Update after rebuttal:[line_break_token][line_break_token]Thanks for the detailed answers to my comments and the additional experiments done with a hinge loss.	O	O	Review	724
I will keep my rating.	O	O	Review	724
hank you very much for your detailed comments and for going through our paper so carefully.	O	O	Reply	724
[line_break_token][line_break_token][line_break_token]1. ‚	O	O	Reply	724
ÄúThe algorithm has a downside in that the groups must be known a priori, is it possible for these groups to be learnt?‚Äù[line_break_token][line_break_token]Thanks for raising this point; please refer to our response to all reviewers.	B-Reply	B-1	Reply	724
[line_break_token][line_break_token][line_break_token]2. ‚	O	O	Reply	724
ÄúCan using a hinge loss also improve robustness to the worse case examples?‚Äù[line_break_token][line_break_token]We ran new experiments using the hinge loss in the CelebA and Waterbirds datasets (since these are binary classification tasks), but performance on the worst-case group did not improve.	B-Reply	B-2	Reply	724
Compared to the logistic loss, performance with the hinge loss was similar or slightly worse across each group.	I-Reply	I-2	Reply	724
For CelebA (on the test set and with early stopping), robust accuracy was 84.4% with the hinge loss and 88.3% with the logistic loss; and similarly for Waterbirds, robust accuracy was 84.7% with the hinge loss and 84.9% with the logistic loss.	I-Reply	I-2	Reply	724
[line_break_token][line_break_token][line_break_token]3. ‚	O	O	Reply	724
ÄúWhat is the effect on the training time of this algorithm?	O	O	Reply	724
Is it just the time for an additional forward prop?‚Äù[line_break_token][line_break_token]Optimizing for the worst-case group loss instead of the average loss has little effect on the run time of the algorithm.	B-Reply	B-3	Reply	724
In practice, optimizing for the worst-case group loss vs. average loss takes a similar amount of time (&lt;5% difference) for a given number of epochs.	O	O	Reply	724
For example, it took 12h 50min to train the CelebA ERM model for 50 epochs on an NVIDIA TITAN Xp, and 13h 20 min to train the corresponding DRO model.	B-Reply	B-3	Reply	724
[line_break_token][line_break_token]The small difference above is expected because the computation of the loss and its gradient dominates the run time of each iteration in both optimization algorithms.	I-Reply	I-3	Reply	724
The robust optimizer in Algorithm 1 requires only a few additional computations over the standard optimizer: a. Multiplying the weights by exponentiated losses and normalizing (second-to-last line in Algorithm 1), and b. Multiplying the loss gradient by (last line in Algorithm 1).	I-Reply	I-3	Reply	724
These are relatively cheap operations.	I-Reply	I-3	Reply	724
[line_break_token][line_break_token]This comparison of training times is an important point to clarify in the paper, and we will make it explicit in our revision.	I-Reply	I-3	Reply	724
Thanks for highlighting it.	I-Reply	I-3	Reply	724
[line_break_token][line_break_token][line_break_token]4. ‚	O	O	Reply	724
ÄúWhat is the effect on the worse-case examples of weight decay on the BERT model?	O	O	Reply	724
Even though it hurts the average performance does it improve the worse case at all?	O	O	Reply	724
[line_break_token][line_break_token]On the BERT model, we found that weight decay (specifically,) did not seem to affect the model‚Äôs accuracy on the worst-case group in comparison to the model without weight decay; training the above models to convergence resulted in similar (bad) performance on the worst-case group.	B-Reply	B-4	Reply	724
[line_break_token][line_break_token]Much larger values of weight decay ) were too conservative and significantly lowered model performance across all groups.	I-Reply	I-4	Reply	724
In CelebA and Waterbirds datasets, we similarly observed that weight decays that are too high result in poor overall performance.	I-Reply	I-4	Reply	724
[line_break_token][line_break_token]While it is possible that we have not found the appropriate value of weight decay for the BERT/MultiNLI model, these results may suggest that weight decay is not an effective form of regularization (compared to early stopping) for this particular model.	I-Reply	I-4	Reply	724
[line_break_token][line_break_token][line_break_token]5. ‚	O	O	Reply	724
ÄúIn the last line of algorithm 1 why is used instead of?‚Äù[line_break_token][line_break_token]That is a typo, and it should indeed be.	B-Reply	B-5	Reply	724
We will fix it.	I-Reply	I-5	Reply	724
Thank you.	I-Reply	I-5	Reply	724
[line_break_token][line_break_token][line_break_token]6. ‚	O	O	Reply	724
ÄúAt the bottom of P5: The ordering of 93.4% and 97.1% seem to be reversed.	O	O	Reply	724
‚Äù[line_break_token][line_break_token]That is also a typo, and we will fix it.	B-Reply	B-6	Reply	724
Thank you.	B-Reply	B-5	Reply	724
[line_break_token][line_break_token][line_break_token]7. ‚	O	O	Reply	724
ÄúAbove eq.	O	O	Reply	724
5 , seems to be overloaded.	O	O	Reply	724
In the paragraph, it first refers to the generalization gap and then later to a heuristic.	O	O	Reply	724
‚Äù[line_break_token][line_break_token]Thanks for catching the overloading.	B-Reply	B-7	Reply	724
We will refer to the heuristic as instead.	I-Reply	I-7	Reply	724
[line_break_token][line_break_token][line_break_token]8. ‚	O	O	Reply	724
ÄúTable 2: The drop in average accuracy for waterbirds does not seem 'small'.	O	O	Reply	724
‚Äù[line_break_token][line_break_token]You‚Äôre right that it is not a small change in relative error.	B-Reply	B-8	Reply	724
Thanks for the catch; we will clarify the text.	I-Reply	I-8	Reply	724
[line_break_token][line_break_token][line_break_token]9.	O	O	Reply	724
Bottom of P8: 'background is more unique', it seems this is supposed to mean the background appears less often?	O	O	Reply	724
[line_break_token][line_break_token]We will explain the example more clearly in the updated version.	B-Reply	B-9	Reply	724
The idea is the following: Assume that the actual spurious association is the same as in the original Waterbirds dataset (whether the background is water or land).	I-Reply	I-9	Reply	724
However, instead of a single water background and single land background, we now have fine-grained labelings of water and land backgrounds, such that waterbirds appear in 9 different water backgrounds (e.g., ‚Äúlake‚Äù, ‚Äúpond‚Äù, ‚Äúsea‚Äù, etc.)	I-Reply	I-9	Reply	724
and 1 land background, while landbirds appear in 9 different land backgrounds and 1 water background.	I-Reply	I-9	Reply	724
In this setting, each group of (waterbird/landbird, background) is the same size, so resampling yields the same model as ERM.	I-Reply	I-9	Reply	724
However, the DRO model would correctly upweight the waterbirds on a land background (and vice versa)	I-Reply	I-9	Reply	724

In this paper, the authors present two contributions:[line_break_token]1)[tab_token]The primary contribution is to show that CycleGAN can be formulated as a probabilistic version of a particular penalized-least squares problem (theory)[line_break_token]2)[tab_token]As proof of concept, they apply their version of CycleGAN to accelerated MRI and deconvolution microscopy (application)[line_break_token][line_break_token]While I find the idea to be potentially interesting, the presentation of the theory is unclear and not well-motivated; after reading, I‚Äôm not convinced that the connection to CycleGAN is as significant as the authors claim.	B-Review	B-10	Review	188
The experimental results are preliminary.	I-Review	I-10	Review	188
My decision is to reject.	O	O	Review	188
Below are separate critiques on the sections.	O	O	Review	188
[line_break_token][line_break_token]Section 2-3: Hope the authors could clarify / strengthen these points in revision:[line_break_token]-[tab_token]Since the discussion in Section 3 is based on the optimization problem in Equation (7), this problem should be well-motivated.	B-Review	B-1	Review	188
Currently it is presented as a problem that has been explored previously by Zhang et al and Aggarwal et al However, after taking a look at those papers, I don‚Äôt understand where this regularization term comes from.	I-Review	I-1	Review	188
In these papers, the regularization term (i.e. equation 2 or 3 of Zhang et al) appears independent of y. Since this term is key to the paper, it should be well explained here.	I-Review	I-1	Review	188
E.g. at the end of section 2.2: G_\theta(y) is a CNN pretrained on what task?	I-Review	I-1	Review	188
[line_break_token][line_break_token]-[tab_token]In the inverse problem, the objective is to estimate x from y. Therefore we care about \argmin x in Equation (7).	B-Review	B-2	Review	188
In the probabilistic setting presented in Equation (8), analogously the objective is to estimate \pi^*, which is the solution to the primal problem.	I-Review	I-2	Review	188
The theory shows that the primal formulation in Equation (8) is equivalent to the dual formulation in Equation (16), but does not show how the dual solution yields the primal solution, which is lacking as obtaining the primal solution seems to be the point of solving the PLS problem. (	I-Review	I-2	Review	188
Interestingly, in Section 4, the authors are using the dual solution x = G_\theta(y) as if it is the mapping given by pi(x|y)‚Ä¶ this needs to be explained.)	I-Review	I-2	Review	188
[line_break_token][line_break_token]-[tab_token]The authors claim that Proposition 1 shows that the cyclic loss term in their dual formulation is a more general version of the cycle-consistency loss in CycleGAN.	B-Review	B-3	Review	188
But looking closely at Proposition 1 and its proof, it seems that the equivalence holds only for specific weights, not for arbitrary weights.	I-Review	I-3	Review	188
Additionally, the specific weights are unknown (they depend on the solution \pi^* to the primal problem‚Ä¶).	I-Review	I-3	Review	188
I do not understand the claim that this is a generalization of cycle-consistency loss, nor do I see how the authors implement their version of the cyclic loss as it depends on unknown weights.	I-Review	I-3	Review	188
[line_break_token][line_break_token]-[tab_token]The connection to CycleGAN seems to hold only when p=q=1?	B-Review	B-4	Review	188
[line_break_token][line_break_token]-[tab_token]End of section 3: The authors conclude ‚Äúour cost formulation using (17) with (18) and (19) is more general compared to the standard CycleGAN, since a general form of measurement data generator Hx can be used‚Äù.	B-Review	B-5	Review	188
I don‚Äôt see the connection between the theory and this claim.	I-Review	I-5	Review	188
Even with CycleGAN, both generators can be arbitrary or fixed if one of them is known.	I-Review	I-5	Review	188
[line_break_token][line_break_token]-[tab_token]The proofs are easy to follow, though perhaps they could be moved to the Appendix in favor of providing more motivation and explanation in the main text.	B-Review	B-6	Review	188
[line_break_token][line_break_token]Section 4:[line_break_token]-[tab_token]The authors motivate the problem with the PLS setup but then they use the learned regularization term x = G_\theta(y) as if it is the mapping given by pi(x|y).	B-Review	B-7	Review	188
 I am confused by this.	I-Review	I-7	Review	188
[line_break_token]-[tab_token]Putting aside the connection to the PLS problem, my interpretation of the experimental setup is that the authors use CycleGAN with Wasserstein GAN loss instead of the classic discriminator loss, where one of the generators is known (and hence only one generator/discriminator pair is needed).	B-Review	B-8	Review	188
I might be missing something, but I‚Äôm not sure that this approach is different enough from CycleGAN.	I-Review	I-8	Review	188
[line_break_token]-[tab_token]Considering that the authors have the ground truth, they could provide quantitative evaluation of their method against other methods, rather than showing a few qualitative results where it is working.	B-Review	B-9	Review	188
[line_break_token]	O	O	Review	188
Q] .. I‚Äôm not convinced that the connection to CycleGAN is as significant as the authors claim... [line_break_token][line_break_token]==&gt;  We would like to assure the reviewer that the primary motivation of this work is to provide a principled method for designing cycleGAN for various inverse problems by using the original physics as regularization for OT.	B-Reply	B-10	Reply	188
This is an important advance over the existing CycleGAN, which is mainly derived from trial and error.	I-Reply	I-10	Reply	188
In particular,  the reason we enforce the proposed PLS cost for the OT problem is to lead the primal solution to become a true inverse of the forward operator at the global minimum.	I-Reply	I-10	Reply	188
As the other reviewers pointed out, our formulation is more generic than the classical cycleGAN formulation, and demonstrating their deep relationships, followed by two clear and concise derivations and their practical application,  is compelling.	I-Reply	I-10	Reply	188
 See General Comments.	I-Reply	I-10	Reply	188
[line_break_token][line_break_token][Q]  ...  Currently it is presented as a problem that has been explored previously by Zhang et al and Aggarwal et al H.. Since this term is key to the paper, . ..	O	O	Reply	188
[line_break_token][line_break_token]==&gt; We found that the latex bib file incorrectly referred to different Zhang's paper.	B-Reply	B-1	Reply	188
We are quoting a correct one now.	I-Reply	I-1	Reply	188
However, we understand the reviewers' concern that the existing deep learning prior approaches are indirectly related to y.  In this revision, rather than emphasizing our method as an extension of the existing PLS with deep learning prior, we have highlighted the difference in our formulation.	I-Reply	I-1	Reply	188
We emphasize that the reason for using (9) is to lead the primal solution to become a true inverse of the forward operator.	I-Reply	I-1	Reply	188
[line_break_token][line_break_token][Q]...   but does not show how the dual solution yields the primal solution....[line_break_token][line_break_token]==&gt; Thanks to our PLS formulation (9),  we confirmed that the dual solution and the primal solution are equivalent when the global optimum is achieved with.	B-Reply	B-2	Reply	188
[line_break_token][line_break_token][Q] The authors claim ... the cyclic loss term in their dual formulation is a more general version of the cycle-consistency loss in CycleGAN. ...	O	O	Reply	188
[line_break_token][line_break_token]==&gt; Kindly note that the term "general version" is used when, under certain conditions, the new formulation can be reduced to the standard one.	B-Reply	B-3	Reply	188
Similar to the standard cycleGAN, the hyperparameters should be selected by trial and error.	I-Reply	I-3	Reply	188
We agree that this is the limitation for both the standard and the proposed cycleGAN.	I-Reply	I-3	Reply	188
However, our "generalized" formulation gives better insight into the selection of hyperparameters.	I-Reply	I-3	Reply	188
In fact, the parameter is the relative match between two data distributions.	I-Reply	I-3	Reply	188
If it turns out that both pairs are perfect, the parameter should be 1.	I-Reply	I-3	Reply	188
In a real training scenario, the perfect match can not be found so that the hyperparamereter should be between 0 and 1.	I-Reply	I-3	Reply	188
[line_break_token][line_break_token][Q] The connection to CycleGAN seems to hold only when p=q=1?	O	O	Reply	188
[line_break_token][line_break_token]==&gt; We only considered  due to the simple c-transformation.	B-Reply	B-4	Reply	188
The widely used W-GAN is derived similarly by assuming p = 1.	I-Reply	I-4	Reply	188
The use of general PLS costs is of course possible and could lead to an interesting variation of the cycleGAN architecture.	I-Reply	I-4	Reply	188
[line_break_token][line_break_token][Q] ... Even with CycleGAN, both generators can be arbitrary or fixed if one of them is known.	O	O	Reply	188
[line_break_token][line_break_token]==&gt; The standard CycleGAN could use a fixed generator, but there is no optimal design criterion to show why this is better.	B-Reply	B-5	Reply	188
On the other hand, our formulation requires only a single deep generator if the measurement physics is given by the forward model Hx.	I-Reply	I-5	Reply	188
In fact, as one of the other reviewers noted,  this can be seen as a consistency term from the forward model to acts as a regularization term for OT.	I-Reply	I-5	Reply	188
[line_break_token][line_break_token][Q]The proofs ... could be moved to the Appendix..[line_break_token][line_break_token]==&gt; Done.	B-Reply	B-6	Reply	188
 [line_break_token][line_break_token][Q] ... but then they use the learned regularization term x = G_\theta(y) as if it is the mapping given by pi(x|y).	O	O	Reply	188
 [line_break_token][line_break_token]==&gt; Our novel PLS cost (9) enforces the dual solution to be the primal solution of the PLS when the global minimum is reached.	B-Reply	B-7	Reply	188
Therefore, in this case, is actually the map given by.	I-Reply	I-7	Reply	188
[line_break_token][line_break_token][Q] ...my interpretation of the experimental setup is that the authors use CycleGAN with Wasserstein GAN loss instead of the classic discriminator loss, where one of the generators is known ...  but I‚Äôm not sure that this approach is different enough from CycleGAN.	O	O	Reply	188
[line_break_token][line_break_token]==&gt; Our main contribution is the principal derivation of the cycleGAN architecture for various inverse problems.	B-Reply	B-8	Reply	188
If we use p = q = 1, the resulting discriminator loss becomes Wasserstein GAN.	I-Reply	I-8	Reply	188
However, with different p, q values and the regularized version of optimal transport, our formulation offers a new class of discriminator architecture.	I-Reply	I-8	Reply	188
In addition, if the forward mapping is unknown, the framework is reduced to the standard cycleGAN with two deep generators.	I-Reply	I-8	Reply	188
 Therefore, our framework is much more flexible.	I-Reply	I-8	Reply	188
[line_break_token][line_break_token][Q] ..they could provide quantitative evaluation of their method against other methods...[line_break_token][line_break_token]==&gt; Done.	B-Reply	B-6	Reply	188
In the revised paper, we have provided the quantitative results for both accelerated MRI and deconvolution microscopy.	B-Reply	B-9	Reply	188
The results clearly showed the advantages of the proposed method.	I-Reply	I-9	Reply	188

This paper combines a contrastive objective measuring the mutual information between the representations learned by a teacher and a student networks for model distillation.	O	O	Review	303
The objective enforces correlations between the learned representations.	O	O	Review	303
When combined with the popular KL divergence between the predictions of the two networks, the proposed model shows consistently improvement over existing alternatives on three distillation tasks.	O	O	Review	303
[line_break_token][line_break_token]This is a solid work ‚Äì it is based on sound principles and provides both rigorous theoretical analysis and extensive empirical evidence.	O	O	Review	303
I only have two minor suggestions.	O	O	Review	303
[line_break_token][line_break_token]1, From Section 3.2 to Section 3.4, it is not clear to me that on the model compression task, are both the proposed contrastive loss and the loss in Eq. (	B-Review	B-1	Review	303
10) used?	I-Review	I-1	Review	303
[line_break_token][line_break_token]2, The ‚ÄúDeep mutual learning‚Äù, Zhang et al, CVPR‚Äô18 paper needs to be discussed.	B-Review	B-2	Review	303
I‚Äôd also like to see some experiments on the effects of training the teacher and student networks jointly from scratch using the proposed loss.	I-Review	I-2	Review	303
[line_break_token]	O	O	Review	303
Dear Reviewer 1,[line_break_token][line_break_token]Thank you very much for the constructive comments.	O	O	Reply	303
[line_break_token][line_break_token]1.	O	O	Reply	303
For our CRD results in Table 1&amp;2, we only use CRD loss.	O	O	Reply	303
We have added CRD+KD results in the revised version to avoid such confusion, and CRD+KD shows further small improvement.	B-Reply	B-1	Reply	303
[line_break_token][line_break_token]2.	O	O	Reply	303
We have added a discussion of the ‚ÄúDeep Mutual Learning‚Äù paper in Sec 6.8.	B-Reply	B-2	Reply	303
We have evaluated several different distillation methods under the mutual learning setting, see Table 8.	I-Reply	I-2	Reply	303
[line_break_token][line_break_token]Please don‚Äôt hesitate to let us know for any further feedback.	O	O	Reply	303
Thanks!	O	O	Reply	303

This paper discusses the application of word prediction for software keyboards.	O	O	Review	265
The goal is to customize the predictions for each user to account for member specific information while adhering to the strict compute constraints and privacy requirements.	O	O	Review	265
[line_break_token][line_break_token]The authors propose a simple method of mixing the global model with user specific data.	O	O	Review	265
Collecting the user specific models and averaging them to form the next global model.	O	O	Review	265
[line_break_token][line_break_token]The proposal is practical.	B-Review	B-1	Review	265
However, I am not convinced that this is novel enough for publication at ICLR.	I-Review	I-1	Review	265
[line_break_token][line_break_token]One major question.	O	O	Review	265
The authors assume that the global model will depict general english.	B-Review	B-2	Review	265
However, it is not necessary that the population of users will adhere to general English and hence the averaged model at the next time step t+1 might be significantly different from general English.	I-Review	I-2	Review	265
It is not clear to me as how this mechanism guarantees that it will not over-fit or that there will be no catastrophic forgetting.	I-Review	I-2	Review	265
Thank you for your review!	O	O	Reply	265
[line_break_token]I would like to make some clarifications and remarks.	O	O	Reply	265
[line_break_token][line_break_token]1) In the review you write [line_break_token]"One major question.	O	O	Reply	265
The authors assume that the global model will depict general english.	O	O	Reply	265
However, it is not necessary that the population of users will adhere to general English and hence the averaged model at the next time step t+1 might be significantly different from general English.	O	O	Reply	265
It is not clear to me as how this mechanism guarantees that it will not over-fit or that there will be no catastrophic forgetting."	O	O	Reply	265
[line_break_token][line_break_token]In our problem statement we consider general English to be the common language i.e. the commonly used language with statistically insignificant portion of user-specific expressions.	B-Reply	B-2	Reply	265
It is NOT necessarily the language induced by our in-house corpus.	I-Reply	I-2	Reply	265
As far as we have a model averaged on many users on the server we can treat this model as general language model.	I-Reply	I-2	Reply	265
So at each stage T the server-side model represents general language.	I-Reply	I-2	Reply	265
When the model is sent to the device it is updated according to the user data so there is a risk of catastrophic forgetting.	I-Reply	I-2	Reply	265
We prevent it by using (eventually) random rehearsal on device (only!).	I-Reply	I-2	Reply	265
[line_break_token][line_break_token]2) I also would like to draw your attention to the original and practically relevant problem statement.	B-Reply	B-1	Reply	265
In the works on Federated Learning issued so far each node is considered only as a client in distributed learning system for gradient calculation.	I-Reply	I-1	Reply	265
In our approach we guarantee that the model sent to the aggregation server is at the same time the actual model used for typing and gives the best performance for the end user.	I-Reply	I-1	Reply	265
It is guaranteed by the forgetting prevention mechanism.	I-Reply	I-1	Reply	265
It has at least following advantages: 1) No need  for synchronization after every iteration as in standard Federated learning scheme.	I-Reply	I-1	Reply	265
Standard Federated learning uses no more than 20 iterations on each device for reduction of the communication cost (McMahan et al 2016, <a href="https://arxiv.org/abs/1602.05629)" target="_blank" rel="nofollow">https://arxiv.org/abs/1602.05629)</a> while we send our models only once in an epoch thus significantly reducing the communication cost. ;	O	O	Reply	265
2) Simpler synchronization scheme on the server; 3) Faster convergence; 4) Only 1 model is stored on the disk.	B-Reply	B-1	Reply	265
We think that these results may be interesting to many ML practitioners.	I-Reply	I-1	Reply	265
[line_break_token][line_break_token]3) You didn't discuss the privacy analysis part of the paper which we included in the list of our contributions.	I-Reply	I-1	Reply	265
We consider our contribution significant at least for the following reason.	I-Reply	I-1	Reply	265
To our knowledge deep neural networks have never been checked for differential privacy coming from the randomness of the training algorithm (combination of SGD, dropout regularization and model averaging in our case).	I-Reply	I-1	Reply	265
Existing approaches (e.g. Papernot et al 2017, <a href="https://arxiv.org/pdf/1610.05755.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1610.05755.pdf)</a> suggest adding random noise at different stages of training leading to the tradeoff between accuracy and privacy.	O	O	Reply	265
At the same time our experiments show that the differential privacy can be guaranteed even without special treatment of the neural networks at least in some situations	B-Reply	B-1	Reply	265

summary:[line_break_token]The paper proposes a method to efficiently verify that generative models are consistent with respect to some known (latent) attribute.	O	O	Review	608
The authors defines attribute consistency by 1) mapping pairs of input (x1, x2) with matching attribute to a latent space using an encoder n_E(x) and 2) measuring how correctly an auxiliary classifier will classify the known attribute using (decoded) linear interpolations between the two latent encodings.	O	O	Review	608
Importantly, the proposed method gives guaranteed bounds on this consistency score, as opposed to simply evaluating the classifier on a fixed set uniformly sampled points between x1 and x2.	O	O	Review	608
In experiments the authors use their method to test for attribute independence as well as consistency under left-right flipping of an image using two different autoencoder models (VAE and CycleAE) obtaining tighter bounds on the ‚Äòattribute consistency‚Äô score than competing methods.	O	O	Review	608
 [line_break_token][line_break_token]Decision &amp; supporting arguments:[line_break_token]Conceptually I found the paper very appealing, and it tackles an important problem in generative modelling.	O	O	Review	608
However I have some concerns with respect to the paper in its current state:[line_break_token]1) It is not clear to me why the attribute consistency score, a key component in the paper, is a good measure of consistency in generative models.	B-Review	B-1	Review	608
Notably, I miss motivation for why linear interpolations between encoded inputs should necessarily keep the attribute stable.	I-Review	I-1	Review	608
[line_break_token]2) Although I found the experiments interesting, I did not find the experimental section completely comprehensive.	B-Review	B-2	Review	608
There is no discussion or experiments probing the dependency on the quality of the auxiliary classifier or the encoder/decoder model used.	I-Review	I-2	Review	608
[line_break_token]3) I did not find the description of the proposed method to be reasonably self-contained.	B-Review	B-3	Review	608
Especially section 3 which describes the proposed method is challenging to follow.	I-Review	I-3	Review	608
The background material in section 2 reads very much like a set of definitions.	I-Review	I-3	Review	608
Since ICLR has a quite broad audience, I think the paper should be written in a more pedagogical way, with for instance clarifying examples.	I-Review	I-3	Review	608
An example of a sentence that is incredibly hard to parse is on page 4, describing domain lifting: ‚ÄúAny deterministic abstract domain can be directly interpreted as a probabilistic abstract domain, where the concretization of an element is given as the set of probability measures whose support is a subset of the set produced by the deterministic concretization.	I-Review	I-3	Review	608
‚Äù I think making this paper more pedagogical requires major rewriting.	I-Review	I-3	Review	608
[line_break_token][line_break_token]Due to the above reasons I currently score the paper as a ‚Äòweak reject‚Äô.	O	O	Review	608
[line_break_token][line_break_token]Further detailed questions/comments:[line_break_token]Consistency Score[line_break_token]Q1: What is the motivation behind the definition of the consistency attribute score.	B-Review	B-4	Review	608
Especially, why is an attribute considered consistent if it is stable to linear interpolations in the latent space?	I-Review	I-4	Review	608
[line_break_token][line_break_token]Experiment Results:[line_break_token]Q2.1: Did you perform any experiments on how the L1 score of the auxiliary classifier affects the consistency score?	B-Review	B-5	Review	608
I would also like to see some quantitative numbers on the auxiliary classifier.	I-Review	I-5	Review	608
[line_break_token]Q2.2: Why is the L1 score used for training the classifier instead of bernoulli which seems more natural for binary attributes?	B-Review	B-6	Review	608
[line_break_token]Q2.3: Similarly, I would like to see some numbers on the quality of the encoder/decodes.	B-Review	B-7	Review	608
Simply inspecting the interpolations in figure 3) the reconstructions seem quite blurry, likely due to the relatively small models used.	I-Review	I-7	Review	608
Is it prohibitively expensive to run the proposed method on bigger models (e.g. ResNet based encoder/decoders or Unet-style models)?	I-Review	I-7	Review	608
[line_break_token]Q2.4: I believe it would be more informative to show the actual confidence intervals in figure 2b) instead of only the width of the confidence intervals?	B-Review	B-8	Review	608
[line_break_token][line_break_token]Readability:[line_break_token]Q3: I found it quite challenging to understand how the proposed is implemented in practice - My suggestion is that the authors add a pseudo-code / algorithm to section 3 clarifying exactly how the bounds reported in the experimental section are calculated.	B-Review	B-9	Review	608
[line_break_token][line_break_token]	O	O	Review	608
hank you for the thorough and clear review.	O	O	Reply	608
 We will answer in two parts.	O	O	Reply	608
[line_break_token][line_break_token]Q1.1: It is not clear to me why the attribute consistency score, a key component in the paper, is a good measure of consistency in generative models.	O	O	Reply	608
Notably, I miss motivation for why linear interpolations between encoded inputs should necessarily keep the attribute stable.	O	O	Reply	608
[line_break_token][line_break_token]There have been a wealth of papers that propose autoencoder/generative model systems that claim that linear interpolations produce "interpretable" results [1-11]. It is in fact possible that not all defined attributes for a dataset should be preserved under "interpretable" interpolations.	B-Reply	B-1	Reply	608
For example, interpolating between a person with only a beard and the same person with only a mustache would likely fail to satisfy the disjunctive attribute "no beard or no mustache."	I-Reply	I-1	Reply	608
However, for many attributes we do expect intuitively consistency along interpolations between examples with those attributes, such as "has blond hair."	I-Reply	I-1	Reply	608
One can examine the named attributes provided with CelebA to decide whether they should remain consistent among interpolations (we believe they should).	I-Reply	I-1	Reply	608
[line_break_token][line_break_token]Interestingly, this brings up the important point that deciding whether an attribute should correspond to a direction in the encoded representation for a dataset is likely a subjective question.	I-Reply	I-1	Reply	608
We do not claim to answer this.	I-Reply	I-1	Reply	608
Rather, our system attempts to verify this for a given dataset and given property.	I-Reply	I-1	Reply	608
[line_break_token][line_break_token]Q1.2: Especially, why is an attribute considered consistent if it is stable to linear interpolations in the latent space?	O	O	Reply	608
[line_break_token][line_break_token]We clarify that we do not measure the consistency of an attribute in vacuum, but with respect to a particular autoencoder.	B-Reply	B-4	Reply	608
An attribute which is consistent for one autoencoder might very well be inconsistent for another autoencoder, and this is not a judgement on the consistency of the attribute as much as it is a judgement on the consistency of the autoencoder.	I-Reply	I-4	Reply	608
[line_break_token][line_break_token][1] Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb, Martin Arjovsky, and Aaron Courville.	O	O	Reply	608
Adversarially learned inference.	O	O	Reply	608
arXiv preprint arXiv:1606.00704, 2016.	O	O	Reply	608
[line_break_token][2] Michael F Mathieu, Junbo Jake Zhao, Junbo Zhao, Aditya Ramesh, Pablo Sprechmann, and Yann LeCun.	O	O	Reply	608
Disentangling factors of variation in deep representation using adversarial training.	O	O	Reply	608
In Advances in Neural Information Processing Systems, pp.	O	O	Reply	608
5040‚Äì5048, 2016.	O	O	Reply	608
[line_break_token][3] Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio.	O	O	Reply	608
[line_break_token]Generating sentences from a continuous space.	O	O	Reply	608
arXiv preprint arXiv:1511.06349, 2015.	O	O	Reply	608
[line_break_token][4] Alec Radford, Luke Metz, and Soumith Chintala.	O	O	Reply	608
Unsupervised representation learning with deep convolutional generative adversarial networks.	O	O	Reply	608
arXiv preprint arXiv:1511.06434, 2015.	O	O	Reply	608
[line_break_token][5] Lars Mescheder, Sebastian Nowozin, and Andreas Geiger.	O	O	Reply	608
Adversarial variational bayes: Unifying variational autoencoders and generative adversarial networks.	O	O	Reply	608
In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp.	O	O	Reply	608
2391‚Äì2400.	O	O	Reply	608
JMLR.	O	O	Reply	608
org, 2017.	O	O	Reply	608
[line_break_token][6] David Ha and Douglas Eck.	O	O	Reply	608
A neural representation of sketch drawings.	O	O	Reply	608
arXiv preprint arXiv:1704.03477, 2017.	O	O	Reply	608
[line_break_token][7] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.	O	O	Reply	608
Density estimation using real nvp.	O	O	Reply	608
arXiv preprint arXiv:1605.08803, 2016.	O	O	Reply	608
[line_break_token][8] Anders Boesen Lindbo Larsen, S√∏ren Kaae S√∏nderby, Hugo Larochelle, and Ole Winther.	O	O	Reply	608
Autoencoding beyond pixels using a learned similarity metric.	O	O	Reply	608
arXiv preprint arXiv:1512.09300, 2015.	O	O	Reply	608
[line_break_token][9] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al Conditional image generation with pixelcnn decoders.	O	O	Reply	608
In Advances in neural information processing systems, pp.	O	O	Reply	608
4790‚Äì4798, 2016.	O	O	Reply	608
[line_break_token][10] Yongyi Lu, Yu-Wing Tai, and Chi-Keung Tang.	O	O	Reply	608
Attribute-guided face generation using conditional cyclegan.	O	O	Reply	608
In Proceedings of the European Conference on Computer Vision (ECCV), pp.	O	O	Reply	608
282‚Äì297, 2018.	O	O	Reply	608
[line_break_token][11] Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, and Xilin Chen.	O	O	Reply	608
Attgan: Facial attribute editing by only changing what you want.	O	O	Reply	608
IEEE Transactions on Image Processing, 2019.	O	O	Reply	608

The authors propose the use of statistics of softmax outputs to estimate the probability of error and probability of a test sample being out-of-domain.	O	O	Review	267
They contrast the performance of the proposed method with directly using the softmax output probabilities, and not their statistics, as a measure of confidence.	O	O	Review	267
[line_break_token][line_break_token]It would be great if the authors elaborate on the idea of ignoring the logit of the blank symbol.	O	O	Review	267
[line_break_token][line_break_token]It would be interesting to see the performance of the proposed methods in more confusable settings, ie.,	B-Review	B-1	Review	267
in cases where the out-of-domain examples are more similar to the in-domain examples.	I-Review	I-1	Review	267
e.g., in the case of speech recognition this might correspond to using a different language's speech with an ASR system trained in a particular language.	I-Review	I-1	Review	267
Here the acoustic characteristics of the speech signals from two different languages might be more similar as compared to the noisy and clean speech signals from the same language.	I-Review	I-1	Review	267
[line_break_token][line_break_token]In section 4, the description of the auxiliary decoder setup might benefit from more detail.	B-Review	B-2	Review	267
[line_break_token][line_break_token]There has been recent work on performance monitoring and accuracy prediction in the area of speech recognition, some of this work is listed below.	B-Review	B-3	Review	267
[line_break_token]1.	O	O	Review	267
Ogawa, Tetsuji, et al "Delta-M measure for accuracy prediction and its application to multi-stream based unsupervised adaptation."	O	O	Review	267
Proceedings of ICASSP.	O	O	Review	267
2015.	O	O	Review	267
[line_break_token][line_break_token]2.	O	O	Review	267
Hermansky, Hynek, et al "Towards machines that know when they do not know."	O	O	Review	267
Proceedings of ICASSP, 2015.	O	O	Review	267
[line_break_token][line_break_token]3.	O	O	Review	267
Variani, Ehsan et al "Multi-stream recognition of noisy speech with performance monitoring."	O	O	Review	267
INTERSPEECH.	O	O	Review	267
2013.	O	O	Review	267
Thank you for your analysis of our paper.	O	O	Reply	267
[line_break_token][line_break_token]When performing detection, we compute the softmax probabilities while ignoring the blank symbol's logit.	B-Reply	B-1	Reply	267
However, in training we leave the blank symbol alone.	I-Reply	I-1	Reply	267
With the blank symbol's presence, the softmax distributions at most time steps predict a blank symbol with high confidence, but without the blank symbol we can better differentiate between normal and abnormal distributions.	I-Reply	I-1	Reply	267
We now added this elaboration to the paper.	I-Reply	I-1	Reply	267
[line_break_token][line_break_token]We tested the model in confusable settings for vision and NLP (CIFAR-10 and SUN, MNIST and Omniglot, IMDB and Movie Reviews, WSJ and Webblog).	B-Reply	B-3	Reply	267
Your comment made us realize we should add a test for speech.	I-Reply	I-3	Reply	267
We used Chinese speech and found that we could still detect the speech reliably (but not as easily), and the abnormality module still generalized to detecting this speech better than softmax probabilities alone.	I-Reply	I-3	Reply	267
These results are in the updated paper.	I-Reply	I-3	Reply	267
[line_break_token][line_break_token]We updated the paper to provide more detail of the abnormality module per your suggestion.	B-Reply	B-2	Reply	267
[line_break_token][line_break_token]Finally, thank you for the links.	O	O	Reply	267
We can differentiate between our work and their work if you want	O	O	Reply	267

This paper evaluates the empirical power of neural tangent kernel (NTK) on small-data tasks.	O	O	Review	647
The authors demonstrate the superior performance of NTK for classification/regression tasks on UCI database, small CIFAR-10 dataset and VOC07 testbed.	O	O	Review	647
[line_break_token][line_break_token]Overall, this paper is well written and organized.	O	O	Review	647
The experimental results are also quite interesting.	O	O	Review	647
Besides, some questions and comments are as follows:[line_break_token][line_break_token]One of the baseline algorithms in Table 1 is NN with NTK initialization.	B-Review	B-1	Review	647
However, this paper does not give the formal definition of NTK initialization.	I-Review	I-1	Review	647
[line_break_token][line_break_token]In Figures 1-2, it can be observed that NTK cannot universally outperform baselines on all dataset.	B-Review	B-2	Review	647
For some dataset, NTK can be worse than baselines but for some other dataset, NTK can be significantly better than baselines.	I-Review	I-2	Review	647
Therefore, I would like the authors to briefly discuss which kind of data can be more efficiently learned through NTK or other training algorithms.	I-Review	I-2	Review	647
[line_break_token][line_break_token]In Tables 2-5, it can be observed that for CIFAR10 dataset, increasing the number of layers leads to higher test accuracy.	B-Review	B-3	Review	647
But for VOC07, one can observe the opposite thing.	I-Review	I-3	Review	647
Is there any explanation for this phenomenon?	I-Review	I-3	Review	647
[line_break_token][line_break_token]The authors should provide a clear description of the experimental setting.	B-Review	B-4	Review	647
For example, do you use batch normalization/weight decay in ResNets?	I-Review	I-4	Review	647
For training NN, which optimization algorithms do you use?	I-Review	I-4	Review	647
Do you use learning rate decay?	I-Review	I-4	Review	647
[line_break_token][line_break_token]======================[line_break_token]After reading authors' response:[line_break_token][line_break_token]Thanks for your response, I would like to keep my score.	O	O	Review	647
[line_break_token]	O	O	Review	647
hank you for your positive review.	O	O	Reply	647
Please find our response to your comments.	O	O	Reply	647
[line_break_token]1.	O	O	Reply	647
[tab_token]NTK initialization means a neural network with parameterization defined in Equation 2 with all weighted being initialized to be i.i.d.. We have added a sentence after Equation 2 to clarify this.	B-Reply	B-1	Reply	647
[line_break_token]2.	B-Reply	B-2	Reply	647
[tab_token]‚ÄúIn Figures 1-2, it can be observed ‚Ä¶..‚Äù There is no clear trend on which dataset NTK can be better than other classifiers.	I-Reply	I-2	Reply	647
We believe that investigating on which dataset NTK gives better performance requires more domain knowledge.	I-Reply	I-2	Reply	647
Some analyses on pairwise comparisons: NTK vs. RF and NTK vs. Gaussian kernel, are provided in Section 4.2.	I-Reply	I-2	Reply	647
[line_break_token]3.	O	O	Reply	647
[tab_token]‚ÄúIn Tables 2-5, it can be observed that ‚Ä¶‚Ä¶‚Äù Note for Tables 2-5, CNTKs are used on top of raw images, so to achieve better performance, one needs to use multi-layer CNTKs to extract higher-level features.	B-Reply	B-3	Reply	647
On the other hand, CNTKs on VOC07 are used on top of extracted features from ResNet-50, which are already high-level features.	I-Reply	I-3	Reply	647
Therefore, shallow CNTKs suffice for this case.	I-Reply	I-3	Reply	647
[line_break_token]4.	B-Reply	B-2	Reply	647
[tab_token]We have stated the experiment details in the third paragraph in Section B.	B-Reply	B-4	Reply	647

Summary:[line_break_token]       The authors take two tasks,sentiment analysis and natural language inference, and identify datasets for them which they counterfactually augment it by asking people over the Amazon Mechanical Turk Platform to change either the sentiment (in the case of sentiment analysis) or the nature of relationship in the NLI task by making minimal changes to the text that produce the targeted changes.	O	O	Review	184
[line_break_token][line_break_token]Authors find that popular models trained on either fail on the other dataset while the models trained on both actually generalize much better.	O	O	Review	184
This is because the original sample and its counterfactual pair the label changed , has the difference in the text that matters to the change and this pair could reduce spurious correlations that models might find in the data distribution.	O	O	Review	184
[line_break_token][line_break_token]Pros: [line_break_token] This is a very interesting experiment and certainly the dataset that will be released would be extremely valuable to the community.	O	O	Review	184
The one part (I dont have much NLP background but I do have a causality background) that I like most is that the new text generated are counterfactual in some real sense with respect to a real world generating process - that is people modifying text with changed targets.	O	O	Review	184
[line_break_token][line_break_token] A lot of existing work that claim to do counterfactual changes do not specify assumptions about the generating mechanism.	O	O	Review	184
For counterfactuals to be valid they have to be intervention on the actual generating mechanism (or an assumed one) acting on a given unit (latent) that produced the current sample.	O	O	Review	184
The paper in that respect (even if it does not explicitly specify relationship between counterfactuals and generating mechanisms) tries to be faithful to a "strict causal notion" by actually asking people to modify the text.	O	O	Review	184
[line_break_token][line_break_token]Cons:[line_break_token]    - I think the authors want to make an explicit connection to counterfactuals as understood in the causality community.	B-Review	B-1	Review	184
Then they shy away from it saying they are inspired by it.	I-Review	I-1	Review	184
May be a formal exposition in the supplement about counterfactuals and generating mechanisms could help readers from other communities (NLP) even it means repeating standard/synthetic examples.	I-Review	I-1	Review	184
Its good to say what exactly in a counterfactual generation process, the "people" in amazon turk were substituting.	I-Review	I-1	Review	184
[line_break_token][line_break_token]   -  Is the romantic/ horror flips and their absence the only spurious thing in Figure 4 ?	B-Review	B-2	Review	184
[line_break_token]  -  In figure 6, it appears that BERT is sensitive to the domain - does it mean that it is bad ? -	B-Review	B-3	Review	184
Authors indicate that ideally it must not be so.	I-Review	I-3	Review	184
Because Table 3 results seem to indicate that BERT performs the best in almost all the cases .	I-Review	I-3	Review	184
[line_break_token] -  Can the authors highlight the best performances in each case in the Tables by a bold face.	B-Review	B-4	Review	184
 It helps easily eye ball the best performing model.	I-Review	I-4	Review	184
[line_break_token] 	B-Review	B-1	Review	184
hank you for the thoughtful review and positive assessment.	O	O	Reply	184
We are glad to see that you appreciate the genuine flavor of causality in our paper and support our paper‚Äôs acceptance.	O	O	Reply	184
[line_break_token][line_break_token]We agree that a formal exposition introducing an NLP/deep learning audience to the basics of interventions and counterfactuals and expressing a toy DAG to explain the spurious associations between the review sentiment and the manifestation in text of other attributes of the review, including but not limited to the genre, actors, budget, etc.	B-Reply	B-1	Reply	184
We are actively working on preparing this exposition and while it is not yet in the draft we plan to have it prepared in advance of the camera-ready version.	I-Reply	I-1	Reply	184
[line_break_token][line_break_token]We thank the reviewer for pointing out that we should have been more thorough in explaining that while genre is a clear example of such a spurious association, it is far from the only one captured in Figure 4.	B-Reply	B-2	Reply	184
Indeed, many other words, including ‚Äúwill‚Äù, ‚Äúmy‚Äù, ‚Äúhas‚Äù, ‚Äúespecially‚Äù, ‚Äúlife‚Äù, ‚Äúworks‚Äù, ‚Äúboth‚Äù, ‚Äúit‚Äù, ‚Äúits‚Äù, ‚Äúlives‚Äù, ‚Äúgives‚Äù, ‚Äúown‚Äù, ‚Äújesus‚Äù, ‚Äúcannot‚Äù, ‚Äúeven‚Äù, ‚Äúinstead‚Äù, ‚Äúminutes‚Äù, ‚Äúyour‚Äù, ‚Äúeffort‚Äù, ‚Äúscript‚Äù, ‚Äúseems‚Äù, and ‚Äúsomething‚Äù, appear to be spuriously associated with sentiment and are captured by the original-only and revised-only classifiers as highly-weighted features.,	I-Reply	I-2	Reply	184
Notably all of these features fall out from the highly-weighted features when our classifier is trained on counterfactually-augmented data.	I-Reply	I-2	Reply	184
[line_break_token][line_break_token]Regarding the sensitivity of BERT models, Table 9 shows the ability of a model explicitly trained to differentiate between the original and the revised data.	B-Reply	B-3	Reply	184
This is to shed some insight on how much the two differ (on account of our intervention).	I-Reply	I-3	Reply	184
Because the two indeed are different, we expect that a model should be able to differentiate them to some degree.	I-Reply	I-3	Reply	184
We note that a model class‚Äôs ability to differentiate between the original and revised data when explicitly trained to do so may not necessarily be correlated with how susceptible that model is to breaking when evaluated out of sample.	I-Reply	I-3	Reply	184
[line_break_token][line_break_token]We‚Äôre grateful for your comments on exposition and will continue to address these points as we improve the draft.	O	O	Reply	184

The aim of this paper is to learn a heuristic for a backtracking search algorithm utilizing Reinforcement learning.	O	O	Review	1049
The proposed model makes use of Graphical Neural Networks to produce literal and clauses embeddings, and use them to predict the quality of each literal, through a NN, which in turn decides the probability of each action.	O	O	Review	1049
[line_break_token][line_break_token]Positives[line_break_token]A new approach on how to employ Machine learning techniques to Automated reasoning problems.	O	O	Review	1049
Works with any 2QBF solver.	O	O	Review	1049
[line_break_token]The learned heuristic seems to perform better than the state of the art in the presented experiments.	O	O	Review	1049
[line_break_token][line_break_token]Negatives[line_break_token]No theoretical justification about why this heuristic should work better than the existing ones.	B-Review	B-1	Review	1049
[line_break_token]Doesn't solve QBF formulas in general, but only 2QBF.	B-Review	B-2	Review	1049
[line_break_token]It is not clear whether the range of formulas that can be solved using this approach is greater than that of existing solvers.	B-Review	B-3	Review	1049
[line_break_token]Having a substantial amount of formulas that produce incomplete episodes, as it might be the case in real world scenarios, hinders learning, so the dataset has to be manually adjusted.	B-Review	B-4	Review	1049
[line_break_token][line_break_token]Conclusion[line_break_token]The proposed framework is an interesting addition to existing techniques in the field and the idea is suitable for further exploration and refinement.	O	O	Review	1049
The experimental results are promising, so the direction of the work is worth pursuing.	O	O	Review	1049
However, some of the foundations and overall nature of the work needs some improvement and maturity.	O	O	Review	1049
We thank the reviewer for the detailed feedback.	O	O	Reply	1049
[line_break_token][line_break_token]> No theoretical justification about why this heuristic should work better than the existing ones.	O	O	Reply	1049
[line_break_token][line_break_token]This is a very interesting question, but surprisingly hard to answer.	B-Reply	B-1	Reply	1049
Even for the simpler question of why CDCL for SAT solvers is so unreasonably effective for a wide range of applications, there is no concrete theoretical explanation - despite two decades of research!	I-Reply	I-1	Reply	1049
When there is no satisfactory theoretical explanation, we suggest that it is better to learn the heuristics based on the data itself.	I-Reply	I-1	Reply	1049
[line_break_token][line_break_token]> Doesn't solve QBF formulas in general, but only 2QBF.	O	O	Reply	1049
[line_break_token][line_break_token]Our approach could be easily applied to general QBF as well.	B-Reply	B-2	Reply	1049
The limitation to 2QBF is also due to the underlying tool.	I-Reply	I-2	Reply	1049
But keep in mind that most applications of QBF, e.g. in verification and program synthesis, can be encoded with just one quantifier alternation, so we believe that we captured the most interesting cases of QBF.	I-Reply	I-2	Reply	1049
[line_break_token][line_break_token]> It is not clear whether the range of formulas that can be solved using this approach is [line_break_token]> greater than that of existing solvers.	O	O	Reply	1049
[line_break_token][line_break_token]Our experiments demonstrate that we can solve significantly more formulas when given enough formulas from a single source (=distribution).	B-Reply	B-3	Reply	1049
We do not claim that the learned models generalize to formulas far away from that distribution.	I-Reply	I-3	Reply	1049
The question whether it is possible to learn models that apply to a wide ‚Äúrange of formulas‚Äù is indeed an open one.	I-Reply	I-3	Reply	1049
[line_break_token][line_break_token]> Having a substantial amount of formulas that produce incomplete episodes, as it might be[line_break_token]> the case in real world scenarios, hinders learning, so the dataset has to be manually[line_break_token]> adjusted.	O	O	Reply	1049
[line_break_token][line_break_token]We believe that this the inherent challenge of problem solving: how can we learn to solve problems that we have never solved?	B-Reply	B-4	Reply	1049
The assumption underlying this paper is that learning how to solve simpler problems faster, helps us to solve harder problems, too.	I-Reply	I-4	Reply	1049
Our experiments demonstrate that this is indeed possible for problems sets containing many related formulas of different hardness levels.	I-Reply	I-4	Reply	1049

# 1.	O	O	Review	281
Summary[line_break_token]The paper introduces a pre-training procedure for visual-linguistic representations.	O	O	Review	281
The model is an extension of BERT (with transformer backbone) to deal with visual input.	O	O	Review	281
Images are encoded using object detectors which regions are masked at pixel level.	O	O	Review	281
Experiments show state-of-the-art results on different downstream tasks.	O	O	Review	281
   [line_break_token][line_break_token]Strengths of the paper:[line_break_token]* State-of-the-art results on 3 vision-language tasks[line_break_token]      [line_break_token]The weak reject decision was mainly guided by the following two weaknesses of the paper:[line_break_token]* Clarity of the paper needs to be improved to make the readers understanding the details of the model (see point 2 below)[line_break_token]* Limited novelty: the paper is an extension of BERT to the visual domain (see point 3 below)[line_break_token][line_break_token]      [line_break_token]# 2.	O	O	Review	281
Clarity[line_break_token]The paper reads quite well, although some points need to be improved:[line_break_token]* How were words split in sub-words (Sec 3.2)?	B-Review	B-2	Review	281
     [line_break_token]* "For each input element, its embedding feature is the summation of four types of embedding, ...": it is not clear how you sum embeddings.	B-Review	B-3	Review	281
E.g., token embedding has 30k dimensions while image one has 2048 dimensions.	I-Review	I-3	Review	281
[line_break_token]* "It is attached to each of the input elements, which is the output of a fully connected layer taking the concatenation of visual appearance feature and visual geometry embedding as input" -&gt; this is not clear; what output are we talking about?	O	O	Review	281
What is the geometry embedding?	B-Review	B-4	Review	281
I suggest to describe the two features first and then say at the end of the paragraph that the representation is the concatenation.	I-Review	I-4	Review	281
[line_break_token]* "For the non-visual elements, the corresponding visual appearance features are of features extracted on the whole input image" -&gt; what is the intuition of having the full image here?	O	O	Review	281
Some terms do not need to have an image associated (e.g., verbs or articles).	B-Review	B-5	Review	281
Do you take care somehow of that?	I-Review	I-5	Review	281
[line_break_token]* Once textual embeddings are masked by [MASK], the related visual embedding (whole image) is also masked?	B-Review	B-6	Review	281
To my understanding the answer is no: what's the intuition of this?	I-Review	I-6	Review	281
[line_break_token]* Segment embedding: is this important?	B-Review	B-7	Review	281
This should be easy to show with an experiment in the ablation study of Table 4?	I-Review	I-7	Review	281
[line_break_token]* It seems that there is a semantic asymmetry of input to the loss during training when considering only the text information (bookscorpus) and the image-text information (conceptual captions): how is training coping with this?	B-Review	B-8	Review	281
Doesn't it make more sense to have 2 pre-training phases: first on text information only and then on image-text information?	I-Review	I-8	Review	281
[line_break_token][line_break_token][line_break_token]# 3.	O	O	Review	281
Novelty and Motivation[line_break_token]The novelty of the paper is quite limited.	B-Review	B-1	Review	281
It strongly relies on transformer networks and then recent success of BERT in the NLP domain.	I-Review	I-1	Review	281
The proposal is an extension of these two ideas to visual domain.	I-Review	I-1	Review	281
[line_break_token][line_break_token]Moreover, there is a body of concurrent work that is very similar to the proposed idea with slight differences (ViLBERT, VisualBERT, LXBERT, UNITER, B2T2), i.e., using transformers with masking operation on the RoIs.	I-Review	I-1	Review	281
It is not clear what is the intuition related to the differences between the methods, i.e.[line_break_token]* Why one is better than the other; why should someone prefer this pre-training technique wrt others?	I-Review	I-1	Review	281
[line_break_token]* Why a unified network (this work) is preferred wrt a two-stream one (ViLBERT, LXMERT)?	I-Review	I-1	Review	281
[line_break_token]It seems that everything heavily depends on the experiments and empirical results obtained by trying many variants during the prototyping phase.	I-Review	I-1	Review	281
It is missing a bit of understanding and intuition on the reasons why this technique should be used.	I-Review	I-1	Review	281
[line_break_token][line_break_token][line_break_token]# 4.	O	O	Review	281
Experimentation[line_break_token]Experiments are the strength of the paper showing state-of-the-art results on 3 vision-language tasks.	O	O	Review	281
Some additional analysis is missing:[line_break_token]* If masking is conducted on the raw pixel, this makes training much slower since you need to perform inference many times.	B-Review	B-9	Review	281
What is the impact in terms of accuracy?	I-Review	I-9	Review	281
Did you carried out an experiment showing that it is better to mask raw pixels instead of conv maps?	I-Review	I-9	Review	281
[line_break_token]* How long is the model trained for?	I-Review	I-9	Review	281
[line_break_token]* What is the performance/accuracy on the pre-training tasks?	I-Review	I-9	Review	281
[line_break_token]* How important is the segment embedding?	I-Review	I-9	Review	281
[line_break_token]* Footnote 2 should be in the main text (Sec 4.1).	I-Review	I-9	Review	281
It is too hidden, but very important to let the reader knowing about it.	I-Review	I-9	Review	281
[line_break_token]	O	O	Review	281
e feel we can well address the concerns of R#3, and hope R#3 give a second thought about the paper.	O	O	Reply	281
[line_break_token][line_break_token]Q#1: Concerns about novelty.	O	O	Reply	281
[line_break_token][line_break_token]A#1: First of all, the existence of concurrent works does not hurt the novelty of our method.	B-Reply	B-1	Reply	281
And it should not be a reason for rejecting the paper.	I-Reply	I-1	Reply	281
One cannot forecast what other research groups are doing when he/she conducts his/her own research.	I-Reply	I-1	Reply	281
[line_break_token][line_break_token]For better understanding of the readers, we even tried our best in comparing all the concurrent works in Related Works and in Appendix.	I-Reply	I-1	Reply	281
The unique advantage of our work compared to other concurrent ones is presented at the end of Section 2.	I-Reply	I-1	Reply	281
We quote the comments of R#1 here, ‚ÄúThe paper does a decent job mentioning all the concurrent work in the space of learning multi-modal representations that have come out very recently.	I-Reply	I-1	Reply	281
‚Äù[line_break_token][line_break_token]In terms of comparison with BERT, we admit VL-BERT is an extension to the original BERT model.	I-Reply	I-1	Reply	281
But it is non-trivial to extend BERT, designed for NLP tasks, to become a generic representation for visual-linguistic tasks.	I-Reply	I-1	Reply	281
[line_break_token][line_break_token]From the technology contribution perspective, numerous design choices are involved in VL-BERT for incorporating the visual information.	I-Reply	I-1	Reply	281
It is interesting to note that in the previous work of VideoBERT, straight-forward design choices are made by directly turning video clips into visual words.	I-Reply	I-1	Reply	281
The derived model is far from optimal.	I-Reply	I-1	Reply	281
Our VL-BERT is well-designed to be: 1) a unified single-stream architecture, while also benefiting from single-modal pre-trained BERT and Fast R-CNN models; 2) end-to-end trainable with both the visual and linguistic branch parameters; 3) joint trained on both visual-linguistic and text-only corpus, so as to alleviate catastrophic forgetting [Kirkpatrick et al, ``Overcoming catastrophic forgetting in neural networks.	I-Reply	I-1	Reply	281
‚Äù PNAS, 2017.]	I-Reply	I-1	Reply	281
of the text-only corpus in training networks for visual-linguistic tasks.	I-Reply	I-1	Reply	281
[line_break_token][line_break_token]From the practical importance perspective, we derived generic representations for various visual-linguistic tasks, which can be pre-trained on large-scale datasets.	I-Reply	I-1	Reply	281
While previously various networks were designed specifically for different visual-linguistic tasks.	I-Reply	I-1	Reply	281
The related discussions can be found in the Introduction and Related Works sections in the paper.	I-Reply	I-1	Reply	281
[line_break_token][line_break_token]Q#2: Concerns with clarity.	O	O	Reply	281
[line_break_token][line_break_token]A#2: In general, we feel many questions raised are because the topic is at the intersection of computer vision and NLP, with much preliminary knowledge involved.	O	O	Reply	281
Such preliminary knowledge is self-explanatory in the corresponding domain but is unfamiliar for others.	O	O	Reply	281
[line_break_token][line_break_token](a)[tab_token]`` How were words split in sub-words?‚Äù[line_break_token]The sub-words split is by WordPiece embeddings, which is a standard practice in NLP.	B-Reply	B-2	Reply	281
For details, please refer to [Wu, Yonghui, et al "Google's neural machine translation system: Bridging the gap between human and machine translation."	I-Reply	I-2	Reply	281
arXiv preprint 2016.]	I-Reply	I-2	Reply	281
[line_break_token][line_break_token](b)[tab_token]Questions about token embedding.	O	O	Reply	281
[line_break_token]The token embedding is different from one-hot word embedding (e.g., 30k dim).	B-Reply	B-3	Reply	281
It is of much lower dim (e.g., 768-d).	I-Reply	I-3	Reply	281
The visual embedding is projected into the same dimension using a fully-connected layer as shown in Figure 1.	I-Reply	I-3	Reply	281
[line_break_token][line_break_token](c)[tab_token]To describe the two features first.	O	O	Reply	281
[line_break_token]Thanks for the suggestion.	O	O	Reply	281
We would rearrange the paragraph in revision.	B-Reply	B-4	Reply	281
[line_break_token][line_break_token](d)[tab_token]What is the intuition of having the whole image embedding for textual input?	O	O	Reply	281
[line_break_token]To provide visual context for the sentence words.	B-Reply	B-5	Reply	281
[line_break_token][line_break_token](e)[tab_token]Once textual embeddings are masked by [MASK], the related whole image embedding is also masked?	O	O	Reply	281
[line_break_token]No, only textual embeddings are masked to block the linguistic input information.	B-Reply	B-6	Reply	281
[line_break_token][line_break_token](f)[tab_token]Is segment embedding important?	O	O	Reply	281
[line_break_token]Yes, as in BERT, the segment embedding is used to distinguish different input formats.	B-Reply	B-7	Reply	281
[line_break_token][line_break_token](g)[tab_token]How is training coping with the loss during training when considering text-only corpus and conceptual captions?	O	O	Reply	281
[line_break_token]There is no special treatment for the loss during training.	B-Reply	B-8	Reply	281
The loss of Task #1 is averaged over the number of masked tokens.	I-Reply	I-8	Reply	281
And the loss of Task #2 is averaged over the number of masked regions.	I-Reply	I-8	Reply	281
[line_break_token][line_break_token](h)[tab_token]Doesn't it make more sense to have 2 pre-training phases.	O	O	Reply	281
[line_break_token]Our experiments without Text-only Corpus is actually the ‚Äò2 pre-training phases‚Äô suggested by R#3.	B-Reply	B-8	Reply	281
This is because our VL-BERT is initialized from a text-only pre-trained BERT.	I-Reply	I-8	Reply	281
In our full version of VL-BERT, we train VL-BERT on visual-linguistic datasets together with text-only corpus.	I-Reply	I-8	Reply	281
This is for alleviating catastrophic forgetting of the text-only corpus in training networks for visual-linguistic tasks.	I-Reply	I-8	Reply	281
[line_break_token][line_break_token]Q#3: Questions about experimentation.	O	O	Reply	281
[line_break_token][line_break_token]A#3: We address one question due to space limit.	O	O	Reply	281
[line_break_token][line_break_token](a)[tab_token]Masking on raw pixels.	B-Reply	B-9	Reply	281
[line_break_token]The masking would not slow down training.	I-Reply	I-9	Reply	281
In a mini-batch, given an image, some RoIs are randomly sampled to be masked ones.	I-Reply	I-9	Reply	281
The pixels lying in all the masked RoIs are set as zeros in the image at once.	I-Reply	I-9	Reply	281
While the training loss drives the network to predict the labels of all the masked RoIs.	I-Reply	I-9	Reply	281
[line_break_token][line_break_token]As for masking conv maps, we observe obvious overfitting due to information leakage.	I-Reply	I-9	Reply	281

The authors propose a method that incorporates two types of graphs into a graph convolutional networks:[line_break_token][line_break_token](1) the given graph, which the authors refer to as node affinity graph, and [line_break_token](2) the graph that models an affinity between node attribute values.	O	O	Review	102
[line_break_token][line_break_token]The main contribution of their work is a type of graph convolution that combines convolutions operating on these two graphs.	O	O	Review	102
[line_break_token][line_break_token]The paper is densely written and provides several mathematical derivations that are unnecessary to convey the proposed method.	B-Review	B-1	Review	102
Personally, I don't see any benefits in having sections 3.1-3.4 in the main paper.	I-Review	I-1	Review	102
The method actually proposed and evaluated in the paper is described in section 3.5.	I-Review	I-1	Review	102
Sections 3.1-3.4 could be moved to an appendix.	I-Review	I-1	Review	102
They confuse the reader more than they help. (	I-Review	I-1	Review	102
They demonstrate knowledge of graph signal processing on the parts of the authors but little more.)	I-Review	I-1	Review	102
[line_break_token][line_break_token]Trying to provide some theoretical analysis of the proposed method (and standard graph convolutions) by showing that the intra-class variance is reduced is laudable.	B-Review	B-2	Review	102
The theorems, however, only hold under strong assumptions and could, in my opinion, also be moved to an appendix.	I-Review	I-2	Review	102
In the end, they don't have any bearing on the performance of the methods using real-world datasets.	I-Review	I-2	Review	102
Adding some experiments to analyse to what extent the assumptions made by the theorems are met in the given datasets would be an interesting addition to the paper.	I-Review	I-2	Review	102
[line_break_token][line_break_token]The authors discuss related work sufficiently with one exception: there has been recent work on learning the structure of graph neural networks.	B-Review	B-3	Review	102
See for example [1]. The structure is derived/bootstrapped using node attribute similarities and it is shown that augmenting the graph with these new edges improves accuracy significantly.	I-Review	I-3	Review	102
I would like to point the authors specifically to Figure 2 and Table 1 in said paper, where the authors show that adding edges (e.g., based on some node attribute affinity before or during training) is beneficial and improves accuracy.	I-Review	I-3	Review	102
It would therefore be interesting to see how the authors proposed 2-D convolution would compare to a baseline where the edges based on attribute affinity are added to the original (node affinity) graph.	I-Review	I-3	Review	102
It is a (somewhat simpler) alternative way to combine node affinity and node attribute graphs.	I-Review	I-3	Review	102
[line_break_token][line_break_token][1] <a href="https://arxiv.org/pdf/1903.11960.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1903.11960.pdf</a>[line_break_token][line_break_token]The empirical results are mixed.	B-Review	B-4	Review	102
Due to the numerous different variations of DSGC for which experiments were conducted, the difference between DSGC and existing methods is probably not statistically significant (a bonferroni correction was not performed to counteract the multiple comparisons).	I-Review	I-4	Review	102
[line_break_token][line_break_token]Overall this an interesting paper that introduces a way to incorporate node attribute affinity graphs.	O	O	Review	102
It is too densely written and could benefit from moving the theoretical parts to an appendix.	B-Review	B-5	Review	102
They don't really add much to the core of the paper.	I-Review	I-5	Review	102
Moreover, the authors do not consider approaches that also add edges to the graph (based, e.g., on attribute value similarity or during learning, see e.g. [1]) showing that that improves performance even when using a vanilla GCN.	I-Review	I-5	Review	102
A comparison to a baseline that simply adds edges based on attribute affinity to the graph and applied a vanilla GCN should be part of the evaluation.	I-Review	I-5	Review	102
The empirical results are mixed and don't show a clear advantage of the proposed method.	I-Review	I-5	Review	102
[line_break_token]	O	O	Review	102
hank you for your positive and constructive feedback.	O	O	Reply	102
[line_break_token][line_break_token]Q1.	O	O	Reply	102
Comparison with works on learning graph structures such as LDS (<a href="https://arxiv.org/pdf/1903.11960.pdf)."	O	O	Reply	102
target="_blank" rel="nofollow">https://arxiv.org/pdf/1903.11960.pdf).</a>[line_break_token][line_break_token]&gt;&gt; First of all, we would like to thank the reviewer for pointing out this interesting work.	B-Reply	B-5	Reply	102
In the revised manuscript, we have included some discussion on this line of research in the 3rd paragraph of section 2.	I-Reply	I-5	Reply	102
[line_break_token][line_break_token]We have also conducted experiments on LDS.	I-Reply	I-5	Reply	102
Since LDS cannot scale to the size of the 20 Newsgroup dataset (out of GPU Memory) used in our experiments, we follow the authors to test on a 10-category subset of the 20 NG.	I-Reply	I-5	Reply	102
We then test LDS on this subset of 20 NG, L-Cora, and Wiki.	I-Reply	I-5	Reply	102
For classification on each dataset, LDS uses 20 labels per class for training and extra 20 labels per class for validation (the algorithm requires validation).	I-Reply	I-5	Reply	102
Note that we do not use any validation data for the proposed DSGC method for classification.	I-Reply	I-5	Reply	102
Due to the differences in datasets and experimental setup, we do not include the results of LDS in Table 1.	I-Reply	I-5	Reply	102
[line_break_token][line_break_token]Instead, we report the results of LDS in Table 2 to see whether the proposed DSGC can be used to improve LDS.	I-Reply	I-5	Reply	102
We incorporate DSGC into LDS as described in section 5.2 by applying attribute graph convolution on the node features before training.	I-Reply	I-5	Reply	102
The results in Table 2 show that DSGC significantly improves LDS on Newsgroup and Wiki and slightly improves LDS on L-Cora.	I-Reply	I-5	Reply	102
We have also tested another case of LDS without using the given node affinity graphs of the three datasets and observed similar results.	I-Reply	I-5	Reply	102
[line_break_token][line_break_token]The experiments show that DSGC can complement and improve LDS, just as it can complement and improve other SOTA methods based on the regular 1-D graph convolution such as GCN/GAT/GraphSAGE as shown in Table 2.	I-Reply	I-5	Reply	102
[line_break_token][line_break_token][line_break_token]Q2.	O	O	Reply	102
The paper is densely written.	O	O	Reply	102
[line_break_token][line_break_token]&gt;&gt; As the reviewer suggested, we have reorganized sections 3 and 4 to make them more compact in the revised manuscript.	B-Reply	B-1	Reply	102
In section 3, we intend to show how the proposed 2-D graph convolution DSGC is derived, which follows a similar path of the development of 1-D GCN (from ‚Äúspectral networks‚Äù to ‚ÄúChebyNet‚Äù to ‚ÄúGCN‚Äù).	I-Reply	I-1	Reply	102
In section 4, we want to provide some insights into why DSGC works by analyzing the variance reduction effect of node graph convolution and attribute graph convolution respectively.	I-Reply	I-1	Reply	102
[line_break_token][line_break_token]Q3.	O	O	Reply	102
The empirical results are mixed.	O	O	Reply	102
[line_break_token][line_break_token]&gt;&gt; We have improved the presentation of the experiments in the revised manuscript.	B-Reply	B-4	Reply	102
We kindly ask the reviewer to read section 7 about the experiments again.	I-Reply	I-4	Reply	102
Our results are statistically significant.	I-Reply	I-4	Reply	102
For datasets with good node affinity graphs such as 20 Newsgroup and L-Cora, the proposed 2-D graph convolution DSGC (GXF) significantly outperforms most SOTA methods.	I-Reply	I-4	Reply	102
For datasets with bad node affinity graphs such as Wiki, the proposed 2-D graph convolution DSGC (GXF) still outperforms most SOTA methods by a large margin but is less effective than DSGC (XF) (since the node affinity graph G is bad).	I-Reply	I-4	Reply	102
DSGC can also be used to significantly improve SOTA methods including GCN, GAT, LDS and GraphSAGE.	I-Reply	I-4	Reply	102
Please refer to section 7 in the manuscript for more detailed explanation.	I-Reply	I-4	Reply	102
[line_break_token]	O	O	Reply	102

In this paper, the authors proposed a novel scheme to interpret deep neural networks‚Äô prediction by identifying the most important neurons/activations for each category using a Lasso algorithm.	O	O	Review	286
[line_break_token][line_break_token]Firstly, the authors produce a 1-dimensional descriptor for each filter in each convolutional layer for each image.	O	O	Review	286
Then these descriptors are concatenated as a new feature vector for this image.	O	O	Review	286
A feature selection algorithm (u-Lasso) is then trained to minimize the classification loss between the prediction from the new feature vector and the original prediction from DNN (formula (1)).	O	O	Review	286
Finally, the importance of each filter is identified by the weights of the lasso for each category.	O	O	Review	286
[line_break_token][line_break_token]The authors also improved the visual feedback quality over the deconvolution+guided back-propagation methods, and release a new synthetic dataset for benchmarking model explanation.	O	O	Review	286
[line_break_token][line_break_token]The paper is well-written, however, I have several concerns about this paper:[line_break_token][line_break_token]1.	O	O	Review	286
     How to verify the importance of the identified relevant features is a problem.	B-Review	B-1	Review	286
In the experiments, the authors removed features in the network by setting their corresponding layer/filter to zero.	I-Review	I-1	Review	286
The authors only compared their method with randomly removing features.	I-Review	I-1	Review	286
And in Fig 4, the differences seem small for ImageNet.	I-Review	I-1	Review	286
The results are not convincing enough to me.	I-Review	I-1	Review	286
It is a bit baffling randomly removing features did almost as well as the proposed approach.	I-Review	I-1	Review	286
[line_break_token][line_break_token]2.	O	O	Review	286
     I don't think one should get away with only showing some results from the synthetic dataset without showing any quantitative results on any real datasets.	B-Review	B-2	Review	286
I like the idea of having a synthetic dataset where all the parameters are controllable.	I-Review	I-2	Review	286
However in this case it is very simple and maybe lacking enough distracting features that can really test the capability of the algorithm.	B-Review	B-3	Review	286
I would believe quantitative results on a realistic dataset are still necessary for the pubilcation of this paper.	I-Review	I-3	Review	286
[line_break_token][line_break_token]3.	O	O	Review	286
     Recently several papers pointed out some significant issues in Guided BP, [line_break_token][line_break_token]Xie et al A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations.	B-Review	B-4	Review	286
ICML 2018[line_break_token]Adebayo et al Sanity Checks for Saliency Maps.	I-Review	I-4	Review	286
NIPS 2018[line_break_token]Kindermans et al The (Un)reliability of saliency methods.	I-Review	I-4	Review	286
NIPS workshop 2017[line_break_token][line_break_token]can the authors comment on that?	I-Review	I-4	Review	286
Based on those papers I don't seem to think Guided BP is actually doing anything that is relevant to the classification, but is just finding prominent gradients.	I-Review	I-4	Review	286
This, unfortunately would lead to reasonably good behavior on the synthetic dataset created by the authors.	I-Review	I-4	Review	286
Thanks for the feedback.	O	O	Reply	286
[line_break_token][line_break_token]Regarding (1), the ablation of features labeled as "random" refers to settings where features were removed by setting to zero the response of randomly selected filters from layers that were indicated to host important features by the u-lasso optimization.	B-Reply	B-1	Reply	286
[line_break_token]As such, these features (filter responses) are not 100% random per se.	I-Reply	I-1	Reply	286
To verify this aspect, we have conducted an experiment on the full imageNet dataset where we ablated completely randomly selected features  (i.e  both layers and filter locations).	I-Reply	I-1	Reply	286
We computed the mean performance after 5 runs and obtained a classification accuracy of 0.33, which is  10% higher than that when the selected relevant features are ablated (0.23).	I-Reply	I-1	Reply	286
[line_break_token]In addition, different from the other datasets tested with a VGG-based method, the setting of the full imageNet dataset has the highest ratio between classes of interest and features.	I-Reply	I-1	Reply	286
At this higher ratio, features internally modeled by the network are more likely to be shared between the classes.	I-Reply	I-1	Reply	286
As such, ablating one feature may have a side effect on another class as well.	I-Reply	I-1	Reply	286
[line_break_token][line_break_token][line_break_token]Regarding (2), we respectfully disagree.	B-Reply	B-2	Reply	286
Our synthetic dataset may look simple and artificial, but that's on purpose to make it clear beyond discussion what elements are crucial to explain a decision.	I-Reply	I-2	Reply	286
To the best of our knowledge there isn't any realistic dataset with such annotation and in fact, we have no idea how one would go about to create one.	I-Reply	I-2	Reply	286
Nor is there any other unbiased quantitative evaluation setup using realistic data, as far as we know.	I-Reply	I-2	Reply	286
For instance, using semantic labels as done in (Zhang et al, CVPR'18 / arXiv:1710.00935¬Ö ignores the validity of any context cues that fall outside of the object boundaries.	I-Reply	I-2	Reply	286
In our synthetic dataset, the regions to be highlighted are controlled by design, therefore providing an objective means of evaluation.	I-Reply	I-2	Reply	286
If however the reviewer can point us towards a realistic dataset which such level of annotation, we would be happy to try it out, to further strengthen our manuscript.	I-Reply	I-2	Reply	286
[line_break_token][line_break_token]Regarding the presence of distracting features mentioned in (2), we are conducting experiments on the classification task of Pascal VOC'07.	B-Reply	B-3	Reply	286
In this dataset there are several distracting instances/objects per image.	I-Reply	I-3	Reply	286
Initial results show that despite the presence of these distracting objects/elements, our method is able to highlight image regions related to the prediction made by the model.	I-Reply	I-3	Reply	286
If requested by the reviewers, we will revise the manuscript in order to include some of these new results.	I-Reply	I-3	Reply	286
[line_break_token]In addition, adding distracting objects/features could be an interesting way to extend our current synthetic dataset.	I-Reply	I-3	Reply	286
We will work towards having an additional variant of our dataset that includes distracting elements for the moment of its official release	I-Reply	I-3	Reply	286

[Paper Summary][line_break_token]This paper tackles the problem of learning dynamics of non-rigid objects in a physics simulator.	O	O	Review	539
This learned dynamics can then be used for planning later.	O	O	Review	539
The non-rigid objects are represented via a particle-based system.	O	O	Review	539
The dynamics model is learned using NVIDIA's particle-based simulator "Flex".	O	O	Review	539
The main idea is to adapt Interaction Networks [Battaglia, 2016] which was earlier proposed for rigid-body simulators to particle-based simulators.	O	O	Review	539
Instead of maintaining interactions at the level of objects as in [Battaglia, 2016], the proposed approach models interaction at the level of particles.	O	O	Review	539
[line_break_token][line_break_token][Paper Strengths][line_break_token]The paper is clearly written and tackles an important research problem.	O	O	Review	539
The existing literature is presented well.	O	O	Review	539
[line_break_token][line_break_token][Paper Weaknesses][line_break_token]=> The introduction and the text in the first two pages seem to be introducing a new way to model "dynamic" interactions between particles for handling non-rigid transformations.	B-Review	B-1	Review	539
However, upon reading the method section, the approach seems to be a direct application of the Interaction Graph Networks (originally applied to the rigid-body simulator) to the particle-based simulator.	I-Review	I-1	Review	539
The only difference is that instead of maintaining a fully-connected graph (memory and computational bottleneck), each particle is only connected to the near-by particles within distance d.[line_break_token][line_break_token]=> One of the major issue with the paper is the experimental section of the paper.	B-Review	B-2	Review	539
Since the proposed method is quite incremental over the prior work, a strong empirical section is must to justify the approach.	I-Review	I-2	Review	539
Here are the comments:[line_break_token]   - Since the proposed approach is an adaptation of [Battaglia, 2016], it should be compared to other existing methods.	I-Review	I-2	Review	539
The experiment section in its current state does not compare to any baseline.	I-Review	I-2	Review	539
The well-written related work (section-2) talks about (Mrowca et.al.	I-Review	I-2	Review	539
2018) and (Schenck and Fox, 2018) as the works which investigate learning dynamics of deformable objects using a particle-based simulator.	I-Review	I-2	Review	539
However, no comparison is provided to either of the methods.	I-Review	I-2	Review	539
Hence, it is not possible to judge the quality of the presented results.	I-Review	I-2	Review	539
[line_break_token][line_break_token]   - All results in Figure-5 or Figure-3 are quite close to each other.	I-Review	I-2	Review	539
It is not clear whether the improvement is significant or not since the error bars are not provided at all.	I-Review	I-2	Review	539
[line_break_token][line_break_token]   - No ablation is performed to test the sensitivity of the proposed method with respect to the hyper-parameters introduced; for instance, the distance 'd'.	I-Review	I-2	Review	539
[line_break_token][line_break_token]=> The name "Dynamic Particle Interaction" is overloaded with terms, especially, the use of word 'dynamic' here just refers to the interaction of particles to model deformable objects.	B-Review	B-3	Review	539
This "dynamic" interaction is not "learned" but simply hard-coded by deleting the edges which are farther than d distance apart and adding near ones.	I-Review	I-3	Review	539
Something like "Particle-level Interaction Networks" would be a more honest description of the approach.	I-Review	I-3	Review	539
[line_break_token][line_break_token][Final Recommendation][line_break_token]I request the authors to address the comments raised above and will decide my final rating based on that.	O	O	Review	539
With the current set of experiments, the paper doesn't seem to be ready yet.	O	O	Review	539
Dear Reviewer 1,[line_break_token][line_break_token]Thanks again for your constructive comments.	O	O	Reply	539
We have made substantial changes in the revision according to your review.	O	O	Reply	539
In particular, we‚Äôve included detailed comparisons with (Mrowca et al, 2018), ablation studies, and errors bars.	B-Reply	B-2	Reply	539
As the discussion period is about to end, please don‚Äôt hesitate to let us know if there are any additional clarifications that we can offer, as we would love to convince you of the merits of the paper.	O	O	Reply	539
Thanks!	O	O	Reply	539

The paper is on an improvement of multi-task learning by considering the input tasks at two levels: (1) at task level, i.e. the relationship between the tasks and (2) by the data associated with each task.	O	O	Review	100
Their major argument is that most current methods hold the assumption that the tasks are correlated with each other but they conjecture that in the real-world this is not necessarily true and try to model the relationship between the input tasks at these two levels and incorporate that in the learning framework.	O	O	Review	100
To show effectiveness of their approach they test their method on differently oriented public datasets representing graphs, nodes and text and compare performance with some of the recent approaches to multi-task learning.	O	O	Review	100
[line_break_token][line_break_token]Comments to authors[line_break_token]1.	O	O	Review	100
Overall while one could get the gist of the arguments in the paper, it was not thoroughly reviewed by the authors for grammar, so it was hard to follow the finer points of the arguments.	B-Review	B-1	Review	100
There are several grammatical mistakes and errors, on every page, it'd be too cumbersome to point them all out.	I-Review	I-1	Review	100
[line_break_token]2.	O	O	Review	100
The distinction between the "general task dependency" and the "data dependency" does not seem significant enough.	B-Review	B-2	Review	100
The data-dependent task dependency actually depends on the "general task dependency" as stated in the paper.	I-Review	I-2	Review	100
This is probably manifested in the relatively slight improvement of the method compared with the SOTA.	I-Review	I-2	Review	100
Perhaps more clarity on the difference and contribution of each "level" would make the significance stand out  clearer.	I-Review	I-2	Review	100
hank you for your constructive comments.	O	O	Reply	100
We address your questions as follows.	O	O	Reply	100
[line_break_token][line_break_token]Q1: ‚ÄúIt was not thoroughly reviewed by the authors for grammar.	O	O	Reply	100
‚Äù[line_break_token][line_break_token]R1: We apologize for the grammar mistakes.	B-Reply	B-1	Reply	100
We have carefully revised the paper and also re-scrutinized to improve the language.	I-Reply	I-1	Reply	100
[line_break_token][line_break_token]Q2: ‚ÄúPerhaps more clarity on the difference and contribution of each "level" would make the significance stand out clearer.	O	O	Reply	100
‚Äù[line_break_token][line_break_token]R2: The motivation for the multi-level task dependency is the hierarchical structure in text and graph data (i.e. word -&gt; sentence and node -&gt; graph).	O	O	Reply	100
The task dependency at word/node level may be different from the general task dependency.	B-Reply	B-2	Reply	100
[line_break_token][line_break_token]Take sentence classification as an example, besides the general relationship between sentiment analysis tasks and discourse relation identification tasks, words like ‚Äúgood‚Äù or ‚Äúbad‚Äù may transfer more knowledge from sentiment analysis tasks, while words like ‚Äúbecause‚Äù and ‚Äúso‚Äù may transfer more from discourse relation identification tasks.	I-Reply	I-2	Reply	100
[line_break_token][line_break_token]Previous work [1] can only capture the general task dependency but does not utilize the inner hierarchical structure of ‚Äúdiscrete‚Äù data (text and graph).	I-Reply	I-2	Reply	100
An extreme case would be each word/node has the same task dependency, in which our model will perform as well as [1].[line_break_token][line_break_token][line_break_token][1] Taskonomy: Disentangling Task Transfer Learning, 201	O	O	Reply	100

*Summary.*	O	O	Review	464
The paper presents and addresses the problem of performing domain adaptation when the target domain is systematically (i.e., not the result of a stochastic process) missing subsets of the data.	O	O	Review	464
The issue is motivated by applications where one modality of data becomes unavailable in the target domain (e.g., when deciding which ads to serve to new users, the predictor may have access to behavior across other websites but not on a specific merchant's website).	O	O	Review	464
The proposed method learns to map source and target data to a latent space where the representations for the source and target are aligned, the missing components of the target can be inferred, and classification can be performed successfully.	O	O	Review	464
These are achieved by adversarial/optimal transport loss on source and target features, a mean-squared error and adversarial loss on latent generation/imputation, and a cross entropy loss on source label prediction, respectively.	O	O	Review	464
Experiments are performed on digits and click-through rate (CTR) prediction and include a thorough set of baselines/oracles for comparison.	O	O	Review	464
[line_break_token][line_break_token]*Review.*	O	O	Review	464
While the problem statement is novel, I am unconvinced that the advertising experiment includes both a domain adaptation and imputation problem.	B-Review	B-1	Review	464
I describe this in detail below.	I-Review	I-1	Review	464
For this reason, I am giving the paper a weak reject.	I-Review	I-1	Review	464
[line_break_token][line_break_token]*Questions that impacted rating.*	I-Review	I-1	Review	464
[line_break_token]1.	I-Review	I-1	Review	464
Ads experiment: From my understanding, the source domain is the traffic of users who have interacted with (clicked through to?)	I-Review	I-1	Review	464
a specific partner and the target domain is the traffic of the users who have not interacted with that specific partner.	I-Review	I-1	Review	464
The data that needs to be imputed is the click through rate for target users with that specific partner.	I-Review	I-1	Review	464
In this case, it is not obvious to me why there is a domain shift between these two groups of users.	I-Review	I-1	Review	464
This would imply that the traffic of source users and target users is different for other partners.	I-Review	I-1	Review	464
I don't see why this would need to be true.	I-Review	I-1	Review	464
Could the authors provide an explanation as to why this is the case (e.g., by showing that CTRs differ with other (partner, publisher) pairs between source and target).	I-Review	I-1	Review	464
From my understanding, Table 5 only shows CTR averaged across all users in each domain, but does not show that the CTRs differ between source and target users for contexts/(partner, publisher) pairs (i.e., the results in table 5 could be due to the fact that the prior distribution over context is different for source and target users).	I-Review	I-1	Review	464
[line_break_token][line_break_token]*Additional notes.	O	O	Review	464
Immaterial to rating.*	O	O	Review	464
[line_break_token]1.	B-Review	B-1	Review	464
I personally felt that the motivation for UDA vs imputation in the first paragraph was a bit muddled.	B-Review	B-2	Review	464
I think sticking to one example would make the motivation more clear to the reader.	I-Review	I-2	Review	464
E.g., explain the prediction problem for medical imaging (which I assume is disease diagnosis, but it is not stated explicitly), describe how some medical imaging may be missing for certain patients (imputation), then explain that there may be noise across different medical imaging systems (UDA), then list the other applications where this arises with citations (e.g., These phenomena have also been documented in advertising applications [1], ...).	I-Review	I-2	Review	464
[line_break_token]2.	O	O	Review	464
I was surprised by the difference between Adaptation-Partial and the other two train/test conditions in Figure 2 when p=30%.	B-Review	B-3	Review	464
Out of curiosity, do the authors have an explanation for this discrepancy?	I-Review	I-3	Review	464
I would have predicted that, if most of the information necessary for prediction was available in the remaining 70% of the image that the performance of these cases would be very similar.	I-Review	I-3	Review	464
 I think it would be helpful to see the accuracy on the source domain and the labeled target domain to better understand that result.	I-Review	I-3	Review	464
hanks a lot for your feedback and your recommendations.	O	O	Reply	464
We provide below a detailed response.	O	O	Reply	464
[line_break_token][line_break_token]A) Joint domain shift and missing data hypothesis for the ads experiments: [line_break_token]    [line_break_token]We do agree that this is not obvious.	B-Reply	B-1	Reply	464
As mentioned in the paper, the ads problem was our initial motivation for this work and our formulation of the problem comes from preliminary exploratory data analyses performed on ads datasets.	I-Reply	I-1	Reply	464
We have added in Appendix E in the new paper version, distribution plots (Figure 6) and mean values (Table 6) for the different observed features used in the ads-kaggle dataset for the source and target domains.	I-Reply	I-1	Reply	464
This shows that there is indeed a domain shift between the two domains.	I-Reply	I-1	Reply	464
The same conclusion holds for the ads-real dataset.	I-Reply	I-1	Reply	464
More details are provided below.	I-Reply	I-1	Reply	464
[line_break_token]    [line_break_token]Your description of the problem in the detailed comments (*Questions that impacted rating.*)	I-Reply	I-1	Reply	464
is basically right.	I-Reply	I-1	Reply	464
We figured out however that we might not have been precise enough in the text and we provide below more details clarifying the experimental setting.	I-Reply	I-1	Reply	464
[line_break_token][line_break_token]The source dataset is composed of all user-partner pairs for which the user visited the partner and the target dataset is composed of all the user-partner pairs for which the user never visited this partner.	I-Reply	I-1	Reply	464
A key point here is that there are several partners (and of course users) per domain, and this was probably not clear enough from the text.	I-Reply	I-1	Reply	464
Typically we could expect thousands of partners depending on the size of an ads company's partner portfolio.	I-Reply	I-1	Reply	464
For the source domain, we have available complete data (mean statistics on all visited partners + traces on a specific ad partner for a user-partner pair) and for the target domain only partial data (mean statistics but no partner specific traces for a user-partner pair).	I-Reply	I-1	Reply	464
[line_break_token]Regarding domain shift, in Figure 6 Appendix E, we plot the normalized feature distributions for the source (blue plots) and target (red plots) domains.	I-Reply	I-1	Reply	464
While some features have a similar distribution for the source and target domains, many have completely different distributions indicating a clear domain shift.	I-Reply	I-1	Reply	464
This is synthesized in Table 6 Appendix E, giving the mean values for all the features for the two domains.	I-Reply	I-1	Reply	464
We notice that feature 5 is missing on the target.	I-Reply	I-1	Reply	464
[line_break_token][line_break_token]This shift was initially a surprising finding for us too.	I-Reply	I-1	Reply	464
Our hypothesis is that the source domain includes users with a higher overall activity both for visiting partner websites and for interacting with the websites.	I-Reply	I-1	Reply	464
Target domain includes users that are probably less active.	I-Reply	I-1	Reply	464
This is confirmed by the mean value of the features in the two domains in Table 6 Appendix E: feature distributions from users in the source domain tend to have higher mean values than features in the target domain.	I-Reply	I-1	Reply	464
These features typically measure click, visit and sale activities which is consistent with the above hypothesis	I-Reply	I-1	Reply	464

Summary:[line_break_token][line_break_token]This paper introduces the use of asymptotic constraints to find[line_break_token]prune the search space of mathematical expressions for symbolic[line_break_token]regression.	O	O	Review	20137
 This is done by training a neural network to[line_break_token]generate production rules conditioned on being given the[line_break_token]asymptotic constraints and previously generated production[line_break_token]rules.	O	O	Review	20137
This neural network is then itself also used to guide a[line_break_token]MCTS to generate mathematical expressions.	O	O	Review	20137
[line_break_token][line_break_token]The algorithms is compared against a reasonable set of baselines[line_break_token]and related algorithms.	O	O	Review	20137
[line_break_token][line_break_token]Feedback:[line_break_token][line_break_token]This is a very clear and well-written paper.	O	O	Review	20137
It was[line_break_token]straightforward to understand and very easy to see how it fits in[line_break_token]with the broader literature.	O	O	Review	20137
The insight about using asymptotic[line_break_token]constraints makes the result a bit limited to only generating[line_break_token]mathematical expressions, and it would have been a bit nicer if[line_break_token]there was something more generically applicable to program[line_break_token]synthesis in general.	B-Review	B-1	Review	20137
It's not really clear to me how the[line_break_token]existing work extends to programs.	I-Review	I-1	Review	20137
[line_break_token][line_break_token]The evaluation was very thorough and the appropriate algorithms[line_break_token]were compared against the work.	O	O	Review	20137
I came away with a good[line_break_token]understanding of how well the model generalizes to larger[line_break_token]expressions compared to existing work.	O	O	Review	20137
[line_break_token][line_break_token]Minor notes:[line_break_token][line_break_token]The abstract is a bit inaccurate as the NN generates production rules[line_break_token]and not expressions.	B-Review	B-2	Review	20137
hank you for your encouraging comments and constructive feedback.	O	O	Reply	20137
[line_break_token][line_break_token]We presented a general two-step framework of first learning a generative model of production rules in a grammar and then using that model to guide MCTS for efficient search.	B-Reply	B-1	Reply	20137
We acknowledge that we evaluated this framework in the context of symbolic regression and focused on the leading power properties.	I-Reply	I-1	Reply	20137
However, we believe our framework and similar modeling ideas could be equally useful in general program synthesis settings, where other properties such as program‚Äôs desired time complexity or maximum control flow nesting could be used to condition the generative model.	I-Reply	I-1	Reply	20137
We hope to explore such directions in future, but we will add more discussion about the generality of our approach.	I-Reply	I-1	Reply	20137
[line_break_token][line_break_token]We agree that the naming of the neural network component is confusing.	B-Reply	B-2	Reply	20137
We have changed the name to "conditional production rule generating neural network" everywhere and clarified it in the paper, including in the abstract	I-Reply	I-2	Reply	20137

Strengths[line_break_token]ÔÅÆ-- An interesting proposal for a smaller CNN architecture designed for embedded CNN applications.	O	O	Review	591
[line_break_token]ÔÅÆ-- Balanced exploration of CNN macroarchitecture and microarchitecture with fire modules.	O	O	Review	591
[line_break_token]ÔÅÆ-- x50 less memory usage than AlexNet, keeping similar accuracy [line_break_token]ÔÅÆ-- strong experimental results[line_break_token][line_break_token]Weaknesses[line_break_token]ÔÅÆ--Would be nice to test Sqeezenet on multiple tasks[line_break_token][line_break_token]ÔÅÆ--lack of insights and rigorous analysis into what factors are responsible for the success of SqueezeNet.	B-Review	B-1	Review	591
For example, how are ResNet and GoogleNet connected to the current architecture?	B-Review	B-2	Review	591
Another old paper (Analysis of correlation structure for a neural predictive model with application to speech recognition, Neural Networks, 1994) also showed that the ‚Äúby-pass‚Äù architecture by mixing linear and nonlinear prediction terms improves long term dependency in NN based on rigorous perturbation analysis.	I-Review	I-2	Review	591
Can the current work be placed more rigorously on theoretical analysis?	I-Review	I-2	Review	591
[line_break_token]	O	O	Review	591
Thank you for your feedback and encouragement.	O	O	Reply	591
Let me take a moment to discuss the weaknesses/questions that you mentioned.	O	O	Reply	591
[line_break_token][line_break_token]1.	O	O	Reply	591
SqueezeNet on other tasks.	O	O	Reply	591
[line_break_token]We recently added a detection layer at the end of SqueezeNet and fine-tuned it on KITTI object detection.	B-Reply	B-1	Reply	591
We identified a variant of SqueezeNet that is simultaneously the fastest, smallest, and most accurate (in terms of mean-average precision) model on the KITTI detection task, compared to previous reported results.	I-Reply	I-1	Reply	591
We will be posting this to the KITTI leaderboard soon, but meanwhile we have released some details in this paper:[line_break_token]<a href="https://arxiv.org/abs/1612.01051" target="_blank" rel="nofollow">https://arxiv.org/abs/1612.01051</a>[line_break_token][line_break_token]2.	O	O	Reply	591
Theoretical analysis.	O	O	Reply	591
[line_break_token]We certainly appreciate the theoretical aspects of deep neural network research.	B-Reply	B-2	Reply	591
If you ask a more specific question, we will do our best to answer it.	I-Reply	I-2	Reply	591
[line_break_token][line_break_token]3.	O	O	Reply	591
Placing SqueezeNet in the context of GoogLeNet and ResNet.	O	O	Reply	591
[line_break_token]Take a look at our response to the earlier comment thread, "SqueezeNet versus other models than AlexNet."	B-Reply	B-2	Reply	591
[line_break_token][line_break_token]	O	O	Reply	591

  *Synopsis*:[line_break_token]  This paper focuses on current limitations of deploying RL approaches onto real world robotic systems.	O	O	Review	604
They focus on three main points: the need to use raw sensory data collected by the robot, the difficulty of handcrafted reward functions without external feedback, the lack of algorithms which are robust outside of episodic learning.	O	O	Review	604
They propose a complete system which addresses these concerns, combining approaches from the literature and novel improvements.	O	O	Review	604
They then provide an empirical evaluation and ablation testing of their approach and other popular systems, and show a demonstration on a real robotic system.	O	O	Review	604
[line_break_token] [line_break_token]  Main Contributions:[line_break_token]  - A discussion of the current limitations of RL on real robotic systems[line_break_token]  - A framework for doing real world robotic RL without extra instrumentation (outside of the robot).	O	O	Review	604
[line_break_token][line_break_token]  *Review*: [line_break_token]  Overall, I think the paper is well written and provides some nice analysis of the current state of RL and robotics.	O	O	Review	604
I am not as familiar with the RL for robotics literature, but from some minor snooping around I believe these ideas to be novel and useful for the community.	O	O	Review	604
I have a few suggestions for the authors, and a few critical pieces I would like added to the main text.	O	O	Review	604
[line_break_token][line_break_token]  Critical additions:[line_break_token]  1.	O	O	Review	604
I would like some more details on your simulation experiments.	B-Review	B-3	Review	604
Specifically:[line_break_token]    - How many runs were your experiments?	I-Review	I-3	Review	604
[line_break_token]    - What are the error bars on your plots?	I-Review	I-3	Review	604
[line_break_token]    - What ranges of hyper-parameters did you test for tuning?	I-Review	I-3	Review	604
[line_break_token][line_break_token]  2.	O	O	Review	604
I would quite like the discussion of the real world tasks from the appendix to appear in the main text.	B-Review	B-1	Review	604
Specifically, giving the evaluation metrics you mentioned in the appendix.	I-Review	I-1	Review	604
[line_break_token][line_break_token]  Suggestions/Questions:[line_break_token][line_break_token]  S1: It is not clear if a VAE is the best choice for unsupervised representation learning for RL agents.	B-Review	B-2	Review	604
Although a reasonable choice, Yashua Bengio recently released a look at several unsupervised techniques for representation learning in Atari which you may want to look at: <a href="https://arxiv.org/pdf/1906.08226.pdf."	O	O	Review	604
target="_blank" rel="nofollow">https://arxiv.org/pdf/1906.08226.pdf.</a> [line_break_token][line_break_token]  Q1: Did you try any of the other approaches on the real robotics system?	B-Review	B-4	Review	604
Or was there no way to deploy these algorithms to your specific setup without instrumentation?	I-Review	I-4	Review	604
e thank the reviewer for their insightful and constructive feedback!	O	O	Reply	604
We have run additional hardware comparisons and quantitative evaluations as requested (Section 6.3) and have updated the paper according to your suggestions and comments to better discuss related work.	B-Reply	B-1	Reply	604
We respond to individual concerns in detail below:[line_break_token][line_break_token]‚Äúdiscussion of the real world tasks from the appendix to appear in the main text.	O	O	Reply	604
‚Äù[line_break_token]-&gt; We have moved this discussion from the Appendix to Section 6.3.	B-Reply	B-1	Reply	604
Additional comparisons to a VICE (Fu et al) baseline have been added for real world experiments in Section 6.3, Fig 8.	I-Reply	I-1	Reply	604
We see that our algorithm is able to outperform this baseline on the real world tasks.	I-Reply	I-1	Reply	604
[line_break_token][line_break_token]‚ÄúIt is not clear if a VAE is the best choice for unsupervised representation learning for RL agents.	O	O	Reply	604
‚Äú[line_break_token]-&gt; While a VAE works well in the domains we considered in this paper, we certainly agree that a VAE is not necessarily the optimal choice for all RL domains.	B-Reply	B-2	Reply	604
We have updated Section 4.2 to reflect this explicitly, and have included references to Anand et al, Hjelm et al and Lee et al as you pointed out as alternative methods for representation learning.	I-Reply	I-2	Reply	604
We did not mean to claim that VAE‚Äôs were the only representation learning scheme that might suffice in this scenario, and many of the schemes suggested might also be effective.	I-Reply	I-2	Reply	604
[line_break_token][line_break_token]‚ÄúI would like some more details on your simulation experiments‚Ä¶‚Äù[line_break_token]-&gt; We have updated Section 6 and Appendix C to include details about the experimental setup, both in simulation and in the real world.	B-Reply	B-3	Reply	604
We have updated Fig 7 after removing a small visual artifact in the environment, which allows the baselines to perform a bit better, but still maintains the same trends.	I-Reply	I-3	Reply	604
[line_break_token]-- The plots are averaged over 5 random seeds for each method and task [line_break_token]-- The (shaded) error regions correspond to the variance of the seeds for each curve[line_break_token]-- Appendix B has been updated to include information on ranges of hyperparameters tuned, in addition to the optimal values used to generate the plots in figures 7 &amp; 8[line_break_token][line_break_token]‚ÄúQ1: Did you try any of the other approaches on the real robotics system?	I-Reply	I-3	Reply	604
Or was there no way to deploy these algorithms to your specific setup without instrumentation?‚Äù[line_break_token]-&gt; Yes we did add a new real-world comparison to the VICE baseline, as requested, in Fig 8.	B-Reply	B-4	Reply	604
We have updated Section 6.3 with a comparison in the real world on the valve rotation and bead manipulation tasks.	I-Reply	I-4	Reply	604
A quantitative evaluation corroborates findings from the simulated environments and shows that our method outperforms these methods in terms of sample efficiency and robustness.	I-Reply	I-4	Reply	604

This paper focuses on transmitting messages reliably by learning joint coding with the bandwidth-limited channel.	O	O	Review	20326
The authors justify joint systems outperform their separate counterparts when coding is performed by flexible learnable function approximators.	O	O	Review	20326
Their experiments show the advantage of their design decisions via improved distoration and FID scores.	O	O	Review	20326
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]1.	O	O	Review	20326
This paper is clearly written and well-structured in logic.	O	O	Review	20326
For example, the authors use Figures 1 and 2 assist readers to catch the difference between joint communication system and separate communication system.	O	O	Review	20326
[line_break_token][line_break_token]2.	B-Review	B-1	Review	20326
This paper gives a reliazation of joint source-channel coding, especially to give auxilary latent variable decoders.	O	O	Review	20326
[line_break_token][line_break_token]3.	O	O	Review	20326
This paper has been verified in both Gaussian channel and bandwidth-limited channel.	O	O	Review	20326
The empirical results show the advantage of joint coding.	O	O	Review	20326
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]1.	O	O	Review	20326
Intuitively, you Section 4.3 should be better than Section 4.2.	B-Review	B-1	Review	20326
However, I don't see any difference or major items to justify this kind of benefits.	I-Review	I-1	Review	20326
Could you please explain why techniques in Section 4.3 can outperform these in Section 4.2.	I-Review	I-1	Review	20326
[line_break_token][line_break_token]2.	I-Review	I-1	Review	20326
Although the authors verified their work on CelebA, it seems that the proposed method has very limited applications.	B-Review	B-2	Review	20326
If possible, the authors should do more datasets to verify their proposed method, which will be more useful to boarder readers.	I-Review	I-2	Review	20326
hank you for your review.	O	O	Reply	20326
In the following, we would like to address both of your questions.	O	O	Reply	20326
[line_break_token][line_break_token]Question 1: Why does joint coding outperform separate coding specifically in the ML setting?	O	O	Reply	20326
[line_break_token][line_break_token]This is indeed very interesting and has sparked various discussions among ourselves as well.	B-Reply	B-1	Reply	20326
[line_break_token]There is of course classical research that illuminates why solving the joint problem may be possible in some scenarios where solving the communication problem separately is not possible (under more realistic assumptions).	I-Reply	I-1	Reply	20326
[line_break_token][line_break_token]More specifically, in the ML context when separate coding is performed, it is understood that the channel coder receives the distribution of source embeddings.	I-Reply	I-1	Reply	20326
However, to be source agnostic, this distribution needs to be a generic (i.e. source data independent) distribution.	I-Reply	I-1	Reply	20326
For example, this could be a standard Gaussian as is used in a basic VAE.	I-Reply	I-1	Reply	20326
This, however, induces a bottleneck: The source coder needs to match the aforementioned generic prior distribution such that the channel coder receives the correct input.	I-Reply	I-1	Reply	20326
At the same time, if the source coder was to perfectly match this prior, there would be no mutual information I(source data; source embedding), and thus nothing would be learned.	I-Reply	I-1	Reply	20326
Joint coding does not suffer from this trade-off problem.	I-Reply	I-1	Reply	20326
We believe this is why it outperforms separate coding in our experiments.	I-Reply	I-1	Reply	20326
[line_break_token][line_break_token]Questions 2a:  Relevance of the bandwidth-limited channel.	O	O	Reply	20326
[line_break_token][line_break_token]We hope in our main rebuttal we could point out why modelling with the bandwidth limited channel has such a central role in modelling communication, and why introducing learning to coding is a relevant contribution.	B-Reply	B-2	Reply	20326
[line_break_token][line_break_token]Question 2b: How does our approach extend to other domains (non-vision)?	O	O	Reply	20326
[line_break_token][line_break_token]Concerning the dataset we used, we are currently running an experiment on imagenet to diversify our claim.	B-Reply	B-2	Reply	20326
[line_break_token]We do believe, however, that our findings extend far beyond image datasets to video, language, audio and even beyond perceptual tasks.	I-Reply	I-2	Reply	20326
We believe that there is evidence that the architecture of the neural encoders and decoders that are employed will determine the success in these domain.	I-Reply	I-2	Reply	20326
Domain specific architectures are, however, not the focus of this work.	I-Reply	I-2	Reply	20326
Farsad et al (2018) for example considers a language application.	I-Reply	I-2	Reply	20326
[line_break_token][line_break_token][line_break_token]We thank the reviewer for any further feedback and are happy to discuss more if desired.	O	O	Reply	20326

The paper proposes a technique to perform reasoning on mathematical formulas in a latent space.	O	O	Review	549
The model is trained to predict whether a rewrite rule can be applied to a formula given its latent representation.	O	O	Review	549
When the rewrite is possible, the model also predicts the embedding of the resulting formula.	O	O	Review	549
Experiments show that the network can be applied multiple steps in a row, while operating only in the embedding space.	O	O	Review	549
[line_break_token][line_break_token]1.	O	O	Review	549
As mentioned in the paragraph before Section 4.1, it would be much simpler to consider a single latent embedding space L. In that case, \sigma and \alpha become unnecessary and we only need to train \omega.	B-Review	B-1	Review	549
Did you try to have a single network?	I-Review	I-1	Review	549
This seems a much more natural approach to me, and I'm surprised that you did not start with that.	I-Review	I-1	Review	549
From my experience, aligning embedding spaces is something that usually does not work very well, especially in high dimension.	I-Review	I-1	Review	549
The role of \sigma seems very redundant given \omega.	I-Review	I-1	Review	549
[line_break_token][line_break_token]2.	O	O	Review	549
If you consider \sigma, why do you also predict the rewrite success with \omega?	B-Review	B-2	Review	549
Couldn't it be simply a function from S x S -&gt; L ?	O	O	Review	549
[line_break_token][line_break_token]3.	O	O	Review	549
The graph neural networks used in the model are not described in the paper, only a reference to Paliwal et al (2019) is given.	B-Review	B-3	Review	549
It would be helpful to have a brief paragraph describing this architecture, for readers not familiar with the referenced paper.	I-Review	I-3	Review	549
[line_break_token][line_break_token]4.	B-Review	B-1	Review	549
How large is the training set of (T, P) pairs?	B-Review	B-4	Review	549
I don't think this is mentioned in the paper.	I-Review	I-4	Review	549
[line_break_token][line_break_token]5.	O	O	Review	549
To train \sigma and \omega, the negative instances are selected randomly.	B-Review	B-5	Review	549
You mention that negative mining should improve over this strategy.	I-Review	I-5	Review	549
What does negative mining correspond to in this context?	I-Review	I-5	Review	549
Are there bad rewrites better than others?	I-Review	I-5	Review	549
[line_break_token][line_break_token]6.	O	O	Review	549
Did you consider using an inverse function (say G), that maps an embedding in L / L' back to S (i.e. the inverse function of gamma / gamma').	B-Review	B-6	Review	549
I would imagine that even if an embedding X is a bit noisy, because not exactly equal to gamma(P) where P is the expression it represents, you could consider doing the propagation with gamma(G(X)).	I-Review	I-6	Review	549
This could be a possibility to remove the noise you have when doing multi-step operations (and potentially go way beyond 4 steps).	I-Review	I-6	Review	549
Also, G could be used to check whether you obtain the expected formula after 4 steps, which would be a more informative information than the L2 distance between the resulting embedding and the embedding of the final formula.	I-Review	I-6	Review	549
[line_break_token][line_break_token]Overall, the model is a bit complicated (e.g. question 1.),	O	O	Review	549
but the results are promising, the paper is well written, and the ability to manipulate formula embeddings is probably going to be useful in the context of theorem proving.	O	O	Review	549
e thank the reviewer for the constructive feedback.	O	O	Reply	549
The use of a fixed embedding space and a separate space was useful as it naturally prevents the collapse of embeddings.	B-Reply	B-1	Reply	549
However this could be counteracted by stopping the gradient at the right place in the simplified architecture  which was suggested in the original paper and is now described in the updated paper.	I-Reply	I-1	Reply	549
[line_break_token][line_break_token]As suggested, we have added further analysis of failure cases, and describe strategies for negative mining from these examples.	B-Reply	B-3	Reply	549
In addition, we have included a brief description of the graph neural network architecture used in Paliwal et al (2019).	I-Reply	I-3	Reply	549
We also include further details on the construction of training set.	I-Reply	I-3	Reply	549
 [line_break_token][line_break_token]Training a decoder to predict the results of rewrites from the latent space is an interesting idea, but is technically challenging and we felt it was out of scope for this paper.	B-Reply	B-5	Reply	549
We managed to counteract the noisiness of predicted embedding by training on noisy embeddings which trains the network to be robust to random changes and improves the prediction of multi-step rewrites significantly.	I-Reply	I-5	Reply	549
[line_break_token][line_break_token]We are grateful for the suggestions that contributed significantly to improving the quality of the paper	O	O	Reply	549

Summary:[line_break_token]The paper proposes a method for coordinating the exploration efforts of agents in a multi-agent reinforcement learning setting.	O	O	Review	705
The approach has two main components: (i) learning different exploration policies using different "joint" intrinsic rewards; and (ii) learning a higher-level policy that selects one of the exploration policies to be executed at the beginning of each episode.	O	O	Review	705
[line_break_token][line_break_token]Each agent has its own novelty function which quantifies the novelty of observation seen by that agent.	O	O	Review	705
To coordinate exploration, these novelty functions are combined using aggregation functions to produce intrinsic reward for the agent.	O	O	Review	705
Each such aggregating function yields a different intrinsic reward.	O	O	Review	705
The authors propose several such aggregating functions as examples, however the method is applicable to other aggregating functions as well, as long as they can be computed off-policy.	O	O	Review	705
[line_break_token][line_break_token]During training, the higher level policy selects one of the exploration policies which is then executed for the entire episode.	O	O	Review	705
The episode data is used in two ways: (i) to train the higher-level policy using policy gradients for maximizing extrinsic rewards along with an entropy term; and (ii) to train each exploration policy using soft actor-critic on its own intrinsic reward function (and extrinsic reward) in an off-policy manner.	O	O	Review	705
[line_break_token][line_break_token]Experiments done on grid-world and VizDoom environment for three different tasks demonstrate that, on most tasks, the proposed approach performs at least as well as separately trained individual intrinsic rewards.	O	O	Review	705
Further ablation studies confirm that both the hierarchical setup and the "joint" intrinsic rewards are useful.	O	O	Review	705
[line_break_token][line_break_token][line_break_token]Questions to the Authors:[line_break_token][line_break_token]1.	O	O	Review	705
The second sentence in section 5 is not clear - "Furthermore, the type of reward ... sufficiently complex".	B-Review	B-1	Review	705
The high-level policy selects an exploration strategy at the beginning of each episode and then sticks to it for the entire duration of the episode.	I-Review	I-1	Review	705
Changing the exploration strategy over the course of training might be useful in cases when agent needs to switch to a different exploration strategy after reaching a particular bottleneck state.	I-Review	I-1	Review	705
However, this would require the exploration strategy to be changed in the middle of an episode which is not supported.	I-Review	I-1	Review	705
Could you give an example where the exploration strategy must be changed over time even if one only selects the strategy at the beginning of each episode?	I-Review	I-1	Review	705
Also, why not select the exploration strategy after every fixed number of time steps within each episode (by making high-level policy a function of the current state)?	I-Review	I-1	Review	705
[line_break_token][line_break_token]2.	O	O	Review	705
Analyzing the role of high-level policy and its evolution over time on different tasks would be a very nice addition to the paper.	B-Review	B-2	Review	705
Qualitative experiments demonstrating that it provides a curriculum which helps the agents in surpassing the performance of individual intrinsic rewards would be helpful.	I-Review	I-2	Review	705
[line_break_token][line_break_token]3.	O	O	Review	705
Should \Pi in (10) also depend on i?	B-Review	B-3	Review	705
[line_break_token][line_break_token]Though paper is reasonably well written I find the contributions are very marginal.	B-Review	B-4	Review	705
If authors can position the paper well with the existing literature and bring out the impact of the contributions it will be helpful.	I-Review	I-4	Review	705
[line_break_token]	O	O	Review	705
hank you for the detailed and insightful comments.	O	O	Reply	705
To address your first point, we can provide an illustrative example.	B-Reply	B-1	Reply	705
Let us say that we are attempting to solve task 1, where agents must spread out and collect all rewards on the map.	I-Reply	I-1	Reply	705
In this case it is possible that Leader-Follower rewards may be most successful at first since they all explore similar areas simultaneously, so if they happen to reach a region where a reward is located, there will be multiple agents there to have a chance at collecting it; however, this behavior is not optimal, as there are other rewards to collect around the map.	I-Reply	I-1	Reply	705
At this point in training, burrowing rewards may become more optimal since at least one of the agents will continue exploring the same region to collect the reward, but the other agents will explore other regions, potentially collecting more rewards.	I-Reply	I-1	Reply	705
We find that this type of situation occurs with reasonable frequency during training.	I-Reply	I-1	Reply	705
Re-selecting the exploration strategy within each episode may be useful for tasks with multi-stage goals, though we don‚Äôt consider these types of tasks in this work.	I-Reply	I-1	Reply	705
[line_break_token][line_break_token][tab_token]We have analyzed the role of the policy selector and have found some interesting behaviors.	B-Reply	B-2	Reply	705
We refer the reviewer to the revised Appendix (section A.6) for a discussion on this analysis.	I-Reply	I-2	Reply	705
Finally, the \Pi in equation 10 (i.e. the policy selector) does not depend on i, as all agents roll out their policies trained on the same intrinsic reward simultaneously.	I-Reply	I-2	Reply	705
In other words, there is no mixing of different policy types.	I-Reply	I-2	Reply	705
[line_break_token][line_break_token][tab_token]With respect to the position of our work within the literature, we believe we are the first work to address the problem of spatially coordinated exploration in deep multi-agent reinforcement learning.	B-Reply	B-4	Reply	705
Many multi-agent tasks require some notion of spatial coordination for optimal performance (e.g. search-and-rescue), and our method induces such coordination in exploration with decentralized agents, enabling success in these types of tasks with sparse rewards.	I-Reply	I-4	Reply	705
We show that naive applications of single-agent methods (Figure 3b independent and centralized intrinsic rewards) to multi-agent systems are relatively ineffective when compared to our approach.	I-Reply	I-4	Reply	705

The paper tackles the task of music generation.	O	O	Review	476
They use an orderless NADE model for the task of "fill in the notes".	O	O	Review	476
Given a roll of T timesteps of pitches, they randomly mask out some pitches, and the model is trained to predict the missing notes.	O	O	Review	476
This follows how the orderless NADE model can be trained.	O	O	Review	476
During sampling, one normally follows an ancestral sampling procedure.	O	O	Review	476
For this, an ordering is defined over outputs, and one runs the model on the current input, samples one of the outputs according to the order, adds this output to the next input, and continues this procedure until all outputs have been sampled.	O	O	Review	476
The key point of the paper is that this is a bad sampling strategy.	O	O	Review	476
Instead, they suggest the strategy of Yao et al 2014, which uses a blocked Gibbs sampling approach.	O	O	Review	476
The blocked Gibbs strategy instead masks N inputs randomly and independently, samples them, and repeats this procedure.	O	O	Review	476
The point of this strategy is the make sure the sampling chain mixes well, which will happen for large N. However, since the samples are independent, having a large N gives incoherent samples.	O	O	Review	476
Thus, the authors follow an annealed schedule for N, making it smaller over time, which will eventually reduce to ancestral sampling (giving global structure to the sample).	O	O	Review	476
They conduct a variety of experiments involving both normal metrics and human evaluations, and find that this blocked Gibbs sampling outperforms other sampling procedures.	O	O	Review	476
[line_break_token][line_break_token]This is a well written paper - great job.	O	O	Review	476
[line_break_token][line_break_token]My main problem with the paper is that having read Uria and Yao, I don't know how much I have learned from this work in the context of this being an ICLR submission.	O	O	Review	476
If this was submitted to some computational music / art conference, this paper would be a clear accept.	O	O	Review	476
However, for ICLR, I don't see enough novelty compared with previous works this builds upon.	O	O	Review	476
Orderless NADE is an established model.	O	O	Review	476
The blocked Gibbs sampling and annealing scheme are basically the exact same one used in Yao.	O	O	Review	476
Thus, the main novelty of this paper is its application to the music domain, and finding that Yao's method works better for sampling music.	O	O	Review	476
This is a good contribution, but more tailored to those working in the music domain.	O	O	Review	476
If the authors found that these results also hold for other domains like images (e.g. on CIFAR / tiny Imagenet) and text (e.g. document generation), then I would change my mind and accept this paper for ICLR.	O	O	Review	476
Even just trying musical domains other than Bach chorales would be useful.	O	O	Review	476
However, as it stands, the experiments are not convincing enough.	O	O	Review	476
Thank you for your review.	O	O	Reply	476
 We respond to your question above.	O	O	Reply	476

This paper proposes a Frank-Wolfe based method, called DFW, for training Deep Network.	O	O	Review	473
The DFW method linearizes the loss function into a smooth one, and also adopts Nesterov Momentum to accelerate the training.	B-Review	B-1	Review	473
Both techniques have been widely used in the literature for similar settings.	B-Review	B-2	Review	473
This paper mainly focuses on the algorithm part, but only empirically demonstrate the convergence results.	B-Review	B-3	Review	473
[line_break_token][line_break_token]After reading the authors‚Äô feedback and the paper again, I think overall this is a good paper and should be of broader interest to the broader audience in machine learning community.	O	O	Review	473
[line_break_token][line_break_token]In Section 6.1, the authors mention the good generalization is due to large number of steps at a high learning rate.	B-Review	B-4	Review	473
Can we possibly get any theoretical justification on this?	I-Review	I-4	Review	473
[line_break_token][line_break_token]This paper uses multi class hinge loss as an example for illustration.	B-Review	B-5	Review	473
Can this approach be applied for structure prediction, for example, various ranking loss?	I-Review	I-5	Review	473
We thank the reviewer for their comments.	O	O	Reply	473
We provide answers below:[line_break_token][line_break_token]* ‚ÄúThe DFW linearizes the loss function into a smooth one, and also adopts Nesterov momentum to accelerate the training.	O	O	Reply	473
‚Äù [line_break_token]We would like to clarify this statement: one of the key ideas of the DFW algorithm is not to linearize the loss function, but only the model.	B-Reply	B-1	Reply	473
[line_break_token][line_break_token]* ‚ÄúBoth techniques have been widely used in the literature for similar settings‚Äù.	O	O	Reply	473
[line_break_token]We wish to clarify the main technical contributions of this paper, since the SVM smoothing and the application of Nesterov acceleration are not the main novelty of this work.	B-Reply	B-2	Reply	473
We discuss the summary of contributions (available at the end of section 1 of the paper) in the context of technical novelty.	I-Reply	I-2	Reply	473
[line_break_token]- Employing a composite framework allows us to use an efficient primal-dual algorithm.	I-Reply	I-2	Reply	473
As stated by Reviewer 1, this is novel in the context of deep neural networks: ‚ÄúTo my knowledge, the submission is the first sound attempt to adapt this type of Dual-based algorithm for optimization of Deep Neural Network [..]‚Äù.	I-Reply	I-2	Reply	473
[line_break_token]- Crucially, our approach yields an update at the same computational cost per iteration as SGD and with the same level of parallelization.	I-Reply	I-2	Reply	473
In contrast, in the closest approach to ours, the algorithm of Singh & Shawe-Taylor (2018) can only process a single sample at a time.	O	O	Reply	473
This results in an approach whose runtime is virtually multiplied by the batch-size (it would be slower by two orders of magnitude in typical classification settings, including for the experiments of this paper).	B-Reply	B-2	Reply	473
[line_break_token]- We do not mean to claim that the application of Nesterov acceleration is a technical novelty in itself.	I-Reply	I-2	Reply	473
However, its use is subtle in our case (see appendix A.7) and it is empirically crucial for good performance, hence its mention in the paper.	I-Reply	I-2	Reply	473
[line_break_token]- To the best of our knowledge, the hyper-parameter free smoothing approach that we propose in this work is novel (but is not the main contribution).	I-Reply	I-2	Reply	473
[line_break_token][line_break_token]We have adapted the abstract and summary of contributions to focus on the main novelty, which is an optimization algorithm for deep neural networks with an optimal step-size at the same computational cost per iteration as SGD.	I-Reply	I-2	Reply	473
[line_break_token][line_break_token]If the reviewer remains concerned by a lack of novelty, we would be grateful if he/she could provide specific references so that we can compare them in detail with the DFW algorithm.	O	O	Reply	473

The paper states that basic transformation (translation and rotation) can easily fool a neural network in image classification tasks.	O	O	Review	719
Thus, image classification models are actually more vulnerable than people thought.	O	O	Review	719
The message conveyed by the paper is clear and easy to get.	O	O	Review	719
The experiments are natural and interesting.	O	O	Review	719
Some interesting points:[line_break_token]  --The model trained with data augmentation that covers the attack space does not alleviate the problem sufficiently.	O	O	Review	719
[line_break_token]  --Gradient descent does not provide strong attack, but grid search does.	O	O	Review	719
This may be due to the high non-concavity, compared to the small perturbation case.	O	O	Review	719
[line_break_token][line_break_token]One possible question is the novelty, as this idea is so simple that probably many people have observed similar phenomenon--but have not experimented that extensively.	B-Review	B-1	Review	719
[line_break_token]Also, there are some related works that also show the vulnerability under spatial transformations.	I-Review	I-1	Review	719
But some are concurrent works to 1st version of the paper (though published), so I tend to not to judge it by those works.	I-Review	I-1	Review	719
 [line_break_token][line_break_token]Other comments: [line_break_token]1.	O	O	Review	719
page 3 in the paragraph starting with ‚ÄòWe implement ‚Ä¶‚Äô, the author chooses a differentiable bilinear interpolation routine.	B-Review	B-3	Review	719
However, the interpolation method is not shown or explained.	I-Review	I-3	Review	719
[line_break_token]2.	O	O	Review	719
In term of transformation, scaling and reflecting are also transformations.	B-Review	B-4	Review	719
It should be straightforward to check the robustness with respect to them.	I-Review	I-4	Review	719
Comments?	I-Review	I-4	Review	719
[line_break_token]3.	O	O	Review	719
Header in tables is vague.	B-Review	B-5	Review	719
Like ‚ÄòNatural‚Äô or ‚ÄòOriginal‚Äô, etc.	I-Review	I-5	Review	719
More description of the Header under tables is helpful.	I-Review	I-5	Review	719
[line_break_token]4.	O	O	Review	719
For CIFAR10 and especially for ImageNet dataset, Aug30 and Aug40 models showed lower accuracy&nbsp;than No Crop model&nbsp;on Nat test set.	O	O	Review	719
This is little strange because data augmentation (such as random rotation) is commonly used strategy to improve test accuracy.	B-Review	B-6	Review	719
I think this might mean that the model is not trained enough and underfitted, maybe because excessive data augmentation lowered the training speed.	I-Review	I-6	Review	719
[line_break_token]	O	O	Review	719
We thank the reviewer for their kind words.	O	O	Reply	719
[line_break_token][line_break_token]Regarding the novelty of our paper: We agree that we are not the first to experimentally study the robustness of classifiers to rotations and translation (as we mention in our paper including relevant citations).	B-Reply	B-1	Reply	719
We would like to emphasize however that simply pointing out this flaw is not enough to establish it as a relevant problem with current classifiers.	I-Reply	I-1	Reply	719
After all, we also need to understand if this issue is only a small glitch that we can fix with a few simple modifications, or if it requires more thought and further research.	I-Reply	I-1	Reply	719
This is why we go into significantly more depth than prior work with respect to possible fixes and show that standard approaches (data augmentation, robust optimization, ensembles / majority voting) do help to some extent, but are still far from fully solving the problem. (	I-Reply	I-1	Reply	719
Please also refer to our response to Reviewer 3 on the same topic.)	I-Reply	I-1	Reply	719
[line_break_token][line_break_token]We will address the other points raised below.	O	O	Reply	719
[line_break_token][line_break_token]1.	O	O	Reply	719
We used the approach from "Spatial Transformer Networks" (Jaderberg et al 2015) and their open source implementation.	B-Reply	B-3	Reply	719
We will clarify this point in our updated manuscript and add a link to the implementation.	I-Reply	I-3	Reply	719
[line_break_token][line_break_token]2.	O	O	Reply	719
We agree that scaling and reflecting are natural transformations to consider.	B-Reply	B-4	Reply	719
We decided to restrict ourselves to two transformations and perform a comprehensive study in this case, rather than perform fewer experiments with more transformations.	I-Reply	I-4	Reply	719
We chose translations since ConvNets are often claimed to be inherently robust to these transformations, and rotations since we believe they are the simplest to describe.	I-Reply	I-4	Reply	719
Moreover, rotations don't discard any image information (other than edge effects) while (say) downscaling does.	I-Reply	I-4	Reply	719
[line_break_token][line_break_token]3.	O	O	Reply	719
 We will update the manuscript to clarify the table headers.	B-Reply	B-5	Reply	719
[line_break_token][line_break_token]4.	O	O	Reply	719
To the best of our knowledge, none of the publicly available implementations for training state-of-the-art ImageNet or CIFAR10 models use random rotations as data augmentation.	B-Reply	B-6	Reply	719
This is likely due to the fact that random rotations typically do not yield  any benefits in (non-robust) test error (as our experimental results show).	I-Reply	I-6	Reply	719
[line_break_token][line_break_token]We would also like to emphasize that all of our models were trained until convergence (the loss plateaued) and hence the reduced test performance is not an artifact of training for insufficient steps (we will add a note about this to our manuscript).	I-Reply	I-6	Reply	719
At a high level, a decrease in test performance due to data augmentation is not surprising.	I-Reply	I-6	Reply	719
If the transformations used are not present in the test set, then a model that has learned to be invariant to these transformations will typically perform worse on the test set. (	I-Reply	I-6	Reply	719
This is also the case when learning models that are adversarially robust to L_p perturbations; there is a decrease in test accuracy.)	I-Reply	I-6	Reply	719
As an extreme, consider an MNIST model that learns to be invariant to rotations up to 180 degrees.	I-Reply	I-6	Reply	719
Clearly, this invariance is only hurting the model's performance since it cannot easily distinguish '6' from '9'.	I-Reply	I-6	Reply	719

Summary: [line_break_token][line_break_token]This paper presents a new training algorithm for vector-quantized autoencoders (VQVAE), a discrete latent variable model akin to continuous variational autoencoders.	O	O	Review	1029
[line_break_token]The authors propose a soft-EM training algorithm for this model, that replaces hard assignment of latent codes to datapoints with a weighted soft-assignment.	O	O	Review	1029
[line_break_token][line_break_token]Overall the technical writing in the paper is sloppy, and the presentation of the generative model takes the form of an algorithmic description of the training algorithm, rather than being a clear definition of the generative model itself.	B-Review	B-1	Review	1029
[line_break_token][line_break_token]The technical presentation of the work by the authors starts only at page 5 (taking less than a full page), after several pages of imprecise presentation of previous and related work.	B-Review	B-2	Review	1029
The paper could be significantly improved by making this preceding material more concise and rigorous.	I-Review	I-2	Review	1029
[line_break_token][line_break_token]Quantitative experimental evaluation is limited to a machine translation task, which is rather uncommon in the literature on generative latent variable models.	B-Review	B-3	Review	1029
I would expect evaluation in terms of held-out data log-likelihood (ie bits-per-dimension) used in probabilistic generative models, and possibly also using measures from the GAN literature such as inception scores.	I-Review	I-3	Review	1029
Datasets that are common include CIFAR-10 and resized variants of the imagenet dataset.	I-Review	I-3	Review	1029
[tab_token] [line_break_token][line_break_token][line_break_token]Specific comments:[line_break_token][line_break_token]- Please adhere to the ICLR template bibliography style, which is far more readable than the style that you used.	B-Review	B-4	Review	1029
[line_break_token][line_break_token]- Figure 1 does not seem to be referenced in the text.	B-Review	B-5	Review	1029
[line_break_token][line_break_token]- The last paragraph of section 2.1 is unclear.	B-Review	B-6	Review	1029
It mentions a sampling a sequence of latent codes.	I-Review	I-6	Review	1029
The notion of sequentiality has not been mentioned before, and it is not clear what it refers to in the context of the model defined so far up to that point.	I-Review	I-6	Review	1029
[line_break_token][line_break_token]- The technical notation is very sloppy.	O	O	Review	1029
[line_break_token]* In numerous places the paper refers to the joint distribution P(x1,‚Ä¶,x_n, z1, ‚Ä¶, zn) without defining that the distribution factorizes across the samples (xi,zi), and without specifying the forms of p(zi) and p(xi|zi).	B-Review	B-7	Review	1029
[line_break_token]* This makes that claims such as ‚Äúcomputing the expectation in the M step (Equation 11) is computationally infeasible‚Äù are not verifiable.	I-Review	I-7	Review	1029
[line_break_token][line_break_token]- Please be clear about how much is gained by replacing the exact M-step with a the one based on the samples from the posterior computed in the E-step.	B-Review	B-8	Review	1029
[line_break_token][line_break_token]- What is the reason to decode the weighted average of the embedding vectors, rather than decoding all of them, and updating the decoder in a weighted manner?	B-Review	B-9	Review	1029
[line_break_token][line_break_token]- reference 14 for Variational autoencoders is incorrect, please use the following citation instead: [line_break_token]@InProceedings{kingma14iclr,[line_break_token]  Title                    = {Auto-Encoding Variational {B}ayes},[line_break_token]  Author                   = {D. Kingma and M. Welling},[line_break_token]  Booktitle                = {{ICLR}},[line_break_token]  Year                     = {2014}[line_break_token]}[line_break_token][line_break_token]- The related work section (4) provides a rather limited overview of relevant related work.	B-Review	B-10	Review	1029
[line_break_token]Half of it is dedicated to recent advances in machine translation, which does not bear a direct connection to the technical material presented in section 3.	B-Review	B-11	Review	1029
[line_break_token][line_break_token]- There is no justification of using *causal* self-attention on the source embedding, is this a typo?	B-Review	B-12	Review	1029
[line_break_token][line_break_token]- As for the experimental evaluation results: it seems that distillation is a much more critical factor to achieve good performance than the proposed EM training of the VQ-VAE model.	B-Review	B-13	Review	1029
Unfortunately, this fact goes unmentioned when discussing the experimental results.	I-Review	I-13	Review	1029
[line_break_token][line_break_token]- What is the significance of the observed differences in BLEU scores?	B-Review	B-14	Review	1029
Please report average performance and standard deviations over several runs with randomized parameter initialization and batch scheduling.	I-Review	I-14	Review	1029
[line_break_token][line_break_token]- It seems that the tuning of the number of discrete latent codes (table 2 in appendix) and other hyper-parameters (table 3 in appendix) was done on the test set, which is also used to compare to related work.	B-Review	B-15	Review	1029
A separate validation set should be used for hyper parameter tuning in machine learning experiments.	I-Review	I-15	Review	1029
[line_break_token][line_break_token]- It seems that all curves in figure 3 collapse from about 45 BLEU to values around 17 BLEU, why is this?	B-Review	B-16	Review	1029
The figure is hard to read since poor quality, and curves that are superposed.	I-Review	I-16	Review	1029
[line_break_token]	O	O	Review	1029
We thank the reviewer for taking the time to read our paper.	O	O	Reply	1029
Below we address the specific points raised by the reviewer:[line_break_token][line_break_token]>[line_break_token]Overall the technical writing in the paper is sloppy....[line_break_token]<[line_break_token][line_break_token]In this work, we improve upon VQ-VAE to learn shorter latent representations of a target sentence in order to speed up MT, rather than to train a generative model.	B-Reply	B-1	Reply	1029
We achieve considerable speedup in decoding state of the art NMT models without much loss in BLEU (a universally accepted metric for translation quality), which has powerful implications for real world, production level MT systems.	I-Reply	I-1	Reply	1029
While evaluating the improvements of our training for generative modeling is interesting, our focus is on using VQ-VAE for a practical task.	I-Reply	I-1	Reply	1029
[line_break_token][line_break_token]Moreover, we have now added a paragraph on the generative process (Page 3).	I-Reply	I-1	Reply	1029
We hope that this will clarify some of the content.	I-Reply	I-1	Reply	1029
We welcome the reviewer to share what they think is "sloppy" and "imprecise", and what would help us further improve the content of the paper.	I-Reply	I-1	Reply	1029
[line_break_token][line_break_token]>[line_break_token]The technical presentation of the work by the authors starts only at page 5...[line_break_token]<[line_break_token][line_break_token]Our goal is to use the autoencoder from VQ-VAE as a tool to compress the target sentence for fast decoding.	B-Reply	B-2	Reply	1029
We therefore chose to focus on the part of the algorithm, describing it's connection to hard-EM and our improvements on it using EM.	I-Reply	I-2	Reply	1029
We would appreciate concrete suggestions to improve the content.	I-Reply	I-2	Reply	1029
[line_break_token][line_break_token]>[line_break_token]Quantitative experimental evaluation is limited to a machine translation task...[line_break_token]<[line_break_token][line_break_token]The main focus of our work is to design a better non-autoregressive machine translation model and which is an area of active research (see for e.g., [1, 2, 3, 4]).	B-Reply	B-3	Reply	1029
None of those works evaluate their proposed method on datasets other than machine translation because the goal of their work is non-autoregressive MT.	I-Reply	I-3	Reply	1029
We do not care about generative modeling of images with VQ-VAE because plenty of other models do it much better (for e.g., a GAN/VAE/PixelCNN++).	I-Reply	I-3	Reply	1029
[line_break_token][line_break_token]The keywords of our paper states: "machine translation, vector quantized autoencoders, non-autoregressive, NMT", while the TL;DR of our submission is "Understand the VQ-VAE discrete autoencoder systematically using EM and use it to design non-autogressive translation model matching a strong autoregressive baseline."	I-Reply	I-3	Reply	1029
[line_break_token][line_break_token]>[line_break_token]- The related work section (4) provides a rather limited overview of relevant related work...[line_break_token]<[line_break_token][line_break_token]Again, the main aim of our work is to speed up the decoding for real world Neural Machine Translation (NMT) systems, which is an active area of research (see e.g., [1, 2, 3, 4]).	B-Reply	B-11	Reply	1029
We have focussed on generative models that are practically relevant to non-autoregressive NMT and because of page limitations we have not been able to include every paper on generative modeling.	I-Reply	I-11	Reply	1029
If we have missed relevant references we would appreciate if the reviewer would let us know what they are.	I-Reply	I-11	Reply	1029
[line_break_token] [line_break_token][1] <a href="https://openreview.net/forum?id=B1l8BtlCb" target="_blank" rel="nofollow">https://openreview.net/forum?id=B1l8BtlCb</a>[line_break_token][2] <a href="http://proceedings.mlr.press/v80/kaiser18a/kaiser18a.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v80/kaiser18a/kaiser18a.pdf</a>[line_break_token][3] <a href="https://openreview.net/forum?id=r1gGpjActQ" target="_blank" rel="nofollow">https://openreview.net/forum?id=r1gGpjActQ</a>[line_break_token][4] <a href="https://arxiv.org/abs/1802.06901" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.06901</a	O	O	Reply	1029

This paper provides a depth learning architecture (global-local structure) from two images.	O	O	Review	10090
It claims that SoTA depth can be estimated from the supervision of a very sparse ground truth by leveraging the optical flow information between two images.	O	O	Review	10090
In the experiments, it shows superior performance than other baseline methods such as Eigen's network and DispNet.	O	O	Review	10090
[line_break_token][line_break_token]Pros:[line_break_token]1: The paper is well written and motivations are clearly explained.	O	O	Review	10090
[line_break_token]2: The architecture proposed is reasonable and generate good results, since it accept the ground truth scale from sparse map and relative dense matching cues from optical flow, where implicitly relative camera pose is from global module.	O	O	Review	10090
[line_break_token][line_break_token][line_break_token]Cons:[line_break_token]1`: It is a fairly standard network design similar to DeMoN[25], where motion network for global pose and local dense network for local matching.	B-Review	B-1	Review	10090
[line_break_token][line_break_token]1: The claim of  robustness to camera intrinsics is not solved in principle but due to training using ground truth from multiple dataset .	B-Review	B-2	Review	10090
It still suffer from depth motion confusion if there is no ground truth depth guidance when testing.	I-Review	I-2	Review	10090
 It is also unfair for comparison of this metric with unsupervised approach where a universal intrinsic is assumed.	I-Review	I-2	Review	10090
[line_break_token][line_break_token]2: I think the comparison might not be fair since the baselines are all single image estimation networks, while the approach has two images, where disparities are serving as a strong cue for depth.	B-Review	B-3	Review	10090
Other possible  architectures such as flow net, pwc net,  DeMoN[25] and stereo networks such as (gc-net or psm-net) should be considered since these networks are more focus on feature matching.	I-Review	I-3	Review	10090
 [line_break_token][line_break_token]3:  Even for single image network, eigen's method is not SoTA, the author may consider (1)  as one of the baseline, etc.	O	O	Review	10090
[line_break_token][line_break_token](1) "Deeper Depth Prediction with Fully Convolutional Residual Networks"[line_break_token][line_break_token]	B-Review	B-4	Review	10090
e thank the reviewer for the detailed comments.	O	O	Reply	10090
 We address the raised concerns below.	O	O	Reply	10090
We hope these clarifications help better understanding our contribution and experiment design and we are looking forward to hearing back from the reviewer.	O	O	Reply	10090
[line_break_token][line_break_token]We respectfully disagree that our architecture is very similar to the one proposed in DeMoN [25]. Here are the main differences:[line_break_token]We predict the convolutional filters in an input dependent way to transform local matches in depth.	B-Reply	B-1	Reply	10090
There is no similar network in the literature to the best of our knowledge.	I-Reply	I-1	Reply	10090
[line_break_token]We do not explicitly predict camera pose, but a hidden representation of it.	I-Reply	I-1	Reply	10090
[line_break_token]We do not iteratively transform flow to depth using geometry equations.	I-Reply	I-1	Reply	10090
[line_break_token][line_break_token]Since the reviewer might have slightly misunderstood our problem setup, we briefly summarize it here.	B-Reply	B-2	Reply	10090
We are interested in the problem of learning depth from very sparse supervision signal (available only at training time!),	I-Reply	I-2	Reply	10090
similar to‚Äúhaptic feedback‚Äù, without explicitly using geometry.	I-Reply	I-2	Reply	10090
 Our evaluation was not designed to thoroughly show the advantage over state-of-the-art methods, but to fairly study the new problem setting.	I-Reply	I-2	Reply	10090
In order to do so, we compared to a set of well known architectures for depth estimation, which we tuned to reach the best performance on our task (see Section 6.2.1  in the Appendix).	I-Reply	I-2	Reply	10090
Since our method and the baselines are tuned for the task and trained on exactly the same data, we believe that our evaluation is fair: any advantage our method has is due to the architecture, not the training regime.	I-Reply	I-2	Reply	10090
We have modified section 4.2 to clarify this point.	I-Reply	I-2	Reply	10090
[line_break_token][line_break_token]The experiment with varying intrinsics was designed with the explicit goal of showing that state-of-the art unsupervised depth estimation approaches strongly depend on the camera calibration parameters: when intrinsics are precisely know they can be very good, but are brittle otherwise.	B-Reply	B-3	Reply	10090
Even though concurrent unsupervised approaches can learn intrinsics together with depth [2], they still require intrinsics to be constant over time.	I-Reply	I-3	Reply	10090
 Our method, in contrast, can adapt to instantaneous  changes in camera parameters.	I-Reply	I-3	Reply	10090
Why is this evaluation not fair?	I-Reply	I-3	Reply	10090
[line_break_token][line_break_token]As requested by the reviewer, we added two additional baselines:[line_break_token]PWC-Net (Table 8, Appendix): We added a convolutional head on top of the off-the-shelf PWC-Net architecture and finetuned the entire system with only the very sparse depth loss.	B-Reply	B-4	Reply	10090
We found its performance to be generally poor, mainly due to overfitting.	I-Reply	I-4	Reply	10090
Details could be found in the Appendix in Table 8.	I-Reply	I-4	Reply	10090
[line_break_token]The FCRN architecture from [1] (Table 2, main manuscript):  In order to make a fair comparison, we tuned this architecture for our task of learning from sparse supervision.	I-Reply	I-4	Reply	10090
Specifically, we changed its input layer to provide it with the same input as ours:  a pair of frames and the optical flow.	I-Reply	I-4	Reply	10090
We also had to change the activation function of the network from Relu to Leaky Relu to have better performance (details in the appendix in section 6.2.1).	I-Reply	I-4	Reply	10090
We then trained this baseline with exactly the same input as ours, and we found its performance to be lower than our method, but similar to our DispNet baseline [48, manuscript].[line_break_token][line_break_token][1] Laina, Iro, et al "Deeper depth prediction with fully convolutional residual networks."	O	O	Reply	10090
2016 Fourth international conference on 3D vision (3DV).	O	O	Reply	10090
IEEE, 2016.	O	O	Reply	10090
[line_break_token][2] Gordon, Ariel, et al "Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras."	O	O	Reply	10090
arXiv preprint arXiv:1904.04998 (2019)	O	O	Reply	10090

This paper tackles the task of rotation estimation in a setting where both labelled and unlabelled examples are available for training.	O	O	Review	10254
It proposes to learn a generative model of images (a VAE), where the ‚Äòcode‚Äô is factored into a latent vector z and the object rotation r.  As in training a VAE, an image encoder that predicts the distribution over (z, r) and the generator are jointly trained, but with additional supervision on the distribution over r for the labelled examples.	O	O	Review	10254
[line_break_token][line_break_token]I think the overall idea of learning a disentangled generative model in a semi-supervised setting is simple and elegant, and could in principle help leverage unlabelled data.	O	O	Review	10254
However,  I do have some concerns regarding the specific contributions of this work, and several reservations about the experiments reported, and would overall argue for rejection.	O	O	Review	10254
[line_break_token][line_break_token]Concerns:[line_break_token]1) The central empirical result stated is that using this approach allows one to reduce amount of labelled data by 10-20 %.	B-Review	B-1	Review	10254
First, even if valid, this is not a very convincing reduction in the amount of supervision.	I-Review	I-1	Review	10254
However, I feel this claim is not well-established by the experiments:[line_break_token][line_break_token]1a)  The paper should report a baseline with only using the loss in eqn 3 and only training the encoder (using various fractions of training data) to predict the rotation i.e. purely discriminative training without training a generative model.	I-Review	I-1	Review	10254
The current plots of performance vs fraction of labelled data don't mean much until compared to a similar plot for this baseline.	I-Review	I-1	Review	10254
The current results don't really highlight the importance of training the generative model or using the unlabelled data.	I-Review	I-1	Review	10254
[line_break_token][line_break_token]1b) I think there are some inconsistencies in performances reported in Fig 2.	B-Review	B-2	Review	10254
I assume the test set is same despite different training data, because the paper states "All of the trained models are evaluated with respect to the complete test set".	I-Review	I-2	Review	10254
In this regard, I am puzzled why using 100% labelled data with 16 renders is significantly better than using 50% labelled data with 32 renders -- these should imply similar number of labelled examples, and more unlabelled ones in the former.	I-Review	I-2	Review	10254
[line_break_token][line_break_token]2) While the discussion points to this, the paper would really benefit from having results in a real setting, in particular as pose estimation is a field with a lot of prior methods that have been shown to work in these settings.	B-Review	B-3	Review	10254
The current results are all in a setup with synthetic, unoccluded data, without background variation, equidistant camera uniformly sampled along a circle.	I-Review	I-3	Review	10254
The central idea of using a generative model would be much more difficult to operationalize in a realistic setting where these simplifying assumptions are not made, and I'd only be convinced about the applicability of the approach by results in that setting.	I-Review	I-3	Review	10254
As a possible setup, one case use many imagenet images in conjunction with labelled examples in PASCAL3D+ to try this approach.	I-Review	I-3	Review	10254
[line_break_token][line_break_token]3) The overall approach maybe novel in context of pose estimation, but this idea of learning a disentangled generative model is not, and there are several papers which do so with varying amount of supervision e.g. see [1] below for similar ideas, and pointers.	B-Review	B-4	Review	10254
While some details here may vary, in context of these prior works, I'd view this paper as mostly applying well-established ideas to a new task.	I-Review	I-4	Review	10254
[line_break_token][line_break_token]--[line_break_token]In addition to the above, I have a question regarding the training/testing data:[line_break_token]Q: The dataset description only states data was randomly divided - was this random division at an image level, or model level i.e. could different renderings of the same model be in train and test set?	B-Review	B-5	Review	10254
[line_break_token]--[line_break_token][line_break_token][1] Learning Disentangled Representations with Semi-Supervised Deep Generative Models, NIPS 2017.	O	O	Review	10254
Siddharth et al	O	O	Review	10254
ear reviewer, I would like to thank you for the time and effort spent in analyzing this paper and for the specific suggestions made to improve this work.	O	O	Reply	10254
We will answer the concerns presented in the review and indicate the future actions to improve the paper.	O	O	Reply	10254
[line_break_token]1) The central empirical result stated is that using this approach allows one to reduce amount of labelled data by 10-20 %.	O	O	Reply	10254
First, even if valid, this is not a very convincing reduction in the amount of supervision.	O	O	Reply	10254
However, I feel this claim is not well-established by the experiments:[line_break_token]1a) The paper should report a baseline with only using the loss in eqn 3 and only training the encoder (using various fractions of training data) to predict the rotation i.e. purely discriminative training without training a generative model.	O	O	Reply	10254
The current plots of performance vs fraction of labelled data don't mean much until compared to a similar plot for this baseline.	O	O	Reply	10254
The current results don't really highlight the importance of training the generative model or using the unlabeled data.	O	O	Reply	10254
[line_break_token]A: Thank you very much for your suggestion.	O	O	Reply	10254
We will include these experiments in a future version of the paper.	B-Reply	B-1	Reply	10254
[line_break_token][line_break_token]1b) I think there are some inconsistencies in performances reported in Fig 2.	O	O	Reply	10254
I assume the test set is same despite different training data, because the paper states "All of the trained models are evaluated with respect to the complete test set".	O	O	Reply	10254
In this regard, I am puzzled why using 100% labelled data with 16 renders is significantly better than using 50% labelled data with 32 renders -- these should imply similar number of labelled examples, and more unlabeled ones in the former.	O	O	Reply	10254
[line_break_token]A: To answer this question, it is important to clarify that the split between labeled and unlabeled data is done at 3D model level.	B-Reply	B-2	Reply	10254
This means that for 100% labeled and 16 renders the CVAE sees all the available 3D models in the training dataset but only from 16 different angles whereas for the 50% labeled and 32 renders, the model just sees half of the 3D models but with renders that have more angle coverage.	I-Reply	I-2	Reply	10254
Therefore, even though the amount of data is similar in both cases, one case has less examples at model level (which would mean that it has seen less variability in).	I-Reply	I-2	Reply	10254
[line_break_token][line_break_token]2) While the discussion points to this, the paper would really benefit from having results in a real setting, in particular as pose estimation is a field with a lot of prior methods that have been shown to work in these settings.	O	O	Reply	10254
The current results are all in a setup with synthetic, unoccluded data, without background variation, equidistant camera uniformly sampled along a circle.	O	O	Reply	10254
The central idea of using a generative model would be much more difficult to operationalize in a realistic setting where these simplifying assumptions are not made, and I'd only be convinced about the applicability of the approach by results in that setting.	O	O	Reply	10254
As a possible setup, one case use many imagenet images in conjunction with labelled examples in PASCAL3D+ to try this approach.	O	O	Reply	10254
[line_break_token]A: Thank you very much for your suggestion, this can further strengthen our claims.	B-Reply	B-3	Reply	10254
We will include these experiments in a future version of the paper.	B-Reply	B-1	Reply	10254
[line_break_token][line_break_token]3) The overall approach maybe novel in context of pose estimation, but this idea of learning a disentangled generative model is not, and there are several papers which do so with varying amount of supervision e.g. see [1] below for similar ideas, and pointers.	O	O	Reply	10254
While some details here may vary, in context of these prior works, I'd view this paper as mostly applying well-established ideas to a new task.	O	O	Reply	10254
[line_break_token]A: We agree with the fact that we are using the established framework from [1] in a new setting.	B-Reply	B-4	Reply	10254
One important detail to be taken into account is that we are incorporating prior geometrical knowledge specific to our task in the method.	I-Reply	I-4	Reply	10254
Since rotations have specific topological properties, we have chosen a suitable latent space for the predictions of the network (in this case choosing a circle S^1 as latent space).	I-Reply	I-4	Reply	10254
In a future version of the paper we will try to emphasize this perspective from our work and search for new ways to include more topological properties into our predictions and latent representations.	I-Reply	I-4	Reply	10254
[line_break_token]4) In addition to the above, I have a question regarding the training/testing data: Q: The dataset description only states data was randomly divided - was this random division at an image level, or model level i.e. could different renderings of the same model be in train and test set?	O	O	Reply	10254
[line_break_token]A: The training/testing dataset were divided at model level i.e. during training the CVAE has received no renders from the testing 3D models.	B-Reply	B-5	Reply	10254
This way we ensure there has been no information leakage about certain models from the training dataset into the testing phase.	I-Reply	I-5	Reply	10254
[line_break_token]Once again, we would like to thank the reviewer for taking the time to analyze the work and provide useful suggestions to improve our work.	O	O	Reply	10254
[line_break_token]-- [1] Learning Disentangled Representations with Semi-Supervised Deep Generative Models, NIPS 2017.	O	O	Reply	10254
Siddharth et al	O	O	Reply	10254

The paper describes a cache side-channel attack on a deep learning model.	O	O	Review	1553
In a cache side-channel attack, the attacker sets up a process on the same machine where the victim process (that is running the training or evaluation job for the DNN model) is running.	O	O	Review	1553
It is assumed that the victim process uses a common shared library for DNN computations as the attacking process.	O	O	Review	1553
The attacking process flushes the cache, then observes access times for key functions.	O	O	Review	1553
The paper shows that, based on the speed of accessing previously flushed functions, the attacker can discover the high-level network architecture, namely the types of layers and their sequence.	O	O	Review	1553
The paper shows that, by spying on such cache access patterns in the Tensorflow library, this method can reliably extract the above high-level information for 11 different network architectures.	O	O	Review	1553
It also describes a few counterattack alternatives whereby the victim can obfuscate its cache access patterns for self-protection.	O	O	Review	1553
[line_break_token][line_break_token]The significance of the results is not clear to me.	B-Review	B-1	Review	1553
The extracted information is very high level.	I-Review	I-1	Review	1553
What realistic attacks can be constructed from such a coarse-grained fingerprinting?	I-Review	I-1	Review	1553
The experimental results show that the fingerprint can be used to map the architecture to one of the 13 well-known architectures (VCC16, ResNet, DenseNet, Inception, etc.).	I-Review	I-1	Review	1553
But so what?	I-Review	I-1	Review	1553
What does the victim lose by revealing that it's using one of a few very well known types of DNNs (the ones tested in this paper).	I-Review	I-1	Review	1553
There may very well be a good reason why this is very dangerous, but that is not explained in the paper.	I-Review	I-1	Review	1553
Not being familiar with this line of research and its significance, I looked up several of the related papers (Suciu et al 2018, Tramer et al 2017, Papernot et al 2017, Yan et al 2018).	I-Review	I-1	Review	1553
None of them could explain why this particular type of fingerprinting is dangerous.	I-Review	I-1	Review	1553
[line_break_token][line_break_token]Of the cited previous work, Yan et al 2018 seems to present the most closely related approach.	B-Review	B-2	Review	1553
The method described in that paper is very similar: cache side attack on a shared library through a co-located attacker process.	I-Review	I-2	Review	1553
They monitor at a finer grain -- Generalized Matrix Multiplications -- and are thus able to infer more details such as the size of the layers.	I-Review	I-2	Review	1553
This also makes the inference problem harder -- they were able to narrow down the search space of networks from >4x10^35 to 16 (on VGG16).	O	O	Review	1553
On the surface, the results presented in this paper seem stronger.	B-Review	B-2	Review	1553
But they are actually solving a much easier problem -- their search space is one of 13 well-known networks.	I-Review	I-2	Review	1553
To me, Yan et al's approach is a much more powerful and promising setup.	I-Review	I-2	Review	1553
[line_break_token][line_break_token]Overall, while the paper is clearly written and presents the idea succinctly, it is derivative of previous research, and the results are not stronger.	O	O	Review	1553
I'm not an expert in this area, so it's possible that I missed something.	O	O	Review	1553
Based on my current understanding, however, I recommend reject.	O	O	Review	1553
We thank the reviewer for the constructive feedback.	O	O	Reply	1553
We will update the paper accordingly.	O	O	Reply	1553
Additionally, we clarify here the significance of DNN fingerprinting attacks and the relation to the concurrent work of (Yan et al 2018).	O	O	Reply	1553
[line_break_token][line_break_token](1) The threat of DNN fingerprinting attacks and the significance of our results.	O	O	Reply	1553
[line_break_token][line_break_token]Prior work on black-box attacks [1, 2, 3] against neural networks assumes an adversary who has knowledge of the victim's network architecture.	B-Reply	B-1	Reply	1553
This is an impractical assumption, and thus, releasing this assumption is the last-mile problem: if an attacker can easily know the architecture of a victim network, this will enable most black-box attacks on DNNs.	I-Reply	I-1	Reply	1553
For instance, without this knowledge, the success of black-box adversarial sample crafting can decrease dramatically, as illustrated in [7]: in attacks against transfer learning services, where the attacker has partial knowledge about the victim network's architecture, having lesser knowledge can decrease the attack's success rate from 88.4% (only the last 3-4/16 layers are unknown) to 1.2% (the last 6/16 layers are unknown).	I-Reply	I-1	Reply	1553
Additionally, DNNs are often proprietary and represent the key intellectual property, and thus their architectures are hidden from attackers.	I-Reply	I-1	Reply	1553
The reconstruction of DNN attributes is also the topic of [4], published at ICLR'18, where the open reviews deemed the problem setting novel and interesting.	I-Reply	I-1	Reply	1553
[line_break_token][line_break_token]What is more, this simple cache side-channel attack is more effective than other network reconstruction attacks proposed in prior work [4, 5]. These approaches are either time intensive (i.e., 40 GPU days for the technique proposed in [4]) or monitor computations while an attacker actively queries a victim model.	I-Reply	I-1	Reply	1553
With our DeepRecon attack, we demonstrate that high-level architectural information --- that prior work aims to extract --- can be easily leaked through our side-channel attacks with little computation and passive monitoring (Sec.	I-Reply	I-1	Reply	1553
3.2-3.4).	I-Reply	I-1	Reply	1553
This allows an attacker to reconstruct the full network architecture of an arbitrary network (Sec.	I-Reply	I-1	Reply	1553
3.5) without specifying or assuming knowledge of a network family.	I-Reply	I-1	Reply	1553
[line_break_token][line_break_token]Moreover, our results go beyond proposing and analyzing a fingerprinting attack.	I-Reply	I-1	Reply	1553
We propose a statistical model for fingerprinting to quantify the importance of each piece of leaked information to the attacker's success (Sec.	I-Reply	I-1	Reply	1553
4).	I-Reply	I-1	Reply	1553
We also propose simple and effective defenses that obfuscate the observations made through cache side-channels, which can be implemented without specific hardware or operating system support (Sec 5).	I-Reply	I-1	Reply	1553
[line_break_token][line_break_token]To the best of our knowledge, this represents the first comprehensive assessment of the vulnerability of DNNs to cache side-channel attacks.	I-Reply	I-1	Reply	1553
We hope that our results will stimulate follow-on work on defending ML systems against such attacks	I-Reply	I-1	Reply	1553

Value-Driven Hindsight Modelling proposes a method to improve value function learning.	O	O	Review	20319
The paper introduces the hindsight value function which estimates the expected return at a state conditioned on the future trajectory of the agent.	O	O	Review	20319
How use this hindsight value function is not obvious, since an agent does not have access to the future states needed in order to take actions (for Q-Learning) and the hindsight value function is a biased gradient estimator for training policy gradient methods.	O	O	Review	20319
[line_break_token][line_break_token]The authors train the standard value function (which does not have access to future information) to predict the features which the highsight value function learns to summarize the value relevant parts of the future trajectory.	O	O	Review	20319
These predicted features can then be used in place of the actual hindsight value function, circumventing the issues discussed above.	O	O	Review	20319
The authors argue that this auxiliary objective provides a richer training signal to the normal value function, helping it to better learn what information in a given state is relevant to predicting future rewards.	O	O	Review	20319
[line_break_token][line_break_token]The paper is well structured and written, flowing from high level motivation and review into the core of the method, followed by analysis of the approach, and then proceeds through three experiments.	O	O	Review	20319
The first two are toy / crafted experiments which build intuition and probe the behavior of the method and finally a large scale test on the Atari 57 benchmark demonstrating improvements when augmenting a state-of-the-art method with HiMo.	O	O	Review	20319
[line_break_token][line_break_token]This reviewer recommends acceptance (I would give a 7 given more granularity) based on the contribution of a new auxiliary objective for value functions and the strength of the experimental suite.	O	O	Review	20319
The Portal Choice environment is well crafted and instrumented with the graphs of figure 5b and 5c to show the behavior of the approach and the clean demonstration of an improvement over a previously SOTA method for Atari 57 is encouraging (the same architecture and the ablation simply sets the auxiliary objective‚Äôs weight to 0).	O	O	Review	20319
However, the reviewer has some caution and concerns as follows:[line_break_token][line_break_token]1) The lack of a large scale experiment demonstrating improvement with an actor-critic method.	B-Review	B-1	Review	20319
While the Portal Choice experiments are informative and use Impala, it is a bit toy, and it would increase the reviewer‚Äôs confidence in the generality and robustness of the approach if improvements were also demonstrated for an actor-critic method on a large environment suite.	I-Review	I-1	Review	20319
Atair 57 could work but ideally a different setting such as DMLab 30 or continuous control from pixels.	I-Review	I-1	Review	20319
Demonstrating improvements in one of these additional settings would raise the reviewer to a strong acceptance.	I-Review	I-1	Review	20319
[line_break_token][line_break_token]2) The potential sensitivity of the approach to the two important hyperparameters that the authors mention, the dimensionality of the hindsight feature space (to reduce approximation error) and the # of future states it conditions on (to avoid just observing the full return directly).	B-Review	B-2	Review	20319
The very low dimensionality of the hindsight feature space (d=3 for Atari) seems a bit at odds with the explanation that the hindsight features provide a strong training signal for learning to better extract value relevant information from the state.	I-Review	I-2	Review	20319
Experiments that studied sensitivity to these would provide better perspective on the robustness of HiMo.	I-Review	I-2	Review	20319
[line_break_token][line_break_token]Questions and suggestions for improving the paper:[line_break_token][line_break_token]For Figure 6 the dynamic range gets squashed by a few games with relatively large performance improvements or regressions.	B-Review	B-3	Review	20319
Changing to a log-scale on the y-axis could be more informative?	I-Review	I-3	Review	20319
For instance, I find it pretty difficult to eyeball the ~1 human normalized score median improvement according to Table 1 from the chart.	I-Review	I-3	Review	20319
[line_break_token][line_break_token]Figure 3 could also be improved.	B-Review	B-4	Review	20319
It requires significant context from definitions in the paper in order to understand.	I-Review	I-4	Review	20319
It could be reworked into a stand alone expository overview of HiMo that helps readers quickly grok the idea of the paper such that abstract + figure is enough.	I-Review	I-4	Review	20319
[line_break_token][line_break_token]Could the authors consider showing / adding full learning curves (median human normalized score?)	B-Review	B-5	Review	20319
for HiMO vs the baseline on Atari 57?	I-Review	I-5	Review	20319
This would help readers get a qualitative feel for the learning dynamics of the algorithm instead of only having a final scalar measure at the end of training.	I-Review	I-5	Review	20319
hank you for taking the time to review our paper.	O	O	Reply	20319
[line_break_token][line_break_token]1- Re: large-scale experiment[line_break_token]We ran a control experiment on the bowling Atari game using Impala (see Figure 7-c)  that tested whether the gains using R2D2 were not specific to Q-value based methods.	B-Reply	B-1	Reply	20319
These results suggest the benefits at scale are not limited to the value-based R2D2 setting.	I-Reply	I-1	Reply	20319
Testing the approach more broadly (on dmlab or challenging continuous control tasks as you suggested) is certainly something we want to look at in the future.	I-Reply	I-1	Reply	20319
[line_break_token][line_break_token]2- RE:sensitivity:[line_break_token]Yes this is a good point.	B-Reply	B-2	Reply	20319
It is not overly sensitive to these exact values (a dimension of 16 for \phi does fine for example) but much larger values did tend to perform worse when we were tuning the architecture.	I-Reply	I-2	Reply	20319
One hypothesis is that a \phi with small dimensionality regularize the representation to only include relevant features, while larger dimensional \phi may contain less relevant information that will distract the modeling effort on phi.	I-Reply	I-2	Reply	20319
We plan to investigate that aspect more in future work.	I-Reply	I-2	Reply	20319
[line_break_token][line_break_token]Thank you for the suggestions regarding the figures.	B-Reply	B-5	Reply	20319
We‚Äôll include the learning curves for all the games in the appendix.	I-Reply	I-5	Reply	20319
[line_break_token][line_break_token]We take your point about Figure 3, we‚Äôll think about a way to make it more useful without relying too much on the text	B-Reply	B-4	Reply	20319

Summary: This paper adapts the UCB Q-learning method to the inifinite-horizon discounted MDP setting.	O	O	Review	20600
With an analysis similar to that of Jin et al (2018), it shows that this algorithm achieves a PAC bound of (1-gamma)^-7 |S||A|/eps^2, improving previous best-known bound (Delayed Q-learning, Strehlet et al, 2006, (1-gamma)^-8 |S||A|/eps^4) for this case.	O	O	Review	20600
[line_break_token][line_break_token]Evaluation: As I see this paper a direct extension of that of Jin et al (2018), I am afraid I have to recommend a rejection.	B-Review	B-1	Review	20600
[line_break_token][line_break_token]Here are some more detailed comments:[line_break_token][line_break_token]Significance: [line_break_token]This paper studies the RL problem for the infinite-horizon discounted MDP setting.	O	O	Review	20600
This is an important setting in reinforcement learning.	O	O	Review	20600
However, the bound is not optimal as the dependence of (1-gamma) is significantly larger than the lower bound.	B-Review	B-2	Review	20600
Moreover, both the algorithm and analysis are direct extensions of that of Jin et al, I do not see a huge technique improvement.	B-Review	B-1	Review	20600
[line_break_token][line_break_token]Technique Novelty:[line_break_token]As stated in the paper, the major difficulty is that the inf-horizon case does not have a set of "consecutive episodes".	O	O	Review	20600
Therefore the "learning error at time t cannot be decomposed as errors from a set of consecutive time[line_break_token]steps before t, but errors from a set of non-consecutive time steps without any structure."	O	O	Review	20600
However, I do not see a major technological innovation is needed to get around this issue.	B-Review	B-1	Review	20600
As a result, the analysis and algorithm in this paper are very similar to that of Jin et al 2018, who nearly implicitly contain the results in this paper.	I-Review	I-1	Review	20600
[line_break_token][line_break_token]Furthermore, I would think there is a (likely) very simple reduction from the inf-horizon to finite-horizon: break the inifinite horizon into episodes of length R = O((1-\gamma)^-1 log(eps^-1)).	B-Review	B-3	Review	20600
Now, although the MDP does not restart, but it can be treated as restarting at a history-dependent initial state distribution at the beginning of every episode.	I-Review	I-3	Review	20600
So, an optimal finit-horizon algorithm in this setting is at most epsilon worse than the optimal inf-horizon algorithm, no matter where/when you start.	I-Review	I-3	Review	20600
With little to no modification, we can see that Jin et al work in this setting.	I-Review	I-3	Review	20600
Thus, we obtain an algorithm for the inf-horizon as well.	I-Review	I-3	Review	20600
[line_break_token][line_break_token]A good match for this conference?	O	O	Review	20600
[line_break_token]As this paper is an adaptation of a previously known Q-learning algorithm to a slightly different setting in RL, I do not see how it fits the "learning representation" paradigm.	B-Review	B-4	Review	20600
Of course, Q-function can be argued as a representation of the MDP model, but this Q-function itself is not a new concept in this paper.	I-Review	I-4	Review	20600
[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Review	20600
irst of all, we thank the reviewer for giving detailed technical comments.	O	O	Reply	20600
The major concern of the reviewer is that there exists simple reduction from infinite-horizon setting to the episodic setting; and it is straightforward to generalize Jin et al (2018) to obtain our results.	B-Reply	B-3	Reply	20600
[line_break_token] [line_break_token]However, the reduction given by the reviewer is incorrect.	I-Reply	I-3	Reply	20600
Below we explain why the reduction doesn‚Äôt hold, and this clearly illustrates the subtle differences between the infinite-horizon setting and the episodic case.	I-Reply	I-3	Reply	20600
In fact, as we already emphasized in the paper (Section 3.2), infinite-horizon setting cannot be solved by reducing to finite-horizon setting as long as we consider sample complexity instead of regret.	I-Reply	I-3	Reply	20600
[line_break_token][line_break_token]We focus on sample complexity of exploration in infinite horizon setting, which is a standard measure widely used in previous results in this setting, while Jin et al proved a regret bound.	I-Reply	I-3	Reply	20600
Please note that sublinear regret does NOT imply finite sample complexity of exploration.	I-Reply	I-3	Reply	20600
[line_break_token][line_break_token]The reduction giving by the reviewer does NOT work for infinite horizon setting.	I-Reply	I-3	Reply	20600
[line_break_token]1.	I-Reply	I-3	Reply	20600
[tab_token]The algorithm in Jin et.	I-Reply	I-3	Reply	20600
al finds a time-dependent policy.	I-Reply	I-3	Reply	20600
Running finite-horizon algorithm can only guarantee near-optimal behavior at step 1, 1+R, 1+2R, etc.	I-Reply	I-3	Reply	20600
For other steps, the policy given by Jin et.	I-Reply	I-3	Reply	20600
al can be suboptimal.	I-Reply	I-3	Reply	20600
For example, at step 1+R/2, the policy given by finite horizon algorithm only maximizes over the reward of remaining R/2 steps, which cannot guarantee optimal bound in the infinite horizon setting.	I-Reply	I-3	Reply	20600
[line_break_token]2.	I-Reply	I-3	Reply	20600
[tab_token]Sublinear regret does NOT imply finite sample complexity of exploration.	I-Reply	I-3	Reply	20600
For example, if an algorithm takes sub-optimal moves at step 1, 4, 9, ‚Ä¶, t^2, ‚Ä¶, the regret is bounded by.	I-Reply	I-3	Reply	20600
However, the sample complexity of exploration of this algorithm is unbounded.	I-Reply	I-3	Reply	20600
Therefore, no direct reduction can be made from sample complexity of exploration to regret.	I-Reply	I-3	Reply	20600
[line_break_token][line_break_token][line_break_token]Response to other comments:[line_break_token][line_break_token]Regarding the dependence of  1-gamma: [line_break_token]Previously best-known model-free algorithm for infinite horizon setting is Delayed Q-learning, which achieves a bound of.	B-Reply	B-2	Reply	20600
We also show that Delayed Q-learning cannot achieve near-optimal bound due to the inefficient usage of samples in Appendix D. Compared to this bound, our result is a significant improvement since we match the lower bound in terms of epsilon as well as S and A up to logarithmic factors.	I-Reply	I-2	Reply	20600
Besides, The previously best claimed result of model-based algorithms is 1/(1-gamma)^6, which is close to our result (1/(1-gamma)^7) and also significantly above the lower bound.	I-Reply	I-2	Reply	20600
Further improving the dependence on 1-gamma is a future direction.	I-Reply	I-2	Reply	20600
[line_break_token][line_break_token]Regarding the technical novelty: [line_break_token]As stated in section 3.2, there are two major difficulties.	B-Reply	B-1	Reply	20600
Firstly, since we need to bound sample complexity of exploration, we need to establish convenient sufficient condition for being epsilon-optimal.	I-Reply	I-1	Reply	20600
We carefully design Condition 1 and Condition 2 to solve this problem.	I-Reply	I-1	Reply	20600
Secondly, we need to decompose errors to that of non-consecutive steps without any structure.	I-Reply	I-1	Reply	20600
See section 3.2 for detailed discussion.	I-Reply	I-1	Reply	20600

The paper proposes a novel trial to alleviate the catastrophic forgetting for continual learning which is kind a mixture model of on and off-policy.	O	O	Review	1195
The core concept of the method is utilizing experience replay buffer for all past events with new experience.	O	O	Review	1195
They mainly worked on their method in the setting of reinforcement learning.	O	O	Review	1195
In the experiments, they show that the model successfully mitigate the catastrophic forgetting with this behavioral cloning, and has the performance comparable to recent continual learning approaches.	O	O	Review	1195
[line_break_token][line_break_token]The paper is easy to follow, and the methodology is quite intuitive and straight forward.	O	O	Review	1195
In this paper, I have several questions.	O	O	Review	1195
[line_break_token][line_break_token]Q1.	O	O	Review	1195
I wonder the reason that every tasks are trained cyclically in sequence.	B-Review	B-1	Review	1195
And is there any trial to learn each task just once and observe the catastrophic forgetting of them when they have to detain the learned knowledge in a long time without training them again, as does most of visual domain experiments of the other continual learning research.	I-Review	I-1	Review	1195
[line_break_token][line_break_token]Q2.	O	O	Review	1195
In figure 5, I wonder why the natlab_varying_map_ramdomize(probe task) can perform well even they didn‚Äôt learn yet.	B-Review	B-2	Review	1195
The score of brown line increases nearly 60~70% of final score(after trained) during training the first task.	I-Review	I-2	Review	1195
Because the tasks are deeply correlated?	I-Review	I-2	Review	1195
or it is just common property of probe task?	I-Review	I-2	Review	1195
[line_break_token][line_break_token]Q3.	O	O	Review	1195
Using reservoir(buffer) to prevent catastrophic forgetting is natural and reasonable.	B-Review	B-3	Review	1195
Is there some of quantitative comparison in the sense of memory requirement and runtime?	I-Review	I-3	Review	1195
I feel that 5 or 50 million experiences at each task are huge enough to memorize and manage.	I-Review	I-3	Review	1195
[line_break_token][line_break_token]Additionally, in the experiment of figure 5, I think it could be much clear with a verification that the probe task  is semantically independent (no interference) over all the other tasks.	B-Review	B-4	Review	1195
[line_break_token][line_break_token]Also, it is quite hard to compare the performance of the models just with plots.	B-Review	B-5	Review	1195
I expect that it could be much better to show some of quantitative  results(as number).	I-Review	I-5	Review	1195
We thank the reviewer for these comments and have made additional changes to the paper to address them, as we describe below.	O	O	Reply	1195
[line_break_token][line_break_token]Q1: We presented tasks cyclically in sequence for several reasons.	B-Reply	B-1	Reply	1195
Presenting all tasks before returning to any one of them to represents a ‚Äúworst-case‚Äù scenario for catastrophic forgetting and tests our method in the hardest situation.	I-Reply	I-1	Reply	1195
 Our experiment is designed to address exactly the scenario the reviewer describes -- spending a lot of time on the other tasks before returning to a specific one.	I-Reply	I-1	Reply	1195
The time spent on each task in the cycle is actually quite long, and if one imagines cutting off each figure after the first iteration of the cycle, one would end up with the figures the reviewer suggests.	I-Reply	I-1	Reply	1195
These figures would already provide ample support for all of our conclusions regarding CLEAR.	I-Reply	I-1	Reply	1195
[line_break_token][line_break_token]Further, presenting tasks cyclically is a natural model of learning in which similar experiences are revisited over and over.	I-Reply	I-1	Reply	1195
Early researchers of human memory, e.g. Ebbinghaus, considered memorization tasks in which memorized items were recurrent and revisited several days in a row or over longer inter-experiment intervals.	I-Reply	I-1	Reply	1195
Recurrent study experiments permit the evaluation of several effects, including the phenomenon of savings, in which forgotten memories are rapidly re-acquired with marginal subsequent study.	I-Reply	I-1	Reply	1195
Here, we are also interested in demonstrating that repeated exposure to a task can be used to train the behavior of an agent.	I-Reply	I-1	Reply	1195
[line_break_token][line_break_token]Q2: This is an interesting phenomenon!	B-Reply	B-2	Reply	1195
It is a demonstration of genuine constructive interference or positive transfer in which learning other tasks promotes coherent exploratory behavior in natlab_varying_map_randomize.	I-Reply	I-2	Reply	1195
This interference does not detract from the conclusions of the figure that catastrophic interference is present in this as in other tasks, that CLEAR fixes the problem, and that the ability of CLEAR to learn from new experience is unaffected by the amount of information already in the replay buffer.	I-Reply	I-2	Reply	1195
[line_break_token][line_break_token]Q3: We understand the motivation behind this question, but the specific memory requirements depend on implementation, including the use of compression and caching techniques, which are engineering-level questions, and beyond the scope of what we can present in the paper, which is focused on the benefits that a mixture of on- and off-policy learning with behavioral cloning provides with respect to learning and forgetting.	B-Reply	B-3	Reply	1195
Notably, the buffer can almost certainly be compressed considerably given the commonalities between experiences.	I-Reply	I-3	Reply	1195
What memory requirements are unavoidable can leverage hard drive storage, with minimal RAM needed.	I-Reply	I-3	Reply	1195
[line_break_token][line_break_token]Re Figure 5: The collection of results in the other figures are designed to show how a newly introduced task affects learning on other tasks.	B-Reply	B-4	Reply	1195
In this experiment, we were specifically interested in one question: Does having a full replay buffer from past experiences on other tasks slow learning on a new task?	I-Reply	I-4	Reply	1195
In Figure 5, note that the final performance obtained on the probe task doesn‚Äôt depend on whether it comes after another task, implying that learning the task is largely independent of the other tasks, except for the initial positive transfer.	I-Reply	I-4	Reply	1195
[line_break_token][line_break_token]In the revision, we include a variation of the probe task experiment in Appendix B, in which we show that when using pure off-policy learning (instead of a mixture of on- and off-policy learning, as in CLEAR), the probe task does indeed decrease in performance when other tasks are learned before it.	I-Reply	I-4	Reply	1195
CLEAR avoids this failure mode by blending new experience with replay.	I-Reply	I-4	Reply	1195
[line_break_token][line_break_token]Re numerical comparison: Absolutely, and we are very grateful for the suggestion.	B-Reply	B-5	Reply	1195
We have added tabulations of the cumulative sum of performance at the end of training for most experiments in Appendix C. We feel this measure captures both how quickly learning occurs and how much performance is maintained over the course of training on multiple tasks	I-Reply	I-5	Reply	1195

This paper presents a method for conditional text generation that has higher factual precision, minimizing hallucination of facts.	O	O	Review	254
The method involves predicting confidence of generation at each time step and using this confidence measure to skip tokens during generation and calibrate output probabilities in test time.	O	O	Review	254
Their method achieves SoTA performance on automatically measured precision and human evaluated "faithfulness."	O	O	Review	254
However their method does see a drop in recall (automatic metric and human evaluation).	O	O	Review	254
[line_break_token][line_break_token]Comments and issues,[line_break_token]- The intuitive explanation for the confidence score is a little confusing.	B-Review	B-1	Review	254
In Section 4, page 3, you say that "If a token is likely a content word (i.e. when its generation probability by the encoder-decoder is much higher than the unconditioned language model), but the attention score is low, then the token might not be predicted based on the source, and could be hallucination."	I-Review	I-1	Review	254
However, this doesn't seem like an airtight conclusion.	I-Review	I-1	Review	254
Isn't it possible that the base-LM and enc-dec model have similar probabilities for a content word with the enc-dec attention being low?	I-Review	I-1	Review	254
This seems possible given your observation that low attention to the source is what may be causing content hallucination.	I-Review	I-1	Review	254
This same thing is essentially restated in section 4.1 "we expect P(y_t |y_&lt;t, x) to be higher than P(y_t | y_&lt;t) for content words so the confidence score will largely depend on the attention score", which seems more tangled up since P(y_t |y_&lt;t, x) inherently depends on the attention score.	O	O	Review	254
This is all clarified when you explain the alteration made to the base-LM.	B-Review	B-1	Review	254
I would recommend rewording/rearranging some of the earlier explanation for the efficacy of the confidence score since it seems that the alteration to the base-LM is an essential part of the explanation.	I-Review	I-1	Review	254
[line_break_token]- Need some explanation for Equation 6.	B-Review	B-2	Review	254
I don't really get the intuition behind it.	I-Review	I-2	Review	254
[line_break_token]- The presented results are pretty good!	B-Review	B-3	Review	254
However, I would like to see some numbers on average score across a few runs.	I-Review	I-3	Review	254
[line_break_token]- It would also be good to see results on one more dataset like E2E.[line_break_token]- Provide a little more detail on human evaluation, you don't even mention if the evaluation was done with crowd-workers or another pool of people like grad students.	B-Review	B-4	Review	254
How many annotators?	B-Review	B-5	Review	254
What is the inter-annotator agreement?	I-Review	I-5	Review	254
What was the prompt/structure?	I-Review	I-5	Review	254
Human evaluation of models is notoriously difficult, more details would give some more weight to the results.	I-Review	I-5	Review	254
[line_break_token][line_break_token]I think this is a well written paper with thought out experiments.	O	O	Review	254
I recommend it be accepted to ICLR.	O	O	Review	254
I'd also be curious to see some future work that improves, or at least maintains recall, while keeping the higher precision.	B-Review	B-7	Review	254
[line_break_token][line_break_token]Minor requests/recommendations: [line_break_token]- Include more examples of generations.	B-Review	B-6	Review	254
Could be an appendix.	I-Review	I-6	Review	254
[line_break_token]	O	O	Review	254
hanks for the detailed review.	O	O	Reply	254
Reviewer #3 has suggested motivating our model designs better, describing more details about our human evaluation, and adding more generation examples.	B-Reply	B-5	Reply	254
We have added these in our revised paper.	I-Reply	I-5	Reply	254
[line_break_token][line_break_token]We have also done some extra work on additional runs and more datasets, as discussed below:[line_break_token][line_break_token]&gt; I would like to see some numbers on average score across a few runs[line_break_token][line_break_token]We do not have an average across multiple runs, but a second run of our model suggests that: similar BLEU and PARENT scores can be achieved by different runs, but the best performing hyper-parameters vary -- the chosen \rho, \gamma and \lambda reported in our paper do not always give the best results; it is better to sweep on these hyper-parameters.	B-Reply	B-3	Reply	254
[line_break_token][line_break_token]&gt; It would also be good to see results on one more dataset like E2E.[line_break_token][line_break_token]Actually, we had results on a second dataset: the RotoWire (Wiseman et al 2017).	B-Reply	B-4	Reply	254
We did not use E2E because E2E seems simpler and has less source-reference divergence; we wanted to test on a more complicated and hallucination-prone dataset.	I-Reply	I-4	Reply	254
Our results on RotoWire are as follows:[line_break_token][line_break_token]Entity Modelling (Puduppully et al 2019): BLEU 16.37  PARENT Prec.	I-Reply	I-4	Reply	254
34.68 Rec.	I-Reply	I-4	Reply	254
36.79 F1 34.47 Avg.	I-Reply	I-4	Reply	254
Len.	I-Reply	I-4	Reply	254
295[line_break_token]Content Planning (Puduppully et al 2018): BLEU 16.85 PARENT Prec.	I-Reply	I-4	Reply	254
35.40 Rec.	I-Reply	I-4	Reply	254
40.41 F1 36.59 Avg.	I-Reply	I-4	Reply	254
Len.	I-Reply	I-4	Reply	254
332[line_break_token]Pointer-Generator: BLEU 9.15 PARENT Prec.	I-Reply	I-4	Reply	254
37.68 Rec.	I-Reply	I-4	Reply	254
36.48 F1 35.94 Avg.	I-Reply	I-4	Reply	254
Len.	I-Reply	I-4	Reply	254
251[line_break_token]Confident Pointer-Generator: BLEU 8.40 PARENT Prec.	I-Reply	I-4	Reply	254
42.64 Rec.	I-Reply	I-4	Reply	254
35.23 F1 37.69 Avg.	I-Reply	I-4	Reply	254
Len.	I-Reply	I-4	Reply	254
233[line_break_token][line_break_token]It seems that our Confident Pointer-Generator achieves SoTA PARENT Precision on RotoWire as well.	I-Reply	I-4	Reply	254
However, we did not report these results in our paper because we did not conduct human evaluation.	I-Reply	I-4	Reply	254
[line_break_token][line_break_token]&gt; I'd also be curious to see some future work that improves, or at least maintains recall, while keeping the higher precision.	O	O	Reply	254
[line_break_token][line_break_token]Absolutely.	B-Reply	B-7	Reply	254
To extend this approach and achieve high precision text generation on more complicated datasets is one of the major topics we are working on.	I-Reply	I-7	Reply	254

Summary[line_break_token]This paper tackles the problem of transferring a policy from source to target MDP, which differ in the state transition function.	O	O	Review	20499
The idea is to add an additional cost that is the KL divergence between the trajectory likelihood under target policy (being learned) and target dynamics and the trajectory likelihood under the source policy (assumed optimal and deterministic) and source dynamics.	O	O	Review	20499
The intuition is that the target policy will learn to match the state distribution of the optimal source policy.	O	O	Review	20499
Results on MuJoCo locomotion robots with varying physics show that the proposed method performs better on target than warm-started RL or learning from scratch.	O	O	Review	20499
[line_break_token][line_break_token]I think the problem of transferring knowledge from one task to another in RL is very important for RL to be applicable to more real-world scenarios.	O	O	Review	20499
[line_break_token][line_break_token]Concerns / Questions[line_break_token]Line 7 of Alg1 is confusing because it refers to a ‚Äútarget task model‚Äù, but in Assumption 2, it says only a model of the source transition function is needed.	B-Review	B-1	Review	20499
I think it makes sense that only the source transition model is needed because the target next state is given by experience.	I-Review	I-1	Review	20499
[line_break_token]I think the combined assumptions of a) access to expert behavior (same as DAGGER) and b) that the MDPs differ only in dynamics functions and c) access to the source transition model are rather strong.	B-Review	B-2	Review	20499
I think (b) is a special case of transfer learning - a lot of transfer learning is concerned with changing reward functions as well, which this method wouldn‚Äôt apply to.	B-Review	B-5	Review	20499
I think this could be made more clear in the paper.	I-Review	I-5	Review	20499
It would be good if all these assumptions were made clear and discussed.	I-Review	I-5	Review	20499
[line_break_token]I think the related work section is missing important areas of research in imitation learning and meta-reinforcement learning.	B-Review	B-6	Review	20499
For imitation learning, the approach strikes me as bearing similarity to PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings (Rhinehart et al), and the topic of imitation learning should be discussed in general.	I-Review	I-6	Review	20499
For meta-RL, mentioning that it shares the same goal of transfer and citing a few main works (e.g. Duan et al 2016, Wang et al 2016, Finn et al 2017 etc) would be good.	I-Review	I-6	Review	20499
[line_break_token][line_break_token]Writing Suggestions[line_break_token]Some terms used throughout the paper are quite unclear (e.g., ‚Äúunsupervised RL‚Äù, ‚Äúintrinsic adaptation reward‚Äù, ‚Äúsupervised reference trajectory tracking‚Äù).	B-Review	B-7	Review	20499
I suggest standardizing and defining terms early to avoid unnecessary confusion.	I-Review	I-7	Review	20499
[line_break_token]Writing the Bellman operator and the value function equations in Section 2 don‚Äôt seem very relevant as they are I think never used again?	B-Review	B-8	Review	20499
[line_break_token]Sections 3.1 and 3.2 are quite difficult to understand on first read (e.g., what does ‚Äúpoint-wise local trajectories‚Äù mean?).	B-Review	B-9	Review	20499
[line_break_token]I find Section 3.2.1 a bit misleading, ‚ÄúThe optimization is more akin to supervised learning‚Äù - I agree the KL minimization is essentially imitation learning, but you are still doing policy search in addition to it?	I-Review	I-9	Review	20499
[line_break_token]	O	O	Review	20499
e thank reviewer #2 for a detailed review of our work.	O	O	Reply	20499
Following are our response to the reviews[line_break_token][line_break_token]1) In line 7, of Algorithm-1, "Propagate the target task model at state s_i and action a_i,": we meant Apply the action a_i at state s_i in the target task.	B-Reply	B-1	Reply	20499
We do not need the target transition model; the target task could be a real agent or a simulation environment.	I-Reply	I-1	Reply	20499
[line_break_token][line_break_token]2) The assumptions, as highlighted by the reviewer.	O	O	Reply	20499
[line_break_token]    a) access to expert behavior (same as DAGGER):  [line_break_token]        We need a source policy.	B-Reply	B-2	Reply	20499
[line_break_token][line_break_token]    b) MDPs differ only in dynamics function:  [line_break_token]       We can also handle cross-domain transfer where the target and source differ in the state and action space dimension and representation, apart from the model transition differences (please refer our cross-domain  domain transfer results in Appendix, Mountain-car to Inverted pendulum and Cart-pole to Bicycle transfer experiments)[line_break_token][line_break_token]    c) access to the source transition model[line_break_token]We do not need the true transition model for source and the target, but only assume to have access to a black box simulator model of the source (Assumption-2)[line_break_token][line_break_token]Given these corrections, we feel the assumptions are not very strong.	B-Reply	B-3	Reply	20499
[line_break_token][line_break_token]Reviewer #2: I think (b) is a special case of transfer learning - a lot of transfer learning is concerned with changing reward functions as well, which this method wouldn't apply to.	B-Reply	B-5	Reply	20499
[line_break_token][line_break_token]The existing Transfer learning architectures which aim at learning task by reward shaping [1-3] or learning an expert reward model and carrying out an Inverse-RL[4-5], do not enjoy similar reduced sample complexity as our method.	B-Reply	B-6	Reply	20499
Methods like Inverse RL, Reward shaping, or Representation transfer are eventually an RL task and suffer the same curse of dimensionality as the RL problem.	I-Reply	I-6	Reply	20499
[line_break_token][line_break_token]Hence we have demonstrated in this paper that adaptation of the learned policy is a more efficient way of transferring skills between tasks.	I-Reply	I-6	Reply	20499
We will try to bring out these discussions more clearly in the paper.	I-Reply	I-6	Reply	20499
[line_break_token][line_break_token]3) Thank you for pointing us to the additional references.	I-Reply	I-6	Reply	20499
We will study and appropriately cite them in the future draft.	I-Reply	I-6	Reply	20499
[line_break_token][line_break_token]4)We will incorporate the changes to define the terms more explicitly and early in the text for better clarity in the future draft.	B-Reply	B-7	Reply	20499
[line_break_token][line_break_token]5) The definition of Bellman operator is provided for the sake of completeness and \epsilon-optimality proof (lemma-4.3) in the Appendix which uses the notion of the \gamma-contraction principle of the operator.	B-Reply	B-8	Reply	20499
[line_break_token][line_break_token]6) Reviewer #2: "The optimization is more akin to supervised learning - I agree the KL minimization is essentially imitation learning, but you are still doing policy search in addition to it?"	O	O	Reply	20499
[line_break_token][line_break_token]Agreed!	B-Reply	B-9	Reply	20499
Environmental rewards are added to intrinsic adaptation rewards through reward mixing, which leads to policy search like architecture.	I-Reply	I-9	Reply	20499
The reward mixing is done for two reasons[line_break_token]a)It aids sufficient exploration, thereby we need not only look into the direction of source behavior mapped onto the target task.	I-Reply	I-9	Reply	20499
[line_break_token]b) Env reward also helps target agent to learn skills beyond what a source policy can teach.	I-Reply	I-9	Reply	20499
[line_break_token][line_break_token]However, we do not need the reward mixing for every experiment.	I-Reply	I-9	Reply	20499
For example, the Hopper env can be learned purely by adapting the source policy to the target agent.	I-Reply	I-9	Reply	20499
 [line_break_token][line_break_token][line_break_token][1] Marco Colombetti and Marco Dorigo.	O	O	Reply	20499
Robot shaping: developing situated agents through learning[line_break_token][2] Tom Erez and William D. Smart.	O	O	Reply	20499
 What does shaping mean for computational reinforcement learn-ing?	O	O	Reply	20499
[line_break_token][3] Maja J. Mataric.	O	O	Reply	20499
Reward functions for accelerated learning.	O	O	Reply	20499
International Conference on MachineLearning[line_break_token][4] Ramachandran, Deepak, and Eyal Amir. "	O	O	Reply	20499
Bayesian Inverse Reinforcement Learning.	O	O	Reply	20499
[line_break_token][5] Andrew Ng and S. Russell.	O	O	Reply	20499
Algorithms for inverse reinforcement learning	O	O	Reply	20499

The paper proposes to stack NMF models on top of each other.	O	O	Review	31
At each level, a non-linear function of normalized decomposition coefficients is used and decomposed using another NMF.	O	O	Review	31
[line_break_token][line_break_token]This is essentially an instance of a deep belief network, where the unsupervised learning part is done using NMF, which, to the best of my knowledge had not been done before.	O	O	Review	31
[line_break_token][line_break_token]The new method is then applied to document data where a hierarchy of topics seems to be discovered.	O	O	Review	31
Applications are also shown on reconstructing digits.	O	O	Review	31
[line_break_token][line_break_token]The extended abstract however does not give many details on all the specifics of the method.	O	O	Review	31
[line_break_token][line_break_token]Comments:[line_break_token]-It would have been nice (a) to relate the hierachy to existing topic models [A,B], and (b) to see more topics.	B-Review	B-1	Review	31
[line_break_token]-On Figure 2, why are reconstruction errors decreasing with the number of features?	B-Review	B-2	Review	31
[line_break_token]-On the digits, the differences between shallow and deep networks are not clear.	B-Review	B-3	Review	31
[line_break_token][line_break_token][A] D. Blei, T. Griffiths, and M. Jordan.	O	O	Review	31
  The nested Chinese restaurant process and Bayesian nonparametric inference of topic hierarchies.	O	O	Review	31
  Journal of the ACM, 57:2 1‚Äì30, 2010.	O	O	Review	31
 [line_break_token][line_break_token][B] R. Jenatton, J. Mairal, G. Obozinski, F. Bach.	O	O	Review	31
Proximal Methods for Hierarchical Sparse Coding.	O	O	Review	31
Journal of Machine Learning Research, 12, 2297-2334, 2011.	O	O	Review	31
[line_break_token][line_break_token]Pros:[line_break_token]-Interesting idea of stacking NMFs.	O	O	Review	31
[line_break_token][line_break_token]Cons:[line_break_token]-Experimental results are interesting but not great.	B-Review	B-4	Review	31
What is exactly achieved is not clear.	I-Review	I-4	Review	31
- Points on the con that experimental results are not great:[line_break_token]When we refer to Figure 2 in the paper, the proposed hierarchical feature extraction method results in much better classification and reconstruction performance, especially for small number of	O	O	Reply	31

Summary:[line_break_token]This paper proposed an ensemble method (CIKD) that train multiple agents and[line_break_token]use knowledge distillation to transfer knowledge from the current best agent to[line_break_token]sub-optimal agents periodically.	O	O	Review	252
 According to the reported results, CIKD is a[line_break_token]simple yet effective approach to improve sample-efficiency and final performance.	O	O	Review	252
 [line_break_token]The experimental results are sufficient, and the ablation studies are conducted thoroughly.	O	O	Review	252
It is shown that both selecting the best agent and using KD to[line_break_token]transfer knowledge are effective comparing to other naive alternatives.	O	O	Review	252
[line_break_token][line_break_token][line_break_token]I recommend the acceptance of this paper.	O	O	Review	252
[line_break_token][line_break_token]The paper proposed a novel approach (CIKD) to improve the sample-efficiency of the state-of-the-art.	O	O	Review	252
The proposed ensemble approach is aligned with our intuition, and it is effective.	O	O	Review	252
The authors proposed to train several agents at the same time and randomly select one of[line_break_token]the agents as a behavior policy during each rollout.	O	O	Review	252
Then the collected trajectory is used to update the policy of all agents.	O	O	Review	252
Meanwhile,[line_break_token]they keep tracking the performance of each agent and use the current best agent to conduct knowledge distillation to other agents periodically.	O	O	Review	252
[line_break_token][line_break_token]This paper first conducts experiments to show when consolidating[line_break_token]the SAC with CIKD, both of the final performance and sample-efficiency can be improved.	O	O	Review	252
Then a set of ablation studies verified the best agent selection strategy, and the knowledge distillation[line_break_token]strategy is necessary for the ensemble method.	O	O	Review	252
[line_break_token][line_break_token][line_break_token]Investigation on the reasons for improvement:[line_break_token]Though extensive ablation studies have shown the effectiveness[line_break_token]of each component of CIKD.	B-Review	B-1	Review	252
It is still not clear why this approach[line_break_token]can be effective.	I-Review	I-1	Review	252
[line_break_token]Intuitively, it is possible that the exploration from a set of agents would outperform[line_break_token]a single agent.	I-Review	I-1	Review	252
The measure of exploration efficiency could help in explaining the results.	I-Review	I-1	Review	252
Furthermore, better exploration not necessarily[line_break_token]leads to better performance and sample-efficiency.	B-Review	B-2	Review	252
Does knowledge distillation serve as a better alternative to exploit existing data?	I-Review	I-2	Review	252
[line_break_token][line_break_token]Model/algorithm agnostic[line_break_token]The proposed method is more convenient to be applied with off-policy approach when the policy is in the form of softmax.	B-Review	B-3	Review	252
Is it also applicable[line_break_token]to other approaches?	I-Review	I-3	Review	252
[line_break_token][line_break_token]Experiments:[line_break_token]How do you determine when to stop the KD process?	B-Review	B-4	Review	252
As mentioned in section 5.5, if we conduce KD fully, all students would be just imitating[line_break_token]the teacher's behavior.	I-Review	I-4	Review	252
It seems the key is to tune a good termination[line_break_token]threshold for each task?	I-Review	I-4	Review	252
Are there any guidelines to set up this threshold?	I-Review	I-4	Review	252
[line_break_token]Do you have some automatic way to terminate the KD procedure?	I-Review	I-4	Review	252
[line_break_token][line_break_token][line_break_token]Minor:[line_break_token]L1, P5, "how to CIKD improves the sample efficiency" [line_break_token][line_break_token]	B-Review	B-5	Review	252
e would like to thank the reviewer for reading our paper and providing feedback on our work.	O	O	Reply	252
We will address the reviewer‚Äôs various points here.	O	O	Reply	252
[line_break_token][line_break_token]- ‚ÄúThough extensive ablation studies have shown the effectiveness of each component of CIKD.	O	O	Reply	252
It is still not clear why this approach can be effective.	O	O	Reply	252
Intuitively, it is possible that the exploration from a set of agents would outperform a single agent.	O	O	Reply	252
The measure of exploration efficiency could help in explaining the results.	O	O	Reply	252
‚Äù[line_break_token][tab_token][line_break_token]The purpose of the Ensemble-SAC baseline was to investigate how CIKD itself improves upon Ensemble-SAC, since Ensemble-SAC may naturally benefit from improved exploration upon a single SAC agent.	B-Reply	B-1	Reply	252
In this way, we can decouple (to a certain degree), the benefits of an ensemble vs. the benefits of applying CIKD to an ensemble.	I-Reply	I-1	Reply	252
In future work, it would be interesting to perform more experiments and analyses on the effect of improved exploration and the benefit of distillation (e.g., through plotting the state-visitation frequencies or distilling the knowledge from a separate hand-crafted dataset as opposed to agent data).	I-Reply	I-1	Reply	252
[line_break_token][line_break_token]- ‚ÄúFurthermore, better exploration not necessarily leads to better performance and sample-efficiency.	O	O	Reply	252
Does knowledge distillation serve as a better alternative to exploit existing data?‚Äù[line_break_token][line_break_token]It is unclear how to compare various approaches to exploiting existing data, since there is no general framework for data exploitation.	B-Reply	B-2	Reply	252
However, we would like to highlight two of our experiments that investigated this question.	I-Reply	I-2	Reply	252
Off-policy RL offers an obvious way to exploit experiences.	I-Reply	I-2	Reply	252
In Section 5.3 (Fig.	I-Reply	I-2	Reply	252
3a), we performed an experiment where we tuned an Ensemble-SAC agent to perform additional off-policy RL updates.	I-Reply	I-2	Reply	252
We found that using CIKD with Ensemble-SAC outperforms Ensemble-SAC with additional RL updates.	I-Reply	I-2	Reply	252
Our second experiment, the ‚Äúhard-copy‚Äù experiment (Fig.	I-Reply	I-2	Reply	252
3b, Section 5.3), copies the best teacher into the students rather than performing distillation.	I-Reply	I-2	Reply	252
We found that distillation performs better than strictly hard-copying the best agent.	I-Reply	I-2	Reply	252
Interesting directions for future work include performing additional analyses on various data exploitation methods.	I-Reply	I-2	Reply	252
[line_break_token][line_break_token]- ‚ÄúModel/algorithm agnostic: The proposed method is more convenient to be applied with off-policy approach when the policy is in the form of softmax.	O	O	Reply	252
Is it also applicable to other approaches? ‚	O	O	Reply	252
Äú[line_break_token][line_break_token]Our method is certainly applicable to other approaches.	B-Reply	B-3	Reply	252
In particular, our KL Loss can be applied to other policy gradient approaches as long as the policy outputs a distribution and is differentiable, as is the case with most modern policy representations.	I-Reply	I-3	Reply	252
In principle, CIKD can be applied to value-based approaches as well by changing the distillation loss from a KL-Loss to another loss, such as mean-squared-error (MSE).	I-Reply	I-3	Reply	252
In fact, in our paper, we distill our critics using an MSE loss.	I-Reply	I-3	Reply	252
[line_break_token][line_break_token]- ‚ÄúHow do you determine when to stop the KD process?	O	O	Reply	252
As mentioned in section 5.5, if we conduce KD fully, all students would be just imitating the teacher's behavior.	O	O	Reply	252
It seems the key is to tune a good termination threshold for each task?	O	O	Reply	252
Are there any guidelines to set up this threshold?	O	O	Reply	252
Do you have some automatic way to terminate the KD procedure?‚Äù[line_break_token][line_break_token]We didn‚Äôt focus on optimizing the terminating threshold for distillation and found that CIKD worked quite well by randomly dividing the entire (bounded) replay buffer into several minibatches and performing distillation on all of these minibatches.	B-Reply	B-4	Reply	252
If this process were to be repeated infinitely, this would amount to imitation learning.	I-Reply	I-4	Reply	252
To verify that CIKD is not tantamount to pure imitation learning, we ran two key experiments.	I-Reply	I-4	Reply	252
In one experiment (Section 5.5, Figure 5d), we tested an alteration of CIKD where we re-initialized the student networks prior to distillation.	I-Reply	I-4	Reply	252
This amounts to pure imitation learning in that we have a randomly initialized student learning to directly imitate the teacher.	I-Reply	I-4	Reply	252
We found that pure imitation learning fails to perform as well as CIKD.	I-Reply	I-4	Reply	252
In Section 5.5 (Fig.	I-Reply	I-4	Reply	252
5c), we show that the student often outperforms the teacher after distillation.	I-Reply	I-4	Reply	252
Note that outperforming the teacher is atypical in imitation learning, which further supports that CIKD does not reduce to imitation learning.	I-Reply	I-4	Reply	252
Returning to the reviewer‚Äôs question, an interesting direction for future work is to investigate the tradeoff between pure imitation learning and a moderate amount of distillation.	I-Reply	I-4	Reply	252
But in this work, we found that CIKD achieved good performance with straightforward distillation termination conditions and is in fact superior to distilling via pure imitation learning.	I-Reply	I-4	Reply	252
[line_break_token][line_break_token]- ‚ÄúMinor: L1, P5, ‚Äòhow to CIKD improves the sample efficiency‚Äô‚Äù [line_break_token][line_break_token]We have corrected this mistake in the paper.	B-Reply	B-5	Reply	252

Summary:[line_break_token][line_break_token]Gradient clipping has been studied as an optimization technique and also as a tool for privacy preserving, but in this paper, it studies the robustness properties of gradient clipping.	O	O	Review	10101
 More specifically, the main question of the paper is: Can gradient clipping mitigate label noise?	O	O	Review	10101
 The paper reveals that the answer is no, but further proposes a simple variant of gradient clipping is robust and has nice property of classification calibration.	O	O	Review	10101
 Experiments show that the proposed variant works under label noise.	O	O	Review	10101
[line_break_token][line_break_token][line_break_token]Strength of the paper:[line_break_token][line_break_token]The motivation and goal of the paper is stated in the title and is very clear, making it easier to follow the story of the paper.	O	O	Review	10101
 There are sufficient background on the loss functions and gradient clipping in the beginning that helps guide the reader.	O	O	Review	10101
 The proposed method is robust to label noise and has theoretical guarantees.	O	O	Review	10101
 The relationship between similar work is summarized.	O	O	Review	10101
 Experiments have both synthetic and benchmark datasets to demonstrate the behavior of the proposed method.	O	O	Review	10101
[line_break_token][line_break_token][line_break_token]Weakness of the paper:[line_break_token][line_break_token]Currently, the experiments only include methods studied in the paper.	B-Review	B-1	Review	10101
 It would be better to include baseline methods stated in the end of Section 5 or in Section 4.3.	I-Review	I-1	Review	10101
[line_break_token][line_break_token]After response:[line_break_token]Thank you for the clarification!	O	O	Review	10101
 I have read the other reviews and author comments.	O	O	Review	10101
hanks for the feedback!	O	O	Reply	10101
[line_break_token][line_break_token]We compare against the generalised cross-entropy (GCE) as this is (to our knowledge) a state-of-the-art loss-based technique for coping with label noise.	B-Reply	B-1	Reply	10101
Note that the methods discussed in Sec 4.3 employ the same base loss as GCE.	I-Reply	I-1	Reply	10101
[line_break_token][line_break_token]The methods listed at the end of Sec 5 are based on distinct, complementary ideas.	I-Reply	I-1	Reply	10101
While certainly combining these with our clipped loss would be of interest, we wished to focus on our main message in the experiments (namely, the study of the viability of clipping to mitigate label noise)	I-Reply	I-1	Reply	10101

The paper presents an approach to learning shared neural representations of temporal abstractions in hierarchical RL, based on actor-critic methods.	O	O	Review	397
The approach is illustrated in two tasks: gridworld with objects and a simplified Minecraft problem).	O	O	Review	397
 The idea of providing symbolic descriptions of tasks and learning corresponding "implementations" is potentially interesting and the empirical results are promising.	O	O	Review	397
 However, there are two main drawbacks of the current incarnation of this work.	B-Review	B-1	Review	397
 First, the ideas presented in the paper have all been explored in other work (symbolic specifications, actor-critic, shared representations).	I-Review	I-1	Review	397
 While related work is discussed, it is not really clear what is new here, and what is the main contribution of this work besides providing a new implementation of existing ideas in the context of deep learning.	I-Review	I-1	Review	397
The main contribution if the work needs to be clearly spelled out.	O	O	Review	397
 Secondly, the approach presented relies crucially on curriculum learning (this is quite clear from the experiments).	B-Review	B-2	Review	397
 While the authors argue that specifying tasks in simplified language is easy, designing a curriculum may in fact be pretty complicated, depending on the task at hand.	I-Review	I-2	Review	397
 The examples provided are fairly small, and there is no hint of how curriculum can be designed for larger problems.	I-Review	I-2	Review	397
Because the approach is sensitive to the curriculum, this limits the potential utility of the work.	I-Review	I-2	Review	397
It is also unclear if there is a way to provide supervision automatically, instead of doing it based on prior domain knowledge.	I-Review	I-2	Review	397
[line_break_token]More minor comments:[line_break_token]- The experiments are not described in enough detail in the paper.	B-Review	B-3	Review	397
It's great to provide github code, but one needs to explain in the paper why certain choices were made in the task setup (were these optimized?	I-Review	I-3	Review	397
What's this the first thing that worked?)	I-Review	I-3	Review	397
Even with the code, the experiments as described are not reproducible[line_break_token]- The description of the approach is pretty tangled with the specific algorithmic choices.	B-Review	B-4	Review	397
Can the authors step back and think more generally of how this approach can be formalized?	I-Review	I-4	Review	397
 I think this would help relate it to the prior work more clearly as well.	I-Review	I-4	Review	397
NOVELTY[line_break_token][line_break_token]As described in the related work section, our approach indeed shares a number of similarities in existing work on learning hierarchical policy representations.	B-Reply	B-1	Reply	397
Structurally the model is quite similar to the Option--Critic approach of Bacon & Precup; this is not intended to be a contribution of the paper.	O	O	Reply	397
What we claim to be novel are (1) the training condition (using discrete high-level policy representations without an explicit grounding or feature abstraction hierarchy) and (2) the objective (using the small amount of extra structure in the training data to decouple actors from critics across multiple tasks).	B-Reply	B-1	Reply	397
You mention that symbolic specifications have been explored in other work---as discussed in our earlier comment, we've done our best to describe the differences with nearest neighbors, but are not aware of any previous approaches that learn with as little high-level supervision as we use here.	I-Reply	I-1	Reply	397
Again, if you can let us know exactly what you have in mind we would greatly appreciate it!	O	O	Reply	397
[line_break_token][line_break_token]CURRICULA[line_break_token][line_break_token]The general curriculum learning approach (Algorithm 2) can construct a sampling distribution for any collection of tasks: it relies only on the sketch length and the current empirical performance of the model, both of which can be computed without any task-specific engineering.	B-Reply	B-2	Reply	397
The collections of tasks in this paper were in fact designed to give rise to particularly challenging curricula (no length-1 tasks, various subpolicies that appear only as constituents of very long tasks, etc.)	I-Reply	I-2	Reply	397
and demonstrate robustness to decisions about task selection and curriculum design.	I-Reply	I-2	Reply	397
[line_break_token][line_break_token]TASKS[line_break_token][line_break_token]We did most of our development on a restricted subset (only length-2 and length-3 sketches) of crafting domain tasks.	I-Reply	I-2	Reply	397
Generalization to longer crafting tasks, as well as generalization to the maze domain, worked out of the box without any modifications to the initial task design or tuning of hyperparameters.	I-Reply	I-2	Reply	397
As some evidence that the task design process is indeed reproducible, we are happy to point to follow-up work by Rob Fergus's group, who have already succeeded in reimplementing our tasks and evaluation for a different model architecture (<a href="https://uclmr.github.io/nampi/talk_slides/rob-nampi.pdf)."	O	O	Reply	397
target="_blank" rel="nofollow">https://uclmr.github.io/nampi/talk_slides/rob-nampi.pdf).</a	O	O	Reply	397

The authors design a program synthesizer that tries to satisfy per-instance specific syntactic and functional constraints,[line_break_token]based on sampling trajectories from an RL agent that at each time-step expands a partial-program.	O	O	Review	481
[line_break_token][line_break_token]The agent is trained with policy gradients with a reward shaped as the ratio of input/output examples that the synthesized program satisfies.	O	O	Review	481
[line_break_token][line_break_token]With the 'out-of-box' evaluation, the authors show that their agent can explore more efficiently the harder problems than their non-learning alternatives even from scratch.	O	O	Review	481
[line_break_token](My intuition is that the agent learns to generate the most promising programs)[line_break_token]It would be good to have a Monte Carlo Tree Search baseline on the'out-of-box' evaluation, to detect exploration exploitation trade-offs.	B-Review	B-1	Review	481
[line_break_token][line_break_token]The authors show with the 'meta-solver' approach that the agent can generalize to and also speed up unseen (albeit easy-ish in the authors words) instances.	B-Review	B-2	Review	481
[line_break_token][line_break_token]Clarity: Paper is clear and nicely written.	O	O	Review	481
[line_break_token][line_break_token]Significance: Imagine a single program synthesizer that could generate C++/Java/Python/DSLs  programs and learn from all its successes and failures!	O	O	Review	481
This is a step towards that.	O	O	Review	481
[line_break_token][line_break_token]Pros:[line_break_token]+ Generating spec-following programs for different grammars.	O	O	Review	481
[line_break_token]+ partial tree expansion takes care of syntactic constraints.	O	O	Review	481
[line_break_token]Neutral[line_break_token]¬∑ The grammar and specification diversity may be too low to feel impressive.	O	O	Review	481
[line_break_token]¬∑ It would have been nicer by computing likelihood for unseen instances with unique and known solutions (that is, without finetuning).	O	O	Review	481
[line_break_token]Cons:[line_break_token]- No Tree Search baseline.	B-Review	B-1	Review	481
[line_break_token]- No results on programs with control flow/internal state.	B-Review	B-3	Review	481
We appreciate your insightful review comments.	O	O	Reply	481
We address the concerns and questions as follows:[line_break_token][line_break_token]> Have you considered any tree search baseline, for example, Monte-Carlo Tree Search?	O	O	Reply	481
[line_break_token][line_break_token]In our evaluation, the ESymbolic baseline is a tree search method, except that it expands the nonterminals in a deterministic depth-first fashion and does pruning using constraint solving (e.g. 2QBF) along the way.	B-Reply	B-1	Reply	481
For the proposed method, however, while the generated program that our model operates on indeed can be represented by a tree, the RL algorithm we use is essentially model-free, i.e. it is agnostic to the transition dynamics.	I-Reply	I-1	Reply	481
We agree with the reviewer that this approach can be further improved with a model-based approach such as MCTS, since we can track the dynamics easily, and presumably yields better performance than the current purely model-free approach.	I-Reply	I-1	Reply	481
On the other hand, as one of the main motivations of our work is to study how to cast the classical problem into a learning task, we have been focused on the comparison between learning and non-learning methods, instead of model-free and model-based methods.	I-Reply	I-1	Reply	481
However, it would be definitely interesting to explore more on the model-based methods for program synthesis, and we leave this to our future work.	O	O	Reply	481
[line_break_token][line_break_token]>  How about generalization without fine-tuning?	O	O	Reply	481
[line_break_token][line_break_token]Indeed, it would be great to generalize to unseen programs even without fine-tuning, but in the meta-learning setting, it is typically very hard as it requires a lot of samples not only in the data space but also in the task space, for which we only have around 200 tasks.	B-Reply	B-2	Reply	481
We did test the performance of the learner without fine-tuning, and, with no surprise, it turns out to perform worse than the out-of-the-box version.	I-Reply	I-2	Reply	481
 [line_break_token][line_break_token]On the other hand, this train-and-finetune fashion is becoming widely accepted by a number of recent works on meta-reinforcement-learning, for instance, ‚ÄúRecasting Gradient-Based Meta-Learning as Hierarchical Bayes‚Äù.	I-Reply	I-2	Reply	481
[line_break_token][line_break_token]> Programs seems too low level and lacks of control flow/internal state, which are common features in general programming language like C, Java, Python, etc.	O	O	Reply	481
[line_break_token][line_break_token]This is a great suggestion for our future work.	B-Reply	B-3	Reply	481
We believe learning programs from logical specifications in a general programming language is an important direction in artificial intelligence, and our work is a step towards this direction	I-Reply	I-3	Reply	481

The paper describes a new study about how to make dialogs more empathetic.	O	O	Review	1120
[line_break_token]The work introduced a new dataset of 25k dialogs designed to evaluate the[line_break_token]role that empathy recognition may play in generating better responses [line_break_token]tuned to the feeling of the conversation partner.	O	O	Review	1120
 Several model[line_break_token]set-ups, and many secondary options of the set-ups are evaluated.	O	O	Review	1120
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]A lot of good thoughts were put into the work, and even though the techniques[line_break_token]tried are relatively unsophisticated, the work represents a serious attempt[line_break_token]on the subject and is of good reference value.	O	O	Review	1120
[line_break_token][line_break_token]The linkage between the use of emotion supervision and better relevancy is interesting.	O	O	Review	1120
[line_break_token][line_break_token]The dataset by itself is a good contribution to the community conducting studies in this area.	O	O	Review	1120
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]The conclusions are somewhat fuzzy as there are too many effects[line_break_token]interacting, and as a result no clear cut recommendations can be made[line_break_token](perhaps with the exception that ensembling a classifier model trained[line_break_token]for emotion recognition together with the response selector is seen[line_break_token]as having advantages).	B-Review	B-1	Review	1120
[line_break_token][line_break_token]There are some detailed questions that are unaddressed or unclear from[line_break_token]the writing.	B-Review	B-2	Review	1120
 See the Misc.	I-Review	I-2	Review	1120
items below.	I-Review	I-2	Review	1120
[line_break_token][line_break_token]Misc.	I-Review	I-2	Review	1120
[line_break_token][line_break_token]P.1, 6th line from bottom: "fro" -> "from"[line_break_token][line_break_token]Table 1:  How is the "situation description" supposed to be related to the[line_break_token]opening sentence of the speaker?	B-Review	B-4	Review	1120
 In the examples there seems to be substantial[line_break_token]overlap.	I-Review	I-4	Review	1120
[line_break_token][line_break_token]Figure 2, distribution of the 32 emotion labels used:[line_break_token]this is a very refined set that could get blurred at the boundaries between similar emotions.	B-Review	B-5	Review	1120
[line_break_token]As for the creators of those dialogs,  does everyone interpret the same emotion label the same way?	I-Review	I-5	Review	1120
[line_break_token]e.g. angry, furious; confident, prepared; ...; will such potential ambiguities impact the work?	I-Review	I-5	Review	1120
[line_break_token]One way to learn more about this is to aggregate related emotions to make a coarser set,[line_break_token]and compare the results.	I-Review	I-5	Review	1120
[line_break_token][line_break_token]Also, often an event may trigger multiple emotions, which one the speaker chooses to focus on[line_break_token]may vary from person to person.	B-Review	B-6	Review	1120
 How may ignoring the secondary emotions impact the results?	I-Review	I-6	Review	1120
[line_break_token]To some extent this is leveraged by the prepending method (with top-K emotion predictions).	I-Review	I-6	Review	1120
[line_break_token]What about the other two methods?	I-Review	I-6	Review	1120
[line_break_token][line_break_token]P. 6, on using an existing emotion predictor:  does it predict the same set of emotions[line_break_token]that you are using in this work?	B-Review	B-7	Review	1120
[line_break_token][line_break_token]	O	O	Review	1120
‚Äúthis is a very refined set that could get blurred at the boundaries between similar emotions.	O	O	Reply	1120
‚Äù:[line_break_token] as mentioned in the paper, we consulted existing works on emotion classification, especially works that had provided previous datasets of similar nature (e.g., Skerry and Saxe 2015).	B-Reply	B-5	Reply	1120
We decided to include all the emotion labels used in those previous works so that people who had used those datasets before could more easily transition to ours, possibly by using only the subset that had those emotion labels.	I-Reply	I-5	Reply	1120
Distinction between similar emotions was not as important to us, since our main focus was generating situations to which Listeners could react with empathy, rather than distinguishing between them.	I-Reply	I-5	Reply	1120
We selected a very fine-grained set of emotion labels so that researchers could group together similar emotions, as needed depending on the application they are interested in (and indeed there is a lot of work on how to cluster labels in a data-driven way, e.g. , Bengio et al 2010 [1]), though we do not try that here.	I-Reply	I-5	Reply	1120
We reasoned that it is easier to group together after the fact than to separate and the focus of this work is not emotion classification.	I-Reply	I-5	Reply	1120
 We also thought that keeping emotions that are similar but suggest some intensity gradation (e.g., angry vs. furious) could even be useful down the line for tasks such as grading emotion intensity, like the task 1 of SemEval 2018.	I-Reply	I-5	Reply	1120
[line_break_token][line_break_token]‚Äúdoes everyone interpret the same emotion label the same way‚Äù: no, indeed, but the agreement between humans is high enough to get good signal, and this has been quantified -- for example, see Fig 1C in Skerry and Saxe 2015  (reference in the paper) that finds an accuracy of 65% for 20 labels (all part of our set of 32), where chance would be 5%.	O	O	Reply	1120
[line_break_token]For an explicit feature-based analysis of similarity, relevant analyses of overlap of features and similarities can also be found in Skerry and Saxe 2015 -- in particular Figure 2 shows how labels (20 labels, that are included in our list of 32) relate to appraisal features (e.g., expectedness, future, familiarity, suddenness, etc), basic emotions, and the affective circumplex.	B-Reply	B-5	Reply	1120
[line_break_token][line_break_token]‚Äú will such potential ambiguities impact the work?	O	O	Reply	1120
[line_break_token]One way to learn more about this is to aggregate related emotions to make a coarser set,[line_break_token]and compare the results.	O	O	Reply	1120
‚Äù ‚ÄúWhat about [multitask and ensemble]?‚Äù:  With supervised fine-tuning or concatenating representations (the multitask and ensemble settings), the representation used in the model is taken before a single winner is outputted, so there isn‚Äôt an information loss caused by the winner-take-all process of outputting a single label  -- however, it is definitely possible that having better clustering of emotions could focus learning on more crucial information than distinguishing whether someone is ‚Äúangry‚Äù or ‚Äúfurious‚Äù while they‚Äôre actually somewhere in between, and this could be tested in future work, for example in conjunction with existing methods to combine labels.	B-Reply	B-5	Reply	1120
Thanks for the suggestion.	I-Reply	I-5	Reply	1120
[line_break_token]As you also mention, ‚ÄúTo some extent this is leveraged by the prepending method (with top-K emotion predictions).‚Äù -- and indeed that was our reason for experimenting with K > 1.	O	O	Reply	1120
[line_break_token][line_break_token]‚Äúon using an existing emotion predictor:  does it predict the same set of emotions[line_break_token]that you are using in this work?‚Äù  all of the emotion predictors that we use from other works were trained with different sets of labels than what we use, and not directly emotions (e.g., emojis), however we fine-tune the deepmoji+ model on our set of labels.	B-Reply	B-7	Reply	1120
The deepmoji paper presents many experiments on transferring their emoji classification learning to multiple loosely emotion-related tasks, like sentiment classification (Table 9 in the appendix lists many of those datasets.)	I-Reply	I-7	Reply	1120
One of those datasets is the ISEAR set, which uses labels that we did include in our list and which also starts from short situation descriptions, so we had reason to believe that deepmoji could transfer well to our task.	I-Reply	I-7	Reply	1120
[line_break_token][line_break_token][1] Bengio, S., Weston, J. and Grangier, D., 2010.	O	O	Reply	1120
Label embedding trees for large multi-class tasks.	O	O	Reply	1120
In Advances in Neural Information Processing Systems (pp.	O	O	Reply	1120
163-171).	O	O	Reply	1120

# Review ICLR20, RGBD-GAN[line_break_token][line_break_token]This review is for the originally uploaded version of this article.	O	O	Review	78
Comments from other reviewers and revisions have deliberately not been taken into account.	O	O	Review	78
After publishing this review, this reviewer will participate in the forum discussion and help the authors improve the paper.	O	O	Review	78
[line_break_token][line_break_token]## Overall[line_break_token][line_break_token]The article proposes a method of modifying image-generating networks to also produce depth maps in an unsupervised way by enforcing rotational consistency.	O	O	Review	78
[line_break_token][line_break_token]I enjoyed reading this work and I'm recommending it to be accepted.	O	O	Review	78
However, first there are some (in my opinion straight-forward) changes that need to be made to this work before I can recommend its publication: [line_break_token][line_break_token]- The common "Related Works" section is missing and some of the literature is taking place in the introduction.	B-Review	B-1	Review	78
I find this unorganized and I'd recommend keeping the intro shorter and just moving the literature either behind the intro or to the end of the paper.	I-Review	I-1	Review	78
[line_break_token]- Most figures and especially your headline figure (1) suffer from not having the depth normalized and not having a scale to it.	B-Review	B-2	Review	78
The fix for this is simple and two-fold: for each depth image, subtract the minimum value and divide by the range (to normalize it and increase contrast), then write in the caption or as a legend that white is closer to the camera and black is further back.	I-Review	I-2	Review	78
[line_break_token]- 3D vs. 2.5D - If the common geometric definition of "3D" was applied here, the article's title was correct.	B-Review	B-3	Review	78
However, in computer vision and especially 3D vision, the term is commonly used to refer only to models that include full scene geometry, including the occluded backs of objects and the term 2.5D is used to describe assigning depth values to pixels in an RGB image (and therefore only covering the view-dependent front of the object), which I think is the case here.	I-Review	I-3	Review	78
However, this is not a hill that I'll die on so if you insist on that terminology, I won't block acceptance.	I-Review	I-3	Review	78
[line_break_token]- When you first discuss HoloGAN, you mention one of its main downsides being scalability and then proceed to not only explain that but also use a HoloGAN-like architecture in one of your experiments.	B-Review	B-4	Review	78
I'd either remove the scalability argument or justify not just that but also how that's not relevant to your experiments.	I-Review	I-4	Review	78
[line_break_token]- The following phrase occurs multiple times throughout: "camera parameter conditional image generation".	B-Review	B-5	Review	78
I _think_ you're missing a dash between "parameter" and "conditional".	I-Review	I-5	Review	78
[line_break_token][line_break_token][line_break_token]## Specific comments and questions[line_break_token][line_break_token]### Abstract[line_break_token][line_break_token]All good.	O	O	Review	78
[line_break_token][line_break_token]### Intro[line_break_token][line_break_token]- Fig.1 normalize image [line_break_token]- The literature section in intro mentions "For all methods, 3D annotations must be used..." - that's not true.	B-Review	B-6	Review	78
See [Rezende, 2016][1] and [Rajeswar, 2018][2][line_break_token]- I understand how some literature is required to position your method, but I think it's better to not have the entire literature section in the center of the introduction[line_break_token][line_break_token][1]: <a href="https://arxiv.org/abs/1607.00662" target="_blank" rel="nofollow">https://arxiv.org/abs/1607.00662</a>[line_break_token][2]: <a href="https://openreview.net/forum?id=BJeem3C9F7" target="_blank" rel="nofollow">https://openreview.net/forum?id=BJeem3C9F7</a>[line_break_token][line_break_token]### Method[line_break_token][line_break_token]- 2.1 clear + nicely written[line_break_token]- Figure 2 good, caption a bit too short - figure+caption should be able to stand on their own[line_break_token]- Illustration of Figure 3 nice, except for unclear DeepVoxel part: what's the wavy orange flag stand for?	B-Review	B-8	Review	78
[line_break_token][line_break_token]### Experiments[line_break_token][line_break_token]- You mention K is fixed, but where does the initial K come from?	B-Review	B-12	Review	78
I assume it's just neglected (since it's not important for StyleGAN/PGGAN), but then this needs to be mentioned in the methods sections closer to the formulas dealing with K.[line_break_token]- Figure 4 - the depth maps need to be normalized.	B-Review	B-13	Review	78
All we see here is a grey mush, even worse in Fig.	I-Review	I-13	Review	78
7[line_break_token]- For ShapeNet cars, the model seems to suffer from not having a reference for the top and bottom of the image - have you tried adding floor/sky?	B-Review	B-14	Review	78
[line_break_token]- Figure 6, the tire marker is a good idea but image still unclear - I recommend slightly less rotation or an intermediate step between generated image and e.g. front view[line_break_token]- For quantitative results/FID: try using Hausdorff or Chamfer distance on the rendered scenes' pixels.	B-Review	B-15	Review	78
We don't care about the goodness of the RGB generation but the depth.	B-Review	B-16	Review	78
[line_break_token][line_break_token]### Conclusion[line_break_token][line_break_token]All good, albeit a bit short.	B-Review	B-17	Review	78
[line_break_token][line_break_token]### Appendix[line_break_token][line_break_token]I don't think I saw any references to the appendix in the main paper.	B-Review	B-18	Review	78
e would like to thank the reviewer for valuable comments.	O	O	Reply	78
[line_break_token][line_break_token]Related works[line_break_token]- We will separate the related work section from the introduction section.	B-Reply	B-1	Reply	78
[line_break_token][line_break_token]Depth visualization[line_break_token]- We will normalize the depth maps and visualize it in colormap (as reviewer2 says) for better visualization.	B-Reply	B-2	Reply	78
[line_break_token][line_break_token]3D vs. 2.5D[line_break_token]- Our model can not only generate RGBD images, which is commonly considered 2.5D, but also explicitly control camera poses while preserving the image content.	B-Reply	B-3	Reply	78
Therefore, it can be regarded that the model can learn full 3D geometry implicitly, though the output is not fully 3D. This is the intuition to use the word "3D".	I-Reply	I-3	Reply	78
[line_break_token][line_break_token]Scalability of HoloGAN[line_break_token]- We agree that the badness of the scalability of HoloGAN is not supported by our experimental results.	B-Reply	B-4	Reply	78
Therefore, we will delete the scalability part from the introduction.	I-Reply	I-4	Reply	78
[line_break_token][line_break_token]Necessity for 3D annotations[line_break_token]- Thank you for introducing related papers.	B-Reply	B-7	Reply	78
Though they do not need annotations, both methods can only deal with synthetic primitive datasets.	I-Reply	I-7	Reply	78
Our method, however, can work on natural images.	I-Reply	I-7	Reply	78
We will add the discussion to the related works section.	I-Reply	I-7	Reply	78
[line_break_token][line_break_token]wavy flag[line_break_token]- This is a conceptual figure of learned DeepVoxels.	B-Reply	B-11	Reply	78
DeepVoxels are implicit representations, and we cannot visualize what is acquired.	I-Reply	I-11	Reply	78
We agree that the figure is ambiguous, we will replace the figure.	I-Reply	I-11	Reply	78
[line_break_token][line_break_token]About K[line_break_token]- Because learning K from single images is difficult, we initialize K with [[2s, 0, s/2], [0, 2s, s/2], [0, 0, 1]] (numpy-style order), where is image size.	B-Reply	B-12	Reply	78
We will add the explanation in the paper.	I-Reply	I-12	Reply	78
[line_break_token][line_break_token]floor/sky[line_break_token]- We did not try adding floor or sky to render the ShapeNet car dataset.	B-Reply	B-14	Reply	78
We think adding simple sky or floor will help learning depth information to some extent, but it is difficult to learn consistent depth.	I-Reply	I-14	Reply	78
This is because foreground regions have common salient concepts across views (eg.	I-Reply	I-14	Reply	78
tire, headlight, window, ...) but the background does not.	I-Reply	I-14	Reply	78
This is also problematic when we train the model on a car image dataset, which has floor and sky, as shown in Figure 7.	I-Reply	I-14	Reply	78
[line_break_token][line_break_token]Evaluation for depth[line_break_token]- Evaluating the generated depth is difficult because we cannot obtain ground truth depth for the generated images.	B-Reply	B-16	Reply	78
A possible approach to evaluate depth images without ground truth images is calculating the inception score (IS) [5] or FID on the generated depth images, but we do not think it is appropriate.	I-Reply	I-16	Reply	78
This is because IS and FID are estimated in the feature space of a pre-trained CNN, and they cannot consider the geometry in the 3D world.	I-Reply	I-16	Reply	78
Therefore it is almost impossible to evaluate how the generated depth is plausible in 3D space.	I-Reply	I-16	Reply	78
Instead, we will evaluate the depth consistency across views to quantitatively compare the generated depth among different methods.	I-Reply	I-16	Reply	78
When we plot point clouds generated from the same but different, all points should be on a single surface.	I-Reply	I-16	Reply	78
Therefore, by calculating the variation of the generated depth, we can quantitatively evaluate the 3D consistency across views.	I-Reply	I-16	Reply	78
It is expected that 3D-latent-feature-based models have better performance than other models.	I-Reply	I-16	Reply	78
We will add the results in the paper.	I-Reply	I-16	Reply	78
[line_break_token][line_break_token][5] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.	O	O	Reply	78
Improved techniques for training gans.	O	O	Reply	78
In NIPS, 2016	O	O	Reply	78

The authors present a method for training probabilistic models by maximizing a stochastic variational-lower-bound-type objective.	O	O	Review	509
Training involves sampling and then learning a transition-based inference to "walk back" samples to the data.	O	O	Review	509
Because of its focus on transitions, it can be used to learn a raw transition operator rather than purely learning an energy-based model.	O	O	Review	509
The objective is intuitively appealing because of its similarity to previous successful but less principled training methods for MRFs like Contrastive Divergence.	O	O	Review	509
[line_break_token][line_break_token]The idea for the algorithm is appealing, and it looks like it could find a nice place in the literature.	O	O	Review	509
However, the submission in its current form is not yet ready for publication.	O	O	Review	509
Experiments are qualitative and the generated samples are not obviously indicative of a high model quality.	O	O	Review	509
As pointed out elsewhere, the mathematical analysis does not currently demonstrate tightness of the variational bound in the case of a learned transition operator.	O	O	Review	509
More evaluation using e.g. annealed importance sampling to estimate held-out likelihoods is necessary.	B-Review	B-1	Review	509
Assuming that the analysis can be repaired, the ability to directly parametrize a transition operator, an interesting strength of this method, should be explored in further experiments and contrasted with the more standard energy-based modeling.	I-Review	I-1	Review	509
[line_break_token][line_break_token]This looks like a promising idea, and other reviews and questions have already raised some important technical points which should help strengthen this paper for future submission.	O	O	Review	509
An appendix was added which clarifies the conditions under which the approximation of the true posterior by the variational estimator Q becomes tight (basically hinging on a slow annealing).	B-Reply	B-1	Reply	509
However, keep in mind that even though Q does not match the true posterior, like for any other variational method, we are optimizing a valid bound on the log-likelihood	I-Reply	I-1	Reply	509

This paper tries to propose a new method to stabilize the training procedure of GAN.	O	O	Review	482
To this end, they use adversarial samples of real data to train the discriminator, and claim that it is helpful to reduce the adversarial noise contained in the gradient.	O	O	Review	482
Although training GAN with adversarial samples of discriminator is somewhat novel, the method and experiments are not convincing.	O	O	Review	482
[line_break_token]I do not recommend the acceptance based on the limited contribution of this paper.	O	O	Review	482
The following is a detailed evaluation.	O	O	Review	482
[line_break_token][line_break_token]1.	O	O	Review	482
The paper uses vague description such as ‚ÄúThis approach can improve the robustness of discriminator and reduce adversarial noise contained in gradient‚Äù without convincing justification.	B-Review	B-1	Review	482
Please give a formal description or notation of ‚Äúadversarial noise contained in gradient‚Äù, and discuss how to remove the effect of ‚Äúadversarial noise‚Äù in principle instead of extensively testing adversarial training of discriminator.	I-Review	I-1	Review	482
[line_break_token][line_break_token]2.	O	O	Review	482
The experiment is not convincing and the improvement is not significant.	B-Review	B-2	Review	482
The author running adversarial training on CIFAR10 dataset with FGSM and the perturbation is tested from 0.2/255 ~ 4/255.	I-Review	I-2	Review	482
The performance (FID score) is a bit sensitive to the amount of perturbation level.	I-Review	I-2	Review	482
Moreover, this The improvement over DCGAN is quite limited given previous works such as WGAN-GP.	I-Review	I-2	Review	482
Combined together, the result is not convincing (it seems to be a heavy tuning result rather than a principled solution).	I-Review	I-2	Review	482
hank you for your thoughtful and detailed review.	O	O	Reply	482
We will address your concerns one by one below.	O	O	Reply	482
[line_break_token][line_break_token]1 . ‚	O	O	Reply	482
ÄùThe paper uses vague description such as ‚ÄúThis approach can improve the robustness of discriminator and reduce adversarial noise contained in gradient‚Äù without convincing justification.	O	O	Reply	482
Please give a formal description or notation of ‚Äúadversarial noise contained in gradient‚Äù, and discuss how to remove the effect of ‚Äúadversarial noise‚Äù in principle instead of extensively testing adversarial training of discriminator.	O	O	Reply	482
‚Äù[line_break_token][line_break_token]Response: [line_break_token]We will make description of main claim more clear in the revised version.	B-Reply	B-1	Reply	482
Adversarial noise means the component in gradient of discriminator used to update generated images, which can not improve the fidelity of generated images but can drastically change the prediction of the discriminator.	I-Reply	I-1	Reply	482
Existence of adversarial noise is because the decision boundary of discriminator is not ideal ,ie, discriminator as a classifier realized by a neural network is vulnerable to small well-crafted perturbation, eg, perturbation in gradient direction, which is an universal property of neural networks [1]. Intuitively, adversarial noise as guide signal can mislead generator so as to make training unstable.	I-Reply	I-1	Reply	482
To this end, we introduce adversarial training on real samples that does not exist in GAN training framework, which can make discriminator more robust and smooth the decision boundary so as to reduce adversarial noise.	I-Reply	I-1	Reply	482
This can be validated by the gradient visualization shown as Fig 1.	I-Reply	I-1	Reply	482
Gradient given by standard discriminator seems like noise but gradient given by adversarially trained discriminator contains less noise and more semantic information, eg, profile of face.	I-Reply	I-1	Reply	482
[line_break_token][line_break_token]2.	O	O	Reply	482
The experiment is not convincing and the improvement is not significant.	O	O	Reply	482
The author running adversarial training on CIFAR10 dataset with FGSM and the perturbation is tested from 0.2/255 ~ 4/255.	O	O	Reply	482
The performance (FID score) is a bit sensitive to the amount of perturbation level.	O	O	Reply	482
Moreover, this The improvement over DCGAN is quite limited given previous works such as WGAN-GP.	O	O	Reply	482
Combined together, the result is not convincing (it seems to be a heavy tuning result rather than a principled solution).	O	O	Reply	482
[line_break_token][line_break_token]Response:[line_break_token]It is reasonable that FID score is sensitive to perturbation level because too small perturbation (0~0.1/255 ) can not improve the robustness of discriminator and too large perturbation (&gt;5/255) can drastically degrade real samples so as to mislead discriminator, which is clarified in Sec 3.4 and 4.1 .	O	O	Reply	482
We validated that best performance improvement can be achieved with default setting of perturbation level (1/255 on image generation tasks) on CIFAR10, CelebA, LSUN with DCGAN and ResNet architecture.	B-Reply	B-2	Reply	482
FID score is improved about 50% on CelebA, and 35% on LSUN.	I-Reply	I-2	Reply	482
This is a significant improvement, which can not be realized by parameter tuning.	I-Reply	I-2	Reply	482
We do not use other tricks to improve FID score.	I-Reply	I-2	Reply	482
Suitability of default perturbation level is quite well and it is not required for heavy searching of perturbation level when applying the proposed method on other datasets with different network architectures.	I-Reply	I-2	Reply	482
Extensive experiments validated that improvement is general and of principle but does not depend on heavy hyper-parameter tuning.	I-Reply	I-2	Reply	482
Moreover, the proposed method is much efficient than gradient penalty.	I-Reply	I-2	Reply	482
[line_break_token]Here is comparison of average training time of one epoch measured on single RTX 2080ti.	I-Reply	I-2	Reply	482
[line_break_token]----------------------------------------------------------------------------------------[line_break_token]Setting              DCGAN   AS-DCGAN(ours)   SN-DCGAN  DCGAN-GP[line_break_token]Training time   19.83s     26.40s                      24.50s          31.57s[line_break_token]----------------------------------------------------------------------------------------[line_break_token][line_break_token]Thank you for your review!	O	O	Reply	482
[line_break_token][line_break_token][1] Szegedy C, Zaremba W, Sutskever I, et al Intriguing properties of neural networks[J]. arXiv preprint arXiv:1312.6199, 2013.	O	O	Reply	482
[line_break_token]	O	O	Reply	482

The authors present an algorithm for actively learning the nodes in a graph that should be sampled/labeled in order to improve classifier performance the most.	O	O	Review	477
The proposed techniques use both the graph structure, and the current classifier performance/accuracy into account while (actively) selecting the next node to be labeled.	O	O	Review	477
[line_break_token][line_break_token]There seem to be two main contributions in the paper.	O	O	Review	477
1) The propose to sample nodes nodes based on "regional" uncertainty rather than node uncertainty 2) They use an variant of pagerank to determine nodes that are central, and hence most likely to affect subsequent classification in graph convolution classifiers.	O	O	Review	477
Both approaches seem to be interesting.	O	O	Review	477
There are experiments to show effectiveness of these techniques, and there are some interesting observations (for example, that the APR technique works better for smaller sample sizes, while the regional uncertainty methods do better for larger sampling fractions.).	O	O	Review	477
[line_break_token][line_break_token]While both techniques seem straightforward extensions of previous approaches (and are well explained in the paper),  the experiments indicate that they work better than prior approaches.	O	O	Review	477
It would have been nice if the authors had also discussed ways in which one or more of these techniques could be combined though, or discussed how we could pick the right approach (in a more empirical way, since it is not clear what the threshold for high sampling rate/low sampling rate distinction is, or if it varies from problem to problem)	B-Review	B-1	Review	477
eviewer 1 has one main critique, which is that there is no clear explanation of how to choose in advance a method.	O	O	Reply	477
This critique is also shared by the second reviewer.	O	O	Reply	477
Following both comments reviews, we now add a clear section on how to choose among the different algorithms that we propose.	O	O	Reply	477

The paper presents an improved analysis of the signSGD gradient estimator.	O	O	Review	10056
The authors propose to relax the requirements on the gradient estimator in Bernstein (2019).	O	O	Review	10056
The only requirement imposed on the gradient is that it should have the correct sign with probability greater than 1/2.	O	O	Review	10056
In particular this approach allows the gradient estimate to be biased as opposed to Bernstein (2019) which requires unbiased gradients.	O	O	Review	10056
The authors also show this condition to be necessary by a small counterexample.	O	O	Review	10056
[line_break_token][line_break_token]In my view the paper presents a relatively minor but still interesting extension of the work in Bernstein (2019).	O	O	Review	10056
The main problem is that the relaxation is not well motivated in terms of scenarios where this might be applicable.	B-Review	B-1	Review	10056
Experimental validation is also very weak.	B-Review	B-3	Review	10056
[line_break_token][line_break_token]It is claimed in the experiment section that the stochastic gradient of the Rosenbrock function g(x) = \del f_i(x) + eps, where eps is a 0-mean Gaussian and i is uniform random is biased.	B-Review	B-2	Review	10056
This seems incorrect to me and the gradient estimate should be unbiased when the expectation is taken over the randomness in i and eps.	I-Review	I-2	Review	10056
[line_break_token][line_break_token]A key claim of the paper is the ability to use biased gradient estimates.	B-Review	B-3	Review	10056
Experimental validation of this (in light of the above) is completely missing.	I-Review	I-3	Review	10056
[line_break_token][line_break_token]The experiments that are presented on MNIST are very general and not very closely connected to the specific claims of the paper.	I-Review	I-3	Review	10056
The only real conclusion drawn is that larger batch sizes improve convergence.	I-Review	I-3	Review	10056
[line_break_token][line_break_token]I think the paper needs better targeted experiments.	B-Review	B-4	Review	10056
They need to show covergence in a case where the conditions in Berstein (2019) do not hold.	I-Review	I-4	Review	10056
[line_break_token][line_break_token]How are the properties of the \rho norm related to the observations on l_1 norm for high and l_2 norm for low SNR components in Bernstein (2019)?	B-Review	B-5	Review	10056
If they are related this should be referenced.	I-Review	I-5	Review	10056
[line_break_token]	O	O	Review	10056
e motivated the relaxation by comparing it with 4 different conditions used in the literature: 1) unimodal symmetric noise assumption.	B-Reply	B-1	Reply	10056
2) Strong growth condition with fixed mini-batch size.	I-Reply	I-1	Reply	10056
3) Adaptive mini-batch size.	I-Reply	I-1	Reply	10056
4) Bounded variance assumption in the sense of uncertainty.	I-Reply	I-1	Reply	10056
[line_break_token][line_break_token]In fact the stochastic gradient of the Rosenbrock function considered in the paper is biased as expectation gives 1/(d-1) times the function itself.	B-Reply	B-2	Reply	10056
[line_break_token]*We will add better targeted experiments.*	B-Reply	B-4	Reply	10056
[line_break_token][line_break_token]The observation on low/high SNR components in (Bernstein et al 2019) were done under the unimodal symmetric noise assumption.	B-Reply	B-5	Reply	10056
Similar observation is done in our paper for rho_norm and the second half of section 3 (including figure 1) is devoted just to that.	I-Reply	I-5	Reply	10056
[line_break_token]*We added an explicit reference to (Bernstein et al 2019) at the end of section 3.	I-Reply	I-5	Reply	10056

POST-REBUTTAL FEEDBACK[line_break_token][line_break_token]Thanks for your response.	O	O	Review	20420
[line_break_token][line_break_token]The justifications provided in the response have not convinced me to improve my score.	B-Review	B-10	Review	20420
They are at times hard to understand: For example, the authors have claimed that while their design choice is not reasonable, it is less unreasonable than the other.	I-Review	I-10	Review	20420
[line_break_token][line_break_token]SUMMARY OF REVIEW[line_break_token][line_break_token]The authors have proposed the use of a neural surrogate model in place of the GP posterior mean and a weighted Reptile algorithm to meta-learn the initial weights of the neural surrogate model.	O	O	Review	20420
This approach appears interesting.	O	O	Review	20420
However, there seems to be multiple highly restrictive (at times impractical) assumptions in this work that are atypical of the BO setting adopted by other meta BO algorithms and not discussed, as detailed below.	O	O	Review	20420
Justifications are required.	O	O	Review	20420
[line_break_token][line_break_token]Clarifications are also needed with regards to how they exactly run their algorithm in the experiments and whether the prior/initial information from related problems/meta tasks provided to the tested algorithms is fair.	O	O	Review	20420
[line_break_token][line_break_token][line_break_token][line_break_token]DETAILED COMMENTS[line_break_token][line_break_token]The authors say that "We still use the variance in Eq. (	B-Review	B-1	Review	20420
4) to measure uncertainty, because the estimation uncertainty should be independent in individual problems."	I-Review	I-1	Review	20420
This does not seem to hold true.	I-Review	I-1	Review	20420
If a meta task or train set is indeed correlated (or provides information) to the new problem, the posterior variance/uncertainty at a point depends on the observations in the meta task or train set near to this point (see, for example, [line_break_token]Feurer et al (2018)).	I-Review	I-1	Review	20420
Can the authors discuss the implications of such an assumption in their work?	I-Review	I-1	Review	20420
[line_break_token][line_break_token]Q and Q_i have always been referred to as problems.	B-Review	B-2	Review	20420
In Algorithm 3, Q is suddenly referred to as meta train set.	I-Review	I-2	Review	20420
On page 4, you have said that x^*_i is the minimizer of i-th problem Q_i(x) in meta train set.	I-Review	I-2	Review	20420
Based on these information, I assume that the authors consider x^*_i as the global minimizer and that x^*_i is known in order to compute the rewards.	I-Review	I-2	Review	20420
Can the authors discuss why is this a reasonable assumption?	I-Review	I-2	Review	20420
[line_break_token][line_break_token]In their proposed weight Reptile algorithm (Algorithm 3), the authors have also assumed access to the black-box functions of the related problems or meta tasks, which is not typical of other meta BO works that only require the existing observations or datasets of the related problems/meta tasks.	B-Review	B-9	Review	20420
As a result, compared with the existing meta BO algorithms, their proposed weighted Reptile is considerably more expensive due to the need to additionally evaluate the black-box functions of the related problems or meta tasks many times during execution.	I-Review	I-9	Review	20420
Can the authors discuss the practical implications of such an assumption and how it affects the types of problems/applications that can be considered by this work?	I-Review	I-9	Review	20420
[line_break_token][line_break_token]The authors have not provided any justification for their choice of reward on page 4.	B-Review	B-10	Review	20420
If the black-box function is indeed complex and highly varying, the distance between points may not work well at all.	I-Review	I-10	Review	20420
Can the authors provide a justification and discuss the practical implications and limitations with such a choice?	I-Review	I-10	Review	20420
[line_break_token][line_break_token]Isn't it more natural to consider a single Bayesian neural network instead of using a neural network for the mean and a GP for the variance?	B-Review	B-11	Review	20420
[line_break_token][line_break_token]For the experiments, it would be good to see two other variants of the proposed algorithm to understand the individual contributions of the neural surrogate model and weighted Reptile algorithm: one without neural surrogate model and the other with simply the use of neural surrogate model.	B-Review	B-3	Review	20420
[line_break_token][line_break_token]Can the authors explain in greater detail how they run their algorithms (Algorithms 2 and 3) in the experiments?	B-Review	B-12	Review	20420
For example, the authors say that "WRA-N starts with learned initial surrogate model".	I-Review	I-12	Review	20420
I assume that WRA-N refers to Algorithm 3 based on its acronym.	I-Review	I-12	Review	20420
Isn't the learned initial surrogate model the output of WRA-N in the first place?	I-Review	I-12	Review	20420
Also, the graphs in Fig.	I-Review	I-12	Review	20420
2 seem to show iteration 1 to 13 in NOE (Algorithm 2).	I-Review	I-12	Review	20420
However, Algorithm 3 accepts N_T = 13 and executes NOE for N_T = 13 (and not 1, 2, or 3, ...) for each problem in each epoch.	I-Review	I-12	Review	20420
How do the authors generate the plot of WRA-N for iterations 1 to 12?	I-Review	I-12	Review	20420
[line_break_token]What seems to make more sense to me is that the authors in fact run Algorithm 2 instead of Algorithm 3 for each experiment and they initialize w in Algorithm 2 to the output of Algorithm 3.	B-Review	B-4	Review	20420
In any case, a clarification is needed here.	I-Review	I-4	Review	20420
[line_break_token][line_break_token]It is not clear to me whether the initial/prior information from related problems/meta tasks provided to WRA-N, TST-R, AND TSR-M is fair.	B-Review	B-13	Review	20420
Can the authors provide a justification?	I-Review	I-13	Review	20420
[line_break_token][line_break_token]To clarify, for each related problem/function, only N_T number of datapoints are used to train a corresponding neural network with 1 hidden layer of 15 hidden units?	B-Review	B-5	Review	20420
[line_break_token][line_break_token]The authors say that "Since TST-R needs base models for combination, we sample 20 points from uniform distribution in (‚àí10, 10) to construct base models."	B-Review	B-6	Review	20420
Is this sampling procedure the same as that in (Wistuba et al 2016)?	I-Review	I-6	Review	20420
[line_break_token][line_break_token]Can the authors explain the comparable performance of WRA-N and TST-R in Fig.	B-Review	B-7	Review	20420
5?	I-Review	I-7	Review	20420
Why are the error bars missing?	I-Review	I-7	Review	20420
[line_break_token][line_break_token]How does the proposed approach compare with that of Feurer et al (2018)?	B-Review	B-8	Review	20420
[line_break_token][line_break_token][line_break_token][line_break_token]Minor issues[line_break_token][line_break_token]Page 1, 3: adapt well to new tasks.	B-Review	B-14	Review	20420
[line_break_token]Page 2: The author says "depends on a GP-based surrogate model fitting function values without learnable parameters".	I-Review	I-14	Review	20420
This is not true: The GP hyperparameters need to be learned and they adapt to new problems.	I-Review	I-14	Review	20420
[line_break_token]Page 4: descent order?	I-Review	I-14	Review	20420
[line_break_token]Pages 4, 5: Why is there an input x to Q_i?	I-Review	I-14	Review	20420
[line_break_token]Algorithm 2: t^* should be at the superscript of x.[line_break_token]Equation 7: What is N?	I-Review	I-14	Review	20420
[line_break_token]Page 5: Does it make a difference in the performance when delta is set to 0?	I-Review	I-14	Review	20420
[line_break_token]Page 5: well define meta-features?	I-Review	I-14	Review	20420
hanks for your review,[line_break_token]1 Feurer et al (2018) used linear combination of variance of related problems.	B-Reply	B-1	Reply	20420
It is not reasonable,  first as the variance of  related problems is not determinate as it depends on sampling points.	I-Reply	I-1	Reply	20420
Thus different sampling points can cause different variance, then cause different surface in new problem.	I-Reply	I-1	Reply	20420
Second, in related problems, lower variance means lower uncertainty, then should this lower uncertainty bring to new problem?	I-Reply	I-1	Reply	20420
 If so, then in new problems, the variance of points sampled in related problems are low and the variance of points not sampled in related problems are high.	I-Reply	I-1	Reply	20420
It is absurd.	I-Reply	I-1	Reply	20420
[line_break_token]2 Knowing accurate global minimizer is acctually hard, however, we can use global minimizer of surrogate model.	B-Reply	B-2	Reply	20420
In other words, when meeting a problem, we sampled some points on it and construct a surrrogate model, then using this global minimizer to substitute.	I-Reply	I-2	Reply	20420
[line_break_token]3 Actually, when tuning hyper-parameters for neural networks, we may have tuned several similar (in structure )networks.	I-Reply	I-2	Reply	20420
Then these knowledge can be used to new tuning process.	I-Reply	I-2	Reply	20420
[line_break_token]4 May be global minimizer is not a reasonable setting.	I-Reply	I-2	Reply	20420
However, using function value is more unreasonable.	I-Reply	I-2	Reply	20420
Our aim is to finding global minimizer of objective function, thus using distance of global minimizer seems no problem.	I-Reply	I-2	Reply	20420
[line_break_token]5  'For the experiments, it would be good to see two other variants of the proposed algorithm to understand the individual contributions of the neural surrogate model and weighted Reptile algorithm: one without neural surrogate model and the other with simply the use of neural surrogate model.'	O	O	Reply	20420
[line_break_token]I can give you the comparation about initialization on ablation study (on problem of synthetic function): [line_break_token]initialization    |2.1|1.2|  0  |-0.8|-1.1|-1.2|-1.3|-1.4|-1.4|-1.4[line_break_token]after training  |0.1|  0 |-0.7|-1.2|-2.4|-3.5|-4.1|-4.8|-5.0|-5.9[line_break_token]But how to use WRA without neural surrogate model?	B-Reply	B-3	Reply	20420
WRA is a training method to train neural surroagte models.	I-Reply	I-3	Reply	20420
Without  neural surrogate model, what should WRA learn?	I-Reply	I-3	Reply	20420
[line_break_token]6 'What seems to make more sense to me is that the authors in fact run Algorithm 2 instead of Algorithm 3 for each experiment and they initialize w in Algorithm 2 to the output of Algorithm 3.'	O	O	Reply	20420
You are right, we do not write clearly.	B-Reply	B-4	Reply	20420
We actually use Alg 2 to get  iterations 1 to 12 and its initialization is got by Alg 3.	I-Reply	I-4	Reply	20420
[line_break_token]7 'To clarify, for each related problem/function, only N_T number of datapoints are used to train a corresponding neural network with 1 hidden layer of 15 hidden units?'	O	O	Reply	20420
We actually use neural network with 1 hidden layer of 15 hidden units.	B-Reply	B-5	Reply	20420
[line_break_token]8   'sample 20 points from uniform distribution in (‚àí10, 10)' is the same as Feurer et al (2018) who has compared TST-R.[line_break_token]9 TST-R based on linear combination of related problems, thus related problems determine the performance of TST-R. The comparable performance in SVM problem may beacuse this data set is suitable to TST-R. However, other datasets are not so suitable.	B-Reply	B-6	Reply	20420
[line_break_token]10  I can give you the comparation about Feurer et al (2018) on ablation study (on problem of synthetic function): [line_break_token]Feurer et al (2018)   |0.1|  0 |-1.7|-1.7|-1.7|-1.7|-1.7|-2.0|-2.0|-2.1[line_break_token]WRA-N                        |0.1|  0 |-1.9|-2.7|-2.8|-2.8|-3.5|-4.1|-4.4|-5.	O	O	Reply	20420

This paper proposed an aggregated momentum methods for gradient based optimization.	O	O	Review	494
The basic idea is instead of using a single velocity vector, multiple velocity vectors with different damping factors are used in order to improve the stability.	O	O	Review	494
[line_break_token][line_break_token]In term of novelty, the proposed method seems quite incremental.	O	O	Review	494
Using multiple velocity vectors seems interesting but not surprising, There is no theoretical guideline how to determine the number of velocity vectors and how to choose the damping factors.	B-Review	B-1	Review	494
[line_break_token][line_break_token]I would also suggest that authors should put some main theoretical results like the convergence analysis to the main paper instead of the appendix.	B-Review	B-2	Review	494
[line_break_token][line_break_token]In terms of the clarity, I think the paper is well written and the experiments are sufficient and convincing.	O	O	Review	494
[line_break_token][line_break_token]One minor question is: what is \lambda in Fig.	B-Review	B-3	Review	494
1?	I-Review	I-3	Review	494
[line_break_token][line_break_token] 	B-Review	B-1	Review	494
"Using multiple velocity vectors seems interesting but not surprising": I am not aware of works using a similar technique, despite momentum dating back to 1964.	B-Reply	B-1	Reply	494
As a result, I am not sure I understand your comment.	I-Reply	I-1	Reply	494
Could you please explain	I-Reply	I-1	Reply	494

This paper presents a system that infers programs describing 3D scenes composed of simple primitives.	O	O	Review	471
The system consists of three stages each of which is trained separately.	O	O	Review	471
First, the perceptual module extracts object masks and their attributes.	O	O	Review	471
The objects are then are split into several groups.	O	O	Review	471
Finally, each group is mapped to a corresponding DSL program using a sequence-to-sequence network similar to the ones typically employed in neural machine translation.	O	O	Review	471
[line_break_token][line_break_token]Pros:[line_break_token]+ The paper is written clearly and easy to read.	O	O	Review	471
[line_break_token]+ Visual program synthesis is very exciting and important direction both for image understanding and generation.	O	O	Review	471
[line_break_token]+ The results on synthetic datasets are good.	O	O	Review	471
The authors also demonstrate the applicability of the approach to real-world data (albeit significantly constrained).	O	O	Review	471
[line_break_token]+ I find it surprising that a seq2seq is good at producing an accurate program for a group of objects.	O	O	Review	471
[line_break_token]+ Visual analogy making experiments are impressive.	O	O	Review	471
[line_break_token][line_break_token]Cons:[line_break_token]- The proposed model requires rich annotation of training data since all the components of the systems are trained in a supervised fashion.	B-Review	B-1	Review	471
It‚Äôs not clear how to use the method on the in-the-wild data without such annotation.	I-Review	I-1	Review	471
[line_break_token]- Related to the previous point, even when it‚Äôs possible to synthesize data, it is non-trivial to obtain the ground-truth grouping of objects.	B-Review	B-2	Review	471
Judging by Table 2, it seems that the system breaks in absence of the grouping information.	I-Review	I-2	Review	471
[line_break_token]- The data used in the paper is quite simplistic (limited number of primitives located in a regular grid).	B-Review	B-3	Review	471
I‚Äôm wondering if there is a natural way to extend the approach to more complex settings.	I-Review	I-3	Review	471
My guess is that the performance will drop significantly.	I-Review	I-3	Review	471
[line_break_token][line_break_token]Notes/questions:[line_break_token]* Section 2, paragraph 1: The paper by [Ganin et al 2018] presents both a system for reproducing an image as well as for sampling from a distribution; moreover, it presents experiments on 3D data (i.e., not limited to drawing).	B-Review	B-4	Review	471
[line_break_token]* Section 3.4, paragraph 2: I‚Äôm not sure I understand the last sentence.	B-Review	B-5	Review	471
How can we know that we successfully recovered the scene at test time?	I-Review	I-5	Review	471
Could the authors elaborate on the stopping criterion for sampling?	I-Review	I-5	Review	471
[line_break_token]* Section 4.2, paragraph 2: Do I understand correctly that the main difference between the test set and the generalization set is the number of groups? (	B-Review	B-6	Review	471
i.e., 2 vs 3).	I-Review	I-6	Review	471
If so, it‚Äôs a fairly limited demonstration of generalization capabilities of the system.	I-Review	I-6	Review	471
[line_break_token]* Section 4.2, paragraph 4: ‚Äúwe search top 3 proposals ...‚Äù ‚Äì How do we decide which one is better?	B-Review	B-7	Review	471
Do we somehow have an access to the ground truth program at test time?	I-Review	I-7	Review	471
[line_break_token]* Could the authors explain the representation of a program more clearly?	B-Review	B-8	Review	471
How are loops handled?	I-Review	I-8	Review	471
How can one subtract/add programs in the analogy making experiment?	I-Review	I-8	Review	471
[line_break_token][line_break_token]Overall, I think it is a interesting paper and can be potentially accepted on the condition that the authors address my questions and concerns.	O	O	Review	471
Thank you for your thoughtful review.	O	O	Reply	471
[line_break_token][line_break_token]1.	O	O	Reply	471
Data annotations [line_break_token][line_break_token]Our model requires supervised training data in the pre-training stage for each of its components, but the program synthesizer needs no further training when generalizing to other data distributions since it works on object attribute space.	B-Reply	B-1	Reply	471
We consider this as an advantage of our model, as it is easy to get synthetic data, but much harder to obtain annotations (in particular program annotations) on in-the-wild images.	I-Reply	I-1	Reply	471
Disentangling vision recognition and program synthesis is a key to our model‚Äôs success on real images (Fig.	I-Reply	I-1	Reply	471
7): our model accurately predicts programs for the test set with only 90 labeled real images for fine-tuning.	I-Reply	I-1	Reply	471
[line_break_token][line_break_token]The group information is inherently included in the program and easy to obtain: when synthesizing data, we first sample several program blocks from our DSL, where each block corresponds to a set of objects that form a group.	I-Reply	I-1	Reply	471
These program blocks are then combined into the overall program description of the scene.	I-Reply	I-1	Reply	471
Our model explicitly learns the group information and shows advantages over baseline methods which learn directly from the overall program.	I-Reply	I-1	Reply	471
[line_break_token][line_break_token]2.	O	O	Reply	471
Scene complexity [line_break_token][line_break_token]In our main experiment, we place objects on a grid and then jitter their positions and orientations.	B-Reply	B-3	Reply	471
Results on these data suggest that scene programs describe these structured images well.	I-Reply	I-3	Reply	471
We agree with reviewers on the importance of handling more complex data.	I-Reply	I-3	Reply	471
In the revision by Nov. 26, we will add results on scenes where objects are placed at random.	I-Reply	I-3	Reply	471
[line_break_token][line_break_token]3.	O	O	Reply	471
Specific questions[line_break_token][line_break_token]1) Ganin et al: We will revise the description of this work in the updated draft.	B-Reply	B-4	Reply	471
[line_break_token][line_break_token]2) The stopping criterion is whether the scene has been successfully reconstructed, i.e., when the execution results of the program are the same as the object parsing results obtained from the vision module.	B-Reply	B-5	Reply	471
[line_break_token][line_break_token]3) Generalization: Yes, the main difference is the number of groups.	B-Reply	B-6	Reply	471
This is only one of our experiments on generalization.	I-Reply	I-6	Reply	471
The experiments on real image show our model‚Äôs ability to generalize to new data distributions.	I-Reply	I-6	Reply	471
[line_break_token][line_break_token]4) Top proposals: Note that the group detector also outputs the classification result of the group category.	B-Reply	B-7	Reply	471
Here ‚Äútop‚Äù refers to the softmax score.	I-Reply	I-7	Reply	471
We don‚Äôt have any information of the ground truth program at test time.	I-Reply	I-7	Reply	471
[line_break_token][line_break_token]5) Program representations: We will give detailed definitions in the Appendix.	B-Reply	B-8	Reply	471
In short, a program is represented as a matrix, where each row contains a program command, which is a program token followed by its parameters.	I-Reply	I-8	Reply	471
[line_break_token][line_break_token]Thanks!	O	O	Reply	471
Please don‚Äôt hesitate to let us know for any additional comments on the paper or on the planned changes.	O	O	Reply	471

If I understood correctly, in experimental part pre-trained embeddings, taken from word2vec, is a ground truth.	O	O	Review	545
Given those embeddings, a system of hyperplanes are trained (every hyperplane refers to a certain word attribute and a region in space, centered around a word, to which reflection is applied).	O	O	Review	545
[line_break_token][line_break_token]In my opinion, the most natural way to check "the reflection hypothesis" is to train new embeddings where to word2vec objective the loss function (16) is added and to look how perplexity will behave with that additional cost and to look how your accuracy and stability will behave on the test set.	B-Review	B-1	Review	545
[line_break_token][line_break_token]It is also interesting to learn how this reflection based attribute transfer can be applied to the same word, but with embeddings that play different role in a model: e.g. input and output embeddings.	O	O	Review	545
[line_break_token]In fact, input and output embeddings are located in the same space, they can be considered as pairs of words with 1 attribute flipped (i.e. role in a model, input-&gt;output).	O	O	Review	545
Can an output embedding be obtained from an input embedding via reflections that you describe.	B-Review	B-2	Review	545
How many hyperplanes we need in that case?	I-Review	I-2	Review	545
This is an interesting edge of the problem.	I-Review	I-2	Review	545
In simplest models, there is some evidence, that output embeddings are result of reflections of input embeddings in half the dimensions.	I-Review	I-2	Review	545
It would be interesting to learn your comment on that.	I-Review	I-2	Review	545
[line_break_token]	O	O	Review	545
hank you for the encouraging feedback.	O	O	Reply	545
We address your comments and questions below.	O	O	Reply	545
[line_break_token][line_break_token]1. "	O	O	Reply	545
In my opinion, the most natural way to check ‚Äúthe reflection hypothesis‚Äù is to train new embeddings where to word2vec objective the loss function (16) is added and to look how perplexity will behave with that additional cost and to look how your accuracy and stability will behave on the test set."	O	O	Reply	545
[line_break_token]In this study, we tried to incorporate reflection into a given word embeddings space as our first step.	B-Reply	B-1	Reply	545
Training word embeddings from scratch with reflection constraints would be promising future work.	I-Reply	I-1	Reply	545
[line_break_token][line_break_token]2. "	O	O	Reply	545
Can an output embedding be obtained from an input embedding via reflections that you describe.	O	O	Reply	545
How many hyperplanes we need in that case?"	O	O	Reply	545
[line_break_token]Yes, that‚Äôs right.	B-Reply	B-2	Reply	545
In this work, we parameterize mirror hyperplanes instead of a single mirror, and the mirror parameters are determined according to an input word embedding.	I-Reply	I-2	Reply	545
In other words, we can use different mirror hyperplanes for different input words	I-Reply	I-2	Reply	545

[Overview][line_break_token][line_break_token]In this paper, the authors proposed a simple but effective way to augmentation the language model through memorization.	O	O	Review	758
Specifically, after obtaining a language model on a dataset, the model further uses the dataset to build a lookup table and then a k-nearest neighbor is used to searching the closest tokens for a token during inference.	O	O	Review	758
Based on this, the output distribution of a target token during the inference time would be modified accordingly.	O	O	Review	758
Through a comprehensive experiments and ablation studies, the authors showed that the proposed strategy can improve the performance of language models significantly for both the in-domain and out-domain testing scenarios.	O	O	Review	758
This is very insightful considering recently a lot of language models are focusing on increasing the size of model and training data.	O	O	Review	758
[line_break_token][line_break_token][Pros]:[line_break_token][line_break_token]Overall I think the paper is well-written and presents clearly.	O	O	Review	758
Detailed points below:[line_break_token][line_break_token]1.	O	O	Review	758
the authors proposed a simple but effective method for increasing the generalization ability of language model through a memorization strategy.	O	O	Review	758
Specifically, the authors proposed to build a lookup table which memorizes the representation and output token pairs which are then used for the inference of language model.	O	O	Review	758
Different from conventional way, the proposed strategy does not introduce any more parameters in the model and also does not need any more training or fine-tuning on the target dataset.	O	O	Review	758
[line_break_token][line_break_token]2.	O	O	Review	758
The authors showed that the proposed strategy can improve the performance of language generation model (i.e., transformer) without any extra training or data, as shown in Table 1.	O	O	Review	758
Also, using the continuous caches  with KNN-LM further improve the performance.	O	O	Review	758
[line_break_token][line_break_token]3.	O	O	Review	758
Besides the main results shown in Table 1 and Table 2, the authors also showed using kNN-LM can probably outperforms the model which is directly trained on it.	O	O	Review	758
Also, it also supports domain adaptation from one language domain to another domain.	O	O	Review	758
[line_break_token][line_break_token]4.	O	O	Review	758
Finally, the authors presented a number of ablation studies to investigate how the performance is affected by the method of building datastore, including the size of nearest neighbor, the interpolation parameter, etc.	O	O	Review	758
These results are also insightful and meaningful for the readers to understand the method.	O	O	Review	758
[line_break_token][line_break_token][Cons]:[line_break_token][line_break_token]I think this paper is a solid paper.	O	O	Review	758
So I would have some suggestions below:[line_break_token][line_break_token]1.	O	O	Review	758
The first concern about the method is the efficiency.	B-Review	B-1	Review	758
At page 3, the authors mentioned that the proposed strategy will bring more time cost.	I-Review	I-1	Review	758
It would be good if the authors can perform more systematical analysis on the time cost of building the datastore and inference for the proposed model.	I-Review	I-1	Review	758
[line_break_token][line_break_token]2.	O	O	Review	758
Second, the authors should not only evaluate the proposed method based on transformers.	B-Review	B-2	Review	758
It would be good to test on various language models to verify the generalization ability across different models, including the old-fashioned one like RNN and CNN.	I-Review	I-2	Review	758
[line_break_token][line_break_token]3.	O	O	Review	758
Also, the authors should try to extend the proposed model to other language tasks, such as translation.	B-Review	B-3	Review	758
[line_break_token][line_break_token][Summary][line_break_token][line_break_token]In this paper, the authors introduced a simple but effective method to augment the pertained language model through memorizations.	O	O	Review	758
Though this is not absolutely new and relatively simple , the authors successfully demonstrate that it can be applied to improve the generation of language model much.	O	O	Review	758
The.	O	O	Review	758
thorough ablation studies help to understand the property of the proposed strategy.	O	O	Review	758
I think this paper overall is insightful and thoughtful.	O	O	Review	758
It would be good to see the authors add more analysis on the computational complexity and also evaluate on more type of language models.	B-Review	B-3	Review	758
[line_break_token]	O	O	Review	758
ello Reviewer1,[line_break_token][line_break_token]Thanks for your comments.	O	O	Reply	758
We‚Äôre glad you enjoyed the paper!	O	O	Reply	758
[line_break_token][line_break_token]Efficiency:[line_break_token]Building the datastore: A single epoch of training over the Wikitext-103 data takes ~5 hours on a single GPU.	B-Reply	B-1	Reply	758
In comparison, a single forward pass over the same dataset to save keys/values took ~4 hours.	I-Reply	I-1	Reply	758
Then, creating the datastore using FAISS took two hours on a single CPU.	I-Reply	I-1	Reply	758
Hence, building the datastore is is comparable to a single epoch of training.	I-Reply	I-1	Reply	758
In addition, the saving of keys/values as well as creating the datastore are trivial to parallelize.	I-Reply	I-1	Reply	758
[line_break_token][line_break_token]Inference: We measured the decoding speed of kNN-LM and found that it can sample roughly 60 tokens per second on one GPU, which is easily fast enough for most applications (albeit slower than the vanilla LM, which can sample roughly 500 tokens per second).	I-Reply	I-1	Reply	758
Improving the efficiency is not a focus of this work, but it is likely that it could be significantly improved - for example, by downsampling frequent words from the datastore.	I-Reply	I-1	Reply	758
[line_break_token][line_break_token]Other architectures:[line_break_token]We are in the process of evaluating the model on a CNN-based LM as well!	B-Reply	B-2	Reply	758
Thanks for the suggestion!	O	O	Reply	758
[line_break_token][line_break_token]Future work:[line_break_token]We also agree that applying kNN-LM to translation would be an exciting next step which we hope to pursue in followup work!	B-Reply	B-3	Reply	758
[line_break_token][line_break_token]Thanks!	O	O	Reply	758

This paper proposes a new and simple framework for learning cross-lingual embeddings that, based on well-supported insights, unifies two standard frameworks: joint learning and alignment-based approaches.	O	O	Review	20407
While I like and acknowledge the fact that the paper examines these frameworks critically and has also some didactic value, I still have some concerns regarding the current experiments, and would like to see some additional analyses in the paper.	O	O	Review	20407
Honestly, this type of work would work better as a short ACL/EMNLP paper, as the core methodological contribution is a very simple combination of the existing techniques.	O	O	Review	20407
[line_break_token][line_break_token]With joint methods, it is true that shared words can be used as implicit bilingual learning signal which gets propagated further in the model.	B-Review	B-1	Review	20407
Even in the case of alignment-based methods, it was shown that this signal can assist in learning shared cross-lingual spaces, but: 1) such spaces are of lower-quality than the spaces learned by relying on seed dictionaries (see e.g., the work of Vulic and Korhonen (ACL 2016)), 2) this is useful only for similar language pairs which use the same script.	I-Review	I-1	Review	20407
The paper fails to provide an insightful discussion on how the scores differ when we move towards more distant languages.	I-Review	I-1	Review	20407
For instance, English-Chinese is included as a more distant language pair, and the combined method seems to work fine, but the reader is left wondering why that happens.	I-Review	I-1	Review	20407
The same is true for English-Russian.	I-Review	I-1	Review	20407
The paper should definitely provide more information and insights here.	I-Review	I-1	Review	20407
[line_break_token][line_break_token]One experiment that would be quite interesting imho is to take seed dictionaries to initialise the joint training method.	B-Review	B-2	Review	20407
It will not be unsupervised any more, but it would be very useful to report the differences in results between fully unsupervised joint initialisation (which, as mentioned should work only with more similar languages) and such weakly supervised init: e.g., the method could take all one-to-one translation pairs from the seed dictionary as 'shared words'.	I-Review	I-2	Review	20407
It would also be interesting to combine such 'shared words' and words that are really shared (identically spelled words) as initialisation and measure how it affects the results, also in light of differences in language distance.	I-Review	I-2	Review	20407
Adding one such experiment would make the paper more interesting.	I-Review	I-2	Review	20407
[line_break_token][line_break_token]Some recent strong baselines are missing: e.g., I wonder how the model that does self-learning on top of seed dictionaries (similar to the work of Vulic et al EMNLP 2019) compares to the proposed method.	B-Review	B-3	Review	20407
Also, can we use the same self-learning technique with the combined method here?	I-Review	I-3	Review	20407
Would that lead to improved results?	I-Review	I-3	Review	20407
Another work I would like to see comparisons to is the work of Zhang et al (ACL 2019) and despite the fact that the authors explicitly stated that they decided not to compare to the work of Artetxe et al (ACL 2019) as they see it as concurrent work, I would still like to see that comparison as the model of Artetxe et al seems very relevant to the presented work.	I-Review	I-3	Review	20407
[line_break_token][line_break_token]I do not see the extension to contextualized representations (described in Section 3.2) as a real contribution: this is a very straightforward method to apply an alignment-based method on multilingual BERT representations, and very similar techniques have been probed in previous work (e.g., by Aldarmaki &amp; Diab), only the bilingual signal/dictionary came from parallel data instead.	O	O	Review	20407
[line_break_token][line_break_token]Finally, as mentioned before, one of the must-have experiments is including more (distant and diverse) language pairs and analysing the results across such language pairs, with an aim to further understand how the levels of sharing, over-sharing, and non-isomorphism affect performance.	B-Review	B-5	Review	20407
Also, while the authors state that reduced isomorphism is the key problem of alignment-based methods, I still fail to see how exactly the alignment refinement step does not suffer from that problem?	I-Review	I-5	Review	20407
More discussion is needed here.	I-Review	I-5	Review	20407
[line_break_token][line_break_token]Other comments:[line_break_token]- It would be useful to also point to the survey paper of Ruder et al (JAIR 2019) where the difference between alignment-based and joint models is described in more detail and could inform an interested reader beyond the confines of the related work section in this paper.	B-Review	B-6	Review	20407
Similarly, differences between joint models and alignment-based models have also been analysed by Upadhyay et al (ACL 2016); Vulic and Korhonen (ACL 2016).	I-Review	I-6	Review	20407
[line_break_token][line_break_token]- I like how Figure 1 clearly visualizes the main intuitions behind the proposed framework, and how mitigating the oversharing problem leads to better alignments.	B-Review	B-7	Review	20407
This was very nice.	I-Review	I-7	Review	20407
[line_break_token][line_break_token]- In light of the problems with silver standard MUSE datasets (see also the recent work of Kementchedjhieva, EMNLP 2019), I would suggest to run BLI experiments on more language pairs: e.g., there are BLI datasets of Glavas et al available for 28 language pairs.	B-Review	B-8	Review	20407
hank you for your comprehensive review and valuable feedback.	O	O	Reply	20407
We address your comments one by one as following:[line_break_token][line_break_token][Improvements of distant language pairs/Reduced isomorphism][line_break_token][line_break_token]The source of improvement for jointly training two distant languages is still an open question.	B-Reply	B-1	Reply	20407
As recently shown in [1], joint training is still beneficial even for languages using disjoint vocabulary sets.	I-Reply	I-1	Reply	20407
Although their findings are based on contextualized representations, we observe similar improvements for non-contextualized representations in our experiments and we hypothesize that the improvement is due to the overlap in training corpus resulting in more similar graph structures of embeddings (i.e. suffer less from the reduced isomorphism issue).	I-Reply	I-1	Reply	20407
[line_break_token][line_break_token]To analyze the effect of reduced isomorphism, we compute the eigenvector similarity proposed in [2]. This metric measures the degree of similarity between two embedding graphs and therefore can be used to estimate the degree of isomorphism.	I-Reply	I-1	Reply	20407
In particular, we compute this metric using four embeddings: monolingual fasttext, fasttext aligned with RCSLS, joint training (unsupervised), and joint_align with RCSLS.	I-Reply	I-1	Reply	20407
The results are shown below (smaller values indicates graphs are more similar).	I-Reply	I-1	Reply	20407
In particular, we observe that jointly trained embeddings share more similar graph structures than independently trained counterparts and thus they suffer less from the reduced isomorphism problem.	I-Reply	I-1	Reply	20407
These results also suggest that the alignment refinement step suffers less from this problem due to a better initialization from joint training.	I-Reply	I-1	Reply	20407
[line_break_token][line_break_token]                                  en-es |en-fr|en-de|en-it|en-ru|en-zh| avg[line_break_token]fasttext                       3.25 | 3.73 | 4.48 | 4.15 | 4.92 | 5.02 | 4.26[line_break_token]fasttext_RCSLS          2.56 | 2.59 | 2.02 | 2.72 | 3.60 | 2.82 | 2.72[line_break_token]Unsupervised Joint   2.59 | 1.98 | 2.38 | 2.59 | 2.94 | 2.79 | 2.55[line_break_token]Joint_Align                  1.48 | 2.00 | 1.75 | 2.45 | 3.07 | 2.68 | 2.24[line_break_token][line_break_token][Joint training with seed dictionary][line_break_token][line_break_token]We agree that adding a joint training baseline using seed dictionaries is didactic.	B-Reply	B-2	Reply	20407
However, this is a non-trivial task since joint training works best with fasttext in order to utilize subword information, which does not take an explicit form of seed dictionary nor allow tokens with different surface forms to share same embeddings.	I-Reply	I-2	Reply	20407
Therefore, instead of fundamentally modifying fasttext, we use a simple approach: (1) for each word in the dictionary, we randomly replace its occurrences in the concatenated corpus with its translation 50% of the time and keep it unchanged for the rest, (2) we then train the joint training embeddings as in the paper, (3) for words in the seed dictionary, we take the average of their embeddings and treat them as one single word shared between the two languages.	I-Reply	I-2	Reply	20407
We use the same seed dictionary from MUSE as in other experiments.	I-Reply	I-2	Reply	20407
As pointed out by reviewer 3, manipulating the degree of sharing is an ambitious goal that we plan to study in the future and may include in a later version.	I-Reply	I-2	Reply	20407
[line_break_token][line_break_token]As shown in the table below, we observe that using the seed dictionary as ‚Äúshared words‚Äù improves the performance of unsupervised joint training.	I-Reply	I-2	Reply	20407
However, since this method still treats identically spelled words as shared words (which is implicitly forced by the nature of fasttext), it still suffer from the oversharing problem as we observe further improvements by applying an extra vocabulary reallocation step.	I-Reply	I-2	Reply	20407
[line_break_token][line_break_token]BLI:[line_break_token]                                 en-es|es-en|en-fr|fr-en |en-de|de-en|en-it|it-en|en-ru|ru-en|en-zh|zh-en|avg[line_break_token]Unsupervised Joint  33.4| 36.6 | 42.2 | 47.4 | 39.5 | 41.4  | 36.8 | 38.8| 4.00 | 3.50 | 17.9  | 10.2  |29.3 [line_break_token]Replace                      48.2| 47.7 | 49.4 | 52.1 | 46.5 | 46.9  | 43.8 | 45.8| 20.3 | 36.6 | 32.7  | 34.1  |42.0 [line_break_token]Replace+VR               67.1| 68.7 | 66.4 | 68.4 | 62.3 | 64.2  | 57.3 | 60.6| 42.6 | 50.1 | 46.5  | 43.6  |58.2 [line_break_token]Joint_Align                 86.0| 88.5 | 83.9 | 85.8 | 79.3 | 78.7  | 79.9 | 83.1| 60.4 | 69.2 | 57.2  | 50.4  |75.2 [line_break_token][line_break_token]NER:[line_break_token]                                       es     |      nl     |     de     |    avg[line_break_token]Unsupervised Joint  50.28   |   42.77  |  21.49  |   38.18[line_break_token]Replace                      65.28   |   68.44  |  51.59  |   61.77 [line_break_token]Joint_Align                 70.46   |   72.10  |  56.47  |   66.34 [line_break_token][line_break_token](The method described above is denoted as ‚ÄúReplace‚Äù and we also include baselines from the paper for your convenience. ‚	I-Reply	I-2	Reply	20407
ÄúVR‚Äù denotes vocabulary reallocation.)	I-Reply	I-2	Reply	20407
[line_break_token][line_break_token][Extension to contextualized representations][line_break_token][line_break_token]We agree that applying alignment methods to contextualized representations is straightforward.	B-Reply	B-4	Reply	20407
The point is to show that further alignment on an already well-trained multilingual model can still improve performance, which has also been shown by [3] and is consistent with findings reported in [1]	I-Reply	I-4	Reply	20407

This paper introduces MusicNet, a new dataset.	O	O	Review	266
Application of ML techniques to music have been limited due to scarcity of exactly the kind of data that is provided here: meticulously annotated, carefully verified and organized, containing enough "hours" of music, and where genre has been well constrained in order to allow for sufficient homogeneity in the data to help ensure usefulness.	O	O	Review	266
This is great for the community.	O	O	Review	266
[line_break_token][line_break_token]The description of the validation of the dataset is interesting, and indicates a careful process was followed.	O	O	Review	266
[line_break_token][line_break_token]The authors provide just enough basic experiments to show that this dataset is big enough that good low-level features (i.e. expected sinusoidal variations) can indeed be learned in an end-to-end context.	O	O	Review	266
[line_break_token][line_break_token]One might argue that in terms of learning representations, the work presented here contributes more in the dataset than in the experiments or techniques used.	O	O	Review	266
However, given the challenges of acquiring good datasets, and given the essential role such datasets play for the community in moving research forward and providing baseline reference points, I feel that this contribution carries substantial weight in terms of expected future rewards. (	O	O	Review	266
If research groups were making great new datasets available on a regular basis, that would place this in a different context.	O	O	Review	266
But so far, that is not the case.)	O	O	Review	266
In otherwords, while the experiments/techniques are not necessarily in the top 50% of accepted papers (per the review criteria), I am guessing that the dataset is in the top 15% or better.	O	O	Review	266
Thank you for your positive comments	O	O	Reply	266

Summary.	O	O	Review	1297
[line_break_token]The paper proposes a vehicle‚Äôs trajectory planner that iteratively predict next-step (longitudinal and latitudinal) position of an ego-vehicle.	O	O	Review	1297
Instead of using a raw image, a set of handcrafted features (i.e., the status of traffic lights, route, roadmap, etc) are mapped onto a fixed-size of bird-eye view map, which is then fed into the recurrent neural network.	O	O	Review	1297
Additional regularizing loss terms are explored for the robustness of the model.	O	O	Review	1297
The effectiveness of the method is demonstrated in simulation and real-world experiment.	O	O	Review	1297
[line_break_token][line_break_token]Strengths.	O	O	Review	1297
[line_break_token]- Impressive demonstrations in simulation and real-world experiments.	O	O	Review	1297
[line_break_token]- The paper is generally well-written and easy to follow.	O	O	Review	1297
[line_break_token][line_break_token]vs. Existing motion planning approaches.	O	O	Review	1297
[line_break_token]There exists a large volume of papers on vehicle motion planning, which has largely been explored for controlling self-driving vehicles.	O	O	Review	1297
Some of them successfully demonstrated their effectiveness for navigating a vehicle in typical driving scenarios, including ‚Äúslowing down for a slow car‚Äù.	O	O	Review	1297
[line_break_token]A notable survey may include:[line_break_token][line_break_token][1] Paden et al ‚ÄúA survey of motion planning and control techniques for self-driving urban vehicles,‚Äù IEEE Transactions on intelligent vehicles, 2016.	O	O	Review	1297
[line_break_token][line_break_token]However, the paper provides neither any works of literature on existing motion planners nor any types of comparison with them.	B-Review	B-1	Review	1297
This makes hard to judge the proposed learning-based motion planner outperforms others including conventional optimization-based methods.	I-Review	I-1	Review	1297
[line_break_token][line_break_token]Missing data collection details.	B-Review	B-2	Review	1297
[line_break_token]This work depends hugely on its own human-designated oracle-like map, which provides driving-related features, such as lane, the status of traffic lights, speed limits, desired route, dynamic objects, etc.	I-Review	I-2	Review	1297
Generating this map would not be a trivial task, but details are missing on (1) how this data collected and (2) how this data can be collected during the testing time (especially for dynamic objects/traffic light status).	I-Review	I-2	Review	1297
Section 6.2 should be explained more in detail.	I-Review	I-2	Review	1297
[line_break_token][line_break_token]A weak novelty of using intermediate-level input/output representation.	B-Review	B-3	Review	1297
[line_break_token]There exist similar approaches that utilized similar representations to determine a vehicle‚Äôs behaviour, examples may include:[line_break_token][line_break_token][1] Lee et al ‚ÄúConvolution Neural Network-based Lane Change Intention Prediction of Surrounding Vehicles for ACC,‚Äù IEEE ITSC 2017.	I-Review	I-3	Review	1297
[line_break_token][2] We et al ‚ÄúModeling trajectories with recurrent neural networks,‚Äù IJCAI, 2017.	I-Review	I-3	Review	1297
[line_break_token][line_break_token]Missing evaluation details.	B-Review	B-4	Review	1297
[line_break_token]In Section 6.2, (though not mentioned) it seems that a training dataset is collected from 60-days of real-world driving (given the context).	I-Review	I-4	Review	1297
But, in the testing phase, it seems that the authors used a simulator to evaluate different driving scenarios with various initial condition (i.e., speed, heading angle, position, etc).	I-Review	I-4	Review	1297
Can authors clarify details of the evaluation environment?	I-Review	I-4	Review	1297
[line_break_token][line_break_token]Minor concerns.	O	O	Review	1297
[line_break_token]A paragraph of contribution summary (in Introduction section) will help.	B-Review	B-5	Review	1297
[line_break_token]Typos (e.g., Section 2 line 17: ‚Äòoff of‚Äô)	B-Review	B-6	Review	1297
Thanks for reviewing the paper and for your valuable feedback.	O	O	Reply	1297
[line_break_token][line_break_token]‚ÄúExisting motion planning approaches‚Äù: We have included this reference in the revised draft.	B-Reply	B-1	Reply	1297
Motion planning is really useful in cases where the cost function, constraints, and dynamics are clear; none of that is true for driving -- writing down the true cost we want optimized is hard and contextual, and the dynamics are hard especially because they involve other people in the environment and what they will do; we thus think it's useful to see how far imitation learning can be pushed as an alternative.	I-Reply	I-1	Reply	1297
We would also like to emphasize that this is not only useful for driving the car, but also can be integrated within a motion planner as a model of how other people will act.	I-Reply	I-1	Reply	1297
[line_break_token][line_break_token]‚ÄúData collection details‚Äù: Data about the prior map of the environment (roadmap) and the speed-limits along the lanes is collected apriori.	B-Reply	B-2	Reply	1297
For the dynamic scene entities like objects and traffic-lights, we employ a separate perception system based on laser and camera data similar to existing works in the literature [1,2]. We have clarified this in the revised version.	I-Reply	I-2	Reply	1297
[line_break_token][line_break_token][1] Fairfield, Nathaniel, and Chris Urmson. "	O	O	Reply	1297
Traffic light mapping and detection."	O	O	Reply	1297
Robotics and Automation (ICRA), 2011 IEEE International Conference on.	O	O	Reply	1297
IEEE, 2011.	O	O	Reply	1297
[line_break_token][2] Yang, Bin, Ming Liang, and Raquel Urtasun. "	O	O	Reply	1297
HDNET: Exploiting HD Maps for 3D Object Detection."	O	O	Reply	1297
Conference on Robot Learning.	O	O	Reply	1297
2018.	O	O	Reply	1297
[line_break_token][line_break_token]‚ÄúOther references‚Äù: Our paper includes recent references to works on autonomous driving using the mid-level input/output representations.	B-Reply	B-3	Reply	1297
In the revised version, we have also included the suggested references which specifically target use-cases like predicting other agents‚Äô intent.	I-Reply	I-3	Reply	1297
[line_break_token][line_break_token]‚ÄúEvaluation details‚Äù: The training data is collected from real-world driving.	B-Reply	B-4	Reply	1297
We perform testing on these kinds of data:[line_break_token] [line_break_token]Simulated Data: For this evaluation, we create specific scenarios as described in section 6.3.1 within our simulator to allow us to test specific conditions without introducing the complexities of real world all at the same time and the quantitative results in Fig.	I-Reply	I-4	Reply	1297
4 point to these results [ <a href="https://sites.google.com/view/learn-to-drive#h.p_XLYMjRiONt1e" target="_blank" rel="nofollow">https://sites.google.com/view/learn-to-drive#h.p_XLYMjRiONt1e</a> ].	O	O	Reply	1297
[line_break_token][line_break_token]Logged Data: For this evaluation, we take logs from our real-driving test data (separate from our training data), and use our trained network to drive the car using the vehicle simulator keeping everything else the same i.e. the dynamic objects, traffic-light states etc.	B-Reply	B-4	Reply	1297
are all kept the same as in the logs.	I-Reply	I-4	Reply	1297
These drives are shown in the supplemental website [ <a href="https://sites.google.com/view/learn-to-drive#h.p_cxFQRIZYOQ7o" target="_blank" rel="nofollow">https://sites.google.com/view/learn-to-drive#h.p_cxFQRIZYOQ7o</a> ].	O	O	Reply	1297
[line_break_token][line_break_token]Logged Ablation Data: This is the same as above, except that we modify some of the rendered inputs like removing the stop-signs or other dynamic objects to generate the input ablation results in section 6.3.2 and the videos on the supplemental site [ <a href="https://sites.google.com/view/learn-to-drive#h.p_WjtxfxJsNmJT" target="_blank" rel="nofollow">https://sites.google.com/view/learn-to-drive#h.p_WjtxfxJsNmJT</a> ].	O	O	Reply	1297
[line_break_token][line_break_token]Real Drive: This is where we let the network drive a real car [ <a href="https://sites.google.com/view/learn-to-drive#h.p_zId3Ux6DONGv" target="_blank" rel="nofollow">https://sites.google.com/view/learn-to-drive#h.p_zId3Ux6DONGv</a> ].	O	O	Reply	1297
[line_break_token][line_break_token]‚ÄúContribution Summary‚Äù: We have updated the introduction to clarify the contributions.	B-Reply	B-5	Reply	1297

- Summary[line_break_token][line_break_token]This paper studies the sample elicitation problem where agents are asked to report samples.	O	O	Review	640
The goal is then to evaluate the quality of these reported samples by means of a scoring function S. Following previous related works, the authors use the equivalence between maximizing the expected proper score and minimizing some f-divergence.	O	O	Review	640
Their approach relies on the dual expression of the f-divergence which writes as a maximum over a set of functions t. Theoretical guarantees are given for f-scorings obtained (with or without ground truth samples) by first computing the empirical optimal function t, then plugged to estimate the f-divergence.	O	O	Review	640
Finally, a deep learning approach is proposed by considering functions f parameterized as sparse deep neural networks.	O	O	Review	640
[line_break_token][line_break_token]- Critics[line_break_token][line_break_token]The paper is globally well written but not well motivated and sometimes difficult to understand.	B-Review	B-1	Review	640
[line_break_token]In particular, the notions of "elicitation", "reports" and "score function" should be defined mathematically more clearly.	I-Review	I-1	Review	640
[line_break_token]Moreover, the deep learning aspect of the paper is not well motivated and is introduced in a very arbitrary way.	I-Review	I-1	Review	640
Why not choosing another parametric family of functions?	I-Review	I-1	Review	640
Is there another (broad) family of functions for which the computation of the argmin in Equation (4.3) is more tractable in practice?	I-Review	I-1	Review	640
[line_break_token]A convincing way to motivate this deep learning approach would be to include numerical experiments and to compare to other parametric families.	I-Review	I-1	Review	640
[line_break_token]	O	O	Review	640
ince ICLR is the premier deep learning conference, we are motivated to collect credible and quality samples from strategic agents (e.g., ordinary people) for deep learning.	B-Reply	B-1	Reply	640
Naturally, we think it is of interest to try using deep learning techniques to solve the score function design problem via a data-driven approach.	I-Reply	I-1	Reply	640
Along the way of developing our results, we realized the connection between our elicitation problem and GAN, which we detail in Section 5.	I-Reply	I-1	Reply	640
[line_break_token][line_break_token]Beyond above, the deep learning based estimators are able to handle complex data.	I-Reply	I-1	Reply	640
And with our deep learning solution, we are further able to provide estimates for the divergence functions used for our scoring mechanisms, with provable finite sample complexity.	I-Reply	I-1	Reply	640
In our opinion, these are highly non-trivial contributions.	I-Reply	I-1	Reply	640
In this paper, we focus on developing theoretical guarantees- other parametric families either can not handle complex data, e.g., it is hard to handle images using kernel methods, or do not have provable guarantees on the sample complexity.	I-Reply	I-1	Reply	640
[line_break_token][line_break_token]We wonder whether there is another reason that leads to the reviewer‚Äôs recommendation of rejection.	O	O	Reply	640
We are happy to further clarify.	O	O	Reply	640

This paper proposes GRAM-nets using MMD as the critic to train GANs.	O	O	Review	448
Similar to MMD-GAN, the MMD is computed on a projected lower dimensional space to prevent the kernel struggle in the high dimensional observed space.	O	O	Review	448
On the other hand, contrary to MMD-GAN, GRAM-nets trains the projection f_{\theta} trying to matching the density ratio of p/q between the observed and the latent space.	O	O	Review	448
The proposed density ratio matching criterion avoids the adversarial training in MMD-GAN, thus can potentially fix the two-player optimization problem.	O	O	Review	448
The paper shows improved FID scores and nice-looking CIFAR10 generations.	O	O	Review	448
[line_break_token][line_break_token]Strengths, [line_break_token]1, Matching density ratios is a novel and interesting idea.	O	O	Review	448
If the data lives in a lower dimensional subspace, matching density ratio could probably reveal the subspace.	O	O	Review	448
Compared to adversarially training f_theta, the proposed approach could lead to more stable training potentially.	O	O	Review	448
[line_break_token]2, By manipulating E (px/qx - pz/qz)^2, they avoid estimating the high-dimensional px/qx and only estimate pz/qz.	O	O	Review	448
[line_break_token][line_break_token][line_break_token]Weakness,[line_break_token]1, The paper needs to be more careful with mathematical expressions.	B-Review	B-1	Review	448
1) Eq(2) should be MMD^2, instead of MMD.	I-Review	I-1	Review	448
2) Eq(5) and Eq(6) are wrong, although the used Eq(7) becomes true again.	I-Review	I-1	Review	448
In Eq(5), Eq(6), the integration should be over f(x) instead of x, that is to say.	I-Review	I-1	Review	448
[line_break_token]2, It is unclear why one needs the regularization in Eq(9).	B-Review	B-2	Review	448
In fact, the major problem of the density ratio estimator lies in that r(x) might be negative, so a clipping might be useful.	I-Review	I-2	Review	448
[line_break_token]3, The major contribution of GRAM-nets lies in removing the adversarial training in MMD-GAN.	B-Review	B-3	Review	448
Therefore, more empirical comparisons should be made with MMD-GAN.	I-Review	I-3	Review	448
For example, how MMD-GAN evolves in Figure 2 is necessary.	I-Review	I-3	Review	448
[line_break_token]4, In real image generation tasks, it is beneficial to show the stability of training GRAM-nets, compared with GAN, MMD-GAN as well as WGAN-GP; And Inception scores should also be reported for better validating the effectiveness of the proposed method.	B-Review	B-4	Review	448
.	B-Reply	B-1	Reply	448
On integration measure: Thanks for correctly pointing out, indeed, the integrals are defined with respect to the measure. (	I-Reply	I-1	Reply	448
7) becomes correct again after invoking LOTUS (law of unconscious statistician).	I-Reply	I-1	Reply	448
We will fix these typos.	I-Reply	I-1	Reply	448
We would also like to clarify if this is what you referred to as the 'fundamental error'?	I-Reply	I-1	Reply	448
If not, could you please point it out.	I-Reply	I-1	Reply	448
[line_break_token][line_break_token]2.	O	O	Reply	448
Clipping DRE: Our motivation to add the non-negativity regularization term is to encourage f_theta to produce a reduced space on which the density ratio estimator tends to produce positive values, which is trying to alleviate the problem that you pointed out.	B-Reply	B-2	Reply	448
In fact, we tried your suggestion on the synthetic datasets and MNIST and found that clipping the estimator works very robustly.	I-Reply	I-2	Reply	448
Thanks for this great suggestion!	I-Reply	I-2	Reply	448
[line_break_token][line_break_token]3.	O	O	Reply	448
Synthetic data experiment for MMD-GAN: We ran the experiments from Figure 2 for MMD-GANs, which are provided in Figure 10 (Appendix F).	B-Reply	B-3	Reply	448
Note that these plots take 4,000 epochs, each with 5 steps for the critic network and 1 step for the generative network, while Figure 2b for GRAM-nets only takes 2,000 epochs with a single joint step for both the networks.	I-Reply	I-3	Reply	448
Even with longer training, the quality of MMD-GAN is visually worse than GRAM-nets in this synthetic example.	I-Reply	I-3	Reply	448
Notice, how the generated samples of MMD-GAN are similar to the successful runs for GAN in Figure 2a: generated samples tend to be too concentrated around the mode of the individual clusters.	I-Reply	I-3	Reply	448
Our method on the other hand, with shorter training time, is clearly able to recover all the 8 clusters along with their spread[line_break_token][line_break_token]4.	O	O	Reply	448
On comparison with WGAN-GP: Wasserstein distance and MMD are both instances of integral probability metrics and have been compared to each other before in great details by Binkowski et al, (2018).	B-Reply	B-4	Reply	448
They were able to show that MMD-GAN is better (stable, efficient with higher IS) than WGAN-GP, therefore we chose to compare to MMD-GAN in this work given its direct relevance.	I-Reply	I-4	Reply	448
Figure 5 shows the stability of GRAM-nets v.s.	I-Reply	I-4	Reply	448
MMD-GANs.	I-Reply	I-4	Reply	448
We have added inception scores for MMD-GANs, GANs and GRAM-nets on CIFAR10 in Appendix E, as per your suggestion.	I-Reply	I-4	Reply	448

This paper attempts to establish a notion of thermodynamics for machine learning.	O	O	Review	971
Let me give an attempt at summary.	O	O	Review	971
First, an objective function is established based on demanding that the multi-information of two graphical models be small.	O	O	Review	971
The first graphical model is supposed to represent the actual dependence of variables and parameters used to learn a latent description of the training data, and the model demands that the latents entirely explain the correlation of the data, with the parameters marginalized out.	O	O	Review	971
Then, a variational approximation is made to four subsets of terms in this objective function, defining four "thermodynamic"  functionals.	O	O	Review	971
Minimizing the sum of these functionals puts a variational upper bound on the objective.	O	O	Review	971
Next, the sum is related to an unconstrained Lagrange multiplier problem making use of the facts (1) that such an objective will likely have many different realizations of the thermodynamic functionals for specific value of the bound and (2) that on the optimal surface the value of one of the functional can be parametrized in terms of the three others.	O	O	Review	971
If we pick the entropy functional to be parameterized in terms of the others, we find ourself precisely in the where the solution to the optimization is a Boltzmann distribution; the coefficients of the Lagrange multipliers will then take on thermodynamic interpretations in of temperature, generalized chemical potentials, etc.	O	O	Review	971
At this point, the machinery of thermodynamics can be brought to bear, including a first law, Maxwell relations (equality of mixed partial derivatives), etc.	O	O	Review	971
[line_break_token][line_break_token]I think the line of thinking in this paper is very much worth pursuing, but I think this paper requires significant improvement and modifications before it can be published.	B-Review	B-1	Review	971
Part of the problem is that the paper is both very formal and not very clear.	I-Review	I-1	Review	971
It's hard to understand why the authors are establishing this analogy, where they are going with it, what's its use will be, etc.	I-Review	I-1	Review	971
Thermodynamics was developed to explain the results of experiments and is often explained by working out examples analytically on model systems.	I-Review	I-1	Review	971
This paper doesn't really have either such a motivation or such examples, and I think as a result I think it suffers.	I-Review	I-1	Review	971
[line_break_token][line_break_token]I also think the "Tale of Two Worlds" laid out in Section 2 requires more explanation.	B-Review	B-2	Review	971
In particular, I think more can be said about why Q is the the "world we want" and why minimizing the difference between these worlds is the right way to create an objective. (	I-Review	I-2	Review	971
I have no real problem with the objective once it is derived.)	I-Review	I-2	Review	971
Since this paper is really about establishing this formal relationship, and the starting point is supposed to be the motivating factor, I think this needs to be made much clearer.	I-Review	I-2	Review	971
[line_break_token][line_break_token]The I(Z_i, X_i, Theta) - I(X_i, Z_i) terms could have been combined into a conditional mutual information. (	B-Review	B-3	Review	971
I see this is discussed in Appendix A.) This leads to a different set of variational bounds and a different thermodynamics.	I-Review	I-3	Review	971
Why do we prefer one way over the other?	I-Review	I-3	Review	971
At the level of the thermodynamics, what would be the relationship between these different ways of thinking?	I-Review	I-3	Review	971
Since it's hard to see why I want to bother with doing this thermodynamics (a problem which could be assuaged with worked examples or more direct and clear experiments), it's hard to know how to think about this sort of freedom in the analogy. (	I-Review	I-3	Review	971
I also don't understand why the world Q graphical model is different in Appendix A when we combined terms this way, since the world Q lead to the objective, which is independent of how we variationally bound it.)	I-Review	I-3	Review	971
I think ultimately the problem can be traced to the individual terms in the objective (7) not being positive definitive, giving us the freedom to make different bounds by arranging the pieces to get different combinations of positive definite terms.	I-Review	I-3	Review	971
How am I supposed to think about this freedom?	I-Review	I-3	Review	971
[line_break_token][line_break_token]In conclusion, I would really like to see analogies like this worked out and be used to better understand machine learning methods.	O	O	Review	971
But for this program to be successful, I think a very compelling case needs to be made for it.	O	O	Review	971
Therefore, I think that this paper needs to be significantly rewritten before it can be published.	O	O	Review	971
Thank you for the review and careful read of the paper, and constructive criticism.	O	O	Reply	971
[line_break_token][line_break_token]We agree that there is more work to be done in further exploring the analogy to thermodynamics, but at least at present thought the existence of the analogy was interesting enough to warrant the current draft.	B-Reply	B-1	Reply	971
 We hope to develop tighter analogies and analytical examples for simple systems, but realistically we are already very pressed for space.	I-Reply	I-1	Reply	971
[line_break_token][line_break_token]We agree that more should be said about the choice of world Q and its implications.	B-Reply	B-3	Reply	971
 Part of the difficulty is the world Q shown in the body of the main work isn't necessarily the best, but it is the one that most directly connects with a wide range of existing objectives in the literature.	I-Reply	I-3	Reply	971
 We thought it is interesting to note that existing objectives can be motivated as minimizing an information projection to the world Q shown.	I-Reply	I-3	Reply	971
 We should better emphasize that if the reader finds world Q suspect, but trusts our general program, this could reasonably fuel a suspicion of the utility of the existing objectives.	I-Reply	I-3	Reply	971
[line_break_token][line_break_token]We are still investigating the utility of the modified objective in Appendix A.  (We note that world Q in Appendix A is Markov equivalent to the one in the main body, the Z<-X arrow simply changed direction.)	O	O	Reply	971
We suspect it might actually prove a more useful objective in practice than the existing formulation.	B-Reply	B-3	Reply	971
 We suspect the existing objective has the form it does not for any deep reason but because people naturally think in terms of decoders as a natural element of learning a useful representation.	I-Reply	I-3	Reply	971
 That in the infinite family limit there is an equivalence in the two forms of objective for a parametric representation with and without a decoder we find interesting.	I-Reply	I-3	Reply	971
 But at present we can only point out this equivalence as we haven't finished the experimental investigation yet	I-Reply	I-3	Reply	971

Deep Randomized Least Squares Value Iteration[line_break_token]=========================================================[line_break_token][line_break_token]This paper proposes a method for exploration via randomized value functions in Deep RL.	O	O	Review	20539
[line_break_token]The algorithm performs a standard DQN update, but then acts according to an exploration policy sampled from a posterior approximation based on a last layer linear rule.	O	O	Review	20539
[line_break_token]The authors show that this algorithm can perform well on a toy domain designed to require efficient exploration, together with some results on Atari games.	O	O	Review	20539
[line_break_token][line_break_token][line_break_token]There are several things to like about this paper:[line_break_token]- The problem of efficient exploration in Deep RL is a pressing one, and there is no clearly effective method out there widely used.	O	O	Review	20539
[line_break_token]- The proposed algorithm is interesting, and appears to have some reasonable properties.	O	O	Review	20539
One nice thing is that it requires only relatively minor changes to the DQN algorithm.	O	O	Review	20539
[line_break_token]- The general flow of the paper and structured progression is nice.	O	O	Review	20539
[line_break_token]- The algorithm generally appears to bring superior exploration and outperform epsilon-greedy baseline.	O	O	Review	20539
[line_break_token][line_break_token][line_break_token]However, there are some other places the work could be improved:[line_break_token]- I think that the name "Deep RLSVI" is a little imprecise... actually RLSVI could already be a "deep" algorithm as defined by the JMLR paper: <a href="http://jmlr.org/papers/volume20/18-339/18-339.pdf" target="_blank" rel="nofollow">http://jmlr.org/papers/volume20/18-339/18-339.pdf</a> (Algorithm 4).	O	O	Review	20539
I see that you mean this as an extension to the linear case for RLSVI... but I do think it would be better to call it something more explicit like "Last-layer RLSVI for DQN".	B-Review	B-1	Review	20539
[line_break_token]- Related to the above, the comparison to other similar methods for exploration via "randomized value functions" is not very comprehensive.	B-Review	B-2	Review	20539
I'm not sure what the pros/cons are of this method versus BootDQN or the very similar work from Azizzadenesheli?	I-Review	I-2	Review	20539
[line_break_token]- It would be good to compare these methods more explicitly, particularly on the domains designed specifically for testing exploration.	B-Review	B-3	Review	20539
To this end, I might suggest bsuite <a href="https://github.com/deepmind/bsuite" target="_blank" rel="nofollow">https://github.com/deepmind/bsuite</a> and particularly the "deep sea" domains?	O	O	Review	20539
[line_break_token]- Something feels a little off about the Atari results, particularly the curves for "rainbow"... these appear to be inconsistent with published results (look at Breakout).	B-Review	B-4	Review	20539
[line_break_token][line_break_token]Overall I think there is interesting material here, and I'd like to see more.	O	O	Review	20539
[line_break_token]However, I do have some concerns about the treatment/comparison to related work and I think without this it's not ready for publication.	B-Review	B-3	Review	20539
 We will consider changing the algorithm‚Äôs name, thank you.	B-Reply	B-1	Reply	20539
[line_break_token]- As you mentioned above, the goal of this paper is to demonstrate the benefit of replacing vanilla DQN‚Äôs exploration strategy to RLSVI.	B-Reply	B-2	Reply	20539
While other methods use an ensemble of networks (BootDQN) or change the network structure and loss (BDQN), we simply change the exploration strategy.	I-Reply	I-2	Reply	20539
[line_break_token]- Thank you, we will consider it.	B-Reply	B-3	Reply	20539
[line_break_token]- For the results of the baselines in the Atari section, we used the publicly available results in <a href="https://github.com/google/dopamine" target="_blank" rel="nofollow">https://github.com/google/dopamine</a> as supplied by DeepMind.	O	O	Reply	20539

This paper presents an approach to modeling videos based on a decomposition into a background + 2d sprites with a latent hidden state.	O	O	Review	387
The exposition is OK, and I think the approach is sensible, but the main issue with this paper is that it is lacking experiments on non-synthetic datasets.	O	O	Review	387
As such, while I find the graphics inspired questions the paper is investigating interesting, I don't think it is clear that this work introduces useful machinery for modeling more general videos.	O	O	Review	387
[line_break_token][line_break_token]I think this paper is more appropriate as a workshop contribution in its current form.	O	O	Review	387
Thanks for your review.	O	O	Reply	387
We will use your suggestions to improve our work	O	O	Reply	387

The authors introduce a class of quasi-hyperbolic algorithms that mix SGD with SGDM (or similar with Adam) and show improved empirical results.	O	O	Review	398
They also prove theoretical convergence of the methods and motivate the design well.	O	O	Review	398
The paper is well-written and contained the necessary references.	O	O	Review	398
Although I did feel that the authors could have better compared their method against the recent AggMom (Aggregated Momentum: Stability Through Passive Damping by Lucas et al).	B-Review	B-1	Review	398
Seems like there are a few similarities there.	I-Review	I-1	Review	398
[line_break_token][line_break_token]I enjoyed reading this paper and endorse it for acceptance.	O	O	Review	398
The theoretical results presented and easy to follow and state the assumptions clearly.	O	O	Review	398
I appreciated the fact that the authors aimed to keep the paper self-contained in its theory.	O	O	Review	398
The numerical experiments are thorough and fair.	O	O	Review	398
The authors test  the algorithms on an extremely wide set of problems ranging from image recognition (including CIFAR and ImageNet), natural language processing (including the state-of-the-art machine translation model), and reinforcement learning (including MuJoCo).	O	O	Review	398
I have not seen such a wide comparison in any paper proposing training algorithms before.	O	O	Review	398
Further, the numerical experiments are well-designed and also fair.	O	O	Review	398
The hyperparameters are chosen carefully, and both training and validation errors are presented.	O	O	Review	398
I also appreciate that the authors made the code available during the reviewing phase.	O	O	Review	398
Out of curiosity, I ran the code on some of my workflows and found that there was some improvement in performance as well.	O	O	Review	398
[line_break_token][line_break_token][line_break_token]	O	O	Review	398
We thank the reviewer for their encouraging and constructive feedback.	O	O	Reply	398
We are heartened that the reviewer has found the algorithms useful for their own applications!	O	O	Reply	398
[line_break_token][line_break_token]# Using multiple momentum buffers[line_break_token][line_break_token]We appreciate the pointer to the AggMo algorithm (Lucas et al 2018), which proposes the additive use of many momentum buffers with different values of beta (the momentum constant).	B-Reply	B-1	Reply	398
We had tried this in independent preliminary experimentation (toward analyzing many-state optimization), and we found that using multiple momentum buffers yields negligible value over using a single slow-decaying momentum buffer and setting an appropriate immediate discount (i.e. QHM with high beta and appropriate nu).	I-Reply	I-1	Reply	398
Given the added costs and complexity of using multiple momentum buffers, we decided against discussing many-state optimization.	I-Reply	I-1	Reply	398
[line_break_token][line_break_token]We believe that the two papers are largely orthogonal, as one paper focuses in depth on two-state optimization, while the other more broadly explores many-state optimization.	I-Reply	I-1	Reply	398
However, in light of AggMo's existence, we believe it is valuable to comment on the relationship between QHM and AggMo.	I-Reply	I-1	Reply	398
Specifically, we have updated the manuscript as follows:[line_break_token]- In section 4.5, we briefly connect QHM to AggMo.	I-Reply	I-1	Reply	398
[line_break_token]- In Appendix H, we provide a supplemental discussion and comparison with AggMo.	I-Reply	I-1	Reply	398
Specifically, we perform the autoencoder study from Appendix D.1 of Lucas et al (2018) with both algorithms, using the EMNIST dataset.	I-Reply	I-1	Reply	398
In short, we believe that the results of this comparison support the above notion from our preliminary experimentation.	I-Reply	I-1	Reply	398

### Summary of contributions[line_break_token][line_break_token]This paper aims to accelerate the training of deep networks using a selective sampling.	O	O	Review	20283
[line_break_token]They adapt ideas from active learning (which use some form of uncertainty estimation about the class of the label) to selectively choose samples on which to perform the backward pass.	O	O	Review	20283
Specifically, they use the minimal margin score (MMS).	O	O	Review	20283
[line_break_token]Their algorithm works by computing the forward pass over a batch of size B (which is much larger than the regular batch of size b), compute the uncertainty measure for each sample, and only perform the backward pass over the b samples with the highest uncertainty.	O	O	Review	20283
The motivation is that the backward pass is more expensive than the forward pass, and that by only performing this pass on a subset of samples, computations are saved.	O	O	Review	20283
[line_break_token][line_break_token][line_break_token]### Recommendation[line_break_token][line_break_token]Reject.	O	O	Review	20283
The central premise of the paper is unclear, the writing/presentation needs improvement, and the experiments are not convincing.	O	O	Review	20283
[line_break_token][line_break_token][line_break_token]### Detailed comments/improvements: [line_break_token][line_break_token][line_break_token]There is a central premise of the paper that I don't understand: that the forward pass is much cheaper than the backward pass.	B-Review	B-1	Review	20283
[line_break_token]This is claimed in the intro by referring to charts that hardware manufacturers publish (but there are no references included), but I don't see why this should be the case.	I-Review	I-1	Review	20283
[line_break_token]For a linear network with weights W, the forward pass is given by the matrix-matrix product (rows of X are minibatch samples):[line_break_token]Y = XW^T[line_break_token][line_break_token]and the backward pass is given by the two matrix-matrix products:[line_break_token]dL/dX = dL/dY*dY/dX = dL/dY*W[line_break_token]dL/dW = dL/dY*dY/dW = dL/dY*X^T[line_break_token][line_break_token]Similarly the two operations in the backward pass for convolutional layers are given by a convolution of the output gradients with the transposed weigtht kernels and the input image respectively.	I-Review	I-1	Review	20283
[line_break_token][line_break_token]Point being, I don't see why the backward pass should be more than 3x more expensive than the forward pass.	I-Review	I-1	Review	20283
A simple experiment in PyTorch confirms this: the code snippet pasted at the bottom shows that the backward pass takes only around 2.6x longer than the forward pass.	I-Review	I-1	Review	20283
 [line_break_token][line_break_token]fprop: 0.009286s[line_break_token]bprop: 0.0240s[line_break_token]bprop/fprop: 2.5893x[line_break_token][line_break_token]In algorithm 1, it is assumed that b &lt;&lt; B. For this to be effective the forward pass would have to be *much* faster than the backward pass for this method to yield an improvement in computation.	O	O	Review	20283
Can the authors comment on where this justification comes from?	B-Review	B-1	Review	20283
[line_break_token][line_break_token]I am unclear on what the purpose of Section 4.1 is.	I-Review	I-1	Review	20283
This shows that the MMS of the proposed method is lower than the other two, but this should be completely expected since that is exactly the quantity being minimized.	I-Review	I-1	Review	20283
[line_break_token]There are also several unsubstantiated claims: "Lower MMS scores resemble a better...batch of samples", "the batches selected by our method provide a higher value for the training procedure vs. the HNM samples.", "	I-Review	I-1	Review	20283
Evidently, the mean MMS provides a clearer perspective...and usefulness of the selected samples".	I-Review	I-1	Review	20283
What does higher value, usefulness, clearer perspective mean?	I-Review	I-1	Review	20283
[line_break_token][line_break_token]More generally, it is unclear if there is really any improvement in the final performance from using the proposed method.	O	O	Review	20283
[line_break_token]In Figure 2, all methods seem to have similar final performance.	B-Review	B-2	Review	20283
[line_break_token]In Figure 5, is there a reason why the curve for MMS is cut off?	B-Review	B-3	Review	20283
How does its final performance compare to that of the baseline method in red?	I-Review	I-3	Review	20283
It looks like the baseline might be better, but it's hard to tell from the figure.	I-Review	I-3	Review	20283
[line_break_token][line_break_token]Why are the experiments with the entropy measure in a seperate section?	B-Review	B-4	Review	20283
Please include them along with the other methods in the same plot, i.e merge Figure 2 and Figure 4.	I-Review	I-4	Review	20283
[line_break_token][line_break_token]My suggestions for improving the experimental section are as follows:[line_break_token]- include all methods together in all the plots/tables[line_break_token]- repeat experiments multiple times with different seeds to get error bars.	B-Review	B-5	Review	20283
Include these both in the learning curves and in the tables.	B-Review	B-6	Review	20283
[line_break_token]- It's hard to see small differences in the learning curves, so including tables as well is important.	B-Review	B-7	Review	20283
Include best performance for all the methods in the tables.	I-Review	I-7	Review	20283
[line_break_token][line_break_token]Finally, in 2019 CIFAR alone is not longer a sufficient dataset to report experiments on.	B-Review	B-8	Review	20283
Please report results on ImageNet as well.	I-Review	I-8	Review	20283
[line_break_token][line_break_token]One of the central premises of the paper is acceleration in terms of compute/time.	B-Review	B-9	Review	20283
To make this point, there should also be results in terms of walltime and floating-point operations.	I-Review	I-9	Review	20283
Please include these results in the paper.	I-Review	I-9	Review	20283
 [line_break_token]    [line_break_token][line_break_token][line_break_token][line_break_token]### Code snippet timing forward/backward passes[line_break_token][line_break_token][line_break_token]import torch, torch.nn as nn, time[line_break_token][line_break_token]model =[tab_token]nn.	I-Review	I-9	Review	20283
Sequential(nn.	I-Review	I-9	Review	20283
Linear(784, 1000),[line_break_token]                      nn.	I-Review	I-9	Review	20283
ReLU(),[line_break_token]                      nn.	I-Review	I-9	Review	20283
Linear(1000, 1000),[line_break_token]                      nn.	I-Review	I-9	Review	20283
ReLU(),[line_break_token]                      nn.	I-Review	I-9	Review	20283
Linear(1000, 10),[line_break_token]                      nn.	I-Review	I-9	Review	20283
LogSoftmax())[line_break_token][line_break_token]data = torch.randn(128, 784)[line_break_token]labels = torch.ones(128).long()[line_break_token]t = time.time()[line_break_token]pred = model.forward(data)[line_break_token]loss = nn.functional.nll_loss(pred, labels)[line_break_token]fprop_time = time.time() - t[line_break_token]t = time.time()[line_break_token]loss.backward()[line_break_token]bprop_time = time.time() - t[line_break_token]print('fprop: {:.4}s'.format(fprop_time))[line_break_token]print('bprop: {:.4f}s'.format(bprop_time))[line_break_token]print('bprop/fprop: {:.4f}x'.format(bprop_time / fprop_time))[line_break_token]	I-Review	I-9	Review	20283
ear reviewer #2:[line_break_token][line_break_token]We would like to thank you for the feedback and the effort involved in running the performance example you presented.	O	O	Reply	20283
We will answer the questions and reply to the comments raised:[line_break_token][line_break_token]1) As for the answer regarding our central premise.	B-Reply	B-1	Reply	20283
In order to select the samples using our MMS scheme, we leverage inference concepts that are entirely different from training.	I-Reply	I-1	Reply	20283
Some of the prominent ideas are low precision arithmetic operations when applying quantization, layers fusion like Convolution-BatchNorm (applying the BN running statistics into the convolutions and eliminating the need of performing BN) and weight compression.	I-Reply	I-1	Reply	20283
These concepts are not theoretical as they are being used when building specialized hardware accelerators as T4 (by Nvidia), Goya (by Habana) and TPU (by Google), allowing these devices to be ~10X faster at inference than running training step on a modern GPU.	I-Reply	I-1	Reply	20283
A detailed explanation and performance charts can be seen in Google‚Äôs TPU paper ‚ÄúIn-Datacenter Performance Analysis of a Tensor Processing Unit‚Äù.	I-Reply	I-1	Reply	20283
[line_break_token][line_break_token]Additionally, for distributed training on large-scale hardware, the advantage of the inference devices is even greater.	I-Reply	I-1	Reply	20283
As the training instances must wait to a gradient reduction across all instances, the inference devices can perform forward passes on multiple instances in full parallelism (i.e. inference is embarrassingly parallel), without the need to wait to any other instance in the system.	I-Reply	I-1	Reply	20283
 Thus, it can potentially select more offline examples for our MMS scheme.	I-Reply	I-1	Reply	20283
[line_break_token][line_break_token]Finally, more performance benchmarks can be found when referring to Habana‚Äôs site (<a href="https://habana.ai/inference/" target="_blank" rel="nofollow">https://habana.ai/inference/</a> and <a href="https://habana.ai/training/)" target="_blank" rel="nofollow">https://habana.ai/training/)</a> as the training vs. inference throughput on their hardware is 1650 vs. 15453 images/sec.	O	O	Reply	20283
[line_break_token][line_break_token]2) As for "In Figure 2 all methods seem to have similar final performance.".	B-Reply	B-2	Reply	20283
Our main goal is not to improve final accuracy but rather to train less steps than the vanilla training regime.	I-Reply	I-2	Reply	20283
For that purpose, we introduced the early LR drop regime (as seen in Figure 5).	I-Reply	I-2	Reply	20283
We presented the plots in Figure 2 in order to show the relatively large deviation in the validation error as well as the training error.	I-Reply	I-2	Reply	20283
The validation error decrease using our MMS method implies a faster convergence and that a faster regime can be used.	I-Reply	I-2	Reply	20283
We further accept the comment and will move these plots to the appendix as well as mention their purpose in the paper.	I-Reply	I-2	Reply	20283
[line_break_token][line_break_token]3) As for cutting CIFAR100 validation error for the early LR drop regime.	B-Reply	B-3	Reply	20283
We decided to end this experiment when the error reaches a sufficient performance w.r.t the baseline training (red).	I-Reply	I-3	Reply	20283
Moreover, we explicitly stated the final accuracy of the baseline and our MMS method in Table 1, showing a drop of 0.07% with almost halving the baseline required steps (from 156K to 80K steps).	I-Reply	I-3	Reply	20283
[line_break_token][line_break_token]4) We kindly accept your comment regarding the entropy experiment and will include it with the other methods plot.	B-Reply	B-4	Reply	20283
[line_break_token][line_break_token]5) We couldn't run many experiments due to time limitations, but we will make the effort to add STD bars.	B-Reply	B-6	Reply	20283
[line_break_token]6) We will expand Table 1 as suggested with the entropy experiment and will add more relevant step information for clarity.	B-Reply	B-7	Reply	20283
[line_break_token]7) We will add the ImageNet experiment.	B-Reply	B-8	Reply	20283

The authors extend recent work in equivariant set encoding to the setting of entity-relation data.	O	O	Review	10055
 Similar to the cited previous work, they encode sets of objects (in this case the tuples of a relational database) with a permutation invariant function.	O	O	Review	10055
They use a parameter tieing scheme to enforce this invariance.	O	O	Review	10055
[line_break_token][line_break_token]I don‚Äôt find the paper to be particularly well motivated.	B-Review	B-1	Review	10055
Relational DBs are not necessarily a setting where you would always want equivariance.	I-Review	I-1	Review	10055
While the ordering of tuples do not matter, relations are often asymmetrical.	I-Review	I-1	Review	10055
Further, the idea of concatenating all tuples of a relational DB to be passed through a particular feed forward layer is infeasible for all but the smallest datasets.	B-Review	B-2	Review	10055
Real world databases such as knowledge bases contains millions to billions of entries.	I-Review	I-2	Review	10055
Scaling issues aside, the experiments do not actually show that this method outperforms any reasonable baselines such as a simple tensor factorization.	B-Review	B-3	Review	10055
[line_break_token][line_break_token]I also found it particularly hard to follow the descriptions of the methods.	B-Review	B-4	Review	10055
A few specific points:[line_break_token]- The text and notation in the beginning of section 2 could be a lot clearer.	I-Review	I-4	Review	10055
I had to read these paragraphs multiple times to pick out precisely what you were trying to say.	I-Review	I-4	Review	10055
Maybe have the set of relations be [R] like your other sets rather than a different script R. [line_break_token]- In the next paragraph you say ‚ÄúA particular relation R is a multiset if it contains multiple copies of the same entity‚Äù but you previously defined R to be a set of instances and not entities.	B-Review	B-5	Review	10055
I think you need to be more consistent with your terminology since the differences between type level entities and instances is important for your definitions and as you noted in your first footnote, these terms are often used very differently.	I-Review	I-5	Review	10055
[line_break_token]- This explanation could be helped a lot by improving the figure.	B-Review	B-6	Review	10055
The caption and images are both very dense but still requires a lot of coreference.	I-Review	I-6	Review	10055
For example, labeling the entities and relations with their ids in figure 1a directly would make it much easier to mentally map to what you are explaining in the caption.	I-Review	I-6	Review	10055
Also figure 1c is not at all clear.	I-Review	I-6	Review	10055
[line_break_token][line_break_token]Lastly, the methodology seems quite incremental over the previous work.	O	O	Review	10055
A lot of the context and background that was sent to the appendix should be included in the main paper, particularly the relation to related work[line_break_token][line_break_token][line_break_token]edits:[line_break_token]double ‚Äòthe‚Äô in abstract ‚Äúlinear complexity in the the data ‚Äú	O	O	Review	10055
hank you for your review.	O	O	Reply	10055
[line_break_token][line_break_token]REVIEW: "I don‚Äôt find the paper to be particularly well motivated.	O	O	Reply	10055
Relational DBs are not necessarily a setting where you would always want equivariance.	O	O	Reply	10055
While the ordering of tuples do not matter, relations are often asymmetrical."	O	O	Reply	10055
[line_break_token][line_break_token]RESPONSE: The notion of ‚Äúasymmetry‚Äù of relations raised in the review is unclear to us.	B-Reply	B-1	Reply	10055
If for example, you mean ‚Äústudent-course‚Äù relation is different from ‚Äúcourse-student‚Äù relation, then we agree.	I-Reply	I-1	Reply	10055
However, we do not understand your concern.	I-Reply	I-1	Reply	10055
Could you please elaborate?	I-Reply	I-1	Reply	10055
[line_break_token][line_break_token]REVIEW: "Further, the idea of concatenating all tuples of a relational DB to be passed through a particular feed forward layer is infeasible for all but the smallest datasets.	O	O	Reply	10055
Real world databases such as knowledge bases contains millions to billions of entries.	O	O	Reply	10055
 "[line_break_token][line_break_token]RESPONSE: Practicality is an important point that we also address in the paper.	B-Reply	B-2	Reply	10055
The model produced here does not perform any subsampling of the database, which is essential for its application to large datasets.	I-Reply	I-2	Reply	10055
We have seen successful examples of subsampling for graphs, and matrices recently.	I-Reply	I-2	Reply	10055
In the case of a relational database, subsampling is more involved, as one has to deal with variable amounts of sparsity across different relations (tables).	I-Reply	I-2	Reply	10055
This is left for future work.	I-Reply	I-2	Reply	10055
[line_break_token][line_break_token]REVIEW: "Scaling issues aside, the experiments do not actually show that this method outperforms any reasonable baselines such as a simple tensor factorization."	O	O	Reply	10055
[line_break_token][line_break_token]RESPONSE: We could not use tensor-factorization as a baseline in our experiments.	B-Reply	B-3	Reply	10055
Tensor factorization applies to settings where we have a single relation ‚Äî for example, a user-move relation, or user-item-tag relation.	I-Reply	I-3	Reply	10055
This is the setting studied by Hartford et al‚Äô18.	I-Reply	I-3	Reply	10055
Since we show that our model reduces to their model in this setting, comparison to tensor factorization would amount to reproducing their results.	I-Reply	I-3	Reply	10055
To use the language of tensor factorization in our setup: we have multiple tensors that share some dimensions and need to be jointly factorized.	I-Reply	I-3	Reply	10055
We do not know of any factorization method for this task.	I-Reply	I-3	Reply	10055
[line_break_token][line_break_token][line_break_token]REVIEW: "- The text and notation in the beginning of section 2..."[line_break_token][line_break_token]RESPONSE: Based on your feedback we will try to make this part more clear (note that Using [R] for the set of relations would be misleading as the notation [X] is often used when X is ordinal or has an ordinal index, while in our paper, R is defined to be a set.)	B-Reply	B-4	Reply	10055
[line_break_token][line_break_token]REVIEW: "In the next paragraph you say ‚ÄúA particular relation R is a multiset if it contains multiple copies of the same entity‚Äù but you previously defined R to be a set of instances and not entities.	O	O	Reply	10055
I think you need to be more consistent with your terminology..."[line_break_token][line_break_token]RESPONSE: We never defined R as a set of instances (could you please identify lines that misled you?	B-Reply	B-5	Reply	10055
Since this is basic notation used throughout the paper, it is important we fix any ambiguity.)	I-Reply	I-5	Reply	10055

In this paper the authors solve for the task of Raven Progressive Matrices (RPM) reasoning.	O	O	Review	583
They do so by considering multiplexed graph networks.	O	O	Review	583
They present an architecture for the same.	O	O	Review	583
The basic premise is a combination of object level representation that is obtained by a method similar to region proposal and combining them with graph network.	O	O	Review	583
The approach uses gated graph networks that also uses an aggregation function.	O	O	Review	583
These are combined and result in node embeddings.	O	O	Review	583
Detailed analysis of the network is provided.	O	O	Review	583
This provides improved results over earlier WREN method.	O	O	Review	583
However, the performance is slightly lesser than another paper simultaneously submitted that achieves similar results.	B-Review	B-3	Review	583
That approach uses transformer network for spatial attention while here the spatial attention is just based on object level representation.	I-Review	I-3	Review	583
[line_break_token][line_break_token]Over all while the contribution is useful, not much analysis is provided on the interpretability of the results.	B-Review	B-1	Review	583
For instance, the statistics in terms of the search space reduction as to how many subsets get pruned.	I-Review	I-1	Review	583
Further, there may be subsets of graphs that could span across rows and columns.	B-Review	B-2	Review	583
The decision in terms of restricting the reduction to span specific rows or columns may result in pertinent nodes also being pruned.	I-Review	I-2	Review	583
Certain aspects that relate to object level representation are not very clear.	I-Review	I-2	Review	583
I am not fully aware about results in this specific area and that may also be a reason for the same.	I-Review	I-2	Review	583
[line_break_token][line_break_token]To conclude, I believe this paper provides a useful contribution by modeling the diagrammatic abstract reasoning as a graph based reasoning approach.	O	O	Review	583
The multiplex graph network could be a useful component that is also relevant for other problems.	O	O	Review	583
The paper provides sufficient analysis to convince us regarding the claims.	O	O	Review	583
hank you for your valuable comments.	O	O	Reply	583
In our revised version, we improved explanations of our models with more details.	O	O	Reply	583
Here we address some of your concerns:[line_break_token][line_break_token]1. "	O	O	Reply	583
the statistics in terms of the search space reduction as to how many subsets get pruned":[line_break_token]We have added more statistics of the search space reduction experiments in Appendix D, such as the top-16 subsets with the highest gating values.	B-Reply	B-1	Reply	583
[line_break_token][line_break_token]2.	O	O	Reply	583
Further, there may be subsets of graphs that could span across rows and columns.	O	O	Reply	583
The decision in terms of restricting the reduction to span specific rows or columns may result in pertinent nodes also being pruned:[line_break_token][line_break_token]The subsets are not constrained to rows and columns.	B-Reply	B-2	Reply	583
During search space reduction we only make the weak assumption that edges in the same subset must be adjacent (defined as two edges linking the same node).	I-Reply	I-2	Reply	583
This allows for subsets other than rows and columns, such as diagonal of the matrix.	I-Reply	I-2	Reply	583
The search space reduction experiments however give lower scores for subsets other than rows and columns.	I-Reply	I-2	Reply	583
This is why we hard-gate only row and columns subsets in the final architecture.	I-Reply	I-2	Reply	583
We explained this more clearly in the revised version.	I-Reply	I-2	Reply	583
[line_break_token][line_break_token]3. "	O	O	Reply	583
However, the performance is slightly lesser than another paper simultaneously submitted that achieves similar results.	O	O	Reply	583
That approach uses transformer network for spatial attention while here the spatial attention is just based on object level representation":[line_break_token][line_break_token]We have just noted this parallel submission and compared it with our results.	B-Reply	B-3	Reply	583
We found that our model performs better for PGM dataset(89.6% against 88.2% in neutral split with beta=10).	I-Reply	I-3	Reply	583
In their response to comments, they stated that their model achieved performance of 19.67% for RAVEN-10000, which is the public dataset we used in the experiments.	I-Reply	I-3	Reply	583
We achieved 83.91% accuracy.	I-Reply	I-3	Reply	583
They did not make it clear how did they obtain 50k samples for each figure configuration, but our guess is that they used the open-source code to generate more data than available in RAVEN-10000	I-Reply	I-3	Reply	583

This paper proposed to use the duality gap sup_f V(f, g*) ‚Äì inf_g V(f*, g) as a metric for GAN training.	O	O	Review	20630
It proves that this metric is an upper bound of F-distance.	O	O	Review	20630
It also proves a generalization bound for this metric.	O	O	Review	20630
Simulation resultson MNIST, CIFAR10, etc.	O	O	Review	20630
are reported.	O	O	Review	20630
[line_break_token][line_break_token]  The contribution of this paper is incremental due to the following reasons.	O	O	Review	20630
[line_break_token][line_break_token] 1) The duality gap is only an upper bound of the F-distance.	B-Review	B-1	Review	20630
This means that if the duality gap is zero then the learned distribution is the true distribution.	I-Review	I-1	Review	20630
However, the converse is not necessarily true: even if the algorithm starts with the true distribution, the duality gap may not be zero.	I-Review	I-1	Review	20630
Thus the metric is not a proper metric.	I-Review	I-1	Review	20630
[line_break_token]  The proof of the upper bound is straightforward.	I-Review	I-1	Review	20630
[line_break_token][line_break_token]  2) Another issue is the gap between the min-max formulation and the real training algorithm.	B-Review	B-2	Review	20630
As for GAN, due to the inexact update, it is not really solving the min-max problem.	I-Review	I-2	Review	20630
For the proposed metric, it is also impossible to solve sup_f V(f, g*) and inf_g V(f*, g) to reasonable accuracy.	I-Review	I-2	Review	20630
Thus what the algorithm is really doing, perhaps, is to optimizing a new loss which is the sum of the original loss and and an extra term.	I-Review	I-2	Review	20630
Viewing it as a ‚Äúduality gap‚Äù seems to be far from the practical training.	I-Review	I-2	Review	20630
This discrepancy exists for GANs, but it is a bigger issue for the duality gap interpretation.	I-Review	I-2	Review	20630
[line_break_token][line_break_token]  3) The simulation is not convincing.	B-Review	B-3	Review	20630
The reported FID for CIFAR10 using WGAN-GP is 54.4, which seems to be a bit high.	I-Review	I-3	Review	20630
I‚Äôm not sure whether it is due to parameter choice or due to weak D/G networks used in the simulation.	I-Review	I-3	Review	20630
If the paper cannot compare various architecture, it is more convincing to at least use some standard architecture, like DCGAN.	I-Review	I-3	Review	20630
Or at least report the parameter tuning effort made for getting the results.	I-Review	I-3	Review	20630
hanks for your attention to our work.	O	O	Reply	20630
[line_break_token]1) For the first problem that the duality gap is only an upper bound of F-distance.	B-Reply	B-1	Reply	20630
Our logic is that: a) There exists a condition s.t.	I-Reply	I-1	Reply	20630
duality gap = 0.	I-Reply	I-1	Reply	20630
b) If duality gap = 0, then the generator is the best one that can generate the true distribution.	I-Reply	I-1	Reply	20630
May be in the algorithm, we will miss the best generator because we do not get the equilibrium.	I-Reply	I-1	Reply	20630
[line_break_token][line_break_token]2) Our method may encounter the same problem as the traditional algorithm.	B-Reply	B-2	Reply	20630
It is a kind of Markov chain to train the Loss.	I-Reply	I-2	Reply	20630
And the essence of the algorithm is in fact to solve and.	I-Reply	I-2	Reply	20630
We should consider some better algorithm to solve it.	I-Reply	I-2	Reply	20630
[line_break_token][line_break_token]3) For the experiments, we will do some modification and improve our network.	B-Reply	B-3	Reply	20630

1) Summary[line_break_token]This paper presents a graph neural network based architecture that is trained to locate and model the interactions of agents in an environment directly from pixels.	O	O	Review	521
They propose an architecture that is a composition of recurrent neural networks where each models a single object independently and communicate with other for the overall environment modeling.	O	O	Review	521
The model is trained with a variational recurrent neural network objective that allows for stochasticity in the predictions while at the same time allows to model the current and future steps simultaneously.	O	O	Review	521
In experiments, they show the advantage of using the proposed model for tasks of tracking as well as forecasting of agents locations.	O	O	Review	521
[line_break_token][line_break_token][line_break_token][line_break_token]2) Pros:[line_break_token]+ Novel recurrent neural network architecture to model structured dynamics of agents in an environment.	O	O	Review	521
[line_break_token]+ Outperforms baseline methods.	O	O	Review	521
[line_break_token]+ New dataset for partially observable prediction research.	O	O	Review	521
[line_break_token][line_break_token]3) Cons:[line_break_token][line_break_token]Forecasting task:[line_break_token]- The authors argue that a discretization needs to be performed because of the many possible futures given the past, and also provide an error measure based on likelihood.	B-Review	B-1	Review	521
However, if trajectories are actually generated from these distributions, I suspect the many possible futures generated will be very shaky.	I-Review	I-1	Review	521
Can the authors provide trajectories sampled from this?	I-Review	I-1	Review	521
If sampling trajectories does not make sense somehow, can the authors comment on how we can sample multiple trajectories?	I-Review	I-1	Review	521
[line_break_token][line_break_token]Lack of baselines:[line_break_token]- The authors mention social LSTM and social GAN in the related work, however, no comparison is provided.	B-Review	B-2	Review	521
From a quick glance, the authors of these papers work on trajectories.	I-Review	I-2	Review	521
However, the ‚Äúsocial‚Äù principle in those papers is general since it‚Äôs done from the computed feature vector.	I-Review	I-2	Review	521
Could it have not been used on top of one of the baselines?	I-Review	I-2	Review	521
If not, could the authors provide a reason why this is not the case?	I-Review	I-2	Review	521
[line_break_token][line_break_token][line_break_token]Additional comments:[line_break_token]As the authors mention, it would be nice to extend this paper to an unsupervised or semi-supervised task.	B-Review	B-3	Review	521
Here are a couple of papers that may interest you:[line_break_token]<a href="https://arxiv.org/abs/1804.04412" target="_blank" rel="nofollow">https://arxiv.org/abs/1804.04412</a>[line_break_token]<a href="https://arxiv.org/abs/1705.02193" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.02193</a>[line_break_token]<a href="https://arxiv.org/abs/1806.07823" target="_blank" rel="nofollow">https://arxiv.org/abs/1806.07823</a>[line_break_token][line_break_token]4) Conclusion[line_break_token]Overall, the paper is well written, easy to understand, and seems to be simple enough to quickly reproduce.	B-Review	B-4	Review	521
Additionally, the proposed dataset may be of use for the community.	I-Review	I-4	Review	521
If the authors are able to successfully address the issues mentioned, I am willing to improve my score.	I-Review	I-4	Review	521
We appreciate your constructive feedback, and very useful references!	O	O	Reply	521
[line_break_token][line_break_token](1) Forecasting task:[line_break_token]We provide the sampled trajectories in Figure 5 and Appendix.	B-Reply	B-1	Reply	521
In particular, Figure 5(a) and Figure A2 show the multiple samples generated by Graph-VRNN.	I-Reply	I-1	Reply	521
We observe the trajectories are relatively stable.	I-Reply	I-1	Reply	521
For soccer data, since the perception task is more challenging and many players are not observed, we find the belief states to be uncertain for the first several steps (having more observed steps would help in this case).	I-Reply	I-1	Reply	521
For basketball data, we find that the belief states for players are usually stable, but the ball is more uncertain (bottom right row of Figure 4).	I-Reply	I-1	Reply	521
We suspect that it‚Äôs due to the movement of ball is much faster (which may be addressed by using a higher FPS).	I-Reply	I-1	Reply	521
[line_break_token][line_break_token](2) Lack of baselines:[line_break_token]As pointed out by the reviewer, Social-LSTM and Social-GAN work with trajectory data by default.	B-Reply	B-2	Reply	521
However, their social-pooling mechanism can be used as an alternative to the relation network used in Graph-RNN.	I-Reply	I-2	Reply	521
We use the pooling mechanism from Social-GAN, which is more recent and has no additional hyper parameters.	I-Reply	I-2	Reply	521
We find it to perform slightly worse than Graph-RNN (which uses Relation Networks), but better than Indep-RNN.	I-Reply	I-2	Reply	521
Note that the graph network module is a building block in our model, and RN can be replaced by other graph network architectures	I-Reply	I-2	Reply	521

The authors use a Gaussian-binary deep Boltzmann machine (GDBM) to model aspects of visual cortex.	O	O	Review	62
Training of the GDBM involves the centering trick of [8]. The comparison to visual cortex is in terms of learned receptive field properties, and by reproducing experimentally observed properties of activity in V1 as reported by [1]. In particular, these findings relate spontaneous activity in the absence of external stimulation to evoked activity.	O	O	Review	62
[line_break_token][line_break_token]On the positive side, I think the issue of the nature of spontaneous activity is interesting, and the authors put effort into reproducing the experimental findings of [1]. On the negative side, the significance of the main contributions seems lacking to me, and the authors need to motivate better why their work is important or relevant.	O	O	Review	62
Quality and clarity need to be improved in several points as well.	O	O	Review	62
[line_break_token][line_break_token][line_break_token]Details:[line_break_token][line_break_token]To expand on the above, I'll discuss three main points: 1) The centered GDBM.	O	O	Review	62
2) Reproducing aspects of visual cortex.	O	O	Review	62
3) The connection to homeostasis.	O	O	Review	62
[line_break_token][line_break_token]1) I wouldn't see this part as a major contribution of the paper.	B-Review	B-1	Review	62
The centering trick was originally applied to a fully binary DBM.	I-Review	I-1	Review	62
Applying the same trick to the GDBM (which only differs in having a Gaussian visible layer) seems a very natural thing to do.	I-Review	I-1	Review	62
Moreover, there is no further analysis on the efficacy of the centering trick.	I-Review	I-1	Review	62
The authors say that centering makes the GDBM easy to train compared to [15], but they don't actually evaluate the performance of the GDBM (other than comparing it to biological phenomenology), and only apply it to image patches.	I-Review	I-1	Review	62
In [15], the GDBM was trained on images of faces and evaluated in terms of filling in missing parts of the image.	I-Review	I-1	Review	62
Hence, it is not clear whether centering makes the more complicated training of [15] obsolete, as suggested by the authors.	I-Review	I-1	Review	62
[line_break_token][line_break_token]Also, when it comes to clarity: given that the authors emphasize the importance of centering, they need to better explain what it is, why it works, and how the centering parameters are computed (the latter is only described in the algorithm float).	I-Review	I-1	Review	62
These things are unclear to the reader unless they look at the reference.	I-Review	I-1	Review	62
[line_break_token][line_break_token][line_break_token]2) Reproducing aspects of visual cortex is the main contribution of the paper.	B-Review	B-2	Review	62
First, the learned receptive fields are suggested to qualitatively resemble those in V1 and V2.	I-Review	I-2	Review	62
Learning V1-like Gabor filters is of course a quite common result nowadays.	I-Review	I-2	Review	62
I don't think it's possible to conclude that the model captures receptive field properties V2 well, just from looking at Figure 1b.	I-Review	I-2	Review	62
[line_break_token][line_break_token]Hence, the main contribution here is the analysis of activity.	O	O	Review	62
I think the results are fine and somewhat interesting, though not surprising.	O	O	Review	62
What is missing is better motivating/explaining why these results are interesting/relevant.	B-Review	B-3	Review	62
Sure, the GDBM reproduces certain experimental findings.	I-Review	I-3	Review	62
But have we learned something new about the brain?	I-Review	I-3	Review	62
Is the GDBM particularly well suited as a general model of visual cortex?	I-Review	I-3	Review	62
Does the model make predictions?	I-Review	I-3	Review	62
What about alternative, perhaps simpler models that could have been used instead?	I-Review	I-3	Review	62
Etc.	I-Review	I-3	Review	62
[line_break_token][line_break_token]Also, are there related models or theoretical approaches to spontaneous activity?	I-Review	I-3	Review	62
For example, this comes to mind:[line_break_token][line_break_token]Berkes, P., Orb√°n, G., Lengyel, M., & Fiser, J. (2011).	O	O	Review	62
Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment.	O	O	Review	62
Science (New York, N.Y.), 331(6013), 83‚Äì7.	O	O	Review	62
doi:10.1126/science.1195870[line_break_token][line_break_token]As for clarity: when collecting the spontaneous frames, presumably you are sampling from the full model distribution P(x,y,z) via Gibbs-sampling, with all layers unclamped, correct?	B-Review	B-4	Review	62
Because writing that samples were collected from P(y|x,z) seems to suggest that you clamp to a specific x and z and collect multiple samples from the same conditional (not just as a step during Gibbs sampling).	O	O	Review	62
[line_break_token][line_break_token][line_break_token]3) Lastly, the connection between homeostasis and the author's model is unclear.	B-Review	B-5	Review	62
The authors mention homeostasis in the abstract, introduction and discussion, but do not explain homeostasis or how their results relate to it specifically.	O	O	Review	62
This needs to be explained better, especially to this audience.	O	O	Review	62
Personally, I know the literature somewhat (e.g. [4]), but am nevertheless unclear about what exactly the authors intend to say.	O	O	Review	62
[line_break_token]Sentences such as 'we are able to make the model learn the homeostasis from natural image patches' are unclear.	O	O	Review	62
[line_break_token][line_break_token]When I first read the paper, I thought the authors were referring to the centering trick as something that can be understood as a homeostatic mechanism (i.e., a neuronal mechanism that maintains a certain average firing rate, see [4], [6,7]), which would make sense to me.	B-Review	B-5	Review	62
However, on further reading it seems to me that the authors refer to the fact that spontaneous activity resembles evoked activity as an aspect of homeostasis?	I-Review	I-5	Review	62
Why?	I-Review	I-5	Review	62
For comparison, [6,7] clamped the input to empty images (to simulate blindness), and had an active homeostatic mechanism at play that led to spontaneous activity resembling evoked activity.	I-Review	I-5	Review	62
In the authors' paper, spontaneous activity resembles evoked activity simply because the former is taken to be sampled from the unconditioned model distribution..?	I-Review	I-5	Review	62
I'm not sure where homeostasis, i.e. being subject to an active self-regularity mechanism, comes into play at this point.	I-Review	I-5	Review	62
[line_break_token][line_break_token](As an aside, I don't think the Friston reference [3] clears up what the authors' notion of homeostasis is, in particular as Friston talks about states of agents in their environments.	I-Review	I-5	Review	62
Frankly, Friston's theoretical claims are often unclear to me, to say the least, in particular when it comes to mixing together internal models in the brain, and methods that should apply to the latter such as variational inference, and external probabilistic descriptions of agents and environments.	I-Review	I-5	Review	62
Either way, if the authors would like to make a connection to Friston's theories in particular, then that connection should be explained better.	I-Review	I-5	Review	62
Generative/predictive brain models and homeostatic mechanisms per se are not exclusive to Friston's theory.)	I-Review	I-5	Review	62
[line_break_token][line_break_token][line_break_token]Further comments:[line_break_token][line_break_token]* Abstract, 'Spontaneous cortical activity [...] are' -> is[line_break_token][line_break_token]* 2.1 first para, 'consisted' -> consisting[line_break_token][line_break_token]* Not sure why x,y,z are sometimes capitalized, sometimes not.	B-Review	B-7	Review	62
[line_break_token][line_break_token]* 3.1 'sparse DBNs show worse match to the biological findings as reported in [1]. A quantitative comparison between centered GDBMs and sparse DBNs is still open for future studies.'	B-Review	B-6	Review	62
Where was it shown to be a worse match then?	I-Review	I-6	Review	62
[line_break_token][line_break_token]* Figure 2: shouldn't the angles (figure titles) go from 0 to 180?	B-Review	B-8	Review	62
[line_break_token][line_break_token][line_break_token]In conclusion, I think this work could potentially be interesting, but in its current form quality and clarity are somewhat lacking and significance is not quite clear.	O	O	Review	62
Thanks for your helpful comments.	O	O	Reply	62
[line_break_token]1) ‚ÄúThe centered GDBM.‚Äù[line_break_token][line_break_token]Clarified applying centering to Gaussian DBM is an extension of the previous work in [8]. The point we want to make here is that GDBM with centering can be trained without the pre-training procedure as described in [3]. In comparison, we followed the same setting in [3] with centered GDBM.	B-Reply	B-1	Reply	62
The reconstruction error here is 41.6 +/- 0.40 compared to the results of about 40 in [3]. We agree that the minor differences are not sufficient to claim the advantages of centered GDBMs over the non-centered version. (	I-Reply	I-1	Reply	62
This is also why we did not include this result in the previous version.)	I-Reply	I-1	Reply	62
Importantly however, as shown in [8], centering leads to improved conditions.	I-Reply	I-1	Reply	62
In our paper, we show that hidden units in both layers of the centered GDBM can learn meaningful features.	I-Reply	I-1	Reply	62
Thus, our present results also show empirically that the centering helps to overcome the commonly observed difficulties during training of GDBMs.	I-Reply	I-1	Reply	62
[line_break_token] [line_break_token]We have added more details about the centering in the revised version.	I-Reply	I-1	Reply	62
Because the main focus of this paper is to illustrate the capacity of GDBM in modeling spontaneous cortical activity, we did not include further analyses of the centering specifically for GDBMs.	I-Reply	I-1	Reply	62
[line_break_token][line_break_token]2) ‚ÄúReproducing aspects of visual cortex‚Äù[line_break_token]2.1) ‚ÄúI don't think it's possible to conclude that the model captures receptive field properties V2 well, just from looking at Figure 1b.	O	O	Reply	62
‚Äù[line_break_token][line_break_token]Done - We removed the statement suggesting that the model captures receptive field properties in V2.	B-Reply	B-2	Reply	62
See more details in the responses to the common comments B).	I-Reply	I-2	Reply	62
[line_break_token][line_break_token]2.2) ‚ÄúWhat is missing is better motivating/explaining why these results are interesting/relevant. ‚	O	O	Reply	62
Ä¶. have we learned something new about the brain?	O	O	Reply	62
Is the GDBM particularly well suited as a general model of visual cortex?	O	O	Reply	62
Does the model make predictions?	O	O	Reply	62
What about alternative, perhaps simpler models that could have been used instead?	O	O	Reply	62
Etc.	O	O	Reply	62
Also, are there related models or theoretical approaches to spontaneous activity?‚Äù[line_break_token][line_break_token]We mainly demonstrate that the GDBM is a meaningful model approach for basic receptive field properties and the emergence of spontaneous activity patterns in early cortical visual areas.	B-Reply	B-3	Reply	62
Compared to other models for modeling spontaneous cortical activity, GDBMs (or DBMs in general) are not limited to simple, low-dimensional, non-hierarchical variables [7], but extend to generative, hierarchical-structured models with an unsupervised learning fashion.	I-Reply	I-3	Reply	62
[line_break_token][line_break_token]Moreover, by reproducing the findings in [1] with centered GDBMs, we suggest that i) the spontaneous activity in early visual cortex are the result of interactions between sensory inputs and feedbacks from higher areas, ii) thus, early visual areas are sufficient to generate the observed spontaneous activity patterns.	I-Reply	I-3	Reply	62
[line_break_token][line_break_token]Together with the discussion of the failures to model the cortical activity with GRBMs and DBN (see details in the responses to the common comments E)), we have a new paragraph in the discussion to describe the interpretations of our results.	O	O	Reply	62
[line_break_token][line_break_token]2.3) ‚Äúwhen collecting the spontaneous frames, presumably you are sampling from the full model distribution P(x,y,z) via Gibbs-sampling, with all layers unclamped, correct?‚Äù[line_break_token][line_break_token]Clarified - During collecting the spontaneous frames, we indeed ran sampling from the full model distribution P(X, Y, Z) via Gibbs-sampling with all layers unclamped.	B-Reply	B-4	Reply	62
This sampling procedure is supposed to approximate the samples from the model‚Äôs prior distribution P(Y), which are the expected states of the Y without any knowledge of X and Z. And we use P(Y|x, z) from a single step during Gibbs sampling as an approximation of Y, which is referred as to a spontaneous frame.	I-Reply	I-4	Reply	62
 We added more details of the samplings procedure in section 3.2.1 and 3.2.2.	I-Reply	I-4	Reply	62
See more details in the responses to common comments C).	I-Reply	I-4	Reply	62
[line_break_token][line_break_token]3) ‚Äúthe connection between homeostasis and the author's model is unclear.	O	O	Reply	62
‚Äù[line_break_token][line_break_token]Removed the term ‚Äúhomeostasis‚Äù to avoid misunderstanding.	B-Reply	B-5	Reply	62
See more details in the responses to common comments D).	I-Reply	I-5	Reply	62
[line_break_token][line_break_token]4) ‚Äú3.1 'sparse DBNs show worse match to the biological findings as reported in [1]. A quantitative comparison between centered GDBMs and sparse DBNs is still open for future studies.'	O	O	Reply	62
Where was it shown to be a worse match then?‚Äù[line_break_token][line_break_token]We have attempted to use the (sparse) DBN to model the cortical activity.	B-Reply	B-6	Reply	62
But the results show worse match to the biological results in [1] as the spontaneous frames show less correlation to the orientation maps.	I-Reply	I-6	Reply	62
Both the comparison of results and the interpretation have been included in the revised discussion part.	I-Reply	I-6	Reply	62
See more details in the responses to common comments E).	I-Reply	I-6	Reply	62
[line_break_token][line_break_token]5)[line_break_token]* ‚ÄúNot sure why x,y,z are sometimes capitalized, sometimes not.	O	O	Reply	62
‚Äù[line_break_token][line_break_token]We use the upper case letters to denote the un-instantiated variables, i.e. the values of variables are not given.	B-Reply	B-7	Reply	62
In contrast, the lower case letters represent the instantiated variables.	O	O	Reply	62
[line_break_token][line_break_token]* ‚ÄúFigure 2: shouldn't the angles (figure titles) go from 0 to 180?‚Äù[line_break_token][line_break_token]Figure 2: Done ‚Äì Thanks for the hint, typo corrected.	B-Reply	B-8	Reply	62
The angles should go from 0 to 180	I-Reply	I-8	Reply	62

This paper studies the problem of identifying (discovering) synonymous entities.	O	O	Review	900
The paper proposes using the "contexts" of the entities as they occur in associated text corpora (e.g. Wiki) in the proposed neural-network based embedding approach for this task.	O	O	Review	900
The key novelties of the approach lie in the "matching" system used, where contexts of one entity are matched with that for the other entity to see how well they align with each other (which effectively determines the similarity of the two entities).	O	O	Review	900
Experiments are conducted on three different datasets to show the efficacy of the proposed approach.	O	O	Review	900
[line_break_token][line_break_token]Overall I found the paper to be an interesting read with some nice ideas mixed in.	O	O	Review	900
However I also had some concerns which are highlighted later down below, which I believe if addressed would lead to a very strong work.	O	O	Review	900
[line_break_token][line_break_token]Quality: Above average[line_break_token][line_break_token]In general the method seems to work somewhat better than the baselines and the method does have a couple of interesting ideas.	O	O	Review	900
[line_break_token][line_break_token]Clarity: Average[line_break_token][line_break_token]I found a few key details to be missing and also felt the paper could have been better written.	B-Review	B-6	Review	900
[line_break_token][line_break_token]Originality: Average[line_break_token][line_break_token]The matching approach and use of the leaky units was interesting tidbits.	O	O	Review	900
Outside of that the work is largely about the application of such Siamese RNNs based networks to this specific problem. (	O	O	Review	900
The use of context of entities has already been looked at in previous works albeit in a slightly more limited manner)[line_break_token][line_break_token]Significance: Slightly below average[line_break_token][line_break_token]I am not entirely sold on the use of this approach for this problem given its complexity and unclear empirical gains vs more sophisticated baselines.	B-Review	B-7	Review	900
The matching aspect may have some use in other problems but nothing immediately jumps out as an obvious application.	I-Review	I-7	Review	900
[line_break_token][line_break_token]----[line_break_token][line_break_token]Strengths / Things I liked about the paper:[line_break_token][line_break_token]- In general the method is fairly intuitive and simple to follow which I liked.	O	O	Review	900
[line_break_token]- The matching approach was an interesting touch.	O	O	Review	900
[line_break_token]- Similarly for the "leaky" unit.	O	O	Review	900
[line_break_token]- Experiments conducted on multiple datasets.	O	O	Review	900
[line_break_token]- The results indicate improvements over the baselines considered on all the three datasets.	O	O	Review	900
[line_break_token][line_break_token]Weaknesses / Things that concerned me:[line_break_token][line_break_token]-  (W1) Slightly unfair baselines?	B-Review	B-1	Review	900
One of the first things that struck me in the experimental results was how competitive word2vec by itself was across all three datasets.	I-Review	I-1	Review	900
This made me wonder what would happen if we were to use a more powerful embedding approach say FastText, Elmo, Cove or the recently proposed BERT? (	I-Review	I-1	Review	900
The proposed method itself uses bidirectional LSTMs)[line_break_token][line_break_token]Furthermore all of them are equally capable of capturing the contexts as well.	I-Review	I-1	Review	900
An even more competitive (and fair) set of baselines could have taken the contexts as well and use their embeddings as well.	I-Review	I-1	Review	900
Currently the word2vec baseline is only using the embedding of the entity (text), whereas the proposed approach is also provided the different contexts at inference time.	I-Review	I-1	Review	900
The paper says using the semantic structure and the diverse contexts are weaknesses of approaches using the contexts, but I don't see any method that uses the context in an embedding manner -- say the Cove context vectors.	I-Review	I-1	Review	900
If the claim is that they won't add any additional value above what is already captured by the entity it would be good to empirically demonstrate this.	I-Review	I-1	Review	900
[line_break_token][line_break_token]- (W2) Significance testing: On the topic of experimentation, I was concerned that significance testing / error estimates weren't provided for the main emprical results.	B-Review	B-2	Review	900
The performance gaps seem to be quite small and to me it is unclear how significant these gaps are.	I-Review	I-2	Review	900
Given how important significance testing is as an empirical practice this seems like a notable oversight which I would urge the authors to address.	I-Review	I-2	Review	900
[line_break_token][line_break_token]- (W3) Missing key details: There were some key aspects of the work that I thought were not detailed.	B-Review	B-3	Review	900
Chief among these was the selection of the contexts for the entities.	I-Review	I-3	Review	900
How was this?	I-Review	I-3	Review	900
How were the 20 contexts identified?	I-Review	I-3	Review	900
Some of these entities are likely far more common than just 20 sentences and hence I wonder how these were selected?	I-Review	I-3	Review	900
[line_break_token][line_break_token]Another key aspect I did not see addressed: How were the entities identified in the text (to be able to find the contexts for them)?	I-Review	I-3	Review	900
The paper claims that they would like to learn from minimal human annotations but I don't understand how these entity annotations in the text were obtained.	I-Review	I-3	Review	900
This again seems like a notable oversight.	I-Review	I-3	Review	900
[line_break_token][line_break_token]- (W4) Concerns about the method: I had two major concerns about the method: [line_break_token][line_break_token](a) Complexity of method :  I don't see an analysis of the computational cost of the proposed method (which scales quadratically with P the number of contexts); [line_break_token][line_break_token](b) Effect of redundant "informative" contexts: Imagine you have a number of highly informative contexts for an entity but they are all very similar to each other.	B-Review	B-4	Review	900
Due to the way the matching scores are aggregated, these scores are made to sum to 1 and hence no individual score would be very high.	I-Review	I-4	Review	900
Given that this is the final coefficient for the associated context, this seems like a significant issue right?	I-Review	I-4	Review	900
[line_break_token][line_break_token]Unless the contexts are selected to be maximally diverse, it seems like this can essentially end up hurting an entity which occurs in similar contexts repeatedly.	I-Review	I-4	Review	900
I would like to see have seen the rationale for this better explained.	I-Review	I-4	Review	900
[line_break_token][line_break_token](c) A smaller concern was understanding the reasoning behind the different loss functions in the siamese loss function with a different loss for the positive and the negative, one using a margin and one which doesn't.	I-Review	I-4	Review	900
One which scales to 1/4, the other scaling to (1-m)^2.	I-Review	I-4	Review	900
This seems pretty arbitrary and I'd like to understand this.	I-Review	I-4	Review	900
[line_break_token][line_break_token]-(W5) Eval setting : My last concern was with the overall evaluation setup.	B-Review	B-5	Review	900
Knowledge bases like Freebase are optimized for precision rather than recall, which is why "discovery" of new relations is important.	I-Review	I-5	Review	900
However if you treat all missing relationships as negative examples then how exactly are you measuring the true ability of a method?	I-Review	I-5	Review	900
Thus overall I'm pretty skeptical about all the given numbers simply because we know the KBs are incomplete, but are penalizing methods that may potentially discover relations not in the KB.	I-Review	I-5	Review	900
We thank the reviewer for the thorough review and constructive feedback.	O	O	Reply	900
[line_break_token][line_break_token]We first would like to thank the reviewer for the positive feedback on our work.	O	O	Reply	900
[line_break_token][line_break_token]For the part that concerned the reviewer, we elaborate point by point as shown below:[line_break_token][line_break_token](W1) For the experiment setting, the proposed model can work with various word embeddings.	B-Reply	B-1	Reply	900
The contribution of our work does not lie in the choice of word embeddings, but the proposed architecture that utilizes entity representations for bilateral matching among multiple pieces of contexts.	I-Reply	I-1	Reply	900
Our model is independent of the choice of word embeddings, and we adopt Word2vec as a base case.	I-Reply	I-1	Reply	900
We aim to experiment the modeling ability of different model architectures given the same word representation information for synonym discovery.	I-Reply	I-1	Reply	900
With sophisticated word embedding methods such as Elmo or BERT, which achieve decent performances on various NLP tasks, we do expect that both baselines and our model will get better performance.	I-Reply	I-1	Reply	900
[line_break_token][line_break_token](W2) We‚Äôve added the significance testing in the experiment and update Table 2 with discussions.	B-Reply	B-2	Reply	900
A single-tailed t-test is performed to see whether or not the proposed model can outperform other baselines with significant improvements.	I-Reply	I-2	Reply	900
[line_break_token][line_break_token](W3) For the missing key details, the contexts are randomly selected from all contexts in which each entity is mentioned.	B-Reply	B-3	Reply	900
Due to limitations on computing resources, we are only able to verify the performance of up to 20 pieces of randomly chosen contexts in which each entity is mentioned.	I-Reply	I-3	Reply	900
For Wiki+Freebase and PubMed+UMLS, the datasets come with entity mentions annotated.	I-Reply	I-3	Reply	900
While in MedBook+MKG, we apply existing NER model [1] with contextualized embeddings [2] to obtain the annotated entities from the text.	I-Reply	I-3	Reply	900
We clarified the claim about the annotation: the proposed model does not require additional structured annotations on the free-text corpus, such as entity ontologies, dependency parsing results during training and inference.	I-Reply	I-3	Reply	900
The inference stage for synonym discovery is also designed to be data-driven so that we do not need pre-specified candidate entity pairs prepared by domain experts to be verified by the model, which further alleviates annotation efforts.	I-Reply	I-3	Reply	900
We added these details in the revised version	I-Reply	I-3	Reply	900

Summary of contributions: Studies the effect of # of parameters, # of layers, and # of units on convolutional net performance.	O	O	Review	86
Uses recurrence to run nets that have e.g. more layers but not more parameters in order to distinguish the effects of these three properties.	O	O	Review	86
[line_break_token][line_break_token]Novelty: moderate[line_break_token]Quality: low[line_break_token][line_break_token]Pros:[line_break_token][tab_token]-Nice empirical demonstration that more parameters helps.	O	O	Review	86
[line_break_token]Cons:[line_break_token][tab_token]-Does not study dropout.	B-Review	B-3	Review	86
I think dropout is really important for this kind of paper, because dropout has a strong effect on the optimal model size.	I-Review	I-3	Review	86
Also, dropout is crucial part of the state of the art system on both CIFAR-10 and SVHN, so it seems out of place for a paper on how to set hyperparameters to good performance out of a neural net to disregard one of the most important techniques for getting good performance.	I-Review	I-3	Review	86
[line_break_token][tab_token]-Insufficient tuning of hyperparameters.	B-Review	B-4	Review	86
[line_break_token][tab_token]-Support for the claims in the abstract seems weak, with many experiments going against the claims[line_break_token][tab_token]-The stated goal is to provide guidance for how to set hyperparameters so that practitioners don‚Äôt have to resort to trial and error.	B-Review	B-5	Review	86
But I don‚Äôt really see anything here that prevents that.	B-Review	B-6	Review	86
For example, Fig 4a shows standard U-shaped curves for the # of layers hyperparameter.	I-Review	I-6	Review	86
The paper says ‚Äúadding more layers tends to increase performance‚Äù but this is only true on the left side of the U!	I-Review	I-6	Review	86
The whole point of trial and error is to figure out where the bottom of the U is, and this paper completely ignores that.	I-Review	I-6	Review	86
[line_break_token][tab_token]-The kind of parameter tying considered in this paper is not one that is typically used in practice, at least not for this kind of problem.	B-Review	B-7	Review	86
The conclusions are therefore not all that helpful.	I-Review	I-7	Review	86
i.e., the authors introduce a new form of parameter tying, and then show it isn‚Äôt useful.	I-Review	I-7	Review	86
We don‚Äôt need to publish that conclusion, because no one is using this useless form of parameter tying anyway.	I-Review	I-7	Review	86
[line_break_token][tab_token]-The authors don‚Äôt investigate the effect of the tiling range of tiled convolution, which is a form of control on the degree of parameter sharing that people actually use.	B-Review	B-8	Review	86
It‚Äôd be much more interesting to study this form of parameter sharing. (	I-Review	I-8	Review	86
This paper feels a bit like it started off as a ‚Äúnew methods‚Äù paper advocating convolutional recurrence, and then when the new method didn‚Äôt perform well, the authors tried to salvage it as an ‚Äúempirical investigation‚Äù paper, but the empirical investigation part isn‚Äôt really targeted at the methods that would be most useful to study)[line_break_token][line_break_token]Detailed comments:[line_break_token][line_break_token]1.1 Related work:[line_break_token][line_break_token][tab_token]You should also mention ‚ÄúMulti-Prediction Deep Boltzmann Machines‚Äù, Goodfellow et al 2013.	B-Review	B-9	Review	86
This paper uses recurrent networks on the image datasets MNIST and NORB.	I-Review	I-9	Review	86
Like DrSAE, it is discriminative.	I-Review	I-9	Review	86
It may be interpreted as a form of autoencoder, like the methods you mention in the second paragraph.	I-Review	I-9	Review	86
[line_break_token][line_break_token][tab_token][line_break_token]2 Approach:[line_break_token][tab_token]Your approach is definitely not the first to use recurrence and convolution in the same model.	B-Review	B-10	Review	86
It‚Äôs probably worth discussing similarities and differences to Honglak Lee‚Äôs convolutional DBN.	I-Review	I-10	Review	86
He describes performing mean field inference in this model.	I-Review	I-10	Review	86
The mean field computations are essentially forward prop in a convolutional recurrent architecture, but the connectivity is different than in yours, since each update reads from two layers, and some of the weight matrices are constrained to be the transpose of each other rather than being constrained to be equal to each other.	I-Review	I-10	Review	86
[line_break_token][line_break_token][tab_token]It‚Äôs also probably worth discussing how you handle the boundaries of the image, since this has a strong effect on the performance of a convolutional net.	I-Review	I-10	Review	86
Since you say all the layers have the same size, I‚Äôm assuming you implicitly pad the hidden layer with zeros when running convolution so that the output of the discrete convolution operation has the same size as the input.	I-Review	I-10	Review	86
[line_break_token][line_break_token][tab_token][line_break_token]2.1 Instantiation on CIFAR-10 and SVHN[line_break_token][line_break_token][tab_token]I don‚Äôt know what it means to put the word ‚Äúsame‚Äù in quotes.	B-Review	B-11	Review	86
I‚Äôm assuming this refers to the zero padding that I described above, but it‚Äôs worth clarifying.	I-Review	I-11	Review	86
[line_break_token][line_break_token]2.2[line_break_token][tab_token]I think it‚Äôs fairly disappointing that you don‚Äôt train with dropout.	B-Review	B-12	Review	86
[line_break_token][tab_token]How did you choose this one fixed learning rate and momentum value?	I-Review	I-12	Review	86
How do you know it doesn‚Äôt bias the results?	I-Review	I-12	Review	86
For example, if you find that deeper models are better, are you really finding that deeper models are better in general, or are you just finding that deeper models are more compatible with this specific learning rate and momentum setting?	I-Review	I-12	Review	86
[line_break_token][tab_token]It seems especially important to tune the learning rate in this work because varying the amount of parameter sharing implies varying the number of gradient terms that affect each parameter.	I-Review	I-12	Review	86
The speed at which the parameters move is probably much higher for the nets with many recurrent steps than it is for the nets with no recurrence.	I-Review	I-12	Review	86
[line_break_token][line_break_token]3.1[line_break_token][tab_token]‚ÄúThat we were able to train networks at these large depths is due to the fact that we initialize all W to the identity‚Äù -> it‚Äôs not obvious to me that it should be hard to train convolutional rectifier networks at most of these depths.	O	O	Review	86
For example, Google‚Äôs house number transcription paper submitted to this conference at the same time trains a 12 layer mostly convolutional network with no mention of network depth posing a challenge or requiring special initialization.	B-Review	B-13	Review	86
The maxout paper reports difficulty training a 7 layer rectifier net on MNIST, but that was densely connected, not convolutional.	I-Review	I-13	Review	86
Was it only difficult to train the recurrent nets, or also the untied ones?	I-Review	I-13	Review	86
This is important to explain, since if the recurrent nets are significantly harder to optimize, that affects the interpretation of your results.	I-Review	I-13	Review	86
[line_break_token][tab_token]Are the higher layer weights for all of the networks initialized to the identity, or only the ones with tied parameters?	I-Review	I-13	Review	86
Is it literally identity or identity times some scalar?	I-Review	I-13	Review	86
If it‚Äôs literally identity rather than identity times some scalar, it might be too hard for SGD to shrink the initial weights and learn a different more interesting function.	I-Review	I-13	Review	86
Have you tried other initializations that don‚Äôt impose such a strong hand-designed constraint, such as James Martens‚Äô sparse initialization, where each hidden units gets exactly k randomly chosen non-zero incoming weights?	I-Review	I-13	Review	86
This initialization scheme is also described as making it easier to train deep or recurrent nets, and it seems to me like it doesn‚Äôt trap the recurrent layer as being a fairly useless memory layer that mostly functions to echo its input.	I-Review	I-13	Review	86
[line_break_token][line_break_token][tab_token]‚ÄúLikewise, for any given combination of feature maps and layers, the untied model outperforms the tied one, since it has more parameters.	I-Review	I-13	Review	86
‚Äù I don‚Äôt agree with the claim that the untied model performs better because it has more parameters.	I-Review	I-13	Review	86
This would make sense if the tied model was in the underfitting regime.	I-Review	I-13	Review	86
But you have already said in the same paragraph that many of the tied models are in the overfitting regime.	I-Review	I-13	Review	86
If you look at fig 2.	I-Review	I-13	Review	86
there are several points where both the tied and untied model have 0 training error and the tied model has higher validation set error.	I-Review	I-13	Review	86
If the correct story here is overfitting due to too many parameters, then the untied model should do worse.	I-Review	I-13	Review	86
I suspect what‚Äôs going on here is something like the identity initialization being a bad prior, so that you fit the training set in a way that doesn‚Äôt generalize well, or maybe just your choice of a single momentum and learning rate setting for all experiments ended up benefiting the untied model somehow.	I-Review	I-13	Review	86
For example, as I said above, the recurrent nets will generally have larger gradients on each parameter, so maybe the high learning rate makes the recurrent net adapt too much to the first few minibatches it sees.	I-Review	I-13	Review	86
[line_break_token][line_break_token][tab_token]Fig 2[line_break_token][tab_token][tab_token]In the abstract you say ‚Äúfor a given parameter budget, deeper models are preferred over shallow ones.	B-Review	B-14	Review	86
‚Äù It would be nice if on the plot on the left you evaluted points along the parameter budget contour lines instead of points on a grid, since the grid points don‚Äôt always hit the contour lines.	I-Review	I-14	Review	86
As is, it‚Äôs hard to evaluate the claim from the abstract.	I-Review	I-14	Review	86
However, I don‚Äôt see a lot of support for it.	I-Review	I-14	Review	86
The best test error you get is toward the bottom right: 0.160 at the rightmost point in the second row from the bottom.	I-Review	I-14	Review	86
Of course, this is the only point on that parameter budget contour, so it may just be winning because of its cost.	I-Review	I-14	Review	86
However, if I look for the point with the most depth, I see one with 0.240 near the 2^18 contour line.	I-Review	I-14	Review	86
At the bottom right of this contour line, the shallow but wide model gets 0.205.	I-Review	I-14	Review	86
[line_break_token][tab_token][tab_token]Overall, here is my summary of all your contour lines:[line_break_token][tab_token][tab_token][tab_token]2^16: only one point on it[line_break_token][tab_token][tab_token][tab_token]2^17: Contradicts claim[line_break_token][tab_token][tab_token][tab_token]2^18: Contradicts claim[line_break_token][tab_token][tab_token][tab_token]2^19: Contradicts claim[line_break_token][tab_token][tab_token][tab_token]2^20: Supports claim (sort of, points aren‚Äôt that close to contour line)[line_break_token][tab_token][tab_token][tab_token]2^21: Supports claim (sort of, points aren‚Äôt that close to contour line)[line_break_token][tab_token][tab_token][tab_token]2^22: Supports claim (sort of, points aren‚Äôt that close to contour line)[line_break_token][tab_token][tab_token]So it seems to me that this plot contradicts the claim from the abstract at least as much as it supports it.	I-Review	I-14	Review	86
[line_break_token][line_break_token][tab_token]Right figure:[line_break_token][tab_token][tab_token]This supports the claim in your abstract.	O	O	Review	86
[line_break_token][line_break_token][tab_token]Table 1: While it does make sense to compare *these* experiments against methods that don‚Äôt use dropout or data augmentation, I don‚Äôt think it makes sense for these to be your only experiments.	B-Review	B-15	Review	86
I think the case for excluding data augmentation from consideration is getting very weak.	I-Review	I-15	Review	86
There is now a lot of commercial interest in using neural nets on very large datasets.	I-Review	I-15	Review	86
Augmentation of small datasets provides a nice low-cost proxy for exploring this regime.	I-Review	I-15	Review	86
[line_break_token]As far as I know, the main reasons for not considering data augmentation are 1) data augmentation requires knowledge of the data domain, in this case that the input is an image and the output is invariant to shifts in the input.	I-Review	I-15	Review	86
But you are already exploiting exactly that same knowledge by using a convolutional net and spatial pooling.	I-Review	I-15	Review	86
2) gaining improvements in performance by improving data augmentation techniques distracts attention from improving machine learning methods and focuses it on these more basic engineering tricks.	I-Review	I-15	Review	86
But I‚Äôm not asking you to engineer new data augmentation methods here; you can just use exactly the same augmentation as many previous authors have already used on CIFAR-10 and SVHN.	I-Review	I-15	Review	86
[line_break_token]I don‚Äôt think there is any valid case at all for excluding stochastic regularization from consideration.	I-Review	I-15	Review	86
It doesn‚Äôt require any knowledge of the data domain and it is absolutely a machine learning technique rather than just an engineering trick.	I-Review	I-15	Review	86
Moreover, it is computationally very cheap, and state of the art across the board.	I-Review	I-15	Review	86
By refusing to study stochastic regularization you are essentially insisting on studying obsolete methods.	I-Review	I-15	Review	86
The only regime in which stochastic regularization is not universally superior to deterministic backprop is in the extremely large data domain, which as academics you probably don‚Äôt have access to and you are also actively avoiding by not using data augmentation.	I-Review	I-15	Review	86
[line_break_token][line_break_token][tab_token]Fig 2 and 3 in general: I understand it‚Äôs too expensive to extensively cross-validate every point on these plots, but I think it‚Äôd be good to pick maybe 4 points for each plot (maybe the upper-left and lower-right of two different contour lines) and run around 10 experiments each for those 4 points.	B-Review	B-16	Review	86
Overall that is 80 training runs, which I think is totally reasonable.	I-Review	I-16	Review	86
The current plots are somewhat interesting but it‚Äôs hard to have much confidence that the trends they indicate are real.	I-Review	I-16	Review	86
Obtaining higher confidence estimates of the real value of a small number of points would help a lot to confirm that the trends are actually caused by the # of feature maps and depth rather than compatibility with a fixed optimization scheme.	I-Review	I-16	Review	86
[line_break_token][line_break_token]Section 4:[line_break_token][tab_token]I don‚Äôt think the ‚Äúreceived wisdom‚Äù is that more depth is always better, just that the optimal depth is usually greater than 1.	B-Review	B-17	Review	86
[line_break_token][tab_token]You say your experiments show that more depth is better for a fixed parameter budget, but doesn‚Äôt Fig 2. (	I-Review	I-17	Review	86
right) contradict this?	I-Review	I-17	Review	86
Thank you for your comments.	B-Reply	B-18	Reply	86
 We have updated the paper with some major revisions, and it is now online.	I-Reply	I-18	Reply	86
 Responses to your comments are below	I-Reply	I-18	Reply	86

[line_break_token]The paper essentially addresses the difficult problem of visual representation evaluation.	O	O	Review	574
It attempts to find a universal way of assessing the quality of a model's representation.	O	O	Review	574
The authors define a good representation as one that can adapt to unseen tasks with few examples.	O	O	Review	574
With this in mind, they propose Visual Task Adaptation Benchmark (VTAB), a benchmark that is focused on sample complexity and task diversity.	O	O	Review	574
[line_break_token][line_break_token]- Very clear, well written and well structured. (	O	O	Review	574
Although not fully self contained in the main body of the paper - 20 pages of supplementary material!)	O	O	Review	574
[line_break_token]- The benchmark tasks are constrained to unseen tasks, which seems obvious but is often violated when evaluating representations[line_break_token]- It does a good attempt at covering a large spectrum of realistic domains (19 tasks!)	O	O	Review	574
to assess generality.	O	O	Review	574
[line_break_token]- Extensive study is conducted, covering the published state of the art methods in each domain.	O	O	Review	574
[line_break_token]- The study leads to interesting finding, such as promising results on self-supervision and negative results on generation.	O	O	Review	574
[line_break_token][line_break_token]Overall, I believe the paper is an important contribution as it provides some interesting analysis of the current state of the art for visual representation learning.	O	O	Review	574
hank you for your very positive comments.	O	O	Reply	574
Do you have feedback on any aspects that could improve this work?	O	O	Reply	574
[line_break_token][line_break_token]We recognise that we defer many details and analyses to the Appendix.	O	O	Reply	574
It was challenging with both a new benchmark and an extensive study, to distill the most important points into 10 pages.	O	O	Reply	574
If you think that there are aspects that we should re-prioritize, we would be happy to try to refactor	O	O	Reply	574

This paper study the lottery ticket hypothesis by observing the properties of lottery tickets.	O	O	Review	96
In particular, the authors tested several different pruning techniques by varying evaluation criteria (L_1, L_2, L_-\infty and random) and pruning structures (structured, unstructured and hybrid).	O	O	Review	96
The authors perform experiments mainly on LeNet with the MNIST dataset and analyze the observations.	O	O	Review	96
[line_break_token][line_break_token]Overall, I think that the observations presented in the paper are not significant due to the following reasons.	O	O	Review	96
[line_break_token][line_break_token]First, the paper consists of the list of observations but how the observations extend to is not clearly described.	B-Review	B-2	Review	96
There are no guidelines how to utilize the observations in future research (e.g., how they can be used for verifying the lottery ticket hypothesis or how they affect to existing pruning techniques) while some observations might be trivial or not very interesting (e.g., contribution 1 and contribution 2) for me.	I-Review	I-2	Review	96
[line_break_token][line_break_token]Second, the observations are only presented for LeNet and MNIST and it is non-trivial whether they extend to large scale models.	B-Review	B-3	Review	96
The authors present VGG11 and AlexNet results in Appendix but they are not large enough to verify their hypothesis for practice.	I-Review	I-3	Review	96
The authors mentioned that larger models are not their subject, but this significantly reduces the confidence of the observations.	I-Review	I-3	Review	96
[line_break_token][line_break_token]Other comments:[line_break_token]I think that Figure 5 is not well described.	B-Review	B-1	Review	96
Explicitly noting the meaning of color in the figure would be better.	I-Review	I-1	Review	96
[line_break_token][line_break_token]Texts in Figure 7 are too small to read.	I-Review	I-1	Review	96
[line_break_token]	O	O	Review	96
irst of all, thank you for your comments.	O	O	Reply	96
[line_break_token][line_break_token]We would like to offer our point of view for why we disagree with the notion that the contributions and observations presented here are not interesting to the field.	B-Reply	B-2	Reply	96
We agree that perhaps these approaches cannot directly be utilized at the moment to help reach SoTA on a given task.	I-Reply	I-2	Reply	96
This utilitarian way of evaluating the contribution is at odds with the stated goal of the paper, which is to simply advance fundamental knowledge in the subdomain of science of deep learning.	I-Reply	I-2	Reply	96
Many of the findings in this paper directly go to address major open questions around the nature and emergence of lottery tickets, including observations #1 and #2, which we therefore deem to be interesting and relevant to the field (or at least to those doing research in this sub-field).	I-Reply	I-2	Reply	96
Objections to the absence of these studies have been raised in the community in the past to challenge the lottery ticket hypothesis itself.	I-Reply	I-2	Reply	96
To the best of the authors knowledge, a thorough study of structure characterization of lottery tickets emerging from a multitude of pruning methods is itself of interest to better begin to understand more about this emergent behavior and move towards principled approaches to lottery ticket discovery.	I-Reply	I-2	Reply	96
[line_break_token][line_break_token]In addition, we disagree that observations on small models are not significant.	B-Reply	B-3	Reply	96
If we are to understand the dynamics of what is happening in pruned models, under the lottery ticket hypothesis or any other hypothesis, we need to remove factors of variation introduced by SoTA seeking architectures.	I-Reply	I-3	Reply	96
Even in the case where dynamics discovered in small networks do not apply to a large, say, ResNeXt or NasNet, that alone is interesting future work and important to understand and document.	I-Reply	I-3	Reply	96
We do agree that confirmatory experiments in larger more complex domains would be a useful extension of this work, but not a necessary one to make these empirical discoveries worthwhile.	I-Reply	I-3	Reply	96
[line_break_token]While we agree that it is non-trivial to extend lottery tickets to larger models (as is well documented in the literature) we believe that understanding why and when lottery tickets emerge in smaller models will help us better apply them to larger models in the future.	I-Reply	I-3	Reply	96
[line_break_token][line_break_token]As per your direct comments, we have improved the description of Fig.	B-Reply	B-1	Reply	96
5. ‚	I-Reply	I-1	Reply	96
Ä®The caption on Figure 7 already contains all the necessary information to decipher what the axes in the subplots represent (the numerical values are not important and the axes could be entirely removed in favor of simply showing the qualitative trend)	I-Reply	I-1	Reply	96

Summary: They tackle the problem of out-of-data distribution by leveraging RND applied to data augmentations.	O	O	Review	265
They train a model f(x) to match the outputs of g_i(aug_i(x)), where g_i is a random network and aug_i is a particular type of augmentation.	O	O	Review	265
An example with high error in this task is treated as an out-of-distribution example.	O	O	Review	265
This work focuses on exploring blurring through SVD, where the smallest K singular values are set to 0, and K varies between different aug_i calls.	O	O	Review	265
They find that their method of consistently can achieve strong detection rates across multiple target-dataset pairs.	O	O	Review	265
[line_break_token][line_break_token]Comments:[line_break_token]* The experimental results in this work are impressive, which introduces many more questions.	O	O	Review	265
[line_break_token]* The model used for f and g is not mentioned in the text.	B-Review	B-1	Review	265
[line_break_token]* Figure 4 (left) suggests that the SVD-RND performs about the same between 10K and 50K examples.	B-Review	B-2	Review	265
The level of robustness is surprising, but doesn‚Äôt seem to square with intuition that more data ought to help.	I-Review	I-2	Review	265
How little data can be used?	I-Review	I-2	Review	265
In other words, extend the graph to the left.	I-Review	I-2	Review	265
[line_break_token]* The geometric transforms baseline is not fair, since SVD-RND uses multiple SVD transforms (b_train &gt; 1) whereas the geometric transforms only have one.	O	O	Review	265
Please run a model with all the geometric transforms.	B-Review	B-3	Review	265
This result is important for understanding whether the gains come from the particular transform (SVD) or the number of transforms used.	I-Review	I-3	Review	265
[line_break_token]* Following the spirit of the previous comment, what other data augmentations can be used in place of SVD?	B-Review	B-4	Review	265
Typical image classification pipelines use a large variety of augmentations.	I-Review	I-4	Review	265
I would suggest taking some augmentations from AutoAugment [1] and running RND on top of them.	I-Review	I-4	Review	265
[line_break_token]* An experiment that is missing is RND trained on blurred images.	B-Review	B-5	Review	265
Is the blurring itself the important component, or is having multiple different heads important?	I-Review	I-5	Review	265
[line_break_token]* In general, I am confused about how a single head RND does not converge to 0 loss by learning the weights of g. This seems to be a simple optimization problem.	B-Review	B-6	Review	265
The original RND paper avoided this problem by also using the network to learn a policy, but this does not exist in this approach.	I-Review	I-6	Review	265
[line_break_token]* Furthermore, a comparison with Ren et al [2] and Nalisnick et al [3] would be useful. [	B-Review	B-7	Review	265
2] also uses data augmentation to create a background model that is compared against the real model.	I-Review	I-7	Review	265
One can probably simulate this approach by comparing the error rates of each head of RND.	I-Review	I-7	Review	265
[line_break_token][line_break_token]In general, this work seems promising, but lacks proper ablations that elucidate what components of the method are important.	O	O	Review	265
I am happy to increase my score if the experiments suggests are added to the work.	O	O	Review	265
[line_break_token][line_break_token][1] AutoAugment: Learning Augmentation Policies from Data.	O	O	Review	265
Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, Quoc V. Le[line_break_token][2] Likelihood Ratios for Out-of-Distribution Detection.	O	O	Review	265
Jie Ren, Peter J. Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark A. DePristo, Joshua V. Dillon, Balaji Lakshminarayanan[line_break_token][3] Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality.	O	O	Review	265
Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Balaji Lakshminarayanan	O	O	Review	265
e first thank the reviewer for the feedback that helped to improve the paper.	O	O	Reply	265
[line_break_token][line_break_token]1.	O	O	Reply	265
The model used for f and g is not mentioned in the text.	O	O	Reply	265
[line_break_token][line_break_token]-&gt; We modified the style of the paper and referenced the structure in Appendix B.[line_break_token][line_break_token]2.	B-Reply	B-1	Reply	265
Figure 4 (left) suggests that the SVD-RND performs about the same between 10K and 50K examples.	O	O	Reply	265
The level of robustness is surprising, but doesn‚Äôt seem to square with intuition that more data ought to help.	O	O	Reply	265
How little data can be used?	O	O	Reply	265
In other words, extend the graph to the left.	O	O	Reply	265
[line_break_token][line_break_token]-&gt; We extended the graph where 2000,4000,6000,8000 training data are available.	B-Reply	B-2	Reply	265
When 8000 training data is available, the performance of SVD-RND drops but still outperforms the performance of RND with 50000 training data.	I-Reply	I-2	Reply	265
When the data size is smaller than 8000, the performance drop is huge.	I-Reply	I-2	Reply	265
We modified Figure 4 to present the phenomenon mentioned above.	I-Reply	I-2	Reply	265
[line_break_token][line_break_token]3.	B-Reply	B-3	Reply	265
 The geometric transforms baseline is not fair, since SVD-RND uses multiple SVD transforms  &gt; 1) whereas the geometric transforms only have one.	O	O	Reply	265
Please run a model with all the geometric transforms.	O	O	Reply	265
This result is important for understanding whether the gains come from the particular transform (SVD) or the number of transforms used.	O	O	Reply	265
[line_break_token][line_break_token]-&gt; First, we have combined the model with geometric transformations in the RND framework.	B-Reply	B-3	Reply	265
We experimented by merging rotation, flip, and translation, and this results in b_train=4*3*2-1=23.	I-Reply	I-3	Reply	265
Such a combination showed TNR(at 95% TPR) of 0.181/0.182/0.199 in CIFAR-10 : (SVHN, LSUN, TinyImageNet) domain.	I-Reply	I-3	Reply	265
This shows that combining different transforms to one does not always improve OOD detection performance.	I-Reply	I-3	Reply	265
[line_break_token][line_break_token]Also, we want to clarify that rotation or translation employs multiple transforms for training.	I-Reply	I-3	Reply	265
For example, in rotation, we assign different target network to each data rotated by 90, 180, and 270 degrees.	I-Reply	I-3	Reply	265
Therefore, rotation already has.	I-Reply	I-3	Reply	265
[line_break_token][line_break_token]4.	O	O	Reply	265
 Following the spirit of the previous comment, what other data augmentations can be used in place of SVD?	O	O	Reply	265
Typical image classification pipelines use a large variety of augmentations.	O	O	Reply	265
I would suggest taking some augmentations from AutoAugment and running RND on top of them.	O	O	Reply	265
 [line_break_token][line_break_token]-&gt; We further experimented with the contrast, shear, and invert introduced in [1], and appended the results on the revised version.	B-Reply	B-4	Reply	265
[line_break_token][line_break_token]5.	O	O	Reply	265
 An experiment that is missing is RND trained on blurred images.	O	O	Reply	265
Is the blurring itself the important component, or is having multiple different heads important?	O	O	Reply	265
[line_break_token][line_break_token]-&gt; We also experimented RND trained on blurred images in the CIFAR-10 : (SVHN, LSUN, TinyImageNet) domain with varying K. This strategy showed the TNR(at 95% TPR) of 0.021/0.809/0.767, which showed slightly improved result compared to RND but still underperforms over SVD-RND.	B-Reply	B-5	Reply	265
Therefore, we hypothesize that "teaching the network to discriminate between blurred images and original images helped OOD detection".	I-Reply	I-5	Reply	265
[line_break_token][line_break_token]6.	O	O	Reply	265
In general, I am confused about how a single head RND does not converge to 0 loss by learning the weights of g. This seems to be a simple optimization problem.	O	O	Reply	265
The original RND paper avoided this problem by also using the network to learn a policy, but this does not exist in this approach.	O	O	Reply	265
[line_break_token][line_break_token]-&gt; First, we set that each target network in the experiment also corresponds to the complex function.	B-Reply	B-6	Reply	265
Therefore, we expect that much strict learning rate scheduling and more training epoch will be required to better convergence.	I-Reply	I-6	Reply	265
[line_break_token][line_break_token]Also, we reviewed the original RND paper and found that they do not update the predictor network via the policy loss.	B-Reply	B-7	Reply	265
The paper updates the predictor network only on the loss, which is the same as us.	I-Reply	I-7	Reply	265
We refer to the 14th page of  <a href="https://openreview.net/pdf?id=H1lJJnR5Ym" target="_blank" rel="nofollow">https://openreview.net/pdf?id=H1lJJnR5Ym</a> for the reference.	O	O	Reply	265
[line_break_token][line_break_token]	O	O	Reply	265

This paper introduces a new framework to interactively interact document retriever and reader for open-domain question answering.	O	O	Review	327
While retriever-reader framework was often used for open-domain QA, this bi-directional interaction between the retriever and the reader is novel and effective because[line_break_token]1) If the retriever fails to retrieve the right document at the first step, the reader can give a signal to the retriever so that the retriever can recover its mistake at the next step[line_break_token]2) The idea of `reader state` from the reader to the retriever is new[line_break_token]3) The retriever use question-independent representation of paragraphs, which does not require different representation depending on the question and makes the framework easily scalable.	O	O	Review	327
[line_break_token][line_break_token]Strengths[line_break_token]1) The idea of multi-step & bi-directional interaction between the retriever and the reader is novel enough (as mentioned above).	O	O	Review	327
The paper contains enough literature studies on existing retriever-reader framework in open-domain setting, and clearly demonstrates how their framework is different from them.	O	O	Review	327
[line_break_token]2) The authors run the experiments on 4 different dataset, which supports the argument about the framework‚Äôs effectiveness.	O	O	Review	327
[line_break_token][line_break_token]Weakness[line_break_token]1) The authors seem to highlight multi-step `reasoning`, while it is not `reasoning` in my opinion.	B-Review	B-1	Review	327
Multi-step reasoning refers to the task which you need evidence from different documents, and/or you need to find first evident to find the second evidence from a different document.	I-Review	I-1	Review	327
I don‚Äôt think the dataset here are not multi-step reasoning dataset, and the authors seem not to claim it either.	I-Review	I-1	Review	327
Therefore, I recommend using another term (maybe `multi-step interaction`?)	I-Review	I-1	Review	327
instead of `multi-step reasoning`.	I-Review	I-1	Review	327
[line_break_token]2) While the idea of multi-step interaction and how it benefits the overall performance is interesting, the analysis is not enough.	B-Review	B-2	Review	327
Figure 3 in the paper does not have enough description ‚Äî for example, I got the left example means step 2 recovers the mistake from step 1, but what does the right example mean?	I-Review	I-2	Review	327
[line_break_token][line_break_token]Questions on result comparison[line_break_token]1) On TriviaQA (both open and full), the authors mentioned the result is on hidden test set ‚Äî did you submit it to the leaderboard?	B-Review	B-3	Review	327
I don‚Äôt see the same numbers on the TriviaQA leaderboard.	I-Review	I-3	Review	327
Also, the authors claim they are SOTA on TriviaQA, but there are higher numbers on the leaderboard (which are submitted prior to the ICLR deadline).	I-Review	I-3	Review	327
[line_break_token]2) There are other published papers with higher result on Quasar-T, SearchQA and TriviaQA (such as <a href="https://aclanthology.info/papers/P18-1161/p18-1161" target="_blank" rel="nofollow">https://aclanthology.info/papers/P18-1161/p18-1161</a> and <a href="https://arxiv.org/abs/1805.08092)" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.08092)</a> which the authors did not compare with.	O	O	Review	327
[line_break_token]3) In Section 4.2, is there a reason for the specific comparison to AQA (5th line), though AQA is not SOTA on SearchQA?	B-Review	B-5	Review	327
I don‚Äôt think it means latent space is better than natural language space.	I-Review	I-5	Review	327
They are totally different model and the only intersection is they contains interaction between two submodules.	I-Review	I-5	Review	327
[line_break_token]4) In Section 5, the authors mentioned their framework outperforms previous SOTA by 15% margin on TriviaQA, but what is that?	B-Review	B-6	Review	327
I don‚Äôt see 15% margin in Table 2.	I-Review	I-6	Review	327
[line_break_token][line_break_token]Marginal comments:[line_break_token]1) If I understood correctly, `TriviaQA-open` and `TriviaQA-full` in the paper are officially called `TriviaQA-full` and `open-domain TriviaQA`.	B-Review	B-7	Review	327
How about changing the term for readers to better understand the task?	I-Review	I-7	Review	327
Also, in Section 4, the authors said TriviaQA-open is larger than web/wiki setting, but to my knowledge, this setting is part of the wiki setting.	I-Review	I-7	Review	327
[line_break_token]2) It would be great if the authors make the capitalization consistent.	B-Review	B-8	Review	327
e.g. EM, Quasar-T, BiDAF.	I-Review	I-8	Review	327
Also, the authors can use EM instead of `exact match` after they mentioned EM refers to exact match in Section 4.2.	I-Review	I-8	Review	327
[line_break_token][line_break_token]Overall comment[line_break_token]The idea in the paper is interesting, and their model and experiments are concrete.	O	O	Review	327
My only worries is that the terms in the paper are confusing and performance comparison are weak.	B-Review	B-9	Review	327
I would like to update the score when the authors update the paper.	I-Review	I-9	Review	327
[line_break_token][line_break_token][line_break_token]Update 11/27/2018[line_break_token]Thanks for the authors for updating the paper.	O	O	Review	327
The updated paper have more clear comparisons with other models, with more & stronger experiments with the additional dataset.	O	O	Review	327
Also, the model is claimed to perform multi-step interaction rather than multi-step reasoning, which clearly resolves my initial concern.	O	O	Review	327
The analysis, especially ablations in varying number of iterations, was helpful to understand how their framework benefits.	O	O	Review	327
I believe these make the paper stronger along with its initial novelty in the framework.	O	O	Review	327
In this regard, I vote for acceptance.	O	O	Review	327
We thank you for your very useful and detailed review.	O	O	Reply	327
We have significantly updated the writing of the paper to hopefully address all confusion and we‚Äôve also updated the results section of the paper for better comparison.	B-Reply	B-9	Reply	327
In a nutshell, we have added a section on retriever performance demonstrating the scalability of our approach (sec 5.1).	I-Reply	I-9	Reply	327
We have improved results for our experiments with BiDAF reader and we have also added new results on the open-domain version of the SQuAD dataset.	I-Reply	I-9	Reply	327
Below we address your concerns point-by-point.	O	O	Reply	327
[line_break_token][line_break_token]1.	B-Reply	B-3	Reply	327
The authors seem to highlight multi-step `reasoning`, while it is not `reasoning` in my opinion.	O	O	Reply	327
Multi-step reasoning refers to the task which you need evidence from different documents, and/or you need to find first evident to find the second evidence from a different document.	O	O	Reply	327
I don‚Äôt think the dataset here are not multi-step reasoning dataset, and the authors seem not to claim it either.	O	O	Reply	327
Therefore, I recommend using another term (maybe `multi-step interaction`?)	O	O	Reply	327
instead of `multi-step reasoning`.	O	O	Reply	327
[line_break_token][line_break_token]After much discussion among us, we have arrived to an agreement with your comment.	B-Reply	B-1	Reply	327
We have renamed the title of the paper to ‚ÄúMulti-step Retriever-Reader Interaction for Scalable Open-domain Question Answering‚Äù.	I-Reply	I-1	Reply	327
[line_break_token]We believe that our framework that supports retriever-reader interaction would be a starting point to build models for multi-hop reasoning but the current datasets do not explicitly need models with such inductive bias.	I-Reply	I-1	Reply	327
There has been some very recent efforts in this direction such as HotpotQA -- but this dataset was very recently released (after the ICLR submission deadline).	I-Reply	I-1	Reply	327
[line_break_token][line_break_token]2.	O	O	Reply	327
While the idea of multi-step interaction and how it benefits the overall performance is interesting, the analysis is not enough.	O	O	Reply	327
Figure 3 in the paper does not have enough description ‚Äî for example, I got the left example means step 2 recovers the mistake from step 1, but what does the right example mean?	O	O	Reply	327
[line_break_token][line_break_token]We have significantly updated this section of the paper with much more analysis.	B-Reply	B-2	Reply	327
We have included a new section on analysis of results (Sec 4.3) in which we quantitatively measure if the iterative interaction between the retriever and the reader is able to retrieve better context for the reader.	I-Reply	I-2	Reply	327
We have also updated Figure 2 to report the results of our model for steps = {1, 3, 5, 7} for SearchQA, Qusar-T and TriviaQA-unfiltered.	I-Reply	I-2	Reply	327
[line_break_token]To answer your specific question about the second example from figure 3, after the query reformulation the new paragraph that was added also has the right answer string, i.e. the total occurrence of the correct answer span increased after the reformulation step.	I-Reply	I-2	Reply	327
Since we sum up the scores of spans, this led to the overall increase in the score of the right answer span (Demeter, in Figure 3)  to be the maximum.	I-Reply	I-2	Reply	327
We have explained this in the text of the paper.	I-Reply	I-2	Reply	327
[line_break_token][line_break_token]3.	O	O	Reply	327
On TriviaQA (both open and full), the authors mentioned the result is on hidden test set ‚Äî did you submit it to the leaderboard?	O	O	Reply	327
I don‚Äôt see the same numbers on the TriviaQA leaderboard.	O	O	Reply	327
Also, the authors claim they are SOTA on TriviaQA, but there are higher numbers on the leaderboard (which are submitted prior to the ICLR deadline).	O	O	Reply	327
[line_break_token][line_break_token]We apologize for the confusion about this experiment.	B-Reply	B-3	Reply	327
Ours and the reported baseline results are on the ‚ÄúTriviaQA-unfiltered‚Äù dataset (unfiltered version in <a href="http://nlp.cs.washington.edu/triviaqa/)," target="_blank" rel="nofollow">http://nlp.cs.washington.edu/triviaqa/),</a> for which there is no official leaderboard.	O	O	Reply	327
The unfiltered version is built for open-domain QA.	B-Reply	B-3	Reply	327
The evidence for each question in this setting are top 10 documents returned by Bing search results along with the Wikipedia pages of entities in the question.	I-Reply	I-3	Reply	327
In the web setting, each question is associated with only one web document and in the Wikipedia setting, each question is associated with the wiki pages of entities in the question (1.78 wiki pages per query on avg.)	I-Reply	I-3	Reply	327
Thus, the unfiltered setting has much more number of paragraphs than the individual web/wiki setting.	I-Reply	I-3	Reply	327
 Moreover, there is no guarantee that every document in the evidence will contain the answer making this setting even more challenging.	I-Reply	I-3	Reply	327
However we did submit our model predictions to the TriviaQA admin who emailed us back the result on the hidden test set and to the best of our knowledge, we achieve the highest result on this setting of TriviaQA.	I-Reply	I-3	Reply	327
We have updated the paper by naming this experiment TriviaQA-unfiltered and have clarified other details.	I-Reply	I-3	Reply	327

The paper proposed a novel SampleRNN to directly model waveform signals and achieved better performance both in terms of objective test NLL and subjective A/B tests.	O	O	Review	246
[line_break_token][line_break_token]As mentioned in the discussions, the current status of the paper lack plenty of details in describing their model.	O	O	Review	246
Hopefully, this will be addressed in the final version.	O	O	Review	246
[line_break_token][line_break_token]The authors attempted to compare with wavenet model, but they didn't manage to get a model better than the baseline LSTM-RNN, which makes all the comparisons to wavenets less convincing.	O	O	Review	246
Hence, instead of wasting time and space comparing to wavenet, detailing the proposed model would be better.	O	O	Review	246
Thanks for reviewing our paper.	O	O	Reply	246
It is much appreciated.	O	O	Reply	246
[line_break_token][line_break_token]Please find the top latest comment for the changelog of the recent revision	O	O	Reply	246

This paper conducts extensive experiments to study batch normalization, a very popular technique for training a deep convolutional network and its relationship with learning rate and batch size.	O	O	Review	20307
In addition, the authors also propose a new initialization scheme, ‚ÄúZeroInit‚Äù, to train a deep ResNet for better test accuracy.	O	O	Review	20307
This is a very empirical study and the authors also show extensive experimental results.	O	O	Review	20307
However, I do not see any novel findings in this study.	B-Review	B-1	Review	20307
Mostly this paper confirms the results of previous studies.	I-Review	I-1	Review	20307
The experimental results do not show much advantage of ZeroInit either.	I-Review	I-1	Review	20307
Overall, it is unclear what is the major novel contribution in this paper.	I-Review	I-1	Review	20307
e thank the reviewer for their assessment of our work.	O	O	Reply	20307
The reviewer agrees that our results are extensive but is unclear what the major contributions of this paper are.	O	O	Reply	20307
To clarify:[line_break_token][line_break_token]1.	O	O	Reply	20307
The two most influential recent works studying the benefits of batch normalization are Bjorck et al and Santurkar et al (both NeurIPS 2018).	B-Reply	B-1	Reply	20307
Both papers argue that the key benefit of batch normalization is to improve the loss conditioning, which enables stable training with larger learning rates.	I-Reply	I-1	Reply	20307
Our experiments prove that this statement is false.	I-Reply	I-1	Reply	20307
When the batch size is small, the optimal learning rate with and without batch normalization is also small, yet batch normalized networks still achieve significantly higher test accuracies and lower training losses.	I-Reply	I-1	Reply	20307
Large learning rates cannot be the key benefit of batch normalization in residual networks.	I-Reply	I-1	Reply	20307
[line_break_token][line_break_token]2.	O	O	Reply	20307
There is great interest in finding alternatives to batch normalization.	B-Reply	B-1	Reply	20307
We propose an extremely simple initialization scheme, ZeroInit, which is competitive with batch normalization and can be trained without any normalization.	I-Reply	I-1	Reply	20307
The key component of ZeroInit is to add a scalar multiplier at the end of each residual branch initialized to zero.	I-Reply	I-1	Reply	20307
Note that this can be implemented in a single line of code.	I-Reply	I-1	Reply	20307
[line_break_token][line_break_token]3.	O	O	Reply	20307
ZeroInit is similar to the recently proposed Fixup initialization (Zhang et al ICLR 2019).	B-Reply	B-1	Reply	20307
However, Zhang et al argued that the key component of Fixup is to rescale the conv layers inside residual branches at initialization.	I-Reply	I-1	Reply	20307
We show empirically that this component is completely unnecessary, even if L2 regularization is also removed.	I-Reply	I-1	Reply	20307
[line_break_token][line_break_token]4.	O	O	Reply	20307
Zhang et al also argued that Fixup is stable at the same large learning rates as batch normalization.	B-Reply	B-1	Reply	20307
Again, we show this claim is false.	I-Reply	I-1	Reply	20307
Both ZeroInit and Fixup are only stable at smaller learning rates and consequently they are both only competitive with batch normalization for small/moderate batch sizes (eg &lt; 1000 on ImageNet)[line_break_token][line_break_token]5.	O	O	Reply	20307
Entire papers have been written whose sole purpose is to provide an alternative to batch normalization when the batch size is too small to estimate batch statistics.	B-Reply	B-1	Reply	20307
Examples include GroupNorm (over 250 citations) and batch renormalization (over 100 citations).	I-Reply	I-1	Reply	20307
ZeroInit can be trained at batch size 1 without any drop in final performance.	I-Reply	I-1	Reply	20307
[line_break_token][line_break_token]In summary, we believe our work contains a number of valuable novel contributions.	I-Reply	I-1	Reply	20307
Crucially, our paper does not confirm the results of previous studies.	I-Reply	I-1	Reply	20307
Instead, it shows that the core claims in a number of highly influential papers are false empirically, while also proposing an alternative to batch normalization in residual networks which is significantly simpler to implement than existing methods.	I-Reply	I-1	Reply	20307

The paper proposes "wavelet pooling" as an alternative for traditional subsampling methods, e.g. max/average/global pooling, etc.,	O	O	Review	510
within convolutional neural networks.	O	O	Review	510
[line_break_token]Experiments on the MNIST, CIFAR-10, SHVN and KDEF datasets, shows the proposed wavelet-based method has[line_break_token]competitive performance with existing methods while still being able to address the overfitting behavior of max pooling.	O	O	Review	510
[line_break_token][line_break_token]Strong points[line_break_token]- The method is sound and well motivated.	O	O	Review	510
[line_break_token]- The proposes method achieves competitive performance.	O	O	Review	510
[line_break_token][line_break_token]Weak points[line_break_token]- No information about added computational costs is given.	B-Review	B-1	Review	510
[line_break_token]- Experiments are conducted in relatively low-scale datasets.	B-Review	B-2	Review	510
[line_break_token][line_break_token][line_break_token]Overall the method is well presented and properly motivated.	O	O	Review	510
The paper as a good flow and is easy to follow.	O	O	Review	510
The authors effectively demonstrate with few toy examples the weaknesses of traditional methods, i.e max pooling and average pooling.	O	O	Review	510
Moreover, their extended evaluation on several datasets show the performance of the proposed method in different scenarios.	O	O	Review	510
[line_break_token][line_break_token]My main concerns with the manuscript are the following.	O	O	Review	510
[line_break_token][line_break_token]Compared to traditional methods, the proposed methods seems to require higher computation costs.	B-Review	B-1	Review	510
In a deep neural network setting where operations are conducted a large number of times, this is a of importance.	I-Review	I-1	Review	510
However, no indication is given on what are the added computation costs of the proposed method and how that compares to existing methods.	I-Review	I-1	Review	510
A comparison on that regard would strengthen the paper.	I-Review	I-1	Review	510
[line_break_token][line_break_token]In many of the experiments, the manuscript stresses the overfitting behavior of max pooling.	B-Review	B-2	Review	510
This makes me wonder whether this is caused by the fact that experiments are conducted or relatively smaller datasets.	I-Review	I-2	Review	510
While the currently tested datasets are a good indication of the performance of the proposed method, an evaluation on a large scale scenario, e.g. ILSVRC'12, could solidify the message sent by this manuscript.	I-Review	I-2	Review	510
Moreover, it would increase the relevance of this work in the computer vision community.	I-Review	I-2	Review	510
[line_break_token][line_break_token]Finally, related to the presentation, I would recommend presenting the plots, i.e. Fig.	B-Review	B-3	Review	510
8,10,12,14, for the training and validation image subsets in two separate plots.	I-Review	I-3	Review	510
Currently, results for training and validation sets are mixed in the same plot, and due to the clutter it is not possible to see the trends clearly.	I-Review	I-3	Review	510
[line_break_token]Similarly, I would recommend referring to the Tables added in the paper when discussing the performance of the proposed method w.r.t.	I-Review	I-3	Review	510
traditional alternatives.	I-Review	I-3	Review	510
[line_break_token][line_break_token]I encourage the authors to address my concerns in their rebuttal	O	O	Review	510
We were actually able to add the computational complexity component as a subsection within the results and discussion.	B-Reply	B-1	Reply	510
We also modified the graphs and referenced the tables as you requested	B-Reply	B-3	Reply	510

The submission proposes to modify the typical GAN architecture slightly to include "encrypt" (Alice) and "decrypt" (Bob) modules as well as a module trying to decrypt the signal without a key (Eve).	O	O	Review	644
 Through repeated transmission of signals, the adversarial game is intended to converge to a system in which Alice and Bob can communicate securely (or at least a designated part of the signal should be secure), while a sophisticated Eve cannot break their code.	O	O	Review	644
 Examples are given on toy data:[line_break_token]"As a proof-of-concept, we implemented Alice, Bob, and Eve networks that take N-bit random plain-text and key values, and produce N-entry floating-point ciphertexts, for N = 16, 32, and 64.	O	O	Review	644
 Both plaintext and key values are uniformly distributed."	O	O	Review	644
[line_break_token][line_break_token]The idea considered here is cute.	O	O	Review	644
 If some, but not necessarily all of the signal is meant to be secure, the modules can learn to encrypt and decrypt a signal, while an adversary is simultaneously learned that tries to break the encryption.	O	O	Review	644
 In this way, some of the data can remain unencrypted, while the portion that is e.g. correlated with the encrypted signal will have to be encrypted in order for Eve to not be able to predict the encrypted part.	O	O	Review	644
[line_break_token][line_break_token]While this is a nice thought experiment, there are significant barriers to this submission having a practical impact:[line_break_token]1) GANs, and from the convergence figures also the objective considered here, are quite unstable to optimize.	B-Review	B-1	Review	644
 The only guarantees of privacy are for an Eve that is converged to a very strong adversary (stronger than a dedicated attack over time).	I-Review	I-1	Review	644
 I do not see how one can have any sort of reliable guarantee of the safety of the data transmission from the proposed approach, at least the paper does not outline such a guarantee.	I-Review	I-1	Review	644
[line_break_token]2) Public key encryption systems are readily available, computationally feasible, and successfully applied almost anywhere.	B-Review	B-2	Review	644
 The toy examples given in the paper do not at all convince me that this is solving a real-world problem at this point.	I-Review	I-2	Review	644
 Perhaps a good example will come up in the near future, and this work will be shown to be justified, but until such an example is shown, the approach is more of an interesting thought experiment.	I-Review	I-2	Review	644
We are glad about your comment that this paper presents ‚Äúan interesting thought experiment‚Äù, as it is in line with how we regard this work.	O	O	Reply	644
As for your points on the possible impact of this work:[line_break_token]1) We also agree that the techniques that we present are not likely to yield high-assurance security.	B-Reply	B-1	Reply	644
They may however yield suitable protection against low-grade attackers (much like spam filters) or against our own actions.	I-Reply	I-1	Reply	644
In particular, as suggested in the submission (page 2), they may be adequate in order to prevent one of our own neural-network components from using information that we want to keep from it because of concerns about privacy or discrimination.	I-Reply	I-1	Reply	644
[line_break_token]2) An important contrast with readily available encryption systems is that, with our approach, one learns what needs to be ‚Äúscrambled‚Äù for a given a protection goal (as indicated in our reply of December 8).	B-Reply	B-2	Reply	644

This paper proposes the use of holographic reduced representations in language modeling, which allows for a cleaner decomposition of various linguistic traits in the representation.	O	O	Review	1586
Results show improvements over baseline language models, and analysis shows that the representations are indeed decomposing as expected.	O	O	Review	1586
[line_break_token][line_break_token]The main reviewer concern was the lack of strength of the baseline, although the authors stress that they were using the default baseline from TensorFlow, which seems like it will be reasonable to me.	B-Review	B-1	Review	1586
Another concern is that there is other work on using HRR to disentangle syntax and semantics in representations for language (e.g. "Distributed Tree Kernels" ICML 2012, but also others), that has not been considered.	B-Review	B-2	Review	1586
[line_break_token][line_break_token]Based on this, this seems like a very borderline case.	O	O	Review	1586
Given that no reviewer is pushing strongly for the paper I'm leaning towards not recommending acceptance, but I could very easily see the paper being accepted as well.	O	O	Review	1586
We thank all reviewers and chair for your comments.	O	O	Reply	1586
While we fully understand your concerns regarding the baseline results and related work, we hope to make it clear (once more) that:[line_break_token]1) Our intention was to make the results easily reproducible based on the widely available Tensorflow open-source implementation of LM on public datasets, with no sophisticated tricks or model modifications involved.	B-Reply	B-1	Reply	1586
At the same time, we strongly believe that the main contribution of our submission - decomposition of representation - does not have to be correlated with perplexity results.	I-Reply	I-1	Reply	1586
Better perplexity results do not guarantee decomposed representation, nor is a good decomposed representation hinged on good perplexity results.	I-Reply	I-1	Reply	1586
[line_break_token]2) We acknowledge Reviewer 1 for pointing out related works, however the existing approaches, although using HRR as a component, are very different from the ones we proposed in our paper.	B-Reply	B-2	Reply	1586
They would not naturally apply to learning disentangled linguistic features, the problem we aim to tackle and major contribution we make in our paper.	I-Reply	I-2	Reply	1586
Our understanding is that Reviewer 1 raised this point in debating with our claim that a naively implemented chunk-level model is intractable, and it was not his intention to directly apply the work on tree kernel HRR to the decomposition task at hand.	I-Reply	I-2	Reply	1586
[line_break_token][line_break_token]We believe that our proposed model, formulated specifically for addressing the topic of disentangled linguistic representation, is novel and effective, and provides a viable approach for future research.	B-Reply	B-3	Reply	1586
We would greatly appreciate it if our comments and previous responses are taken into more serious consideration, and decisions properly revised	I-Reply	I-3	Reply	1586

This paper presents TopicRNN, a combination of LDA and RNN that augments traditional RNN with latent topics by having a switching variable that includes/excludes additive effects from latent topics when generating a word.	O	O	Review	275
[line_break_token]Experiments on two tasks are performed: language modeling on PTB, and sentiment analysis on IMBD.	O	O	Review	275
[line_break_token]The authors show that TopicRNN outperforms vanilla RNN on PTB and achieves SOTA result on IMDB.	O	O	Review	275
[line_break_token][line_break_token]Some questions and comments:[line_break_token]- In Table 2, how do you use LDA features for RNN (RNN LDA features)?	B-Review	B-1	Review	275
[line_break_token]- I would like to see results from LSTM included here, even though it is lower perplexity than TopicRNN.	B-Review	B-2	Review	275
I think it's still useful to see how much adding latent topics close the gap between RNN and LSTM.	I-Review	I-2	Review	275
[line_break_token]- The generated text in Table 3 are not meaningful to me.	B-Review	B-3	Review	275
What is this supposed to highlight?	I-Review	I-3	Review	275
Is this generated text for topic "trading"?	I-Review	I-3	Review	275
What about the IMDB one?	I-Review	I-3	Review	275
[line_break_token]- How scalable is the proposed method for large vocabulary size (>10K)?	O	O	Review	275
[line_break_token]- What is the accuracy on IMDB if the extracted features is used directly to perform classification? (	B-Review	B-5	Review	275
instead of being passed to a neural network with one hidden state).	I-Review	I-5	Review	275
I think this is a fairer comparison to BoW, LDA, and SVM methods presented as baselines.	I-Review	I-5	Review	275
Thanks for your questions and for suggesting we add results for TopicLSTM!	O	O	Reply	275
[line_break_token][line_break_token]- In Table 2, the first two lines were results reported in Mikolov et al 2012.	B-Reply	B-1	Reply	275
They run LDA separately and extract features for words using the topic matrix.	I-Reply	I-1	Reply	275
[line_break_token][line_break_token]- We included results from TopicRNN, TopicLSTM, and TopicGRU.	B-Reply	B-2	Reply	275
Contrary to what we mentioned earlier, TopicLSTM and TopicGRU actually perform very well.	I-Reply	I-2	Reply	275
We corrected a bug on the computation of the ELBO.	I-Reply	I-2	Reply	275
The new results are consistent with the story and are reported in table 2. (	I-Reply	I-2	Reply	275
We are also running experiments with TopicGRU/TopicLSTM on IMDB data.	I-Reply	I-2	Reply	275
However, it takes some time to finish.	I-Reply	I-2	Reply	275
We will add them when they are available.)	I-Reply	I-2	Reply	275
[line_break_token][line_break_token]- Each text is generated using one example input document.	B-Reply	B-3	Reply	275
The input for IMDB was a negative review.	I-Reply	I-3	Reply	275
That sentiment is reflected in the generated text.	I-Reply	I-3	Reply	275
Note one can sample from the prior for the topic vector \theta and use that as bias on the trained model.	I-Reply	I-3	Reply	275
[line_break_token][line_break_token]-TopicRNN is a language model.	B-Reply	B-4	Reply	275
As reported at the bottom of page 5, the complexity is dominated by the computation of the softmax output layer as is the case for language models.	I-Reply	I-4	Reply	275
As such, all methods for dealing with the softmax layer are also applicable to TopicRNN.	I-Reply	I-4	Reply	275
We reported the computation time in the experiments section to give an idea.	I-Reply	I-4	Reply	275
[line_break_token][line_break_token]- We followed the procedure in Paragraph&nbsp;Vector.	O	O	Reply	275
The main comparison here is against other unsupervised neural network based approaches (ex: Le and Mikolov 2014).	B-Reply	B-5	Reply	275
Note it is also possible to train the classifier directly with TopicRNN.	I-Reply	I-5	Reply	275
However, we wanted to highlight TopicRNN as unsupervised feature extractor.	I-Reply	I-5	Reply	275

The paper presents a method to analyse how and what the auto-encoder models that use reconstruction error together with a regularisation cost, are learning with respect to the underlying data distribution.	O	O	Review	10
The paper focuses on contractive auto-encoder models and also reformulates denoising auto-encoder as a form of contractive auto-encoder where the contraction is achieved through regularisation of the derivative of reconstruction error wrt to the input data.	O	O	Review	10
The rest of the paper presents a theoretical analysis of this form of auto-encoders and also provides couple of toy examples showing empirical support.	O	O	Review	10
[line_break_token][line_break_token]The paper is easy to read and the theoretical analysis is nicely split between the main paper and appendices.	O	O	Review	10
The details in the main paper are sufficient for the reader to understand the concept that is presented in the paper.	O	O	Review	10
[line_break_token][line_break_token]The theory and empirical data show that one can recover the true data distribution if using contractive auto-encoders of the given type.	O	O	Review	10
I think this is quite an important result.	B-Review	B-1	Review	10
even though limited to this specific type of model, quantitative analysis of generative capabilities of auto-encoders have been limited.	I-Review	I-1	Review	10
[line_break_token][line_break_token]I find the experiment shown in Figure 4 somewhat confusing.	B-Review	B-2	Review	10
The text suggests that the only difference between the two models is their initial conditions and optimisation hyper parameters.	I-Review	I-2	Review	10
Is the main reason due to initial conditions or hyper parameters?	I-Review	I-2	Review	10
Which hyper parameters?	I-Review	I-2	Review	10
Is the difference in initial condition just a different random seed or different type of initialisation of the network?	I-Review	I-2	Review	10
I think this requires more in depth explanation.	I-Review	I-2	Review	10
Is it normal to expect such different solutions depending on initial conditions?	I-Review	I-2	Review	10
[line_break_token][line_break_token]Section 3.2.4.	B-Review	B-3	Review	10
I am not clear what is the importance of this section.	I-Review	I-3	Review	10
It seems to state the relationship between the score and reconstruction derivative.	I-Review	I-3	Review	10
[line_break_token][line_break_token]Is it possible to link these results and theory to other forms of auto-encoders, such as sparse auto-encoders or with different type of non-linear activation functions?	B-Review	B-4	Review	10
It would be very useful to have similar analysis for more general types of auto-encoders too.	I-Review	I-4	Review	10
> I think this is quite an important result.	O	O	Reply	10
even though limited to this specific type of model[line_break_token][line_break_token]As argued in a previous response (to reviewer 4222), we believe that at least at a qualitative level the same is true in general of regularized auto-encoders.	B-Reply	B-1	Reply	10
We copy here the response: [line_break_token]'We have worked on the denoising/contracting auto-encoders with squared error because we were able to prove our results with them, but we believe that other regularized auto-encoders (even those with discrete inputs) also estimate something related to the score, i.e., the direction in input space in which probability increases the most.	I-Reply	I-1	Reply	10
The intuition behind that statement can be obtained by studying figure 2: the estimation of this direction arises out of the conflict between reconstructing training examples well and making the auto-encoder as constant (regularized) as possible.'	I-Reply	I-1	Reply	10
[line_break_token]We have added a brief discussion in the conclusion about how we believe these results could be extended to models with discrete inputs, following the tracks of ratio matching (Hyvarinen 2007).	I-Reply	I-1	Reply	10
[line_break_token][line_break_token]We have also added (in new sec.	I-Reply	I-1	Reply	10
3.2.3) a brief discussion of how these new results (on r(x)-x estimating the score) contradict previous interpretations of the reconstruction error of auto-encoders (Ranzato & Hinton NIPS 2007) as being akin to an energy function.	O	O	Reply	10
Indeed whereas both interpretations agree on having a low reconstruction error at training examples, the score interpretation suggests (and we see it experimentally) other (median) regions that are local maxima of density, where the reconstruction error is also low.	B-Reply	B-1	Reply	10
[line_break_token][line_break_token]> I find the experiment shown in Figure 4 somewhat confusing.	O	O	Reply	10
[line_break_token][line_break_token]We have addressed this concern that many of the reviewers had.	B-Reply	B-2	Reply	10
The whole section 3.2.3 has been edited and we decided to remove two of the plots which may have introduced confusion.	I-Reply	I-2	Reply	10
Reviewers seem to focus on the difference between the two models and wanted to know why the outcomes were different.	I-Reply	I-2	Reply	10
They were only different because of the non-convexity of the problem and the dependance on initial conditions (along with the random noise used for training).	I-Reply	I-2	Reply	10
At the end of the day, the point is that the vector field points in the direction of the energy gradient, and that is illustrated nicely by the two plots left (far and close distance).	I-Reply	I-2	Reply	10
[line_break_token][line_break_token][line_break_token]> Section 3.2.4.	O	O	Reply	10
I am not clear what is the importance of this section.	O	O	Reply	10
It seems to state the relationship between the score and reconstruction derivative.	O	O	Reply	10
[line_break_token][line_break_token]Are you referring to section 3.3 ?	B-Reply	B-3	Reply	10
If you are indeed referring to section 3.2.4, the idea there is that it is possible to start the investigation from a trained DAE where the noise level for the training is unknown to us (but it is known by the person who trained the DAE).	I-Reply	I-3	Reply	10
In that case, we would be in a situation where we the best that could be done was to recover the energy function gradient up to a scaling constant.	I-Reply	I-3	Reply	10
[line_break_token][line_break_token][line_break_token]> Is it possible to link these results and theory to other forms of auto-encoders, such as sparse auto-encoders or with different type of non-linear activation functions?	O	O	Reply	10
It would be very useful to have similar analysis for more general types of auto-encoders too.	O	O	Reply	10
[line_break_token][line_break_token]See our first response above.	O	O	Reply	10
[line_break_token][line_break_token]Please also have a look at a new short section (now identified as 3.2.5) that we just added in	O	O	Reply	10

This paper aims to synthesize programs in a Java-like language from a task description (X) that includes some names and types of the components that should be used in the program.	O	O	Review	336
The paper argues that it is too difficult to map directly from the description to a full program, so it instead formulates the synthesis in two parts.	O	O	Review	336
First, the description is mapped to a "sketch" (Y) containing high level program structure but no concrete details about, e.g., variable names.	O	O	Review	336
Afterwards, the sketch is converted into a full program (Prog) by stochastically filling in the abstract parts of the sketch with concrete instantiations.	O	O	Review	336
[line_break_token][line_break_token]The paper presents an abstraction method for converting a program into a sketch, a stochastic encoder-decoder model for converting descriptions to trees, and rejection sampling-like approach for converting sketches to programs.	O	O	Review	336
Experimentally, it is shown that using sketches as an intermediate abstraction outperforms directly mapping to the program AST.	O	O	Review	336
The data is derived from an online repository of ~1500 Android apps, and from that were extracted ~150k methods, which makes the data very respectable in terms of realisticness and scale.	O	O	Review	336
This is one of the strongest points of the paper.	O	O	Review	336
[line_break_token][line_break_token]One point I found confusing is how exactly the Combinatorial Concretization step works.	O	O	Review	336
Am I correct in understanding that this step depends only on Y, and that given Y, Prog is conditionally independent of X?	B-Review	B-1	Review	336
If this is correct, how many Progs are consistent with a typical Y?	I-Review	I-1	Review	336
Some additional discussion of why no learning is required for the P(Prog | Y) step would be appreciated.	B-Review	B-2	Review	336
[line_break_token][line_break_token]I'm also curious whether using a stochastic latent variable (Z) is necessary.	B-Review	B-3	Review	336
Would the approach work as well using a more standard encoder-decoder model with determinstic Z?	I-Review	I-3	Review	336
[line_break_token][line_break_token]Some discussion of Grammar Variational Autoencoder (Kusner et al) would probably be appropriate.	B-Review	B-4	Review	336
[line_break_token][line_break_token]Overall, I really like the fact that this paper is aiming to do program synthesis on programs that are more like those found "in the wild".	O	O	Review	336
While the general pattern of mapping a specification to abstraction with a neural net and then mapping the abstraction to a full program with a combinatorial technique is not necessarily novel, I think this paper adds an interesting new take on the pattern (it has a very different abstraction than say, DeepCoder), and this paper is one of the more interesting recent papers on program synthesis using machine learning techniques, in my opinion.	O	O	Review	336
[line_break_token]	O	O	Review	336
Thank you for your feedback about the paper.	O	O	Reply	336
We answer your specific questions below.	O	O	Reply	336
[line_break_token][line_break_token]Question: Am I correct in understanding that [Combinatorial Concretization] step depends only on Y, and that given Y, Prog is conditionally independent of X?	O	O	Reply	336
If this is correct, how many Progs are consistent with a typical Y?	O	O	Reply	336
[line_break_token][line_break_token]Answer: Yes, Prog is conditionally independent of X given a sketch Y. In theory, there may be an infinite number of Progs for every Y. A simple example is two Progs that differ only in variable names, thereby corresponding to the same Y; for another example, there can be very many expressions that match the type of an API method argument.	B-Reply	B-1	Reply	336
However, in practice, we use certain heuristics to limit the space of Progs from a given Y (these heuristics are abstractly captured by the distribution P(Prog | Y).	I-Reply	I-1	Reply	336
In particular, these heuristics prioritize smaller, simpler programs over complex ones, and name local variables in a canonical way.	I-Reply	I-1	Reply	336
[line_break_token][line_break_token]While we didn't collect this data systematically, our experience with the system suggests that under the heuristics actually implemented in it, a typical Y leads to only ~5-10 distinct Progs in our experiments.	I-Reply	I-1	Reply	336
We will collect this data more thoroughly and add it to the paper.	I-Reply	I-1	Reply	336
[line_break_token][line_break_token]Question: Some additional discussion of why no learning is required for the P(Prog | Y) step would be appreciated.	O	O	Reply	336
[line_break_token][line_break_token]Answer: In principle, this step could be made data-driven; however, the resulting learning problem would be very difficult.	B-Reply	B-2	Reply	336
This is because a single sketch used for training can correspond to many training programs that only differ in superficial details (for example local variable names).	I-Reply	I-2	Reply	336
Learning to decide which differences between programs are superficial and which are not, solely by looking at the syntax of programs, is hard.	I-Reply	I-2	Reply	336
In contrast, our approach of heuristically choosing P(Prog | Y) utilizes our domain knowledge of language semantics (for example, that local variable names do not matter, and that some algebraic expressions are semantically equivalent).	I-Reply	I-2	Reply	336
This knowledge allows us to limit the set of programs that we end up generating.	I-Reply	I-2	Reply	336
We will clarify this in more detail in the paper.	I-Reply	I-2	Reply	336
[line_break_token][line_break_token][line_break_token]Question: I'm also curious whether using a stochastic latent variable (Z) is necessary.	O	O	Reply	336
Would the approach work as well using a more standard encoder-decoder model with deterministic Z?	O	O	Reply	336
[line_break_token][line_break_token]Answer: The randomness associated with the latent variable Z serves as a way to regularize the learning process (a similar argument is made in the context of VAEs for the stochastic latent variable used during VAE learning).	B-Reply	B-3	Reply	336
We were concerned that without the stochasticity (i.e., with a deterministic Z), training the model would be more likely to be affected by overfitting.	I-Reply	I-3	Reply	336
Practically speaking, the stochasticity also serves as a way to ensure that we can generate a wide variety of possible programs from a given X. If Z was not random, a particular set of labels X will always result in exactly the same value of Z.[line_break_token][line_break_token]Comment: Some discussion of Grammar Variational Autoencoder (Kusner et al) would probably be appropriate.	O	O	Reply	336
[line_break_token][line_break_token]Answer: Kusner et al‚Äôs work proposes a VAE for context-free grammars.	B-Reply	B-4	Reply	336
Being an auto-encoder it is a generative model, but it is not a conditional model such as ours.	I-Reply	I-4	Reply	336
In their application towards synthesizing molecular structures, given a particular molecular structure, their model can be used to search the latent space for similar valid structures.	I-Reply	I-4	Reply	336
In our setting, however, we are not given a sketch but only labels about the sketch, and our task is learn a conditional model that can predict a whole sketch given labels.	O	O	Reply	336
[line_break_token][line_break_token]We will add the discussion about this work in the final version of the paper.	O	O	Reply	336

This work makes use of uncertainty estimation methods from active learning to select a subset of training data that produces models with similar (or better) performance compared to models trained on the full training set.	O	O	Review	526
It proposes a way to improve the Monte Carlo estimation of model uncertainty by including multiple checkpoints that are generated "for free" during a training run, thereby increasing the number of samples from 5-10 in previous work to 100 in this work.	O	O	Review	526
It compares several initialization schemes for the subset model using mutual information as the acquisition function, finds that a "build-up" approach (based on Chitta et.	O	O	Review	526
al 2018a) works best, and uses that for the rest of the studies.	O	O	Review	526
It then compares several acquisition functions, using the build-up approach, finds that variation ratio performs best, and uses that for the rest of the studies.	O	O	Review	526
Next, it compares the Top-1 accuracy on ImageNet obtained by evaluating the ensemble models produced by different ensembling schemes, and finds that ensembling 20 checkpoints from 5 training runs with different random seeds work best.	O	O	Review	526
Then, it uses acquisition models that use ensembles from each ensembling scheme to select subsets of the ImageNet data to be used for training the subset model, and then compares the performance of the subset models.	O	O	Review	526
Finally, it demonstrates this method of selecting a subset of the training data works even if the subset is used to train a model with a different architecture from the acquisition model.	O	O	Review	526
[line_break_token][line_break_token]Strengths:[line_break_token]- Algorithm is likely to be useful in practice.	O	O	Review	526
Training dataset can be "compressed" using a smaller architecture like ResNet-18, then used to train larger architectures like DenseNet-121, thus saving the amount of compute per training epoch.	O	O	Review	526
Using training checkpoints in the ensemble is very practical but not obvious (to me), since my first intuition would be that checkpoints from the same training run would not provide enough diversity to improve the acquisition function.	O	O	Review	526
I am glad that there were thorough experiments to address this concern and demonstrate that it works.	O	O	Review	526
[line_break_token]- Experiments answer key questions about the method proposed, and the sequence of experiments have a clear logical flow.	O	O	Review	526
Good baselines.	O	O	Review	526
Clear notation and problem set-up.	O	O	Review	526
[line_break_token][line_break_token]Weakness that affected the score:[line_break_token]- Missing detail on the build-up initialization scheme.	B-Review	B-1	Review	526
The work referred to Chitta et al 2018a, but that algorithm requires selecting a growth parameter.	I-Review	I-1	Review	526
This growth parameter determines the number of times the subset model needs to be retrained, which can affect the viability of this method in practice.	I-Review	I-1	Review	526
I would like to see the build-up initialization scheme described in greater detail.	I-Review	I-1	Review	526
[line_break_token][line_break_token]Clarifications:[line_break_token]- In Table 2 and Table 3, are the results in the "Single (1)",  "Checkpoints (5)", and "Checkpoints (20)" columns obtained by averaging over the 5 random seeds?	B-Review	B-2	Review	526
[line_break_token]- In the last column of Table 2, Top-1 accuracy of ~84% from an ensemble of 100 ResNet-18s (Table 2) seem very high.	B-Review	B-3	Review	526
In comparison, ResNet-50 and AmoebaNet-A (2019) obtained a Top-1 accuracy of 77.2% and 83.9% respectively.	I-Review	I-3	Review	526
What do the authors think about this?	I-Review	I-3	Review	526
[line_break_token]- Why would one expect high accuracy of the ensemble of NNs in the acquisition model to indicate good sampling quality of the acquisition model? (	B-Review	B-4	Review	526
caption for table 2)[line_break_token][line_break_token]Minor issues:[line_break_token]- Algorithm 1: first two steps should be kept un-italicized, like the rest of the steps.	B-Review	B-5	Review	526
[line_break_token]- Page 7, first paragraph: "This shows that the checkpoints are obtained with no additional computational cost at train time can be used to generate diverse ensembles."	B-Review	B-6	Review	526
The first "are" in this sentence is unnecessary.	I-Review	I-6	Review	526
[line_break_token]- Build-up was chosen as the initialization scheme for the rest of the studies, as it performed best when the acquisition function was fixed at *mutual information*. However, the acquisition function that was finally chosen for the rest of the studies is *variation ratio*, since it performed best when the initialization scheme was fixed at build-up.	B-Review	B-7	Review	526
It would be more convincing if figure 1 also includes variation ratio.	I-Review	I-7	Review	526
e appreciate the thoughtful and helpful feedback provided by the reviewer.	O	O	Reply	526
We address the clarifications requested in the review as follows:[line_break_token][line_break_token]1.	O	O	Reply	526
Missing detail on the build-up initialization scheme.	O	O	Reply	526
[line_break_token][line_break_token]Please refer to Section 2.1 on Page 3 of the revised draft, where we have included additional details regarding our use of the build up initialization scheme as follows:[line_break_token][line_break_token]‚ÄúFinally, in the build up scheme, we follow an iterative AL loop.	B-Reply	B-1	Reply	526
Specifically, we start by initializing with a randomly selected subset of the data to train an acquisition model.	I-Reply	I-1	Reply	526
After performing acquisition, instead of training a single subset model, we optimize an ensemble of networks.	I-Reply	I-1	Reply	526
This ensemble is used as an acquisition model for a subsequent iteration.	I-Reply	I-1	Reply	526
Our goal is to finally reach a subset of samples.	I-Reply	I-1	Reply	526
As observed by [1], exponentially growing the dataset size offers practical benefits in an AL loop setting.	I-Reply	I-1	Reply	526
We therefore follow this approach, by initializing with random samples, and iterating two further times at and samples before obtaining a final subset of size.	I-Reply	I-1	Reply	526
‚Äù[line_break_token][line_break_token]2.	O	O	Reply	526
Number of seeds in Tables 2 and 3.	O	O	Reply	526
[line_break_token][line_break_token]We would like to clarify that the rows ‚ÄòSingle (1)‚Äô, ‚ÄòCheckpoints (5)‚Äô and ‚ÄòCheckpoints (20)‚Äô use the best seed of the 5 runs.	B-Reply	B-2	Reply	526
We have now clarified this in the text after referencing Table 2, on Page 7.	I-Reply	I-2	Reply	526
[line_break_token][line_break_token]3.	O	O	Reply	526
High accuracy of the ResNet-18 100-model ensemble compared to state-of-the-art.	O	O	Reply	526
[line_break_token][line_break_token]We would like to highlight that the results in Table 2 are not on the official 50,000 image validation set for ImageNet, but on the 40% seen and 60% unseen data out of the 1.28M samples in the ImageNet training partition.	B-Reply	B-3	Reply	526
Since the algorithm selects the harder samples to its training data, these numbers are not indicative of performance on an i.i.d validation dataset and cannot be compared directly to state-of-the-art results.	I-Reply	I-3	Reply	526
Evaluating accuracy gains due to the proposed implicit ensembling technique is an interesting direction which we will look into for future research.	I-Reply	I-3	Reply	526
[line_break_token] [line_break_token]4.	O	O	Reply	526
Why would one expect high accuracy of the ensemble of NNs to indicate good sampling quality?	O	O	Reply	526
[line_break_token][line_break_token]The increase in accuracy in Table 2 shows that there is a significant shift in the final prediction of the ensemble with more checkpoints, indicating diversity.	B-Reply	B-4	Reply	526
Since the stored checkpoints are large in number and diverse enough to cause an improvement in accuracy, we believe they could also lead to better sampling by Monte Carlo estimation.	I-Reply	I-4	Reply	526
We have rephrased the caption of Table 2 to better convey our intended point.	I-Reply	I-4	Reply	526
[line_break_token][line_break_token]5.	O	O	Reply	526
Minor typos in Algorithm 1 and Page 7.	O	O	Reply	526
[line_break_token][line_break_token]Thank you, we have made the recommended changes.	B-Reply	B-5	Reply	526
[line_break_token][line_break_token]6.	O	O	Reply	526
Comparing initialization schemes for variation ratios.	O	O	Reply	526
[line_break_token][line_break_token]Please refer to Fig.	B-Reply	B-7	Reply	526
2 on Page 13 of the revised draft.	I-Reply	I-7	Reply	526
Unfortunately, we could not run the complete set of experiments from Fig.	I-Reply	I-7	Reply	526
1 using variation ratios, but we plot the validation curve for pretrain, compress and build up on 80% of ImageNet using variation ratios.	I-Reply	I-7	Reply	526
We observe that the performance of all three initialization schemes is similar at 80%.	I-Reply	I-7	Reply	526
The build up scheme which is used in most of our experiments in the main paper does slightly better than the compress scheme in terms of final validation accuracy.	I-Reply	I-7	Reply	526
[line_break_token][line_break_token][1] Kashyap Chitta, Jose M. Alvarez, Adam Lesnikowski.	O	O	Reply	526
Large-Scale Visual Active Learning with Deep Probabilistic Ensembles.	O	O	Reply	526
arXiv:1811.03575, 2018	O	O	Reply	526

SLM Lab is a software framework for reinforcement learning, which includes many different algorithms, networks, and memory types.	O	O	Review	451
The framework is well structured and modular.	O	O	Review	451
Thus, it is easily extendable for anyone and can be a pinnacle for future RL research.	O	O	Review	451
[line_break_token][line_break_token]The really like the paper.	O	O	Review	451
It is well written, easy to read, and provide a valuable platform / framework to the community, both the scientific community as well as practitioners.	O	O	Review	451
Although the scientific contribution may be low in the paper, I think the significance and potential impact of the paper outweigh that.	B-Review	B-1	Review	451
[line_break_token][line_break_token]The paper also include many results from running the framework in various configurations, showing the flexibility and usefulness of it.	O	O	Review	451
[line_break_token][line_break_token]The code for SLM Lab is released open source, which is very valuable and enables future research in RL.	O	O	Review	451
[line_break_token]	O	O	Review	451
hank you for taking the time to read the paper and for your comments	O	O	Reply	451

This paper proposes a recurrent neural network for visual question answering.	O	O	Review	462
The recurrent neural network is equipped with a carefully designed recurrent unit called MAC (Memory, Attention and Control) cell, which encourages sequential reasoning by restraining interaction between inputs and its hidden states.	O	O	Review	462
The proposed model shows the state-of-the-art performance on CLEVR and CLEVR-Humans dataset, which are standard benchmarks for visual reasoning problem.	O	O	Review	462
Additional experiments with limited training data shows the data efficiency of the model, which supports its strong generalization ability.	O	O	Review	462
[line_break_token][line_break_token]The proposed model in this paper is designed with reasonable motivations and shows strong experimental results in terms of overall accuracy and the data efficiency.	O	O	Review	462
However, an issue in the writing, usage of external component and lack of experimental justification of the design choices hinder the clear understanding of the proposed model.	O	O	Review	462
[line_break_token][line_break_token]An issue in the writing[line_break_token]Overall, the paper is well written and easy to understand, but Section 3.2.3 (The Write Unit) has contradictory statements about their implementation.	B-Review	B-1	Review	462
Specifically, they proposed three different ways to update the memory (simple update, self attention and memory gate), but it is not clear which method is used in the end.	I-Review	I-1	Review	462
[line_break_token][line_break_token]Usage of external component[line_break_token]The proposed model uses pretrained word vectors called GloVE, which has boosted the performance on visual question answering.	B-Review	B-2	Review	462
This experimental setting makes fair comparison with the previous works difficult as the pre-trained word vectors are not used for the previous works.	I-Review	I-2	Review	462
To isolate the strength of the proposed reasoning module, I ask to provide experiments without pretrained word vectors.	I-Review	I-2	Review	462
[line_break_token][line_break_token]Lack of experimental justification of the design choices[line_break_token]The proposed recurrent unit contains various design choices such as separation of three different units (control unit, read unit and memory unit), attention based input processing and different memory updates stem from different motivations.	B-Review	B-3	Review	462
However, these design choices are not justified well because there is neither ablation study nor visualization of internal states.	I-Review	I-3	Review	462
Any analysis or empirical study on these design choices is necessary to understand the characteristics of the model.	I-Review	I-3	Review	462
Here, I suggest to provide few visualizations of attention weights and ablation study that could support indispensability of the design choices.	I-Review	I-3	Review	462
[line_break_token]	O	O	Review	462
[line_break_token]Thank you very much for your review - we truly appreciate it!	O	O	Reply	462
[line_break_token]We have uploaded a revision (by the rebuttal deadline, jan 5) that addresses all your comments:[line_break_token][line_break_token]1.	O	O	Reply	462
We have revised the description of the writing unit to make it more clear - we have experimented with several variants for this unit - the "standard" one (for which all the results are about), and 3 variants: a. with self-attention, b. with gating, and c. with both self-attention and gating.	B-Reply	B-1	Reply	462
In the ablations study section we have included results for each of these for the whole dataset, 10% of the dataset and also showed training curves for each variant.	I-Reply	I-1	Reply	462
[line_break_token][line_break_token]2.	O	O	Reply	462
We have trained the models without GloVE and added these results along with clarification to the experiments section.	B-Reply	B-2	Reply	462
[line_break_token][line_break_token]3.	B-Reply	B-3	Reply	462
We have included ablation studies in order to justify the architecture design choices and elucidate their impact.	I-Reply	I-3	Reply	462
We have also added visualizations of attention weights for several examples and discussed them.	I-Reply	I-3	Reply	462
[line_break_token][line_break_token]Thanks a lot again for your review!	O	O	Reply	462
[line_break_token]- Paper858 Author	O	O	Reply	462

The paper is well-written with a few figures to illustrate the ideas and components of the proposed method.	O	O	Review	1646
However, one of the main components in the proposed method is based on Tulsiani et al CVPR'18.	B-Review	B-1	Review	1646
The remaining components of the proposed method are not very new.	I-Review	I-1	Review	1646
Hence, I am not very sure whether the novelty of the paper is significant.	I-Review	I-1	Review	1646
Nevertheless, the performance of the proposed method is fairly good outperforming all baseline methods.	O	O	Review	1646
[line_break_token]I also have a few questions:[line_break_token]1.	O	O	Review	1646
How did you get the instance boxes, union boxes, and binary masks in testing?	B-Review	B-2	Review	1646
[line_break_token]2.	O	O	Review	1646
What are the training and inference time?	B-Review	B-3	Review	1646
We are grateful for your feedback.	O	O	Reply	1646
We hope that the above discussion assuaged the reviewer‚Äôs concerns regarding novelty and some unclear details.	O	O	Reply	1646
We briefly address the two questions regarding the setup:[line_break_token][line_break_token]During testing, in the setting with known GT boxes (Sec 4.2), we assume that the 2D instance boxes are given.	B-Reply	B-2	Reply	1646
In the detection setting, the 2D instance boxes are the result of the learned detector.	I-Reply	I-2	Reply	1646
Given the (detected or known) instance boxes, the union boxes and binary masks can be easily computed - the union box is just the larger box containing both instance boxes, and the mask highlights these instance boxes in the union box.	I-Reply	I-2	Reply	1646
[line_break_token]Training and Testing  Inference Time on a single GPU (Maxwell Titan X)[line_break_token]1.	B-Reply	B-3	Reply	1646
Train time: 65 hrs[line_break_token]2.	I-Reply	I-3	Reply	1646
Test time: 0.55s per image	I-Reply	I-3	Reply	1646

--------------[line_break_token]Summary:[line_break_token]--------------[line_break_token]This paper presents a series of experiments on language emergence through referential games between two agents.	O	O	Review	329
They ground these experiments in both fully-specified symbolic worlds and through raw, entangled, visual	O	O	Review	329
[line_break_token]<review>[line_break_token]random chance of probe classifiers.	O	O	Reply	329
[line_break_token]</review>[line_break_token]When generating the dataset, we sample locations and floor colors from a continuous scale.	B-Reply	B-1	Reply	329
For the probe classifiers, we quantize location by clustering each coordinate in 5 clusters (and thus accuracy is reported by averaging the performance of the x and y probe classifiers with chance being at 20% for each co-ordinate) and floor colors in 3 clusters (with chance being at 33%).	I-Reply	I-1	Reply	329
We will include the chance levels in Table 4.	I-Reply	I-1	Reply	329
[line_break_token][line_break_token]<review>[line_break_token]Why not use cross-entropy loss for listener?	O	O	Reply	329
[line_break_token]</review>[line_break_token]We decided to train both agents via REINFORCE for symmetry.	B-Reply	B-2	Reply	329
Given the nature of the listener‚Äôs choice, we don‚Äôt anticipate full supervision to have an effect other than speeding up learning.	I-Reply	I-2	Reply	329
[line_break_token][line_break_token][line_break_token]<review>[line_break_token]What about message length?	O	O	Reply	329
[line_break_token]</review>[line_break_token]Without any explicit penalty on the length of the messages (Section 2), agents are not motivated to produce shorter messages (despite the fact that as the reviewer points, agents can decide to do so) since this constrains the space of messages (and thus the possibility of the speaker and listener agreeing on a successful naming convention).	B-Reply	B-3	Reply	329
When we introduced a penalty on the length of the message (Section 3), agents produced shorter messages for the ambiguous messages (since this strategy maximizes the total expected reward).	I-Reply	I-3	Reply	329
[line_break_token][line_break_token]<review>[line_break_token]Why use reinforcement learning over some sort of differentiable sampler?	O	O	Reply	329
[line_break_token]</review>[line_break_token]While a differentiable communication channel would make learning faster, it goes against the basic and fundamental principles of human communication (and also against how this phenomenon is studied in language evolution).	B-Reply	B-4	Reply	329
 Simply put, having a differentiable channel would mean in practice that speakers can back-propagate through listeners‚Äô brains (which unfortunately is not the case in real life :)) We wanted to stay as close as possible to this communication paradigm, thus using a discrete communication channel	I-Reply	I-4	Reply	329

The authors propose a model that learns to play the China Competitive Poker game.	O	O	Review	1552
The model uses CNN to predict the actions, and is trained from actual human game records.	O	O	Review	1552
The model is shown to beat the current best AI and human amateur players.	O	O	Review	1552
[line_break_token][line_break_token]The performance is certainly strong (if it were true).	O	O	Review	1552
But given the double-blinded policy, there is literally no way to verify the correctness of the performance---in other words, the paper is currently not reproducible at all.	B-Review	B-1	Review	1552
So the following comments are based on the trust-worthiness of the paper.	O	O	Review	1552
[line_break_token][line_break_token](1) immature writing: The writing lacks formality and looks like a final project report.	B-Review	B-2	Review	1552
For instance, the super-short Section 2 is rather unprofessional---it is hard to believe that the related works can be described within two paragraphs anyway.	I-Review	I-2	Review	1552
Even as someone who understands the game of China Competitive Poker, I find it very hard to follow Section 3.	I-Review	I-2	Review	1552
There is a big room for improving the English writing.	I-Review	I-2	Review	1552
[line_break_token][line_break_token](2) ill-illustrated specialty of the model: In particular, it is not clear why the model should be superior than other modeling choices.	B-Review	B-3	Review	1552
For instance, what role does the neighboring connections of CNNs play?	I-Review	I-3	Review	1552
What are the cons and pros of choosing CNNs?	I-Review	I-3	Review	1552
Are there strong motivations to design the model this way?	I-Review	I-3	Review	1552
[line_break_token][line_break_token](3) many unanswered mysteries: why does the model trained with human records readily super-human?	B-Review	B-4	Review	1552
Note that this is controversial to common imitation learning where the typical performance is bound by the human-level performance.	I-Review	I-4	Review	1552
Even though authors claimed in the response that there are "many professional records"---but how many is many?	I-Review	I-4	Review	1552
Did the authors analyze the records and separate the professional versus amateur ones?	I-Review	I-4	Review	1552
Thanks for your review.	O	O	Reply	1552
[line_break_token][line_break_token](1)in other words, the paper is currently not reproducible at all.	O	O	Reply	1552
So the following comments are based on the trust-worthiness of the paper.	O	O	Reply	1552
[line_break_token][line_break_token]We will offer a online interface to public, it will return a action when you sent cards and game process.	B-Reply	B-1	Reply	1552
You can test the model as you wish.	I-Reply	I-1	Reply	1552
It will take a few days to prepare I think.	I-Reply	I-1	Reply	1552
And, I can offer the video of test match (all 10 games) and public email addresses of four top amateur players, you can check with them.	I-Reply	I-1	Reply	1552
[line_break_token][line_break_token](2)immature writing: The writing lacks formality and looks like a final project report.	O	O	Reply	1552
For instance, the super-short Section 2 is rather unprofessional---it is hard to believe that the related works can be described within two paragraphs anyway.	O	O	Reply	1552
Even as someone who understands the game of China Competitive Poker, I find it very hard to follow Section 3.	O	O	Reply	1552
There is a big room for improving the English writing.	O	O	Reply	1552
[line_break_token][line_break_token]I am really sorry about it.	B-Reply	B-2	Reply	1552
I will continue to optimize the paper and improve English.	I-Reply	I-2	Reply	1552
[line_break_token][line_break_token](3)ill-illustrated specialty of the model: In particular, it is not clear why the model should be superior than other modeling choices.	O	O	Reply	1552
For instance, what role does the neighboring connections of CNNs play?	O	O	Reply	1552
What are the cons and pros of choosing CNNs?	O	O	Reply	1552
Are there strong motivations to design the model this way?	O	O	Reply	1552
[line_break_token][line_break_token]The following is the reason written in the paper:[line_break_token][line_break_token]We choose CNN to solve the problem in CCP due to the following reasons: First, CNN has achieved superhuman performance in perfect information games.	B-Reply	B-3	Reply	1552
Second, there is semi-translational invariance in CCP, e.g. there are two sets of cards in the same category but with different ranks (like ‚Äú34567‚Äù and ‚Äú45678‚Äù, see more information in section 3), if we add each card‚Äôs rank, ‚Äú34567‚Äù become ‚Äú45678‚Äù, this is translational invariance.	I-Reply	I-3	Reply	1552
The player can play out ‚Äú45678‚Äù after another one played out ‚Äú34567‚Äù, but it is illegal if we swap the order, this is the reason for ‚Äúsemi‚Äù.	I-Reply	I-3	Reply	1552
[line_break_token][line_break_token]Besides X-axis, I think there is translation invariance in Z-axis also.	I-Reply	I-3	Reply	1552
CNN can get good performance dealing with translation invariance.	I-Reply	I-3	Reply	1552
[line_break_token][line_break_token](4)many unanswered mysteries: why does the model trained with human records readily super-human?	O	O	Reply	1552
Note that this is controversial to common imitation learning where the typical performance is bound by the human-level performance.	O	O	Reply	1552
Even though authors claimed in the response that there are "many professional records"---but how many is many?	O	O	Reply	1552
Did the authors analyze the records and separate the professional versus amateur ones?	O	O	Reply	1552
[line_break_token][line_break_token]First, many authors proved that the neural network can get the top amateur level in games just by supervised learning, like Chris J. Maddison‚Äôs paper ‚ÄúMOVE EVALUATION IN GO USING DEEP CONVOLUTIONAL NEURAL NETWORKS‚Äù showed: ‚ÄúWe train a large 12-layer convolutional neural network by supervised learning from a database of human professional games.	B-Reply	B-4	Reply	1552
The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player.	I-Reply	I-4	Reply	1552
‚Äù 6 dan is top level in amateur players.	I-Reply	I-4	Reply	1552
Deepmind got similar conclusion in their paper.	I-Reply	I-4	Reply	1552
[line_break_token][line_break_token]Second, compared to Go, there are seldom professional players in the strict sense in CCP.	I-Reply	I-4	Reply	1552
It is not a full time job for "CCP professional players", because players can not get enough money in CCP match.	I-Reply	I-4	Reply	1552
Maybe "semi-professional player" is more suitable, but they are really top players than others.	I-Reply	I-4	Reply	1552
As I said in previous reply, game records came from online platform.	I-Reply	I-4	Reply	1552
Players only need to offer a cellphone number or a tencent account to online platform.	I-Reply	I-4	Reply	1552
I think it is really very hard to distinguish just by them.	I-Reply	I-4	Reply	1552
many online platforms support for visitors to log in	I-Reply	I-4	Reply	1552

The paper is interesting and I like it.	O	O	Review	191
I draws parallels from biological learning and the well known critical learning phases in biological systems to artificial neural network learning.	O	O	Review	191
[line_break_token]A series of empirical simulation experiments that all aim to disturb the learning process of the DNN and to artificially create criticality are presented.	O	O	Review	191
They are providing food for thought, in order to introduce some quantitative results, the authors use well known Fisher Information to measure the changes.	O	O	Review	191
So far so good and interesting.	O	O	Review	191
[line_break_token]I was disappointed to see Tishby's result (2017) only remotely discussed, an earlier work than the one by Tishby is by Montavon et al 2011 in JMLR.	B-Review	B-1	Review	191
Also in this work properties of successive compression and dimensionality reduction are discussed, perhaps the starting point of quantitative analysis of various DNNs.	I-Review	I-1	Review	191
[line_break_token][line_break_token]To this point the paper presents no theoretical contribution, rather empirical findings only, that may or may not be ubiquitous in DNN learning systems.	B-Review	B-2	Review	191
The latter point may be worthwhile to discuss and analyse.	I-Review	I-2	Review	191
[line_break_token]Overall, the paper is interesting with its nice empirical studies but stays somewhat superficial.	I-Review	I-2	Review	191
To learn more a simpler toy model may be worthwhile to study.	B-Review	B-3	Review	191
[line_break_token][line_break_token]	O	O	Review	191
We thank the reviewer for their feedback and suggestions.	O	O	Reply	191
We have updated the paper accordingly, and address some of the points more in detail below:[line_break_token][line_break_token]> I was disappointed to see Tishby's result (2017) only remotely discussed, an earlier work than the one by Tishby is by Montavon et al 2011 in JMLR.	O	O	Reply	191
Also in this work properties of successive compression and dimensionality reduction are discussed, perhaps the starting point of quantitative analysis of various DNNs.	O	O	Reply	191
[line_break_token][line_break_token]We preferred not to elaborate at length on the connections with Schwartz and Tishby's results, since the relationship between the FIM of the weights (which we use in our paper) and the Shannon information of the activations, used by Tishby, is non-trivial and has already been discussed in more detail by other authors.	B-Reply	B-1	Reply	191
However, given how important this aspect is and since it has also been discussed by the other reviewers, we have included in the revised version an extended discussion on it, which hopefully will also make the manuscript more self-contained.	I-Reply	I-1	Reply	191
[line_break_token][line_break_token]Concerning Montavon's paper, that is indeed our miss; we have added the paper to the revised discussion, and thank the reviewer for pointing it out.	I-Reply	I-1	Reply	191
[line_break_token][line_break_token]> To this point the paper presents no theoretical contribution, rather empirical findings only, that may or may not be ubiquitous in DNN learning systems.	O	O	Reply	191
The latter point may be worthwhile to discuss and analyse.	O	O	Reply	191
[line_break_token]Overall, the paper is interesting with its nice empirical studies but stays somewhat superficial.	O	O	Reply	191
[line_break_token][line_break_token]The empirical findings are observed across the most commonly used architectures and optimization algorithms, as we also confirm with the new experiments in Fig.	B-Reply	B-2	Reply	191
3.	I-Reply	I-2	Reply	191
But it is true that it will take much more experimentation to assess whether they are truly ubiquitous and how they may affect different kinds of data.	I-Reply	I-2	Reply	191
On the theoretical side, the analysis of the transient, irreversible, properties of the learning process using the Fisher information in the weights is not only novel, but also different from other theoretical analyses, such as the study of flat minima, which focuses on the asymptotic behavior of the optimization (see the last paragraph of the Discussion).	I-Reply	I-2	Reply	191
In particular, our analysis suggests that crossing bottlenecks in the loss landscape, as opposed to convergence to critical points, may play a fundamental role in characterizing the final behavior of the network.	I-Reply	I-2	Reply	191
This aspect has, until now, been largely ignored and we are hopeful it may be fruitfully integrated in the current understanding of deep networks using, for example, tools from non-equilibrium dynamics, where such studies are common.	I-Reply	I-2	Reply	191
[line_break_token][line_break_token]Although we agree on the need for an analytical model, we tried to avoid the pitfalls of prematurely settling on a particular abstraction of the problem in order to paint a clearer picture, both through empirical experiments and by establishing connections with the most recent theories in deep learning, and yet providing a novel approach where the Fisher Information becomes one of the central quantities to consider.	I-Reply	I-2	Reply	191
[line_break_token][line_break_token]> To learn more a simpler toy model may be worthwhile to study.	O	O	Reply	191
[line_break_token][line_break_token]We fully agree.	B-Reply	B-3	Reply	191
In this paper, we focused on testing our hypotheses on current state-of-the-art models and relatively complex datasets, in order to understand what are the key aspects that need to be captured by any simplified model.	I-Reply	I-3	Reply	191
Now that this is established, and shown to be of practical relevance, given the widespread practice of fine-tuning, we can and will focus on simpler models that perhaps are also tractable analytically	I-Reply	I-3	Reply	191

This paper describes how to use Sum- and Maximum product networks for unsupervised feature learning and decoding and evaluate it within three different learning scenarios by either directly classifying a binary label set based on the original feature space, or by classifying the labels from generated feature encodings or decoding labels from their embedding.	O	O	Review	73
The authors further propose a full pipeline that produces feature embeddings and decodes them into the label space.	O	O	Review	73
[line_break_token][line_break_token]The paper alone is quite hard to comprehend and as a reader without prior knowledge in SPN/MPNs I had to consult a lot of literature, which however was provided sufficiently in the paper.	B-Review	B-1	Review	73
 The authors compare their method to state of the art approaches like RBMs and auto-encoders and show promising results in their framework.	I-Review	I-1	Review	73
Unfortunately the tasks were not described properly and again required to consult further literature.	I-Review	I-1	Review	73
I would recommend putting the evaluations partly into the appendix and to elaborate a little bit on that.	I-Review	I-1	Review	73
[line_break_token][line_break_token]Minor remarks:[line_break_token][line_break_token]- Typo in first sentence of section 3: usupervisedly[line_break_token]- The change in font size and face on emphasized words makes the general look of the text inconsistent and is quite uncommon	B-Review	B-2	Review	73
Dear reviewer,[line_break_token][line_break_token]thanks for your time reviewing our work and "imputing" the missing parts, we really appreciate it.	O	O	Reply	73
[line_break_token][line_break_token]We acknowledge that the current presentation omits several details about the experimental setting.	B-Reply	B-1	Reply	73
Therefore, we updated the paper by including an appendix comprising the full decoding procedure, some paragraphs about[line_break_token]training the models employed and finally more experimental results.	I-Reply	I-1	Reply	73
We also refactored the notation following your suggestions.	I-Reply	I-1	Reply	73
[line_break_token][line_break_token]Even if the time is running out, let us know if other modifications are required	O	O	Reply	73

Paper summary: [line_break_token]In this paper, the authors propose a general framework for multi-task learning (MTL) in neural models.	O	O	Review	634
The framework is general for including some of the current neural models for MTL.	O	O	Review	634
Under the framework, the author propose a new method that could allow tasks to communicate each other with explicit gradients.	O	O	Review	634
Based on the gradients being communicated, the system could adjust the updates of one task based on the gradient information of the other task.	O	O	Review	634
Also, prior task relatedness information could be incorporated to the system.	O	O	Review	634
[line_break_token][line_break_token]The idea of incorporating passing gradients among tasks seems very interesting, which is new as far as I am aware of.	O	O	Review	634
Although the idea is simple, but it seems intuitive since purely aggregating gradient updates might have undesired cancelling effects on each other.	O	O	Review	634
 [line_break_token][line_break_token]There are some questions I have about this method.	O	O	Review	634
[line_break_token]1.	O	O	Review	634
[tab_token]I‚Äôm curious about how the sequential update in pairwise task communication affects the performance.	B-Review	B-1	Review	634
[line_break_token]2.	O	O	Review	634
[tab_token]Also, how does sequential update nature of the method affect the training speed, as for now, the parameter update consists of two sequential steps which also involve changes to the traditional update rule.	B-Review	B-2	Review	634
[line_break_token]3.	O	O	Review	634
[tab_token]What is fast weight for and how it is used in (9)?	B-Review	B-3	Review	634
It would be better if there are more details on how the update is carried out during the gradient communication.	I-Review	I-3	Review	634
[line_break_token]4.	O	O	Review	634
[tab_token]Regarding the relatedness for List-wise communication, is it possible to update the relatedness dynamically?	B-Review	B-4	Review	634
Since the pre-computed relatedness might not always make sense.	I-Review	I-4	Review	634
During the learning of the representations, the task relatedness could change in the process.	I-Review	I-4	Review	634
[line_break_token]The system framework for MTL introduced by the authors seem to be kind of isolated to the method proposed.	B-Review	B-5	Review	634
I feel that the framework is not quite easy to understand from the way it is presented.	I-Review	I-5	Review	634
 From my perspective, the effectiveness of analyzing MTL methods using the framework seems a bit limited to me, as it serves more like a way of abstracting MTL models instead of analyzing it.	I-Review	I-5	Review	634
Therefore, I feel the content devoted to that part might be too much.	I-Review	I-5	Review	634
[line_break_token][line_break_token]Overall, I think the paper is interesting although the method itself is relatively simple.	O	O	Review	634
And the direction of utilizing gradient communication among tasks seem interesting and could be further explored.	O	O	Review	634
But I do feel the organization of the paper is a bit too heavy on the framework instead of the methodology proposed.	B-Review	B-6	Review	634
And more details of the algorithm proposed could be provided.	I-Review	I-6	Review	634
[line_break_token][line_break_token]On a side note, I think the paper exceeds the required length limit of 10 pages if appendices are counted towards it.	O	O	Review	634
[line_break_token]	O	O	Review	634
Thanks for your comments and the response of each point is listed below.	O	O	Reply	634
[line_break_token]      1.	O	O	Reply	634
 Both pairwise and listwise communication mechanisms are designed for addressing the inconsistent updating problem of shared parameters between different tasks.	B-Reply	B-1	Reply	634
The difference is that pairwise communication considers the updating consistency of parameter between two tasks, which is a relatively relaxed constraint. (	I-Reply	I-1	Reply	634
In the real scenario, there are features which can be shared partially).	I-Reply	I-1	Reply	634
[line_break_token]      2.	O	O	Reply	634
 Yes, explicitly passing gradients to different tasks will take additional time while the overall training processing is still very efficient.	B-Reply	B-2	Reply	634
 [line_break_token]      3.	O	O	Reply	634
 Here we choose a function without learnable parameters to compute the fast weight.	B-Reply	B-3	Reply	634
We have give more detailed formulation in our revised version.	I-Reply	I-3	Reply	634
[line_break_token]      4.	O	O	Reply	634
Yes, as we have also claimed in the paper, the relatedness can be computed in a static or dynamic way.	B-Reply	B-4	Reply	634
The question ‚Äúhow to choose weights for different tasks ?‚	I-Reply	I-4	Reply	634
Äù is a classic problem and pre-compute the task relatedness has been widely used in existing work.	I-Reply	I-4	Reply	634
Here, we don‚Äôt explore more about this to make our paper more focused.	I-Reply	I-4	Reply	634

The paper presents a Neural Network based method for learning ordinal embeddings only from triplet comparisons.	O	O	Review	152
[line_break_token]A nice, easy to read paper, with an original idea.	O	O	Review	152
[line_break_token][line_break_token]Still, there are some issues the authors should address:[line_break_token][line_break_token]- for the experiment with Imagenet images, it is not very clear how many pictures are used.	B-Review	B-1	Review	152
Is this number 2500?	I-Review	I-1	Review	152
[line_break_token]- the authors state that they use "the power of DNNs" while they are experimenting with a neural network with only 4 layers.	B-Review	B-2	Review	152
While there is no clear line between shallow and deep neural networks, I would argue that a 4 layer NN is rather shallow.	I-Review	I-2	Review	152
[line_break_token]- the authors fix the number of layers of the used network based on "our experience".	B-Review	B-3	Review	152
For the sake of completeness, more experiments in this area would be nice.	I-Review	I-3	Review	152
[line_break_token]- for Figure 6, there is not a clear conclusion.	B-Review	B-4	Review	152
While, it supports that " that logarithmic growth of the layer width respect to n is enough to obtain desirable performance."	I-Review	I-4	Review	152
 I don't see a clear conclusion of how to pick the width of hidden layers, maybe a better representation could be used.	I-Review	I-4	Review	152
[line_break_token]- I don't see a discussion about the downsides of the method (for example, the large number of triplet comparison examples needed for training; and possible methods to overcome this problem).	B-Review	B-5	Review	152
[line_break_token]- in section 4.4 when comparing the proposed approach with another methods why not use more complex datasets (like those used in section 4.3)[line_break_token]- in section 4.3, there is no guarantee that the intersection between the training set and test set is empty.	B-Review	B-6	Review	152
[line_break_token]- in section 4.3 how is the reconstruction built (Figure 3b)?	B-Review	B-8	Review	152
[line_break_token][line_break_token]A few typos found:[line_break_token]- In figure 3 (c) "number |T of input" should be  "number |T| of input"[line_break_token]- In figure 5 (a) "cencept" should be "concept"[line_break_token]- In figure 8 "Each column corresponds to ..." should be "Each row corresponds to ...".	B-Review	B-9	Review	152
[line_break_token]- In the last paragraph of A1 "growth of the layer width respect" should be "growth of the layer width with respect"[line_break_token]- In the second paragraph of A2 "hypothesize the that relation" should be "hypothesize that the relation".	I-Review	I-9	Review	152
[line_break_token]- In section 4.3 last paragraph, first sentence: "with the maximunm number" should be "with the maximum number"[line_break_token]	I-Review	I-9	Review	152
e thank the reviewer for the insightful comments.	O	O	Reply	152
We address the questions in the following:[line_break_token][line_break_token]- How many images did you have in the experiment?	O	O	Reply	152
[line_break_token][line_break_token]We had 7500 images in total.	B-Reply	B-1	Reply	152
We had 3 concept classes, and 2500 images for each concept.	I-Reply	I-1	Reply	152
We will mention the total number in the main text.	I-Reply	I-1	Reply	152
[line_break_token][line_break_token]- The proposed network is not deep, but shallow[line_break_token][line_break_token]We agree that a clear distinction line between shallow and deep networks does not exist.	B-Reply	B-2	Reply	152
So we will make a note on that issue.	I-Reply	I-2	Reply	152
[line_break_token][line_break_token]- More experiments on the number of layers [line_break_token][line_break_token]We had experimented with fewer layers.	B-Reply	B-3	Reply	152
We realized that in this case the width of the network should be increased to compensate for the representation power of the network.	I-Reply	I-3	Reply	152
As we already had an extensive set of experiments, we decided not to report that.	I-Reply	I-3	Reply	152
As the proposed architecture already performs well to solve the ordinal embedding problem, we found it unnecessary to try deeper networks.	I-Reply	I-3	Reply	152
[line_break_token][line_break_token]- "I don't see a clear conclusion of how to pick the width of hidden layers, maybe a better representation could be used."	O	O	Reply	152
[line_break_token][line_break_token]There exist three parameters in this experiment, which makes it hard to come up with the most conclusive representation.	B-Reply	B-4	Reply	152
We also generated line plots (multiple curves in one plot) and 3D mesh plots to show the dependency.	I-Reply	I-4	Reply	152
In the end, we found the heat-map more informative.	I-Reply	I-4	Reply	152
In the revision, we will add the other plots to support the claim.	I-Reply	I-4	Reply	152
[line_break_token][line_break_token][line_break_token]- "I don't see a discussion about the downsides of the method"[line_break_token][line_break_token]One of the drawbacks is that our method needs GPUs, while the more traditional algorithms run on CPUs.	B-Reply	B-5	Reply	152
This can be of disadvantage if non-machine learning experts want to use our method.	I-Reply	I-5	Reply	152
However, this is the case for most recent ML methods based on neural nets.	I-Reply	I-5	Reply	152
[line_break_token][line_break_token]The number of required triplets is theoretically lower bounded by nd log n, and this is also being confirmed by our experiments (our algorithm, as well as our competitors, break down when they get fewer triplets).	I-Reply	I-5	Reply	152
Therefore, in a setting with passive triplet answers, and without extra information, it is impossible to overcome this problem.	I-Reply	I-5	Reply	152
[line_break_token][line_break_token]- "in section 4.4 when comparing the proposed approach with another method why not use more complex datasets (like those used in section 4.3)"[line_break_token][line_break_token]Independent of the dataset complexity, provided with enough triplet answers, all methods can yield less than 5% triplet error.	B-Reply	B-6	Reply	152
However, the computation time is significantly lower for our proposed method.	I-Reply	I-6	Reply	152
Due to the iterative nature of all algorithms, the computation time does not depend on the data distribution, but on the number of input points.	I-Reply	I-6	Reply	152
Thus, a simple uniform dataset could serve to show our intention in this section.	I-Reply	I-6	Reply	152
[line_break_token][line_break_token]- "in section 4.3, there is no guarantee that the intersection between the training set and the test set is empty."	O	O	Reply	152
[line_break_token][line_break_token]Yes, in theory that is true, but in practice this is negligible: the total number of possible triplets is about 10^9.	B-Reply	B-7	Reply	152
So the likelihood that two sets of size 1000 intersect is close to 0.	I-Reply	I-7	Reply	152
[line_break_token][line_break_token]- "in section 4.3 how is the reconstruction built (Figure 3b)?"	O	O	Reply	152
[line_break_token][line_break_token]Figure 3b is the exact output of the ordinal embedding in two dimensions.	B-Reply	B-8	Reply	152
The colors are the initial labels of the input items.	I-Reply	I-8	Reply	152
There are two or three labels assigned to demonstrate the quality of reconstruction.	I-Reply	I-8	Reply	152
Note that the ordinal embedding output is unique only up to isometric transforms.	I-Reply	I-8	Reply	152
In other words, every valid output is still valid with rotation, scaling and translation.	I-Reply	I-8	Reply	152
[line_break_token]	O	O	Reply	152

Overall the method proposed in this paper is simple but effective, and adequate experimental results are given to show its performance improvements.	O	O	Review	308
 However, the literature survey of this paper is not satisfactory.	O	O	Review	308
[line_break_token][line_break_token]1.	O	O	Review	308
To reduce model size, there are several different ways including efficient architecture design, parameter pruning, quantization, tensor decomposition and knowledge distillation.	B-Review	B-1	Review	308
The authors forgot to mention tensor decomposition and mixed it with efficient architecture design.	I-Review	I-1	Review	308
As for parameter pruning and quantization,  many important papers are missing.	I-Review	I-1	Review	308
[line_break_token][line_break_token]2.	O	O	Review	308
Utilizing the "soft targets" to transfer knowledge from teacher to student model is not first proposed by Hinton et al (2015).	B-Review	B-2	Review	308
To the best of my knowledge, it is first proposed in  [line_break_token]J. Li, R. Zhao, J.-T. Huang, Y. Gong, ‚ÄúLearning small-size DNN with output-distribution-based criteria,‚Äù Proc.	I-Review	I-2	Review	308
Interspeech-2014, pp.1910-1914.	I-Review	I-2	Review	308
[line_break_token][line_break_token]3.	O	O	Review	308
Leveraging back part of teacher model's guidance to improve student performance has been investigated by other researchers on OCR tasks in [line_break_token]Ding H, Chen K, Huo Q. Compressing CNN-DBLSTM models for OCR with teacher-student learning and Tucker decomposition[J]. Pattern Recognition, 2019, 96: 106957.	B-Review	B-3	Review	308
[line_break_token]They combine student's CNN with teacher's DBLSTM to learn better representations.	I-Review	I-3	Review	308
[line_break_token][line_break_token]In conclusion, I will give a weak reject currently, unless the authors improve their literature survey and modify their claims.	O	O	Review	308
[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Review	308
ear reviewer #2,[line_break_token][line_break_token]We would like to extend our sincere thanks to you for your constructive feedback.	O	O	Reply	308
We have modified our claims and improved our literature survey based on your comments.	O	O	Reply	308
Here are our responses to your major concerns.	O	O	Reply	308
[line_break_token][line_break_token]Q: To reduce model size, there are several different ways including efficient architecture design, parameter pruning, quantization, tensor decomposition and knowledge distillation.	O	O	Reply	308
The authors forgot to mention tensor decomposition and mixed it with efficient architecture design.	O	O	Reply	308
As for parameter pruning and quantization, many important papers are missing.	O	O	Reply	308
[line_break_token][line_break_token]A: We apologize for the unclear description in our ‚ÄúRelated Work‚Äù section and have improved the literature survey based on your suggestions in the updated version of our paper.	B-Reply	B-1	Reply	308
Due to the page limitation mentioned in ICLR submission instructions, some of the related works can only be described briefly in our article.	I-Reply	I-1	Reply	308
We hope to get your understanding.	I-Reply	I-1	Reply	308
[line_break_token][line_break_token]Q: Utilizing the "soft targets" to transfer knowledge from teacher to student model is not first proposed by Hinton et al (2015).	O	O	Reply	308
To the best of my knowledge, it is first proposed in J. Li, R. Zhao, J.-T. Huang, Y. Gong, ‚ÄúLearning small-size DNN with output-distribution-based criteria,‚Äù Proc.	O	O	Reply	308
Interspeech-2014, pp.1910-1914.	O	O	Reply	308
[line_break_token][line_break_token]A: In paper ‚ÄúLearning small-size DNN with output-distribution-based criteria‚Äù, authors took the KL divergence between the posterior probabilities produced by the softmax operation from student and teacher model as loss function for knowledge transfer.	B-Reply	B-2	Reply	308
Hinton et al (2015) improved the posterior probability from teacher network by employing the softmax function on the teacher logits with temperature T and called it as ‚Äúsoft target‚Äù.	I-Reply	I-2	Reply	308
The definition of ‚Äúsoft target‚Äù in our paper is the same as in Hinton‚Äôs.	I-Reply	I-2	Reply	308
In other knowledge transfer methods, such as FitNet, AT and FT, the definition of ‚Äúsoft target‚Äù is the same as ours.	I-Reply	I-2	Reply	308
We have cited the prior paper in the updated version.	I-Reply	I-2	Reply	308
[line_break_token][line_break_token]Q: Leveraging back part of teacher model's guidance to improve student performance has been investigated by other researchers on OCR tasks in Ding H, Chen K, Huo Q. Compressing CNN-DBLSTM models for OCR with teacher-student learning and Tucker decomposition[J]. Pattern Recognition, 2019, 96: 106957.	O	O	Reply	308
They combine student's CNN with teacher's DBLSTM to learn better representations.	O	O	Reply	308
[line_break_token][line_break_token]A: We are sorry for missing this paper in our literature survey.	B-Reply	B-3	Reply	308
However, our work started half a year ago, while this paper is published on July 7, 2019.	I-Reply	I-3	Reply	308
We have cited this paper in the updated version of our paper.	I-Reply	I-3	Reply	308
[line_break_token]In paper ‚ÄúCompressing CNN-DBLSTM models for OCR with teacher-student learning and Tucker decomposition‚Äù, authors employed a knowledge distillation method with DarkNet-DBLSTM as student network and VGG-DBLSTM as teacher network.	I-Reply	I-3	Reply	308
The DBLSTM modules of the student and teacher networks in this paper have same topology, so the student‚Äôs BLSTM and inner product layers can borrow parameters from the teacher‚Äôs counterparts during training and inference.	I-Reply	I-3	Reply	308
In contrast, the student networks in our proposed method do not take any part of teacher network for inference and the back part of the teacher network is only employed during the training process.	I-Reply	I-3	Reply	308
Therefore, our method can be generalized to situations where the student network and the teacher network have different structure.	I-Reply	I-3	Reply	308
Besides, our method can also be applied to different tasks, which has been confirmed through our experiments.	I-Reply	I-3	Reply	308
[line_break_token][line_break_token][line_break_token]Best regards,	O	O	Reply	308

Summary:  This paper analyzes and extends a recently proposed goodness-of-fit test based on typicality [Nalisnick et al ArXiv 2019].  Firstly, the authors give bounds on the type-II error of this test, showing it can be characterized as a function of KLD[q || p_true] where p is the true data generating process and q is an alternative generative process.	O	O	Review	20318
 The paper then shifts to the main contribution: an in-depth study of a Gaussian mixture simulation along with accompanying theoretical results.	O	O	Review	20318
 The simulation shows that maximum likelihood estimation (MLE)---due to it optimizing KLD[p_true || p_model]---does not penalize the model for placing probability in places not occupied by p_true.	O	O	Review	20318
 This means that while samples from p_true should fall within the model‚Äôs typical set, the model typical set may be broader than p_true‚Äôs.	O	O	Review	20318
 Table 1 makes this clear by showing that only 30-40% of samples from the model fall within the typical set of p_true.	O	O	Review	20318
 Yet &gt;93% of samples from p_true fall within the models‚Äô typical sets.	O	O	Review	20318
 The paper then makes the observation that the models do not have high overlap in their typical sets, and thus p_true‚Äôs typical set could be well approximated by the intersection of the various models‚Äô typical sets.	O	O	Review	20318
 Applying this procedure to the Gaussian mixture simulation, the authors observe that ~95% of samples drawn from the intersection of the ensemble fall within p_true‚Äôs typical set.	O	O	Review	20318
 Moreover, ~97% of samples from p_true are in the ensemble (intersection) typical set.	O	O	Review	20318
 The paper closes by proving that the diversity of the ensemble controls the overlap in their typical sets, and hence increasing diversity should only improve the approximation of p_true‚Äôs typical set.	O	O	Review	20318
            [line_break_token][line_break_token]____[line_break_token][line_break_token]Pros:  This paper contributes some interesting ideas to a recent topic of interest in the community---namely, that deep generative models assign high likelihood to out-of-distribution (OOD) data [Nalisnick et al ICLR 2019] and how should we address this problem if we are to use them for anomaly detection, model validation [Bishop, 1994], etc.	O	O	Review	20318
 This paper makes some careful distinctions between the true data process, the model, and the alternative distribution, which I have not seen done often in this literature.	O	O	Review	20318
 And while the mass-covering effect of MLE on the resulting model fit is well known, this paper is the first with which I am aware that translates that fact into a practical recommendation (i.e. their intersection method).	O	O	Review	20318
 Furthermore, this connection to ensembling may provide important theoretical grounding to other ensemble-based methods for OOD detection [Choi et al ArXiv 2019].   [line_break_token][line_break_token]____[line_break_token][line_break_token]Cons:  The primary deficiency in the paper is experimental.	B-Review	B-1	Review	20318
 While the text does make some compelling arguments in the Gaussian mixture simulations, some validation on real data must be provided.	I-Review	I-1	Review	20318
 Ideally experiments on CIFAR-10 vs SVHN (OOD) and FashionMNIST vs MNIST (OOD) should be reported as these data set pairings have become the benchmark cases in this line of literature.	I-Review	I-1	Review	20318
 [line_break_token][line_break_token]Besides the lack of experiments on real data, I find the paper‚Äôs material to be a bit disjointed and ununified.	B-Review	B-2	Review	20318
 For instance, Theorem 1 is never discussed again after it is presented in Section 2.1.	I-Review	I-2	Review	20318
 I thought for sure the presence of the KLD-term would be referenced again to relate the ensembling methodology back to the bound on the type-II error.	I-Review	I-2	Review	20318
 For another example, normalizing flows are discussed in Section 2.3 and the change-of-variables formula given in Equation 5.	I-Review	I-2	Review	20318
 However, normalizing flows are never mentioned again except in passing in the Related Work section.	I-Review	I-2	Review	20318
     [line_break_token][line_break_token]____[line_break_token][line_break_token]Final Evaluation:  While I find the paper to contain interesting ideas, it is too unfinished for me to recommend acceptance at this time.	O	O	Review	20318
 Experiments on real data must be included and the overall coherence of the draft improved.	B-Review	B-1	Review	20318
[line_break_token]	O	O	Review	20318
fter reading the two other reviews, it seems that all reviewers agree that the lack of non-toy experiments is a major deficiency in the paper.	B-Reply	B-3	Reply	20318
 I find R3 to be too harsh in claiming Eqs 3 and 4 are "wrong": the authors clearly show is approximated with samples in Eq 4.	I-Reply	I-3	Reply	20318
 I also disagree with R3 that the included experiment is "unclear".	I-Reply	I-3	Reply	20318
 Rather, I find its motivation and results easy to interpret (see my summary).	I-Reply	I-3	Reply	20318
 I mostly concur with R2's review except for its final conclusion.	I-Reply	I-3	Reply	20318
 The questions that R2 lists under 'cons' could indeed be answered with a more comprehensive and realistic set of experiments.	I-Reply	I-3	Reply	20318
 And until high-dimensional experiments are included, I leave my recommendation at "reject".	I-Reply	I-3	Reply	20318

[line_break_token]I am putting "weak accept" because I think the paper addresses an important problem (domain adaptation) and has an interesting approach.	O	O	Review	134
 As the other reviewers pointed out, it's maybe not *super* novel.	O	O	Review	134
 But it's still interesting, and pretty readable for the most part.	O	O	Review	134
 [line_break_token][line_break_token]I do question the statistical significance of the TIMIT experiments: TIMIT has a very tiny test set to start with, and by focusing on the female portion only you are further reducing the amount.	B-Review	B-1	Review	134
[line_break_token][line_break_token]Small point: I don't think GANs are technically nonparametric, as the neural nets do have parameters.	B-Review	B-2	Review	134
[line_break_token][line_break_token]I am a little skeptical that this method would have as general applicability or usefulness as the authors seem to think.	B-Review	B-3	Review	134
 The reason is that, since the cycle constraint no longer exists, there is nothing to stop the network from just figuring out the class label of the input (say) image, and treating all the rest of the  information in that image as noise the same way a regular non-cyclic GAN would treat it.	I-Review	I-3	Review	134
 Of course, one wouldn't expect a convolutional network to behave like this, but in theory it could happen in general cases.	I-Review	I-3	Review	134
 This is just speculation though.	I-Review	I-3	Review	134
 Personally I would have tended to accept the paper, but I'm not going to argue with the other reviewers, who are probably more familiar with GAN literature than me.	I-Review	I-3	Review	134
[line_break_token][line_break_token]--[line_break_token]I am changing from "marginally above acceptance threshold" to "clear accept" after reading the response and thinking about the paper a bit more.	B-Review	B-4	Review	134
 I acknowledge that the difference from previously published methods is not that large, but I still think it has value as it's getting quite close to being a practical method for generating fake training data for speech recognition.	I-Review	I-4	Review	134
[line_break_token]	O	O	Review	134
- Comment on ‚Äústatistical significance on TIMIT experiments‚Äù:[line_break_token]We have chosen TIMIT dataset because of its inherent low-resource domain for different genders.	B-Reply	B-1	Reply	134
As shown in Table 3, when using only Male speech for training the network, testing on female	I-Reply	I-1	Reply	134

Authors have introduced a new type of adversarial attacks that perturb abstract features of the image.	O	O	Review	20331
They have shown that pixel space adversarial attack detection and defense techniques are ineffective in guarding against feature space attacks.	O	O	Review	20331
[line_break_token][line_break_token]I have some concerns about the novelty of the attack and the appropriateness of defenses that have been tested.	B-Review	B-1	Review	20331
[line_break_token][line_break_token]- Since the attack is done in the feature space, the defense should also be done in the feature space.	B-Review	B-2	Review	20331
For example, adversarial training or smoothing can be done in the feature space.	I-Review	I-2	Review	20331
See: <a href="https://arxiv.org/abs/1802.03471" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.03471</a>[line_break_token][line_break_token]- There are attacks that perturb colors or other interpretable features of the image that have not been mentioned in the paper.	B-Review	B-3	Review	20331
For example, see <a href="https://arxiv.org/abs/1804.00499" target="_blank" rel="nofollow">https://arxiv.org/abs/1804.00499</a> and <a href="https://arxiv.org/pdf/1906.00001" target="_blank" rel="nofollow">https://arxiv.org/pdf/1906.00001</a>[line_break_token][line_break_token]- If the decoder has a high Lipschitz constant, a small perturbation in the feature scape 'can' lead to a large and visible perturbation in the pixel space.	B-Review	B-4	Review	20331
It was not clear to me how this is being controlled in the current method.	I-Review	I-4	Review	20331
[line_break_token] 	B-Review	B-1	Review	20331
e thank for your constructive comments.	O	O	Reply	20331
Here we list your concerns and answer them one by one.	O	O	Reply	20331
[line_break_token][line_break_token]R2Q1: novelty[line_break_token]It is a novel way to conduct feature space attack with the combination of style transfer and manipulation of model internal embedding, as pointed out by Review #1.	B-Reply	B-1	Reply	20331
Common style transfer task requires additional information such as painting styles.	I-Reply	I-1	Reply	20331
In this paper, we instead use samples from the same class that share rich style features, which is not explored by existing work.	I-Reply	I-1	Reply	20331
We leverage these implicitly learned features to launch our feature-space attack, which distinguishes ours among various existing attack methods.	I-Reply	I-1	Reply	20331
[line_break_token]Unlike in [3], where a vanilla GAN-based attack method generates over a distribution of limited support, and has no control of the generated samples, our encoder-decoder based structure enables attacking each individual sample with controlled content and there is no limit on the number of samples, which is also mentioned in Review #3.	I-Reply	I-1	Reply	20331
[line_break_token]We also conducted an experiment that explores the defensive methods in different spaces.	I-Reply	I-1	Reply	20331
We observed that pixel-level defense is not effective against feature-space attack, and as we will show in the R2Q2 and R1Q3, existing defense that can be used in the feature space cannot defend our attack.	I-Reply	I-1	Reply	20331
[line_break_token][line_break_token]R2Q2: add Pixel-DP as possible feature space defense [line_break_token]We use the code provided by authors and the same setting to conduct experiments on Pixel-DP defense.	B-Reply	B-2	Reply	20331
When using l2 norm bound of 0.1, the model accuracy (with Pixel-DP defense) is 80% under PGD l2 attack and 0% under our feature space attacks.	I-Reply	I-2	Reply	20331
When using l2 norm bound of 1, the model accuracy (with Pixel-DP defense) is 31% under PGD l2 attack and 0% under ours.	I-Reply	I-2	Reply	20331
When further increasing l2 norm bound to 10, we found the accuracy on normal images degrades to below 15%.	I-Reply	I-2	Reply	20331
Pixel-DP is hence ineffective against our feature space attack.	I-Reply	I-2	Reply	20331
The results are reasonable as Pixel-DP can only certify the l_2 norm bound up to 1, whereas our feature space attack generates adversarial samples with l_2 norm usually larger than 10.	I-Reply	I-2	Reply	20331
[line_break_token]We have also conducted adversarial training experiments over pixel/feature spaces, which is shown in Table 4 in appendix.	I-Reply	I-2	Reply	20331
When the model is trained with one type of adversarial attacks, it can only achieve non-trivial accuracy on the same attack but is ineffective to other types of attacks.	I-Reply	I-2	Reply	20331
It is non-trivial to design an effective adversarial training that is robust to all types of adversarial attacks, and it is out of scope of this paper.	I-Reply	I-2	Reply	20331
[line_break_token][line_break_token]R2Q3: color space attacks[line_break_token]The paper [1] proposed to modify the HSV color space to generate adversarial samples, which transforms all pixels by a non-parametric function uniformly.	B-Reply	B-3	Reply	20331
 The experiments were only conducted on CIFAR-10 dataset and Madry model.	I-Reply	I-3	Reply	20331
Differently, feature space attack changes colors of specific objects or background alone and the transformation is learned from similar images, which is more imperceptible.	I-Reply	I-3	Reply	20331
 The paper [2] proposed to change the lighting condition and color similarly in [1] to generate adversarial samples.	I-Reply	I-3	Reply	20331
We observe in experiments that feature space attack also learns to modify lightning condition, color and texture as well, please refer to Fig.	I-Reply	I-3	Reply	20331
3.	B-Reply	B-1	Reply	20331
Compared to these, our attack is more general, and the features attacked are more subtle.	B-Reply	B-3	Reply	20331
We will include the discussion in the paper.	I-Reply	I-3	Reply	20331
[line_break_token][line_break_token]R2Q4: large and visible perturbation[line_break_token]Our Decoder is trained to minimize difference between the reconstructed image and the original image.	B-Reply	B-4	Reply	20331
We only modify the mean and variance of activations that are considered style of features [5], where the content of images is preserved.	I-Reply	I-4	Reply	20331
When launching attack, we bound the perturbation of mean and variance, which controls the perturbation introduced in the pixel space.	I-Reply	I-4	Reply	20331
Fig.	B-Reply	B-3	Reply	20331
3, Fig.	B-Reply	B-4	Reply	20331
5 and Fig.	I-Reply	I-4	Reply	20331
6 show the pixel/feature space distance of all the generated adversarial samples.	I-Reply	I-4	Reply	20331
It can be observed that our feature space attack has small feature space distance and even smaller than (pixel-space l_inf bounded) PGD attack in most cases.	I-Reply	I-4	Reply	20331
And we conducted an additional user study, suggesting feature space attack has comparable perceptual quality as PGD, please refer to R1Q1.	I-Reply	I-4	Reply	20331
[line_break_token][line_break_token][1] H. Hosseini, R. Poovendran.	O	O	Reply	20331
Semantic Adversarial Examples.	O	O	Reply	20331
<a href="https://arxiv.org/abs/1804.00499" target="_blank" rel="nofollow">https://arxiv.org/abs/1804.00499</a>[line_break_token][2] C. Laidlaw, S. Feizi.	O	O	Reply	20331
Functional Adversarial Attacks.	O	O	Reply	20331
<a href="https://arxiv.org/pdf/1906.00001" target="_blank" rel="nofollow">https://arxiv.org/pdf/1906.00001</a>[line_break_token][3] Y. Song, R. Shu, N. Kushman, S. Ermon.	O	O	Reply	20331
Constructing unrestricted adversarial examples with generative models.	O	O	Reply	20331
<a href="https://arxiv.org/abs/1805.07894" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.07894</a>[line_break_token][4] H. Hosseini, S. Kannan, R. Poovendran, Are Odds Really Odd?	O	O	Reply	20331
Bypassing Statistical Detection of Adversarial Examples.	O	O	Reply	20331
<a href="https://arxiv.org/pdf/1907.12138.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1907.12138.pdf</a>[line_break_token][5] L. A. Gatys, A. S. Ecker, and M. Bethge.	O	O	Reply	20331
Image style transfer using convolutional neural networks.	O	O	Reply	20331
In CVPR, 2016.	O	O	Reply	20331
[line_break_token][6] D. Ulyanov, A. Vedaldi, V. Lempitsky.	O	O	Reply	20331
Instance Normalization: The Missing Ingredient for Fast Stylization.	O	O	Reply	20331
<a href="https://arxiv.org/abs/1607.08022" target="_blank" rel="nofollow">https://arxiv.org/abs/1607.08022</a>[line_break_token][7] X. Huang and S. Belongie.	O	O	Reply	20331
Arbitrary style transfer in real-time with adaptive instance normalization.	O	O	Reply	20331

UPDATE: I think the authors' rebuttal and updated draft address my points sufficiently well for me to update my score and align myself with the other reviewers.	O	O	Review	537
[line_break_token][line_break_token]-----[line_break_token][line_break_token]ORIGINAL REVIEW: The paper proposes a method for learning post-hoc to condition a decoder-based generative model which was trained unconditionally.	O	O	Review	537
Starting from a VAE trained with an emphasis on good reconstructions (and at the expense of sample quality, via a small hard-coded standard deviation on the conditional p(x | z)), the authors propose to train two "critic" networks on the latent representation:[line_break_token][line_break_token]1.	O	O	Review	537
The "realism" critic receives either a sample z ~ q(z) (which is implicitly defined as the marginal of q(z | x) over all empirical samples) or a sample z ~ p(z) and must tell them apart.	O	O	Review	537
[line_break_token]2.	B-Review	B-2	Review	537
The "attribute" critic receives either a (latent code, attribute) pair from the dataset or a synthetic (latent code, attribute) pair (obtained by passing both the attribute and a prior sample z ~ p(z) through a generator) and must tell them apart.	O	O	Review	537
[line_break_token][line_break_token]The goal is to find a latent code which satisfies both the realism and the attribute-exhibiting criteria, subject to a regularization penalty that encourages it to stay close to its starting point.	O	O	Review	537
[line_break_token][line_break_token]It seems to me that the proposed realism constraint hinges exclusively on the ability to implictly capture the marginal distribution q(z) via a trained discriminator.	B-Review	B-1	Review	537
Because of that, any autoencoder could be used in conjunction with the realism constraint to obtain good-looking samples, including the identity encoder-decoder pair (in which case the problem reduces to generative adversarial training).	B-Review	B-2	Review	537
I fail to see why this observation is VAE-specific.	B-Review	B-3	Review	537
The authors do mention that the VAE semantics allow to provide some weak form of regularization on q(z) during training, but the way in which the choice of decoder standard deviation alters the shape of q(z) is not explained, and there is no justification for choosing one standard deviation value in particular.	B-Review	B-4	Review	537
[line_break_token][line_break_token]With that in mind, the fact that the generator mapping prior samples to "realistic" latent codes works is expected: if the VAE is trained in a way that encourages it to focus almost exclusively on reconstruction, then its prior p(z) and its marginal q(z) have almost nothing to do with each other, and it is more convenient to view the proposed method as a two-step procedure in which an autoencoder is first trained, and an appropriate prior on latent codes is then learned.	O	O	Review	537
In other words, the generator represents the true prior by definition.	O	O	Review	537
[line_break_token][line_break_token]The paper is also rather sparse in terms of comparison with existing work.	B-Review	B-5	Review	537
Table 1 does compare with Perarnau et al but as the caption mentions, the two methods are not directly comparable due to differences in attribute labels.	I-Review	I-5	Review	537
[line_break_token][line_break_token]Some additional comments:[line_break_token][line_break_token]- BiGAN [1] should be cited as concurrent work when citing (Dumoulin et al 2016).	B-Review	B-6	Review	537
[line_break_token]- [2] and [3] should be cited as concurrent work when citing (Ulyanov et al 2016).	I-Review	I-6	Review	537
[line_break_token][line_break_token]Overall, the relative lack of novelty and comparison with previous work make me hesitant to recommend the acceptance of this paper.	O	O	Review	537
[line_break_token][line_break_token]References:[line_break_token][line_break_token][1] Donahue, J., Kr√§henb√ºhl, P., and Darrell, T. (2017).	O	O	Review	537
Adversarial feature learning.	O	O	Review	537
In Proceedings of the International Conference on Learning Representations.	O	O	Review	537
[line_break_token][2] Li, C., and Wand, M. (2016).	O	O	Review	537
Precomputed real-time texture synthesis with markovian generative adversarial networks.	O	O	Review	537
In European Conference on Computer Vision.	O	O	Review	537
[line_break_token][3] Johnson, J., Alahi, A., and Fei-Fei, L. (2016).	O	O	Review	537
Perceptual losses for real-time style transfer and super-resolution.	O	O	Review	537
In European Conference on Computer Vision.	O	O	Review	537
Thank you for your time and insight in your review.	O	O	Reply	537
We've done our best to address your concerns with paper revisions and in the comments below:[line_break_token][line_break_token][line_break_token]> ‚Äùthe way in which the choice of decoder standard deviation alters the shape of q(z) is not explained, and there is no justification for choosing one standard deviation value in particular.	O	O	Reply	537
‚Äù[line_break_token][line_break_token]This was not made sufficiently clear in the original version.	B-Reply	B-3	Reply	537
We chose a standard deviation parameter of 0.1 because it maximizes the ELBO.	I-Reply	I-3	Reply	537
Using ELBO maximization as a hyperparameter selection scheme is a very natural and well-established practice (cf.	I-Reply	I-3	Reply	537
Bishop's 2006 Pattern Recognition and Machine Learning textbook, for example).	I-Reply	I-3	Reply	537
We have updated the text to highlight this and added Table 4 to the appendix, which shows the very significant improvement in ELBO from sigma=1.0 to sigma=0.1.	I-Reply	I-3	Reply	537
[line_break_token][line_break_token][line_break_token]> ‚Äúany autoencoder could be used in conjunction with the realism constraint to obtain good-looking samples‚Ä¶‚Äù[line_break_token][line_break_token]This is true enough, and worth emphasizing‚Äîour contributions are not specific to VAEs, but can be used to generate good-looking conditional samples from pretrained classical autoencoders.	B-Reply	B-1	Reply	537
We have added Figure 15 to the supplement, which explores what happens when the VAE‚Äôs sigma parameter goes to 0 (equivalent to a classical autoencoder).	I-Reply	I-1	Reply	537
We obtain reasonably good conditional samples with high-frequency spatial artifacts.	I-Reply	I-1	Reply	537
[line_break_token][line_break_token]We focused on VAEs rather than classical AEs both because they have natural sampling semantics and because they produced slightly better results.	I-Reply	I-1	Reply	537
We believe this is because the KL divergence term encourages q(z) to fill up as much of the latent space as possible (without sacrificing reconstruction quality).	I-Reply	I-1	Reply	537
This penalty encourages more of the latent space to map to reasonable-looking images.	I-Reply	I-1	Reply	537
[line_break_token][line_break_token][line_break_token]> ‚Äú...including the identity encoder-decoder pair (in which case the problem reduces to generative adversarial training).‚Äù[line_break_token][line_break_token]This is an interesting observation, and may be true for the simplest version of our approach (although the identity mapping would stretch the definition of ‚Äúlatent‚Äù space).	B-Reply	B-2	Reply	537
But it breaks down when we regularize the GAN to not move too far from the input z vector, which we found was essential to combat mode collapse and find identity-preserving transformations.	I-Reply	I-2	Reply	537
In that case, it is essential that Euclidean distance in latent space be more meaningful than distance in pixel space, making the identity ‚Äúautoencoder‚Äù a poor choice.	I-Reply	I-2	Reply	537
[line_break_token][line_break_token][line_break_token]> ‚Äúthe way in which the choice of decoder standard deviation alters the shape of q(z) is not explained‚Äù[line_break_token][line_break_token]Smaller standard deviations will lead to lower-variance posteriors, and therefore a more concentrated q(z).	B-Reply	B-4	Reply	537
This may not be obvious to all readers, so we updated the text to emphasize it, and added Supplemental Figure 16, which demonstrates the effect experimentally.	I-Reply	I-4	Reply	537
[line_break_token][line_break_token][line_break_token]> ‚ÄúThe paper is also rather sparse in terms of comparison with existing work.	O	O	Reply	537
Table 1 does compare with Perarnau et al but as the caption mentions, the two methods are not directly comparable due to differences in attribute labels.	O	O	Reply	537
‚Äù[line_break_token][line_break_token]We do our best to find work with which to compare, and match experimental conditions, however, there are not well established benchmarks for this type of task.	B-Reply	B-5	Reply	537
Unfortunately, Perarnau et al do not list the specific attributes that they selected as most salient, so an exact comparison is not possible.	I-Reply	I-5	Reply	537
We do our best to match conditions, and provide a list our 10 salient features in supplemental Table 3 for future comparison.	I-Reply	I-5	Reply	537
[line_break_token][line_break_token][line_break_token]> ‚Äú- BiGAN [1] should be cited as concurrent work when citing (Dumoulin et al 2016).	O	O	Reply	537
 [2] and [3] should be cited as concurrent work when citing (Ulyanov et al 2016).‚Äù[line_break_token][line_break_token]Thank you for bringing these citations to our attention.	B-Reply	B-6	Reply	537
They are indeed concurrent work with Dumoulin et al‚Äôs and Ulyanov et al‚Äôs work, and we have cited them as such.	I-Reply	I-6	Reply	537
[line_break_token]	O	O	Reply	537

This paper proposes fully unsupervised learning algorithm for speech recognition.	O	O	Review	240
It involves two alternating trained component, a phoneme classifier, and a boundary refining model.	O	O	Review	240
The experiment results demonstrate that it achieves first success on speech recognition that approaches the supervised learning performance.	O	O	Review	240
 [line_break_token][line_break_token]Pros:[line_break_token]+ The paper propose to use a frame-wise smoothing term J_FS added on J_ODM cost.	O	O	Review	240
In the new cost function, J_ODM controls the coarse-grained inter-segment distribution using a prepared language model P_LM, while J_FS controls the fine-grained intra-segment distribution.	O	O	Review	240
It is actually benefit to take use of this hierarchical 2-level scopes than only 1-level scope on evaluate the distribution mismatch in the cost function.	O	O	Review	240
Because otherwise, if only focus on fine-grained frame level,  much larger number of frame labels and longer N-gram have to be considered to evaluate the distribution of phoneme.	O	O	Review	240
Consequently, the computation can be exploding.	O	O	Review	240
[line_break_token]+ The proposed unsupervised phoneme classification method is superior to the baseline (Liu et al 2018) because the baseline relies on a clustering which is upper-bounded by cluster purity.	O	O	Review	240
Directly optimize on \theta using an end-to-end scheme is preferred.	O	O	Review	240
[line_break_token]+ I like the idea to use an iterative training algorithm to jointly improve classifier parameter \theta and segment boundaries b. [line_break_token]+ It is quite impressive that unsupervised learning system get close to performance of supervised system on speech recognition.	O	O	Review	240
The proposed system also outperforms state-of-the-art baseline with large margin.	O	O	Review	240
[line_break_token]+ The settings of experiments are rather comprehensive.	O	O	Review	240
Especially the ‚Äúnon-matching language model‚Äù, tests the case where language model cannot directly estimated from training set.	O	O	Review	240
 [line_break_token][line_break_token]Questions:[line_break_token]1.	O	O	Review	240
[tab_token]In Appendix B you mentioned that for the N-gram you choose N=5.	B-Review	B-1	Review	240
So the original language model P_LM can be a high-dim matrix with exactly 39^5 elements.	I-Review	I-1	Review	240
How sparse is the original P_LM?	I-Review	I-1	Review	240
It describes that 10000 elements are chosen, which are only 0.001%(=10000/39^5) of elements in the original one.	I-Review	I-1	Review	240
How representative are they?	I-Review	I-1	Review	240
[line_break_token][line_break_token]2.	O	O	Review	240
[tab_token]I notice for the balance weight of J_FS in (3), you empirically take the best \lambda=1e-5 during experiment.	B-Review	B-2	Review	240
To me, the scale of optimal \lambda is such small value maybe because the order of J_FS is improperly determined.	I-Review	I-2	Review	240
My suggestion is, could you try using square root on the current J_FS, or using standard deviation of intra-segment outputs.	I-Review	I-2	Review	240
The reasons are, first, minimizing std is a more interpretable penalty on diversion in a same segment; second, since you have used mean of outputs in J_ODM, then it is better to use a same dimension statistics, such as std of outputs in J_FS rather than sum of squared differences, when you combine J_ODM and J_FS in a uniform cost.	I-Review	I-2	Review	240
[line_break_token][line_break_token]3.	O	O	Review	240
[tab_token]What is the time complexity of running a comparable supervised speech recognition task with unsupervised learning method?	B-Review	B-3	Review	240
[line_break_token][line_break_token]Minor issues:[line_break_token]Maybe it is a typo that the second term of Eqn (2) should be ‚Äú-p_\theta(y_(t+1)=y|x_(t+1))‚Äù instead?	B-Review	B-4	Review	240
Since the p_\theta is defined as posterior probability of the frame label given the corresponding input.	I-Review	I-4	Review	240
[line_break_token]	O	O	Review	240
We thank the reviewer for the constructive feedback!	O	O	Reply	240
[line_break_token][line_break_token][Top-10000 of P_LM] We found that among the 48^5 elements in the P_LM only 69553 of them are non-zero.	B-Reply	B-1	Reply	240
We also found that the top 10000 elements of P_LM account for about 48.7% of the total probability in P_LM.	I-Reply	I-1	Reply	240
That is, this extremely small portion of the elements in P_LM occupy almost half of the total probability.	I-Reply	I-1	Reply	240
[line_break_token][line_break_token][Balance weight of J_FS] As suggested by the reviewer, we conducted experiments by taking the square root of J_FS and obtain results for different values of \lambda.	B-Reply	B-2	Reply	240
We found that the best value of \lambda becomes 1e-6, which is even smaller than the original value of 1e-5.	I-Reply	I-2	Reply	240
The possible reasons are explained below.	I-Reply	I-2	Reply	240
First, we observe that the value of J_FS is in fact much smaller than J_ODM  (e.g., 0.15 vs 6.21).	I-Reply	I-2	Reply	240
When taking the square root of J_FS, it becomes larger and we will need a smaller lambda to balance it.	I-Reply	I-2	Reply	240
Second, the reason that we do not need a large lambda for J_FS is that it mainly plays the role of regularization.	I-Reply	I-2	Reply	240
Ideally, if we sample all possible trajectories of \tau in (1) and match their predicted output distribution to P_LM, then the prediction within each segment would also be close to each other.	I-Reply	I-2	Reply	240
However, the number of all the possible trajectories \tau in S_1 x S_2 x ‚Ä¶ S_K is exponentially large, and we cannot sample all of them in our training.	I-Reply	I-2	Reply	240
Therefore, J_FS would play the role of a regularization that helps promote the consistency in the intro-segment predictions.	I-Reply	I-2	Reply	240
For this reason, the regularization term J_FS does not need to be too large in practice.	I-Reply	I-2	Reply	240
[line_break_token][line_break_token][Training time of unsupervised learning] In Figure 2(a), we show a learning curve of the validation error over training time when the segmentation is given by a supervised oracle.	B-Reply	B-3	Reply	240
We can see that the total training could be completed in about an hour, which is similar to supervised learning.	I-Reply	I-3	Reply	240
With unsupervised segmentation boundaries, it takes a longer time to converge, which is usually 4-5 hours.	I-Reply	I-3	Reply	240
[line_break_token][line_break_token][Typos and minor issues] We have fixed the typos in Eq (2).	B-Reply	B-4	Reply	240

The paper proposes a novel model that reads in information, decide whether this information is surprising and hence whether or not to keep it in memory and also utilizing information in the memory to quickly adapt or reason.	O	O	Review	222
The authors experimented with few-shot Omniglot classification and meta learning reasoning tasks.	O	O	Review	222
[line_break_token][line_break_token]Novelty:[line_break_token][line_break_token]The authors introduced a novel self-contained model that decides what to write to the external memory and making use of the external memory for different tasks.	O	O	Review	222
[line_break_token][line_break_token]My comments are mostly as follows: [line_break_token][line_break_token]1.	O	O	Review	222
The paper is well written, the problems are clearly stated, the solution is presented in a clear way, overall very easy to follow.	B-Review	B-1	Review	222
[line_break_token][line_break_token]2.	O	O	Review	222
This is an interesting paper that combines a novel technique for writing to external memory based on surprisal and using it for more difficult tasks such as deductive reasoning.	B-Review	B-2	Review	222
 I really like the surprisal mechanism, there are cognitive/ neuroscience materials that supports this approach (that the brain tends to write to memory things that are surprising).	I-Review	I-2	Review	222
This also makes total sense from a machine learning perspective.	I-Review	I-2	Review	222
[line_break_token][line_break_token]3.	O	O	Review	222
Could another objective  be used for surprisal?	B-Review	B-3	Review	222
Also, instead of a determinstic encoder, decoder, is it possible to use a variational objective?	I-Review	I-3	Review	222
[line_break_token][line_break_token]4.	O	O	Review	222
The experiments look convincing.	B-Review	B-4	Review	222
[line_break_token][line_break_token]Overall a very nice paper, nice idea, could show more resul	O	O	Review	222
Thanks a lot for your comments and suggestions.	O	O	Reply	222
In the following we address three of the points you raised:[line_break_token][line_break_token]1.	O	O	Reply	222
Alternative measure of surprise: We have added a discussion on this point as a general comment above.	B-Reply	B-1	Reply	222
[line_break_token][line_break_token]3.	O	O	Reply	222
Variational objective.	B-Reply	B-3	Reply	222
In this paper the main idea was to test the effectiveness of the memory controller mechanism coupled with a relational decoder.	I-Reply	I-3	Reply	222
It is definitely possible to adapt a variational objective in the architecture and it would be a very interesting avenue for future work.	I-Reply	I-3	Reply	222
Thank you for the suggestion.	I-Reply	I-3	Reply	222
[line_break_token][line_break_token]Additional experiments: as you suggested we have carried out more experiments to further consolidate our presentation of the model.	I-Reply	I-3	Reply	222
We have applied APL to a set of continual learning experiments suggested by reviewer 3 and show that APL performs en par with progressive networks.	I-Reply	I-3	Reply	222
These results are included the final version of the paper along with some pointers to the relevant literature.	I-Reply	I-3	Reply	222
[line_break_token][line_break_token]In light of the positive nature of your reviews we hope that these comments and the additional experiments can sway you to increase your rating of the paper.	I-Reply	I-3	Reply	222
[line_break_token]Thanks again for the useful comments	O	O	Reply	222

* Summary:[line_break_token]The paper introduces a novel tensor decomposition that is reminiscent of canonical decomposition (CP) with low-rank factors, based on the observation that the core tensor in Tucker decomposition can be decomposed, resulting in a model interpolating between CP and Tucker.	O	O	Review	414
The authors argue that a straight application of AdaGrad on this decomposition is inadequate, and propose Ada^{imp} algorithm that enforces rotation invariance of the gradient update.	O	O	Review	414
The new decomposition is applied to ComplEx model (called PComplEx) that demonstrates better performance than the baseline.	O	O	Review	414
[line_break_token][line_break_token]* Comments:[line_break_token]Although the approach is well motivated, the paper has many ambiguities that need to better clarification.	O	O	Review	414
[line_break_token]1.	O	O	Review	414
Tucker decomposition results in lower dimension factors, "d" in the paper.	B-Review	B-1	Review	414
So the resulting core tensor is of size (d \times d \times d).	I-Review	I-1	Review	414
However, this core tensor is further decomposed with a rank-D CP as shown in Section 3, where D &gt;= d. Basically, first the original tensor is factored into lower rank d, and the core tensor is then expanded into rank D &gt;= d. The reader did not understand what is the justification for this approach?	O	O	Review	414
Please provide further explanation on this part.	B-Review	B-1	Review	414
[line_break_token]2.	O	O	Review	414
The confusion of P_2 and P_3 terms in the paper.	B-Review	B-2	Review	414
At the beginning of Section 3, P_2 is assumed to be identity through out the paper.	I-Review	I-2	Review	414
But P_2 is mentioned to have specific attributes in other parts of the paper, such as in the second paragraph from the bottom of page 4, the first paragraph and first equation on page 5.	I-Review	I-2	Review	414
And P_2 does not appear in AdaGrad algorithm.	I-Review	I-2	Review	414
[line_break_token]3.	O	O	Review	414
The experiment is lacking.	B-Review	B-3	Review	414
First, the paper does not explain the meaning of evaluation metrics.	I-Review	I-3	Review	414
Second, the authors do not provide an insight, why PComplEx is better than the ComplEx baseline on SVO dataset, but performs similarly on other datasets.	I-Review	I-3	Review	414
Which factors lead to such improvement?	I-Review	I-3	Review	414
[line_break_token]4.	O	O	Review	414
The comparison to other state-of-the-arts is inadequate, each compared method only has one or few configurations in terms of number of parameters.	B-Review	B-4	Review	414
[line_break_token][line_break_token]Overall the proposed decomposition method might have significant contribution to research progress in this field, but the paper fails to convince the reader of its significance.	O	O	Review	414
I feel the paper should be overhauled.	O	O	Review	414
.	B-Reply	B-1	Reply	414
Tucker decomposition results in lower dimension factors, "d" in the paper.	O	O	Reply	414
So the resulting core tensor is of size (d \times d \times d).	O	O	Reply	414
However, this core tensor is further decomposed with a rank-D CP as shown in Section 3, where D &gt;= d. Basically, first the original tensor is factored into lower rank d, and the core tensor is then expanded into rank D &gt;= d. The reader did not understand what is the justification for this approach?	O	O	Reply	414
Please provide further explanation on this part.	O	O	Reply	414
[line_break_token][line_break_token]‚Üí We start from a tensor of size n x n x p. A Tucker decomposition of rank d leads to :[line_break_token]d x (n +n + p) parameters for the factors and d x d x d parameters for the core tensor.	B-Reply	B-1	Reply	414
[line_break_token]In order to link this decomposition with the CP decomposition which is easier to optimize, we further decompose this core tensor with a CP decomposition of rank D. Thus, d x d x d parameters become d x (D + D + D) (which is smaller than d x d x d as long as D &lt; d^2/3).	O	O	Reply	414
[line_break_token]We allow D &gt; d because a tensor of shape d x d x d can have a CP rank as high as d^2.	O	O	Reply	414
[line_break_token][line_break_token][line_break_token]2.	B-Reply	B-1	Reply	414
The confusion of P_2 and P_3 terms in the paper.	O	O	Reply	414
At the beginning of Section 3, P_2 is assumed to be identity through out the paper.	O	O	Reply	414
But P_2 is mentioned to have specific attributes in other parts of the paper, such as in the second paragraph from the bottom of page 4, the first paragraph and first equation on page 5.	O	O	Reply	414
And P_2 does not appear in AdaGrad algorithm.	O	O	Reply	414
[line_break_token]‚Üí There is indeed a confusion between P_2 and P_3 in the paper,  we thank the reviewer for pointing this out.	B-Reply	B-2	Reply	414
Since P_2 is assumed to be the identity, it should not appear in the paper outside of the definition of CPT (beginning of Section 3).	I-Reply	I-2	Reply	414
All further occurrences of P_2 are typos and have been fixed in the revision.	I-Reply	I-2	Reply	414
[line_break_token][line_break_token]3.	O	O	Reply	414
The experiment is lacking.	O	O	Reply	414
First, the paper does not explain the meaning of evaluation metrics.	O	O	Reply	414
Second, the authors do not provide an insight, why PComplEx is better than the ComplEx baseline on SVO dataset, but performs similarly on other datasets.	O	O	Reply	414
Which factors lead to such improvement?	O	O	Reply	414
[line_break_token]‚Üí Regarding evaluation metrics, we have added the definition of the mean reciprocal rank and hits@5% in Appendix 9.11.	B-Reply	B-3	Reply	414
We attribute the difference in performance on SVO to a difference in the underlying structure of the data that makes Tucker decomposition particularly suited.	I-Reply	I-3	Reply	414
Similarly to MurP being better on WN18RR than on FB237, it is possible that SVO is a dataset that is more amenable to a Tucker decomposition.	I-Reply	I-3	Reply	414
[line_break_token][line_break_token]4.The comparison to other state-of-the-arts is inadequate, each compared method only has one or few configurations in terms of number of parameters.	O	O	Reply	414
[line_break_token]‚Üí We performed new experiments.	B-Reply	B-4	Reply	414
Please, see the general comments.	I-Reply	I-4	Reply	414

This paper presents a generative sequence model based on the dilated CNN[line_break_token]popularized in models such as WaveNet.	O	O	Review	346
Inference is done via a hierarchical[line_break_token]variational approach based on the Variational Autoencoder (VAE).	O	O	Review	346
While VAE[line_break_token]approach has previously been applied to sequence modeling (I believe the[line_break_token]earliest being the VRNN of Chung et al (2015)), the innovation where is the[line_break_token]integration of a causal, dilated CNN in place of the more typical recurrent[line_break_token]neural network.	O	O	Review	346
[line_break_token][line_break_token]The potential advantages of the use of the CNN in place of[line_break_token]RNN is (1) faster training (through exploitation of parallel computing across[line_break_token]time-steps), and (2) potentially (arguably) better model performance.	O	O	Review	346
This[line_break_token]second point is argued from the empirical results shown in the[line_break_token]literature.	O	O	Review	346
The disadvantage of the CNN approach presented here is that[line_break_token]these models still need to generate one sample at a time and since they are[line_break_token]typically much deeper than the RNNs, sample generation can be quite a bit[line_break_token]slower.	B-Review	B-1	Review	346
[line_break_token][line_break_token]Novelty / Impact: This paper takes an existing model architecture (the[line_break_token]causal, dilated CNN) and applies it in the context of a variational[line_break_token]approach to sequence modeling.	O	O	Review	346
It's not clear to me that there are any[line_break_token]significant challenges that the authors overcame in reaching the proposed[line_break_token]method.	B-Review	B-2	Review	346
That said, it certainly useful for the community to know how the[line_break_token]model performs.	I-Review	I-2	Review	346
[line_break_token][line_break_token]Writing: Overall the writing is fairly good though I felt that the model[line_break_token]description could be made more clear by some streamlining -- with a single[line_break_token]pass through the generative model, inference model and learning.	B-Review	B-3	Review	346
[line_break_token][line_break_token]Experiments: The experiments demonstrate some evidence of the superiority[line_break_token]of this model structure over existing causal, RNN-based models.	O	O	Review	346
One point[line_break_token]that can be drawn from the results is that a dense architecture that uses multiple levels of the[line_break_token]latent variable hierarchy directly to compute the data likelihood is[line_break_token]quite effective.	O	O	Review	346
This observation doesn't really bear on the central message[line_break_token]of the paper regarding the use of causal, dilated CNNs.	B-Review	B-4	Review	346
[line_break_token][line_break_token]The evidence lower-bound of the STCN-dense model on MNIST is so good (low)[line_break_token]that it is rather suspicious.	O	O	Review	346
There are many ways to get a deceptively good[line_break_token]result in this task, and I wonder if all due care what taken.	B-Review	B-5	Review	346
In[line_break_token]particular, was the binarization of the MNIST training samples fixed in[line_break_token]advance (as is standard) or were they re-binarized throughout training?	I-Review	I-5	Review	346
[line_break_token][line_break_token]Detailed comments:[line_break_token]- The authors state "In contrast to related architectures (e.g. (Gulrajani et[line_break_token]al, 2016; Sonderby et al 2016)), the latent variables at the upper layers[line_break_token]capture information at long-range time scales" I believe that this is[line_break_token]incorrect in that the model proposed in at least Gulrajani et al also [line_break_token][line_break_token]- It also seems that there is an error in Figure 1 (left).	B-Review	B-6	Review	346
I don't think[line_break_token]there should be an arrow between z^{2}_{t,q} and z^{1}_{t,p}. The presence[line_break_token]of this link implies that the prior at time t would depend -- through[line_break_token]higher layers -- on the observation at t. This would no longer be a prior[line_break_token]at that point.	B-Review	B-7	Review	346
By extension you would also have a chain of dependencies[line_break_token]from future observations to past observations.	I-Review	I-7	Review	346
It seems like this issue is[line_break_token]isolated to this figure as the equations and the model descriptions are[line_break_token]consistent with an interpretation of the model without this arrow (and[line_break_token]including an arrow between z^{2}_{t,p} and z^{1}_{t,p}.[line_break_token][line_break_token]- The term "kla" appears in table 1, but it seems that it is otherwise not[line_break_token]defined.	B-Review	B-8	Review	346
I think this is the same term and meaning that appears in Goyal et[line_break_token]al. (	I-Review	I-8	Review	346
2017), but it should obviously be defined here.	I-Review	I-8	Review	346
[line_break_token]	O	O	Review	346
To better understand if the experimental improvements shown in our paper only stem from the hierarchical latent space or whether the synergy between the dilated CNNs and latent variable hierarchy is important, we ran additional experiments (as suggested by R1).	B-Reply	B-1	Reply	346
We replaced the deterministic TCN blocks with LSTM cells and kept the latent structure intact, dubbed RNNLadder.	I-Reply	I-1	Reply	346
We used TIMIT and IAM-OnDB for speech and handwriting datasets.	I-Reply	I-1	Reply	346
The log-likelihood performance measured by ELBO is provided below:[line_break_token][line_break_token]=======================================================[line_break_token]                                                                             TIMIT          IAM-OnDB  [line_break_token]=======================================================[line_break_token]  25x256-LadderRNN (Normal)                         28207             1305    [line_break_token]  25x256-LadderRNN-dense (Normal)             27413             1278    [line_break_token]=======================================================[line_break_token]  25x256-LadderRNN (GMM)                             24839             1381    [line_break_token]  25x256-LadderRNN-dense (GMM)                 26240             1377    [line_break_token]=======================================================[line_break_token]  5x512-LadderRNN (Normal)                           49770             1299    [line_break_token]  5x512-LadderRNN-dense (Normal)               48612             1374    [line_break_token]=======================================================[line_break_token]  5x512-LadderRNN (GMM)                               47179             1359    [line_break_token]  5x512-LadderRNN-dense (GMM)                   50113             1581    [line_break_token]=======================================================[line_break_token]  25x256-STCN (Normal)                                    64913             1327    [line_break_token]  25x256-STCN-dense (Normal)                        70294             1729    [line_break_token]=======================================================[line_break_token]  25x256-STCN (GMM)                                        69195             1339    [line_break_token]  25x256-STCN-dense (GMM)                            71386             1796    [line_break_token]=======================================================[line_break_token][line_break_token]Models in the table have similar number of trainable parameters.	B-Reply	B-5	Reply	346
The most direct translation of the the STCN architecture into an RNN counterpart has 25 stacked LSTM cells with 256 units each.	I-Reply	I-5	Reply	346
Similar to STCN, we use 5 stochastic layers.	I-Reply	I-5	Reply	346
Please note that stacking this many LSTM cells is unusual and resulted in instabilities during training.	I-Reply	I-5	Reply	346
The performance is similar to vanilla RNNs.	I-Reply	I-5	Reply	346
Hence, we didn‚Äôt observe a pattern of improvement with densely connected latent variables.	I-Reply	I-5	Reply	346
The second RNNLadder configuration uses 5 stacked LSTM cells with 512 units and a one-to-one mapping with the stochastic layers.	I-Reply	I-5	Reply	346
[line_break_token][line_break_token]This experiments show that the modular structure of our latent variable design does allow for the usage of different building blocks.	I-Reply	I-5	Reply	346
Even when attached to LSTM cells, it boosts the log-likelihood performance (see 5x512-LadderRNN), in particular when used with dense connections.	I-Reply	I-5	Reply	346
However, the empirical results suggest that the densely connected latent hierarchy interacts particularly well with dilated CNNs.	I-Reply	I-5	Reply	346
We believe this is due to the hierarchical nature in both sides of the architecture.	I-Reply	I-5	Reply	346
On both datasets STCN models achieved the best performance and presented significant improvements with the dense connections.	I-Reply	I-5	Reply	346
This supports our contribution of a latent variable hierarchy, which models different aspects of information from the input time-series.	I-Reply	I-5	Reply	346

This paper proposes an new 8-bit quantization strategy for rapid deployment.	O	O	Review	1092
[line_break_token][line_break_token]8-bit quantization has attracted many attentions recently.	O	O	Review	1092
And it is already well used in GPU servers (cudnn), phones, ARM chips and various ASIC neural network chips.	O	O	Review	1092
In these situations, almost no performance drop is observed for classification and detection tasks.	O	O	Review	1092
[line_break_token][line_break_token]So, the novelty of this paper is limited.	O	O	Review	1092
Thank you very much for your comments.	O	O	Reply	1092
Competing methods in other papers require retraining or needs to cope with high accuracy loss when quantized in a layer-wise fashion.	O	O	Reply	1092
The proposed method is the first of its kind to resolve these issues by incorporating channel-wise quantization and moment-analysis method which DOES NOT require retraining or the training dataset.	O	O	Reply	1092
Na√Øve channel-wise quantization requires adding huge number of HW shifters and providing values for them which make it unrealistic for implementation (please see Figure 1 (b) in the revised manuscript).	O	O	Reply	1092
The biggest contribution of our paper is the HW-friendly channel-wise quantization by manipulating the kernels prior to inference.	O	O	Reply	1092
For your reference, Figure 1 has been modified to make the distinction clearer	O	O	Reply	1092

The main contributions of the work are the new datasets and the overall integration of previous modeling tools in such a way that the final architecture is able to encode semantic spatial relations from textual descriptions.	O	O	Review	699
This is demonstrated by an implementation that, given textual descriptions, is able to render images from novel viewpoints.	O	O	Review	699
In terms of these two contributions, as I explain below, I believe there is space to improve the datasets and the paper needs further analysis/comments about the merits of the proposed approach.	O	O	Review	699
So my current overall rating is below acceptance level.	O	O	Review	699
[line_break_token][line_break_token]In terms of data, authors provide 2 new datasets: i) a large datasets (10M) with synthetic examples (images and descriptions) and ii) a small dataset (6k) with human textual descriptions corresponding to synthetic images.	O	O	Review	699
As the main evaluation method of the paper, the author include direct human evaluation of the resulting renderings (3 level qualitative evaluation: perfect-match/partial-match/no-match).	O	O	Review	699
I agree that, for this application, human evaluation is more adequate than comparing a pixel-level output with respect to a gold image.	B-Review	B-1	Review	699
In this sense, it is surprising that for the synthetic dataset the perfect match score of human evaluation for ground truth data is only 66%.	I-Review	I-1	Review	699
It will be good to increase this number providing a cleaning dataset.	I-Review	I-1	Review	699
[line_break_token][line_break_token]Related to the previous comment, it will be good to provide a deeper analysis about the loss function used to train the model.	B-Review	B-2	Review	699
  [line_break_token][line_break_token]In terms of the input data, it is not clear how the authors decide about the 10 views for each scene.	B-Review	B-3	Review	699
[line_break_token][line_break_token]In terms of the final model, if I understood correctly, the paper does not claim any contribution, they use a model presented in a previous work (actually information about the model is mostly included as a supplemental material).	B-Review	B-4	Review	699
If there are relevant contributions in terms of model integration and/or training scheme, it will be good to stress this in the text.	I-Review	I-4	Review	699
[line_break_token][line_break_token]Writing is correct, however, authors incorporate important details about the dataset generation process as well as the underlying model in the supplemental material.	B-Review	B-5	Review	699
Given that there is a page limit, I believe the relevant parts of the paper should be self-contain.	I-Review	I-5	Review	699
Thank you for the thorough review and insightful comments.	O	O	Reply	699
[line_break_token][line_break_token]> ‚ÄòIn this sense, it is surprising that for the synthetic dataset the perfect match score of human evaluation for ground truth data is only 66%.	O	O	Reply	699
It will be good to increase this number providing a cleaning dataset.	O	O	Reply	699
‚Äô For the synthetic dataset, the noise added by certain objects missing from the captions does not degrade the performance of the model - the model is *only* fed captions as input which means it can integrate the information of multiple captions to create a reconstruction of the scene, and it only reconstructs image pixels, which means it never sees that picture‚Äôs caption.	B-Reply	B-1	Reply	699
Therefore the imperfect match between pixels and text is an issue that only arises at [human] evaluation time.	I-Reply	I-1	Reply	699
Given the cost of cleaning up these captions, we believe the most practical course of action was to collect human evaluations with this mapping and keeping in mind that the gold truth sets an upper bound.	I-Reply	I-1	Reply	699
[line_break_token][line_break_token]> ‚Äòdeeper analysis about the loss function used to train the model.	O	O	Reply	699
‚Äô We use the loss function from previous work by Eslami et al (2018)--.	B-Reply	B-2	Reply	699
We have added more details to the model section in the main text and also provide a detailed description in Appendix section A.2.	I-Reply	I-2	Reply	699
[line_break_token][line_break_token]> ‚ÄòIn terms of the input data, it is not clear how the authors decide about the 10 views for each scene.	O	O	Reply	699
‚Äô For non-language related hyperparameters, we followed the choices in Eslami et.	B-Reply	B-3	Reply	699
al 2018.	I-Reply	I-3	Reply	699
Optimizing this hyperparameter choice is an interesting avenue to explore however we felt it was outside of the scope of this work.	I-Reply	I-3	Reply	699
[line_break_token][line_break_token]> ‚ÄòIf there are relevant contributions in terms of model integration and/or training scheme, it will be good to stress this in the text.	O	O	Reply	699
‚Äô  We have updated the text to explain the novel aspects of the model, which is the integration of language inputs, as well as dataset generation as much as possible.	B-Reply	B-4	Reply	699
In the appendix you can also find a detailed description of the model setup, hyperparameters, and dataset generation which did not fit into the main text.	I-Reply	I-4	Reply	699

The authors present a framework for symbolic superoptimization using methods from deep learning.	O	O	Review	113
A deep learning approach operating on the expression tree structures is proposed based on a combination of subtree embeddings, LSTM RNN structures, and an attention mechanism.	O	O	Review	113
[line_break_token][line_break_token]The approach avoids the exploitation of human-generated equivalence pairs thus avoiding human interaction and corresponding bias.	O	O	Review	113
Instead, the approach is trained using random generated data.	B-Review	B-1	Review	113
It remains somewhat unclear how the corresponding random data generation influences general applicability w.r.t.	I-Review	I-1	Review	113
other tasks, as the authors apply constraints on the generation process for complexity reasons.	I-Review	I-1	Review	113
A corresponding discussion would be valuable here.	I-Review	I-1	Review	113
[line_break_token][line_break_token]In Secs.	O	O	Review	113
3 &amp; 4, the authors present their specific modeling and learning approach.	O	O	Review	113
However, they do not report on modeling or learning alternatives.	B-Review	B-2	Review	113
It would be interesting for the audience to understand, how the authors reached these specific choices, and how (some of) these choice influence performance and learning stability.	I-Review	I-2	Review	113
For example, in Sec.	I-Review	I-2	Review	113
4.1, an additional loss term is introduced to further support the learning of embeddings.	I-Review	I-2	Review	113
However, it might interesting to see comparative results quantitatively investigating the effect of this additional loss term.	I-Review	I-2	Review	113
Also, as far as I can see, no information on the choice of hyperparameters (e.g. LSTM dimensions) are provided or analyzed w.r.t.	I-Review	I-2	Review	113
their effect on the performance of the proposed approach.	I-Review	I-2	Review	113
e have updated our paper.	O	O	Reply	113
Please refer to the thread ‚ÄúRevised Paper Uploaded‚Äù for a summary of major updates in our revision.	O	O	Reply	113
Following is a detailed response to Review #2 comments.	O	O	Reply	113
[line_break_token][line_break_token]1) Ablation studies.	O	O	Reply	113
[line_break_token]Our revised Appendix C introduces a set of ablation studies.	B-Reply	B-3	Reply	113
Specifically, figure 5 shows that the performance drops significantly if the subtree embedding similarity loss is removed.	I-Reply	I-3	Reply	113
In addition, appendix C.1 explores why the embedding similarity loss is important.	I-Reply	I-3	Reply	113
In short, this loss will provide a more concrete training signal to assist convergence, which is otherwise difficult due to REINFORCE.	I-Reply	I-3	Reply	113
In addition to the embedding similarity loss, the ablation studies also investigate the significance of the subtree selector and the tree-LSTM architecture.	I-Reply	I-3	Reply	113
For more details, please kindly refer to appendix C.[line_break_token][line_break_token]2) Hyperparameter settings.	O	O	Reply	113
[line_break_token]Our hyperparameters, including the LSTM dimensions, follow the common setting in previous works, without any explicit tuning.	B-Reply	B-2	Reply	113
Our revised Appendix A.3 describes our hyperparameter setting and our decision making in detail.	I-Reply	I-2	Reply	113
[line_break_token][line_break_token]3) How data generation affects performance.	O	O	Reply	113
[line_break_token]Our revised Section 5.1 and Appendix A.1 &amp; A.2 provide a detailed description of datasets preparation and use.	O	O	Reply	113
We use two datasets: (a) the ‚Äútraverse equivalence dataset‚Äù (mentioned by Review#3) is only used for stage-I training; (b) the benchmark dataset ‚ÄúHalide dataset‚Äù is used by the stage-II training.	B-Reply	B-1	Reply	113
The former dataset mainly contains short expressions under a depth of four; the goal is to assist the stage-II training to be performed on the latter dataset.	I-Reply	I-1	Reply	113
Therefore, It does not affect the performance that the traverse space is reduced when generating the dataset for complexity reasons.	I-Reply	I-1	Reply	113
Section 5.1 and Appendix A.1 &amp; A.2 describes more details about the datasets.	O	O	Reply	113

The paper presents video generation method with spacio-temporally consistent features.	O	O	Review	239
This is done through: a) temporal adversarial learning, b) Ping Pong loss, and c) metrics that quantify the quality.	O	O	Review	239
The methods are evaluated on two datasets and user studies.	O	O	Review	239
[line_break_token][line_break_token]The idea is interesting and the paper is well written.	O	O	Review	239
The results are convincing.	O	O	Review	239
[line_break_token][line_break_token]The originality of the concatenation of several frames is somewhat limited, since it is a standard procedure in other domains such as robotics.	B-Review	B-1	Review	239
Nevertheless the results are positive.	I-Review	I-1	Review	239
[line_break_token][line_break_token]Seems like the metrics definitions were not included in the main body of the paper - the authors should either include them to remove from the contributions.	B-Review	B-2	Review	239
ear reviewer, thank you very much for the review and suggestions.	O	O	Reply	239
[line_break_token][line_break_token]Q1: ‚Äúoriginality of the concatenation of several frames is somewhat limited‚Äù[line_break_token]A1: It is correct that such a concatenation is used in a variety of other settings.	B-Reply	B-1	Reply	239
The core aim of our work is to highlight its importance in a very challenging setting, i.e., for training spatio-temporal GANs for natural image sequences.	I-Reply	I-1	Reply	239
In this field, L2-based losses dominate, and with our work, we demonstrate how much additional detail can be generated with the right approach for adversarial training.	I-Reply	I-1	Reply	239
We will clarify this in the text of our submission.	I-Reply	I-1	Reply	239
[line_break_token][line_break_token]Q2: ‚Äúthe metrics definitions were not included in the main body of the paper‚Äù[line_break_token]A2: We will move the metrics definitions into the main part in a future version of the paper.	B-Reply	B-2	Reply	239

The paper proposes an algorithm for training memory networks which have very large memories.	O	O	Review	528
Training such models in traditional ways, by using soft-attention mechanism over all the memory slots is not only slow, it is also harder to train due to dispersion of gradients.	O	O	Review	528
The paper proposes to use the k-mips algorithm over the memories to choose a subset of the memory slots over which the attention is applied.	O	O	Review	528
Since the cost of exact k-mips is the same as doing full attention, the authors propose to use approximate k-mips, which while faster to compute, results in inferior performance.	O	O	Review	528
An artifact of using k-mips is that one cannot learn the memory slots.	O	O	Review	528
Hence they are pre-trained and kept fixed during entire training.	O	O	Review	528
The experimental section shows the efficacy of using k-mips using the SimpleQuestions dataset.	O	O	Review	528
The exact k-mips results in the same performance as the full attention.	O	O	Review	528
The approximate k-mips results in deterioration in performance.	O	O	Review	528
The paper is quite clearly written and easy to understand.	O	O	Review	528
[line_break_token][line_break_token]I think the ideas proposed in the paper are not super convincing.	O	O	Review	528
I have a number of issues with this paper.	O	O	Review	528
[line_break_token][line_break_token]1.	O	O	Review	528
The k-mips algorithm forces the memories to be fixed.	B-Review	B-1	Review	528
This to me is a rather limiting constraint, especially on problems/dataset which will require multiple hops of training to do compounded reasoning.	I-Review	I-1	Review	528
As a results I'm not entirely sure about the usefulness of this technique.	I-Review	I-1	Review	528
[line_break_token]2.	O	O	Review	528
Furthermore, the exact k-mips is the sample complexity as the full attention.	B-Review	B-2	Review	528
The only way to achieve speedup is to use approx k-mips.	I-Review	I-2	Review	528
That, as expected, results in a significant drop in performance.	I-Review	I-2	Review	528
[line_break_token]3.	B-Review	B-3	Review	528
The paper motivates the ideas by proposing solutions to eliminate heuristics used to prune the memories.	I-Review	I-3	Review	528
However in Section 3.1 the authors themselves end up using multiple heuristics to make the training work.	I-Review	I-3	Review	528
Agreed, that the used heuristics are not data dependent, but still, it feels like they are kicking the can down the road as far as heuristics are concerned.	I-Review	I-3	Review	528
[line_break_token]4.	O	O	Review	528
The experimental results are not very convincing.	B-Review	B-4	Review	528
First there is no speed comparison.	I-Review	I-4	Review	528
Second, the authors do not compare with methods other than k-mips which do fast nearest neighbor search, such as, FLANN.	I-Review	I-4	Review	528
Thanks for your valuable feedback.	O	O	Reply	528
[line_break_token][line_break_token]> The k-mips algorithm forces the memories to be fixed.	O	O	Reply	528
This to me is a rather limiting constraint, especially on problems/dataset which will require multiple hops of training to do compounded reasoning.	O	O	Reply	528
As a results I'm not entirely sure about the usefulness of this technique.	O	O	Reply	528
[line_break_token][line_break_token]It is true that the k-mips algorithm forces the memories to be fixed.	B-Reply	B-1	Reply	528
However, it is not the issue with k-mips algorithm only.	I-Reply	I-1	Reply	528
We have this issue with nearest neighbor search algorithms and maximum cosine similarity search algorithms as well.	I-Reply	I-1	Reply	528
When we need to update the memory, then one can do periodic memory reorganization after every few epochs as done by Vijayanarasimhan et al 2014 or Rae et al 2016.	I-Reply	I-1	Reply	528
[line_break_token][line_break_token]However, this is not a limiting constraint on problems which will require multiple hops.	I-Reply	I-1	Reply	528
One can design a separate inference module (like the episodic memory in end-to-end memory nets) that will take care of multiple hops and the main memory can still be fixed.	I-Reply	I-1	Reply	528
So we believe that this technique is still useful in the setting mentioned by the reviewer.	I-Reply	I-1	Reply	528
[line_break_token][line_break_token]> Furthermore, the exact k-mips is the sample complexity as the full attention.	O	O	Reply	528
The only way to achieve speedup is to use approx k-mips.	O	O	Reply	528
That, as expected, results in a significant drop in performance.	O	O	Reply	528
[line_break_token][line_break_token]Yes true.	B-Reply	B-2	Reply	528
Exact k-mips has the sample complexity of full attention.	I-Reply	I-2	Reply	528
Our k-mips experiments serve two purposes: 1.	I-Reply	I-2	Reply	528
It is a proof of concept that approximate k-mips if done correctly would help us achieve scalability as well as performance.	I-Reply	I-2	Reply	528
2.	I-Reply	I-2	Reply	528
It is suggestive to use k-mips instead of full attention even in situations where full attention is cheap.	I-Reply	I-2	Reply	528
We think that both are important messages.	I-Reply	I-2	Reply	528
Our approximate k-mips experiments benchmark the existing state-of-the-art methods for approximate k-mips and show that they are not good enough for this task.	I-Reply	I-2	Reply	528
This demands more research on better approximate k-mips methods.	I-Reply	I-2	Reply	528
[line_break_token][line_break_token]> The paper motivates the ideas by proposing solutions to eliminate heuristics used to prune the memories.	O	O	Reply	528
However in Section 3.1 the authors themselves end up using multiple heuristics to make the training work.	O	O	Reply	528
Agreed, that the used heuristics are not data dependent, but still, it feels like they are kicking the can down the road as far as heuristics are concerned.	O	O	Reply	528
[line_break_token][line_break_token]We agree with the reviewer.	B-Reply	B-3	Reply	528
As the reviewer rightly pointed out, we replaced the dataset-specific heuristics with dataset-independent heuristics which is a research direction worth exploring since it will be applicable to any kind of datasets.	I-Reply	I-3	Reply	528
[line_break_token][line_break_token] > The experimental results are not very convincing.	O	O	Reply	528
First there is no speed comparison.	O	O	Reply	528
Second, the authors do not compare with methods other than k-mips which do fast nearest neighbor search, such as, FLANN.	O	O	Reply	528
[line_break_token][line_break_token]FLANN is a standard library that people use for nearest neighbor search.	B-Reply	B-4	Reply	528
However, please note that PCA-tree is a better method than FLANN and is a state-of-the-art in tree based methods.	I-Reply	I-4	Reply	528
We benchmark three search algorithms each state-of-the-art in clustering-based, tree-based, and hashing-based approaches respectively.	I-Reply	I-4	Reply	528
[line_break_token]Speed comparison of different approximate k-mips algorithms used in this paper has already been done in an extensive setup in Auvolat et al 2015	I-Reply	I-4	Reply	528

The paper deals with an interesting application of adversarial training to encryption.	O	O	Review	644
It considers the standard scenario of Alice, Eve and Bob, where A and B aim to exchange messages conditioned on a shared key, while Eve should be unable to encrypt the message.	O	O	Review	644
Experiments are performed in a simple symmetric 16 bit encryption task, and an application on privacy.	O	O	Review	644
The concepts, ideas and previous literature are quite nicely and carefully presented.	O	O	Review	644
[line_break_token][line_break_token]The only major concern I have - and I apologize to the authors for not raising this earlier - are the experiments in section 3.	O	O	Review	644
In particular, I don't quite get the scenario.	O	O	Review	644
The reasoning here seems to be as follows: given information < A, B, C, D >, I want to give the public the value of D (e.g. movies watched) without releasing information about C (e.g. gender).	O	O	Review	644
In this scenario, Eve would need to be able to reconstruct D as good as possible without gaining information about C. What is described in section 3, however, is that D and D-public are both reconstructed by Bob, but why would Bob reconstruct the latter (he is not public, in particular because he is allowed to reconstruct C, which is not tested here)?	O	O	Review	644
Also, Eve only tries to estimate C, thus rendering the scenario not different in any way to the scenario considered in section 2.	O	O	Review	644
[line_break_token][line_break_token]I have two more minor concerns:[line_break_token][line_break_token]1) As raised in the pre-review, Eve should actually be stronger then Alice and Bob in order to be able to compensate for the missing key.	B-Review	B-1	Review	644
The authors noted they have been doing these experiments and are going to add the results.	I-Review	I-1	Review	644
[line_break_token][line_break_token]2) In any natural encryption case I would expect the length of the key to be much shorter then the length of the message.	B-Review	B-2	Review	644
This, however, could potentially make the scenario much easier for Eve (although I doubt any of the results will change if the key is long enough).	I-Review	I-2	Review	644
[line_break_token][line_break_token]I like the creative application of adversarial training to a completely different domain, and I believe it could be the starting point of a very interesting direction in cryptographic systems or in privacy applications (although it is unclear whether the weak guarantees of neural network based approaches can ever be overcome).	O	O	Review	644
At the same time the application in the privacy setting leaves me quite confused, and the symmetric encryption example is not particularly strong either.	O	O	Review	644
I'd appreciate if the authors could address the major concern I raised above, and I will be quite happy to raise the score in case this confusion can be resolved.	O	O	Review	644
Thank you for your encouraging comments.	O	O	Reply	644
[line_break_token][line_break_token]Regarding the experiments of section 3, the scenario is that Alice provides information so that anyone can observe an estimate of D without gaining information about C. The fact that C is hidden is formulated by introducing Eve, which attempts to reconstruct C. Alice also provides additional information so that Bob, with whom Alice shares a key, can do an even better job at estimating D, but may learn something about C. In sum, the main difference with section 2 is that here the ‚Äúcommunication goal‚Äù and the ‚Äúhiding goal‚Äù concern two different parts of the plaintext (D and C respectively).	O	O	Reply	644
We hope that this clarifies the matter; we would certainly be happy to expand the discussion in section 3 (perhaps adding diagrams which we have used in talks, but which seemed too long for the submission).	O	O	Reply	644
[line_break_token][line_break_token]Regarding minor concern (1), we will indeed be glad to include the results indicated in our response and some updated ones in the event that the paper is accepted.	B-Reply	B-1	Reply	644
We agree that it is interesting to think about stronger Eve networks, as suggested by the reviewer.	I-Reply	I-1	Reply	644
On the other hand, we believe that the appropriate strength of Eve may sometimes be dictated by intended applications; for example, if we are trying to hide information from one of our own neural-network components (as suggested in page 2), it makes sense that Eve be of a similar size and architecture as that component.	I-Reply	I-1	Reply	644
[line_break_token][line_break_token]Regarding minor concern (2), we have two thoughts.	B-Reply	B-2	Reply	644
 First, it may often be appropriate to generate arbitrary-length key material using standard cryptographic key-generation techniques.	I-Reply	I-2	Reply	644
 (These techniques generate an arbitrary-length stream of bits given a short initial seed, and parts of that stream of bits could be used as the keys passed into the neural cryptography).	I-Reply	I-2	Reply	644
 Second, as a generalization of our work, we agree that the treatment of larger messages could be interesting.	I-Reply	I-2	Reply	644
It is natural to evaluate neural cryptography with messages larger than keys;  this should be a straightforward extension of our current work.	I-Reply	I-2	Reply	644
 As a more futuristic step, one could explore so-called ‚Äúmodes of operation‚Äù using RNNs or similar architectures	I-Reply	I-2	Reply	644

The proposed method is suitable for many NLP tasks, since it can handle the sequence data.	O	O	Review	238
[line_break_token][line_break_token]I find it difficult to follow through the model descriptions.	B-Review	B-1	Review	238
 Perhaps a more descriptive figures would make this easier to follow, I feel that the ART model is a very strait forward and it can be easily described in much simpler and less exhausting (sorry for the strong word) way, while there is nothing wrong with being as elaborating as you are, I feel that all those details belong in an appendix.	I-Review	I-1	Review	238
[line_break_token]Can you please explain the exact learning process?	B-Review	B-2	Review	238
[line_break_token]I didn‚Äôt fully understand the exact way of collocations, you first train on the source domain and then use the trained source network when training in the target domain with all the collocated words for each training example?	B-Review	B-7	Review	238
I deeply encourage you to improve the model section for future readers.	I-Review	I-7	Review	238
[line_break_token]In contrast to the model section, the related work and the experimental settings sections are very thin.	B-Review	B-3	Review	238
[line_break_token]The experimental setup for the sentiment analysis experiments is quite rare in the transfer learning/domain adaptation landscape, having equal amount of labeled data from both source and target domains is not very realistic in my humble opinion.	B-Review	B-6	Review	238
[line_break_token]More realistic setup is unsupervised domain adaptation (like in DANN and MSDA-DAN papers) or minimally supervised domain adaptation (like you did in your POS and NER experiments).	I-Review	I-6	Review	238
[line_break_token][line_break_token]In addition to the LSTM baseline (which is trained with target data only), I think that LSTM which is trained on both source and target domains data is required for truly understand ART gains ‚Äì this goes for the POS and NER tasks as well.	B-Review	B-5	Review	238
[line_break_token]The POS and NER experiments can use some additional baselines for further comparison, for example:[line_break_token]<a href="http://www.aclweb.org/anthology/Q14-1002" target="_blank" rel="nofollow">http://www.aclweb.org/anthology/Q14-1002</a>[line_break_token]<a href="https://hornhehhf.github.io/hangfenghe/papers/14484-66685-1-PB.pdf" target="_blank" rel="nofollow">https://hornhehhf.github.io/hangfenghe/papers/14484-66685-1-PB.pdf</a>[line_break_token][line_break_token]I am not sure I understand the ‚Äúcell level transfer‚Äù claim, did you mean that you are the first to apply inner LSTM/RNN cell transfer or that you are the first ones to apply word-level fine grained transfer, the latter has already been done:[line_break_token]<a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.05365.pdf</a>[line_break_token]<a href="https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=4531&context=sis_research" target="_blank" rel="nofollow">https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=4531&context=sis_research</a>[line_break_token]<a href="http://www.aclweb.org/anthology/N18-1112" target="_blank" rel="nofollow">http://www.aclweb.org/anthology/N18-1112</a>[line_break_token]<a href="https://openreview.net/pdf?id=rk9eAFcxg" target="_blank" rel="nofollow">https://openreview.net/pdf?id=rk9eAFcxg</a>[line_break_token]	O	O	Review	238
Thank you for your insightful and supportive comments.	O	O	Reply	238
We have made the following revisions: (1) We added two baselines according to your comments.	B-Reply	B-5	Reply	238
The results further justify the effectiveness of ART. (	O	O	Reply	238
2) We added a new experiment for minimally supervised domain adaptation in Table 3.	B-Reply	B-6	Reply	238
ART still outperforms all the competitors by a large margin. (	O	O	Reply	238
3) We clarified the ART model and model training process in the revised paper.	B-Reply	B-1	Reply	238
We will give more details below:[line_break_token][line_break_token]== Writing ==[line_break_token]1.	O	O	Reply	238
High level description of the ART model.	O	O	Reply	238
[line_break_token]We have added the following description of ART model in section 2.	B-Reply	B-1	Reply	238
[line_break_token]‚ÄúThe source domain and the target domain share an RNN layer, from which the common information is transferred.	I-Reply	I-1	Reply	238
We pre-train the neural network of the source domain.	I-Reply	I-1	Reply	238
Therefore the shared RNN layer represents the semantics of the source domain.	I-Reply	I-1	Reply	238
The target domain has an additional RNN layer.	I-Reply	I-1	Reply	238
Each cell in it accepts transferred information through the shared RNN layer.	I-Reply	I-1	Reply	238
Such information consists of (1) the information of the same word in the source domain (the red edge in figure 2); and (2) the information of all its collocated words (the blue edges in figure 2).	I-Reply	I-1	Reply	238
ART uses attention to decide the weights of all candidate collocations.	I-Reply	I-1	Reply	238
The RNN cell controls the weights between (1) and (2) by an update gate.	I-Reply	I-1	Reply	238
‚Äù[line_break_token][line_break_token]2.	O	O	Reply	238
Model training.	B-Reply	B-2	Reply	238
We add more details of the model training part in section 2.	I-Reply	I-2	Reply	238
[line_break_token]We first pre-train the parameters of the source domain by its training samples.	I-Reply	I-2	Reply	238
Then we fine-tune the pre-trained model with additional layers of the target domain.	I-Reply	I-2	Reply	238
The fine-tuning uses the training samples of the target domain.	I-Reply	I-2	Reply	238
All parameters are jointly fine-tuned.	I-Reply	I-2	Reply	238
[line_break_token][line_break_token]3.	B-Reply	B-6	Reply	238
Related work.	O	O	Reply	238
[line_break_token]We have rewritten the related work section.	B-Reply	B-3	Reply	238
We compare with other cell-level transfer learning approaches and pre-trained models.	I-Reply	I-3	Reply	238
[line_break_token][line_break_token]== Innovation of cell-level transfer ==[line_break_token]We agree that some previous transfer learning approaches also consider cell-level transfer.	B-Reply	B-4	Reply	238
But none of them considers the word collocations.	I-Reply	I-4	Reply	238
As a pre-trained model, ELMo uses bidirectional LSTMs to generate contextual features.	I-Reply	I-4	Reply	238
Instead, ART uses attention mechanism in RNN that each cell in the target domain directly access information of all cells in the source domain.	I-Reply	I-4	Reply	238
We added more details in the related work section.	I-Reply	I-4	Reply	238
[line_break_token][line_break_token]== Baselines ==[line_break_token]We added two baselines, LSTM-u and FLORS, according to your comments.	B-Reply	B-5	Reply	238
LSTM-u uses a standard LSTM and is trained by the union data of the source and the target domain.	I-Reply	I-5	Reply	238
FLORS is a domain adaptation model for POS tagging (<a href="http://www.aclweb.org/anthology/Q14-1002)."	O	O	Reply	238
target="_blank" rel="nofollow">http://www.aclweb.org/anthology/Q14-1002).</a> Their results are shown in Table 2 and Table 5.	O	O	Reply	238
ART outperforms LSTM-u in almost all settings by a large margin.	B-Reply	B-5	Reply	238
Note that FLORS is independent of the target domain.	I-Reply	I-5	Reply	238
If the training corpus of the target domain is quite rare (Twitter/0.01), FLORS performs better.	I-Reply	I-5	Reply	238
But with richer training data of the target domain (Twitter/0.1), ART outperforms FLORS by a large margin.	I-Reply	I-5	Reply	238
[line_break_token][line_break_token]Table 2: ClassiÔ¨Åcation accuracy on the Amazon review dataset.	I-Reply	I-5	Reply	238
[line_break_token]Source[tab_token][tab_token]Target[tab_token][tab_token]LSTM-u[tab_token]ART[line_break_token]Books[tab_token][tab_token]DVD[tab_token][tab_token]0.770 [tab_token]0.870 [line_break_token]Books[tab_token][tab_token]Electronics[tab_token]0.805 [tab_token]0.848 [line_break_token]Books[tab_token][tab_token]Kitchen[tab_token][tab_token]0.845 [tab_token]0.863 [line_break_token]DVD[tab_token][tab_token]Books[tab_token][tab_token]0.788 [tab_token]0.855 [line_break_token]DVD[tab_token][tab_token]Electronics[tab_token]0.788 [tab_token]0.845 [line_break_token]DVD[tab_token][tab_token]Kitchen[tab_token][tab_token]0.823 [tab_token]0.853 [line_break_token]Electronics[tab_token]Books[tab_token][tab_token]0.740 [tab_token]0.868 [line_break_token]Electronics[tab_token]DVD[tab_token][tab_token]0.753 [tab_token]0.855 [line_break_token]Electronics[tab_token]Kitchen[tab_token][tab_token]0.863 [tab_token]0.890 [line_break_token]Kitchen[tab_token][tab_token]Books[tab_token][tab_token]0.760 [tab_token]0.845 [line_break_token]Kitchen[tab_token][tab_token]DVD[tab_token][tab_token]0.758 [tab_token]0.858 [line_break_token]Kitchen[tab_token][tab_token]Electronics[tab_token]0.815 [tab_token]0.853 [line_break_token]        Average[tab_token][tab_token][tab_token][tab_token]0.792 [tab_token]0.858[line_break_token][line_break_token]Table 5: Performance over POS tagging.	I-Reply	I-5	Reply	238
[line_break_token]Task[tab_token][tab_token][tab_token]Source[tab_token]Target[tab_token][tab_token]FLORS[tab_token]ART[line_break_token]POS Tagging[tab_token]        PTB[tab_token][tab_token]Twitter/0.1[tab_token]0.763[tab_token]0.859[line_break_token]POS Tagging[tab_token]        PTB[tab_token][tab_token]Twitter/0.01[tab_token]0.763[tab_token]0.658[line_break_token][line_break_token]== Experimental settings ==[line_break_token]Based on your comment, we added a new experiment for minimally supervised domain adaptation in sentence classification.	B-Reply	B-6	Reply	238
For each target domain in the Amazon review dataset, we combined the training/development data of rest three domains as the source domain.	I-Reply	I-6	Reply	238
We show the results in Table 3.	I-Reply	I-6	Reply	238
ART outperforms the competitors by a large margin.	I-Reply	I-6	Reply	238
This verifies its effectiveness in the setting of minimally supervised domain adaptation.	I-Reply	I-6	Reply	238
[line_break_token][line_break_token]Table 3: Classification accuracy with scarce training samples of the target domain.	I-Reply	I-6	Reply	238
[line_break_token]Target[tab_token][tab_token]LSTM[tab_token]LSTM-u[tab_token]CCT[tab_token][tab_token]LWT[tab_token]HATN[tab_token]ART[line_break_token]Books[tab_token][tab_token]0.745 [tab_token]0.813 [tab_token]0.848 [tab_token]0.808 [tab_token]0.820 [tab_token]0.895 [line_break_token]DVD[tab_token][tab_token]0.695 [tab_token]0.748 [tab_token]0.870 [tab_token]0.770 [tab_token]0.828 [tab_token]0.875 [line_break_token]Electronics[tab_token]0.733 [tab_token]0.823 [tab_token]0.848 [tab_token]0.818 [tab_token]0.863 [tab_token]0.865 [line_break_token]Kitchen[tab_token][tab_token]0.798 [tab_token]0.840 [tab_token]0.860 [tab_token]0.840 [tab_token]0.833 [tab_token]0.870 [line_break_token]Average[tab_token][tab_token]0.743 [tab_token]0.806 [tab_token]0.856 [tab_token]0.809 [tab_token]0.836 [tab_token]0.87	I-Reply	I-6	Reply	238

Overview: [line_break_token]The authors proposed a weakly-supervised method to localize video moments given text queries.	O	O	Review	10041
 The model builds multi-level relational graphs among pairs of word and video frame, and the graph is used to aggregate visual-semantic feature for each word and each frame.	O	O	Review	10041
Then the attentive features are used to localize the sentence query in videos by calculating the similarity of words and frames.	O	O	Review	10041
In summary, the proposed weakly-supervised Moment Alignment Network (wMAN) utilizes a multi-level co-attention mechanism to learn richer multimodal representations for language based video retrieval..[line_break_token][line_break_token]Pros:[line_break_token]1.	B-Review	B-4	Review	10041
Significant performance improvement on Didemo and Charades-STA datasets.	O	O	Review	10041
The authors achieved very good performance on both dataset, even higher than some of the full-supervision methods, such as CTRL and MLVI.	O	O	Review	10041
[line_break_token][line_break_token]Cons:[line_break_token]1.	B-Review	B-4	Review	10041
The overall novelty of the proposed methods is limited.	B-Review	B-1	Review	10041
Essentially, the key points of the model is hierarchical visual semantic co-attention.	I-Review	I-1	Review	10041
,which is proposed originally in [Hierarchical Question-Image Co-Attention[line_break_token]for Visual Question Answering], although the original application is VQA in image domain.	I-Review	I-1	Review	10041
So in this way, the novelty is only marginal.	I-Review	I-1	Review	10041
[line_break_token]2.	B-Review	B-4	Review	10041
Paper writing can be improved.	B-Review	B-2	Review	10041
Figure 2 shows the overall structure of the model, however, the caption doesn't explain all the notations in the figure, such as WCVG, and the equations.	I-Review	I-2	Review	10041
Additionally, the reference is very far away from Figure 2, which makes the whole paper hard to read.	I-Review	I-2	Review	10041
[line_break_token]3.	O	O	Review	10041
For evaluation part, one important ablation study is missing: the number of steps T for message passing.	B-Review	B-3	Review	10041
This eval is important, as it shows the necessity of using "multi-level" attention.	I-Review	I-3	Review	10041
[line_break_token][line_break_token]Minor comments:[line_break_token]1.	B-Review	B-4	Review	10041
Make the caption of Figure 2 self-explainable, e.g. the meaning of LSE.	I-Review	I-4	Review	10041
[line_break_token]2.	I-Review	I-4	Review	10041
There is a "word-conditioned" visual graph network, why not the other way, "frame-conditioned" semantic graph net and iterate over it?	I-Review	I-4	Review	10041
[line_break_token]	O	O	Review	10041
hank you for your review.	O	O	Reply	10041
We address your concerns below.	O	O	Reply	10041
[line_break_token][line_break_token]1) This is addressed in the general response.	B-Reply	B-1	Reply	10041
[line_break_token][line_break_token]2) We will update the next version of the paper with the necessary clarifications to the caption and modifications.	B-Reply	B-2	Reply	10041
[line_break_token][line_break_token]3) We have updated the submission with an ablation study of how the number of message-passing steps affects the performance of our proposed approach.	B-Reply	B-3	Reply	10041
They are included in Section B of the appendix.	I-Reply	I-3	Reply	10041
In our experiments across both Charades-Sta and DiDeMo, we have observed that 3 steps work the best.	I-Reply	I-3	Reply	10041
[line_break_token][line_break_token]We hope that we have addressed your concerns satisfactorily.	O	O	Reply	10041
Please let us know if you have any further concerns or questions	O	O	Reply	10041

The paper proposes to use a multi-step prediction model in model-based RL.	O	O	Review	656
The proposed model maps from current state and a sequence of actions to the state after taking those actions.	O	O	Review	656
The paper demonstrates on 2 tasks that in a model-predictive control loop combined with planning by cross-entropy method, this can yield better asymptotic performance than using single-step models.	O	O	Review	656
[line_break_token][line_break_token]The insight of using multi-step prediction models is certainly appealing and makes a lot of sense in deterministic tasks.	O	O	Review	656
A systematic empirical comparison of multi-step deep models in RL is of interest, which this paper does provide to some extent.	O	O	Review	656
[line_break_token][line_break_token]An obvious limitation of the proposed deterministic multi-step forward model is the restriction to deterministic systems.	B-Review	B-1	Review	656
One would expect that the performance deteriorates quickly as the system becomes more stochastic.	I-Review	I-1	Review	656
An extension to the stochastic case along the lines of Chua et al, 2018 is non-trivial as capturing the stochasticity is typically more challenging in long-term predictions.	I-Review	I-1	Review	656
Yet, the paper makes an additional assumption that is less clearly communicated: To be able to plan with a R-step model, one needs to be able to evaluate or approximate the sum of R rewards just from the first and last state in that R-long sequence.	B-Review	B-2	Review	656
This work uses simply the reward at the end r(s_{t+R}) as a proxy which works well in these MuJoCo tasks but can fail horribly in others.	I-Review	I-2	Review	656
One can imagine that a model not only outputs s_{t+R} but also the sum of R rewards given s_t and a_{t:t+R} which could work in more general settings but this is not explored in this paper.	I-Review	I-2	Review	656
The contribution in this paper limited as the proposed approach as well as the experimental comparison is restricted to a relatively specific class of problems and no attempts to generalize are made.	B-Review	B-3	Review	656
[line_break_token][line_break_token]The experiments nicely compare against using single-step dynamics models and the results show that using the multi-step models for MPC performs better in the two considered tasks.	O	O	Review	656
However, as fas as I understand both the ACP and Chua et al baseline using the single-step prediction accuracy to train their models.	B-Review	B-4	Review	656
The paper is missing a comparison to single-step models that are trained using multi-step prediction losses ("backprop through time" as in Learning Nonlinear Dynamic Models by Langford et al 2009).	I-Review	I-4	Review	656
These models should be much more robust to error blow-up for multi-step prediction and do not require the specific reward structure assumed in this paper.	I-Review	I-4	Review	656
[line_break_token][line_break_token]The proposed R-step model-based RL approach could be connected to the use of options (the planner and model operate on R-step options, but the MPC does update the policy after every time step).	O	O	Review	656
It would be interesting to discuss this potential connection in the paper.	O	O	Review	656
The paper does a good job of discussing existing recent work in the deep RL literature but it would also be good to also discuss earlier work on multi-step prediction (e.g. in time-series modeling).	O	O	Review	656
[line_break_token][line_break_token]All in all, I think the paper makes a small contribution demonstrating that multi-step models are useful for model-based RL in specific domains -- which is interesting but certainly not surprising.	O	O	Review	656
Unfortunately the paper stops somewhat early by not comparing to relevant baselines (single-step models trained with multi-step losses) and by not considering tasks where the benefit of multi-step planning would be less clear.	O	O	Review	656
We thank the reviewer for a very detailed review.	O	O	Reply	656
[line_break_token][line_break_token]"capturing the stochasticity is typically more challenging in long-term predictions": Yes, this is an interesting direction.	B-Reply	B-1	Reply	656
Such a model would need the ability to produce complex multimodal distributions of outcomes.	I-Reply	I-1	Reply	656
As our goal in this work was to understand why existing methods failed even on deterministic tasks, we leave it to future work to propose classes of multi-step models appropriate for stochastic environments.	I-Reply	I-1	Reply	656
[line_break_token][line_break_token]"This work uses simply the reward at the end": In fact, our model is able to use reward at intermediate time steps.	B-Reply	B-2	Reply	656
To do this, we can use the variable-action-length version of our model, as used for visualization (mentioned in Section 2.2 paragraph 2 of the original version).	I-Reply	I-2	Reply	656
We also use this version in Fig 5.	I-Reply	I-2	Reply	656
to evaluate prediction error as a function of timesteps in the future.	I-Reply	I-2	Reply	656
We have added Section 2.2.1 to clarify this.	I-Reply	I-2	Reply	656
[line_break_token][line_break_token]In our main experiments we use a transformed version of the reward function to select trajectories which have an outcome with the greatest x-axis position.	I-Reply	I-2	Reply	656
This is approximately equal to the sum of the rewards obtained along the trajectory under the original reward function, which provides a reward at each timestep proportional to the forward progress at that timestep.	I-Reply	I-2	Reply	656
We have updated Section 2.3.1 to better reflect this.	I-Reply	I-2	Reply	656
[line_break_token][line_break_token]We apologize for not making these points more clear in the paper.	I-Reply	I-2	Reply	656
[line_break_token][line_break_token]"single-step models that are trained using multi-step prediction losses": Yes, we agree that other models which directly minimize long-term prediction error will also produce better predictions that single-step models.	B-Reply	B-4	Reply	656
However, the main goal of this work is to point out the deficiencies of the single-step class of models typically used in the field.	I-Reply	I-4	Reply	656
As such, we simply chose one simple member of the class of multistep models to illustrate our point.	I-Reply	I-4	Reply	656
[line_break_token][line_break_token]We have since run experiments to evaluate the potential of recurrent training of single-step models with multi-step loss functions.	I-Reply	I-4	Reply	656
While using a multi-step loss provides significant improvement over a single-step loss, the PCP remains somewhat more accurate.	I-Reply	I-4	Reply	656
We have updated Figure 5 and the related text with this result.	I-Reply	I-4	Reply	656
[line_break_token][line_break_token]We furthermore have run these RNN models on the full bootstrapped planning task.	I-Reply	I-4	Reply	656
Planning with these models is hugely slower than with the PCP, as for each prediction of length H the RNN must be run forward H times, whereas the PCP need only be run H/R times; that is, the RNNs take 50 times as long on Swimmer.	I-Reply	I-4	Reply	656
We have included preliminary results with RNNs in Figure 7 and will update the paper with the completed experiments before camera ready.	I-Reply	I-4	Reply	656
We do not believe these results alter the message of the paper.	I-Reply	I-4	Reply	656
[line_break_token][line_break_token]The Langford et al reference is very helpful and we will add a discussion of this paper to our related work.	I-Reply	I-4	Reply	656

This paper proposes a framework for deep metric learning.	O	O	Review	56
Using ideas from distributionally robust optimization, the loss (in each batch) is the worst case weighted average of all pairwise classification losses, taken over an uncertainty set of possible weights.	O	O	Review	56
The framework is shown to be general and encompass various previous approaches.	O	O	Review	56
Based on it, the authors propose several new algorithms, which are shown to outperform the SOTA on image retrieval data sets in terms of recall.	O	O	Review	56
[line_break_token][line_break_token]The main contribution of the paper is a unification of previous deep metric learning algorithms, which would be helpful to the community and could inspire new approaches.	O	O	Review	56
I found the empirical observation that the proposed algorithms are able to reduce the computation time by nearly half to be compelling.	O	O	Review	56
However, apart from DRO-TopK-PN, the proposed algorithms appear to be minor modifications of existing algorithms.	B-Review	B-1	Review	56
[line_break_token][line_break_token]Questions about the experimental protocol:[line_break_token]1.	O	O	Review	56
Are the results from one run, or averaged over several?	B-Review	B-2	Review	56
Standard errors of the evaluation metrics would be very helpful to judge the improvements made by the algorithms, especially as the algorithms are stochastic due to batching.	I-Review	I-2	Review	56
[line_break_token]2.	O	O	Review	56
The proposed algorithms seem to be similar to those of Fan et al (2017) and Namkoong and Duchi (2017).	B-Review	B-3	Review	56
Is there a particular reason why they weren‚Äôt included in the experiments?	I-Review	I-3	Review	56
hanks for your comments!	O	O	Reply	56
For differences between our framework and traditional DRO method, please also check response to Reviewer 3.	B-Reply	B-3	Reply	56
We want to emphasize that the modifications (i.e., defining over a mini-bath for the robust loss, and more general and flexible regularization of the dual variables) are subtle but very important for achieving better empirical results than complicated losses and bringing more theoretical insights for complicated losses.	I-Reply	I-3	Reply	56

Privacy concerns arise when data is shared with third parties, a common occurrence.	O	O	Review	713
This paper proposes a privacy-preserving classification framework that consists of an encoder that extracts features from data, a classifier that performs the actual classification, and a decoder that tries to reconstruct the original data.	O	O	Review	713
In a mobile computing setting, the encoder is deployed at the client side and the classification is performed on the server side which accesses only the output features of the encoder.	O	O	Review	713
The adversarial training process guarantees good accuracy of the classifier while there is no decoder being able to reconstruct the original input sample accurately.	O	O	Review	713
Experimental results are provided to confirm the usefulness of the algorithm.	O	O	Review	713
[line_break_token][line_break_token]The problem of privacy-preserving learning is an important topic and the paper proposes an interesting framework for that.	O	O	Review	713
However, I think it needs to provide more solid evaluations of the proposed algorithm, and presentation also need to be improved a bit.	O	O	Review	713
[line_break_token][line_break_token]Detailed comments:[line_break_token]I don‚Äôt see a significant difference between RAN and DNN in Figure 5.	B-Review	B-1	Review	713
Maybe more explanation or better visualization would help.	I-Review	I-1	Review	713
[line_break_token]The decoder used to measure privacy is very important.	B-Review	B-2	Review	713
Can you provide more detail about the decoders used in all the four cases?	I-Review	I-2	Review	713
If possible, evaluating the privacy with different decoders may provide a stronger evidence for the proposed method.	B-Review	B-3	Review	713
[line_break_token]It seems that DNN(resized) is a generalization of DNN.	B-Review	B-4	Review	713
If so, by changing the magnitude of noise and projection dimensions for PCA should give a DNN(resized) result (in Figure 3) that is close to DNN.	I-Review	I-4	Review	713
If the two NNs used in DNN and DNN(resized) are different, I believe it‚Äôs still possible to apply the algorithm in DNN(resized) to the NN used in DNN, and get a full trace in the figure as noise and projection changes, which would lead to more fair comparison.	I-Review	I-4	Review	713
[line_break_token]The abstract mentioned that the proposed algorithm works as an ‚Äúimplicit regularization leading to better classification accuracy than the original model which completely ignores privacy‚Äù.	B-Review	B-5	Review	713
But I don‚Äôt see clearly from the experimental results how the accuracy compares to a non-private classifier.	I-Review	I-5	Review	713
[line_break_token]Section 2.2 mentioned how different kind of layers would help with the encoder‚Äôs utility and privacy.	B-Review	B-6	Review	713
It would be better to back up the argument with some experiments.	I-Review	I-6	Review	713
[line_break_token]I think it needs to be made clearer how reconstruction error works as a measure of privacy.	B-Review	B-7	Review	713
For example, an image which is totally unreadable for human eye might still leak sensitive information when fed into a machine learning model.	I-Review	I-7	Review	713
[line_break_token]In term of reference, it‚Äôs better to cite more articles with different kind of privacy attacks for how raw data can cause privacy risks.	B-Review	B-8	Review	713
For the ‚ÄúNoisy Data‚Äù method, it‚Äôs better to cite more articles on differential privacy and local differential privacy.	B-Review	B-9	Review	713
[line_break_token]Some figures, like Figure 3 and 4, are hard to read.	B-Review	B-10	Review	713
The author may consider making the figures larger (maybe with a 2 by 2 layout), adjusting the position of the legend & scale of x-axis for Figure 3, and using markers with different colors for Figure 4.	O	O	Review	713
[line_break_token]	O	O	Review	713
We thank the comments with cares and insights, which are helpful for improving the quality and readability of our paper.	O	O	Reply	713
We are glad that you support our paper.	O	O	Reply	713
We have addressed all the comments as follows:[line_break_token][line_break_token]Response #1: In the revision, we had added a new experiment to zoom in on two categories for clearer utility visualization.	B-Reply	B-1	Reply	713
In particular, we show the DNN‚Äôs deep features and RAN‚Äôs Encoder output to illustrate how they push the features to cluster with the ‚Äúcar with/without road‚Äù & ‚Äúsailboat with/without water‚Äù images in the feature space.	O	O	Reply	713
[line_break_token] [line_break_token]Response #2: We agree that we should provide more details about the decoders.	B-Reply	B-2	Reply	713
Generally, we set the Decoder to mirror the Encoder's architecture.	I-Reply	I-2	Reply	713
That is, we assume a powerful adversary that knows the Encoder in training.	I-Reply	I-2	Reply	713
Because the Encoders are different for different tasks, the Encoders are different too.	I-Reply	I-2	Reply	713
In particular, we select the architecture of Encoder plus Classifier to be LeNet for MNIST, Ubisound and Har, to be AlexNet for CIFAR-10, and to be VGG-16 for ImageNet.	I-Reply	I-2	Reply	713
The architectures of Encoder in four cases are different, so the Decoder is varied as well.	I-Reply	I-2	Reply	713
In the revision, we have added above explanations about Decoder in Section 2.3 and in experiment settings of Section 3.	I-Reply	I-2	Reply	713
[line_break_token][line_break_token]Response #3: We agree that the description of three baselines should be more precise, especially the DNN and DNN(resized) baseline.	B-Reply	B-4	Reply	713
In the revision, we have added explanations on the difference/similarity between DNN (resized) and DNN baselines.	I-Reply	I-4	Reply	713
And explain why we include them as baselines to compare RAN against in Section 3.1.	I-Reply	I-4	Reply	713
[line_break_token] [line_break_token]Response #4: We have added more explanations in Section 3.1 about how ‚Äúthe proposed algorithm works as an implicit regularization leading to better classification accuracy than the original model which completely ignores privacy‚Äù.	B-Reply	B-5	Reply	713
As shown in Figure 3, the utility of RAN‚Äôs Encoder output is higher than that of DNN.	I-Reply	I-5	Reply	713
Here the DNN model stands for the non-private feature extractor followed by a non-private classifier.	I-Reply	I-5	Reply	713
[line_break_token] [line_break_token]Response #5: We agree that it is necessary to conduct experiments to compare RAN‚Äôs performance concerning privacy and accuracy with/without a different kind of layers so that we can back up the argument mentioned in Section 2.2.	B-Reply	B-6	Reply	713
On the one hand, we have already conducted exhaustive micro-benchmark experiments to determine the current design of RAN.	I-Reply	I-6	Reply	713
For example, we select different model architectures (layers and building blocks), weight updating schemes of different parts (when and how to update Encoder, Decoder and Classifier) and settings of some important hyper-parameters (the setup of ‚Äún‚Äù epochs and ‚Äúk‚Äù steps, learning rate) to select the empirically optimized one.	I-Reply	I-6	Reply	713
However, we only present the most important results in this paper due to the space limit.	I-Reply	I-6	Reply	713
On the other hand, for all the arguments in Section 2.2, we have added the citation to support them.	I-Reply	I-6	Reply	713
[line_break_token] [line_break_token]Response #6: We agree that it is important to justify how the reconstruction error works as a measure of privacy in this paper.	B-Reply	B-7	Reply	713
 In the revision, we have added the following explanation and justification on privacy quantification in Section 1, Section 2, Section 4 and Section 5.	I-Reply	I-7	Reply	713
[line_break_token][line_break_token]First, there is no single standard definition of data privacy-preserving and corresponding adversary attacks.	I-Reply	I-7	Reply	713
And a fundamental problem is the natural privacy-utility tradeoff which is affected by different data privacy-preserving methods.	I-Reply	I-7	Reply	713
We note that our principal contribution in this paper is the RAN framework and the training algorithm, which can accommodate different choices of privacy attacker and privacy quantification.	I-Reply	I-7	Reply	713
[line_break_token][line_break_token]Second, finding the right measurement for privacy is an open problem in itself.	I-Reply	I-7	Reply	713
To evaluate RAN, one has to pick some quantifications.	I-Reply	I-7	Reply	713
In the present paper, we chose the ‚Äúreconstructive error‚Äù because it is the most intuitive one to measure the risk of original data disclosure given perturbed data (Encoder output).	I-Reply	I-7	Reply	713
[line_break_token][line_break_token]Third, in the future, we will evaluate RAN using other quantifications of privacy as well in a defined application.	I-Reply	I-7	Reply	713
For example, we could measure the privacy by the hidden failure, i.e., the ratio between the background patterns that were discovered based on RAN‚Äôs Encoder output, and the sensitive patterns founded from the raw data, in an object recognition task.	I-Reply	I-7	Reply	713
[line_break_token] [line_break_token]Response #7: Thanks for pointing out the citation problem in Section 3.1.	B-Reply	B-9	Reply	713
In the revision, we have added explanation and cited more articles about several attacks for how the raw data can cause privacy risks in Section 1.	I-Reply	I-9	Reply	713
For example, underlying correlation detection, re-identification and other malicious mining.	I-Reply	I-9	Reply	713
As for the ‚ÄúNoisy Data‚Äù method, we have added the citation on differential privacy in Section 3.1.	I-Reply	I-9	Reply	713
[line_break_token] [line_break_token]Response #8: We have re-plotted Figure 3 and Figure 4 to improve the readability.	B-Reply	B-10	Reply	713

[line_break_token][line_break_token][ Summary ][line_break_token][line_break_token]This paper presents a new modified beam search algorithm that promotes diverse beam candidates.	O	O	Review	499
It is a well known problem ‚Äîwith both RNNs and also non-neural language models‚Äî that beam search tends to generate beam candidates that are very similar with each other, which can cause two separate but related problems: (1) search error: beam search may not be able to discover a globally optimal solution as they can easily fall out of the beam early on, (2) simple, common, non-diverse output: the resulting output text tends to be generic and common.	O	O	Review	499
[line_break_token][line_break_token]This paper aims to address the second problem (2) by modifying the search objective function itself so that there is a distinct term that scores diversity among the beam candidates.	O	O	Review	499
In other words, the goal of the presented algorithm is not to reduce the search error of the original objective function.	O	O	Review	499
In contrast, stack decoding and future cost estimation, common practices in phrase-based SMT, aim to address the search error problem.	O	O	Review	499
[line_break_token][line_break_token][ Merits ][line_break_token][line_break_token]I think the Diverse Beam Search (DBS) algorithm proposed by the authors has some merits.	O	O	Review	499
It may be useful when we cannot rely on traditional beam search on the original objective function either because the trained model is not strong enough, or because of the search error, or because the objective itself does not align with the goal of the application.	O	O	Review	499
[line_break_token][line_break_token][ Weaknesses ][line_break_token][line_break_token]It is however not entirely clear how the proposed method compares against more traditional approaches like stack decoding and future cost estimation, on tasks like machine translation, as the authors compare their algorithm mainly against L&J‚Äôs diverse LM models and simple beam search.	O	O	Review	499
[line_break_token][line_break_token]In fact, modification to the objective function has been applied even in the neural MT context.	B-Review	B-2	Review	499
For example, see equation (14) in page 12 of the following paper:[line_break_token][line_break_token]"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation" (<a href="https://arxiv.org/pdf/1609.08144v2.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1609.08144v2.pdf)</a>[line_break_token][line_break_token]where the attention coverage term serves a role similar to stack decoding (though unlike stack decoding, the objective term is entirely re-defined, more similarly to DBS proposed in this work), and the length penalty may have an effect that indirectly promotes more informative (thus more likely diverse) responses.	O	O	Review	499
[line_break_token][line_break_token]Comparison against these existing algorithms would make the proposed work more complete.	B-Review	B-2	Review	499
[line_break_token][line_break_token]Also, I have a mixed feeling about computing and reporting only *oracle* BLUE, CIDEr, METEOR, etc.	B-Review	B-3	Review	499
Especially given how these oracle scores are very close to each other, and that developing a high performing ranking has not been addressed in this work (and that doing so must be not all that trivial), I‚Äôm somewhat skeptical how much of DBS results make a practical difference.	I-Review	I-3	Review	499
[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]**** [Update after the author responses] ****[line_break_token][line_break_token]The authors addressed some of my concerns by adding a new baseline comparison against Wu et al 2016.	O	O	Review	499
Thus I will raise my score to 6.	O	O	Review	499
[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Review	499
Thank you for the feedback.	O	O	Reply	499
[line_break_token][line_break_token]Comparison to Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation: As noted by the reviewer, this paper uses two methods for diverse decodings ‚Äî (1) modified objective that includes a coverage penalty and (2) length normalization. (	B-Reply	B-2	Reply	499
eq.	I-Reply	I-2	Reply	499
14)‚Ä®[line_break_token][line_break_token]The coverage penalty term as proposed in that paper (using attention over the inputs to define ‚Äòcoverage‚Äô) is intricately tied to the task of NMT and unlike DBS does not generalize to other sequence decoding tasks (e.g. image captioning, visual question generation, dialog, etc).	I-Reply	I-2	Reply	499
Unlike NMT, some input information can be ignored in other tasks.	I-Reply	I-2	Reply	499
In contrast, the length-normalization term to select the top-B completed beams can be easily implemented for any decoding scenario.	I-Reply	I-2	Reply	499
[line_break_token][line_break_token]Thus, following your request, we have updated the paper to include comparison to this for both captioning and machine translation.	I-Reply	I-2	Reply	499
Following the experimental setup in the paper, for fairness to all techniques, we tune the strength \alpha through a grid search for the oracle accuracy on a held-out validation set (0.8 and 0.6 for captioning on PASCAL-50S and 0.6 for MT).	I-Reply	I-2	Reply	499
Table 1 and 2 in the updated pdf show results on captioning and MT respectively.	I-Reply	I-2	Reply	499
We find that DBS length normalization helps over BS in the order of 0.4 BLEU points, but performs 0.2 BLEU points worse than DBS on MT.	I-Reply	I-2	Reply	499
Thank you for this suggestion.&nbsp;‚Ä®[line_break_token][line_break_token]We also investigate the importance of the length term (in the Discussion section of the Appendix) by computing the correlation between the length and the accuracy obtained for each generated hypothesis.	B-Reply	B-4	Reply	499
On the PASCAL-50S dataset, we observe that the correlation with length and SPICE is insignificant for all decoding methods - BS, DBS and L&J16.	O	O	Reply	499
[line_break_token]Ôøº[line_break_token]Significance of DBS results:&nbsp;The oracle accuracy is a measure of the maximum accuracy that can be achieved by a list of M decoded solutions (assuming access to a perfect re-ranker).	O	O	Reply	499
As the goal of our paper is to develop an efficient diverse decoding technique, coming up with better re-ranking methods is an entirely different problem that is beyond the scope of this work.&nbsp;‚Ä®[line_break_token][line_break_token]We perform additional analysis between the beam budget and corresponding oracle accuracy of the generated lists (presented in the Discussion section in the supplementary).	B-Reply	B-1	Reply	499
We notice that DBS generates high-scoring sequences at smaller beam sizes as compared to the baselines -- meaning that it utilizes the beam budget better to explore the search space.	I-Reply	I-1	Reply	499
In this context, we believe that efficient diverse decoding techniques can help us use simpler re-rankers that need to perform fewer comparisons to select the top-1 solution.&nbsp;‚Ä®[line_break_token][line_break_token]Also, we would like to point out that the gains obtained from diverse decoding on NMT are consistent with L&J16 -- oracle@20 increases by a score of 0.6 due to DBS, compared to using BS. (	O	O	Reply	499
L&J16 obtain a score increase of 0.3 due to diverse decoding at B=200).	O	O	Reply	499
While it is possible that machine translation as a task does not require significant diversity in its outputs, DBS shows the potential of obtaining competitive gains provided access to a good re-ranker.&nbsp;‚Ä®[line_break_token][line_break_token]Finally, we note that oracle accuracies are a well-established performance metric, used by a line of previous work -- Batra et al 2012, Prasad et al 2014, Kirillov et al 2015 and Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles (Lee et al 2016).&nbsp	O	O	Reply	499

The authors present a heirarchical graph-to-graph translation method for generating novel organic molecules.	O	O	Review	20046
[line_break_token]Working from the model of Jin et al (2019), the authors introduce a three step heirarchy - the model first determines where a substructure should be generated, what is the substructure, then the attachments to the existing molecule.	O	O	Review	20046
[line_break_token]All steps of this uses embeddings generated from a message passing network - these embeddings are input into a few bilinear attention layers to obtain the heirarchical generation scheme.	O	O	Review	20046
[line_break_token]The model is trained with molecular pairs (X, Y), and a VAE loss - a hidden z vector controls the way to modify X to improve its properties.	O	O	Review	20046
[line_break_token]The encoder is just a MLP over the difference between sum of embeddings at a atom level and at the substructure level.	O	O	Review	20046
[line_break_token]The model is evaluated on accuracy and diversity, in both conditional and unconditional settings.	O	O	Review	20046
[line_break_token]The experiments show a small improvement over previous SOTA algorithms.	O	O	Review	20046
[line_break_token][line_break_token]This is a borderline paper, and I'm leaning towards a weak reject, because I don't believe the model is well motivated enough:[line_break_token]- Sec 3.1 it's unclear how the substructures are generated - they provide a lot of inductive bias for the algorithm.	B-Review	B-1	Review	20046
[line_break_token]  Are they automatically generated or built from a database of substructures?	I-Review	I-1	Review	20046
[line_break_token]- Variational decoding does not seem well motivated enough - would a stochastic decoding procedure not work as well as having a latent vector that essentially adds noise to the training?	B-Review	B-2	Review	20046
[line_break_token]- The experiments seem interesting and comprehensive - it seems that the model learns to exploit the biases and increase logP, as well as showing the ability to conditionally turn off DRD2-active properties of the molecules.	O	O	Review	20046
[line_break_token][line_break_token]Some questions:[line_break_token]- Why not use a Transformer instead of an LSTM or GRU?	B-Review	B-3	Review	20046
The cell naturally acts over sets of neighbors and transformers are a natural model to tackle this problem.	I-Review	I-3	Review	20046
[line_break_token]- Sec 3.1 Topological Prediction, the attention is over c_{X}^{S} but the text claims it should be over c_{X}^{G}?	B-Review	B-4	Review	20046
Is ^G the attention substructure?	I-Review	I-4	Review	20046
[line_break_token]- Sec 3.1 Attachment Layer MPN: the A_i seem to be a tuple (S_i, {v_j}).	B-Review	B-5	Review	20046
The set of attaching atoms is limited to 2 right?	I-Review	I-5	Review	20046
It might be more clear to simply enumerate them here if so.	I-Review	I-5	Review	20046
[line_break_token]- Sec 3.1 Substructure Tree: Since tree decompositions are not unique, does this work use the different tree decompositions and DFS traversals as data augmentations?	B-Review	B-6	Review	20046
[line_break_token]- Table 2b: What is a "two-layer" and "one layer" encoder?	B-Review	B-7	Review	20046
Is it the size of the MLP or the removal of the attachment MPNs?	I-Review	I-7	Review	20046
[line_break_token]- Ablation study: Since the Attachment Layer has all the substructure information, this ablation should ideally make sure the models all have a similar number of parameters, and the decrease in performance isn't due to the decrease in parameters.	B-Review	B-8	Review	20046
[line_break_token][line_break_token]Nits:[line_break_token]- Sec 3.1 "bi-linear" should not have a dash, bilinear is one word.	B-Review	B-9	Review	20046
[line_break_token]	O	O	Review	20046
hank you for your insightful comments.	O	O	Reply	20046
We want to first explain the motivation of our approach.	B-Reply	B-10	Reply	20046
The proposed hierarchical architecture seeks to address two key limitations of the junction tree method [Jin et al 2019], which is illustrated in Figure 1 in the paper (page 2):[line_break_token] - Their decoding is a strictly two-stage process (latent vectors -&gt; junction tree -&gt; graph).	O	O	Reply	20046
In the first stage, substructures are chosen without regard to how they can be attached to each other in the second stage.	B-Reply	B-10	Reply	20046
Therefore, it can result in invalid junction trees that cannot be realized into any molecule (see Figure 1a).	I-Reply	I-10	Reply	20046
[line_break_token] - Their local graph decoder can lead to inconsistent substructure attachments (see Figure 1b).	O	O	Reply	20046
[line_break_token][line_break_token]The first problem is addressed by our hierarchical decoding process, where the predicted attachments are fed into decoder message passing network to guide substructure prediction.	B-Reply	B-10	Reply	20046
We solve the second problem by using an autoregressive decoder where previous attachment choices directly impact later substructure and attachment predictions.	I-Reply	I-10	Reply	20046
[line_break_token][line_break_token]Some clarifications:[line_break_token] - The encoder is the hierarchical message passing network that outputs substructure and atom vectors (not MLP).	B-Reply	B-11	Reply	20046
MLP is the variational inference module that learns the latent vector z, which is in addition to the message passing network.	I-Reply	I-11	Reply	20046
[line_break_token] - The model achieves pretty large improvements on some tasks.	I-Reply	I-11	Reply	20046
For example, on the DRD2 task our model shows large improvement over previous SOTA (77.8% -&gt; 85.9%).	O	O	Reply	20046
[line_break_token][line_break_token]Q1: How are the substructures generated?	O	O	Reply	20046
[line_break_token]Substructures are automatically extracted from the molecules in the training set, in order to ensure structural coverage.	B-Reply	B-1	Reply	20046
For a given molecule, we extract its (smallest) rings and bonds as substructures and add them to the vocabulary.	I-Reply	I-1	Reply	20046
This procedure is purely data-driven.	I-Reply	I-1	Reply	20046
[line_break_token]Indeed, the substructure vocabulary provides a lot of inductive bias for the algorithm and optimizing the vocabulary for downstream task is an interesting future work.	I-Reply	I-1	Reply	20046
[line_break_token][line_break_token]Q2: Variational decoding is not well motivated.	O	O	Reply	20046
Why not using a stochastic decoding procedure?	O	O	Reply	20046
[line_break_token]We used variational decoding for two reasons:[line_break_token] - All the prior work (Seq2Seq and JTNN) used variational decoding.	B-Reply	B-2	Reply	20046
Therefore we adopted the same strategy to establish a direct comparison.	I-Reply	I-2	Reply	20046
[line_break_token] - Recent work has shown that variational decoding can generate more diverse outputs than stochastic decoding (e.g., in image translation [Zhu et al 2017] and machine translation [Shen et al 2019]).	I-Reply	I-2	Reply	20046
The reason is that stochastic decoding tends to learn small, local variations (e.g., replacing single atoms), while variational decoding captures diversity beyond local variations.	I-Reply	I-2	Reply	20046
To show this, we trained our model without variational inference and used stochastic decoding at test time.	I-Reply	I-2	Reply	20046
On the logP (sim 0.6) dataset, the performance drops from 2.49 to 2.06 and diversity drops from 0.381 to 0.342.	I-Reply	I-2	Reply	20046
On the logP (sim 0.4) dataset, the performance drops from 3.98 to 3.72 and diversity drops from 0.564 to 0.502.	I-Reply	I-2	Reply	20046
[line_break_token][line_break_token]Q3: Why not use a Transformer instead of an LSTM or GRU?	O	O	Reply	20046
[line_break_token]We used LSTM / GRU because message passing networks (MPN) are standard choices for molecules and many previous works build upon MPNs (with various parameterizations).	B-Reply	B-3	Reply	20046
We agree that transformer is a promising architecture for graphs (especially if further tailored to graphs) but the gains are unclear at this point.	I-Reply	I-3	Reply	20046
[line_break_token][line_break_token]Q4: Topological Prediction: the attention is over but the text claims it should be over?	O	O	Reply	20046
[line_break_token]We apologize for the confusion.	B-Reply	B-4	Reply	20046
This is a typo and it should be.	I-Reply	I-4	Reply	20046
The typo is now fixed.	I-Reply	I-4	Reply	20046
[line_break_token][line_break_token]Q5: Attachment Layer MPN: the A_i seem to be a tuple.	O	O	Reply	20046
The set of attaching atoms is limited to 2 right?	O	O	Reply	20046
[line_break_token]The set of attaching atoms can be more than 2 because two rings can have three or more overlapping atoms.	B-Reply	B-5	Reply	20046
[line_break_token][line_break_token]Q6: Since tree decompositions are not unique, does this work use different tree decompositions and DFS traversals as data augmentations?	O	O	Reply	20046
[line_break_token]We didn‚Äôt use different tree decompositions / DFS traversals for data augmentation because none of the baselines used any data augmentation strategies.	B-Reply	B-6	Reply	20046
[line_break_token][line_break_token]Q7: Table 2b: What is a "two-layer" and "one-layer" encoder?	O	O	Reply	20046
[line_break_token]Two-layer encoder means the top substructure layer MPN is removed.	B-Reply	B-7	Reply	20046
One-layer encoder means the attachment layer MPN is also removed.	I-Reply	I-7	Reply	20046
[line_break_token][line_break_token]Q8: Ablation studies, number of parameters.	O	O	Reply	20046
[line_break_token]For ablation studies, all models have a similar number of parameters.	B-Reply	B-8	Reply	20046
For both datasets, all the model parameters are between 6M to 6.2M. [line_break_token][line_break_token]References[line_break_token]Zhu et al "Toward multimodal image-to-image translation."	O	O	Reply	20046
Advances in Neural Information Processing Systems.	O	O	Reply	20046
2017.	O	O	Reply	20046
[line_break_token]Shen et al "Mixture Models for Diverse Machine Translation: Tricks of the Trade."	O	O	Reply	20046
International Conference on Machine Learning.	O	O	Reply	20046
2019	B-Reply	B-2	Reply	20046

[line_break_token]After the rebuttal:[line_break_token][line_break_token]The paper contains an interesting set of results (mainly produced after the initial submission), but novelty is limited, and presentation is suboptimal.	O	O	Review	427
[line_break_token][line_break_token]For me now the biggest problem now is that the title and the content do not correspond.	B-Review	B-8	Review	427
The authors clearly attack deterministic encoder-decoder models (as described in 3.2), which are not at all the same as generative models, even though many generative models make use of this architecture.	I-Review	I-8	Review	427
A small experiment with sampling is interesting, but does not change the overall focus of the paper.	I-Review	I-8	Review	427
This inconsistency in not acceptable.	I-Review	I-8	Review	427
The whole issue could be resolved for example by simply replacing "generative models" by "encoder-decoder networks" in the title.	I-Review	I-8	Review	427
Then I would tend towards recommending acceptance.	I-Review	I-8	Review	427
[line_break_token][line_break_token]------[line_break_token]Initial review:[line_break_token][line_break_token]The paper describes three approaches to generating adversarial examples for deep encoder-decoder generative networks (trained as VAE or VAE-GAN), and shows a comparative analysis of these.	O	O	Review	427
While the phenomenon of adversarial examples in discriminative models is widely known and relatively well studied, I am not aware of previous work on adversarial examples for generative networks, so this work is novel (there is a concurrent work by Tabacof et al which should be cited, though).	O	O	Review	427
 The paper has significantly improved since the initial submission; still, I have a number of remarks on presentation and experimental evaluation.	O	O	Review	427
I am in the borderline mode, and may change my rating during the discussion phase.	O	O	Review	427
[line_break_token][line_break_token]Detailed comments:[line_break_token][line_break_token]1) The paper is 13 pages long - significantly over the recommended page limit of 8 pages.	B-Review	B-1	Review	427
Reviewers have to read multiple papers, multiple versions of each, it is a lot of work.	I-Review	I-1	Review	427
Large portions of the paper should be shortened and/or moved to the appendix.	I-Review	I-1	Review	427
It is job of the authors to make the paper concise and readable. "	I-Review	I-1	Review	427
in our attempts to be thorough, we have had a hard time keeping the length down" is a bad excuse - it may be hard, but has to be done.	I-Review	I-1	Review	427
[line_break_token][line_break_token]2) I intentionally avoided term "generative model" above because it is not obvious to me if the attacks described by the authors indeed attack generative models.	B-Review	B-2	Review	427
To clarify, the authors train encoder-decoders as generative models (VAE or VAE-GAN), but then remove all stochasticity (sampling) and prior on the latent variables: that is, they treat the models as deterministic encoders-decoders.	I-Review	I-2	Review	427
It is not a big surprise that a deterministic deep network can be easily tricked; it would be much more interesting to see if the probabilistic aspect of generative models makes them more robust to such attacks.	I-Review	I-2	Review	427
Am I missing something?	I-Review	I-2	Review	427
I would like the authors to clarify their view on this and adjust the claims in the paper if necessary.	I-Review	I-2	Review	427
[line_break_token][line_break_token]3) The paper is motivated by possible attacks on a data channel which uses a generative network for compressing information.	B-Review	B-3	Review	427
Description of the attack scenario in 3.1 does not look convincing to me.	I-Review	I-3	Review	427
It takes a huge amount of space and I do not think it adds much to the paper.	I-Review	I-3	Review	427
First, experiments on natural images are necessary to judge if the proposed attack could succeed in a realistic scenario and second, I am not aware of any existing practical applications of VAEs to image compression: attacking JPEG would be much more practical.	I-Review	I-3	Review	427
[line_break_token][line_break_token]4) Experiments are limited to MNIST and, in the latest version, SVHN (which is very nice).	B-Review	B-4	Review	427
While no good generative models of general natural images exist, it is common to evaluate generative models on datasets of faces, so this would be another very natural domain for testing the proposed approach.	I-Review	I-4	Review	427
[line_break_token][line_break_token]Smaller remarks:[line_break_token]1) Usage of "Oracle" in 3.2 does not look appropriate - oracle typically has access to (part of) ground truth, which is not the case here as far as I understand.	B-Review	B-5	Review	427
[line_break_token]2) Beginning of section 4: "All three methods work for any generative architecture that relies on a learned latent representation z" - "are technically applicable to" would be more correct than "work for".	B-Review	B-6	Review	427
[line_break_token]3) 4.1: "confidentally"[line_break_token]	B-Review	B-7	Review	427
Thanks for the review!	O	O	Reply	427
 The new draft is shorter, reducing it to 11 pages while also adding some new results.	B-Reply	B-1	Reply	427
[line_break_token][line_break_token]In this draft we have added experimental results using stochastic sampling.	B-Reply	B-2	Reply	427
They are referenced in the second paragraph of Section 5 with a figure in the appendix.	I-Reply	I-2	Reply	427
The results show that for most examples, sampling doesn‚Äôt meaningfully change the reconstructed adversarial examples, and the attack is similarly successful even when sampling is being used.	I-Reply	I-2	Reply	427
[line_break_token][line_break_token]We have also added some citations to clarify where the attack scenario sits in the current literature.	B-Reply	B-3	Reply	427
 There are a few recent publications exploring using deep networks as compression models, similar to what we describe in Section 3.1, for example: <a href="https://arxiv.org/abs/1511.06085," target="_blank" rel="nofollow">https://arxiv.org/abs/1511.06085,</a> and <a href="https://arxiv.org/abs/1608.05148."	O	O	Reply	427
target="_blank" rel="nofollow">https://arxiv.org/abs/1608.05148.</a>  We are not attempting to directly attack these networks in this work, however -- we are instead motivating why this type of attack is relevant to current work.	O	O	Reply	427
[line_break_token][line_break_token]Thanks for the suggestion to use faces!	B-Reply	B-4	Reply	427
 We have added experiments on CelebA in the latest draft.	I-Reply	I-4	Reply	427
 The results in Section 5.3 show that the attacks are equally effective even in the more complex domain.	I-Reply	I-4	Reply	427
 We have also addressed your other comments in this draft.	I-Reply	I-4	Reply	427
[line_break_token]	O	O	Reply	427

UPDATE: [line_break_token]I acknowledge that I‚Äòve read the author responses as well as the other reviews.	O	O	Review	265
[line_break_token]I appreciate the clarifications and improvements made to the paper.	O	O	Review	265
I‚Äòve updated my score to 6 Weak Accept.	O	O	Review	265
[line_break_token][line_break_token]####################[line_break_token][line_break_token]This paper presents the idea to use blurred images as regularizing examples to improve out-of-distribution (OOD) detection performance based on Random Network Distillation (RND).	O	O	Review	265
The paper proposes to generate sets of such blurred images via Singular Value Decomposition (SVD) on the training images by pruning the lowest K non-zero singular values.	O	O	Review	265
The proposed method, SVD-RND, then extends the standard RND objective, which is to train a predictor network f to minimize the L2 loss to the output of some randomly initialized network over the (original) training data, with an additional regularization term that minimizes the L2 loss to the outputs of further multiple randomly initialized networks over the sets of blurred images.	O	O	Review	265
In OOD experiments on CIFAR-10, SVHN, TinyImageNet, LSUN, and CelebA, the proposed SVD-RND consistently outperforms baselines and recent competitors which are demonstrated to be vulnerable to blurred images.	O	O	Review	265
[line_break_token][line_break_token]I find it hard to make a definitive evaluation for this work at this point and would like to take the authors' responses into account for my final recommendation.	O	O	Review	265
The main idea of the paper to generate adversarial examples for training via blurring is rather simple and thus the novelty of this work is somewhat minor.	B-Review	B-8	Review	265
I think the quality of the paper also suffers from many statements in the text that draw too general and too bold conclusions at this point in my mind.	I-Review	I-8	Review	265
The presentation overall is rather unpolished (see comments below).	I-Review	I-8	Review	265
However, I find the empirical results itself quite strong and convincing and think they would make a relevant and significant contribution to the community.	O	O	Review	265
I do have questions left open though that need clarification:[line_break_token][line_break_token](i) I don‚Äôt see why different techniques for blurring (SVD, DCT, GB) should lead to such different results as the approach remains conceptually similar.	B-Review	B-1	Review	265
Do you have a reason/intuition why SVD gives the best results?	I-Review	I-1	Review	265
Might SVD just be the easiest to tune method?	I-Review	I-1	Review	265
[line_break_token][line_break_token](ii) What do you think is the key reason that SVD-RND also appears to generalize too non-blurry OOD samples?	B-Review	B-2	Review	265
Could you elaborate more on the two reasons you give in the paper? (	I-Review	I-2	Review	265
1.	I-Review	I-2	Review	265
RND performance on samples orthogonal to the data; 2.	I-Review	I-2	Review	265
Discrimination between data and its low-rank projection)[line_break_token][line_break_token](iii) The generation and tuning of multiple sets of blurred images (how many samples per set?)	B-Review	B-3	Review	265
may get quite extensive for large datasets.	I-Review	I-3	Review	265
Could you be specific on the computational cost?	I-Review	I-3	Review	265
[line_break_token][line_break_token](iv) Might the deep generative models (e.g. GPND) fail to detect blurred images due to insufficient model capacity of the decoder which results in blurry reconstructions?	B-Review	B-4	Review	265
Have you varied the network capacity or latent space dimensionality of such models?	I-Review	I-4	Review	265
[line_break_token][line_break_token](v) What is the idea behind choosing the log effective rank in such an equidistant manner as proposed?	B-Review	B-5	Review	265
[line_break_token][line_break_token][line_break_token]####################[line_break_token]*Additional Feedback*[line_break_token][line_break_token]*Positive Highlights*[line_break_token]1.	O	O	Review	265
SVD-RND shows strong OOD detection performance in OOD experiments on a variety of image dataset combinations (CIFAR-10, SVHN, TinyImageNet, LSUN, and CelebA).	O	O	Review	265
[line_break_token]2.	B-Review	B-2	Review	265
The related work includes major works from all the related lines of research (Deep anomaly detection; OOD detection using side information; Adversarial examples/training)[line_break_token]3.	O	O	Review	265
Useful hyperparameter selection criterion based on effective rank if no OOD validation data is available.	O	O	Review	265
[line_break_token][line_break_token]*Ideas for Improvement* [line_break_token]4.	O	O	Review	265
I think the tone of the paper would greatly benefit from not drawing too general conclusions and too bold implications.	B-Review	B-6	Review	265
Keep statements precise and evidence-based.	I-Review	I-6	Review	265
Declare hypotheses as such.	I-Review	I-6	Review	265
[line_break_token]5.	B-Review	B-15	Review	265
I would appreciate a plot showing samples before and after blurring in the appendix to see the most effective degree of blurring.	B-Review	B-7	Review	265
Maybe also compare the different blurring baselines here to see differences.	I-Review	I-7	Review	265
[line_break_token]6.	B-Review	B-15	Review	265
Report std.	B-Review	B-9	Review	265
devs.	I-Review	I-9	Review	265
with your performance results to infer statistical significance.	I-Review	I-9	Review	265
[line_break_token]7.	B-Review	B-15	Review	265
Compare to the specific geometric transforms method as proposed in the paper [3] and not only using those transformations within your RND approach.	B-Review	B-10	Review	265
[line_break_token]8.	B-Review	B-15	Review	265
Add missing deep anomaly detection related work [6, 2, 5, 1].[line_break_token]9.	B-Review	B-11	Review	265
Expand the sensitivity analysis in Figure 3 (left) over a greater range of K. Especially, I would like to also see K = 0 (unblurred, original images) as a sanity check which may only improve over RND due to ensembling over multiple randomly initialized networks.	B-Review	B-12	Review	265
[line_break_token]10.	B-Review	B-15	Review	265
Consider the one-vs-rest anomaly detection evaluation benchmarks from Ruff et al [4] or Golan and El-Yaniv [3] to further infer the generalization performance of the proposed method.	B-Review	B-13	Review	265
[line_break_token]11.	O	O	Review	265
I think the paper spends too much time on introducing previous work.	B-Review	B-14	Review	265
Section 2 Related Work and Section 3 Background might be combined into one section.	I-Review	I-14	Review	265
[line_break_token][line_break_token]*Minor comments*[line_break_token]12.	B-Review	B-15	Review	265
In the abstract: ‚Äú... VAE or RND are known to assign lower uncertainty to the OOD data than the target distribution.	I-Review	I-15	Review	265
‚Äù is a bit strong.	I-Review	I-15	Review	265
Rather ‚Äúhave been observed‚Äù etc.	I-Review	I-15	Review	265
This is a working hypothesis in the community, but there is recent work (<a href="https://openreview.net/forum?id=Skg7VAEKDS)" target="_blank" rel="nofollow">https://openreview.net/forum?id=Skg7VAEKDS)</a> indicating (at least for VAEs) those are effects of poor model design.	O	O	Review	265
[line_break_token]13.	B-Review	B-15	Review	265
In the abstract: ‚Äú... efficient in test time ...‚Äù ¬ª ‚Äú... efficient at test time ...‚Äù[line_break_token]14.	I-Review	I-15	Review	265
In the abstract: ‚Äú... in CelebA domain.	I-Review	I-15	Review	265
‚Äù ¬ª ‚Äú... on the CelebA dataset.	I-Review	I-15	Review	265
‚Äù or just ‚Äú... on CelebA.‚Äù[line_break_token]15.	I-Review	I-15	Review	265
Section 1: ‚ÄúHowever, such models show underwhelming performance on detecting OOD, such as detecting SVHN from CIFAR-10.	I-Review	I-15	Review	265
Specifically, generative models assign a higher likelihood to the OOD data than the training data.	I-Review	I-15	Review	265
‚Äù.	I-Review	I-15	Review	265
I think those are way too general conclusions at the moment.	I-Review	I-15	Review	265
Rather something like ‚ÄúOOD detection performance of deep generative models has been called into question‚Äù and ‚Äúhave been observed to assign ...‚Äù.	I-Review	I-15	Review	265
[line_break_token]16.	I-Review	I-15	Review	265
Section 1: ‚ÄúSuch results clearly support the degeneracy of deep OOD detection schemes‚Äù.	I-Review	I-15	Review	265
Again, I find this way too bold of a statement at this point in time.	I-Review	I-15	Review	265
[line_break_token]17.	I-Review	I-15	Review	265
Section 2: ‚Äú... a recently proposed paper ...‚Äù ¬ª ‚Äú... a recent paper ...‚Äù[line_break_token]18.	I-Review	I-15	Review	265
Section 2: ‚Äú... outlier data independent of OOD data.	I-Review	I-15	Review	265
‚Äù.	I-Review	I-15	Review	265
What would outlier data not being out-of- distribution be?	I-Review	I-15	Review	265
[line_break_token]19.	I-Review	I-15	Review	265
Section 2: ‚ÄúGolan et al (2018) design geometrically transformed data and regularized the classifier ...‚Äù.	I-Review	I-15	Review	265
Not regularized.	I-Review	I-15	Review	265
They trained a classifier on labels identified with these transformations.	I-Review	I-15	Review	265
[line_break_token]20.	I-Review	I-15	Review	265
Section 2: ‚Äú..., resulting in OOD detection in each labeled data‚Äù ¬ª ‚Äú..., resulting in OOD detection on labeled data‚Äù[line_break_token]21.	I-Review	I-15	Review	265
A subsection title directly following a section title is bad style.	I-Review	I-15	Review	265
A major section should be introduced with a few sentences on what this section is about.	I-Review	I-15	Review	265
[line_break_token]22.	I-Review	I-15	Review	265
Figure 2, right plot: These loss curves are rather strange... Increasing, then sharply decreasing again.	I-Review	I-15	Review	265
Is there a drop in learning rate at epoch 80?	I-Review	I-15	Review	265
[line_break_token]23.	I-Review	I-15	Review	265
Many axis labels are too small and hard to read.	I-Review	I-15	Review	265
[line_break_token]24.	I-Review	I-15	Review	265
In Section 3.3.: ‚	I-Review	I-15	Review	265
Äú.. in Section 7.2.‚Äù ¬ª ‚Äú.. in Section 4.2.‚Äù?	I-Review	I-15	Review	265
[line_break_token]25.	I-Review	I-15	Review	265
The definition of the log effective rank in Eq.~2 is weird.	I-Review	I-15	Review	265
It's the entropy over the singular value distribution, i.e.. Also, the parameters/notation involved are not introduced.	I-Review	I-15	Review	265
[line_break_token]26.	I-Review	I-15	Review	265
Make clear you apply SVD on single images.	I-Review	I-15	Review	265
The paper alters formulations between data matrix and images...[line_break_token]27.	I-Review	I-15	Review	265
Several instances where citet is used instead of citep.	I-Review	I-15	Review	265
[line_break_token]28.	I-Review	I-15	Review	265
In Table 1: Separate the target column from the three OOD columns more clearly. (	I-Review	I-15	Review	265
e.g. vertical separator, center OOD, target in bold, etc.)	I-Review	I-15	Review	265
[line_break_token]29.	I-Review	I-15	Review	265
In Section 5.1: ‚Äúarea of the region under the ... curve‚Äù ¬ª ‚Äúarea under the ... curve‚Äù.	I-Review	I-15	Review	265
[line_break_token]30.	I-Review	I-15	Review	265
Figure 3: Better explain the plots.	I-Review	I-15	Review	265
Are the three curves the respective target classes?	I-Review	I-15	Review	265
What is the OOD set?	I-Review	I-15	Review	265
[line_break_token]31.	I-Review	I-15	Review	265
Figure 4: Maybe use subfigures with individual titles/captions.	I-Review	I-15	Review	265
[line_break_token]32.	I-Review	I-15	Review	265
Section 6: ‚ÄúFor evidence, we fine-tune the classifier ...‚Äù ¬ª ‚ÄúFor evidence, we fine-tune a classifier ...‚Äù[line_break_token]33.	I-Review	I-15	Review	265
Plots and Figures are somewhat scattered and not referenced chronologically.	I-Review	I-15	Review	265
[line_break_token]34.	I-Review	I-15	Review	265
Introduce the effective rank at the point where it is used (Section 6.2).	I-Review	I-15	Review	265
Somewhat unclear why to introduce this in Section 3 already.	I-Review	I-15	Review	265
[line_break_token]35.	I-Review	I-15	Review	265
Visually speaking, I find the RND examples in Figure 4 actually more anomalous than the top-anomalous SVD-RND samples (flashy colors, weird angles, borders, high contrast, ...)[line_break_token][line_break_token][line_break_token]####################[line_break_token]*References*[line_break_token][1] R. Chalapathy and S. Chawla.	O	O	Review	265
Deep learning for anomaly detection: A survey.	O	O	Review	265
arXiv preprint arXiv:1901.03407, 2019.	O	O	Review	265
[line_break_token][2] H. Choi, E. Jang, and A. A. Alemi.	O	O	Review	265
Waic, but why?	O	O	Review	265
generative ensembles for robust anomaly detection.	O	O	Review	265
arXiv preprint arXiv:1810.01392, 2018.	O	O	Review	265
[line_break_token][3] I. Golan and R. El-Yaniv.	O	O	Review	265
Deep anomaly detection using geometric transformations.	O	O	Review	265
In NIPS, 2018.	O	O	Review	265
[line_break_token][4] L. Ruff, R. A. Vandermeulen, N. G√∂rnitz, L. Deecke, S. A. Siddiqui, A. Binder, E. M√ºller, and M. Kloft.	O	O	Review	265
Deep one-class classification.	O	O	Review	265
In International Conference on Machine Learning, pages 4393‚Äì4402, 2018.	O	O	Review	265
[line_break_token][5] L. Ruff, R. A. Vandermeulen, N. G√∂rnitz, A. Binder, E. M√ºller, K.-R. M√ºller, and M. Kloft.	O	O	Review	265
Deep semi-supervised anomaly detection.	O	O	Review	265
arXiv preprint arXiv:1906.02694, 2019.	O	O	Review	265
[line_break_token][6] T. Schlegl, P. Seeb√∂ck, S. M. Waldstein, U. Schmidt-Erfurth, and G. Langs.	O	O	Review	265
Unsupervised anomaly detection with generative adversarial networks to guide marker discovery.	O	O	Review	265
In Proceedings International Conference on Information Processing in Medical Imaging, pages 146‚Äì157.	O	O	Review	265
Springer, 2017.	O	O	Review	265
[line_break_token]	O	O	Review	265
e thank the reviewer for extensive and worthy feedback.	O	O	Reply	265
[line_break_token][line_break_token]1.	B-Reply	B-3	Reply	265
I don‚Äôt see why different techniques for blurring (SVD, DCT, GB) should lead to such different results as the approach remains conceptually similar.	O	O	Reply	265
Do you have a reason/intuition why SVD gives the best results?	O	O	Reply	265
Might SVD just be the easiest to tune method?	O	O	Reply	265
[line_break_token][line_break_token]-&gt; We first note that the performance of Table 2.	B-Reply	B-1	Reply	265
was conducted on the small size of the hyperparameter search, which cannot cover the whole parameter space of DCT-RND and GB-RND.	I-Reply	I-1	Reply	265
Potentially, when we increase b_train or hyperparameter search space, GB-RND or DCT-RND can outperform SVD-RND.	I-Reply	I-1	Reply	265
For example, GB-RND shows similar results to SVD-RND on LSUN : SVHN, or TinyImageNet : SVHN domain.	I-Reply	I-1	Reply	265
 Therefore, although the result in Table 2 favors SVD-RND, we hesitate to assert that there is something special about SVD-RND.	I-Reply	I-1	Reply	265
[line_break_token]Rather, we just think SVD-RND is much easier to optimize than DCT-RND or GB-RND, and this contributed to the success of SVD-RND in Table 2.	I-Reply	I-1	Reply	265
[line_break_token][line_break_token]2.	I-Reply	I-1	Reply	265
What do you think is the key reason that SVD-RND also appears to generalize too non-blurry OOD samples?	O	O	Reply	265
Could you elaborate more on the two reasons you give in the paper? (	O	O	Reply	265
1.	B-Reply	B-3	Reply	265
RND performance on samples orthogonal to the data; 2.	O	O	Reply	265
Discrimination between data and its low-rank projection)[line_break_token][line_break_token]-&gt; Reviewer 1 also mentioned this aspect and we conducted an ablation study on reasoning #2.	B-Reply	B-2	Reply	265
We conducted the ablation by setting two cases: adversarial images that have the same rank to the blurred images, and adversarial images that have the same effective rank to the blurred images.	I-Reply	I-2	Reply	265
The result of those ablations was much worse than SVD-RND.	I-Reply	I-2	Reply	265
Therefore, we hypothesize that blurred images function as "projection" helps SVD-RND to achieve better OOD detection.	I-Reply	I-2	Reply	265
[line_break_token][line_break_token]3.	O	O	Reply	265
The generation and tuning of multiple sets of blurred images (how many samples per set?)	O	O	Reply	265
may get quite extensive for large datasets.	O	O	Reply	265
Could you be specific on the computational cost?	O	O	Reply	265
[line_break_token][line_break_token]-&gt; We generate each blurred image as equal to the size of the training data, which is 50000 on the experiment.	B-Reply	B-3	Reply	265
To be fair, we scaled the training epochs proportional to.	I-Reply	I-3	Reply	265
[line_break_token][line_break_token]In the training phase, we observed that generating blurred images compared to geometric transforms does not contribute much to the computation cost.	I-Reply	I-3	Reply	265
Rather, based on our setting, we employ an additional target network per blurred image and found that evaluation of the target network is the major factor in the computation cost when increases.	I-Reply	I-3	Reply	265
[line_break_token][line_break_token]Specifically, when, 0.255 seconds are taken per batch.	I-Reply	I-3	Reply	265
When, 0.294 seconds are taken per batch.	I-Reply	I-3	Reply	265
When, 0.333 seconds are taken per batch on average.	I-Reply	I-3	Reply	265
Therefore, we can extrapolate that the load of 0.039 seconds is appended for computation cost when b_train increases by 1.	I-Reply	I-3	Reply	265
[line_break_token][line_break_token]4.	O	O	Reply	265
Might the deep generative models (e.g. GPND) fail to detect blurred images due to insufficient model capacity of the decoder which results in blurry reconstructions?	O	O	Reply	265
Have you varied the network capacity or latent space dimensionality of such models?	O	O	Reply	265
[line_break_token][line_break_token]-&gt; We have tried some ablation studies on GPND in CIFAR-10 : (SVHN, LSUN, TinyImageNet ) domain.	O	O	Reply	265
[line_break_token][line_break_token]1) First, we doubled the size of the latent dimension, and this gave worse results.	B-Reply	B-4	Reply	265
[line_break_token]2) We changed the structure of encoder to ResNet34 and this gave TNR(at 95% TPR) of 0.052/0.807/0.692.	I-Reply	I-4	Reply	265
[line_break_token]3) We changed the capacity of the network by doubling the output size of each layer of the encoder, decoder, and discriminator.	I-Reply	I-4	Reply	265
This gave TNR of 0.053/0.820/0.725.	I-Reply	I-4	Reply	265
[line_break_token][line_break_token]In conclusion, through our ablation analysis, performance on SVHN : (LSUN, TinyImageNet) improved by varying the network capacity of GPND.	I-Reply	I-4	Reply	265
However, we failed to improve OOD detection performance in CIFAR-10 : SVHN domain.	I-Reply	I-4	Reply	265
[line_break_token][line_break_token]5.	I-Reply	I-4	Reply	265
What is the idea behind choosing the log effective rank in such an equidistant manner as proposed?	O	O	Reply	265
[line_break_token][line_break_token]-&gt; By setting target log effective rank equidistantly, we wanted to minimize the worst-case log effective rank difference between the potential OOD and the blurred data chosen by our heuristic.	B-Reply	B-5	Reply	265
 [line_break_token][line_break_token]6.	O	O	Reply	265
I think the tone of the paper would greatly benefit from not drawing too general conclusions and too bold implications.	O	O	Reply	265
Keep statements precise and evidence-based.	O	O	Reply	265
Declare hypotheses as such.	O	O	Reply	265
[line_break_token][line_break_token]-&gt; Thanks for the feedback.	B-Reply	B-6	Reply	265
We have modified strong assertions in the revised version.	I-Reply	I-6	Reply	265
[line_break_token][line_break_token]7.	O	O	Reply	265
I would appreciate a plot showing samples before and after blurring in the appendix to see the most effective degree of blurring.	O	O	Reply	265
Maybe also compare the different blurring baselines here to see differences.	O	O	Reply	265
[line_break_token][line_break_token]-&gt; We also appended the CIFAR-10 sample before and after blurring in Appendix E. We plotted with the best performing parameters of SVD-RND, DCT-RND, and GB-RND.	B-Reply	B-7	Reply	265

Summary:[line_break_token]This paper proposed an extension of the dynamic coattention network (DCN) with deeper residual layers and self-attention.	O	O	Review	463
It also introduced a mixed objective with self-critical policy learning to encourage predictions with high word overlap with the gold answer span.	O	O	Review	463
The resulting DCN+ model achieved significant improvement over DCN.	O	O	Review	463
[line_break_token][line_break_token]Strengths:[line_break_token]The model and the mixed objective is well-motivated and clearly explained.	O	O	Review	463
[line_break_token]Near state-of-the-art performance on SQuAD dataset (according to the SQuAD leaderboard).	O	O	Review	463
[line_break_token][line_break_token]Other questions and comments:[line_break_token]The ablation shows 0.7 improvement on EM with mixed objective.	B-Review	B-1	Review	463
It is interesting that the mixed objective (which targets F1) also brings improvement on EM.	I-Review	I-1	Review	463
[line_break_token]	O	O	Review	463
Thanks for your comments.	O	O	Reply	463
In practice the F1 and EM metrics are closely correlated.	B-Reply	B-1	Reply	463
We chose to use the F1 score as a metric because it offers fine grain signals as to how well the span predicted matches the ground truth span, whereas the EM score only rewards exact gloss matches	I-Reply	I-1	Reply	463

* Summarize what the paper claims to do/contribute.	O	O	Review	570
[line_break_token]This paper claims to extend existing image translation works, like CycleGAN, to domain pairs that are not similar in shape.	O	O	Review	570
It is proposed to do so by using a VGG network trained on classification (I assume on Imagenet), extracting features from the two domains and learn 5 CycleGANs to translate for each level of the feature hierarchy.	O	O	Review	570
At each level of the hierarchy the translation from the previous level is used to condition the translation for the current level.	O	O	Review	570
During inference, the final image translation is done by "feature inversion" (a technique proposed in Dosovitsikiy and Brox, 2016) from the final feature layer.	O	O	Review	570
The technique is show on example from a number of pairs of domains like Zebra-to-Elephant (and back), Giraffe-to-Zebra (and back), Dog-to-Cat (and back) and is compared with a number of baselines qualitatively and quantitatively with the FID score.	O	O	Review	570
 [line_break_token][line_break_token]* Clearly state your decision (accept or reject) with one or two key reasons for this choice.	O	O	Review	570
[line_break_token]Weak Reject.	O	O	Review	570
[line_break_token][line_break_token]Major reasons:[line_break_token]- The problem itself, as stated in the introduction, seems ill-posed to me.	B-Review	B-1	Review	570
One of the struggles I had while looking through the results was to understand what the images should be looking like.	I-Review	I-1	Review	570
ie What should a zebra translated to a giraffe look like?	I-Review	I-1	Review	570
The motivation for such a problem is also not immediately clear either.	I-Review	I-1	Review	570
[line_break_token]- Most of the resulting images do not seem "translated" to me.	B-Review	B-2	Review	570
As stated in the paper (end of p.2) "one aims to transform a specific type of object without changing the background."	I-Review	I-2	Review	570
As one can see in eg Fig.	I-Review	I-2	Review	570
1 the resulting translations are completely different images with the foreground object of the new domain in roughly similar poses.	I-Review	I-2	Review	570
The background in most cases does not persist.	I-Review	I-2	Review	570
What I suspect is actually happening here is that the high-level semantics from the first image are used as some sort of noise to generate new images from the new domain.	I-Review	I-2	Review	570
One question I had, for example: could we be getting similar results if we used the VGG bottleneck as the noise vector in an InfoGAN?	I-Review	I-2	Review	570
Since the VGG network is pretrained and used in the same way in both domains, I imagine we would be seeing something very similar. (	I-Review	I-2	Review	570
and it would be def.	I-Review	I-2	Review	570
preferrable to tuning 10 GANs!)	I-Review	I-2	Review	570
[line_break_token][line_break_token]* Provide supporting arguments for the reasons for the decision.	O	O	Review	570
[line_break_token]Some of the decisions made in the paper were unclear and not supported adequately.	B-Review	B-3	Review	570
The questions (in rough order of importance) that made some of the contributions unclear to me:[line_break_token]- Why wasn't a final translator used for the final image, conditioned on the final \tilde{b}_1?	I-Review	I-3	Review	570
[line_break_token]- Is the VGG network pretrained on ImageNet?	B-Review	B-4	Review	570
Why wasn't another task used that could be retaining more of the relevant features?	I-Review	I-4	Review	570
eg on semantic segmentation[line_break_token]- Could this be used for networks pretrained on other datasets?	B-Review	B-5	Review	570
Presumably ImageNet has information about the animals translated in this paper.	I-Review	I-5	Review	570
Even better, could we somehow learn these features for the domain pairs automatically somehow?	I-Review	I-5	Review	570
[line_break_token]- How meaningful is the FID score really in this case?	B-Review	B-6	Review	570
[line_break_token]- How were the 10 GANs tuned?	B-Review	B-7	Review	570
[line_break_token][line_break_token]* Provide additional feedback with the aim to improve the paper.	O	O	Review	570
Make it clear that these points are here to help, and not necessarily part of your decision assessment.	O	O	Review	570
[line_break_token]- It is mentioned on p.4 that "clamping is potentially a harmful irreversible operation" but that harmful results were not observed.	B-Review	B-8	Review	570
As I was reading that I was wondering how these results would actually look like.	I-Review	I-8	Review	570
[line_break_token]- On p. 6 it is mentioned that the number of images for 2 categories are reported in another paper.	B-Review	B-9	Review	570
I think it'd take less space to actually report the number of images here.	I-Review	I-9	Review	570
[line_break_token]- On p.7 it is mentioned that the number of instances is preserved, however it should be made clear that it's is perserved in some (or most if that is what was observed) of the examples.	B-Review	B-10	Review	570
[line_break_token]	O	O	Review	570
hank you for taking the time to review our paper and for your thoughtful suggestions and questions.	O	O	Reply	570
[line_break_token][line_break_token]--- The problem itself is ill-posed.	O	O	Reply	570
 [line_break_token]Generally UNIT (unpaired image translation) is an ill-posed task: what should a real image look like when translated to a Monet painting?	B-Reply	B-1	Reply	570
One can imagine the outcome, yet there‚Äôs no precise definition.	I-Reply	I-1	Reply	570
We would argue that the degree of ill-posedness depends on the domain.	I-Reply	I-1	Reply	570
In the case of animal to animal translation, you would expect the result to contain a realistic looking animal with the same:[line_break_token]    1.	I-Reply	I-1	Reply	570
Semantic parts of an animal (i.e. head of a zebra to head of a giraffe).	I-Reply	I-1	Reply	570
That also includes translating the correct amount of instances (i.e. 2 zebras to 2 giraffes).	I-Reply	I-1	Reply	570
[line_break_token]    2.	I-Reply	I-1	Reply	570
 Location and scale of the objects (i.e. a small zebra at the left corner of the image should translate to small giraffe at the same location).	I-Reply	I-1	Reply	570
[line_break_token]    3.	I-Reply	I-1	Reply	570
Pose [line_break_token]    4.	I-Reply	I-1	Reply	570
Background[line_break_token]While we mostly succeed at 1-3, preserving the background is indeed problematic when translating deep features.	I-Reply	I-1	Reply	570
However, this is common in UNIT.	I-Reply	I-1	Reply	570
While shape non-deforming methods, such as cycleGAN, might not change the structures in the background, the color/style is typically changed.	I-Reply	I-1	Reply	570
Shape deforming methods exhibit changes in both style and geometry of the background, see for example the recently proposed TransGaGa.	I-Reply	I-1	Reply	570
[line_break_token]While we made some preliminary attempts to incorporate an attention mechanism, the results were unsatisfactory, and we therefore stopped pursuing this direction, as we felt it to be outside the main focus of this work.	I-Reply	I-1	Reply	570
[line_break_token][line_break_token]--- One question I had, for example: could we be getting similar results if we used the VGG bottleneck as the noise vector in an InfoGAN?	O	O	Reply	570
[line_break_token]Using a different architecture instead of cycleGAN for unpaired deep feature translation is indeed interesting.	B-Reply	B-2	Reply	570
Could the reviewer please elaborate exactly how did he envision here the use of infoGAN?	I-Reply	I-2	Reply	570
Is the noise composed of a domain-part (i.e., zero or one with p=0.5 for each) and the VGG bottleneck features instead of the "traditional" noise?	I-Reply	I-2	Reply	570
[line_break_token]Regardless, directly inverting the bottleneck is difficult.	I-Reply	I-2	Reply	570
We refer the reviewer to the results of the inversion network proposed by Dosovitskiy and Brox on AlexNet for different layers ("Generating Images with Perceptual Similarity Metrics based on Deep Networks").	I-Reply	I-2	Reply	570
In addition, as we show in our ablation study, the cascaded manner of our translation further improves the result achieved by the deepest layer translation only.	I-Reply	I-2	Reply	570
[line_break_token][line_break_token]---Why wasn't a final translator used for the final image, conditioned on the final \tilde{b}_1?	O	O	Reply	570
[line_break_token]We noticed that shallow layers contribution was negligible.	B-Reply	B-3	Reply	570
Thus, we omitted the use of \tilde{b}_1.	I-Reply	I-3	Reply	570
[line_break_token][line_break_token]--- Is the VGG network pretrained on ImageNet?	O	O	Reply	570
Why wasn't another task used that could be retaining more of the relevant features?	O	O	Reply	570
eg on semantic segmentation[line_break_token]Yes, the VGG was pre-trained on ImageNet, we will clarify it in our revision.	B-Reply	B-4	Reply	570
[line_break_token]VGG pretrained on ImageNet is widely used for feature extraction, from perceptual similarity to cross domain correspondence.	I-Reply	I-4	Reply	570
It is remarkable that a network pretrained only with image-level annotations can assist in the translation process.	I-Reply	I-4	Reply	570
[line_break_token]Semantic segmentation networks require more elaborate supervision (pixel-level annotation) and allow a different kind of translation approaches, which can directly use the segmentation maps.	I-Reply	I-4	Reply	570
[line_break_token][line_break_token] --- Could this be used for networks pretrained on other datasets?	O	O	Reply	570
Presumably ImageNet has information about the animals translated in this paper.	O	O	Reply	570
Even better, could we somehow learn these features for the domain pairs automatically somehow?	O	O	Reply	570
[line_break_token][line_break_token]Yes, different networks can be used, as the approach is generic, although, a good feature extraction network, such as VGG pretrained on ImageNet, is required for a meaningful translation.	B-Reply	B-5	Reply	570
Please note that while ImageNet does contain several of the animals translated in this paper, it does *not* contain giraffe and the different types of dogs and cats presented.	I-Reply	I-5	Reply	570
We believe that learning the features in a self-supervised manner, will not yield the same quality as VGG features and fine-tuning VGG on the specific domains did not yield better results.	I-Reply	I-5	Reply	570
[line_break_token][line_break_token]--- How meaningful is the FID score really in this case?	O	O	Reply	570
[line_break_token]FID metric is still commonly used to assess how close fake and real samples are.	B-Reply	B-6	Reply	570
[line_break_token]FID uses layer of inception trained on ImageNet, thus, it is closely related to our deep features translation.	I-Reply	I-6	Reply	570
In a sense, we minimize it directly.	I-Reply	I-6	Reply	570
 [line_break_token][line_break_token] --- How were the 10 GANs tuned[line_break_token]The GANs were tuned manually, experimenting with several architecture (similar to all layers), and losses.	B-Reply	B-7	Reply	570
Same parameters where used for all translation tasks.	I-Reply	I-7	Reply	570
We found this process to be relatively simple.	I-Reply	I-7	Reply	570
[line_break_token][line_break_token]--- On p.7 it is mentioned that the number of instances is preserved, however, it should be made clear that it's preserved in some (or most if that is what was observed) of the examples.	O	O	Reply	570
[line_break_token]In most cases the number of instances was preserved, we will clarify it in our revision, thanks	B-Reply	B-10	Reply	570

**Summary**[line_break_token][line_break_token]In this paper, the authors extend an existing feature interpretation method for LSTMs to more generic DNNs.	O	O	Review	444
They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction.	O	O	Review	444
[line_break_token][line_break_token]**Strength**[line_break_token][line_break_token]1.	O	O	Review	444
Splitting information into binary groups at each layer is a neat approach to segregate interpretations.	O	O	Review	444
[line_break_token]2.	O	O	Review	444
Experiments are elaborate and cover the breadth of the proposed method well.	O	O	Review	444
[line_break_token]3.	O	O	Review	444
The paper is well presented and fairly easy to follow.	O	O	Review	444
[line_break_token][line_break_token][line_break_token]**Weakness**[line_break_token][line_break_token]1.	O	O	Review	444
Limited contributions in terms of novelty.	B-Review	B-1	Review	444
This approach for RNNs is presented fairly well in the previous paper [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](<a href="https://arxiv.org/abs/1801.05453)."	O	O	Review	444
target="_blank" rel="nofollow">https://arxiv.org/abs/1801.05453).</a>[line_break_token]2.	O	O	Review	444
It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers.	B-Review	B-2	Review	444
[line_break_token]	O	O	Review	444
Thanks for your response.	O	O	Reply	444
We see that you have responded to our comments by adding the sentence "They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction."	O	O	Reply	444
onto the summary of our paper, and leaving the strengths, weaknesses and rating unchanged.	O	O	Reply	444
[line_break_token][line_break_token]In light of your updated summary, we feel your main concern should also be revisited.	B-Reply	B-1	Reply	444
Your stated concern is that "This approach for RNNs is presented fairly well in the previous [CD] paper".	I-Reply	I-1	Reply	444
Our main contribution, hierarchical interpretations, was not presented in the CD paper, or in any other paper, and is independent of CD (it can be applied to any phrase/patch importance score).	I-Reply	I-1	Reply	444
The bulk of recent work in this area has focused on (non-hierarchical) heat maps (we cite 13 recent papers in our related work that do this).	I-Reply	I-1	Reply	444
Our experiments show that applying our hierarchical interpretation algorithm to CD, yields higher user trust, and more insight into a model's predictive accuracy, than CD alone, or any of our other baselines.	I-Reply	I-1	Reply	444
[line_break_token][line_break_token]To be clear, our point is that moving from heat-maps, such as Table 1 in [1] (the CD paper),  Figure 5 in [2], or Figure 4 in [3] (our three baselines), to hierarchies, such as Figure 2 in our paper, is not incremental.	I-Reply	I-1	Reply	444
[line_break_token][line_break_token]We responded to concern #2 above, and also modified paragraph 5 of section 3.1 and added a figure on page 27 of the supplement (Fig S5).	B-Reply	B-2	Reply	444
Did this address your concern?	I-Reply	I-2	Reply	444
[line_break_token][line_break_token][1] <a href="https://arxiv.org/pdf/1801.05453.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1801.05453.pdf</a>[line_break_token][2] <a href="https://arxiv.org/pdf/1612.08220.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.08220.pdf</a>[line_break_token][3] <a href="https://arxiv.org/pdf/1703.01365.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1703.01365.pdf</a	O	O	Reply	444

Summary[line_break_token][line_break_token]This paper showed that out-of-distribution and adversarial samples can be detected effectively if we utilize logits (without softmax activations).	O	O	Review	20548
Based on this observation, the authors proposed 2-logit based detectors and showed that they outperform the detectors utilizing softmax activations using MNIST and CIFAR-10 datasets.	O	O	Review	20548
[line_break_token][line_break_token]I‚Äôd like to recommend "reject" due to the following[line_break_token][line_break_token]The main observation (removing softmax activation can be useful for detecting abnormal samples) is a bit interesting (but not surprising) but there is no theoretical analysis for this.	B-Review	B-1	Review	20548
It would be better if the authors can provide the reason why softmax activation hinders the novelty detection.	I-Review	I-1	Review	20548
[line_break_token][line_break_token]The logit-based detectors proposed in the paper are simple variants of existing methods.	B-Review	B-2	Review	20548
Because of that, it is hard to say that technical contributions are very significant.	I-Review	I-2	Review	20548
[line_break_token][line_break_token]Questions[line_break_token][line_break_token]For evaluation, could the authors compare the performance with feature-based methods like Mahalanobis [1] and LID [2]?	B-Review	B-3	Review	20548
[line_break_token][line_break_token]I would be appreciated if the author can evaluate their hypothesis using various datasets like CIFAR-100, SVHN, and ImageNet.	B-Review	B-4	Review	20548
[line_break_token][line_break_token][1] Lee, K., Lee, K., Lee, H. and Shin, J., 2018.	O	O	Review	20548
A simple unified framework for detecting out-of-distribution samples and adversarial attacks.	O	O	Review	20548
In Advances in Neural Information Processing Systems (pp.	O	O	Review	20548
7167-7177).	O	O	Review	20548
[line_break_token][line_break_token][2] Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Schoenebeck, G., Song, D., Houle, M.E. and Bailey, J., 2018.	O	O	Review	20548
Characterizing adversarial subspaces using local intrinsic dimensionality.	O	O	Review	20548
arXiv preprint arXiv:1801.02613.	O	O	Review	20548
hank you for you comments and feedback.	O	O	Reply	20548
We agree that our work would benefit from using more datasets for evaluation and comparing with more methods.	B-Reply	B-3	Reply	20548
We will include these improvements in the next version of the paper	O	O	Reply	20548

This paper proposed a model that is capable of tracking dialogue states in a non-recursive fashion.	O	O	Review	533
The main techniques behind the non-recursive model is similar to that of the ICLR 2018 paper "NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION".	O	O	Review	533
Unfortunately, as state tacking can be formulated as one special case of sequence decoding, there is not much of innovation that can be claimed in this paper considering the "fertility" idea was already been proposed.	B-Review	B-1	Review	533
The paper did illustrate a strong experimental results on a recent dataset comparing with many state-of-the-art models.	I-Review	I-1	Review	533
However, it is not clear how much innovation this work generates and how the ICLR community would benefit from the problem that the paper is addressing.	I-Review	I-1	Review	533
 [line_break_token][line_break_token] 	O	O	Review	533
hanks for reviewing our work.	O	O	Reply	533
Below are our responses to clarify a few misunderstanding points by the reviewer.	O	O	Reply	533
[line_break_token][line_break_token]1.	O	O	Reply	533
We note that NMT and DST are very different research tasks, and DST has different settings, unique characteristics and challenges.	B-Reply	B-2	Reply	533
NMT aims to generate an output sequence that has the same meaning as input sequence and the two sequences are of different languages/domains.	I-Reply	I-2	Reply	533
By contract, DST aims to make accurate dialogue state prediction, instead of matching the semantic meanings between input and output.	I-Reply	I-2	Reply	533
Our DST approach treats input as a prior for each (domain, slot) pair, and the prior is used as a channel vector to obtain high-level and low-level (token-level) dependencies to achieve better dialogue state prediction.	I-Reply	I-2	Reply	533
Hence, the proposed technical approach and contributions in our work are actually quite different from the previous NMT work, although the idea of non-autoregressive was partly inspired by ICLR‚Äô18 NMT paper.	I-Reply	I-2	Reply	533
[line_break_token][line_break_token]2.	O	O	Reply	533
About the novelty and innovation, we highlight that one of our key contributions is to overcome a critical limitation of many existing DST methods.	B-Reply	B-1	Reply	533
These methods do not detect dependencies among (domain, slot) pairs because they do not allow the model to explicitly learn signals across domains and slots.	I-Reply	I-1	Reply	533
This is a very important contribution that is unique to DST tasks, and is very different from the previous non-autoregressive NMT work.	I-Reply	I-1	Reply	533
We also noted that technically it is non-trivial and not straightforward at all to apply the non-autoregressive idea to develop a new state-of-the-art DST technique, which involves several other techniques (such as delexicalization, designs of slot gating, fertility, etc as presented in our paper).	I-Reply	I-1	Reply	533
[line_break_token][line_break_token]3.	O	O	Reply	533
About the significance of this work, our new approach not only achieves the new state-of-the-art results for DST tasks on the MultiWOZ dataset, but the decoding speed is also an order of magnitude faster than the existing DST methods, making it a practically very useful technique to many real-world dialog systems applications.	B-Reply	B-3	Reply	533
From a scientific aspect, our technique is also not restricted to DST tasks.	I-Reply	I-3	Reply	533
It potentially could be applied to tackle many other similar NLP or machine learning problems that involve structured or compositional prediction such as outline-based or template-based generation.	I-Reply	I-3	Reply	533

The paper proposes a neural architecture for summarizing trees inspired by capsule networks from computer vision.	O	O	Review	667
The authors re-use a tree convolution from previous work for the bottommost layer, and then propose adaptations to the dynamic routing from capsule networks so that it can be applied to variable-sized trees.	O	O	Review	667
The paper applies the proposed architecture to three different program classification datasets, which are in three different languages.	O	O	Review	667
The paper reports empirical gains compared to two architectures proposed by previous work.	O	O	Review	667
[line_break_token][line_break_token]I think that it's interesting to apply the capsule network architecture to tree classification, but unfortunately it doesn't appear that some of the motivation for capsule networks on images didn't seem to transfer neatly to this setting; for example, there is no equivalent of inverse graphics as there is no reconstruction loss (as pointed out by the authors in Section 6.4).	B-Review	B-1	Review	667
[line_break_token][line_break_token]Also, the variable-to-static capsule routing indeed appears novel, but I was a bit confused by its internal details.	B-Review	B-2	Review	667
It appears that the outputs of the previous layer which occur most often will get routed (considering lines 6-8 of Algorithm 1 which up-weights each of the based on its similarity to; the are initially a re-numbered subset of), without any prior transformation of the previous layer first.	I-Review	I-2	Review	667
It seems to me that this doesn't allow for the prior layer to predict more complex features about the input that the subsequent layer is expected to capture.	I-Review	I-2	Review	667
In fact, for certain code classification tasks, it may be that rare capsule outputs from the initial layer are the most important to preserve.	I-Review	I-2	Review	667
[line_break_token][line_break_token]My biggest concern has to do with the empirical results.	B-Review	B-3	Review	667
The source of Dataset C (Mou et al 2016, <a href="https://arxiv.org/pdf/1409.5718.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1409.5718.pdf)</a> reports 94.0% accuracy in Table 3 on their TBCNN method on the same dataset, whereas this paper reports 79.40% accuracy for TBCNN.	O	O	Review	667
I understand that the later result comes from a reimplementation, but it seems fairer to compare against (or additionally report) the results from the original authors of the method.	B-Review	B-3	Review	667
[line_break_token][line_break_token]Also, the paper cites ASTNN (Zhang et al 2019, <a href="https://dl.acm.org/citation.cfm?id=3339604)" target="_blank" rel="nofollow">https://dl.acm.org/citation.cfm?id=3339604)</a> in the introduction, and even though that paper reports (in table 2) 98.2% accuracy on Dataset C, the results table of the paper under review does not mention this in the evaluation section.	O	O	Review	667
I don't think that a paper necessarily has to achieve empirical results beating all previous ones in order to merit acceptance, but the way that the comparison is currently set up doesn't seem to facilitate a clear comparison of the pros and cons of this method versus other ones in the literature.	B-Review	B-4	Review	667
[line_break_token][line_break_token]For the above reasons, I vote to reject the paper.	O	O	Review	667
For future submissions, it would be good to see a more comprehensive empirical comparison of the proposed method compared to others, and also to have more explanations about the design of the network.	O	O	Review	667
e would like to thank the reviewer for his valuable time, helpful feedback and insightful suggestions to further improve our study.	O	O	Reply	667
[line_break_token][line_break_token]Q2-1: It doesn‚Äôt appear that some of the motivation for capsule networks on images didn‚Äôt seem to transfer neatly to this setting;  for example, there is no equivalent of inverse graphics as there is no reconstruction loss.	O	O	Reply	667
[line_break_token][line_break_token]Response:[line_break_token][line_break_token]We thank the reviewer for this very important comment.	B-Reply	B-1	Reply	667
 We kindly invite the reviewer to refer to the common response above. (	I-Reply	I-1	Reply	667
<a href="https://openreview.net/forum?id=SJgXs1HtwH&amp;noteId=r1eiYk0oiH)" target="_blank" rel="nofollow">https://openreview.net/forum?id=SJgXs1HtwH&amp;noteId=r1eiYk0oiH)</a>[line_break_token][line_break_token]Q2-2: Variable to Static Routing Algorithm[line_break_token][line_break_token]Response:[line_break_token][line_break_token]We acknowledge the reviewer‚Äôs concern with respect to the preservation of rare capsules.	B-Reply	B-2	Reply	667
The initialization of is based on the length of the capsule output vector (L2 norm), which represents the probability of existence of the entity learnt by the capsule.	I-Reply	I-2	Reply	667
For a given training/testing sample, not all the capsules are activated in a given layer, and source code often consists of non-essential entities, where only a portion of all entities determine the code class.	I-Reply	I-2	Reply	667
Hence, we initialize the next layer with the capsules which represent entities with highest probability of existence (in other words, highest activation), and dynamically route the rest of the capsules based on the similarity between the respective vector outputs.	I-Reply	I-2	Reply	667
Therefore, it is not necessarily the capsules that occur most often that get routed to the next layer, instead it is the capsules with the most prominent outputs along with the capsules with the highest vector similarities to them.	I-Reply	I-2	Reply	667
In this way, rare capsules are still preserved and routed to the next layer.	I-Reply	I-2	Reply	667
[line_break_token][line_break_token]Further, we acknowledge that we do not use prior transformations between the primary dynamic layer and the primary static layer.	I-Reply	I-2	Reply	667
However, in the layers subsequent to the primary static layer, we use prior transformations aiding them to predict more complex features.	I-Reply	I-2	Reply	667
We can use multiple layers similar to the code capsule layer to predict further complex features, depending on the complexity of the classification task.	I-Reply	I-2	Reply	667
According to Section 6.3.3, empirical evidence suggests that using more such layers is not very effective for the three particular datasets that we have used.	I-Reply	I-2	Reply	667
However, more complex datasets may benefit from stacking multiple code capsule layers.	I-Reply	I-2	Reply	667
[line_break_token][line_break_token]Q2-3: Empirical Results[line_break_token][line_break_token]Response:[line_break_token][line_break_token]We acknowledge the reviewer‚Äôs concern with respect to the empirical results.	B-Reply	B-3	Reply	667
The primary reason for the ambiguity between TBCNN [Mou et al (2016)] and our re-implementation is the initial embeddings, as explained in Section 6.2.	I-Reply	I-3	Reply	667
Mou et al (2016) have used custom-trained initial embeddings for a small set of about 50 AST node types defined specifically for C language only, while our approach generates the initial embeddings for a much larger vocabulary of more than three hundred unified AST node types for both C and Java.	I-Reply	I-3	Reply	667
We decided to follow a more generalized approach across programming languages, at the expense of performance gain resulting from small, specific vocabularies.	I-Reply	I-3	Reply	667
[line_break_token]We believed that it would be more general and fairer to compare across datasets in more than one programming language by using the same (and larger) set of AST node vocabulary used in our approach.	I-Reply	I-3	Reply	667
[line_break_token][line_break_token]We acknowledge the reviewer's perspective on the fairness of the results and potential errors or discrepancies in our re-implementation of TBCNN [Mou et al (2016)]. Retrospectively, in addition to using the larger set of AST node vocabulary, we should have also applied our approach directly to the initial embeddings with the same smaller set of AST node vocabulary used in TBCNN [Mou et al (2016)] and ASTNN [Zhang et al (2019)] etc.	B-Reply	B-4	Reply	667
for the dataset in C language so that we may have a clearer comparison.	I-Reply	I-4	Reply	667

Quick summary:[line_break_token][line_break_token]The author investigate if we can learn a linearized state space model using deep generative models to guide and transform non-linear dynamic observations into linear state space processes.	O	O	Review	1299
A quick analysis of the feasibilty of the model and its relation to existing models is provided.	O	O	Review	1299
Experimental results include a GAN and a VAE as the generative model on a few datasets.	O	O	Review	1299
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]  - The model is interesting and the motivation is quite clear[line_break_token]  - analysis is quite nice[line_break_token]  - writing is quite clear and decent[line_break_token][line_break_token]Cons:[line_break_token][line_break_token] - Extremely lacking experimental validation - there are literally no baseline models, no numbers or any kind of quantitative analysis.	B-Review	B-1	Review	1299
The figures show samples from the model with very little explanation or discussion and it's entirely unclear what we learn from this model.	I-Review	I-1	Review	1299
Scientifically speaking, this is not up to par.	I-Review	I-1	Review	1299
[line_break_token][line_break_token]Bottom line - I think this is a good start for a paper about an interesting model, but I don't feel that this teaches us anything about what the model learns and how it relates in practice to other models.	B-Review	B-2	Review	1299
We thank the reviewer for the constructive feedback.	O	O	Reply	1299
Please find our replies below.	O	O	Reply	1299
Like the other two reviewers, AnonReviewer1 pointed out several shortcomings of the paper that could not be corrected within the revision period.	O	O	Reply	1299
We have therefore decided to withdraw the paper in order to improve it by taking into account the reviewers' comments.	O	O	Reply	1299
[line_break_token][line_break_token]The main concern raised by the AnonReviewer1 is the lack of experimental baselines.	B-Reply	B-1	Reply	1299
[line_break_token][line_break_token]We understand the importance of experimental comparison with state-of-the-art methods and will do our best to provide a comprehensive evaluation in future versions of our work.	I-Reply	I-1	Reply	1299
We acknowledge that the experimental section was neglected with respect to this, but we would like to provide some insight into the reasons for this.	I-Reply	I-1	Reply	1299
[line_break_token][line_break_token]The aim of the work is to learn a generative model of a stochastic process.	I-Reply	I-1	Reply	1299
Comparative experimental evaluation of such a model is particularly challenging, since a ground truth, by definition, does not exist.	I-Reply	I-1	Reply	1299
The authors of [1], a seminal work in the field of generative models for video point this difficulty out on the respective project page [2]:[line_break_token][line_break_token]"Evaluation of generative models is hard.	I-Reply	I-1	Reply	1299
We used a psychophysical 2AFC test on Mechanical Turk asking workers 'Which video is more realistic?'	I-Reply	I-1	Reply	1299
We think this evaluation is okay, but it is important for the community to settle on robust automatic evaluation metrics."	I-Reply	I-1	Reply	1299
[line_break_token][line_break_token]Unfortunately, we did not have the means to perform a psychophysical evaluation, so we chose the option that we have seen in some of the papers that have inspired our work, e.g. [3] and [4], namely presenting example sequences of synthesized video and let the reader judge the performance.	I-Reply	I-1	Reply	1299
We understand that we might have overlooked further possibilities and will do our best to come up with better measures in the future.	I-Reply	I-1	Reply	1299
[line_break_token][line_break_token][1] Vondrick et al "Generating Videos with Scene Dynamics"[line_break_token][2] <a href="http://www.cs.columbia.edu/~vondrick/tinyvideo/" target="_blank" rel="nofollow">http://www.cs.columbia.edu/~vondrick/tinyvideo/</a>[line_break_token][3] Johnson et al "Composing graphical models with neural networks for structured representations and fast inference"[line_break_token][4] Goroshin et al "Learning to Linearize Under Uncertainty"	O	O	Reply	1299

This paper proposes to compare different methods to build BERT/GPT  representations of long documents, to bypass the limitation of the input size of these models.	O	O	Review	655
One of the proposed method uses attention mechanism to discover the most significant portion of the text which are use to backpropagate the error on the language model.	O	O	Review	655
Three combination methods (concatenation, RNN and attention)  are tested on 2 databases plus one modified version of one of the databases to show the impact of the presentation bias in the texts (most important part are at the beginning).	O	O	Review	655
[line_break_token]Results show that the largest improvement is the base BERT model over the previously proposed model : this aspect should be comment : what is the reason of the improvement ?	B-Review	B-1	Review	655
[line_break_token]Combination of textual part also yields improvement, but to a smaller extend.	B-Review	B-2	Review	655
Hyper-parameter and Training/Testing time are reported, which is useful from a practical point of view if one should decide to implement the proposed method or not, considering the extra computational load and the relatively small improvement.	I-Review	I-2	Review	655
The Shuffling experiment demonstrate an interesting behaviour of the models, that should be confirmed on a real dataset.	I-Review	I-2	Review	655
[line_break_token][line_break_token] 	B-Review	B-1	Review	655
hank you for taking the time to review our paper.	O	O	Reply	655
We clarify some points below, and we have added further discussion to the paper.	O	O	Reply	655
[line_break_token][line_break_token]Q: Why does the BERT-base model show the most improvement over the previously proposed models?	O	O	Reply	655
[line_break_token][line_break_token]Our BERT-base improves over the PatentBert implementation because PatentBert does not combine the title, abstract, and claim-- but only the title+abstract or just the first claim.	B-Reply	B-1	Reply	655
This was done to prevent truncation, but these combinations don't always reach the max input size.	I-Reply	I-1	Reply	655
Additionally, our BERT-base improves over the Deep Patent methods and Local Word Glimpses as they use word level embeddings instead of language model based embeddings.	I-Reply	I-1	Reply	655
[line_break_token][line_break_token][line_break_token]Comment: Shuffling should be confirmed on a real dataset[line_break_token][line_break_token]While we would like to confirm the results of our shuffling experiment on other datasets, we were unable to find any sufficiently long document classification task that would be illuminative.	B-Reply	B-2	Reply	655
For future work, we would like to find more datasets for this task.	I-Reply	I-2	Reply	655

This paper presents an interesting quantization technique that is, unusually, end-to-end trainable and not just an inference technique.	O	O	Review	20025
According to the experiments, the method achieves better performance and computational savings as compared to other quantization method baselines.	O	O	Review	20025
The results are admirably demonstrated on a variety of models, including CNN and RNN-based neural nets, as well as on several datasets in different domains, including ImageNet, CIFAR10, and PTB.	O	O	Review	20025
We see the method seems to generalize across all of these.	O	O	Review	20025
[line_break_token][line_break_token]Nevertheless, while I found this is very interesting work, I have a number of issues with the experiments, which I'll go into below.	O	O	Review	20025
I feel this work is being released prematurely and could use some more polish to help sell the method better.	O	O	Review	20025
Below are a few remarks and questions for the authors that would be helpful to be answered.	O	O	Review	20025
[line_break_token][line_break_token]* Why only report on ResNet-18?	B-Review	B-1	Review	20025
It would be far more useful to show numbers against ResNet-50.	I-Review	I-1	Review	20025
It would also be useful to show the non-quantized best results on these models and datasets.	I-Review	I-1	Review	20025
[line_break_token]* I wish more effort had been spent to analyze the experiments.	B-Review	B-2	Review	20025
For example, I am not sure I understand the effects of the threshold on this method.	I-Review	I-2	Review	20025
What happens when it's set manually?	I-Review	I-2	Review	20025
[line_break_token]* How exactly is computation cost savings calculated so crudely?	B-Review	B-3	Review	20025
If it uses B_avg, why not calculate the bitwidth per layer and sum things up?	I-Review	I-3	Review	20025
Using B_avg strikes me as being quite crude.	I-Review	I-3	Review	20025
[line_break_token]* When the authors address runtime changes except in table 6, they changed their baseline to a vanilla ResNet-18 with dense weights.	B-Review	B-4	Review	20025
What are the runtime effects relative to ShuffleNet and ShiftNet?	I-Review	I-4	Review	20025
hank you for the insightful comments that have led to improvements in our paper.	O	O	Reply	20025
Below are our answers to your questions.	O	O	Reply	20025
[line_break_token][line_break_token]Q1: "Why only report on ResNet-18?	O	O	Reply	20025
It would be far more useful to show numbers against ResNet-50.	O	O	Reply	20025
It would also be useful to show the non-quantized best results on these models and datasets."	O	O	Reply	20025
[line_break_token][line_break_token]Reply: In Table 1, we report the results of the floating point baseline for the three models in the first column as ‚Äúfp‚Äù.	B-Reply	B-1	Reply	20025
For example, the floating-point ShiftNet-20 CIFAR-10 model has an accuracy of 89.4%.	I-Reply	I-1	Reply	20025
In Table 4, we report the floating-point PPW of the LSTM PTB model in the caption.	I-Reply	I-1	Reply	20025
[line_break_token][line_break_token]To empirically show PG works on more models, we apply PG to ResNet-56 and ResNet-32, then train it on the CIFAR-10 dataset.	I-Reply	I-1	Reply	20025
The training settings are the same as described in Section 4.	I-Reply	I-1	Reply	20025
In the latest revision, the additional results are shown in Table 7 in Section A.2.	I-Reply	I-1	Reply	20025
[line_break_token][line_break_token]Compared to the 8-bit PACT baseline, PG achieves 4x computational cost reduction on both models at the same level of prediction accuracy.	I-Reply	I-1	Reply	20025
The sparsity in ResNet-56 (98.2%) and ResNet-32 (96.3%) are higher than that (90.1%) in ResNet-18 for CIFAR-10 dataset.	I-Reply	I-1	Reply	20025
Compared to the fix-threshold baseline, the accuracy of PG increases by 42.5% for ResNet-56 and 46.4% for ResNet-32 with the same computational cost.	I-Reply	I-1	Reply	20025
This increasing accuracy gap empirically shows that PG also works well on larger DNN models.	I-Reply	I-1	Reply	20025
[line_break_token][line_break_token]Q2: " I am not sure I understand the effects of the threshold on this method.	O	O	Reply	20025
What happens when it's set manually?"	O	O	Reply	20025
[line_break_token][line_break_token]Reply: We can consider the threshold in PG as a measurement of the importance of an output feature.	B-Reply	B-2	Reply	20025
If the MSB result exceeds the threshold, it means that the corresponding output feature is important.	I-Reply	I-2	Reply	20025
We will then compute this important feature in high precision.	I-Reply	I-2	Reply	20025
In the bell shaped activation distribution, the larger a threshold is, the less likely an output feature will exceed the threshold, and thus the more output features will be computed using reduced precision.	I-Reply	I-2	Reply	20025
Hence a large threshold is desired to reduce the computational cost.	I-Reply	I-2	Reply	20025
We introduce a threshold loss to make the threshold approach a large value.	I-Reply	I-2	Reply	20025
Moreover, the threshold is also optimized by minimizing the accuracy loss.	I-Reply	I-2	Reply	20025
As a result, the trainable thresholds are learned to jointly minimize the threshold loss and the accuracy loss.	I-Reply	I-2	Reply	20025
[line_break_token][line_break_token]We‚Äôve already compared PG to manually set thresholds.	I-Reply	I-2	Reply	20025
The results of which are shown  in Table 1 under columns of ‚ÄúFix-Threshold‚Äù.	I-Reply	I-2	Reply	20025
We notice that manually set thresholds yield a much lower model accuracy compared to PG at a similar computational cost.	I-Reply	I-2	Reply	20025
[line_break_token][line_break_token]In the latest revision, we also show the results of sweeping a series of manually set thresholds on the ResNet-18 for CIFAR-10 with=3/2 in Table 8 in Section A.2.	I-Reply	I-2	Reply	20025
As the threshold decreases from 3 to -4, the average bitwidth in the update phase consistently increases.	I-Reply	I-2	Reply	20025
This is expected because we compute more output features in high precision.	I-Reply	I-2	Reply	20025
The model prediction accuracy therefore increases.	I-Reply	I-2	Reply	20025
However, compared to the manually set threshold, PG achieves a much better model accuracy (91.2%) with a larger sparsity (90.1%).	I-Reply	I-2	Reply	20025
[line_break_token][line_break_token]Q3: "How exactly is computation cost savings calculated so crudely?	O	O	Reply	20025
If it uses B_avg, why not calculate the bitwidth per layer and sum things up?"	O	O	Reply	20025
[line_break_token][line_break_token]Reply: The average bitwidth is a good indicator for the compute efficiency when we run PG on customized hardware as it reflects the energy consumption per arithmetic operation.	B-Reply	B-3	Reply	20025
Prior art proposed by Song et al (ISCA‚Äô2018) cited in the paper also adopts the same metric of compute efficiency.	I-Reply	I-3	Reply	20025
[line_break_token][line_break_token]We agree that calculating the bitwidth per layer and summing them up is another good metric.	I-Reply	I-3	Reply	20025
However, it is essentially equivalent to the average bitwidth reported in the paper.	I-Reply	I-3	Reply	20025
The average bitwidth is obtained by normalizing the sum of the bitwidth per layer using the total number of features in the network.	I-Reply	I-3	Reply	20025
[line_break_token][line_break_token]Q4: "When the authors address runtime changes except in table 6, they changed their baseline to a vanilla ResNet-18 with dense weights.	O	O	Reply	20025
What are the runtime effects relative to ShuffleNet and ShiftNet?"	O	O	Reply	20025
[line_break_token][line_break_token]Reply: In Section 4.3, we show the kernel speedup of applying PG to the ResNet-18 model on CIFAR-10 dataset.	B-Reply	B-4	Reply	20025
Since PG works by modifying linear layers (i.e., convolutional layers or fully connected layers) instead of the model architectures, it generalizes to other models containing linear layers	I-Reply	I-4	Reply	20025

This paper proposes to modify how noise factors are treated when developing VAE models.	O	O	Review	267
 For example, the original VAE work from (Kingma and Welling, 2013) applies a deep network to learn a diagonal approximation to the covariance on the decoder side.	O	O	Review	267
 Subsequent follow-up papers have often simplified this covariance to sigma^2*I, where sigma^2 is assumed to be known or manually tuned.	O	O	Review	267
 In contrast, this submission suggests either treating sigma^2 as a trainable parameter, or else introducing a more flexible zero-mean mixture-of-Gaussians (MoG) model for the decoder noise.	O	O	Review	267
 These modeling adaptations are then analyzed using various performance indicators and empirical studies.	O	O	Review	267
[line_break_token][line_break_token]The primary issues I have with this work are threefold:  (i) The paper is not suitably organized/condensed for an ICLR submission, (ii) the presentation quality is quite low, to the extent that clarity and proper understanding are jeopardized, and (iii) the novelty is limited.	B-Review	B-1	Review	267
 Consequently my overall impression is that this work is not yet ready for acceptance to ICLR.	B-Review	B-3	Review	267
[line_break_token][line_break_token]First, regarding the organization, this submission is 19 pages long (*excluding* references and appendices), despite the clear suggestion in the call for papers to limit the length to 8 pages: "There is no strict limit on paper length.	B-Review	B-1	Review	267
However, we strongly recommend keeping the paper at 8 pages, plus 1 page for the references and as many pages as needed in an appendix section (all in a single pdf).	I-Review	I-1	Review	267
The appropriateness of using additional pages over the recommended length will be judged by reviewers."	I-Review	I-1	Review	267
 In the present submission, the first 8+ pages contain minimal new material, just various background topics and modified VAE update rules to account for learning noise parameters via basic EM algorithm techniques.	I-Review	I-1	Review	267
 There is almost no novelty here.	I-Review	I-1	Review	267
 In my mind, this type of well-known content is in no way appropriate justification for such a long paper submission, and it is unreasonable to expect reviewers to wade through it all during a short review cycle.	I-Review	I-1	Review	267
[line_break_token][line_break_token]Secondly, the presentation quality is simply too low for acceptance at a top-tier international conference (e.g., it is full of strange sentences like "Such amelioration facilitates the VAE capable of always reducing the artificial intervention due to more proper guiding of noise learning."	B-Review	B-2	Review	267
 While I am sympathetic to the difficulties of technical writing, and realize that at times sufficiently good ideas can transcend local grammatical hiccups, my feeling is that, at least for now, another serious pass of editing is seriously needed.	I-Review	I-2	Review	267
 This is especially true given that it can be challenging to digest so many pages of text if the presentation is not relatively smooth.	I-Review	I-2	Review	267
[line_break_token][line_break_token]Third and finally, I do not feel that there is sufficient novelty to overcome the issues already raised above.	B-Review	B-3	Review	267
 Simply adapting the VAE decoder noise factors via either a trainable noise parameter or an MoG model represents an incremental contribution as similar techniques are exceedingly common.	I-Review	I-3	Review	267
 Of course, the paper also invents some new evaluation metrics and then applies them on benchmark datasets, but this content only appears much later in the paper (well after the soft 8 page limit) and I admittedly did not read it all carefully.	I-Review	I-3	Review	267
 But on a superficial level, I do not believe these contributions are sufficient to salvage the paper (although I remain open to hearing arguments to the contrary).	I-Review	I-3	Review	267
We‚Äôd like to thank the reviewer for their making effort to reviewing and providing helpful suggestions although they didn't provide fair assessments of our contribution, especially the important content which appears later that used to reveal some basic facts and behaviors of idealistic VAE as well as our indicators.	O	O	Reply	267
 We have made a number of changes to address them.	O	O	Reply	267
[line_break_token][line_break_token]A.[tab_token]We condense the original paper into 10 pages.	B-Reply	B-1	Reply	267
We also try to reduce the number of strange sentences.	I-Reply	I-1	Reply	267
[line_break_token][line_break_token]B.[tab_token]We weaken our discussion on noise modeling due to the limitation of the paper length and strengthen the theoretical troubleshooting  of   VAE's properties  and they are listed below[line_break_token][line_break_token]    1.	B-Reply	B-2	Reply	267
[tab_token]Intrinsic dimension Issue:  "Could the VAE learn the intrinsic number of factors underlying the data?	I-Reply	I-2	Reply	267
[line_break_token]Our paper: Yes, idealistic VAE learns and only learns the intrinsic factor dimension and the VAE objective induced by the Gaussian prior also encourages the information sparsity in dimension which is contributing to the learn the intrinsic dimension.	I-Reply	I-2	Reply	267
[line_break_token]Besides, in real implementations, the conclusion is also instructive if the noise is proper modeling and the disentanglement(clarified in our paper) is achieved to some extent.	I-Reply	I-2	Reply	267
[line_break_token][line_break_token]    2.	O	O	Reply	267
[tab_token]Disentanglement Issue:  "What are need and range induced by word disentanglement?"	O	O	Reply	267
[line_break_token]We provide the clarification according to information conservation theorem:[line_break_token]the learned the factors are close to being independent.	B-Reply	B-2	Reply	267
[line_break_token]the factors incline to generate the oracle signal and to be inferred perfectly from the oracle signal through a continuous procedure/mapping.	I-Reply	I-2	Reply	267
[line_break_token][line_break_token]   3.	O	O	Reply	267
[tab_token]Real Factor Issue:  "Could the VAE learn the real generating factor underlying the data or just some fantasies?"	O	O	Reply	267
[line_break_token]We show that idealistic VAE possibly learn any factors set in the equivalence class.	B-Reply	B-2	Reply	267
Besides, the experiment results also suggest that the VAE's factor equivalence generally exist.	I-Reply	I-2	Reply	267
[line_break_token][line_break_token]   4.	O	O	Reply	267
[tab_token]Indicator Issue: "Could the effectiveness of current disentanglement metric be guaranteed?"	O	O	Reply	267
[line_break_token]We show that the current disentanglement introduced by (beta-VAE) is based on "simulated factors" while idealistic VAE possibly learns any factor set in equivalence class induced by the "simulated factors".	B-Reply	B-2	Reply	267
Hence, that metric may work sometimes and suffer instability among different trials.	I-Reply	I-2	Reply	267
[line_break_token]We further introduce some indicator regarding the mutual information I(x;z) and Dkl(q(z)||p(z)) which provide the assessment to the determination of ``used factors" and to the disentanglement.	I-Reply	I-2	Reply	267
[line_break_token][line_break_token]   5.	O	O	Reply	267
[tab_token]Implementation Issue: "Could the aforementioned analysis be instructive in real implementation?'	O	O	Reply	267
[line_break_token]We introduce noise modeling to relax the consideration of the real situation.	B-Reply	B-2	Reply	267
The experiment results empirically testify the knowledge derived from the idealistic case could be instructive in the real situation.	I-Reply	I-2	Reply	267
 They also demonstrate own characteristic of noise modeling in pursuing the disentanglement.	I-Reply	I-2	Reply	267
[line_break_token][line_break_token]C.[tab_token]Despite the theoretical discussion on the intrinsic properties of VAE, if we just discuss the novelty of noise modeling of VAE alone, we don't think it is limited.	B-Reply	B-3	Reply	267
 If you find different noise assumptions/specifications just significantly influence the disentanglement you will believe it	I-Reply	I-3	Reply	267

The authors propose an approach for calibrated predictions under domain shift scenarios.	O	O	Review	801
The approach, that leverages (unlabeled) test samples allows for unsupervised post-processing calibration, even for off-the-shelf models for which the training data is not available.	O	O	Review	801
Experiments compare the proposed approach with existing calibration methods in shifted domains.	O	O	Review	801
[line_break_token][line_break_token]Equation (5) is confusing.	B-Review	B-1	Review	801
If I understand correctly, the authors are simply making the point that q(x,y=k) can be written in terms of q(x,y\neq k) by weighting by the ratio of conditionals, which are available.	I-Review	I-1	Review	801
[line_break_token][line_break_token]Sensitivity to noisy labels.	B-Review	B-2	Review	801
The experiment is reasonable and the results are convincing, however, the authors do not justify why accurate (manual) labels on the target set are not feasible in many applications.	I-Review	I-2	Review	801
The authors could point to a few examples for context.	I-Review	I-2	Review	801
[line_break_token][line_break_token]The authors assume that q_s(y) = q_t(y), which seems restrictive in practice.	B-Review	B-3	Review	801
Though it does not impact my opinion of the proposed approach, it seems narrow to think of a practical situation where the space of covariates is changing but the class composition remains unchanged.	I-Review	I-3	Review	801
This is vaguely addressed in Section 6.	I-Review	I-3	Review	801
Perhaps it can be elaborated further.	I-Review	I-3	Review	801
[line_break_token][line_break_token]I enjoyed reading the paper, the proposed reinterpretation of NLL in terms of a weighted average and its approximation based on weights that do not depend on the labels but the (assumed known) labels marginal is interesting and seems to yield good results.	O	O	Review	801
hank you for your insightful comments, and we are happy that you find the paper interesting.	O	O	Reply	801
We address your concerns and add some parts to the paper accordingly:[line_break_token][line_break_token]Concerns:[line_break_token]1- Equation (5) is confusing.	O	O	Reply	801
[line_break_token][line_break_token] We mean exactly the point that the reviewer mentioned.	B-Reply	B-1	Reply	801
As it was not clear in the text, we rewrite Eq.(5) explanation to make it more clear and precise.	I-Reply	I-1	Reply	801
[line_break_token][line_break_token]2- the authors do not justify why accurate (manual) labels on the target set are not feasible in many applications.	O	O	Reply	801
The authors could point to a few examples for context.	O	O	Reply	801
[line_break_token][line_break_token]We add three examples of applications (Neuron cells classification taken by electron microscope, pathology images and skin disease classification) that have expensive labeling procedure with high risk of labeling noise to the introduction of the paper (Section 1) to make it clear why labeling even for few number of samples is not possible sometimes.	B-Reply	B-2	Reply	801
[line_break_token][line_break_token]3- The authors assume that, which seems restrictive in practice.	O	O	Reply	801
[line_break_token][line_break_token]In domain shift, UTS is valid under Covariate Shift assumption for classification problem which means the test and training datasets are different in representation but keeps the same proportions of each class occurrence.	B-Reply	B-3	Reply	801
Covariate shift assumption is a common domain adaptation assumption that is valid for many classification problems.	I-Reply	I-3	Reply	801
For instance in medical image classification, it is very probable that the illumination, capturing noise, resolution, image size or viewpoint of the test images to be different from the training dataset.	I-Reply	I-3	Reply	801
In this case,  the representation of two domains is changed  that means but the probability of happening a class of object is staying the same which means.	I-Reply	I-3	Reply	801
[line_break_token]In classification problems as the domain is discrete, UTS only needs to calculate empirically the number of occurrence of each class to the total number of samples in the training set which is equal to and use it as to calibrate the model.	I-Reply	I-3	Reply	801
[line_break_token][line_break_token]Update to the paper:[line_break_token]We add one extra paragraph to Section 4.1 with the title of  "Validity of UTS in Practice" focusing on Covariate shift assumption in practice and how to calculate  to address this important concern.	I-Reply	I-3	Reply	801

After  rebuttal period: I recommend accepting  this  paper.	O	O	Review	20505
[line_break_token]======================================[line_break_token]Summary:[line_break_token][line_break_token]This paper attempts to understand if the success of MAML is due to rapid learning or feature reuse.	O	O	Review	20505
The analysis shows that MAML is performing better mainly due to feature reuse.	O	O	Review	20505
Authors use this result to derive a simpler version of MAML called ANIL.	O	O	Review	20505
ANIL does not update the non-final layers of the network during inner loop training and still has similar performance to MAML.	O	O	Review	20505
[line_break_token][line_break_token]My comments:[line_break_token][line_break_token]Overall I think this is an interesting analysis paper which sheds some light on how MAML works, However, I see these analysis not just as a criticism towards MAML.	O	O	Review	20505
I also see these analysis as a criticism against the meta-learning datasets that we use.	O	O	Review	20505
All these datasets are artifically created from the same dataset and hence it might be very easy to reuse features to get good performance.	O	O	Review	20505
I am not sure if the same analysis will hold if we consider a dataset where tasks are not this similar (like Meta-dataset, Triantafillou et al 2019).	B-Review	B-1	Review	20505
I encourage the authors to have this disclaimer in the end of the paper so that the community does not falsely conclude that MAML cannot do rapid learning.	I-Review	I-1	Review	20505
hank you very much for your review and comments on our paper.	O	O	Reply	20505
We will update the latest version of our paper with the disclaimer you have mentioned.	B-Reply	B-1	Reply	20505
We think that exploring how our analysis applies to other datasets from Meta-dataset (Triantafillou et al 2019), or across more diverse tasks, will be interesting future work.	I-Reply	I-1	Reply	20505

[line_break_token]This paper proposed to improve pre-training of language models (e.g. BERT) by incorporating information around entities based on English Wikipedia.	O	O	Review	295
The idea is very simple and straightforward: it takes all the anchor links from Wikipedia and replaces some entities by randomly sampling negative ones of the same entity type (according to Wikidata) and adds an extra binary prediction task which predicts if the entity has been replaced or not.	O	O	Review	295
[line_break_token][line_break_token]The model was initialized by BERT (or the authors‚Äô BERT reimplementation) and trained for another 1M steps with the new training objective and reduced % of masking tokens.	O	O	Review	295
[line_break_token][line_break_token]The model was evaluated on a fact completion task (created by the authors on the 10 sampled Wikidata relations) and several open-domain QA datasets and an entity typing dataset FIGER, and achieved significant improvements on the BERT baselines.	O	O	Review	295
[line_break_token][line_break_token]Overall, I think this is a strong paper.	O	O	Review	295
The idea is simple but effective, the experiments are thorough and improvements over the BERT baselines are significant.	O	O	Review	295
[line_break_token][line_break_token]Below are some concerns I had when I read the paper and also some suggestions on how to improve this paper: [line_break_token][line_break_token]1) I am slightly concerned about the evaluation of the fact completion task and its baselines.	O	O	Review	295
[line_break_token][line_break_token]- Why are there only 190-906 candidates for these relations?	B-Review	B-1	Review	295
How were the candidates chosen?	I-Review	I-1	Review	295
Why not use the full set of possible candidates of that entity type?	I-Review	I-1	Review	295
[line_break_token][line_break_token]- I am not sure why you picked the most common entities for predictions.	I-Review	I-1	Review	295
Fact completion for rare entities would be more challenging and practical.	I-Review	I-1	Review	295
Also, the models might favor choosing more common entities as well.	I-Review	I-1	Review	295
[line_break_token][line_break_token]- I am also not sure if the BERT baseline (by using k [MASK] tokens when the candidate answer has k tokens and taking the average of the k probabilities) is a strong one or not in this setting, as BERT was not trained in this way and it is unclear if this would make BERT favor shorter entities or not.	I-Review	I-1	Review	295
[line_break_token][line_break_token]2) OpenQA results (Table 4): there is a very strong baseline coming out recently (an EMNLP‚Äô19 paper): [line_break_token][line_break_token]Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering.	B-Review	B-2	Review	295
[line_break_token][line_break_token]Even for their BERT-base model, TriviaQA F1 was 67.5, SearchQA F1 was 70.6 and Quasar-T F1 was 59.0.	I-Review	I-2	Review	295
It is okay to not directly compare to their results (the focus is different), but the authors should be aware of their results and perhaps remove the state-of-the-art claim.	I-Review	I-2	Review	295
[line_break_token][line_break_token]3) I‚Äôd be interested in seeing more ablation studies on the importance of masking/replacement choices.	B-Review	B-3	Review	295
What is the percentage of entities that have been replaced?	I-Review	I-3	Review	295
50%?	I-Review	I-3	Review	295
The only thing I can find is that no adjacent entities have been replaced at the same time.	I-Review	I-3	Review	295
How important is that?	I-Review	I-3	Review	295
 I imagine that the percentage of entities that have been replaced should also matter the performance significantly.	I-Review	I-3	Review	295
[line_break_token][line_break_token]4) If I understand correctly, the model was first trained (as BERT) on English Wikipedia + BooksCorpus and then later trained only on English Wikipedia.	B-Review	B-4	Review	295
I wonder how important the first stage would still be.	I-Review	I-4	Review	295
Could add an experiment that trains on Wikipedia only?	I-Review	I-4	Review	295
[line_break_token][line_break_token]Minor suggestions:[line_break_token]1) Please use ‚ÄúEnglish Wikipedia‚Äù instead of ‚ÄúWikipedia‚Äù (#BenderRule)[line_break_token]2) Table 1: don‚Äôt put ‚Äú572‚Äù next to ‚ÄúAverage Hits @10‚Äù.	B-Review	B-5	Review	295
It is confusing.	I-Review	I-5	Review	295
[line_break_token]	O	O	Review	295
hank you for the detailed comments, we have updated the paper accordingly.	O	O	Reply	295
Please see our reply below:[line_break_token][line_break_token]On Fact Completion Evaluation:[line_break_token][line_break_token]Candidate selection: For each relation, we use the groundtruth answer entities from all queries as the candidate set.	B-Reply	B-1	Reply	295
Using the full set of entities of the same type could result in much larger candidate sets (there are more than 5 million person entities), which makes it computational expensive to evaluate each query.	I-Reply	I-1	Reply	295
Note that we view the fact completion task as a probing task instead of a real-world application.	I-Reply	I-1	Reply	295
Thus, we choose to use the compact candidate sets for fast evaluation.	I-Reply	I-1	Reply	295
[line_break_token][line_break_token]Why selecting common entities for evaluation: We focus on common entities since common world knowledge is likely to be more useful to NLP applications.	I-Reply	I-1	Reply	295
Automatically completing knowledge bases with rare long-tail entities is an important problem, but that‚Äôs not the primary focus of this work.	I-Reply	I-1	Reply	295
[line_break_token][line_break_token]BERT baselines: BERT is not trained to handle multi-token entities, so using the average token probability is the best BERT baseline we could think of for the fact completion task.	I-Reply	I-1	Reply	295
Our further inspection shows that the BERT baseline does not favor single-token entities: the average ratio of single-token candidates is 24.5% while the ratio of single-token entities among the BERT‚Äôs top10 predictions is 20.0%.	I-Reply	I-1	Reply	295
[line_break_token][line_break_token]On OpenQA results:[line_break_token]Thank you for pointing us to the new model (Wang et al EMNLP‚Äô19, which is presented after the submission deadline).	B-Reply	B-2	Reply	295
Wang et al show the benefits of normalizing the prediction probabilities across multiple passages during training.	I-Reply	I-2	Reply	295
As stated by the reviewer, our focus is different: instead of investigating more effective ways to use pretrained models for QA, we focus on improving the pretrained model itself and our model can easily stack with the new method.	I-Reply	I-2	Reply	295
Thus, we use a quite straightforward method for the QA experiments.	I-Reply	I-2	Reply	295
We have included a discussion in the revision.	I-Reply	I-2	Reply	295
[line_break_token] [line_break_token]On entity replacement strategy:[line_break_token]With the current replacement strategy, the replacement ratio is approximately 50%.	B-Reply	B-3	Reply	295
With limited resources, we have tried replacing all entities and also increasing the margin to 2 between replaced entities.	I-Reply	I-3	Reply	295
These two model variants are able to match vanilla BERT‚Äôs performance on SQuAD (~89.0F1 and ~90.0F1 compared to 90.5F1 with BERT) but fail to produce as much improvement as our final model.	I-Reply	I-3	Reply	295
These numbers suggest that the new training objective will be less effective if the replacements are too sparse or too dense.	I-Reply	I-3	Reply	295
Also, as we are doing joint training (with MLM), the performance of the two variants is still able to match the vanilla BERT.	I-Reply	I-3	Reply	295
[line_break_token][line_break_token]On two-stage training:[line_break_token]We designed our two-stage method in view of the practices of several existing work (<a href="https://arxiv.org/abs/1905.07129," target="_blank" rel="nofollow">https://arxiv.org/abs/1905.07129,</a> <a href="https://arxiv.org/abs/1909.04164,https://arxiv.org/abs/1905.03197)."	O	O	Reply	295
target="_blank" rel="nofollow">https://arxiv.org/abs/1909.04164,https://arxiv.org/abs/1905.03197).</a> The BERT initialization allows us to start with a strong baseline and the second stage training is also very stable after the initialization.	O	O	Reply	295
As the pretraining + end tasks takes a long time to finish, we are unable to add the ablation during the discussion period due to resource constraints.	B-Reply	B-4	Reply	295
We are happy to add those experiments in the next revision.	I-Reply	I-4	Reply	295

Thank the authors for the response.	O	O	Review	716
The update looks good to me.	O	O	Review	716
The discussion section looks much better now.	O	O	Review	716
[line_break_token]----------------------------------------[line_break_token]Summary[line_break_token]This paper conducts research on adversarial policy against a fixed and black-box policy (victim).	O	O	Review	716
In this setting, the victim has a fixed policy but the adversary has no access to its white-box information.	O	O	Review	716
Instead, the adversary can freely access the black-box policy of the victim.	O	O	Review	716
The experiments show that the trained adversary outperforms the baseline in some scenarios, with three interesting findings: 1) the adversary successfully found the weakness of the victim.	O	O	Review	716
In some scenarios, the adversary wins by doing some weird actions which make no sense, but those weird actions somehow make the victim fail; 2) the victim fails due to the weird (or I should say adversarial) observation from the adversary but not the physical inference.	O	O	Review	716
The authors demonstrate this by showing that the victim has a much higher success rate when the observation is replaced with a ‚Äònormal‚Äô opponent.	O	O	Review	716
I am kind of on the borderline, but still lean to accept paper.	O	O	Review	716
[line_break_token]Strengths[line_break_token]- This paper presents some experiments on adversarial learning when the policy of the victim is fixed and black-box with interesting findings, demonstrates that the adversary can successfully figure out the weakness of the victim.	O	O	Review	716
[line_break_token]- The paper formalizes the problem into an MDP whose dynamics is unknown, which is clear.	O	O	Review	716
[line_break_token]- This paper comes with many experiments supported by great demos, which clearly support the authors‚Äô arguments.	O	O	Review	716
[line_break_token]Weaknesses[line_break_token]- The paper becomes messy in the end and does not come with a good conclusion.	B-Review	B-1	Review	716
With a lot of experiments conducted, the author fails to summarize them into an (or a few) interesting conclusion(s), but end up with a page-long conclusion paragraph, which makes the paper less focused but like listing miscellaneous experiments.	I-Review	I-1	Review	716
From the reader‚Äôs perspective, a (or a few) clear conclusion would be very helpful.	I-Review	I-1	Review	716
[line_break_token]Possible Improvements[line_break_token]My suggestion is to reorganize the second half of the paper, to make a few clear arguments.	I-Review	I-1	Review	716
Currently, the paper looks pretty narrative, and the author might easily get lost while reading the paper.	I-Review	I-1	Review	716
e‚Äôre glad that you found the experimental results interesting and that you agree they clearly support our argument.	O	O	Reply	716
Your concerns center around the clarity of the second-half of the paper, and especially the Discussion section on the final page.	B-Reply	B-1	Reply	716
[line_break_token][line_break_token]Thank you for your feedback.	I-Reply	I-1	Reply	716
In retrospect, the Discussion section was too crowded, trying to present a conclusion, discussion of consequences and future work.	I-Reply	I-1	Reply	716
We have revised this section to be more tightly focused, and have introduced sub-headings to signpost different material.	I-Reply	I-1	Reply	716
Two paragraphs justifying our threat model have been removed, with an abbreviated version included in the Framework section.	I-Reply	I-1	Reply	716
The Contributions sub-section has been rewritten to be itemized and less narrative.	I-Reply	I-1	Reply	716
[line_break_token][line_break_token]Clarity is important to us, and so we would appreciate your thoughts on the revised paper.	I-Reply	I-1	Reply	716
We are happy to continue the editing process to improve comprehensibility.	I-Reply	I-1	Reply	716
It would be particularly helpful to know if there are any specific sections of the paper you find confusing, or if there are any overarching questions about the work you feel the paper did not address.	I-Reply	I-1	Reply	716

This paper introduces ‚Äústiffness‚Äù, a new metric to characterize generalization in neural networks.	O	O	Review	20500
Stiffness is a pretty simple concept and is relatively straightforward to compute.	O	O	Review	20500
The authors evaluate this metric on standard datasets using two relatively small neural networks.	O	O	Review	20500
On the whole, the paper is written clearly and explains its methodology in simple language.	O	O	Review	20500
[line_break_token][line_break_token]I have a few observations:[line_break_token]1.	O	O	Review	20500
The equivalence between equation 2 and equation 3 is mentioned in passing but no explanation is provided.	B-Review	B-2	Review	20500
Th equivalence is not clear so I would encourage the authors to provide a short proof.	I-Review	I-2	Review	20500
[line_break_token]2.	B-Review	B-6	Review	20500
 Since stiffness depends on the gradients obtained on points in the input space, which in turn depends on the loss, why would a practitioner training a neural network turn to stiffness to diagnose overfitting instead of just looking at the values of the training and validation losses?	B-Review	B-3	Review	20500
Indeed, the authors themselves say that a network has overfitted when training and validation losses diverge.	I-Review	I-3	Review	20500
The paper fails to motivate why stiffness is better than just looking at losses during training.	I-Review	I-3	Review	20500
[line_break_token]3.	B-Review	B-6	Review	20500
The authors mention ‚ÄúThe train-val stiffness is directly related to generalization, as it corresponds to the amount of improvement on the training set transferring to the improvement of the validation set. ‚	B-Review	B-4	Review	20500
Äù.	I-Review	I-4	Review	20500
Typically, generalization is evaluated on a held out test set so I fail to understand what the authors mean by this statement.	I-Review	I-4	Review	20500
We would expect validation error to underestimate test error  so while they are related, train-val stiffness would not necessarily characterize generalization.	I-Review	I-4	Review	20500
It would be interesting to see a train-test stiffness graph to test the authors claim.	I-Review	I-4	Review	20500
[line_break_token]4.	B-Review	B-6	Review	20500
The paper fails to motivate the the utility of the concept of ‚ÄúDynamical Critical distance‚Äù.	B-Review	B-5	Review	20500
Since the primary goal of  paper is to understand generalization, I would like the authors to clarify the motivation to study this quantity.	I-Review	I-5	Review	20500
What additional insight does this provide with respect to generalization?	I-Review	I-5	Review	20500
[line_break_token]5.	O	O	Review	20500
The term ‚Äúdynamical critical distance‚Äù is not used uniformly.	B-Review	B-6	Review	20500
For example, it is mentioned as ‚Äúdynamical critical scale‚Äù in section 3.3 and ‚Äúdynamical critical length‚Äù in section 4.2.	I-Review	I-6	Review	20500
[line_break_token]6.	O	O	Review	20500
While the paper on the whole is written in a clear fashion, I found section 4.4 to be particularly confusing.	B-Review	B-7	Review	20500
The authors should consider rewriting that section to make it clearer.	I-Review	I-7	Review	20500
[line_break_token][line_break_token]In summary, the concept of stiffness seems to closely follow training and validation losses and any problem diagnosed using stiffness would therefore be also diagnosed via examining the loss values.	B-Review	B-1	Review	20500
This along with other concerns mentioned above mean that I cannot recommend this paper for publication.	I-Review	I-1	Review	20500
-----------------------[line_break_token]‚ÄúIn summary, the concept of stiffness seems to closely follow training and validation losses and any problem diagnosed using stiffness would therefore be also diagnosed via examining the loss values.	O	O	Reply	20500
This along with other concerns mentioned above mean that I cannot recommend this paper for publication.	O	O	Reply	20500
‚Äù[line_break_token][line_break_token]We do not agree with your characterization of our contribution.	B-Reply	B-1	Reply	20500
It is of course true that we could look at losses directly and it is indeed what we do -- we defined stiffness as the correlation between loss changes.	I-Reply	I-1	Reply	20500
That, however, is not the main contribution of our paper.	I-Reply	I-1	Reply	20500
We study how this concept depends on class membership, the stage of training, and the learning rate used for training.	I-Reply	I-1	Reply	20500
Those results could certainly not be inferred from the total loss and (according to us) deserve a closer look	I-Reply	I-1	Reply	20500

This paper builds a model of motivation-dependent learning.	O	O	Review	705
 A motivation channel is provided as an additional input to and RL-based learning system (essentially concatenated to state information), similar to goal-conditioned approaches (as the authors mention).	O	O	Review	705
 The motivational variables evolve according to their own rules, and are designed/interpreted as biological motivations such as water, food, sleep and work.	O	O	Review	705
 While the narrative is interesting, I lean towards reject as I believe it failed to deliver on what it promised.	O	O	Review	705
[line_break_token][line_break_token]In the first experiment, the satisfaction of these motivations are mapped onto a 4-room setting, where being in each room satisfies a motivation.	O	O	Review	705
 The choice to map the four rooms to biological drives is cute, but possibly confusing/misleading since this navigation problem really has nothing to do with these biological drives.	O	O	Review	705
A claim is that by providing the motivation as input to the policy, it is more robustly (across seeds) able to learn the "migration" (i.e. cycling) behavior among the rooms.	O	O	Review	705
 In a second example, a similar problem is solved involving navigation on a graph.	O	O	Review	705
[line_break_token][line_break_token]The final, most substantial example, is a policy trained to solve a simple, abstract version of a behavioral task.	B-Review	B-2	Review	705
In this setting, a motivation channel was again used.	I-Review	I-2	Review	705
 However, the motivation channel value is now fixed to one of two discrete values, essentially meaning it is simply a task-label variable, a paradigm that has already been applied in the context of simple models of neuroscience tasks, e.g. see Song et al 2017 "Reward-based training of recurrent neural networks for cognitive and value-based tasks".	I-Review	I-2	Review	705
 [line_break_token][line_break_token]There is a bit of a mixed framing overall as to whether it is being claimed that the "motivation" being passed as an input is a fundamental contribution to AI/RL (I think it is not), versus the computational modeling of biological motivation.	B-Review	B-4	Review	705
 I think the people qualified to judge whether the computational model is a worthwhile model of motivation specifically are probably a narrower set of computational neuroscientists.	I-Review	I-4	Review	705
 I do think there is value in the kind of computational modeling performed, involving establishing a relationship between training a neural network to solve a behavioral task and comparing this with real neural data.	I-Review	I-4	Review	705
 This paradigm already becoming increasingly popular within computational neuroscience.	I-Review	I-4	Review	705
 However, while I find the results slightly interesting, but not very significant, as someone interested in the biology of motivation, I question whether the nature of these contributions would be of broad interest at this venue.	I-Review	I-4	Review	705
 [line_break_token][line_break_token]More fundamentally, I don't believe there is a meaningful ML/AI/RL contribution, and I have some issues with the presentation of the first two examples.	B-Review	B-5	Review	705
 While I do like the narrative inspiring these problems, I find the implementations of the problems too simplified to really be meaningfully related to their inspiration (in terms of motivated behaviors).	I-Review	I-5	Review	705
 Rather than really model motivation as part of the policy architecture, the authors have proposed a solution to modeling motivation that makes motivation a feature of the environment.	I-Review	I-5	Review	705
 Essentially, the reward provided by the environment depends on an extra latent variable and by hiding this (in the cases where the policy does not see motivation inputs), it is quite likely that it becomes too difficult for the value function to predict what is happening (the environment has become partially observed).	I-Review	I-5	Review	705
 This seems less a setting where motivation channels solve a problem, and more just an example of an environment that has more complex rules for generating rewards being more challenging to learn about, especially if latent variables are not available to the value function.	I-Review	I-5	Review	705
 Critically, it has not been shown that motivational systems are useful for artificial agents, rather the tasks themselves have been designed to attempt to be models of biological motivation.	I-Review	I-5	Review	705
 [line_break_token][line_break_token]Personally, I am interested in motivated behaviors and think that future AI developments should take note of this field, but again, the present work does not provide actionable insights into implementing an artificial motivation system.	B-Review	B-1	Review	705
 At the same time, this work does not provide interesting enough neurobiological results for those to stand on their own either.	I-Review	I-1	Review	705
[line_break_token][line_break_token]Minor clarification:[line_break_token][line_break_token]"trained to perform in realistic tasks" -- the task is very simple.	B-Review	B-3	Review	705
 I would consider this a fairly abstract model of the task.	I-Review	I-3	Review	705
 [line_break_token]	B-Review	B-1	Review	705
e thank the reviewer for careful reading of our paper at least twice and providing the thorough, meaningful, and in depth review.	O	O	Reply	705
We would like to debate, however, the assessment of value of this work for both neuroscience and machine learning communities and its relevance to the venue.	O	O	Reply	705
We agree with the reviewer that ‚Äúfuture AI developments should take a note‚Äù of motivated behaviors.	B-Reply	B-1	Reply	705
Our overall goal is to facilitate this exchange.	I-Reply	I-1	Reply	705
It is also clear that neuroscience community should take notice of many developments in AI.	I-Reply	I-1	Reply	705
One of such developments in the hierarchical RL (HRL) that has not been mapped on neural circuits yet.	I-Reply	I-1	Reply	705
Our paper proposes that motivational salience, which we call ‚Äòmotivation‚Äô for brevity, may have evolved from modulating simple feeding behaviors to solving more complex hierarchical cognitive tasks.	I-Reply	I-1	Reply	705
As such, our paper aims at bridging the gap between HRL community in ML and neuro communities interested in understanding motivated behaviors.	I-Reply	I-1	Reply	705
Clearly, building a motivated HRL model is not a task for a single paper.	I-Reply	I-1	Reply	705
Our goal was therefore to introduce the concept of motivational salience to the ML community.	I-Reply	I-1	Reply	705
In addition, we believe, we have made substantial contributions to computational neuroscience and to understanding of computational algorithms run by circuits in ventral pallidum (VP) as detailed below[line_break_token][line_break_token]1) Our paper presents the first example of neural network processing information about motivational salience.	B-Reply	B-4	Reply	705
Motivational salience has been described in RL framing before, but the networks processing motivation are missing.	I-Reply	I-4	Reply	705
The reviewer may not agree with how we frame the problem, but, perhaps, it is also important to formulate one solution in order to compel community to find alternatives.	I-Reply	I-4	Reply	705
Our solution is useful, however, because it helps solve complex computational tasks and allows to make sense of responses of neurons in basal ganglia.	I-Reply	I-4	Reply	705
[line_break_token][line_break_token]2) We explain the presence of two oppositely-tuned populations of neurons in VP as resulting from the need to solve temporal credit assignment problem via maintaining working memory about reward expectation between CS and US.	I-Reply	I-4	Reply	705
[line_break_token][line_break_token]3) Our general framework allows to derive clear experimentally testable predictions about network structure in VP.	B-Reply	B-2	Reply	705
We use a conventional machine learning algorithm (recurrent network training using backpropagation) to derive the structure of the network in VP from the first principles and show that it should contain inhibitory connections between two populations of neurons.	I-Reply	I-2	Reply	705
We agree with the reviewer that backpropagation has been used to train recurrent RL V-networks before, for example, in the neuroscience setting by Song et al (2017).	I-Reply	I-2	Reply	705
However, Song et al (2017) did not show that the network has a push-pull architecture.	I-Reply	I-2	Reply	705
Since this particular architecture is known to be important in neural systems, it is valuable to show that the same connectivity can be used in circuits implementing motivated behavior.	I-Reply	I-2	Reply	705
We argue that the presence of the push-pull circuit leads to the emergence of the two oppositely tuned populations of neurons.	I-Reply	I-2	Reply	705
[line_break_token][line_break_token][line_break_token]Overall we suggest that our paper introduces motivational salience as a potential basis of HRL, uses the general machine learning framework based on motivational salience to explain existing experimental data (two populations of neurons), and generates clear experimentally testable predictions about the structure of network of real biological neurons in basal ganglia.	B-Reply	B-1	Reply	705
We thus humbly suggest that it makes a substantial contribution to the understanding of the circuit basis of computation involved in motivated behaviors	I-Reply	I-1	Reply	705

First, the authors propose to train a model for natural language inference (NLI) on multiple languages simultaneously.	O	O	Review	10217
In particular, they translate English examples into all target languages and fine-tune a pretrained language model on all thereby obtained data at once.	O	O	Review	10217
This is different from the previous state-of-the-art approach which consisted of, after translating from English into target languages, fine-tuning one NLI model for each language individually.	O	O	Review	10217
The authors show that their approach is superior to training individual models for each language.	O	O	Review	10217
For evaluation, XNLI is used.	O	O	Review	10217
[line_break_token][line_break_token]Second, they introduce cross-lingual knowledge distillation (XD), where the same polyglot model is used both as teacher and student across languages to improve its sentence representations without using the target task labels.	O	O	Review	10217
The main idea is that the same sentence in all languages should receive output representations as similar as possible.	O	O	Review	10217
[line_break_token][line_break_token]The paper seems okay to me and the experiments seem solid.	O	O	Review	10217
However, the results are not particularly surprising and the methods are not very innovative.	B-Review	B-6	Review	10217
The writing could be improved.	I-Review	I-6	Review	10217
[line_break_token][line_break_token]This paper could further be improved in the following ways:[line_break_token]- A more detailed investigation which combination of languages improve performance (and why?).	B-Review	B-1	Review	10217
[line_break_token]- Similarly: A combination of MTL and XD doesn't seem straightforward.	B-Review	B-2	Review	10217
Why?	I-Review	I-2	Review	10217
What is learned?	I-Review	I-2	Review	10217
[line_break_token][line_break_token]Smaller comments:[line_break_token]- Articles are missing frequently (e.g., "we substitute the word prediction head with classification layer" -&gt; "we substitute the word prediction head with a classification layer")[line_break_token]- Table 5: "w/0" -&gt; "w/o"?	O	O	Review	10217
[line_break_token]- Have you run any significance tests?	B-Review	B-5	Review	10217
hank you for your review!	O	O	Reply	10217
We will make sure to improve the writing and clarity of the paper, sorry for making you read a hurried submission.	O	O	Reply	10217
We will definitely incorporate your smaller comments.	O	O	Reply	10217
[line_break_token][line_break_token]We did not run any significance test for the submitted version; since it was suggested by several reviewers, we will do it via bootstrapping, as well as re-run the key models to estimate the variance of their results.	B-Reply	B-5	Reply	10217
[line_break_token][line_break_token]We agree that a more detailed investigation of language combinations would be exciting, we did our best to explain the motivation for the choices we did in this paper.	B-Reply	B-1	Reply	10217
We hope to provide a more thorough comparison in the next paper.	I-Reply	I-1	Reply	10217
[line_break_token][line_break_token]As for ‚ÄúSimilarly: A combination of MTL and XD doesn't seem straightforward.	O	O	Reply	10217
Why?	O	O	Reply	10217
What is learned?‚Äù:[line_break_token]In the case of MTL, data from low-resource unrelated (to English) languages were used just as well as data for resource-rich high-translation-quality languages.	B-Reply	B-2	Reply	10217
Our case studies with particular languages suggest that the quality of the parallel signal matters for XD.	I-Reply	I-2	Reply	10217
By using XD with only a high-quality parallel signal from high-resource languages we are able to further improve the system learned with multilanguage finetuning that used data from all sources.	I-Reply	I-2	Reply	10217

This paper looks at the idea of fusing multiple layers (typically a convolution and a LRN or pooling layer) into a single convolution via retraining of just that layer, and shows that simpler, faster models can be constructed that way at minimal loss in accuracy.	O	O	Review	442
This idea is fine.	O	O	Review	442
Several issues:[line_break_token]- The paper introduces the concept of a 'Deeprebirth layer', and for a while it seems like it's going to be some new architecture.	B-Review	B-1	Review	442
Mid-way, we discover that 1) it's just a convolution 2) it's actually a different kind of convolution depending on whether one fuses serial or parallel pooling layers.	I-Review	I-1	Review	442
I understand the desire to give a name to the technique, but in this case naming the layer itself, when it's actually multiple things, non of which are new architecturally, confuses the argument a lot.	I-Review	I-1	Review	442
[line_break_token]- There are ways to perform this kind of operator fusion without retraining, and some deep learning framework such as Theano and the upcoming TensorFlow XLA implement them.	B-Review	B-2	Review	442
It would have been nice to have a baseline that implements it, especially since most of the additional energy cost from non-fused operators comes from the extra intermediate memory writes that operator fusion removes.	I-Review	I-2	Review	442
[line_break_token]- Batchnorm can be folded into convolution layers without retraining by scaling the weights.	B-Review	B-3	Review	442
Were they folded into the baseline figures reported in Table 7?	I-Review	I-3	Review	442
[line_break_token]- At the time of writing, the authors have not provided the details that would make this research reproducible, in particular how the depth of the fused layers relates to the depth of the original layers in each of the experiments.	B-Review	B-4	Review	442
[line_break_token]- Retraining: how much time (epochs) does the retraining take?	B-Review	B-5	Review	442
Did you consider using any form of distillation?	I-Review	I-5	Review	442
[line_break_token]Interesting set of experiments.	I-Review	I-5	Review	442
This paper needs a lot of improvements to be suitable for publication.	I-Review	I-5	Review	442
[line_break_token]- Open-sourcing: having the implementation be open-source always enhances the usefulness of such paper.	B-Review	B-6	Review	442
Not a requirement obviously.	I-Review	I-6	Review	442
[line_break_token][line_break_token]	O	O	Review	442
(1) I understand the desire to give a name to the technique, but in this case naming the layer itself, when it's actually multiple things, non of which are new architecturally, confuses the argument a lot.	O	O	Reply	442
[line_break_token][line_break_token]Ans: Well, we name our approach as ‚Äúdeep-rebirth‚Äù because in our proposed speed optimization pipeline, we have replaced multiple deep network layers which run much slower compared to the newly generated and faster layer (e.g., convolution layer in our experiment) like a rebirth.	B-Reply	B-1	Reply	442
[line_break_token][line_break_token](2) There are ways to perform this kind of operator fusion without retraining, and some deep learning framework such as Theano and the upcoming TensorFlow XLA implement them.	O	O	Reply	442
It would have been nice to have a baseline that implements it, especially since most of the additional energy cost from non-fused operators comes from the extra intermediate memory writes that operator fusion removes.	O	O	Reply	442
[line_break_token][line_break_token]Ans: As far as we know, the operator fusion without retraining can only be applied to some specific structure, i.e.,  batch normalization or mean normalization after convolution.	B-Reply	B-2	Reply	442
This kind of operator fusion can‚Äôt be applied to other kinds of layers, such as pooling, LRN, etc.	I-Reply	I-2	Reply	442
Our pipeline is much more general.	I-Reply	I-2	Reply	442
[line_break_token][line_break_token]The deep learning framework such as Theano and XLA performs the operator fusion to reduce the memory.	I-Reply	I-2	Reply	442
However, the execution time of these models may not be accelerated due to the use of same architectures (i.e., performing exactly the same set of floating-point operations).	I-Reply	I-2	Reply	442
 If we view them as the baseline, their execution time would be much ‚Äúhigher‚Äù than deep-rebirth.	I-Reply	I-2	Reply	442
In contrast, our method re-trained the rebirth layers and significantly speeds up the execution time.	I-Reply	I-2	Reply	442
[line_break_token][line_break_token](3) Batchnorm can be folded into convolution layers without retraining by scaling the weights.	O	O	Reply	442
Were they folded into the baseline figures reported in Table 7?	O	O	Reply	442
[line_break_token][line_break_token]Ans: We agree that batchnorm can be folded into convolution layer without retraining by scaling the weights.	B-Reply	B-3	Reply	442
The results listed in Table 7 also include other layers‚Äô  optimization, e.g., pooling, not limited to batchnorm.	I-Reply	I-3	Reply	442
[line_break_token][line_break_token](4) At the time of writing, the authors have not provided the details that would make this research reproducible, in particular how the depth of the fused layers relates to the depth of the original layers in each of the experiments.	O	O	Reply	442
Open-sourcing: having the implementation be open-source always enhances the usefulness of such paper.	O	O	Reply	442
Not a requirement obviously.	O	O	Reply	442
[line_break_token][line_break_token]Ans:  We have listed the details in our revision.	B-Reply	B-4	Reply	442
We plan to release the code after final decision.	I-Reply	I-4	Reply	442
Our first step for open-source would be the release of the model architectures (in caffe‚Äôs prototxt format) used in our paper.	I-Reply	I-4	Reply	442
[line_break_token][line_break_token](5) Retraining: how much time (epochs) does the retraining take?	O	O	Reply	442
Did you consider using any form of distillation?	O	O	Reply	442
[line_break_token][line_break_token]Ans: Each step of our optimization pipeline takes around 2 epochs (in section 4.1.1).	B-Reply	B-5	Reply	442
For GoogleNet, it takes 9 steps and 18 epochs.	I-Reply	I-5	Reply	442
We regard this training time (or rebirth time) as a one-time cost and once trained it can be deployed to any mobile devices.	I-Reply	I-5	Reply	442
[line_break_token][line_break_token]Our ‚Äúrebirth‚Äù method can be considered as a special form of distillation that transfers the knowledge from the cumbersome substructure of multiple layers to the rebirthed accelerated substructure.	I-Reply	I-5	Reply	442
Different from traditional distillation method, our approach adopts layer-wise optimization and maintains the knowledge of the rest layers.	I-Reply	I-5	Reply	442
Also, our method utilizes a softmax at the end of our CNN to optimize classification accuracy.	I-Reply	I-5	Reply	442
[line_break_token][line_break_token](6) Interesting set of experiments.	O	O	Reply	442
This paper needs a lot of improvements to be suitable for publication.	O	O	Reply	442
[line_break_token][line_break_token]Ans: Thanks for your appreciation of our paper.	B-Reply	B-6	Reply	442
We are constantly improving the quality of our paper.	I-Reply	I-6	Reply	442

This paper studies knowledge transfer problem from small capacity network to bigger one.	B-Review	B-3	Review	395
This is a follow-up work of Net2Net (ICLR 2015) and NetMorph(ICML 2016).	O	O	Review	395
 [line_break_token]Comments[line_break_token]- 1) This paper studies macroscopic problem, with the morphing process composed by multiple atomic operations.	B-Review	B-1	Review	395
While the atomic operations are proposed in Net2Net and NetMorph, there has not been study of the general modularized process principally.	I-Review	I-1	Review	395
Thus this paper asks a novel question.	I-Review	I-1	Review	395
[line_break_token]- 2) The solution by composing multiple atomic transformations seems to be quite reasonable.	O	O	Review	395
[line_break_token]- 3) In the ‚Äúrelated work‚Äù section, it is better to change ‚Äúnetwork morphism‚Äù to ‚Äúknowledge transfer‚Äù or in the subsection title, most of these works are known as knowledge transfer and it helps to connect to the existing works.	B-Review	B-2	Review	395
[line_break_token]- 4) The author shows experiments on variants of ResNet.	B-Review	B-3	Review	395
While the experiment shows that initializing from ResNet gives better error rate than the ones trained from scratch, it is unclear what the source This paper studies knowledge transfer problem from small capacity network to bigger one.	I-Review	I-3	Review	395
This is a follow-up work of Net2Net (ICLR 2015) and NetMorph(ICML 2016).	O	O	Review	395
 [line_break_token]Comments[line_break_token]- 1) This paper studies macroscopic problem, with the morphing process composed by multiple atomic operations.	B-Review	B-1	Review	395
While the atomic operations are proposed in Net2Net and NetMorph, there has not been study of the general modularized process principally.	I-Review	I-1	Review	395
Thus this paper asks a novel question.	I-Review	I-1	Review	395
[line_break_token]- 2) The solution by composing multiple atomic transformations seems to be quite reasonable.	O	O	Review	395
[line_break_token]- 3) In the ‚Äúrelated work‚Äù section, it is better to change ‚Äúnetwork morphism‚Äù to ‚Äúknowledge transfer‚Äù or in the subsection title, most of these works are known as knowledge transfer and it helps to connect to the existing works.	B-Review	B-2	Review	395
[line_break_token]- 4) The author shows experiments on variants of ResNet.	B-Review	B-3	Review	395
While the experiment shows that initializing from ResNet gives better error rate than the ones trained from scratch, it is unclear what the source is.	O	O	Review	395
[line_break_token]- 5) One major advantage of this type of knowledge transfer (Net2Net, NetMorph) is to speedup training and model exploration.	B-Review	B-4	Review	395
There seems to be no experiments demonstrate such advantage (possibly due to the lose initialization of BatchNorm).	I-Review	I-4	Review	395
This is the major drawback of this paper.	I-Review	I-4	Review	395
[line_break_token]-6)  The method proposed by the author can in principle do quite complicated transformation, e.g. transform  an entire resnet from a single conv layer, the experiment only consists of simple module transformations, which in some way can be covered by atomic operations.	B-Review	B-5	Review	395
It would be more interesting to see what the results of more complicated transformations are (even if they are not as effective).	O	O	Review	395
[line_break_token][line_break_token]In summary, this paper studies a novel problem of knowledge transfer in a macroscopic level.	O	O	Review	395
The method could be of interest to the ICLR community.	O	O	Review	395
The experiments should be improved (comment 5) to make the results more convincing and practically useful and I strongly encourage the authors to do so.	B-Review	B-4	Review	395
[line_break_token]	O	O	Review	395
We appreciate the recognition and detailed comments from Reviewer #4, and have the following responses to address the concerns.	O	O	Reply	395
[line_break_token][line_break_token]3) In the ‚Äúrelated work‚Äù section, it is better to change ‚Äúnetwork morphism‚Äù to ‚Äúknowledge transfer‚Äù or in the subsection title, most of these works are known as knowledge transfer and it helps to connect to the existing works.	O	O	Reply	395
[line_break_token][line_break_token]We have made the change as suggested.	B-Reply	B-2	Reply	395
[line_break_token][line_break_token]4) The author shows experiments on variants of ResNet.	O	O	Reply	395
While the experiment shows that initializing from ResNet gives better error rate than the ones trained from scratch, it is unclear what the source is.	O	O	Reply	395
[line_break_token][line_break_token]When available, the results were cited from their original papers.	B-Reply	B-3	Reply	395
For example, the accuracies of ResNet on the CIFAR10 dataset in Table 1 were from [He2015]. For other ones that cannot be found in any existing paper, we trained the models by ourselves.	I-Reply	I-3	Reply	395
[line_break_token][line_break_token]5) One major advantage of this type of knowledge transfer (Net2Net, NetMorph) is to speedup training and model exploration.	O	O	Reply	395
There seems to be no experiments demonstrate such advantage (possibly due to the lose initialization of BatchNorm).	O	O	Reply	395
This is the major drawback of this paper.	O	O	Reply	395
[line_break_token][line_break_token]It has been verified in our previous work [Wei2016] that VGG16 could be easily morphed into a 19-layer network (NetMorph-VGG16), with a 15x speedup compared with training from scratch. (	B-Reply	B-4	Reply	395
NetMorh-VGG16 performed better than both VGG16 and VGG19.)	I-Reply	I-4	Reply	395
In this work, our focus is to study the macroscopic problem of network morphism, i.e., modularized morphing.	I-Reply	I-4	Reply	395
Thus we adopted a uniform training procedure for both of these two learning schemes.	I-Reply	I-4	Reply	395
Therefore, the training time for network morphism is the same as training from scratch in this research.	I-Reply	I-4	Reply	395
But the training can be greatly speeded up as in [Wei2016], which however is not our focus in this research.	I-Reply	I-4	Reply	395
[line_break_token][line_break_token]It is much cheaper to adopt network morphism to explore and design a new effective network architecture.	I-Reply	I-4	Reply	395
For example, for the network architectures illustrated in Fig.	I-Reply	I-4	Reply	395
4, we simply split the branches to compose new modules, which does not require domain-specific knowledge.	I-Reply	I-4	Reply	395
However, designing such a new network architecture via training from scratch requires significant insight to the network architectures, and it is also hard to tell whether the newly designed network will achieve a better performance until it is fully trained.	I-Reply	I-4	Reply	395
[line_break_token][line_break_token]Another advantage when exploring new network architectures with network morphism is that, one can quickly check whether a morphed architecture deserves further exploration by continuing to train the morphed network in a finer learning rate (e.g. 1e-5), to see if the performance is improved.	I-Reply	I-4	Reply	395
Hence, one does not have to wait for days or even months of training time to tell whether the new network architecture will achieve a better performance.	I-Reply	I-4	Reply	395
This could significantly save human time for deciding which network architecture is worth for exploring.	I-Reply	I-4	Reply	395
[line_break_token] [line_break_token]For BatchNorm, it is not a problem in our proposed algorithms.	I-Reply	I-4	Reply	395
While it will cause the morphed network not to exactly preserve the network function, this small perturbation introduced by BatchNorm actually will not affect the performance of the morphed network.	I-Reply	I-4	Reply	395
We observed almost identical accuracies for the original network and the morphed network before continual training.	I-Reply	I-4	Reply	395
This was stated in the last paragraph of Section 3.7.	I-Reply	I-4	Reply	395
[line_break_token][line_break_token]6) The method proposed by the author can in principle do quite complicated transformation, e.g. transform an entire resnet from a single conv layer, the experiment only consists of simple module transformations, which in some way can be covered by atomic operations.	O	O	Reply	395
It would be more interesting to see what the results of more complicated transformations are (even if they are not as effective).	O	O	Reply	395
[line_break_token][line_break_token]This is a very good suggestion.	B-Reply	B-5	Reply	395
Theoretically, an entire ResNet could be morphed from a single convolutional layer.	I-Reply	I-5	Reply	395
However, intuitively, this will not be that effective as the change to the network architecture is too large.	I-Reply	I-5	Reply	395
Instead, we proposed to grow the network depth in an exponential order by network morphism.	I-Reply	I-5	Reply	395
It was demonstrated to be very effective.	I-Reply	I-5	Reply	395
This is not trivial topic, and we have organized the findings in another paper which is under review.	I-Reply	I-5	Reply	395

Pros:[line_break_token]The paper is easy to read.	O	O	Review	288
Logic flows naturally within the paper.	O	O	Review	288
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]1.	O	O	Review	288
Experimental results are neither enough nor convincing.	O	O	Review	288
[line_break_token][line_break_token]Only one set of data is used throughout the paper: the Cifar10 dataset, and the architecture used is only a 100 layered MLP.	B-Review	B-1	Review	288
Even though LCW performs better than others in this circumstance, it does not prove its effectiveness in general or its elimination of the gradient vanishing problem.	I-Review	I-1	Review	288
For the 100 layer MLP, it's very hard to train a simple MLP and the training/testing accuracy is very low for all the methods.	B-Review	B-2	Review	288
More experiments with different number of layers and different architecture like ResNet should be tried to show better results.	B-Review	B-3	Review	288
[line_break_token][line_break_token]In Figure (7), LCW seems to avoid gradient vanishing but introduces gradient exploding problem.	B-Review	B-4	Review	288
[line_break_token][line_break_token]The proposed concept is only analyzed in MLP with Sigmoid activation function.	B-Review	B-5	Review	288
In the experimental parts, the authors claim they use both ReLU and Sigmoid function, but no comparisons are reflected in the figures.	I-Review	I-5	Review	288
[line_break_token][line_break_token]2.	B-Review	B-10	Review	288
The whole standpoint of the paper is quite vague and not very convincing.	B-Review	B-6	Review	288
[line_break_token]In section 2, the authors introduce angle bias and suggest its effect in MLPs that with random weights, showing that different samples may result in similar output in the second and deeper layers.	I-Review	I-6	Review	288
However, the connection between angle bias and the issue of gradient vanishing lacks a clear analytical connection.	I-Review	I-6	Review	288
The whole analysis of the connection is built solely on this one sentence "At the same time, the output does not change if we adjust the weight vectors in Layer 1", which is nowhere verified.	I-Review	I-6	Review	288
[line_break_token][line_break_token]Further, the phenomenon is only tested on random initialization.	B-Review	B-7	Review	288
When the network is trained for several iterations and becomes more settled, it is not clear how "angle affect" affects gradient vanishing problem.	I-Review	I-7	Review	288
[line_break_token][line_break_token][line_break_token]Minors:[line_break_token]1.	O	O	Review	288
Theorem 1,2,3 are direct conclusions from the definitions and are mis-stated as Theorems.	B-Review	B-8	Review	288
[line_break_token][line_break_token]2. '	O	O	Review	288
patters' -> 'patterns'[line_break_token][line_break_token]3.	O	O	Review	288
In section 2.3, reasons 1 and 2 state the similar thing that output of MLP has relatively small change with different input data when angle bias occurs.	B-Review	B-10	Review	288
Only reason 1 mentions the gradient vanishing problem, even though the title of this section is "Relation to Vanishing Gradient Problem".	I-Review	I-10	Review	288
[line_break_token]	O	O	Review	288
We thank the reviewer for the insightful comments on our paper.	O	O	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 1: Only one set of data is used throughout the paper: the Cifar10 dataset, and[line_break_token]the architecture used is only a 100 layered MLP.	O	O	Reply	288
[line_break_token][line_break_token]Response 1: We did additional experiments with the SVHN dataset and the CIFAR-100 dataset[line_break_token]for each of which we trained 5 layered, 50 layered, and 100 layered MLPs.	B-Reply	B-1	Reply	288
[line_break_token]Results are shown in Figure 12, Figure 14, and Figure 15 in the revised manuscript.	I-Reply	I-1	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 2: For the 100 layer MLP, it's very hard to train a simple MLP and the[line_break_token]training/testing accuracy is very low for all the methods.	O	O	Reply	288
[line_break_token][line_break_token]Response 2: We do not agree to the comment.	B-Reply	B-2	Reply	288
The training accuracy for CIFAR-10 or SVHN dataset[line_break_token]is high for the 100 layer MLP, if we apply LCW (proposed method) or batch normalization,[line_break_token]as shown Figure 12 (a) and Figure 14 (a) in the revised manuscript.	I-Reply	I-2	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 3: More experiments with different number of layers and different architecture[line_break_token]like ResNet should be tried to show better results.	O	O	Reply	288
[line_break_token][line_break_token]Response 3: As mentioned in Response 1, we did experiments with several sizes of MLPs.	B-Reply	B-3	Reply	288
[line_break_token]We also tried ResNet, but it was unable to train ResNet with LCW.	I-Reply	I-3	Reply	288
This is mainly because[line_break_token]ReLU is used in ResNet, and the gradient explosion explained in Section 5.2 occurs.	I-Reply	I-3	Reply	288
[line_break_token]We are now developing methods that make LCW applicable to ReLU nets, including ResNet.	I-Reply	I-3	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 4: In Figure (7), LCW seems to avoid gradient vanishing but introduces gradient exploding problem.	O	O	Reply	288
[line_break_token][line_break_token]Response 4: We agree to the comment.	B-Reply	B-4	Reply	288
We have added an explanation on these points to the[line_break_token]second paragraph of Section 6 in the revised manuscript.	I-Reply	I-4	Reply	288
[line_break_token][line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 5: The proposed concept is only analyzed in MLP with Sigmoid activation function.	O	O	Reply	288
[line_break_token]In the experimental parts, the authors claim they use both ReLU and Sigmoid function,[line_break_token]but no comparisons are reflected in the figures.	O	O	Reply	288
[line_break_token][line_break_token]Response 5: We omitted results with ReLU in the figures, because MLPs with ReLU were not[line_break_token]trainable at all when LCW is applied, as mentioned in Section 5.2.	B-Reply	B-5	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 6: In section 2, the authors introduce angle bias and suggest its effect in MLPs that[line_break_token]with random weights, showing that different samples may result in similar output in the second[line_break_token]and deeper layers.	O	O	Reply	288
However, the connection between angle bias and the issue of gradient[line_break_token]vanishing lacks a clear analytical connection.	O	O	Reply	288
The whole analysis of the connection is built[line_break_token]solely on this one sentence "At the same time, the output does not change if we adjust the[line_break_token]weight vectors in Layer 1", which is nowhere verified.	O	O	Reply	288
[line_break_token][line_break_token]Response 6: We have enriched the explanation in Section 2.1 in the revised manuscript,[line_break_token]denoting that the shrinking of the distribution of the angle between the weight vector and the[line_break_token]activation vector is a reason for why the activation becomes almost constant in deep layers.	B-Reply	B-6	Reply	288
[line_break_token]Moreover, we have added analytical results in Section 2.3 that examine the relationship[line_break_token]between the constant activation in deeper layers and the vanishing gradient of weights.	I-Reply	I-6	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 7: The phenomenon is only tested on random initialization.	O	O	Reply	288
When the network is trained[line_break_token]for several iterations and becomes more settled, it is not clear how "angle affect" affects[line_break_token]gradient vanishing problem.	O	O	Reply	288
[line_break_token][line_break_token]Response 7: We have added Figures 8 and 9, which show the activation and the distribution of[line_break_token]angles in a MLP with sigmoid activation, respectively, after 10 epochs training.	B-Reply	B-7	Reply	288
[line_break_token]We have also added discussions on these figures to the third paragraph of Section 3.1.1 in[line_break_token]the revised manuscript.	I-Reply	I-7	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 8: Theorem 1,2,3 are direct conclusions from the definitions and are mis-stated as Theorems.	O	O	Reply	288
[line_break_token][line_break_token]Response 8: We have modified the manuscript to refer to these statements as propositions instead of theorems.	B-Reply	B-8	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 9: 'patters' -> 'patterns'[line_break_token][line_break_token]Response 9: In accordance with the comment, we have modified the expression.	B-Reply	B-9	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 10: In section 2.3, reasons 1 and 2 state the similar thing that output of MLP has relatively[line_break_token]small change with different input data when angle bias occurs.	O	O	Reply	288
Only reason 1 mentions the gradient[line_break_token]vanishing problem, even though the title of this section is "Relation to Vanishing Gradient Problem".	O	O	Reply	288
[line_break_token][line_break_token]Response 10: In accordance with the comment, we have deleted the second reason from the manuscript.	B-Reply	B-10	Reply	288
[line_break_token]Also, we have enriched the explanation related to reason 1, as mentioned in Response 6.	I-Reply	I-10	Reply	288

This paper discusses the problem of evaluating and diagnosing the representations learnt using a generative model.	O	O	Review	1446
This is a very important and necessary problem.	O	O	Review	1446
[line_break_token][line_break_token]However, this paper lacks in terms of experimental evaluation and has some technical flaws.	O	O	Review	1446
[line_break_token]1.	O	O	Review	1446
Morphological properties deals with only the "shape" properties of the image object.	B-Review	B-1	Review	1446
However, when the entire image is subject to the generative model, it learns multiple properties from the image apart from shape too - such as texture and color.	I-Review	I-1	Review	1446
Additionally, there are lot of low level pixel relations that the model learns to fit the distribution of the given images.	I-Review	I-1	Review	1446
However, here the authors have assumed that the latent space of the generative models are influenced only by the morphological properties of the image - which is wrong.	I-Review	I-1	Review	1446
Latent space features could be affected by the color or texture of the image as well.	I-Review	I-1	Review	1446
[line_break_token][line_break_token]2.	O	O	Review	1446
Extracting morphological properties of the image is straight-foward for MNIST kind of objects.	B-Review	B-2	Review	1446
However, it becomes really difficult for other datasets such as CIFAR or some real world images.	I-Review	I-2	Review	1446
Studying the properties of a generative model on such datasets is very challenging and the authors have not added a discussion around that.	I-Review	I-2	Review	1446
[line_break_token][line_break_token]3.	O	O	Review	1446
Now assuming that my GAN model has learnt good representation in Morpho-MNIST dataset, is it guaranteed to learn good representations in other datasets as well?	B-Review	B-3	Review	1446
There is no guarantee on generalizability or extensibility of the work.	I-Review	I-3	Review	1446
We thank the reviewer for acknowledging the importance of the problem we aimed to address, however, we very much disagree with the statements made regarding our assumptions.	O	O	Reply	1446
[line_break_token][line_break_token]Regarding the reviewer‚Äôs first point, we believe there is a misunderstanding.	B-Reply	B-1	Reply	1446
We absolutely agree that a generative model needs to learn about colour, texture, and low-level pixel relations to be able to extract its representations and to produce reasonable samples.	I-Reply	I-1	Reply	1446
Regarding the reviewer‚Äôs statement that ‚Äúthe authors have assumed that the latent space of the generative models are influenced only by the morphological properties of the image‚Äù, we would like to stress that we never made such assumptions nor have we claimed that the latent space of models trained on MNIST capture exclusively shape variations.	I-Reply	I-1	Reply	1446
What the Morpho-MNIST methodology aims to answer is: ‚Äúto what extent has my model learned to represent these specific factors of variation in the data?‚Äù If colour and texture are important factors for a given application or dataset, it suffices to design the relevant scalar metrics and include them in the very same framework.	I-Reply	I-1	Reply	1446
[line_break_token][line_break_token]This brings us to the second point.	B-Reply	B-2	Reply	1446
As far as we are aware, this is the first attempt in *any* context to quantitatively characterise inferential and generative behaviour of learned representations.	I-Reply	I-2	Reply	1446
We propose to do it in terms of measurable features: here we exploit shape attributes, and in the conclusion we point to various possible extensions involving colours or object properties.	I-Reply	I-2	Reply	1446
In our view, it just makes sense that the first step in that direction builds on a simple dataset with well understood and easily measurable factors of variation.	I-Reply	I-2	Reply	1446
[line_break_token][line_break_token]Finally, although it is correct that there are no generalisability guarantees, that is the case for any model evaluated on MNIST, CIFAR-10, or even ImageNet (cf.	B-Reply	B-3	Reply	1446
<a href="https://arxiv.org/abs/1806.00451," target="_blank" rel="nofollow">https://arxiv.org/abs/1806.00451,</a> for example).	O	O	Reply	1446
As argued above, we are proposing a toolset to inspect and diagnose trained generative models that works with any collection of measurable attributes.	B-Reply	B-3	Reply	1446
Evidently conclusions may not be transferable if the datasets have different relevant attributes	I-Reply	I-3	Reply	1446

The authors find 2 issues with Adversarial Imitation Learning-style algorithms: I) implicit bias in the reward functions and II) despite abilities of coping with little data, high interaction with the environment is required.	O	O	Review	317
The authors suggest "Discriminator-Actor-Critic" - an off-policy Reinforcement Learning reducing complexity up to 10 and being unbiased, hence very flexible.	O	O	Review	317
[line_break_token][line_break_token]Several standard tasks, a robotic, and a VR task are used to show-case the effectiveness by a working implementation in TensorFlow Eager.	O	O	Review	317
[line_break_token][line_break_token]The paper is well written, and there is practically no criticism.	O	O	Review	317
[line_break_token][line_break_token]	O	O	Review	317
We thank the reviewer for the feedback and appreciate the strong recommendation.	O	O	Reply	317

The motivation of the paper is to be able to train low precision networks to a high-accuracy.	O	O	Review	437
Quantization is a useful tool in model compression, and doing it well for very low-precision models (2-3 bit precision specifically), is challenging.	O	O	Review	437
[line_break_token][line_break_token]The main contribution of the paper comes from:[line_break_token]a) Step Size Gradient: They propose a gradient which is sensitive to the distance between the value and the transition point.	O	O	Review	437
This is different from other methods which have gradients dependent only on the clip point.	O	O	Review	437
[line_break_token]b) Step Size Gradient Scale: This is an interesting contribution, where they try to match the ratio of average update of the step size ‚Äòs‚Äô and average magnitude of ‚Äòs‚Äô, with that of the network weights.	O	O	Review	437
This leads them to scale the gradient according to the precision and number of parameters.	O	O	Review	437
They demonstrate that this scaling actually helps improve the accuracy.	O	O	Review	437
[line_break_token][line_break_token]The results for 8-bit precision are not new.	O	O	Review	437
Several results (Quantization and Training of Neural Networks for Efficient[line_break_token]Integer-Arithmetic-Only Inference, Jacob et al Quantizing deep convolutional networks for[line_break_token]efficient inference: A whitepaper, Krishnamoorthi et al), show 8-bit quantization results where the accuracy matches floating point accuracy, and in some case exceeds it (low precision quantization acting as a regularizer).	O	O	Review	437
However, the results for lower precision are impressive.	O	O	Review	437
[line_break_token][line_break_token]There are a few questions:[line_break_token]1.	O	O	Review	437
In sec 2.1, you mention that ‚Äòeach layer of weights and activations has a distinct step size, represented as an fp32 value, initialized to ‚Ä¶‚Äô.	B-Review	B-1	Review	437
Can you explain the intuition behind the initial value of the step size, and how is it a function of v?	I-Review	I-1	Review	437
[line_break_token]2. ‚	O	O	Review	437
ÄòModel Compression via Distillation and Quantization‚Äô (Polino et al) shows distillation actually helps significantly improve accuracy.	B-Review	B-2	Review	437
I wonder if the authors have tried different weight combinations for the distillation loss, and using bigger models as teacher models.	I-Review	I-2	Review	437
[line_break_token]3.	O	O	Review	437
I would like to get more details of the inference setup, specifically the size and inference latency improvements over full-precision networks.	B-Review	B-3	Review	437
The practical applicability of low-precision networks, specifically 2-bit and 3-bit networks, equally depends on the inference infrastructure, as it does on the training improvements.	I-Review	I-3	Review	437
[line_break_token]4.	O	O	Review	437
Have you evaluated your method for a non-Vision usecase?	B-Review	B-4	Review	437
[line_break_token][line_break_token]Overall this is a good work, I would tend towards accepting this.	O	O	Review	437
[line_break_token]	O	O	Review	437
Question 1:[line_break_token]We expect that a step size that provides a reasonable quantization of some data, "v", should scale with the magnitude of that data (captured by "&lt;|v|&gt;"), so that the values are reasonably spread across the bins of the quantizer.	O	O	Reply	437
 We also expect that as the number of quantized states increases, the step size itself should decrease, so that the data can be quantized more finely (captured by "1/sqrt(Q)").	B-Reply	B-1	Reply	437
 The particular heuristic we chose worked well in practice to give a reasonably good initial quantization that could then be further improved through training.	I-Reply	I-1	Reply	437
[line_break_token][line_break_token][line_break_token]Question 2:[line_break_token]Knowledge distillation for quantized networks is certainly an interesting area for research, but we didn't want to expand the focus of our manuscript too far beyond the quantizer training method proposed, particularly as Polino et al and Mishra and Marr already have provided a good overview of knowledge distillation in this domain.	B-Reply	B-2	Reply	437
 Thus, we chose to show only the simplest knowledge distillation setup we are are aware of, distilling from a full precision teacher to a low precision student network with the same architecture.	I-Reply	I-2	Reply	437
 This approach offers has the benefit that the same trained high precision network used for weight initialization also serves as our teacher, and thus no additional networks are required, whereas distilling from a larger architecture would require training (or otherwise having access to) an additional network.	I-Reply	I-2	Reply	437
 However, we have since run an experiment to look at different weights on the distillation loss, and now note in section 3.7: "we used the distillation loss function of Hinton with temperature of 1 and equal weight given to the standard loss and the distillation loss (we found this gave comparable results to weighting the the distillation loss two times more or less than the standard loss on 2-bit ResNet-18)."	I-Reply	I-2	Reply	437
[line_break_token][line_break_token][line_break_token]Question 3:[line_break_token]To show the reduction in model size offered by lower precision models, we have modified Figure 3 to include full precision model sizes.	B-Reply	B-3	Reply	437
[line_break_token][line_break_token]We did not measure latency or related performance metrics on actual hardware, as our approach was developed in advance of commercially available inference hardware optimized for low precision operations.	I-Reply	I-3	Reply	437
 Since algorithms are much cheaper to develop than new hardware, we believe it is the correct first step to demonstrate the ability of deep networks to achieve high accuracy at these extremely low precisions before hardware is created to optimize for these precisions.	I-Reply	I-3	Reply	437
 As new low precision inference chips become available, we look forward to benchmarking these low precision networks against full precision alternatives.	I-Reply	I-3	Reply	437
 [line_break_token][line_break_token][line_break_token]Question 4:[line_break_token]While we have not done so yet due to time constraints, we anticipate evaluating this approach for domains beyond vision as a next step in our research.	B-Reply	B-4	Reply	437

The motivation of the work is not clear but the novelty seems to be present.	B-Review	B-1	Review	1270
[line_break_token][line_break_token]The paper is very hard to follow as the problem description and intuition of the D-GAN is not clearly written.	B-Review	B-2	Review	1270
[line_break_token][line_break_token]Based on the experiments, the proposed method achieves marginal improvement in terms of F1 score but sometimes also slightly lower performance than other GAN based such as PGAN, so the impact of this work to solve positive unlabelled data problem is not evident.	B-Review	B-3	Review	1270
[line_break_token][line_break_token]I am personally not as familiar with the PU problem and existing frameworks so my confidence in the assessment is low; my main experience is in the computer vision for autonomous driving and sparse coding.	O	O	Review	1270
[line_break_token][line_break_token]But my feeling is this paper is marginally below the threshold of acceptance.	O	O	Review	1270
Thanks for your review,[line_break_token][line_break_token]Firstly we apologize for not making the text clear enough.	O	O	Reply	1270
[line_break_token]We hope the following answers to your respective points will clarify the proposed contributions.	O	O	Reply	1270
[line_break_token][line_break_token][line_break_token]***[line_break_token][line_break_token]‚ÄúThe motivation of the work is not clear‚Äù[line_break_token][line_break_token]Motivations can be expressed as follow.	O	O	Reply	1270
[line_break_token]1: Overcome the previous state of the art approaches disadvantages.	B-Reply	B-1	Reply	1270
[line_break_token]      -[tab_token]GenPU architecture is more computational demanding (three discriminators and two generators) than standard GAN architectures (one discriminator and one generator).	I-Reply	I-1	Reply	1270
Furthermore, GenPU requires prior knowledge and additional loss function hyper-parameters.	I-Reply	I-1	Reply	1270
[line_break_token]      -[tab_token]The PGAN method has overfitting issues on simple datasets (see figure 6. (	I-Reply	I-1	Reply	1270
b)) because its approach is based on GANs imperfections.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token]2: A framework easily adaptable to GANs variants.	I-Reply	I-1	Reply	1270
[line_break_token]      -[tab_token]A GAN PU framework similar to standard GAN could enable a better adaptability to last and potentially future GANs variants.	I-Reply	I-1	Reply	1270
It is an important point because the state of the art is updated continuously but the architectures remain similar (one generator and one discriminator).	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token]3: Adversarial training of GAN-based approaches enables to learn automatically relevant high level feature metrics.	I-Reply	I-1	Reply	1270
[line_break_token]      -[tab_token]GANs generate semantically realistic images.	I-Reply	I-1	Reply	1270
The most interesting aspect is probably that the error computed to evaluate the generated images quality is estimated from a high level feature point of view: the discriminator output.	I-Reply	I-1	Reply	1270
In this way, GANs enable relevant data augmentation.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token][line_break_token]***[line_break_token][line_break_token]‚Äúthe novelty seems to be present‚Äù[line_break_token][line_break_token]The two article contributions can be highlighted as follow.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token][line_break_token]Contribution 1: We propose to incorporate a PU risk inside the discriminator loss function.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token]We show that a GAN can solve by itself a Positive Unlabeled learning task if the problem is well formulated: We combine a PU risk with the GAN discriminator loss function.	I-Reply	I-1	Reply	1270
That enables the G convergence to the distribution of counter-examples included in the unlabeled dataset.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token]Previous GAN-based PU approaches do not include the PU risk in the discriminator cost function.	I-Reply	I-1	Reply	1270
GenPU and PGAN logics are as follow:[line_break_token]      -[tab_token]GenPU convergence is inspired by the original GAN convergence exposed by GoodFellow in 2014.	I-Reply	I-1	Reply	1270
The main idea is in this sentence: ‚ÄúDu is aimed at separating the unlabelled training samples from the fake samples of both Gp and Gn‚Äù.	I-Reply	I-1	Reply	1270
Thus the global system GenPU enables the convergence ‚Äúpi Pgp + (1-pi) Pgn -> Pu‚Äù, with Pgp the distribution of positive samples generated by Gp, Pgn the distribution of the negative samples generated by Gn, and Pu the distribution of unlabeled samples.	O	O	Reply	1270
However, the same reasoning can be expressed using one single generator Gn if we replace the generated positive samples by the positive labeled samples that we have in a PU dataset.	B-Reply	B-1	Reply	1270
Thus training five different models is not necessary to address standard PU learning challenge where we have enough positive samples.	I-Reply	I-1	Reply	1270
This reasoning is different to the propose one.	I-Reply	I-1	Reply	1270
[line_break_token]      -[tab_token]PGAN is trained to converge towards the unlabeled dataset distribution during the first step.	I-Reply	I-1	Reply	1270
The PGAN exploits GANs imperfections such that the generated distribution at the adversarial equilibrium is still separable from the unlabeled samples distribution by a classifier.	I-Reply	I-1	Reply	1270
The PGAN does not use a PU learning risk to train its GAN part.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token][line_break_token]Contribution 2: Highlight of a critical normalization issue discussed in the context of the proposed framework[line_break_token][line_break_token]Batch-normalization (BN) technique cannot be used when several minibatches distributions (unlabeled, positive, and generated ones) are used to train a learning model.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token]With BN, a classifier prediction for a given sample is critically influenced by the other samples of the same minibatch.	I-Reply	I-1	Reply	1270
As presented in the article, the consequence with a PU learning risk is that BN does not allow a classifier to distinguish positive from negative samples (see figure 5(a) and subsections 2.3 and 3.1).	I-Reply	I-1	Reply	1270
These sections include the analysis of this BN effect and alternative normalization solutions, such that this effect disappears.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token]In practice, a D-GAN using BN converges towards the unlabeled samples distribution.	I-Reply	I-1	Reply	1270
Without, it converges exclusively towards the negative samples distribution.	I-Reply	I-1	Reply	1270
The normalization training impact is clearly highlighted in the figure 5.	I-Reply	I-1	Reply	1270
[line_break_token]To the best of our knowledge, we are the first to highlight this critical phenomenon for the PU learning task.	I-Reply	I-1	Reply	1270
[line_break_token][line_break_token][line_break_token]***[line_break_token][line_break_token]‚Äú intuition of the D-GAN is not clearly written.	O	O	Reply	1270
‚Äù [line_break_token][line_break_token]The D-GAN intuition can be expressed as follow.	B-Reply	B-2	Reply	1270
The discriminator D addresses to the generator G the riddle: [line_break_token]‚ÄúShow me what IS unlabeled AND NOT positive.	I-Reply	I-2	Reply	1270
‚Äù[line_break_token]It turns out that negative samples included in the unlabeled dataset are both unlabeled and not positive.	I-Reply	I-2	Reply	1270
Consequently G addresses this riddle by learning to show the negative samples distribution to D.	I-Reply	I-2	Reply	1270

Motivated by a link between LSTMs and counter machines (suggested by recent work, e.g. Merrill, 2019 et al), this paper studies the formal properties of counter machines (and LSTMs by extension) as grammars, in hopes of discovering why LSTMs perform particularly well in language tasks despite having no obvious hierarchical structure.	O	O	Review	20497
[line_break_token][line_break_token]It makes the following contributions.	O	O	Review	20497
It shows that: (1) many variants of counter machine converge to the same formal language, (2) the counter languages are closed under common set operations (e.g. intersection, union, and complement), (3) counter machines are incapable of evaluating boolean expressions, and (4) only a weak subclass of CLs are sublinear (and most are not).	O	O	Review	20497
[line_break_token][line_break_token]While this paper gives thorough proofs, I would have liked to see more connection to practical NLP with some experiments.	B-Review	B-1	Review	20497
Also, I would have liked to see more concrete takeaways from this paper: if correctly detecting surface patterns doesn't mean that LSTMs build correct semantic representations, what can ensure that LSTMS do have a correct semantic representation?	B-Review	B-2	Review	20497
[line_break_token][line_break_token]As this paper is far from my area of expertise, I'm willing to change my score based on my co-reviewers.	O	O	Review	20497
hank you for your review.	O	O	Reply	20497
We agree that experiments would make the connection to modern NLP more concrete.	B-Reply	B-1	Reply	20497
As an initial direction, we have conducted an experiment comparing the ability of LSTMs to 1) evaluate boolean expressions and 2) verify their well-formedness.	I-Reply	I-1	Reply	20497
If accepted, we will include this in a revised version.	I-Reply	I-1	Reply	20497
[line_break_token][line_break_token]Another experimental followup we have begun is evaluating pre-trained language models by assessing their ability to perform semantic evaluation of natural language.	B-Reply	B-3	Reply	20497
However, we believe this larger effort is beyond the scope of this paper.	I-Reply	I-3	Reply	20497
We think the community could benefit from our paper because it provides context for such future work, either by ourselves or others	I-Reply	I-3	Reply	20497

This paper proposes an approach to building random forests that are[line_break_token]balanced in such a way as to facilitate domain adaptation.	O	O	Review	252
The authors[line_break_token]propose to split nodes not only based on the Information Gain, but[line_break_token]also so that the sizes of each set passed to left and right children[line_break_token]are equal.	O	O	Review	252
Another extension to the standard random forest training[line_break_token]procedure is the use of a collaborative term subtracted from the[line_break_token]information gain over the source domain.	O	O	Review	252
This term encourages[line_break_token]alignment of the source and target domains in the leaves of trees in[line_break_token]the forest.	O	O	Review	252
Experimental results are given on a range of standard[line_break_token]and open-set domain adaptation datasets.	O	O	Review	252
[line_break_token][line_break_token]The paper has a number of issues:[line_break_token][line_break_token]1.	O	O	Review	252
There are some problems with clarity, and the English is somewhat rough[line_break_token]   throughout.	B-Review	B-1	Review	252
These problems are not terribly distracting, but the[line_break_token]   manuscript could use more polish.	I-Review	I-1	Review	252
[line_break_token]2.	O	O	Review	252
I don't see a detailed discussion anywhere about the[line_break_token]   hyperparameters used for fitting the random forests.	B-Review	B-2	Review	252
How many trees[line_break_token]   are used?	I-Review	I-2	Review	252
What is the max depth?	I-Review	I-2	Review	252
These parameters should be[line_break_token]   discussed and included in the ablations in order to appreciate the[line_break_token]   complexity/performance tradeoffs.	I-Review	I-2	Review	252
[line_break_token][line_break_token]This paper has some interesting ideas in it, and the experimental[line_break_token]results are excellent.	O	O	Review	252
I would encourage the authors to move salient[line_break_token]material from the supplementary material to the main article and to[line_break_token]provide a more thorough discussion of the complexity of the models[line_break_token](the structural parameters of the trees/forests).	B-Review	B-2	Review	252
hank you for helpful comments on our paper.	O	O	Reply	252
[line_break_token][line_break_token]1.	O	O	Reply	252
We will revise the paper to improve readability.	B-Reply	B-1	Reply	252
We will do our best to refine the rough expressions of the paper.	I-Reply	I-1	Reply	252
We are working on improving the paper, and we will make it better for the final version.	I-Reply	I-1	Reply	252
It would be greatly appreciated if more detailed comments could be provided.	I-Reply	I-1	Reply	252
[line_break_token][line_break_token]2.	B-Reply	B-2	Reply	252
We added hyperparameter settings such as the number of trees, maximum depth, feature dimensionality of the SVM training, and the number of repeats in training a random forest to page 6.	I-Reply	I-2	Reply	252
We also supplemented the ablation study with regard to the number of trees and maximum depths in Table 3.	I-Reply	I-2	Reply	252
In the ablation study, the maximum depth is 8 with 100 decision trees to consider both accuracy and complexity.	I-Reply	I-2	Reply	252
[line_break_token][line_break_token]‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî--Revised paper ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-[line_break_token]To train the CoBRF, we use 100 trees with a maximum depth of 8.	I-Reply	I-2	Reply	252
[line_break_token]When there is no training data fallen on a node, we prune the tree at that node.	I-Reply	I-2	Reply	252
[line_break_token]The number of randomly selected feature dimension for the SVM training is set to 250.	I-Reply	I-2	Reply	252
[line_break_token]The input feature of SVM is normalized for the stable learning of the hyperplane.	I-Reply	I-2	Reply	252
[line_break_token]We repeat the SVM training 15 times to select the optimal split in each node.	I-Reply	I-2	Reply	252
[line_break_token][line_break_token]   Depth | The number of trees (T)[line_break_token]               |  5 | 10 | 50 | 100 |  [line_break_token]      6   | 62.2 | 65.4 | 67.5 | 67.7 |[line_break_token]      7   | 60.2 | 63.5 | 67.1 | 67.8 |[line_break_token]      8   | 58.9 | 63.3 | 67.5 | 68.0 |[line_break_token]      9   | 55.6 | 60.0 | 66.2 | 67.6 |[line_break_token]‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-‚Äî-‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-[line_break_token][line_break_token]Please refer to page 6, 7, and Table 3 for more information on the hyperparameters and ablation study.	I-Reply	I-2	Reply	252

The work proposes to use the geometry of data (that is considered to be known a priori) in order to have more consistent sparse coding.	O	O	Review	327
Namely, two data samples that are similar or neighbours, should have a sparse code that is similar (in terms of support).	O	O	Review	327
The general idea is not unique, but it is an interesting one (if one admits that the adjacency matrix A is known a priori), and the novelty mostly lies on the definition of the regularisation term that is an l1-norm (while other techniques would mostly use l2 regularisation).	O	O	Review	327
[line_break_token][line_break_token]Based on this idea, the authors develop a new SRSC algorithm, which is analysed in detail and shown to perform better than its competitors based on l2 sparse coding regularisation and other schemes in terms of clustering performance.	O	O	Review	327
[line_break_token][line_break_token]Inspired by LISTA, the authors then propose an approximate solution to the SRSC problem, called Deep-SRSC, that acts as a sort of fast encoder.	O	O	Review	327
Here too, the idea is interesting and seems to be quite efficient from experiments on USPS data, even if the framework seems to be strongly inspired from LISTA.	O	O	Review	327
That scheme should however be better motivated, by the limitations of SRSC that should be presented more clearly.	B-Review	B-1	Review	327
[line_break_token][line_break_token]Overall, the paper is well written, and pretty complete.	O	O	Review	327
It is not extremely original in its main ideas though, but the actual algorithm and implementation seem new and effective.	O	O	Review	327
Thank you for your comment!	O	O	Reply	327
[line_break_token][line_break_token]We have included a more clear motivation of Deep-SRSC in the beginning of Section 4 in the revised paper, namely ‚ÄúThe goal of Deep-SRSC is to approximate the sparse codes of the input data in a fast way by feeding the data through the Deep-SRSC network, instead of running the iterative optimization algorithm for SRSC in Section 2.1. ‚	B-Reply	B-1	Reply	327
Äù[line_break_token][line_break_token]In fact, SRSC is efficient from the perspective of the conventional optimization algorithms for the sparse coding methods.	I-Reply	I-1	Reply	327
Please refer to the complexity analysis of SRSC in the subsection ‚ÄúTime Complexity‚Äù in Section 2.1 of the revised paper.	I-Reply	I-1	Reply	327
Deep-SRSC is proposed as a fast approximation of SRSC with considerable (around 8.3 times) speedup for obtaining the approximate support regularized sparse codes of the new data or the test data (more details in Section 4.1 of the revised paper: Deep-SRSC As Fast Encoder).	I-Reply	I-1	Reply	327
[line_break_token][line_break_token]Moreover, we have presented the additional experiments in the revised paper on the MNIST and CIFAR-10 data for the clustering and semi-supervised learning tasks, which further demonstrate the effectiveness of SRSC and Deep-SRSC.	I-Reply	I-1	Reply	327

This paper proposes a new method of detecting in vs. out of distribution samples.	O	O	Review	403
Most existing approaches for this deal with detecting out of distributions at *test time* by augmenting input data and or temperature scaling the softmax and applying a simple classification rule based on the output.	O	O	Review	403
This paper proposes a different approach (with could be combined with these methods) based on a new training procedure.	O	O	Review	403
[line_break_token][line_break_token]The authors propose to train a generator network in combination with the classifier and an adversarial discriminator.	O	O	Review	403
The generator is trained to produce images that (1) fools a standard GAN discriminator and (2) has high entropy (as enforced with the pull-away term from the EBGAN).	O	O	Review	403
Classifier is trained to not only maximize classification accuracy on the real training data but also to output a uniform distribution for the generated samples.	O	O	Review	403
[line_break_token][line_break_token]The model is evaluated on CIFAR-10 and SVNH, where several out of distribution datasets are used in each case.	O	O	Review	403
Performance gains are clear with respect to the baseline methods.	O	O	Review	403
[line_break_token][line_break_token]This paper is clearly written, proposes a simple model and seems to outperform current methods.	O	O	Review	403
One thing missing is a discussion of how this approach is related to semi-supervised learning approaches using GANS where a generative model produces extra data points for the classifier/discriminator.	B-Review	B-4	Review	403
[line_break_token][line_break_token] I have some clarifying questions below:[line_break_token]- Figure 4 is unclear: does "Confidence loss with original GAN" refer to the method where the classifier is pretrained and then "Joint confidence loss" is with joint training?	B-Review	B-1	Review	403
What does "Confidence loss (KL on SVHN/CIFAR-10)" refer to?	I-Review	I-1	Review	403
[line_break_token][line_break_token]- Why does the join training improve the ability of the model to generalize to out-of-distribution datasets not seen during training?	B-Review	B-2	Review	403
[line_break_token][line_break_token]- Why is the pull away term necessary and how does the model perform without it?	B-Review	B-3	Review	403
Most GAN models are able to stably train without such explicit terms such as the pull away or batch discrimination.	I-Review	I-3	Review	403
Is the proposed model unstable without the pull-away term?	I-Review	I-3	Review	403
[line_break_token][line_break_token]- How does this compare with a method whereby instead of pushing the fake sample's softmax distribution to be uniform, the model is simply a trained to classify them as an additional "out of distribution" class?	B-Review	B-4	Review	403
This exact approach has been used to do semi supervised learning with GANS [1][2]. More generally, could the authors comment on how this approach is related to these semi-supervised approaches?	I-Review	I-4	Review	403
[line_break_token][line_break_token]- Did you try combining the classifier and discriminator into one model as in [1][2]?	B-Review	B-5	Review	403
[line_break_token][line_break_token][1] Semi-Supervised Learning with Generative Adversarial Networks (<a href="https://arxiv.org/abs/1606.01583)" target="_blank" rel="nofollow">https://arxiv.org/abs/1606.01583)</a>[line_break_token][2] Good Semi-supervised Learning that Requires a Bad GAN (<a href="https://arxiv.org/abs/1705.09783)" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.09783)</a>	O	O	Review	403
We very much appreciate your valuable comments, efforts and times on our paper.	O	O	Reply	403
We provide our responses for all questions below.	O	O	Reply	403
Revised parts in the new draft are colored by blue.	O	O	Reply	403
[line_break_token][line_break_token]Q1: "Figure 4 is unclear."	O	O	Reply	403
[line_break_token][line_break_token]A1: First, "Confidence loss with original GAN" corresponds to a variant of confidence loss (1) which trains a classifier by optimizing the KL divergence term using samples from a pre-trained original/standard GAN, i.e., GAN generates in-distribution samples.	B-Reply	B-1	Reply	403
Next, "Joint confidence loss" is the proposed loss (4) optimized by Algorithm 1.	I-Reply	I-1	Reply	403
Here, we remark that only "Joint confidence loss" optimizes the KL divergence terms using implicit samples from the proposed GAN, i.e., GAN generates "boundary" samples in the low-density area of in-distribution.	I-Reply	I-1	Reply	403
Finally, "Confidence loss (KL on SVHN/CIFAR-10)" corresponds to the confidence loss (1) using explicit out-of-distribution samples (SVHN or CIFAR-10).	I-Reply	I-1	Reply	403
For example, "Confidence loss (KL on SVHN)" refers to the method where the KL divergence term in the confidence loss (1) is optimized using SVHN training data.	I-Reply	I-1	Reply	403
In the revision, we clarified the notations such that the KL divergence term is optimized on samples indicated in the parentheses, i.e., "Confidence loss with original GAN" and "Confidence loss (KL on SVHN/CIFAR-10)" were revised to "Confidence loss (samples from original GAN)" and "Confidence loss (SVHN/CIFAR-10)", respectively.	I-Reply	I-1	Reply	403
We updated Figure 2 and Figure 4 accordingly.	I-Reply	I-1	Reply	403
[line_break_token][line_break_token]Q2: "Why does the joint training improve the ability of the model to generalize to out-of-distribution datasets not seen during training?"	O	O	Reply	403
[line_break_token][line_break_token]A2: It is explained in Section 2.3.	B-Reply	B-2	Reply	403
In Section 2.1, we suggest to use out-of-distribution samples for training a confident classifier.	I-Reply	I-2	Reply	403
Conversely, in Section 2.2.,	I-Reply	I-2	Reply	403
we suggest to use a confident classifier for training a GAN generating out-of-distribution samples.	I-Reply	I-2	Reply	403
Namely, two models can be used for improving each other.	I-Reply	I-2	Reply	403
Hence, this naturally suggests a joint training scheme in Section 2.3 for confident classifier and the proposed GAN, where both improve as the training proceeds.	I-Reply	I-2	Reply	403
We emphasize the effect of joint training again in the revision.	I-Reply	I-2	Reply	403
Please see our revision of Section 2.3 for details.	I-Reply	I-2	Reply	403
[line_break_token][line_break_token]Q3: "Why is the pull away term necessary and how does the model perform without it?"	O	O	Reply	403
[line_break_token][line_break_token]A3: We really appreciate your valuable comments.	O	O	Reply	403
[line_break_token][line_break_token]The pull away term (PT) is not related to "stability."	B-Reply	B-3	Reply	403
Our intuition was that the entropy of out-of-distribution is expected to be much higher compared to that of in-distribution since the out-of-distribution is typically on a much larger space than the in-distribution.	I-Reply	I-3	Reply	403
Consequently, we expected that optimizing the PT term is useful for generating better out-of-distribution samples.	I-Reply	I-3	Reply	403
[line_break_token]We also note that the PT was recently used [2] for a similar purpose as ours.	I-Reply	I-3	Reply	403
[line_break_token][line_break_token]However, since we suggest to generate out-of-distribution samples nearby in-distribution (for efficient sampling purpose), its entropy might be not that high and the effect of PT is not clear.	I-Reply	I-3	Reply	403
After our submission, we actually verified that PT sometimes helps (but not always), and its gains are relatively marginal in overall.	I-Reply	I-3	Reply	403
Since PT increases the training complexity, we decided to remove the PT in the revision and have updated all experimental results without using PT.	I-Reply	I-3	Reply	403
Still, for interested readers, we also report the effects of PT in the Appendix D. We updated Section 2.2 and 2.3, Figure 3, 4 and 5, and Appendix D, accordingly.	I-Reply	I-3	Reply	403
[line_break_token][line_break_token]Q4: "How is this approach related to the semi-supervised approaches in [1][2]?	O	O	Reply	403
Did you try combining the classifier and discriminator into one model as in [1][2]?"	O	O	Reply	403
[line_break_token][line_break_token]A4: As briefly mentioned in Section 4, we expect that our proposed GAN might be useful for semi-supervised settings.	B-Reply	B-4	Reply	403
Also, we actually thought about combining the classifier and discriminator into one model, i.e., adding K+1 class.	I-Reply	I-4	Reply	403
However, we choose a more "conservative" way to design network architectures so that the original classification performance does not degrade.	I-Reply	I-4	Reply	403
Extension to semi-supervised learning should be an interesting future direction to explore.	I-Reply	I-4	Reply	403
[line_break_token][line_break_token][1] Odena, A. Semi-supervised learning with generative adversarial networks.	O	O	Reply	403
In NIPS, 2016. (	O	O	Reply	403
<a href="https://arxiv.org/abs/1606.01583)" target="_blank" rel="nofollow">https://arxiv.org/abs/1606.01583)</a>[line_break_token][2] Dai, Z., Yang, Z., Yang, F., Cohen, W.W. and Salakhutdinov, R. Good Semi-supervised Learning that Requires a Bad GAN.	O	O	Reply	403
In NIPS, 2017. (	O	O	Reply	403
<a href="https://arxiv.org/abs/1705.09783)" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.09783)</a> [line_break_token][line_break_token]Thanks,[line_break_token]Author	O	O	Reply	403

This paper focuses on the problem of developing deep learning systems that can prove theorems in a mathematical formalism -- in this case, MetaMath.	O	O	Review	11
This has been a rapidly growing topic in the past few years, as evidenced by the numerous cited works.	O	O	Review	11
What sets this work apart from others is its focus on the instrumental task of generating data to train a prover, rather than directly training the prover on human theorems (via reinforcement learning) or human proofs (via imitation learning).	O	O	Review	11
[line_break_token][line_break_token]The paper proposer two approaches to generating theorems imitation learning (IL) and reinforcement learning (RL).	O	O	Review	11
The IL approach trains a neural policy to imitate the same steps taken in human proofs.	O	O	Review	11
The RL approach first trains a language model on human theorems (not proofs), and uses the likelihood under the model as a reward function for an RL agent which must take forward proof steps.	O	O	Review	11
[line_break_token][line_break_token]Both approaches result in a policy that can be used to take proof steps, with the goal of producing new theorems which are similar to the human ones.	O	O	Review	11
Since the proof steps are known for the generated theorems, a prover agent (which operates in backwards mode, working from the goal back to the hypotheses) can be trained to imitate the steps taken in the synthetic proofs (along with the human ones, if any are present).	O	O	Review	11
[line_break_token][line_break_token]At test time, the learned prover imitation policy is then used to guide an MCTS agent, as described in the Holophrasm paper.	O	O	Review	11
It is compared against the original Holophrasm algorithm, rerun on modern hardware.	O	O	Review	11
[line_break_token][line_break_token]This is to my knowledge a novel approach in the neural theorem proving domain, and in my opinion one that offers a potentially significant advantage over the existing fixed-dataset appraoches.	O	O	Review	11
[line_break_token][line_break_token]The main result of the paper is that an extra 35/2720 (1.2%) of the test theorems are proven, a 6% improvement over the Holophrasm baseline of 539.	B-Review	B-1	Review	11
It is difficult to judge how relevant of an improvement this is, and there is no analysis of the difficulty of the MetaMath problem set.	I-Review	I-1	Review	11
In addition, due to the 10-1-1 train-validation-test split, the neural agents are likely shown relatively similar problems during training as at test time, including potentially stronger versions of the same theorems.	B-Review	B-2	Review	11
There is also no comparison against non-neural approaches, such as Z3, Vampire, or similar theorem provers.	I-Review	I-2	Review	11
[line_break_token][line_break_token]To accept this paper, I would like to see stronger evidence that the introduced method produces significant improvements in prover ability.	B-Review	B-3	Review	11
For example, the same method could be applied to datasets such as HOList, Mizar, and CoqGym which have received more attention recently than MetaMath.	I-Review	I-3	Review	11
[line_break_token][line_break_token]Some additional questions and comments:[line_break_token]1.	O	O	Review	11
How big does the theorem graph G get?	B-Review	B-4	Review	11
Since the relevance policy is over all nodes of the graph, this could lead to a very large neural network that would be difficult to fit into memory.	I-Review	I-4	Review	11
Certainly not all 1M synthetic theorems could be generated in one graph.	I-Review	I-4	Review	11
[line_break_token]2.	O	O	Review	11
The paper claims that all theorems from set.mm are used as background theorems in algorithm 1, including the test ones -- this potentially sounds like training on the test set, or even worse, having access to the test theorems as "proven background knowledge" at test time.	B-Review	B-5	Review	11
[line_break_token]3.	O	O	Review	11
Please include some more details about the training of the Holophrasm baseline.	B-Review	B-1	Review	11
Does it simply do RL on the human theorems, or does it also do IL on human proofs?	I-Review	I-1	Review	11
hank you for your comments and your time for reviewing our submission.	O	O	Reply	11
We address your individual points below in a QA format.	O	O	Reply	11
[line_break_token][line_break_token]Q1: The main result of the paper is that an extra 35/2720 (1.2%) of the test theorems are proven, a 6% improvement over the Holophrasm baseline of 539.	O	O	Reply	11
It is difficult to judge how relevant of an improvement this is, and there is no analysis of the difficulty of the MetaMath problem set.	O	O	Reply	11
[line_break_token][line_break_token]A: In our experiments, the improvement from MetaGen over the Holophrasm baseline is significant because it is virtually impossible to prove a new theorem by random guessing.	B-Reply	B-1	Reply	11
The average proof length is 55 in set.mm, and the prover can find a proof only after taking a long sequence of correct proof steps.	I-Reply	I-1	Reply	11
In addition, a proof step can require composing a new expression, further increasing the search space.	I-Reply	I-1	Reply	11
This means that the probability of proving a new theorem through random guessing is close to zero, and proving a few dozens more theorems is a significant improvement.	I-Reply	I-1	Reply	11
As shown in Table 3, we achieve consistent improvement from MetaGen in different training settings.	I-Reply	I-1	Reply	11
When trained on all human proofs, our method with MetaGen-IL could find 21 extra proofs with five proof steps or more.	I-Reply	I-1	Reply	11
[line_break_token][line_break_token]Q2: The same method could be applied to datasets such as HOList, Mizar, and CoqGym which have received more attention recently than Metamath.	O	O	Reply	11
[line_break_token][line_break_token]A: Set.mm in Metamath is a good benchmark for automated theorem proving.	B-Reply	B-3	Reply	11
Mathmath only relies on substitution, the most general and fundamental inference rule of deductive reasoning, and therefore can serve as a meta-language to implement different logics, like first-order logic, higher-order logic, and set theory, while other systems are usually built on a particular logical foundation.	I-Reply	I-3	Reply	11
Such simplicity and generality offer a unique advantage for developing ML provers, because we can generate all potential theorems by handling substitution only.	I-Reply	I-3	Reply	11
[line_break_token][line_break_token]Set.mm is the largest corpus of math theorems in Metamath.	I-Reply	I-3	Reply	11
It contains 29,337 theorems and almost 1.5M proof steps.	I-Reply	I-3	Reply	11
It implements the Tarski-Grothendieck set theory and covers various math topics, including but not limited to first-order logic, real and complex analysis, linear algebra, graph theory, elementary geometry and topology.	I-Reply	I-3	Reply	11
It formalizes 71 of the ‚Äútop 100‚Äù math theorems, only behind HOL Light and Isabelle/HOL among all formal math databases [1] , and its coverage is still actively growing.	I-Reply	I-3	Reply	11
This makes set.mm a good benchmark to train and evaluate learning-based theorem provers.	I-Reply	I-3	Reply	11
[line_break_token][line_break_token]The idea of theorem generation can be applied to other systems beyond Metamath, but realizing it on another system is highly nontrivial.	I-Reply	I-3	Reply	11
It can even involve new research challenges.	I-Reply	I-3	Reply	11
In particular, due to large differences in logic foundations, grammar, inference rules, and benchmarking environments, the generation process, which is a key component of our approach, would be almost completely different for a new system.	I-Reply	I-3	Reply	11
And the entire pipeline essentially needs to be re-designed and re-coded from scratch for a new formal system, which can require an unreasonable amount of engineering.	I-Reply	I-3	Reply	11
Because of this, it is a standard practice in prior work to target a specific formal system and experiment only in this system [2,3,4,5,6,7,8]. [line_break_token][line_break_token]In addition, existing benchmarking environments for other systems have limitations that make it infeasible to implement our method.	I-Reply	I-3	Reply	11
HOList [2] and CoqGym [3] are built on tactic-based theorem provers.	I-Reply	I-3	Reply	11
Their environments only provide interfaces to call tactics implemented in backend provers.	I-Reply	I-3	Reply	11
Most tactics execute backward reasoning.	I-Reply	I-3	Reply	11
To generate new theorems, we need to be able to execute the corresponding reverse tactics, but this functionality is not provided in the current version of HOList and CoqGym.	I-Reply	I-3	Reply	11
[tab_token][line_break_token][line_break_token]Our approach cannot be directly applied to Mizar, because it does not provide human proofs in a format that can be understood by an automatic prover like the E prover (see [5]).	I-Reply	I-3	Reply	11
Prior works have used machine learning to improve the E prover [4,5,6] on Mizar, but they have only trained on proofs automatically found by the E prover, not those written by humans.	I-Reply	I-3	Reply	11
E expresses theorems as CNFs and proves by refutation at the level of CNF clauses.	I-Reply	I-3	Reply	11
The CNF representation of theorems and proofs are incomprehensible to humans.	I-Reply	I-3	Reply	11
Thus it is an open research question how to do forward reasoning to generate synthetic theorems in the CNF form that are similar to human theorems.	I-Reply	I-3	Reply	11
[line_break_token][line_break_token][line_break_token][line_break_token]	O	O	Reply	11

I have read the authors' response.	O	O	Review	20578
Their points regarding baseline comparisons are sensible in that there isn't a reason to expect the observations to *not* generalization to other datasets.	O	O	Review	20578
It is odd that mLSTM is outperformed by LSTM in Table 3, but as the authors note in section 4.2 this may be due to instability of mLSTM during training.	O	O	Review	20578
The results in the paper demonstrate significant improvement over LSTM, and while there are not as many baseline comparison to similar models as I would have liked to see, the quality of this work is sufficiently high that this is not a fatal flaw.	O	O	Review	20578
In light of the author response and other reviews, I am revising my rating to 6: Weak Accept.	O	O	Review	20578
[line_break_token][line_break_token]=====[line_break_token][line_break_token]This paper proposes a modification of LSTM networks in the context of language modeling called Mogrifier LSTM.	O	O	Review	20578
Ordinary LSTMs are defined as recurrent operations on the current input, previous hidden state, and previous cell state.	O	O	Review	20578
The proposed Mogrifier LSTM utilizes the same recurrent unit as the LSTM, but the input and previous hidden state are updated with several rounds of mutual gating.	O	O	Review	20578
In each round, the input  is multiplied elementwise by a gate computed as a function of the hidden state (or vice versa).	O	O	Review	20578
The authors experiment on word-level and character-level modeling and compare their Mogrifier LSTMs to several state-of-the-art approaches.	O	O	Review	20578
They also conduct an ablation study to show the effect of various design choices and hyperparameters and experiments on a reverse copy task.	O	O	Review	20578
[line_break_token][line_break_token]Specific contributions include:[line_break_token]* Proposal of a novel approach for modulating inputs to a recurrent unit by mutual gating.	O	O	Review	20578
[line_break_token]* Experiments demonstrating strong performance on a number of language modeling tasks.	O	O	Review	20578
[line_break_token]  [line_break_token]The paper in its current state is borderline, leaning towards weak reject.	O	O	Review	20578
Points in favor of acceptance include the high clarity of writing, good experiments of the proposed model, and a discussion of possible reasons for why the mogrification operation works well.	O	O	Review	20578
The main shortcoming of the paper is experimental comparison to baselines.	O	O	Review	20578
[line_break_token][line_break_token]The authors were able to train baseline LSTMs to high levels of performance (presumably due to tuning of hyperparameters) and then demonstrate that Mogrifier LSTMs improve upon LSTMs significantly.	B-Review	B-1	Review	20578
This is perhaps not entirely surprising, because the hyperparameter range of the Mogrifier LSTM includes zero rounds of updates, which would render it identical to the baseline LSTM.	I-Review	I-1	Review	20578
Therefore, if the hyperparameters are tuned sufficiently well, the performance of the Mogrifier LSTM should be at least as good as the LSTM.	I-Review	I-1	Review	20578
What the experiments do not show is that the proposed mogrification outperforms other forms of multiplicative interaction and/or gating.	B-Review	B-2	Review	20578
The closest that the authors come to this is the single validation perplexity of the Multiplicative LSTM in Table 3.	I-Review	I-2	Review	20578
If thorough hyperparameter tuning is applied to the Multiplicative LSTM or the approaches of Wu et al (2016) and/or Sutskever et al (2011), does the Mogrifier LSTM still outperform them?	I-Review	I-2	Review	20578
[line_break_token][line_break_token]Other than this critical issue of baseline comparison, the experiments are quite informative.	O	O	Review	20578
The ablation study showing the effect of different design decisions and the hyperparameter visualiztion in Appendix B are particularly useful.	O	O	Review	20578
The mogrification operation is described precisely enough for other researchers to implement and the arguments made in 4.4 are compelling.	O	O	Review	20578
[line_break_token][line_break_token]Question for the authors:[line_break_token]* Some qualitative analysis of the learned mogrification operation would be helpful for understanding the nature of the modulation.	B-Review	B-3	Review	20578
For example, how do the predictions change depending on the modulation?	I-Review	I-3	Review	20578
If x is modulated by different hidden states, is there a noticeable effect on the output?	I-Review	I-3	Review	20578
[line_break_token]* Did you experiment with other forms of modulation before arriving upon the mogrification formulation?	B-Review	B-4	Review	20578
There are some naive approaches such as concatenating the hidden state to the input and applying a nonlinear layer, or predicting affine parameters for the input as a function of the hidden state in the style of FiLM [1]. Are there obvious shortcomings in these naive approaches that mogrification handles gracefully?	I-Review	I-4	Review	20578
[line_break_token][line_break_token][1] Perez, E., Strub, F., De Vries, H., Dumoulin, V. and Courville, A., 2018, April.	O	O	Review	20578
Film: Visual reasoning with a general conditioning layer.	O	O	Review	20578
In Thirty-Second AAAI Conference on Artificial Intelligence.	O	O	Review	20578
e thank Reviewer #1 for the critical but thoughtful review.	O	O	Reply	20578
We try to[line_break_token]address the issues brought up below.	O	O	Reply	20578
[line_break_token][line_break_token]&gt; The authors were able to train baseline LSTMs to high levels of[line_break_token]&gt; performance (presumably due to tuning of hyperparameters) and then[line_break_token]&gt; demonstrate that Mogrifier LSTMs improve upon LSTMs significantly.	O	O	Reply	20578
[line_break_token]&gt; This is perhaps not entirely surprising, because the hyperparameter[line_break_token]&gt; range of the Mogrifier LSTM includes zero rounds of updates, which[line_break_token]&gt; would render it identical to the baseline LSTM.	O	O	Reply	20578
Therefore, if the[line_break_token]&gt; hyperparameters are tuned sufficiently well, the performance of the[line_break_token]&gt; Mogrifier LSTM should be at least as good as the LSTM[line_break_token][line_break_token]It is indeed unsurprising that the Mogrifier is not worse than the[line_break_token]LSTM since it includes the LSTM as a special case.	B-Reply	B-1	Reply	20578
But in Figure 3[line_break_token]where perplexity is plotted as the function of rounds, the setting[line_break_token]that corresponds to the LSTM (rounds=0) is clearly the worst and the[line_break_token]gap is very significant.	I-Reply	I-1	Reply	20578
[line_break_token][line_break_token]&gt; What the experiments do not show is that the proposed mogrification[line_break_token]&gt; outperforms other forms of multiplicative interaction and/or gating.	O	O	Reply	20578
[line_break_token]&gt; The closest that the authors come to this is the single validation[line_break_token]&gt; perplexity of the Multiplicative LSTM in Table 3.	O	O	Reply	20578
If thorough[line_break_token]&gt; hyperparameter tuning is applied to the Multiplicative LSTM or the[line_break_token]&gt; approaches of Wu et al (2016) and/or Sutskever et al (2011), does[line_break_token]&gt; the Mogrifier LSTM still outperform them?	O	O	Reply	20578
[line_break_token][line_break_token]We agree that having these baselines would strengthen the contribution[line_break_token]and help position our work more precisely in their context.	B-Reply	B-2	Reply	20578
Due to[line_break_token]time and resource constraints, we focussed on the most similar model,[line_break_token]the mLSTM, and evaluated it on PTB (which has been predictive of[line_break_token]performance on other tasks in our experience) using the same[line_break_token]hyperparameter tuning methodology as everywhere else in the paper, the[line_break_token]only exceptions being a shortened schedule and small BPTT window size.	I-Reply	I-2	Reply	20578
[line_break_token]These concessions to practicality make results slightly worse (2-3[line_break_token]perplexity points), but there is little reason to believe they benefit[line_break_token]one model or the other.	I-Reply	I-2	Reply	20578
And if the mLSTM were more similar to the[line_break_token]mogrifier than we'd like, we should see that in these experiments.	I-Reply	I-2	Reply	20578
As[line_break_token]it is, what we found is that the mLSTM does not improve on the[line_break_token]baseline LSTM while the Mogrifier does.	I-Reply	I-2	Reply	20578
[line_break_token][line_break_token]&gt; * Some qualitative analysis of the learned mogrification operation[line_break_token]&gt;   would be helpful for understanding the nature of the modulation.	O	O	Reply	20578
For[line_break_token]&gt;   example, how do the predictions change depending on the modulation?	O	O	Reply	20578
If[line_break_token]&gt;   x is modulated by different hidden states, is there a noticeable[line_break_token]&gt;   effect on the output?	O	O	Reply	20578
[line_break_token][line_break_token]Obviously, in terms of perplexity there is a noticable effect.	B-Reply	B-3	Reply	20578
In[line_break_token]terms of statistics of the modulated vs unmoodulated input vectors, we[line_break_token]do not have the data.	I-Reply	I-3	Reply	20578
The closest we have in the paper is that "the[line_break_token]means of the standard LSTM gates in the Mogrifier were very close[line_break_token]between the two models but their variance was smaller in the[line_break_token]Mogrifier".	I-Reply	I-3	Reply	20578
[line_break_token][line_break_token]&gt; * Did you experiment with other forms of modulation before arriving[line_break_token]&gt;   upon the mogrification formulation?	O	O	Reply	20578
There are some naive[line_break_token]&gt;   approaches such as concatenating the hidden state to the input and[line_break_token]&gt;   applying a nonlinear layer, or predicting affine parameters for[line_break_token]&gt;   the input as a function of the hidden state in the style of FiLM[line_break_token]&gt;   [1]. Are there obvious shortcomings in these naive approaches that[line_break_token]&gt;   mogrification handles gracefully?	O	O	Reply	20578
[line_break_token][line_break_token]We tried concatenation of hidden state and input and saw no benefit[line_break_token]compared to the Mogrifier to offset the significantly higher number of[line_break_token]parameters.	B-Reply	B-4	Reply	20578
FiLM sounds similar to one round mogrifier without a[line_break_token]non-linearity.	I-Reply	I-4	Reply	20578
As to obvious shortcomings to these methods, we do not[line_break_token]know of any.	I-Reply	I-4	Reply	20578
Probably we would need to understand a mogrifier much[line_break_token]better to answer that question.	I-Reply	I-4	Reply	20578

The work in this paper is focused on the task of knowledge base completion, dealing specifically with temporal relations, which is quite important in practice, and also not as well studied in literature.	O	O	Review	10102
Specifically, the authors have 3 main contributions in this paper:[line_break_token]1.	O	O	Review	10102
They present an order 4 tensor factorization for dealing with temporal data, which is a nice extension of the work in Lacroix 2018.	O	O	Review	10102
The authors introduce different forms of regularization to extend to the order 4 tensors.	O	O	Review	10102
Inspired by previous work, they produce different regularization strategies for order 4 tensor by unfolding the modes to reduce it ot an order 3 formulation.	O	O	Review	10102
They also describe a regularization term for smoothing the temporal embeddings.	O	O	Review	10102
[line_break_token]3.	O	O	Review	10102
Finally, the authors mine wikidata for temporal relations and contribute a dataset based on wikidata that is much larger than existing datasets for this task.	O	O	Review	10102
[line_break_token][line_break_token][line_break_token]Overall, I think this paper is  interesting as it provides an incremental extension of ComplEx to the temporal case, and the experiments to support the formulation show improvements in MRR.	O	O	Review	10102
However, the experiments around standard benchmarks as well as the data produced by the authors do not always support the hypothesis that modeling temporal dimension in the proposed formulation is a win for the KB completion task.	B-Review	B-1	Review	10102
 For example, the use of auxiliary losses  for enforcing temporal constraints makes the overall performance worse.	I-Review	I-1	Review	10102
This is mentioned in a section, but I think it deserves a more thorough explanation.	I-Review	I-1	Review	10102
Also, there is no mention about statistical significance of the results, and so it is hard to judge the claim of these being SOTA as made by the authors.	B-Review	B-4	Review	10102
For example, on the wikidata dataset produced, the ComplEx model outperforms the proposed models.	I-Review	I-4	Review	10102
[line_break_token][line_break_token][line_break_token][line_break_token]Strengths:[line_break_token]1.	O	O	Review	10102
The work in this paper is quite well motivated and the modeling formulation is clear and easy to follow.	O	O	Review	10102
The authors did a great job in citing relevant work and walking through the model formulation as well as the various regularization terms introduced.	O	O	Review	10102
[line_break_token]2.	B-Review	B-2	Review	10102
The authors compare their work to the previous SOTA - the ComplEx models for multiple datasets, including their own released datasets.	O	O	Review	10102
They present a clear set of experiments to demonstrate the effectiveness of their approach both on non-temporal and temporal relations.	O	O	Review	10102
[line_break_token]3.	O	O	Review	10102
There is a dataset being released and also code, which should aid in reproducibility of the results (though I have not tested the code).	O	O	Review	10102
[line_break_token][line_break_token]Areas to be addressed:[line_break_token]1.	O	O	Review	10102
The work seems to assume that the time is discretized by year.	B-Review	B-1	Review	10102
However, it is unclear how one would deal with a KB where the temporal relations can change on the order of weeks (example popular movies).	I-Review	I-1	Review	10102
For that matter, how would the model be modified to deal with heterogenous time scales in the evolution of the relations in the KB?	I-Review	I-1	Review	10102
Can the authors add some clarification as well as explanations for how this would be addressed in this formulation?	I-Review	I-1	Review	10102
[line_break_token]2.	B-Review	B-2	Review	10102
While there is a section devoted to different regularization, from Table 3, the impact of choosing the right regularizer seems minimal in terms of MRR.	I-Review	I-2	Review	10102
Also, it seems that the results in Table 3 are comparable to the ‚Äúranks multiplied by 10‚Äù setting in Table 2.	I-Review	I-2	Review	10102
What is the reason for this choice?	I-Review	I-2	Review	10102
[line_break_token]3.	O	O	Review	10102
For Table 4, why is there a performance difference between static and non-static relations?	B-Review	B-3	Review	10102
It would help if the authors could provide some more error analyses to dive into this performance difference - is it just data imbalance or inherent difficulty in the task for temporal relations.	I-Review	I-3	Review	10102
[line_break_token]4.	B-Review	B-4	Review	10102
Section 6 talks about enforcing another auxiliary loss, however, these results are not part of the table.	I-Review	I-4	Review	10102
I would urge the authors to add this to Table 4.	I-Review	I-4	Review	10102
Also, the loss in MRR mentioned is it the average loss or does enforcing this auxiliary loss also influence performance on T-MRR as well?	I-Review	I-4	Review	10102
If so, might it be that the auxiliary loss is too strong and might need to be penalized?	I-Review	I-4	Review	10102
Did the authors try penalizing the auxiliary loss?	I-Review	I-4	Review	10102
Finally, the graph in Figure 2 is hard to follow when printed in black and white.	I-Review	I-4	Review	10102
What would the plot look like in comparison to a model that does not enforce the auxiliary function for the same example?	I-Review	I-4	Review	10102
I would recommend re-working Section 6 to provide some more details about the performance of the models both across the various datasets as well as error analyses of a few examples compared across TNTComplex, TNTComplex + auxiliary loss + Baseline Complex.	I-Review	I-4	Review	10102
Having some representative examples would make it easy to understand where these models differ in their performance.	I-Review	I-4	Review	10102
[line_break_token]5.	O	O	Review	10102
In the results, can the authors include metrics like filtered MRR as well as Hits@10, similar to the one suggested by Bordes 2013?	B-Review	B-5	Review	10102
This would make it easier to compare against previous literature results which all seem to be reporting on these metrics.	I-Review	I-5	Review	10102
[line_break_token]	O	O	Review	10102
.	B-Reply	B-1	Reply	10102
The work seems to assume that the time is discretized by year.	O	O	Reply	10102
However, it is unclear how one would deal with a KB where the temporal relations can change on the order of weeks (example popular movies).	O	O	Reply	10102
For that matter, how would the model be modified to deal with heterogenous time scales in the evolution of the relations in the KB?	O	O	Reply	10102
Can the authors add some clarification as well as explanations for how this would be addressed in this formulation?	O	O	Reply	10102
[line_break_token]‚Üí Changing the discretization of time is not an issue unless the number of timestamps to be considered becomes too large.	B-Reply	B-1	Reply	10102
For the exemple of movies, with 52 weeks per year, this would lead to 5200 timestamps for 100 years worth of movies, which is completely manageable.	I-Reply	I-1	Reply	10102
As mentioned in our answer to Reviewer #2 however, the temporal regularizer becomes more important when the granularity along time increases.	I-Reply	I-1	Reply	10102
[line_break_token]Regarding heterogeneous timescales : in the temporal regularizer, we penalize the difference of embeddings of successive timestamps, irrespective of the actual timestamps.	I-Reply	I-1	Reply	10102
In preliminary experiments, we also tried weighting by the time difference: ||T_i - T_{i+1}||_2^2 / (ts_{i+1} - ts_i), where T_i is the embedding corresponding to timestamp ts_i.	I-Reply	I-1	Reply	10102
This reduces the temporal regularization for embeddings of timestamps that are far from their neighbors.	I-Reply	I-1	Reply	10102
This did not lead to improvements on the datasets considered.	I-Reply	I-1	Reply	10102
[line_break_token][line_break_token]2.	O	O	Reply	10102
While there is a section devoted to different regularization, from Table 3, the impact of choosing the right regularizer seems minimal in terms of MRR.	O	O	Reply	10102
Also, it seems that the results in Table 3 are comparable to the ‚Äúranks multiplied by 10‚Äù setting in Table 2.	O	O	Reply	10102
What is the reason for this choice?	O	O	Reply	10102
[line_break_token]‚Üí Impact of regularizer: the impact is e.g., 2 points of MRR absolute on ICEWS-5, which is substantial.	B-Reply	B-2	Reply	10102
 We consider our results with higher ranks as the new state-of-the-art (since performances are significantly better than previous methods), so we compare the regularizers in Table 3 in this most challenging and important setup.	I-Reply	I-2	Reply	10102
[line_break_token][line_break_token]3.	O	O	Reply	10102
For Table 4, why is there a performance difference between static and non-static relations?	O	O	Reply	10102
It would help if the authors could provide some more error analyses to dive into this performance difference - is it just data imbalance or inherent difficulty in the task for temporal relations.	O	O	Reply	10102
[line_break_token]‚Üí The difference in performance is due to a discrepancy in temporal vs non-temporal data.	B-Reply	B-3	Reply	10102
Notably, 93% of temporal tuples (subject, predicate) have two or more valid objects.	I-Reply	I-3	Reply	10102
This proportion is only 47% for non-temporal tuples.	I-Reply	I-3	Reply	10102
 One-to-many relations lead to lower MRR than one-to-one relations (see table 3, Lacroix et al 2018 Canonical Tensor Decomposition for Knowledge Base Completion)  [line_break_token][line_break_token]4.	O	O	Reply	10102
Section 6 talks about enforcing another auxiliary loss, however, these results are not part of the table.	O	O	Reply	10102
I would urge the authors to add this to Table 4.	O	O	Reply	10102
Also, the loss in MRR mentioned is it the average loss or does enforcing this auxiliary loss also influence performance on T-MRR as well?	O	O	Reply	10102
If so, might it be that the auxiliary loss is too strong and might need to be penalized?	O	O	Reply	10102
Did the authors try penalizing the auxiliary loss?	O	O	Reply	10102
[line_break_token][line_break_token]‚Üí The auxiliary loss has no influence on the T-MRR,  the point of MRR is lost over non-temporal triples.	B-Reply	B-4	Reply	10102
We did not try reducing the weight of this loss in the overall loss to obtain the best (MRR, time AUC) operating point as this section is meant to be an example of new metrics that could be interesting on this dataset.	I-Reply	I-4	Reply	10102
[line_break_token][line_break_token]Finally, the graph in Figure 2 is hard to follow when printed in black and white.	I-Reply	I-4	Reply	10102
What would the plot look like in comparison to a model that does not enforce the auxiliary function for the same example?	I-Reply	I-4	Reply	10102
[line_break_token][line_break_token]‚Üí We will add different strokes for each presidents in the final version of the paper.	I-Reply	I-4	Reply	10102
 On this example, the plot for TNTComplEx trained without the auxiliary loss gives similar scores to the presidents over time.	I-Reply	I-4	Reply	10102
[line_break_token][line_break_token]Having some representative examples would make it easy to understand where these models differ in their performance.	O	O	Reply	10102
[line_break_token]‚Üí The breakdown we provide shows that the difference comes from non-temporal triples, which is expected when comparing a temporal and non-temporal model.	B-Reply	B-4	Reply	10102
Since the non-temporal triples account for 90% of the link prediction loss, it is natural that adding a new loss will impact in majority the MRR of these triples and leave the MRR of temporal triples intact, which is what we observe.	I-Reply	I-4	Reply	10102
[line_break_token][line_break_token]5.	O	O	Reply	10102
In the results, can the authors include metrics like filtered MRR as well as Hits@10, similar to the one suggested by Bordes 2013?	O	O	Reply	10102
This would make it easier to compare against previous literature results which all seem to be reporting on these metrics.	O	O	Reply	10102
[line_break_token]‚Üí We report the filtered MRR similarly to previous state of the art on these datasets.	B-Reply	B-5	Reply	10102
This is specified in the experimental set-up section.	I-Reply	I-5	Reply	10102
To avoid clutter, we added hits@k in the supplementary materials (Appendix 8.5).	I-Reply	I-5	Reply	10102

The paper studies the role of depth on incremental learning in several toy models for neural networks.	O	O	Review	20068
In particular, they show that in these models, deep models require polynomially small initializations to exhibit incremental learning than shallow models.	O	O	Review	20068
The paper is well written, and I think there are several interesting contributions.	O	O	Review	20068
[line_break_token][line_break_token]The authors contribute analysis for non-asymptotically small initializations, and study an interesting role of depth in how small this initialization must be.	O	O	Review	20068
Furthermore, they extend their results to several other models including matrix sensing, linear convnets, and classification.	O	O	Review	20068
[line_break_token][line_break_token]I think nonetheless the paper suffers from a few issues.	O	O	Review	20068
Some very important ones.	O	O	Review	20068
[line_break_token][line_break_token]1) The authors study the role of depth on incremental learning, and exhibit how several models theoretically have this property.	B-Review	B-1	Review	20068
However, they do not study how incremental learning drives generalization.	I-Review	I-1	Review	20068
In the entire paper, the gradient flow is with respect to the *expected* loss, rather than the empirical loss.	I-Review	I-1	Review	20068
The research program of incremental learning for deep neural networks would show something like "Incremental learning exists when minimizing empirical loss", "Incremental learning and early stopping imply certain properties (like low capacity) on the resulting neural network" and "These properties imply low generalization error".	I-Review	I-1	Review	20068
However, the fact that the authors' models minimize the expected loss altogether a priori rules out the direct applicability of this result to explaining generalization.	I-Review	I-1	Review	20068
That is OK, in the sense that one could aim for these results to be modified and applied with empirical losses, and then a separate line of research could study how incremental learning bounds generalization error.	I-Review	I-1	Review	20068
[line_break_token]In this sense, I think the authors should take out the "how incremental learning drives generalization" since there is no study on generalization whatsoever, just how depth plays a role in incremental learning.	I-Review	I-1	Review	20068
An alternative title could be "How depth drives incremental learning."	I-Review	I-1	Review	20068
or something like that.	I-Review	I-1	Review	20068
[line_break_token][line_break_token]2) Another point is that all these models are very toy and mostly linear.	B-Review	B-2	Review	20068
That is OK again, but the introduction overclaims in this respect.	I-Review	I-2	Review	20068
The sentences "we characterize the effect of the model's depth [...] showing how deeper models allow for incremental learning in larger (realistic) initialization scales."	I-Review	I-2	Review	20068
and "Once incremental learning has been defined and characterized for the toy model, we generalize our results theoretically and empirically for larger models".	I-Review	I-2	Review	20068
This makes it seem that results apply to realistic settings, which is really far from true.	I-Review	I-2	Review	20068
I'm not expecting realistic results, this is a nascent theory, but I am expected the claims made to be validated and not misleading.	I-Review	I-2	Review	20068
[line_break_token][line_break_token]3) In section 2.2, sigma(t) for N-&gt; \infty is undefined, and the proof for this result is missing (only for finite N appears).	O	O	Review	20068
In particular, it is not clear if sigma(t) for N -&gt; \infty is obtained by a) taking limit N -&gt; \infty in the ODE of equation (8), and then finding the solution of this limiting ODE, or b) finding \sigma(t) for equation (8) on finite N and then taking limit N -&gt; \infty of the solution.	O	O	Review	20068
I.e. there are two potentially different ways to define \sigma(t) for N -&gt; \infty which are solving the ODE and then taking limit or taking limit and then solving the limiting ODE.	O	O	Review	20068
The definition of \sigma(t) for N -&gt; \infty is completely missing so I have no way to assess the validity of this result.	O	O	Review	20068
[line_break_token][line_break_token]A small pet peeve: when writing math, try to avoid using symbols like \forall and \exists unless you're writing a logic paper.	B-Review	B-4	Review	20068
Instead, try to write equation 2 like, which reads a lot nicer.	I-Review	I-4	Review	20068
Also, avoid assigning equation numbers to equations you never reference.	I-Review	I-4	Review	20068
hank you for the detailed review of our paper.	O	O	Reply	20068
[line_break_token][line_break_token]As we understand it, the main issues are with us overclaiming our results, and we accept some of this criticism.	O	O	Reply	20068
[line_break_token]Regarding our introduction where it can be interpreted that the models we analyze are "realistic", we see the models we analyze as non-trivial but concede that the wording could be interpreted as a claim for deep nonlinear networks, which our analysis by no means covers.	B-Reply	B-2	Reply	20068
Our revision fixes this, clarifying which models we generalize to.	I-Reply	I-2	Reply	20068
[line_break_token]Regarding the claim that our paper deals with generalization while the analysis is for the expected loss (meaning the theoretical study is about the path to the optimum and not the specific optimum chosen) - it is true that our theorems do not deal with empirical losses, but our experiments seen in figure 1 and the appendices strongly suggest that the dynamics we analyze for the expected loss are exhibited for different empirical losses and for small datasets.	B-Reply	B-1	Reply	20068
The bias towards sparsity, which leads to generalization when the labeling function is itself sparse, appears to be caused by the combination of gradient descent and a deep parameterization which we analyze, and is consistent for many deep models.	I-Reply	I-1	Reply	20068
[line_break_token][line_break_token]As for the third issue, the limit we take is for the ODE in equation (8), which leads to the equation, which is solvable like the ODEs for finite N. This result also appears in Saxe et al (2013).	B-Reply	B-3	Reply	20068
Our revision treats this case more clearly in the proof of theorem 1	I-Reply	I-3	Reply	20068

This paper studies a very simple and intuitive method to boost the training speed of deep neural networks.	O	O	Review	1685
The authors first train some light weighted proxy models, using these models to rank the data according to its uncertainty, and then pick the most uncertain subset to train the final model.	O	O	Review	1685
Experiments on CIFAR10/SVHN/Amazon Review Polarity demonstrates the effectiveness.	O	O	Review	1685
[line_break_token][line_break_token]In general, I think the authors did a decent job in showing that such a simple idea could surprisingly work well to boost NN training.	O	O	Review	1685
I believe it will inspire future works on speeding up NN training.	O	O	Review	1685
However, to form a solid ICLR publication, plenty of future works need to be done.	O	O	Review	1685
[line_break_token][line_break_token]1)[tab_token]I will not be fully convinced if an idea aiming to speed up, is only verified on small scale dataset (e.g., CIFAR10).	B-Review	B-1	Review	1685
It will be much better if there are large scale experiments conducted such as on ImageNet and WMT neural machine translation.	I-Review	I-1	Review	1685
[line_break_token][line_break_token]2)[tab_token]Please well position some related works.	B-Review	B-2	Review	1685
First, it would be more interesting and informative if some baselines in section 2 (especially those in ‚ÄúOptimization and Importance Sampling‚Äô), are compared with.	I-Review	I-2	Review	1685
Second, there are important related works omitted such as L2T [1], which also talks/shows the possibly of using partial training data to achieve speed up.	B-Review	B-3	Review	1685
[line_break_token][line_break_token]3)[tab_token]Some writing issues: it would be better to *clearly* demonstrate the final accuracy of different models (i.e. ResNet 164 trained on whole data and selected subset), such as putting them into a table, but not merely showing them vaguely in the curves and text.	B-Review	B-4	Review	1685
I‚Äôm also note sure about the meaning of `epoch‚Äô in Table 1: does it mean how many epochs the proxy model is trained?	B-Review	B-5	Review	1685
If so, I can hardly get the intuition of why smaller epochs works better.	I-Review	I-5	Review	1685
I noted a conjecture raised by the authors in the last sentence of paragraph ‚Äúcomparing different proxies‚Äù.	I-Review	I-5	Review	1685
However, I cannot catch the exact meaning.	I-Review	I-5	Review	1685
[line_break_token][line_break_token][1] Fan, Y., Tian, F., Qin, T., Li, X. Y., & Liu, T. Y. Learning to Teach.	O	O	Review	1685
ICLR 2018[line_break_token]	O	O	Review	1685
Thank you for your thoughtful review and suggestions.	O	O	Reply	1685
Here are our responses:[line_break_token][line_break_token]# large-scale experiments[line_break_token]We are currently running experiments on ImageNet, but the results will not be ready before the response deadline.	B-Reply	B-1	Reply	1685
[line_break_token][line_break_token]# Comparison against baselines in section 2[line_break_token]We agree that more comparison against existing methods such as importance sampling would be valuable.	B-Reply	B-2	Reply	1685
we aimed to compare against ‚ÄúNot All Samples Are Created Equal: Deep Learning with Importance Sampling‚Äù from Katharopoulos & Fleuret (2018) as it represents the most recent published work in the area.	O	O	Reply	1685
Unfortunately, we were unable to complete the experiments before the response deadline.	B-Reply	B-2	Reply	1685
[line_break_token][line_break_token]# Learning to teach (L2T)[line_break_token]We agree learning to teach is relevant and included it in the related work section.	B-Reply	B-3	Reply	1685
[line_break_token][line_break_token]# Final accuracy of different models in a table[line_break_token]We believe Table 1 should address this concern, and we changed the structure to make it more clear.	B-Reply	B-4	Reply	1685
The most important data from Figure 4 and 5 is captured in the table.	I-Reply	I-4	Reply	1685
We could add the additional metrics from Figure 5, but the main point of that figure is to show that all of the metrics perform about the same, which would just add redundant rows to the table.	I-Reply	I-4	Reply	1685
[line_break_token][line_break_token]# Smaller number of epochs[line_break_token]Great question.	B-Reply	B-5	Reply	1685
Yes, "epoch" in Table 1 means how many epochs the proxy model is trained.	I-Reply	I-5	Reply	1685
We have preliminary results that suggest the diversity of the subset is an important factor in maintaining quality.	I-Reply	I-5	Reply	1685
Looking at the CDF of entropy on CIFAR10, for example, shows that only around 20% of points have relatively high entropy and that entropy quickly decays after the first 20%.	I-Reply	I-5	Reply	1685
However, the target model is only able to match the same level of accuracy with a larger subset as shown in Table 1.	I-Reply	I-5	Reply	1685
This suggests that the subset needs to be sufficiently representative in addition to containing the most difficult.	I-Reply	I-5	Reply	1685
We hypothesize that the higher error of smaller architectures and partial training might result in increased randomness, which could improve the representativeness of the resulting subsets	I-Reply	I-5	Reply	1685

This paper presents a reinforcement learning based approach to learn a search strategy to search for programs in the generic syntax-guided synthesis (SyGuS) formulation.	O	O	Review	481
Unlike previous neural program synthesis approaches, where the DSL grammar is fixed or the specification is in the form of input-output examples only, the SyGuS formulation considers different grammars for different synthesis problems and the specification format is also more general.	O	O	Review	481
The main idea of the approach is to first learn a joint representation of the specification and grammar using a graph neural network model, and then train a policy using reinforcement learning to guide the search with a grammar adaptive policy network that is conditioned on the joint representation.	O	O	Review	481
Since the specifications considered here are richer logical expressions, it uses a SAT solver for checking the validity of the proposed solution and to also obtain counterexamples for future rewards.	O	O	Review	481
The technique is evaluated on 210 SyGuS benchmarks coming from the cryptographic circuit synthesis domain, and shows significant improvements in terms of number of instances solved compared to CVC4 and ESymbolic baseline search techniques from the formal methods community.	O	O	Review	481
Moreover, the learnt policy is also showed to generalize beyond the benchmarks on which it is trained and the meta-solver performs reasonably well compared to the per-task out-of-box solver.	O	O	Review	481
[line_break_token][line_break_token]Overall, this paper tackles a more challenging synthesis problem than the ones typically considered in recent neural synthesis approaches.	O	O	Review	481
The previous synthesis approaches have mostly focused on learning programs in a fixed grammar (DSL) and with specifications that are typically based on either input-output examples or natural language descriptions.	O	O	Review	481
In the SyGuS formulation, each task has a different grammar and moreover, the specifications are much richer as they can be arbitrary logical expressions on program variables.	O	O	Review	481
The overall approach of using graph neural networks to learn a joint representation of grammars with the corresponding logical specifications, and then using reinforcement learning to learn a search policy over the grammar is quite interesting and novel.	O	O	Review	481
The empirical results on the cryptographic benchmarks compare favorably to state of the art CVC4 synthesis solver.	O	O	Review	481
[line_break_token][line_break_token]However, there were some details in the model description and evaluation that were not very clear in the current presentation.	O	O	Review	481
[line_break_token][line_break_token]First, the paper mentions that it uses the idea of Static Single Assignment (SSA) form for the graph representation.	O	O	Review	481
What is the SSA form of a grammar and of a specification?	O	O	Review	481
[line_break_token][line_break_token]It was also not very clear how the graphs are constructed from the grammar.	O	O	Review	481
For example, for the rule d1 -> X OR Y | d2 OR d2 in Figure 1, are there two d_OR nodes or a single node d_OR shared by both the rules?	O	O	Review	481
Similarly, what is the d_T node in the figure?	O	O	Review	481
It would be good to have a formal description of the nodes and edges in the graph constructed from the spec and grammar.	O	O	Review	481
[line_break_token][line_break_token]Since the embedding matrix H_d can be of variable size (different sizes of expansion rules), it wasn‚Äôt clear how the policy learns a conditional distribution over the variable number of actions.	O	O	Review	481
Is there some form of padding of the matrix and then masking being used?	O	O	Review	481
[line_break_token][line_break_token]For the reward design, the choice of using additional examples in the set B_\phi was quite interesting.	O	O	Review	481
But there was no discussion about how the interpolation technique works to generate more examples around a counterexample.	O	O	Review	481
Can you provide some more details on how the interpolation is being performed?	O	O	Review	481
[line_break_token][line_break_token]Also, how many examples were typically used in the experiments?	O	O	Review	481
It might be interesting to explore whether different number of examples lead to different results.	O	O	Review	481
How does the learning perform in the absence of these examples with the simple binary 0/1 reward?	O	O	Review	481
[line_break_token][line_break_token]From last year‚Äôs SyGuS competition, it seems that the EUSolver solves 152 problems from the set of 214 benchmarks (Table 4 in <a href="http://sygus.seas.upenn.edu/files/SyGuSComp2017.pdf)."	O	O	Review	481
target="_blank" rel="nofollow">http://sygus.seas.upenn.edu/files/SyGuSComp2017.pdf).</a> For the evaluation, is ESymbolic baseline solver different that the EUSolver?	O	O	Review	481
Would it be possible to evaluate the EUSolver on the same hardware and timeout to see how well it performs on the 210 benchmarks?	O	O	Review	481
[line_break_token][line_break_token]The current transfer results are only limited to the cryptographic benchmarks.	O	O	Review	481
Since SyGuS also has benchmarks in many other domains, would it be interesting to evaluate the policy transfer to some other non-cryptographic benchmark domain?	O	O	Review	481
[line_break_token]	O	O	Review	481
Reviewer 3, the authors of this paper have submitted a fairly detailed response to your own detailed review (thanks for that!).	O	O	Reply	481
It is important that there be some consideration of their reply, and if needed, discussion.	O	O	Reply	481
Please take the time to review and respond to their rebuttal, and either reconsider your assessment or explain why you stand by it in its current form	O	O	Reply	481

As mentioned in a previous comment I want to report back with[line_break_token]preliminary results from the hyperparameter search I am conducting.	O	O	Review	51
[line_break_token]Essentially I am optimizing over all notable parameters except the[line_break_token]number of units in each layer - in order to fix the model size [line_break_token](More specifically this includes: learning rate,[line_break_token]momentum, pooling shape, pooling stride, size of the convolutional[line_break_token]kernels).	O	O	Review	51
[line_break_token][line_break_token]My preliminary results suggest that on CIFAR-10 the best probout[line_break_token]network trained without data augmentation can achieve an error rate of <= 10.7% .	O	O	Review	51
[line_break_token]During the hyperparameter search I however also became aware that the[line_break_token]parameter search carried out for the original maxout paper was[line_break_token]probably  not very exhaustive, as improved performance can also[line_break_token]be achieved with a vanilla maxout model.	B-Review	B-1	Review	51
[line_break_token]While the difference in performance between probout and maxout appears[line_break_token]to be observable for all hyperparameter settings, the best maxout model [line_break_token]I obtained so far achieves 10.92% error on CIFAR-10 without data[line_break_token]augmentation.	I-Review	I-1	Review	51
[line_break_token][line_break_token]Interestingly, the best hyperparameter settings found so far[line_break_token]are much closer to the parameters that seem to be used in the 'Network[line_break_token]in Network' paper (also submitted to ICLR) than the original settings[line_break_token]used in the maxout paper (and maxout seems to perform on par[line_break_token]with 'Network in Network' when a fully connected layer is used after the convolutional[line_break_token]layers).	B-Review	B-2	Review	51
I will cross-link these results in the discussion to that paper.	I-Review	I-2	Review	51
[line_break_token][line_break_token]I will include the results into the paper as soon as the full[line_break_token]parameter search is finished and disclose the parameters found.	I-Review	I-2	Review	51
[line_break_token][line_break_token]It would be interesting if Ian could jump in with a short comment on[line_break_token]how exactly he fixed hyperparameters for his original work.	B-Review	B-3	Review	51
My co-author David Warde-Farley chose the final hyperparameters for CIFAR-10.	B-Reply	B-1	Reply	51
Our goal was simply to improve upon the state of the art with the limited computational resources that were available to us, so we did not run an exhaustive, automated search.	I-Reply	I-1	Reply	51
Instead, both David and I guessed a small number of hyperparameter settings by hand, and we stopped working on that particular task after we started to get diminishing marginal utility from our time spent on it.	I-Reply	I-1	Reply	51
The hyperparameters for the case with no data augmentation are probably particularly poor.	I-Reply	I-1	Reply	51
We just used the best hyperparameters from the data augmentation case.	I-Reply	I-1	Reply	51
[line_break_token][line_break_token]I think if you want to do an explicit comparison between two methods, like maxout and probabilistic maxout, it's best to do an automated search, like we did for our comparison between maxout and rectifiers.	B-Reply	B-2	Reply	51
Unfortunately, when we did this automated search, we had to do it for a small maxout model, since we wanted to compare maxout against a significantly larger rectifier model	I-Reply	I-2	Reply	51

* Overview*[line_break_token]The paper tackles instance segmentation for images of beef cattle.	O	O	Review	26
[line_break_token]Mostly the paper is badly written and important details of the proposed approach are missing.	O	O	Review	26
Overall the results are extremely underwhelming on the public benchmarks, and the gains on the in-house cattle dataset are very small.	O	O	Review	26
Most importantly, the novelty of the approach is non-existent.	O	O	Review	26
See below for clarifications.	O	O	Review	26
[line_break_token][line_break_token]* Details*[line_break_token]The authors build on FCN, a method designed for instance segmentation as they correctly mention in the intro.	B-Review	B-1	Review	26
During the description of the approach, they mention that they predict blobs from the FCN output.	I-Review	I-1	Review	26
There is no mention of what that is, how they obtain it from the semantic mask predictions.	I-Review	I-1	Review	26
Unless I am missing this information, this is a crucial point.	I-Review	I-1	Review	26
Moving beyond that important detail, the authors propose two modules, which are essentially hard negative mining (similar to Training Region-based Object Detectors with Online Hard Example Mining, Shrivastava et al CVPR 2016) and another layer of classification.	O	O	Review	26
[line_break_token]If I were to ignore the extremely limited novelty of the proposed approach, the results (Table 1) are not compelling at all.	O	O	Review	26
The authors build on a shallow architecture and show underwhelming results on the public benchmarks.	O	O	Review	26
On top of that, the hyper-parameters used for computing published approaches are suboptimal (e.g. image size) which lead to lower performance than the ones reported by the original papers.	O	O	Review	26
[line_break_token][line_break_token]Last, while the above review sounds harsh I want to emphasize that it is quite legitimate to study a problem of particular interest (here image of beef cattle) and to care to obtain good results with low compute and at a low cost presumably.	O	O	Review	26
However, a publication is not necessarily justified based on the observations.	O	O	Review	26
I truly believe that there is people that will be interested in this approach (e.g. farmers, producers etc.)	O	O	Review	26
but a publication at an ICLR workshop is not the right venue for this paper.	O	O	Review	26
The network was not designed to compete against leaders in MS COCO/Pascal datasets, it is specific to this problem, like tumor segmentation or similar.	B-Reply	B-1	Reply	26
Results for MS COCO and Pascal were produced for reference, which is stated in the paper.	I-Reply	I-1	Reply	26
On our test data finetuned state-of-the-art algorithm Mask R-CNN produces 68.7% AP at 0.5 threshold and 27.7% mAP (at 50%:95% thresholds) vs FCN+MaskExtractor+BadOverlapsExtractor producing 69.4% AP at 0.5 threshold and 35.2% mAP (at 50%:95% thresholds).	I-Reply	I-1	Reply	26
Reported improvements in benchmark datasets are rarely larger.	I-Reply	I-1	Reply	26
[line_break_token][line_break_token]Giving all the details is simply intractable in a 3-page paper, it was intended to demonstrate the applicability and the potential of the idea of transforming (ignore pixels) and extracting additional information from the ground truth mask (count the number of 'bad' overlaps, e.g. 1 prediction/2+ cows or 2+ predictions/1 cow).	O	O	Reply	26
 There are two additional modules, one that learns good predictions and one that learns which ones are 'bad'.	O	O	Reply	26
They were intended to get the network to output single prediction (mask) per single observation (cow, in this case).	O	O	Reply	26
This solution is perfectly transferable to any object vs background problem with heavy partial occlusion.	O	O	Reply	26
I didn't use any negative hardmining: only positive blobs were segmented in the ground truth.	O	O	Reply	26
  [line_break_token][line_break_token]     	O	O	Reply	26

This paper suggests a quantization approach for neural networks, based on the Product Quantization (PQ) algorithm which has been successful in quantization for similarity search.	O	O	Review	20373
The basic idea is to quantize the weights of a neuron/single layer with a variant of PQ, which is modified to optimize the quantization error of inner products of sample inputs with the weights, rather than the weights themselves.	O	O	Review	20373
This is cast as a weighted variant of k-means.	O	O	Review	20373
The inner product is more directly related to the network output (though still does not account for non-linear neuron activations) and thus is expected to yield better downstream performance, and only requires introducing unlabeled input samples into the quantization process.	O	O	Review	20373
This approach is built into a pipeline that gradually quantizes the entire network.	O	O	Review	20373
[line_break_token][line_break_token]Overall, I support the paper and recommend acceptance.	O	O	Review	20373
PQ is known to be successful for quantization in other contexts, and the specialization suggested here for neural networks is natural and well-motivated.	O	O	Review	20373
The method can be expected to perform well empirically, which the experiments verify, and to have potential impact.	O	O	Review	20373
[line_break_token][line_break_token]Questions:[line_break_token]1.	O	O	Review	20373
Can you comment on the quantization time of the suggested method?	B-Review	B-1	Review	20373
Repeatedly solving the EM steps can add up to quite an overhead.	I-Review	I-1	Review	20373
Does it pose a difficulty?	I-Review	I-1	Review	20373
How does it compare to other methods?	I-Review	I-1	Review	20373
[line_break_token]2.	O	O	Review	20373
Can you elaborate on the issue of non-linearity?	B-Review	B-2	Review	20373
It is mentioned only briefly in the conclusion.	I-Review	I-2	Review	20373
What is the difficulty in incorporating it?	I-Review	I-2	Review	20373
Is it in solving equation (4)?	I-Review	I-2	Review	20373
And perhaps, how do you expect it to effect the results?	I-Review	I-2	Review	20373
e thank Reviewer 2 for their support and questions.	O	O	Reply	20373
We answer them below.	O	O	Reply	20373
[line_break_token][line_break_token]Quantization time[line_break_token]As we state in our paper, quantizing a ResNet-50 (quantization + finetuning steps) takes about one day on one Volta V100 GPU.	B-Reply	B-1	Reply	20373
The time of quantization is around 1 to 2 hours, the rest being dedicated to finetuning.	I-Reply	I-1	Reply	20373
Thus, the time dedicated to quantization is relatively short, especially compared with the fine-tuning and even more with the initial network training.	I-Reply	I-1	Reply	20373
This is because we optimized our EM implementation in at least two ways as detailed below.	I-Reply	I-1	Reply	20373
[line_break_token]-[tab_token]The E-step is performed on the GPU (see file src/quantization/distance.py, lines 61-75) with automatic chunking.	I-Reply	I-1	Reply	20373
This means that the code chunks the centroids and the weight matrices into blocks, performs the distance computation on those blocks and aggregates the results.	I-Reply	I-1	Reply	20373
This falls within the map/reduce paradigm.	I-Reply	I-1	Reply	20373
Note that the blocks are automatically calculated to be the largest that fit into the GPU, such that the utilization of the GPU is maximized, so as to minimize the compute time.	I-Reply	I-1	Reply	20373
[line_break_token]-[tab_token]The M-step involves calculating a solution of a least squares problem (see footnote 2 in our paper).	I-Reply	I-1	Reply	20373
The bottleneck for this is to calculate the pseudo-inverse of the activations x. However, we fix x when iterating our EM algorithm, therefore we can factor the computation of the pseudo inverse of x before alternating between the E and the M steps (see file src/quantization/solver.py and in particular the docstring).	I-Reply	I-1	Reply	20373
[line_break_token][line_break_token]We provided pointers to the files in the code anonymously shared on OpenReview.	I-Reply	I-1	Reply	20373
To our knowledge, these implementation strategies are novel in this context and were key in the development of our method to be able to iterate rapidly.	I-Reply	I-1	Reply	20373
Both strategies are documented in the code so that they can benefit to the community.	I-Reply	I-1	Reply	20373
[line_break_token][line_break_token]Incorporating the non-linearity[line_break_token]As the Reviewer rightfully stated, optimally we should take the non-linearity in Equation (4) into account.	B-Reply	B-2	Reply	20373
One could hope for a higher compression ratio.	I-Reply	I-2	Reply	20373
Indeed, the approximation constraint on the positive outputs would stay the same (they have to be close to the original outputs).	I-Reply	I-2	Reply	20373
On the other hand, the only constraint lying on the negative outputs is that they should remain negative (with a possible margin), but not necessarily close to the original negative outputs.	I-Reply	I-2	Reply	20373
 However, our early experiments with this method resulted in a rather unstable EM algorithm.	I-Reply	I-2	Reply	20373
This direction may deserve further investigation.	I-Reply	I-2	Reply	20373

Review: This paper deals with the issue of learning rotation invariant autoencoders and classifiers.	B-Review	B-7	Review	1409
 While this problem is well motivated, I found that this paper was fairly weak experimentally, and I also found it difficult to determine what the exact algorithm was.	I-Review	I-7	Review	1409
 For example, how the optimization was done is not discussed at all.	I-Review	I-7	Review	1409
 At the same time, I'm not an expert in group theory, so it's possible that the paper has technical novelty or significance which I did not appreciate.	I-Review	I-7	Review	1409
 [line_break_token][line_break_token]Strengths: [line_break_token][line_break_token] -The challenge of learning rotation equivariant representations is well motivated and the idea of learning representations which transfer between different scales also seems useful.	B-Review	B-8	Review	1409
 [line_break_token][line_break_token]Weaknesses: [line_break_token]  [line_break_token]-I had a difficult time understanding how the preliminaries (section 2) were related to the experiments (section 3).	B-Review	B-1	Review	1409
 [line_break_token][line_break_token]-The reference (Kondor 2018) is used a lot but could refer to three different papers that are in the references.	B-Review	B-2	Review	1409
 [line_break_token][line_break_token]  -Only reported results are on rotated mnist, but the improvements seem reasonable, but unless I'm missing something are worse than the 1.62% error reported by harmonic nets (mentioned in the introduction of the paper).	B-Review	B-3	Review	1409
 In addition to rot-mnist, harmonic nets evaluated boundary detection on the berkeley segmentation dataset.	I-Review	I-3	Review	1409
 [line_break_token][line_break_token]  -It's interesting that the model learns to be somewhat invariant across scales, but I think that the baselines for this could be better.	B-Review	B-4	Review	1409
 For example, using a convolution network with mean pooling at the end, one could estimate how well the normal classifier handles evaluation at a different scale from that used during training (I imagine the invariance would be somewhat bad but it's important to confirm).	I-Review	I-4	Review	1409
 [line_break_token][line_break_token][line_break_token]Questions: [line_break_token][line_break_token]-Section 3.1 makes reference to "learning parameters".	B-Review	B-5	Review	1409
 I assume that this is done in the usual way with backpropagation and then SGD/Adam or something?	I-Review	I-5	Review	1409
 [line_break_token][line_break_token]-How is it guaranteed that W is orthogonal in the learning procedure?	B-Review	B-6	Review	1409
 [line_break_token]	B-Review	B-1	Review	1409
Thanks for the review comments.	O	O	Reply	1409
[line_break_token]>Review: This paper deals with the issue of learning rotation invariant autoencoders and classifiers.	O	O	Reply	1409
 While this problem is well motivated, I found that this paper was fairly weak experimentally, and I also found it difficult to determine what the exact algorithm was.	O	O	Reply	1409
 For example, how the optimization was done is not discussed at all.	O	O	Reply	1409
 At the same time, I'm not an expert in group theory, so it's possible that the paper has technical novelty or significance which I did not appreciate.	O	O	Reply	1409
 [line_break_token][line_break_token][Reply] The algorithm for learning a CW basis is now stated explicitly in the appendix.	B-Reply	B-7	Reply	1409
We have summarised our approach in the response to AnonReviewer3.	I-Reply	I-7	Reply	1409
We have given it as comments titled "Summary 1 of 2" & "Summary 2 of 2".	O	O	Reply	1409
[line_break_token][line_break_token]We discuss our Implementation now in Section 3.4.	B-Reply	B-7	Reply	1409
The main technical novelty is that equivariance is easily learned in the CW basis.	I-Reply	I-7	Reply	1409
As AnonReviewer1 points out, tensor product nonlinearity is perhaps more important than the basis itself.	I-Reply	I-7	Reply	1409
[line_break_token]-----[line_break_token][line_break_token]>Strengths: [line_break_token][line_break_token]> -The challenge of learning rotation equivariant representations is well motivated and the idea of learning representations which transfer between different scales also seems useful.	O	O	Reply	1409
 [line_break_token][line_break_token][Reply] Thanks for this encouragement.	B-Reply	B-8	Reply	1409
[line_break_token]-----[line_break_token][line_break_token]>Weaknesses: [line_break_token]  [line_break_token]>-I had a difficult time understanding how the preliminaries (section 2) were related to the experiments (section 3).	O	O	Reply	1409
 [line_break_token][line_break_token][Reply] Sorry about this.	B-Reply	B-1	Reply	1409
Perhaps a reason for confusion is that whereas we use the phrase G-morphism[line_break_token]in Section 2, we use the phrase SO(2) equivariant maps in Section 3.	I-Reply	I-1	Reply	1409
These are the same.	I-Reply	I-1	Reply	1409
[line_break_token]-----[line_break_token][line_break_token]>-The reference (Kondor 2018) is used a lot but could refer to three different papers that are in the references.	O	O	Reply	1409
 [line_break_token][line_break_token][Reply] Sorry about this.	B-Reply	B-1	Reply	1409
This is now corrected.	B-Reply	B-2	Reply	1409
[line_break_token]-----[line_break_token][line_break_token]>  -Only reported results are on rotated mnist, but the improvements seem reasonable, but unless I'm missing something are worse than the 1.62% error reported by harmonic nets (mentioned in the introduction of the paper).	O	O	Reply	1409
 In addition to rot-mnist, harmonic nets evaluated boundary detection on the berkeley segmentation dataset.	O	O	Reply	1409
 [line_break_token][line_break_token][Reply] Yes we get about 97%, less than what harmonic nets get but the architecture is very simple.	B-Reply	B-3	Reply	1409
One aspect we did not emphasise much is the last column in table 1.	I-Reply	I-3	Reply	1409
It is known that Harmonic nets (and many other equivariant networks) need a large amount of data augmentation to perform well on MNIST-rot when trained on upright MNIST.	I-Reply	I-3	Reply	1409
We need no such augmentation once we have a reasonable W_{28}. In that sense our network is like spherical and FFS2CNN - truly rotation equivariant.	I-Reply	I-3	Reply	1409
 [line_break_token][line_break_token]We will take a look at Berkeley segmentation data and see what harmonic nets do and see if we can conduct those experiments.	I-Reply	I-3	Reply	1409
Thanks for this suggestion.	I-Reply	I-3	Reply	1409
[line_break_token]-----[line_break_token][line_break_token]>  -It's interesting that the model learns to be somewhat invariant across scales, but I think that the baselines for this could be better.	O	O	Reply	1409
 For example, using a convolution network with mean pooling at the end, one could estimate how well the normal classifier handles evaluation at a different scale from that used during training (I imagine the invariance would be somewhat bad but it's important to confirm).	O	O	Reply	1409
 [line_break_token][line_break_token][Reply] Thanks for this suggestion.	B-Reply	B-4	Reply	1409
We have run these experiments.	I-Reply	I-4	Reply	1409
We trained a CNN with about 489K parameters on MNIST-rot 28x28 images, getting a 95.1 percent accuracy.	I-Reply	I-4	Reply	1409
[line_break_token]When this was fed 14x14 images scaled up to 28x28, we get 90.5 percent accuracy.	I-Reply	I-4	Reply	1409
Should we report this in the main paper?	I-Reply	I-4	Reply	1409
[line_break_token]-----[line_break_token][line_break_token]>Questions: [line_break_token][line_break_token]>-Section 3.1 makes reference to "learning parameters".	O	O	Reply	1409
 I assume that this is done in the usual way with backpropagation and then SGD/Adam or something?	O	O	Reply	1409
 [line_break_token][line_break_token][Reply] Yes, backpropogation using ADAM optimiser.	B-Reply	B-5	Reply	1409
We make this explicit in Section 3.4[line_break_token]-----[line_break_token][line_break_token]>-How is it guaranteed that W is orthogonal in the learning procedure?	O	O	Reply	1409
[line_break_token][line_break_token][Reply] Sorry, we should have mentioned this -we do so now - we add a regularizer to the reconstruction loss.	B-Reply	B-6	Reply	1409
[line_break_token]----	O	O	Reply	1409

This paper tackles the problem of black-box hyperparameter optimization when multiple related optimization tasks are available simultaneously, performing transfer learning between tasks.	O	O	Review	246
Different tasks correspond to different datasets and/or metrics.	O	O	Review	246
Gaussian copulas are used to synchronize the different scales of the tasks.	O	O	Review	246
[line_break_token][line_break_token]I have several reservations with this paper.	O	O	Review	246
First and foremost, it seems to be lacking a fair and trivial baseline (I will describe it below) that justifies the apparently unnecessary complicated path followed in this paper.	B-Review	B-2	Review	246
Second, there are a few small incorrect or improperly justified technical details throughout the paper.	O	O	Review	246
[line_break_token][line_break_token][line_break_token]1) Mistaken/unjustified technical details:[line_break_token][line_break_token]- In equation 1, the last term seems to be constant.	B-Review	B-2	Review	246
For each task, the function psi is not parametric, so its gradient is also not parametric and the input is the inverse of z, i.e., y, which is also fixed.	I-Review	I-2	Review	246
So why is it included in the cost function?	I-Review	I-2	Review	246
This sort of probabilistic renormalization is important in e.g. warped GPs because the transformation is parametric.	I-Review	I-2	Review	246
In this case, I don't see the point.	I-Review	I-2	Review	246
It can be treated as a normalization of the input data, prior to its probabilistic modeling.	I-Review	I-2	Review	246
[line_break_token][line_break_token]- Before equation 1, the text says "by minimizing the Gaussian negative log-likelihood on the available evaluations (x, z)" But then, equation 1 is not the NLL on z but on y.[line_break_token][line_break_token]- In section 4.2 the authors model the residuals of the previous model using a powerful Matern-5/2 GP.	B-Review	B-3	Review	246
Why modeling the residuals this way and not the observations themselves?	B-Review	B-4	Review	246
The split of modeling between a parametric and non-parametric part is not justified.	I-Review	I-4	Review	246
[line_break_token][line_break_token]- One of the main points of the variable changes is to normalize the scales of the different tasks.	B-Review	B-5	Review	246
However, equations 1 adds together the samples of the different tasks (which, as pointed out by the authors might have different sizes).	I-Review	I-5	Review	246
Even if the scales of the outputs are uniform, the different dataset sizes will bias the solutions towards larger datasets.	I-Review	I-5	Review	246
Why would that be a good thing?	I-Review	I-5	Review	246
This is not mentioned and doesn't seem correct: there should not be a connection between a dataset size and the prior influence of the corresponding task.	I-Review	I-5	Review	246
In fact, this will have the same effect as if the cost had different scales for different tasks, which is precisely the problem that the authors are trying to avoid.	I-Review	I-5	Review	246
[line_break_token][line_break_token][line_break_token]2) Trivial baseline[line_break_token][line_break_token]Given that the authors are trying to aggregate information about the optimal hyperparameters from several tasks, they should not compare with single-task approaches, but with the simplest way to combine all the tasks.	B-Review	B-1	Review	246
For instance:[line_break_token]    a) Normalize the outputs of every task.	I-Review	I-1	Review	246
This can be accomplished in the usual way by dividing by the standard deviation, or even better, by computing the fixed transform z = psi(y), separately for each task.	I-Review	I-1	Review	246
[line_break_token]    b) Collect the z of all tasks and feed them into an existing GP black-box Bayesian optimizer.	I-Review	I-1	Review	246
[line_break_token][line_break_token]This is a very simple way to get "transfer learning" and it's unclear that the extra complexities of this paper (copulas, changes of variable with proper renormalization when the transformation is parameter free, etc) are buying much else.	I-Review	I-1	Review	246
[line_break_token][line_break_token][line_break_token]Minor improvements:[line_break_token][line_break_token]- Page 2: "is the output of a multi-layer perceptron (MLP) with d hidden nodes" Is d really the number of hidden nodes of the MLP?	B-Review	B-6	Review	246
Or the number of outputs?	I-Review	I-6	Review	246
Given that d is also the size of w, it seems it's actually the latter.	I-Review	I-6	Review	246
[line_break_token][line_break_token]- Explain why the EI approach is used for the second model (with the GP), but not for the first model.	B-Review	B-7	Review	246
[line_break_token][line_break_token]Edit after rebuttal:[line_break_token]‚ÄúThe term is not constant over z‚Äù -&gt; Sure, it‚Äôs not constant over z. But z is constant.	O	O	Review	246
So the term is constant.	B-Review	B-2	Review	246
[line_break_token][line_break_token]‚ÄúThe NLL is minimized in z and there is indeed no y in equation 1.‚Äù -&gt; Sure, there‚Äôs no y in the equation, that‚Äôs correct.	O	O	Review	246
But it is still the NLL of y, and not the NLL of z.[line_break_token][line_break_token]About the new baseline: Instead of simply renormalizing using mean and standard deviation, I suggested above using the same z=psi(y) that is used in the paper for the normalization.	B-Review	B-1	Review	246
Is that where the advantage of the proposed method is coming from?	I-Review	I-1	Review	246
[line_break_token][line_break_token]"Note that this is orthogonal to the scale issues we focus on: larger tasks will have larger gradient contributions but the scaling we propose still allows us to learn tied parameters across tasks as their scales are made similar. "	B-Review	B-5	Review	246
Both issues affect the scaling of the task, so I don't see how they can be orthogonal.	I-Review	I-5	Review	246
Their scales are not made similar precisely because of the different sample sizes.	I-Review	I-5	Review	246
[line_break_token]	O	O	Review	246
 "In equation 1, the last term seems to be constant. [...]	O	O	Reply	246
So why is it included?"	O	O	Reply	246
[line_break_token][line_break_token]The term is not constant over and is needed when performing the change of variable.	B-Reply	B-2	Reply	246
It weights more the error (and gradients) occurring when the quantile function of is changing rapidly.	I-Reply	I-2	Reply	246
In other words, error in regions where the quantile function changes rapidly should cost more compared to flat regions.	I-Reply	I-2	Reply	246
[line_break_token][line_break_token]* "Before equation 1, the text says 'by minimizing the Gaussian negative log-likelihood on the available evaluations (x, z)' But then, equation 1 is not the NLL on z but on y."[line_break_token][line_break_token]The NLL is minimized in and there is indeed no in equation 1.	B-Reply	B-3	Reply	246
[line_break_token][line_break_token]* "Why modeling the residuals this way and not the observations themselves?	O	O	Reply	246
The split of modeling between a parametric and non-parametric part is not justified."	O	O	Reply	246
[line_break_token][line_break_token]This is in fact a key point of the paper.	B-Reply	B-4	Reply	246
Modeling the residuals allows us to set a parametric prior that can transfer well across tasks by avoiding the numerical issues caused by different task and metric scales.	I-Reply	I-4	Reply	246
Note that using a parametric prior also avoids the cubic complexity in the number of evaluations that makes it prohibitive to fit a GP on all task evaluations.	I-Reply	I-4	Reply	246
[line_break_token][line_break_token]* "Given that the authors are trying to aggregate information about the optimal hyperparameters from several tasks, they should not compare with single-task approaches, but with the simplest way to combine all the tasks.	O	O	Reply	246
For instance: a) Normalize the outputs of every task. [...]	O	O	Reply	246
b) Collect the z of all tasks and feed them into an existing GP black-box Bayesian optimizer.	O	O	Reply	246
This is a very simple way to get "transfer learning" and it's unclear that the extra complexities of this paper (copulas, changes of variable with proper renormalization when the transformation is parameter free, etc) are buying much else."	O	O	Reply	246
[line_break_token][line_break_token]a) We asked ourselves the same question when designing our approach.	B-Reply	B-1	Reply	246
For this reason a simple standardization to normalize tasks (where mean and std computed on each task separately) was evaluated in our ablation study in Section 5.2 and Table 3, where we probe the benefits of the Copulas and parametric priors against simpler alternatives.	I-Reply	I-1	Reply	246
The results shows that standard normalizations are not competitive with our proposal, and these baselines perform poorly due to the scale issues met across different tasks and metrics.	I-Reply	I-1	Reply	246
Given that this method was not seen in your first review, we renamed it and referenced it better in the ablation description to make it more visible.	I-Reply	I-1	Reply	246
[line_break_token][line_break_token]b) Following on the reviewer‚Äôs feedback, we ran additional experiments standardizing the outputs of every task and feeding these into warm-start GP.	I-Reply	I-1	Reply	246
While this approach scales cubically in the number of observations, which makes it prohibitive with a large number of observations per task, our proposal of learning a prior does not have this limitation.	I-Reply	I-1	Reply	246
Nonetheless, we applied this method by selecting the best hyperparameter evaluations from each related task for a total of 100 evaluations (so as to match the number of observations used in the warm-start GP baseline in the paper).	I-Reply	I-1	Reply	246
The results show that our approach significantly outperforms this variant of warm-start GP, confirming as in Table 3 that standardization is not sufficient to transfer information successfully across heterogeneous tasks.	I-Reply	I-1	Reply	246
We thank the reviewer for the suggestion and have incorporated this additional baseline into the paper.	I-Reply	I-1	Reply	246
[line_break_token][line_break_token]* "One of the main points of the variable changes is to normalize the scales of the different tasks.	O	O	Reply	246
However, equations 1 adds together the samples of the different tasks (which, as pointed out by the authors might have different sizes)... the different dataset sizes will bias the solutions towards larger datasets... In fact, this will have the same effect as if the cost had different scales for different tasks, which is precisely the problem that the authors are trying to avoid."	O	O	Reply	246
[line_break_token][line_break_token]It is true that we do not normalize by the dataset size.	B-Reply	B-5	Reply	246
Note that this is orthogonal to the scale issues we focus on: larger tasks will have larger gradient contributions but the scaling we propose still allows us to learn tied parameters across tasks as their scales are made similar.	I-Reply	I-5	Reply	246
We thank the reviewer for the observation and revised the manuscript to discuss this option.	I-Reply	I-5	Reply	246
[line_break_token][line_break_token]* "Is d really the number of hidden nodes of the MLP?	O	O	Reply	246
Or the number of outputs?	O	O	Reply	246
Given that d is also the size of w, it seems it's actually the latter."	O	O	Reply	246
[line_break_token][line_break_token]We clarified in the main text that the number of outputs and nodes coincide.	B-Reply	B-6	Reply	246
[line_break_token][line_break_token]* "Explain why the EI approach is used for the second model (with the GP), but not for the first model."	O	O	Reply	246
[line_break_token][line_break_token]As the first model is stateless, the same hyperparameter minimizing EI would be sampled at each step (as opposed to the GP-based model).	B-Reply	B-7	Reply	246
This is why we perform Thompson sampling instead	I-Reply	I-7	Reply	246

This paper compares two approaches to learn cross-lingual word embeddings: cross-lingual alignment (where separately trained embeddings in different languages are mapped into a shared space) and joint training (which combines the training data in all languages and jointly learns a cross-lingual space).	O	O	Review	20407
The authors argue that each approach has its own advantages, and propose a "unified framework" that essentially applies them sequentially (first train jointly, and then further align them after the necessary vocabulary reallocation).	O	O	Review	20407
[line_break_token][line_break_token]I have generally positive feelings about the paper.	O	O	Review	20407
To be honest, I do not like the way the authors frame their work (e.g. the way the method is motivated in Section 2.3 or calling it a "unified framework"), but the actual method they propose does make sense, the experimental evaluation is solid, and the results are generally convincing.	O	O	Review	20407
[line_break_token][line_break_token][line_break_token]Strengths:[line_break_token][line_break_token]- Good coverage of related work, including recent publications.	O	O	Review	20407
[line_break_token][line_break_token]- Thorough evaluation in 3 different tasks, much better than what is common in the area (usually limited to BLI).	O	O	Review	20407
[line_break_token][line_break_token]- The authors experiment with contextual embeddings in addition to conventional word embeddings.	O	O	Review	20407
[line_break_token][line_break_token]- Generally convincing results with relevant ablations and reasonable baselines.	O	O	Review	20407
[line_break_token][line_break_token][line_break_token]Weaknesses:[line_break_token][line_break_token]- I feel that framing this as a "unified framework" for cross-lingual alignment and joint training is going a bit too far.	B-Review	B-1	Review	20407
The proposed method is as simple as first doing the joint training and then the cross-lingual alignment (with a special treatment for vocabulary reallocation).	I-Review	I-1	Review	20407
This is just a sequential application of two class of methods, and not what I would understand as a "unified framework" (which suggests some form of generalization or at least a closer interaction to me).	I-Review	I-1	Review	20407
At the same time, the only "joint training" that the authors explore is training regular embeddings over concatenated monolingual corpora, which as far as I know has only been explored by Lample et al (2018), and I would not consider as a representative example of this family of methods.	I-Review	I-1	Review	20407
[line_break_token][line_break_token]- It is not clear how the different vocabulary spaces are handled in BLI.	B-Review	B-2	Review	20407
My understanding is that if the query is in the source vocabulary subset the retrieval is done over the target subset, and if it is in the shared subset it is the same query word that is returned, but this is not clear at all.	I-Review	I-2	Review	20407
[line_break_token][line_break_token]- I think that the issue of "oversharing" is magnified in the paper.	B-Review	B-3	Review	20407
I understand that this is directly connected to the reallocation step in the proposed method, and it of course makes sense to also map words that predominantly appear in a single language.	I-Review	I-3	Review	20407
However, in relation to the downstream tasks themselves, oversharing only seems relevant for BLI, where one needs to delimit the retrieval space and avoid returning the query word (which is of course its own nearest neighbor) unless it actually exists in the target language.	I-Review	I-3	Review	20407
This is connected to my previous point, and I think should be discussed in isolation.	I-Review	I-3	Review	20407
[line_break_token][line_break_token][line_break_token]Other minor things to improve:[line_break_token][line_break_token]- Please make Figure 2c an actual table instead of an image.	B-Review	B-4	Review	20407
hank you for your comprehensive review and valuable feedback.	O	O	Reply	20407
We address your comments one by one as following:[line_break_token][line_break_token][Terminology and joint training][line_break_token][line_break_token]While we meant to say this is a method that unifies two previously exclusive approaches by calling it a framework, we agree that it can be stated in a better way.	B-Reply	B-1	Reply	20407
We will rephrase our terminology in an updated version.	I-Reply	I-1	Reply	20407
[line_break_token][line_break_token]The joint training paradigm attracts the community‚Äôs growing attention recently, especially for the contextualized representations such as multilingual BERT.	I-Reply	I-1	Reply	20407
There are still many open questions such as why joint training models work and how to further improve them.	I-Reply	I-1	Reply	20407
In addition to the non-contextualized joint training explored by [1], we also conduct experiments for the contextualized representations and show that alignment can still improve pretrained models.	I-Reply	I-1	Reply	20407
This is consistent with (very) recent results [2], which also suggest combining ideas from alignment as a future research direction.	I-Reply	I-1	Reply	20407
[line_break_token][line_break_token][BLI evaluation][line_break_token][line_break_token]Your understanding of the evaluation protocol is correct.	B-Reply	B-2	Reply	20407
We concatenate each language‚Äôs own subset with the shared subset and use the two concatenated parts for evaluation.	I-Reply	I-2	Reply	20407
This is equivalent to your description since if the query is in the shared part it will automatically retrieve itself by the nature of CSLS.	I-Reply	I-2	Reply	20407
We will make this clear in an updated version.	I-Reply	I-2	Reply	20407
[line_break_token][line_break_token][Oversharing][line_break_token][line_break_token]The oversharing issue has three undesirable effects: (1) it results in a poor seed dictionary for the joint initialization (2) it prohibits the application of alignment refinement, and because of which, (3) it hinders performance on downstream tasks by making false assumptions on word translations.	B-Reply	B-3	Reply	20407
While we agree that it is most relevant for BLI in our experiments, recent work [3] also shows less sharing (thus a larger vocab size &amp; more parameters) can be beneficial for contextualized representations on harder downstream tasks such as language understanding and question answering, and we hypothesize this is partly due to oversharing of tokens with different meanings in different languages.	O	O	Reply	20407
[line_break_token][line_break_token][1] Phrase-Based &amp; Neural Unsupervised Machine Translation.	O	O	Reply	20407
Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, Marc'Aurelio Ranzato.	O	O	Reply	20407
EMNLP 2018[line_break_token][2] Emerging Cross-lingual Structure in Pretrained Language Models.	O	O	Reply	20407
Shijie Wu, Alexis Conneau, Haoran Li, Luke Zettlemoyer, Veselin Stoyanov.	O	O	Reply	20407
Preprint 2019 <a href="https://arxiv.org/abs/1911.01464" target="_blank" rel="nofollow">https://arxiv.org/abs/1911.01464</a>[line_break_token][3] On the Cross-lingual Transferability of Monolingual Representations.	O	O	Reply	20407
Mikel Artetxe, Sebastian Ruder, Dani Yogatama.	O	O	Reply	20407
Preprint 2019 <a href="https://arxiv.org/abs/1910.11856" target="_blank" rel="nofollow">https://arxiv.org/abs/1910.11856</a>	O	O	Reply	20407

The authors propose to approximate the posterior over weights by minimizing KL(p||q) where p denotes the true posterior and q denotes a diagonal Gaussian approximation.	O	O	Review	80
The authors collect multiple samples from the posterior by running SGLD and learn the variational approximation by updating the mean and variance of the weights in an incremental fashion (which removes the need to store all previous samples).	O	O	Review	80
In practice, the authors use Adam + small gradient noise with fixed standard deviation instead of a properly tuned SGLD.	O	O	Review	80
Overall, it's a quite simple idea to learn a distribution over weights and   looks promising for outlier detection.	O	O	Review	80
It under-performs compared to explicit ensemble, however the proposed method is more memory efficient and requires just training 1 model.	O	O	Review	80
[line_break_token][line_break_token]Questions:[line_break_token]- Do you use all the samples or do you have some sort of "burn-in" phase where you ignore the first few samples as they could be quite bad?	B-Review	B-1	Review	80
Did you try "thinning" the samples, i.e. use only every K-th sample or so?	I-Review	I-1	Review	80
[line_break_token]- how do you choose d_x in (4)?	B-Review	B-2	Review	80
[line_break_token]- There has been some work on expectation propagation for Bayesian neural networks which also minimize KL(p||q).	B-Review	B-3	Review	80
See "Stochastic expectation propagation" by Li et al 2015 and "Distributed Bayesian learning with stochastic natural-gradient expectation propagation and the posterior server" by Hasenclever et al 2015.	I-Review	I-3	Review	80
It would be nice to discuss connections to these works.	I-Review	I-3	Review	80
[line_break_token]- The snapshot ensemble code is available online at <a href="https://github.com/gaohuang/SnapshotEnsemble."	O	O	Review	80
target="_blank" rel="nofollow">https://github.com/gaohuang/SnapshotEnsemble.</a> It'd be worth understanding why/when it underperforms.	O	O	Review	80
Thanks for your remarks.	O	O	Reply	80
Answering each of the points  in the same order:[line_break_token]- We burn the first 100 iterations.	B-Reply	B-1	Reply	80
Since all the collected samples are used in the calculation of the Gaussian parameters, including the samples of low likelihood from the beginning of training did result in decreased performance.	I-Reply	I-1	Reply	80
We tried thinning (between 2 and 20 steps) and it did not yield a significant change in performance, in the cases that the number of samples collected were the same, i.e. collecting 100 samples from 100 steps yields similar performance to collection 100 samples from 200 steps with thinning factor of 2 (assuming the previous burn-in).	I-Reply	I-1	Reply	80
Given this, we chose to not use thinning and have a smaller number of gradient descent steps.	I-Reply	I-1	Reply	80
[line_break_token]- d_x is defined as the ensemble prediction disagreement for the input x, as per Lakshminarayanan[line_break_token]et al (2016).	B-Reply	B-2	Reply	80
[line_break_token]- Thanks for the suggestion, we were not aware of that line of work.	B-Reply	B-3	Reply	80
We are looking into it and will update the paper to include any similarities worth mentioning.	I-Reply	I-3	Reply	80
[line_break_token]- Yes, we are also suspicious about why we couldn't get snapshot ensembles to yield results in the same line of the original paper - we were a bit short on time and didn't manage to figure it out before the deadline.	B-Reply	B-4	Reply	80
We have looked into the implementation and ours seems to be aligned, but we will keep looking (it is possible that this is a matter of hyperparameter choice, since there are several additional hyperparameters at play in this model)	I-Reply	I-4	Reply	80

This paper proposes a method to address the interesting task, i.e. controllable human activity synthesis, by conditioning on the previous frames and the input control signal.	O	O	Review	20591
To synthesis the next frame, a Pose2Pose network is proposed to first transfer the input information into the next frame body structure and object.	O	O	Review	20591
Then, a Pose2Frame network is applied to generate the final result.	O	O	Review	20591
The results on several video sequences look nice with more natural boundaries, object, and backgrounds compared to previous methods.	O	O	Review	20591
[line_break_token][line_break_token]Pros:[line_break_token]1.	O	O	Review	20591
The proposed Pose2Pose successfully transfer the pose conditioned on the past pose and the input control signal.	O	O	Review	20591
The proposed conditioned residual block, occlusion augmentation and stopping criteria seem to help the Pose2Pose network work well.	O	O	Review	20591
Besides, the object is also considered in this network, which makes the method generalized well to the videos where human holds some rigid object.	O	O	Review	20591
[line_break_token]2.	O	O	Review	20591
The Pose2Frame network is similar to previous works but learns to predict the soft mask to incorporate the complex background and to produce shallow.	O	O	Review	20591
The mask term in Eq. (	O	O	Review	20591
7) seems to work well for the foreground (body+object) and the shallow regions.	O	O	Review	20591
[line_break_token]3.	O	O	Review	20591
The paper is easy to follow.	O	O	Review	20591
[line_break_token][line_break_token]Cons:[line_break_token]1.	O	O	Review	20591
Since the method is only evaluated on several video sequences, I am not sure how the method will perform on other different scenes.	B-Review	B-1	Review	20591
Results on more scenes will make the performance more convincing.	I-Review	I-1	Review	20591
I also wonder if the video data will be released, which could be important for the following comparisons.	I-Review	I-1	Review	20591
[line_break_token]2.	O	O	Review	20591
As to the results of the Pose2Pose network, I wonder if there are some artifacts that will affect the performance of the Pose2Frame network.	B-Review	B-2	Review	20591
Then, there will be another question: how the two networks are trained?	I-Review	I-2	Review	20591
Are they trained separately or jointly?	I-Review	I-2	Review	20591
I assume the authors first train the Pose2Pose network, then use the output to train the Pose2Frame network.	I-Review	I-2	Review	20591
Otherwise, the artifacts from Pose2Pose will affect the testing performance of the Pose2Frame network.	I-Review	I-2	Review	20591
[line_break_token]3.	O	O	Review	20591
The mask term seems to work well for the shallow part.	B-Review	B-3	Review	20591
I wonder how the straightforward regression term plus the smooth term will perform for the mask.	I-Review	I-3	Review	20591
Here, the straightforward regression term means directly regress the output mask to the target densepose mask.	I-Review	I-3	Review	20591
Will the proposed mask term perform better?	I-Review	I-3	Review	20591
[line_break_token]	O	O	Review	20591
1.	O	O	Reply	20591
We aimed to provide a broad variety of example applications (playing tennis, walking, fencing, dancing), while mainly focusing on the most complicated (tennis) application, for a thorough analysis of our method.	B-Reply	B-1	Reply	20591
Unfortunately, we cannot release the dataset, since we do not own the videos, but we will share our code.	I-Reply	I-1	Reply	20591
[line_break_token][line_break_token]2.	O	O	Reply	20591
The Pose2Pose and Pose2Frame networks are trained separately.	B-Reply	B-2	Reply	20591
Specifically, the P2F network is trained on the original data, and not on the output frames of the P2P network.	I-Reply	I-2	Reply	20591
You are correct that some artifacts are added to the final P2F output at test time, yet they are minor due to the structural stability of the poses generated by the P2P network.	I-Reply	I-2	Reply	20591
Furthermore, training the P2F network with the P2P outputs is problematic, since we do not have the ground-truth for the new pose generated by the P2P network.	I-Reply	I-2	Reply	20591
[line_break_token][line_break_token]3.	O	O	Reply	20591
The mask loss proposed in the review is similar to our implementation, except that we make a distinction between an inner-mask control and an outer-mask control.	B-Reply	B-3	Reply	20591
Our mask regression losses consist of a first loss penalizing the mask from being active outside the densepose mask, and a second loss penalizing the mask from being inactive inside the densepose mask.	I-Reply	I-3	Reply	20591
Combining them both results in the suggested loss	I-Reply	I-3	Reply	20591

The paper proposes to integrate sequential information into imitation learning techniques.	O	O	Review	1135
 The assumption is that mostly all the IL techniques are learning a policy which depends on state at time t, while the information contained in this state may be not sufficient to choose the right action (actually, this is the POMDP setting, the notion of POMDP not appearing in the paper....).	O	O	Review	1135
The authors thus propose to use a recurrent neural network to encode the state by aggregating past information, instead of just using the features of the state at time t. They thus instantiate this idea on different methods and show that, on some problems, this approach can increase the quality of the final policy.	O	O	Review	1135
[line_break_token][line_break_token]Actually, the contribution of the paper is a simple extension of existing methods: using a RNN instead of a simple NN in imitation learning models.	B-Review	B-5	Review	1135
First of all, when dealing with classical environments such as Atari, many papers propose to use the last N frames as a state encoding (instead of the last frame), following the same intuition.	O	O	Review	1135
The studied setting thus corresponds to the PO-MDP case and using a RNN in POMDP is for example what is done in  [Merel etal.	O	O	Review	1135
2017]. Moreover, the problem of imitation learning (and particularly inverse RL) in POMDP has been of the interest of many papers like [Choi et al 2008] for instance and many more, and it is unclear what is the positioning of this paper w.r.t existing works.	B-Review	B-4	Review	1135
Since the paper proposes just to encode history with a RNN, the proposed solution lacks of originality, and the contribution of the paper in term of model is quite low.	B-Review	B-1	Review	1135
 But the authors explain how this can be instantiated in three different settings (IRL, GAIL and BC) -- note that the section concerning the use of Adaboost is not clear and could be better described -- which can be of the interest of the community.	I-Review	I-1	Review	1135
[line_break_token]Concerning the experiments, I don't understand what is the split between training and testing data.	B-Review	B-2	Review	1135
Is it pairs of state-action coming from the experts ?	I-Review	I-2	Review	1135
or trajectories ?	I-Review	I-2	Review	1135
Moreover, I don't understand why these environments correspond to POMDP cases and the authors have to give details on that.	B-Review	B-3	Review	1135
For instance, mountain-car is clearly not a POMDP problem in its classical shape, nor Acrobot.	I-Review	I-3	Review	1135
As if, it makes the experiments very difficult to reproduce.	I-Review	I-3	Review	1135
The interest of using the RNN to encode history does not seem clear for each of the cases since it often degrades the final performance, so I don't know exactly what insights I can extract from the paper.	I-Review	I-3	Review	1135
[line_break_token][line_break_token]Pro:[line_break_token]* The approach is proposed for IRL, GAIL and BC[line_break_token][line_break_token]Cons:[line_break_token]* Lack of positionning w.r.t POMDP litterature[line_break_token]* Lack of details in the experiments, and lack of good experimental results[line_break_token]* Low contribution in term of model[line_break_token][line_break_token][line_break_token][Merel et al 2017]  Learning human behaviors from motion capture[line_break_token]by adversarial imitation[line_break_token][Choi et al] Inverse Reinforcement Learning in Partially Observable[line_break_token]Environments	I-Review	I-3	Review	1135
We thank the reviewer for valuable comments.	B-Reply	B-5	Reply	1135
While the idea is simple and the contribution in term of model seems small, we posed an important problem that sequential information is important in the RL-related approaches.	I-Reply	I-5	Reply	1135
[line_break_token][line_break_token]We are sorry that we have missed the connection between this work and POMDPs.	B-Reply	B-3	Reply	1135
The mentioned papers will be cited and discussed thoroughly.	I-Reply	I-3	Reply	1135
We provide a simple solution to RL in POMDPs, which is the major contribution of this work.	I-Reply	I-3	Reply	1135
[line_break_token][line_break_token]Regarding "lack of good experimental results", we achieved much better scores in most scenarios, and in some of them, we achieved better performance than human experts.	I-Reply	I-3	Reply	1135
[line_break_token][line_break_token]Regarding experimental details, we can provide more in the revised version.	I-Reply	I-3	Reply	1135
[line_break_token][line_break_token]Thanks again for helping us improve the quality of this paper	O	O	Reply	1135

The paper develops a new method for adapting models trained on labeled data from some source domain to unlabeled data in a target domain.	O	O	Review	20179
The authors accomplish this by adapting a technique from [1] and [2] enforcing that the deep features learned during training approximately follow a Gaussian mixture distribution.	O	O	Review	20179
With the learned features in this form, the authors ensure domain adaptation by minimizing the discrepancy between the distributions arising from the source and target datasets.	O	O	Review	20179
[line_break_token][line_break_token]Strengths:[line_break_token] + The paper's experiments show an improvement in the model's performance relative to past work, utilizing a large number of comparison models.	O	O	Review	20179
[line_break_token] + The use of explicit distributional information within the learned representations seems like a good fit for the task at hand, and the authors' experiments back this up.	O	O	Review	20179
[line_break_token][line_break_token]Weaknesses:[line_break_token] - The proposed method for unsupervised domain adaptation is very similar to the prototypical networks approach in [3], with the primary difference being a loss term incentivizing a Gaussian mixture distribution over features.	B-Review	B-1	Review	20179
[line_break_token] - While the authors achieve improved performance over [3], the gains in classification accuracy on the target dataset aren't especially huge (~1-3%).	B-Review	B-2	Review	20179
[line_break_token] - The paper is a bit hard to follow, and would be improved by giving a more explicit comparison of the methods used here to past work, especially [1] and [3].[line_break_token][line_break_token][line_break_token][1] Weitao Wan, Yuanyi Zhong, Tianpeng Li, and Jiansheng Chen.	B-Review	B-3	Review	20179
Rethinking feature distribution for loss functions in image classification.	O	O	Review	20179
2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.	O	O	Review	20179
9117‚Äì9126, 2018.	O	O	Review	20179
[line_break_token][line_break_token][2] Hong-Ming Yang, Xu-Yao Zhang, Fangying Yin, and Chenglin Liu.	O	O	Review	20179
Robust classification with convolutional prototype learning.	O	O	Review	20179
2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.	O	O	Review	20179
3474‚Äì3482, 2018.	O	O	Review	20179
[line_break_token][line_break_token][3] Yingwei Pan, Ting Yao, Yehao Li, Yu Wang, Chong-Wah Ngo, and Tao Mei.	O	O	Review	20179
Transferrable prototypical networks for unsupervised domain adaptation.	O	O	Review	20179
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.	O	O	Review	20179
2239‚Äì2247, 2019.	O	O	Review	20179
hanks for reviewing our paper.	O	O	Reply	20179
Here are some points that are not fair to our work based on the weaknesses you have mentioned and we want to argue about them:[line_break_token][line_break_token]1).	O	O	Reply	20179
There is some connection between our work and the work in [1]. As we have stated in the Related Works section, in [2], "learning PN is equivalent to performing mixture density estimation on the deep features with an exponential density".	B-Reply	B-3	Reply	20179
Thus, modeling the feature distribution as Gaussian Mixture, which is a type of exponential density, is equivalent to learn a Prototypical Network.	I-Reply	I-3	Reply	20179
This statement induces some connection between our work and the work in [1]. However, this equivalence is only true when learning a model in a single domain.	I-Reply	I-3	Reply	20179
Our work is way different from Pan et al's work in the setting of domain adaptation.	I-Reply	I-3	Reply	20179
[line_break_token][line_break_token]First, we are based on different ideas.	I-Reply	I-3	Reply	20179
While Pan et al propose a novel idea to remold PN for domain adaptation, as stated in their paper, our work is based on the idea that almost all existing domain adaptation methods are minimizing the feature distribution discrepancy for effective knowledge transfer from source domain to target domain, but none of them explicitly models the feature distribution though intuitively it facilitates the measuring of distribution discrepancy.	I-Reply	I-3	Reply	20179
[line_break_token][line_break_token]Second, the two works propose different distribution discrepancy loss functions.	I-Reply	I-3	Reply	20179
While Pan et al propose multi-granular distribution discrepancy loss functions at both class-level and sample-level, our work proposes two new distribution discrepancy loss functions based on probability, one is Gaussian Component Mean Matching (GCMM) and one is Pseudo Distribution Matching (PDM).	I-Reply	I-3	Reply	20179
These two discrepancy loss functions work at different aspects and complement each other, where GCMM brings the two distributions closer, while PDM shapes the two distributions alike.	I-Reply	I-3	Reply	20179
One central component of a domain adaptation method is the distribution discrepancy loss function, as most domain adaptation methods follow a similar framework to minimize the distribution discrepancy loss function together with a classification loss function for knowledge transfer.	I-Reply	I-3	Reply	20179
Thus, you may think our work is very similar to Pan et al's.	I-Reply	I-3	Reply	20179
This is because almost all domain adaptation methods follow this similar framework.	I-Reply	I-3	Reply	20179
We do not agree with the claim that "the primary difference between our work and Pan et al's is a loss term incentivizing a Gaussian mixture distribution over features."	I-Reply	I-3	Reply	20179
Due to the central role distribution discrepancy loss functions play in a domain adaptation method, devising new distribution discrepancy loss functions is an active research area in domain adaptation [3,4,5]. Please do not ignore the two novel discrepancy loss functions we propose based on our feature distribution modeling.	I-Reply	I-3	Reply	20179
[line_break_token][line_break_token]Third, in terms of training algorithm, our method learns the distribution parameters automatically, while the Pan et al's work needs to manually calculate the prototypes for assigning pseudo labels.	I-Reply	I-3	Reply	20179
[line_break_token][line_break_token]Finally, our proposed method fills the important gap in the area of domain adaptation, and to the best of our knowledge, no existing UDA methods have tried to model the feature distribution for domain adaptation.	I-Reply	I-3	Reply	20179
[line_break_token][line_break_token]2).	O	O	Reply	20179
For the digits image transfer tasks, state-of-the-art results are already quite high, all above 92%, thus a 1~3% of accuracy increase should be considered as significant.	B-Reply	B-2	Reply	20179
There is not much room for a new method to make a huge improvement.	I-Reply	I-2	Reply	20179
If we treat the "Train-on-target" accuracy as the upper bound, the difference of accuracy between the second best results and the upper bound is quite limited, being 5.2%, 2.6%, 6.3% for the transfer M-&gt;U, U-&gt;M, S-&gt;M respectively.	O	O	Reply	20179
For VisDA-2017 dataset, our method improved from the second best by 1%, having a accuracy results of 81.4%.	B-Reply	B-2	Reply	20179
[line_break_token]And it is 1.4% lower than [6], which won the first place in the VisDA-2017 competition.	I-Reply	I-2	Reply	20179
Thus, although this improvement is not huge, but it should not be considered as marginal	I-Reply	I-2	Reply	20179

This paper studies whether language composition may emerge by partially re-sampling new agents inside a pool of language agents.	O	O	Review	20544
They set up a consistent experimental setting for assessing compositionality,  assess different agent architectures, e.g., memory vs. memoryless agents,  and explore how the language remains close to each other by re-sampling new agents.	O	O	Review	20544
[line_break_token][line_break_token]The paper is well-motivated with substantial background literature on the cognitive science and emergent communication side.	O	O	Review	20544
The claim is clear, the hypotheses are well-stated, and the experiments look solid (I particularly appreciated the paragraph on shortcoming evaluation).	O	O	Review	20544
In the end, I enjoy reading the paper despite its density, and I could see that the authors made quite some effort in that direction.	O	O	Review	20544
[line_break_token][line_break_token]Improvement direction, questions:[line_break_token] - The authors made were careful not to take ownership of Kottur et al 's works.	B-Review	B-1	Review	20544
Yet, the writing sometimes gives the feeling that their work is solely an extension of Kottur's work, which is not the case.	I-Review	I-1	Review	20544
It also gives the feeling that Kottur et al is the only valid experimental setting, which is not the case (at the authors pointed out in the related work section).	I-Review	I-1	Review	20544
Thus, I would recommend to summarise at some point the similarity/difference between the two papers, or at least stop referring the paper every two lines!	I-Review	I-1	Review	20544
[line_break_token] - Replacement strategy: the authors use simple replacement strategies, and conclude that it has little impact.	O	O	Review	20544
Althought It sounds reasonable in the current setting, the conclusion may be a bit premature.	B-Review	B-2	Review	20544
I would recommend to discuss further this result with complementary experiments could be the following: see the impact of epsilon, trying tournament strategies, why 8 populations (this sounds a bit arbitrary too).	I-Review	I-2	Review	20544
I would also like to put those observations in perspective with the evolutionary literature [1], and even provide a full paragraph in the related work section.	I-Review	I-2	Review	20544
[line_break_token] - Population dynamics: I am missing a key element in the paper: an analysis of the population dynamics.	B-Review	B-3	Review	20544
Although the paper deals with generational transmissions, there are no experiments that analyze the evolution of language generations after generations.	I-Review	I-3	Review	20544
Most of the experiments deal with the final convergence state.	I-Review	I-3	Review	20544
Again, I would recommend having a look at the evolutionary literature to see which protocol they use to analyze such behavior.	I-Review	I-3	Review	20544
[line_break_token] - Literature side: The authors did an excellent job on the emergent communication and cognitive science side.	B-Review	B-4	Review	20544
I think that it is worth extending the comparison further.	I-Review	I-4	Review	20544
For instance: [line_break_token]    * generational transmission can be studied in the light of game theory [2] where compositionality can be seen as a Nash Equilibrium between agent.	I-Review	I-4	Review	20544
[line_break_token]    * generational transmission is a form of dynamic distillation [3][line_break_token]    * and evolutionary algorithms!	I-Review	I-4	Review	20544
[line_break_token] - I had some difficulties in understanding Fig4, and the final-take away correctly.	B-Review	B-5	Review	20544
Would it be possible to give me one or two examples to correctly parse the table?	I-Review	I-5	Review	20544
More generally, I would recommend to add a few lines with some concrete and cherry-picked examples from the experiments to help the reader to have more intuition).	I-Review	I-5	Review	20544
[line_break_token] - In a similar spirit, it is hard to interpret the distance in Figure 3.	B-Review	B-6	Review	20544
What would correspond to an increase of 1pt of distance?	I-Review	I-6	Review	20544
Having said that, the experiment is sound, and it is insightful.	I-Review	I-6	Review	20544
[line_break_token] - reproducible: having a final table in the array in the appendix could be very helpful [line_break_token] - crazy experiment: even if I am also a DRL addict, I would be curious to train one of the models with evolutionary algorithms (CMA-ES over parameters, for instance) to assess whether RL has an impact on compositionality (or it is solely the experimental protocol that matters).	B-Review	B-7	Review	20544
[line_break_token] - I may have missed this point, but how many seeds did you use to run your experiments?	B-Review	B-9	Review	20544
[line_break_token] - I may have also missed this point, what is the average length of the dialogue.	B-Review	B-10	Review	20544
Can you upload (non-understandable) dialogue example?	I-Review	I-10	Review	20544
[line_break_token][line_break_token]Last point... but it does not undermine the soundness of the experimental protocol!	O	O	Review	20544
[line_break_token] - In the end, Is 25 accuracy points really compositionality?	B-Review	B-11	Review	20544
What would be the score of simple strategies with overcomplete tokens?	I-Review	I-11	Review	20544
What is the score of the minimal vocab if we are only correct with one modality, two modalities?	I-Review	I-11	Review	20544
[line_break_token][line_break_token][line_break_token][line_break_token]Remarks:[line_break_token] - in the introduction, you mention that previous old agents have grounded language, I am not sure whether we can speak of grounded language here, they have a predefined language, but it is not grounded.	B-Review	B-12	Review	20544
[line_break_token] - Please remove the bold sentence in the introduction :) The claim is clear!	B-Review	B-13	Review	20544
[line_break_token] - P11: Alg undefined[line_break_token] - P12: the legend cannot be read[line_break_token] [line_break_token][line_break_token]Conclusion[line_break_token]I am familiar with this type of experimental protocols, and I am well aware that they are never-ending works.	B-Review	B-14	Review	20544
There are always more experiments to do, more parameters to analyze.	O	O	Review	20544
The final question is the following: is this paper have enough of these never-ending experiments?	B-Review	B-16	Review	20544
I think that this paper is just above this threshold by a short margin, and I vouch for weak accept.	O	O	Review	20544
[line_break_token][line_break_token]However, I am missing at least one dynamic figure (to see the impact of the population along time, which is one of the core concepts of the paper), and there are several links with other ML communities that still have to be highlighted (especially evolutionary algorithms).	B-Review	B-3	Review	20544
[line_break_token]Besides, I somehow feel that the authors pursue two different goals in this paper: they both analyze memory/memoryless complete/overcomplete agents, which is somehow orthogonal to the general transmission hypothesis.	B-Review	B-8	Review	20544
Maybe, It would have made more sense to focus on one (or two) of the models and change the experimental setting on them (population size, training time, etc.)	I-Review	I-8	Review	20544
[line_break_token][line_break_token]In the end, I would favor a weak accept.	O	O	Review	20544
[line_break_token]I am open to discussion regarding this scoring.	O	O	Review	20544
[line_break_token][line_break_token][1] B√§ck, Thomas, and Frank Hoffmeister. "	O	O	Review	20544
Extended selection mechanisms in genetic algorithms." (	O	O	Review	20544
1991).	O	O	Review	20544
[line_break_token][2] Lanctot, Marc, et al "A unified game-theoretic approach to multiagent reinforcement learning."	O	O	Review	20544
Advances in Neural Information Processing Systems.	O	O	Review	20544
2017.	O	O	Review	20544
[line_break_token][3] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. "	O	O	Review	20544
Distilling the knowledge in a neural network."	O	O	Review	20544
arXiv preprint arXiv:1503.02531 (2015).	O	O	Review	20544
hanks for the well balanced review and depth of feedback!	O	O	Reply	20544
We generally agree with the comments and suggestions and add clarifications, additional information, and some rebuttal below.	O	O	Reply	20544
[line_break_token][line_break_token]__Comment (referencing Kottur et al)__: ‚ÄúThe authors made were careful not to take ownership of Kottur et al 's works.	O	O	Reply	20544
Yet, the writing sometimes gives the feeling that their work is solely an extension of Kottur's work, which is not the case.	O	O	Reply	20544
‚Äù[line_break_token]__Response__: Thanks!	B-Reply	B-1	Reply	20544
This is something we struggled with, so it‚Äôs nice to get feedback.	I-Reply	I-1	Reply	20544
We will try to better isolate references and clearly indicate the differences.	I-Reply	I-1	Reply	20544
[line_break_token][line_break_token]__Comment (population dynamics)__: ‚ÄúPopulation dynamics: I am missing a key element in the paper: an analysis of the population dynamics.	O	O	Reply	20544
Although the paper deals with generational transmissions, there are no experiments that analyze the evolution of language generations after generations.	O	O	Reply	20544
Most of the experiments deal with the final convergence state.	O	O	Reply	20544
‚Äù[line_break_token]__Response__: In initial experiments we measured D (the language dissimilarity metric from section 5.2) over training iterations.	B-Reply	B-3	Reply	20544
We will compute this plot for our final experiments and report it in the appendix.	I-Reply	I-3	Reply	20544
Initial experiments looked as expected: After some initial stabilization D looks like a typical learning curve for the 3 Multi Agent replacement methods, decreasing quickly at first then continuing to decrease slowly in later generations.	I-Reply	I-3	Reply	20544
The No Replacement strategy converges immediately and then either stays fixed throughout training or sometimes (for Small Vocab models) actually increases over the course of training.	I-Reply	I-3	Reply	20544
[line_break_token][line_break_token]__Comment (literature)__: ‚ÄúLiterature side: The authors did an excellent job [...] I think that it is worth extending[...]‚Äù[line_break_token]__Response__: Thanks for pointing out the relations to game theory and dynamic distillation.	B-Reply	B-4	Reply	20544
Previous drafts did briefly discuss the relation to evolutionary algorithms, but we ended up cutting that discussion to help meet the page limit.	I-Reply	I-4	Reply	20544
We will add these changes as space allows.	I-Reply	I-4	Reply	20544
[line_break_token][line_break_token]__Commen (qualitative figure clarification)__: ‚ÄúI had some difficulties in understanding Fig4, and the final-take away correctly.	O	O	Reply	20544
Would it be possible to give me one or two examples to correctly parse the table?	O	O	Reply	20544
More generally, I would recommend[...]‚Äù[line_break_token]__Response__: Thanks for the suggestion.	B-Reply	B-5	Reply	20544
We will add further explanation along the lines of what follows to the paper: Consider the top left example of Fig 4a.	I-Reply	I-5	Reply	20544
In this case A-bot is presented with a dashed blue circle.	I-Reply	I-5	Reply	20544
Due to space constraints, the figure leaves out what Q-bot says.	I-Reply	I-5	Reply	20544
A-bot‚Äôs first response is the symbol ‚Äú2‚Äù and A-bot‚Äôs 2nd response is the symbol ‚Äú0‚Äù.	I-Reply	I-5	Reply	20544
The checkmark indicates Q-bot guessed correctly.	I-Reply	I-5	Reply	20544
The solid green star is a shape in the test set (because the text is in bold).	I-Reply	I-5	Reply	20544
After the first generation (Fig 4a) Q-bot guessed some other shape.	I-Reply	I-5	Reply	20544
After subsequent generations (Figs 4b and 4c) Q-bot guessed it correctly, qualitatively demonstrating the improvement in test accuracy we see after many generations.	I-Reply	I-5	Reply	20544
We will clarify our explanation in the final version.	I-Reply	I-5	Reply	20544
[line_break_token][line_break_token]__Comment (meaning of D)__: ‚ÄúIn a similar spirit, it is hard to interpret the distance in Figure 3.‚Äù[line_break_token]__Response__: We only intended this metric to be used to compare models and we find it hard to ground in an absolute sense.	B-Reply	B-6	Reply	20544
The Single Agents Combined (roughly most different language) and Random Initialization (roughly most similar language) baselines can be compared to to get a sense of the range of performance for a particular model.	I-Reply	I-6	Reply	20544
[line_break_token][line_break_token]__Comment (raw results table)__: ‚Äúreproducible: having a final table in the array in the appendix could be very helpful‚Äù[line_break_token]__Response__: We will add this.	B-Reply	B-7	Reply	20544
[line_break_token][line_break_token]__Comment__: Number of seeds and average length.	O	O	Reply	20544
[line_break_token]__Response__: Dialogs all take 2 rounds and we use 4 different random seeds.	B-Reply	B-10	Reply	20544
This makes 16  runs per experiment because there are also 4 splits. (	I-Reply	I-10	Reply	20544
As we mention in sections 2 and 4)[line_break_token][line_break_token]__Comment__: ‚ÄúLast point... but it does not undermine the soundness of the experimental protocol!	O	O	Reply	20544
In the end, Is 25 accuracy points really compositionality?[...]‚Äù[line_break_token]__Response__: Our models are usually not completely compositional in the sense of 100% test accuracy, but we seem to agree that an intermediate sense of compositionality (between 0% and 100% test accuracy) is useful.	B-Reply	B-11	Reply	20544
What simple strategies should we consider in addition those we already reported?	I-Reply	I-11	Reply	20544
With respect to modalities, is the reviewer asking about single attribute accuracy (One as in the One vs Both accuracy from Kottur et al)?	I-Reply	I-11	Reply	20544
[line_break_token][line_break_token]__Comment (grounding)__ ‚Äú[...]I am not sure whether we can speak of grounded language here[...]‚Äù[line_break_token]__Response__: The observations made by A-bot are of simple attribute tokens fed through a learned embedding.	B-Reply	B-12	Reply	20544
They are not perceptual observations, so the language is not grounded in any perceptual environment in the normal sense.	I-Reply	I-12	Reply	20544
We think it is reasonable to say the language is grounded in these tokens, but agree the perspective is more controversial than the normal sense of grounding.	I-Reply	I-12	Reply	20544
We will make this discussion a bit more delicate	I-Reply	I-12	Reply	20544

This paper proposes a method to train graph neural networks on dense hardware such as TPUs.	O	O	Review	20504
The method is motivated by an observation that connections in graphs have locality in some datasets.	O	O	Review	20504
 Experiments show significant improvements in training speed compared to single-GPU training.	O	O	Review	20504
[line_break_token][line_break_token]The overall score of this paper is slightly positive.	O	O	Review	20504
There is a certain demand to perform training on hardware targeted to dense computations.	O	O	Review	20504
Even though the applications of the proposed method is limited to data with low-bandwidth, the paper shows there are real applications of the method.	O	O	Review	20504
The effectiveness of the proposed method is well-supported by the experiments.	O	O	Review	20504
[line_break_token][line_break_token]Major comments:[line_break_token]Comparisons with single-GPU training can be unfair.	B-Review	B-1	Review	20504
The method in Ma et al (2018) is indeed not easy to scale many GPUs because their target is processing extremely large graphs in parallel.	I-Review	I-1	Review	20504
Since the experiments in the submitted paper use relatively small graphs that fit in a single GPU memory, it will not be so challenging to scale many GPUs.	I-Review	I-1	Review	20504
At least, it is recommended to compare the results with training on several GPUs using data-parallel execution implemented in TensorFlow (or any other suitable frameworks).	I-Review	I-1	Review	20504
If it is difficult, please provide more specific reasons why it is challenging to perform multi-GPU training.	I-Review	I-1	Review	20504
hanks for your encouraging review!	O	O	Reply	20504
[line_break_token][line_break_token]We don't claim that it is impossible to match our training speeds using a large number of GPUs, but we are not aware of any work that has successfully done so.	B-Reply	B-1	Reply	20504
Our claim in this regard is simply that we have achieved training speeds that are far better than any existing results.	I-Reply	I-1	Reply	20504
While we agree Ma et al [2018] focus on larger graphs, we do not think all the challenges they encounter could be totally avoided on the Allamanis et al [2018] dataset that we use.	I-Reply	I-1	Reply	20504
For example, we believe the challenges related to shared PCIe interconnect [Ma et al 2018, Sec.	I-Reply	I-1	Reply	20504
6.3] would still persist.	I-Reply	I-1	Reply	20504
[line_break_token][line_break_token]We reported single GPU training times to establish that training the model to state of the art accuracy takes a reasonable amount of time.	I-Reply	I-1	Reply	20504
This helps contextualize the results we get on multi-TPU training.	I-Reply	I-1	Reply	20504
[line_break_token][line_break_token]We'd like to reiterate that before this work, it was not clear that it would be possible to use dense hardware to train sparse GNNs in any reasonable timeframe at all, because the hardware is very specialized to fixed-size dense computation, and a naive densification of large graphs isn't feasible.	I-Reply	I-1	Reply	20504
Our results showing that it's possible are valuable because this style of dense hardware is becoming increasingly prevalent as hardware becomes more specialized to matrix multiply-based workloads.	I-Reply	I-1	Reply	20504
Since the presented techniques did allow us to train on TPUs, we exploited the ease of scaling up to 512 cores (with TPUs it is a matter of changing a single parameter) in order to report results from large-batch training of sparse GGNNs, and we also pointed out the fast training time one can achieve this way	I-Reply	I-1	Reply	20504

This paper fits models to spike trains of retinal ganglion cells that are driven by natural images.	O	O	Review	185
I think the title should thus include the word ‚Äúactivity‚Äù at the end for otherwise it is actually formally incorrect.	B-Review	B-1	Review	185
[line_break_token][line_break_token]Anyhow, this paper proposes more specifically a recurrent network for this time series prediction and compares it to what seems to be the previous approach of a generalized linear model.	O	O	Review	185
Overall the stated paradigm is that when one can predict the spikes well then one can look into the model and learn how nature does it.	O	O	Review	185
[line_break_token][line_break_token]In general the paper sounds plausible, though I am not convinced that I learned a lot.	O	O	Review	185
The results in figure 2 show that the RNN model can predict the spikes a bit better.	B-Review	B-2	Review	185
So this is nice.	I-Review	I-2	Review	185
But now what?	I-Review	I-2	Review	185
You have shown that a more complicated model can produce better fits to the data, though there are of course still some variations to the real data.	I-Review	I-2	Review	185
Your initial outline was that a better predictive model helps you to better understand the neural processing in the retina.	I-Review	I-2	Review	185
So tell us what you learned.	I-Review	I-2	Review	185
I am not a specialist of the retina, but I know that there are several layers and recurrencies in the retina, so I am not so surprised that the new model is better than the GLM.	I-Review	I-2	Review	185
[line_break_token][line_break_token]It seems that more complicated recurrent models such as LSTM do not improve the performance according to a statement in the paper.	B-Review	B-3	Review	185
However, comparisons on this level are also difficult as a more complex models needs more data.	I-Review	I-3	Review	185
Hence, I would actually expect that more layers and even a more detailed model of the retina could eventually improve the prediction even further.	I-Review	I-3	Review	185
[line_break_token]I was also a bit puzzled that all the neurons in the network share all the same parameters (weights).	B-Review	B-4	Review	185
While the results show that these simplified models can capture a lot of the spike train characteristics, couldn‚Äôt a model with free parameters eventually outperform this one (with correspondingly more training data)?	I-Review	I-4	Review	185
[line_break_token]	O	O	Review	185
Thanks for taking the time to review our manuscript.	O	O	Reply	185
We will change the title as suggested.	B-Reply	B-1	Reply	185
We think, as other reviewers have mentioned, that this work is exciting because it introduces the idea that deep neural networks can be used in a neural modeling context with limited experimental data.	I-Reply	I-1	Reply	185
In particular, the framework we introduced for sharing information across neurons allows us to fit richer models given less data, and we believe this will be a powerful approach for modeling data from a number of other brain areas - most of which are much less studied / understood than the retina.	I-Reply	I-1	Reply	185
[line_break_token][line_break_token]Yes, a model with free parameters or more complicated structure could eventually outperform the shared model with enough training data but there are real biological and experimental limitations to the amount of data one can collect in these experiments and more broadly in most neuroscience experiments.	B-Reply	B-2	Reply	185
[line_break_token][line_break_token]We also believe we have taken important first steps to understanding the model improvement through model comparisons.	B-Reply	B-3	Reply	185
Whether the gap between linear-nonlinear model performance and optimal performance could be explained by a combination of  long-range spatial interactions and spatial and temporal nonlinearities might seem simple, but it is an important question in the field that has been difficult to address.	I-Reply	I-3	Reply	185
 We showed that the former is not true (at least up to the level of RNN performance) and that both spatial nonlinearities and nonlinear temporal processing are important.	I-Reply	I-3	Reply	185
These results can guide future research and experiments and further demonstrate the utility of our approach.	I-Reply	I-3	Reply	185
 This is a first step: in future work, we plan to further interrogate the RNN models to understand more specifically what information they are capturing.	I-Reply	I-3	Reply	185
As noted above, we also plan to apply this framework to non-retinal neurons where there are larger gaps between what current models capture and the optimal predictions.	B-Reply	B-4	Reply	185
In these systems, there is more room for improvement and more basic questions can be answered using our approach.	I-Reply	I-4	Reply	185

This paper studies multi-task learning (MTL) from the deep learning perspective where a number of layers are shared between tasks followed by specific heads for each task.	O	O	Review	20502
One of the main challenges in this problem is to decide the best configuration among a large number of possible ones (e.g., the number of layers , number of neurons, when to stop the shared part of the network).	O	O	Review	20502
In this paper, the authors fix the network architecture, and learn which filters (among the already learned ones) should be dedicated to (and hence fine-tuned for) a specific, and which ones should be shared between multiple tasks.	O	O	Review	20502
[line_break_token][line_break_token]Instead of deciding on other hyper-parameters such as the number of layers, the authors chose to study how to efficiently share the capacity of the network: to decide which filters should be used for which tasks, and which filters should be shared between tasks.	O	O	Review	20502
[line_break_token]Specifically, this is controlled by task specific binary vectors which get multiplied with feature activations for each task, hence blocking or allowing the signal to pass for a specific filter.	O	O	Review	20502
In addition, they define a different set of binary vectors for the foreground and background passes.	O	O	Review	20502
This allows simpler tasks to benefit from features learnt from more complicated tasks such as ImageNet classification while avoiding ‚Äòcatastrophic forgetting‚Äô at the same time.	O	O	Review	20502
[line_break_token][line_break_token]Moreover, the authors develop a simple yet elegant strategy to reduce their parameter search space (by using the matrix P which controls the percentage of filters used per task + the percentage of filters shared between each pair of tasks) and quickly evaluate the performance of each configuration (using distillation).	O	O	Review	20502
The advantages of these approaches are well discussed and validated quantitatively.	O	O	Review	20502
[line_break_token][line_break_token]The paper is well written and the approach itself appears to be sound and it led to improvement over independent task estimator.	O	O	Review	20502
 However, I am mostly concerned about the experimental setting: there are no comparisons with any other MTL algorithm.	B-Review	B-2	Review	20502
[line_break_token][line_break_token]The authors perform a search over the matrix P, which is similar to neural architecture search over the entire possible ways of sharing the capacity of a network.	I-Review	I-2	Review	20502
This could potentially lead to improvement beyond multi-task learning.	I-Review	I-2	Review	20502
Experimental comparison on this could be provided.	I-Review	I-2	Review	20502
[line_break_token]I think the paper will make a strong case if it is compared with existing deep MTL algorithms including [Misra et al: Cross-stitch networks for multi-task learning]. In addition, the network seems to share a similar spirit with [Mallya et al: PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning], in that they also share the capacity of the network between tasks, and hence a comparison here seems reasonable.	B-Review	B-1	Review	20502
[line_break_token][line_break_token]Overall, I think this paper makes a borderline case.	O	O	Review	20502
[line_break_token][line_break_token]Other comments: [line_break_token]In the supplementary material, providing a detailed description of the algorithm (e.g., pseudo code and an accompanying discussion) that calculates the matrices M from P could help reproduce and build upon the experiments reported in the paper.	B-Review	B-3	Review	20502
I wonder if M is uniquely defined from M.	I-Review	I-3	Review	20502
hank you for all of your comments and taking the time to review.	O	O	Reply	20502
[line_break_token][line_break_token]Cross-stitch networks and PackNet would make for interesting comparisons.	B-Reply	B-1	Reply	20502
While we do not have experiments to compare to these methods, it is worth noting some differences and advantages that our proposed method has to offer:[line_break_token]- Cross-stitch networks calculate a linear combination of activations across a parallel set of layers.	I-Reply	I-1	Reply	20502
Thus, the full model is required to compute the activation for an individual task, and computation grows as a function of the number of tasks.	I-Reply	I-1	Reply	20502
Our work allows pruning down to what is needed for an individual task.	I-Reply	I-1	Reply	20502
[line_break_token]- PackNet also does pruning, but does so by iteratively pruning and retraining a model for each new task.	I-Reply	I-1	Reply	20502
This raises challenges that do not occur in our work.	I-Reply	I-1	Reply	20502
The amount of the network available to be retrained drops as each new task is added.	I-Reply	I-1	Reply	20502
Furthermore, the order in which tasks are trained plays a significant role in final performance.	I-Reply	I-1	Reply	20502
As seen in their paper, accuracy drops by a couple percentage points for a task if it is added second instead of first, and a couple more if added third instead of second.	I-Reply	I-1	Reply	20502
It is unclear how well this would scale to a large number of tasks, and how much capacity remains in the network for each successive retraining step.	I-Reply	I-1	Reply	20502
[line_break_token][line_break_token]For comparison to other MTL algorithms, here we report the test performance of our method which allows a comparison to two recent works that have evaluated on Visual Decathlon.	B-Reply	B-2	Reply	20502
For context, these methods work by freezing an ImageNet model and adding additional layers for each task to augment intermediate activations.	I-Reply	I-2	Reply	20502
We see that our performance is comparable to these methods despite using less computation and parameters per task.	I-Reply	I-2	Reply	20502
Note, we use the ImageNet pretrained model provided by Rebuffi et al 2018, so our base architecture is identical to theirs.	I-Reply	I-2	Reply	20502
[line_break_token][line_break_token]Decathlon test set results:[line_break_token][line_break_token]      Airc,   C100, DPed, DTD,   GTSR, Flwr,  Oglt,   SVHN, UCF[line_break_token][1] 60.34, 82.12, 92.82, 55.53, 99.42, 81.41, 89.12, 96.55, 51.20[line_break_token][2] 64.11, 80.07, 91.29, 56.54, 98.46, 86.05, 89.67, 96.77, 49.38[line_break_token][3] 66.04, 81.86, 94.23, 57.82, 99.24, 85.74, 89.25, 96.62, 52.50[line_break_token][4] 69.31, 78.81, 91.13, 56.17, 99.14, 85.09, 89.85, 96.41, 51.52[line_break_token][line_break_token][1] separate networks finetuned for each task (as reported by Rebuffi et al 2018)[line_break_token][2] Rosenfeld et al 2017[line_break_token][3] Rebuffi et al 2018[line_break_token][4] ours[line_break_token]	O	O	Reply	20502

The paper presents a method to derive shaping rewards from a representation learnt with CPC.	O	O	Review	742
They propose learning a CPC representation from some random data and fix it.	O	O	Review	742
They assume exploration is not too difficult so that rewards are achievable without additional mechanisms.	O	O	Review	742
Once a reward is achieved they can compute the embedding of the corresponding state as a goal under the CPC learnt representation either directly ie.	O	O	Review	742
distance or via a clustering step.	O	O	Review	742
The paper is clearly written and presents a nice idea.	O	O	Review	742
The paper is correct and part of the approach seems novel.	O	O	Review	742
I find the analysis of the results well executed though I think that they should be improved for publication.	O	O	Review	742
[line_break_token][line_break_token]Major points: [line_break_token]* I think this is a valid contribution and it seems like something the RL audience might be interested in.	O	O	Review	742
[line_break_token]* I am very surprised that CPC does such a good job given that the main object for learning in CPC is the distribution of trajectories which should be quite different in random exploration and the optimal policy.	B-Review	B-1	Review	742
I presume this is because the environments are quite simple.	I-Review	I-1	Review	742
This issue is of interest to the readers so an example of a simple failure case should make that point.	I-Review	I-1	Review	742
[line_break_token]* Secondly, as nice as those embeddings in figure 5 look I wonder what happens in larger mazes with more structure i.e. somewhere where random walk will not be a uniform distribution and thus CPC will (most likely) not work as intended.	B-Review	B-2	Review	742
[line_break_token]* The clustering bonus how do you prevent it from staying at the edge of the goal region and deriving infinite rewards from that ?	B-Review	B-3	Review	742
[line_break_token]* Since these are not potential functions how do you prevent the rewards from biasing learning ?	B-Review	B-4	Review	742
Ng et al -- Policy invariance under reward transformations.	I-Review	I-4	Review	742
This should be discussed in the paper because it is of practical importance.	I-Review	I-4	Review	742
[line_break_token]* Contrastive learning has been used to find goal embeddings before Warde-Farley et al Unsupervised control through non-parametric discriminative rewards.	B-Review	B-5	Review	742
In that paper they don't need the CPC future state predictors but instead contrast the goal and the final state of the trajectory.	I-Review	I-5	Review	742
They use the resulting embedding to learn a reward function and ignore the extrinsic reward.	I-Review	I-5	Review	742
Interestingly, they show that the rewards can be learnt online (maybe ideas from that paper can be applied here).	I-Review	I-5	Review	742
[line_break_token]Minor points:[line_break_token]* please make legends on plots readable size.	B-Review	B-6	Review	742
[line_break_token]	O	O	Review	742
hank you very much for your insightful review.	O	O	Reply	742
Below are our responses to some of your concerns:[line_break_token][line_break_token]* The clustering bonus how do you prevent it from staying at the edge of the goal region and deriving infinite rewards from that ?	O	O	Reply	742
[line_break_token][line_break_token]The cluster reward is one time only.	B-Reply	B-3	Reply	742
With the cluster reward, the MDP is no longer time-homogeneous, so we convert it to a time-homogeneous MDP by treating entering the cluster as the first goal, and entering the environment goal as the second goal.	I-Reply	I-3	Reply	742
[line_break_token][line_break_token][line_break_token]* Contrastive learning has been used to find goal embeddings before Warde-Farley et al Unsupervised control through non-parametric discriminative rewards.	O	O	Reply	742
In that paper they don't need the CPC future state predictors but instead contrast the goal and the final state of the trajectory.	O	O	Reply	742
They use the resulting embedding to learn a reward function and ignore the extrinsic reward.	O	O	Reply	742
Interestingly, they show that the rewards can be learnt online (maybe ideas from that paper can be applied here).	O	O	Reply	742
[line_break_token][line_break_token]Although our approach is currently off-line, we discussed near the end of our paper that converting the scheme to an online fashion is straightforward.	B-Reply	B-5	Reply	742
Our goal in this paper is to focus on the properties of predictive embedding, and how they may contain information useful for RL; our contribution is largely on the finding that the predictive embedding flattens out the original state space and provide straightforward paths to any goal in the environment.	I-Reply	I-5	Reply	742
We believe an online approach would work with our scheme, but that was not the focus of our paper.	I-Reply	I-5	Reply	742
[line_break_token][line_break_token][line_break_token]* I am very surprised that CPC does such a good job given that the main object for learning in CPC is the distribution of trajectories which should be quite different in random exploration and the optimal policy.	O	O	Reply	742
I presume this is because the environments are quite simple.	O	O	Reply	742
This issue is of interest to the readers so an example of a simple failure case should make that point.	O	O	Reply	742
[line_break_token]* Secondly, as nice as those embeddings in figure 5 look I wonder what happens in larger mazes with more structure i.e. somewhere where random walk will not be a uniform distribution and thus CPC will (most likely) not work as intended.	O	O	Reply	742
[line_break_token][line_break_token]With our scheme, having good exploration of the state space is key to training good predictive embedding.	B-Reply	B-1	Reply	742
This is more challenging for more difficult environments such as a large maze.	I-Reply	I-1	Reply	742
We believe that the need for good exploration is not unique to our approach; our focus of the paper is to provide a method to leverage good exploration data without reward signals, and this method is to train predictive embedding.	I-Reply	I-1	Reply	742
[line_break_token][line_break_token]For environments where random exploration is not enough (including the AntMaze environment), we overcame the issue by a) sampling from a robust distribution of initial states in the simulator b) training goal-conditioned policies for pure exploration strategies.	I-Reply	I-1	Reply	742
These two approaches allowed us to collect good exploration data and train high-quality predictive embedding in more difficult environments [line_break_token][line_break_token][line_break_token]* Since these are not potential functions how do you prevent the rewards from biasing learning ?	O	O	Reply	742
Ng et al -- Policy invariance under reward transformations.	O	O	Reply	742
This should be discussed in the paper because it is of practical importance.	O	O	Reply	742
[line_break_token][line_break_token]A rigorous investigation of the mathematical properties of the latent space is out of the scope of this applicative paper.	B-Reply	B-4	Reply	742
From an empirical perspective, however, the ability for an agent to learn an optimal policy in various experimental settings with our scheme reflect that the negative distance scheme is likely a potential function.	I-Reply	I-4	Reply	742
Ultimately, this depends on whether the latent space induced by the encoder preserves the metric property of the original state space, and one could train an invertible map to enforce this.	I-Reply	I-4	Reply	742

This paper is technically sound.	O	O	Review	287
It highlights well the strengths and weaknesses of the proposed simplified model.	O	O	Review	287
[line_break_token][line_break_token]In terms of impact, its novelty is limited, in the sense that the authors did seemingly the right thing and obtained the expected outcomes.	O	O	Review	287
The idea of modeling deep learning computation is not in itself particularly novel.	O	O	Review	287
As a companion paper to an open source release of the model, it would meet my bar of acceptance in the same vein as a paper describing a novel dataset, which might not provide groundbreaking insights, yet be generally useful to the community.	B-Review	B-1	Review	287
[line_break_token][line_break_token]In the absence of released code, even if the authors promise to release it soon, I am more ambivalent, since that's where all the value lies.	B-Review	B-2	Review	287
It would also be a different story if the authors had been able to use this framework to make novel architectural decisions that improved training scalability in some way, and incorporated such new insights in the paper.	I-Review	I-2	Review	287
[line_break_token][line_break_token]UPDATED: code is now available.	O	O	Review	287
Revised review accordingly.	O	O	Review	287
As a follow-up to the previous response, we have release a live demo at <a href="https://talwalkarlab.github.io/paleo/." target="_blank" rel="nofollow">https://talwalkarlab.github.io/paleo/.</a>[line_break_token]Notably, we added a cost estimation feature that predicts dollar costs on AWS instances.	O	O	Reply	287
[line_break_token][line_break_token]The current interface provides a predefined set of configurations and works with data parallelism.	B-Reply	B-2	Reply	287
We will allow users to upload customized networks and model splits in the coming releases of the interface; although core implementations are already include in the open-sourced repository	I-Reply	I-2	Reply	287

The paper is well written and structured, presenting the problem clearly and accurately.	O	O	Review	387
It contains considerable relevant references and enough background knowledge.	O	O	Review	387
It nicely motivates the proposed approach, locates the contributions in the state-of-the-art and reviews related work.	O	O	Review	387
It is also very honest in terms of how it differs on the technical level from existing approaches.	O	O	Review	387
[line_break_token]The paper presents interesting and novel findings to further state-of-the-art‚Äôs understanding on how language concepts are represented in the intermediate layers of deep convolutional neural networks, showing that channels in convolutional representations are selectively sensitive to specific natural language concepts.	O	O	Review	387
It also nicely discusses how concepts granularity evolves with layers‚Äô deepness in the case of natural language tasks.	O	O	Review	387
[line_break_token]What I am missing, however, is an empirical study of concepts coverage over multiple layers, studying the multiple occurrences of single concepts at different layers, and a deeper dive on the rather noisy elements of natural language and the layers‚Äô activation dynamics towards such elements.	B-Review	B-1	Review	387
[line_break_token]Overall, however, the ideas presented in the paper are interesting and original, and the experimental section is convincing.	O	O	Review	387
My recommendation is to accept this submission.	O	O	Review	387
[line_break_token]	O	O	Review	387
[line_break_token]We thank Reviewer 1 for positive and constructive review.	O	O	Reply	387
Please see our revisions in blue font to check how our paper is updated.	O	O	Reply	387
[line_break_token][line_break_token]1.	O	O	Reply	387
Concepts coverage over multiple layers[line_break_token]===================================[line_break_token]We plot the number of unique concepts per layer in Figure 13.	B-Reply	B-1	Reply	387
In all datasets, the number of unique concepts increases with the layer depth, which implies that the units in a deeper layer represent more diverse concepts.	I-Reply	I-1	Reply	387
[line_break_token][line_break_token][line_break_token]2.	O	O	Reply	387
Multiple occurrences of each concept at different layers[line_break_token]===================================[line_break_token]We add Figure 16 to Appendix H to show how many layers each concept appears.	B-Reply	B-2	Reply	387
Although task and data specific concepts emerge at different layers, there is no strong pattern between the concepts and their occurrences at multiple layers.	I-Reply	I-2	Reply	387
[line_break_token][line_break_token][line_break_token]3.	B-Reply	B-1	Reply	387
The layers‚Äô activation dynamics towards noisy elements[line_break_token]===================================[line_break_token]It is an interesting suggestion to investigate how unit activations vary with noisy elements of natural language such as synthetic adversarial examples or natural noise (Belinkov et al[1]) that could attack the model.	B-Reply	B-3	Reply	387
Since we discover some units that capture the abstract semantics rather than low-level text patterns in Section 4.2, we expect that those units will be not sensitive to such noisy transformation of the concepts.	I-Reply	I-3	Reply	387
More thorough analysis for this topic will be one of our emergent future works.	I-Reply	I-3	Reply	387
[line_break_token][line_break_token]References[line_break_token]===================================[line_break_token][1] Yonatan Belinkov et al Synthetic and Natural Noise Both Break Neural Machine Translation (ICLR 2018)	O	O	Reply	387

This paper presents a new semi-supervised method for bilingual dictionary induction and proposes a new metric to measure isometry between embedding spaces.	O	O	Review	793
[line_break_token][line_break_token]Pros:[line_break_token]- The paper proposes to use a new metric, the Gromov-Hausdorff distance to measure how isometric two word embedding spaces are.	O	O	Review	793
[line_break_token]- The toy example is useful for motivating the use case of the method.	O	O	Review	793
[line_break_token]- The approach achieves convincing results on the dataset.	O	O	Review	793
[line_break_token][line_break_token]Cons:[line_break_token]- Beyond the isometry metric, the main innovation as far as I can see seems to be the hubness filtering, which is incremental and not ablated, so it is not clear how much improvement it yields.	B-Review	B-1	Review	793
The weak orthogonality constraint has already been used in [2].[line_break_token]- It is not clear to me what the proposed metric adds beyond the eigenvector similarity metric proposed in [1]. The authors should compare to this metric at least.	B-Review	B-2	Review	793
[line_break_token]- The authors might want to add the results of [3] for an up-to-date comparison.	B-Review	B-3	Review	793
[line_break_token][line_break_token][1] S√∏gaard, A., Ruder, S., & Vuliƒá, I. (2018).	O	O	Review	793
On the Limitations of Unsupervised Bilingual Dictionary Induction.	O	O	Review	793
In Proceedings of ACL 2018.	O	O	Review	793
[line_break_token][2] Zhang, M., Liu, Y., Luan, H., & Sun, M. (2017).	O	O	Review	793
Adversarial Training for Unsupervised Bilingual Lexicon Induction.	O	O	Review	793
In Proceedings of ACL.	O	O	Review	793
[line_break_token][3] Artetxe, M., Labaka, G., & Agirre, E. (2018).	O	O	Review	793
A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings.	O	O	Review	793
In Proceedings of ACL 2018.	O	O	Review	793
Thank you for your feedback and insightful comments.	O	O	Reply	793
Below we try and address your comments individually:[line_break_token][line_break_token]> Beyond the isometry metric, the main innovation as far as I can see seems to be the hubness filtering, which is incremental and not ablated, so it is not clear how much improvement it yields.	O	O	Reply	793
The weak orthogonality constraint has already been used in [s 2].[line_break_token][line_break_token]In addition to the Gromov-Hausdorff metric, our joint framework is a novel contribution.	B-Reply	B-1	Reply	793
We show that it improves over both its corresponding supervised and unsupervised counterparts for two instantiations of our framework (BLISS(M) based on MUSE(S), and BLISS(R) based on RCSLS, incorporating reviewer feedback), which in turn illustrates its efficacy, with  BLISS(R) obtaining state-of-the-art results (to the best of our knowledge).	I-Reply	I-1	Reply	793
[line_break_token][line_break_token]> It is not clear to me what the proposed metric adds beyond the eigenvector similarity metric proposed in [1]. The authors should compare to this metric at least.\[line_break_token][line_break_token]Thank you for pointing this reference out; we have updated our paper to include the metric from [1] (Table 2).	B-Reply	B-2	Reply	793
From the Table, we observe that our method correlates better than the eigenvector similarity metric.	I-Reply	I-2	Reply	793
[line_break_token][line_break_token]> The authors might want to add the results of [3] for an up-to-date comparison.	O	O	Reply	793
[line_break_token][line_break_token]We have incorporated this baseline in our latest draft, along with an accompanying discussion (Section 4.2.4).	B-Reply	B-3	Reply	793

This paper studies the impact of angle bias on learning deep neural networks, where angle bias is defined to be the expected value of the inner product of a random vectors (e.g., an activation vector) and a given vector (e.g., a weight vector).	O	O	Review	288
 The angle bias is non-zero as long as the random vector is non-zero in expectation and the given vector is non-zero.	O	O	Review	288
 This suggests that the some of the units in a deep neural network have large values (either positive or negative) regardless of the input, which in turn suggests vanishing gradient.	O	O	Review	288
 The proposed solution to angle bias is to place a linear constraint such that the sum of the weight becomes zero.	O	O	Review	288
 Although this does not rule out angle bias in general, it does so for the very special case where the expected value of the random vector is a vector consisting of a common value.	O	O	Review	288
 Nevertheless, numerical experiments suggest that the proposed approach can effectively reduce angle bias and improves the accuracy for training data in the CIFAR-10 task.	O	O	Review	288
 Test accuracy is not improved, however.	O	O	Review	288
[line_break_token][line_break_token]Overall, this paper introduces an interesting phenomenon that is worth studying to gain insights into how to train deep neural networks, but the results are rather preliminary both on theory and experiments.	O	O	Review	288
[line_break_token][line_break_token]On the theoretical side, the linearly constrained weights are only shown to work for a very special case.	O	O	Review	288
 There can be many other approaches to mitigate the impact of angle bias.	O	O	Review	288
 For example, how about scaling each variable in a way that the mean becomes zero, instead of scaling it into [-1,+1] as is done in the experiments?	B-Review	B-1	Review	288
 When the mean of input is zero, there is no angle bias in the first layer.	I-Review	I-1	Review	288
 Also, what about if we include the bias term so that b + w a is the preactivation value?	B-Review	B-2	Review	288
[line_break_token][line_break_token]On the experimental side, it has been shown that linearly constrained weights can mitigate the impact of angle bias on vanishing gradient and can reduce the training error, but the test error is unfortunately increased for the particular task with the particular dataset in the experiments.	B-Review	B-3	Review	288
 It would be desirable to identify specific tasks and datasets for which the proposed approach outperforms baselines.	I-Review	I-3	Review	288
 It is intuitively expected that the proposed approach has some merit in some domains, but it is unclear exactly when and where it is.	I-Review	I-3	Review	288
[line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]In Section 2.2, is Layer 1 the input layer or the next?	B-Review	B-4	Review	288
We thank the reviewer for the insightful comments on our paper.	O	O	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 1: How about scaling each variable in a way that the mean becomes zero, instead of[line_break_token]scaling it into [-1,+1] as is done in the experiments?	O	O	Reply	288
 When the mean of input is zero,[line_break_token]there is no angle bias in the first layer.	O	O	Reply	288
[line_break_token][line_break_token]Response 1: We did experiments with CIFAR-10, in which each variable was scaled to have[line_break_token]zero mean.	B-Reply	B-1	Reply	288
As the reviewer pointed out, we have no angle bias in the first layer (the layer[line_break_token]after the input layer) in this case.	I-Reply	I-1	Reply	288
[line_break_token]However, the training of MLPs then got harder and the test accuracy was very row, even if[line_break_token]we applied either LCW or batch-normalization.	I-Reply	I-1	Reply	288
We think this is because normalizing each pixel[line_break_token]of images in CIFAR-10 ruined the relationship between pixels.	I-Reply	I-1	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 2: What about if we include the bias term so that b + w a is the preactivation value?	O	O	Reply	288
[line_break_token][line_break_token]Response 2: We have already included the bias term in our original experiment, although[line_break_token]it was omitted in Equation 2 for simplicity.	B-Reply	B-2	Reply	288
We have modified Equation 2 to include[line_break_token]the bias term for clarity in the revised manuscript.	I-Reply	I-2	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 3: It would be desirable to identify specific tasks and datasets for which[line_break_token]the proposed approach outperforms baselines.	O	O	Reply	288
It is intuitively expected that the proposed[line_break_token]approach has some merit in some domains, but it is unclear exactly when and where it is.	O	O	Reply	288
[line_break_token][line_break_token]Response 3: We did additional experiments with the SVHN dataset and the CIFAR-100 dataset,[line_break_token]which are reported in the appendix B of the revised manuscript.	B-Reply	B-3	Reply	288
The peak value of the test[line_break_token]accuracy of the proposed method was comparable to that of batch-normalization when the MLP[line_break_token]has 5 layers or 50 layers, as shown in Figure 12 (f) and (i), Figure 14 (f) and (i), and[line_break_token]Figure 15 (f) and (i).	I-Reply	I-3	Reply	288
[line_break_token]An interesting point is that the peak of the test accuracy is around 20 epochs in the[line_break_token]proposed method.	I-Reply	I-3	Reply	288
However, we have no clear explanation for this finding.	I-Reply	I-3	Reply	288
We have added[line_break_token]a description on this point in the third paragraph of Section 5.1 in the revised manuscript.	I-Reply	I-3	Reply	288
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 4: In Section 2.2, is Layer 1 the input layer or the next?	O	O	Reply	288
[line_break_token][line_break_token]Response 4: Layer 1 is the layer next to the input layer.	B-Reply	B-4	Reply	288
We have added an explanation of[line_break_token]these points to the first paragraph of Section 2.2.1 in the revised version.	I-Reply	I-4	Reply	288

This is an interesting application of DL in rhythm-based video games that learns two sub-tasks: step placement from raw audio, and step selection from ground truth placement.	O	O	Review	88
This seems to be a work in progress, as it doesn't address the complete end-to-end problem yet.	B-Review	B-1	Review	88
[line_break_token][line_break_token]Some key information is missing in the paper.	B-Review	B-2	Review	88
For example, the authors observed that data augmentation and inclusion of manual features (beta phase etc) significantly improved the performance but there is no comparison results given.	I-Review	I-2	Review	88
Have the authors tried to learn such manual features from data?	I-Review	I-2	Review	88
[line_break_token][line_break_token]Also there is a clear performance gap between Fraxtill and ITG, particularly on the step selection task under the best model LSTM64.	B-Review	B-3	Review	88
Also,  there is little difference between LSTM5 and LSTM64 on ITG while the improvement is more clear on Fraxtill.	I-Review	I-3	Review	88
What are the reasons behind these observations?	I-Review	I-3	Review	88
Dear reviewer, [line_break_token][line_break_token]Thank you for the thoughtful review.	O	O	Reply	88
We omitted some of these details to accommodate the extended abstract length.	O	O	Reply	88
[line_break_token][line_break_token]An unconditioned LSTM64 model trained on non-augmented Fraxtil data achieved a perplexity of 3.53 while the same unconditioned LSTM64 model trained on augmented data achieved a perplexity of 3.35.	B-Reply	B-3	Reply	88
These scores are significantly worse than the 3.01 perplexity achieved by the beat-conditioned LSTM64 model trained on augmented data.	O	O	Reply	88
[line_break_token][line_break_token]We believe the performance gap (on step selection) between the two datasets can be attributed to the fact that Fraxtil is a single-author dataset while ITG contains annotations from 9 choreographers.	B-Reply	B-2	Reply	88
Author style tends to be distinctive and thus the single-author sequences are more predictable.	I-Reply	I-2	Reply	88
[line_break_token][line_break_token]We have updated the workshop draft to address these points.	O	O	Reply	88

This paper applies the Gumbel-softmax to optimizing task-specific routing in deep multi-task learning.	O	O	Review	20282
Experiments demonstrate improvements of the method over no sharing or full sharing, and it is used to achieve s-o-t-a results in the Omniglot MTL benchmark.	O	O	Review	20282
[line_break_token][line_break_token]Although the end results are good, and the approach is well-motivated, I am leaning to reject, because the experiments have not made clear when the method works and how it behaves.	O	O	Review	20282
The improvements over the full-sharing baselines appear fairly small, and in the analysis it appears the model is mainly discarding unneeded pooling layers.	B-Review	B-3	Review	20282
Is there some real task-specific routing that the method is able to take advantage of?	B-Review	B-1	Review	20282
Maybe an experiment where full-sharing is detrimental, i.e., because there are some highly unrelated tasks, would help to highlight how the approach selects appropriate module subsets for each task.	I-Review	I-1	Review	20282
E.g., what are the routing patterns in Section 6.1 that are the same within each pair of MNIST tasks, but different across task pairs?	I-Review	I-1	Review	20282
Is there a way to visualize differences between routing of different Omniglot tasks?	B-Review	B-2	Review	20282
[line_break_token][line_break_token]Similarly, the experiment in Section 2 is interesting, but the conclusion that negative transfer exists is not novel.	B-Review	B-4	Review	20282
Is there a way to include the Gumbel approach in these synthetic experiments to show that it addresses this issue?	I-Review	I-4	Review	20282
E.g., something like the result in A.3 could be promoted to Section 2.	I-Review	I-4	Review	20282
More compelling synthetic datasets could be generated by the method in A.1.	I-Review	I-4	Review	20282
for the case where tasks are somewhat related, in which case we can actually see if how the sharing occurs.	I-Review	I-4	Review	20282
Could Gumbel see a bigger boost in these synthetic experiments if training data were limited and generalization was tested instead of training loss?	I-Review	I-4	Review	20282
[line_break_token]	O	O	Review	20282
e thank the reviewer for the valuable comments.	O	O	Reply	20282
We are open to any further suggestions for improving our paper.	O	O	Reply	20282
Our responses to specific comments are provided below.	O	O	Reply	20282
[line_break_token][line_break_token]1) Routing patterns for Omniglot[line_break_token][line_break_token]For the Omniglot experiment, it was indeed the case that discarding unwanted pooling layers was one of the clearest trends learned by our method.	B-Reply	B-2	Reply	20282
However, as pointed out in the paper, there were still important differences in allocation patterns corresponding to different tasks.	I-Reply	I-2	Reply	20282
Specifically, we grouped the tasks based on the pattern (i.e. the concatenation of all binary routing matrices), and we found around 10 groups on average, while the number of tasks was 20.	I-Reply	I-2	Reply	20282
Notice that differences in patterns may result in arbitrarily large differences in outputs.	I-Reply	I-2	Reply	20282
[line_break_token][line_break_token]2) Routing patterns for MNIST[line_break_token][line_break_token]In the case of no budget penalty, the routing commonly converged to the pattern of the following form: one pair of MNIST tasks would use all components (12 components, since there were 3 layers of 4 components each), while the other pair would use all but one component (11 components).	B-Reply	B-1	Reply	20282
Since MNIST and MNIST-rot are still highly related, this shows that the model preferred almost full sharing, except for dropping a single connection to allow for processing the first pair of tasks differently than the second.	I-Reply	I-1	Reply	20282
[line_break_token][line_break_token]With budget penalty enabled, each pair would usually use three out of four components in each layer, exactly matching the budget of 75% active connections.	I-Reply	I-1	Reply	20282
Note that the resulting accuracy was the same with and without the budget penalty.	I-Reply	I-1	Reply	20282
[line_break_token][line_break_token]3) Magnitude of gains on Omniglot over the full-sharing baseline[line_break_token][line_break_token]Even though the improvement on top of full sharing for Omniglot is not very large, full sharing is actually a pretty strong baseline; even stronger than previous SotA based on a sparse Mixture-of-Experts (P. Ramachandran et al, ICLR 2019).	B-Reply	B-3	Reply	20282
Our interpretation of this result is that in the case of limited data (Omniglot has very few samples per class), it is hard to learn task-specific routing without incurring an accuracy drop due to optimization difficulties.	I-Reply	I-3	Reply	20282
Since our routing method managed to learn task-conditioned routing and improve the accuracy, while the methods from previous works did not, we consider our Omniglot result to be a strong one.	I-Reply	I-3	Reply	20282
[line_break_token][line_break_token]4) Other comments[line_break_token][line_break_token]We are happy to move the result from Appendix A.3 to Section 2, if that helps the paper.	B-Reply	B-4	Reply	20282
[line_break_token][line_break_token]Also, the reviewer proposed considering the case of limited data and generalization.	I-Reply	I-4	Reply	20282
However, note that Omniglot might already be seen as such a case, and our experiments show that Gumbel-Matrix routing does produce solutions that generalize well	I-Reply	I-4	Reply	20282

This paper proposes to use TensorTrain representation to transform discrete tokens/symbols to its vector representation.	O	O	Review	681
[line_break_token]Since neural networks can only work with numerical numbers, in many NLP tasks, where the raw inputs are in the discrete token/symbol format, the popular technique is to use "embedding" matrices to find a vector representation of those inputs.	O	O	Review	681
[line_break_token][line_break_token]As the authors point out, the embedding matrices usually require huge number of parameters, since it assigns one vector for each input token for one embedding vector, but to attain a competitive performance in the real world applications, we need to use large number of embedding vectors, which results in a large number of parameters in the neural networks.	O	O	Review	681
[line_break_token][line_break_token]The paper assumes that those embedding matrices can be compressed by assuming that the low-rank property of embedding matrices.	O	O	Review	681
I think this is a valid assumption in many cases, and the paper shows the performance degradation according to this assumption is relatively small compared to the gain, a dramatically reduced size of parameters in the embedding stage, is substantial.	O	O	Review	681
[line_break_token][line_break_token]I think the paper is well written and proposes a new direction to find a memory efficient representation of symbols.	O	O	Review	681
I am not sure the current initialization techniques, nor the training method in the paper are the right way to train a tensor train "embedding" but I expect that the authors would perform the follow up work on those topics.	B-Review	B-1	Review	681
hank you for reviewing the paper and providing a positive feedback to our work!	O	O	Reply	681
[line_break_token][line_break_token]Our current initialization scheme was inspired by the common way to initialize token embeddings from the literature [1], which does not take into account the factorizative nature of our layers.	B-Reply	B-1	Reply	681
For the experiments, we simply implemented TT-embedding and TT-softmax layers to be easily optimized along with other parameters in autodiff framework (PyTorch in our case).	I-Reply	I-1	Reply	681
However, we are also aware of more advanced optimization algorithms particularly suitable for tensor decompositions (see [2] for a brief overview).	I-Reply	I-1	Reply	681
There is indeed a room for improvements to our current practices of initializing and optimizing TT-embeddings which require further investigation.	I-Reply	I-1	Reply	681
[line_break_token][line_break_token][1] T. Kocmi, O. Bojar.	O	O	Reply	681
An Exploration of Word Embedding Initialization in Deep-Learning Tasks.	O	O	Reply	681
In ICON, 2017.	O	O	Reply	681
[line_break_token][2] A. Novikov, P. Izmailov, V. Khrulkov, M. Figurnov, I. Oseledets.	O	O	Reply	681
Tensor Train decomposition on TensorFlow (T3F).	O	O	Reply	681
On arxiv, 2018	O	O	Reply	681

This paper provides new insights on what is captured contextualized word embeddings by compiling a set of ‚Äúedge probing‚Äù tasks.	O	O	Review	439
 This is not the first paper to attempt this type of analysis, but the results seem pretty thorough and cover a wider range of tasks than some similar previous works.	O	O	Review	439
 The findings in this paper are very timely and relevant given the increasing usage of these types of embeddings.	O	O	Review	439
 I imagine that the edge probing tasks could be extended towards looking for other linguistic attributes getting encoded in these embeddings.	B-Review	B-4	Review	439
[line_break_token][line_break_token]Questions & other remarks:[line_break_token]-The discussion of the tables and graphs in the running text feels a bit condensed and at times unclear about which rows are being referred to.	B-Review	B-1	Review	439
[line_break_token]-In figures 2 & 3: what are the tinted areas around the lines signifying here?	O	O	Review	439
Standard deviation?	B-Review	B-2	Review	439
 Standard error?	I-Review	I-2	Review	439
 Confidence intervals?	I-Review	I-2	Review	439
[line_break_token]-It seems the orthonormal encoder actually outperforms the full elmo model with the learned weights on the Winograd Schema.	B-Review	B-3	Review	439
 Can the authors comment on this a bit more?	I-Review	I-3	Review	439
[line_break_token]	O	O	Review	439
Thank you for the review!	O	O	Reply	439
[line_break_token][line_break_token]We‚Äôre very interested in probing for other linguistic attributes - while we present a broad analysis in this paper, there‚Äôs certainly room to use edge probing to study more focused phenomena like PP attachment or ambiguities between specific semantic roles.	B-Reply	B-4	Reply	439
We use a standardized data format that makes it easy to add new tasks, and we hope that our code release will be a useful platform for this kind of analysis.	I-Reply	I-4	Reply	439
[line_break_token][line_break_token]We‚Äôll be sure to update the text to more clearly describe the tables.	B-Reply	B-1	Reply	439
[line_break_token][line_break_token]Whoops!	B-Reply	B-2	Reply	439
In Figure 2 and 3, the bars/bands are 95% confidence intervals calculated using the Normal approximation.	I-Reply	I-2	Reply	439
We wanted to emphasize that the SPR and Winograd datasets are quite small and that the differences between models are often not significant.	I-Reply	I-2	Reply	439
We‚Äôll add this to the caption in the final version	I-Reply	I-2	Reply	439

Summary: This paper attempts to better understand the notion of prototypes and in some sense create a taxonomy for characterizing various prototypicality metrics.	B-Review	B-7	Review	1493
While the idea of thinking about such a taxonomy is novel, I think the paper falls in clearly justifying certain design choices such as why are the properties outlined at the beginning of Section 2 desirable.	I-Review	I-7	Review	1493
I also felt that the paper is resorting to rather informal ways of describing various properties and metrics without precisely quantifying them.	I-Review	I-7	Review	1493
[line_break_token][line_break_token]Pros:[line_break_token]1.	O	O	Review	1493
Novel attempt at understanding prototypes.	O	O	Review	1493
Two specific contributions: a) outlining the properties desirable in prototypicality metrics b) proposing new prototypicality metrics and demonstrating the relevance of the various prototypicality metrics.	O	O	Review	1493
[line_break_token]2.	B-Review	B-3	Review	1493
Detailed experimental analysis along with some user studies[line_break_token][line_break_token]Cons:[line_break_token]1.	O	O	Review	1493
An important drawback of this paper is that the notion of prototype is not very clearly contextualized and explained.	B-Review	B-1	Review	1493
There is often a purpose associated with identifying prototypes - are we summarizing a dataset?	I-Review	I-1	Review	1493
are we thinking about helping humans understand the behavior of a specific learning model?	I-Review	I-1	Review	1493
Answers to these questions guide the process of choosing prototypes.	I-Review	I-1	Review	1493
However, this paper seems to approach the problem of choosing prototypes via the "one approach fits all" strategy which I am not sure is even possible.	I-Review	I-1	Review	1493
[line_break_token]2.	B-Review	B-3	Review	1493
The choice of desirable properties is not clearly justified (Beginning of Section 2).	B-Review	B-2	Review	1493
For instance, why should prototypes be independent of learning tasks?	I-Review	I-2	Review	1493
[line_break_token]3.	O	O	Review	1493
Lack of rigor in defining prototypicality metrics as well as properties in Section 2.	B-Review	B-3	Review	1493
For example, wouldn't it be possible to theoretically prove that the metrics outlined in Section 2 satisfy the desired properties?	I-Review	I-3	Review	1493
[line_break_token][line_break_token]Detailed Comments: [line_break_token]1.	O	O	Review	1493
I would strongly encourage the authors to illustrate using examples in the introduction the significance of finding prototypes.	B-Review	B-4	Review	1493
What are the end goals for which these prototypes would be used?	I-Review	I-4	Review	1493
Why do you think the metric for chooosing prototypes should be independent of the learning task or model?	I-Review	I-4	Review	1493
[line_break_token]2.	B-Review	B-3	Review	1493
Along the same lines as the comment above, please provide detailed justifications for the list of properties provided in the beginning of Section 2.	B-Review	B-5	Review	1493
It would be even better if you could formalize these a bit more.	I-Review	I-5	Review	1493
[line_break_token]3.	O	O	Review	1493
Would it be possible to theoretically show that the metrics defined in Section 2 satisfy any of the desirable properties highlighted in Section 2?	B-Review	B-6	Review	1493
We thank the reviewer for their very knowledgeable review.	O	O	Reply	1493
 It gave us new insights, and made us see how our paper could be read in a way that we did not anticipate.	O	O	Reply	1493
[line_break_token][line_break_token]In particular, we see how our writing may give the impression that we are trying to create a taxonomy of ‚Äúprototype definitions.	B-Reply	B-7	Reply	1493
‚Äù  That was not at all our intention, as we elaborate on below.	I-Reply	I-7	Reply	1493
 Instead, inspired by the metric of Stock & Cisse (2018), we were interested in what were the differences between the examples contained in the dataset (both training and testing)---when evaluated by that metric, or the other four metrics we came up with---and how those differences might shed light on aspects such hard-to-learn and inherently-ambiguous submodes, memorized exceptions, and other concerns of example data corpus construction and curation.	O	O	Reply	1493
[line_break_token][line_break_token]Below, we further respond to each of the reviewer‚Äôs comments:[line_break_token][line_break_token]> Summary: This paper attempts to better understand the notion of prototypes and in some sense create a taxonomy for characterizing various prototypicality metrics.	O	O	Reply	1493
While the idea of thinking about such a taxonomy is novel, I think the paper falls in clearly justifying certain design choices such as why are the properties outlined at the beginning of Section 2 desirable.	O	O	Reply	1493
I also felt that the paper is resorting to rather informal ways of describing various properties and metrics without precisely quantifying them.	O	O	Reply	1493
[line_break_token][line_break_token]We agree with the reviewer that it feels less-than-satisfactory to give such informal definitions for prototypes.	B-Reply	B-7	Reply	1493
 Indeed, this is how the list at the start of Section 2 came about: it is our own attempt at clarifying what we mean by ‚Äúprototypes.	I-Reply	I-7	Reply	1493
‚Äù Before doing this work, we had no concrete definition for what ‚Äúprototypes‚Äù actually were, whether they generally existed in data corpora for ML tasks, or---if they did---whether they corresponded to human intuition.	I-Reply	I-7	Reply	1493
Reading the existing literature on ‚Äúprototypes‚Äù in the ML literature didn‚Äôt surface any precise definition: we found only informal statements and rather subjective goals for each metric, whereas the mechanism of each metric was often clearly defined.	I-Reply	I-7	Reply	1493
 Hence, for our own benefit, and that of the readers, we felt it was worth re-stating the common understanding from the prototype literature (even though it was vague); while doing this, we also added a few properties that seemed obvious, and were supported by our experiments, such as those of the last bullet in the list.	I-Reply	I-7	Reply	1493
However, we do not see this list as a real contribution of our work, and its removal would not affect our results	I-Reply	I-7	Reply	1493

This paper introduces a new type of Graph Neural Network (GNN) that incorporates Feature-wise Linear Modulation (FiLM) layers.	O	O	Review	20181
Current GNNs update the target representations by aggregating information from neighbouring nodes without taking into the account the target node representation.	O	O	Review	20181
As graph networks might benefit from such target-source interactions, the current work proposes to use FiLM layers to let the target node modulate the source node representations.	O	O	Review	20181
The authors thoroughly evaluate this new architecture ‚Äî called GNN-FiLM‚Äî-on several graph benchmarks, including Citeseer, PPI, QM9, and VarMisuse.	O	O	Review	20181
The proposed network outperforms the other methods on QM9 and is on par on the other benchmarks.	O	O	Review	20181
[line_break_token][line_break_token]Strengths[line_break_token]- The literature review of existing work on GNN was a pleasure to read and provided a good motivation for the proposed GNN-FiLM architecture.	O	O	Review	20181
[line_break_token]- The authors put significant effort into reproducing other GNN baselines.	O	O	Review	20181
Perhaps the most surprising result of this work is that all GNNs perform remarkably similar (contrary to what previous work has reported)[line_break_token][line_break_token]Weaknesses[line_break_token]- There seems to be a much tighter relationship between GNN-FiLM and Gated GNNs than currently discussed.	B-Review	B-1	Review	20181
If you actually write down the equations of the recurrent cell in Eq 1), you‚Äôll notice that there are feature-wise interactions between the target node representations and the (sum of) source node representations.	I-Review	I-1	Review	20181
The paper should discuss in more depth what the exact differences are.	I-Review	I-1	Review	20181
Some visualizations would also help here.	I-Review	I-1	Review	20181
[line_break_token]- Related to the previous point, I‚Äôd like to see a bit more discussion on *why* tight interactions between target and source nodes are helpful.	B-Review	B-2	Review	20181
For example, one could perhaps provide a toy example for which that‚Äôs obviously the case.	I-Review	I-2	Review	20181
[line_break_token][line_break_token]All in all, I believe the ideas and results of this paper are promising but insufficient for publication in its current form.	O	O	Review	20181
The paper tries to communicate two messages: 1) a model paper arguing for GNN-FiLM, 2) an unbiased evaluation of existing GNN models, showing that their performance is surprisingly similar on a number of benchmarks (with equal hyperparameter search).	O	O	Review	20181
Both points are interesting but are not worked out sufficiently to pass the bar.	O	O	Review	20181
For 1), I‚Äôd like to see an in-depth discussion on the benefits of target-source interactions, providing more insights into why this might be beneficial.	B-Review	B-3	Review	20181
Your current experiments report very minimal gains for your proposed network, questioning why such interactions might be necessary in the first place.	I-Review	I-3	Review	20181
For 2), I‚Äôd suggest to rewrite the paper from a slightly different angle and add more graph benchmarks if available (disclaimer: I‚Äôm not in the graph network community, so I can‚Äôt fully evaluate how significant these results are)[line_break_token][line_break_token][line_break_token]Typos[line_break_token]‚Äî‚Äî-[line_break_token]Last paragraph of intro: ‚Äútwo two‚Äù - &gt; two[line_break_token][line_break_token]*EDIT[line_break_token]After reading the rebuttal and revised paper, I've updated my score to "Weak Accept".	O	O	Review	20181
The toy example and connection to GGNN are important additions which makes the paper more complete, though I believe there's room for further improvement here (see comments below).	O	O	Review	20181
All in all, I weakly recommend to accept the paper.	O	O	Review	20181
hank you for your kind (emergency?)	O	O	Reply	20181
review and engaging with this submission.	O	O	Reply	20181
[line_break_token][line_break_token]&gt; - There seems to be a much tighter relationship between GNN-FiLM and[line_break_token]&gt;   Gated GNNs than currently discussed.	O	O	Reply	20181
If you actually write down the[line_break_token]&gt;   equations of the recurrent cell  in Eq 1), you‚Äôll notice that there[line_break_token]&gt;   are feature-wise interactions between the target node representations[line_break_token]&gt;   and the (sum of) source node representations.	O	O	Reply	20181
[line_break_token][line_break_token]This is indeed true (for GRU/LSTM cells) and should maybe discussed in the paper in more depth, though it is a bit unclear where to best do this to not interrupt the flow of presentation.	B-Reply	B-1	Reply	20181
[line_break_token]The differences arise from the application of the gated cell after summation of incoming messages.	I-Reply	I-1	Reply	20181
Concretely, the "forgetting" of memories in a GRU/LSTM is similar to modulation of messages from the self-loop edges, and the gating of the cell input is similar to the modulation of incoming messages.	I-Reply	I-1	Reply	20181
However, as GNN-FiLM uses _different_ values for different edge types, the modulation is additionally dependent on the kind of relationship between nodes.	I-Reply	I-1	Reply	20181
In the case of a single edge type (+ a fresh self-loop edge type), GGNNs are indeed mathematically very similar to GNN-FiLM.	I-Reply	I-1	Reply	20181
[line_break_token][line_break_token]&gt; - Related to the previous point, I‚Äôd like to see a bit more discussion[line_break_token]&gt;   on *why* tight interactions between target and source nodes are[line_break_token]&gt;   helpful.	O	O	Reply	20181
For example, one could perhaps provide a toy example for[line_break_token]&gt;   which that‚Äôs obviously the case.	O	O	Reply	20181
[line_break_token][line_break_token]A simple toy example may be the following: Assume nodes are of type VA and type VB, and there are two edge types E1 and E2.	B-Reply	B-2	Reply	20181
Our task is to count the number of E1-neighbours of VA nodes, and the number of E2-neighbours of VB nodes.	I-Reply	I-2	Reply	20181
In FiLM, we can "filter" edges by using for VA nodes and for VB nodes.	I-Reply	I-2	Reply	20181
Hence, GNN-FiLM can solve this task using a single layer.	I-Reply	I-2	Reply	20181
Other models obviously can solve this task as well with more layers and feature dimensions by counting VA-E1, VA-E2, VB-E1, VB-E1 neighbours separately in a first message passing step, and then projecting to the desired dimension in a second layer.	I-Reply	I-2	Reply	20181
[line_break_token][line_break_token]More generally, as the modulation of messages depends on the edge target representation and the edge type, GNN-FiLM can learn to (softly) select a subset of the graph edges for message passing, conditioned on the current representation of nodes, _per feature dimension_ (this is a substantial difference to the newly-introduced R-GAT setting; the original GAT model has no notion of edge types).	I-Reply	I-2	Reply	20181
For example, in the Program Graph setting of the VarMisuse task, it may choose to emphasise "NextVariableUse" edges for some dimensions to gain information about how a variable is used later.	I-Reply	I-2	Reply	20181
[line_break_token][line_break_token]You're right that this intuition is not provided clearly in the paper at the moment, and will be added in the next revision (but maybe only after feedback if these explanations make sense to a reader).	I-Reply	I-2	Reply	20181
[line_break_token][line_break_token]&gt; Your current experiments report very minimal gains for your proposed[line_break_token]&gt; network, questioning why such interactions might be necessary in the[line_break_token]&gt; first place.	O	O	Reply	20181
[line_break_token][line_break_token]Note that the experimental gains over _standard_ baselines are quite substantial:[line_break_token]* For Tab.	B-Reply	B-3	Reply	20181
1, the reported state of the art is a Micro-F1 of 0.973 +/- 0.002[line_break_token]* For Tab.	I-Reply	I-3	Reply	20181
2, there is no clear state of the art as many papers use slightly different experiment design for this task (e.g., provide more features, ...); but the standard models are GGNN/R-GCN.	I-Reply	I-3	Reply	20181
[line_break_token]* For Tab.	I-Reply	I-3	Reply	20181
3, the reported state of the art is 84.0% (on SeenProjTest) and 74.1% (on UnseenProjTest) accuracy.	I-Reply	I-3	Reply	20181
[line_break_token]While more graph tasks are studied, these 3 provide a good coverage of graph tasks (from small to large graph, classification and regression, node-level and graph-level).	I-Reply	I-3	Reply	20181
The trends in these results are very likely to hold for the majority of tasks.	I-Reply	I-3	Reply	20181
[line_break_token][line_break_token]Early feedback (and curiosity) led to more and more baselines in the experiments, and existing baselines were improved in a number of ways (e.g., the generalisations to the multi-relational setting, which are crucial for the performance in the reported experiments).	I-Reply	I-3	Reply	20181
[line_break_token][line_break_token]Your review fits exactly to fear around submitting this paper: By doing a very thorough job on the experiments, the importance of the new method looks smaller; doing a worse job on the experiments (not including GNN-MLP*; not extending GAT/GIN to R-GAT/R-GIN) would have made it look better.	I-Reply	I-3	Reply	20181
These nuances cannot be obvious to someone who's not active in the GNN research community (and so this rant is not meant as a "you did a bad job as a reviewer"), but this explanation may help to understand the context.	I-Reply	I-3	Reply	20181
[line_break_token][line_break_token]However, the result that the differences between well-tuned, equally-well implemented models are small (and that the GNN-MLP baselines outperform other models) seems to be scientifically quite relevant, and of particular importance to the GNN research community.	I-Reply	I-3	Reply	20181
Disseminating this result more widely should be a reason for acceptance for publication.	I-Reply	I-3	Reply	20181

========== Edit following authors' response  ==========[line_break_token][line_break_token]Thank you for your detailed response and updated version.	O	O	Review	387
I think the new revision is significantly improved, mainly in more quantitative analyses and details in several places.	O	O	Review	387
I have updated my ev	O	O	Review	387
[line_break_token]We are deeply grateful to reviewer3 for thoughtful post-rebuttal suggestions.	O	O	Reply	387
We will clarify terminology, add more analyses and modify the figures accordingly.	O	O	Reply	387
For example, we will match the detected concepts with those in WordNet (ConceptNet) tree and update Fig 7 and Fig 14 to show which concepts are detected at each bin	O	O	Reply	387

This paper claims to propose a new approach to solve the computational problems of self-attention.	O	O	Review	171
However, the paper mainly focuses on adapting Transformer for image generation, which has far less applications.	B-Review	B-1	Review	171
The whole paper needs to be rewritten to make their target and contribution clearer.	I-Review	I-1	Review	171
[line_break_token][line_break_token]1.	O	O	Review	171
The authors overclaim that they provide a new approach for accelerating self-attention.	B-Review	B-2	Review	171
However, they only adapted Transformer for image generation.	I-Review	I-2	Review	171
In fact, Transformer does not equal to self-attention.	I-Review	I-2	Review	171
Currently, two directional self-attention like Bert has much wider applications compared with Transformer like sequential self-attention.	I-Review	I-2	Review	171
[line_break_token][line_break_token]2.	O	O	Review	171
For a paper claim to improve self-attention, they should show its effectiveness on a broad range of tasks, with comprehensive experimental evaluation.	B-Review	B-3	Review	171
However, authors mainly reported the image generation on several datasets.	I-Review	I-3	Review	171
[line_break_token][line_break_token]Overall, the authors need to rewrite the paper.	O	O	Review	171
They should either show more applications with the proposed self-attention approach or treat it as a new approach for image generation.	O	O	Review	171
hank you for remarks.	O	O	Reply	171
Since one of your major objections is at its core the same objection as that by reviewer #1, please see comment above.	O	O	Reply	171
We want to treat our paper as a new architecture for image (and video) generation and we are making this clear in the text	O	O	Reply	171

The paper proposes a class-conditional GAN model for video generation called DVD-GAN.	O	O	Review	20183
The generator uses a single latent variable and uses ConvGRU modules and ResNet blocks to generate N frames.	O	O	Review	20183
The model uses a dual discriminator, with one discriminator that discriminates individual frames, i.e. an image discriminator, and one that discriminates the whole video.	O	O	Review	20183
This is similar to the MoCoGAN model, with the main difference being that the video discriminator operates on a smaller resolution video, thus reducing the dimensionality of the input to discriminate.	O	O	Review	20183
The model is used to generate videos after being trained on the large-scale Kinetics-600 dataset, which contains multiple examples and has a lot of variability across videos.	O	O	Review	20183
The main contribution of the paper is to successfully train this large GAN model on the very large-scale Kinetics dataset.	O	O	Review	20183
The samples from the model are very visually appealing and are qualitatively  superior to any previous video prediction model.	O	O	Review	20183
[line_break_token][line_break_token]While the paper mostly focuses on scaling up current models, it achieves significantly better qualitative results than previous models on a very challenging dataset, and therefore I believe it should be accepted as it is a significant advance in the field which probably will lead to follow-up work based on the model proposed here.	O	O	Review	20183
[line_break_token][line_break_token]However, there are a number of things that could be improved/minor comments:[line_break_token][line_break_token]- Further details about the generator should be included in the main body of the paper, only having a figure to describe its architecture is not enough when the model and how to scale it up are key contributions.	B-Review	B-1	Review	20183
[line_break_token]- The authors introduce a FID score for video which is similar to FVD, but FID is only used to report results in one experiment, while FVD is used for the rest of the experiments.	B-Review	B-2	Review	20183
Since the community uses FVD and there is a publicly available implementation of this metric, I'd suggest that the authors also include FVD scores in Table 1 to help reproduce the results.	I-Review	I-2	Review	20183
This is important since the FID metric is not explained thoroughly in the paper and small implementation details matter when using these metrics.	I-Review	I-2	Review	20183
[line_break_token]- The related work section is missing many references to video prediction models, please add them to the paper.	B-Review	B-3	Review	20183
Some examples include:[line_break_token]Decomposing motion and content for natural video sequence prediction.	I-Review	I-3	Review	20183
Villegas et al ICLR 2017[line_break_token]Unsupervised Learning of Disentangled Representations from Video.	I-Review	I-3	Review	20183
Denton and Birodkar.	I-Review	I-3	Review	20183
NIPS 2017[line_break_token]Predrnn: Recurrent neural networks for predictive learning using spatiotemporal lstms.	I-Review	I-3	Review	20183
Wang et al NIPS 2017 [line_break_token]PredRNN++, ContextVP, ...[line_break_token]- Additional metrics for the BAIR experiment, including LPIPS and SSIM.	B-Review	B-4	Review	20183
While FVD correlates well with human judgement, LPIPS does so as well and provides another evaluation of the model.	I-Review	I-4	Review	20183
Furthermore, metrics such as SSIM as used in SVG-LP can help better understand how well do the models cover the ground-truth sequence for given context frames.	I-Review	I-4	Review	20183
[line_break_token]- Qualitative results for the BAIR experiment.	B-Review	B-5	Review	20183
Since most current models are not trained on Kinetics, qualitative samples for the BAIR dataset would help to qualitatively compare current methods to DVD-GAN.	I-Review	I-5	Review	20183
[line_break_token]- In practice people have found that it is very difficult to train BigGAN-like models on images and videos.	B-Review	B-6	Review	20183
A common difficulty is that training diverges after a number of iterations, with the model starting to show mode collapse and big oscillations in terms of FID scores.	I-Review	I-6	Review	20183
Since the models are trained for a big number of iterations, have you observed these kind of issues with different hyperparameter configurations?	I-Review	I-6	Review	20183
If so, did you find any strategies to address it?	I-Review	I-6	Review	20183
hanks for your review.	O	O	Reply	20183
We‚Äôve detailed responses to your comments individually below.	O	O	Reply	20183
[line_break_token][line_break_token]&gt; Further details about the generator should be included in the main body of the paper...[line_break_token]We give a detailed overview of the generator architecture in Appendix A.2 but were unable to fit all the details in the main body for length considerations.	B-Reply	B-1	Reply	20183
If there are important details you feel are worth moving to the main text we would be happy to do so.	I-Reply	I-1	Reply	20183
[line_break_token][line_break_token]&gt; ...I'd suggest that the authors also include FVD scores in Table 1 to help reproduce the results...[line_break_token]The revision just uploaded makes explicit that the FID metric we propose is identical to FVD except for using a different classifier for feature extraction -- one which has been trained on Kinetics-600 instead of Kinetics-400.	B-Reply	B-2	Reply	20183
We also use hidden layer activations as features instead of the logits -- more in line with the FID metric used for images.	I-Reply	I-2	Reply	20183
The new revision details in Appendix A.4 the (extremely minor) changes needed to be made to the publicly available FVD code to represent our metric.	I-Reply	I-2	Reply	20183
Nevertheless, we agree with the reviewer in the value of providing both metrics and will update the paper with FVD metrics for the synthesis case in the next revision.	I-Reply	I-2	Reply	20183
[line_break_token][line_break_token]&gt; The related work section is missing many references to video prediction models...[line_break_token]Thank you for the references!	B-Reply	B-3	Reply	20183
We‚Äôve added them and other relevant references in the new revision.	I-Reply	I-3	Reply	20183
[line_break_token][line_break_token]&gt; Additional metrics for the BAIR experiment ...[line_break_token]The paper which introduced FVD reported a substantially weaker correlation between SSIM and human judgement, which was our motivation for focusing on FVD, but nevertheless we have just run an evaluation for SSIM on our best model.	B-Reply	B-4	Reply	20183
We would like to include LPIPS results as well, however this will require more setup and will not be complete until a later revision.	I-Reply	I-4	Reply	20183
[line_break_token][line_break_token]For 16 frames of BAIR with 1 conditioning frame, our per-frame SSIM scores are:[line_break_token][1.0, 0.92, 0.88, 0.87, 0.84, 0.84, 0.82, 0.82, 0.82, 0.81, 0.81, 0.80, 0.79, 0.79, 0.78, 0.78][line_break_token][line_break_token]VideoTransformer does not give explicit numbers (just a plot) so an exact numeric comparison is not possible.	I-Reply	I-4	Reply	20183
Judging from Figure 2a in VideoTransformer, DVD-GAN‚Äôs SSIM frame-1 score of 0.92 is on par with VideoTransformer and slightly below VideoFlow‚Äôs 0.95.	I-Reply	I-4	Reply	20183
Frames 2-6 of DVD-GAN are better than any other model, with the rest of the frames being roughly on par with VideoFlow and VideoTransformer.	I-Reply	I-4	Reply	20183
The final value of 0.78 at frame 16 is slightly lower than VideoTransformer.	I-Reply	I-4	Reply	20183
[line_break_token][line_break_token]&gt; Qualitative results for the BAIR experiment...[line_break_token]Agreed, the revision just uploaded includes samples from BAIR in the Appendix B as well as synthesis samples from UCF-101 in Appendix D.[line_break_token][line_break_token]&gt;... difficult to train BigGAN-like models on images and videos ... any strategies to address it?	B-Reply	B-5	Reply	20183
[line_break_token]With an extremely small amount of initial hyperparameter tuning (settling on the results listed in the paper) our model was very stable on large datasets.	B-Reply	B-6	Reply	20183
While DVD-GANs will eventually diverge on smaller datasets like UCF-101 and BAIR, at no point up to 1M iterations (the largest number of steps we have trained these models for) did a DVD-GAN diverge on the full Kinetics dataset, which we attribute to the dataset‚Äôs increased complexity and difficulty to be overfit.	I-Reply	I-6	Reply	20183

[line_break_token]Summary[line_break_token]The authors propose training to optimize individual fairness using sensitive subspace robustness (SenSR) algorithm.	O	O	Review	20126
[line_break_token][line_break_token]Decision[line_break_token]Overall, I recommend borderline as the paper seems legit in formulating the individual fairness problem into a minmax robust optimization problem.	O	O	Review	20126
The authors show improvement in gender and racial biases compared to non-individual fair approaches.	O	O	Review	20126
However, I think some sections are hard to follow for people not in the field.	O	O	Review	20126
[line_break_token][line_break_token]Supporting argument:[line_break_token]1.	O	O	Review	20126
End of P3, it is not clear to me why solving the worst case is better.	B-Review	B-1	Review	20126
[line_break_token]2.	B-Review	B-6	Review	20126
Though this paper studied individual fairness, can it also work for group fairness?	B-Review	B-2	Review	20126
I am not sure whether this is the only work in this direction (baselines are not for individual fairness).	I-Review	I-2	Review	20126
[line_break_token]3.	O	O	Review	20126
Some of the metrics in the experiments are not precisely defined such as Race gap, Cuis.	B-Review	B-3	Review	20126
gap, S-Con, GR-Con.	I-Review	I-3	Review	20126
It is hard to follow from the text description.	I-Review	I-3	Review	20126
[line_break_token]4.	O	O	Review	20126
Some baseline models are not clearly defined such as ‚ÄúProject‚Äù in Table 1.	B-Review	B-4	Review	20126
[line_break_token]5.	O	O	Review	20126
Not sure how Section 3 connects with the rest of the paper.	B-Review	B-5	Review	20126
[line_break_token][line_break_token][line_break_token]Additional feedback:[line_break_token]1.	B-Review	B-6	Review	20126
Missing reference: <a href="https://arxiv.org/abs/1907.12059" target="_blank" rel="nofollow">https://arxiv.org/abs/1907.12059</a>[line_break_token]2.	O	O	Review	20126
What‚Äôs TV distance in introduction?	B-Review	B-6	Review	20126
[line_break_token]	O	O	Review	20126
hank you for the feedback.	O	O	Reply	20126
We address your concerns below.	O	O	Reply	20126
[line_break_token][line_break_token]1.	O	O	Reply	20126
The objective that we minimize is the worst-case performance of a predictor on hypothetical training sets that are similar (only differ in irrelevant features) to the observed training set.	B-Reply	B-1	Reply	20126
This leads to fairness because it penalizes predictors that perform well on the observed training set but poorly on similar hypothetical training sets.	I-Reply	I-1	Reply	20126
For example, an unfair resume screening model may perform very well on a set of training resumes from mostly white men, but poorly on resumes from women or minorities.	I-Reply	I-1	Reply	20126
By considering hypothetical sets of resumes from women or minorities during training, the objective we minimize penalizes models that only perform well on white men.	I-Reply	I-1	Reply	20126
[line_break_token][line_break_token]2.	O	O	Reply	20126
You can certainly encode group fairness by picking a metric that declares a pair of inputs similar whenever they are from the same group, but this is tangential to our goal of operationalizing individual fairness.	B-Reply	B-2	Reply	20126
We have baselines and metrics for group fairness because group fairness is the prevalent notion in the literature.	I-Reply	I-2	Reply	20126
[line_break_token][line_break_token]3.	O	O	Reply	20126
Each of the experiments has a dedicated "Comparison metrics" paragraph.	B-Reply	B-3	Reply	20126
We clarified the definitions of race and gender gaps in the corresponding paragraph.	I-Reply	I-3	Reply	20126
They are the differences between average logits output by the classifier evaluated at Caucasian vs African-American names for the Race gap and Male vs Female names for the Gender gap.	I-Reply	I-3	Reply	20126
Cuisine gap is the difference between logits of the embedded sentences: "Let‚Äôs go get Italian food" and "Let‚Äôs go get Mexican food".	I-Reply	I-3	Reply	20126
Spouse Consistency (S-Con.)	I-Reply	I-3	Reply	20126
and Gender and Race Consistency (GR-Con.)	I-Reply	I-3	Reply	20126
quantify the individual fairness intuition, i.e. how often classifier prediction remains unchanged when we evaluate it on a hypothetical "counterfactual" example created by changing features such as gender and keeping all other features unchanged.	I-Reply	I-3	Reply	20126
For these individual fairness metrics we did not write mathematical definition, but are happy to add one if the reviewer believes it would improve clarity.	I-Reply	I-3	Reply	20126
[line_break_token][line_break_token]4.	O	O	Reply	20126
In our experiments we discuss all baselines in the corresponding "Results" paragraphs.	B-Reply	B-4	Reply	20126
Project is the pre-processing baseline where we project data onto the orthogonal complement of the sensitive subspace and then train regular classifier with the projected data.	I-Reply	I-4	Reply	20126
SenSR outperforms this baseline suggesting that simply projecting out sensitive subspace is not sufficient and that robustness to unfair perturbations through SenSR gives better results in terms of fairness.	I-Reply	I-4	Reply	20126
This is analogous to the observation made in the group fairness literature that simply excluding protected attribute is not sufficient to achieve fairness.	I-Reply	I-4	Reply	20126
[line_break_token][line_break_token]5.	O	O	Reply	20126
The main point of section 3 is to show that the fairness constraint generalizes; i.e. if you  train a model with SenSR, and it performs well on all hypothetical training sets that are similar to the observed training set (i.e. it seems fair on the training data), then it also performs well with high probability (WHP) on all hypothetical test sets that are similar to a test set (i.e. it is fair WHP at test time).	B-Reply	B-5	Reply	20126
[line_break_token][line_break_token]We added the missing reference and clarified what is TV distance in the introduction	B-Reply	B-6	Reply	20126

The authors propose two approaches to combine multiple weak generative models into a stronger one using principles from boosting.	O	O	Review	426
The approach is simple and elegant and basically creates an unnormalized product of experts model, where the individual experts are trained greedily to optimize the overall joint model.	O	O	Review	426
Unfortunately, this approach results in a joint model that has some undesirable properties: a unknown normalisation constant for the joint model and therefore an intractable log-likelihood on the test set; and it makes drawing exact samples from the joint model intractable.	B-Review	B-1	Review	426
These problems can unfortunately not be fixed by using different base learners, but are a direct result of the product of experts formulation of boosting.	I-Review	I-1	Review	426
[line_break_token]  [line_break_token]The experiments on 2 dimensional toy data illustrate that the proposed procedure works in principle and that the boosting formulation produces better results than individual weak learners and better results than e.g. bagging.	O	O	Review	426
But the experiments on MNIST are less convincing: Without an undisputable measure like e.g. log-likelihood it is hard to draw conclusions from the samples in Figure 2; and visually they look weak compared to even simple models like e.g. NADE.	B-Review	B-2	Review	426
[line_break_token][line_break_token]I think the paper could be improved significantly by adding a quantitative analysis: investigating the effect of combining undirected (e.g. RBM), undirected (e.g. VAE) and autoregressive (e.g. NADE) models and by measuring the improvement over the number of base learners.	B-Review	B-3	Review	426
But this would require a method to estimate the partition function Z or estimating some proxy.	I-Review	I-3	Review	426
[line_break_token]	O	O	Review	426
Thanks for your helpful comments.	O	O	Reply	426
Please refer to the common rebuttal posted for response to questions regarding MNIST experiments.	B-Reply	B-2	Reply	426
 Regarding the concerns with the unnormalized final density, we highlight that probabilistic models frequently make a trade-off between expressiveness and tractability.	I-Reply	I-2	Reply	426
Simple models such as NADE and mixture of Bernoullis make assumptions that lend tractability but are not very flexible in modeling complex structure in the data.	I-Reply	I-2	Reply	426
On the other hand, latent variable models such as VAEs and RBMs have great expressive power but need to approximate intractable integrals.	B-Reply	B-3	Reply	426
Boosted generative models also have a computationally intractable partition function  with the trade-off made in expressiveness just like VAEs, RBMs, GANs (where even the unnormalized log-likelihood cannot be directly computed), etc.	I-Reply	I-3	Reply	426
We argue that intractability is however not a deal-breaker since a).	I-Reply	I-3	Reply	426
many use cases of generative models (such as sampling, unsupervised feature learning) do not require the partition function, b).	I-Reply	I-3	Reply	426
wherever required, there are some generic techniques available for estimating the partition function	I-Reply	I-3	Reply	426

This paper presents a new method for fully- and semi-supervised few-shot classification that is based on learning a general embedding as usual, and then learning a sub-space of it for each class.	O	O	Review	1616
A query point is then classified as the class whose sub-space is closest to it.	O	O	Review	1616
[line_break_token][line_break_token]Pros: This is a neat idea and achieves competitive results.	O	O	Review	1616
Learning a sub-space per class makes intuitive sense to me since it‚Äôs plausible that there is a lower-dimensional subspace of the overall embedding space that captures the properties that are common to only examples of a certain class.	O	O	Review	1616
If this is indeed the case, it seems that indeed classifying query examples into classes based on their distances from the corresponding sub-spaces would lead to good discrimination.	O	O	Review	1616
[line_break_token][line_break_token]Cons: First, an inherent limitation is that this approach is not applicable to one-shot learning, and I have doubts in its merit for very low shot learning (explained below).	B-Review	B-1	Review	1616
Second, I‚Äôm missing the justification behind a key point used to motivate the approach, which requires clarification (explained below).	B-Review	B-2	Review	1616
Third, I feel that certain aspects of the approach were unclear (details to follow).	B-Review	B-3	Review	1616
Finally, I feel more analysis is needed to better understand the differences of this method from previous work (concrete suggestions follow).	B-Review	B-4	Review	1616
For semi-supervised learning, the novelty regarding how the unlabeled examples are incorporated is limited, as the approach used is previously-introduced in Ren et al, 2018.	B-Review	B-5	Review	1616
[line_break_token][line_break_token]Overall, even though I like the idea and the results are good, there are a few points, mentioned in the above section that I feel require additional work before I can strongly recommend acceptance.	O	O	Review	1616
Most importantly, relating to getting more intuition about why and when this works best, and tying it in better with previous approaches.	O	O	Review	1616
[line_break_token][line_break_token]A key point requiring clarification.	O	O	Review	1616
[line_break_token]There is a key fact that the authors used to motivate this approach which remains unclear to me: why is it the case that this approach is less sensitive to outliers than previous approaches?	B-Review	B-2	Review	1616
In Figure 1, an outlier is pictured in each of subfigures (a) and (b) corresponding to Matching and Prototypical Networks, but not in subfigure (c) which corresponds to PSN.	I-Review	I-2	Review	1616
No explanation is provided to justify this conjecture, other than empirical evaluation that is based on the overall accuracy only.	I-Review	I-2	Review	1616
In particular, since SVD is used to obtain the sub-spaces, instead of an end-to-end learned projector that directly optimizes the query set accuracy, it‚Äôs not clear why if a support point is an outlier it would not affect the sub-space creation.	I-Review	I-2	Review	1616
If I‚Äôm missing something, please clarify!	I-Review	I-2	Review	1616
[line_break_token][line_break_token](A) Comments on the approach.	O	O	Review	1616
[line_break_token](1) Why define X_k as the support set examples minus the class prototype instead of just the support examples themselves?	B-Review	B-6	Review	1616
The latter seems simpler, and should have all the required information for shaping the class‚Äô subspace.	I-Review	I-6	Review	1616
[line_break_token](2) Note that if X_k is defined as [x_{k,1}, \dots, x_{k,K}] as proposed in the above point (ie.	B-Review	B-7	Review	1616
without subtracting the class mean from each support point) then this method would have been applicable to 1-shot too.	I-Review	I-7	Review	1616
How would it then compare to a 1-shot Prototypical Network?	I-Review	I-7	Review	1616
Notice that in this case the mean of the class is equal to this one example.	I-Review	I-7	Review	1616
[line_break_token](3) In general, the truncated SVD decomposition for a class can be written using the matrices U, \Sigma and V^T with dimensions [D, n], [n, n] and [n, K] respectively, where D is the embedding dimensionality and K is the number of support points belonging to the given class.	B-Review	B-8	Review	1616
The middle matrix \Sigma in the non-truncated version would have dimensions [D, K]. Does this mean that when truncating, n is enforced to be smaller than each of D and K?	I-Review	I-8	Review	1616
This would mean that the dimensionality n of the sub-space is limited by the number of the support examples, which in some cases may be very small in few-shot learning.	I-Review	I-8	Review	1616
Can you comment on this?	I-Review	I-8	Review	1616
[line_break_token](4) How to set n (the dimensionality of each subspace) is not obvious.	B-Review	B-9	Review	1616
What values were explored?	I-Review	I-9	Review	1616
Is there a sweet spot in the trade-off between the observed complexity and the final accuracy?	I-Review	I-9	Review	1616
[line_break_token][line_break_token](B) Comparison with Prototypical Networks.	B-Review	B-4	Review	1616
[line_break_token](1) In what situations do we expect learning a sub-space per class to do better than learning a  prototype per class?	I-Review	I-4	Review	1616
For example, Figure 4 shows the test-time performance as a function of the test ‚Äòway‚Äô.	I-Review	I-4	Review	1616
A perhaps more interesting analysis would be to compare the models‚Äô performance as a function of the test *shot*: if more examples are available it may be less appropriate to create a prototype and more beneficial to create a sub-space?	I-Review	I-4	Review	1616
[line_break_token](2) Can we recover Prototypical Networks as a special case of PSN?	I-Review	I-4	Review	1616
If so, how?	I-Review	I-4	Review	1616
It would be neat to show under which conditions these are equivalent.	I-Review	I-4	Review	1616
[line_break_token][line_break_token](C) Clarifications regarding the semi-supervised setup.	B-Review	B-5	Review	1616
[line_break_token](1) Are distractor classes sampled from a disjoint pool of classes, or is it that, for example, a class which is a distractor in an episode is a non-distractor in another episode.	I-Review	I-5	Review	1616
[line_break_token](2) Similarly for labeled / unlabaled at training time.	I-Review	I-5	Review	1616
Can the same example appear as labeled in one episode but unlabaled in another?	I-Review	I-5	Review	1616
In Ren et al, 2018, this was prevented by creating an additional labeled/unlabeled split even for the training examples.	I-Review	I-5	Review	1616
Therefore they use strictly less overall information at meta-training time than if that split weren‚Äôt used.	I-Review	I-5	Review	1616
To be comparable with them, it‚Äôs important to apply this same setup.	I-Review	I-5	Review	1616
[line_break_token][line_break_token](D) Additional minor comments.	B-Review	B-10	Review	1616
[line_break_token](1) ‚ÄúTo work at the presence of distractors, we propose to use a fake class with zero mean‚Äù.	I-Review	I-10	Review	1616
Note that this was already proposed in Ren et al, 2018.	I-Review	I-10	Review	1616
They used a zero-mean, high-variance additional cluster whose aim was to ‚Äòsoak up‚Äô the distractor examples to prevent them for polluting legitimate clusters (this was the second model they proposed).	I-Review	I-10	Review	1616
[line_break_token](2) In the introduction, regarding contribution iii.	I-Review	I-10	Review	1616
A more appropriate way to describe this is as exploring generalization to different numbers of classes, or ‚Äòways‚Äô at test time than what was used at training time.	I-Review	I-10	Review	1616
[line_break_token](3) Gidaris and Komodakis (2018) is described in the related work as using a more complicated pipeline.	I-Review	I-10	Review	1616
Note however that their pipeline is in place for solving a more challenging problem than standard few-shot classification: they study how a model can maintain the ability to remember training classes while rapidly learning about new ‚Äòtest‚Äô classes.	I-Review	I-10	Review	1616
[line_break_token](4) In the last line of section 5.3, use N-way instead of K-way since in the rest of the paper K was used to refer to the shot, not the way.	I-Review	I-10	Review	1616
[line_break_token]	O	O	Review	1616
[line_break_token]Q: ``Why is it the case that ... less sensitive to outliers ...''[line_break_token][line_break_token]A: A prototype in the Prototypical Networks (PN) is the average of a set and as such is sensitive to any perturbation of the set, outliers being one.	B-Reply	B-2	Reply	1616
On the other hand, in PSN, a set is represented by a subspace.	I-Reply	I-2	Reply	1616
To have a noticeable change in the orientation of the subspace, one needs to induce drastic changes to the set.	I-Reply	I-2	Reply	1616
Having said this, we performed two extra-experiments to reinforce our conjecture here.	I-Reply	I-2	Reply	1616
[line_break_token][line_break_token]In the first one, depicted in Fig.	I-Reply	I-2	Reply	1616
2, we empirically studied the decision boundaries of PSN and PN.	I-Reply	I-2	Reply	1616
The samples (triangle symbol) are drawn from the normal distribution for a two-class problem (column 1 and 2) and a problem with three classes (column 3 and 4).	I-Reply	I-2	Reply	1616
The outliers (square symbol) are spread around initial samples.	I-Reply	I-2	Reply	1616
The facecolors for outliers indicate to which class they have been assigned.	I-Reply	I-2	Reply	1616
In the odd columns, we can see that the prototypes and subspaces discriminate the classes equally well.	I-Reply	I-2	Reply	1616
[line_break_token]However, in the even columns, it is clearly shown that the outliers sway the prototypes and their decision boundaries while the subspace approach handles them more robustly.	I-Reply	I-2	Reply	1616
  [line_break_token][line_break_token]In the second experiment, placed in appendix A, we provide the 5-way 5-shot and 5-way 10-shot results on the Mini-ImageNet by adding outliers and noise to support examples.	I-Reply	I-2	Reply	1616
There are two setups conducted to examine the robustness of PSN to outliers and additive noise.	I-Reply	I-2	Reply	1616
In the first experiment, the support set contains samples from classes absent in this set.	I-Reply	I-2	Reply	1616
We did not split the dataset into disjoint inlier/outlier sets though, as the outliers were only presented at the test time, leading to more realistic experiments.	I-Reply	I-2	Reply	1616
In the second experiment, perturbations were generated from a Gaussian distribution with random mean and predefined [line_break_token]variance.	I-Reply	I-2	Reply	1616
The results shown in Fig.	I-Reply	I-2	Reply	1616
4 demonstrate that on both tasks, PSN outperforms PN by a significant gap.	I-Reply	I-2	Reply	1616
Note that, we utilized the same CNN architecture (4-convolutional layers) for both PSN and PN.	I-Reply	I-2	Reply	1616
[line_break_token][line_break_token]Q: ``Why define as the support set examples minus the class prototype instead of just the support examples themselves?''	O	O	Reply	1616
[line_break_token][line_break_token]A: Our idea here is to represent a class by an affine subspace which is indeed a generalization of [line_break_token]the concept of linear subspace (where the origin is a common point).	B-Reply	B-6	Reply	1616
We indeed started by using linear-subspaces to model each class but empirically found that affine subspaces perform slightly better.	I-Reply	I-6	Reply	1616
To address this comment, we have added a remark to Section 6.	I-Reply	I-6	Reply	1616
[line_break_token][line_break_token]Q: ``How would it then compare to a 1-shot Prototypical Network?''	O	O	Reply	1616
[line_break_token][line_break_token]A: We cannot build an affine subspace with only one example per class, as such we cannot use PSN to address 1-shot learning problems per se.	B-Reply	B-7	Reply	1616
However, simply augmenting support images to obtain two or more samples per class alleviates such an issue straight away.	I-Reply	I-7	Reply	1616
However, this simple issue is beyond the points we make in our paper (it is an orthogonal research direction in one- and few-shot learning).	I-Reply	I-7	Reply	1616
We have reflected this in Section 6 of the revised draft to address the reviewer's comment.	I-Reply	I-7	Reply	1616
[line_break_token][line_break_token]Q: ``Does this mean the dimensionality n of the sub-space is limited by the number of the support examples''[line_break_token][line_break_token]A: Affirmative.	B-Reply	B-8	Reply	1616
Our idea is to construct a subspace representing the set.	I-Reply	I-8	Reply	1616
The reviewer's comment raises an interesting point, whether parts of the orthogonal complement of each subspace can be used to make better decisions.	I-Reply	I-8	Reply	1616
We believe that investigating the effect of orthogonal complements demands a dedicated study and goes beyond our work.	I-Reply	I-8	Reply	1616
Having said this, we reflect this comment in Section 7.	I-Reply	I-8	Reply	1616

This paper describes a new architecture for parallelizing off-policy reinforcement learning systems with a pool of independent learners trained on identical, but independent instances of the environment with a scheme for periodically synchronizing the the policy knowledge across the pool.	O	O	Review	637
The paper provides demonstrations in several continuous control domains.	O	O	Review	637
[line_break_token][line_break_token]I think this paper should be rejected because: 1) the approach is not well justified or placed within the large literature on parallel training architectures and population-based training methods, (2) the results are competitive with the best in each domain, but there are many missing details.	B-Review	B-1	Review	637
Since the contribution is entirely support by empirical evidence, these issues need to be clarified.	B-Review	B-2	Review	637
I look forward to the author response, as I will pose several questions below and my final score will carefully take the answers into account.	O	O	Review	637
[line_break_token][line_break_token]Justification of decision.	B-Review	B-1	Review	637
There are numerous papers on parallel architectures for training deep RL systems [1,2, 6] and you cited a few, and while not all of them focus on continuous control there are design decisions and insights in those works must be relevant to your efforts.	I-Review	I-1	Review	637
You should make those connections clear in the paper.	I-Review	I-1	Review	637
One line of the paper is not nearly enough.	I-Review	I-1	Review	637
The stated focus of the paper is exploration-exploitation yet there is little to no discussion of other ideas including noisy networks, intrinsic motivation, or count-based exploration methods.	I-Review	I-1	Review	637
The paper is missing a lot of key connections to the literature.	I-Review	I-1	Review	637
[line_break_token][line_break_token]I am certainly not a fan of architectures that assume access to many instances of the environment.	B-Review	B-3	Review	637
In this case that assumption seems worse because of the target application: continuous control domains.	I-Review	I-3	Review	637
These domains are simulations of physical control systems; on a robot the agent receives only one stream of experience and thus these architectures would not work well.	I-Review	I-3	Review	637
Though there is some work on applying these multi-environment architectures to farms of robot arms; the reality of the real-world is that the arms end up being very different due to wear and tear, and engineers must constantly fix the hardware because these multi-environment architectures do not work when the environments are different.	I-Review	I-3	Review	637
We cannot loose sight of the goal here‚Äîmaximizing these simulation environments is not of interest itself, its a stepping stone‚Äîarchitectures that only work on simulations that afford multiple identical environments but fail in the real world have very limited application.	I-Review	I-3	Review	637
I think this paper needs to motivate why parallel training in this way in these robotics inspired domains is interesting and worthwhile.	I-Review	I-3	Review	637
   [line_break_token][line_break_token]The main area of concern with this paper is the experiment section.	O	O	Review	637
There are several issues/questions I would like the authors to address:[line_break_token]1) You built on top of TD3, however you just used the parameter settings of TD3 as published and didn‚Äôt tune them.	B-Review	B-4	Review	637
This is a problem because it could just be that the existing parameter choices for TD3 were just better for the new approach.	I-Review	I-4	Review	637
You have to take additional effort in this case to ensure your method is actually better than just using TD3.	I-Review	I-4	Review	637
Additional parameter tuning of TD3 is required here.	I-Review	I-4	Review	637
[line_break_token]2) I think its an odd choice for TD3 to have an infinite buffer, as recent work has show at least for DQN that large buffers can hurt performance [7].  Can you justify this choice beyond ‚Äúthe authors of TD3 did it that way‚Äù?	B-Review	B-5	Review	637
[line_break_token]3) Why is R_eval different for each method?	B-Review	B-6	Review	637
[line_break_token]4) Why did you not compare to TD3 on the same set of domains as used in the TD3 paper?	B-Review	B-7	Review	637
Why a subset?	I-Review	I-7	Review	637
Why these particular domains?	I-Review	I-7	Review	637
[line_break_token]5) In 2 of the 4 domains the proposed method ties or is worse than the baselines.	B-Review	B-8	Review	637
In half-cheetah it looks close to significant, and in the ant domain the result is unlikely to be significant because the error-bars overlap and the error-bars of TD3 are wider than the other methods so a simple visual inspection is not enough.	I-Review	I-8	Review	637
There does not seem to be a strong case for the new method here.	I-Review	I-8	Review	637
I may be misunderstanding the results.	I-Review	I-8	Review	637
Help me see the significance.	I-Review	I-8	Review	637
[line_break_token]6) The paper claims improvement in variance, but this requires additional analysis in the form of an F-test of better.	B-Review	B-9	Review	637
[line_break_token]7) Why these baselines (e.g., SAC) and not others?	B-Review	B-10	Review	637
Why did you not include D4PG [6]?	I-Review	I-10	Review	637
Soft Q-learning?	I-Review	I-10	Review	637
A population-based training method [3,4,5,8] to name a few?	I-Review	I-10	Review	637
[line_break_token][line_break_token][1] GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning[line_break_token][2] IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures[line_break_token][3] Human-level performance in first-person multiplayer games with population-based deep reinforcement learning[line_break_token][4] Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents[line_break_token][5] Structured Evolution with Compact Architectures for Scalable Policy Optimization[line_break_token][6] Distributed Distributional Deterministic Policy Gradients[line_break_token][7] A Deeper Look at Experience Replay[line_break_token][8] Evolution Strategies as a Scalable Alternative to Reinforcement Learning[line_break_token] [line_break_token][line_break_token]Small things that did not impact the score:[line_break_token]1) references to ‚Äúsearch interval‚Äù in the abstract are confusing because the reader has not read the paper yet[line_break_token]2) Description of the method in abstract is too specific[line_break_token]3) P1 intro, not a topic sentence for what follows[line_break_token]4) ‚Äúperforms an action to its environment‚Äù > grammar[line_break_token]5) ‚ÄúOne way to parallel learning‚Ä¶‚Äù > grammar[line_break_token]6) ‚Äúthat the value parameter and‚Äù > grammar[line_break_token]7) ‚Äúpitfalls‚Äù > minima [line_break_token]8) Did you try combining you method with other base off-policy methods?	O	O	Review	637
how did it work?	B-Review	B-11	Review	637
[line_break_token]9) GAE undefined?	I-Review	I-11	Review	637
[line_break_token]10) ‚Äúamong the baseline and‚Äù>grammar‚Ä¶there are many grammar errors	O	O	Review	637
Response to Relation with Previous Works: We agree with the reviewer in that the proposed method is not properly placed in the literature in the original paper.	B-Reply	B-1	Reply	637
However, the proposed method has new ingredients in parallel learning, as mentioned by Reviewer 2.	I-Reply	I-1	Reply	637
In Section 4.3 of the revised paper, one can clearly see the impact of the new ingredients in the context of the previous works.	I-Reply	I-1	Reply	637
During the revision, we did extensive literature survey and framed our work in the context of the previous works including the references that the reviewer mentioned.	I-Reply	I-1	Reply	637
Please see Section 2 of the revised paper.	I-Reply	I-1	Reply	637
[line_break_token][line_break_token]Response to Missing Details: We agree with the reviewer in that there were many things missing in the original paper.	B-Reply	B-2	Reply	637
We included relevant new results in the revised paper.	I-Reply	I-2	Reply	637
Please see Section 2, Section 4.3 and Appendices.	I-Reply	I-2	Reply	637
Please see the response to all reviewers for what we have done during the revision.	I-Reply	I-2	Reply	637
[line_break_token][line_break_token]Response to Motivation in Parallel Learning in Continuous-Action RL: Please see the response to all reviewers.	B-Reply	B-3	Reply	637
Indeed, fast prototyping for development of large complex robot systems based on precise Newtonian-dynamics simulation platforms becomes more and more important to alleviate the difficulties that the reviewer mentioned.	I-Reply	I-3	Reply	637
Please visit <a href="https://cyberbotics.com/" target="_blank" rel="nofollow">https://cyberbotics.com/</a> .	O	O	Reply	637
 Furthermore, the proposed IPE method can be applied to off-policy RL algorithms with discrete actions such as DQN.	B-Reply	B-3	Reply	637
The constructed IPE-DQN algorithm is shown in Appendix E of the revised paper.	I-Reply	I-3	Reply	637
We tried IPE-DQN on several Atari games but could not obtain numerical result in this short revision time.	I-Reply	I-3	Reply	637
We have added a few sentences regarding this motivation in the conclusion of the revised paper.	I-Reply	I-3	Reply	637
[line_break_token][line_break_token]Response to Parameter Setting of TD3: Based on common sense, we believe that the authors of TD3 fine-tuned the parameters of their TD3.	B-Reply	B-4	Reply	637
As shown in Appendix D of the revised paper, IPE-SAC also performs better than SAC with the parameters in the SAC paper.	I-Reply	I-4	Reply	637
This is another evidence of generality of IPE.	I-Reply	I-4	Reply	637
[line_break_token][line_break_token]Response to The Infinite Buffer Size of TD3: The simulation is over 1 million environment steps, so the buffer size is actually 1 million.	B-Reply	B-5	Reply	637
For clarity in the revised paper we explicitly set the size of replay buffer as 1 million and obtained new performance plots in the revised paper.	I-Reply	I-5	Reply	637
[line_break_token][line_break_token]Response to R_eval: R_eval is the frequency of measuring the performance, and it does not affect training at all.	B-Reply	B-6	Reply	637
The reason for different R_eval is that the implementations of algorithms have different frequencies for writing logs.	I-Reply	I-6	Reply	637
This can be modified easily, so we set the R_eval = 4000 environment steps for all algorithms in the revised paper.	I-Reply	I-6	Reply	637
[line_break_token][line_break_token]Response to Other Environments for TD3: The environments (Reacher-v1, InvertedPendulum-v1, InvertedDoublePendulum-v1) were not considered because the performance of the previous algorithms on these environments already saturated, as seen in the original TD3 paper (Fujimoto et al 2018).	B-Reply	B-7	Reply	637
It seems that they achieved the optimal performance already.	I-Reply	I-7	Reply	637
IPE-TD3 will not provide improvement on these environments over other algorithms.	I-Reply	I-7	Reply	637
So, we did not feel the necessity for test of IPE-TD3 on these tests.	I-Reply	I-7	Reply	637
What we need is more challenging tasks.	I-Reply	I-7	Reply	637
[line_break_token][line_break_token]Response to Significance of IPE: The two of the four domains in the paper are easy tasks so that other algorithms already work well.	B-Reply	B-8	Reply	637
What we need is more challenging tasks to see the real gain of the method, as mentioned by Reviewers 2 and 3.	I-Reply	I-8	Reply	637
In more challenging Humanoid suggested by other reviewers, the constructed IPE-SAC outperforms SAC, as seen in Appendix D. Here, TD3 does not ever work.	I-Reply	I-8	Reply	637
[line_break_token][line_break_token]Response to F-test: F-test for variance is conducted with null hypothesis var_TD3 = var_IPE-TD3 and alternative hypothesis var_TD3 > var_IPE-TD3.	O	O	Reply	637
The F-statistics are 280.37, 0.69, 2.73, and 9.45 for Hopper-v1, Walker2d-v1, HalfCheetah-v1, and Ant-v1, respectively.	B-Reply	B-9	Reply	637
Thus, it seems that the variance of IPE-TD3 is smaller than that of TD3 in Hopper-v1 and Ant-v1 tasks.	I-Reply	I-9	Reply	637
[line_break_token][line_break_token]Response to Other Baselines: The revised paper includes more baselines (ACKTR and SQL).	B-Reply	B-10	Reply	637
As shown Figure 3, IPE-TD3 outperforms all baselines in the four MuJoCo tasks.	I-Reply	I-10	Reply	637
In ablation study of the revised paper, we considered other parallel enhancement methods.	I-Reply	I-10	Reply	637
Among them, the reloading method is based on the idea in PBT (Jaderberg et al 2017) and simply copies the best policy parameter to other learners.	I-Reply	I-10	Reply	637
As seen in Table 1 and the figures, IPE outperforms the reloading method.	I-Reply	I-10	Reply	637
So, it seems that the proposed way of fusing the best policy parameter is more effective than simply copying.	I-Reply	I-10	Reply	637
Note that simple copying means that the search area covered by all learners collapses to one point at the time of copying.	I-Reply	I-10	Reply	637
We don‚Äôt need to do this.	I-Reply	I-10	Reply	637
[line_break_token][line_break_token]Response to Minor Comments: Thanks for careful reading.	B-Reply	B-11	Reply	637
We checked the grammar.	I-Reply	I-11	Reply	637
Moreover IPE-enhanced algorithms do not use GAE	I-Reply	I-11	Reply	637

# Summary[line_break_token][line_break_token]This paper presents a BERT-inspired pretraining/finetuning setup for source code tasks.	O	O	Review	374
It collects a corpus of[line_break_token]unlabeled Python files for BERT pretraining, designs or adopts 5 tasks on established smaller-scale Python corpora, and[line_break_token]adjusts the BERT model to tokenize and encode source code snippets appropriately.	O	O	Review	374
[line_break_token][line_break_token]# Strengths[line_break_token][line_break_token]* The idea of applying the pretraining/finetuning paradigm to program analysis tasks makes sense, and has been[line_break_token]  informally attempted by multiple groups in the community in 2019.	O	O	Review	374
This is the first high-quality submission to a[line_break_token]  top-tier ML conference I've seen on the subject, though.	O	O	Review	374
[line_break_token]* The authors exercised commendable care and diligence in preparing the training data, adopting BERT to source code[line_break_token]  inputs, and ensuring correctness of the experimental setup.	O	O	Review	374
I appreciated all the provided details on tokenization[line_break_token]  (Section 3.3), deduplication (Sections 3.1-3.2), and task setup (Section 3.5).	O	O	Review	374
This should become a technical standard[line_break_token]  in the community.	O	O	Review	374
[line_break_token]* The paper is written clearly and concisely, and is generally a pleasure to read.	O	O	Review	374
[line_break_token][line_break_token]# Weaknesses[line_break_token][line_break_token]I have a gripe with the authors' choice to ignore program structure (e.g. abstract syntax trees) or features (e.g.[line_break_token]types) in their program representation.	B-Review	B-1	Review	374
Without this extra information (easily available from a compiler/interpreter[line_break_token]API) the pipeline is not substantially different from the original NLP pipeline of BERT et al The main program-related[line_break_token]representation insight comes in tokenization (Section 3.3) and the definition of "sentences".	I-Review	I-1	Review	374
To repeat, I appreciate[line_break_token]the effort the authors put in making tokenization appropriate for BERT processing of source code, but this is a drop in[line_break_token]the bucket compared to the all the other program-related features the work is leaving off the table.	I-Review	I-1	Review	374
Programs are not[line_break_token]natural language.	I-Review	I-1	Review	374
[line_break_token]The argument that source code analysis would "pass on the burden ... to downstream tasks" (Page 3) is odd.	B-Review	B-2	Review	374
First, most[line_break_token]downstream tasks of interest occur in the settings where this analysis is already available: IDEs, code review[line_break_token]assistants, linters, etc.	I-Review	I-2	Review	374
Second, one often needs program analysis to even define downstream tasks in the first place --[line_break_token]for example, determining whether function arguments are swapped required detecting a function call and boundaries of its[line_break_token]arguments, thus parsing the program!	I-Review	I-2	Review	374
[line_break_token][line_break_token]This work obtains (and nicely analyzes) impressive results obtained by applying CuBERT.	B-Review	B-3	Review	374
However, it does not put the[line_break_token]results in context with prior work based on structured program representations.	I-Review	I-3	Review	374
Without this, it is difficult to say[line_break_token]whether the improvement comes from pretraining or from the language model simply learning a better "parsed"[line_break_token]representation of an input program from all the unlabeled corpus.	I-Review	I-3	Review	374
If it's the latter, one might argue that supplying the[line_break_token]model with structured program features explicitly might eliminate much of the need for the unlabeled corpus.	I-Review	I-3	Review	374
[line_break_token]I personally think that there will still be a gap between pretraining and finetuning even with structured program[line_break_token]features simply due to the sheer volume of available data, which, as the authors showed, is crucial for good[line_break_token]generalization of Transformer.	I-Review	I-3	Review	374
However, this still needs to be shown empirically.	I-Review	I-3	Review	374
[line_break_token][line_break_token]The "Function-Docstring Mismatch" task, as presented, seems too easy.	B-Review	B-4	Review	374
If the distractors (negative examples) are truly[line_break_token]chosen at random, most of them are going to use obviously different vocabulary from the original function signature (as[line_break_token]Figure 4 demonstrates).	I-Review	I-4	Review	374
A well designed task would somehow bias the sampling toward subtle distractors such as `get` vs.[line_break_token]`set` docstrings, but this seems challenging.	I-Review	I-4	Review	374
[line_break_token]This also explains why the task is not influenced as much by reduction of training data (Table 3).	I-Review	I-4	Review	374
[line_break_token][line_break_token]The Next Sentence Prediction pretraining task, as adapted for CuBERT, seems too difficult, in contrast.	B-Review	B-5	Review	374
If the paired[line_break_token]sentences (i.e. code lines) are chosen at random, the model would lack most of the context required to make a decision[line_break_token]about the logical relationship between them, such as which variables are defined and available in context, which[line_break_token]functionality is being implemented, etc.	I-Review	I-5	Review	374
I wonder, can the authors experiment with pretraining CuBERT only with the[line_break_token]Masked Language Model task?	I-Review	I-5	Review	374
Will it worsen the results substantially or at all?	I-Review	I-5	Review	374
[line_break_token][line_break_token]# Questions[line_break_token][line_break_token]Section 3.2: "similar files according to the same similarity metric..."[line_break_token]What are these metrics?	B-Review	B-6	Review	374
[line_break_token][line_break_token]What is the fraction of positive/negative examples in the constructed finetuning datasets?	B-Review	B-7	Review	374
[line_break_token][line_break_token]What is the motivation for making Variable Misuse and Wrong Operator/Operand into a simple classification tasks instead[line_break_token]of the original (more useful) correction task?	B-Review	B-8	Review	374
[line_break_token]	O	O	Review	374
e thank the reviewer for the helpful comments and suggestions.	O	O	Reply	374
[line_break_token][line_break_token]&gt;&gt; Choice to ignore program structure (e.g. abstract syntax trees) or features (e.g. types)[line_break_token][line_break_token]Natural languages are also endowed with structure (e.g., different types of parse trees, phrase structures, etc.).	B-Reply	B-1	Reply	374
However, the prevailing pre-training methods in NLP such as BERT do not make explicit use of such structure, and still attain state-of-the-art results.	I-Reply	I-1	Reply	374
The task of learning useful (structural) features is left to the self-attention mechanism of the Transformer model.	I-Reply	I-1	Reply	374
In this work, we apply the same approach to program-understanding tasks.	I-Reply	I-1	Reply	374
We recognize that it may be possible to extend CuBERT with explicitly provided structural information using approaches like relation-aware Transformers (see "Self-attention with relative position representations", <a href="https://www.aclweb.org/anthology/N18-2074.pdf)" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/N18-2074.pdf)</a> in place of the usual Transformers based on sinusoidal positional encodings, and hope to try this in future work; this submission will provide a strong baseline to evaluate such future work.	O	O	Reply	374
We thank the reviewer for raising this point.	B-Reply	B-1	Reply	374
We now include this possibility as a future extension in Section 5, which we rename from ‚ÄúConclusions‚Äù to ‚ÄúConclusions and Future Work‚Äù.	I-Reply	I-1	Reply	374
[line_break_token][line_break_token]With regard to types, we do not assume that the source code is written in a statically typed language and hence, do not use types as features.	I-Reply	I-1	Reply	374
We train CuBERT for Python code, which is dynamically typed.	I-Reply	I-1	Reply	374
We leave exploring type information for statically-typed languages for future work.	I-Reply	I-1	Reply	374
[line_break_token][line_break_token]&gt;&gt; Burden of program analysis[line_break_token][line_break_token]The reviewer‚Äôs point is well taken.	B-Reply	B-2	Reply	374
We have reworded our relevant text in the paper.	I-Reply	I-2	Reply	374
To recap, our goal is to understand and evaluate a BERT-like pre-training approach (i.e., purely on lexical information) for program-understanding tasks, without exposing to the pre-training model additional information gleaned through program analysis.	I-Reply	I-2	Reply	374
[line_break_token][line_break_token]&gt;&gt; Simplicity of the Function-Docstring Mismatch task[line_break_token][line_break_token]We agree with the reviewer‚Äôs observation.	B-Reply	B-4	Reply	374
Nevertheless, the inherent ability of Transformer to relate every pair of tokens through self-attention plays a crucial role in CuBERT getting +7.5% improvement over the baseline model even on this relatively simple task.	I-Reply	I-4	Reply	374
[line_break_token][line_break_token]&gt;&gt; Utility of Next Sentence Prediction task[line_break_token][line_break_token]A recent work has argued that using only the Masked Language Model objective (coupled with more training on larger datasets) can improve the performance of BERT (see "RoBERTa: An optimized method for pretraining self-supervised NLP systems", <a href="https://arxiv.org/abs/1907.11692)."	O	O	Reply	374
target="_blank" rel="nofollow">https://arxiv.org/abs/1907.11692).</a> It will take more experimentation to check how inclusion/exclusion of next-sentence-prediction affects CuBERT.	O	O	Reply	374
[line_break_token][line_break_token]&gt;&gt; Explanation of similarity metric[line_break_token][line_break_token]Two files are considered similar to each other if the Jaccard similarity between the sets of tokens (identifiers and string literals) is above 0.8 and in addition, it is above 0.7 for multi-sets of tokens.	B-Reply	B-6	Reply	374
This is based on the criteria used in Allamanis (2018).	I-Reply	I-6	Reply	374
We have added this explanation in the revised version.	I-Reply	I-6	Reply	374
[line_break_token][line_break_token]&gt;&gt; Fraction of positive/negative examples in the finetuning tasks[line_break_token][line_break_token]We have provided these details in Appendix A now.	B-Reply	B-7	Reply	374
To summarize, all classification tasks except Exception Type classification, and the new pointer task (Section 4.7), have a 50-50 split of buggy/bug-free examples.	I-Reply	I-7	Reply	374
The per-class counts for the Exception Type classification task are shown in the (new) Table 6.	I-Reply	I-7	Reply	374
[line_break_token][line_break_token]&gt;&gt; Motivation for making Variable Misuse and Wrong Operator/Operand as classification tasks instead of correction tasks[line_break_token][line_break_token]We have now included experimentation for the joint task of classification, localization and repair of variable misuse errors from Vasic et al (2019).	B-Reply	B-8	Reply	374
Please see Section 4.7 for the results.	I-Reply	I-8	Reply	374
The original Wrong Operator and Swapped Operand tasks from (Pradel &amp; Sen 2018) are binary classification tasks similar to ours.	O	O	Reply	374
They were not error correction tasks.	B-Reply	B-8	Reply	374

This paper proposes analysis of regularization, weight Froebius-norm and feature L2 norm, showing that it is equivalent to another proposed regularization, gradient magnitude loss.	O	O	Review	604
They then argue that: 1) it is helpful to low-shot learning, 2) it is numerically stable, 3) it is a soft version of Batch Normalization.	O	O	Review	604
Finally, they demonstrate experimentally that such a regularization improves performance on low-shot tasks.	O	O	Review	604
[line_break_token][line_break_token]First, this is a nice analysis of some simple models, and proposes interesting insights in some optimization issues.	B-Review	B-1	Review	604
Unfortunately, the authors do not demonstrate, nor argue in a convincing manner, that such an analysis extends to deep non-linear computation structures.	I-Review	I-1	Review	604
I feel like the authors could write a full paper about "results can be derived for œÜ(x) with convex differentiable non-linear activation functions such as ReLU", both via analysis and experimentation to measure numerical stability.	I-Review	I-1	Review	604
[line_break_token][line_break_token]Second, the authors again show an interesting correspondance to batch normalization, but IMO fail to experimentally show its relevance.	B-Review	B-2	Review	604
[line_break_token][line_break_token]Finally, I understand the appeal of the proposed method from a numerical stability point of view, but am not convinced that it has any effect on low-shot learning in the high dimensional spaces that deep networks are used for.	B-Review	B-3	Review	604
[line_break_token][line_break_token]I commend the authors for contributing to the mathematical understanding of our field, but I think they have yet to demonstrate the large scale effectiveness of what they propose.	O	O	Review	604
At the same time, I feel like this paper does not have a clear and strong message.	O	O	Review	604
It makes various (interesting) claims about a number of things, but they seem more or less disparate, and only loosely related to low-shot learning.	O	O	Review	604
[line_break_token][line_break_token]notes:[line_break_token]- "an expectation taken with respect to the empirical distribution generated by the training set", generally the training set is viewed as a "montecarlo" sample of the underlying, unknown data distribution \mathcal{D}.[line_break_token]- "we can see that our model learns meaningful representations", it gets a 6.5% improvement on the baseline, but there is no analysis of the meaningfulness of the representations.	B-Review	B-4	Review	604
[line_break_token]- "Table 13.2" should be "Table 2".	I-Review	I-4	Review	604
[line_break_token]- please be mindful of formatting, some citations should be parenthesized and there are numerous extraneous and missing spacings between words and sentences.	I-Review	I-4	Review	604
[line_break_token]	O	O	Review	604
To AnonReview1:[line_break_token]We appreciate your valuable comments and suggestions.	O	O	Reply	604
We have modified our paper accordingly and submitted a revised version on Jan 11th.	O	O	Reply	604
Sorry for the long delay.	O	O	Reply	604
It takes us a while to carry out experiments on the large-scale ImageNet benchmark.	O	O	Reply	604
[line_break_token][line_break_token]* About Non-linear cases to derive similar results:[line_break_token]Great thanks.	B-Reply	B-1	Reply	604
More general idea could be derived for (1) non-linear ReLU and max-pooling as well as (2) deeper models with 3+ layers.	I-Reply	I-1	Reply	604
Many other popular forms such as tanh could also be used.	I-Reply	I-1	Reply	604
[line_break_token]We are working on this question and focus on ReLU case here.	I-Reply	I-1	Reply	604
The ReLU operator on a hidden "h" and changes the 1st order gradient of dE/dh.	I-Reply	I-1	Reply	604
A tricky problem is that ReLU is not 2nd-order differentiable with infinite Hessian.	I-Reply	I-1	Reply	604
If we substitute ReLU(x)=max{0,x} with a 2nd-order differentiable version CReLU(x)=ln(1+e^x), the revised Hessian of Eqn(11) is still convex and could be numerically more stable with regularizer added.	I-Reply	I-1	Reply	604
Also, for max-pooling case, the selected max-value among the max operation channels will dominate the computation and set the 1st and 2nd order derivatives of non-maximum elements to zero.	I-Reply	I-1	Reply	604
[line_break_token][line_break_token]These are our preliminary extension to the more common non-linear scenario and added in the revised version.	I-Reply	I-1	Reply	604
Though linear case is also non-trivial due to the non-convexity of the optimization problem as a whole, a more general analysis will make our conclusion more complete.	I-Reply	I-1	Reply	604
We are working on the extension now.	I-Reply	I-1	Reply	604
[line_break_token][line_break_token]* About comparison with batch-normalization[line_break_token]Great thanks for the very good suggestion.	B-Reply	B-2	Reply	604
This issue is raised by several reviewers and is of importance to evaluate the proposed model completely.	I-Reply	I-2	Reply	604
We add classification performance comparison between our feature penalty method (FP) and batch normalization (BN).	I-Reply	I-2	Reply	604
It is a little tricky to set up a fair comparison, since our model only includes regularization on the last hidden layer and BN modules are generally added on every layer.	I-Reply	I-2	Reply	604
For now we still keep BN layers in previous layers.	I-Reply	I-2	Reply	604
Our current comparison on supervised learning tasks indicates that the two methods achieves similar performance on MNIST, CIFAR-10 and Omniglot; on ImageNet, BN is slightly better than FP (75% v.s.	I-Reply	I-2	Reply	604
74%).	I-Reply	I-2	Reply	604
Both BN and FP outperforms baseline CNN, and the best classification performance can be achieved with both modules added.	I-Reply	I-2	Reply	604
[line_break_token]We include this part in our revised version.	I-Reply	I-2	Reply	604
We notice that FP can substitute BN in every layer rather than only the last layer.	I-Reply	I-2	Reply	604
We are working on a more complete comparison.	I-Reply	I-2	Reply	604
[line_break_token][line_break_token]* About why feature regularizer works in case of low-shot learning:[line_break_token]This is the central question we try to answer in our paper, and we are carefully rethinking about this problem from the angle of generalization ability.	B-Reply	B-3	Reply	604
[line_break_token][line_break_token]In the origin paper of SGM, the intuitive explanation is that a large gradient might be outlier.	I-Reply	I-3	Reply	604
[line_break_token][line_break_token]We observe that in the supervised learning the CNN model achieves almost 100% accuracy on training and lower accuracy on testing, especially the several low-shot scenarios experimentally.	I-Reply	I-3	Reply	604
We regard the performance discrepancy is actually from over-fitting, due to the complexity and parameter amount of neural network models.	I-Reply	I-3	Reply	604
The training/testing performance discrepancy could be reduced if a good regularizer (with both feature penalty and weight decay) is introduced.	I-Reply	I-3	Reply	604
The regularizer acts like a "max-margin" (an analogy to SVM, the distance from support vectors to the plane) to limit the selection of parameter space and thus further reduce the "VC-dimension".	I-Reply	I-3	Reply	604
[line_break_token][line_break_token]This is our preliminary guess and we have included some analysis in our revised version.	I-Reply	I-3	Reply	604
We are working on improving it.	I-Reply	I-3	Reply	604
[line_break_token][line_break_token]* Strict in presentation and reorganization of the paper:[line_break_token]Great thanks for the suggestions of presentation improvement.	B-Reply	B-4	Reply	604
We have already modified some of them accordingly in our revised version.	I-Reply	I-4	Reply	604
We will further proof-read to make it better.	I-Reply	I-4	Reply	604
[line_break_token]Also, current version is a little bit too dense.	I-Reply	I-4	Reply	604
We manage to include new experimental results and analysis in our revised paper.	I-Reply	I-4	Reply	604
We will trim it down within 9 pages, with some detailed derivations left in supplemental materials	I-Reply	I-4	Reply	604

Summary:[line_break_token]This paper proposes learning a pooling layer (not necessarily of a convolutional network) by using temporal coherence to learn the pools.	O	O	Review	53
Training is accomplished by minimizing a criterion that encourages the features to change slowly but have high entropy over all.	O	O	Review	53
[line_break_token]Detailed comments:[line_break_token]-The method demonstrates improvement over a spatial pooling baseline[line_break_token]-The experiments here don't allow comparison to prior work on learning pools, such as the paper by Jia and Huang.	B-Review	B-1	Review	53
[line_break_token]- The method is not competitive with the state of the art[line_break_token][line_break_token]Suggestions to authors:[line_break_token][line_break_token]In future revisions of this paper, please be more specific about what your source of natural videos was.	B-Review	B-2	Review	53
Just saying vimeo.com is not very specific.	B-Review	B-3	Review	53
vimeo.com has a lot of videos.	I-Review	I-3	Review	53
How many did you use?	I-Review	I-3	Review	53
Do they include the same kinds of objects as you need to classify on CIFAR-10?	I-Review	I-3	Review	53
[line_break_token]Comparing to Jia and Huang is very important, since they also study learning pooling structure.	I-Review	I-3	Review	53
Note that there are also new papers at ICLR on learning pooling structure you should consider in the future.	I-Review	I-3	Review	53
I think Y-Lan Boureau also wrote a paper on learning pools that might be relevant.	I-Review	I-3	Review	53
[line_break_token]Pros:[line_break_token]-The method demonstrates some improvement over baseline pooling systems applied to the same task.	O	O	Review	53
[line_break_token][line_break_token]Cons:[line_break_token]-Doesn't compare to prior work on learning pools[line_break_token]-The method isn't competitive with the state of the art, despite having access to extra training data.	B-Review	B-1	Review	53
First of all, thank you for reviewing our paper.	O	O	Reply	53
It was a valuable feedback.	O	O	Reply	53
We will try to include mentioned papers in the next revision.	O	O	Reply	53
[line_break_token][line_break_token]About the video dataset:[line_break_token]- We will include a detailed explanation in the next revision.	B-Reply	B-3	Reply	53
In short, 40 short (2-5 minutes in length) videos are used in our experiments.	I-Reply	I-3	Reply	53
We tried to collect videos containing the same objects as CIFAR10.	I-Reply	I-3	Reply	53
However, images extracted from the videos were very different from CIFAR10 images.	I-Reply	I-3	Reply	53
Many of them didn't include any object, and some only showed a small part of an object.	I-Reply	I-3	Reply	53
[line_break_token][line_break_token]Comparison to Jia and Huang's method:[line_break_token]- We didn't compare our method to Jia and Huang's method, because they are fundamentally different methods.	B-Reply	B-1	Reply	53
While Jia and Huang's method learns pooling regions in a supervised way, our method tries to learn pooling regions in an unsupervised way, which has many advantages.	I-Reply	I-1	Reply	53
[line_break_token]- Although our method uses additional data, the data used for learning pooling regions was not labeled.	I-Reply	I-1	Reply	53
On the other hand, Jia and Huang's method has an advantage of using labeled data, which produces pooling regions specialized for the classification task.	I-Reply	I-1	Reply	53
[line_break_token][line_break_token]Comparison to state-of-art methods:[line_break_token]- It is true that our result on CIFAR10 is below the state-of-art.	B-Reply	B-2	Reply	53
However, as shown by Adam Coates (ICML, 2011), classification results are largely influenced by the configuration of feature learning, especially by the number of features.	I-Reply	I-2	Reply	53
Since the feature learning was not our research focus, we did little tweaking and optimization in the feature learning step.	I-Reply	I-2	Reply	53
Also, restricted by the computation time, we didn't use large number of features (100 instead of 1600), which is likely the main reason of the low test accuracies.	I-Reply	I-2	Reply	53
[line_break_token][line_break_token]- In the end, let us restate the main contribution of our paper.	I-Reply	I-2	Reply	53
Our pooling method is novel because it learned pooling regions in an unsupervised way.	I-Reply	I-2	Reply	53
In addition, it does not use explicit spatial information and it can be used with any pre-learned features.	I-Reply	I-2	Reply	53
To the best our knowledge, there is no other pooling method that suffices those conditions	I-Reply	I-2	Reply	53

The paper describes a method for integrating scale equivariance into convolutional networks using steerable filters.	O	O	Review	87
 After developing the theory using continuous scale and translation space, a discretized implementation using a fixed set of steerable basis elements is described.	O	O	Review	87
 Experiments are performed measuring the error from true equivariance, varying number of layers, image scale and scales in scale interactions.	O	O	Review	87
 The method is evaluated using MNIST-scale and STL-10, with convincing results on MNIST-scale and bit less convincing but still good results on STL-10.	O	O	Review	87
[line_break_token][line_break_token]Overall, I think this is a nice paper with generally good explanations and experiments probing the behavior.	O	O	Review	87
 I would have liked to see more probing into the effects of number and distance between scales.	B-Review	B-1	Review	87
 Table 1 and corresponding text say that a significant advantage of the approach is that it can handle arbitrary scale values, but there was no explicit exploration of the effects of using this beyond one set of scales per experiment/dataset.	I-Review	I-1	Review	87
 What scale values can be sampled, which work best, and why?	I-Review	I-1	Review	87
[line_break_token][line_break_token]Also, while the MNIST-scale experiment seems convincing, I think the STL-10 is a bit less (but still OK):  Although the method outperforms other methods and appropriate baseline models, it's a little disappointing that pooling over scales (which I would would convert the equivariance to invariance) is best, and inter-scale interactions increase error.	B-Review	B-2	Review	87
 (Perhaps this is not too surprising in retrospect, as images may have limited scale variation from camera position in this dataset, but significant within-class viewpoint variation.)	I-Review	I-2	Review	87
[line_break_token][line_break_token]Even so, I still find the method concise and of interest, with the basics evaluated, even if some of its unique advantages may have been better explored.	O	O	Review	87
[line_break_token][line_break_token][line_break_token]Additional Questions:[line_break_token][line_break_token]* Inter-scale interaction could be elaborated a bit more.	B-Review	B-3	Review	87
 End of sec 4 says, "use convHH for each scale sequentially and .. sum".	I-Review	I-3	Review	87
 I believe this is sequencing over scales in the kernel; explaining a bit better how this is implemented, including the shape of w in this case, would be helpful.	I-Review	I-3	Review	87
[line_break_token][line_break_token]* Which scales were chosen for the fixed basis?	B-Review	B-4	Review	87
 How large in spatial extent are the kernels in the basis elements, at each scale?	I-Review	I-4	Review	87
[line_break_token][line_break_token]* In the implementation, what is the value of V (sampled 2d conv kernel size)?	B-Review	B-5	Review	87
[line_break_token]	O	O	Review	87
hank you for your review.	O	O	Reply	87
[line_break_token][line_break_token]We compared our results on STL-10 to the current state-of-the-art model in the supervised learning setting known as Harm-WRN.	B-Reply	B-2	Reply	87
Our model SESN-B ourperformes it by more than 1% and achieves new state-of-the-art result on this dataset in the supervised learning setting.	I-Reply	I-2	Reply	87
We include Harm-WRN  in Table 3 for comparison.	I-Reply	I-2	Reply	87
[line_break_token][line_break_token]Q: Inter-scale interaction could be elaborated a bit more.	O	O	Reply	87
I believe this is sequencing over scales in the kernel.	O	O	Reply	87
[line_break_token] [line_break_token]A: Indeed.	B-Reply	B-2	Reply	87
You are right.	I-Reply	I-2	Reply	87
In the case of interscale interaction has shape.	I-Reply	I-2	Reply	87
We iterate over all scales in interaction, we shift for each scale and choose a corresponding part of and apply convHH.	I-Reply	I-2	Reply	87
We sum the obtained results afterwards.	I-Reply	I-2	Reply	87
Thank you for this comment.	I-Reply	I-2	Reply	87
We rephrased this section of our paper to make it easier for understanding.	I-Reply	I-2	Reply	87
[line_break_token][line_break_token]-------------------------[line_break_token][line_break_token]Q: Which scales were chosen for the fixed basis?	O	O	Reply	87
How large in spatial extent are the kernels in the basis elements, at each scale?	O	O	Reply	87
In the implementation, what is the value of V?	O	O	Reply	87
[line_break_token][line_break_token]A: The scales and therefore are the hyperparameters of the proposed method.	B-Reply	B-5	Reply	87
The set of values we choose from is tailored by the requirement of the completeness of the obtained basis on the smallest scale when it is projected to the pixel grid.	I-Reply	I-5	Reply	87
[line_break_token][line_break_token]For MNIST-scale experiment we used 4 scales with a step of.	I-Reply	I-5	Reply	87
We generate filters for and store them in an array of spatial extent of.	I-Reply	I-5	Reply	87
We choose by relying on prior knowledge about the dataset.	I-Reply	I-5	Reply	87
And the value of 1.5 is chosen from a set of with a step of 0.1 by using cross-validation.	I-Reply	I-5	Reply	87
We choose the value which gives the best accuracy on the validation set.	I-Reply	I-5	Reply	87
The variation of the accuracy during cross-validation is of 0.1% on the scale of about 2%.	I-Reply	I-5	Reply	87
[line_break_token][line_break_token]For STL-10 experiment, we sample 3 bases for and store them in an array of spatial extent of.	I-Reply	I-5	Reply	87
We chose the maximum number of scales we are able to use on our hardware.	I-Reply	I-5	Reply	87
Here we use value of as it generated the complete basis on the smallest scale.	I-Reply	I-5	Reply	87
And the value of is motivated by the assumption that in natural images of cats, cars, horses, etc.	I-Reply	I-5	Reply	87
the scale variations are usually of factor 2.	I-Reply	I-5	Reply	87
We did not run cross validation on this dataset	I-Reply	I-5	Reply	87

This paper proposes a new method for solving the metric constrained problem based on projections on cutting planes.	O	O	Review	20199
Its main contribution comes from the "forgetting" part, where unnecessary constraints (that are inactive) are removed in order to keep the number of constraints manageable.	O	O	Review	20199
[line_break_token][line_break_token]Pros: [line_break_token][line_break_token]The methods seem practically useful as verified in the experiments.	O	O	Review	20199
[line_break_token][line_break_token]Cons: [line_break_token][line_break_token]Most importantly, the paper is out of format and there exist some critical typos that need to be fixed.	O	O	Review	20199
[line_break_token]- The margin of the paper is wider than the official ICLR format.	B-Review	B-1	Review	20199
It needs to be reformatted and verified to be under 10 pages limit.	I-Review	I-1	Review	20199
[line_break_token]- There seem to be multiple Latex bugs on referring the section numbers, e.g., "see appendix refsec:genealProblem" at bottom of page 5.	B-Review	B-2	Review	20199
[line_break_token][line_break_token]There is no theoretical guarantee on its improvement over existing methods, i.e., the forgotten constraints can reappear during optimization for multiple numbers of times.	B-Review	B-3	Review	20199
However, I think this point is not crucial given the empirical usefulness of the algorithm.	I-Review	I-3	Review	20199
[line_break_token][line_break_token]Minor questions: [line_break_token]- To my knowledge, cutting plane methods for the integer programming method (including Gurobi) already use an instance "project and forget" method, i.e., iteratively solving linear programs and then adding &amp; removing cutting planes.	O	O	Review	20199
See [1] for an example.	B-Review	B-4	Review	20199
Could the authors discuss the relationship between the two methods and highlight the relative difference &amp; contribution?	O	O	Review	20199
[line_break_token][line_break_token][1] The cutting plane method is polynomial for perfect matchings, Chandrasekaran et al 2012[line_break_token][line_break_token]========= [line_break_token][line_break_token]I have checked that the authors have re-formatted the paper into a correct form.	O	O	Review	20199
I raise my score since I think the paper is interesting and provides a practically useful algorithm.	O	O	Review	20199
he question about cutting planes is a great question.	B-Reply	B-4	Reply	20199
As far as this author understands it, the cutting plane method in Gurobi is for mixed integer programming (MIP) and uses Gromov cuts.	I-Reply	I-4	Reply	20199
[line_break_token][line_break_token]The difficulty of MIPs comes from the integrality constraints and not because they have a large number of constraints.	I-Reply	I-4	Reply	20199
Hence using Gromov cuts lets us reduce the choices for the integral constraints until we can add the constraint.	I-Reply	I-4	Reply	20199
Thus, reducing it to a linear program.	I-Reply	I-4	Reply	20199
[line_break_token][line_break_token]However, in general, the cutting plane method highly depends on the choice of cuts.	I-Reply	I-4	Reply	20199
 See [2,3] for in-depth discussions.	I-Reply	I-4	Reply	20199
For other problems that are not MIPs, we have some success cases such as [1], but we have not had success in all problems.	I-Reply	I-4	Reply	20199
[line_break_token][line_break_token]One of the key differences between the standard cutting plane method and Project and Forget is that in the standard cutting plane method, every time we introduce new constraints, we solve the whole optimization problem again.	I-Reply	I-4	Reply	20199
In the case of Project and Forget, we do a round of projections.	I-Reply	I-4	Reply	20199
 [line_break_token][line_break_token]Re-solving the LP again has potential issues.	I-Reply	I-4	Reply	20199
In the case of metric constrained problems, we have a large number of constraints.	I-Reply	I-4	Reply	20199
Thus, if we added a large portion of these constraints, we still cannot solve the LP using standard techniques.	I-Reply	I-4	Reply	20199
 We could add in the constraints slowly so that this is not an issue.	I-Reply	I-4	Reply	20199
However, then the intermediate solutions do not necessarily tell us anything about the final solution, and it is unclear whether progress is being made, and we may need too many rounds.	I-Reply	I-4	Reply	20199
[line_break_token][line_break_token]The Project and Forget method addresses this issue.	I-Reply	I-4	Reply	20199
If we added into many inactive constraints, then we only need to do one round of projections.	I-Reply	I-4	Reply	20199
This is less computationally expensive than solving a whole LP.	I-Reply	I-4	Reply	20199
Thus, we get to the forget step much faster.	I-Reply	I-4	Reply	20199
Thus in practice, we add a large number of constraints initially, as seen in Figure 1.	I-Reply	I-4	Reply	20199
However, we forget the inactive constraints quickly, and the projections done onto the active constraints constitute some progress towards finding the final solution. (	I-Reply	I-4	Reply	20199
We may have projected onto inactive constraints, but experimentally, we tend to undo this relatively quickly.)	I-Reply	I-4	Reply	20199
[line_break_token][line_break_token]Finally, we also have the generic version of our algorithm presented in the appendix.	I-Reply	I-4	Reply	20199
For the general version of the algorithm, we have a subroutine that we dub the oracle.	I-Reply	I-4	Reply	20199
Here the oracle is just the cutting plane selection method.	I-Reply	I-4	Reply	20199
Here we show that under some weak assumptions (property 1) that our algorithm has a linear rate of convergence.	I-Reply	I-4	Reply	20199
Additionally, we show that if we randomly sample constraints, then with probability 1, we have a linear rate of convergence.	I-Reply	I-4	Reply	20199
[line_break_token][line_break_token][1]Karthekeyan Chandrasekaran, L√°szl√≥ A. V√©gh, and Santosh Vempala.	O	O	Reply	20199
The cutting plane method is polynomial for perfect matchings.	O	O	Reply	20199
In 2012 IEEE 53rd Annual Symposium on Foundations of Computer Science[line_break_token][2]Santanu S. Dey and Marco Molinaro.	O	O	Reply	20199
Theoretical challenges towards cutting-plane selection.	O	O	Reply	20199
Math.	O	O	Reply	20199
Program.	O	O	Reply	20199
[line_break_token][3]Laurent Poirrier and James Yu.	O	O	Reply	20199
On the depth of cutting planes.	O	O	Reply	20199
arXiv e-prints.	O	O	Reply	20199

Summary[line_break_token]This paper propose an extention method of SGD, deep gradient boosting (DGB), which views the back-propagation procedure as a pseudo-residual targets of a gradient boosting problem.	O	O	Review	170
To apply DGB to the real CNNs, DGB is simplified to a input normalization layer, conditioned on the assumption that the convolution kernels should be small.	O	O	Review	170
After applying the input normalization layer to CNNs, the model could achieve comparable performance to the model with BN on CIFAR-10 and ImageNet recognition.	O	O	Review	170
[line_break_token][line_break_token]There are several concerns influencing my rating:[line_break_token]* I cannot catch the advantages of this input normalization layer compared to BN.	B-Review	B-1	Review	170
For example, could this input normalization layer help to address the problem that BN performs bad when batch size is small?	I-Review	I-1	Review	170
The authors mention that this layer does not have additional parameters.	I-Review	I-1	Review	170
But as I know, the parameter size of BN is small, which downgrades the significance of the proposed method.	I-Review	I-1	Review	170
[line_break_token][line_break_token]* In the CIFAR-10 and ImageNet experiments, only the VGG model is adopted, which obviously limits the application scope.	B-Review	B-2	Review	170
Could the proposed method work well on ResNet, DenseNet or other more recent deep architectures?	I-Review	I-2	Review	170
[line_break_token][line_break_token]* In the DGB experiments, the improvements of DGB compared with SGD in four datasets all seem marginal, in which DGB is slower than SGD.	B-Review	B-3	Review	170
[line_break_token][line_break_token]Overall, I recognize the exploration of this method.	O	O	Review	170
But the advantages of DGB compared to SGD seem marginal.	O	O	Review	170
[line_break_token]	O	O	Review	170
hank you for carefully reading the paper.	O	O	Reply	170
[line_break_token][line_break_token]Though we mostly focus on INN(l), INN(l) is an alternative to batch norm and INN(r) is an alternative to layer norm.	B-Reply	B-1	Reply	170
This work shows how both formulations are equivalent and emerge from the dual solution to ridge regression.	I-Reply	I-1	Reply	170
INN also gives a specific meaning to alpha which can be treated as a hyper-parameter and adjusted according to the problem.	I-Reply	I-1	Reply	170
It is true that the parameter space of BN is small in comparison the the space of parameters of modern deep networks but could be significant in smaller applications.	I-Reply	I-1	Reply	170
In addition, without the extra parameters memory saving schemes could be employed where the intermediate outputs don't need to be saved during the forward pass and could be calculated on the fly during the backward pass.	I-Reply	I-1	Reply	170
[line_break_token][line_break_token]For ImageNet, we have added a couple of experiments performed using ResNet101 to the manuscript.	B-Reply	B-2	Reply	170
[line_break_token][line_break_token]We have added running times for the MNIST experiment and showed that for a batch size of 100 samples DGB(r) takes just 13% more time per iteration.	B-Reply	B-3	Reply	170
We'd also like to point out that the performance increase for Air and Higgs are significant given the standard deviations shown in Tables A1 and A4.	I-Reply	I-3	Reply	170

The authors propose TD-VAE to solve an important problem in agent learning, simulating the future by doing jumpy-rollouts in abstract states with uncertainty.	O	O	Review	122
The authors first formulate the sequential TD-VAE and then generalize it for jumpy rollouts.	O	O	Review	122
The proposed method is well evaluated for four tasks including high dimensional complex task.	O	O	Review	122
[line_break_token][line_break_token]Pros.	O	O	Review	122
[line_break_token]- Advancing a significant problem[line_break_token]- Principled and quite original modeling based on variational inference[line_break_token]- Rigorous experiments including complex high dimensional experiments[line_break_token]- Clear and intuitive explanation (but can be improved further)[line_break_token][line_break_token]Cons.	O	O	Review	122
[line_break_token]- Some details on the experiments are missing (due to page limit).	B-Review	B-1	Review	122
It would be great to include these in the Appendix.	I-Review	I-1	Review	122
[line_break_token]- It is a complex model.	B-Review	B-2	Review	122
For reproducibility, detail specification on the hyperparameters and architecture will be helpful.	I-Review	I-2	Review	122
[line_break_token][line_break_token]Minor comments[line_break_token]- Why q(z_{t-1}|z_t, b_{t-1}, b_t) depends both  b_{t-1}, b_t, not only b_t?	B-Review	B-3	Review	122
[line_break_token]- The original model does not take the jump interval as input.	B-Review	B-4	Review	122
Then, it is not clear how the jump interval is determined in p(z‚Äô|z)?	I-Review	I-4	Review	122
[line_break_token]	O	O	Review	122
Thank you for the review and comments.	O	O	Reply	122
[line_break_token]Thanks for the suggestion - we added missing experiment details, network specifications and hyperparameters in the appendix.	B-Reply	B-1	Reply	122
[line_break_token]You are correct that q(z_{t-1}|z_t, b_{t-1}, b_t) does not need to depend on b_{t-1}, but it does not hurt to do so; we chose to do so in order to further facilitate the learning of b_{t-1}, but it may not have affected experiments.	B-Reply	B-3	Reply	122
[line_break_token]If the model does not take the jump interval as input, the model has to represent the jump size by way of a multimodal distribution over possible future events.	B-Reply	B-4	Reply	122
One could imagine that one of the latent variables could be learned to correspond to dt.	I-Reply	I-4	Reply	122
[line_break_token]	O	O	Reply	122

This paper first theoretically demonstrates that a commonly used reinforcement learning method for neural sequence-to-sequence models (e.g. in NMT), contrastive minimum risk training (CMRT), is not guaranteed to converge to local (let alone global) optima of the reward function.	O	O	Review	10112
The paper then empirically demonstrates that the REINFORCE algorithm, while not subject to the same theoretical flaws as CMRT, in practice fails to improve NMT models unless the baseline model is already "nearly correct" (i.e. the correct tokens were already within the few most probable tokens before the fine-tuning steps with REINFORCE).	O	O	Review	10112
In fact, some of the performance gains of using REINFORCE/CMRT can be attributed to making the model's output probability distribution more peaked, and not necessarily from making the target tokens more probable as commonly assumed.	O	O	Review	10112
[line_break_token][line_break_token]Overall, this is an excellent paper that offers significant contributions for the field.	O	O	Review	10112
I have summarised the key strengths of the paper below, along with several suggestions and questions that I hope will be addressed by the authors.	O	O	Review	10112
Based on my assessment, I am recommending a rating of "Accept" for this paper.	O	O	Review	10112
[line_break_token][line_break_token]Strengths:[line_break_token]1.	O	O	Review	10112
The paper is very well-written and well-structured.	O	O	Review	10112
It starts off by pointing out the theoretical limitations of CMRT (and concisely recaps the key differences between CMRT and REINFORCE), and continues with an extensive set of experiments that clearly illustrates the limitations of REINFORCE in practice.	O	O	Review	10112
[line_break_token][line_break_token]2.	O	O	Review	10112
I also like the use of both controlled simulations (including one where the reward is constant) and NMT experiments with real data.	O	O	Review	10112
The controlled simulations are useful to abstract away from the full complexity of the model and investigate what happens under various control scenarios, while the NMT experiments demonstrate that the findings still hold under the realistic setup.	O	O	Review	10112
[line_break_token][line_break_token]3.	O	O	Review	10112
The findings are really interesting and clearly illustrate the limitations of existing REINFORCE/CMRT methods for neural sequence-to-sequence models.	O	O	Review	10112
It is very interesting to see that REINFORCE fails to make the target token most probable when the initial model ranks the target token as the third or more probable tokens under the model (Figure 2), even under the simple controlled simulations, which highlights the prohibitively high sample complexity of the model.	O	O	Review	10112
[line_break_token][line_break_token]4.	B-Review	B-1	Review	10112
The peakiness effect hypothesis (i.e. attributing the gains of REINFORCE to making the output distribution more peaked, and not necessarily by making the target tokens more probable) is well-supported by the paper's empirical evidence.	O	O	Review	10112
It is really illuminating that using a constant reward of 1 leads to the same BLEU score as actually optimising for BLEU in NMT (Section 5.2).	O	O	Review	10112
[line_break_token][line_break_token]Suggestions and questions:[line_break_token]1.	O	O	Review	10112
Section 4.2 (NMT Experiments) indicates that REINFORCE fine-tuning is done for 10 epochs, with 5,000 sentences per epoch, and k=1.	B-Review	B-1	Review	10112
Considering the enormous discrete sample space, one could expect that using multi-sample REINFORCE (i.e. k &gt; 1) and training the model for many more epochs might mitigate the identified problems to some extent, and thus change the findings.	O	O	Review	10112
Training for 5,000 sentences * 10 epochs may just not be enough for the RL fine-tuning to make a big difference.	B-Review	B-1	Review	10112
[line_break_token][line_break_token]2.	O	O	Review	10112
In Figure 1, the x-axis is the "Update Size" with a scale between -1.0 and 1.0.	B-Review	B-2	Review	10112
This "Update Size" variable is not really explained in the paper, and why the scale is between -1.0 and 1.0.	I-Review	I-2	Review	10112
[line_break_token][line_break_token]3.	O	O	Review	10112
In my understanding, the controlled simulations (Section 4.1) is done at the word-level (including word-level rewards, as opposed to the NMT experiments which are done at the sequence-level with sentence-level rewards).	B-Review	B-3	Review	10112
If this is the case, this should be made clearer.	I-Review	I-3	Review	10112
[line_break_token][line_break_token]4.	B-Review	B-1	Review	10112
To make Figure 3 easier to understand, the caption should indicate that a lower cumulative percentage means a more peaked output distribution.	B-Review	B-4	Review	10112
[line_break_token][line_break_token]5.	O	O	Review	10112
Rather than breaking down the analysis by where the target token is ranked by the initial, pre-RL model (e.g. the target token is ranked second/third best in Figures 2 and 5), perhaps what really matters is the probability assigned to the target token.	B-Review	B-5	Review	10112
For instance, even if the target token is ranked third best by the initial model, there will be a big difference whether it is assigned a probability of 0.1 or 0.01 (i.e. the latter case is much less likely to be sampled, which would exacerbate the problem).	I-Review	I-5	Review	10112
Including this analysis might help strengthen the paper further.	I-Review	I-5	Review	10112
[line_break_token]	O	O	Review	10112
hank you for the positive review and for taking the time to thoroughly read and comment on our paper.	O	O	Reply	10112
[line_break_token][line_break_token]We will, of course, address all your comments regarding changes in the last version of the paper (e.g. elaborating more on ‚Äúupdate size‚Äù).	O	O	Reply	10112
[line_break_token][line_break_token]You mentioned the number of epochs run: it is possible to run more epochs, even though it is not a short process as it is (there are Monte Carlo roll-ups involved in the process too).	B-Reply	B-1	Reply	10112
The experiments indeed suggest that if we want to use this method effectively, we need to run for much longer.	I-Reply	I-1	Reply	10112
In practice, at this point of training, the patience already stops training and results drop.	I-Reply	I-1	Reply	10112
Increasing the patience might work, and is worth exploring, but if it does end up helping (if no other changes are made), our results suggest it‚Äôll take much more than a few tens of epochs.	I-Reply	I-1	Reply	10112
[line_break_token][line_break_token]Regarding the probabilities given to the third token, it is on average 0.04. (	B-Reply	B-5	Reply	10112
Note that in our simulations we used those numbers so the on point 0 the frequencies mentions can be observed).	I-Reply	I-5	Reply	10112

Update: I thank the authors for their comments!	O	O	Review	199
After reading them, I still think the paper is not novel enough so I'm leaving the rating untouched.	O	O	Review	199
[line_break_token][line_break_token]This paper proposes a domain adaptation technique for time series.	O	O	Review	199
The core of the approach is a combination of variational recurrent neural networks and adversarial domain adaptation (at the last time step).	O	O	Review	199
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]1.	O	O	Review	199
The authors consider a very important application of domain adaptation.	O	O	Review	199
[line_break_token][line_break_token]2.	O	O	Review	199
The paper is well-written and relatively easy to read.	O	O	Review	199
[line_break_token][line_break_token]3.	O	O	Review	199
Solid empirical evaluation.	O	O	Review	199
The authors compare their method against several recent domain adaptation techniques on a number of datasets.	O	O	Review	199
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]1.	O	O	Review	199
The novelty of the approach is relatively low: it‚Äôs just a straightforward fusion of the existing techniques.	B-Review	B-1	Review	199
[line_break_token][line_break_token]2.	O	O	Review	199
The paper lacks any motivation for use of the particular combination (VRNN and RevGrad).	B-Review	B-2	Review	199
I still believe comparable results can be obtained by polishing R-DANN (e.g. carefully penalizing domain discrepancy at every step)[line_break_token][line_break_token]Additional comments:[line_break_token][line_break_token]1.	O	O	Review	199
I‚Äôm not convinced by the discussion presented in Section 4.4.	B-Review	B-3	Review	199
I don‚Äôt think the visualization of firing patterns can be used to support the efficiency of the proposed method.	I-Review	I-3	Review	199
[line_break_token][line_break_token]2.	O	O	Review	199
Figure 1(c) looks very suspicious.	B-Review	B-4	Review	199
I can hardly believe t-SNE could produce this _very_ regular structure for non-degenerate (non-synthetic, real-world) data.	I-Review	I-4	Review	199
[line_break_token][line_break_token]Overall, it‚Äôs a solid paper but I‚Äôm not sure if it is up to the ICLR standard.	O	O	Review	199
Thank you for your comments and questions.	O	O	Reply	199
Below we provide more detailed comments to your questions.	O	O	Reply	199
[line_break_token][line_break_token]1.	O	O	Reply	199
The novelty of the approach is relatively low: it‚Äôs just a straightforward fusion of the existing techniques.	O	O	Reply	199
[line_break_token]A: We have clarified and highlighted our paper‚Äôs key novel contributions in the above 'Response to all reviewers' comment.	B-Reply	B-1	Reply	199
To briefly summarize - in this paper, we have focused on a very important problem in the healthcare application domain.	I-Reply	I-1	Reply	199
As far as we know, we are the first to propose unsupervised deep domain adaptation techniques to capture and transfer complex temporal dependencies present in healthcare multivariate time series data.	I-Reply	I-1	Reply	199
Our domain adaptation framework is general and is suitable for applications where dependencies are present in the multivariate time series data.	I-Reply	I-1	Reply	199
[line_break_token][line_break_token][line_break_token]2.	B-Reply	B-3	Reply	199
The paper lacks any motivation for use of the particular combination (VRNN and RevGrad).	O	O	Reply	199
I still believe comparable results can be obtained by polishing R-DANN (e.g. carefully penalizing domain discrepancy at every step)[line_break_token]A: We apologize for not being clear as to why we specifically used VRNN and reversal gradients.	B-Reply	B-2	Reply	199
Using a VRNN in VRADA, adds two capabilities: capture complex temporal dependencies present in the data and learns to create the data‚Äôs reconstruction.	I-Reply	I-2	Reply	199
 Both of these help our model learn more significant patterns within the data.	I-Reply	I-2	Reply	199
Using adversarial training via reversal gradients helps to learn domain-invariant representations.	I-Reply	I-2	Reply	199
We used this particular combination of VRNN with adversarial training since in healthcare applications matching the data distributions is more interesting than minimizing the distance between the data distribution means across domains (such as Mean Maximum Discrepancy (MMD)).	I-Reply	I-2	Reply	199
 Moreover, from a theoretical perspective, adversarial training idea [Ganin et.	I-Reply	I-2	Reply	199
al, JMLR 2016] is derived from the seminal works of [Ben-David et .	I-Reply	I-2	Reply	199
al, MLJ 2010]. [line_break_token]We would also like to inform that we have extensively fined tuned R-DANN to show the best results in our paper.	I-Reply	I-2	Reply	199
We have compared our approach fairly to Variational FAIR Autoencoder (denoted by VFAE) [Louizos C. et.	I-Reply	I-2	Reply	199
al, ICLR 2016], which uses MMD criterion.	I-Reply	I-2	Reply	199
We have empirically shown that VRADA outperforms both R-DANN and  VFAE on the healthcare datasets used in our paper.	I-Reply	I-2	Reply	199
[line_break_token][line_break_token]Additional comments:[line_break_token]Q 1.	O	O	Reply	199
I‚Äôm not convinced by the discussion presented in Section 4.4.	O	O	Reply	199
I don‚Äôt think the visualization of firing patterns can be used to support the efficiency of the proposed method.	O	O	Reply	199
[line_break_token]A: The discussion in section 4.4 is used to visualize and qualitatively compare the temporal dependencies captured by different domain adaptation approaches.	B-Reply	B-3	Reply	199
We used memory cell state activations for visualization.	I-Reply	I-3	Reply	199
In order to show that domain adaptation results in regular firing patterns, we have added plots to the appendix that show how firing patterns differ when domain adaptation isn‚Äôt applied.	I-Reply	I-3	Reply	199
You can then see a clear direction in the regularity of the firing patterns as (a) domain adaptation is applied, and (b) a better domain adaptation technique is applied.	I-Reply	I-3	Reply	199
We addressed the regularity found in Figure 4 in appendix section 6.2.3.	I-Reply	I-3	Reply	199
[line_break_token][line_break_token][line_break_token]Q 2.	O	O	Reply	199
Figure 1(c) looks very suspicious.	O	O	Reply	199
I can hardly believe t-SNE could produce this _very_ regular structure for non-degenerate (non-synthetic, real-world) data.	O	O	Reply	199
[line_break_token]A: Inspired by the feature representation visualization shown in [Ganin et.	B-Reply	B-4	Reply	199
al, JMLR 2016], we also use t-SNE plots to show the domain invariant feature representations learned by various domain adaptation approaches.	I-Reply	I-4	Reply	199
In Figure 1, we showed the t-SNE results which we consistently obtained for the source-target pairs from Adult-AHRF to Child-AHRF data.	I-Reply	I-4	Reply	199
It was surprising for us to see a regular t-SNE plot but that is the plot we obtained for the 3-1 source-target pair.	I-Reply	I-4	Reply	199
We also varied perplexity (from 5 to 100) and obtained similar t-SNE plots from our VRADA model.	I-Reply	I-4	Reply	199
We will release our codes to public for reproducibility.	I-Reply	I-4	Reply	199
[line_break_token][line_break_token][line_break_token]References:[line_break_token][Ganin et.	O	O	Reply	199
al, JMLR 2016] Ganin, Yaroslav, et al "Domain-adversarial training of neural networks."	O	O	Reply	199
Journal of Machine Learning Research 17.59 (2016): 1-35.	O	O	Reply	199
[line_break_token][Ben-David et.	O	O	Reply	199
al, MLJ 2010] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan.	O	O	Reply	199
A theory of learning from different domains.	O	O	Reply	199
Machine Learning, 9(1-2):151‚Äì175, 2010.	O	O	Reply	199
[line_break_token][Louizos C. et.	B-Reply	B-2	Reply	199
al, ICLR 2016] Louizos, Christos, et al "The variational fair autoencoder."	O	O	Reply	199
ICLR (2016)	O	O	Reply	199

This paper proposes an efficient algorithm to learn  neural embedding models with a dot-product structure over very large corpora.	O	O	Review	321
The main method is to reformulate the objective function in terms of generalized Gramiam matrices, and maintain estimates of those matrices in the training process.	O	O	Review	321
The algorithm uses less time and achieves significantly better quality than sampling based methods.	O	O	Review	321
[line_break_token][line_break_token]1.	O	O	Review	321
About the experiments, it seems the sample size for sampling based experiments is not discussed.	B-Review	B-1	Review	321
The number of noise samples have a large influence on the performance of the models.	I-Review	I-1	Review	321
In figure 2, different sampling strategies are discussed.	I-Review	I-1	Review	321
It would be cool if we can also see how the sampling size affects the estimation error.	I-Review	I-1	Review	321
[line_break_token][line_break_token]2.	O	O	Review	321
If we just look at the sampling based methods, in figure 2a, uniform sampling‚Äôs Gramian estimates is the worst.	B-Review	B-2	Review	321
But the MAP of uniform sampling on validation set for all three datasets are not the worst.	I-Review	I-2	Review	321
Do you have any comments?	I-Review	I-2	Review	321
[line_break_token][line_break_token]3.	O	O	Review	321
wheter an edge -> whether an edge.	O	O	Review	321
[line_break_token]	O	O	Review	321
Thank you for your review and your helpful suggestions.	O	O	Reply	321
[line_break_token][line_break_token]1) On the effect of sample size: we agree that the sample size directly affects the performance of these methods.	B-Reply	B-1	Reply	321
We investigated this effect in Appendix D.2 (which is now Appendix E.4 in the revision), where we ran the same experiment on Wikipedia English with batch sizes 128, 512 (Tables 3 and 4), and compared the results to batch size 1024 (Table 2).	I-Reply	I-1	Reply	321
We simultaneously varied the learning rate to understand its effect as well, but focusing on the effect of batch size only, we can observe that[line_break_token](i) the performance of all methods increases with the batch size (at least in the 128-1024 range).	I-Reply	I-1	Reply	321
[line_break_token](ii) the relative improvement of our methods (compared to the baseline) is larger for smaller batch sizes: the relative improvement is 19.5% for 1024, 26.7% for 512, and 29.1% for 128.	I-Reply	I-1	Reply	321
[line_break_token]Of course, one cannot increase the batch size indefinitely as there are hard limits on memory size, and the key advantage of our methods is in problems where sampling-based methods give poor estimates even with the largest feasible batch size.	I-Reply	I-1	Reply	321
[line_break_token]The effect of the batch size can also be seen to some extent in Figure 2.a, where we show the quality of the Gramian estimates for batch size 128 and 1024.	I-Reply	I-1	Reply	321
The figure suggests that the quality improves, for all methods, with larger batch sizes, and that SOGram with batch size 128 has a comparable estimation quality to the baseline with batch size 1024.	I-Reply	I-1	Reply	321
[line_break_token][line_break_token]2) The reviewer raises an interesting point.	B-Reply	B-2	Reply	321
We have observed in our experiments that for a fixed sampling distribution, improving the Gramian estimates generally leads to better MAP, but we cannot draw conclusions when the sampling distribution changes.	I-Reply	I-2	Reply	321
One possible explanation is that the sampling distribution affects both the quality of the Gramian estimates, and the frequency at which the item embeddings are updated.	I-Reply	I-2	Reply	321
In particular, tail items are sampled more often under uniform sampling than under the other distributions, and updating their embeddings more frequently may contribute to improving the MAP.	I-Reply	I-2	Reply	321
We added a comment (Appendix E.2 in the revision) to highlight this observation	I-Reply	I-2	Reply	321

This paper proposed another GAN-based PU learning method.	O	O	Review	1270
The mathematics in this paper is not easy to follow, and there are many other critical issues.	O	O	Review	1270
[line_break_token][line_break_token]*****[line_break_token][line_break_token]The clarity is really an issue.	O	O	Review	1270
First of all, I cannot easily follow the meanings behind the equations.	B-Review	B-1	Review	1270
I guess the authors first came up with some concrete implementation and then formalize it into an algorithm.	I-Review	I-1	Review	1270
Given the current version of the paper, I am not sure whether this clarity of equations can be fixed without an additional round of review or not.	I-Review	I-1	Review	1270
[line_break_token][line_break_token]Moreover, the logic in the story line is unclear to me, especially the 3rd paragraph that seems to be mostly important in the introduction.	B-Review	B-2	Review	1270
There are two different binary classification problems, of separating the positive and negative classes, and of separating the given and generated data.	I-Review	I-2	Review	1270
I cannot see why the generated data can serve as negative data.	I-Review	I-2	Review	1270
This paragraph is discussing GenPU, PGAN and the proposed method, and consequently the motivation of the current paper does not make sense at least to me.	I-Review	I-2	Review	1270
[line_break_token][line_break_token]*****[line_break_token][line_break_token]The paper classified PU learning methods into two categories, one-stage methods and two-stage methods.	B-Review	B-3	Review	1270
This is interesting.	I-Review	I-3	Review	1270
However, before that, they should be classified into two categories, for censoring PU learning and for case-control PU learning.	I-Review	I-3	Review	1270
The former problem setting was proposed very early and formalized in "learning classifiers from only positive and unlabeled data", KDD 2008; the latter problem setting was proposed in "presence-only data and the EM algorithm", Biometrics 2009 and formalized in "analysis of learning from positive and unlabeled data", NIPS 2014.	O	O	Review	1270
Surprisingly, none of these 3 papers was cited.	O	O	Review	1270
By definition, GAN-based PU learning belongs to the latter problem setting while Rank Prune can only be applied to the former but was included as a baseline method.	O	O	Review	1270
[line_break_token][line_break_token]The huge difference between these two settings and their connections to learning with noisy labels are known for long time.	O	O	Review	1270
To be short, class-conditional noise model corrupts P(Y|X) and covers censoring PU, mutual contamination distribution framework corrupts P(X|Y) and covers case-control PU, and mathematically mutual contamination distribution framework is more general than class-conditional noise model and so is case-control PU than censoring PU.	O	O	Review	1270
See "learning from corrupted binary labels via class-probability estimation", ICML 2015 for more information where the above theoretical result has been proven.	O	O	Review	1270
An arXiv paper entitled "on the minimal supervision for training any binary classifier from only unlabeled data" has some experimental results showing that methods for class-conditional noise model cannot handle mutual contamination distributions.	O	O	Review	1270
The situation is similar when applying censoring PU methods to case-control PU problem setting.	O	O	Review	1270
[line_break_token][line_break_token]Furthermore, the class-prior probability pi is well-defined and easy to estimate in censoring PU, see "learning classifiers from only positive and unlabeled data" mentioned above.	O	O	Review	1270
However, it is not well-defined in case-control PU due to an identifiability issue described in "presence-only data and the EM algorithm" mentioned above.	O	O	Review	1270
Thus, the target to be estimated is defined as the maximal theta such that theta*P(X|Y)<=P(X) following "estimating the class prior and posterior from noisy positives and unlabeled data", NIPS 2016.	O	O	Review	1270
BTW, "mixture proportion estimation via kernel embedding of distributions" is SOTA in class-prior estimation; the previous NIPS paper was written earlier and accepted later.	O	O	Review	1270
[line_break_token][line_break_token]In summary, as claimed in the paper and shown in Table 1 in the introduction, all discriminative PU methods and GenPU require to know pi for learning.	O	O	Review	1270
This is true, but this is because they are designed for a more difficult problem setting---learning classifiers and estimating pi are both more difficult.	O	O	Review	1270
Lacking some basic knowledge of PU learning is another big issue.	O	O	Review	1270
[line_break_token][line_break_token]*****[line_break_token][line_break_token]The novelty is to be honest incremental and thus below the bar of ICLR.	O	O	Review	1270
The significance is similarly poor, due to that the experiments mixed up methods for censoring PU and those for case-control PU.	O	O	Review	1270
What is more, F1-score is a performance measure for information retrieval rather than binary classification.	O	O	Review	1270
We all know GANs are pretty good at MNIST but not CIFAR-10.	O	O	Review	1270
In fact, GenPU has a critical issue of mode collapse, and this is why GenPU reports 1-vs-1 rather than 5-vs-5 on MNIST.	O	O	Review	1270
Even though, I still think GenPU makes much more sense than PGAN and D-GAN.	O	O	Review	1270
Thanks for your constructive review,[line_break_token]Your comments indicate that the text and equations are not clear enough and that some previous state of the art methods were omitted.	O	O	Reply	1270
We understand that the lack of clarity can be an issue.	O	O	Reply	1270
We made during this rebuttal period a clarification effort.	O	O	Reply	1270
[line_break_token]Moreover, please find as follow the answers to your comments.	O	O	Reply	1270
[line_break_token][line_break_token][line_break_token]*****[line_break_token][line_break_token][line_break_token]‚ÄúI cannot easily follow the meanings behind the equations.	O	O	Reply	1270
‚Äù[line_break_token][line_break_token]We have clarified the equations.	B-Reply	B-1	Reply	1270
[line_break_token][line_break_token][line_break_token]‚ÄúI cannot see why the generated data can serve as negative data.	O	O	Reply	1270
‚Äù ‚ÄúThis paragraph is discussing GenPU, PGAN and the proposed method, and consequently the motivation of the current paper does not make sense at least to me.	O	O	Reply	1270
‚Äù [line_break_token][line_break_token]GANs are known to be relevant because of their ability of finding a boundary between real and generated samples: A GAN discriminator is trained to find autonomously the best metric to evaluate the generated samples quality.	B-Reply	B-2	Reply	1270
This metric is considered as more relevant than previous ones such as the auto-encoders per-pixel reconstruction loss function.	I-Reply	I-2	Reply	1270
[line_break_token]The GAN-based PU approaches main idea is to exploit this GAN benefit to address a PU learning problem: The initial goal of GANs is to imitate the unlabeled distribution.	I-Reply	I-2	Reply	1270
In the context of the PU task, this goal is adapted to identify and imitate autonomously the distribution of relevant counter-examples hidden in the unlabeled dataset.	I-Reply	I-2	Reply	1270
[line_break_token][line_break_token]The motivation in this paragraph is to discuss the previous GAN-based approaches following issues: [line_break_token]-[tab_token]GenPU issues: GenPU is not easily adaptable to the current GAN state of the art (fast) evolutions because of its untraditional adversarial framework.	I-Reply	I-2	Reply	1270
Moreover, GenPU uses prior knowledge.	I-Reply	I-2	Reply	1270
This is unpractical for example on some real application incremental datasets in which the fraction pi value can change continuously at each new training minibatch.	I-Reply	I-2	Reply	1270
[line_break_token]-[tab_token]PGAN issue: It has a first stage overfitting problem when it is applied on relatively simple datasets as MNIST.	I-Reply	I-2	Reply	1270
In fact, it is mentioned in their article: ‚ÄúIt is also known that a GAN is not perfect in its operation when it is applied to high dimensional data, ‚Ä¶ Thus it is possible to estimate the non-zero distance d computed into the cost function of Db‚Äù.	I-Reply	I-2	Reply	1270
In other words, the PGAN exploits the GANs convergence defaults to address the PU learning problem.	I-Reply	I-2	Reply	1270
[line_break_token][line_break_token]The proposed approach overcomes the above enumerated issues while keeping their respective advantages.	I-Reply	I-2	Reply	1270
This is done by using a different technique: The D-GAN directly incorporates a PU learning risk into the discriminator loss function.	I-Reply	I-2	Reply	1270
This guides naturally the generator to converge towards the distribution of the negative samples included in the unlabeled dataset.	I-Reply	I-2	Reply	1270
[line_break_token][line_break_token][line_break_token]*****[line_break_token][line_break_token][line_break_token]‚ÄúThe paper classified PU learning methods into two categories, one-stage methods and two-stage methods.	O	O	Reply	1270
This is interesting.	O	O	Reply	1270
However, before that, they should be classified into two categories, for censoring PU learning and for case-control PU learning.	O	O	Reply	1270
‚Äù[line_break_token][line_break_token]Previous relevant state of the art articles, like nnPU, classify PU learning methods in two-stage and one-stage categories.	B-Reply	B-3	Reply	1270
The article nnPU (‚ÄúPositive-Unlabeled Learning with Non-Negative Risk Estimator‚Äù, NIPS 2017) says: ‚ÄúExisting PU methods can be divided into two categories based on how U data is handled.	I-Reply	I-3	Reply	1270
The first category (e.g., [11, 12]) identifies possible negative (N) data in U data, and then performs ordinary supervised (PN) learning; the second (e.g., [13, 14]) regards U data as N data with smaller weights.	I-Reply	I-3	Reply	1270
‚Äù.	B-Reply	B-2	Reply	1270
[line_break_token][line_break_token]GAN-based approaches generate samples in the first step, and they perform ordinary PN learning during the second step by considering the generated samples as relevant counter-examples.	B-Reply	B-3	Reply	1270
RP prepares a PN dataset from a PU dataset.	I-Reply	I-3	Reply	1270
Thus it is relevant to classify into the same category (two-stage) RP, and GAN-based approaches (D-GAN, PGAN, GenPU).	I-Reply	I-3	Reply	1270
[line_break_token][line_break_token]We introduce these categories (one-stage/two-stage) because our goal is to focus the attention on methods which aim at producing a relevant PN dataset from a PU dataset.	I-Reply	I-3	Reply	1270
[line_break_token]	O	O	Reply	1270

The problem is of increasing practical interest and importance.	O	O	Review	773
[line_break_token][line_break_token]The ablation study on the contribution and effects of each constituent  part is a strong part of the experiment section and the paper.	O	O	Review	773
[line_break_token][line_break_token]One major concern is about the novelty of the work.	B-Review	B-1	Review	773
There are many similar works under the umbrella of Neural Architecture search who are trying to connect different building blocks (modules) to build larger CNNs.	I-Review	I-1	Review	773
One example that explicitly makes sparse connections between them is [1]. Other examples of very similar works are [2,3,4].[line_break_token][line_break_token]The presentation of the paper can be improved a lot.	B-Review	B-3	Review	773
In the current setup it‚Äôs very similar to a collection of ideas and tricks and techniques combined together.	I-Review	I-3	Review	773
[line_break_token][line_break_token]There are some typos and errors in the writing.	B-Review	B-2	Review	773
A thorough grammatical  proofreading is necessary.	I-Review	I-2	Review	773
[line_break_token][line_break_token]In conclusion there is a claim about tackling overfitting.	B-Review	B-4	Review	773
It‚Äôs not well supported or discussed in the experiments.	I-Review	I-4	Review	773
[line_break_token][line_break_token][1] Shazeer, Noam, et al "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer."	O	O	Review	773
arXiv preprint arXiv:1701.06538 (2017).	O	O	Review	773
[line_break_token][2] Xie, Lingxi, and Alan L. Yuille. "	O	O	Review	773
Genetic CNN."	O	O	Review	773
ICCV.	O	O	Review	773
2017.	O	O	Review	773
[line_break_token][3] Real, Esteban, et al "Large-scale evolution of image classifiers."	O	O	Review	773
arXiv preprint arXiv:1703.01041 (2017).	O	O	Review	773
[line_break_token][4] Liu, Hanxiao, et al "Hierarchical representations for efficient architecture search."	O	O	Review	773
arXiv preprint arXiv:1711.00436 (2017).	O	O	Review	773
[line_break_token]	O	O	Review	773
We are very excited about the positive and enthusiastic support of our core idea.	O	O	Reply	773
Thank you for your feedback about our strong part.	O	O	Reply	773
We totally agree with you that our strong part is Section 4.4.	O	O	Reply	773
[line_break_token] [line_break_token]About your main concerns:[line_break_token]We belive we have enough novelty for our work.	O	O	Reply	773
[line_break_token] [line_break_token]Paper [2] claimed that they use a genetic algorithm for searching network structures.	B-Reply	B-1	Reply	773
As I understand, their work mostly concentrates on searching skip connections of layers.	I-Reply	I-1	Reply	773
As it is shown in Fig.	I-Reply	I-1	Reply	773
2 in [2], the optimization object is only connections between layers, however, strictly speaking, they didn‚Äôt change the structure of the network.	I-Reply	I-1	Reply	773
 Our focus is combining the locally dense and externally sparse property of the human brain into the neural network.	I-Reply	I-1	Reply	773
Our optimization object is sparse connections between dense modules.	I-Reply	I-1	Reply	773
In our paper, we figure out a method to achieve local density and global sparsity and demonstrate it with our solid experiments.	I-Reply	I-1	Reply	773
 We have typical hierarchical structures, and our experiment figures out how different parts of the network will influence the final result.	I-Reply	I-1	Reply	773
Yes, many papers could use genetic algorithms, but they all have their own contributions.	I-Reply	I-1	Reply	773
Moreover, according to the experiment part in page 8 of [2], we acquire more solid experiment results.	I-Reply	I-1	Reply	773
  As these two papers have different core ideas, we believe that our paper have enough novelty.	I-Reply	I-1	Reply	773
[line_break_token] [line_break_token]Paper [3] focuses on minimizing human participation as much as possible.	I-Reply	I-1	Reply	773
They search all parameters including learning rate, identity, reset weights, insert & remove convolutions.	O	O	Reply	773
 We think paper [3] has the same motivation and idea as paper [2] that reduce human participation as much as possible.	B-Reply	B-1	Reply	773
We think paper [3] is even better than paper [2] as they are in the same direction.	I-Reply	I-1	Reply	773
[line_break_token]Our motivation is different from these two papers.	I-Reply	I-1	Reply	773
 Our focus is combining locally dense and globally sparse properties of network structures.	I-Reply	I-1	Reply	773
 We do analysis about how different parts of the network or the different types of connections will influence the final performance in Section 4.4.	I-Reply	I-1	Reply	773
[line_break_token] [line_break_token] [line_break_token]Paper [4] has a similar idea of hierarchical structures as our paper.	I-Reply	I-1	Reply	773
But our basic elements are modules which contain several dense layers.	I-Reply	I-1	Reply	773
We notice that in their paper, evolving algorithm could form cliques in the end.	I-Reply	I-1	Reply	773
We think it might have some interesting conclusions if they look into properties like density and which connections are important.	I-Reply	I-1	Reply	773
We think searching network structure is a big topic.	I-Reply	I-1	Reply	773
It worth many good papers on this topic.	I-Reply	I-1	Reply	773
But all of them have different contributions.	I-Reply	I-1	Reply	773
[line_break_token]Different from their work, we focus on the implement of human-like locally dense but externally sparse structures in our paper.	I-Reply	I-1	Reply	773
And we make a detailed analysis of how each long-distance connection will influence the final result.	I-Reply	I-1	Reply	773
[line_break_token] [line_break_token]Paper [1] is a good NLP paper with special layers and searching strategy.	I-Reply	I-1	Reply	773
This paper is also under the network search topic.	I-Reply	I-1	Reply	773
But we focus on totally different aspects.	I-Reply	I-1	Reply	773
[line_break_token] [line_break_token]Thank you for mentioning some typos and grammar mistakes.	B-Reply	B-2	Reply	773
We apologize for this.	I-Reply	I-2	Reply	773
We spend a lot of time doing several rounds of proofreading and revising.	I-Reply	I-2	Reply	773
We hope this version may make you feel better.	I-Reply	I-2	Reply	773
[line_break_token] [line_break_token]In all, although there are some papers having similar topics to our paper (network searching, hierarchical network structures, network pruning), we think a good topic worth many good papers to contribute to it.	B-Reply	B-1	Reply	773
Also, we think we have enough novelty as present above.	I-Reply	I-1	Reply	773
In that case, we think it worth to be accepted.	I-Reply	I-1	Reply	773
Thank you very much.	I-Reply	I-1	Reply	773
[line_break_token]	O	O	Reply	773

This paper introduces a method for generating training/test data for measuring the model's ability of "compositional generalization" in complex compositional tasks/domains such as natural language understanding, visual understanding and other domains.	O	O	Review	494
[line_break_token]The idea of the proposed method is to essentially keep the "atom" distribution unchanged between the training and test data, but maximize the divergence between the "compound" distributions between them.	O	O	Review	494
[line_break_token]The authors have conducted a thorough and systematic experimentation, comparing the proposed approach with a number of other heuristic approaches for train test splits (such as random and input/output length, etc.)	O	O	Review	494
and using both a new large data set they generated (CFQ) and existing data set (SCAN).	O	O	Review	494
[line_break_token]The experimental results verify that using their method they can obtain train test data sets with uniform atom distributions with large divergence in compound distributions, and they find that there is a surprisingly large negative correlation between the accuracy of existing state-of-the-art learning methods and the compound divergence.	O	O	Review	494
[line_break_token]The data generation mechanism is systematic and involved, consisting of different categories of rules (logical form, grammar, rule application DAG's, etc.)	O	O	Review	494
and it would seem that the generation method/system and the generated data would be useful as benchmark data for the community.	O	O	Review	494
[line_break_token]The paper lacks technical novelty other than the training and test data generation approach, but having one available to the community with these apparently desirable characteristics as benchmark data for measuring complex, compositional generalization capabilities, and that could be invaluable to the research community.	B-Review	B-1	Review	494
e thank the reviewer for reading our paper in detail and for providing a careful review of the paper along with a summary of the contributions.	O	O	Reply	494
We agree with the reviewer that some of the primary areas of technical novelty in the paper are related to the training and test data generation approach.	B-Reply	B-1	Reply	494
More specifically, we would suggest that the novelty consists of at least two aspects: one being the approach to generation of a structurally diverse dataset through maximization of the entropy of the compound distribution; the second (and in our opinion more fundamental) novel aspect being the DBCA approach to measuring compositional generalization capability through the creation of data splits of varied compound divergence (while keeping atom distribution similar).	I-Reply	I-1	Reply	494

This paper proposes the Layerwise Origin Target Synthesis (LOTS) method, which entails computing a difference in representation at a given layer in a neural network and then projecting that difference back to input space using backprop.	O	O	Review	489
Two types of differences are explored: linear scalings of a single input‚Äôs representation and difference vectors between representations of two inputs, where the inputs are of different classes.	O	O	Review	489
[line_break_token][line_break_token]In the former case, the LOTS method is used as a visualization of the representation of a specific input example, showing what it would mean, in input space, for the feature representation to be supressed or magnified.	O	O	Review	489
While it‚Äôs an interesting computation to perform, the value of the visualizations is not very clear.	O	O	Review	489
[line_break_token][line_break_token]In the latter case, LOTS is used to generate adversarial examples, moving from an origin image just far enough toward a target image to cause the classification to flip.	O	O	Review	489
As expected, the changes required are smaller when LOTS targets a higher layer (in the limit of targetting the last layer, results similar to the original adversarial image results would be obtained).	O	O	Review	489
[line_break_token][line_break_token]The paper is an interesting basic exploration and would probably be a great workshop paper.	O	O	Review	489
However, the results are probably not quite compelling enough to warrant a full ICLR paper.	O	O	Review	489
[line_break_token][line_break_token]A few suggestions for improvement:[line_break_token] - Several times it is claimed that LOTS can be used as a method for mining for diverse adversarial examples that could be used in training classifiers more robust to adversarial perturbation.	B-Review	B-1	Review	489
But this simple experiment of training on LOTS generated examples isn‚Äôt tried.	I-Review	I-1	Review	489
Showing whether the LOTS method outperforms, say, FGS would go a long way toward making a strong paper.	I-Review	I-1	Review	489
[line_break_token] - How many layers are in the networks used in the paper, and what is their internal structure?	B-Review	B-2	Review	489
This isn‚Äôt stated anywhere.	I-Review	I-2	Review	489
I was left wondering whether, say, in Fig 2 the CONV2_1 layer was immediately after the CONV1_1 layer and whether the FC8 layer was the last layer in the network.	I-Review	I-2	Review	489
[line_break_token] - In Fig 1, 2, 3, and 4, results of the application of LOTS are shown for many intermediate layers but miss for some reason applying it to the input (data) layer and the output/classification (softmax) layer.	B-Review	B-3	Review	489
Showing the full range of possible results would reinforce the interpreatation (for example, in Fig 3, are even larger perturbations necessary in pixel space vs CONV1 space?	I-Review	I-3	Review	489
And does operating directly in softmax space result in smaller perturbations than IP2?)	I-Review	I-3	Review	489
[line_break_token] - The PASS score is mentioned a couple times but never explained at all.	B-Review	B-4	Review	489
E.g. Fig 1 makes use of it but does not specify such basics as whether higher or lower PASS scores are associated with more or less severe perturbations.	I-Review	I-4	Review	489
A basic explanation would be great.	I-Review	I-4	Review	489
[line_break_token] - 4.2 states ‚ÄúIn summary, the visualized internal feature representations of the origin suggest that lower convolutional layers of the VGG Face model have managed to learn and capture features that provide semantically meaningful and interpretable representations to human observers.	B-Review	B-5	Review	489
‚Äù I don‚Äôt see that this follows from any results.	I-Review	I-5	Review	489
If this is an important claim to the paper, it should be backed up by additional arguments or results.	I-Review	I-5	Review	489
[line_break_token][line_break_token][line_break_token][line_break_token]1/19/17 UPDATE AFTER REBUTTAL:[line_break_token]Given that experiments were added to the latest version of the paper, I'm increasing my review from 5 -> 6.	O	O	Review	489
I think the paper is now just on the accept side of the threshold.	O	O	Review	489
Thank you for your valuable suggestions for improvement!	O	O	Reply	489
[line_break_token][line_break_token]We believe that operating directly on softmax to produce adversarial examples, i.e., taking the difference of the captured probabilities, would not be different than using the logits as those probabilities are calculated directly from the logits. (	B-Reply	B-1	Reply	489
Also, considering that those probabilities add up to one, taking the difference would violate that.)	I-Reply	I-1	Reply	489
[line_break_token][line_break_token]We will upload a revised paper in a few days.	O	O	Reply	489
We try to address all suggestions/comments coming from reviewers including using them for improved learning.	O	O	Reply	489

This paper presents a general framework for sentence generation using a BERT-like model.	O	O	Review	20047
The authors decompose the problem of sentence generation into two problems.	O	O	Review	20047
One is selecting the positions at which changes should be made, and the other is actually replacing the current word with a new word.	O	O	Review	20047
This framework enables them to represent many decoding strategies including that of Ghazvininejas et al (2019) in a unified manner, and they propose a new decoding strategy that considers the prediction confidence of the current and the new word.	O	O	Review	20047
The paper also presents a heuristic algorithm for beam search decoding to find the most likely generation path.	O	O	Review	20047
Their experimental results on the WMT14 English-German dataset suggest that the proposed approach could achieve translation quality comparable to that of the standard autoregressive approach under a constant-time translation setting.	O	O	Review	20047
[line_break_token][line_break_token]It is nice to see existing decoding strategies represented in a generalized framework, but I was a bit disappointed that the authors do not seem to address the most critical problem in using a BERT-like model for sentence generation, namely, how to find the most likely sentence in a probabilistically sound way.	B-Review	B-1	Review	20047
It seems to me that the authors rely on at least two approximations.	B-Review	B-2	Review	20047
One is using pseudo-likelihood and the other is using the most likely generation path instead of performing marginalization.	I-Review	I-2	Review	20047
It is fine that the authors focus on empirical results of translation quality but then I would like to see more strong and extensive evidence that supports the use of such approximation.	I-Review	I-2	Review	20047
[line_break_token]	O	O	Review	20047
e believe that our framework is a probabilistically sound way of generating from masked language models, and language models generally.	B-Reply	B-1	Reply	20047
Our methodology does require some approximations to tractably generate sentences, but the overall generative story we offer is still valid.	I-Reply	I-1	Reply	20047
Moreover, even generating in traditional left-to-right autoregressive models requires approximations (e.g. greedy decoding or beam search) due to the exponential hypothesis space.	I-Reply	I-1	Reply	20047
[line_break_token][line_break_token]We believe our approximations are theoretically sensible, but they are difficult to verify how good they are due to the fact that what we‚Äôre trying to approximate in the first place is highly intractable to compute.	B-Reply	B-2	Reply	20047
One piece of evidence we‚Äôve looked at and included in the paper (Fig 3 in appendix in revision) is the probability of the intermediate sequences over the generation process.	I-Reply	I-2	Reply	20047
The energy (in the sense of energy-based models, see <a href="https://arxiv.org/abs/1902.04094)" target="_blank" rel="nofollow">https://arxiv.org/abs/1902.04094)</a> of the target sequence decreases (equivalently, the probability increases) throughout the generation process.	O	O	Reply	20047
The figure also shows that more sophisticated decoding schemes such as left2right, easy-first, and least2most converge to lower energy (higher probability) target sequences faster compared to uniformly picking positions.	B-Reply	B-2	Reply	20047
Overall, we believe that this is evidence that even with the approximations involved, our framework is able to find target sequences in a probabilistically sound manner and points to the value of further research in developing better coordinate selection mechanisms.	I-Reply	I-2	Reply	20047
If the reviewer has any thoughts on further experiments or evidence to explore, we‚Äôd be happy to hear it.	I-Reply	I-2	Reply	20047

