This paper propose a video instance embedding loss for jointly tackling the instance tracking and depth estimation from self-supervised learning.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1: I think the method is moving towards the right direction that 3d geometry and 2d instance representation should be considered jointly under the scenario of video learning.	Review	O	0
[line_break_token]2: The video instance embedding loss is also making sense as an extension of image instance embedding.	Review	O	0
[line_break_token][line_break_token]Cons: [line_break_token]1: I think the major argument I have is this method is lack of technical novelty, since it is straight forward to adopt the loss of  Brabandere et.al 2017 to video cases for including pixels in the same group under ground truth tracking, and the self-supervised loss is exactly the same as previous methods.	Review	O	0
The fusion between depth and segments are relatively weak since it just ask the embedding to also decode depth, is there any further analysis of visual effect of explaining where the depth helps segments?	Review	B-Review	1
[line_break_token][line_break_token]2: In the experiments, the baseline for comparison over MOTS is fairly old, and I think it makes sense to include the number of MOTS paper, which is currently hard to align with that shown in the paper.	Review	O	0
 In Tab.2, the author only highlight the improved motion metric, while in per-frame AP the results are actually lower than the baselines.	Review	B-Review	2
It also needs to be well explained.	Review	I-Review	2
[line_break_token][line_break_token]3: The paper claims `"it generates temporal consistent segmentation " (which is not guaranteed, maybe just statistically better but not exact).	Review	O	0
[line_break_token][line_break_token]Overall, in my opinion I suggest it to be a workshop paper, but the contribution is somehow not significant for a major publication.	Review	O	0
[line_break_token]	Review	O	0
any thanks for your careful review and helpful comments.	Reply	O	0
Here‚Äôs our answer to the concerns you have raised:[line_break_token][line_break_token]1a. "	Reply	O	0
I think the major argument I have is this method is lack of technical novelty, since it is straight forward to adopt the loss of  Brabandere et.al 2017 to video cases for including pixels in the same group under ground truth tracking, and the self-supervised loss is exactly the same as previous methods."	Reply	O	0
[line_break_token][line_break_token]Although it might be straightforward to extend the loss of Brabandere et al. [	Reply	B-Reply	1
1] to time, it is challenging to design an architecture that jointly integrates context from motion (3D Causal convolutions) and geometry (self-supervised depth estimation) to learn a spatio-temporal embedding that can consistently segment instances over time.	Reply	I-Reply	1
[line_break_token][line_break_token]1b. "	Reply	O	0
The fusion between depth and segments are relatively weak since it just ask the embedding to also decode depth, is there any further analysis of visual effect of explaining where the depth helps segments?"	Reply	O	0
[line_break_token][line_break_token]Incorporating depth context greatly improves the quality of the embedding as shown in the three examples added in the Appendix (section A.3).	Reply	B-Reply	1
[line_break_token]We compare the outputs of the model trained with and without self-supervised depth estimation.	Reply	I-Reply	1
For each figure, we have from left to right: RGB image, ground truth segmentation, predicted segmentation, embedding visualised in 2D, embedding visualised in RGB by projecting the three main components in the image space, and depth map.	Reply	I-Reply	1
[line_break_token][line_break_token](i) Without depth, the car circled in red is wrongly tracked in frame 5 and 9, while our model correctly tracks it as the network has learned a consistent embedding based not only on appearance, but also on 3D geometry.	Reply	I-Reply	1
Also, the RGB projection of the embedding from our model is considerably better and much more structured.	Reply	I-Reply	1
[line_break_token](ii) Without depth, the circled car merges into the red-segmented car, while our model does not as there is a significant difference in depth between the two cars.	Reply	I-Reply	1
[line_break_token](iii) The model without depth is not able to handle complete occlusion, while ours can.	Reply	I-Reply	1
[line_break_token][line_break_token]2. "	Reply	O	0
In the experiments, the baseline for comparison over MOTS is fairly old, and I think it makes sense to include the number of MOTS paper, which is currently hard to align with that shown in the paper.	Reply	O	0
In Tab.2, the author only highlight the improved motion metric, while in per-frame AP the results are actually lower than the baselines.	Reply	O	0
It also needs to be well explained."	Reply	O	0
[line_break_token][line_break_token]Please refer to the general response (point 1 and 3).	Reply	B-Reply	2
[line_break_token][line_break_token]3. "	Reply	O	0
The paper claims `"it generates temporal consistent segmentation " (which is not guaranteed, maybe just statistically better but not exact)."	Reply	O	0
[line_break_token][line_break_token]Quantitatively, we show that our model improves the baselines with IoU correspondence, and qualitatively we can see that the segmentation is temporally consistent as shown in the accompanying video: <a href="https://youtu.be/pqRPXRUlQ2I" target="_blank" rel="nofollow">https://youtu.be/pqRPXRUlQ2I</a>[line_break_token]And on more qualitative video examples here: <a href="https://drive.google.com/open?id=1u-kGxQEWIoC6FguUiXFHyxUcOiG2iIIf" target="_blank" rel="nofollow">https://drive.google.com/open?id=1u-kGxQEWIoC6FguUiXFHyxUcOiG2iIIf</a> [line_break_token][line_break_token][line_break_token]References[line_break_token][1] ‚ÄúSemantic Instance Segmentation with a Discriminative Loss Function‚Äù Bert De Brabandere, Davy Neven, Luc Van Gool	Reply	O	0

This paper introduces a memory-augmented RNN (MARNN) which aims at being lightweight and   differentiable.	Review	O	0
In a nutshell, authors propose to augment a LSTM-type architecture with several memory cells.	Review	O	0
At each time-step, MARNN retrieves one memory cell, updates his state, and updates the memory cell content.	Review	O	0
To learn the retrieval operation that requires discrete addressing,  authors rely on the Gumbel-Softmax.	Review	O	0
Authors evaluate their approach on PennTreeBank character level modelling where they demonstrate competitive performances.	Review	O	0
They also report state-of-art performance on the Thumos dataset.	Review	O	0
The paper is overall clear and pleasant to read.	Review	O	0
[line_break_token][line_break_token]Authors highlight that MARNN is more lightweight compared to existing memory networks.	Review	B-Review	1
MARNN can indeed retrieves only memory cells at inference.	Review	I-Review	1
However,  since MARNN uses a Gumbel-Softmax to train the discrete addressing scheme, it is it not clear if there is any advantage in term of memory and computation of MARNN relatively to other network during training?	Review	I-Review	1
It would be nice to compare the computation time/memory usage of MARNN with other memory augmented network such as TARDIS, NTM or Memory Network during training and inference.	Review	I-Review	1
[line_break_token][line_break_token]Another claim is that MARNN can possibly boost training speed by reducing the lengths of TBTT.	Review	I-Review	2
 But MARNN also haves a training time overhead as showed in Figure 2.	Review	I-Review	2
 How does the overall training time/performances of MARNN with TBPTT of 50 compared to a LSTM with TBPTT of 100/150?	Review	I-Review	2
[line_break_token][line_break_token]The writing can be sometime a bit imprecise.	Review	I-Review	3
For instance authors say that MARNN ‚Äúlearns better representations that many hierarchical RNN structure‚Äù.	Review	I-Review	3
I agree that MARNN outperforms in term of accuracy, however, it is not clear what the author are referring to by ‚Äúbetter representation‚Äù of the MARNN hidden state?	Review	I-Review	3
Performance gain of MARNN could also be due to the external memory which allows  to retain more information of the input?	Review	I-Review	3
In addition, it would be nice to precise which type of hierarchical RNN structure MARNN does (or doesn‚Äôt) outperform.	Review	I-Review	4
Another claim is that MARNN can ‚Äúeasily learn long-term dependencies‚Äù.	Review	I-Review	5
While this is reasonable, I am unsure that the empirical evaluation support this.	Review	I-Review	5
 It would be nice to show how the gradients backpropagated through time behave in practice to support this claim?	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]Memory-augmented network are a very important research directions and the MARNN architecture is interesting.	Review	I-Review	6
However, it is not entirely clear to me what is the main advantage of MARNN relatively to other memory networks network such as TARDIS, NTM or Memory Network for training and/or inference.	Review	I-Review	6
Although authors do compare with TARDIS, further comparison with the other networks and in term of computation time and memory could help clarify those points.	Review	I-Review	6
[line_break_token]	Review	O	0
Thank you for your valuable comment and pointing out the insufficient evidence in our work to support our claims.	Reply	O	0
We have added more experiments and can address your concerns as follows:[line_break_token][line_break_token]Q1:It would be nice to compare the computation time/memory usage of MARNN with other memory augmented network such as TARDIS, NTM or Memory Network during training and inference.	Reply	O	0
[line_break_token][line_break_token]We have compared our network (renamed as ARMIN)  with LSTM, NTM, TARDIS, ARMIN+TARDIS-addr in terms of speed/memory consumption during training and inference in section 5.	Reply	B-Reply	1
The results shows our network constantly outperforms other memory networks.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2:Another claim is that MARNN can possibly boost training speed by reducing the lengths of TBTT.	Reply	O	0
 But MARNN also haves a training time overhead as showed in Figure 2.	Reply	O	0
 How does the overall training time/performances of MARNN with TBPTT of 50 compared to a LSTM with TBPTT of 100/150?	Reply	O	0
[line_break_token][line_break_token]We conduct a control experiment in section 5, and compare 2 different setup of ARMIN with TBPTT  of 50 against LSTM with TBPTT of 100/150.	Reply	B-Reply	2
We show that ARMIN setup 1 obtain 40% training speed gain than LSTM with TBPTT of 150 while keeping a slightly better performance and 16% less parameter count; in ARMIN setup 2, we observe that with only 8.8% more memory consumption, we obtain about 1.5 points of BPC performance gain and 7.1% training speed gain under similar parameter count.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3:The writing can be sometime a bit imprecise.	Reply	O	0
For instance authors say that MARNN ‚Äúlearns better representations that many hierarchical RNN structure‚Äù.	Reply	O	0
I agree that MARNN outperforms in term of accuracy, however, it is not clear what the author are referring to by ‚Äúbetter representation‚Äù of the MARNN hidden state?	Reply	O	0
Performance gain of MARNN could also be due to the external memory which allows  to retain more information of the input?	Reply	O	0
[line_break_token][line_break_token]By saying ‚Äúbetter representations‚Äù, we refer to the concatenation of the gated contents from h_t and r_t.	Reply	B-Reply	3
 The performance gain comes from two aspect.	Reply	I-Reply	3
a)If we remove the gated contents of r_t from o_t, the ARMIN undergoes a BPC performance drop from 1.202 to 1.220, which is still better than the best performing BPC of 1.24 of the LSTM.	Reply	I-Reply	3
b)The rest of the performance gain comes from the recurrent memory integration of the ARMIN cell, which also favors a paradigm of deep transition, as is shown by the success of the deep transition RNNs on this task.	Reply	I-Reply	3
Please refer to line 10 in page 7 for more details.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4:It would be nice to precise which type of hierarchical RNN structure MARNN does (or doesn‚Äôt) outperform.	Reply	O	0
[line_break_token][line_break_token]We have specified in our paper that our network outperforms HM-LSTM, 2-Layer HyperLSTM and 21 layer IndRNN, and is outperformed by state-of-the-art BPC of 1.19 of HyperRHN and FS-LSTM.	Reply	B-Reply	4
[line_break_token][line_break_token]Q5:Another claim is that MARNN can ‚Äúeasily learn long-term dependencies‚Äù.	Reply	O	0
While this is reasonable, I am unsure that the empirical evaluation support this.	Reply	O	0
[line_break_token][line_break_token]We add algorithmic tasks which require exact long-term dependencies introduce by the NTM paper, where we demonstrate the fast converge speed in most of the tasks both in terms of wall clock time and iteration numbers.	Reply	B-Reply	5
We think this can support our claim of being able to ‚Äúeasily learn long-term dependencies‚Äù.	Reply	I-Reply	5
[line_break_token][line_break_token]Q6:it is not entirely clear to me what is the main advantage of MARNN relatively to other memory networks network such as TARDIS, NTM or Memory Network for training and/or inference.	Reply	O	0
Although authors do compare with TARDIS, further comparison with the other networks and in term of computation time and memory could help clarify those points.	Reply	O	0
[line_break_token][line_break_token]We have done further comparison to address the concern, as we state in Q1.	Reply	B-Reply	6
Our main advantage with respect to NTM and TARDIS are faster running speed, less memory consumption and better performance in real-world tasks (where we doubt the practicability of the carefully designed and complex addressing mechanism of the NTM).	Reply	I-Reply	6
[line_break_token][line_break_token]We hope these answers can address your concerns, thanks!	Reply	O	0
[line_break_token]	Reply	O	0

- algorithm 1 has a lot of problem specific hyperparametes that may be difficult to get right.	Review	O	0
Not clear how important they are[line_break_token]- they analyze the simpler (analytically and likely computationally) Boolean hyperparameter case (each hyperparameter is binary	Review	O	0
Thank you for your comments!	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Continuous vs. Boolean:   the Boolean setting is actually without loss of generality because we can search over a continuous range via binary search on discrete variables.	Reply	O	0
 This seems to work well in practice.	Reply	O	0
[line_break_token][line_break_token]2.	Reply	O	0
Our theory works for any domain; the discrete non-Boolean case is handled just the same.	Reply	O	0
[line_break_token][line_break_token]3.	Reply	O	0
The number of hyperparameters for Harmonica is significantly lower than the input number (6 vs. 60, or any input #) and manageable by grid search.	Reply	O	0
 We have also found that Harmonica is stable with respect to these six hyperparameters.	Reply	O	0
[line_break_token][line_break_token]4. ‚	Reply	O	0
Äúhammer in need of a nail‚Äù suggests a complicated algorithm.	Reply	O	0
This is far from the truth - the algorithm is very simple - just run LASSO on uniformly sampled measurements over the Fourier representation of the objective (and recurse).	Reply	O	0
This is arguably simpler than Bayesian Optimization, or reinforcement learning based approaches, which require sophisticated updating and handling of prior distributions.	Reply	O	0

Summary:[line_break_token]This paper explores the properties of an auto-encoder to behave as an associative memory retrieval mechanism.	Review	O	0
The authors show really interesting results where they are able to retrieve a small subset of encoded images (mnist) by giving the autoencoder random noise.	Review	O	0
They also show they can retrieve full videos by giving the autoencoder the output frame from the previous timestep.	Review	O	0
[line_break_token][line_break_token]The overall problem is a really interesting one which is to try to develop associative memory, retrieval models.	Review	O	0
[line_break_token][line_break_token]Decision:[line_break_token]Reject[line_break_token][line_break_token]Reasons:[line_break_token]1.	Review	O	0
Although the work is interesting, the only related work the authors cover is hopfield networks.	Review	B-Review	1
A cursory search indicates that this has been done before (k. Niki IEEE, Trischler 2016, M.A.Kramer 1992).	Review	I-Review	1
[line_break_token][line_break_token]Improvement:[line_break_token]1.	Review	O	0
A more thorough discussion of related work would be helpful.	Review	B-Review	1
[line_break_token]2.	Review	O	0
A direct qualitative comparison to related work would also be helpful.	Review	B-Review	1
e thank the reviewer for the comments and for emphasizing that the problem we consider is interesting.	Reply	O	0
 [line_break_token][line_break_token]In writing our paper, we have performed a careful literature review.	Reply	O	0
[line_break_token][line_break_token]The phenomenon that networks trained using standard optimization methods store training examples as attractors or sequences of examples as limit cycles has to the best of our knowledge not been observed before in the literature.	Reply	B-Reply	1
[line_break_token][line_break_token]Thank you for the references, but after carefully checking, none of the papers make the observation that training examples become attractors: (1) M.A. Kramer merely introduces and defines autoencoders.	Reply	I-Reply	1
 (2) K. Niki is work from 1989 that studies small networks in the binary input setting. (	Reply	I-Reply	1
3) Trischler 2016 studies how to train recurrent networks to model dynamical systems.	Reply	I-Reply	1
[line_break_token][line_break_token]We hope this addresses your concerns and please let us know if there are any other questions.	Reply	O	0

The paper proposes a straightforward method for end-to-end learning of active contours, based on predicting a dense field of 2D offsets, and then iteratively evolving the contour based on these offsets.	Review	O	0
A differentiable rendering formulation by Kato et al is employed to make the process of aligning a contour to a GT mask differentiable.	Review	O	0
[line_break_token][line_break_token]The model shows rather compelling results on small datasets, and is very simple, with very strong parallels to active contours, which is a strength.	Review	O	0
The results improve those of DARNet, which to the best of my knowledge is the main published work in the space other than Curve-GCN.	Review	O	0
One thing that would be helpful, is  to have an experiment on a large dataset, such as Cityscapes -- right now all the datasets are testing the model in only the small-data regime.	Review	B-Review	5
Perhaps in a supplement, it would also help to do ablation of how input image / dense deformation resolution affects the result quality -- the input can be subsampled by powers of 2 for the experiment.	Review	I-Review	5
[line_break_token][line_break_token]As Amlan Kar helpfully points out, the work heavily overlaps with his approach "Fast Interactive Object Annotation with Curve-GCN", CVPR 2019, which is not cited or compared to.	Review	O	0
Curve-GCN similarly utilizes differential rendering (only a different variant) to match the GT masks.	Review	O	0
To me, the main difference wrt Curve-GCN is that explicit dense displacement fields are generated by the net and used directly for the iterative refinement steps, while Curve-GCN leverages implicit feature embeddings and uses GCN layers for their iterative updates.	Review	O	0
A second main difference is that Curve-GCN supports splines and interactive editing, while the proposed approach does not.	Review	O	0
Beyond these, there are multiple other differences that the authors point out, but those are more of a technical nature.	Review	O	0
Unfortunately, without a more direct comparison, it is very difficult to evaluate the design choices in the two approaches, which I feel is necessary for proper understanding of the paper.	Review	B-Review	1
[line_break_token][line_break_token]AFTER REBUTTAL: The authors made additions that covered my concerns, so I have switched my recommendation.	Review	O	0
[line_break_token][line_break_token]A few more minor clarity / presentation issues.	Review	O	0
[line_break_token]-- ‚ÄúThe recent learning-based approaches are either non-competitive or proven to be effective in the specific settings of building segmentation".	Review	O	0
It's not exactly clear what the point is in the context.	Review	B-Review	2
Which "learning-based approaches"?	Review	I-Review	2
[line_break_token]-- Typo 'backpropogation'.	Review	O	0
[line_break_token]-- A little better explanation of how a differentiable renderer of Kato works would have been helpful.	Review	O	0
[line_break_token]-- Figure 3 is not referenced in the text, takes a little bit of thought why it is relevant (helps explain Fig 1, but maybe better to show it prior to Fig 1).	Review	O	0
[line_break_token]-- In Eq 4 it‚Äôs not clear what F is.	Review	O	0
 (I see it is explained in Algorithm box, but that's much later)[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]	Review	B-Review	4
e thank the reviewer for the comprehensive review.	Reply	O	0
[line_break_token][line_break_token]We apologize for the typos in the previous draft.	Reply	B-Reply	6
These have been corrected.	Reply	I-Reply	6
[line_break_token][line_break_token]To your comments:[line_break_token][line_break_token]Comparison to Curv-GCN: as noted by the reviewer, the differences between the methods are in the support of splines and working with an embedding space in Curve-GCN, vs. displacement map.	Reply	O	0
To emphasize: our method employs a single learned network that produces a displacement image in a single forward pass.	Reply	B-Reply	1
The CNN used by Curve-GCN predicts an embedding space of size 28x28 that is further processed by graph neural networks.	Reply	I-Reply	1
[line_break_token][line_break_token]Following the review, we have conducted experiments on Cityscapes, which is the only public dataset available from Curve-GCN experiments (their code is not available).	Reply	I-Reply	5
In this dataset, our method obtains SOTA for 6/8 classes and SOTA, by a sizable margin that is larger than the difference between the performance of previous work, in the overall mean mIoU. We believe that this also directly addressed the reviewer‚Äôs comment regarding larger datasets.	Reply	I-Reply	5
[line_break_token][line_break_token]All of our models are trained at the resolution of 64x64 pixels.	Reply	I-Reply	5
As noted in the original submission when discussing the Vaihingen dataset ‚Äúwe experiment with different resizing factors during training‚Äù.	Reply	I-Reply	5
Following the review, we share these results in Tab.5 of the revised submission.	Reply	I-Reply	5
As can be seen, there is a steep degradation in performance below 64x64, which we attribute to the lack of details.	Reply	I-Reply	5
When doubling the resolution to 128x128, the performance slightly degrades, however, that model could improve with further training epochs.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]The recent learning-based approaches are either non-competitive or proven to be effective in the specific settings of building segmentation" ‚Äî we have clarified in the text that we mean learning-based active contour methods and have limited the scope of the claim.	Reply	I-Reply	2
[line_break_token][line_break_token]We have added a paragraph regarding the use of a 3D renderer for 2D maps.	Reply	I-Reply	3
We simply fix the third coordinate and use the code of Kato as is.	Reply	I-Reply	3
[line_break_token][line_break_token]The letter ‚ÄúF‚Äù (for faces) is defined at the beginning of the ‚ÄúMethod‚Äù section.	Reply	I-Reply	4
[line_break_token][line_break_token]We believe that various issues raised by the reviewer were fully addressed in a way that considerably improved the manuscript.	Reply	O	0
With the CVPR deadline in a week, we would appreciate a timely response, in order for us to be able to plan our submission strategy.	Reply	O	0

The paper proposes the regularized framework of self-training, for the unsupervised domain adaptation.	Review	O	0
Authors reformulate basic self training problem with some relaxation and regularization encouraging not to use unconfident pseudo-labels.	Review	O	0
They also different instantiations of such regularizers under the proposed framework based on L2, entropy and KL and evaluate them on semantic segmentation and image classification tasks.	Review	O	0
 Overall, while the idea is potentially interesting and worthwhile to further explore, the current versions does not seem to be ready to be published:  the structure of paper needs to be improved, details about the experiments are missing and the connection to the EM should be clarified.	Review	O	0
 [line_break_token][line_break_token]Detailed question/comments:[line_break_token]-The structure of the paper is very kind in providing details on their derivations.	Review	O	0
However, given the space constraint, it seems the balance between the model derivation and experiments should considered.	Review	B-Review	1
 The experimental verification is quite weak as it is while there are lots of white space and redundancies in equations.	Review	I-Review	1
[line_break_token]- After Eq. (	Review	O	0
1), authors argue that the constraint of (1) has the problem of over-confidence on wrong pseudo labels and derive Eq (2) with simplex relaxation.	Review	B-Review	2
But it turns out after Eq (4) that the optimal solution for y_hat is still one hot binary vector.	Review	I-Review	2
Can we say (2) is better in terms of pseudo label overconfidence problem (not just ease of optimization)?	Review	I-Review	2
[line_break_token]- In section 3, it is not clear which part is the contribution and which is just review.	Review	O	0
It would be great to add some references and comparisons on existing literatures.	Review	B-Review	3
[line_break_token]- In section 3, it is not clear to me how one p rules all lambda_t; it seems we need additional parameters to adaptively increase (5% for instance as authors mentioned) for every iteration.	Review	O	0
[line_break_token]- Algorithm 1 and 2 are not given in the main part.	Review	O	0
This should be explicitly mentioned.	Review	B-Review	5
[line_break_token]- The connection to EM seems wrong.	Review	O	0
In E-step, we compute the posterior distribution given the parameter computed in previous M step.	Review	B-Review	6
It's not computing "argmax", but should be computing the [line_break_token]distribution", which will not probably be one-hot in eq (e).	Review	I-Review	6
[line_break_token][line_break_token][line_break_token] 	Review	I-Review	1
We thank the reviewer for appreciating the idea and kindly pointing out the weakness of this paper, which helped us very much in comprehensively rewriting the paper.	Reply	O	0
We agree with the reviewer that the paper is not well-balanced with enough details.	Reply	O	0
We also apologize for the hurry submission that leads to bad paper writing.	Reply	O	0
Given the significant difference between new version and previous one submission, we decide to withdraw our paper and resubmit to a new venue	Reply	O	0

The paper tries to ask if there is a good neural net architecture that works as effectively as gradient boosting decision trees on tabular data.	Review	O	0
The authors propose an architecture (NODE) that satisfies this conditions.	Review	O	0
NODE is an architecture consisting of differentiable oblivious decision trees that can be trained end to end via back propagation.	Review	O	0
The paper is readable and the experiments are well presented.	Review	O	0
They make use of an alpha-entmax transformation to obtain a differentiable architecture.	Review	O	0
The approach seems well motivated in the literature.	Review	O	0
It is unclear how novel the contribution is.	Review	B-Review	1
It is unclear if in the experimental section the datasets used are standard for this classes of tasks.	Review	I-Review	1
Would be good to mention if it is the case.	Review	I-Review	1
e thank you for the review.	Reply	O	0
[line_break_token][line_break_token][It is unclear if in the experimental section the datasets used are standard for this classes of tasks.]	Reply	O	0
[line_break_token]All datasets from our experiments are standard for tabular data processing: each dataset was previously featured in multiple published studies.	Reply	B-Reply	1
We deliberately chose these six datasets to cover different domain areas [web, natural sciences, etc.],	Reply	I-Reply	1
tasks [classification/regression] and dataset sizes.	Reply	I-Reply	1

unsupervised neural machine translation[line_break_token][line_break_token]This is an interesting paper on unsupervised MT.	Review	O	0
It trains a standard architecture using:[line_break_token][line_break_token]1) word embeddings in a shared embedding space, learned using a recent approach that works with only tens of bilingual word papers.	Review	O	0
[line_break_token][line_break_token]2) A encoder-decoder trained using only monolingual data (should cite <a href="http://www.statmt.org/wmt17/pdf/WMT15.pdf)."	Review	O	0
target="_blank" rel="nofollow">http://www.statmt.org/wmt17/pdf/WMT15.pdf).</a> Training uses a ‚Äúdenoising‚Äù method which is not new: it uses the same idea as contrastive estimation (<a href="http://www.aclweb.org/anthology/P05-1044," target="_blank" rel="nofollow">http://www.aclweb.org/anthology/P05-1044,</a> a well-known method which should be cited).	Review	O	0
[line_break_token][line_break_token]3) Backtranslation.	Review	O	0
[line_break_token][line_break_token]All though none of these ideas are new, they haven‚Äôt been combined in this way before, and that what‚Äôs novel here.	Review	O	0
The paper is essentially a neat application of (1), and is an empirical/ systems paper.	Review	O	0
It‚Äôs essentially a proof-of-concept that it is that it‚Äôs possible to get anything at all using no parallel data.	Review	O	0
That‚Äôs surprising and interesting, but I learned very little else from it.	Review	O	0
The paper reads as preliminary and rushed, and I had difficulty answering some basic questions:[line_break_token][line_break_token]* In Table (1), I‚Äôm slightly puzzled by why 5 is better than 6, and this may be because I‚Äôm confused about what 6 represents.	Review	O	0
It would be natural to compare 5 with a system trained on 100K parallel text, since the systems would then (effectively) differ only in that 5 also exploits additional monolingual data.	Review	B-Review	1
But the text suggests that 6 is trained on much more than 100K parallel sentences; that is, it differs in at least two conditions (amount of parallel text and use of monolingual text).	Review	I-Review	1
Since this paper‚Äôs primary contribution is empirical, this comparison should be done in a carefully controlled way, differing each of these elements in turn.	Review	I-Review	1
[line_break_token][line_break_token]* I‚Äôm very confused by the comment on p. 8 that ‚Äúthe modifications introduced by our proposal are also limiting‚Äù to the ‚Äúcomparable supervised NMT system‚Äù.	Review	O	0
According to the paper, the architecture of the system is unchanged, so why would this be the case?	Review	B-Review	2
This comment makes it seem like something else has been changed in the baseline, which in turn makes it somewhat hard to accept the results here.	Review	I-Review	2
[line_break_token][line_break_token]Comment:[line_break_token]* The qualitative analysis is not really an analysis: it‚Äôs just a few cherry-picked examples and some vague observations.	Review	O	0
While it is useful to see that the system does indeed generate nontrivial content in these cases, this doesn‚Äôt give us further insight into what the system does well or poorly outside these examples.	Review	B-Review	3
The BLEU scores suggest that it also produces many low-quality translations.	Review	I-Review	3
What is different about these particular examples? (	Review	I-Review	3
Aside: since the cross-lingual embedding method is trained on numerals, should we be concerned that the system fails at translating numerals?)	Review	I-Review	3
[line_break_token][line_break_token]Questions:[line_break_token]* Contrastive estimation considers other neighborhood functions (‚Äúrandom noise‚Äù in the parlance of this paper), and it‚Äôs natural to wonder what would happen if this paper also used these or other neighborhood functions.	Review	O	0
More importantly, I suspect the the neighborhood functions are important: when translating between Indo-European languages as in these experiments, local swaps are reasonable; but in translating between two different language families (as would often be the case in the motivating low-resource scenario that the paper does not actually test), it seems likely that other neighborhood functions would be important, since structural differences would be much larger.	Review	B-Review	4
[line_break_token][line_break_token]Presentational comments (these don‚Äôt affect my evaluation, they‚Äôre mostly observations but they contribute to a general feeling that the paper is rushed and preliminary):[line_break_token][line_break_token]* BPE does not ‚Äúlearn‚Äù, it‚Äôs entirely deterministic.	Review	O	0
[line_break_token][line_break_token]* This paper is at best tangentially related to decipherment.	Review	O	0
Decipherment operates under two quite different assumptions: there is no training data for the source language ciphertext, only the ciphertext itself (which is often very small); and the replacement function is deterministic rather than probabilistic (and often monotonic).	Review	B-Review	6
The Dou and Knight papers are interesting, but they‚Äôre an adaptation of ideas rather than decipherment per se.	Review	I-Review	6
Since none of those ideas are used here this feels like hand-waving.	Review	I-Review	6
[line_break_token][line_break_token]* Future work is vague: ‚Äúwe would like to detect and mitigate the specific causes‚Ä¶‚Äù ‚Äúwe also think that a better handling of rare words‚Ä¶‚Äù That‚Äôs great, but how will you do these things?	Review	O	0
Do you have specific reasons to think this, or ideas on how to approach them?	Review	B-Review	7
Otherwise this is just hand-waving.	Review	I-Review	7
Thanks for the insightful review.	Reply	O	0
We have tried to make the paper more clear in the revised version taking these comments into account.	Reply	O	0
Please find the answers to each specific point below:[line_break_token][line_break_token]General:[line_break_token][line_break_token]- To clarify what the semi-supervised and supervised systems represents in Table 1: (5) is the same as (4), but in addition to training on monolingual corpora using denoising and backtransaltion, it is also trained in a subset of 100K parallel sentences using standard supervised cross-entropy loss (it alternates one mini-batch of denoising, one mini-batch of backtranslation and one mini-batch of  this supervised training). (	Reply	O	0
6) is the same as (5) except for two differences: 1) it uses the full parallel corpus instead of the subset of 100K parallel sentences, and 2) it does not use any monolingual corpora nor denoising or backtranslation.	Reply	B-Reply	1
We think that the main reason why (5) is better than (6) is related to the domain: the parallel corpus of (6) is general, whereas the subset of 100K parallel sentences and the monolingual corpus used for (5) are in the news domain just as the test set.	Reply	I-Reply	1
While these facts were already mentioned in the paper, the new version includes a more detailed discussion.	Reply	I-Reply	1
At the same time, we agree that the fact that the comparable system differs from the semi-supervised system in two aspects makes the comparison more difficult, and we are currently working to extend our experiments accordingly.	Reply	I-Reply	1
[line_break_token][line_break_token]- Regarding the comment that ‚Äúthe modifications introduced by our proposal are also limiting‚Äù to the ‚Äúcomparable supervised NMT system‚Äù, note that, as discussed in the previous point, the comparable NMT system uses the exact same architecture and hyperparameters as the unsupervised system (number of layers, hidden units, attention model etc.)	Reply	O	0
and, as such, it also incorporates the non-standard variations in Section 3.1 (dual structure using a shared encoder with fixed embeddings).	Reply	B-Reply	2
These are what we were referring to as ‚Äúthe modification introduced by our proposal‚Äù, but the only difference between the unsupervised and the supervised systems is that, instead of training in monolingual corpora using denoising and backtranslation, we train in parallel corpora just as in standard NMT.	Reply	I-Reply	2
We have tried to make this more clear in the revised version of the paper.	Reply	I-Reply	2
[line_break_token][line_break_token]Comment:[line_break_token][line_break_token]- We agree that the qualitative analysis in the current version is limited.	Reply	O	0
It was done mainly to check and illustrate that the proposed unsupervised NMT system generates sensible translations despite the lack of parallel corpora.	Reply	B-Reply	3
We believe that a more detailed investigation and analysis into the properties and characteristics of translation generated by unsupervised NMT must be conducted in the future.	Reply	I-Reply	3
[line_break_token][line_break_token]- Note that we only use shared numerals to initialize the iterative embedding mapping method, so it is understandable that the system fails to translate numerals after the training of both the embedding mapping and the unsupervised NMT system itself.	Reply	O	0
While it would certainly be possible to perform an ad-hoc processing to translate numerals under the assumption that they are shared by different languages, our point was to show that the system has some logical adequacy issues for very similar concepts (e.g. different numerals or month names).	Reply	B-Reply	3
[line_break_token][line_break_token]Questions:[line_break_token][line_break_token]- Thanks for pointing out the connection with contrastive estimation, which is now properly discussed in the revised version of the paper.	Reply	O	0
As for the role of neighborhood functions, we agree that there are many possible choices beyond local swaps, and the optimal choice could greatly depend on the typological divergences between the languages involved.	Reply	B-Reply	4
In this regard, we think that this is a very interesting direction to explore in the future, and we have tried to better discuss this matter in the revised version of the paper.	Reply	I-Reply	4
[line_break_token][line_break_token]Having said that, please note that we have considered two language pairs (English-French and English-German) in our experiments.	Reply	I-Reply	4
Despite being indo-european, there are important properties that distinguish these language pairs, such as the verb-final construction and the prevalence of compounding in German in contrast to French.	Reply	I-Reply	4
In fact, English-German has often been studied in machine translation as a particularly challenging language pair.	Reply	I-Reply	4
For that reason, we believe that the experiments on these two distinct language pairs support the effectiveness of the proposed approach, despite the potential for future investigation on the effect of contrastive functions on the choice of language pairs	Reply	I-Reply	4

The authors propose a method to model sequential data from multiple interconnected sources using a mixture of common pool of HMM's.	Review	O	0
The composition of the mixture for each data source is both sparse and similar to that of other data sources that are close to it, with the closeness determined by the weights of the edges of an undirected graph.	Review	O	0
[line_break_token][line_break_token]The introduction section is unfocused and sloppy.	Review	O	0
HMM's are well understood models in machine learning but the paper falls short in explaining the particular distributed scenario of interest.	Review	O	0
The narrative jumps from sports, to neuroscience to wireless communications to fMRI,  without mentioning the common denominator.	Review	B-Review	1
The proposed model section lacks also some focus, jumping from distributed sparse representations to multitask learning.	Review	O	0
The key concept here seems to be the poorly defined concept of 'a sparse HMM mixture over a large dictionary of HMM's'.	Review	B-Review	2
The formalization of this rather complicated object is not well justified and leaves a lot of guesswork to the reader.	Review	I-Review	2
[line_break_token][line_break_token]Instead of maximizing the likelihood, an alternative objective function (4) is proposed as maximizing the inner products of posterior probability vectors at each node.	Review	I-Review	3
The authors probably try to say something sensible but the sloppy notation is not very helpful here.	Review	I-Review	3
  [line_break_token][line_break_token]The way authors introduced the graph structure into their cost function creates potentially a flexibility.	Review	O	0
However, the authors could have spent more energy on explaining why sparseness of the mixtures should be a desirable property for the problems they hope to solve with the model.	Review	O	0
The graph structure could potentially be used without necessitating sparsity, so opting for sparsity needs to be justified.	Review	B-Review	4
[line_break_token][line_break_token]One also suspects that the authors could have written a clearer generative model instead of modifying the maximum likelihood criterion for learning.	Review	O	0
This would have enabled the readers to appreciate the generative model better.	Review	O	0
[line_break_token][line_break_token]Moreover, the parameter controls how much effect the graphical interrelations is to have on the final learned parameters of the model.	Review	O	0
The authors however do not present a detailed examination of empirical results of varying, and only suffice to determine it with cross-validation.	Review	O	0
A more interpretive stance towards lambda would confer increased understanding of how sparsity functions in this model.	Review	O	0
The cluster analysis at the end of the experiments indeed provide a more tangible demonstration of how sparsity affects the results obtained and why it might be desirable.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is not of sufficient quality to be presented at ICLR.	Review	O	0
[line_break_token]	Review	O	0
Thank you very much for your review and for your insightful comments.	Reply	O	0
We, however, believe that there are some points that were misunderstood, probably because our explanation was not as clear as it should be.	Reply	O	0
We would like to clarify those:[line_break_token][line_break_token]¬´The narrative jumps from sports, to neuroscience to wireless communications to fMRI, without mentioning the common denominator.	Reply	O	0
¬ª[line_break_token][line_break_token]As argued in the first sentences of that paragraph, in all those scenarios one has multiple data streams that come from a set of distinct entities that are somehow interdependent and interconnected, forming a network ‚Äì this is the common denominator.	Reply	O	0
What we propose in the paper is a principled way to exploit the known network topology in order to build a generative model for those streams.	Reply	B-Reply	1
[line_break_token][line_break_token]¬´The key concept here seems to be the poorly defined concept of 'a sparse HMM mixture over a large dictionary of HMM's'.	Reply	O	0
The formalization of this rather complicated object is not well justified and leaves a lot of guesswork to the reader.¬ª[line_break_token][line_break_token]The model is described formally in section 2.2.1 and it actually corresponds to ‚Äúa sparse HMM mixture over a ‚Äòlarge‚Äô dictionary of HMMs‚Äù.	Reply	O	0
As clearly defined in equations 2 and 3, this is a mixture model, where each mixture component is an HMM.	Reply	B-Reply	2
Moreover, the ‚Äú‚Äôlarge‚Äô  dictionary of HMMs‚Äù consists of all HMMs of the mixture.	Reply	I-Reply	2
Because the mixtures for each node tend to be sparse, the distributions will then consist of the aforementioned ‚Äúsparse HMM mixture over a ‚Äòlarge‚Äô dictionary of HMMs‚Äù.	Reply	I-Reply	2
[line_break_token][line_break_token]¬´Instead of maximizing the likelihood, an alternative objective function (4) is proposed as maximizing the inner products of posterior probability vectors at each node.	Reply	O	0
The authors probably try to say something sensible but the sloppy notation is not very helpful here.¬ª[line_break_token][line_break_token]We are sorry that you did not understand the proposed regularizer term, since this was one of the central contributions of the paper.	Reply	O	0
However, we do not agree that the notation is sloppy and we actually think that it is quite precise.	Reply	B-Reply	3
The probabilities do not denote any posteriors, but rather the vector  of mixture coefficients for the node or, equivalently, the prior distribution of the latent variable for the node.	Reply	I-Reply	3
Therefore, as pointed out in the proof of Proposition 1.,	Reply	I-Reply	3
the considered expectations correspond to the inner products of the vectors and, which are the mixture coefficients for the nodes and.	Reply	I-Reply	3
Thus, if the weight associated with the edge connecting and is positive, the regularizer promotes that the mixtures for these two nodes are similar.	Reply	I-Reply	3
Otherwise, if is negative, the regularizer promotes that the mixtures for these two nodes do not share any components.	Reply	I-Reply	3
[line_break_token][line_break_token]¬´The graph structure could potentially be used without necessitating sparsity, so opting for sparsity needs to be justified.¬ª[line_break_token][line_break_token]This is entirely correct.	Reply	O	0
However, note that the rationale behind our model is that, in each node, the observations are well modeled by a mixture of only a few HMMs.	Reply	B-Reply	4
By promoting sparsity in the mixtures, we may accomplish this goal and still have a large (overcomplete) pool of components (HMMs).	Reply	I-Reply	4
Therefore, some components in the pool will specialize in describing the behavior of a few nodes, while others will specialize in different nodes.	Reply	I-Reply	4
Moreover,  sparsity yields faster inference, less overfitting and more interpretable models, which are all desirable properties.	Reply	I-Reply	4
[line_break_token]We agree that we should improve the explanation in the paper.	Reply	I-Reply	4

The authors presented an interesting paper which tries to solve a practically important question.	Review	O	0
Biomedical and tech industries usually hire human labelers for machine learning tasks, whose labels are usually noisy.	Review	O	0
Therefore, it is important to have a metric that can distinguish the performance of models with noisy labels.	Review	O	0
[line_break_token][line_break_token]In this paper, the authors proposed to measure the model performance based on the ratio of the discrepancy between the model prediction and the labeler, with the discrepancy between the labelers.	Review	O	0
The authors showed that in binary classification settings, their proposed metric can be reduced to simple to analyze quantities.	Review	O	0
The authors demonstrated the performance of their proposal in synthetic data as well in two real-world medical image datasets.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is well motivated with a reasonable amount of novelty.	Review	O	0
The numerical experiments are well conducted, but I am not totally convinced by their results.	Review	O	0
[line_break_token][line_break_token]Detailed comments:[line_break_token]Significance: The paper is trying to address a practically important issue in machine learning.	Review	O	0
[line_break_token]Novelty: The mathematical formulation of the metric consists of simple sums and averages, which in itself is not novel.	Review	O	0
However, the authors' choice of using such formulations to assess model performance is novel.	Review	B-Review	3
[line_break_token]Clarity: The authors could simplify their notations, and could periodically remind the readers about the notations.	Review	O	0
For example, I was stuck by the sigma^2 notation in (6) (undefined) and the m notation in (7) defined in the past page in small texts.	Review	B-Review	1
It would help me a lot if the authors reminded me the definition of those notations when they appeared.	Review	I-Review	1
[line_break_token]Numerical Experiments: This is my biggest complain.	Review	O	0
I wasn't able to conclude that the authors proposal is better than majority voting based on Figures 1b and 2b.	Review	B-Review	2
To me they look qualitatively the same.	Review	I-Review	2
Is there any reason that the discrepancy ratio is superior to the majority vote?	Review	I-Review	2
In addition, I didn't see whether the curves in Figures 1 and 2 are an average of numerous simulated samples.	Review	I-Review	2
if not, the authors should use the average to mitigate randomness; and if the curves are averages, then the distribution of the metrics should be described, because I think ultimately, we don't care about whether the average black curve is above the average red curve, but the chance of black curve being above the red curve.	Review	I-Review	2
e thank the reviewer for their helpful comments and suggestions.	Reply	O	0
We have addressed in detail all of the reviewer‚Äôs concerns and hope the resulting paper (uploaded) merits unambiguous acceptance.	Reply	O	0
Our point-by-point response is detailed below.	Reply	O	0
[line_break_token][line_break_token]‚ÄúNovelty: The mathematical formulation of the metric consists of simple sums and averages, which in itself is not novel.	Reply	O	0
However, the authors' choice of using such formulations to assess model performance is novel.	Reply	O	0
‚Äù[line_break_token][line_break_token]The derivation of the model and annotator discrepancies in Section 3.3 was simply meant to serve as a concrete example of how these metrics are calculated in a particularly simple case.	Reply	O	0
We hope that this example clarifies to the reader the more general formalism presented in Section 3.1 and helps to build intuition for the properties of the discrepancy ratio (see for example the last paragraph of Section 3.3).	Reply	B-Reply	3
We would also like to point out that the novelty of our paper is not in this simple example but in providing a robust, task-independent and highly-interpretable metric that allows us to quantify model performance in the context of how humans perform relative to each other.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]‚ÄúClarity: The authors could simplify their notations, and could periodically remind the readers about the notations.	Reply	O	0
For example, I was stuck by the sigma^2 notation in (6) (undefined) and the m notation in (7) defined in the past page in small texts.	Reply	O	0
It would help me a lot if the authors reminded me the definition of those notations when they appeared.	Reply	O	0
‚Äù[line_break_token][line_break_token]Thanks for pointing this out.	Reply	O	0
We have added to the revised manuscript the definition of the variance to Eq.	Reply	B-Reply	1
5 and included several additional reminders of the meaning of symbols when they occur far from their definitions.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]‚ÄúNumerical Experiments: This is my biggest complain.	Reply	O	0
I wasn't able to conclude that the authors proposal is better than majority voting based on Figures 1b and 2b.	Reply	O	0
To me they look qualitatively the same.	Reply	O	0
Is there any reason that the discrepancy ratio is superior to the majority vote?	Reply	O	0
[line_break_token][line_break_token]This is a subtle point that could have been made more clear in our initial submission.	Reply	B-Reply	2
The discrepancy ratio is indeed superior to the majority vote method, as discussed in detail in Section 2, Section 4.1.2 and Section 4.2.1, though this may not be entirely clear from simply looking at Figures 1b and 2b.	Reply	I-Reply	2
The curves in these figures look qualitatively similar only in the sense that both allow us to decide which model is better.	Reply	I-Reply	2
Indeed, if the goal is simply to rank models, then *any* of the baseline metrics are perfectly suitable.	Reply	I-Reply	2
If, however, one needs to know how a particular model performs *relative to humans*, the majority vote method simply does not answer that question.	Reply	I-Reply	2
This is the main motivation for using the discrepancy ratio and has been clarified in Section 4.1.2.	Reply	I-Reply	2
[line_break_token][line_break_token]In other words, evaluating against majority vote does not give a clear indication of whether a machine learning model is reasonably substitutable for humans who are currently performing a given task in the real world.	Reply	I-Reply	2
This is especially important in medical applications since decisions in the field are usually made by a single individual, not majority consensus.	Reply	I-Reply	2
The discrepancy ratio, on the other hand, unambiguously answers the question of how a model performs against the humans by considering human-to-human disagreement.	Reply	I-Reply	2
An additional property that makes the discrepancy ratio superior to the majority vote method is that the majority vote method gives a metric that is dependent on the number of annotators that annotated the dataset (as can be inferred from Figures 1a and 1b), while the discrepancy ratio is independent of the number of annotators (Figure 2c).	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]‚ÄúIn addition, I didn't see whether the curves in Figures 1 and 2 are an average of numerous simulated samples.	Reply	O	0
if not, the authors should use the average to mitigate randomness; and if the curves are averages, then the distribution of the metrics should be described, because I think ultimately, we don't care about whether the average black curve is above the average red curve, but the chance of black curve being above the red curve.	Reply	O	0
‚Äú[line_break_token][line_break_token]The curves in Figures 1 and 2 are generated by taking the MNIST test set and randomly swapping the labels with probability p, as described in Section 4.1.	Reply	O	0
Each point on these plots is generated with an independent swapping of the labels resulting in the small fluctuations that are evident in these curves.	Reply	B-Reply	2
As requested by the reviewer, in the revised version of the paper we have replaced the curves with their averages as well as overlaid 95% quantiles to indicate the distributions of all the metrics	Reply	I-Reply	2

The paper presents a VAE that uses labels to separate the learned representation into an invariant and a covariant part.	Review	O	0
The method is validated using experiments on the MNIST dataset.	Review	O	0
[line_break_token][line_break_token]The writing in this paper is somewhat problematic.	Review	B-Review	1
Although it is hard to put the finger on a particularly severe instance, the paper is filled with vague and hyperbolic statements.	Review	I-Review	1
Words like "efficiently", "meaningful", "natural", etc.	Review	I-Review	1
are sprinkled throughout to confer a positive connotation, often without having a specific meaning in their context or adding any information.	Review	I-Review	1
Where the meaning is somewhat clear, the claims are often not supported by evidence.	Review	I-Review	1
Sometimes the claims are so broad that it is not clear what kind of evidence could support such a claim.	Review	I-Review	1
[line_break_token][line_break_token]A relatively large amount of space is used to explain the general concept of invariant/covariant learning, which, as a general concept, is widely understood and not novel.	Review	I-Review	2
There are other instances of overclaiming, such as "The goal of CoVAE is to provide an approach to probabilistic modelling that enables meaningful representations [...]".	Review	I-Review	2
In fact, CoVAE is a rather specific model(class), rather than an approach to probabilistic modelling.	Review	I-Review	2
[line_break_token][line_break_token]The paper is at times meandering.	Review	I-Review	3
For instance, the benefits of and motivation for the proposed approach are not simply stated in the introduction and then demonstrated in the rest of the paper, but instead the paper states some benefits and motivations, explains some technical content, mentions some more benefits, repeats some motivations stated before, etc.	Review	I-Review	3
[line_break_token][line_break_token]Many researchers working on representation learning hope to discover the underlying learning principles that lead to representations that seem natural to a human being.	Review	I-Review	4
In this paper, labels are used to guide the representation into the "right" representation.	Review	I-Review	4
It is in my opinion not very surprising that one can use labels to induce certain qualities deemed desirable in the representation.	Review	I-Review	4
[line_break_token][line_break_token]To conclude, because of the writing, limited novelty, and limited experiments, I think this paper currently does not pass the bar for ICLR.	Review	O	0
We thank the reviewer for their helpful feedback.	Reply	O	0
The reviewer's main criticism was the writing: both the usage of vague, hyperbolic statements, as well as unnecessary discussion and meandering.	Reply	O	0
[line_break_token][line_break_token]On the vague, hyperbolic statements, the authors' intention was to provide clarity-by-repetition with these statements, but concede with regret in retrospect that they came across unhelpfully vague or unjustified.	Reply	B-Reply	1
We have purged this language throughout the paper.	Reply	I-Reply	1
There is now not a single usage of "efficient", "meaningful", or "natural" in describing our own work (we do still use such words in the Introduction when discussing the literature and representation learning in general).	Reply	I-Reply	1
We have also tried to eradicate other examples of similar language (e.g. "general" in the original conclusions, EquiVAE is no longer described as a "framework").	Reply	I-Reply	1
We feel that the writing is now clearer and more objective.	Reply	I-Reply	1
[line_break_token][line_break_token]To improve the conciseness and linearity of the paper, we have completely removed Section 2.1, which perhaps over repeated obvious attributes of our modelling choices.	Reply	I-Reply	1
Section 2.1 also contained some of the problematic language referred to above.	Reply	I-Reply	1
Similarly, the semi-supervised objective function and surrounding discussion was brought from Section 3.2 into Section 2 for linearity.	Reply	O	0
[line_break_token][line_break_token]The reviewer also briefly mentioned limited novelty and limited experiments as weaknesses of the paper.	Reply	O	0
We have addressed both of these points.	Reply	O	0
Firstly, we have added 9 new references to relevant work in the literature along with discussions of how our approach is related, and indeed novel (e.g. our usage multiple same-class complementary data points for the invariant latent).	Reply	B-Reply	2
Secondly, we have run all of our experiments on the Street View House Numbers (SVHN) data set in order to add robustness to our experimental results.	Reply	I-Reply	4
Indeed the results on SVHN are consistent with our original results on MNIST (e.g. invariant representations are well separated, semi-supervised accuracies are competitive with Siddharth et al. (	Reply	I-Reply	4
2017)) with minimal changes to our modelling setup (i.e. to accommodate different image sizes).	Reply	I-Reply	4
[line_break_token][line_break_token]We regret the way the paper came out originally in its writing, but with the reviewers poignant criticism on this front, we feel that the updated version of our paper is much more appropriate and clear.	Reply	O	0
We hope this, as well as the additional experimental results, now justify its publication	Reply	O	0

Summary:[line_break_token][line_break_token]The paper proposes a hybrid weights representation method where the weights of the neural network is split into two portions: a major portion of ternary weights and a minor portion of weights that are represented with different number of bits.	Review	O	0
The two portions of weights are differentiated by using the previous unused state of a typical ternary neural network since only three states are used out of the four states given 2-bit representation.	Review	O	0
The experiments are solid based on the selected baseline model on CIFAR-100 and Imagenet dataset.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]‚Ä¢[tab_token]The idea of using the previous unused state in ternary neural network is interesting[line_break_token]‚Ä¢[tab_token]Overall, the paper is well written.	Review	O	0
The proposed method is presented clearly with proper graph illustration.	Review	O	0
[line_break_token]Cons:[line_break_token]‚Ä¢[tab_token]The idea of using mixed bit width for neural network quantization is not new.	Review	O	0
However, the experiments in the paper only compare with basic quantization method which makes the comparison not fair enough.	Review	B-Review	1
For example, in ABC-net[1], a few full precision coefficients are used to binarize the network.	Review	I-Review	1
With 3 bit for both weights and activations, it achieves 61% top 1 classification on ImageNet dataset with ResNet-18 as backbone model.	Review	I-Review	1
This is around 3% higher than the paper‚Äôs proposed method with 2/4 bits for weights and 4 bits for activations.	Review	I-Review	1
[line_break_token]‚Ä¢[tab_token]In the paper, it claims that the proposed weight ridge method ‚Äúcan obtain better accuracy than L2 weights decay‚Äù.	Review	O	0
However, there are no experiments or any theoretical supports for it.	Review	B-Review	2
[line_break_token]‚Ä¢[tab_token]After utilizing the forth state of a ternary neural network, it implies that all four states provided by 2 bit representation are used.	Review	O	0
Hence, the comparison with a quantized neural network of 2 bits should be given in the experiments also.	Review	B-Review	3
[line_break_token][line_break_token][1] Lin, Xiaofan, Cong Zhao, and Wei Pan. "	Review	O	0
Towards accurate binary convolutional neural network."	Review	O	0
Advances in Neural Information Processing Systems.	Review	O	0
2017.	Review	O	0
[line_break_token]	Review	O	0
hank you for giving us a chance to improve our paper.	Reply	O	0
We also agree with your concerns and hope our replies would work for you.	Reply	O	0
[line_break_token][line_break_token]1) The experiments in the paper only compare with the basic quantization method which makes the comparison not fair enough.	Reply	O	0
[line_break_token]&gt;&gt; This is a really great question.	Reply	O	0
Actually, we concentrated on the effect of centralized quantization using sparse-large weights.	Reply	B-Reply	1
As you mentioned, there are many state-of-the-art quantization methods.	Reply	I-Reply	1
To minimize some unexpected or different effects by using state-of-the-art quantization methods such as PACT[1] or QIL[2] when evaluating the centralized quantization, we selected a simple quantization method which is the Basic Quantization (Sec 3.1).	Reply	I-Reply	1
Our future work is that applying the centralized quantization to other state-of-the-art quantization methods.	Reply	I-Reply	1
As you mentioned, the quantization methods of PACT[1] and QIL[2] is better than Basic Quantization (Sec 3.1).	Reply	I-Reply	1
In a reflection of your advice, we will add other state-of-the-art results.	Reply	I-Reply	1
Can you recommend a proper section to add the contents of state-of-the-art quantization methods?	Reply	I-Reply	1
i) related work, ii) Sec 3.1 (Basic quantization), ii) experimental results (like ABC-net[3]), or iv) multiple choice.	Reply	I-Reply	1
[line_break_token][line_break_token]2) There are no experiments or any theoretical supports for the proposed weight ridge method.	Reply	O	0
[line_break_token]&gt;&gt; We think that our presentation was unclear.	Reply	O	0
Table 1 and Sec 4.1 show the ablation study investigating the effect of the weighted ridge in full-precision models.	Reply	B-Reply	2
[line_break_token]Like your opinion, we will separate the main experimental results (table 3, 4) and ablation studies (table 1, 2).	Reply	I-Reply	2
[line_break_token][line_break_token]3) The comparison with a quantized neural network of 2 bits should be given in the experiments also.	Reply	O	0
[line_break_token]&gt;&gt; It seems a considerable point.	Reply	O	0
In my understanding, you suggest that experiments of a quantized neural network of 2 bits should be given.	Reply	B-Reply	3
Actually, we do not consider the quantized neural network of 2 bits because we cannot keep the benefit of ternary weights.	Reply	I-Reply	3
Ternary weights do not require multiply operations in inference-time, while 2-bits weights require multiply operations.	Reply	I-Reply	3
And there is a potential to keep this benefit when using our hybrid representation method by applying the variant of sparse convolution operations[4]. We will add more details about inference process to appendices.	Reply	I-Reply	3
[line_break_token][line_break_token]We'll update your addressed points.	Reply	O	0
If you want, we can remind you after revising by adding a comment.	Reply	O	0
[line_break_token][line_break_token]If you have more ambiguous terms or any questions, please claim those for revising our paper.	Reply	O	0
[line_break_token][line_break_token]Best Regards.	Reply	O	0
[line_break_token][line_break_token][1] Choi, Jungwook, et al. "	Reply	O	0
Pact: Parameterized clipping activation for quantized neural networks."	Reply	O	0
arXiv preprint arXiv:1805.06085 (2018).	Reply	O	0
[line_break_token][2] Jung, Sangil, et al. "	Reply	O	0
Learning to quantize deep networks by optimizing quantization intervals with task loss."	Reply	O	0
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.	Reply	O	0
2019.	Reply	O	0
[line_break_token][3] Lin, Xiaofan, Cong Zhao, and Wei Pan. "	Reply	O	0
Towards accurate binary convolutional neural network."	Reply	O	0
Advances in Neural Information Processing Systems.	Reply	O	0
2017.	Reply	O	0
[line_break_token][4] Park, Jongsoo, et al. "	Reply	O	0
Faster cnns with direct sparse convolutions and guided pruning."	Reply	O	0
arXiv preprint arXiv:1608.01409 (2016)	Reply	O	0

The paper considers the problem of interpreting the predictions for survival analysis using topic models.	Review	O	0
The classical survival analysis problem assumes each datapoint is a subject (X,Y,\delta) where X is a feature vector and Y is a life time or a censoring time depending on whether the subject is dead (when delta=1) or alive (when delta=0).	Review	O	0
The usual objective here is to predict survival times.	Review	O	0
The authors assume the features in X are interpretable readings (eg "low blood pressure") and indicate the number of times that reading was observed.	Review	O	0
Under this setting, such features can also be seen as words with datapoints being (BoW) documents.	Review	O	0
The goal then becomes that of finding topics that help predict life times on unseen subjects.	Review	O	0
[line_break_token][line_break_token]My main concerns with this paper are the following:[line_break_token]- setting is very niche and might not be a great fit for ICLR.	Review	O	0
[line_break_token]- novelty is limited since most pieces were already present in previous work.	Review	O	0
[line_break_token]- experimental section only uses two datasets with little improvements.	Review	O	0
 Such small performance gap hardly convinces that the improvement by the proposed method is statistically meaningful.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
hanks for the feedback.	Reply	O	0
Please see our responses to the other reviewers	Reply	O	0

The transfer/ interference perspective of lifelong learning is well motivated, and combining the meta-learning literature with the continual learning literature (applying reptile twice), even if seems obvious, wasn't explored before.	Review	O	0
In addition, this paper shows that a lot of gain can be obtained if one uses more randomized and representative memory (reservoir sampling).	Review	O	0
However, I'm not entirely convinced with the technical contributions and the analysis provided to support the claims in the paper, good enough for me to accept it in its current form.	Review	O	0
Please find below my concerns and I'm more than happy to change my mind if the answers are convincing.	Review	O	0
[line_break_token][line_break_token]Main concerns:[line_break_token][line_break_token]1) The trade-off between transfer and interference, which is one of the main contributions of this paper, has recently been pointed out by [1,2]. GEM[1] talks about it in terms of forward transfer and RWalk[2] in terms of "intransigence".	Review	O	0
Please clarify how "transfer" is different from these.	Review	B-Review	1
A clear distinction will strengthen the contribution, otherwise, it seems like the paper talks about the same concepts with different terminologies, which will increase confusion in the literature.	Review	I-Review	1
   [line_break_token][line_break_token]2) Provide intuitions about equations (1) and (2).	Review	O	0
Also, why is this assumption correct in the case of "incremental learning" where the loss surface itself is changing for new tasks?	Review	B-Review	2
[line_break_token][line_break_token]3) The paper mentions that the performance for the current task isn't an issue, which to me isn't that obvious as if the evaluation setting is "single-head [2]" then the performance on current task becomes an issue as we move forwards over tasks because of the rigidity of the network to learn new tasks.	Review	O	0
Please clarify.	Review	B-Review	3
[line_break_token][line_break_token]4) In eq (4), the second sample (j) is also from the same dataset for which the loss is being minimized.	Review	O	0
Intuitively it makes sense to not to optimize loss for L(xj, yj) in order to enforce transfer.	Review	B-Review	4
Please clarify.	Review	I-Review	3
[line_break_token][line_break_token]5) Since the claim is to improve the "transfer-interference" trade-off, how can we verify this just using accuracy?	Review	O	0
Any metric to quantify these?	Review	B-Review	5
What about forgetting and forward transfer measures as discussed in [1,2]. Without these, its hard to say what exactly the algorithm is buying.	Review	I-Review	5
[line_break_token][line_break_token]6) Why there isn't any result showing MER without reservoir sampling.	Review	O	0
Also, please comment on the computational efficiency of the method (which is crucial for online learning), as it seems to be very slow.	Review	B-Review	6
[line_break_token][line_break_token]7)The supervised learning experiments are only shown on the MNIST.	Review	O	0
Maybe, at least show on CONV-NET/ RESNET (CIFAR etc).	Review	B-Review	7
[line_break_token][line_break_token]8) It is not clear from where the gains are coming.	Review	O	0
Do the ablation where instead of using two loops of reptile you use one loop.	Review	B-Review	8
[line_break_token][line_break_token]Minor:[line_break_token]=======[line_break_token]1) In the abstract, please clarify what you mean by "future gradient".	Review	I-Review	9
Is it gradient over "unseen" task, or "unseen" data point of the same task.	Review	I-Review	9
It's clear after reading the manuscript, but takes a while to reach that stage.	Review	I-Review	9
[line_break_token]2) Please clarify the difference between stationary and non-stationary distribution, or at least cite a paper with the proper definition.	Review	I-Review	9
[line_break_token]3) Please define the problem precisely.	Review	I-Review	9
Like a mathematical problem definition is missing which makes it hard to follow the paper.	Review	I-Review	9
Clarify the evaluation setting (multi/single head etc [2])[line_break_token]4) No citation provided for "reservoir sampling" which is an important ingredient of this entire algorithm.	Review	I-Review	9
[line_break_token]5) Please mention appendix sections as well when referred to appendix.	Review	I-Review	9
[line_break_token]6) Provide citations for "meta-learning" in section 1.	Review	I-Review	9
[line_break_token][line_break_token][line_break_token][1] GEM: Gradient episodic memory for continual learning, NIPS17.	Review	O	0
[line_break_token][2] RWalk: Riemannian walk for incremental learning: Understanding forgetting and intransigence, ECCV2018.	Review	O	0
Thank you for your detailed review and questions.	Reply	O	0
We will address each comment individually:  [line_break_token][line_break_token]Main Concern #1) Thank you for pointing out that the terminology used in our submitted version may be confusing.	Reply	O	0
As you pointed out, it is important to make clear that many of the main ideas we used in our paper including the concepts of transfer and interference in forward and backward directions, the link between transfer and weight sharing, and the idea of involving gradient alignment in a formulation for continual learning have been explored before.	Reply	B-Reply	1
The main contribution of the transfer-interference tradeoff we propose in this work is a novel perspective on the goal of gradient alignment for the continual learning problem.	Reply	I-Reply	1
We have added additional details in the abstract, Section 1, Section 2, and Appendix B in an attempt to make the comparative novelty of our approach clearer.	Reply	I-Reply	1
The transfer-interference tradeoff view of continual learning can be very useful as this temporally symmetric view of this tradeoff in relation to weight sharing leads to a natural meta-learning perspective of continual learning.	Reply	I-Reply	1
We have attempted to make this clearer in Figure 1 and Section 2 Footnote 3.	Reply	I-Reply	1
Moreover, we have added Appendix C to make the connection with weight sharing more explicit.	Reply	I-Reply	1
 [line_break_token][line_break_token]However, our operational measures of transfer and interference are in fact the same as forward and backward transfer considered in (Lopez-Paz & Ranzato, NIPS 2017).	Reply	O	0
Following the terminology of (Lopez-Paz & Ranzato, NIPS 2017), we simply use the term ‚Äútransfer‚Äù to refer to our temporally symmetric view of the problem that does not make a distinction between the forward and backward direction.	Reply	O	0
We use ‚Äúinterference‚Äù as is common in the literature to refer to the case where transfer is negative.	Reply	B-Reply	1
Intransigence and forgetting are also very related to our work as well as the stability-plasticity dilemma.	Reply	I-Reply	1
Intransigence and forgetting measure very similar phenomenon to the metrics learned accuracy (LA) and backward transfer and interference (BTI) that we have added to our experiments.	Reply	I-Reply	1
We should clarify that we do not consider the way we measure performance to be novel or noteworthy.	Reply	I-Reply	1
We have tried to emphasize this by adding additional performance measures such as backward transfer (BTI) and forward transfer (FTI) as used in (Lopez-Paz & Ranzato, NIPS 2017) to our experiments.	Reply	O	0
  [line_break_token][line_break_token]Main Concern #2) We have tried to make it clear at the beginning of Section 2 that these operational statements only hold at an instant in time with a set of parameters theta.	Reply	O	0
Because we are considering both data points to be evaluated by the same set of parameters, these equations hold despite the fact that the data points may be drawn from different tasks.	Reply	B-Reply	2
This is in fact very similar to the instantaneous notion of transfer considered for continual learning in (Lopez-Paz & Ranzato, NIPS 2017) with the main distinction being that we consider transfer on the example level and not the task level.	Reply	O	0
Obviously, you are right that gradients with respect to the parameters at different points in time may be out of date, which would mean these equations wouldn‚Äôt hold.	Reply	B-Reply	2
However, it is important to note that we do not implement this case even in the continual learning setting as replayed memories are always considered with the current parameters theta along with the current example.	Reply	I-Reply	2
It is true that the notion of generalizing based on this learning about transfer and interference into the future will itself be a non-stationary learning problem.	Reply	I-Reply	2
This is because as the parameters change, the notion of good updates for transfer and interference with past examples changes as well.	Reply	I-Reply	2
That being said, we are also stabilizing learning for this non-stationary process with experience replay.	Reply	I-Reply	2
 [line_break_token][line_break_token]Main Concern #3) Thank you for your comment.	Reply	O	0
We would first like to clarify that our experiments on Omniglot would be considered ‚Äúmulti-head‚Äù (Chaudhry et al.,	Reply	B-Reply	3
ECCV 2018).	Reply	I-Reply	3
We have updated the text to make this clearer.	Reply	I-Reply	3
We have also added a new metric learned accuracy (LA) representing performance on a task right after learning that task to our supervised learning experiments and made the task switches clearer for our RL experiments to directly address your concern.	Reply	I-Reply	3
Empirically speaking we find that MER results in the best LA in all cases.	Reply	I-Reply	3
Despite using a single head, MER is apparently able to efficiently navigate the transfer-interference tradeoff of weight sharing to achieve good LA while at the same time achieving good backward transfer and interference (BTI) performance.	Reply	I-Reply	3
 [line_break_token]	Reply	I-Reply	1

This is a very interesting and fairly easy to read paper.	Review	O	0
[line_break_token]The authors present a small, yet nifty approach to make Neural Programming Interpreters significantly more powerful.	Review	O	0
By allowing recursion, NPI generalizes better from fewer execution traces.	Review	O	0
[line_break_token]It's an interesting example of how a small but non-trivial extension can make a machine learning method significantly more practical.	Review	O	0
[line_break_token][line_break_token]I also appreciate that the same notation was used in this paper and the original Deepmind paper.	Review	O	0
As a non-expert on this topic, it was easy to read the original paper in tandem.	Review	O	0
[line_break_token][line_break_token]My one point of critique is that the generalization proves are a bit vague.	Review	B-Review	1
For the numerical examples in the paper, you can iterate over all possible execution paths until the next recursive call.	Review	I-Review	1
However, how would this approach generalize a continuous input space (e.g. the 3D car example in the original paper).	Review	I-Review	1
It seems that a prove of generalization will still be intractable in the continuous case?	Review	I-Review	1
[line_break_token][line_break_token]Are you planning on releasing the source code?	Review	I-Review	2
Thanks for your comments!	Reply	O	0
[line_break_token][line_break_token]Your question about proof over continuous space is similar to one of the questions below, so we refer you to our comment ‚ÄúFeasibility of Verification Procedure‚Äù.	Reply	B-Reply	1
[line_break_token][line_break_token]We plan to clean up our source code and release it in the near future	Reply	I-Reply	2

This paper proposes a graph convolutional  network based model for joint embedding of nodes and relations in a multi-relational graph.	Review	O	0
The framework comprises of node/relation embedding, nonparametric compositional operation as in knowledge graph embedding, and finally convolution operation with direction specific weight matrices.	Review	O	0
The performance is evaluated on link prediction, and node/graph classification tasks.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is well written and literature is sufficiently discussed.	Review	O	0
The performance of the proposed model on the diverse tasks looks good.	Review	O	0
 I have just two minor comments:[line_break_token][line_break_token]1.	Review	O	0
The difference and overlap with Schlichtkrull et al. (	Review	B-Review	1
2017) should be more elaborated on.	Review	I-Review	1
Right now, the paper reads that the main difference is only in employing the basis representation for initial relation features in your work.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	2
There are some inconsistencies in Table 2.	Review	I-Review	2
For example, H@3 for SCAN is same as COMPGCN for FB15k dataset.	Review	I-Review	2
Also, for WN18RR dataset, MR of ConvKB is better but it's not in boldface!	Review	I-Review	2
e thank the reviewer for the constructive comments.	Reply	O	0
[line_break_token]1.	Reply	O	0
Thanks for pointing it out.	Reply	O	0
We have added an additional table (Table 1) in the revised version of the paper to clearly demarcate how our method differs from R-GCN in terms of its applicability and parameter complexity.	Reply	B-Reply	1
We have also added additional explanation to make the differences more explicit.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Please note that in Table 2 (submitted version), we have taken results directly from the previous papers.	Reply	B-Reply	2
SACN authors have reported results rounded to 2 significant digits, so we were not sure whether their method outperforms CompGCN or not.	Reply	I-Reply	2
Moreover, their reported scores are not reproducible from their provided code and hyperparameters.	Reply	I-Reply	2
Nevertheless, we apologize for the mistake and have corrected the error in the revised version of the paper	Reply	I-Reply	2

Summary:[line_break_token]      This paper discussed an approach to do named entity resolution (NER, the paper focuses only on Chinese NER but I think it could generalize to other languages as well).	Review	O	0
The idea is based on smart integration and extension of multiple existing building blocks: 1) BERT pre-trained model 2) a previous work to get document embedding by doing weighted average of word embedding (<a href="https://openreview.net/pdf?id=SyK00v5xx)" target="_blank" rel="nofollow">https://openreview.net/pdf?id=SyK00v5xx)</a> and 3) Scaled dot-product attention mechanism applied directly to multi-label classification.	Review	O	0
The "Introduction", "Related work", and "Experiment Settings" sections are well written and covers many details and decent references.	Review	O	0
Especially, the "experiments" section is described in a great amount of details, which should be very helpful for reproducibility.	Review	O	0
[line_break_token]      [line_break_token]Contributions:[line_break_token]      * The author found an interesting application of the original algorithm (<a href="https://openreview.net/pdf?id=SyK00v5xx)" target="_blank" rel="nofollow">https://openreview.net/pdf?id=SyK00v5xx)</a> to represent the entity class embedding based on averaging "BERT" embeddings of all the component words.	Review	O	0
This could be implemented as a pre-processing step against any training dataset to derive "pre-learned" entity class embedding.	Review	O	0
[line_break_token]      * Instead of the common approach of connecting the BERT sequence outputs directly to CRF layer, the author added an intermediate layer to calculate the classification attention between a sentence (sequence of token embedding) and any entity class (based on the above pre-learned entity embedding).	Review	O	0
This result plus the original sentence embedding are concatenated.	Review	O	0
 The concatenation is further fed into a few additional layers to produce the final inputs into CRF layer.	Review	O	0
[line_break_token][line_break_token]Weakness:[line_break_token]     * The paper lacks novelty.	Review	O	0
As pointed above, I did not see that the contribution from the paper is sufficiently original.	Review	B-Review	1
It is a good application of various existing methods though.	Review	I-Review	1
[line_break_token][line_break_token]I also have a few suggestions/questions below:[line_break_token][line_break_token]* The ERNIE paper (<a href="https://arxiv.org/abs/1907.12412v1)" target="_blank" rel="nofollow">https://arxiv.org/abs/1907.12412v1)</a> is mentioned in the related work.	Review	O	0
Since ERNIE can potentially learn a good vocab for Chinese, did you ever compare your approach vs ERNIE+CRF?	Review	B-Review	2
[line_break_token]* There is one paper that I know which is pretty relevant to what you are doing here, which is probably worth a reference.	Review	O	0
<a href="https://arxiv.org/abs/1805.04174."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1805.04174.</a>  In that paper, the idea is to co-learn a class embedding and perform text classification.	Review	O	0
Their class attention is performed through dot-production attention though.	Review	B-Review	3
[line_break_token]* The Table index seems wrong in your paper. (	Review	O	0
I think Table 2 is not mentioned in your paper, but all tables (3-6) is offset by 1).	Review	B-Review	4
[line_break_token]* There are some minor typos or places that need some clarifications.	Review	O	0
[line_break_token]   - in the abstract: "character-based" model.	Review	O	0
This is a little confusing.	Review	B-Review	5
Because BERT is a word-piece based model.	Review	I-Review	5
word-piece could across multiple characters for English.	Review	I-Review	5
IIUC, You probably want to say "Chinese-character" instead of character.	Review	I-Review	5
[line_break_token]   - in "Introduction", "providing greater weight to characters identical to each entity class", you might want to revise this sentence to clarify its meaning further.	Review	O	0
[line_break_token]   - In section 3.2, you might want to give some explanation to some notations (the first time you refer to it).	Review	O	0
For example, what is, what is and.	Review	B-Review	7
 What is?	Review	I-Review	7
 Also why the denominator of Emb(Word) is not?	Review	I-Review	7
[line_break_token][line_break_token]   - The last paragraph in section 3.3 needs more clarification as well.	Review	O	0
How do you merge the three tensors after attention stage? (	Review	B-Review	8
a concatenation ?) .	Review	I-Review	8
The last sentence mentioned "residential", I guess instead you want to say "residual".	Review	I-Review	8
 You might also want to clarify where the "3 layers" of residual appear in your network.	Review	I-Review	8
[line_break_token][line_break_token]  - In your experiment, (if I did not miss), did you freeze the BERT parameters and entity embeddings when finetuning your NER model?	Review	O	0
[line_break_token][line_break_token]  - in Table 2 and Table 3, why the 13-layer BERT + CRF performs significantly worse on Recall (Table 2) and significantly better on Recall (Table 3)?	Review	O	0
[line_break_token][line_break_token][line_break_token]  	Review	B-Review	3
hank you so much for your kind review.	Reply	O	0
Here gives answsers to all of your questions[line_break_token][line_break_token]1„ÄÅ[tab_token]Result compare with ERNIE+CRF[line_break_token]        Baidu did not publish the pre-training model for the Ernine 2.0, but from the paper, the results of MSRA are as follows:[line_break_token]       Ernie 1.0 Base    f1:93.8[line_break_token]       Ernie  2.0 Base   f1:93.8[line_break_token]       Ernie  2.0 large  f1:95.0[line_break_token]       Also,we are trying to conduct experiment of Ernine 1.0 +CRF[line_break_token][line_break_token]2„ÄÅ[tab_token]Similarities with published papers „ÄäJoint Embedding of Words and Labels for Text Classification„Äã[line_break_token]       Thanks to the reviewer's recommendation, but I had not read any papers about label embeddings in NLP including the paper„ÄäJoint Embedding of Words and Labels for Text Classification„Äãbefore.	Reply	O	0
[line_break_token]       The idea that giving greater weight to characters in the statement that are similar to a particular entity type was gradually formed in working with NER task.	Reply	B-Reply	3
The original source of inspiration came from the Lattice paper <a href="https://arxiv.org/abs/1805.02023."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1805.02023.</a> I found it pretty useful to combine word embeddings to the character-level model.	Reply	O	0
However, the effect of the whole model has a lot to do with the completeness of predefined lexicon (word level) and pretrained word embedding.	Reply	B-Reply	3
So, I tried to eliminate the step of obtaining predefined lexicon, and directly replace the external resources with the easy-to-obtain entity class embeddings.	Reply	I-Reply	3
[line_break_token]     After reading this article many times in the past two days, I found that although the results of both methods are weighted representations of certain words in the article, the process of achieving this result is two completely different approaches.	Reply	I-Reply	3
[line_break_token]     In the paper„ÄäJoint Embedding of Words and Labels for Text Classification„Äã, the label embeddings are trained together with the model, hoping to obtain a class template that could highlight related words with the particular text Topic .For instance, in Figure4(a),it highlights ‚Äúcoaches‚Äù„ÄÅ‚Äùsports‚Äù for STORT news and ‚Äúrock‚Äù, ‚Äúdrummer‚Äù for Entertainment news.	Reply	I-Reply	3
[line_break_token]      However, our goal is to highlight word closed to predefined names-entity classes only.	Reply	I-Reply	3
The class embeddings are fixed at the initial stage of training[line_break_token]      For instance, suppose there is a series of Olympic news and entertainment news that needs to be classified.	Reply	I-Reply	3
According to the model proposed by„ÄäJoint Embedding of Words and Labels for Text Classification„ÄãÔºåwords like ‚Äúgymnasium‚Äù„ÄÅ‚Äùswimming pool‚Äù„ÄÅ‚Äùgold medal‚Äù may also be highlighted along with PERSON- related words ‚Äúathlete‚Äù, ‚Äúcoaches‚Äù.	Reply	I-Reply	3
However, if the predefined entity class in our method is only PERSON, entities in the remaining categories will not be highlighted under ideal conditions[line_break_token]      In my opinion, our approach has a more dominant effect on the NER field, or in areas with a defined reading goal, because the class embedding for attention is preset to the entity class that you want to extract.	Reply	I-Reply	3
But label embedding also gives potential entity information from the opposite perspective.	Reply	I-Reply	3
In the future, we can even try to combine the two methods and discover more potential entities, especially for Internet data!	Reply	I-Reply	3
[line_break_token]     As can be seen from the experimental department, compared to the regular datasets, our method works especially well for user generated data like Weibo, which also shows the validity of class attention in searching potential entities.	Reply	I-Reply	3
[line_break_token]    Finally, I would like to thank the reviewers for recommending the paper„ÄäJoint Embedding of Words and Labels for Text Classification„Äã.	Reply	I-Reply	3
We will continue to follow other articles in this direction.	Reply	I-Reply	3
[line_break_token][line_break_token]4,Sorry for the problems of Table index and notations.	Reply	O	0
They will be fixed in the next version.	Reply	B-Reply	4
[line_break_token][line_break_token]5,We did not freeze the pretrained BERT model, but we freeze all the class embeddings.	Reply	O	0
[line_break_token][line_break_token]6,- in Table 2 and Table 3, why the 13-layer BERT + CRF performs significantly worse on Recall (Table 2) and significantly better on Recall (Table 3)?	Reply	O	0
[line_break_token]This is the result of a real experiment.	Reply	B-Reply	10
My own guess is the irregularity of Weibo data.	Reply	I-Reply	10

This paper proposes a method for dealing with noisy human annotated in training data.	Review	O	0
The idea is to unify the annotation aggregation and model training whilst modelling the sample annotation difficulty and annotator competency level.	Review	O	0
The experiments on five datasets show improvements over a number of baselines.	Review	O	0
[line_break_token][line_break_token]This is a solid piece work that deals with a very practical problem ‚Äì training ML models with crowdsourced data with imperfect annotations.	Review	O	0
The proposed method is not completely new: many ideas have been adopted from previous works.	Review	O	0
However putting everything together seems to work as demonstrated by the experiments.	Review	O	0
[line_break_token][line_break_token]I have a number of concerns:[line_break_token][line_break_token]1, One of the main claimed novelties of the paper is an ‚Äúend-to-end‚Äù approach that unifies ground truth label prediction and label aggregation.	Review	O	0
However there is no ablation study to show that this is indeed better than a two-stepped variant with everything else remaining the same.	Review	B-Review	1
[line_break_token][line_break_token]2, The authors made a claim on the ability to estimate the quality of the annotator.	Review	O	0
But the statement is the Introduction is misleading ‚Äì it suggests that the attributes of the annotator such as age and gender will be used as input to the estimator, but later it is clear that no benchmarks contain that information hence it is not implemented.	Review	B-Review	2
Also it is not clear how this vector embedding (Sec.	Review	I-Review	2
3.2) is implemented.	Review	I-Review	2
Any evidence that this embedding is indeed a clustering index?	Review	I-Review	2
[line_break_token][line_break_token]3, In the implementation, the strong BERT model was used for language but VGG was used for image representation.	Review	O	0
Stronger CNN feature extractors such as ResNet101 should be used.	Review	B-Review	3
[line_break_token][line_break_token]4, In general, the lack of any ablation study is a problem for analysing why the model works.	Review	O	0
 [line_break_token]	Review	B-Review	1
hank you for the feedback and helpful comments!	Reply	O	0
We address your concerns below.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Lack of end-to-end vs. two-step ablation:[line_break_token][line_break_token]This is a valid concern.	Reply	O	0
To this end, we have added an entirely new section (4.3) where we perform an ablation study to try and understand which parts of the proposed model contribute to its performance gains.	Reply	B-Reply	1
Overall we observe that both end-to-end learning and the use of instance features play an important role, with the former being perhaps the most valuable contribution.	Reply	I-Reply	1
As part of this study we also compare with two-stage variants.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Annotator representations:[line_break_token][line_break_token]As you point out, in the datasets considered in our study, no worker features were available besides their IDs.	Reply	O	0
In fact, we were unable to find datasets where the worker features were available (partially because no prior models were able to use that information).	Reply	B-Reply	2
Hence we opted to model workers with embeddings.	Reply	I-Reply	2
If worker features were available, our framework could directly accommodate for that.	Reply	I-Reply	2
We have added a brief note on that in the current paper revision.	Reply	I-Reply	2
Regarding the learned embeddings behaving as a clustering index, we have also added a couple of visualizations that showcase this point (Section 4.4 in the revised version).	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
ResNet101 feature extractors:[line_break_token][line_break_token]This is a valid point and we thank you for your suggestion.	Reply	O	0
We actually re-ran all image-based experiments using a pre-trained ResNet101 feature extractor and have already updated the submitted manuscript.	Reply	B-Reply	3
This change resulted in even more significant performance gains for our method (e.g., our results for BlueBirds shown in Table 2 are now significantly stronger).	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	1
Ablation study:[line_break_token][line_break_token]We addressed this concern by adding an ablation study section (4.3)	Reply	O	0

The paper proposes a learning approach for zero-shot imitation learning in an RL setting across domains with different embodiments and viewpoint mismatch.	Review	O	0
The proposed approach involves two steps, alignment and adaptation.	Review	O	0
In contrast to previous work, the alignment between domains, represented as MDPs, is learned from unpaired, unaligned samples from both domains.	Review	O	0
The paper presents a theoretical formulation of the cross-domain imitation learning problem, and presents an algorithm for training alignment and adaptation from data.	Review	O	0
[line_break_token][line_break_token]I think the paper is well written and theoretically well-founded.	Review	O	0
The authors provide experiments comparing to many previous works in cross-domain imitation learning and show that their approach outperforms previous approaches.	Review	O	0
[line_break_token][line_break_token]I only have minor comments.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
For imitation between reacher2 and reacher3, there are multiple correspondences between the two domains due to the redundancy in the 3-link robot (and in general with n-link robots).	Review	B-Review	1
How does GAMA deal with these redundancies?	Review	I-Review	1
For example, an n-link robot is able to perform the same task with different configurations (elbow up, elbow down, etc.,)	Review	I-Review	1
and all these will correspond to one configuration of a 2-link robot.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
In practise, can 'alignment complexity' and 'adaptation complexity' help identify if transfer with GAMA between two domains is not beneficial?	Review	B-Review	2
Results in Figure 5 only shows cases for GAMA in which the two metrics are good, resulting in good transfer.	Review	I-Review	2
However, I am interested in knowing if there could be cases in which the two complexity metrics tell beforehand that transfer will not be beneficial.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
In Figure 5's caption, Adaptation complexity is on Left and Alignment Complexity in the Middle.	Review	B-Review	3
However, the text refers to Alignment complexity on the Left and Adaptation complexity in the Middle.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
A reference is missing in Appendix B.	Review	B-Review	4
Thank you for your feedback.	Reply	O	0
Below we respond to your questions.	Reply	O	0
We've uploaded a revised draft that addresses all of your suggestions.	Reply	O	0
[line_break_token][line_break_token]Q. For imitation between reacher2 and reacher3, there are multiple correspondences between the two domains due to the redundancy in the 3-link robot (and in general with n-link robots).	Reply	O	0
How does GAMA deal with these redundancies?	Reply	O	0
For example, an n-link robot is able to perform the same task with different configurations (elbow up, elbow down, etc.,)	Reply	O	0
and all these will correspond to one configuration of a 2-link robot.	Reply	O	0
[line_break_token][line_break_token]A: If there exists multiple MDP reductions from a lower dimensional robot to a high dimensional robot, any one of them will be a global optimum of our optimization objective by Theorem 1.	Reply	O	0
Hence GAMA should learn to map the states of the lower dimensional robot to states of the high dimensional robot which together compose one (out of potentially many) sequence of configurations in which the high dimensional robot accomplishes the task.	Reply	B-Reply	1
We observe this empirically: reacher3 has many different sequences of states that correspond to successful goal reaching (due to redundancy).	Reply	I-Reply	1
The (learned) statemap from reacher2 to reacher3 converges to one of them.	Reply	I-Reply	1
Last paragraph of section 3 is also relevant to this point.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Q. In practise, can 'alignment complexity' and 'adaptation complexity' help identify if transfer with GAMA between two domains is not beneficial?	Reply	O	0
Results in Figure 5 only shows cases for GAMA in which the two metrics are good, resulting in good transfer.	Reply	O	0
However, I am interested in knowing if there could be cases in which the two complexity metrics tell beforehand that transfer will not be beneficial.	Reply	O	0
[line_break_token][line_break_token]A: Yes, we believe good adaptation complexity and good adaptation complexity implies good transferability since good zero-shot imitation performance will ‚Äúkick start‚Äù the policy getting rid of the burn-in phase.	Reply	O	0
This is especially useful if the target task reward is sparse.	Reply	B-Reply	2
If the adaptation complexity and alignment complexity are bad, we indeed observed that transferability is worse.	Reply	I-Reply	2
For example, in the W2C task if we train on a small alignment task set (which has worse adaptation/alignment performance), then the policy trains slower on the target task.	Reply	I-Reply	2
We can include these results in the final submission.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Q. In Figure 5's caption, Adaptation complexity is on Left and Alignment Complexity in the Middle.	Reply	O	0
However, the text refers to Alignment complexity on the Left and Adaptation complexity in the Middle.	Reply	O	0
[line_break_token][line_break_token]A: Thank you for catching this.	Reply	O	0
We have updated the submission.	Reply	B-Reply	3
[line_break_token][line_break_token][line_break_token]Q. A reference is missing in Appendix B.[line_break_token][line_break_token]A: Thank you for pointing this out.	Reply	O	0
We have updated the submission.	Reply	B-Reply	3

The paper proposes learning physical derivatives, the derivative of the trajectory distribution with respect to policy parameters.	Review	O	0
The proposed method estimates changes in  trajectories at a particular theta by using finite differences,[line_break_token]then fitting Gaussian Processes per timestep to generalize to new dtheta's.	Review	O	0
The paper then proposes techniques to robustify the process against noise in the system.	Review	O	0
[line_break_token]To deal with temporal noise, where trajectories are approximately equal up to a time shift, they simply[line_break_token]estimate the optimal shift and use the shifted version to estimate.	Review	O	0
To address more complicated noise, they assume sensitivity of trajectories to noise is small relative [line_break_token]to sensitivity to the parameters, and discretize the state space at a level such that trajectories that [line_break_token]differ primarily due to inherent noise look the same at the discretized level, while perturbed policy [line_break_token]parameters still lead to different trajectories.	Review	O	0
They then use the discretized trajectories to estimate [line_break_token]the finite differences.	Review	O	0
[line_break_token][line_break_token]Experiments illustrate how the learned predictions compared to actual resulting perturbations and [line_break_token]illustrate resulting trajectories on certain toy domains and a physical robotic finger.	Review	B-Review	1
All experiments[line_break_token]are done with very low dimensional state and policy spaces (1-3 dimensions each).	Review	I-Review	1
[line_break_token][line_break_token]Without much more extensive experimental validation, this paper should be rejected.	Review	I-Review	2
While I am not aware [line_break_token]of any prior work on learning physical derivatives, the actual methods used are not novel in of themselves[line_break_token]beyond being applied towards learning derivatives with respect to the policy.	Review	I-Review	2
As such, the method should be[line_break_token]of practical interest in order to be accepted.	Review	I-Review	2
With limited experiments on a single very low dimensional [line_break_token]domain and no comparisons against any alternative methods, there is little evidence demonstrating the actual [line_break_token]effectiveness of the proposed method, especially on more complex domains and for downstream tasks.	Review	I-Review	2
[line_break_token][line_break_token]Suggested Experiments:[line_break_token][line_break_token]- Stability in gradient estimation[line_break_token]It seems like it could require huge amounts of samples to be able to estimate gradients at parameters [line_break_token]where for which the system is not very stable, as states in at later timesteps can easily change in [line_break_token]hard to predict ways as the dynamics are propogated through time.	Review	O	0
This should be an especially big issue [line_break_token]if we do not already have good stable controllers close to the desired solution and needed to actually [line_break_token]conduct exploration in parameter space to solve a taask.	Review	B-Review	8
I would appreciate more extensive evaluation [line_break_token]across multiple different (simulated) domains and assessing the effectiveness of gradient estimation [line_break_token]along random parameters.	Review	I-Review	8
[line_break_token][line_break_token]- Dimensionality of policy parameters and state spaces[line_break_token]The current experiments only involve very small parameter spaces.	Review	O	0
It would be important to see how well[line_break_token]using finite differences and GP regression scales with a higher dimensional search space, which can be [line_break_token]demonstrated on varying dimensionalities of an LQR system for example.	Review	B-Review	9
It would also be important to see[line_break_token]how gradient estimation scales with high dimensional state spaces even with a small parameter space (like[line_break_token]in the PD controller experiment in the paper).	Review	I-Review	9
[line_break_token][line_break_token]- Direct Comparison against learning dynamics models[line_break_token]Using the same data, compare (with same metrics as in table 1) physical derivatives estimated with the [line_break_token]proposed approach against learning GP dynamics models and rolling out the perturbed policy with the learned[line_break_token]model.	Review	O	0
Without a direct comparison against learning dynamics models and understanding what situations [line_break_token]learning physical derivatives provides better estimates, it is unclear when or why one would prefer to learn [line_break_token]physical derivatives in this way compared to a model based approach.	Review	B-Review	3
[line_break_token][line_break_token]- Quantitative results measuring costs of learned controllers[line_break_token]Despite the name of the paper and a description of how to compute a policy gradient via physical derivatives, [line_break_token]there are no experiments involving such policy gradient updates as far as I can tell.	Review	O	0
While one advantage of the [line_break_token]method (as well as model based approaches) is the ability to learn in unsupervised manner, it would be extremely [line_break_token]helpful to validate how well the physical derivatives are estimated in terms of how useful they are for a downstream [line_break_token]task, such as optimizing a controller for a cost function.	Review	B-Review	4
Right now, experimental results lack any comparisons[line_break_token]to other methods or any other way to assess the effectiveness of estimating physical derivatives.	Review	I-Review	4
[line_break_token]A comparison against regular RL policy gradient methods (or other model free algorithms) and model based RL [line_break_token]would give an idea as to whether the physical derivatives learned are actually useful.	Review	I-Review	4
[line_break_token][line_break_token]Other questions and comments:[line_break_token][tab_token]- Table 1: is this evaluating the accuracy of the physical derivatives on the shaking data that it was[line_break_token][tab_token]  used for learning, or on a validation set?	Review	O	0
If on a validation set, would the validation perturbations be[line_break_token][tab_token]  drawn from the same distribution as the training set?	Review	B-Review	5
[line_break_token][tab_token]- The zero shot planning experiment in section 4.4 seems very contrived.	Review	O	0
It does not seem like a useful task[line_break_token][tab_token]  to adjust the parameters of the PD controller in order to reach a state that isn't the target.	Review	B-Review	6
The figures [line_break_token][tab_token]  illustrating trajectories are also not very convincing and unclear.	Review	I-Review	6
Two points are labelled source state and[line_break_token][tab_token]  target state, but it is not clear which is the intermediate state it is supposed to reach.	Review	I-Review	6
In any case, most [line_break_token][tab_token]  of the trajectories seem to vastly overshoot the target?	Review	I-Review	6
final state, and it is hard to assess how close the[line_break_token][tab_token]  trajectories end up being to the intended states from a 2d representation of a 3d space.	Review	I-Review	6
Quantitative results[line_break_token][tab_token]  would perhaps have been more useful in illustrating the effectiveness of using physical derivatives.	Review	I-Review	6
[line_break_token][tab_token]- What is the purpose of figure 4?	Review	O	0
It does not appear to be referenced in the text and it is not clear what is[line_break_token][tab_token]  being shown.	Review	B-Review	7
[line_break_token][tab_token][line_break_token]Other notes not part of decision:[line_break_token][tab_token]Paper exceeds the 8 page recommended length[line_break_token][tab_token]Lots of small typos in the text[line_break_token][line_break_token][tab_token]	Review	O	0
e thank the respected reviewer for the careful reading of our work and the constructive remarks.	Reply	O	0
In the following, we separate the mentioned points and answer each in a distinct paragraph.	Reply	O	0
[line_break_token][line_break_token]Regarding low-dimensional experiments: [line_break_token]This is true but it is due to the nature of the robotic arm and the controller.	Reply	O	0
We don‚Äôt see this as a limitation of the method since we work with parametric controllers here not neural network policies.	Reply	B-Reply	1
[line_break_token][line_break_token]Regarding Novelty, practical interest and the need for extensive experimentation: [line_break_token]This paper is an initial step towards learning a quantity from physical systems which is independent of a specific task.	Reply	O	0
Compared to conventional RL where the reward function is an inseparable component, this work tries to test the feasibility of learning a useful quantity other than value functions.	Reply	B-Reply	2
[line_break_token]We believe learning physical derivatives is a fundamental learning problem and has not been addressed before.	Reply	I-Reply	2
Therefore, showing its feasibility and methods to deal with its issues is a challenging problem by itself that we addressed in this work.	Reply	I-Reply	2
Comparing with state of the art methods in RL and Control in downstream tasks is, of course, important but will be the next steps.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding exploration in the parameter space:[line_break_token]Physical derivatives is an unsupervised quantity and we do not learn it to solve a specific task.	Reply	O	0
It might not be a good idea to learn physical derivatives for a wide range of parameters only to solve a single RL task.	Reply	B-Reply	8
One can think of physical derivatives as the derived proxy model of the system that can be useful in all RL and Control tasks not only one.	Reply	I-Reply	8
[line_break_token][line_break_token]Regarding the number of required samples, Yes, it can be true.	Reply	I-Reply	8
However, the exact purpose of learning Gaussian Process regressors from perturbations in parameter to deviations in trajectories and showing the prediction accuracy on test data is to emphasize the generalizability of the method that was shown qualitatively in the figures 16-24 in the appendix and also in Table 1.	Reply	I-Reply	8
[line_break_token][line_break_token]Regarding high-dimensional policy: Yes, this is an important question but is beyond the scope of this paper as the first work in learning physical derivatives.	Reply	I-Reply	9
Moreover, many practical controllers live in low-dimensional parameter space.	Reply	I-Reply	9
For example 3 parameters in a PID controller or a few parameters in a nonlinear controller (e.g. bang-bang controller with a single on-off threshold).	Reply	I-Reply	9
[line_break_token][line_break_token]Regarding high-dimensional state space: We constructed separate predictors from the parameter perturbations to each dimension of the state space and showed the high accuracy of the predictions in Table 1.	Reply	O	0
Please notice that we built a robot to conduct the experiments since we intentionally wanted to go beyond simulations and show the efficacy of the method on physical systems.	Reply	B-Reply	9
One can build another robot with a higher dimensional state space that satisfies the safety requirements of the intended experiments in order to test the method in higher dimensions.	Reply	I-Reply	9
[line_break_token][line_break_token]Regarding direct comparison against methods that learn dynamics: We agree these are interesting comparisons but can be future steps.	Reply	O	0
Learning physical derivatives from physical systems (not simulators) by itself has challenges and the goal of this paper is to address those challenges and finally showcasing one of its applications as in section 4.4.	Reply	B-Reply	3
[line_break_token][line_break_token]Regarding the usefulness of the method in downstream tasks:[line_break_token]Please see 4.4 where the usefulness of physical derivatives for a downstream task.	Reply	O	0
[line_break_token][line_break_token]Regarding the content of Table 1:[line_break_token]The prediction performance is evaluated on validation data which is left out of the initial training set.	Reply	O	0
[line_break_token][line_break_token]Regarding zero-shot experiment:[line_break_token]We did not argue that using physical derivatives is the best way to perform the task of 4.4.	Reply	O	0
The goal of this experiment is to show that the trained mapping from controller perturbations to trajectory deviations generalizes well and consequently can be used to tackle a downstream task.	Reply	B-Reply	6
[line_break_token][line_break_token]Regarding the purpose of Figure 4:[line_break_token]Figure 4 shows the effect of perturbing the parameters of the controller on the trajectories of the physical system.	Reply	O	0
The reference was mistakenly omitted from the text.	Reply	B-Reply	7

This paper presents a solution to tackling the problem of delusional bias in Deep Q-learning, building upon Lu et.al. (	Review	O	0
NeuRIPS 2018).	Review	O	0
 Delusional bias arises because independently choosing maximizing actions at a state may be inconsistent as the backed-up values may not be realizable by any policy.	Review	O	0
They encourage non-delusional Q-functions by adding a penalty term that enforces that the max_a in Q-learning chooses actions that do not give rise to actions outside the realizable policy class.	Review	O	0
Further, in order to keep track of all consistent assignments, they pose a search problem and propose heuristics to approximately perform this search.	Review	O	0
The heuristics are based on sampling using exponentiated Q-values and scoring possible children using scores like Bellman error, and returns of the greedy policy.	Review	O	0
Their final algorithm is evaluated on a DQN and DDQN, where they observe some improvement from both components (consistency penalty and approximate search).	Review	O	0
[line_break_token][line_break_token]I would lean towards being slightly negative towards accepting this paper.	Review	O	0
However, I am not sure if the paper provides enough evidence that delusional bias is a very relevant problem with DQNs, when using high-capacity neural net approximators.	Review	B-Review	1
Further, would the problem go away, if we perform policy iteration, in the sense of performing policy iteration instead of max Q-learning (atleast in practice)?	Review	I-Review	1
Maybe, the paper benefits with some evidence answering this question.	Review	I-Review	1
To summarize, I am mainly concerned about the marginal benefit at the cost of added complexity and computation for this paper.	Review	O	0
I would appreciate more evidence justifying the significance of this problem in practice.	Review	B-Review	2
[line_break_token][line_break_token]Another comment about experiments is that the paper uses pre-trained DQN for the ConQur results, where only the last linear layer of the Q-network is trained with ConQur.	Review	I-Review	3
I think this setting might hide some properties which arise through the learning process without initial pre-training, which might be more interesting.	Review	I-Review	3
Also, how would other auxilliary losses compare in practice, for example, losses explored in the Reinforcement Learning with Auxilliary Tasks (Jaderberg et.al.)	Review	O	0
paper?	Review	B-Review	4
hank you for the constructive feedback and for raising some important questions.	Reply	O	0
Some brief responses to specific points/questions you raise.	Reply	O	0
[line_break_token][line_break_token][DOES DELUSION ARISE IN PRACTICE?]	Reply	O	0
The purpose of the experiments is to show that mitigating delusional bias, even with high-capacity NNs, can offer improvements.	Reply	B-Reply	1
We believe the experiments show that delusional bias does occur in practice since the pre-trained Q-regressors upon which we improve are Dopamine-trained DQNs/DDQNs.	Reply	I-Reply	1
Our methods differ only from (say) DQN in the use of the soft-consistency penalty (plus the use of search to explore multiple assignments against which to apply this penalty).	Reply	I-Reply	1
We claim that this tackles only ‚Äúpolicy inconsistency‚Äù (i.e., delusion).	Reply	I-Reply	1
Because we obtain improvements over the pre-trained DQNs, our conclusion is that delusion does, indeed, arise in practice.	Reply	I-Reply	1
In retrospect, we should have made this important point much more explicit in the paper---our apologies for not doing so originally---and we will do so in revision.	Reply	I-Reply	1
[line_break_token][line_break_token]Our experiments, we believe, do not demonstrate the full power of removing delusion, since we only retrain the last FC layer of the pre-trained DQN, which in fact limits our performance opportunities vs. training on all layers---this alone results in significantly better greedy policies in many instances.	Reply	I-Reply	1
[line_break_token][line_break_token][WILL DELUSION ARISE IN POLICY ITERATION?]	Reply	O	0
This is a good point, and while it may depend on the implementation, generally policy iteration will not have delusional bias.	Reply	B-Reply	2
However, our contribution is focused on improving ‚Äúpure‚Äù value-based methods like Q-learning (and related methods like DDQN).	Reply	I-Reply	2
These are widely used algorithms, that researchers and practitioners often have strong reasons to use---our focus is to mitigate delusional bias to extract maximum value from such methods whenever they are used.	Reply	I-Reply	2
[line_break_token][line_break_token][WHY USE PRE-TRAINED NETWORKS]?	Reply	O	0
The rationale for improving with pre-trained DQNs is three-fold.	Reply	B-Reply	3
[line_break_token][line_break_token]First, it demonstrates that delusion actually causes problems in practice (as discussed above, we will articulate this point much more explicitly in revision).	Reply	I-Reply	3
In some sense, by freezing the feature representation learned by DQN, and demonstrating that a ‚Äúlinear‚Äù value function over those same features can be trained in (partially) non-delusional  fashion to extract improvements gives more of a focus on non-delusional training (as opposed to novel ‚Äúfeature discovery‚Äù).	Reply	I-Reply	3
[line_break_token][line_break_token]The second reason is a practical one---it allowed us to scale our experiments to cover a range of hyperparameters and run the entire Atari suite (rather than selecting just a few high-performing games).	Reply	I-Reply	3
 We completely agree with your broader point about experimenting with our methods with full network training (i.e., from scratch) to understand their performance.	Reply	I-Reply	3
In some sense, this paper provides a (we hope, compelling) first exploration of these ideas.	Reply	I-Reply	3
[line_break_token][line_break_token]Third, from a practical point of view, this ‚Äúlinear tuning‚Äù approach offers a relatively inexpensive alternative to extract improvements from a model learned using classic techniques (e.g., linear tuning requires many fewer training samples).	Reply	I-Reply	3
[line_break_token][line_break_token]We also note that, if the full application of ConQUR is too expensive in some settings, adding a our simple consistency penalty can sometimes provide a lift (and rarely hurts), as shown by the experiments in Section 4.1.	Reply	I-Reply	3
This requires no major changes to standard DQN, DDQN or the like and adds no significant implementation complexity or computational cost.	Reply	I-Reply	3
[line_break_token][line_break_token][AUXILIARY LOSSES] Thanks for making the reference to auxiliary losses, this is an interesting question.	Reply	O	0
While our penalty term focuses on consistency for a single task and auxiliary losses help accelerate learning for the main task, we can imagine applying a consistency penalty for each auxiliary objective (in addition to minimizing task‚Äôs Bellman error).	Reply	B-Reply	4
This direction is interesting to explore, which we will cite in the revised paper	Reply	I-Reply	4

A sparse coding model of natural sounds (speech) is proposed.	Review	O	0
The signal is represented by a complex sparse coding problem with smoothness priors on both amplitude and phase.	Review	O	0
Learning and inference proceeds as in standard sparse coding.	Review	O	0
The method is analyzed in terms of statistics of complex pairs filters as well as denoising.	Review	O	0
[line_break_token][line_break_token]The method is not very novel.	Review	B-Review	1
Complex sparse coding was already introduced in the past and the sparsity priors on the amplitudes and coefficients are a straightforward extension (or simplification compared to the work by Cadieu et al.).	Review	I-Review	1
[line_break_token][line_break_token]Pros:[line_break_token]- interesting application[line_break_token]- fairly clear written paper[line_break_token][line_break_token]Cons:[line_break_token]- insights may be good but I probably did not fully understood them.	Review	O	0
Why are sounds inherently different from images?	Review	B-Review	2
Is it an artifact of how the experimental set up?	Review	I-Review	2
Without sparsity/smoothness constraints, the problem is clearly underdetermined and therefore filters do not necessarily converge to quadrature pairs.	Review	I-Review	2
[line_break_token]- what is the contribution of this work compared to Cadieu et al?	Review	O	0
They had an extra layer, but the basic idea of smoothness of phase and amplitude is present also in that work.	Review	B-Review	6
[line_break_token]- empirical validation is not sufficient because:[line_break_token]  - more quantitative results would be beneficial to assess the benefits of this model.	Review	O	0
For instance, the authors may want to compare and cite:[line_break_token]Y. Karklin, C. Ekanadham, and E. P. Simoncelli, Hierarchical spike coding of sound, Adv in Neural Information Processing Systems (NIPS), 2012[line_break_token]- some parts need clarification[line_break_token]  - eq.	Review	O	0
9: why is this a good choice?	Review	B-Review	8
wouldn‚Äôt it be better to have it bounded below?	Review	I-Review	8
[line_break_token]   - sec.	Review	O	0
2.2 why rescaling the gradients when there are beta and gamma?	Review	B-Review	9
[line_break_token]   - in the compression experiment, shouldn‚Äôt the reconstruction error be taken into account?	Review	O	0
[line_break_token][line_break_token]Overall, this is interesting work.	Review	B-Review	5
However, several clarifications are required in order to better assess novelty and to understand the method.	Review	I-Review	5
Also, the empirical validation should be strengthened.	Review	I-Review	5
Thank you for your comments and suggestions.	Reply	O	0
[line_break_token][line_break_token]Firstly, I agree that the paper does not introduce any fundamentally novel method.	Reply	B-Reply	1
What may be considered as technical novelties are:[line_break_token][line_break_token]- the fact that priors are placed on basis functions [line_break_token]- smoothness priors are placed on both: phases and amplitudes (Cadieu et al, penalized only amplitude dynamics, not phase)[line_break_token]- an additional term in the phase penalty, which enforces it's monotonicity.	Reply	I-Reply	1
[line_break_token][line_break_token]The purpouse of the paper was not, however to introduce a novel method - it was to learn representations of a certain class of signals (natural sounds) and to study the properties of obtained features.	Reply	I-Reply	1
Such representations may find applications in tasks which operate on sound data.	Reply	I-Reply	1
[line_break_token]That is why I do not think that the present paper should be directly compared with the hierarchical model introduced by Cadieu et al.	Reply	I-Reply	1
especially in the context of a method novelty.	Reply	I-Reply	1
Cadieu and Olshausen, constructed a hierarchical representation of natural videos with a purpouse of extracting motion invariances.	Reply	I-Reply	1
The present paper learns single layer representations of natural sounds - this is a fundamental difference.	Reply	I-Reply	1
[line_break_token][line_break_token]It is an interesting question, in which (statistical) sense sounds are different from images (please, see my response to the previous review).	Reply	I-Reply	2
After all, physcially they are very different stimuli.	Reply	I-Reply	2
Suggested by the results presented in [21, 22] I have introduced a brief analysis of harmonic relationships between real and imaginary vectors.	Reply	I-Reply	2
A full answer to that problem requires extensive research.	Reply	I-Reply	2
[line_break_token][line_break_token]I have performed two kinds of quantitative analysis: denoising and comparison of coefficient entropies.	Reply	I-Reply	3
The analysis was performed as in cited literature [14, 28]. Due to the space constraints I have not presented more details.	Reply	I-Reply	3
Personally, I find presented results conclusive.	Reply	I-Reply	3
The work by Karklin et al you cite analyzed the learned representation also by performing a denoising task.	Reply	I-Reply	3
I do not fully understand, how should I compare the present study to their results, as you suggest.	Reply	I-Reply	3
[line_break_token][line_break_token]I understand that by compression experiment you mean the comparison of coefficient entropies.	Reply	I-Reply	4
Of course, a trivial solution would be a basis set which yields 0 entropies, while not being able to reconstruct the data at all (an 'infinite' reconstruction error).	Reply	I-Reply	4
As the denoising experiment shows, this is not the case for any of the learned bases.	Reply	I-Reply	4
Entropy estimates give therefore an idea of a relative coding cost, and according to Shannon's source coding theorem, the model yielding the lowest coding cost is closest to the true data distribution.	Reply	I-Reply	4
For a detailed discussion please refer to [14, 15]. The entropy values should be considered together with the denoising performance.	Reply	I-Reply	4
[line_break_token][line_break_token]Bounding the phase derivative from below is also a possible way to enforce the phase monotonicity.	Reply	I-Reply	8
However, it would require introduction of another parameter - the bound itself.	Reply	I-Reply	8
The proposed prior does not require any additional parametrization.	Reply	I-Reply	8
I have modified the description of equation 9 to address your suggestion.	Reply	I-Reply	8
[line_break_token][line_break_token]For convenience, gamma and beta lie in the [0, 1] interval.	Reply	I-Reply	9
The gradient moduli (before multiplying by gamma, beta and the step size) can be much larger than 1.	Reply	I-Reply	9
In such a case, prior strength parameters affect the gradient step very weakly.	Reply	I-Reply	9
That is why gradient terms are firstly normalized to have the same length, and then multiplied by gamma and beta	Reply	I-Reply	9

This is an important contribution to understand finite depth and width corrections to the NTK.	Review	O	0
The authors show that the diagonal terms of NTK remain stochastic when depth and width approach infinity at the same rate.	Review	O	0
[line_break_token][line_break_token]NTK [1] is one of the most exciting discovers for extremely over-parameterized NNs in the last year.	Review	O	0
In the single limit setting, i.e. fixing depth and letting width -&gt; infinity, the [1] showed that the NTK converges in distribution to a deterministic kernel and remained almost unchanged during gradient descent.	Review	O	0
 This regime is known as the kernel regime or linearized regime, where the training dynamics of the NN is well-approximated by its first order Taylor expansion.	Review	O	0
[line_break_token][line_break_token]In this paper, the authors show that in the double limit regime, i.e. depth/width = \beta and depth, width -&gt; infinity, the diagonal terms of the NTK, as well as the first gradient step, is NOT deterministic.	Review	O	0
More precisely, they upper and lower bound the second moment of the diagonal terms of NTK (and first gradient step) through the temperature \beta.	Review	O	0
Their method builds on the `"sum-over-path approach" developed in [3], etc.	Review	O	0
[line_break_token][line_break_token]Overall, this is a very interesting result, proposing a new scaling limit that gradient descent dynamics can be highly nontrivial (i.e. not in the kernel regime.)	Review	O	0
and NNs can possibly learn useful representation.	Review	O	0
[line_break_token][line_break_token]Other comments: [line_break_token]1.	Review	O	0
It will be very helpful to have some experiments to support the main theorems in the paper since the proof is quite involved.	Review	B-Review	1
[line_break_token]2.	Review	O	0
How difficult is it to compute the off-diagonals?	Review	B-Review	2
Is it possible to obtain other statistics of of the NTK, trace, max eigenvalue, etc.	Review	I-Review	2
[line_break_token]3.	Review	O	0
Is it possible to extend the results to other non-linearities, e.g. Tanh?	Review	B-Review	3
[line_break_token][line_break_token][line_break_token][1]Arthur Jacot, Franck Gabriel, and Clement Hongler.	Review	O	0
Neural tangent kernel: Convergence and gen- ¬¥[line_break_token]eralization in neural networks.	Review	O	0
In Advances in neural information processing systems, pp.	Review	O	0
8571‚Äì[line_break_token]8580, 2018.	Review	O	0
[line_break_token][2] Jaehoon Lee, Lechao Xiao, Samuel S Schoenholz, Yasaman Bahri, Jascha Sohl-Dickstein, and Jeffrey Pennington.	Review	O	0
Wide neural networks of any depth evolve as linear models under gradient[line_break_token]descent.	Review	O	0
arXiv preprint arXiv:1902.06720, 2019.	Review	O	0
[line_break_token][3]Boris Hanin and David Rolnick.	Review	O	0
How to start training: The effect of initialization and architecture.	Review	O	0
[line_break_token]In Advances in Neural Information Processing Systems, pp.	Review	O	0
571‚Äì581, 2018	Review	O	0
e thank the reviewer for his/her careful reading of our paper and various questions.	Reply	O	0
We respond to them in order:[line_break_token][line_break_token]1.	Reply	O	0
About experiments, please see point 1 in our response to Reviewer #1 and point 1c in our response to Reviewer #2.	Reply	B-Reply	1
However, we would like to point out that in lieu of having simulations, we devote Section 3.1 to giving an informal  overview of the main steps and ideas in our proofs.	Reply	I-Reply	1
 [line_break_token][line_break_token]2.	Reply	O	0
As explained in point 1b in our response to Reviewer #2, computing finite depth/width corrections to the statistics for the off-diagonal entries K(x,x') of the NTK appears to be challenging at the moment.	Reply	B-Reply	2
We are certainly thinking about it and hope to address it in future work.	Reply	I-Reply	2
We also think that computing spectral statistics of the NTK would be very interesting but may involve even more difficulties since it would may require knowing not only the joint distribution of the terms such as K(x,x') but also of all the entries in the full dataset by dataset size kernel matrix.	Reply	I-Reply	2
Thank you for bringing up this point: we will add a short discussion in our revision.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	1
As mentioned in point 1b of our response to Reviewer #2, we do not know at the moment if our techniques (and indeed the qualitative nature of our results) would extend to other non-linearities.	Reply	I-Reply	3
Intuitively, bounded non-linearities may lead to very different spectral statistics for the NTK.	Reply	I-Reply	3
For instance, even in the infinite width limit different non-linearies give rise to different spectral statistics for the much simpler computation of the input-output Jacobian.	Reply	I-Reply	3
Again, we thank you for bringing up this point and will mention this issue in our revision.	Reply	I-Reply	3

The paper is written very nicely and the experiments are convincing (though you can always show more)[line_break_token][line_break_token]In terms of novelty, I shamelessly can say the idea is very simple and the basic form, the Hoyer regularization, was known.	Review	O	0
That said, I am all in for simple and efficient solutions so I am giving this paper a weak accept for now.	Review	O	0
[line_break_token][line_break_token]There is not much to ask here (unless I say I want to see how this would work on other backbones and problems).	Review	O	0
nevertheless, to improve this work, I think the authors need to compare which solution (referring to algorithms in Table1, 2 etc.)	Review	B-Review	2
is faster/more well-behaved given the combo explained at the bottom of page 5 .	Review	I-Review	2
This is basically my question/request for the rebuttal.	Review	I-Review	2
 	Review	I-Review	1
hank you for your positive feedback to our paper.	Reply	O	0
I‚Äôd like to emphasize that the main idea of this paper is to find a sparsity-inducing regularizer leveraging the desired property of both the L0 regularizer (scale-invariant, minima along the axis) and the L1 regularizer (almost everywhere differentiable).	Reply	B-Reply	1
With these requirements in consideration, we find that Hoyer Square, the square of the traditional Hoyer regularizer, satisfies all the desired properties and behaves as a differentiable approximation to the L0 norm.	Reply	I-Reply	1
Extensive experiments are then performed to prove the desired property of Hoyer-Square is truly helpful for both element-wise and structural pruning of DNN models.	Reply	I-Reply	1
[line_break_token][line_break_token]The three-stage pruning operations mentioned at the bottom of page 5 is a common practice for DNN pruning.	Reply	I-Reply	2
Previous works like iterative pruning (Han et al.,	Reply	I-Reply	2
2015b), regularization-based methods (Liu el al.,	Reply	I-Reply	2
2015; Wen et al.,	Reply	I-Reply	2
2016; Ma et al.,	Reply	I-Reply	2
2019), and ADMM (Zhang et al.,	Reply	I-Reply	2
2018) etc.	Reply	I-Reply	2
all follow similar operations.	Reply	I-Reply	2
Since the DeepHoyer regularizer is almost everywhere differentiable, it can be directly added to the original loss function of DNN training and be minimized with SGD (or other gradient-based) optimizers.	Reply	I-Reply	2
Thus, the optimization process is as fast as applying L1 regularization, and a lot faster than ADMM which requires complex interplay between multiple objectives.	Reply	I-Reply	2
Our experiment results show that DeepHoyer can achieve the lowest sparsity without introducing further complexity in the training process.	Reply	I-Reply	2
Among all the pruning methods, SNIP (Lee et al.,	Reply	I-Reply	2
2019) is the only one that does not require the 3-stage operations, as it prunes the model at initialization.	Reply	I-Reply	2
SNIP might be faster than DeepHoyer, but the final solution it can achieve has much larger amount of parameters (2.5x on MNIST models).	Reply	I-Reply	2
As mentioned in the second to last paragraph on page 5, the optimization of DeepHoyer well behaves under SGD.	Reply	I-Reply	2
We do not observe any difficulties for training the DNN with DeepHoyer applied.	Reply	I-Reply	2
Hope this explanation can address your concern.	Reply	I-Reply	2

To solve the problem fo ‚Äúpreserving relative positions of nodes‚Äù, the paper applied the capsule network to the graph node embedding task and proposed the model named ‚ÄúCapsG‚Äù.	Review	O	0
The CapsG construct two capsule layers and utilize the dynamic routing between capsules to iteratively update the target node representation in a random walk.	Review	O	0
The experimental results on datasets with node features and without node features both seem promising.	Review	O	0
I think the idea of the model is interesting, but I have some concerns about the motivation and the soundness of the model.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
I am not convinced of the motivation of ‚Äúpreserving the relative positions of nodes‚Äù.	Review	B-Review	1
The authors claimed in the Introduction that the CNN has the problem of preserving the relative positions, and the problem of GCN based models are just because they used ‚Äúthe variant of CNNs‚Äù.	Review	I-Review	1
To me the GNNs, even the GCN based models have very different mechanisms from CNNs, this simple inference is not convincing at all.	Review	I-Review	1
I would like to see more detailed example or explanation about how GCNs encounter this problem.	Review	I-Review	1
In fact, many graph node embedding models, such as Deepwalk, node2vec or GAT seem not to have this problem to me.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
I enjoyed the section ‚ÄúComparing CapsG with related works‚Äù, but after reading that section I had a strong feeling that using capsule layers may not be necessary in this model, or at least not a very natural selection.	Review	B-Review	2
One question is about the definition of the capsule layers.	Review	I-Review	2
The approach used the capsule layers for each random walk, where the capsules in the first capsule layer are just single nodes.	Review	I-Review	2
It is essentially just an extension to the node aggregation mechanism by using multi-hop node information.	Review	I-Review	2
Another question is about ‚ÄúW_i‚Äù in Eq. (	Review	I-Review	2
1).	Review	I-Review	2
It is an important parameter which defines the transformation for each capsule.	Review	I-Review	2
And it is one of the major differences from other models such as GAT.	Review	I-Review	2
However, The index of capsules are randomly decided and different indices will result in different output vectors, which seems to conflict with the motivation of position invariance.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
For experiments, I think it is better to demonstrate the advantages by adding two results: the ablation model using the same ‚ÄúW_i‚Äù for different capsules in Eq. (	Review	B-Review	3
1); the running time of CapsG. As it samples a number of random walks for each node, and update target node representation in each random walk with many iterations, I am curious whether it slows down compared to other GNNs.	Review	I-Review	3
We would like to thank you so much for your useful comments.	Reply	O	0
We will get back you soon	Reply	O	0

This paper considers the problem of training mixed-precision models.	Review	O	0
[line_break_token]Since quantization involves non-differentiable operations, this paper discusses how to use the straight-through estimator to estimate the gradients,  and how different parameterizations of the quantized DNN affect the optimization process.	Review	O	0
The authors conclude that using the parameterization wrt the stepsize d and quantization range q_max has the best performance.	Review	O	0
[line_break_token][line_break_token]In the discussion for the three parameterization choices in section 2.1.	Review	B-Review	1
[line_break_token]It is not clear how the range for U2 is obtained.	Review	I-Review	1
Given d an integer, the gradient wrt b is also bounded.	Review	I-Review	2
In this case, why is case U3 better than U2?	Review	I-Review	2
In Table 1, it is shown that U2 also has good performance for uniform quantization.	Review	I-Review	2
[line_break_token][line_break_token]Indeed, the gradient of any of the three parameters (stepsize, bitwidth and quantization range) can be derived by using chain rule given the gradients of the other two.	Review	I-Review	3
It is not clear to me why some of them can be unbounded while others do not.	Review	I-Review	3
In addition, It is not clear to me why having different gradient scales is a big problem.	Review	I-Review	4
Adaptive learning rate methods like Adam should be able to help deal with the different scale of the gradients for three parameters.	Review	I-Review	4
Can the authors compare the three parameterizations using Adam and see if similar empirical results can still be observed.	Review	I-Review	4
[line_break_token][line_break_token]At the end of Section 2.1, the authors said that "similar considerations can be made for power-of-two quantization".	Review	I-Review	5
 However, from table 1, these three parameterizations indeed have quite different performances for uniform and power-of-two quantization.	Review	I-Review	5
 E.g., for uniform quantization, U2 and U3 perform significantly better than U1, while for power-of-two quantization, U1 and U3 perform significantly better than U2.	Review	I-Review	5
Can the authors elaborate more on the difference?	Review	I-Review	5
[line_break_token][line_break_token]Is the proposed differential quantization method used for both weight and activation?	Review	I-Review	6
If so, how are the gradients w.r.t.	Review	I-Review	6
the weights propagated through the quantized activations?	Review	I-Review	6
[line_break_token][line_break_token]---------- post-rebuttal comment -------------[line_break_token]I thank the authors for their detailed response.	Review	O	0
It has solved most of my concerns and I accordingly raised my score.	Review	O	0
[line_break_token]---------------------------------------------------------	Review	O	0
hank you very much for your time and comments ‚Äì please find below our point-to-point reply to each of them.	Reply	O	0
[line_break_token][line_break_token]"[...] in section 2.1.	Reply	O	0
It is not clear how the range for U2 is obtained."	Reply	O	0
[line_break_token][line_break_token]To obtain the range of U2, we can have a look at eq. (	Reply	B-Reply	1
3b).	Reply	I-Reply	1
First, the derivative with respect to is bounded as the magnitude of the gradient is always smaller than one.	Reply	I-Reply	1
For the derivative with respect to, we know that can be bounded by.	Reply	I-Reply	1
Furthermore, the ratio will be largest for and, hence, the  derivative is in where for U2 depends on and via.	Reply	I-Reply	1
We noticed that it is confusing that we use  in Eq. (	Reply	I-Reply	1
3b) and will replace it by in the final version of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]"Given d an integer, the gradient wrt b is also bounded.	Reply	O	0
In this case, why is case U3 better than U2?	Reply	O	0
In Table 1, it is shown that U2 also has good performance for uniform quantization."	Reply	O	0
[line_break_token][line_break_token]Please note that the step size does not need to be an integer but (and it should be a pow2 for an efficient implementation).	Reply	B-Reply	2
As we have shown above, the gradient can grow arbitrarily large as is not bounded.	Reply	I-Reply	2
[line_break_token]However, since a large is mostly not desired, you are right that exploding gradients are very unlikely in case of parametrization U2.	Reply	I-Reply	2
U3 is superior to U2 mainly because the gradients with respect to and are decoupled for parametrization U3.	Reply	I-Reply	2
This means that the derivative wrt is zero if the derivative wrt is non-zero and vice versa (as you can observe in eq. (	Reply	I-Reply	2
3c)).	Reply	I-Reply	2
Such a decoupling of the gradients is desirable for gradient-based optimization as we always optimize along conjugate directions, which is very effective.	Reply	I-Reply	2
[line_break_token][line_break_token]"Indeed, the gradient of any of the three parameters [...] can be derived by using chain rule given the gradients of the other two.	Reply	O	0
It is not clear to me why some of them can be unbounded while others do not."	Reply	O	0
[line_break_token][line_break_token]As you you pointed out correctly, the derivatives of the three different parametrizations are related by the chain rule.	Reply	B-Reply	3
The fact that some parametrizations have unbounded gradients is caused by the non-linear relationship of the parameters, i.e.,.	Reply	I-Reply	3
When converting the gradient of one parametrization to another, we will have to multiply with derivatives of this function.	Reply	I-Reply	3
Note, that for example might grow arbitrarily large for small and.	Reply	I-Reply	3
[line_break_token][line_break_token]"Adaptive learning rate methods like Adam should be able to help deal with the different scale of the gradients for three parameters.	Reply	O	0
Can the authors compare the three parameterizations using Adam and see if similar empirical results can still be observed."	Reply	O	0
[line_break_token][line_break_token]We also thought of this in our experiments, but did not include the results because of the page limit.	Reply	B-Reply	4
In fact, our toy example in the appendix (e.g. page 12, Fig.	Reply	I-Reply	4
9) was run with the Adam optimizer.	Reply	I-Reply	4
The performance difference is still considerable although an optimizer with adaptive learning rate was used.	Reply	I-Reply	4
We will add this missing information to the appendix.	Reply	I-Reply	4
[line_break_token]The cause is mainly, that Adam needs the statistics of the gradients change smoothly over the parameter space to work well.	Reply	I-Reply	4
If this is not the case, the estimated first and second moments of the gradients will be too noisy.	Reply	I-Reply	4
[line_break_token]Please note, that it also is not a simple scaling issue of the gradients, which can be solved by estimating the gradient magnitude and by normalizing it out.	Reply	I-Reply	4
The gradient magnitude depends on the position in the quantization and weight parameter space, meaning that the gradient magnitude can explode for some parameter values (e.g. large for U1).	Reply	I-Reply	4
[line_break_token][line_break_token]"At the end of Section 2.1, the authors said that "similar considerations can be made for power-of-two quantization". [...]	Reply	O	0
Can the authors elaborate more on the difference?"	Reply	O	0
[line_break_token][line_break_token]We did not intend to say that both uniform and pow2 quantizations have equal performance if we choose the right parametrizations.	Reply	B-Reply	5
What we meant with ‚Äúsimilar considerations‚Äù is, that for pow2 quantization, there are also three different parametrizations from which we can choose and that the parametrization that does not involve the bitwidth directly is better suited for optimization.	Reply	I-Reply	5
Please note that the pow2 quantization scheme is much more restrictive as it constraints the weights to be pow2.	Reply	I-Reply	5
This results in general in networks with worse performance compared to uniform quantization.	Reply	I-Reply	5
[line_break_token][line_break_token]"Is the proposed differential quantization method used for both weight and activation?	Reply	O	0
If so, how are the gradients w.r.t.	Reply	O	0
the weights propagated through the quantized activations?"	Reply	O	0
[line_break_token][line_break_token]Our method can be used to quantize both weights and activations.	Reply	B-Reply	6
As we stated in Sec.	Reply	I-Reply	6
3 and 4, we used both activation and weight quantization in all of our experiments.	Reply	I-Reply	6
[line_break_token][line_break_token]We hope that we have answered all your concerns, we are welcoming any further discussion	Reply	O	0

[line_break_token]Summary:[line_break_token][line_break_token]In this paper, the authors propose a new method to alleviate the effect of meta over-fitting.	Review	O	0
The designed method is based on the information-theoretic meta-regularization objective.	Review	O	0
Experiments demonstrate the effectiveness of the proposed model.	Review	O	0
[line_break_token][line_break_token]Strong Points:[line_break_token][line_break_token]+ The authors aim to alleviate the effect of meta over-fitting.	Review	O	0
In this paper, they mainly focus on alleviating the effect of brute-force memorization in the meta-training process.	Review	O	0
The problem is important in the meta-learning field.	Review	O	0
[line_break_token][line_break_token]+ The motivation for this paper is clear.	Review	O	0
The authors try to maximize the mutual information between x*, \theta and \bar{y}^*, D. [line_break_token][line_break_token]+ Experiments on both sinusoid regression, pose regression and image classification show that MR-MAML outperforms MAML and MR-CNP outperforms CNP.	Review	O	0
[line_break_token][line_break_token]Weak Points:[line_break_token][line_break_token]- My first concern is about the novelty of the proposed model.	Review	O	0
The framework and the derivations are straightforward.	Review	B-Review	1
I think the problem is very important, however, the technical contribution may not enough to be accepted.	Review	I-Review	1
It is better for the authors to clarify their contributions.	Review	I-Review	1
[line_break_token][line_break_token]- It will be more helpful if the authors can describe the algorithm of the meta-testing process in Appendix A.1.	Review	O	0
In the meta-testing process, do we need to sample \theta from q(\theta|\tau)?	Review	B-Review	2
If so, is the accuracy calculated by the averaged value of tasks with sampled weight?	Review	I-Review	2
[line_break_token][line_break_token]- I am a little curious about the results in Table 5.	Review	O	0
The results of MAML and TAML is quite high.	Review	B-Review	3
It would be better if the authors explain more.	Review	I-Review	3
[line_break_token][line_break_token]After rebuttal[line_break_token]I think the authors' response and the revised paper address most of my concerns.	Review	O	0
I raise my score to 6.	Review	O	0
hanks for your acknowledgement on the significance of the memorization problem and the effectiveness of our method.	Reply	O	0
 We believe that our response addresses each of the major weak points raised in the review -- we would appreciate it if you could let us know whether you have any remaining reservations, or if all of your concerns have been addressed.	Reply	O	0
[line_break_token][line_break_token]Q1) First concern is about the novelty of the proposed model. [...]	Reply	O	0
It is better for the authors to clarify their contributions.	Reply	O	0
[line_break_token][line_break_token]A1: Our primary contributions and novelties are:[line_break_token][line_break_token]i) We are the first to identify and formalize the memorization problem in meta-learning, a previously unappreciated issue.	Reply	O	0
We find that its main cause is the non-mutually-exclusive task distribution.	Reply	B-Reply	1
 Furthermore, as the reviewer notes, we demonstrate that it exists in multiple meta-learning algorithms and can significantly deteriorate performance.	Reply	I-Reply	1
Hence, we believe the identification and formalization of this problem to be a significant contribution.	Reply	I-Reply	1
[line_break_token][line_break_token]ii) We propose an effective and principled regularization approach, and it is not a trivial application of existing ideas.	Reply	O	0
Firstly, as revealed in Table 2 and 3, vanilla regularization on all the model parameters does not solve the memorization problem.	Reply	B-Reply	1
Knowing what parameters to be regularized is important for the meta-regularizer to be effective and the theory matters.	Reply	I-Reply	1
Secondly, we identify that regularization on activations can fail to prevent the memorization problem and hypothesize why.	Reply	I-Reply	1
This indicates that seemingly reasonable alternatives are insufficient.	Reply	I-Reply	1
Finally, we consider the simplicity of our approach an advantage because it is then compatible with multiple meta-learning algorithms and easy to implement in practice.	Reply	I-Reply	1
[line_break_token][line_break_token]iii) We designed and constructed a novel non-mutually-exclusive pose regression dataset which can serve as a benchmark for future algorithms.	Reply	O	0
[line_break_token][line_break_token]In sum, the problem we identified and studied, the methods we proposed and the pose dataset we created are all novel.	Reply	B-Reply	1
We believe this paper can bring awareness of the memorization problem when developing new meta-learning methodologies or applications.	Reply	I-Reply	1
Moreover, the datasets and experiments we developed can provide a benchmark for further study of the memorization problem in meta-learning.	Reply	I-Reply	1

This paper presents a domain adaptation algorithm based on the self-ensembling method proposed by [Tarvainen & Valpola, 2017]. The main idea is to enforce the agreement between the predictions of the teacher and the student classifiers on the target domain samples while training the student to perform well on the source domain.	Review	O	0
The teacher network is simply an exponential moving average of different versions of the student network over time.	Review	O	0
  [line_break_token][line_break_token]Pros:[line_break_token]+ The paper is well-written and easy to read[line_break_token]+ The proposed method is a natural extension of the mean teacher semi-supervised learning model by [Tarvainen & Valpola, 2017][line_break_token]+ The model achieves state-of-the-art results on a range of visual domain adaptation benchmarks (including top performance in the VisDA17 challenge)[line_break_token][line_break_token]Cons:[line_break_token]- The model is tailored to the image domain as it makes heavy use of the data augmentation.	Review	O	0
That restricts its applicability quite significantly.	Review	B-Review	1
I‚Äôm also very interested to know how the proposed method works when no augmentation is employed (for fair comparison with some of the entries in Table 1).	Review	I-Review	1
[line_break_token]- I‚Äôm not particularly fond of the engineering tricks like confidence thresholding and the class balance loss.	Review	O	0
They seem to be essential for good performance and thus, in my opinion, reduce the value of the main idea.	Review	B-Review	2
[line_break_token]- Related to the previous point, the final VisDA17 model seems to be engineered too heavily to work well on a particular dataset.	Review	O	0
I‚Äôm not sure if it provides many interesting insights for the scientific community at large.	Review	B-Review	3
[line_break_token][line_break_token]In my opinion, it‚Äôs a borderline paper.	Review	O	0
While the best reported quantitative results are quite good, it seems that achieving those requires a significant engineering effort beyond just applying the self-ensembling idea.	Review	O	0
[line_break_token][line_break_token]Notes:[line_break_token]* The paper somewhat breaks the anonymity of the authors by mentioning the ‚Äúwinning entry in the VISDA-2017‚Äù.	Review	O	0
Maybe it‚Äôs not a big issue but in my opinion it‚Äôs better to remove references to the competition entry.	Review	B-Review	4
[line_break_token]* Page 2, 2.1, line 2, typo: ‚Äústanrdard‚Äù -> ‚Äústandard‚Äù[line_break_token][line_break_token]Post-rebuttal revision:[line_break_token]After reading the authors' response to my review, I decided to increase the score by 2 points.	Review	O	0
I appreciate the improvements that were made to the paper but still feel that this work a bit too engineering-heavy, and the title does not fully reflect what's going on in the full pipeline.	Review	O	0
Thank you for your review[line_break_token][line_break_token]* We agree that our work is tailored to the image domain.	Reply	O	0
With a view to addressing your concerns, we have run further experiments to quantify the effects of each part of our approach - including data augmentation - for all of the small image benchmarks.	Reply	B-Reply	1
We have therefore removed Table 2 as the information that it presented can be more compactly shown in Table 1, alongside everything else.	Reply	I-Reply	1
We have added further discussion of the effect of our affine augmentation to section 3.3 and demonstrated its effect on both domain adaptation and plain supervised experiments.	Reply	I-Reply	1
What we currently have is the same augmentation scheme used by Lain et al.	Reply	I-Reply	1
and Tarvainen at al, which consists of translations (all) and horizontal flips (CIFAR/STL only).	Reply	I-Reply	1
Experiments with minimal augmentation (gaussian noise added to the input only, therefore usable outside the image domain) are currently running; we will add them if the experiments complete on time.	Reply	I-Reply	1
[line_break_token][line_break_token]Furthermore, we found that our model performs slightly better on the MNIST <-> SVHN experiments when using RGB images rather than greyscale, so we have replaced our greyscale results with RGB ones.	Reply	O	0
This represents a slightly bigger domain jump, so we hope that this increases your confidence in our work.	Reply	B-Reply	1
[line_break_token][line_break_token]* We see what you mean concerning engineering tricks.	Reply	O	0
In defence of confidence thresholding, rather than being a new additional trick it replaces a time-dependent ramp-up curve used by Laine et al.	Reply	B-Reply	2
in their work.	Reply	I-Reply	2
We have made this a little more explicit in section 3.3.	Reply	I-Reply	2
As for class balancing loss, it is similar in purpose and implementation to the entropy maximisation loss used in the IMSAT model of Hu et al. (	Reply	I-Reply	2
an unsupervised clustering model that also uses data augmentation).	Reply	I-Reply	2
We have mentioned this in section 3.4.	Reply	I-Reply	2
We did not cite this paper in our original version as we were unaware of it at the time.	Reply	I-Reply	2
[line_break_token][line_break_token]* We have run further VisDA experiments.	Reply	O	0
We found that pairing back our augmentation scheme improved performance on the validation set and made little different on the test set.	Reply	B-Reply	3
Our original complex augmentation scheme was tested on a very small subset (1280 samples) of the training and validation sets during the development of our model.	Reply	I-Reply	3
It turns out that these results did not generalise to the full set, so lesson learned (we were facing a tight competition deadline too).	Reply	I-Reply	3
Our new reduced augmentation scheme consists of random crops, random horizontal flips and random uniform scaling, thus bringing it in line with augmentation schemes commonly used in ImageNet networks, such as He et al.	Reply	I-Reply	3
's ResNets.	Reply	I-Reply	3
We have also performed 5 independent runs of each of our newer experiments and given a breakdown of the results	Reply	I-Reply	3

**Paper Summary**[line_break_token]    This paper proposes a self-supervised method, RotNet, to learn effective image feature from images by predicting the rotation, discretized into 4 rotations of 0, 90, 180, and 270 degrees.	Review	O	0
The authors claim that this task is intuitive because a model must learn to recognize and detect relevant parts of an image (object orientation, object class) in order to determine how much an image has been rotated.	Review	O	0
[line_break_token]They visualize attention maps from the first few conv layers and claim that the attend to parts of the image like faces or eyes or mouths.	Review	O	0
They also visualize filters from the first convolutional layer and show that these learned filters are more diverse than those from training the same model in a supervised manner.	Review	O	0
[line_break_token][tab_token]They train RotNet to learn features of CIFAR-10 and then train, in a supervised manner, additional layers that use RotNet feature maps to perform object classification.	Review	O	0
They achieve 91.16% accuracy, outperforming other unsupervised feature learning methods.	Review	O	0
They also show that in a semi-supervised setting where only a small number of images of each category is available at training time, their method outperforms a supervised method.	Review	O	0
[line_break_token][tab_token]They next train RotNet on ImageNet and use the learned features for image classification on ImageNet and PASCAL VOC 2007 as well as object detection on PASCAL VOC 2007.	Review	O	0
They achieve an ImageNet and PASCAL classification score as well as an object detection score higher than other baseline methods.	Review	O	0
[line_break_token]    This task requires the ability to understand the types, the locations, and the poses of the objects presented in images and therefore provides a powerful surrogate supervision signal for representation learning.	Review	O	0
To demonstrate the effectiveness of the proposed method, the authors evaluate it under a variety of tasks with different settings.	Review	O	0
[line_break_token]    [line_break_token]    [line_break_token][line_break_token]**Paper Strengths**[line_break_token]- The motivation of this work is well-written.	Review	O	0
[line_break_token]- The proposed self-supervised task is simple and intuitive.	Review	O	0
This simple idea of using image rotation to learn features, easy to implement image rotations without any artifacts[line_break_token]- Requiring no scale and aspect ratio image transformations, the proposed self-supervised task does not introduce any low-level visual artifacts that will lead the CNN to learn trivial features with no practical value for the visual perception tasks.	Review	O	0
[line_break_token]- Training the proposed model requires the same computational cost as supervised learning which is much faster than training image reconstruction based representation learning frameworks.	Review	O	0
[line_break_token]- The experiments show that this representation learning task can improve the performance when only a small amount of annotated examples is available  (the semi-supervised settings).	Review	O	0
[line_break_token]- The implementation details are included, including the way of implementing image rotations, different network architectures evaluated on different datasets, optimizers, learning rates with weight decayed, batch sizes, numbers of training epochs, etc.	Review	O	0
[line_break_token]- Outperforms all baselines and achieves performance close to, but still below, fully supervised methods[line_break_token]- Plots rotation prediction accuracy and object recognition accuracy over time and shows that they are correlated[line_break_token][line_break_token][line_break_token][line_break_token]**Paper Weaknesses**[line_break_token]- The proposed method considers a set of different geometric transformations as discrete and independent classes and formulates the task as a classification task.	Review	O	0
However, the inherent relationships among geometric transformations are ignored.	Review	B-Review	6
For example, rotating an image 90 degrees and rotating an image 180 degrees should be closer compared to rotating an image 90 degrees and rotating an image 270 degrees.	Review	I-Review	6
[line_break_token]- The evaluation of low-level perception vision task is missing.	Review	O	0
In particular, evaluating the learned representations on the task of image semantic segmentation is essential in my opinion.	Review	B-Review	7
Since we are interested in assigning the label of an object class to each pixel in the image for the task, the ability to encode semantic image feature by learning from performing the self-supervised task can be demonstrated.	Review	I-Review	7
[line_break_token]- The figure presenting the visualization of the first layer filters is not clear to understand nor representative of any finding.	Review	O	0
[line_break_token]- ImageNet Top-1 classification results produced by Split-Brain (Zhang et al.,	Review	O	0
2016b) and Counting (Noroozi et al.,	Review	B-Review	9
2017) are missing which are shown to be effective in the paper [Representation Learning by Learning to Count](<a href="https://arxiv.org/abs/1708.06734)."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1708.06734).</a>[line_break_token]- An in-depth analysis of the correlation between the rotation prediction accuracy and the object recognition accuracy is missing.	Review	O	0
Showing both the accuracies are improved over time is not informative.	Review	B-Review	10
[line_break_token]- Not fully convinced on the intuition, some objects may not have a clear direction of what should be ‚Äúup‚Äù or ‚Äúdown‚Äù (symmetric objects like balls), in Figure 2, rotated image X^3 could plausibly be believed as 0 rotation as well, do the failure cases of rotation relate to misclassified images?	Review	O	0
[line_break_token]- ‚Äúremarkably good performance‚Äù, ‚Äúextremely good performance‚Äù ‚Äì vague language choices (abstract, conclusion)[line_break_token]- Per class breakdown on CIFAR 10 and/or PASCAL would help understand what exactly is being learned[line_break_token]- In Figure 3, it would be better to show attention maps on rotated images as well as activations from other unsupervised learning methods.	Review	O	0
With this figure, it is hard to tell whether the proposed model effectively focuses on high level objects.	Review	B-Review	3
[line_break_token]- In Figure 4, patterns of the convolutional filters are not clear.	Review	O	0
It would be better to make the figures clear by using grayscale images and adjusting contrast.	Review	B-Review	11
[line_break_token]- In Equation 2, the objective should be maximizing the sum of losses or minimizing the negative.	Review	O	0
Also, in Equation 3, the summation should be computed over y = 1 ~ K, not i = 1 ~ N.[line_break_token][line_break_token][line_break_token][line_break_token]**Preliminary Evaluation**[line_break_token]This paper proposes a self-supervised task which allows a CNN to learn meaningful visual representations without requiring supervision signal.	Review	O	0
In particular, it proposes to train a CNN to recognize the rotation applied to an image, which requires the understanding the types, the locations, and the poses of the objects presented in images.	Review	O	0
The experiments demonstrate that the learned representations are meaningful and transferable to other vision tasks including object recognition and object detection.	Review	O	0
Strong quantitative results outperforming unsupervised representation learning methods, but lacking qualitative results to confirm/interpret the effectiveness of the proposed method.	Review	B-Review	12
This is the 3rd part of the answer to the reviewer's comments.	Reply	O	0
[line_break_token][line_break_token]Comment:[line_break_token]"Not fully convinced on the intuition, some objects may not have a clear direction of what should be ‚Äúup‚Äù or ‚Äúdown‚Äù (symmetric objects like balls), in Figure 2, rotated image X^3 could plausibly be believed as 0 rotation as well, do the failure cases of rotation relate to misclassified images?"	Reply	O	0
[line_break_token][line_break_token]Answer:[line_break_token]Regarding the fact that some images might have ambiguous orientation, we note that this type of training examples comprise only a small part of the dataset and can essentially be seen as a small amount of label noise, which thus poses no problem for learning.	Reply	O	0
On the contrary, the great majority of the used images have an unambiguous orientation.	Reply	B-Reply	5
Therefore, the ConvNet, by trying to solve the rotation prediction task, will eventually be forced to learn object-specific features.	Reply	I-Reply	5
This is also evidenced by the very strong experimental performance of these features when applied on a variety of different tasks including those of object recognition, object detection, object segmentation, and scene classification tasks (section 3 of the paper).	Reply	I-Reply	5
[line_break_token][line_break_token]Concerning the question posed by the reviewer if there is any connection between failure cases for rotation prediction and misclassifications w.r.t.	Reply	I-Reply	6
object recognition, we did the following test in order to explore if there is any such correlation: first, we define as y0 a binary variable that indicates if an image is misclassified in the object recognition task by a fully supervised model, as y1 a binary variable that indicates if an image is misclassified in the object recognition task by our unsupervised learned RotNet model (by training a non-linear classifier on top of the RotNet features), and as x a continuous variable that indicates the fraction of rotations (out of the 4 possible ones per image) that are misclassified by RotNet.	Reply	I-Reply	6
The point biserial correlation coefficient (<a href="https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pointbiserialr.html)" target="_blank" rel="nofollow">https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pointbiserialr.html)</a> between the y1 and x variables on CIFAR-10 is 0.1473 with p-value 1.286e-49 while between the y0 and x variables is 0.1799 with p-value=1.5404e-73.	Reply	O	0
Therefore, it seems that there is little correlation between failing to classify the rotations of an image and failing to classify the object that it depicts.	Reply	B-Reply	6
Moreover, this holds regardless if we use a fully supervised object classifier (0.1799 correlation) or if we use an object classifier based on features learnt on the rotation prediction task.	Reply	I-Reply	6
[line_break_token][line_break_token]------[line_break_token][line_break_token]Comment:[line_break_token]" ‚Äúremarkably good performance‚Äù, ‚Äúextremely good performance‚Äù ‚Äì vague language choices (abstract, conclusion) "[line_break_token][line_break_token]Answer:[line_break_token]We rephrased the corresponding text to make it even more clear that the above statements relate to the state-of-the-art experimental results achieved by our method, which surpass prior approaches by a significant margin.	Reply	O	0
[line_break_token][line_break_token]------[line_break_token][line_break_token]Comment:[line_break_token]"Per class breakdown on CIFAR 10 and/or PASCAL would help understand what exactly is being learned"[line_break_token][line_break_token]Answer:[line_break_token]We added such results in Tables 8 and 9 (in appendix B) of the revised version of the paper.	Reply	O	0
[line_break_token][line_break_token]------[line_break_token][line_break_token]Comment:[line_break_token]"In Figure 3, it would be better to show attention maps on rotated images as well as activations from other unsupervised learning methods.	Reply	O	0
With this figure, it is hard to tell whether the proposed model effectively focuses on high level objects."	Reply	O	0
[line_break_token][line_break_token]Answer:[line_break_token]In the revised version of the paper in Figure 3 we added attention maps generated by a supervised model.	Reply	O	0
By comparing them with those of our unsupervised model we observe that both of them focus on similar areas of the image in order to accomplish their task.	Reply	B-Reply	3
Also, in Figure 6 (in appendix A), we added the attention maps of the rotated versions of the images.	Reply	I-Reply	3
We observe that the attention maps of all the rotated images is roughly the same which means the attention maps are equivariant w.r.t.	Reply	I-Reply	3
image rotations.	Reply	I-Reply	3
This practically means that in order to accomplish the rotation prediction task the network focuses on the same object parts regardless of the image rotation.	Reply	I-Reply	3
[line_break_token][line_break_token]------[line_break_token][line_break_token]Comment:[line_break_token]"In Equation 2, the objective should be maximizing the sum of losses or minimizing the negative.	Reply	O	0
Also, in Equation 3, the summation should be computed over y = 1 ~ K, not i = 1 ~ N."[line_break_token][line_break_token]Answer:[line_break_token]We thank the reviewer for identifying the above typos.	Reply	O	0
We fixed them in the revised version of the paper (see equation 3).	Reply	B-Reply	4
[line_break_token][line_break_token]-----	Reply	O	0

This paper studies the phenomenon of incremental learning in several deep models.	Review	O	0
It starts with analyzing the optimization dynamics of a toy model, and showing that it follows incremental learning, a notion defined clearly in the paper.	Review	O	0
In particular, it shows that depth affects the strength of incremental learning in the sense that when the depth of the model is increased (especially when going from N=2 to N=3), the maximal initialization value with which incremental learning can occur is increased.	Review	O	0
In this sense, deeper models experience incremental learning more easily.	Review	O	0
The paper then moves on to other ‚Äúdeep linear‚Äú models, including matrix sensing, one-hidden-layer quadratic neural networks and diagonal/convolutional linear neural networks, derives ODEs for the evolution of the singular values in the learned models, which is argued to also lead to incremental learning.	Review	O	0
[line_break_token][line_break_token]I would recommend a ‚Äúweak accept‚Äù for this paper.	Review	O	0
The nice contributions include a clear definition of incremental learning, results showing the depth‚Äôs effect on incremental learning as well as extensions to several other models.	Review	O	0
My main question is regarding the relevance of the toy model to more realistic models, as I will discuss below, and I‚Äôd love to hear more about the authors‚Äô thoughts on this.	Review	B-Review	4
[line_break_token][line_break_token]Besides being linear, another important simplification of the toy model is that there is no interaction among the hidden units, which is rather crucial for ordinary neural networks.	Review	I-Review	1
I am curious to what extent the authors think this simplification matters for incremental learning.	Review	I-Review	1
It‚Äôs nice that similar analysis can be extended to other settings including matrix sensing, quadratic NNs and linear diagonal/convolutional NNs.	Review	I-Review	1
But it seems that there is no theorem analogous to theorems 2 and 3 for those models, and I am curious why.	Review	I-Review	1
[line_break_token][line_break_token]The qualitative transition from N=2 to N=3 in the toy model is interesting.	Review	I-Review	2
Is there a more intuitive explanation for it?	Review	I-Review	2
Also, from Figure 2, it seems hard to say whether there really is a qualitative change between N=2 and N=3.	Review	I-Review	2
[line_break_token][line_break_token]Some other suggestions for improvement:[line_break_token]1.	Review	I-Review	3
It may be helpful to somehow visualize the bounds obtained in theorems 2 and 3.	Review	I-Review	3
[line_break_token]2.	Review	I-Review	3
Some typos: [line_break_token]1) ‚Äúit‚Äôs‚Äù should be ‚Äúits‚Äù in the last paragraph of section 2.	Review	I-Review	3
[line_break_token]2) ‚Äùeffect‚Äù should be ‚Äúaffect‚Äù in the first paragraph of section 3.	Review	I-Review	3
hank you for your thoughtful review.	Reply	O	0
We will try to answer any open questions:[line_break_token][line_break_token]Regarding your comments about the interaction of the layers in realistic models and lack thereof in our toy model, you touch on an interesting open question.	Reply	O	0
[line_break_token]First, we would like to clarify that even when interaction does occur between hidden neurons, there can be theoretical results like our theorem 2 and 3 - the deep matrix sensing model we analyze parameterizes the matrix as a product of N matrices, and these N matrices interact similarly to "regular" deep linear networks.	Reply	B-Reply	1
While perhaps not stated clearly enough, our theorem 4 shows that under the right conditions, the singular values of the matrix sensing model have the same dynamics as our toy model, and this means that under these conditions theorems 2 and 3 apply for matrix sensing.	Reply	I-Reply	1
The same goes for quadratic networks (although the conditions are admittedly not as natural).	Reply	I-Reply	1
Also, when we look at the original work of Saxe et al. [	Reply	I-Reply	1
1], we see derivations of very similar dynamical equations for the singular values of deep linear networks under the squared loss - slight adaptations to our analysis would lead to an incremental learning result for this model as well.	Reply	I-Reply	1
[line_break_token]However, things are not as simple as one would hope - if we look at classification tasks (with exponential-tailed losses), we see that the interaction between layers has a different effect.	Reply	I-Reply	1
In [2], we see that deep linear networks trained on separable data converge to the max-margin solution regardless of the depth of the network, while when there is no interaction between the layers (diagonal/convolutional models), deeper models tend towards sparser solutions (which we claim is caused by a form incremental learning dynamics, but only show empirical evidence of this).	Reply	I-Reply	1
[line_break_token]It seems that there is more to incremental learning than the depth and initialization of the model - the loss function and exact parameterization play a role.	Reply	I-Reply	1
The interactions between the parameterization and depth of the model, the initialization and the loss function are non-trivial and an interesting research direction.	Reply	I-Reply	1
[line_break_token][line_break_token]As for the strong difference between depth-2 and depth-3 models, we're afraid we can't really offer an intuitive explanation.	Reply	I-Reply	2
When looking at figure 2, the qualitative difference that we were referring to is when comparing different initializations.	Reply	I-Reply	2
The top row ) has both depths not really exhibiting incremental learning, but once we decreases the initialization in the second row ), we see the difference - the depth-2 model hardly changes its dynamics (still no strong incremental learning) while the depth-3 model exhibits very strong incremental learning dynamics.	Reply	I-Reply	2
[line_break_token][line_break_token][1] - Andrew M Saxe, James L McClelland, and Surya Ganguli.	Reply	O	0
Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.	Reply	O	0
ICLR, 2014.	Reply	O	0
[line_break_token][2] - Suriya Gunasekar, Jason D Lee, Daniel Soudry, and Nati Srebro.	Reply	O	0
Implicit bias of gradient descent on linear convolutional networks.	Reply	O	0
In Advances in Neural Information Processing Systems, pp.	Reply	O	0
9461‚Äì9471, 201	Reply	O	0

This paper tests various pretraining objectives (language modeling, machine translation, skip-thought, and autoencoding) on two syntactic tasks: POS tagging and CCG tagging.	Review	O	0
It finds that language modeling outperforms the other pretraining objectives; additionally, randomly-initializing an encoder achieves decent performance when given a large amount of labeled data for the tagging task.	Review	O	0
The experiments in this paper are very thorough and explained well.	Review	O	0
By controlling for pretraining data size, the authors are able to reasonably claim that language modeling is superior to translation as a syntactic transfer learning task.	Review	O	0
On the other hand, I have some concerns regarding the significance of the paper's contributions, and as such I am borderline on its acceptance.	Review	B-Review	1
[line_break_token][line_break_token]comments:[line_break_token]- the experiments in the paper feel biased towards language modeling.	Review	O	0
Language modeling is the only token-level prediction task of the four objectives here, but both of the two downstream tasks are at the token level.	Review	B-Review	2
It is perhaps unsurprising then that language modeling performs best; perhaps the authors could have considered some sentence-level downstream tasks as well to properly control for this?	Review	I-Review	2
Or added some more word-level pretraining objectives?	Review	I-Review	2
[line_break_token][line_break_token]- sort of relatedly, the authors do not provide any explanations as to *why* language modeling is a better pretraining objective than translation.	Review	O	0
What kinds of examples do the tagging models using LM pretraining get right that the translation models do not?	Review	B-Review	3
Such an analysis could help provide more concrete insights into what kind of information each objective is encoding.	Review	I-Review	3
[line_break_token][line_break_token]- the claim that LMs > translation is not a new finding.	Review	O	0
The authors cite Blevins et al, who find the same result on the task of dependency arc prediction.	Review	B-Review	4
Similarly, the surprisingly good performance of random encoders was also found in Conneau et al.,	Review	I-Review	4
ACL 2018.	Review	I-Review	4
As the main contribution of this paper seems to be a more controlled study of Blevins et al on different syntactic tasks, I don't think there is enough here for an ICLR submission.	Review	I-Review	4
[line_break_token][line_break_token]- what is the effect of the specific dataset and architecture on the results?	Review	O	0
Here we just look at a couple translation datasets (all news data) and LSTM models.	Review	B-Review	5
Do things change when we move to transformers or more diverse domains?	Review	I-Review	5
- All the tasks use the same training data.	Reply	O	0
The data each model is trained on was pre-processed in the same way, word-level tokenization.	Reply	B-Reply	5
All the training objectives we compare all have the same loss: average negative log likelihood of the target sequenc	Reply	I-Reply	5

This paper shows (theorem 1) that data augmentation (DA) induces a reduction of rugsity on the loss function associated to the model.	Review	O	0
Here rugosity is defined as a measure of the curvature (2nd order) of the function.	Review	O	0
However, the two concepts seems to be different because the authors empirically show that directly reducing the rugosity of a network does not improve generalization (in contrast to DA).	Review	O	0
[line_break_token][line_break_token]I lean to reject this paper because the contributions, even if interesting, do not lead to any new understanding of the topic.	Review	O	0
More in detail, data augmentation improves the generalization on deep learning models.	Review	B-Review	2
This paper shows that DA induces rugosity (theorem 1), but rugosity does not improve generalization (empirically).	Review	I-Review	2
Thus, rugosity is not responsible for generalization, which is the interesting property that we care about.	Review	I-Review	2
[line_break_token][line_break_token]The paper is well written and easy to follow, however I found the actual contribution limited because:[line_break_token]- The definition of rugosity is an extension of (Donoho &amp; Grimes (2003)) in which the extension is not really improving anything or used anywhere in the paper.	Review	O	0
[line_break_token]- The Hessian-based rugosity analysis of DA is correct, but it does not help to understand the generalization performance or any other useful property of DA.	Review	O	0
[line_break_token] [line_break_token]Additional Comments:[line_break_token]- In 3.4 second paragraph the authors suggest that reducing rugosity can improve generalization as DA, but later we see that this is not the case.	Review	O	0
[line_break_token]- The entire paper seems written with the idea of using rugosity as a surrogate of DA, but at the end it does not work[line_break_token]	Review	O	0
e thank the reviewer for positive comments and useful suggestions.	Reply	O	0
We provide the following responses for the comments.	Reply	O	0
[line_break_token][line_break_token]1&gt; The definition of rugosity is an extension of (Donoho &amp; Grimes (2003)) in which the extension is not really improving anything or used anywhere in the paper.	Reply	O	0
[line_break_token][line_break_token]The rugosity measure that we defined and used is in fact inspired by the tangent Hessian measure proposed by (Donoho &amp; Grimes (2003)).	Reply	O	0
We have modified the tangent Hessian integral measure provided in this paper to make it suitable to use for piecewise linear functions and for making it easier to compute.	Reply	B-Reply	1
We believe that this measure can provide useful information about the landscape and complexity of the prediction function generated by the deep network.	Reply	I-Reply	1
[line_break_token][line_break_token]2&gt; Data augmentation improves the generalization on deep learning models.	Reply	O	0
This paper shows that DA induces rugosity (theorem 1), but rugosity does not improve generalization (empirically).	Reply	O	0
Thus, rugosity is not responsible for generalization, which is the interesting property that we care about.	Reply	O	0
The Hessian-based rugosity analysis of DA is correct, but it does not help to understand the generalization performance or any other useful property of DA.	Reply	O	0
[line_break_token][line_break_token]We agree that our empirical results do not show significant classification performance improvement as a result of using rugosity as explicit regularization.	Reply	B-Reply	2
However, the effect of data augmentation on rugosity (and also generalization) is a significant observation and points to the question of what other properties data augmentation possesses that lead to improve generalization.	Reply	I-Reply	2
We believe that this is an important question that requires a more thorough and comprehensive understanding of regularization in the overparameterized (interpolating) regime.	Reply	I-Reply	2
What our results suggest is that, although there is a close connection between rugosity and data augmentation, rugosity (or smoothness) cannot by itself explain the entire effect of data augmentation on generalization.	Reply	I-Reply	2
[line_break_token][line_break_token]In addition, understanding generalization is not the primary goal of our paper.	Reply	I-Reply	2
We believe that our rugosity measure can be a very useful data-driven measure for understanding the prediction function generated by a deep network.	Reply	I-Reply	2
One of our applications was understanding data augmentation, which we illustrated through theoretical and empirical analysis.	Reply	I-Reply	2
We showed the close connection between data augmentation and rugosity which suggests that rugosity can be a more effective complexity measure than other common complexity measures, e.g., the Jacobian.	Reply	I-Reply	2
Further, there can be many other properties of deep networks, such as adversarial robustness, that rugosity can help us to better understand and improve.	Reply	I-Reply	2
We believe that our work is only the first step in this direction.	Reply	I-Reply	2
[line_break_token][line_break_token]3&gt; In 3.4 second paragraph the authors suggest that reducing rugosity can improve generalization as DA, but later we see that this is not the case.	Reply	O	0
[line_break_token][line_break_token]The effect of rugosity as explicit regularization on improving generalization is what can be initially expected from Theorem 1 and the empirical results showing the connection between data augmentation and rugosity.	Reply	B-Reply	3
However, surprisingly, this is not what we observed in our further experiments.	Reply	I-Reply	3
This suggests that understanding generalization requires a more comprehensive understanding of properties (other than just the rugosity or smoothness) of the function generated by a deep network.	Reply	I-Reply	3
[line_break_token][line_break_token]4&gt; The entire paper seems written with the idea of using rugosity as a surrogate of DA, but at the end it does not work.	Reply	O	0
[line_break_token][line_break_token]We do not suggest to use rugosity as a surrogate for data augmentation.	Reply	B-Reply	4
Rather, we propose rugosity as a useful, data-driven measure for studying a deep network and the complexity of the prediction function it produces.	Reply	I-Reply	4
While we showed that rugosity has a close connection to data augmentation, our experiments show also that rugosity, by itself, cannot completely explain the generalization properties of deep nets or data augmentation.	Reply	I-Reply	4

This paper investigates residual networks (ResNets) in an empirical way.	Review	O	0
The authors argue that shallow layers are responsible for learning important feature representations, while deeper layers focus on refining the features.	Review	O	0
They validate this point by performing a series of lesion study on ResNet.	Review	O	0
[line_break_token][line_break_token]Overall, the experiments and discussions in the first part of Section 4.2 and 4.3 appears to be interesting, while other observations are not quite surprising.	Review	O	0
I have two questions:[line_break_token]1)[tab_token]What is the different between the layer-dropping experiment in sec 4.2 and that in [Veit, et al, Residual networks are exponential ensembles of relatively shallow networks] ?	Review	B-Review	1
What is the main point here?	Review	I-Review	1
[line_break_token]2)[tab_token]I don't quite understand the first paragraph of sec 4.5.	Review	O	0
Could you elaborate more on this?	Review	B-Review	2
[line_break_token]	Review	O	0
We thank reviewer for his remarks, and positive assessment.	Reply	O	0
  [line_break_token][line_break_token]In his first point, reviewer asks what is difference between our 4.2 and Veit et al.	Reply	O	0
We cite Veit et al, and extend his observations.	Reply	B-Reply	1
Our novel observation is that blocks in residual network have different function, and only subset of blocks focus on iterative inference.	Reply	I-Reply	1
More specifically, some blocks have large l2 ratio (ratio of output to input norms for given block), and cannot be dropped without drastic effect on performance.	Reply	I-Reply	1
This allows us to specify concretely in what sense residual network performs iterative inference.	Reply	I-Reply	1
We made edits in text to clarify this.	Reply	I-Reply	1
[line_break_token][line_break_token]In his second point reviewer requests clarification on first paragraph of 4.5.	Reply	I-Reply	2
First paragraph of 4.5 reads: ‚ÄúGiven the iterative inference view, we now study the effects of sharing residual blocks.	Reply	I-Reply	2
Contrary to (Liao & Poggio, 2016) we observe that naively sharing the higher (iterative refinement) residual blocks of a Resnets in general leads to overfitting (especially for deeper Resnets).‚Äù.	Reply	O	0
First, we say that our results suggest that residual network perform iterative inference, and that top blocks are performing similar function (feature refinement), there it is plausible that top blocks in residual network should be shareable.	Reply	B-Reply	2
However, during this investigation, we report a surprising observation that has not been made before (Liao & Poggio tested relatively small ResNets) that when we share layers of residual network, it leads to drastic overfitting.	Reply	O	0
In Fig.8 we compare Resnet-110-shared and Resnet-32, where Resnet-110-shared has same number of parameters as Resnet-32.	Reply	B-Reply	2
We observe strong overfitting (train accuracy remains the same, while validation accuracy is much lower for Resnet110).	Reply	I-Reply	2
We made edits in text to clarify this first paragraph.	Reply	I-Reply	2

This paper proposes Ladder Polynomial Neural Networks (LPNNs) that use a new type of activation primitive -- a product activation -- in a feed-forward architecture.	Review	O	0
Unlike other polynomial architectures that grow in the order exponentially with network depth, the proposed approach gives explicit control over the order and smoothness of the network output and enables training with standard techniques.	Review	O	0
[tab_token][line_break_token][tab_token][tab_token][tab_token][tab_token][line_break_token]The proposed architecture is closely related to a decomposition of a k‚Äôth order multivariate polynomial function[line_break_token][T, x^{\otimes k}] = \lambda^\top (A x \odot A x \odot ‚Ä¶  \odot A x)[tab_token]=  \lambda^\top (A x)^{\odot k}[line_break_token]where T is a symmetric tensor of polynomial coefficients and [\cdot,\cdot] denotes contraction.	Review	O	0
This is a shallow (one layer architecture) and sometimes referred as a Waring decomposition.	Review	O	0
[line_break_token][line_break_token]In this paper, the authors propose a specific chain factorization of the polynomial (Eq 5 in the paper), where they write the factors recursively, that they name as a ladder polynomial neural network.	Review	O	0
[line_break_token][line_break_token]h^\ell = (W_\ell h^{\ell-1} \odot V^{\ell} x)[line_break_token][line_break_token]The ladder architecture is very closely related to tensor trains (<a href="https://epubs.siam.org/doi/10.1137/090752286)."	Review	O	0
target="_blank" rel="nofollow">https://epubs.siam.org/doi/10.1137/090752286).</a> I found it surprising and somewhat alarming that this literature is not being cited as these methods are also quite well known in deep learning.	Review	O	0
[line_break_token][line_break_token]I like the smoothness analysis of section 3.1 -- the proof is quite easy to follow and direct.	Review	B-Review	2
I would be quite surprised if this result would not be known in the literature in some other form but I don‚Äôt recall seeing it.	Review	I-Review	2
On the other hand it seems to be inevitably very loose for a deep ladder network unless the network models the zero function.	Review	I-Review	2
It would have been a valuable addition to the experimental section, if this bound would have been illustrated numerically on synthetic examples.	Review	I-Review	2
[line_break_token][line_break_token]In 3.2, The authors say that the objective is multiconvex -- I would argue that it is multilinear (apart from the regularization term, that is later introduces).	Review	I-Review	3
The observation in 3.3, that batch-normalization or dropout can be used for this model is perhaps tangential to the main argument.	Review	I-Review	4
These is investigated in the experimental section but I don‚Äôt see a clear conclusion.	Review	I-Review	4
The section in 3.4 must include links to tensor decompositions beyond factorization machines.	Review	I-Review	4
[line_break_token][tab_token][tab_token][line_break_token]Overall, I think the paper has some merit and could be interesting for some readers, despite the fact that the contribution is not very original and the treatment could be improved in many ways.	Review	O	0
[line_break_token]	Review	O	0
hank you for your insightful comments.	Reply	O	0
We address your concerns as follows.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Thank you for pointing the tensor train paper to us.	Reply	B-Reply	1
We have no intention to omit this citation.	Reply	I-Reply	1
We don't view or claim the chain factorization of LPNN as our main contribution.	Reply	I-Reply	1
Our first contribution is the new activation, the *product activation*. The factorization of LPNN is a consequence of this activation.	Reply	I-Reply	1
 Our second contribution is the connection between the feedforward architecture and the factorization.	Reply	I-Reply	1
We show the factorization in the paper to provide readers an understanding besides the understanding from the feedforward structure.	Reply	I-Reply	1
[line_break_token][line_break_token]Actually, the tensor train paper provides further support for our work.	Reply	I-Reply	1
With the method in our paper, we may have an activation that leads to a model corresponding to the tensor train, then we can learn such a model with standard training techniques (e.g. dropout and batch normalization).	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
smoothness proof: the bound is consistent with the bound in [1]. However, we need to do the proof again because the new activation does not meet the assumption in [1]. There are some advanced techniques in [1] to further tight the smoothness bound.	Reply	O	0
We will consider applying these techniques to our model.	Reply	B-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
multiconvex vs multilinear: yes, it is better to say the model is multilinear -- we will correct it.	Reply	O	0
[line_break_token][line_break_token]4.	Reply	O	0
batch normalization and dropout: we want to make a point that batch normalization and dropout are beneficial for training a polynomial model (equivalently the LPNN factorization).	Reply	O	0
The empirical investigation *does* show the performance improvement from dropout or batch normalization or both.	Reply	B-Reply	4
In Table 3 and Table 4, errors in the last column are generally larger than the errors in the first three columns.	Reply	I-Reply	4
Without batch normalization, the network sometimes does not converge (the large error rates at col 2 &amp; 4, row 4 of Table 4).	Reply	O	0
[line_break_token][line_break_token]5.	Reply	O	0
citation: yes, we will include the citation to the tensor train paper.	Reply	O	0
[line_break_token][line_break_token]Finally, we hope our explanations clarify some of your concerns.	Reply	O	0
We would like to politely ask you to reconsider the originality of the paper.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Citation:[line_break_token]1.	Reply	O	0
Aladin Virmaux and Kevin Scaman.	Reply	O	0
Lipschitz regularity of deep neural networks: analysis and[line_break_token]efficient estimation.	Reply	O	0
In Advances in Neural Information Processing Systems, pp.	Reply	O	0
3835‚Äì3844,[line_break_token]2018	Reply	O	0

The paper is about hyperparameter optimization, which is an important problem in deep learning due to the large number of hyperparameters in contemporary model architectures and optimization algorithms.	Review	O	0
[line_break_token][line_break_token]At a high-level, hyperparameter optimization (for the challenging case of discrete variables) can be seen as a black-box optimization problem where we have only access to a function evaluation oracle (but no gradients etc.).	Review	O	0
In the entirely unstructured case, there are strong lower bounds with an exponential dependence on the number of hyperparameters.	Review	O	0
In order to sidestep these impossibility results, the current paper assumes structure in the unknown function mapping hyperparameters to classification accuracy.	Review	O	0
In particular, the authors assume that the function admits a representation as a sparse and low-degree polynomial.	Review	O	0
While the authors do not empirically validate whether this is a good model of the unknown function, it appears to be a reasonable assumption (the authors *do* empirically validate their overall approach).	Review	O	0
[line_break_token][line_break_token]Based on the sparse and low-degree assumption, the paper introduces a new algorithm (called Harmonica) for hyperparameter optimization.	Review	O	0
The main idea is to leverage results from compressed sensing in order to recover the sparse and low-degree function from a small number of measurements (i.e., function evaluations).	Review	O	0
The authors derive relevant sample complexity results for their approach.	Review	O	0
Moreover, the method also yields new algorithms for learning decision trees.	Review	O	0
[line_break_token][line_break_token]In addition to the theoretical results , the authors conduct a detailed study of their algorithm on CIFAR10.	Review	O	0
They compare to relevant recent work in hyperparameter optimization (Bayesian optimization, random search, bandit algorithms) and find that their method significantly improves over prior work.	Review	O	0
The best parameters found by Harmonica improve over the hand-tuned results for their "base architecture" (ResNets).	Review	O	0
[line_break_token][line_break_token]Overall, I find the main idea of the paper very interesting and well executed, both on the theoretical and empirical side.	Review	O	0
Hence I strongly recommend accepting this paper.	Review	O	0
[line_break_token][line_break_token][line_break_token]Small comments and questions:[line_break_token][line_break_token]1.	Review	O	0
It would be interesting to see how close the hyperparameter function is to a low-degree and sparse polynomial (e.g., MSE of the best fit).	Review	B-Review	1
[line_break_token][line_break_token]2.	Review	O	0
A comparison without dummy parameters would be interesting to investigate the performance differences between the algorithms in a lower-dimensional problem.	Review	B-Review	2
[line_break_token][line_break_token]3.	Review	O	0
The current paper does not mention the related work on hyperparameter optimization using reinforcement learning techniques (e.g., Zoph & Le, ICLR 2017).	Review	O	0
While it might be hard to compare to this approach directly in experiments, it would still be good to mention this work and discuss how it relates to the current paper.	Review	B-Review	3
[line_break_token][line_break_token]4.	Review	O	0
Did the authors tune the hyperparameters directly using the CIFAR10 test accuracy?	Review	B-Review	4
Would it make sense to use a slightly smaller training set and to hold out say 5k images for hyperparameter evaluation before making the final accuracy evaluation on the test set?	Review	I-Review	4
The current approach could be prone to overfitting.	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	O	0
While random search does not explicitly exploit any structure in the unknown function, it can still implicitly utilize smoothness or other benign properties of the hyperparameter space.	Review	B-Review	5
It might be worth adding this in the discussion of the related work.	Review	I-Review	5
[line_break_token][line_break_token]6.	Review	I-Review	3
Algorithm 1: Why is the argmin for g_i  (what does the index i refer to)?	Review	I-Review	6
[line_break_token][line_break_token]7.	Review	O	0
Why does PSR truncate the indices in alpha?	Review	B-Review	7
At least in "standard" compressed sensing, the Lasso also has recovery guarantees without truncation (and empirically works sometimes better without).	Review	I-Review	7
[line_break_token][line_break_token]9.	Review	O	0
Definition 3: Should C be a class of functions mapping {-1, 1}^n to R?	Review	B-Review	8
 (Note the superscript.)	Review	I-Review	8
[line_break_token][line_break_token]10.	Review	I-Review	10
On Page 3 we assume that K = 1, but Theorem 6 still maintains a dependence on K. It might be cleaner to either treat the general K case throughout, or state the theorem for K = 1.	Review	I-Review	9
[line_break_token][line_break_token]11.	Review	O	0
On CIFAR10, the best hyperparameters do not improve over the state of the art with other models (e.g., a wide ResNet).	Review	B-Review	10
It could be interesting to run Harmonica in the regime where it might improve over the best known models for CIFAR10.	Review	I-Review	10
[line_break_token][line_break_token]12.	Review	O	0
Similarly, it would be interesting to see whether the hyperparameters identified by Harmonica carry over to give better performance on ImageNet.	Review	B-Review	11
The authors claim in C.3 that the hyperparameters identified by Harmonica generalize from small networks to large networks.	Review	I-Review	11
Testing whether the hyperparameters also generalize from a smaller to a larger dataset would be relevant as well.	Review	I-Review	11
Thank you for your summary and comments!	Reply	O	0
Answers to your questions:[line_break_token][line_break_token]1.	Reply	O	0
Great suggestion.	Reply	B-Reply	1
We have shown that the function does fit a low-degree polynomial by merit of optimization, but an MSE test is a good idea, and we‚Äôll do that.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
In fact, besides Spearmint (which runs without dummy parameters in our experiment) and Harmonica, other algorithms like random search, successive halving or hyperband will have exactly the same performance with/without dummy variables as they are based on random search in the parameter space.	Reply	O	0
Therefore, by removing the dummy variables, only Harmonica might give better performance while the others will stay the same.	Reply	B-Reply	2
[line_break_token]So in short, the experiment is *non-favorable* to Harmonica with respect to dummy variables, showing its robustness.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Certainly, we will add discussion about this paper.	Reply	B-Reply	3
The difficulty from comparing comes from the fact that the RL approach is inherently sequential, needing more information to proceed.	Reply	I-Reply	3
Our approach is also based on a different assumption (sparse low degree polynomial).	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
We did not try this because our main goal was to try to do an apples to apples comparison of hyperparameter settings found by other algorithms on the entire training set (and indeed we found some that are even better than hand-tuning as in Figure 2).	Reply	B-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
Right, we‚Äôll add discussion.	Reply	B-Reply	5
[line_break_token][line_break_token]6.	Reply	O	0
Typo, thanks!	Reply	B-Reply	6
[line_break_token][line_break_token]7.	Reply	I-Reply	4
This is simply a heuristic we tried, but it is definitely worth investigating no truncation (which we didn‚Äôt investigate enough).	Reply	I-Reply	7
[line_break_token][line_break_token]9.	Reply	O	0
Typo, yes!	Reply	B-Reply	8
[line_break_token][line_break_token]10.	Reply	O	0
Yes, we will remove the Ks.	Reply	B-Reply	9
[line_break_token][line_break_token]11.	Reply	O	0
When we started the project (around Sep, 2016), resnet was considered to be a pretty good model, but now maybe densenet is better.	Reply	B-Reply	10
 Note that in Resnet, Harmonica does do better than best hand-tuned model, we hope same is true for densenet.	Reply	I-Reply	10
[line_break_token][line_break_token]12.	Reply	O	0
We did not have enough resources to do hyperparameter tuning for Imagenet, but intend to try this idea for CIFAR100 with densenet (i.e., using a subset of the data first).	Reply	B-Reply	11

Summary:[line_break_token]The authors propose a method for learning hierarchical policies in a multi-task setting built on options and casts the concepts into the Planning as Inference framework.	Review	O	0
They claim that the method brings several advantages such as:[line_break_token]-Stabilize end-to-end mtl,[line_break_token]-Leads to coordination b/w master policies,[line_break_token]-Allows fine-tuning of options[line_break_token]-Learn termination policies naturally[line_break_token][line_break_token]The proposed approach derives the reward Eq.6 by extending the graph to options for Levine‚Äôs tutorial.	Review	O	0
Eq.6 is simply the extension of the reward of maximum entropy RL to the options framework.	Review	O	0
The ideas presented in the paper are interesting, but I have concerns about the scalability of such an approach.	Review	O	0
Please see the detailed comments below.	Review	O	0
 Additionally, please note that although I have marked a weak reject, I am open to adjusting my score if the rebuttal addresses enough issues.	Review	O	0
[line_break_token][line_break_token]Detailed Comments:[line_break_token]A primary weakness of this approach is that it seems like there is one network that learns the options and is shared across all task (that would be the prior) and then there is a task-specific network for all options (posterior), wouldn‚Äôt this be very difficult to scale if we want to learn reusable options over the lifetime of an agent?	Review	O	0
If there are n tasks, do you need to use n different networks?	Review	B-Review	1
[line_break_token][line_break_token]The authors assume that all options are present everywhere i.e. I ‚äÜ S. I think the work could benefit from removing this assumption.	Review	I-Review	7
[line_break_token][line_break_token]The authors mention that unlike (Frans et al.,	Review	I-Review	2
2018), they learn both intra-option and termination policies: there is definitely more work that aims to learn both the skill and its termination.	Review	I-Review	2
It would be more complete to cite additional references here that learn both of these or rephrase this sentence.	Review	I-Review	2
[line_break_token][line_break_token]It does not seem clear why ‚Äúterm 1 of the regularization is only nonzero whenever we terminate an option and the master policy needs to select another to execute.	Review	I-Review	3
‚Äù This doesn‚Äôt seem true as this is a ratio of the two probabilities and not just the instantiation of the random variable.	Review	I-Review	3
[line_break_token][line_break_token]The results in moving bandits alone are very convincing.	Review	I-Review	4
However, in Taxi (2b) distral+action seems to be as good as/even better MSOL.	Review	I-Review	4
In directional Taxi (2c) Distral(+action) manages to reach the same final performance (if we care about that), can you please comment on this.	Review	I-Review	4
[line_break_token][line_break_token]Some parts of the experiments section does not seem clear to me, Does the proposed approach use a network per task?	Review	I-Review	5
if yes, then it is obvious that their method could improve over learning on 12 tasks with one set of network.	Review	I-Review	5
Please clarify.	Review	I-Review	5
[line_break_token][line_break_token]One major concern is that the only high dimensional experiment is a swimmer and it is not immediately clear how much do we gain there.	Review	I-Review	6
Distral is relatively closer in performance to both MSOL and MSOL frozen.	Review	I-Review	6
I would recommend evaluation in a variety of high-dimensional domains such as other instances in Mujoco, and visual domains.	Review	I-Review	6
In particular, the proposed ideas would make a stronger case if the baselines included other multitask hierarchical agents such as [4] for example.	Review	I-Review	6
A discussion including some of the missing relevant related multi-task literature would also be helpful [1,2,4,5,6].[line_break_token][line_break_token][1] Mann, T. A., Mannor, S., &amp; Precup, D. (2015).	Review	O	0
Approximate value iteration with temporally extended actions.	Review	O	0
JAIR, 53, 375-438.	Review	O	0
[line_break_token][2] Konidaris, G., &amp; Barto, A. G. (2007).	Review	O	0
Building Portable Options: Skill Transfer in Reinforcement Learning.	Review	O	0
In IJCAI,[line_break_token][3] Andreas, J., Klein, D., &amp; Levine, S. (2017).	Review	O	0
Modular multitask reinforcement learning with policy sketches.	Review	O	0
ICML[line_break_token][4] Tessler, Chen, et al. "	Review	O	0
A deep hierarchical approach to lifelong learning in minecraft."	Review	O	0
Thirty-First AAAI Conference on Artificial Intelligence.	Review	O	0
2017.	Review	O	0
[line_break_token][5] Ammar, Haitham Bou, et al. "	Review	O	0
Online multi-task learning for policy gradient methods."	Review	O	0
International Conference on Machine Learning.	Review	O	0
2014.	Review	O	0
[line_break_token][6] Mankowitz, Daniel J., Timothy A. Mann, and Shie Mannor. "	Review	O	0
Adaptive skills adaptive partitions (ASAP)."	Review	O	0
Advances in Neural Information Processing Systems.	Review	O	0
2016.	Review	O	0
hank you for your detailed review and feedback.	Reply	O	0
We welcome any further comments and questions.	Reply	O	0
[line_break_token][line_break_token]Scalability:[line_break_token]We choose to use one network per task, but this is not strictly necessary if one wanted to scale to more tasks.	Reply	O	0
For example, in the non-hierarchical case with prior/posterior networks, Galashov et al.	Reply	B-Reply	1
use just one posterior network, providing task information as additional input.	Reply	I-Reply	1
Their findings could be applied to our hierarchical approach.	Reply	I-Reply	1
[line_break_token]Furthermore, we show that the derived loss function incentivises specialized options during training, i.e. options for which the prior and posterior are the same.	Reply	I-Reply	1
Consequently, given sufficient options, eventually one can forget the posteriors as the option priors should be good enough to solve the tasks encountered so far.	Reply	I-Reply	1
[line_break_token][line_break_token]Fairness of comparison:[line_break_token]Both MSOL and Distral use one network per task so this comparison is fair.	Reply	O	0
[line_break_token]We also included MSOL(frozen) which, once the prior options are trained, only uses this one network without further adaptation for transfer, allowing a fair comparison to MLSH, which it still outperforms.	Reply	B-Reply	4
[line_break_token][line_break_token]Environmental complexity and additional baselines: [line_break_token]One key goal of MSOL is to find good (i.e. transferable) options and terminations without any additional human-designed prior knowledge regarding subgoals.	Reply	O	0
This is challenging because during option-learning the algorithm not only needs to solve each task, but needs to find a way to segment tasks into reusable sub-tasks - all without additional human information.	Reply	B-Reply	6
This is a main difference to many previous algorithms which receive additional information, for example in the form of landmarks, policy sketches or designated sub-tasks for each option.	Reply	I-Reply	6
[line_break_token]Our goal with the Swimmer environment was to show that our algorithm is applicable to continuous tasks.	Reply	I-Reply	6
Applying the algorithm in practice to much more complex multi-task domains in MuJoCo was infeasible given our limited computational resources.	Reply	I-Reply	6
Hierarchical approaches applied to such settings often receive additional prior information (like sub-tasks or goals per option as in Tessler et.	Reply	I-Reply	6
al) or are not constrained to learn transferable options (like in Option Critic).	Reply	I-Reply	6
[line_break_token][line_break_token]Option initiation sets:[line_break_token]We agree that learning to restrict the initiation sets of options is an interesting avenue for future research, but believe that learning good options and termination functions, robustly, just from a set of tasks is already a significant enough contribution.	Reply	O	0
[line_break_token] [line_break_token]Intra-option and termination learning: [line_break_token]We agree and have rephrased this sentence.	Reply	O	0
We have also extended the related work section.	Reply	B-Reply	2
The main difference to our work is that those approaches do not rely on a multitask setting to find good termination functions, but on other ideas, like landmarks, bottleneck states or predictability.	Reply	I-Reply	2
[line_break_token][line_break_token]Term 1 being nonzero: [line_break_token]When b_t=0, i.e. when we do not terminate, both the prior p^H and the posterior q^H are, by definition, delta(z_t-z_{t-1}), i.e. both assign a probability of 1 to the last active option.	Reply	O	0
Consequently, in this case the fraction becomes one and we have for the term: beta * ln 1 = 0[line_break_token]On the other hand, if b_t=1, then the prior is uniform and the posterior is the learned posterior, leading in general to a non-zero term.	Reply	B-Reply	3
[line_break_token][line_break_token]Comparison to Distral:[line_break_token]Final performance: We would like to note that because Distal, similarly to MSOL, learns a separate posterior policy which is regularized against the prior, it will always ultimately achieve optimal performance for weak enough regularization.	Reply	I-Reply	6
So it is to be expected that both MSOL and Distral achieve the same final performance.	Reply	I-Reply	6
[line_break_token]Our experiments show two things:[line_break_token]For learning a hierarchy, we have a more robust optimization algorithm than MLSH[line_break_token]Learning a hierarchy (compared to a flat prior as in Distral or compared to a heuristic hierarchy as in Distral+Action) is useful because it can accelerate learning.	Reply	I-Reply	6
[line_break_token][line_break_token]We intentionally included the non-directional Taxi domain to show in which cases a simpler architecture (here Distral+Action) is sufficient for optimal transfer, so its strong performance is expected.	Reply	I-Reply	6
[line_break_token]The main difference of this domain is that here, passing the last action is sufficiently informative to predict the likely future behavior.	Reply	I-Reply	6
It is like walking in a corridor with only one door at either end: Knowing which direction we are walking in carries the same amount of information as knowing which door we want to walk towards.	Reply	I-Reply	6
[line_break_token]However, in directional Taxi, knowing the last action is not as informative (because it might involve a rotation) and in Moving Bandits, one could infer the intended goal from the last action if one takes the goal positions into account.	Reply	I-Reply	6
However, we found that Distral+Action was unable to learn this more complex relationship.	Reply	I-Reply	6
In those cases a learned hierarchy in which options carry learned semantics outperforms Distral+Action in terms of transfer speed.	Reply	I-Reply	6
[line_break_token][line_break_token]Related literature:[line_break_token]Thank you for the pointers to additional literature.	Reply	O	0
We have included them in the related work section.	Reply	B-Reply	6

Summary: [line_break_token]The paper addresses the ill-posedness of the unsupervised domain translation (UDT) problem.	Review	O	0
It provides a more structured and rigorous problem definition than previous works (mainly CycleGAN-based), and proposes the theory of optimal transport (OT) as a better framework for solving UDT.	Review	O	0
The paper provides an interesting link between a dynamical formulation of OT and residual networks, which leads to a practical algorithm for solving OT/UDT.	Review	O	0
Experiments highlight two main points: 1) CycleGAN are biased towards learning nearly identity mappings, and 2) the OT formulation allows for modelling explicit biases in the learned solution through the design of the cost function.	Review	O	0
[line_break_token][line_break_token]Strengths &amp; Weaknesses:[line_break_token]  +  The paper addresses an important problem, which as far as I know, is widely known but not properly or explicitly addressed in prior work.	Review	O	0
[line_break_token]  -  While most definitions are rather intuitive, some are still vague so they cannot be constructive.	Review	O	0
For example, a UDT task is a subset of all possible mappings which are *desirable* for the given task, but it is not clear how we can exactly define *desirable* mappings.	Review	B-Review	1
[line_break_token]  -  In addition, it is not clear why the set of all mappings X_{alpha,beta} needs to be constrained to invertible mappings.	Review	O	0
I see invertibility as only a constraint added by CycleGAN to limit the set of possible learned mappings.	Review	B-Review	2
[line_break_token][line_break_token]  +  The paper makes an interesting observation that CycleGAN is biased towards simple, and nearly identity mappings (which I believe is the main consequence of small initialization values), which could explain its practical success.	Review	O	0
[line_break_token]  -  However, the paper needs to emphasize that this is particularly tied to the choice of resnet architectures that is commonly used.	Review	O	0
[line_break_token][line_break_token]  +  I like the proposed dynamical formulation for solving OT and the link to resnets, which provides an interesting practical algorithm.	Review	O	0
[line_break_token]  -  The main problem that remains unsolved is how to choose the cost function.	Review	O	0
The paper acknowledges that, and proposes a specific cost functions for the specific tasks of the experimental section.	Review	B-Review	4
[line_break_token][line_break_token]  -  While experiments support the main claims of the paper, they are still quite limited and do not really have a clear practical significance.	Review	O	0
The paper would have been much stronger if the proposed approach solves a more practical problem.	Review	B-Review	5
[line_break_token][line_break_token]In conclusion, while I think that the practical significance of the proposed approach is rather limited, I think that overall it makes an interesting contribution to the domain of UDT which can be useful for future work.	Review	O	0
[line_break_token]	Review	O	0
ear reviewer, thank you for having taken the time to read our work and for your detailed review.	Reply	O	0
In the following we will try to address your comments and questions point by point, do not hesitate to respond, we would be interested in having your feedback.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Notion of desirable mapping:[line_break_token][line_break_token][line_break_token]‚Äú- While most definitions are rather intuitive‚Ä¶‚Äù‚Äù[line_break_token][line_break_token]Your remark is very relevant: It is indeed difficult in general to define what a *desirable* mapping is.	Reply	O	0
Ideally, the set of desirable mappings we used in the definition would be defined through some quantitative criterion.	Reply	B-Reply	1
For example, in the image translation experiments (section 4.2), a desirable mapping should preserve as much information as possible about the face being transformed (hence the relevance of the quadratic constraint).	Reply	I-Reply	1
However, there are many situations where it is difficult to construct a precise one and, in practice, practitioners try different mappings until a qualitatively satisfying one is found.	Reply	I-Reply	1
In all generality, it is difficult to have a general constructive solution: in Prop 2, Section 2.2, we have shown that there is no algorithm that can solve all UDT Tasks without additional information.	Reply	I-Reply	1
This is precisely the strongest motivation for the use of OT: If the user knows how to characterize precisely the mappings solving his UDT task he can find a suitable cost which we know must exist for any given UDT task as we prove in Prop.	Reply	I-Reply	1
3 (with mild additional assumptions).	Reply	I-Reply	1
If the characterization is more vague, it becomes more difficult to construct a cost for the task and there has to be some trial and error as for any modelling problem.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Importance of invertible mappings:[line_break_token][line_break_token]‚Äú-I see invertibility...‚Äù[line_break_token][line_break_token]For deterministic mappings (like CycleGAN), if invertibility is not verified on the support of the domains, there is either creation or destruction of mass.	Reply	O	0
In other words, a coherent map as defined in section 1 of the paper is invertible in general which means that invertibility doesn‚Äôt really further constrain the solution.	Reply	B-Reply	2
We chose to keep this redundancy in order to stay close from the CycleGAN formulation and to stress the fact that we are also looking for a backward mapping which is the inverse of the forward one when we are solving a UDT task.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Architecture choice:[line_break_token][line_break_token]‚Äú- However, the paper needs to emphasize‚Ä¶‚Äù[line_break_token][line_break_token]We studied the ResNet architecture in particular for two reasons: It is the most used one and the similarity of its structure to the discretization of ODEs makes its analysis easier and its generalization to dynamical OT more natural.	Reply	O	0
However, the implicit bias we show is also present in other architectures, e.g. the Unet with its skip connections: The results produced by ‚Äúgood‚Äù CycleGAN-like models always seem to have the property of preserving the structure of the input which means that the transformation is a low-energy one.	Reply	B-Reply	3
[line_break_token][line_break_token][line_break_token][line_break_token]Cost definition:[line_break_token][line_break_token]‚Äú- The main problem that remains unsolved‚Ä¶‚Äù[line_break_token][line_break_token]We do agree that constructing a cost is challenging in general, as we wrote in the paper.	Reply	O	0
However, we think that, while our main focus has been on explaining the empirical success of CycleGAN, the insights we gained through this analysis do have some practical significance:[line_break_token][line_break_token]-As we show in the CelebA experiment, explicitly enforcing a quadratic cost makes the model more robust to the choice of hyper-parameters and there is less variance in the calculated mappings between different training runs.	Reply	B-Reply	4
This can be of importance when the training resources are limited.	Reply	I-Reply	4
It has to be noted that the quadratic cost already covers the most common situations and in particular all those covered by the CycleGAN model.	Reply	I-Reply	4
[line_break_token][line_break_token]-In some situations, the implicit low-energy biais present in CycleGAN might not be the right one when we would like to transport different mathematical objects: e.g. if we were to transport matrices, one would preferably consider minimally displacing the eigenvectors instead of minimally displacing each component as would be done in a trivial extension of CycleGAN.	Reply	I-Reply	4
Our approach allows to handle those situations, provided that enough is known to construct a cost; otherwise trial and error is needed but it has to be noted that ground costs can be taken from a large family of functions as the Twist condition is the only necessary property.	Reply	I-Reply	4
[line_break_token][line_break_token]‚Äú- While experiments support the main claims of the paper‚Ä¶‚Äù[line_break_token][line_break_token]- We add to the updated version of the paper another image experiment with a cost over color histograms where the color palette of images is minimally transported instead of their L2 norm.	Reply	O	0
The results show that by using a well chosen cost, we are able to avert the consequences of a bias about hair color in the datasets while the L2 biased mapping fails to do so.	Reply	B-Reply	5
This is a good example of how different costs can be leveraged for different tasks (even though quadratic costs are already quite useful in practice) to inject prior knowledge.	Reply	I-Reply	5
Looking for other practical applications is then another endeavour and one we will be working on in the future	Reply	I-Reply	5

This paper includes several controlled empirical studies comparing MC and TD methods in predicting of value function with complex DNN function approximators.	Review	O	0
Such comparison has been carried out both in theory and practice for simple low dimensional environments with linear (and RKHS) value function approximation showing how TD methods can have much better sample complexity and overall performance compared to pure MC methods.	Review	O	0
This paper shows some results to the contrary when applying RL to complex perceptual observation space.	Review	O	0
[line_break_token][line_break_token]The main results include:[line_break_token](1) In a rollout update a mix of MC and TD update (i.e. a rollout of > 1 and < horizon) outperforms either extreme.	Review	O	0
This is inline with TD-lambda analysis in previous work.	Review	O	0
[line_break_token](2) Pure MC methods can outperform TD methods when the rewards becomes noisy.	Review	O	0
[line_break_token](3) TD methods can outperform pure MC methods when the return is mostly dominated by the reward in the terminal state.	Review	O	0
[line_break_token](4) MC methods tend to degrade less when the reward signal is delayed.	Review	O	0
[line_break_token](5) Somewhat surprising: MC methods seems to be on-par with TD methods when the reward is sparse and even longer than the rollout horizon.	Review	O	0
[line_break_token](6) MC methods can outperform TD methods with more complex and high dimensional perceptual inputs.	Review	O	0
[line_break_token][line_break_token]The authors conjecture that several of the above observations can be explained by the fact that the training target in MC methods is "ground truth" and do not rely on bootstrapping from the current estimates as is done in a TD rollout.	Review	O	0
They suggest that training on such signal can be beneficial when training deep models on complex perceptual input spaces.	Review	O	0
[line_break_token][line_break_token]The contributions of the paper are in parts surprising and overall interesting.	Review	O	0
I believe there are far more caveats in this analysis than what is suggested in the paper and the authors should avoid over-generalizing the results based on a few domains and the analysis of a small set of algorithms.	Review	O	0
Nonetheless I find the results interesting to the RL community and a starting point to further analysis of the MC methods (or adaptations of TD methods) that work better with image observation spaces.	Review	O	0
Publishing the code, as the authors mentioned, would certainly help with that.	Review	O	0
[line_break_token][line_break_token]Notes:[line_break_token]- I find the description of the Q_MC method presented in the paper very confusing and had to consult the reference to understand the details.	Review	O	0
Adding a couple of equations on this would improve the readability of the paper.	Review	B-Review	1
[line_break_token][line_break_token]- The first mention of partial observability can be moved to the introduction.	Review	O	0
[line_break_token][line_break_token]- Adding results for m=3 to table 2 would bring further insight to the comparison.	Review	O	0
[line_break_token][line_break_token]- The results for the perceptual complexity experiment seem contradictory and inconclusive.	Review	O	0
One would expect Q_MC to work well in Grid Map domain if the conjecture put forth by the authors was to hold universally.	Review	B-Review	4
[line_break_token][line_break_token]- In the study on reward sparsity, although a prediction horizon of 32 is less than the average steps needed to get to a rewarding state, a blind random walk might be enough to take the RL agent to a close-enough neighbourhood from which a greedy MC-based policy has a direct path to the goal.	Review	O	0
What is missing from this picture is when a blind walk cannot reach such a state, e.g. when a narrow corridor is present in the environment.	Review	B-Review	5
Such a case cannot be resolved by a short horizon MC method.	Review	I-Review	5
In other words, a sparse reward setting is only "difficult" if getting into a good neighbourhood requires long term planning and cannot be resolved by a (pseudo) blind random walk.	Review	I-Review	5
[line_break_token][line_break_token]- The extrapolation of the value function approximator can also contribute to why the limited horizon MC method can see beyond its horizon in a sparse reward setting.	Review	O	0
That is, even if there is no way to reach a reward state in 32 steps, an MC value function approximation with horizon 32 can extrapolate from similar looking observed states that have a short path to a rewarding state, enough to be better than a blind random walk.	Review	B-Review	6
It would have been nice to experiment with increasing model complexity to study such effect.	Review	I-Review	6
We thank the reviewer for the valuable comments and detailed suggestions.	Reply	O	0
[line_break_token][line_break_token]> I find the description of the Q_MC method presented in the paper very confusing and had to consult the reference to understand the details.	Reply	O	0
Adding a couple of equations on this would improve the readability of the paper.	Reply	O	0
[line_break_token][line_break_token]The equations describing the Q_MC method were in the "Network details" section of the supplement material.	Reply	B-Reply	1
We have renamed the section into "Q_MC and n-step Q details"  and refer to the section in the main paper to make it easier to find this information.	Reply	I-Reply	1
[line_break_token][line_break_token]> The first mention of partial observability can be moved to the introduction.	Reply	O	0
[line_break_token][line_break_token]We changed the introduction accordingly.	Reply	B-Reply	2
[line_break_token][line_break_token]> Adding results for m=3 to table 2 would bring further insight to the comparison.	Reply	O	0
[line_break_token][line_break_token]m=3 results were added to the supplement.	Reply	B-Reply	3
[line_break_token][line_break_token]> The results for the perceptual complexity experiment seem contradictory and inconclusive.	Reply	O	0
One would expect Q_MC to work well in Grid Map domain if the conjecture put forth by the authors was to hold universally.	Reply	O	0
[line_break_token][line_break_token]We think that the grid worlds were presented in the paper in a misleading manner.	Reply	B-Reply	4
The two grid worlds are not clearly different in their perceptual difficulty.	Reply	I-Reply	4
In one of them the agent receives its location and locations of health kits as 2D vectors of coordinates (sorted by distance to the agent) and in the other one as k-hot vectors.	Reply	I-Reply	4
In both cases, the relevant information is readily available.	Reply	I-Reply	4
It is not obvious which of these representations is easier for a deep network to process.	Reply	I-Reply	4
We have changed the grid world names to "Coord.	Reply	I-Reply	4
Grid" and "k-hot Grid", modified the Figure 4 caption, and adjusted the paper text to clarify the grid tasks results.	Reply	I-Reply	4
[line_break_token][line_break_token]> What is missing from this picture is when a blind walk cannot reach such a state, e.g. when a narrow corridor is present in the environment.	Reply	O	0
[line_break_token][line_break_token]We agree that this is an interesting problem.	Reply	B-Reply	5
However, if a random agent is never reaching a reward, both TD and MC cannot improve the policy.	Reply	I-Reply	5
Both rely on receiving a reward for the Q_target to start improving.	Reply	I-Reply	5
We believe this problem is more related to improving on the epsilon-greedy exploration or introducing auxiliary rewards encouraging exploration, and less related to the comparison between TD and MC algorithms.	Reply	I-Reply	5
One example of such a problem is the Pitfall Atari game where a random agent is unable to reach any positive rewards.	Reply	I-Reply	5
To the best of our knowledge, so far no epsilon-greedy-based algorithm was able to reach a positive average reward, as for example seen for multiple algorithms in Figure 14 in Bellemare et al. "	Reply	I-Reply	5
A Distributional Perspective on Reinforcement Learning", 2017.	Reply	I-Reply	5

This work probes graph classification datasets for isomorphism bias.	Review	O	0
They find substantial amount of bias in some datasets and show that they suffer from data leakage.	Review	O	0
They further perform a more fine-grained evaluation taking into consideration the node/edge types which reduce the perceived effects.	Review	O	0
They also provide some recommendations for measuring the 'right metrics' and release clean versions of the considered datasets.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]- The methodology is rigorous and the datasets considered is extensive[line_break_token]- The paper is well written[line_break_token][line_break_token]Concerns:[line_break_token]- Isomorphism is not necessarily a bad thing in graph classification tasks.	Review	O	0
Especially in chemistry where a bond decides if a compound is poisonous or not.	Review	B-Review	1
Also, as the authors themselves mention, taking node/edge labels decrease the isomorphism in most datasets.	Review	O	0
[line_break_token]- The results and recommendations presented in the paper are intuitive and somewhat trivial[line_break_token]- I am not sure if ICLR is the right venue for this work	Review	O	0
ince the area of graph classification is rapidly growing (with several submissions just in ICLR 2020 that use these data sets), it‚Äôs important to set the right rules for correct validation of newly proposed models.	Reply	B-Reply	5
As we described in the related work section, such a problem is already the case for Computer Vision data sets, which can severely skew the validation accuracy and we want to prevent this for graph classification domain.	Reply	I-Reply	5
[line_break_token][line_break_token]The fact that so many data sets contain so many isomorphic graphs is a newly discovered phenomenon and is novel to the community.	Reply	I-Reply	5
While there were some mentions [1] about this fact, no one has run a full analysis of the data sets, for obvious reasons: it‚Äôs very time- and resource-consuming problem.	Reply	I-Reply	5
It‚Äôs not trivial to find all isomorphic pairs in 54 data sets: for example for the largest data set, there are more than 71 million graph pairs that need to be checked on isomorphism.	Reply	I-Reply	5
Isomorphism test is known to be a challenging task and we had to write efficient code to preprocess pairs for this task and yet it still takes hours to compute statistics for all data sets.	Reply	I-Reply	5
One of our contributions is that we release code and anyone with a new data set can easily run a pairwise isomorphism test on it.	Reply	I-Reply	5
[line_break_token][line_break_token]Regarding your first concern.	Reply	O	0
Isomorphism in itself is not a bad thing and incorporating isomorphism features into the models has proven to lead to better results.	Reply	B-Reply	1
The main issue of having isomorphic graphs in the data sets is that the model can ‚Äúmemorize‚Äù, explicitly or implicitly, the target labels during the training phase; this is obviously a leakage for validation and artificially increases the accuracy as we show in Table 4.	Reply	I-Reply	1
It‚Äôs important to note here that if a model can memorize, it can also solve graph isomorphism, which is GI-hard and no one has claimed such model yet.	Reply	I-Reply	1
But, many successful models [2,3,4] incorporate the features efficiently (e.g. via WL algo), which solves isomorphism problem for almost all pairs of graphs, including all pairs in used graph data sets.	Reply	I-Reply	1
That means that such models can essentially memorize which graphs were seen in the training, by comparing test graph embedding with train graph embeddings.	Reply	I-Reply	1
Now, imagine increasing the data set size by adding isomorphic graphs.	Reply	I-Reply	1
Then, no matter how _weak_ classification model is, the accuracy on the increased data set will be approaching 100%, by just memorizing the labels from the train set and all models would be the same in such data sets.	Reply	I-Reply	1
This is not the goal for the graph classification problem, which rather asks to find a model that would be correct on as large set of new instances as possible.	Reply	I-Reply	1
Informally, comparing performance on a data set of 100 different graphs is better than on a data set of 1000 isomorphic graphs.	Reply	I-Reply	1
That's why having clean data sets without isomorphic instances has more fair validation comparison.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding using node/edge labels for the models, indeed it reduces the number of isomorphic graphs, however (1) many data sets still contain isomorphic graphs as we show in Figures 3,4,5; (2) some models do not use node/edge attributes; and (3) not all data sets have such meta-data (e.g. IMDB-MULTI contains 80% of isomorphic graphs, but does not have any attributes).	Reply	O	0
Moreover, this is a new insight from our work as to why it is important to use _given_ node/edge attributes when designing a model, instead of designing attributes heuristically, as it has been tried before.	Reply	B-Reply	2
[line_break_token][line_break_token]Regarding your second concern.	Reply	O	0
Having a paper intuitive is not necessarily a bad thing.	Reply	B-Reply	3
We kept in mind that it should be an easy-to-read work so that more graph practitioners could use the right framework (data sets, meta-data, validation procedures, etc.)	Reply	I-Reply	3
and these hidden parts should be known to all who want to design a model.	Reply	I-Reply	3
While property and theorem are easily derived facts, it is important to state them as they partially explain the current performance of classification models.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding your last concern, please note that our analyzes encompasses almost all datasets currently used for graph classification benchmarking.	Reply	O	0
This area has been dominant for representation learning of graphs, leading to advancements in Graph Neural Networks research, and thus a clean data set is a prerequisite for learning a good graph embedding.	Reply	B-Reply	4
We also note that many of the data sets come from the Biological application, one of the ICLR main applications (as denoted in the main website) and some results of this paper provide new insights into this application (e.g. noisy target labels for many graphs; necessity to use node/edge attributes; etc.).	Reply	I-Reply	4
[line_break_token][line_break_token]We hope this feedback addresses your concerns and we hope it can lead to your reevaluation of this paper.	Reply	O	0
If you have further questions, please let us know.	Reply	O	0
[line_break_token][line_break_token][1] ‚ÄúA Survey on Graph Kernels‚Äù 2019[line_break_token][2] ‚ÄúWeisfeiler-Lehman Graph Kernels‚Äù 2012[line_break_token][3] ‚ÄúAnonymous Walk Embeddings‚Äù 2018[line_break_token][4] ‚ÄúHow Powerful are Graph Neural Networks?‚Äù 201	Reply	O	0

The paper proposes fine-tune methodologies for BERT-like models (namely, SeasameBERT).	Review	O	0
 This includes a method that considers all BERT layers and captures local information via Gaussian blurring.	Review	O	0
The methods were evaluated on several baseline datasets (e.g., GLUE, HANS)[line_break_token][line_break_token]Strengths: [line_break_token][line_break_token]* The paper is easy to follow.	Review	O	0
[line_break_token][line_break_token]*  Squeeze-and-extraction was used to incorporate all hidden layers instead of the common-practice of averaging last 4-layers.	Review	O	0
I find it both logical and useful.	Review	O	0
[line_break_token][line_break_token]* The suggested gaussian blurring method is able to capture local dependencies, which is missing in attention-based transformer layer.	Review	O	0
[line_break_token][line_break_token]*  SesameBERT improves performance on some GLUE metrics and on HANS dataset.	Review	O	0
Also ablation analysis suggests squeeze-and-extraction is a good technique to extract features from BERT model compared to other common practices. ‚	Review	O	0
Ä®[line_break_token][line_break_token][line_break_token]Weaknesses:[line_break_token][line_break_token]* In my opinion, the paper novelty is not significant enough.	Review	O	0
Although useful, the suggested techniques are based on existing methods.	Review	B-Review	1
[line_break_token][line_break_token]*  Incorporate spatial/context-information is usually done by concatenating a location-based embedding with the original word embedding.	Review	O	0
I‚Äôm curious if the blurring Gaussian will be as useful compared to such version.	Review	B-Review	2
[line_break_token][line_break_token]* Since the suggested methods are generic, It can be more convincing to see results on recent models, and not only BERT.	Review	O	0
Currently, the results are not significantly better.	Review	B-Review	3
 [line_break_token][line_break_token]* The HANS DATASET RESULTS section seems rushed, will be good to elaborate more about HANS.	Review	O	0
also the first sentences of the section discusses GLUE results not HANS.	Review	B-Review	4
[line_break_token][line_break_token]To conclude: The paper is easy to follow, suggests two nice methods for fine-tune BERT.	Review	O	0
But although useful, the suggested methods are not novel enough.	Review	O	0
The performance does not significantly improves, and the methods are applied only to BERT model.	Review	O	0
e thank the reviewer for the detailed comments.	Reply	O	0
In what follows, we address in detail the raised issues.	Reply	O	0
[line_break_token][line_break_token]1„ÄÅ3.	Reply	O	0
Like we've mentioned in official response.	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Sorry, not pretty sure what you mean.	Reply	B-Reply	2
[line_break_token][line_break_token]4.	Reply	O	0
We first talked GLUE results on the section because we wanted to prove that the significant improvement on HANS dataset was based on a model with similar accuracy on GLUE tasks.	Reply	B-Reply	4
We will highlight more on HANS dataset in the final version	Reply	I-Reply	4

SUMMARY[line_break_token]-------[line_break_token][line_break_token]This paper explores a series of incremental variations of existing pruning techniques for compressing Resnet-50 for ImageNet.	Review	O	0
Specifically, it proposes concentrating all pruning during an early "era" of training (the first 20-50 epochs out of 100 total).	Review	O	0
It also explores hybrids between sparse pruning and structured pruning.	Review	O	0
Finally, it considers the adversarial robustness of the resulting networks to the FGSM attack.	Review	O	0
[line_break_token][line_break_token]This paper makes no novel proposals and experiments are minimal.	Review	O	0
There are no clear takeaways from the results of these experiments.	Review	O	0
The goals of the paper are unclear, and it is difficult to compare this paper to existing work.	Review	O	0
[line_break_token][line_break_token]This paper has no clear motivation and makes no tangible contributions to the literature and, therefore, I recommend a rejection.	Review	O	0
[line_break_token][line_break_token]CONTRIBUTIONS[line_break_token]-------------[line_break_token][line_break_token]1) A study of the appropriate window ("pruning era") for pruning Resnet-50 on ImageNet and TinyImageNet[line_break_token]2) A study of the tradeoffs between various forms of structured and unstructured pruning.	Review	O	0
[line_break_token]3) An analysis of the adversarial robustness of the pruned networks.	Review	O	0
[line_break_token][line_break_token][line_break_token]DETAILED COMMENTS[line_break_token]------[line_break_token][line_break_token]PROBLEMS ADDRESSED[line_break_token][line_break_token]It was challenging to discern the specific problems that this paper sought to address and, relatedly, the goals that the paper sought to achieve.	Review	O	0
The introduction of the paper lists a wide variety of problems in the existing literature:[line_break_token][line_break_token]1) Paragraph 3: Structured sparsity introduces "regularization and computational overhead."	Review	O	0
[line_break_token]2) Paragraph 3: "Coarse-grained sparsity" cannot eliminate enough parameters to perform well on "edge devices."	Review	O	0
[line_break_token]3) Paragraph 4: Dynamic sparsity techniques require more training epochs.	Review	O	0
[line_break_token]4) Paragraph 4: Dynamic sparsity techniques do not preserve network accuracy (1-2 percentage point drop at 80% sparsity).	Review	O	0
[line_break_token]5) Paragraph 4: Dynamic sparsity requires reconfiguring the sparsity pattern frequently, which is computationally expensive.	Review	O	0
[line_break_token][line_break_token]The paper does not justify the fact that any of these are actually problems, nor does it make any attempt to quantify the extent of these problems.	Review	O	0
Moreover, the proposed techniques do not resolve any of these problems.	Review	O	0
Corresponding to the numbers above:[line_break_token][line_break_token]1) The paper never measures this overhead nor justifies that it is a problem in practice.	Review	O	0
Meanwhile, the techniques proposed in the paper introduce substantial overhad of their own, including training for an extra ten epochs.	Review	O	0
It is possible that the techniques proposed in this paper have worse overhead than the techniques that are criticized in the introduction.	Review	O	0
Since the paper provides on numbers either way, it is impossible to tell.	Review	O	0
In short, computational cost is a key part of the author's argument despite the fact that there is no empirical support for any of these claims.	Review	O	0
[line_break_token][line_break_token]2) I believe the paper means that, in order to get to sufficient levels of sparsity to work on "edge devices," accuracy drops unacceptably far.	Review	O	0
What does the paper mean by "edge devices," what are sufficient levels of sparsity, and what does it mean for accuracy to drop unacceptably far?	Review	O	0
The paper has numbers for the proposed methods, so it should be possible to make this comparison if such baselines are explicit.	Review	O	0
[line_break_token][line_break_token]3) The proposed techniques also require the same number of additional training epochs, so this complaint is unaddressed.	Review	O	0
[line_break_token][line_break_token]4) The proposed techniques show a 2-3 percentage point drop at 80% sparsity (Table 1), which is actually worse than the technique that the authors criticize.	Review	O	0
[line_break_token][line_break_token]5) The proposed techniques require pruning after every single training step during the "pruning era."	Review	O	0
This is likely to be more computationally expensive than any of the other gradual pruning and dynamic sparsity techniques listed, which prune at intervals of hundreds or thousands of iterations.	Review	O	0
In addition, the authors never justify why changing the sparsity pattern frequently throughout training will affect performance.	Review	O	0
On GPUs with modern frameworks, I see no reason why this should matter so long as the sparsity pattern does not change too frequently (although that is exactly what this paper proposes to do during the "pruning era").	Review	O	0
[line_break_token][line_break_token][line_break_token]GOALS[line_break_token][line_break_token]It was also challenging to discern the goals of the paper.	Review	O	0
Was it:[line_break_token][line_break_token]1) To produce the smallest possible trained networks with the highest possible accuracy?	Review	O	0
[line_break_token][line_break_token]2) To reduce the cost of obtaining a pruned network for inference-time? (	Review	O	0
Or to reduce the cost of obtaining a sufficiently efficient pruned network for inference-time?)	Review	O	0
[line_break_token][line_break_token]3) To reduce the cost of training neural networks in general by pruning them during training?	Review	O	0
[line_break_token][line_break_token]In the introduction and the related work section, these goals go unstated, making it difficult to determine how this paper compares to existing work.	Review	O	0
The comparisons provided in the paper focus on specific aspects of each related work rather than the entire picture.	Review	O	0
For example, in comparison to Mao et al.,	Review	O	0
the authors claim better accuracy at one sparsity level, implying goal 1.	Review	O	0
However, for to Lym et al.,	Review	O	0
the paper focuses on the computational costs of training the network, implying goal 3.	Review	O	0
[line_break_token][line_break_token][line_break_token]UNJUSTIFIED CLAIMS ABOUT NEURAL NETWORK COMPUTATION[line_break_token][line_break_token]Throughout the paper, there are a number of unjustified claims about which neural network configurations will perform better on contemporary hardware.	Review	O	0
Considering computational efficiency appears to be a key element of the paper's argument, these claims require citations or - particularly when various configurations are compared to one another - empirical support.	Review	O	0
Some examples:[line_break_token][line_break_token]* Section 1, Paragraph 3: "The regularization term [of structured sparsity] modifies the original training and can be expensive in hardware."	Review	O	0
[line_break_token]* Section 1, Paragraph 3: "The final network [from Lym et al.	Review	O	0
2019] contains an insufficient degree of sparsity for deployment on edge devices."	Review	O	0
[line_break_token]* Section 1, Paragraph 4: "Continuous reconfiguration of the sparsity pattern is expensive as it does not allow for compression of weights during training"[line_break_token]* Section 1, Paragraph 5: "having a fixed sparse multiply-accumulate pattern allows weight compression during training and can save compute and energy in hardware"[line_break_token]* Section 5, Paragraph 2: "A strict parameter allows the hardware mapping to plan for a fixed number of multiply-accumulate operations."	Review	O	0
[line_break_token]* Section 5, Paragraph 2: "Regularization, although useful in forcing the network to learn prunable weights, adds more irregularity to computation flow."	Review	O	0
[line_break_token][line_break_token][line_break_token]PRUNING TECHNIQUES[line_break_token][line_break_token]* Recomputing the pruning mask at every training step seems gratuitously inefficient.	Review	O	0
[line_break_token]* Sorting the weights in the entire network shouldn't be particularly inefficient if it isn't done on every single iteration. (	Review	O	0
Section 2.1 paragraph 1)[line_break_token]* Why do you maintain the same number of weights in each convolutional filter with window pruning? (	Review	O	0
Presumably for performance reasons, but you never say that.)	Review	O	0
[line_break_token]* None of the pruning methods are novel.	Review	O	0
They're simply various permutations of structured and unstructured magnitude pruning as proposed by many others in the literature.	Review	O	0
[line_break_token][line_break_token][line_break_token]EXPERIMENTS[line_break_token][line_break_token]* Section 3.1 Paragraph 2: It appears that you are exploring the best "pruning era."	Review	O	0
If you are to do so, you will have to sweep over (1) the length of the pruning era (2) the starting epoch of the pruning era, and (3) the shape of the function used to determine sparsity.	Review	O	0
Instead, it sounds like you tried two arbitrary pruning eras (0-30 and 30-50).	Review	O	0
Likewise, in Paragraph 3, you test only a small number of possible scenarios.	Review	O	0
[line_break_token]* Section 3.1 is generally hard to parse.	Review	O	0
It is unclear what you are studying.	Review	O	0
The ideal pruning era?	Review	O	0
The relative performance of the pruning methods introduced in section 2?	Review	O	0
[line_break_token]* How many times did you replicate each experiment?	Review	O	0
You should ideally include at least 3 (and preferrably 5) replicates with mean and stddev reported.	Review	O	0
[line_break_token]* What baselines are you including?	Review	O	0
You should include a random pruning baseline and you should ideally replicate any methods that you compare to.	Review	O	0
[line_break_token][line_break_token][line_break_token]RESULTS[line_break_token][line_break_token]* Section 4.1: The data you refer to is in an appendix even though it is crucial to the main body of the paper.	Review	O	0
The appendices should contain material that is nonessential for making sense of the paper.	Review	O	0
[line_break_token]* Section 4.2 Paragraph 1: Are these numbers good?	Review	O	0
A standard sparse pruning technique (Gale et al.	Review	O	0
2019, <a href="https://arxiv.org/pdf/1902.09574.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1902.09574.pdf)</a> achieve 70% sparsity without any change in accuracy.	Review	O	0
Please include baselines comparing to other methods in the literature.	Review	O	0
[line_break_token]* Table 2: It is difficult to compare the results in these papers.	Review	O	0
PruneTrain aims to reduce the cost of training and measures cost reductions in FLOPS.	Review	O	0
If you intend to compare against this paper, you should quantify the cost of training using your method against that of PruneTrain.	Review	O	0
Merely presenting sparsity and accuracy numbers is insufficient.	Review	O	0
Likewise for the dynamic sparsity experiments.	Review	O	0
What is your goal in showing this comparison, and did Mostafa and Wang share that goal when they justified their technique?	Review	O	0
[line_break_token]* You do not describe the hyperparameters for Intraepoch pruning (the balance between window and CK - last paragraph of 2.1.1)[line_break_token][line_break_token][line_break_token]ADVERSARIAL ROBUSTNESS[line_break_token][line_break_token]Considering the fact that this paper focuses on proposing new variations of existing pruning techniques, any discussion of adversarial robustness seems to be (1) out of place and (2) an afterthought.	Review	O	0
If the authors delete a half-page of content (one phrase from the abstract, a paragraph and bullet from the introduction, and a paragraph each from sections 3 and 4), this content could be removed with minimal impact to the paper's main contributions.	Review	O	0
The content on adversarial robustness is cursory, uses a weak and out-of-date attack (FGSM), and does not compare to any other pruning methods.	Review	O	0
In fact, the one comparison is to the results in a paper (Wang et al, 2018) that looks at both FGSM and PGD (a stronger attack) on completely different networks and tasks (MNIST and CIFAR10).	Review	O	0
The paper would be stronger if content on adversarial robustness was removed entirely.	Review	O	0
[line_break_token][line_break_token][line_break_token]OTHER MINOR COMMENTS[line_break_token][line_break_token]* The title includes the word "starfire," but it never appears again in the paper.	Review	O	0
The paper proposes no specific technique, so there isn't anything to name.	Review	O	0
[line_break_token]* Use the \ begin{appendix} command before you create the appendices and the \ end{appendix} command when you are done.	Review	O	0
You can then use \section normally and each section so-created will appear with a letter rather than a number.	Review	O	0
[line_break_token]* Figure 4 is very hard to read.	Review	O	0
1) This paper studies the sparse training for maximum convergence accuracy of Resnet50  with Imagenet and delivers the best result for sparse training with static mask for over 70-80 epochs of training schedule in terms accuracy and acceleration potential.	Reply	O	0
[line_break_token]The experiments performed all the sensitivity studies and report over 34 experiments covering various levels of sparsity, length pruning era, start epoch of pruning era, both Resnet50 v1 and v1.5, and various sparsity granularities just in Table 1 alone.	Reply	O	0
[line_break_token]To give a context some of the main references in Table 2 report less than 10 data points.	Reply	O	0
[line_break_token] [line_break_token](2) Thanks for you for comment regarding the problems we highlighted with current literature.	Reply	O	0
We will cite literature to address all the above.	Reply	O	0
[line_break_token]Just to give context:[line_break_token]1) Regularization contains operations such as vector norm (normalization, divide, square root) that are not typically multiply accumulate nature and hence are expensive for accelerators and GPUs as they are atypical with high latency.	Reply	O	0
[line_break_token] [line_break_token]2) Sorry for the miscommunication, our meaning with this sentence was that the levels of sparsity in previous coarse grain sparsity methods were not high-enough for a given convergence accuracy.	Reply	O	0
Therefore, the overheads incurred to handle sparsity (indexing/compression/decompression) were not justified.	Reply	O	0
Our main point is that edge devices are one example area where a high level of coarse grained sparsity while maintaining accuracy is desirable, and this paper achieved this goal.	Reply	O	0
This paper also achieves similar goals for sparse training that we will address below.	Reply	O	0
[line_break_token] [line_break_token]3-4) This is supported by Table 2: given a target convergence accuracy Mostafa and Wang had to train for an extra 10 epochs (100 epochs) to be able to reach within 1% of a 90 epoch baseline.	Reply	O	0
We showed our results at all relevant epochs and the difference to baseline both at 90 and 100 epochs.	Reply	O	0
[line_break_token] [line_break_token]5) This reconfiguration happens throughout the whole network.	Reply	O	0
Restructuring the sparsity masks is extremely expensive in any system.	Reply	O	0
It includes decompression and recompression which in turn triples memory accesses.	Reply	O	0
[line_break_token]Replacing the non-zeros and refreshing the indexes is a memory intensive operation.	Reply	O	0
It has high latencies and high energy consumption.	Reply	O	0
However ours only happens after every epoch.	Reply	O	0
This was represented as after every step in Algorithm 1, and we will correctly update the figure to accurately represent our mask update schedule.	Reply	O	0
[line_break_token] [line_break_token] [line_break_token](3) We can show the nature of the computation incurred for reparametrization.	Reply	O	0
While the point is taken that we have no empirical study to support this, we make the argument that our overheads are minimal given that they are only incurred during 20% of total training schedule and that we eliminated regularization overheads.	Reply	O	0
Also, we update the sparsity only for a total of 20 times once/epoch during pruning era (again this was misrepresented in Algorithm 1 and will be corrected).	Reply	O	0
[line_break_token]  [line_break_token](4) The reason we mentioned edge devices was to highlight that the accuracy drop does not justify using low levels of sparsity because the overheads of indexing/compression/decompression are higher than just keeping data dense. [	Reply	O	0
<a href="https://en.wikipedia.org/wiki/Sparse_matrix]" target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Sparse_matrix]</a> [<a href="https://kkourt.io/phd/phd-en.pdf]," target="_blank" rel="nofollow">https://kkourt.io/phd/phd-en.pdf],</a> [<a href="https://arxiv.org/pdf/1901.07827.pdf]." target="_blank" rel="nofollow">https://arxiv.org/pdf/1901.07827.pdf].</a> [line_break_token]For example, CUSparse library performs only better than CUBLAS when degrees of sparsity are over 90% (<a href="https://developer.nvidia.com/cusparse)" target="_blank" rel="nofollow">https://developer.nvidia.com/cusparse)</a>[line_break_token] [line_break_token](5) We show both convergence at epoch 90 and 100 for comparison to baseline and all other methods.	Reply	O	0
The argument here is that those extra 10 epochs with high degrees of sparse training are much cheaper.	Reply	O	0
The epoch 90 results are in Table 6 in the appendix.	Reply	O	0
[line_break_token]Even compared to 90 epoch baseline we drop less than 1% in accuracy.	Reply	O	0
[line_break_token] [line_break_token](6) Dynamic sparse reparametrization is impossible to implement on any target architecture because it changes sparsity mask every step.	Reply	O	0
This means changing indexes of non-zeros and decompression/recompression at every step.	Reply	O	0
This is basically infeasible on any accelerator.	Reply	O	0
We contacted the authors and they told us they trained the network like a dense network.	Reply	O	0
Our goals are clear: we want fixed sparsity mask after certain epoch and we wanted to eliminate any irregular computation that is expensive on accelerators.	Reply	O	0
[line_break_token] [line_break_token](7) This a mistake on our behalf in the algorithm text and it is actually after each epoch in our code.	Reply	O	0
Thank you for pointing this out.	Reply	O	0
We only prune total of 20 times (length of pruning era).	Reply	O	0

UPDATE: The response helped address my questions.	Review	O	0
I've raised the score to 6.	Review	O	0
[line_break_token][line_break_token]This paper studies reinforcement learning for settings where the observations contain noise and where observations have long-range dependencies with the past.	Review	O	0
The proposed approach builds on the LSTM model and adds an aggregated memory cell, which decreases noise by allowing them to cancel at a high level.	Review	O	0
[line_break_token][line_break_token]Extensive experiments are provided on two sets of tasks, the TMaze and the Minecraft tasks.	Review	O	0
The experimental results look convincing to me.	Review	O	0
However, as someone who is outside the area, it is difficult to understand the details of the paper.	Review	B-Review	3
There are numerous observations and experimental design choices which are not clearly explained I think.	Review	I-Review	3
[line_break_token]- The current version (~ 10 pages) is significantly over length.	Review	O	0
[line_break_token]- LSTMs are sensitive to noise: Is there an explanation for this observation?	Review	O	0
Also, is the claim still true by suitably regularizing the LSTM, etc?	Review	B-Review	2
[line_break_token]- TMaze Long-Short: What's the intuition for why this setting requires learning over long-term memory tasks?	Review	O	0
[line_break_token][line_break_token]More detailed comments/questions:[line_break_token]- Intro P1: You start by talking about tasks that require long-term memory.	Review	B-Review	4
Then you talk about full vs partial observations.	Review	I-Review	4
What's the connection between these two?	Review	I-Review	4
[line_break_token]- Intro P4: This observation is interesting -- is there an explanation or intuition for what's happening here?	Review	I-Review	4
[line_break_token]- Figure 1: Why 68% confidence interval?	Review	I-Review	4
[line_break_token]- Aggregators: The 1/2 notation in the definition of m_t looks very confusing.	Review	I-Review	4
[line_break_token]- Definition of a_t, P5: what is FF_2?	Review	I-Review	4
[line_break_token]- TMaze Long Noise: By adding noise, do you mean that the observations are simply randomly sampled from {-1, +1}?	Review	I-Review	4
[line_break_token]	Review	O	0
hank you for you feedback.	Reply	O	0
We appreciate you noting the strength of the experimental results and appreciate the opportunity to improve the clarity so that our paper can be made more accessible.	Reply	O	0
We address the specific questions you raised below and will incorporate your feedback into the updated version of the paper:[line_break_token][line_break_token]-‚ÄúLSTMs are sensitive to noise‚Äù: Our analysis and discussion sections hypothesize why we see this drop in performance and how to fix it.	Reply	O	0
At a high level, LSTMs are more sensitive to more recent observations.	Reply	B-Reply	2
By integrating over fewer (recent) samples, they are more sensitive to slight variations in those samples.	Reply	I-Reply	2
Regularization of the inputs may help deal with noise in the observation function, but is unlikely to help with stochasticity in the trajectory.	Reply	I-Reply	2
Regularization naively applied to the RNN can be destructive (e.g. dropout. ‚	Reply	I-Reply	2
ÄúRecurrent Neural Network Regularization‚Äù [ICLR‚Äô14])  or require additional learning parameters.	Reply	I-Reply	2
In our work we show that, as opposed to changing the objective function, we can address the limitations of RNNs constitutionally and without learning, which give us the sample efficiency critical for RL.	Reply	I-Reply	2
[line_break_token]Moreover, by incorporating all inputs, not only does our approach address prototypical noise in the inputs, but also stochasticity in the trajectory from policy entropy, which is a general challenge we face, given the high degree of exploration almost always necessary at the beginning of training.	Reply	I-Reply	2
The benefits we get in terms of noise while not losing - and in fact improving - sensitivity to distant past observations is introduced specifically by order invariant operators.	Reply	I-Reply	2
The elegance of solving both problems (stochasticity from multiple sources and gradient decay) at once, with no additional parameters, was the motivation for order invariant aggregators.	Reply	I-Reply	2
[line_break_token][line_break_token]-‚ÄùTMaze Long-Short‚Äù: In TMaze experiments, including TMaze Long-Short, the indicator is only observed at the beginning but is required to be remembered until the end of the episode to get the full reward.	Reply	O	0
[line_break_token][line_break_token]-‚Äùlength‚Äù: The current version is 10 pages.	Reply	O	0
It is our understanding that this is the limit and is allowable if necessary.	Reply	B-Reply	1
We feel that the extra pages allow for additional figures, discussion, and explanation of our experiments.	Reply	I-Reply	1
We highlight the fact that we have many experiments and also many instructive diagrams to aid in visual comprehension.	Reply	I-Reply	1
[line_break_token][line_break_token]More detailed comments:[line_break_token]1) Intro P1.	Reply	I-Reply	4
If an environment is not fully-observable, memory is needed to recall previous observations that may be important.	Reply	I-Reply	4
E.g. the color of the indicator in MineCraft experiments is part of the state (and will determine reward at termination), but the only way to know the color is via memory, since this part of the state is not observable from the terminal state.	Reply	I-Reply	4
We will clarify this in the updated paper.	Reply	I-Reply	4
[line_break_token]2) Intro P4.	Reply	I-Reply	4
Are you referring to the observations regarding figure 1?	Reply	I-Reply	4
If so, our analysis and discussion sections hypothesize why we see this drop in performance and how to fix it.	Reply	I-Reply	4
Please also see our response to "LSTMS are sensitive to noise.	Reply	I-Reply	4
‚Äù[line_break_token]3) Figure 1.	Reply	I-Reply	4
We use 68% confidence interval to show approximately 1 standard deviation.	Reply	I-Reply	4
This makes the plots easy to read while giving a sense of variability of our results.	Reply	I-Reply	4
[line_break_token]4) Notation: Thanks for pointing out this lack of clarity in the slicing 1/2 notation.	Reply	I-Reply	4
We have introduced the notation at first usage in the updated paper.	Reply	I-Reply	4
[line_break_token]5) FF2: Just as FF1, FF2 are feedforward layers defined in the appendix.	Reply	I-Reply	4
We will add a reference similar to the one for FF1 that points to the appendix in the updated paper.	Reply	I-Reply	4
Thank you for pointing this out.	Reply	I-Reply	4
[line_break_token]6) TMaze Long-Noise.	Reply	I-Reply	4
Not quite: We append noise in the range {-1, +1} to the observation, which is vector-valued.	Reply	I-Reply	4
We will clarify this in the updated paper.	Reply	I-Reply	4

The paper considers the problem of sequential learning where data access for the previous tasks is completely prohibited.	Review	O	0
Authors propose a conceptually simple framework to learn structures (it is the selection of reusing, adapting previously learned layers or training new layers) as well as corresponding parameters in the sequential learning.	Review	O	0
[line_break_token][line_break_token]The paper is potentially interesting and providing possibly important framework for life-long learning.	Review	O	0
It is well written in most of cases and easy to follow (however I got the impression that the paper was rushed in the last minute; there are some trivial typos and very low resolution images etc.)	Review	O	0
[line_break_token][line_break_token]However, I have a huge concern about the empirical evaluations.	Review	B-Review	3
 This area is really huge and has attracted lots of interest from many researchers, meaning that we lots of methods to compare.	Review	I-Review	3
Nevertheless, authors only focus on providing insights on effects of different components of the propose model.	Review	I-Review	3
This is also critical but comparing against state-of-the-arts is also very important.	Review	I-Review	3
Especially, comparing against Lee et al 2017 seems essential.	Review	I-Review	3
I can see the difference against that paper from the authors' argument in the related work, but that is the difference not comparison.	Review	I-Review	3
It would be great to compare the performances as well as the number of increased memory sizes as the number of task increases.	Review	I-Review	3
[line_break_token][line_break_token]Moreover, the details should be provided; for instance provide the explicit form of R(s).	Review	I-Review	4
[line_break_token][line_break_token]---------------------------------------------[line_break_token][line_break_token]Thanks for the update.	Review	O	0
But are they fair comparisons (evaluation only in terms of accuracy)?	Review	B-Review	1
Different methods expand the network different amount.	Review	I-Review	1
Hence, they should be compared on this metric too.	Review	I-Review	1
Are they fair comparisons (evaluation only in terms of accuracy)?	Reply	O	0
Different methods expand the network different amount.	Reply	O	0
Hence, they should be compared on this metric too.	Reply	O	0
[line_break_token][line_break_token]As mentioned in the paper, we make sure that all methods use similar amount of parameters.	Reply	B-Reply	1
In particular, we make sure that all other methods at least match the number of parameters for our final model (after 10 tasks).	Reply	I-Reply	1
In other words, all compared methods has same or more capacity as compared to our model, and we believe this comparison represents a fair comparison.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that the expansion amount is also an important metric, and we will this metric in the final version	Reply	I-Reply	1

Summary: This paper proposes a technique for quantizing the weights and activations of a CNN.	Review	O	0
The main contribution is in replacing the heuristic to find good quantization intervals of (Zhu et al, 2016) with a different heuristic based on a hierarchical clustering algorithm, and empirically validating its effectiveness.	Review	O	0
[line_break_token][line_break_token]Strenghts:[line_break_token]- The proposed nested-means heuristic is simple and makes sense intuitively.	Review	O	0
[line_break_token]- The experiments on two modern architectures seem solid and demonstrate good empirical performance.	Review	O	0
[line_break_token][line_break_token]Weaknesses:[line_break_token]- The main weakness is the limited novelty of this paper.	Review	O	0
The proposed setup is almost identical to the one in (Zhu et al, 2016), except for the replacement of the heuristic to find quantization intervals with another one.	Review	B-Review	1
While the experiments demonstrate the empirical effectiveness of the method as a whole, what is missing is a direct, controlled comparison between the original heuristic and the proposed one.	Review	I-Review	1
Now it is hard to tell whether the accuracy increases are obtained through the proposed adaptation or because of other factors such as a better implementation or longer training.	Review	I-Review	1
[line_break_token]- In section 4, it is not made clear whether the activations are quantized according to the same scheme as the weights (apart from the issue of selecting a good clipping interval, which is addressed).	Review	O	0
[line_break_token]- The paper is a bit short on references, considering the many recent works on quantized neural networks.	Review	O	0
[line_break_token][line_break_token]Minor comments and questions:[line_break_token]- The wording is sometimes imprecise, making some arguments hard to follow.	Review	O	0
Two examples:[line_break_token]-- "Lowering the learning rate for re-training can diminish heavy changes in the weight distribution, at the cost of longer time to converge and the risk to get stuck at plateau regions, which is especially critical for trainable scaling factors"[line_break_token]-- "This approach is beneficial because it defines cluster thresholds which are influenced by large weights that were shown to play a more important role than smaller weights (Han et al.,	Review	O	0
2015b)"[line_break_token]- The title says "for compression and inference acceleration", so it would be nice if the paper reports some compression and timing metrics in the experiments section.	Review	O	0
[line_break_token]- The notation in section 3.1 overly complicated, could probably be simplified a bit for readability.	Review	O	0
[line_break_token]- Section 3.3: "However, having an additional hyperparameter t_i for each scaling factor alpha_i renders the mandatory hyperparameter tuning infeasible." -	Review	O	0
> From section 4.2 in (Zhu et al, 2016), I believe the constant factor t is shared across all layers, making it only a single hyperparameter.	Review	O	0
[line_break_token]- Last paragraph of section 4: "(Cai et al.,	Review	O	0
2017) experimentally showed that the pre-activation distribution after batch normalization are all close to a Gaussian with zero mean and unit variance.	Review	B-Review	8
Therefore, we propose to select a fixed clipping parameter gamma.". -	Review	I-Review	8
> But what about the activations *before* the batchnorm layer where the assumption of zero mean and unit variance does not hold?	Review	O	0
Many thanks for the detailed feedback, which helped us to (hopefully) improve the revised version of the paper[line_break_token][line_break_token]- Novelty: the difference you point out to (Zhu et al, 2016) is correct, we adopted the gradient-based scaling factors.	Reply	O	0
We evaluated several ways of obtaining the scaling factors but the approach of (Zhu et al, 2016) is the best performing.	Reply	B-Reply	1
Our contributions are as follows: (1) a novel clustering approach that achieves better performance and allows for configurable quantization levels without additional hyperparameters.	Reply	I-Reply	1
As a result, we achieve 2.6% better Top1 accuracy (Inception on ImageNet) for the ternary (2-bit encoding) representation.	Reply	I-Reply	1
The configurable quantization levels enables the quaternary (2-bit encoding) representation which achieves 3.8% better Top1 accuracy without increasing quantization footprint. (	Reply	I-Reply	1
2) Activation quantization by arguing about appropriate clipping intervals. (	Reply	I-Reply	1
3) An analysis of the inference workload using reduce-scale architecture that minimizes the number of multiplications and substantially reduces the amount of additions.	Reply	I-Reply	1
[line_break_token][line_break_token]- Comparison to (Zhu et al, 2016): as part of our result discussion we compare to (Zhu et al, 2016), with the same training parameters as for our quantization.	Reply	O	0
The accuracy we obtain is actually higher than the one reported in (Zhu et al, 2016), most likely because we used adaptive learning rate.	Reply	B-Reply	1
We hope that this methodology demonstrates the improvement of this quantization compared to prior work.	Reply	I-Reply	1
[line_break_token][line_break_token]- Activation quantization: we quantize activations differently to weights by a simple linear transformation, because non-uniform activations are extremely difficult to implement efficiently for inference.	Reply	O	0
We addressed this issue in the revised submission.	Reply	B-Reply	2
[line_break_token][line_break_token]- References: please refer to the general comments, where we discuss our limited selection due to space constraints.	Reply	O	0
[line_break_token][line_break_token]- Notation: we changed the notation to a less cluttered notation.	Reply	O	0
[line_break_token][line_break_token]- Hyperparameter t: this is correct, t is shared across all layers.	Reply	O	0
However, the number of hyper parameters increases if multiple quantization levels are used.	Reply	B-Reply	7
[line_break_token][line_break_token]- Batchnormalization: the output of the batchnorm layer is the input for the next convolution layer.	Reply	O	0
Hence, we don‚Äôt have to quantize activations *before* the batchnorm layer in order to accelerate convolutions.	Reply	B-Reply	8

The paper analyzes if enforcing internal-consistency for speaker-listener setup can (i) improve the ability of the agents to refer to unseen referents (ii) generalize for different communicative roles.	Review	O	0
The paper evaluates a transformer and arecurrent model modified with various sharing strategies on a single-turn reference game.	Review	O	0
Finally, the paper claims that results with self-play suggest that internal consistency doesn‚Äôt help (i) but improves cross-role performance for (ii).	Review	O	0
[line_break_token][line_break_token]As a reader, the paper doesn‚Äôt provide me a concrete finding which can help in designing future multi-agent systems.	Review	B-Review	3
Most of the results for the experiments (except self-play) don‚Äôt have a uniform signal across the board to deduce whether the internal-consistency works in all of the cases.	Review	I-Review	3
Most of the speaker-listener scenarios emerge in dialog based settings which are multi-turn and require agents to act both as speaker and listener.	Review	I-Review	3
Though paper advocates through some of its results that self-play is helpful in generalization across roles via internal-consistency, without multi-step experiments, qualitative and quantitative analysis of what is happening and why there is so much variation, the paper is weak in its current form.	Review	I-Review	3
Therefore, I recommend weak reject as my rating.	Review	I-Review	3
Below I discuss some of the concerns in detail:[line_break_token][line_break_token]Without multi-step evaluation, it is hard to gauge the extent to which self-play for internal consistency help in generalization of the roles.	Review	I-Review	3
For e.g., task from Das et.	Review	I-Review	3
al. (	Review	I-Review	3
2017) [1] provides a clear signal on how well the agents are able to communicate through dialog evaluation.	Review	I-Review	3
So in 5.2.1, the setup which requires training in both roles can provide better signal overall if it was trained to do multi-step conversation.	Review	I-Review	3
[line_break_token][line_break_token]Paper is missing any kind of quantitative or qualitative analysis.	Review	I-Review	1
What are the differences between the embeddings of the agent that learned via self-play and the one which learned directly.	Review	I-Review	1
It also be interesting to see how the shared embeddings and symmetric encoding and decoding affect these embedding and might help explain the drop and randomness.	Review	I-Review	1
In Table 4.,	Review	I-Review	1
the results on symmetric encoding suggest that the claim of generalization through internal consistency might not hold everywhere.	Review	I-Review	1
For Shared Embedding results, on RNN shapes, it is surprising that training in one role improves performance through internal consistency while in both roles it drops.	Review	I-Review	2
These require further analysis to solidify the claim.	Review	I-Review	2
Given the flaky results, to boost the claim, have authors tried other settings to test internal-consistency like Predator-Prey?	Review	I-Review	2
[line_break_token][line_break_token]Things that didn‚Äôt affect the score:[line_break_token][line_break_token]Related work section is missing the relevant discussion on continuous communication work and discussion on why internal consistency wasn‚Äôt tested on those settings as well. (	Review	O	0
See Singh et.al [2]., Sukhbaatar et.al. [	Review	B-Review	4
3], Das et.al. [	Review	I-Review	4
4] etc)[line_break_token][line_break_token]The number of pages are above eight, you should reduce the redundancy between table descriptions and text and maybe squeeze Section 2, decrease setup explanation.	Review	O	0
[line_break_token][line_break_token]The setup for training and test sets explained at the end of page 7 isn‚Äôt very clear to me and needs to be rephrased.	Review	B-Review	6
[line_break_token][line_break_token][1] Das, Abhishek, Satwik Kottur, Jos√© MF Moura, Stefan Lee, and Dhruv Batra. "	Review	O	0
Learning cooperative visual dialog agents with deep reinforcement learning."	Review	O	0
In Proceedings of the IEEE International Conference on Computer Vision, pp.	Review	O	0
2951-2960.	Review	O	0
2017.	Review	O	0
[line_break_token][2] Sukhbaatar, Sainbayar, and Rob Fergus. "	Review	O	0
Learning multiagent communication with backpropagation."	Review	O	0
In Advances in Neural Information Processing Systems, pp.	Review	O	0
2244-2252.	Review	O	0
2016.	Review	O	0
[line_break_token][3] Singh, Amanpreet, Tushar Jain, and Sainbayar Sukhbaatar. "	Review	O	0
Learning when to communicate at scale in multiagent cooperative and competitive tasks."	Review	O	0
arXiv preprint arXiv:1812.09755 (2018).	Review	O	0
[line_break_token][4] Das, Abhishek, Th√©ophile Gervet, Joshua Romoff, Dhruv Batra, Devi Parikh, Michael Rabbat, and Joelle Pineau. "	Review	O	0
Tarmac: Targeted multi-agent communication."	Review	O	0
arXiv preprint arXiv:1810.11187 (2018).	Review	O	0
[line_break_token][line_break_token]=========[line_break_token]Post-rebuttal Comments[line_break_token]=========[line_break_token]Thanks for updating the manuscript to resolve my and R2's concerns.	Review	O	0
The new analysis section does provide good insights into what exactly is happening.	Review	O	0
[line_break_token][line_break_token]When I was talking about actionable insights, I was talking about both negative and positive insights.	Review	O	0
Currently, the only take-away is that self-play helps in generalizing to listener roles as well.	Review	O	0
For the other negative insight that internal consistency doesn't help with generalization, as R2 suggested, it is unclear why that would be case in the first place (I read the pscyhology arguments, but I am not still not convinced).	Review	B-Review	2
I still believe that without multi-step communication, the work is as useful as it can be in current form.	Review	I-Review	3
In real world, no meaningful conversation is usually one step.	Review	I-Review	3
[line_break_token][line_break_token]For Predator-Prey setup, I was talking about OpenAI <a href="https://github.com/openai/multiagent-particle-envs" target="_blank" rel="nofollow">https://github.com/openai/multiagent-particle-envs</a> in which multiple tasks can be setup.	Review	O	0
For e.g. if prey thinks of what action predator might take, does internal consistency help prey to perform better?	Review	B-Review	2
[line_break_token][line_break_token]I think most of what you got is correct for multi-step, see second para for more details in this response.	Review	O	0
[line_break_token][line_break_token]Thanks for bringing the manuscript under 8 pages. [	Review	O	0
3] is still missing from references.	Review	O	0
[line_break_token][line_break_token]Final comments: I would like to see multi-step experiments due to the reasons I explained above.	Review	O	0
The scheme of internal-consistency should be applicable beyond conversation to Predator-Prey setups also, thus, I feel experiments are not enough (only on 1 setting) to claim generalization of the hypothesis.	Review	B-Review	3
Beyond these comments, I feel this is still a step in right direction and I would like to update my rating to weak accept while hoping that authors try to address these issues in camera-ready version if paper gets accepted.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
lease see our general reply to all reviewers above, as we reply to many of your points there.	Reply	O	0
We also added several new analysis to the paper in reply to your comments; these can be found in Section 6 of the updated draft.	Reply	O	0
In addition, we provide several direct replies to your comments below.	Reply	O	0
[line_break_token][line_break_token]* Why no multi-step communication?	Reply	O	0
[line_break_token][line_break_token]We understand your concern about not using multi-step communication as follows: the agents may behave similarly to agents that self-play if they had to act over multiple turns and correspondingly ‚Äî as part of the game itself ‚Äî both speak and listen.	Reply	B-Reply	3
[line_break_token][line_break_token]This is a great idea and may extend the range of the results.	Reply	I-Reply	3
We‚Äôd love to pursue something along these lines in future work.	Reply	I-Reply	3
As a starting point, we chose to focus on tasks like reference games, with an applied setting of instruction-following robots.	Reply	I-Reply	3
In these contexts, there are often no follow ups to ‚Äúget me my coffee cup‚Äù or ‚ÄúI‚Äôd like to buy that red sweatshirt‚Äù other than proffering the predicted item within the context.	Reply	I-Reply	3
Given that real interactions with humans are expensive (much more so than self-play), it would be beneficial if learning agents could leverage pre-existing data and self-play in order generalize to untrained roles.	Reply	I-Reply	3
We did not flesh out this viewpoint because this work does not fully extend into this setting, but your concerns suggest that we should have clarified this.	Reply	I-Reply	3
[line_break_token][line_break_token]* What are the differences between the embeddings of the agent that learned via self-play and the one which learned directly? (	Reply	O	0
e.g more qualitative and quantitative analysis!)	Reply	O	0
[line_break_token][line_break_token]We did not heavily inspect the embeddings of the agents, however we did add a section (now Section 6) of additional qualitative and quantitative analysis that inspects the efficacy of selplay, the agents‚Äô communication, and finally, shows the lexicon the agent‚Äôs produced.	Reply	B-Reply	1
[line_break_token][line_break_token]* For Shared Embedding results, on RNN shapes, it is surprising that training in one role improves performance through internal consistency while in both roles it drops.	Reply	O	0
Why?	Reply	O	0
[line_break_token][line_break_token]It appears that the additional signal does not provide useful information to the agents: perhaps the resultant protocols do not utilize the lexicon developed by the agents in the original role.	Reply	B-Reply	2
This would be the case if there were a one-to-one mapping between features and symbols (or something like this).	Reply	I-Reply	2
In the new analysis section (Section 6), we inspect this further.	Reply	I-Reply	2
[line_break_token][line_break_token]* Follow up[line_break_token]- Can you elaborate the mentioned predator-prey setting (or point us in the direction you were thinking of)?	Reply	O	0
[line_break_token]- Is our interpretation of your concern with multi-step games correct?	Reply	O	0
[line_break_token]- Thank you for highlighting additional related work and for stressing the 8-pages.	Reply	O	0
We worked to amend the report to address both of these concerns.	Reply	B-Reply	6

This paper proposed a new pre-trained language model based on BERT, called StructBERT.	Review	O	0
The key contributions are the two new pre-train objectives, (1) word structural objective, where the goal is to reconstruct the right order of intentionally shuffled word tokens, and (2) sentence structural objective, a three-class sentence-pair prediction, either the 2nd sentence precedes the 1st, the 2nd succeeds the 1st, or the 2nd is randomly selected.	Review	O	0
Unlike the original NSP (next sentence prediction) task, which is simple but tends out to be not so helpful in many downstream tasks, both proposed pre-train objectives seem to be rather useful in benchmarks tested in the paper, including GLUE, SNLI, and SQuAD.	Review	O	0
[line_break_token][line_break_token]The paper is well written and understandable for anyone who has a basic background about BERT or pre-train.	Review	O	0
The experimental results are impressive.	Review	O	0
Some of my questions / suggestions:[line_break_token][line_break_token]- The two auxiliary tasks are evidently helpful.	Review	O	0
I wonder what intuition/theory leads to the selection of these two tasks?	Review	B-Review	1
If the authors have test multiple other tasks that were not as helpful, it is also interesting to know them.	Review	I-Review	1
[line_break_token][line_break_token]- The wording of the text should be revised to reflect the up-to-date leaderboard results.	Review	O	0
Personally, I don't think the leaderboard results are that critical, but just want to make sure the writing is accurate at the time of publishing.	Review	B-Review	2
[line_break_token][line_break_token]- Please also update the results from SQuAD 1.1 CodaLab.	Review	O	0
hank you so much for going through the paper carefully and providing such a positive feedback.	Reply	O	0
Please see below our response to your comments:[line_break_token][line_break_token]C1.	Reply	O	0
The intuition of word ordering task is from the task of Grammatical error correction, while the intuition of sentence ordering task is inspired from the discourse-level coherence property and causal relationship between the natural  sentences.	Reply	B-Reply	1
Yes, we have also tested some other tasks: 1) mask only entities or nouns, 2) increase the mask rate, 3) predict the next sentence, nonadjacent sentence in the same document, and random sentence from another document.	Reply	I-Reply	1
But we did not observe more improvement.	Reply	I-Reply	1
[line_break_token][line_break_token]C2.	Reply	O	0
We agree with the reviewer about this and it has been fixed accordingly.	Reply	B-Reply	2
[line_break_token][line_break_token]C3.	Reply	O	0
We have been in touch with SQuAD's administrator to evaluate our submitted model and update its score on the leaderboard.	Reply	B-Reply	3
This process involves much manual effort from both us and the administrator.	Reply	I-Reply	3
We have not got the updated score from the administrator yet.	Reply	I-Reply	3
We will update our results on SQuAD upon receipt	Reply	I-Reply	3

# 1.	Review	O	0
Summary[line_break_token]The paper introduces a pre-training procedure for visual-linguistic representations.	Review	O	0
The model is an extension of BERT (with transformer backbone) to deal with visual input.	Review	O	0
Images are encoded using object detectors which regions are masked at pixel level.	Review	O	0
Experiments show state-of-the-art results on different downstream tasks.	Review	O	0
   [line_break_token][line_break_token]Strengths of the paper:[line_break_token]* State-of-the-art results on 3 vision-language tasks[line_break_token]      [line_break_token]The weak reject decision was mainly guided by the following two weaknesses of the paper:[line_break_token]* Clarity of the paper needs to be improved to make the readers understanding the details of the model (see point 2 below)[line_break_token]* Limited novelty: the paper is an extension of BERT to the visual domain (see point 3 below)[line_break_token][line_break_token]      [line_break_token]# 2.	Review	O	0
Clarity[line_break_token]The paper reads quite well, although some points need to be improved:[line_break_token]* How were words split in sub-words (Sec 3.2)?	Review	O	0
     [line_break_token]* "For each input element, its embedding feature is the summation of four types of embedding, ...": it is not clear how you sum embeddings.	Review	O	0
E.g., token embedding has 30k dimensions while image one has 2048 dimensions.	Review	B-Review	3
[line_break_token]* "It is attached to each of the input elements, which is the output of a fully connected layer taking the concatenation of visual appearance feature and visual geometry embedding as input" -&gt; this is not clear; what output are we talking about?	Review	O	0
What is the geometry embedding?	Review	B-Review	4
I suggest to describe the two features first and then say at the end of the paragraph that the representation is the concatenation.	Review	I-Review	4
[line_break_token]* "For the non-visual elements, the corresponding visual appearance features are of features extracted on the whole input image" -&gt; what is the intuition of having the full image here?	Review	O	0
Some terms do not need to have an image associated (e.g., verbs or articles).	Review	B-Review	5
Do you take care somehow of that?	Review	I-Review	5
[line_break_token]* Once textual embeddings are masked by [MASK], the related visual embedding (whole image) is also masked?	Review	O	0
To my understanding the answer is no: what's the intuition of this?	Review	B-Review	6
[line_break_token]* Segment embedding: is this important?	Review	O	0
This should be easy to show with an experiment in the ablation study of Table 4?	Review	B-Review	7
[line_break_token]* It seems that there is a semantic asymmetry of input to the loss during training when considering only the text information (bookscorpus) and the image-text information (conceptual captions): how is training coping with this?	Review	O	0
Doesn't it make more sense to have 2 pre-training phases: first on text information only and then on image-text information?	Review	B-Review	8
[line_break_token][line_break_token][line_break_token]# 3.	Review	O	0
Novelty and Motivation[line_break_token]The novelty of the paper is quite limited.	Review	O	0
It strongly relies on transformer networks and then recent success of BERT in the NLP domain.	Review	B-Review	1
The proposal is an extension of these two ideas to visual domain.	Review	I-Review	1
[line_break_token][line_break_token]Moreover, there is a body of concurrent work that is very similar to the proposed idea with slight differences (ViLBERT, VisualBERT, LXBERT, UNITER, B2T2), i.e., using transformers with masking operation on the RoIs.	Review	I-Review	1
It is not clear what is the intuition related to the differences between the methods, i.e.[line_break_token]* Why one is better than the other; why should someone prefer this pre-training technique wrt others?	Review	I-Review	1
[line_break_token]* Why a unified network (this work) is preferred wrt a two-stream one (ViLBERT, LXMERT)?	Review	I-Review	1
[line_break_token]It seems that everything heavily depends on the experiments and empirical results obtained by trying many variants during the prototyping phase.	Review	I-Review	1
It is missing a bit of understanding and intuition on the reasons why this technique should be used.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]# 4.	Review	O	0
Experimentation[line_break_token]Experiments are the strength of the paper showing state-of-the-art results on 3 vision-language tasks.	Review	O	0
Some additional analysis is missing:[line_break_token]* If masking is conducted on the raw pixel, this makes training much slower since you need to perform inference many times.	Review	O	0
What is the impact in terms of accuracy?	Review	B-Review	9
Did you carried out an experiment showing that it is better to mask raw pixels instead of conv maps?	Review	I-Review	9
[line_break_token]* How long is the model trained for?	Review	I-Review	9
[line_break_token]* What is the performance/accuracy on the pre-training tasks?	Review	I-Review	9
[line_break_token]* How important is the segment embedding?	Review	I-Review	9
[line_break_token]* Footnote 2 should be in the main text (Sec 4.1).	Review	I-Review	9
It is too hidden, but very important to let the reader knowing about it.	Review	I-Review	9
[line_break_token]	Review	O	0
e feel we can well address the concerns of R#3, and hope R#3 give a second thought about the paper.	Reply	O	0
[line_break_token][line_break_token]Q#1: Concerns about novelty.	Reply	O	0
[line_break_token][line_break_token]A#1: First of all, the existence of concurrent works does not hurt the novelty of our method.	Reply	O	0
And it should not be a reason for rejecting the paper.	Reply	B-Reply	1
One cannot forecast what other research groups are doing when he/she conducts his/her own research.	Reply	I-Reply	1
[line_break_token][line_break_token]For better understanding of the readers, we even tried our best in comparing all the concurrent works in Related Works and in Appendix.	Reply	I-Reply	1
The unique advantage of our work compared to other concurrent ones is presented at the end of Section 2.	Reply	I-Reply	1
We quote the comments of R#1 here, ‚ÄúThe paper does a decent job mentioning all the concurrent work in the space of learning multi-modal representations that have come out very recently.	Reply	I-Reply	1
‚Äù[line_break_token][line_break_token]In terms of comparison with BERT, we admit VL-BERT is an extension to the original BERT model.	Reply	I-Reply	1
But it is non-trivial to extend BERT, designed for NLP tasks, to become a generic representation for visual-linguistic tasks.	Reply	I-Reply	1
[line_break_token][line_break_token]From the technology contribution perspective, numerous design choices are involved in VL-BERT for incorporating the visual information.	Reply	I-Reply	1
It is interesting to note that in the previous work of VideoBERT, straight-forward design choices are made by directly turning video clips into visual words.	Reply	I-Reply	1
The derived model is far from optimal.	Reply	I-Reply	1
Our VL-BERT is well-designed to be: 1) a unified single-stream architecture, while also benefiting from single-modal pre-trained BERT and Fast R-CNN models; 2) end-to-end trainable with both the visual and linguistic branch parameters; 3) joint trained on both visual-linguistic and text-only corpus, so as to alleviate catastrophic forgetting [Kirkpatrick et.	Reply	I-Reply	1
al.,	Reply	I-Reply	1
``Overcoming catastrophic forgetting in neural networks.	Reply	I-Reply	1
‚Äù PNAS, 2017.]	Reply	I-Reply	1
of the text-only corpus in training networks for visual-linguistic tasks.	Reply	I-Reply	1
[line_break_token][line_break_token]From the practical importance perspective, we derived generic representations for various visual-linguistic tasks, which can be pre-trained on large-scale datasets.	Reply	I-Reply	1
While previously various networks were designed specifically for different visual-linguistic tasks.	Reply	I-Reply	1
The related discussions can be found in the Introduction and Related Works sections in the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]Q#2: Concerns with clarity.	Reply	O	0
[line_break_token][line_break_token]A#2: In general, we feel many questions raised are because the topic is at the intersection of computer vision and NLP, with much preliminary knowledge involved.	Reply	O	0
Such preliminary knowledge is self-explanatory in the corresponding domain but is unfamiliar for others.	Reply	O	0
[line_break_token][line_break_token](a)[tab_token]`` How were words split in sub-words?‚Äù[line_break_token]The sub-words split is by WordPiece embeddings, which is a standard practice in NLP.	Reply	O	0
For details, please refer to [Wu, Yonghui, et al. "	Reply	B-Reply	2
Google's neural machine translation system: Bridging the gap between human and machine translation."	Reply	I-Reply	2
arXiv preprint 2016.]	Reply	I-Reply	2
[line_break_token][line_break_token](b)[tab_token]Questions about token embedding.	Reply	O	0
[line_break_token]The token embedding is different from one-hot word embedding (e.g., 30k dim).	Reply	B-Reply	3
It is of much lower dim (e.g., 768-d).	Reply	I-Reply	3
The visual embedding is projected into the same dimension using a fully-connected layer as shown in Figure 1.	Reply	I-Reply	3
[line_break_token][line_break_token](c)[tab_token]To describe the two features first.	Reply	O	0
[line_break_token]Thanks for the suggestion.	Reply	O	0
We would rearrange the paragraph in revision.	Reply	B-Reply	4
[line_break_token][line_break_token](d)[tab_token]What is the intuition of having the whole image embedding for textual input?	Reply	O	0
[line_break_token]To provide visual context for the sentence words.	Reply	B-Reply	5
[line_break_token][line_break_token](e)[tab_token]Once textual embeddings are masked by [MASK], the related whole image embedding is also masked?	Reply	O	0
[line_break_token]No, only textual embeddings are masked to block the linguistic input information.	Reply	B-Reply	6
[line_break_token][line_break_token](f)[tab_token]Is segment embedding important?	Reply	O	0
[line_break_token]Yes, as in BERT, the segment embedding is used to distinguish different input formats.	Reply	B-Reply	7
[line_break_token][line_break_token](g)[tab_token]How is training coping with the loss during training when considering text-only corpus and conceptual captions?	Reply	O	0
[line_break_token]There is no special treatment for the loss during training.	Reply	B-Reply	8
The loss of Task #1 is averaged over the number of masked tokens.	Reply	I-Reply	8
And the loss of Task #2 is averaged over the number of masked regions.	Reply	I-Reply	8
[line_break_token][line_break_token](h)[tab_token]Doesn't it make more sense to have 2 pre-training phases.	Reply	O	0
[line_break_token]Our experiments without Text-only Corpus is actually the ‚Äò2 pre-training phases‚Äô suggested by R#3.	Reply	B-Reply	8
This is because our VL-BERT is initialized from a text-only pre-trained BERT.	Reply	I-Reply	8
In our full version of VL-BERT, we train VL-BERT on visual-linguistic datasets together with text-only corpus.	Reply	I-Reply	8
This is for alleviating catastrophic forgetting of the text-only corpus in training networks for visual-linguistic tasks.	Reply	I-Reply	8
[line_break_token][line_break_token]Q#3: Questions about experimentation.	Reply	O	0
[line_break_token][line_break_token]A#3: We address one question due to space limit.	Reply	O	0
[line_break_token][line_break_token](a)[tab_token]Masking on raw pixels.	Reply	B-Reply	9
[line_break_token]The masking would not slow down training.	Reply	I-Reply	9
In a mini-batch, given an image, some RoIs are randomly sampled to be masked ones.	Reply	I-Reply	9
The pixels lying in all the masked RoIs are set as zeros in the image at once.	Reply	I-Reply	9
While the training loss drives the network to predict the labels of all the masked RoIs.	Reply	I-Reply	9
[line_break_token][line_break_token]As for masking conv maps, we observe obvious overfitting due to information leakage.	Reply	I-Reply	9

This paper proposes a multi-agent hierarchical reinforcement learning algorithm so that multiple humanoid robots can navigate in multi-agent settings (e.g. avoid collisions, collaboration, chase and escape) in a physically simulated environment.	Review	O	0
The key difference of this paper with the prior work on MARL is that it used an accurate physics simulation of humanoid robots.	Review	O	0
This is the main reason of using the hierarchical RL.	Review	O	0
[line_break_token][line_break_token]In general, I like this paper.	Review	O	0
It is an important step towards multi-agent learning in complex physical environments.	Review	O	0
The results look appealing, too.	Review	O	0
However, I voted for "Weak Reject" for two reasons.	Review	O	0
First, the technical contribution is lean.	Review	B-Review	1
Neither the multi-agent learning or the hierarchical learning of the algorithm is novel.	Review	I-Review	1
The combination of these two methods seems straightforward.	Review	I-Review	1
Once a low-level walking controller is trained, the high-level multi-agent navigation control is not much different from simple environments, e.g. point mass control, used in the previous works.	Review	I-Review	1
I do not understand the "deep integration of MARL and HRL" that is claimed in the Introduction.	Review	I-Review	1
I also do not agree with another claim that "We consider the simulation and training environment to be another novel contribution... few simulator support more than one agent, at most 2".	Review	I-Review	1
In most of the simulators that I am familiar with, such as Mujoco, Bullet, DART, it is straightforward to add multiple simulated robots.	Review	I-Review	1
[line_break_token][line_break_token]Second, the writing can be greatly improved.	Review	I-Review	2
Almost half of the technical details are buried in "8.	Review	I-Review	2
Supplementary material".	Review	I-Review	2
Since it is not fair to use "Supplementary material" as a way to extend the page limit, I will make my judgement of the paper solely based on the contents up to Section 7.	Review	I-Review	2
In the main text (up to Section 7), there is no mentioning of how the low-level controllers are learned, and how to combine PPO in a MARL partial parameter sharing setting.	Review	I-Review	2
I think that these are important details and may also be the contributions of this paper.	Review	I-Review	2
Most of these should be moved to the main text.	Review	I-Review	2
[line_break_token][line_break_token]Here are some more suggestions on writing:[line_break_token]1) Certain paragraphs in the main text can be significantly shortened, such as the reward shaping in Section 5.2.	Review	O	0
[line_break_token]2) It would be great if the paper can clearly define the experiments: "waypoint", "oncoming", "mall", and "bottleneck".	Review	O	0
[line_break_token]3) The paper needs a thorough proof-reading.	Review	O	0
There are many grammar mistakes, typos, missing citations.	Review	B-Review	2
For example,[line_break_token]promiss-&gt;promise[line_break_token]week signal-&gt;weak signal[line_break_token]missing citation [?]	Review	O	0
in page 3[line_break_token]reuse the same symbol v_{com} for agent's velocity and desired speed in eq(3)[line_break_token]	Review	B-Review	2
e appreciate your time and comments on the work.	Reply	B-Reply	1
While the method is the first to be applied to a multi-agent simulation with articulated humanoid character, our main contribution is a method to allow sophisticated controllers to be learned in this case.	Reply	I-Reply	1
Our unique combination of structured learning enables the learning of strong polices without incredible amounts of computing time (cite openAI Emergent Tool Use from Multi-Agent Interaction).	Reply	I-Reply	1
We also argue that the learning and control problem for the high-level policies is more complicated than a ‚Äúpoint mass‚Äù environment.	Reply	I-Reply	1
The high level needs to learn strategies to cope with a dynamic simulation that includes, pushes, slips, balancing, etc, all through the capabilities of a low-level policy while optimizing a goal-seeking objective.	Reply	I-Reply	1
This simulation environment it also novel in that no other simulation has put multiple dynamic humanoid agents in a simulation that observe each other using egocentric vision.	Reply	I-Reply	1
In other simulation libraries, it is possible to add more agents, but no tasks have been constructed or learned that match the complexity in this work.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that the paper writing can be improved.	Reply	I-Reply	2
Significant edits to the paper have been made to make the method and its contribution more clear.	Reply	I-Reply	2
These edits include moving the details for training the goal-conditioned low-level controller to the main paper, including adding a new task for 2-on-2 soccer for which MAHRL has shown significant progress on learning.	Reply	I-Reply	2

This work introduces a novel method for training GANs by displacing simultaneous SGD, and unrolling the inner optimization in the minmax game as a computational graph.	Review	O	0
The paper is very clearly written, and explains the justification very well.	Review	O	0
The problem being attacked is very significant and important.	Review	O	0
The approach is novel, however, similar ideas have been tried to solve problems unrelated to GANs.	Review	B-Review	1
[line_break_token][line_break_token]The first quantitative experiment is section 3.3.1, where the authors attempt to find the best z which can generate training examples.	Review	O	0
This is done by using L-BFGS on |G(z) - x|. The claim is that if we're able to find such a z, then the generator can generate this particular training example.	Review	O	0
It's demonstrated that 0-step GANs are not able to generate many training examples, while unrolled GANs do.	Review	O	0
However, I find this experiment unreasonable.	Review	B-Review	2
Being able to find a certain z, which generates a certain sample does not guarantee that this particular mode is high probability.	Review	I-Review	2
In fact, an identity function can potentially beat all the GAN models in the proposed metric.	Review	I-Review	2
And due to Cantor's proof of equivalence between all powers of real spaces, this applies to smaller dimension of z as well.	Review	I-Review	2
More realistically, it should be possible to generate *any* image from a generator by finding a very specific z. That a certain z exists which can generate a sample does not prove that the generator is not missing modes.	Review	I-Review	2
It just proves that the generator is similar enough to an identity function to be able to generate any possible image.	Review	I-Review	2
This metric is thus measuring something potentially tangential to diversity or mode-dropping.	Review	I-Review	2
Another problem with this metric is that that showing that the optimization is not able to find a z for a specific training examples does not prove that such a z does not exist, only that it's harder to find.	Review	I-Review	2
So, this comparison might just be showing that unrolled GANs have a smoother function than 0-step GANs, and thus easier to optimize for z.[line_break_token][line_break_token]The second quantitative experiment considers mean pairwise distance between generated samples, and between data samples.	Review	O	0
The first number is likely to be small in the case of a mode-dropping GAN.	Review	B-Review	3
The authors argue that the two numbers being closer to each other is an indication of the generated samples being as diverse as the data.	Review	I-Review	3
Once again, this metric is not convincing.	Review	I-Review	3
1.	Review	I-Review	3
The distances are being measured in pixel-space.	Review	I-Review	3
2.	Review	I-Review	3
A GAN model could be generating garbage, and yet still perform very well in this metric.	Review	I-Review	3
[line_break_token][line_break_token]There are no other quantitative results in the paper.	Review	I-Review	4
Even though the method is optimizing diversity, for a sanity check, scores for quality such as Inception scores or SSL performance would have been useful.	Review	I-Review	4
Another metric that the authors can consider is training GAN using this approach on the tri-MNIST dataset (concatenation of 3 MNIST digits), which results in 1000 easily-identifiable modes.	Review	I-Review	4
Then, demonstrate that the GAN is able to generate all the 1000 modes with equal probability.	Review	I-Review	4
This is not a perfect metric either, but arguably much better than the metrics in this paper.	Review	I-Review	4
This metric is used in this ICLR submission: <a href="https://openreview.net/pdf?id=HJKkY35le" target="_blank" rel="nofollow">https://openreview.net/pdf?id=HJKkY35le</a>[line_break_token][line_break_token]Whether this paper is accepted or not, I encourage the authors to investigate this approach further, since the method is promising and interesting.	Review	O	0
[line_break_token][line_break_token]# Post-rebuttal review[line_break_token][line_break_token]The authors have incorporated changed in the paper by adding more experiments.	Review	O	0
These experiments now demonstrate the claims of the paper better.	Review	O	0
The paper was already well-written and introduced a novel idea and addressed an important problem.	Review	O	0
The only thing holding this paper back was unconvincing experiments, which now has been corrected.	Review	B-Review	5
Thus, I would increase my score by 2 points, and recommend accepting the paper.	Review	I-Review	5
Thank you for your review, and for your specific suggestions for improving our analysis!	Reply	O	0
We have performed additional experiments as you suggest, including on the tri-MNIST dataset.	Reply	O	0
This has significantly improved the quantitative portion of our paper, and we hope you will raise your score as a result.	Reply	O	0
[line_break_token][line_break_token]You make a good point on the difficulty of interpreting the results of the optimization-based inference.	Reply	B-Reply	1
Approaches similar to this have recently been used in several applications [1,2,3], so we are not alone in our choice.	Reply	I-Reply	1
We believe the results are strongly suggestive of the learned models more completely covering the image manifold, but we are not able to rule out unrolling smoothing the loss landscape.	Reply	I-Reply	1
[line_break_token][line_break_token]‚ÄúMore realistically, it should be possible to generate *any* image from a generator by finding a very specific z.	Reply	I-Reply	2
‚Äù: In current GAN architectures, z-space is actually far lower dimensional than x-space.	Reply	I-Reply	2
As a result (barring edge cases with large fractal dimension), the manifold of achievable images does not fill x-space, and in general there is no z vector that can exactly reconstruct an image.	Reply	I-Reply	2
Depending on the learned generator, it will therefore be possible to reconstruct some images with lower error than others.	Reply	I-Reply	2
[line_break_token][line_break_token]The pairwise distance histogram could be matched by a high entropy sampling distribution that did not match the data.	Reply	I-Reply	3
However, the combination of high quality samples and large pairwise distances do lead to a meaningful metric of diversity.	Reply	I-Reply	3
Furthermore, we optimize the GAN to match the data distribution not to match pairwise distances, and this correspondence is unlikely to happen purely by chance.	Reply	I-Reply	3
This metric additionally bears resemblance to commonly used non-parametric estimates of entropy using nearest neighbors.	Reply	I-Reply	3
[line_break_token][line_break_token]Alternative metrics like the inception score suffer from similar flaws: if the generated samples are all from a single class it can have a high inception score (the distribution over classes will be peaked at that one class for all samples) but very poor sample diversity (the generator only produces one class) (see also Odena et al.	Reply	I-Reply	4
‚Äôs ICLR submission[4]).	Reply	I-Reply	4
[line_break_token][line_break_token]Thank you for suggesting the tri-MNIST dataset, and the associated analysis technique of counting the discrete modes covered.	Reply	I-Reply	5
This is a particularly appealing approach, since it allows us to directly measure the property of interest, on a (nonlinear) projection of the model distribution.	Reply	I-Reply	5
We tested unrolled GANs on this task, and found that they consistently cover more modes than standard GANs.	Reply	I-Reply	5
To address the issue of mode collapse for continuous manifolds, we additionally introduced a new colored MNIST dataset, where we can measure the extent to which the generated samples match the continuous distribution of colors.	Reply	I-Reply	5
We have updated the paper to include these results (see Section 3.4).	Reply	I-Reply	5
[line_break_token][line_break_token]Thank you again for your feedback!	Reply	O	0
[line_break_token][line_break_token][1] <a href="https://arxiv.org/abs/1609.07093" target="_blank" rel="nofollow">https://arxiv.org/abs/1609.07093</a>[line_break_token][2] <a href="https://arxiv.org/abs/1609.03552" target="_blank" rel="nofollow">https://arxiv.org/abs/1609.03552</a>[line_break_token][3] <a href="https://arxiv.org/abs/1605.09304" target="_blank" rel="nofollow">https://arxiv.org/abs/1605.09304</a>[line_break_token][4] <a href="https://arxiv.org/abs/1610.09585" target="_blank" rel="nofollow">https://arxiv.org/abs/1610.09585</a	Reply	O	0

This paper presents works on neural network / CNN architecture morphing.	Review	O	0
[line_break_token]Results are not reported on ImageNet larger ResNet and new network architecture such as Xception and DenseNet - which are maybe too new!	Review	B-Review	1
Also most results are reported in small datasets and network, which do not offer confidence in the usability in production systems.	Review	I-Review	1
[line_break_token]My biggest issue is that computational time and effort for these techniques is not mentioned in detail.	Review	I-Review	2
We always want to be able to quantify the extra effort of understanding and using a new technique, especially if the results are minor.	Review	I-Review	2
We appreciate the recognition and detailed comments from Reviewer #1, and have the following responses to address the concerns.	Reply	O	0
[line_break_token][line_break_token]1) ‚ÄúResults are not reported on ImageNet larger ResNet and new network architecture such as Xception and DenseNet - which are maybe too new!	Reply	O	0
Also most results are reported in small datasets and network, which do not offer confidence in the usability in production systems.	Reply	O	0
‚Äù[line_break_token][line_break_token]In Section 4.4, we reported the results of the morphed network morph18_1c1 and the original ResNet-18 on ImageNet.	Reply	O	0
In the updated version, we also added the results of the original and morphed 34-layer networks on ImageNet.	Reply	B-Reply	1
These results are consistent with an absolute performance improvement of 1% and a relative improvement up to 4%.	Reply	I-Reply	1
The results of the 34-layer network were added in the second paragraph of Section 4.4, Table 5, and Fig.	Reply	I-Reply	1
6.	Reply	I-Reply	1
[line_break_token][line_break_token]As for the newly proposed network architectures, definitely, it would be better if we are able to provide comparison results with all state-of-the-art networks beyond residual networks.	Reply	I-Reply	1
However, in this paper, we target at introducing a general learning scheme, instead of a specific neural network model.	Reply	I-Reply	1
Owning to the strict definition of this learning scheme and the proposed morphing algorithms, it has potential to build a more powerful model based on an (arbitrary) existing parent network.	Reply	I-Reply	1
Due to the computational resource limitation, we decided to select the residual networks, the most representative network architecture, as the parent network to morph.	Reply	I-Reply	1
[line_break_token][line_break_token]2) ‚ÄúMy biggest issue is that computational time and effort for these techniques is not mentioned in detail.	Reply	O	0
We always want to be able to quantify the extra effort of understanding and using a new technique, especially if the results are minor.	Reply	O	0
‚Äù[line_break_token][line_break_token]It has been verified in our previous work [Wei2016] that VGG16 could be easily morphed into a 19-layer network (NetMorph-VGG16), with a 15x speedup compared with training from scratch. (	Reply	O	0
NetMorh-VGG16 performed better than both VGG16 and VGG19.)	Reply	B-Reply	2
In this research, we are expecting to use a minimal extra cost to achieve a maximum possible performance improvement.	Reply	I-Reply	2
As shown in Table 1 and 3, both the number of parameters and the computational cost (measured in FLOP) of the morphed models are only slightly larger than the original models (around 1.1x), yet with noticeable performance improvements (absolute performance improvements up to 2% and relative performances up to 20%).	Reply	I-Reply	2
In this work, our focus is to study the macroscopic problem of network morphism, i.e., modularized morphing.	Reply	I-Reply	2
Thus we adopted a uniform training procedure for both of these two learning schemes.	Reply	I-Reply	2
Therefore, the training time for network morphism is the same as training from scratch in this research.	Reply	I-Reply	2
But the training can be greatly speeded up as in [Wei2016], which however is not our focus in this research.	Reply	I-Reply	2

Paper Claims[line_break_token][line_break_token]The paper offers a new deep learning approach to symbolic reasoning over text.	Review	O	0
They propose using Neural Module Networks to perform explicit reasoning steps that are nevertheless differentiable.	Review	O	0
The process is separated into a semantic parsing of the question, and a resolution using MNMs.	Review	O	0
Auxiliary tasks improve performance and enable using a BERT pretrained model as a seed.	Review	O	0
The proposed model's performance surpasses previous SOTA on several question types.	Review	O	0
[line_break_token][line_break_token]Decision[line_break_token][line_break_token]I'm in favor of accepting this paper because it tackles an extremely challenging and important problem in a novel and successful way.	Review	O	0
Reasoning has progressed more slowly than other NLP domains, and answering complex multi-reasoning-step questions is a good way to tackle the core of the problem.	Review	O	0
Regarding the approach, I find the mix of explicit reasoning steps, deep learning modeling, and even heuristics for some of the data preparation, powerful and effective.	Review	O	0
I see this as a useful step to advance the body of work in this space -- despite not being the desired end-result, it is nevertheless very instructive of what might work for at least some parts of the larger, AI-complete reasoning problem.	Review	O	0
Also, the paper is clear, well-written, and well-motivated.	Review	O	0
[line_break_token][line_break_token]Further details on Decision[line_break_token][line_break_token]I'm more than satisfied with the breadth of question types tackled here, and correspondingly the variety of modules.	Review	O	0
There's extensive, valuable work in designing these modules and making them work together.	Review	O	0
As the authors point out, it appears that other types of questions will require more intricate modules (or some other means), and I suspect that predetermined modules will not be what generalizes eventually.	Review	B-Review	2
Nevertheless, the NMN approach taken here can be a stepping stone to further understanding how to tackle symbolic reasoning in a deep neural network.	Review	I-Review	2
It will be instructive in designing a more ambitious, generalizable model.	Review	I-Review	2
[line_break_token][line_break_token]The auxiliary supervision tasks appear to be essential to obtaining the results, most notably the unsupervised loss for IE.	Review	O	0
I think this area has room for further improvement, but what is achieved in the paper is sufficient for publication.	Review	B-Review	1
In particular, the writing of heuristics is a very specific solution targeting specific types of question and this will not scale to the full scope of natural language questions, and much less to all reasoning.	Review	I-Review	1
Discussion of how to expand on them, scale them (automatic discovery, some other means?),	Review	I-Review	1
etc.	Review	I-Review	1
would be very welcome, as it is the main weakness of the paper.	Review	I-Review	1
[line_break_token][line_break_token]I also think the methodology is sound and the results are obtained in a reasonable and mostly reproducible way.	Review	O	0
[line_break_token][line_break_token]This is truly great work that deserves to be published, discussed, and expanded upon.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
hank you for your comments and appreciating our contributions.	Reply	O	0
We completely agree with your evaluation that the exact model we propose in this paper is not going to solve all of the challenges in reasoning but the ideas presented here should benefit future work.	Reply	B-Reply	1
[line_break_token][line_break_token]We agree that additional avenues of auxiliary supervision need to be explored for the success of NMNs.	Reply	I-Reply	2
Additionally, these do not necessarily have to come from QA supervision.	Reply	I-Reply	2
One possible direction is to distantly supervise IE modules from noisy alignments between text and knowledge graphs, or supervise ‚Äúfind‚Äù like modules using entity-linking or other grounding supervision.	Reply	I-Reply	2
Another one is to create paired questions that share substructures in the reasoning (even if we don‚Äôt have the correct answer for one of the questions), and supervise consistency on the shared substructures, which might help the model avoid shortcutting the intended reasoning (e.g., doing the ‚Äúlongest‚Äù operation inside of the encoder, or inside of ‚Äúfind‚Äù).	Reply	I-Reply	2
 Future work should explore these directions that allow for better transfer of modules and supervision.	Reply	I-Reply	2

The paper proposes learning NN to correct for inaccuracies in numerical solvers of PDEs, with experimental focus on fluid flow simulation.	Review	O	0
It lists two approaches: (1) compute correction in high resolution simulation from reference states, convert to low-resolution correction, and train NN to predict low-res correction (optionally with temporal regularization, and (2) directly simulate forward using correction prediction and differentiable PDE solver and optimize to match the given reference states.	Review	O	0
It shows empirical results on better approximating fluid flow simulation.	Review	O	0
[line_break_token][line_break_token]The paper tackles an important problem of using NN to speed up expensive simulation computations.	Review	O	0
The main limitation appears to be the significance of machine learning approaches.	Review	B-Review	1
Approach (1) is a naive prediction using NN, and approach (2) involves interesting differentiation through PDEs, but that‚Äôs directly borrowed from another concurrent anonymized submission.	Review	I-Review	1
This paper alone does not seem to have enough novel ML contributions for acceptance.	Review	I-Review	1
[line_break_token][line_break_token]The writing can benefit from more clarity and better structure.	Review	I-Review	2
For example,[line_break_token]- Write prediction as \hat{c}_L(s) to show what is input for the NN[line_break_token]- Put definition for c_H in Section 3.1.	Review	O	0
It seems to be based on v_R and v_B but would benefit from being explicit.	Review	B-Review	3
[line_break_token]- If beta=0 is used, why do you need Section 3.2?	Review	O	0
Is it a typo?	Review	B-Review	4
[line_break_token]- In Section 3.3, I am unsure if it should be called unsupervised, as you are given reference state s_H. How is the assumption different from Sections 3.1 and 3.2?	Review	O	0
Also, a relevant reference [1][line_break_token][line_break_token][1] Bengio, Samy, et al. "	Review	O	0
Scheduled sampling for sequence prediction with recurrent neural networks."	Review	O	0
Advances in Neural Information Processing Systems.	Review	O	0
2015.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
hank you very much for taking the time to review our paper.	Reply	O	0
We would like to clarify a set of points below.	Reply	O	0
[line_break_token][line_break_token]Our second approach, which we call unsupervised, could be adapted to a variety of PDE problems.	Reply	B-Reply	1
The key advantage of this approach is that it directly integrates an NN model for the proposed correction with a numerical solver to be improved.	Reply	I-Reply	1
This also means that, in fact, you do not need to provide the reference state s_H since we can also integrate an advanced solver with a higher resolution configuration and acquire the reference data on the fly.	Reply	I-Reply	1
Nevertheless, it is natural to precompute the reference data since it is very time consuming.	Reply	I-Reply	1
We reused the reference data for our target problem; however, this is not a prerequisite.	Reply	I-Reply	1
[line_break_token][line_break_token]Yes, beta=0 is a typo; it should be beta=1 instead.	Reply	I-Reply	4
Thank you for the suggestions.	Reply	I-Reply	4
We would be happy to incorporate your suggestions for better exposition.	Reply	I-Reply	4

[Summary][line_break_token]The paper presents a video classification framework that employs 4D convolution to capture longer term temporal structure than the popular 3D convolution schemes.	Review	O	0
This is achieved by treating the compositional space of local 3D video snippets as an individual dimension where an individual convolution is applied.	Review	O	0
The 4D convolution is integrated in resnet blocks and implemented via first applying 3D convolution to regular spatio-temporal video volumes and then the compositional space convolution, to leverage existing 3D operators.	Review	O	0
Empirical evaluation on three benchmarks against other baselines suggested the advantage of the proposed method.	Review	O	0
        [line_break_token][line_break_token][Decision][line_break_token]Overall, the paper addresses an important problem in computer vision (video action recognition) with an interesting.	Review	O	0
I found the motivation and solution are reasonable (despite some questions pending more elaboration), and results also look promising, thus give it a weak accept (conditional on the answers though).	Review	O	0
[line_break_token][line_break_token][Comments][line_break_token]At the conceptual level, the idea of jointly modeling local video events is not novel, and can date back to at least ten years ago in the paper ‚ÄúLearning realistic human actions from movies‚Äù, where the temporal pyramid matching was combined with the bag-of-visual-words framework to capture long-term temporal structure.	Review	O	0
The problem with this strategy is that the rigid composition only works for actions that can be split into consecutive temporal parts with prefixed duration and anchor points in time, which is clearly challenged by many works later when more complicated video events are studied.	Review	B-Review	1
It seems to me that the proposed framework also falls in this category, with a treatment from deep learning.	Review	I-Review	1
It is definitely worth some discussion on this path.	Review	I-Review	1
           [line_break_token][line_break_token]That said, I would like to see more analysis on the behavior of the proposed method under various interesting cases not tested yet.	Review	O	0
Despite the claim that the proposed method can capture long-term video patterns, the static compositional nature seems to work best for activities with well-defined local events and clear temporal boundaries.	Review	B-Review	2
These assumptions hold mostly true for the three datasets used in the experiment, and also are suggested by results in table 2(e), where 3 parts are necessary to achieve optimal results.	Review	I-Review	2
How does the proposed method perform in more complicated tasks such as        [line_break_token]- action detection or localization (e.g., in benchmarks JHMDB or UCF101-24).	Review	I-Review	2
[line_break_token]- complex video event modeling (e.g., recognizing activities in extended video of TRECVID).	Review	I-Review	2
[line_break_token]Will it still be more favorable than other concerning baselines?	Review	I-Review	2
 [line_break_token][line_break_token]Besides, on the computation side, it would be complexity, an explicit comparison of complexity makes it easier to evaluate the performance when compared to other state-of-the-art methods.	Review	O	0
[line_break_token][line_break_token][Area to improve][line_break_token]Better literature review to reflect the relevant previous video action recognitions, especially those on video compositional models.	Review	O	0
 [line_break_token]Proof reading - The word in the title should be ‚ÄúConvolutional‚Äù, right?	Review	O	0
hank you for your comments and suggestions.	Reply	O	0
We will address the issues you mentioned.	Reply	O	0
[line_break_token][line_break_token][line_break_token]1.	Reply	B-Reply	2
[tab_token]Thank you for the insightful suggestion.	Reply	O	0
We now have added related work about video compositional methods in section 2.3 in the second version of the paper.	Reply	B-Reply	4
[line_break_token][line_break_token][line_break_token]2.	Reply	I-Reply	3
  In the original version of the paper, all experiments are conducted on trimmed video classification datasets.	Reply	I-Reply	2
Although most papers in this field only report results on the trimmed video datasets, we do agree that more complicate cases should be tested.	Reply	I-Reply	2
Additionally, we evaluated our V4D for untrimmed video classification on ActivityNet v1.3, which contains videos of 5 to 10 minutes and typically large time lapses of the videos are not related with any activity of interest.	Reply	I-Reply	2
The very competitive result is reported in the appendix of the second version of paper, which demonstrated the generalization and robustness of our V4D. In fact, unlike previous video compositional methods, even when local events are not well aligned or misclassified, long-term modelling with 4D convolution and video-level aggregation with global average pooling are very likely to correct the partial error.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]3.About complexity, in the original version of the paper, we have reported parameters and FLOPs of V4D and compared it with other baseline methods in Table 2.	Reply	O	0
[line_break_token][line_break_token][line_break_token]4.	Reply	O	0
We have already corrected the typo in title in the second version of the paper.	Reply	B-Reply	5
Yet it seems that we are not able to modify the title on OpenReview.	Reply	I-Reply	5
Thank you for pointing it out.	Reply	I-Reply	5
[line_break_token][line_break_token]Hopefully our rebuttal could stress your concerns.	Reply	O	0
If there are still any possible issues, please don‚Äôt hesitate to tell us and we will response as soon as possible.	Reply	O	0
[line_break_token]	Reply	O	0

The submission proposes to train a GAN on discrete sequences using the straight-through Gumbel estimator introduced in Jang et al. (	Review	O	0
2016) in combination with gradient centering.	Review	O	0
The proposed approach is evaluated on COCO and EMNLP News in terms of BLEU and Self-BLEU scores, Fr√©chet Embedding Distance, Language Model Score, and Reverse Language Model Score.	Review	O	0
[line_break_token][line_break_token]My assessment is that the submission is below the acceptance bar, mainly due to clarity and novelty concerns.	Review	B-Review	1
The proposed approach does have empirical backing, but I would argue that it is a very straightforward application of the straight-through Gumbel estimator to GANs, which is itself similar to existing work on applying the Gumbel-softmax estimator to GANs (Kusner &amp; Hern√°ndez-Lobato, 2016).	Review	O	0
Detailed comments can be found below.	Review	O	0
[line_break_token][line_break_token]The submission does not feel self-contained.	Review	B-Review	2
For instance, it borrows notation from Jang et al. (	Review	I-Review	2
2016) without explicitly acknowledging it, and my personal experience is that reading Jang et al. (	Review	I-Review	2
2016) beforehand makes a big difference in terms of clarity in Section 2.2.	Review	I-Review	2
[line_break_token][line_break_token]The notation is inconsistent and confusing, and gets in the way of understanding the proposed approach.	Review	I-Review	2
Here‚Äôs a (non-exhaustive) list of examples:[line_break_token][line_break_token]- The reward function is first introduced as f_\phi(\mathbf{x}) above Equation 3, but all subsequent mentions of the reward function use f_\phi(\hat{\mathbf{x}}).	Review	O	0
[line_break_token]- The \mathbf{m}_\theta variable is introduced in Equation 5 and is immediately replaced with \mathbf{p}_\theta, which adds notational overhead without any benefit.	Review	O	0
[line_break_token]- The difference between \hat{\mathbf{x}} and \hat{x} is not explained in the text.	Review	O	0
From the context I understand that \hat{x} is a categorical scalar in {1, ‚Ä¶, V}; is this correct?	Review	B-Review	2
[line_break_token]- In Equation 6, x_1, ‚Ä¶, x_V are used to denote the *values* that \hat{x} can take.	Review	O	0
This clashes with the previous convention that \mathbf{x} is a sequence sampled from p_{data} (Equation 1).	Review	B-Review	2
Given that convention and the difference between bolded and non-bolded variables discussed above, I would have expected that x_1, ‚Ä¶, x_V would correspond to the categorical values of elements of the \mathbf{x} sequence.	Review	I-Review	2
That contributes to confusion in Equation 9, where \mathbf{e}_{x_t} and p_\theta(x_t) are *not* time-dependent.	Review	I-Review	2
[line_break_token]- Equation 8 sums over time steps, but the first summation that appears in Equation 8 does not make use of the temporal index.	Review	O	0
There is also a symbol collision for T, which is used both as the sequence length and as the "transpose" symbol.	Review	B-Review	2
[line_break_token][line_break_token]As a result, the proposed centering method and the rationale for it is still not entirely clear to me.	Review	O	0
In particular, is the gradient centering approach necessary to avoid the drawback of score function-based approaches (i.e. the generator is only given feedback on the tokens it samples), or does the non-centered, straight-through variant of the proposed approach also avoid this drawback?	Review	B-Review	4
[line_break_token][line_break_token]I‚Äôm also not convinced that the centering heuristic is a crucial component of the proposed approach when the biggest improvement observed over the straight-through baseline is obtained by adding spectral normalization.	Review	I-Review	3
I would argue that the proposed approach is a straightforward application of the straight-through Gumbel gradient estimator to GAN training, which is similar in spirit to work by Kusner &amp; Hern√°ndez-Lobato (2016) (not cited in the submission) -- the main difference being that the latter uses the Gumbel-softmax distribution directly and anneals the temperature parameter over the course of training.	Review	O	0
A comparison between the two would be warranted.	Review	B-Review	3
[line_break_token][line_break_token]References:[line_break_token][line_break_token]- Kusner, M. J., &amp; Hern√°ndez-Lobato, J. M. (2016).	Review	O	0
GANs for sequences of discrete elements with the Gumbel-softmax distribution.	Review	O	0
arXiv:1611.04051.	Review	O	0
egarding the contribution:[line_break_token][line_break_token]Yes, the straight-through estimator helps avoid the drawback of the score-function estimator by providing extra information, which is the gradient of the discriminator, to the generator from the discriminator.	Reply	O	0
There is technically an infinite number of possible ‚Äústraight-through estimators‚Äù.	Reply	B-Reply	1
The one we think of as the straight-through estimator is just the most obvious way to define the backward gradient (by pretending the activation is an identity function) - but there is no reason to think that it is the best.	Reply	I-Reply	1
Thus it is worth searching for modifications.	Reply	I-Reply	1
[line_break_token][line_break_token]Spectral normalization is not so much an ‚Äúaddon‚Äù as it is a crucial prerequisite for our method.	Reply	I-Reply	3
Since we want to incorporate the gradient of the discriminator in the generator, we need to bound the Lipschitz constant of the discriminator (using spectral normalization) and makes it possible for the generator to use gradient of the discriminator effectively.	Reply	I-Reply	3
For more details, please see the revised version of section 5.7.	Reply	I-Reply	3
[line_break_token][line_break_token]Our experiments show that the recentering trick increases 20% FED compared to the baseline straight-through estimator (both using spectral normalization), which is why we feel it is worth incorporating	Reply	I-Reply	3

This work presents Backpropamine, a neuromodulated plastic LSTM training regime.	Review	O	0
It extends previous research on differentiable Hebbian plasticity by introducing a neuromodulatory term to help gate information into the Hebbian synapse.	Review	O	0
The neuromodulatory term is placed under network control, allowing it to be time varying (and hence to be sensitive to the input, for example).	Review	O	0
Another variant proposes updating the Hebbian synapse with modulated exponential average of the Hebbian product.	Review	O	0
This average is linked to the notion of an eligibility trace, and ties into some recent biological work that shows the role of dopamine in retroactively modulating synaptic plasticity.	Review	O	0
[line_break_token][line_break_token]Overall the work is nicely motivated and clearly presented.	Review	O	0
There are some interesting ties to biological work -- in particular, to retroactive plasticity phenomena.	Review	O	0
There should be sufficient details for a reader to implement this model, thought there are some minor details missing regarding the experimental setup, which will be addressed below.	Review	B-Review	1
[line_break_token][line_break_token]The authors test their model on three tasks: cue-award association, maze learning, and Penn Treebank (PTB).	Review	O	0
In the cue-award association task the retroactive and simple modulation networks perform well, while the non-modulated and non-plastics fail.	Review	O	0
For the maze navigation task the modulated networks perform better than the non-modulated networks, though the effect is less pronounced.	Review	O	0
Finally, on PTB the authors report improvements over baseline LSTMs.	Review	O	0
[line_break_token][line_break_token]One of the main claims of this paper is that neuromodulated plastic LSTMs...outperform standard LSTMs on a benchmark language modeling task‚Äù, and that therefore ‚Äúdifferentiable neuromodulation of plasticity offers a powerful new framework for training neural networks‚Äù.	Review	O	0
This claim is unfortunately unfounded for a very important reason: the LSTM performance is not at all close to that which can be achieved by LSTMs in general.	Review	B-Review	2
The authors cite such models in the appendix (Melor et al), but claim that ‚Äúmuch larger models‚Äù are needed, potentially with other mechanisms, such as dropout.	Review	I-Review	2
Though this may be true, these models still undermine the claim that ‚Äúneuromodulated plastic LSTMs...outperform standard LSTMs on a benchmark language modeling task‚Äù.	Review	I-Review	2
This claim is simply not true, and more care is needed in reporting the results here in the wider context of the literature.	Review	I-Review	2
Also, I am left wondering what are considered the parameters of the models -- are only the neuromodulatory terms considered as the additional trainable parameters compared to baseline LSTMs?	Review	I-Review	1
How are the Hebbian synapses themselves considered in this calculation?	Review	I-Review	1
If the Hebbian synapses are not considered, then the authors need a control with matched memory-capacities to account for the extra capacity afforded by the Hebbian synapses.	Review	I-Review	1
Given the ties between Hebbian synapses and attention (see Ba et al), an important control here could be an LSTM with Bahdanau (2014) style attention.	Review	I-Review	1
[line_break_token][line_break_token]Finally, the style (font) of the paper does not adhere to the ICLR style template, and must be changed.	Review	I-Review	3
[line_break_token][line_break_token]Overall, the ideas presented in the paper are intriguing, and further research down this line is encouraged.	Review	O	0
However, in its current state the work lacks sufficiently strong baselines to support the paper‚Äôs claims; thus, the merits of this approach cannot yet be properly assessed.	Review	B-Review	2
[line_break_token]	Review	O	0
Thank you to Reviewer 1 for noting the clarity of our presentation and reproducibility.	Reply	O	0
 We also appreciate the constructive criticism and thought that went into your review.	Reply	O	0
[line_break_token][line_break_token]We spent a considerable amount of time trying to fulfill the reviewer‚Äôs request to match state of the art (SOTA) on PTB.	Reply	B-Reply	4
To get SOTA on PTB, we need massive architectures, which considerable computing power and experimentation at the extreme limit of what is achievable for our team.	Reply	I-Reply	4
Still, we pursued two directions.	Reply	I-Reply	4
First, we tried to reimplement an architecture similar to  Melis et al.	Reply	I-Reply	4
2017.	Reply	I-Reply	4
However, they did not publish their code, hyperparameters, or weights, requiring re-implementing and re-training from scratch.	Reply	I-Reply	4
We tried this path, but soon realized we would not be done in time (especially with a hyperparameter search).	Reply	I-Reply	4
[line_break_token][line_break_token]We then tried to weave neuromodulation and differentiable plasticity into the architecture and code base of Merity et al.,	Reply	I-Reply	4
ICLR 2018 (also tied for SOTA).	Reply	I-Reply	4
However, while they could simply leverage existing PyTorch implementations of LSTMs (written in extremely fast C++), we had to re-implement LSTMs ‚Äúby hand‚Äù (i.e. as a series of connected layers) in PyTorch to introduce plasticity and neuromodulation.	Reply	I-Reply	4
As a result, our networks thus ran considerably slower, by more than 10x (not because our method is intrinsically slower, but just for lack of engineering optimizations on our bespoke Python implementations; we confirmed this by observing that a similar ‚Äúhand-built‚Äù reimplementation of simple, non-plastic LSTMs ran similarly slower, while producing results identical to Merity et al.).	Reply	I-Reply	4
These experiments are thus unfortunately still running.	Reply	I-Reply	4
 For these reasons (and more provided below), we thus think it more fair (and necessary) to make such experiments the subject of a future paper.	Reply	I-Reply	4
[line_break_token][line_break_token]That said, we still believe the results in the current paper demonstrate the benefits of our techniques on a sizable model, and thus it would benefit the community to allow people to know about, and build upon, these new methods and results.	Reply	I-Reply	4
The purpose of the present paper is to introduce a novel technique and show that it can produce an advantage in realistic settings, which we believe our PTB task confirms.	Reply	I-Reply	4
Our claim is that, all other things being equal (especially the number of parameters), a neuromodulated plastic LSTM outperformed a standard LSTM on this particular benchmark task.	Reply	I-Reply	4
We do **not** want to claim that our results are anywhere near SOTA.	Reply	I-Reply	4
We have modified our text to avoid possible misunderstandings (see end of next-to-last paragraph in Section 4).	Reply	I-Reply	4
[line_break_token][line_break_token]Additionally, philosophically, If SOTA results are the bar for all papers to be accepted into conferences like ICLR, then those venues will be the exclusive domain of those with either the computation or time (i.e. large-scale resources) to dedicate to such results.	Reply	I-Reply	4
 In that case, many cutting edge ideas will by necessity be excluded from the discussion, as will many research groups.	Reply	I-Reply	4
Moreover, insisting on papers to be SOTA to be accepted also likely encourages p-hacking and shoddy science to game the results (even if unintentionally), reducing the quality of science our community tries to build on.	Reply	I-Reply	4
[line_break_token][line_break_token]Re: "Parameters of the model": All trainable parameters of the Hebbian synapses (alpha and w in Equation 1, plus the neuromodulation parameters) are included in this parameter count.	Reply	O	0
To equalize the number of parameters across architectures, we reduce the number of hidden units in the plastic models in comparison to the non-plastic baseline.	Reply	B-Reply	1
We have clarified this in the text.	Reply	I-Reply	1
 [line_break_token][line_break_token]Re: "Attention": Non-trainable, homogenous plasticity can indeed be compared to a form of attention, i.e. ‚Äúattending to the recent past‚Äù in the words of Ba et al.	Reply	O	0
2016.	Reply	B-Reply	2
However, differentiable plasticity allows for the plasticity of each connection to be trained; as a result, different connections play different roles and it is not at all clear that the analogy with attention remains relevant (see e.g. the clever mechanisms automatically implemented by the trained plasticity connections in the image completion experiment of the Differentiable Plasticity paper, Miconi et al.	Reply	I-Reply	2
2018, sections 4.3 and S.3, which can hardly be described as simply ‚Äúattention‚Äù)[line_break_token][line_break_token]Re: "Style (font)": We used the template and do not see the discrepancy.	Reply	O	0
Can you clarify?	Reply	B-Reply	3
We are happy to fix it.	Reply	I-Reply	3

This paper addresses one of the major shortcomings of generative adversarial networks - their lack of mechanism for evaluating held-out data.	Review	O	0
While other work such as BiGANs/ALI address this by learning a separate inference network, here the authors propose to change the GAN objective function such that the optimal discriminator is also an energy function, rather than becoming uninformative at the optimal solution.	Review	O	0
Training this new objective requires gradients of the entropy of the generated data, which are difficult to approximate, and the authors propose two methods to do so, one based on nearest neighbors and one based on a variational lower bound.	Review	O	0
The results presented show that on toy data the learned discriminator/energy function closely approximates the log probability of the data, and on more complex data the discriminator give a good measure of quality for held out data.	Review	O	0
[line_break_token][line_break_token]I would say the largest shortcomings of the paper are practical issues around the scalability of the nearest neighbors approximation and accuracy of the variational approximation, which the authors acknowledge.	Review	O	0
Also, since entropy estimation and density estimation are such closely linked problems, I wonder if any practical method for EGANs will end up being equivalent to some form of approximate density estimation, exactly the problem GANs were designed to circumvent.	Review	B-Review	3
Nonetheless, the elegant mathematical exposition alone makes the paper a worthwhile contribution to the literature.	Review	I-Review	3
[line_break_token][line_break_token]Also, some quibbles about the writing - it seems that something is missing in the sentence at the top of pg.	Review	I-Review	4
5 "Finally, let's whose discriminative power".	Review	I-Review	4
I'm not sure what the authors mean to say here.	Review	I-Review	4
And the title undersells the paper - it makes it sound like they are making a small improvement to training an existing model rather than deriving an alternative training framework.	Review	I-Review	4
Thank you very much for the comments.	Reply	O	0
[line_break_token][line_break_token]Firstly, we are really sorry about the writing problem at the top of page 5.	Reply	B-Reply	4
Due to some careless editing after submission, a paragraph that was originally in the paper was erratically deleted.	Reply	I-Reply	4
We have recovered that part and it should read clearly now.	Reply	I-Reply	4
[line_break_token][line_break_token]We agree that a scalable entropy estimation method is the core to the proposed formulation.	Reply	I-Reply	3
Also, it is true the entropy estimation problem is closely related to density estimation, especially for the exponential families.	Reply	I-Reply	3
However, for the proposed formulation, what we really need is the estimation of entropy ‚Äúgradient‚Äù, which can be practically easier.	Reply	I-Reply	3
As shown by Equation (9) of the updated paper, it amounts to estimating the score function: d log p_gen(x) / d x. In this work, the nearest neighbors approximation is an example of thinking in this direction.	Reply	I-Reply	3
[line_break_token][line_break_token]Another direction of thinking is that since we only need a proper gradient, is it possible to build another network to provide the gradient estimation.	Reply	I-Reply	3
Actually, this extra network can provide the gradient estimation by backward propagation, or even by forward propagation [1]. For now, the variational inference is an example of using the backward propagation to provide a gradient estimation.	Reply	I-Reply	3
More interestingly, as GANs were initially designed to bypass an explicit density estimation, it is conceptually tempting to think about using an adversarial process to get an implicit entropy estimation.	Reply	I-Reply	3
[line_break_token][line_break_token]We believe all these ideas are worth exploring as future work.	Reply	I-Reply	3
[line_break_token][line_break_token]In addition to these technical possibilities, another ‚Äúadvantage‚Äù here is that in theory, we can have infinite samples from the generator to estimate the entropy (gradient), which is usually impossible for normal density estimation based on empirical data.	Reply	I-Reply	3
[line_break_token][line_break_token][1] Jaderberg, Max, et al. "	Reply	O	0
Decoupled neural interfaces using synthetic gradients."	Reply	O	0
arXiv preprint arXiv:1608.05343 (2016)	Reply	O	0

The paper presents an interesting incremental approach for exploring new convolutional network hierarchies in an incremental manner after a baseline network has reached a good recognition performance.	Review	O	0
[line_break_token][line_break_token]The experiments are presented for the CIFAR-100 and ImageNet benchmarks by morphing various ResNet models into better performing models with somewhat more computation.	Review	O	0
[line_break_token][line_break_token]Although the baselines are less strong than those presented in the literature, the paper claims significant error reduction for both ImageNet and CIFAR-100.	Review	O	0
[line_break_token][line_break_token]The main idea of the paper is to rewrite convolutions into multiple convolutions while expanding the number of filters.	Review	O	0
It is quite unexpected that this approach yields any improvements over the baseline model at all.	Review	O	0
[line_break_token][line_break_token]However, for some of the basic tenets of network morphing, experimental evidence is not given in the paper.	Review	O	0
Here are some fundamental questions raised by the paper:[line_break_token]- How does the quality of morphed networks compares to those with the same topology trained from scratch?	Review	O	0
[line_break_token]- How does the incremental training time after morphing relate to that of the network trained from scratch?	Review	O	0
[line_break_token]- Where is the extra computational cost of the morphed networks come from?	Review	O	0
[line_break_token]- Why is the quality of the baseline ResNet models lag behind those that are reported in the literature and github? (	Review	O	0
E.g. the github ResNet-101 model is supposed to have 6.1% top-5 recall vs 6.6 reported in the paper)[line_break_token]More evidence for the first three points would be necessary to evaluate the validity of the claims of the paper.	Review	O	0
[line_break_token][line_break_token]The paper is written reasonably well and can be understood quite well, but the missing evidence and weaker baselines make it looks somewhat less convincing.	Review	O	0
[line_break_token]I would be inclined to revise up the score if a more experimental evidence were given for the main message of the paper (see the points above).	Review	O	0
[line_break_token]	Review	O	0
We appreciate the recognition and detailed comments from the reviewer, and have the following responses to address the concerns.	Reply	O	0
[line_break_token][line_break_token]1) How does the quality of morphed networks compares to those with the same topology trained from scratch?	Reply	O	0
[line_break_token][line_break_token]The proposed learning scheme produced much better results than the learning from scratch scheme.	Reply	B-Reply	1
For example, on the CIFAR10 dataset, for morph110_1c1, the absolute performance improvement is up to 2.66%, and the relative improvement is up to 32.6%.	Reply	I-Reply	1
On the CIFAR100 dataset, for morph110_1c1, the absolute performance improvement is up to 5.13%, and the relative improvement is up to 16.1%.	Reply	I-Reply	1
These results have been updated in this paper with, a) two newly added tables (Table 2 & 4), b) one newly added paragraph (the second to the last one at the end of Section 4.2).	Reply	O	0
[line_break_token][line_break_token]2) How does the incremental training time after morphing relate to that of the network trained from scratch?	Reply	O	0
[line_break_token][line_break_token]In this work, we adopted a uniform training procedure for both of these two learning scheme.	Reply	B-Reply	2
The setup is the same as [He2015]. Therefore, the incremental training time is the same as training from scratch in this research.	Reply	I-Reply	2
But the incremental training time after morphing can be greatly speeded up since the weights are already learned.	Reply	I-Reply	2
From experience, the incremental training does not necessarily need a full training.	Reply	I-Reply	2
Currently we are inspecting on this topic.	Reply	I-Reply	2
[line_break_token][line_break_token]3) Where is the extra computational cost of the morphed networks come from?	Reply	O	0
[line_break_token][line_break_token]The extra computational cost comes from the newly added parts of the network.	Reply	B-Reply	3
More precisely speaking, it is the computational cost of the part that the network morphs to, minus the computational cost of the part that the network morphs from.	Reply	I-Reply	3
As an example for ResNet, please refer to Fig.	Reply	I-Reply	3
3 (a) and (b), where the newly added part is shadowed in green.	Reply	I-Reply	3
[line_break_token][line_break_token]4) Why is the quality of the baseline ResNet models lag behind those that are reported in the literature and github? (	Reply	O	0
E.g. the github ResNet-101 model is supposed to have 6.1% top-5 recall vs 6.6 reported in the paper)[line_break_token][line_break_token]There might be some misunderstanding.	Reply	O	0
6.61% is the top-1 error rate for ResNet-110 on CIFAR10 ([He2015] (Table 6)), while 6.1% is the top-5 error rate for ResNet-101 on ImageNet.	Reply	B-Reply	4

In this paper, the authors attempt to provide a perspective on CCA that is based on implicit distributions.	Review	O	0
 The authors compare and discuss several variants on CCA that have been proposed over the years, ranging from Linear CCA to Deep CCA and autoencoder variants.	Review	O	0
 In order to overcome the prior/likelihood distribution assumptions, the authors propose a CCA view that is based on learning implicit distributions, e.g, by using generative adversarial networks.	Review	O	0
  The authors further motivate their work by comparing with (Bi-)VCCA, claiming that the underlying assumptions lead to inconsistent constraints (or idealistic).	Review	O	0
 I think the work has merit, and I like the motivation.	Review	O	0
 Nevetheless, I think stronger experiments are required, as well as improvements in terms of clarity in the writing of the paper, and stronger support for the motivation.	Review	O	0
  Figure 2 should be better explained in text.	Review	B-Review	1
 The MNIST experiment is useful, but using GANs usually results in sharper images than say VAE.	Review	I-Review	1
 Also, comparisons with (i) other models besides Bi-VCCA, and (ii) on other multi-view real-world data (besides the MNIST_LR) would be very useful in terms of communicating the true benefits of this model.	Review	O	0
Thanks for your constructive comments and suggestions for improvement of our work.	Reply	O	0
[line_break_token][line_break_token]We have made revisions in the adapted version for a better understanding of our work.	Reply	B-Reply	3
[line_break_token]1).	Reply	I-Reply	3
 Section 1 and section 3 are revised for clarity of our work; [line_break_token]2).	Reply	I-Reply	3
 Figure1 is further explained in the caption; [line_break_token][line_break_token]Furthermore, our primary objective for MNIST cross-view generation task is to show the multi-view consistency achieved by the proposed ACCA.	Reply	O	0
This VAE generation is consistent with our formulation (section 4.3) and structure design (Figure2) of ACCA.	Reply	B-Reply	1
Consequently, the quality of the generated images is not the major consideration in this part.	Reply	I-Reply	1
However, we can easily adopt GANs, e. g. VAE- GANs, to improve the quality of the generated images of our model.	Reply	I-Reply	1
[line_break_token][line_break_token]We will address your suggestion about the experiments in the future version.	Reply	O	0

This paper proposes a memory layer for Graph Neural Networks (GNNs) and two deep models for hierarchical graph representation learning.	Review	O	0
The proposed memory layer models the memory as a multi-head array of keys with a soft clustering mechanism and applies a convolution operator over the heads.	Review	O	0
The proposed models are experimentally evaluated on seven graph classification and regression tasks.	Review	O	0
[line_break_token][line_break_token]Generally, the paper is technically justified.	Review	O	0
The proposed technique is well motivated and properly presented.	Review	O	0
A novel clustering-convolution mechanism is proposed  for memory augmentation and graph pooling.	Review	O	0
However, there are still some rebuttal requests.	Review	O	0
1- Some details are insufficient.	Review	O	0
For the multi-head mechanism, it is not stated clearly whether for each head an independent query is computed or a shared query is used for all heads.	Review	B-Review	1
 [line_break_token]2- Additionally, a related work published in NIPS 2016 should be cited and discussed.	Review	O	0
[line_break_token]Jack Rae et al.	Review	B-Review	2
Scaling memory-augmented neural networks with sparse reads and writes.	Review	I-Review	2
 [line_break_token]	Review	I-Review	1
hank you for your supportive comments.	Reply	O	0
We would like to address the points as follows:[line_break_token][line_break_token]1- We revised section 3 to add the requested details.	Reply	O	0
In short: the input query is shared among the key heads.	Reply	B-Reply	1
Therefore applying an input query to a layer with for example 10 key heads results in 10 assignment matrices (i.e., C).	Reply	I-Reply	1
We stack the matrices to form a tensor of size where is the number of heads (i.e., depth in standard convolution analogy and 10 in this case), and is the size of the cluster assignment matrix (i.e., height and width in standard convolution analogy).	Reply	I-Reply	1
In other words, we treat each head as a separate channel.	Reply	I-Reply	1
Because there is no spatial structure, we use convolution to aggregate thes across channels and therefore the convolution behaves as a weighted pooling that reduces the heads to one head.	Reply	I-Reply	1
We then pass the aggregated to a non-linearity.	Reply	I-Reply	1
[line_break_token][line_break_token]2- We added this work to section 2.	Reply	O	0
Similar to this work, we use ‚Äúcontent addressable memory‚Äù and use Student‚Äôs t-distribution as a kernel to measure the similarity.	Reply	B-Reply	2
However, because the number of memory words is fairly small in our case (i.e., number of cluster centroids), we do not in practice need to apply the tricks mentioned in this paper for faster retrieval and updates.	Reply	I-Reply	2
For example, in a few datasets that we experimented on, the maximum number of keys in each array were 32 which can be updated efficiently without requiring using approximate nearest neighbor to select the top keys to be updated	Reply	I-Reply	2

This paper introduces a novel exploitation of the centralized training for decentralized execution regime for Dec-POMDPs with publicly/commonly known actions.	Review	O	0
 In particular, the paper augments independent value-based reinforcement learning by allowing each agent to announce the action it would have taken, had it acted greedily.	Review	O	0
This relaxation is consistent with decentralized execution, at which time agents always act greedily and no counterfactual announcement is required.	Review	O	0
The paper demonstrates the utility of this trick in Hanabi, where it achieves strong performance when combined with distributed Q-learning and an auxiliary task.	Review	O	0
The paper is largely well-written.	Review	O	0
[line_break_token][line_break_token]I think that the trick introduced in this paper is a valuable contribution to the community.	Review	O	0
As the paper discusses, SAD is simpler and easier to implement than BAD, the algorithm with the most comparable ambitions with respect to scalability.	Review	O	0
Also, unlike BAD, it is model-free.	Review	O	0
I think that investigating lightweight alternatives to common/public knowledge based approaches, such as SAD, is an important research direction.	Review	O	0
[line_break_token][line_break_token]That being said, I have some issues with the presentation of the content in the paper.	Review	O	0
[line_break_token][line_break_token]1.	Review	B-Review	7
Section 4 is problematic.	Review	I-Review	1
The entirety of the section is based on the assumption that agent a‚Äô observes the Markov state.	Review	I-Review	1
The paper claims that this assumption is made for simplicity: ‚Äúwhere for simplicity we have assumed that agent a‚Äô uses a feed-forward policy and observes the Markov state of the environment.	Review	I-Review	1
‚Äù [line_break_token]    a. First, this assumption is unmet, with few exceptions.	Review	I-Review	1
Other agents do [line_break_token]        NOT in general observe the Markov state.	Review	I-Review	1
This is a very significant [line_break_token]        part of why Dec-POMDPs are so difficult.	Review	I-Review	1
Justifying SAD in a setting [line_break_token]        that so radically departs from its use case is not informative.	Review	I-Review	1
[line_break_token]    b. Second, the claim made by the paper (that the assumption is made [line_break_token]        for simplicity) is misleading.	Review	I-Review	1
The assumption is made out of [line_break_token]        necessity.	Review	I-Review	1
The cost of neglecting public/common knowledge, as SAD [line_break_token]        does, is that principled Bayesian reasoning is not possible.	Review	I-Review	1
It is [line_break_token]        important that the paper acknowledges this to counterbalance its [line_break_token]        (valid) criticisms that public/common knowledge based approaches [line_break_token]        are difficult to scale.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	4
That the experiments are expensive is understandable and a fully complete ablation study is not expected.	Review	I-Review	2
But the results of these experiments should be presented clearly.	Review	I-Review	2
[line_break_token]    a. In both Table 1 and Table 2, presenting the ‚Äúbest seed‚Äù is [line_break_token]        not appropriate.	Review	I-Review	2
The paper should report the mean or the median.	Review	I-Review	2
[line_break_token]        Given that only three seeds could be afforded, it is understandable [line_break_token]        that the results would have high variance.	Review	I-Review	2
[line_break_token]    b. In Table 2, (if I am understanding the paper correctly) it is claimed [line_break_token]        that the s.e.m.	Review	O	0
is less than or equal to 0.01 over a set of three seeds [line_break_token]        for all of the experiments.	Review	B-Review	3
But looking at Figure 4, this is clearly not [line_break_token]        the case, especially in the four and five player settings.	Review	I-Review	3
The intended [line_break_token]        meaning should be clarified.	Review	I-Review	3
[line_break_token]    c. In Table 1, the paper should report the results for the baseline, VDN, [line_break_token]        VDN with greedy input, and SAD separately, as is done in Table 2.	Review	O	0
[line_break_token]        These are the main experimental results and merit space in the main [line_break_token]        body of the paper.	Review	B-Review	4
Moreover, there are a number of results that [line_break_token]        deserve written attention.	Review	I-Review	4
[line_break_token]        i. It looks the baseline is very competitive with BAD in two player [line_break_token]           Hanabi.	Review	I-Review	4
This in itself is a very interesting finding and is worth [line_break_token]           discussing.	Review	I-Review	4
[line_break_token]        ii.	Review	O	0
Looking at Table 2, it appears that VDN with GreedyInput [line_break_token]            outperforms SAD in three of the four settings and quite [line_break_token]            significantly in the five player setting.	Review	B-Review	4
If this is also the case when [line_break_token]            results are aggregated over the median or mean, it should be [line_break_token]            discussed.	Review	I-Review	4
[line_break_token]3.	Review	I-Review	7
The greedy input approach is specific to Dec-POMDPs in which actions are publicly/commonly available.	Review	I-Review	5
This should at least be mentioned somewhere.	Review	I-Review	5
[line_break_token][line_break_token]Overall, I think the ideas and experimental findings in the paper are very interesting.	Review	O	0
However, as outlined above, there are a number of issues.	Review	B-Review	6
At a high level, I think that the paper is too concerned with 1) justifying greedy input with Bayesian reasoning and 2) promoting state of the art results.	Review	I-Review	6
The ideas and experimental findings are more than sufficient for strong contribution without these things.	Review	I-Review	6
[line_break_token][line_break_token]In its current state, I feel that this work is a rejection.	Review	O	0
However, its issues are relatively easily amendable:[line_break_token]1.	Review	O	0
For each algorithm and each setting, separately report median or mean results over the seeds, with uncertainty.	Review	B-Review	7
[line_break_token]2.	Review	I-Review	4
Reallocate space to section 6.2 for a scientific discussion of the experimental results.	Review	I-Review	7
[line_break_token]3.	Review	I-Review	7
Remove or qualify the arguments made in section 4.	Review	I-Review	7
[line_break_token]4.	Review	I-Review	7
Mention that the greedy input approach is specific to Dec-POMDPs with publicly/commonly available actions.	Review	I-Review	7
[line_break_token][line_break_token]Were these issues addressed, my opinion would change.	Review	O	0
irst of all, many thanks for an extremely thorough and insightful review.	Reply	O	0
Below we address each of the individual requests.	Reply	O	0
[line_break_token][line_break_token]@1)[line_break_token]As suggested by R2, we have redone the derivations in Section 4.	Reply	O	0
We now account for partial observability throughout.	Reply	B-Reply	1
We had originally chosen to use an agent with access to the Markov state as a simplified setting to motivate the method, but as pointed out by R2 this does hide interesting technical and conceptual challenges.	Reply	I-Reply	1
[line_break_token][line_break_token]We also added a paragraph that explains the issues around explicit Bayesian beliefs and the rationale for using common knowledge beliefs instead.	Reply	I-Reply	1
We believe that in the current formulation the motivation is appropriate, since implicit Bayesian beliefs are not affected by the same kind of recursive explosion.	Reply	I-Reply	1
[line_break_token][line_break_token]@2)[line_break_token]To make these numbers meaningful we carried out further experimentations resulting in 13 seeds for each of the settings and algorithms.	Reply	O	0
While we do not believe that there is a meaningful way to report averages and uncertainties across the original 3 seeds, we now report average results and best results (incl.	Reply	B-Reply	2
uncertainties) for each of the settings and algorithms in the updated Table 1 and updated Table 2.	Reply	I-Reply	2
We have updated the captions of both tables to clarify how the numbers were computed.	Reply	I-Reply	2
[line_break_token][line_break_token]We also include training curves showing the average performance of our methods (including s.e.m.)	Reply	I-Reply	2
across the training process.	Reply	I-Reply	2
[line_break_token][line_break_token]@2.b) [line_break_token]The numbers in Table 2 are obtained by first select the best model among 13 runs of each algorithm and then evaluating that model over 100K games with different seeds.	Reply	O	0
The original numbers in the Hanabi challenge and BAD used population based training, effectively taking a max over 32 runs.	Reply	B-Reply	3
Therefore, we do believe it is important for reproducibility purposes to also report the results for our best models.	Reply	I-Reply	3
[line_break_token][line_break_token]@2.c)[line_break_token]We have also added a more in depth scientific discussion of the results in Section 6, as suggested by R2.	Reply	O	0
[line_break_token]In particular we point out that the auxiliary task only helps for 2 players and VDN matches the performance of SAD for 3 players.	Reply	B-Reply	4
[line_break_token][line_break_token]@3) [line_break_token]Indeed, SAD requires all agents to be able to observe the last actions.	Reply	O	0
This was mentioned in the later part of Section 3.1 (‚Äú.	Reply	B-Reply	5
Since we are interested in ToM, in our setting the observation function includes the last action of the acting agent, which is observed by all other agents at the next time step.	Reply	I-Reply	5
We note that actions are commonly observable not only in board games but also in some real world multi-agent settings, such as autonomous driving.	Reply	I-Reply	5
‚Äù).	Reply	I-Reply	5
We now moved this towards the beginning of Section 3.1 to emphasize the assumption.	Reply	I-Reply	5
[line_break_token][line_break_token]We also added a paragraph to Section 4.3 which explores how the greedy-action input could be extended to settings where the last action is not directly observed, but can in principle be decoded by all agents through the environment dynamics and observation function.	Reply	I-Reply	5
[line_break_token][line_break_token]Other questions:[line_break_token]@"VDN with GreedyInput outperforms SAD":[line_break_token]Yes - the auxiliary task only helps for the 2 player setting.	Reply	O	0
As mentioned in our ‚Äògeneral comments‚Äô we have now restructured the paper to clearly mark the auxiliary task as optional, rather than being part of the core method.	Reply	B-Reply	4
We also believe that it is an interesting question for future work to investigate why the auxiliary task only helps for 2 players.	Reply	I-Reply	4
[line_break_token][line_break_token]We added some discussion on this point to Section 6.2.	Reply	I-Reply	4

Summary:[line_break_token]This paper proposes a training strategy called Multi-Precision Policy Enforced Training(MUPPET).	Review	O	0
This strategy aims to reduce training time by low-precision data representation and computations during the training stage.	Review	O	0
According to the gradient diversity, the authors introduce a precision-switching mechanism which chooses the best epoch to increase the precision.	Review	O	0
The validation accuracy and training time across several networks and datasets are shown in the experiments.	Review	O	0
However, the results are not superior enough compared with the state-of-the-art.	Review	B-Review	8
[line_break_token][line_break_token]My detailed comments are as follows.	Review	O	0
[line_break_token][line_break_token][line_break_token]Positive points: [line_break_token][line_break_token]1.	Review	O	0
This paper proposes a new reduced-precision training scheme to speed up training by progressively increasing the precision of computations from 8-bit fixed-point to 32-bit floating-point.	Review	O	0
This scheme moves to reduced-precision fixed-point computations while updating an FP32 model in order to push the boundaries of reduced-precision training.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
The authors propose a metric to decide when to switch the precision inspired by gradient diversity introduced by [1]. In this paper, the gradient diversity is enhanced by considering gradients across epochs instead of mini-batches.	Review	O	0
The proposed metric can be seen as a proxy for the amount of new information gained in each training step.	Review	O	0
Therefore, the metric can decide the most appropriate epoch at run time to increase the precision.	Review	O	0
[line_break_token] [line_break_token]3.	Review	B-Review	3
The proposed low-precision CNN training scheme is orthogonal and complementary to existing low-precision training techniques.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]Negative points:[line_break_token][line_break_token]1.	Review	O	0
The proposed approach does not match the description in this paper.	Review	B-Review	1
The authors describe ‚ÄúThis approach enables the design of a policy that can decide at run time the most appropriate quantization level for the training process‚Äù.	Review	I-Review	1
In fact, this approach just decides which epoch to increase the quantization level while the levels of quantized precisions are fixed, rather than deciding the most appropriate quantization level.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The setting of quantized precision levels (8-, 12-, 14- and 16-bit precisions) is confusing.	Review	B-Review	2
Please illustrate how to choose the number of quantized bit and the number of quantized precision levels.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	3
The presentation of the precision switching policy is confusing and the notations are unclear.	Review	I-Review	3
For example, in section 3.3, the ratio ‚Äúp‚Äù needs more description because it is a key value in the policy, but lacks an explanation in this section.	Review	I-Review	3
So please explain more about the motivation of ratio ‚Äúp‚Äù in this section.	Review	I-Review	3
[tab_token]In section 3.3, in step 5 of the proposed precision switching policy, the authors do not explain the meaning of ‚Äúy‚Äù.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
In figure 2, the precision switch is not triggered even though the value of p violates the threshold more than 2 times, which mismatches the description in section 3.3.	Review	B-Review	4
[line_break_token][line_break_token]5.	Review	O	0
The proposed strategy has no obvious advantages.	Review	B-Review	5
There are some scenes that the proposed strategy does not perform well.	Review	I-Review	5
For example, the Top-1 validation accuracy on ImageNet of AlexNet and ResNet with MuPPET strategy is much lower than FP32 baseline.	Review	I-Review	5
Compared with [2], the proposed method is more complex but not superior enough.	Review	I-Review	5
[line_break_token][line_break_token]6.	Review	O	0
The authors do not show the training and validation curves.	Review	B-Review	6
However, the training and validation curves are common used to show more details of the training process, such as in [2] and [3]. Please show and analyze the training and validation curves of the proposed scheme and the baseline.	Review	I-Review	6
[line_break_token][line_break_token][line_break_token]Minor issues:[line_break_token]Some spelling and grammar mistakes.	Review	O	0
[line_break_token][line_break_token][line_break_token]ReferenceÔºö[line_break_token][1] Dong Yin, Ashwin Pananjady, Max Lam, Dimitris Papailiopoulos, Kannan Ramchandran, and Peter Bartlett.	Review	O	0
Gradient Diversity: a Key Ingredient for Scalable Distributed Learning.	Review	O	0
In 21st International Conference on Artificial Intelligence and StatiZZstics (AISTATS), pp.	Review	O	0
1998‚Äì2007, 2018.	Review	O	0
[line_break_token][2] Paulius Micikevicius, Sharan Narang, Jonah Alben, Gregory Diamos, Erich Elsen, David Garcia, Boris Ginsburg, Michael Houston, Oleksii Kuchaiev, Ganesh Venkatesh, and Hao Wu.	Review	O	0
Mixed Precision Training.	Review	O	0
In International Conference on Learning Representations (ICLR), 2018.	Review	O	0
[line_break_token][3]  Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan.	Review	O	0
Deep Learning with Limited Numerical Precision.	Review	O	0
In 32nd International Conference on Machine Learning (ICML), pp.	Review	O	0
1737‚Äì1746, 2015.	Review	O	0
                                                                                                                                                                                                                                                                                                       [line_break_token]	Review	O	0
hank you for your review.	Reply	O	0
[line_break_token]Regarding point 1), we have edited the sentence towards the end of the introduction to better phrase the impact and purpose of this work.	Reply	B-Reply	1
[line_break_token][line_break_token]Regarding point 2), it has been added to Section 3.3.1 that these quantisation levels were empirically chosen.	Reply	I-Reply	2
The reasoning behind this is that we want to increase the utilised word length as little as possible in order to gain the most performance (runtime) from the computation platform, but moving too little will not result in ‚Äúenough‚Äù information gain and will force the system to switch regimes too often leading to the waste of computational resources.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding point 3), Section 3.3 has been updated to address all the mentioned points.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding point 4), this never occurs, however, Fig.	Reply	I-Reply	4
2 will be updated to highlight the exact points at which the threshold is violated.	Reply	I-Reply	4
A short discussion has also been added in Sec.4.1 to clearly indicate switching points.	Reply	I-Reply	4
[line_break_token][line_break_token]Regarding point 5), we feel that a difference of &lt; 1% in Top-1 Validation Accuracy on ImageNet is not considered ‚Äúmuch lower‚Äù and fluctuations at these levels can be seen between identical training runs.	Reply	O	0
Furthermore, with respect to GoogLeNet, for the exact same hyperparameters, we achieve a +4.55% improvement in validation accuracy which is significant.	Reply	B-Reply	5
Compared to [2], as has been added to the discussion in Section 4.3, this work pushes this boundary even further and opens the possibility for performing computations at wordlengths much lower than 16-bit, and at fixed-point instead of floating-point.	Reply	I-Reply	5
With the availability of native hardware (e.g. 8-bit fixed-point computations in NVIDIA‚Äôs Turing GPUs), being able to perform training at these precisions without compromising accuracy (as shown in this paper) carries significant advantages.	Reply	I-Reply	5
[line_break_token][line_break_token]Regarding point 6), we have added these graphs to Appendix A with a short description of what they show.	Reply	I-Reply	6

This paper proposes a first framework of large-scale spiking neural network that exploits the the sparsity of the gradient during backpropagation, to save training energy.	Review	O	0
[line_break_token]Later, it provides detailed analysis to show the equivalence of accumulated response and the corresponding integer activation ANN.	Review	O	0
[line_break_token][line_break_token]The paper is clearly written.	Review	O	0
The forward and backward process with the spike activation and error activation function respectively to save energy is clearly demonstrated.	Review	O	0
The response equivalence of the proposed architecture and integer ANNs provides theoretical gurantee for the good performance in training accuracy.	Review	O	0
 [line_break_token][line_break_token]My only concern is the lack of empirical support for the energy saving of the proposal.	Review	O	0
In order to show the effectiveness of the proposal, the authors should also provide time consumptions of the SNN and normal ANN.	Review	B-Review	1
A mere comparison on sparsity doesn't really show the advantage of the proposal, since there is some computational overhead.	Review	I-Review	1
For a system-level improvement, it's not sufficient to show the epoch-operation relation.	Review	I-Review	1
[line_break_token]If the authors could provide wall clock time comparisons, I will consider raising my score.	Review	O	0
[line_break_token][line_break_token]==========[line_break_token]I find the response of the authors reasonable and address some of my concerns.	Review	O	0
Therefore I'm willing to raise my score to 6.	Review	O	0
ased on your review, we updated the discussion section and added a more detailed treatment of the points you raised.	Reply	B-Reply	1
We added references to current work on neuromorphic hardware and explain that hardware overheads have to be taken into account when assessing system level improvements in event-based SNN systems	Reply	I-Reply	1

Error-correcting codes constitute a well-researched area of study within communication engineering.	Review	O	0
In communication, messages that are to be transmitted are encoded into binary vector called codewords that contained some redundancy.	Review	O	0
The codewords are then transmitted over a channel that has some random noise.	Review	O	0
At the receiving end the noisy codewords are then decoded to recover the messages.	Review	O	0
Many well known families of codes exist, notably convolutional codes and Turbo codes, two code families that are central to this paper, that achieve the near optimal possible performance with efficient algorithms.	Review	O	0
For Turbo and convolutional codes the efficient MAP decodings are known as Viterbi decoder and the BCJR decoder.	Review	O	0
For drawing baselines, it is assumed that the random noise in channel is additive Gaussian (AWGN).	Review	O	0
[line_break_token][line_break_token]This paper makes two contributions.	Review	O	0
First, recurrent neural networks (RNN) are proposed to replace the Viterbi and BCJR algorithms for decoding of convolutional and Turbo decoders.	Review	O	0
These decoders are robust to changes in noise model and blocklength - and shows near optimal performance.	Review	O	0
[line_break_token][line_break_token]It is unclear to me what is the advantage of using RNNs instead of Viterbi or BCJR, both of which are optimal, iterative and runs in linear time.	Review	B-Review	1
Moreover the authors point out that RNNs are shown to emulate BCJR and Viterbi decodings in prior works - in light of that, why their good performance surprising?	Review	I-Review	1
[line_break_token][line_break_token]The second contribution of the paper constitutes the design and decoding of codes based on RNNs for a Gaussian channel with noisy feedback.	Review	O	0
For this channel the optimal codes are unknown.	Review	O	0
The authors propose an architecture to design codes for this channel.	Review	O	0
This is a nice step.	Review	O	0
However, in the performance plot (figure 8), the RNN based code-decoder does not seem to be outperforming the existing codes except for two points.	Review	B-Review	2
For both in high and low SNR the performance is suboptimal to  Turbo codes and a code by Schalkwijk & Kailath.	Review	O	0
The section is also super-concise to follow.	Review	B-Review	2
I think it was necessary to introduce an LSTM encoder - it was hard to understand the overall encoder.	Review	I-Review	2
This is an issue with the paper - the authors previously mentioned (8,16) polar code without mentioning what the numbers mean.	Review	I-Review	4
[line_break_token][line_break_token]However, I overall liked the idea of using neural nets to design codes for some non-standard channels.	Review	O	0
While at the decoding end it does not bring in anything new (modern coding theory already relies on iterative decoders, that are super fast), at the designing-end the Gaussian feedback channel part can be a new direction.	Review	B-Review	2
This paper lacks theoretical aspect, as to no indication is given why RNN based design/decoders can be good.	Review	I-Review	1
I am mostly satisfied with the experiments, barring Fig 8, which does not show the results that the authors claim.	Review	I-Review	3
[line_break_token]	Review	O	0
Thank you for your comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Representability, Learnability and Generalization:[line_break_token]There are three aspects to showing that a learning problem can be solved through a parametric architecture.	Reply	O	0
[line_break_token][line_break_token](1) Representability: The ability to represent the needed function through a neural network.	Reply	O	0
For Viterbi/BCJR algorithms, this representability was shown in prior work by handcrafting parameters that represent the Viterbi/BCJR algorithms.	Reply	B-Reply	2
We note that neural networks with sufficient number of parameters can indeed represent any function through the universal approximation theorem for feedforward networks and RNNs (Cybenko,G.1989, Siegelmann,H.T.&Sontag,E.D.1995) and therefore this result is not that surprising.	Reply	O	0
[line_break_token][line_break_token](2) Learnability: Can the required function be learnt directly through gradient descent on the observed data?	Reply	O	0
For Viterbi and BCJR, learnability was neither known through prior work nor is it obvious.	Reply	B-Reply	2
One of the main contributions of our work is that those algorithms can be learnt from observed data.	Reply	I-Reply	2
[line_break_token][line_break_token](3) Generalization: Does the learnt function/algorithm generalize to unobserved data?	Reply	O	0
We show this not only at the level of new unobserved codewords, but also show that the learnt algorithm trained on shorter blocks of length 100 can generalize well to longer blocks of length up to 10,000.	Reply	B-Reply	2
Such generalization is rare in many realistic problems.	Reply	I-Reply	2
[line_break_token][line_break_token]To summarize, out of the three aspects, only representability was known from prior work (and, we agree with the reviewer, that it is the least surprising given universal representability).	Reply	I-Reply	2
Learnability and generalization of the learnt Viterbi and BCJR algorithms to much larger block lengths are both unknown from prior art and they are surprising, and interesting in their own right.	Reply	I-Reply	2
We note that Viterbi and BCJR algorithms are useful in machine learning beyond communications problem, representing dynamic programming and forward-backward algorithms, respectively.	Reply	I-Reply	2
[line_break_token][line_break_token]Peter Elias introduced convolutional codes in 1955 but efficient decoding through dynamic programming (Viterbi decoding) was only available in 1967 requiring mathematical innovation.	Reply	I-Reply	2
We note that ability to learn the Viterbi algorithm from short block length data (which can be generated by full-search) and generalizing them to much longer blocks implies an alternative methodology to solve the convolutional code problem.	Reply	I-Reply	2
Such an approach could have significant benefits in problems where corresponding mathematically optimal algorithms are not known at the moment.	Reply	I-Reply	2
[line_break_token][line_break_token]We demonstrate the power of this approach by studying the problem of channel-with-feedback where no good coding schemes are known despite 70 years of research.	Reply	I-Reply	2
[line_break_token][line_break_token]2.	Reply	O	0
Advantages of using RNNs instead of Viterbi or BCJR:[line_break_token]There are two advantages to RNN decoders, that go beyond mimicing Viterbi/BCJR.	Reply	O	0
[line_break_token][line_break_token](1) Robustness: Viterbi and BCJR decoders are known to be vulnerable to changes in the channel, as those are highly tailored for the AWGN.	Reply	O	0
We show in Section 3, via numerical experiments with T-dsitributed noise, that the neural network decoder trained on AWGN is much more robust against the changes in the channel.	Reply	B-Reply	1
This makes, among other things, our neural network decoder much more attractive alternative to Viterbi/BCJR decoders in practice, where the channel model is not available.	Reply	I-Reply	1
[line_break_token][line_break_token](2) Adaptivity: It is not easy to extend the idea of Viterbi decoder and iterative Turbo decoding beyond the simple convolutional codes and the standard Gaussian channel (or any other Discrete Memoryless Channel).	Reply	O	0
On the other hand, our neural network decoder provides a new paradigm for decoding that can be applied to any encoder and any channel, as it learns from training examples.	Reply	B-Reply	1
To showcase the power of this ‚Äúadaptivity‚Äù, we show improved performance on the bursty channel.	Reply	I-Reply	1
[line_break_token][line_break_token]A more stark example of the utility presents itself in the feedback channel.	Reply	I-Reply	1
There exists no known practical encoding-decoding scheme for a feedback channel.	Reply	I-Reply	1
Only because we have a neural network decoder that can adapt to any encoder, we are able to find a novel encoder (also neural network based) that uses the feedback information correctly and achieves the performance significantly better than any other competing schemes.	Reply	I-Reply	1
This would have not been possible without a neural network decoder and the techniques we learned in training one to mimic the simple Viterbi.	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
Updated curve for new codes on AWGN channel with feedback:[line_break_token]We have improved our encoder significantly by borrowing the idea of zero-padding from coding theory.	Reply	O	0
In short, most of the errors occurs in the last bit, whose feedback information was not utilized by our encoder.	Reply	B-Reply	3
We resolved this issue by padding a zero in the end of information bits (Hence, the codeword length is 3(K+1) for K information bits).	Reply	I-Reply	3
This significantly improves the performance as shown in the new Figure 8.	Reply	I-Reply	3
A full description of the encoder-decoder architecture is provided in Appendix D. [line_break_token][line_break_token]4.	Reply	O	0
We replaced "(8,16) polar code" by ‚Äúrate 1/2 polar code over 8 information bits‚Äù	Reply	B-Reply	4

Pros:[line_break_token]- The paper address the problem of zero-shot translation.	Review	O	0
The proposed method is essentially to bootstrap a Dual Learning process using a multilingual translation model that already has some degree of zero-shot translation capabilities.	Review	O	0
The idea is simple, but the approach improves the zero-shot translation performance of the baseline model, and seems to be better than either pivoting or training on direct but out-of-domain parallel data.	Review	O	0
[line_break_token]- The paper is mostly well written and easy to follow.	Review	O	0
There are some missing details that I've listed below.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- There is very little comparison to related work.	Review	O	0
For example, related work by Chen et al. [	Review	B-Review	9
1], Gu et al. [	Review	I-Review	9
2] and Lu et al. [	Review	I-Review	9
3] are not cited nor compared against.	Review	I-Review	9
[line_break_token][line_break_token]Misc questions/comments:[line_break_token]- In a few places you call your approach unsupervised (e.g., in Section 3: "Our method for unsupervised machine translation works as follows: (...)"; Section 5.2 is named "Unsupervised Performance").	Review	O	0
But your method is not unsupervised in the traditional sense, since you require lots of parallel data for the target languages, just not necessarily directly between the pair.	Review	B-Review	1
This may be unrealistic in low-resource settings if there is not an existing suitable pivot language.	Review	I-Review	1
It'd be more accurate to simply say "zero-shot" (or maybe "semi-supervised") in Section 3 and Section 5.2.	Review	I-Review	1
[line_break_token]- In Section 3.1 you say that your process implements the three principles outlined in Lample et al. (	Review	O	0
2018b).	Review	B-Review	2
However, the Initialization principle in that work refers to initializing the embeddings -- do you pretrain the word embeddings as well?	Review	I-Review	2
[line_break_token]- In Section 4 you say that the "UN corpus is of sufficient size".	Review	O	0
Please mention what the size is.	Review	B-Review	3
[line_break_token]- In Section 4.2, you mention that you set dropout to p=0.65 when training your language model -- this is very high!	Review	O	0
Did you tune this?	Review	B-Review	4
Does your language model overfit very badly with lower dropout values?	Review	I-Review	4
[line_break_token]- In Section 5.2, what is the BLEU of an NMT system trained on the es->fr data (i.e., what is the upper bound)?	Review	O	0
What is the performance of a pivoting model?	Review	B-Review	5
[line_break_token]- In Section 5.3, you say you use "WMT News Crawl, all years."	Review	O	0
Please indicate which years explicitly.	Review	B-Review	6
[line_break_token]- In Table 3, what is the performance of a supervised NMT system trained on 1M en-fr sentences of the NC data?	Review	O	0
Knowing that would help clarify the impact of the domain mismatch.	Review	B-Review	7
[line_break_token]- minor comment: in Section 4.3 you say that you trained on Tesla-P100, but do you mean Pascal P100 or Tesla V100?	Review	O	0
[line_break_token][line_break_token][1] Chen et al.:	Review	O	0
<a href="http://aclweb.org/anthology/P17-1176" target="_blank" rel="nofollow">http://aclweb.org/anthology/P17-1176</a>[line_break_token][2] Gu et al.:	Review	O	0
<a href="http://aclweb.org/anthology/N18-1032" target="_blank" rel="nofollow">http://aclweb.org/anthology/N18-1032</a>[line_break_token][3] Lu et al.:	Review	O	0
<a href="http://www.statmt.org/wmt18/pdf/WMT009.pdf" target="_blank" rel="nofollow">http://www.statmt.org/wmt18/pdf/WMT009.pdf</a>	Review	O	0
1.	Reply	O	0
We'd argue that our approach is unsupervised in the sense that we are training a model without data for the task we are training.	Reply	B-Reply	1
From a practical perspective, having parallel data for another language pair is not always possible, as is, to a lesser extent, having monolingual data.	Reply	I-Reply	1
We do agree that we should stress that our approach is zero-shot to avoid confusion with unsupervised learning.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	5
We do not pretrain the embeddings on their own; they are trained with the rest of the baseline multilingual model.	Reply	I-Reply	2
That is, the zero-shot training (before RL) performs the embedding pre-training as the initialization step.	Reply	I-Reply	2
This step initializes not only the embeddings but also the weights of the translation model, which could be considered a stronger variant of the unsupervised lexicon induction via word vectors.	Reply	I-Reply	2
Apart from the initialization, our approach also leverages language models and back-translation to learn the zero-shot translation directions in the form of rewards.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	6
We use the bilingually aligned data for each language pair.	Reply	I-Reply	3
They are approximately of size 18M, 25M and 22M for en-es, en-fr and es-fr, respectively.	Reply	I-Reply	3
Each of the development and test sets contain 4000 sentences.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	5
It is indeed high.	Reply	I-Reply	4
We did not tune the hyperparameters of the language model (we use the default ones for the big model in the Tensorflow RNN tutorial) since the weight that we currently use for its reward (the one presented in He et al.)	Reply	I-Reply	4
is so low (0.005).	Reply	I-Reply	4
However, we plan to analyze its role and we will then need to analyze all hyperparameters more in depth to obtain a better performance.	Reply	I-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
For a single direction model with the same capacity, es->fr and fr->es achieve 42.50 and 44.86 respectively.	Reply	O	0
These models were trained on the same 1M sentences used for RL (also using their corresponding translations).	Reply	B-Reply	5
As for the pivoting experiments on the UN setup, we do not have the exact numbers but they were slightly below the Dual-0 performance.	Reply	I-Reply	5
[line_break_token][line_break_token]6.	Reply	O	0
All the years that include Spanish: 2007-2013.	Reply	B-Reply	6
[line_break_token][line_break_token]7.	Reply	O	0
The NewsCrawl is monolingual and thus, we cannot train a supervised NMT system on it.	Reply	B-Reply	7
We did not use the News Commentary corpus, which, while more 'newsy', still differs in style.	Reply	I-Reply	7
The Pseudo-NMT is the closest scenario to supervised in-domain training for this setting and we do report these numbers.	Reply	I-Reply	7
[line_break_token][line_break_token]8.	Reply	O	0
We train on NVIDIA Tesla P100 which use the NVIDIA Pascal GPU architecture.	Reply	B-Reply	8

This paper revisits a subject that I have not seen revisited empirically since the 90s: the relative performance of TD and Monte-Carlo style methods under different values for the rollout length.	Review	O	0
Furthermore, the paper performs controlled experiments using the VizDoom environment to investigate the effect of a number of other environment characteristics, such as reward sparsity or perceptual complexity.	Review	O	0
The most interesting and surprising result is that finite-horizon Monte Carlo performs competitively in most tasks (with the exception of problems where terminal states play a big role (it does not do well at all on Pong!),	Review	O	0
and simple gridworld-type representations), and outperforms TD approaches in many of the more interesting settings.	Review	O	0
There is a really interesting experiment performed that suggests that this is the case due to finite-horizon MC having an easier time with learning perceptual representations.	Review	O	0
They also show, as a side result, that the reward decomposition in Dosvitskiy & Koltun (oral presentation at ICLR 2017) is not necessary for learning a good policy in VizDoom.	Review	O	0
[line_break_token][line_break_token]Overall, I find the paper important for furthering the understanding of fundamental RL algorithms.	Review	O	0
However, my main concern is regarding a confounding factor that may have influenced the results: Q_MC uses a multi-headed model, trained on different horizon lengths, whereas the other models seem to have a single prediction head.	Review	O	0
May this helped Q_MC have better perceptual capabilities?	Review	B-Review	1
[line_break_token][line_break_token]A couple of other questions:[line_break_token]- I couldn't find any mention of eligibility traces - why?	Review	O	0
[line_break_token]- Why was the async RL framework used?	Review	O	0
It would be nice to have a discussion on whether this choice may have affected the results.	Review	B-Review	3
We thank the reviewer for the careful review and useful suggestions.	Reply	O	0
[line_break_token][line_break_token]> Q_MC uses a multi-headed model, trained on different horizon lengths, whereas the other models seem to have a single prediction head.	Reply	O	0
May this helped Q_MC have better perceptual capabilities?	Reply	O	0
[line_break_token][line_break_token]As we discuss in the supplement section "Difference between asynchronous n-step Q and Q_MC", n-step Q learning relies on the use of multiple rollouts within one batch.	Reply	B-Reply	1
The only way to use multiple rollouts in a finite horizon MC setting is by having multiple heads.	Reply	I-Reply	1
Therefore we used the better variants of both algorithms throughout the paper.	Reply	I-Reply	1
To make sure that the multiple heads are not the reason for the better perceptual capabilities, we added perception learned by the 1-head Q_MC algorithm to the Table 3, receiving similar results to the multi head perception.	Reply	I-Reply	1
[line_break_token][line_break_token]> I couldn't find any mention of eligibility traces - why?	Reply	O	0
[line_break_token][line_break_token]Eligibility traces are used in order to implement the TD(lambda) algorithm in the backward view.	Reply	B-Reply	2
In our paper we interpolate between MC and TD using n-step Q learning with different n values instead of TD(lambda).	Reply	I-Reply	2
There are multiple reasons for this decision.	Reply	I-Reply	2
First, most of the recent RL algorithms use a forward view implementation.	Reply	I-Reply	2
Second, recent methods achieve best performance using RMS or Adam optimizers, but algorithms with eligibility traces are based on stochastic gradient descent and do not trivially carry over to other optimizers.	Reply	I-Reply	2
Third, van Seijen has shown that standard TD(lambda) with eligibility traces does not perform well when combined with non-linear function approximation (van Seijen, Effective Multi-step Temporal-Difference Learning for Non-Linear Function Approximation 2016).	Reply	I-Reply	2
Therefore, we decided to focus on algorithms that do not use eligibility traces.	Reply	I-Reply	2
[line_break_token][line_break_token]> Why was the async RL framework used?	Reply	O	0
[line_break_token][line_break_token]Q_MC and n-step Q (n>1) are both on-policy algorithms.	Reply	O	0
We follow the asynchronous training framework for on-policy RL algorithms from Mnih at al.	Reply	B-Reply	3
2016.	Reply	I-Reply	3
 Asynchronous training allows us to run experiments efficiently on CPUs, which are more easily available than GPUs.	Reply	I-Reply	3
Moreover, we have found that asynchronous Q_MC achieves similar performance as synchronous DFP, therefore we expect no major impact of this implementation detail on the results.	Reply	I-Reply	3

This paper discusses several interesting phenomena regarding the training and testing error curves over the course of training deep network models on image classification tasks.	Review	O	0
Among the findings are that test error performance can be nonmonotonic with certain learning rates, and imposing a cyclic alternation between low and high learning rates can speed learning.	Review	O	0
[line_break_token][line_break_token]-While these results may point to something deeper, additional control experiments would greatly strengthen the paper.	Review	O	0
The finding that a cyclic learning schedule can speed learning would be potentially of practical interest, but the experiments compare just one particular cyclic scheme to one particular fixed learning rate.	Review	B-Review	1
Does a carefully optimized fixed learning rate match the cyclic performance?	Review	I-Review	1
Is a cycle really necessary, or can the learning rate just decrease monotonically over the course of learning?	Review	I-Review	1
[line_break_token][line_break_token]-There may be simple standard explanations of these phenomena.	Review	O	0
The test error spikes up on each cycle as the learning rate crosses some threshold, which seems a straightforward case of SGD becoming unstable and diverging when the learning rate is made too high.	Review	B-Review	2
After taking a giant bad step, higher learning rates can make progress because the network is terrible and fine adjustments are not necessary.	Review	I-Review	2
More is necessary to back up the claim that these results provide insight into the "loss function topology."	Review	I-Review	2
[line_break_token][line_break_token]+The finding of faster convergence with cyclic learning rate schedules, if it remains faster than the optimal fixed or monotonically decreasing schedule, would be very interesting and merits more investigation.	Review	O	0
[line_break_token][line_break_token]+The suggestion of interpolating many models to yield higher generalization performance is also a potentially interesting direction.	Review	O	0
We believe the intent of the ICLR workshop is to provide a forum for late-breaking results, even if a paper hasn't been fully developed into what one expects for a conference paper.	Reply	O	0
 Our workshop paper is such a paper, providing experimental results that have not been seen before, though it isn't as fully developed as a conference paper.	Reply	O	0
[line_break_token][line_break_token]Unfortunately, the 3-page limit meant not showing the control experiments and many of the other results we've obtained.	Reply	B-Reply	1
 We ran experiments with a variety of learning rate schedules, architectures, solvers, and hyper-parameters.	Reply	I-Reply	1
We mentioned some of the other results very briefly in our conclusion but could not include them fully due to space limitations.	Reply	I-Reply	1
[line_break_token][line_break_token]The original cyclical learning rate paper (Smith 2015, Smith 2017) discusses that the current scheme was compared with many other cyclic methods and the linear scheme was chosen because the more complex methods provided no additional benefit.	Reply	I-Reply	1
 Please skim the earlier paper for more details.	Reply	I-Reply	1
 The purpose of this current paper was not to introduce cyclical learning rate as a practical tool but to show it is also an experimental tool that demonstrates the new phenomena described.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding Figure 2a, some simple explanations are possible, and there are certainly many examples in the literature where SGD becomes unstable and diverges.	Reply	I-Reply	2
 However, to our knowledge, the literature does not show examples where SGD becomes unstable, diverges, and then starts converging (note that the test accuracy falls slightly and recovers quickly), especially while the learning rate continues to increase.	Reply	I-Reply	2
 This is why we include this as a novel phenomenon.	Reply	I-Reply	2
 Furthermore, from a geometric perspective, one can imagine that the increasing learning rate causes the solution to jump out of a local minimum and hence the sudden jump but, if so, why would it continue to converge while learning rate increases?	Reply	I-Reply	2
 We believe these phenomena are unusual and are providing some insight into the loss function topology.	Reply	I-Reply	2
[line_break_token][line_break_token]In addition, Figure 1 shows the plots that started our investigation and we don't think your explanation holds for this example.	Reply	I-Reply	2
These plots show test accuracy during regular training (not using cyclical learning rates), so the learning rate is monotonically decreasing.	Reply	I-Reply	2
Furthermore, the dip in test accuracy happens for an initial learning rate of 0.14 but not for 0.24 or 0.35.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding Figure 2b, it does show the cyclical learning rate result compared to an optimal monotonically decreasing schedule.	Reply	I-Reply	3
 The point is that within 20,000 iterations it produced a better solution than the optimal schedule could in 80,000 - 100,000 iterations.	Reply	I-Reply	3
 We also feel it is interesting that such high performance is possible when the smallest value used for the learning rate is 0.1, which is commonly considered large.	Reply	I-Reply	3
[line_break_token][line_break_token]As we say in the Conclusions, we are actively searching for a collaborator who can provide a theoretical analysis for a full follow-up paper.	Reply	O	0
We welcome any readers who feel they understand the theoretical causes for these phenomena to please contact me.	Reply	O	0

= Summary[line_break_token]A variation of Neural Turing Machines (and derived models) storing the configuration of the controller in a separate memory, which is then "softly" read during evaluation of the NTM.	Review	O	0
Experiments show moderate improvements on some simple multi-task problems.	Review	O	0
[line_break_token][line_break_token]= Strong/Weak Points[line_break_token]+ The idea of generalising NTMs to "universal" TMs is interesting in itself ...[line_break_token]- ... however, the presented solution seems to be only half-way there, as the memory used for the "program" is still separate from the memory the NUTM operates on.	Review	O	0
Hence, modifying the program itself is not possible, which UTMs can do (even though it's never useful in practice...)[line_break_token]- The core novelty relative to standard NTMs is that in principle, several separate programs can be stored, and that at each timestep, the "correct" one can be read.	Review	O	0
However this read mechanism is weak, and requires extra tuning with a specialized loss (Eq. (	Review	B-Review	2
6))[line_break_token]~ It remains unclear where this is leading - clearly NTMs and NUTMs (or their DNC siblings) are currently not useful for interesting tasks, and it remains unclear what is missing to get there.	Review	O	0
The current paper does not try show the way there.	Review	B-Review	3
[line_break_token]- The writing is oddly inconsistent, and important technical details (such as the memory read/write mechanism) are not documented.	Review	O	0
I would prefer the paper to be self-contained, to make it easier to understand the differences and commonalities between NTM memory reads and the proposed NSM mechanism.	Review	B-Review	4
[line_break_token][line_break_token]= Recommendation[line_break_token]Overall, I don't see clear, actionable insights in this submission, and thus believe that it will not provide great value to the ICLR audience; hence I would recommend rejecting the paper to allow the authors to clarify their writing and provide more experimental evidence of the usefulness of their contribution.	Review	O	0
[line_break_token][line_break_token]= Minor Comments[line_break_token]+ Page 6: "As NUTM requires fewer training samples to converge, it generalizes better to unseen sequences that are longer than training sequences." -	Review	O	0
I don't understand the connecting between the first and second part of the sentence.	Review	B-Review	5
This seems pure speculation, not a fact.	Review	I-Review	5
e thank the reviewer for your helpful comments.	Reply	O	0
We address your concerns one by one as follows,[line_break_token][line_break_token]‚ÄúHence, modifying the program itself is not possible, ...‚Äù.	Reply	O	0
We want to clarify that our working program (the one that is loaded into the interface network) is modified across timestep and our basis program (the one that is stored in the program memory) is modified by backpropagation.	Reply	B-Reply	1
[line_break_token][line_break_token]‚ÄúHowever this read mechanism is weak, ...‚Äù.	Reply	O	0
Our program reading mechanism may be simple.	Reply	B-Reply	2
Yet, it helps boost the performances of various MANNs.	Reply	I-Reply	2
More importantly, it helps the models behave as designed (see Fig.	Reply	I-Reply	2
3 (a,b,c) and other figures in Appendix).	Reply	I-Reply	2
[line_break_token][line_break_token]‚ÄúIt remains unclear where this is leading ...‚Äù.	Reply	O	0
Our method leads to a new class of MANNs that can store and query both the weights and data of their own controllers.	Reply	B-Reply	3
One reason why MANNs maybe not useful is the lack of program memory.	Reply	I-Reply	3
Without program memory, MANNs are inflexible, prone to perseveration and fail to simulate UTM.	Reply	I-Reply	3
We aim to fix this weakness in this paper.	Reply	I-Reply	3
Our attempts help MANNs improve their performance in various experiments including algorithmic, compositional, continual, few-shot learning and question-answering tasks (Sec.	Reply	I-Reply	3
4).	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúThe writing is oddly inconsistent, ...‚Äù.	Reply	O	0
As our method is generic and can apply to various MANNs, we cannot describe all memory access mechanisms of the chosen MANNs in the main manuscript.	Reply	B-Reply	4
NSM's memory access uses key-value attention, which can be thought of as an extension of content-based attention presented in NTM or DNC.	Reply	I-Reply	4
The main difference is that the value in NSM is the weight of a neural network, not the data as in other MANNs.	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúOverall, I don't see clear, actionable insights, ...‚Äù.	Reply	O	0
In this paper, we provide the reader with a new insight into the simulation capacity of MANNs.	Reply	B-Reply	6
We point out the missing part of current MANN literature and propose a more generic architecture that can simulate UTM.	Reply	I-Reply	6
We have conducted 6 experiments to validate the benefit of our proposed architecture.	Reply	I-Reply	6
[line_break_token][line_break_token]Thank you for your minor comment.	Reply	O	0
The sentence is based on our intuition and validated by Table 1.	Reply	B-Reply	5
To make it less confusing, in the updated manuscript, we just report facts and do not assume any causality: ‚ÄúNUTM requires fewer training samples to converge and it generalizes better to unseen sequences that are longer than training sequences‚Äù	Reply	I-Reply	5

GEOM-GCN: GEOMETRIC GRAPH CONVOLUTIONAL NETWORKS [line_break_token][line_break_token]The paper introduces a novel GCN framework, whose purpose is to overcome weaknesses of existing GCN approaches, namely loss of structural neighbor information and failure to capture important dependencies between distant nodes.	Review	O	0
The paper uses a mapping from nodes to an embedded space and introduces a second type of a neighborhood: a proximity in the embedded space.	Review	O	0
In the embedded space, a set of relations of nodes is defined.	Review	O	0
For each node v, the paper uses a 2-stage convolution scheme: 1) for each neighborhood type, the nodes in the same relation with v are combined; 2) the resulting nodes are again combined into a new feature vector.	Review	O	0
This approach allows one to overcome the issues described above.	Review	O	0
The experiments show that in most cases the approach outperforms the existing GCN solutions, sometimes with a large gap.	Review	O	0
[line_break_token][line_break_token]I have the following concerns about the paper:[line_break_token]-- My main concern is the learning time, which is an issue for a straightforward GCN implementation.	Review	O	0
There were multiple attempts to decrease it (GraphSAGE, FastGCN, etc.).	Review	B-Review	1
Therefore, I would like to see running times on the presented graphs as well as on relatively large graphs (see e.g. <a href="https://arxiv.org/pdf/1902.07153.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1902.07153.pdf</a> for candidates).	Review	O	0
If some techniques were used to make the implementation faster, I would be good to include them in the paper (or, if they are standard, they should be referenced).	Review	B-Review	1
At the very least, I believe it should be prioritized as a future direction.	Review	I-Review	1
[line_break_token]-- It‚Äôs unclear why we should use the same latent space and the same œÑ for both N_g and N_s.	Review	O	0
I would expect that mapping into different spaces could provide better results: the two neighborhood types seem very different, and I don‚Äôt see why the neighbors should be aggregated in the same way.	Review	B-Review	2
If using different spaces doesn‚Äôt provide an improvement, an explanation for this would be very useful.	Review	I-Review	2
[line_break_token]-- Œ± and Œ≤ are defined and shown in Table 2, but they are never used (as it stands now, Œ± and Œ≤ can simply be removed).	Review	O	0
If the results in Table 3 correlate with them, then this dependence should be highlighted.	Review	B-Review	3
In such case, it would also be better to move Œ± and Œ≤ to Table 3.	Review	I-Review	3
[line_break_token]-- The paper uses 3 different node embedding strategies.	Review	O	0
These strategies can be combined in q with different weights (which can be learned as hyperparameters).	Review	B-Review	4
Will it produce the best of 3 (or better) result?	Review	I-Review	4
[line_break_token]-- ‚ÄúWe use an embedding space of dimension 2 for ease of explanation‚Äù But what œÑ is used in the real implementation?	Review	O	0
[line_break_token]-- There are various GCN implementations; however, the comparison is performed with only 2 of them.	Review	O	0
I would like to see either comparison with more implementations, or the explanation why the comparison with the given two suffices.	Review	B-Review	6
[line_break_token]-- Is it possible to make the implementation available?	Review	O	0
[line_break_token][line_break_token]While there are a lot of possible improvements, I believe that some of them can be addressed in a future research, and the paper‚Äôs novel approach is noteworthy in itself.	Review	O	0
My current verdict is 5/10, and I‚Äôll be happy to improve it if the above issues are fixed.	Review	O	0
[line_break_token][line_break_token]Presentation issues:[line_break_token]-- The notation used in definition of m_v^l is unclear.	Review	O	0
[line_break_token]-- Why œÑ is a part of each node‚Äôs structural neighborhood?	Review	O	0
It‚Äôs a global function, isn‚Äôt it?	Review	B-Review	9
[line_break_token]-- Introduction: I believe that the exact problems which GCNs solve (e.g. node classification) should be mentioned.	Review	O	0
[line_break_token]-- The flow in Section 2.1 is a bit weird.	Review	O	0
Namely, it says ‚ÄúTo overcome the first weakness‚Äù, but the first wickness wasn‚Äôt stated in the previous paragraph (of course, one can deduce it, and it also was defined long ago, but it‚Äôs disturbing for a reader).	Review	B-Review	11
[line_break_token]-- Figure 1B is confusing: it looks like the nodes from N_g(v) lie in a small region around v.[line_break_token]-- I think that splitting Figure 1C into 2 figures would make it clearer.	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for the helpful comments.	Reply	O	0
We have revised the paper according to the suggestions and would like to answer the reviewer‚Äôs questions as follows:[line_break_token][line_break_token]Q1.	Reply	O	0
My main concern is the learning time, which is an issue for a straightforward GCN implementation.	Reply	O	0
There were multiple attempts to decrease it (GraphSAGE, FastGCN, etc.).	Reply	O	0
Therefore, I would like to see running times on the presented graphs as well as on relatively large graphs (see e.g. <a href="https://arxiv.org/pdf/1902.07153.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1902.07153.pdf</a> for candidates).	Reply	O	0
If some techniques were used to make the implementation faster, I would be good to include them in the paper (or, if they are standard, they should be referenced).	Reply	O	0
At the very least, I believe it should be prioritized as a future direction.	Reply	O	0
[line_break_token][line_break_token]Response: [line_break_token][line_break_token]It's a great suggestion.	Reply	O	0
According to it, we add a new section (Section 4.3.3) in the revision to systematically analyze the running time of the proposed Geom-GCN.	Reply	B-Reply	1
In this section, we firstly present the theoretical time complexity of Geom-GCN and then compare the real running time of GCN, GAT, and Geom-GCN.	Reply	I-Reply	1
To decrease the running time, we think it's promising future work to apply the accelerating technologies for GCN (e.g., FastGCN and SCG) to Geom-GCN.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Q2.	Reply	O	0
It‚Äôs unclear why we should use the same latent space and the same for both N_g and N_s.	Reply	O	0
I would expect that mapping into different spaces could provide better results: the two neighborhood types seem very different, and I don‚Äôt see why the neighbors should be aggregated in the same way.	Reply	O	0
If using different spaces doesn‚Äôt provide an improvement, an explanation for this would be very useful.	Reply	O	0
[line_break_token][line_break_token]Response: [line_break_token][line_break_token]Thanks for the suggestion.	Reply	O	0
We add a new section (Section 4.3.2) in the revision to study how the embedded latent spaces influence the structural neighborhood.	Reply	B-Reply	2
 To this end, we construct several new Geom-GCN variants, which use a combination of neighborhoods defined by different embedded spaces.	Reply	I-Reply	2
From Table 5, we can observe that several variants achieve better performance than the original Geom-GCN with neighborhoods defined by only one embedded space.	Reply	I-Reply	2
On the other hand, there are also many variants that have bad performances.	Reply	I-Reply	2
 That is, the efficacy of Geom-GCN would depend on the selected embedded spaces.	Reply	I-Reply	2
Thus, we think it's important future work to design an end-to-end framework that is able to automatically determine the right embedded spaces for Geom-GCN.	Reply	I-Reply	2
We have finished the analysis on six small datasets in the current revision, and comprehensive results will be added in the future revision.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Q3.	Reply	O	0
and are defined and shown in Table 2, but they are never used (as it stands now, and can simply be removed).	Reply	O	0
If the results in Table 3 correlate with them, then this dependence should be highlighted.	Reply	O	0
In such a case, it would also be better to move and to Table 3.	Reply	O	0
[line_break_token][line_break_token]Response:[line_break_token][line_break_token]Thanks for the suggestion.	Reply	O	0
In the revision, we analysis the correlate between and the results in Table 4.	Reply	B-Reply	3
We find that the latent space neighborhoods have larger contributions in disassortative graphs (with a small) than assortative ones, which implies relevant information from disconnected nodes is aggregated effectively in the neighborhood of the latent space.	Reply	I-Reply	3
Please see Section 4.3.1 in revision for details.	Reply	I-Reply	3
And we removed in the revision.	Reply	I-Reply	3
 [line_break_token][line_break_token][line_break_token]Q4.	Reply	O	0
The paper uses 3 different node embedding strategies.	Reply	O	0
These strategies can be combined in q with different weights (which can be learned as hyperparameters).	Reply	O	0
Will it produce the best of 3 (or better) result?	Reply	O	0
[line_break_token][line_break_token]Response:[line_break_token][line_break_token]It's a very interesting idea.	Reply	O	0
To implement the idea, we construct a new Geom-GCN variant that contains six neighborhoods defined by all the three embedded spaces.	Reply	B-Reply	4
Then we evaluate the variant on the graph datasets.	Reply	I-Reply	4
However, its performance is not good.	Reply	I-Reply	4
We think it is because of two reasons, i) the variant is very hard to train since it has too many parameters; ii) there is too much irrelevant information from the six neighborhoods, which implies that the relevant information may be ‚Äúwashed out‚Äù by too much irrelevant information.	Reply	I-Reply	4
We also release the code of this experiment in GitHub anonymously, please find the link in the following.	Reply	I-Reply	4
[line_break_token][line_break_token]Q5. ‚	Reply	O	0
ÄúWe use an embedding space of dimension 2 for ease of explanation‚Äù But what is used in the real implementation?	Reply	O	0
[line_break_token][line_break_token]Response:[line_break_token][line_break_token]In the real implementation, we use the that we defined in Table 1 (section 3).	Reply	O	0
In the revision, we exactly mention which is used in the experiment section	Reply	B-Reply	5

*UPDATE* I have read the other reviews and authors' responses.	Review	O	0
All the reviewers agree that improving single-shot NAS is an important problem, and that sampling single-paths can be a plausible approach for it that avoids weight coupling.	Review	O	0
Consequently, I have updated my rating to weak accept.	Review	O	0
I think the paper can be substantially stronger though.	Review	O	0
[line_break_token]The key claim that set this paper apart from other single-path NAS approaches is that they use a fixed distribution (in particular, the uniform distribution) to sample from unlike others like FBnet who use a trainable distribution.	Review	O	0
They argue that uniform is parameter-free whereas trainable distributions introduce additional parameters that need to be trained.	Review	O	0
Their findings motivate a natural follow-up question: could we use a different fixed distribution?	Review	B-Review	1
Reviewer2 has a similar question in their review.	Review	I-Review	1
Perhaps a distribution that is weighted according to (some proxy of) how much computational resource the networks take to train?	Review	I-Review	1
Could such a distribution also be parameter-free and give good benefit over uniform distribution without needing to be updated during supernet training?	Review	I-Review	1
Such an analysis of the prior distribution will make the paper even stronger.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]The paper studies a sequential optimization approach to neural architecture search that can provide some benefit over nested or joint approaches.	Review	O	0
The core challenge in sequential approaches (which first train the weights of a supernetwork; then search through possible architectures which inherit appropriate weights from the supernetwork) is that the weights for a giant network may not be optimal for the weights of a sub-network encountered during subsequent architecture search.	Review	O	0
The core benefit of such an approach compared to nested approaches is that the subsequent search phase only needs to perform network inference with inherited weights; not train a sub-network from scratch.	Review	O	0
[line_break_token]The primary contribution is to fix a prior distribution over architectures and sample from them when training the supernetwork.	Review	O	0
This simple fix helps the weights of the giant network be more useful when inherited into any sub-networks during architecture search.	Review	O	0
[line_break_token]The paper will be substantially stronger with a careful study of the choice of the prior distribution and how it affects (a) the rejection sampling step needed to ensure the sampled architectures satisfy complexity constraints, and (b) the performance of the eventual neural architecture search procedure.	Review	B-Review	1
[line_break_token]Another experiment that will be valuable is to rigorously validate the hypothesis that reducing weight coupling in the supernetwork training is crucially linked to improving the downstream architecture search performance.	Review	O	0
[line_break_token][line_break_token]Minor (writing comments):[line_break_token]Introduction: "Complex optimization techniques are adopted."	Review	B-Review	2
This statement is awkward.	Review	I-Review	2
Does this paper specifically adopt more complex methods to address the shortcomings of gradient methods.	Review	I-Review	2
Or, does the community broadly research more complex methods as a consequence (and you are advocating for a return to simpler gradient methods)?	Review	I-Review	2
[line_break_token]Pg5: "we randomly choice a range" -&gt; "choose"[line_break_token]	Review	O	0
hanks for your comments.	Reply	O	0
[line_break_token]        1.	Reply	O	0
I read the comments thoroughly and find that you give a detailed summary of our paper.	Reply	O	0
It seems that you have understood the idea and the contribution of our paper from your comments.	Reply	O	0
But I didn‚Äôt see any problem about the paper was pointed out except the minor writing problems.	Reply	O	0
 If you have any concerned question, it is our pleasure to give you an answer.	Reply	O	0
[line_break_token]        2.	Reply	O	0
As for the writing problems, we have revised them.	Reply	B-Reply	2
Thanks for pointing out that.	Reply	O	0

One extra comment: the approach bears some similarity to the model of Grave, Obozinski and Grave (CoNLL 2013), where they associate latent variables with nodes in a syntactic dependency tree and draw words conditioned on the variables.	Review	B-Review	1
As in this paper, Grave et al.	Review	I-Review	1
do not perform hard clustering (as in Brown clustering) but rather approximate posteriors at test time (based on the entire sentence).	Review	I-Review	1
Thank you for your comments.	Reply	O	0
We try to answer them below:[line_break_token]1, 2 and 3: We have updated the paper by taking your suggestions in consideration.	Reply	O	0
In short, 1)we have properly cited the original FHMM model where necessary, 2) They are found by setting the derivative of the objective function wrt phi to zero which has a closed form solution and 3) We updated the results by using the prefixes of size 4, 6, 10 and 20 in addition to the whole path of the brown clusters.	Reply	B-Reply	2
[line_break_token]4.	Reply	O	0
Although it is an interesting idea, we have not used it in our current results.	Reply	B-Reply	3
[line_break_token]5.	Reply	O	0
We have updated the paper with the results from using 50-dimensional word embedding trained on our data using Collobert and Weston (2008).	Reply	B-Reply	4
[line_break_token]6 and extra comment: Thank you for the pointers on the related work.	Reply	O	0
We have added them in our previous work section	Reply	B-Reply	1

The paper presents an unsupervised method for graph embedding.	Review	O	0
[line_break_token][line_break_token]Despite having good experimental results, the paper is not of the quality to be accepted to the conference yet.	Review	B-Review	1
The approach is rather a mix of previous works and hence not novel.	Review	I-Review	1
[line_break_token][line_break_token]In particular, the algorithm for WL decomposition is almost fully taken from the original paper with a slight modification.	Review	I-Review	1
Advantage of using it for unlabeled data is poorly motivated as unlabeled graphs can easily take statistics such as degree as the node labels, which was shown well in practice.	Review	I-Review	2
[line_break_token][line_break_token]Modified PV-DBOW is in fact the same algorithm as the original CBOW model but applied to different context.	Review	I-Review	3
It has been used in many papers, including Deep GK, graph2vec, anonymous walks.	Review	I-Review	3
[line_break_token][line_break_token]Also, the Figure 1.	Review	I-Review	4
is taken from the original paper of WL kernel.	Review	I-Review	4
The algorithms 1 and 2 are taken from the original papers with slight modifications.	Review	I-Review	4
[line_break_token][line_break_token]There is no discussion of [1], which uses CBOW framework, has theoretical properties, and produces good results in experiments.	Review	I-Review	5
There is no comparison with GNN models such as [2]. [line_break_token][line_break_token]I would be more interested to see explanation of the obtained results for each particular dataset (e.g. why MUTAG has 92% accuracy and PTC 67%); what so different about dataset and whether we reached a limit on most commonly used datasets.	Review	O	0
[line_break_token][line_break_token][1] Anonymous Walk Embeddings?	Review	O	0
ICML 2018, Ivanov et.	Review	O	0
al.	Review	O	0
[line_break_token][2] How Powerful are Graph Neural Networks?	Review	O	0
ICLR 2019, Xu et.	Review	O	0
al.	Review	O	0
irst of all thank you very much for your review of this work, we will attempt to address some of the comments and questions below.	Reply	O	0
[line_break_token][line_break_token]‚ÄúDespite having good experimental results, the paper is not of the quality to be accepted to the conference yet.	Reply	O	0
The approach is rather a mix of previous works and hence not novel.	Reply	O	0
‚Äù [line_break_token]And[line_break_token]‚ÄúIn particular, the algorithm for WL decomposition is almost fully taken from the original paper with a slight modification... ‚Äú[line_break_token][line_break_token]This paper relies on previous models such as Deep Graph Kernels and Graph2Vec to extract and explicitly specify a general pipeline for building models capable of learning distributed representations of graphs.	Reply	O	0
 The pipeline is based on two parts: the decompositions of graphs into substructures (walks, subtrees, nodes, etc) and the learning distributed representations using such substructures with different definitions of context and associated embedding methods (word2vec, GLoVe, etc.).	Reply	B-Reply	1
[line_break_token][line_break_token]The second half of the write-up focuses on G2DR (explicitly stated as an extension of Graph2Vec) as an instance of this pipeline described above.	Reply	I-Reply	1
G2DR is a straightforward extension of the Graph2Vec to more graph types (unlabelled graphs) through adoption of Shervashidze et al‚Äôs WL algorithm to find subtree patterns, we have put it in this work with minor modification for notation because otherwise it wouldn‚Äôt be the same WL algorithm.	Reply	I-Reply	1
We believe in keeping the algorithm in the paper as it aids description of the specific implementation used and is correctly acknowledged as being the Shervashidze WL algorithm within the paper (section 3.1.1).	Reply	I-Reply	1
We are afraid that simply pointing to the Shervashidze et al‚Äôs exact presentation would detract from the reading and flow of the paper as different notation is used.	Reply	I-Reply	1
[line_break_token][line_break_token]To summarise we can garner two contributions here:[line_break_token]Specification of a general pipeline for building models capable of learning distributed representations of graphs.	Reply	I-Reply	1
[line_break_token]An extended version of Graph2Vec, called G2DR which is applicable to unlabelled graphs and is also more amenable to diagonal dominance through pruning of the subgraph vocabularies.	Reply	I-Reply	1
This makes it perform better on larger graphs/datasets.	Reply	I-Reply	1
[line_break_token][line_break_token]‚ÄùAdvantage of using it for unlabeled data is poorly motivated as unlabeled graphs can easily take statistics such as degree as the node labels, which was shown well in practice.	Reply	O	0
‚Äù[line_break_token][line_break_token]We explicitly state our use of Shervashize et al‚Äôs suggestion to label unlabelled nodes initially by their degree, otherwise the WL algorithm cannot be run for the unlabelled graphs such as the Reddit datasets.	Reply	O	0
The contribution here is the application of this suggestion within another existing algorithm (Graph2Vec) to expand its applicability to more graph types and improve the performance of the GetSubgraph() (which is their rendition of the subtree decomposition algorithm) algorithm stated in Graph2Vec.	Reply	B-Reply	2
[line_break_token][line_break_token]Once the unlabelled nodes are labelled by their degree, the motivation of using the WL algorithm falls upon motivating the usage of the rooted subtree patterns extracted.	Reply	I-Reply	2
We touch upon this section 3.1.1 and is potentially better covered in the WL Kernel and Graph2Vec works.	Reply	I-Reply	2
Essentially the motivation is that they are higher order substructures (than nodes), non-linear around definition of the neighbourhood around a node (as compared to a random walk), and the exhaustive nature of decomposition for subtree patterns for every node in the graph is useful to characterise all the patterns (subtree patterns) within a given graph.	Reply	I-Reply	2
Another pragmatic motivation is that the WL Kernel has been shown to work well in graph classification tasks.	Reply	I-Reply	2
We will try to make these motivations more clear in the paper, thank you for this comment and suggestion.	Reply	I-Reply	2
[line_break_token][line_break_token]‚ÄúModified PV-DBOW is in fact the same algorithm as the original CBOW model but applied to different context.	Reply	O	0
It has been used in many papers, including Deep GK, graph2vec, anonymous walks. ‚	Reply	O	0
Äú[line_break_token][line_break_token]Yes you are completely correct!	Reply	O	0
We explicitly say that we are using the embedding method from Graph2Vec (hence the name of the algorithm also being TrainGraph2Vec).	Reply	B-Reply	3
We kept the misleading Doc2Vec analogies used in Graph2Vec as it aided exposition of how one can think of a graph as composition of substructures, like documents being compositions of words.	Reply	I-Reply	3
As the contexts of the graphs are defined as the subtree patterns within it, it is actually more similar to training a word2vec model as you mention.	Reply	I-Reply	3
To make this clear we will change the title of this section in the revision.	Reply	I-Reply	3
Thank you for this comment.	Reply	O	0
[line_break_token][line_break_token]	Reply	O	0

This paper presents an adversarial learning model for generating diverse responses for dialogue systems based on HRED (hierarchical recurrent encoder-decoder) network.	Review	O	0
The contribution of the work mainly lies in: 1.	Review	O	0
adversarial learning, and 2.	Review	O	0
injecting Gaussian noise at word-level and sentence-level to encourage the diversity.	Review	O	0
Overall, the idea is interesting, and the automatic evaluation based on perplexity, BLEU, ROUGE, etc shows that the proposed methods outperform existing methods.	Review	O	0
[line_break_token][line_break_token]Several suggestions:[line_break_token]- It seems like injection noise at word-level almost always outperforms adding sentence-level noise.	Review	O	0
It would be better if the authors can explain why this happens and whether it can be applied for other response generation tasks.	Review	B-Review	1
[line_break_token][line_break_token]- Built on above comment, the authors can also experiment with other response generation datasets, e.g. interactions on social media.	Review	O	0
[line_break_token][line_break_token]- From examples in Table 3 and 4, the generated responses are of low quality overall.	Review	O	0
I suggest the authors run human evaluation to see whether there is any significant difference among system responses by different models on aspects of informativeness and fluency at least.	Review	B-Review	3
Thank you for your review.	Reply	O	0
[line_break_token][line_break_token]-- Why noise injection at the word level seems to performs better.	Reply	O	0
[line_break_token]We believe this is because the response distribution is a factor over independent word-level conditional distributions.	Reply	B-Reply	1
Therefore, matching the singleton categorical distribution to the Gaussian distribution easily captures the modalities in the response space.	Reply	I-Reply	1
Injecting at the utterance level seems to indicate a single probability distribution for all responses.	Reply	I-Reply	1
This result is in contrast with the assumption in VHRED where noise sample was injected at the utterance level only but we believe it is responsible for the better performance.	Reply	I-Reply	1
[line_break_token]--Other social media data[line_break_token]We will explore this in our future work[line_break_token]-- Human evaluation[line_break_token]We have crowdsourced the human evaluation and we will be reporting the results here soon.	Reply	O	0
[line_break_token][line_break_token]Let us know if you have additional questions while we collate and analyze the human evaluation results.	Reply	O	0

This paper studies the problem of making predictions with a model trained using dropout.	Review	O	0
Authors try to provide a theoretical foundation for using dropout when making predictions.	Review	O	0
For this purpose, they show that when using dropout training we are maximizing a common lower bound on the objectives of a family of models, including most of the previously used methods for prediction with dropout.	Review	O	0
[line_break_token][line_break_token]I find that the paper addresses a relevant problem and try to apply a novel approach.	Review	O	0
But, in general, I find the paper is not easy to follow and to grasp the main ideas.	Review	B-Review	1
[line_break_token][line_break_token]Here I detail my main concerns:[line_break_token][line_break_token][line_break_token]1.	Review	O	0
This is one of my main concerns.	Review	B-Review	2
The contraposition between the geometric and the average model.	Review	I-Review	2
I don't like this contraposition.	Review	I-Review	2
The average model is just the standard marginalization operation over the weights,.	Review	I-Review	2
This is the natural solution for the prediction problem to the problem if we accept the generative model given in Eq (3).	Review	I-Review	2
[line_break_token][line_break_token]In the case of the variational dropout, we depart from the same generative model, but we employ an approximation.	Review	I-Review	2
It is the variational approximation the one that induces the geometric mean provided in eq (6).	Review	I-Review	2
I.e. if we want to compute the posterior over the label y* for a sample x*, after training, we should compute the associated lower bound[line_break_token]In this case, q(w) = p(w|\Theta), as stated Eq (3) and in the corresponding equation provided in page 2 (the q(w) is not learnt because it only depends on the dropout rate, while the are learnt by maximum log-likelihood and do not have a associated).	Review	I-Review	2
 This gives rise to the geometric mean approximation provided in Eq (6).	Review	I-Review	2
 I.e. the geometric mean prediction is simply the result of using a variational approximation at prediction time.	Review	I-Review	2
  [line_break_token][line_break_token]My problem here is that authors employ convoluted arguments to introduce this geometric mean prediction and the average prediction, without making the connection discussed above.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	3
Section 3.3 and 3.4 introduces new arguments for modifying the dropout rate (and the alpha) parameter at test time.	Review	I-Review	3
But, again, I find the arguments convoluted.	Review	I-Review	3
We consider the dropout rate a hyper-parameter of the model, the standard learning theory tells us to fix the parameters with the training data and evaluate them later when making predictions.	Review	I-Review	3
Why should we use different dropout rates at training and testing?	Review	I-Review	3
Authors arguments about the tightness of the bound of Eq (8) and Eq(9).	Review	I-Review	3
are not convincing to me.	Review	I-Review	3
[line_break_token][line_break_token]So, I don't find authors provide convincing answers to the raised questions at the beginning of the paper about the use of dropout when making predictions.	Review	I-Review	3
[line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]1.	Review	I-Review	4
The generative model for Variational dropout is the same than the generative model for the "conditional model", eq. (	Review	I-Review	4
3).	Review	I-Review	2
[line_break_token][line_break_token]2.	Review	I-Review	4
In Eq. (	Review	I-Review	4
7) authors are defining the weighted power mean.	Review	I-Review	4
I think it would be clearer to directly introduce the weighted power mean instead of the standard power mean in Section 3.2.	Review	I-Review	4
[line_break_token][line_break_token]3.	Review	I-Review	3
Section 3.3.	Review	I-Review	4
I find some parts are difficult to understand. "	Review	I-Review	4
suppose we pick a base model from the power mean family and have a continuum of subvariants with gradually reduced variance in their predictions but the same expectation."	Review	I-Review	4
Later, I can understand authors are referring to the possibility of reducing the dropout rate.	Review	I-Review	4
We thank reviewer #1 for their comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We agree that marginalizing out the weights is the natural thing to do if we accept the generative model.	Reply	B-Reply	2
However, due to the training objective being a lower bound on the true objectives of the proposed family of models why would we prefer the arithmetic model to the others?	Reply	I-Reply	2
This one of the main points of the paper.	Reply	I-Reply	2
[line_break_token][line_break_token] As to the variational approximation leading to the geometric mean prediction, they are closely related but the variational approximation lacks the normalizing constant Z present in eq 6.	Reply	I-Reply	2
We acknowledge this relationship by saying that "oftentimes the geometric average (GMC) is used, because of its close relationship to the loss".	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
There is no disagreement with standard learning theory, in a sense we propose a shortcut: there is no need to train the model for different alpha, lambda choices since these hyperparameters only affect evaluation.	Reply	B-Reply	3
This is due to the training objective being a lower bound on the true objectives of the proposed family of models.	Reply	I-Reply	3
[line_break_token][line_break_token]It is unclear what is unconvincing about the tightness of the bound argument.	Reply	I-Reply	3
In any case, our intention there is to argue that in the absence of validation data, the most natural evaluation method is the deterministic one.	Reply	I-Reply	3
However, if there is validation data available, then the tightness of the bound argument is not necessary: tuning alpha, lambda only requires the common lower bound.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]In general, regarding the paper not being convincing, sound and the arguments being convoluted, we would like to improve both content and presentation.	Reply	I-Reply	3
To that end, we ask for more detailed feedback on these points, if possible.	Reply	I-Reply	3

This paper tackles out-of-distribution samples detection via training VAE-like networks.	Review	O	0
The key idea is to inject learnable Gaussian noise to each layer across the network in the hope that the variance of the noise correlates well with the uncertainty of the input features.	Review	O	0
The network is trained to minimize the empirical loss subject to noise perturbation.	Review	O	0
The paper is well written, and the background is introduced clearly.	Review	O	0
[line_break_token] [line_break_token]As I understand it, the goal of *out-of-distribution sample detection* is to train a deep network that simultaneously generalizes well and also be discriminative to outliers.	Review	O	0
However, it‚Äôs not clear to me why the proposed method server this purpose; empirical results are not convincing either.	Review	B-Review	1
My major concerns are as follows:[line_break_token] [line_break_token]First of all, from my intuition, it would be much easier to train deterministic networks than their counterparts with randomness.	Review	O	0
Empirically, researchers also often observe near-zero training loss for large deterministic networks such as Dense-BC trained on simple CIFAR/SVHN datasets.	Review	B-Review	2
Especially, in this case, the training goal is simply to map higher-dimensional inputs to lower-dimensional classification categories.	Review	I-Review	2
That being said, one would expect the variances go to zero at convergence to achieve lower empirical loss in the case of no additional diversity (or uncertainty) promotion terms.	Review	I-Review	2
[line_break_token] [line_break_token]It is not clear to me how to avoid degenerate solutions at convergence [line_break_token]while maintaining good testing performance with the proposed training strategy.	Review	O	0
[line_break_token]From the empirical results, it also appears that all models reported might not be fully optimized?	Review	B-Review	4
[line_break_token]The baseline results are significantly worse than those reported in previous work.	Review	I-Review	4
 [line_break_token]Specifically, [line_break_token]in table 1, the testing accuracy of Dense-BC trained on CIFAR-100 is only 71.6.	Review	I-Review	4
[line_break_token]In table 2, the reported testing accuracy on CIFAR-10 using Dense-BC is 92.4.	Review	I-Review	4
[line_break_token] [line_break_token]However, the results of DenseNet-BC (k=12, L=100, table 2) reported in the original paper are:[line_break_token]CIFAR10  94.0  (also leave 5K examples as validation set)[line_break_token]CIFAR100 75.9[line_break_token]  [line_break_token]Meanwhile, the reported accuracy of WRN-40-4 trained on CIFAR-10 and CIFAR-100 are 89.6 and 66.0, respectively.	Review	I-Review	4
However, the corresponding baseline numbers in the original WRN paper are much higher,  [line_break_token]CIFAR-10  95.03[line_break_token]CIFAR-100 77.11 [line_break_token][line_break_token]Could the authors comment on that?	Review	I-Review	4
[line_break_token][line_break_token]References:[line_break_token]Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger.	Review	O	0
[line_break_token]Densely Connected Convolutional Networks[line_break_token]<a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="nofollow">https://arxiv.org/abs/1608.06993</a>[line_break_token][line_break_token]Sergey Zagoruyko, Nikos Komodakis.	Review	O	0
[line_break_token]Wide Residual Networks.	Review	O	0
 [line_break_token]<a href="https://arxiv.org/pdf/1605.07146.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1605.07146.pdf</a>[line_break_token]	Review	O	0
hank you for reviewing my paper.	Reply	O	0
[line_break_token][line_break_token]&gt; That being said, one would expect the variances go to zero at convergence to achieve lower empirical loss in the case of no additional diversity (or uncertainty) promotion terms.	Reply	O	0
[line_break_token][line_break_token]This is true for the training data, but the variance term does not reduce to zero for the test data.	Reply	B-Reply	2
[line_break_token]In the discriminative space close to the output layer, the variance of OOD is larger than that of ID, thus we can detect OOD using this phenomenon.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; It is not clear to me how to avoid degenerate solutions at convergence while maintaining good testing performance with the proposed training strategy.	Reply	O	0
[line_break_token][line_break_token]According to the Eq. (	Reply	B-Reply	3
17) of [Alemi, 2016], the performance of classification is better, when the \beta is non-zero, namely there exists a regularization term.	Reply	I-Reply	3
However, if we set \beta to a value that is close to zero, the model approaches the original deterministic function.	Reply	I-Reply	3
Therefore, the performance will not be worse.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; From the empirical results, it also appears that all models reported might not be fully optimized?	Reply	O	0
The baseline results are significantly worse than those reported in previous work.	Reply	O	0
[line_break_token][line_break_token]We cannot access the test data to validate our method, thus we used 5,000 validation images taken from the 50,000 training data.	Reply	B-Reply	4
This degenerates the performance of the classification.	Reply	I-Reply	4
Therefore, the experimental conditions of the results reported in the paper you mention differ from those in our study.	Reply	I-Reply	4
We confirmed that if we use all 50,000 training data, we obtain the same results as reported in the papers [He, 2016; Huang, 2017].[line_break_token][line_break_token][reference][line_break_token]Alexander A Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy.	Reply	O	0
Deep variational information[line_break_token]bottleneck.	Reply	O	0
arXiv preprint arXiv:1612.00410, 2016	Reply	O	0

The authors consider two problems: Overcomplete dictionary learning (ODL)[line_break_token]and convolution dictionary learning (CDL).	Review	O	0
[line_break_token]Dictionary learning learns a matrix factorization of the data[line_break_token]Y = A X[line_break_token]where A is the dictionary and X is the (known to be sparse) code.	Review	O	0
[line_break_token]Y consists of n rows (sample size) and p columns (dimension).	Review	O	0
[line_break_token]In the overcomplete version A is n x m where m &gt; n, i.e. the number of learned[line_break_token]features is larger than the sample size.	Review	O	0
[line_break_token]The CDL problem is a special case of the ODL problem where the dictionary[line_break_token]matrix is known to consist of convolution filters instead of being unstructured.	Review	O	0
[line_break_token][line_break_token]The authors show that under a given set of assumptions local nonconvex[line_break_token]optimization can be used to find globally relevant solutions.	Review	O	0
[line_break_token]The basic assumptions are:[line_break_token](i) unit norm tight frame[line_break_token](ii) mu-incoherence[line_break_token][tab_token](relates the angles of the columns of a, e.g.\ if columns are orthogonal,[line_break_token][tab_token]they are incoherent / have small mu)[line_break_token](ii) stochastic model of the code X that says entries are Gaussian and sparse[line_break_token][tab_token]according to a Bernoulli random variable[line_break_token]The authors present the idea of maximizing the l^4 norm of A^T q in order to[line_break_token]find q as rows of A.[line_break_token]Apparently l^4 norm maximization leads to "spikiness" which is exactly[line_break_token]desirable under mu-incoherence.	Review	O	0
[line_break_token][line_break_token]The authors show (assuming p \to \infty) that the optimization nonconvex[line_break_token]landscape (constrained to the sphere) does not contain any stationary points[line_break_token]without negative curvature.	Review	O	0
[line_break_token]A saddle avoiding optimizer therefore converges to local minimizers from[line_break_token]random initialization.	Review	O	0
[line_break_token][line_break_token]The authors also show that the analysis extends to CDL via a preconditioned[line_break_token]initializer.	Review	O	0
[line_break_token]Finally, they go on to briefly show some experiments that further validate[line_break_token]the theory presented in the paper.	Review	O	0
[line_break_token][line_break_token]Overall, the authors present a rigorous technical analysis using powerful[line_break_token]mathematical tools for nonconvex optimization (which is relevant to many[line_break_token]machine learning problems).	Review	O	0
[line_break_token][line_break_token]I am recommending to accept based on the high quality of the work.	Review	O	0
[line_break_token]But I am not confident as to the accessibility of the paper to the wide[line_break_token]audience of ICLR as it is rather technical.	Review	O	0
[line_break_token]Perhaps, the complete contribution would be better suited as a journal article.	Review	O	0
[line_break_token][line_break_token]Notes:[line_break_token]It would have been useful to give some more intuition about what "spikiness"[line_break_token]of A^T q is, why spikiness exists under mu-incoherence and why l^4 norm[line_break_token]maximization improves spikiness.	Review	O	0
[line_break_token][line_break_token]I am not sure that the inclusion of the CDL problem is beneficial for a[line_break_token]converence paper and would rather have more space allocated to the intuition on[line_break_token]why the method works for ODL.	Review	B-Review	2
[line_break_token]	Review	O	0
e thank the reviewer for the comprehensive summary of our results and invaluable suggestions.	Reply	O	0
We have double checked our paper and revised accordingly.	Reply	O	0
[line_break_token][line_break_token]On Page 4 of the revised draft, we have introduced a notion of the spikiness and used simulations in Figure 2 to provide a better explanation of why maximizing promotes spikiness (we are not aware of any formal definition of spikiness in the literature).	Reply	B-Reply	1
Intuitively, we characterize the spikiness of a vector by the ratio between the largest and the second largest entries in magnitude.	Reply	I-Reply	1
In Figure 2, we added simulations to demonstrate that the-norm tends to be larger when the spikiness of the vector increases.	Reply	I-Reply	1
If is close to one of the columns of (e.g.,), around Equation (2.5) we explained why the vector should be spiky, given the small incoherence of (i.e.,).	Reply	I-Reply	1
In theory, we rigorously proved that is close to one of the global optimizers due to the spikiness of.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree with the reviewer that the inclusion of CDL might overexpose the readers.	Reply	I-Reply	2
Indeed, the authors had several discussions over this before the submission.	Reply	I-Reply	2
That being said, we had included CDL because we believe the inclusion of CDL is very beneficial to the audience in the ICLR community.	Reply	I-Reply	2
The CDL problem can be reviewed as a more structured ODL problem such that it can be analyzed in a similar fashion with a few new ingredients (e.g., initialization, preconditioning, new concentration ideas).	Reply	I-Reply	2
Building on the intuition and theory for ODL, it could make our introduction of CDL more accessible to the audience and save us the effort for another repetitive work.	Reply	I-Reply	2
Moreover, the CDL can be reviewed as a very simple one-layer convolutional neural network (CNN) (Papyan et al.,	Reply	I-Reply	2
2017a; 2018).	Reply	I-Reply	2
The theory developed here has the potential to serve as a building block for developing more interpretable deep CNN, which closely relates to the core interest of the ICLR community.	Reply	I-Reply	2
If the reviewer thinks it would be beneficial to address this issue, we will release a much-extended version of this work on arxiv in the future and provide a link in the final version of this paper.	Reply	I-Reply	2

This paper explores 3 language modeling applications with an explicit modeling of reference expressions: dialog, receipt generation and coreferences.	Review	O	0
While these are important tasks for NLP and the authors have done a number of experiments, the paper is limited for a few reasons:[line_break_token][line_break_token]1.	Review	O	0
This paper is not clearly written and is pretty hard to follow some details.	Review	B-Review	1
In particular,  there are many obvious math errors, such as missing the marginalization sum in Eq (1), and P(z_{i,v}...) = 1 (should be 0 here) on page 5, pointer switch section.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The major novelty seems to be the 2-dimensional attention from the table and the pointer to the 2-D table.	Review	B-Review	2
These are more of a customization of existing work to a particular task with 2-D tables as a part of the input to seq2seq model with both attentions and pointer networks.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
The empirical results are not very conclusive yet, limited by either the relatively small data size, or the lack of well-established baseline for some new applications (e.g., the recipe generation task).	Review	B-Review	3
[line_break_token][line_break_token]Overall, this paper, as it is for now, is more suitable for a workshop rather than for the main conference.	Review	O	0
1) We thank the reviewer for the constructive review and feedback.	Reply	O	0
We have rewritten the paper to make it more readable.	Reply	O	0
Please refer to our new draft for the revision.	Reply	O	0
[line_break_token][line_break_token]2) Coupling neural network with database is an interesting direction and we are the first (to the best of our knowledge) to explore in this direction.	Reply	O	0
There lacks good data sets for this type of research.	Reply	B-Reply	2
[line_break_token][line_break_token]3) We want to point out that although the data sets (dialogues and recipes) we used are relatively small, they are new data sets that we build ourselves.	Reply	O	0
For the coreference based language models, there is no standard data set either.	Reply	B-Reply	3
Building the data sets is one of our contributions.	Reply	I-Reply	3
We have provided the state of art baseline methods (seq2seq with attention and lstm language models) on these newly constructed data set and shown our model performs better than those baselines.	Reply	I-Reply	3

The paper propose a adversary method to train a bidirectional GAN with both an encoder and decoder.	Review	O	0
Comparing to the existing works, the main contribution is the introducing of an augmented reconstruction loss by training a discriminator to distinguish the augmentation data from the reconstructed data.	Review	B-Review	1
Experimental results are demonstrated to show the generating and reconstruction performance.	Review	O	0
[line_break_token][line_break_token]The problem studied in this paper is very important, and has drawn a lot of researchers' attentions in recent years.	Review	O	0
 However, the novelties of this paper is very limited.	Review	O	0
The techniques used to train a bidirectional GAN are very standard.	Review	B-Review	2
The only new stuff may be is the proposed reconstruction loss defined on augmented samples and reconstructed ones.	Review	I-Review	2
But this is also not a big contribution, seems just using a slightly different way to guarantee reconstruction.	Review	I-Review	2
Dear reviewer,[line_break_token]We would like to thank you for the thoughtful review.	Reply	O	0
The main concern you raised is about the novelty of the paper.	Reply	O	0
We will address each point of the review below:[line_break_token][line_break_token]> Comparing to the existing works, the main contribution is the introducing of an augmented reconstruction loss by training a discriminator to distinguish the augmentation data from the reconstructed data.	Reply	O	0
[line_break_token][line_break_token]The summary of our contribution is accurate at a high-level.	Reply	B-Reply	1
Just to be sure that there is no misunderstanding we add the key detail: the discriminator distinguishes pairs (x, a(x)) from the pairs (x, G(E(x))) where x is a real object, a(x) is its augmentation and G(E(x)) is its reconstruction.	Reply	I-Reply	1
Adding x as the first element in each pair is crucial because it ensures that reconstructions G(E(x)) will correspond to the source object x. Otherwise, if we classify just the augmentation data a(x) from the reconstructions G(E(x)) instead of pairs the auto-encoding model will not be penalized for incorrect reconstructions.	Reply	I-Reply	1
[line_break_token][line_break_token]> The techniques used to train a bidirectional GAN are very standard.	Reply	O	0
The only new stuff may be is the proposed reconstruction loss defined on augmented samples and reconstructed ones.	Reply	O	0
But this is also not a big contribution, seems just using a slightly different way to guarantee reconstruction.	Reply	O	0
[line_break_token][line_break_token]It is true that the key distinction of our method from other algorithms of training a bidirectional GAN is the proposed adversarial reconstruction loss defined on pairs.	Reply	B-Reply	2
Despite the simplicity of the concept, to the best of our knowledge it is the first successful attempt of applying the content-aware trainable distance between two images.	Reply	I-Reply	2
[line_break_token][line_break_token]Other approaches [1, 2, 3, 4, 5, 6] mainly utilize standard L1 and L2 distances which lead to undesirable artifacts and blurriness in reconstructions.	Reply	I-Reply	2
In ALICE [6] paper authors consider a discriminator on pairs (x, x) and (x, G(E(x)) without augmentation and mention that it degrades to a delta function which is even worse than L1 and L2.	Reply	I-Reply	2
Our proposed augmentation allows for the discriminator to classify pairs based not on the pixels but on the content of the image which is invariant to the augmentation.	Reply	I-Reply	2
[line_break_token][line_break_token]In the paper, the main motivation of the adversarial reconstruction loss over the standard pixel-wise losses is as follows: the latter match images in the space of pixels which is highly noisy and does not capture perceptual similarity while the proposed loss matches images in the space of high level features learned by the discriminator on pairs.	Reply	I-Reply	2
In experiments, we show that introducing the adversarial reconstruction loss instead of L1 distance significantly improves both the visual quality of generated images and reconstructions and standard metrics such as Inception Score and Frechet Inception Distance.	Reply	I-Reply	2
Therefore, we argue that the proposed loss is conceptually very different from the standard pixel-wise losses.	Reply	I-Reply	2
[line_break_token][line_break_token]Additionally, we want to notice that in the paper we introduce a novel metric Reconstruction Inception Dissimilarity (RID) as alternative to the standard RMSE.	Reply	I-Reply	3
We empirically show that RID is more robust to content-preserving transformations and captures perceptual similarity between source image and its reconstruction rather than a pixel-wise coincidence.	Reply	I-Reply	3
[line_break_token][line_break_token][1] Variational Approaches for Auto-Encoding Generative Adversarial Networks, <span class="CtxtMenu_Attached_0" tabindex="0" ctxtmenu_counter="0">\</span> <a href="https://arxiv.org/abs/1706.04987" target="_blank" rel="nofollow">https://arxiv.org/abs/1706.04987</a>[line_break_token][2] It Takes (Only) Two: Adversarial Generator-Encoder Networks, <a href="https://arxiv.org/abs/1704.02304" target="_blank" rel="nofollow">https://arxiv.org/abs/1704.02304</a>[line_break_token][3] Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, <a href="https://arxiv.org/abs/1703.10593" target="_blank" rel="nofollow">https://arxiv.org/abs/1703.10593</a>[line_break_token][4] Neural Photo Editing with Introspective Adversarial Networks, <a href="https://arxiv.org/abs/1609.07093" target="_blank" rel="nofollow">https://arxiv.org/abs/1609.07093</a>[line_break_token][5] Wasserstein Auto-Encoders, <a href="https://arxiv.org/abs/1711.01558" target="_blank" rel="nofollow">https://arxiv.org/abs/1711.01558</a>[line_break_token][6] ALICE: Towards Understanding Adversarial Learning for Joint Distribution Matching, <a href="https://arxiv.org/abs/1709.01215" target="_blank" rel="nofollow">https://arxiv.org/abs/1709.01215</a	Reply	O	0

The paper proposed an interesting algorithm and direction, which tries fill the gap of NN in tabular data learning.	Review	O	0
My concern is, given this is an empirical work,  the number of datasets used in evolution is a bit small.	Review	B-Review	1
[line_break_token][line_break_token]Also, xgboost was the winning algorithm for many competitions for tabular data, would be good to compare the NN with properly optimised xgboost.	Review	I-Review	2
[line_break_token][line_break_token]In chapter 2, related work.	Review	I-Review	3
The authors state that "tree-based models still yield two obvious shortages: (1) Hard to be integrated into complex end-to-end frameworks... (2) Hard to learn from streaming data.	Review	I-Review	3
[line_break_token][line_break_token]To me these two reasoning statements are not particularly convincing.	Review	I-Review	4
One could also say:[line_break_token][line_break_token]NN models yield two obvious shortages: (1) Hard to be integrated into complex end-to-end frameworks... (2) Hard to learn from streaming data...[line_break_token][line_break_token]Actually, tree ensemble based algorithms, eg Hoeffding tree ensembles, are among the best performed algorithms for data streaming tasks.	Review	O	0
[line_break_token]Thanks for your efforts in reviewing our paper and the valuable comments.	Reply	O	0
We attempt to address your concerns using the following points and hope they can help you better understand our work.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
the number of benchmark datasets[line_break_token][line_break_token]Currently, there are 5 datasets in our experiments.	Reply	O	0
Actually, we have evaluated the proposed methods by conducting experiments in many datasets and observed the similar results.	Reply	B-Reply	1
Due to the space restriction, however, we cannot present them all in the paper.	Reply	I-Reply	1
We can provide more experiment results in appendix to eliminate this concern.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
XGBoost[line_break_token][line_break_token]We use LightGBM to learn GBDT model in the experiment part.	Reply	O	0
LightGBM is proven comparable (even better) with XGBoost in many Kaggle competitions (refer to <a href="https://www.kaggle.com/shivamb/data-science-trends-on-kaggle" target="_blank" rel="nofollow">https://www.kaggle.com/shivamb/data-science-trends-on-kaggle</a> and <a href="https://github.com/Microsoft/LightGBM/tree/master/examples)."	Reply	O	0
target="_blank" rel="nofollow">https://github.com/Microsoft/LightGBM/tree/master/examples).</a> Therefore, we think using LightGBM is sufficient for comparison.	Reply	O	0
[line_break_token][line_break_token]3.	Reply	O	0
Two shortages of tree-based models[line_break_token][line_break_token]Let us describe these two shortages with more details here.	Reply	O	0
[line_break_token][line_break_token]  1) Hard to be integrated into complex end-to-end frameworks.	Reply	O	0
In such framework, there are many modules, each of which may correspond to one sub-task with a global optimization goal.	Reply	B-Reply	3
The outputs of modules can serve as the inputs of other modules.	Reply	I-Reply	3
Therefore, to train such a framework in an end-to-end way, the module should be able to propagate the errors from its outputs to its inputs.	Reply	I-Reply	3
NN can naturally support this, as its learning algorithm is the back-propagation.	Reply	I-Reply	3
In contrast, tree-based models do not support this as the tree learning process is not differentiable and therefore cannot propagate the errors to its inputs.	Reply	I-Reply	3
As stated in the Section 2, although there are some works targeting to address this problem, these solutions will lose the automatic feature selection ability and cannot work well on the tabular data.	Reply	I-Reply	3
[line_break_token][line_break_token]  2) Hard to learn from streaming data.	Reply	O	0
For NN's learning, we can use Stochastic Gradient Descent (SGD) or mini-batch SGD to naturally learn from streaming data, since the NN model could be updated per data sample or per mini-batch of samples.	Reply	B-Reply	3
However, it is not effective for tree-based model to support this as its learning needs the global statistical information.	Reply	I-Reply	3
Using the partial statistical information may produce the sub-optimal split points and results in worse models.	Reply	I-Reply	3
There are some works addressed this problem, like Hoeffding trees, which stores the statistical histograms into leaf nodes.	Reply	I-Reply	3
[line_break_token]  However, most of these solutions are designed for the single decision tree.	Reply	I-Reply	3
Although there are ensemble versions of them, most of them are based on bagging (like Random Forest), which is proven not as good as GBDT.	Reply	I-Reply	3
[line_break_token][line_break_token]In short, NN does not suffer from these two problems due to its mini-batch back-propagation learning process.	Reply	I-Reply	3
In contrast, tree-based model is hard to solve these two problems due to its learning algorithm is based on global statistical information.	Reply	I-Reply	3
Therefore, TabNN is a better general solution for tabular data	Reply	I-Reply	3

Summary:[line_break_token]This paper proposes a new initialization method for recurrent neural networks.	Review	O	0
They first obtain the weight from a linear optimal autoencoder.	Review	O	0
And then they use the weight to initialize the Lieanr Memory Networks(LMN).	Review	O	0
Basically, this paper is a combination of [1] and [2].[line_break_token][line_break_token]Strength:[line_break_token]The method of initializing LMN using a linear RNN is natural and simple. (	Review	O	0
section 3.2)[line_break_token]The proposed initialization outperforms the baselines on the MNIST dataset.	Review	O	0
[line_break_token][line_break_token]Weakness:[line_break_token]What do you mean by the "optimal autoencoder"?	Review	O	0
[line_break_token]The performance on TIMIT is worse than the baseline methods.	Review	B-Review	2
[line_break_token]The scale of the experiments is too small.	Review	I-Review	2
Do you have any experiment results on any large dataset?	Review	I-Review	2
e.g. Penn Treebank.	Review	I-Review	2
[line_break_token] [line_break_token][line_break_token]Reference:[line_break_token][1] Pre-training of Recurrent Neural Networks via Linear Autoencoders[line_break_token][2] Linear Memory Networks	Review	O	0
&gt;&gt;&gt; Weakness: What do you mean by the "optimal autoencoder"?	Reply	O	0
[line_break_token] [line_break_token]We use a linear autoencoder because we can find the optimal solution (in the sense that it optimizes the mean squared error) with a closed-form solution.	Reply	O	0
We approximate this solution by taking a fixed number of components.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; The performance on TIMIT is worse than the baseline methods.	Reply	O	0
The scale of the experiments is too small.	Reply	O	0
Do you have any experiment results on any large dataset?	Reply	O	0
e.g. Penn Treebank.	Reply	O	0
[line_break_token][line_break_token]We did not perform experiments on PTB, but our expectation is that models based on autoencoding are not a good choice for language modeling tasks.	Reply	B-Reply	2
This can be seen by looking at the performance of orthogonal models on language modeling tasks [1,2], which are always inferior to gated models.	Reply	I-Reply	2
Our guess is that language modeling does not require the memorization of long sequences, and it is probably sufficient to remember a small amount of information.	Reply	I-Reply	2
[line_break_token] [line_break_token][1]  Eugene Vorontsov, Chiheb Trabelsi, Samuel Kadoury, and Chris Pal.	Reply	O	0
On orthogonality and learning[line_break_token]recurrent networks with long term dependencies.	Reply	O	0
In ICML, pp.	Reply	O	0
3570‚Äì3578, 1 2017.	Reply	O	0
URL [line_break_token][2] Cijo Jose, Moustpaha Cisse, and Francois Fleuret.	Reply	O	0
Kronecker Recurrent Units.	Reply	O	0
In ICML, pp.	Reply	O	0
[line_break_token]2385‚Äì2394, 5 2018.	Reply	O	0
URL <a href="http://arxiv.org/abs/1705.10142."	Reply	O	0
target="_blank" rel="nofollow">http://arxiv.org/abs/1705.10142.</a>	Reply	O	0

Paper Summary:[line_break_token][line_break_token]The paper considers training oblivious trees ensemble with gradient descent by introducing a relaxation for feature selection and node thresholding.	Review	O	0
The relaxation is based on the recently introduced EntMax.	Review	O	0
The approach is compared with standard gradient boosting tree learning on benchmark datasets.	Review	O	0
[line_break_token][line_break_token]Review Summary:[line_break_token][line_break_token]The paper reads well, is technically sound.	Review	O	0
The approach is novel and relevant to ICLR.	Review	O	0
Reference to related work are appropriate.	Review	O	0
Experimental comparison with CatBoost, neural nets could be more rigorous, more ablations could give a complete picture.	Review	B-Review	2
Overall this is a good paper that gives an extra tool applicable to many practical settings.	Review	O	0
[line_break_token][line_break_token]Detailed Review:[line_break_token][line_break_token]The introduction needs to define "tabular data".	Review	O	0
In your case, it seems that you mean mostly numerical heterogeneous features.	Review	B-Review	1
Could you comment on using categorical features as well?	Review	I-Review	1
[line_break_token][line_break_token]The method is clearly explained and references are appropriate, so most of my questions relate to the empirical setup and results.	Review	O	0
[line_break_token][line_break_token]First, it seems to me that the paper would be much stronger if you were to reproduce the results from an established paper.	Review	B-Review	2
If you take the catboost paper (arXiv:1706.09516v5 [cs.	Review	I-Review	2
LG] 20 Jan 2019), the error on epsilon dataset is 10.9 which is better than the number your report, similarly click reports 15.6 error rate.	Review	I-Review	2
To me, the paper would be much better if you simply added an FCNN and a NODE column to Table 2 and 3 of the catboost paper.	Review	I-Review	2
It does not mean that your approach has to be better in all cases, but it will give a clear picture of when it is useful and it would clear any doubt on the tuning of the catboost baseline.	Review	I-Review	2
[line_break_token][line_break_token]Second, the model you propose builds upon the densenet idea while the FCNN you compare with has no densenet connections.	Review	I-Review	3
It would be fairer to consider neural net with this kind of residual.	Review	I-Review	3
[line_break_token][line_break_token]Third, I feel you need to report results over CPU as well.	Review	I-Review	4
Boosted trees primary advantage is their low cost on regular CPU, the entmax formulation requires integrating over more leaves [line_break_token]than typical thresholded trees and it would be interesting to compare the effect on CPU.	Review	I-Review	4
Reporting timing with batch and individual sample evaluation would make sense as well.	Review	I-Review	4
[line_break_token][line_break_token] As a side note, I would advise to define entmax with its equation.	Review	O	0
It is too recent to consider it should be known by the reader.	Review	B-Review	5
[line_break_token][line_break_token]Overall, this is a good paper than reads well.	Review	O	0
The method is novel, interesting and practical.	Review	O	0
With the extra experiments, it would make an excellent ICLR paper.	Review	O	0
hank you for your comments, we address your concerns below.	Reply	O	0
[line_break_token][line_break_token][add comparison to FCNN with DenseNet connections][line_break_token]We agree and conduct an additional set of experiments focused on densely-connected FCNN models.	Reply	O	0
We use the standard FCNN tuning procedure described in the submission.	Reply	B-Reply	2
Numbers in the table below correspond to the performance on the val/test subsets.	Reply	I-Reply	2
[line_break_token][line_break_token]FCNN              |    Epsilon         | YearPrediction |     Higgs           |   Microsoft      |     Yahoo           |     Click             |[line_break_token]Sequential     | 0.1041/0.1043 |   70.07/79.99   | 0.2140/0.2140 | 0.5411/0.5608 | 0.5977/0.5773 | 0.3303/0.3325 |[line_break_token]DenseNet      | 0.1044/0.1043 |   69.00/81.17   | 0.2146/0.2139 | 0.5403/0.5595 | 0.5899/0.5691 | 0.3302/0.3324 |[line_break_token][line_break_token]As you can see, DenseNet does indeed sometimes outperform the sequential architecture but does not outperform NODE, which indicates that the inductive bias of oblivious decision ensembles is important.	Reply	I-Reply	2
We have included dense connections in FCNN parameter tuning scheme and have updated Table 2 in a new revision[line_break_token][line_break_token][it seems to me that the paper would be much stronger if you were to reproduce the results from an established paper.]	Reply	O	0
[line_break_token][line_break_token]We agree with this concern.	Reply	B-Reply	2
However, the choice of benchmark datasets in the Catboost paper is biased to categorical features as it is the main focus of Catboost.	Reply	I-Reply	2
Moreover, most of the datasets are quite small, see Table 7 in <a href="https://arxiv.org/pdf/1706.09516.pdf."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1706.09516.pdf.</a> In contrast, we aim to cover different dataset sizes and domain areas.	Reply	O	0
[line_break_token][line_break_token][Third, I feel you need to report results over CPU as well][line_break_token]We agree that this would be a valuable addition.	Reply	O	0
However, our pytorch-based implementation specifically targets GPU training and inference.	Reply	B-Reply	4
A naive conversion of 8-layer NODE to run on 28-core Xeon E5-2660 v4 has an average training time of 49min 40s and inference time of 1m 4.5s per million predictions on the YearPrediction dataset.	Reply	I-Reply	4
[line_break_token][line_break_token]The majority of this time is spent on multiplying activations by zero - a side-effect of a highly parallel GPU-friendly implementation.	Reply	I-Reply	4
We expect that in a CPU-optimized NODE implementation (e.g. with natively compiled C++), inference would take between 100% and 200% of CatBoost inference time.	Reply	I-Reply	4
However, development of such optimized implementation would take up immense amounts of time and effort and is not possible till the end of discussion period.	Reply	I-Reply	4
[line_break_token][line_break_token][I would advise to define entmax with its equation][line_break_token][line_break_token]We have described entmax with more details in a new revision.	Reply	O	0

Summary[line_break_token][line_break_token]This paper provides an interesting application of GAN which can generate the outlier distribution of training data which forces generator to learn the distribution of the low probability density area of given data.	Review	O	0
To show the effectiveness of the method, the author intuitively shows how it works on 2-D points data as well as the reconstructed Mnist dataset.	Review	O	0
Additionally, this approach reaches a comparable performance on semi-supervised learning and novelty detection task.	Review	O	0
[line_break_token][line_break_token]Paper Strengths[line_break_token][line_break_token]1.	Review	O	0
The idea of this paper is novel, and the implementation of this method is easily interacted with any GAN model.	Review	O	0
Also, due to its concise structure compared to the existing method, it saves more computational memory and is time efficiency.	Review	O	0
[line_break_token][line_break_token]Paper Weaknesses[line_break_token][line_break_token]1.	Review	O	0
Experimental settings are clear, however, what makes me confused is that the construction for p_{\bar{d}} is straightforward for simple distribution like 2D points dataset, however, it might be intractable for complex high dimensional data such as images.	Review	B-Review	1
[line_break_token]2.	Review	O	0
The model seems to be sensitive to the hyper-parameter \alpha, is this parameter always fixed at 0.5 or needed to fine-tune for different datasets?	Review	B-Review	2
hanks for your comments!	Reply	O	0
[line_break_token][line_break_token]&gt;&gt;&gt; Experimental settings are clear, however, what makes me confused is that the construction for is straightforward for simple distribution like 2D points dataset, however, it might be intractable for complex high dimensional data such as images.	Reply	O	0
[line_break_token][line_break_token]In responding to this comment and the comment of Reviewer #1, we perform one more experiment on CelebA to demonstrate that DSGAN can work well even for complicated images.	Reply	B-Reply	1
In this experiment, we generate the color images of size 64 64.	Reply	I-Reply	1
Similar to 1/7 experiments on the MNIST dataset, we let be the distribution of face images with glasses and without glasses, and let be images without glasses.	Reply	I-Reply	1
 We sample 10000 images with glasses and 10000 images without glasses from CelebA, and we set to 0.5.	Reply	I-Reply	1
 [line_break_token][line_break_token][line_break_token]In order to verify the generated image quality of DSGAN, we also train a GAN for comparison.	Reply	I-Reply	1
GAN is trained with the same amount of training images (but only using face images with glasses since GAN is to learn the distribution of training data).	Reply	I-Reply	1
In other words, we assume GAN can use complement data as training data directly.	Reply	I-Reply	1
On the contrary, DSGAN only uses complement data indirectly (the difference between and).	Reply	I-Reply	1
[line_break_token][line_break_token]Figure 10 in Appendix G shows generated images and FID for both methods.	Reply	I-Reply	1
We can see that our DSGAN can generate images with glasses from the given and, and the FID of DSGAN are comparable to that of GAN.	Reply	I-Reply	1
The experiment validates that DSGAN still works well to create complement data for complicate images.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; The model seems to be sensitive to the hyper-parameter, is this parameter always fixed at 0.5 or needed to fine-tune for different datasets?	Reply	O	0
[line_break_token][line_break_token]Since the optimal of generating "unseen" data in DSGAN depends on the degree of overlap between and, it might need to be fine-tuned for different datasets.	Reply	B-Reply	2
However, in our experiments, we set to in most cases.	Reply	I-Reply	2
[line_break_token][line_break_token]Theorem 1 illustrates should be expected to be as large as possible if both network G and D have infinite capacity.	Reply	I-Reply	2
Though the networks never have the infinite capacity in real applications, a general rule is to pick a large and force the complement data to be far from p_d, which is similar to the ablation studies in Sec.	Reply	I-Reply	2
5.1.	Reply	I-Reply	2
According to our empirical observations, is the good choice for all datasets.	Reply	I-Reply	2
Table 11 in Sec.	Reply	I-Reply	2
F of Appendix shows the experimental results of how affects the performances.	Reply	I-Reply	2
We use different values in the MNIST, SVHN and CIFAR10 dataset, respectively.	Reply	I-Reply	2
One can see that we achieve the best performances at.	Reply	I-Reply	2
[line_break_token]	Reply	O	0

Summary: the authors propose a new algorithm, APL, for a few-shot and a life-long learning based on an external memory module.	Review	O	0
APL uses a surprise-based signal to determine which data points to store in memory and an attention mechanism to the most relevant points for prediction.	Review	O	0
The authors evaluate APL on a few-shot classification task on Omniglot dataset and on a number analogy task.	Review	O	0
[line_break_token][line_break_token]Quality: the authors consider interesting approach to life-long learning and I really liked the idea of a surprise-based signal to choose the data to store.	Review	O	0
However, I am not convinced by the learning setting that authors study.	Review	O	0
While a digit-symbol task from the introduction is interesting to study the properties of APL, I fail to see any real world analogy where it is useful.	Review	O	0
The same happens in a few-shot omniglot classification.	Review	O	0
The authors decided to shuffle the labels within episodes that, I guess, is supposed to represent different tasks in a typical life-long learning scenario.	Review	O	0
Again, it maybe interesting to study the behaviour of the algorithm, but I don't see any practical relevance here.	Review	B-Review	1
It would make more sense to study the algorithm in a life-long learning setting, for example, considered in [1] and [2].[line_break_token][line_break_token]Clarity: the paper is well-written in general.	Review	O	0
I failed to decode the meaning behind the paragraph under Figure 3 on page 4 and would advise the authors to re-write it.	Review	B-Review	2
The same goes to the first paragraph on page 3.	Review	I-Review	2
[line_break_token][line_break_token]Originality: the paper builds on the prior work of Kaiser et al.,	Review	O	0
2017 and Santoro et al.,	Review	O	0
2016, but the proposed modifications are novel to my best knowledge.	Review	O	0
[line_break_token][line_break_token]Significance: below average: the paper combines interesting ideas that potentially can be used in different learning contexts and with other algorithms, however, the evaluation does not show the benefit in an obvious way.	Review	O	0
[line_break_token][line_break_token]Other comments: [line_break_token]* throughout the whole paper it is not clear if the embeddings are learned or not.	Review	O	0
I suppose they are, but what then happens to the ones in memory?	Review	B-Review	4
If they are not, like in ImageNet example, where do they come from?	Review	I-Review	4
[line_break_token]* the hyperparameter \sigma: the authors claim "the value of \sigma seems to not matter too much".	Review	O	0
Matter for what?	Review	B-Review	5
It's great if the performance is stable for a wide range of \sigma, but it seems like it should have a great influence over the memory footprint of APL.	Review	I-Review	5
I feel this is an important point that needs more attention.	Review	I-Review	5
[line_break_token]* it would be interesting to see how APL performs with a simple majority vote instead the decoder layer.	Review	O	0
This would count for an ablation study and could emphasize the role of the decoder.	Review	B-Review	6
[line_break_token]* Figure 4, b) plots are completely unreadable on black-and-white print, the authors might like to address that[line_break_token]* In conclusion, the first claim about state-of-the-art accuracy with smaller memory footprint: I don't think that the results of the paper justify this claim.	Review	O	0
[line_break_token][line_break_token][1] Yoon et al, Lifelong Learning with Dynamically Expandable Networks, ICLR 2017[line_break_token][2] Rebuffi et al,  iCaRL: Incremental Classifier and Representation Learning, CVPR 2017[line_break_token][line_break_token]********************[line_break_token]After authors response:[line_break_token][line_break_token]Thanks to the authors for a detailed response.	Review	O	0
The introduction led me to believe that the paper solves a different task from what it actually does.	Review	O	0
I still like the algorithm and, given that the scope of the paper is limited to a few-shot learning, I tend to change my evaluation and recommend to accept the paper.	Review	O	0
It was a good idea to change the title to avoid possible confusion by other readers.	Review	O	0
The introduction is still misleading though.	Review	B-Review	9
It creates the impression that APL solves a more general problem where it would be good enough to limit the discussion to a few-shot learning setting and explain it in greater detail for an unfamiliar reader.	Review	I-Review	9
Some details also seem to be missing, e.g. I didn't get that the memory is flushed after each episode and could not find where this is mentioned in the paper.	Review	I-Review	9
> the hyperparameter \sigma: the authors claim "the value of \sigma seems to not matter too much".	Reply	O	0
Matter for what?	Reply	O	0
It's great if the performance is stable for a wide range of \sigma, but it seems like it should have a great influence over the memory footprint of APL.	Reply	O	0
I feel this is an important point that needs more attention.	Reply	O	0
[line_break_token][line_break_token]Thanks for the excellent question!	Reply	B-Reply	5
We have added a detailed analysis of the behavior of the model as a function of \sigma in the supplementary information.	Reply	I-Reply	5
To give you a quick summary \sigma does not affect the memory footprint of APL as much as might be assumed a priori as the model exhibits 2 regimes: before being completely trained, the model basically writes everything to memory; while after being trained the model is either completely surprised with a new data point (has never seen it before, or is significantly different from what it‚Äôs seen before), or classifies it with high accuracy.	Reply	I-Reply	5
Therefore the model ends up writing roughly the same number of points to memory for a wide range of \sigma (obviously if you make it too high or too low the model breaks).	Reply	I-Reply	5
[line_break_token][line_break_token]> it would be interesting to see how APL performs with a simple majority vote instead the decoder layer.	Reply	O	0
This would count for an ablation study and could emphasize the role of the decoder.	Reply	O	0
[line_break_token][line_break_token]Matching networks can be seen as a special case of APL without a decoder and where all points are written to memory.	Reply	B-Reply	6
Therefore the performance numbers for Matching Networks serve as an upper bound to the performance of APL ablated without a decoder.	Reply	I-Reply	6
We will clarify this point in the text.	Reply	I-Reply	6
[line_break_token][line_break_token]> Figure 4, b) plots are completely unreadable on black-and-white print, the authors might like to address that[line_break_token][line_break_token]Thank you, we will strive to optimize the visual presentation of these plots in the final version of the paper	Reply	O	0

This work introduces a new algorithm to improve decoding in discrete autoregressive models (ARMs).	Review	O	0
Because exact decoding of ARMs is computationally difficult, the contribution of this paper is to introduce a new approximate solution.	Review	O	0
The authors show experimentally that this new framework is very effective and outperforms multiple baselines such as greedy and bean search and another text filing algorithm called TIGC on a text-filling benchmark.	Review	O	0
This work is not in my domain of expertise so I am not able to have a very accurate evaluation.	Review	O	0
However, based on the references cited in this paper, there are other approximate solution for ARMs and I believe the authors need to use those as baselines to show that the proposed approximate solution is useful.	Review	B-Review	1
e thank the reviewer for the feedback.	Reply	O	0
 We would like to make the following clarifications.	Reply	O	0
[line_break_token][line_break_token]Q. Comparison with other approximate inference methods for ARMs.	Reply	O	0
[line_break_token]A. In addition to comparison with classical inference methods, i.e. greedy and beam search, we have also compared our inference technique with TIGS, which is introduced in ACL 2019 [1]. TIGS is state-of-the-art inference method for the text infilling task.	Reply	O	0
It is a strong and sophisticated inference method representative of the body of the literature which consider a continuous relaxation of the discrete optimisation involved in the decoding process.	Reply	B-Reply	1
These methods then use algorithms for continuous optimisation to solve the relaxed problem, and then project back the ‚Äòfractional‚Äô solution to the discrete space (c.f.	Reply	I-Reply	1
please see the Related Work section in the paper for more details).	Reply	I-Reply	1
[line_break_token][line_break_token]Given that our method outperforms TIGS in comparable experimental conditions to [1], it implies that our method will outperform the other inference methods which are compared with TIGS as well [1], including bidirectional beam search and inference algorithms that can be applied directly to generative models including [2,3].[line_break_token] [line_break_token][1]  Dayiheng Liu, Jie Fu, Pengfei Liu, and Jiancheng Lv.	Reply	O	0
Tigs: An inference algorithm for text infilling with gradient search.	Reply	O	0
ACL, 2019[line_break_token][2] Berglund, M., Raiko, T., Honkala, M., K√§rkk√§inen, L., Vetek, A., &amp; Karhunen, J. T. (2015).	Reply	O	0
Bidirectional recurrent neural networks as generative models.	Reply	O	0
In Advances in Neural Information Processing Systems (pp.	Reply	O	0
856-864).	Reply	O	0
[line_break_token][3] Sun, Q., Lee, S., &amp; Batra, D. (2017).	Reply	O	0
Bidirectional beam search: Forward-backward inference in neural sequence models for fill-in-the-blank image captioning.	Reply	O	0
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp.	Reply	O	0
6961-6969).	Reply	O	0

******[line_break_token]Update: revising reviewer score to 6 after acknowledging revisions and improved manuscript[line_break_token]******[line_break_token][line_break_token]The authors propose a new regularization term modifying the VAE (Kingma et al 2013) objective to encourage learning disentangling representations.	Review	O	0
[line_break_token]Specifically, the authors suggest to add penalization to ELBO in the form of -KL(q(z)||p(z)) , which encourages a more global criterion than the local ELBOs.	Review	O	0
[line_break_token]In practice, the authors decide that the objective they want to optimize is unwieldy and resort to moment matching of covariances of q(z) and p(z) via gradient descent.	Review	O	0
[line_break_token]The final objective uses a persistent estimate of the covariance matrix of q and upgrades it at each mini-batch to perform learning.	Review	O	0
[line_break_token][line_break_token]The authors use this objective function to perform experiments measuring disentanglement and find minor benefits compared to other objectives in quantitative terms.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token]1.	Review	O	0
The originally proposed modification in Equation (4) appears to be rigorous and as far as I can tell still poses a lower bound to log(p(x)).	Review	B-Review	1
The proof could use the result posed earlier: KL(q(z)||p(z)) is smaller than E_x KL(q(z|x)||p(z|x)).	Review	I-Review	1
[line_break_token]2.	Review	O	0
The proposed moment matching scheme performing decorrelation resembles approaches for variational PCA and especially independent component analysis.	Review	B-Review	6
The relationship to these techniques is not discussed adequately.	Review	I-Review	6
In addition, this paper could really benefit from an empirical figure of the marginal statistics of z under the different regularizers in order to establish what type of structure is being imposed here and what it results in.	Review	I-Review	6
[line_break_token]3.	Review	I-Review	2
The resulting regularizer with the decorrelation terms could be studied as a modeling choice.	Review	I-Review	3
In the probabilistic sense, regularizers can be seen as structural and prior assumptions on variables.	Review	I-Review	3
As it stands, it is unnecessarily vague which assumptions this extra regularizer is making on variables.	Review	I-Review	3
[line_break_token]4.	Review	I-Review	4
Why is using the objective in Equation (4) not tried and tested and compared to?	Review	I-Review	2
It could be thought that subsampling would be enough to evaluate this extra KL term without any need for additional variational parameters \psi.	Review	I-Review	2
The reason for switching to the moment matching scheme seems not well motivated here without showing explicitly that Eq (4) has problems.	Review	I-Review	2
[line_break_token]5.	Review	O	0
The model seems to be making on minor progress in its stated goal, disentanglement.	Review	B-Review	7
It would be more convincing to clarify the structural properties of this regularizer in a statistical sense more clearly given that experimentally it seems to only have a minor effect.	Review	I-Review	7
[line_break_token]6.	Review	O	0
Is there a relationship to NICE (Laurent Dinh et al)?	Review	B-Review	4
[line_break_token]7.	Review	O	0
The infogan is also an obvious point of reference and comparison here.	Review	B-Review	8
[line_break_token]8.	Review	O	0
The authors claim that there are no models which can combine GANs with inference in a satisfactory way, which is obviously not accurate nowadays given the progress on literature combining GANs and variational inference.	Review	B-Review	5
[line_break_token][line_break_token]All in all I find this paper interesting but would hope that a more careful technical justification and derivation of the model would be presented given that it seems to not be an empirically overwhelming change.	Review	O	0
Thank you for the careful reading of the paper and thoughtful comments!	Reply	O	0
[line_break_token][line_break_token][[Lower bound to log p(x):]][line_break_token]The proposed objective is indeed a lower bound to the evidence log p(x).	Reply	O	0
However the proof is really trivial and doesn‚Äôt need to use Inequality (3).	Reply	B-Reply	1
It can simply be shown by using nonnegativity of the distance between q(z) and p(z) (KL or any other divergence) -- since standard ELBO is a lower bound, subtracting any nonnegative quantity is also a lower bound.	Reply	I-Reply	1
[line_break_token][line_break_token][[Optimizing objective (4):]][line_break_token]Optimizing (4) with KL(q(z)||p(z)) ( = E_{q(z)} log (q(z)/p(z))) is not tractable with sampling because of the \log q(z) term (q(z)=E_{p(x)} q(z|x)).	Reply	O	0
One possibility (as we discuss in the paper) is to use variational form of KL as first proposed in (Nguyen et al.,	Reply	B-Reply	2
2010) and later in (Nowozin et al.,	Reply	I-Reply	2
2016) for GANs, however it will involve training a separate ‚Äúdiscriminator‚Äù that is expected to approximate the KL divergence at every iteration, which can be minimized using backprop.	Reply	I-Reply	2
We have tried this recently and found that the covariance matrix of z~q(z) has significant off-diagonal entries (ie, it does not decorrelate the latents well).	Reply	I-Reply	2
[line_break_token][line_break_token][[Structural properties / assumptions in the regularizer:]][line_break_token]The proposed regularizer KL(q(z)||p(z)) is trying to match the inferred prior q(z) to the hypothesized prior p(z), which will automatically happen if p_\theta(x) is close to p(x) (the model is good) and q(z|x) is close to p(z|x).	Reply	O	0
We have also discussed this in the paragraph just after Eq (3).	Reply	B-Reply	3
The regularizer is trying to enforce this explicitly which is totally natural (unless the hypothesized prior itself is too unreasonable).	Reply	I-Reply	3
[line_break_token][line_break_token][[Relationship to NICE (Dinh et al, 2016):]][line_break_token]NICE is another framework to do density estimation with latent variables where encoder and decoder are exact inverses of each other by design (encoder maps from data distribution to a factored distribution of same dimensionality following a specific architecture that allows for easy inverse computation, and hence easy sampling as well as tractable maximum likelihood based learning).	Reply	O	0
It can be compared/contrasted with the VAE which our proposed method is based upon -- eg, the reconstruction error is zero by design.	Reply	B-Reply	4
We restrict ourselves to the VAE in this work.	Reply	I-Reply	4
[line_break_token][line_break_token][[Comparison with InfoGAN:]][line_break_token]Unlike VAE, InfoGAN does not have a trained inference mechanism for real observations.	Reply	O	0
Though it has a network Q (shared with discriminator) that implicitly minimizes E_{x~G(z)} KL(p(z|x) || q(z||x)), this is targeted towards inference for fake examples from the generator. [	Reply	B-Reply	5
Higgins et al, 2017] compare \beta-VAE with InfoGAN finding that \beta-VAE outperforms and one of the reasons could be the lack of a true inference model.	Reply	I-Reply	5
[line_break_token][line_break_token][[Inference in GANs:]][line_break_token]We are aware of ALI [Dumoulin et al, ‚Äé2017] and BiGAN [Donahue et al, 2017] which still suffer from bad reconstruction (D(E(x)) is far from x) as observed in [Kumar et al, 2017]. There is also a recent work [Arora et al, 2017] showing that the encoder in ALI/BiGAN may potentially learn non-informative codes.	Reply	O	0
[line_break_token][line_break_token][Arora et al, 2017] Theoretical limitations of Encoder-Decoder GAN architectures, arXiv:1711.02651 2017[line_break_token][Dumoulin et al, ‚Äé2017] Adversarially learned inference, ICLR 2017[line_break_token][Donahue et al, 2017] Adversarial feature learning, ICLR 2017[line_break_token][Kumar et al, 2017] Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference, NIPS 2017	Reply	O	0

This paper deals with the open set classification problem, where in addition to the known classes, the method should also be able to recognize the unknown class.	Review	O	0
The main idea is based on two parts: learning a discriminative representation, and a threshold based detection rule.	Review	O	0
To learn the embedding, the authors propose to minimize the inner class distance (between each instance to its center) and enlarge the distance between centers.	Review	O	0
The outlier score of an instance is computed as the minimum distance between known class prototypes.	Review	O	0
Experiments on various datasets show the ability of the learned method.	Review	O	0
[line_break_token][line_break_token]I'm not completely sure whether the whole approach is novel or not in the open set recognition domain, but both parts are not novel enough.	Review	B-Review	1
Pulling similar instances together and pushing dissimilar ones away is the main idea in embedding learning.	Review	I-Review	1
The ii-loss is similar to the triplet-center loss in the paper "He et al.	Review	I-Review	1
Triplet-Center Loss for Multi-View 3D Object Retrieval.	Review	I-Review	1
CVPR18".	Review	I-Review	1
[line_break_token][line_break_token]Although in the experiments the proposed method achieves good results in most cases, the reviewer suggests the authors comparing with more baselines to make the work solid.	Review	O	0
[line_break_token]1.	Review	O	0
Comparing with other embedding learning methods with the same outlier detection score.	Review	B-Review	2
[line_break_token]The authors should prove that the proposed embedding is important enough in the open set case.	Review	I-Review	2
For example, using the center loss (Wen et al.	Review	I-Review	2
A discriminative feature learning approach for deep face recognition.	Review	I-Review	2
ECCV16), triplet-center loss, triplet loss (computing class centers after embedding).	Review	I-Review	2
[line_break_token][line_break_token]2.	Review	O	0
Discuss more on the outlier score part.	Review	B-Review	3
[line_break_token]How to differentiate the known class outlier and new class?	Review	I-Review	3
Will the problem be more difficult when the unknown class contains more heterogeneous classes?	Review	I-Review	3
The authors can also apply existing open set recognition rule on the learned embedding.	Review	I-Review	3
[line_break_token][line_break_token]Some detailed questions:[line_break_token]1.	Review	O	0
What's the difference between "the network weights are first updated to minimize on ii-loss and then in a separate step updated to minimize cross entropy loss" and optimize both loss terms simultaneously?	Review	B-Review	4
[line_break_token]2. "	Review	O	0
We assume that a certain percent of the training set to be noise/outliers", how to determine the concrete value?	Review	B-Review	5
Is 1% the helpful one for all cases?	Review	I-Review	5
[line_break_token]3.	Review	O	0
Since there is not optimize over the unknown classes in training, could the reason for "the unknown class instances fully occupy the open space between the known classes" is the unknown classes are randomly sampled from the whole class set?	Review	B-Review	6
For example, if classes about animals are known classes and classes about scene compose the unknown class, will the unknown class also occupy the whole space in this case?	Review	I-Review	6
[line_break_token]4.	Review	O	0
What is the motivation of making "the unknown class instances fully occupy the open space between the known classes"?	Review	B-Review	7
We thank the reviewer for this comment.	Reply	O	0
[line_break_token][line_break_token]We have conducted further experiments to quantify the advantage of  ii-loss over central loss.	Reply	B-Reply	1
Here are the results from experiments on using central loss:[line_break_token]MNIST dataset: 30-run average AUC=0.9264 [line_break_token]Android dataset: 30-run average AUC=0.7514[line_break_token]MS dataset: 30-run average AUC=0.9234[line_break_token][line_break_token]In all cases ii-loss based approach records a statistically significant improvement over central loss based approach.	Reply	I-Reply	1
[line_break_token][line_break_token]The authors of triplet-center loss (which incorporates inter-class distance) also found improvement over center-loss in (regular) classification tasks.	Reply	I-Reply	2
  Also, although both ii-loss and triplet-center loss consider inter-class distance, ii-loss has less computational overhead.	Reply	I-Reply	2
  In ii-loss, centroids (centers) are first calculated and inter-class distances between centroids are then calculated.	Reply	I-Reply	2
 In triplet-center loss, for each sample, the closest sample from another class need to be found.	Reply	I-Reply	2
 [line_break_token][line_break_token]With regards to the reviewers question about how to differentiate the known class outlier and new class:[line_break_token]- Our work focuses on differentiating new class rather than on the problem of known class outliers.	Reply	O	0
Although we believe the proposed approach can be applied to the known class outlier problem we have not conducted experiments to verify this.	Reply	B-Reply	3
[line_break_token][line_break_token]With regards to heterogeneous unknown classes:[line_break_token]- The open set problem is actually easier when the unknown classes are more different from the known classes.	Reply	O	0
[line_break_token][line_break_token]The following are answers to the detail questions:[line_break_token]1.	Reply	O	0
There shouldn‚Äôt be much of a difference between optimizing the ii-loss and cross-entropy loss separately or simultaneously.	Reply	B-Reply	4
Our decision to do this separately was many an engineering decision to allow as to experiment with different network topology.	Reply	I-Reply	4
[line_break_token]2.	Reply	O	0
In our experiments we found the 1% contamination ratio to be widely applicable.	Reply	B-Reply	5
We chose contamination ratio based threshold because it is easier to understand by the user.	Reply	I-Reply	5
For example, if catching more unknown class instances is more important to the user she/he can set a higher contamination ratio and vise versa.	Reply	I-Reply	5
[line_break_token]3.	Reply	O	0
When the unknown class and the known class are different (for example the reviewer mentions animals vs scene) the unknown classes are not projected close to any articular known class hence occupying more space between the known classes.	Reply	B-Reply	6
The more difficult problem is when the unknown classes are very similar to the known.	Reply	I-Reply	6
In which case their projection  will be closer to one of the known and might even overlap making it more difficult.	Reply	I-Reply	6
Hence why in the classes in our experiments are similar.	Reply	I-Reply	6
[line_break_token]4.	Reply	O	0
The motivation for making "the unknown class instances fully occupy the open space between the known classes" is to reduce the chance of unknown class projection overlapping a known class projection.	Reply	B-Reply	7
[line_break_token][line_break_token]Finally, we would like to point out that the papers on center loss and triplet-center loss did not  address the task of open-set recognition.	Reply	O	0
 However, our paper focuses on open-set recognition.	Reply	O	0
Also, the papers on center loss and triple-center loss focus on computer vision-related problems.	Reply	O	0
 However, our paper discusses the utility of our proposed approaches in two very different domains: computer security and computer vision.	Reply	O	0

This paper proposes an unsupervised method for learning representations of speech signals using contrastive predictive coding.	Review	O	0
[line_break_token]The authors provide results for the speech recognition task, in which they trained their model on up to 8000 hours of speech.	Review	O	0
The authors provide results on several English benchmark datasets in addition to four low-resource African language datasets.	Review	O	0
[line_break_token]The authors compared their method to the traditional signal processing representations and show that the proposed method is superior.	Review	O	0
[line_break_token][line_break_token]My main concern with this submission is its novelty.	Review	O	0
[line_break_token]The proposed method was previously explored in [1] and presented similar results.	Review	B-Review	1
If I understand it correctly, the main novelty in this work is the usage of bi-directional models together with more data.	Review	I-Review	1
However, it is not clear what made the improvements.	Review	I-Review	1
Considering the fact that such an approach was suggested recently by [1], a detailed comparison with uni-directional models is needed.	Review	I-Review	1
[line_break_token]For example, in Table 2, the authors provide results for WSJ dataset, however, with no LM decoding.	Review	I-Review	4
Can the authors provide experiments of WSJ while using LM similarly to [1]?	Review	I-Review	4
 Moreover, if the authors wanted to eliminate the effect of LM as they stated in the paper, why not calculating Character Error Rates instead or in addition to Word Error Rates?	Review	I-Review	4
Again, as done in [1], and in many other papers in the field [2]. [line_break_token][line_break_token]Additionally, in Table 1 and Table 5, the error rates seem pretty high, especially for the baseline model, did the authors investigated different architectures/stronger ones for these tasks?	Review	O	0
Different representations such as LogFilterBanks / MFCCs?	Review	B-Review	2
[line_break_token][line_break_token]I'm willing to increase my score, in case the authors will address my concerns.	Review	I-Review	1
However, at the moment, I do not see much novelty in this paper comparing to previous work.	Review	I-Review	1
Additionally, the authors are missing an essential comparison to previous work so we could better understand the contribution of this paper.	Review	I-Review	1
[line_break_token][line_break_token]Minor comments: "using a simpler convolutional architecture than is common" -&gt; should be rephrased.	Review	O	0
[line_break_token][line_break_token][line_break_token][1] Schneider, Steffen, et al. "	Review	O	0
wav2vec: Unsupervised Pre-training for Speech Recognition."	Review	O	0
arXiv preprint arXiv:1904.05862 (2019).	Review	O	0
[line_break_token][line_break_token][2] Adi, Yossi, et al. "	Review	O	0
To Reverse the Gradient or Not: an Empirical Comparison of Adversarial and Multi-task Learning in Speech Recognition."	Review	O	0
ICASSP, 2019.	Review	O	0
[line_break_token]	Review	O	0
hank you for the review.	Reply	O	0
[line_break_token][line_break_token]We would like to clarify the novelty of our work and its relation to published work.	Reply	B-Reply	1
The representation learning objectives and model architectures are indeed quite similar to [1, 2]; however, we did not intend to imply that either the architecture or training objective is what makes this paper novel, rather we contribute three significant results:[line_break_token]1.	Reply	I-Reply	1
We demonstrate the feasibility and advantages of pre-training on large-scale and noisy data.	Reply	I-Reply	1
[line_break_token]2.	Reply	I-Reply	1
We demonstrate robustness on out-of-domain evaluation that large-scale pre-training provides.	Reply	I-Reply	1
[line_break_token]3.	Reply	I-Reply	1
We demonstrate that large-scale pre-training results in representations that are universal, as demonstrated by performance on low-resource languages.	Reply	I-Reply	1
[line_break_token]All three of these points are new compared to results shown in previous papers.	Reply	I-Reply	1
[line_break_token][line_break_token]Moreover, these are important aspects of representation learning.	Reply	I-Reply	1
And, not only do we explore them systematically for the first time, but we also apparently find that large-scale pretraining reverse a trend toward worse performance with larger data that was hinted at in [2], where they show that increasing the amount of pre-training data did not lead to improved downstream performance.	Reply	I-Reply	1
Also, in our replication, the models trained only on Librispeech data did not perform well in out-of-domain evaluations or in low-resource languages, demonstrating the importance of diverse kinds of pre-training data - again, a novel and important result.	Reply	I-Reply	1
Those findings are of considerable interest since certainly a major benefit of unsupervised learning is being able to improve the robustness of ASR systems, which is a long standing challenge.	Reply	I-Reply	1
The low-resource aspect has been investigated in Zerospeech challenge.	Reply	I-Reply	1
We will explain the connections in the final version of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the effect of the LM on the WSJ task- again, the point of this paper is the robustness of the acoustic representations across datasets, domains, and languages.	Reply	I-Reply	4
The results of our in-domain setup demonstrate that these representations are adequate for this setup, but exploring the in-domain setup in detail distracts from the point of the paper.	Reply	I-Reply	4
[line_break_token][line_break_token]Regarding the minor tweaks to the model: The improvements to the model (bidirectional context network and dense residual connections) certainly improved the performance to the level that our representations only needs 10% of the labelled data to achieve the same result as the same model trained on spectrogram features using 100% of the training data.	Reply	I-Reply	3
[line_break_token][line_break_token]We used exactly the same model architecture, learning rate schedule for different features.	Reply	I-Reply	3
We fixed the model to DeepSpeech2 and tuned the learning rate and its scheduler for baseline features (not for our features).	Reply	I-Reply	3
It is quite likely we could further improve the results with our features if we re-tuned the hyperparameters, but the scientific point we wished to make was already made.	Reply	I-Reply	3
[line_break_token][line_break_token][1] Representation Learning with Contrastive Predictive Coding, van den Oord et al.	Reply	O	0
[line_break_token][2] Wav2vec: unsupervised pre-training for speech recognition, Schneider et al	Reply	O	0

This paper proposes an end-to-end deep reinforcement learning-based algorithm for the 2D and 3D bin packing problems.	Review	O	0
Its main contribution is conditional query learning (CQL) which allows effective decision over mutually conditioned action spaces through policy expressed as a sequence of conditional distributions.	Review	O	0
Efficient neural architectures for modeling of such a policy is proposed.	Review	O	0
Experiments validate the effectiveness of the algorithm through comparisons with genetic algorithm and vanilla RL baselines.	Review	O	0
[line_break_token][line_break_token]Overall, the paper provides a solid contribution by proposing a new RL-based algorithm for the bin packing problem.	Review	O	0
In particular, the dense reward design for the MDP is quite interesting.	Review	O	0
I also think solving the 2D and 3D bin packing problem via RL is already quite valuable as an application.	Review	O	0
[line_break_token][line_break_token]However, I do not think the proposed method is novel enough.	Review	B-Review	1
Most importantly, I perceive the concept of conditional query learning indifferent from the autoregressive modeling of the policy (with conditionally masked inputs).	Review	I-Review	1
Although the authors divide the processing of each bin into three steps of MDP (not strictly), the steps can be merged into one without any change in the environment.	Review	I-Review	1
Since other parts of the algorithm also come from the existing literature (except the reward design), I think this point is crucial for the paper to be published at the conference.	Review	I-Review	1
[line_break_token][line_break_token]Minor comment:[line_break_token]- I think the genetic algorithm described in the experiments should be equipped with more details, i.e., the type of processor used and elapsed time.	Review	I-Review	2
[line_break_token]- In table 2, I think bold numbers for the lowest variance of performance is very confusing since it does not necessarily mean a better algorithm.	Review	I-Review	2
hank you for your constructive comments and it seems you have understood our paper quite well.	Reply	O	0
However, we want to reiterate our major contributions again.	Reply	O	0
[line_break_token][line_break_token]The conditional query model learning is a new method to address mutually conditioned action space problems.	Reply	B-Reply	1
[line_break_token][line_break_token]If sub-action steps are merged to one, the subsequent step can not condition on previous results, although the underline inference of results are saved in the network parameters, the specific actions are sampled from the probability distribution of model's outputs, so the merged model may perform overall not too bad.	Reply	I-Reply	1
However, it can not produce a well fitted result for individual instance since the model lack of the knowledge of sampled results.	Reply	I-Reply	1
By conditional query, the model get attention of the packing object over all packed boxes to inference next sub-action without effected by random sampling of previous actions.	Reply	I-Reply	1
[line_break_token][line_break_token]We conduct the experiment of merged model in the 'no query' model, the results shows that our conditional model greatly improves the performance of algorithm.	Reply	I-Reply	1
[line_break_token][line_break_token]The other two minor comments are very helpful, and we will revise it in our updated version.	Reply	I-Reply	2

The paper presents a meta-learning algorithm to automatically detemine the depth of neural network through a policy to add depth if this bring improvement on accuracy.	Review	O	0
[line_break_token][line_break_token]I have conserved opinion based on the technique being used here is extremely simple, basically is an implementation of naive greedy algorithm in such a scenario, which implies the problem may not be intrinsically hard, or even useful.	Review	B-Review	3
The paper consists of detailed narrative about how these procedure are conducted, but still, it is really hard for me to find the true merit to appreciate, and why this brings a nontrivial and usefull contribution.	Review	O	0
The tables, visualization figures also didnot imply too much about whether this is more than overfitting on previous works with hand-chosen depth.	Review	B-Review	2
hanks for the review.	Reply	O	0
[line_break_token][line_break_token]We actually started from more complex and "nicer" methods, such as network morphism.	Reply	B-Reply	1
[line_break_token]However, our experiments showed that those more complex methods worked worse than our simple solution (covered in this paper).	Reply	I-Reply	1
[line_break_token]Therefore, one of our contribution is that complex growing is NOT necessary, a simple periodic  growing can even does better.	Reply	I-Reply	1
[line_break_token][line_break_token]Then the question is: should we appreciate more complex methods which have worse results or appreciate simple but more effective methods?	Reply	I-Reply	1
[line_break_token][line_break_token]Others:[line_break_token]* "implies the problem may not be intrinsically hard, or even useful.":	Reply	O	0
growing architecture is harder than pruning architecture [1]. Pruning starts from a predefined large space and just need to find a subspace within it, while growing performs in a reversed order, during which the search space is totally open.	Reply	B-Reply	3
A simple pruning method [1] inspires lots of following work and we wish our method can inspire others from a new perspective.	Reply	I-Reply	3
We also believe, in the future, that combining pruning and growing will be important.	Reply	I-Reply	3
[line_break_token]We need more details from the reviewer regarding why automatically growing neural architecture will not be useful.	Reply	I-Reply	3
[line_break_token]* "detailed narrative" is exactly how we showed that complex methods are not necessary and can even be worse.	Reply	O	0
[line_break_token]* "overfitting": all results are cross validated by a standard machine learning procedure.	Reply	O	0
It is not a question specifically for our paper.	Reply	B-Reply	2
It is a question for the whole community that if using validation dataset of ImageNet can result in overfitting.	Reply	I-Reply	2
[line_break_token][line_break_token][1] Han, Song, Jeff Pool, John Tran, and William Dally. "	Reply	O	0
Learning both weights and connections for efficient neural network."	Reply	O	0
In Advances in neural information processing systems, pp.	Reply	O	0
1135-1143.	Reply	O	0
2015	Reply	O	0

This paper targets at a deep learning theory contribution based on information geometry.	Review	O	0
This contribution is tightly based on Zhang et al. (	Review	O	0
2018) and explains the generalization of deep learning from a Bayesian perspective.	Review	O	0
The main contribution the authors claimed is an optimal degree of curvature exist which gives the best generalization guarantees, which is in contrast to the commonly perceived "the wider the better".	Review	O	0
[line_break_token][line_break_token]First of all, the writing (including language etc) is of poor quality, to the extent that the submission is very difficult to read and can be rejected merely based on this, with unusual expressions, missing  punctuations, super long sentenses, and wongly used words.	Review	B-Review	1
The reviewer won't list example here because they are everywhere.	Review	I-Review	1
[line_break_token][line_break_token]What is even worse is the conceptral errors and defected derivations.	Review	I-Review	2
For example, in eq.(1), the authors equate the Fisher information matrix (which is an expected Hessian) to the Hessian matrix, this is subject to conditions which must be clearly given right before/after the equation.	Review	I-Review	2
As their results are largely based on the correctness of eq.(2), let's examine the derivations in appendix A.1.	Review	I-Review	3
 In the first equation in A.1, what is the subindex "j"?	Review	I-Review	3
 "Utilizing Laplace Approximation of the integral": such approximations have conditions that must be clearly stated.	Review	I-Review	3
It is not clear how one can get the last approximation in page 12 from the previous equations.	Review	I-Review	3
In summary, their eq.(2) is a loose approximation which is subject to a set of conditions (that are not given), and the derivation is of poor quality.	Review	I-Review	3
[line_break_token][line_break_token]As a theoreiritical contirbution, the authors did not manage to converge to some simple and clear statements (theorems or equvalent).	Review	I-Review	4
Instead, the contribution is largely *explanatory*. It is hard to observe anything new, given the poor writing and organization.	Review	I-Review	5
The first 4 pages are mainly introductions of previous works.	Review	I-Review	6
[line_break_token][line_break_token]The authors used information geometry and minimum description length to explain the generalization of deep learning.	Review	I-Review	7
This is a small area.	Review	I-Review	7
It is hard to miss closely related works by simple searching.	Review	I-Review	7
Instead, the authors only cited Rissanen (1978).	Review	I-Review	7
On the other hand, as the authors used the spectrum properties of the Fisher information matrix, there are some recent works by Amari which can be cited.	Review	I-Review	7
e thank the reviewer for their constructive feedback.	Reply	O	0
[line_break_token][line_break_token]Q1) On the point of the poor writing quality.	Reply	O	0
[line_break_token][line_break_token]A1) We apologize for this and are working hard to improve the literary standard of the paper.	Reply	O	0
[line_break_token][line_break_token]Q2) In eq.(1), the authors equate the Fisher information matrix (which is an expected Hessian) to the Hessian matrix, this is subject to conditions which must be clearly given right before/after the equation.	Reply	O	0
[line_break_token][line_break_token]A2) Thank you for pointing this out.	Reply	O	0
We will correct this error in the updated version.	Reply	B-Reply	2
[line_break_token][line_break_token]Q3) In the first equation in A.1, what is the subindex "j", "Utilizing Laplace Approximation of the integral": such approximations have conditions that must be clearly stated."	Reply	O	0
and "It is not clear how one can get the last approximation in page 12 from the previous equations."	Reply	O	0
[line_break_token][line_break_token]A3) The merits of the Laplace Approximation are discussed in [1]. We are adapting the discussion from [1] for the updated version of Appendix A. We are in the process of improving the general quality of Appendix A, including the discussion on the assumptions of the derivation and making the link between certain steps in the derivation more explicit.	Reply	O	0
Thank you for the feedback and assistance in improving this Appendix.	Reply	B-Reply	3
[line_break_token][line_break_token]Q4) As a theoreiritical contirbution, the authors did not manage to converge to some simple and clear statements (theorems or equvalent).	Reply	O	0
[line_break_token][line_break_token]A4) We believe Reviewer #2 provides an excellent summary statement, and one which we have included in the paper.	Reply	O	0
Namely, "The authors provide theoretical arguments and claim that there exists an optimal width beyond which generalization can be poor".	Reply	B-Reply	4
[line_break_token][line_break_token]Q5)  It is hard to observe anything new, given the poor writing and organization.	Reply	O	0
[line_break_token][line_break_token]A5) We apologise if this was unclear and have made this clearer throughout the paper.	Reply	O	0
In addition, we point to the last paragraph of the Introduction beginning at the bottom of Page 1 where we outline what we perceive to be our 3 main contributions.	Reply	B-Reply	5
In summary:[line_break_token]1) We reflect that a correlation exists between energy and entropy as opposed to a competition or trade-off as was first presented in [1].[line_break_token]2) We reflect that an optimal level of curvature exists within the[line_break_token]landscape which does not necessarily occur at the point in the landscape with the least curvature.	Reply	O	0
We provide the novel perspective that the propensity of the model to find points of minimal curvature is a direct result of the model's propensity to overfit the training data.	Reply	B-Reply	5
[line_break_token]3) We show that at the point in the landscape which corresponds to the Jeffreys prior the test error of the model reaches its minimum value and at this point the dimension of principal curvature of the model is at its maximum entropy.	Reply	O	0
In doing so we also reflect the noise invariance of the dimension of principal curvature.	Reply	B-Reply	5
[line_break_token][line_break_token]Q6) The first 4 pages are mainly introductions of previous works.	Reply	O	0
[line_break_token][line_break_token]A6) We acknowledge that our work does rely heavily on past work and provides a detailed exposition of these past works, however, we view this as being necessary as we utilize a number of different field in this work.	Reply	O	0
Namely Objective Bayes statistic, Information Theory, Differential Geometry and Machine Learning.	Reply	B-Reply	6
We believe it necessary to not only provide sufficient background information for each field separately but also to illustrate the necessary overlap of the different concepts in these field for the full impact of this work to be seen.	Reply	I-Reply	6
For example, a reader who is aware of the Jeffreys prior from an Objective Bayesian perspective may be unaware of its use as a right Haar measure in Differential Geometry.	Reply	I-Reply	6
Thus, we aim to reflect the key fact that the Fisher Information, and as a result the Jeffreys Prior, is the commonality between the fields and guides our argument from the Objective Bayesian perspective of Section 3 to the Information Geometry perspective in Sections 4 and 5.	Reply	I-Reply	6
We are, however, working at reducing the excess information in the paper, such as the overlap between the MDL property and Bias-Variance Dilemma, and restructuring aspects of our arguments to ensure that our contributions are clearer.	Reply	I-Reply	6
[line_break_token][line_break_token]Q7) The authors used information geometry and minimum description length to explain the generalization of deep learning.	Reply	O	0
This is a small area.	Reply	O	0
It is hard to miss closely related works by simple searching.	Reply	O	0
Instead, the authors only cited Rissanen (1978).	Reply	O	0
[line_break_token][line_break_token]A7) Given the fact that the Minimum Description Length Principle can be equally phrased in light of the Bias-Variance trade-off which is also discussed in this work we see this as an opportunity to reduce the length of this work closer to 8 pages in line with the Conference standards and will, thus, rephrase our argument more in term of the Bias-Variance trade-off.	Reply	O	0
[line_break_token]	Reply	O	0

[line_break_token]This paper attempts to formalize the notion of 'computational creativity' from a machine learning perspective, in order for machine learning researchers to make better progress on this problem.	Review	O	0
In particular, the authors propose measuring the 'computational creativity' of a model by several metrics intending to capture whether the model can generate new objects from classes unseen during training.	Review	O	0
[line_break_token][line_break_token]I think this is an interesting paper and a good first step in this area.	Review	O	0
Indeed, absent proper definitions and metrics for vague concepts such as 'creativity', it is difficult to make progress on related computational problems.	Review	B-Review	1
While the proposed metrics are not perfect,* they seem reasonable enough to warrant future investigation, and thus I think this paper is worthy of acceptance as an ICLR workshop paper.	Review	I-Review	1
[line_break_token][line_break_token]*Further thoughts: I'm not convinced that these metrics are selecting for the "right" models from a creativity point of view.	Review	O	0
If Figure 1 is really a random sample of digits generated by one of the 'most creative' models according to the proposed metrics, it seems like it is mostly just good at capturing lower-level correlations in the data, while generating random high-level details.	Review	B-Review	2
Thus it seems like a 'creative' model is one that has been artificially limited in order to poorly model high-level features of the data.	Review	O	0
This seems intuitively to contrast with creativity as we perceive it in humans -- creative humans are still capable of modeling the world around them, they are just able to combine what they've learned in new and interesting ways.	Review	O	0
Perhaps 'true creativity' is out of the reach of current generative models? (	Review	B-Review	1
Or, perhaps the word 'creativity' is not really meaningful from a computational perspective?)	Review	I-Review	1
 However, I'm not an expert in this area, and I still think the idea is worthwhile presenting, as it may generate interesting discussions.	Review	O	0
In future work, I'd like to see a more thorough analysis of what model settings lead to  the most 'creative behaviour' according to these metrics.	Review	O	0
Thank you for your comments and suggestions.	Reply	O	0
[line_break_token]We are working on a more detailed analysis to understand under [line_break_token]which conditions we obtain a model that generates novelty	Reply	B-Reply	1

I generally like the paper.	Review	O	0
The paper discussed a constrained value iteration setting where the safety contraints must be greater some threshold, and thresholds \delta are parameters.	Review	O	0
The paper attempts to develop an value iteration algorithm to compute a class of optimal polices with such a parameter.	Review	O	0
The algorithm is mainly based on a special design of representation/data structure of PWC function, which can be used to store value functions and allows to efficiently compute several relevant operations in bellman equation.	Review	O	0
A graph-based data structure is developed for continuous state domains and hence value iteration can be extended to such cases.	Review	O	0
[line_break_token][line_break_token]In general, the paper presents an interesting direction which can potentially help solve RL problems with the proposed constraint setting.	Review	O	0
However, the paper spends lots of effort explaining representations, but only a few sentences explaining about how the proposed representations/data structures can help find a somehow generic value iteration solution, which allows to efficiently compute/retrieve a particular solution once a \delta vector is specified.	Review	B-Review	1
The paper should show in detail (or at least give some intuitive explanations) that using the proposed method can be more efficient than solving a value iteration for each individual constraint given that the constraints are independent.	Review	I-Review	1
Specifically, the author uses the patient case to motivate the paper, saying that different patients may have different preferred thresholds and it is good to find class of policies so that any one of those policies can be retrieved once a threshold is specified.	Review	I-Review	1
However, in this case, when dealing with only one patient, the dimension of reward is reduced to 1 (d = 1), while the computation of the algorithm is exponential in d, plus that the retrieval time is not intuitive to be better, so it is unsure whether computing such a class of policies worth.	Review	I-Review	1
[line_break_token][line_break_token]In terms of novelty, the scalarization method of the vector-valued reward seems intuitive, since breaking a constraint means a infeasible solution.	Review	I-Review	2
Furthermore, it is also unclear why the representation of PWC in discrete case is novel.	Review	I-Review	3
A partial order on a high-dimensional space is naturally to be based on dominance relation, as a result, it seems natural to store value function by using right-top coordinates of a (hyper)rectangle.	Review	I-Review	3
[line_break_token][line_break_token]As for the clarity, though the author made the effort to explain clearly by using examples after almost every definition/notation, some important explanations are missing.	Review	I-Review	4
I would think the really interesting things are the operations based on those representations.	Review	I-Review	4
For example, the part of computing summation of two PWC function representation is not justified.	Review	I-Review	4
Why the summation can be calculated in that way?	Review	I-Review	4
Though the maximum operation is intuitive, however, the summation should have some justification.	Review	I-Review	4
I think a better way to explain those things is to redefine a new bellman operator, which can operate on those defined representations of PWC function.	Review	I-Review	4
[line_break_token][line_break_token]I think it could be a nice work if the author can improve the motivation and presentation.	Review	I-Review	5
Experiments on some simple domains can be also helpful.	Review	I-Review	5
- To avoid confusion, d is the dimension of the parameter space and is not related to the number of users.	Reply	O	0
But yes, for a single patient, the parameters will be fixed and the reward vector will be scalarized.	Reply	B-Reply	1
We added a comment below about the motivation	Reply	I-Reply	5

The paper introduces an efficient, unbiased contrastive divergence-like algorithm for training energy-based generative models on the example of Restricted Boltzmann Machine.	Review	O	0
[line_break_token]The proposed algorithm is built upon a very interesting work on unbiased finite-step MCMC approximations by Jacob et al, 2017.	Review	O	0
[line_break_token]Despite the actual theory being published some time ago, the submitted paper popularises these ideas in the machine learning community and contains optimised variants of the existing algorithms for training of RBMs.	Review	O	0
[line_break_token][line_break_token]The paper is mostly written well and does a good job of introducing unbiased MCMC estimators.	Review	O	0
[line_break_token]Authors evaluate their method on rather toyish datasets (by modern standards), however, their empirical analysis is thorough.	Review	O	0
The improvement upon the standard CD and persistent CD is clear.	Review	O	0
[line_break_token]It also appears that the algorithm actually does not require too many steps and generally does not introduce a lot of computational overhead.	Review	O	0
[line_break_token]The only question I have is why CD has only been tried with k=1 steps?	Review	B-Review	1
[line_break_token]I would be interested in its performance for different number of steps including the dynamically chosen number provided by the empirical \tau in UCD for a given iteration.	Review	I-Review	1
[line_break_token]Even though I do not expect a significant improvement to be obtained, this would separate the effect of the number of steps chosen ‚Äúright‚Äù from unbiasedness of the gradient estimator.	Review	I-Review	2
[line_break_token]Other baselines, including those mentioned in the related work, could also make the comparison more complete.	Review	I-Review	3
[line_break_token][line_break_token]I would also suggest including <a href="https://arxiv.org/abs/1905.04062," target="_blank" rel="nofollow">https://arxiv.org/abs/1905.04062,</a> as it seems to be relevant in the spirit.	Review	O	0
hanks for the suggestions.	Reply	O	0
We have added more comparisons in the new version.	Reply	B-Reply	3
[line_break_token][line_break_token]&gt;&gt;&gt; The only question I have is why CD has only been tried with k=1 steps?	Reply	O	0
[line_break_token]I would be interested in its performance for different number of steps including the dynamically chosen number provided by the empirical \tau in UCD for a given iteration.	Reply	O	0
[line_break_token]Even though I do not expect a significant improvement to be obtained, this would separate the effect of the number of steps chosen ‚Äúright‚Äù from unbiasedness of the gradient estimator.	Reply	B-Reply	1
[line_break_token]Other baselines, including those mentioned in the related work, could also make the comparison more complete.	Reply	I-Reply	1
[line_break_token][line_break_token]We have significantly improved the numerical experiments with larger models, and have included CD-k algorithms with larger k in Appendix B.[line_break_token][line_break_token]&gt;&gt;&gt; I would also suggest including <a href="https://arxiv.org/abs/1905.04062," target="_blank" rel="nofollow">https://arxiv.org/abs/1905.04062,</a> as it seems to be relevant in the spirit.	Reply	O	0
[line_break_token][line_break_token]We have added this article to our reference	Reply	B-Reply	4

[line_break_token]The manuscript proposes an evaluation methodology to obtain deeper insights regarding the strength and weaknesses of different methods on different datasets.	Review	O	0
The method considers a set of methods addressing the task of Named Entity Recognition (NER) as case study.	Review	O	0
In addition, it proposes a set of attribute-based criteria, i.e. bucketization strategies, under which the dataset can be divided and analyzed in order to highlight different properties of the evaluated methods.	Review	O	0
[line_break_token][line_break_token]As said earlier, the manuscript proposes an evaluation methodology to obtain deeper insights regarding the strength and weaknesses of different methods on different datasets.	Review	O	0
The characteristic of being able to provided deeper insights on strength/weaknesses and relevant factors on the inner-workings of a given method is [line_break_token]something very desirable for every evaluation.	Review	O	0
As such, in my opinion, the "interpretable" tag associate to the proposed method is somewhat out of place.	Review	B-Review	1
Having said that, I would recommend removing the "interpretable" tag and stress the contribution of this manuscript as an evaluation protocol.	Review	I-Review	1
[line_break_token][line_break_token]In Section 4.2, for the R-Bucket strategy it is stated as having the requirement of discrete and finite attributes.	Review	I-Review	2
Based on the equations of the other two strategies (R-bucket and F-bucket), it seems that they also have the requirement of having discrete attributes.	Review	I-Review	2
Is this indeed the case?	Review	I-Review	2
if so, it should be explicitly indicated.	Review	I-Review	2
[line_break_token]Having said that, this raises another question: Is this protocol exclusive to tasks/problems with explicit discrete attributes?	Review	I-Review	2
[line_break_token][line_break_token]The goal of this manuscript is to propose a general evaluation protocol for NLP tasks.	Review	O	0
[line_break_token]However, it seems to be somewhat tailored to the NER task.	Review	O	0
My question is: How well the proposed method generalizes to other NLP tasks without attributes?	Review	O	0
Similarly, how well the proposed bucketization strategies generalize beyond the NER task?	Review	B-Review	3
Perhaps the generalization characteristics and limitations of the proposed evaluation methodology should be explicitly discussed in the manuscript.	Review	I-Review	3
[line_break_token][line_break_token]Last paragraph of Section 4.2 summarizes ideas that were just presented.	Review	I-Review	4
It feels somewhat redundant.	Review	I-Review	4
I suggest removing in in favor of extending the existing discussions and analysis.	Review	I-Review	4
[line_break_token][line_break_token]I may consider upgrading my initial rating based on on the feedback given to my questions/doubts.	Review	O	0
[line_break_token]	Review	O	0
1: ‚ÄúHowever, it seems to be somewhat tailored to the NER task.	Reply	O	0
My question is: How well the proposed method generalizes to other NLP tasks without attributes?	Reply	O	0
Similarly, how well the[line_break_token]proposed bucketization strategies generalize beyond the NER task?‚Äù[line_break_token]A1: To adapt this methodology to other tasks, we honestly admit that the process of attribute definition usually requires some domain knowledge.	Reply	O	0
However, we would like to show the process is not complicated since many task-agnostic attributes could be applied, such as oov, sentence length.	Reply	B-Reply	3
Importantly, we believe each domain-specific expert should take responsibility for driving the development of the domain based on their understanding of the task, and hopefully, this work could provide such a methodology in which domain knowledge from different tasks could be utilized.&nbsp;[line_break_token]As a preliminary summary in the  table (Part1), we share some task-specific definition of attributes, where ‚ÄúTasks‚Äù represents different types of tasks; ‚ÄúAttributes‚Äù denotes the criterion that we use to divide the test set, and ‚ÄúMeasures‚Äù represents the measure we use to evaluate each divided sub-set. ‚	Reply	O	0
ÄúRelated ref.	Reply	B-Reply	3
‚Äù shows the corresponding papers that have adopted the attribute for fine-grained evaluation.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Q2: In Section 4.2, for the R-Bucket strategy it is stated as having the requirement of discrete and finite attributes.	Reply	O	0
Based on the equations of the other two strategies (R-bucket and F-bucket), it seems that they also have the requirement of having discrete attributes.	Reply	O	0
Is this indeed the case?	Reply	O	0
if so, it should be explicitly indicated.	Reply	O	0
Having said that, this raises another question: Is this protocol exclusive to tasks/problems with explicit discrete attributes?	Reply	O	0
[line_break_token]A2: We are sorry for not making it clear, and we have refined the description of the bucket strategy more clearly.	Reply	O	0
Specifically, R- and F- Bucket strategies could be applied to[line_break_token]attributes with discrete value and continuous value.	Reply	B-Reply	2
For example, the ‚Äúentity density‚Äù attribute we used in this paper.	Reply	I-Reply	2
Although its value is continuous, we could discretize the value into different ranges (i.e. low, medium, high), and then we could adopt the R- or F-Bucket strategies.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Q3: ‚ÄúLast paragraph of Section 4.2 summarizes ideas that were just presented.	Reply	O	0
It feels somewhat[line_break_token]redundant.	Reply	O	0
I suggest removing in in favor of extending the existing discussions[line_break_token]and analysis.	Reply	O	0
‚Äù[line_break_token]A3: Thanks for your granular suggestions, and you can see the modification in our revised version.	Reply	O	0
[line_break_token][line_break_token]Q4: "something very desirable for every evaluation.	Reply	O	0
As such, in my opinion, the "interpretable" tag associate to the proposed method is somewhat out of place.	Reply	O	0
Having said that, I would recommend removing the "interpretable" tag and stress the contribution of this manuscript as[line_break_token]an evaluation protocol."	Reply	O	0
[line_break_token]A4: Thanks for your constructive suggestion, and we have carefully considered it.	Reply	O	0
However, we have not taken it yet in our revised version, and we would like to share our reasons:[line_break_token]&nbsp;&nbsp;1) In this work, we aim to interpret the model biases, dataset biases, and their correlation.	Reply	O	0
Some of the previous work also involves the "bucketize-then-evaluate" idea (As we have listed in the above table and mentioned in the introduction section) while they are without a quantitative process to analyze these biases.	Reply	B-Reply	1
[line_break_token]&nbsp; 2) We also would like to show that this attribute-aided evaluation method could be a way for us to understand our black-box models and datasets.	Reply	O	0
[line_break_token][line_break_token]Thanks again for your insightful comments!	Reply	O	0
We have already refined the paper, please check the latest version.	Reply	O	0
Hope we answer your questions correctly and look forward to your feedback again	Reply	O	0

This paper creates a physics simulator using theano, and uses it to learn a neural network policy by back propagating gradients through the simulation.	Review	O	0
The approach is novel, and is motivated by being able to learn policies for robotics.	Review	O	0
[line_break_token][line_break_token]My two key reservations with the paper are as follows:[line_break_token]1.	Review	O	0
The method is motivated by learning policies for robotics.	Review	B-Review	1
However, the proposed method is *only* useful for robotics if the learned policy can transfer the real world.	Review	I-Review	1
Transferring policies from simulation to real-world is an open research problem, and is particularly challenging with less realistic simulators.	Review	I-Review	1
[line_break_token]2.	Review	O	0
They key novelty/benefit of this approach over other model-based approaches is that the simulator is differentiable.	Review	B-Review	2
However, the only empirical comparison in the paper is to a model-free approach (CMA-ES).	Review	I-Review	2
To appropriately demonstrate the approach, it should be compared to other model-based approaches, which do not require analytic derivatives of the model.	Review	I-Review	2
[line_break_token][line_break_token]For the reader to fully understand the pros and cons of the approach, the paper should also include quantitative comparison between the speed of the proposed simulator, and that of standard simulation platforms.	Review	I-Review	3
[line_break_token][line_break_token]Because the idea is interesting and novel, I think it lies above the acceptance threshold.	Review	I-Review	3
However, it would be significantly improved with the aforementioned comparisons.	Review	I-Review	3
[line_break_token][line_break_token]Lastly, the writing of the paper could be improved, as it is rather informal and/or imprecise in a number of places.	Review	I-Review	4
Here are some examples:[line_break_token]-- ‚Äúwe model the use of a neural network as a general controller for a robot‚Äù - can be more concisely phrased as something like ‚Äúwe model the robot controller using a neural network‚Äù or ‚Äúthe robot controller is modeled using a neural network"[line_break_token]-- ‚ÄúIn previous research, finding a gradient‚Ä¶‚Äù - This is a run-on sentence.	Review	I-Review	4
[line_break_token]-- ‚ÄúWe basically jam this entire equation into‚Äù - This sentence is informal and imprecise.	Review	I-Review	4
[line_break_token]-- ‚Äúdeep learning neural network‚Äù - the word ‚Äúlearning‚Äù should be omitted[line_break_token]-- ‚Äúone big RNN, where we unfold over time‚Äù - should be ‚Äú‚Ä¶RNN, which we unfold over time‚Äù or ‚Äú‚Ä¶RNN, unfolded over time‚Äù[line_break_token][line_break_token]The writing would also be improved by making it more concise and fitting the paper into 8 pages.	Review	O	0
Thank you for your remarks.	Reply	O	0
We have indeed removed informal and imprecise wording from our paper to the best of our capabilities, including the ones you have mentioned.	Reply	O	0
Some details have been moved to the appendix and other paragraphs have been made more concise to fit the paper into 8 pages.	Reply	B-Reply	8
[line_break_token][line_break_token]However, as long as the engine is not feature complete, we feel it is no use to perform quantitative speed comparisons with other engines.	Reply	I-Reply	3
The comparison would not be a fair one.	Reply	I-Reply	3
We believe the novelty lies indeed in the following:[line_break_token][line_break_token]* it is feasible to evaluate exact gradients of these robotic frameworks within a reasonable time.	Reply	I-Reply	3
Exact gradients should form a favorable approach to finite differences when the number of states of the system rises drastically, for instance when manipulating cloth.	Reply	I-Reply	3
[line_break_token]* the recent automatic differentiation libraries are powerful enough to become an important tool in the differentiation of robot models.	Reply	I-Reply	3
[line_break_token][line_break_token]Instead, we have made more clear how fast our engine is on our small models.	Reply	O	0
[line_break_token][line_break_token]In order to add more novelty to this approach in this paper, we have added a fourth example to this paper.	Reply	O	0
In this example, the controller relies on a differentiable camera in the differentiable physics engine in order to control a system.	Reply	O	0
To the best of our knowledge, differentiable cameras are a new approach to learning vision in robotics as well	Reply	O	0

This paper presents a GAN-based method to perform audio super-resolution.	Review	O	0
In contrast to previous work, this work uses auto-encoder to obtain feature losses derived from unlabeled data.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token](1) Redundant comma: ‚Äúfilters with very large receptive fields are required to create high quality, raw audio‚Äù.	Review	O	0
[line_break_token][line_break_token](2) There are some state-of-the-art non-autoregressive generative models for audio waveform e.g., parallel wavenet, clarinet.	Review	O	0
One may properly discuss them in related work section.	Review	B-Review	2
Although GAN performs very well for images, it hasn't obtained any compelling results for raw audios.	Review	I-Review	2
Still, it‚Äôs very interesting to explore that.	Review	I-Review	2
Any nontrivial insight would be highly appreciated.	Review	I-Review	2
[line_break_token][line_break_token](3) In multiscale convolutional layers, it seems only larger filter plays a significant role.	Review	O	0
What if we omit small filter, e.g., 3X1?	Review	B-Review	3
[line_break_token][line_break_token](4) It seems the proposed MU-GAN introduces noticeable noise in the upsampled audios.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- Interesting idea and fascinating problem.	Review	O	0
[line_break_token]Cons:[line_break_token]- The results are fair.	Review	O	0
I didn‚Äôt see big improvement over previous work (Kuleshov et al.,	Review	B-Review	5
2017).	Review	I-Review	5
[line_break_token][line_break_token]I'd like to reconsider my rating after the rebuttal.	Review	O	0
[line_break_token]	Review	O	0
[line_break_token]We thank the reviewer for the feedback.	Reply	O	0
Please see our enumerated responses below.	Reply	O	0
 [line_break_token]We have also posted a comment above that summarized the changes in the latest revision.	Reply	O	0
[line_break_token][line_break_token]*Q1*: Redundant comma: ‚Äúfilters with very large receptive fields are required to create high quality, raw audio‚Äù.	Reply	O	0
[line_break_token][line_break_token]*A1*: We have corrected this, thank you.	Reply	O	0
[line_break_token][line_break_token]*Q2*: There are some state-of-the-art non-autoregressive generative models for audio waveform e.g., parallel wavenet, clarinet.	Reply	O	0
One may properly discuss them in related work section.	Reply	O	0
Although GAN performs very well for images, it hasn't obtained any compelling results for raw audios.	Reply	O	0
Still, it‚Äôs very interesting to explore that.	Reply	O	0
Any nontrivial insight would be highly appreciated.	Reply	O	0
[line_break_token][line_break_token]*A2*: Thanks for pointing this out.	Reply	O	0
We have added a discussion of these works, and a comparison to other GAN-based methods in the Related Works section.	Reply	B-Reply	2
[line_break_token][line_break_token]*Q3*: In multiscale convolutional layers, it seems only larger filter plays a significant role.	Reply	O	0
What if we omit small filter, e.g., 3X1?	Reply	O	0
[line_break_token][line_break_token]*A3*: This is a good point - we found that small filters do play a marginal but noticeable role in audio quality and speed of convergence.	Reply	O	0
We suspect that while smaller filters are comparatively less powerful, they are easier to optimize and may have an important role in fitting many of the ‚Äúeasy‚Äù components in audio signals.	Reply	B-Reply	3
Smaller filters also have lower overhead in terms of computational requirements, making our networks (which have hundreds of feature maps in some layers) feasible to train in a few days or less with a single GPU.	Reply	I-Reply	3
  [line_break_token][line_break_token]*Q4*:  It seems the proposed MU-GAN introduces noticeable noise in the upsampled audios.	Reply	O	0
[line_break_token][line_break_token]*A4*: Thanks for this comment - we noticed this as well.	Reply	O	0
We have copied our answer A4 to reviewer #1 below:[line_break_token]We did notice that in some samples, especially at higher upsampling rates, there are instances of noise on utterances with significant high-frequency content (e.g., fricatives and aspiration).	Reply	B-Reply	4
We are not entirely certain on the cause of this noise, but we suspect that it is related to inherent ambiguity in the phase and magnitude of high frequency signals.	Reply	I-Reply	4
Furthermore, we found that this noise is present even if we replace the unsupervised feature loss with other conventional feature losses.	Reply	I-Reply	4
Nevertheless, we made sure to include samples at high up-sampling ratios that included this noise in the user study, which indicated that users preferred audio produced by our method in spite of spurious noise.	Reply	I-Reply	4
We have added a note in the paper regarding this problem.	Reply	I-Reply	4
[line_break_token][line_break_token]*Q5*: The results are fair.	Reply	O	0
I didn‚Äôt see big improvement over previous work (Kuleshov et al.,	Reply	O	0
2017).	Reply	O	0
[line_break_token][line_break_token]*A5*: We appreciate the criticism.	Reply	O	0
We wanted to highlight that while our baselines are based on the work from Kuleshov et al.,	Reply	B-Reply	5
2017, our primary baseline for evaluation (U-net8) is a much deeper and more powerful model compared to the model evaluated in Kuleshov et al.,	Reply	I-Reply	5
2017.	Reply	I-Reply	5
For a more direct comparison with Kuleshov et al.,	Reply	I-Reply	5
2017, see the results for U-net4 in the Experiments section, which are taken from the authors‚Äô paper.	Reply	I-Reply	5

The paper proposes a model for stochasticity for conditional image generation, building upon the previously available (DCFNet) results on composition of  convolutional filters out of the elements of the filter basis.	Review	O	0
[line_break_token][line_break_token]The idea of introducing stochasticity by convolutional filters into the conditional generative models seems to be novel and the reviewer thinks it could be of interest for the community.	Review	O	0
[line_break_token][line_break_token]The following remarks could be given to improve the presentation:[line_break_token]1) Theorem 1 is an existence theorem, so it does not give the procedure for construction of the basis.	Review	O	0
Does the construction procedure for the basis, described under the theorem formulation, meet the conditions of Theorem 1?	Review	B-Review	1
[line_break_token]2) The Theorem 1 formulation states that ‚Äú If there exists a set of deterministic linear transforms‚Äù.	Review	O	0
Should the linear independence be stated as well as one of the theorem conditions ( so that the space dimensionality would indeed be K)?	Review	B-Review	2
[line_break_token]3) The reviewer finds the structure of Section 4 confusing: it starts from the problem statement (first paragraph 'Using the method above, filters of each stochastic layer‚Ä¶‚Äô), then provides the description of the approach and only then outlines Theorem 1.	Review	O	0
It might be that stating Theorem 1 and then defining the method for generation of the basis (how exactly could we get to the basis? )	Review	B-Review	4
could improve readability of the paper.	Review	I-Review	4
Essentially, the question is: is there any way to emphasise the procedure for filter generation and inform the reader in which circumstances these filters would be the basis (e.g. why it wouldn't be prone to the analogue of mode collapse when the filters do not effectively have enough diversity for linear independence)?	Review	I-Review	3
[line_break_token]***[line_break_token]In addition to this list, it might be useful to provide some evidence on whether there is any inherent mechanism to regulate the diversity of filters and therefore of samples (so that to change the variability of the conditional samples from the model with the impact analogous to the one of temperature in Glow (Kingma et al, 2018)).	Review	O	0
If there is one, further experimental evidence, which shows the impact on diversity of filters, would contribute to improvement of the paper.	Review	B-Review	5
 [line_break_token]	Review	I-Review	1
Thanks for your support and all the insightful suggestions.	Reply	O	0
[line_break_token][line_break_token]*Construction procedure for the basis[line_break_token][line_break_token]The network construction procedure meets the condition of Theorem 1, that is, we constrain the number of basis to a small number of K (e.g. K=7), which imposes low-rankness of the generated filters as stated in Theorem 1.	Reply	O	0
[line_break_token]As discussed in Section 4, when we directly generate random convolution filters, we consistently observe that the obtained filters are always of low effective rank.	Reply	B-Reply	1
This observation of low-rankness motivates our construction of non-random (trainable) 1x1 convolutional layers 's) and randomly generated basis layers.	Reply	I-Reply	1
In the revised version, we additionally present an ablation study in supplemental material Section E and Table A.2 to show that increasing K, i.e. using more basis elements, does not provide any performance improvement.	Reply	I-Reply	1
We thus think K may serve as a parameter to regularize the model, also see below in "Model collapse".	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]*Linear Independence[line_break_token][line_break_token]Theoretically, linear independence is not needed for Theorem 1 to hold.	Reply	O	0
In case that's are linearly dependent, it does not affect the existence result of the theorem, and the dimensionality of the subspace (the true rank) will be K' &lt; K. We have revised the proof in supplemental material Section B to clarify this point.	Reply	O	0
In practice, the trained's are of rank-K, due to that the choice of relatively small K is a tight restriction of the model.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token]*Mode collapse[line_break_token][line_break_token]In all experiments on real-world datasets, our model does not develop mode collapse as shown by the good diversity score.	Reply	O	0
We are working to understand the precise relation between the fidelity-diversity trade-off.	Reply	B-Reply	3
Based on the experiments (see supplemental material Table A.2) so far, we think the constraint rank K serves as a parameter to regularize the generative model.	Reply	I-Reply	3
We will keep this as a direction of future efforts.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]The content of Section 4 is organized as following: we start with filter generation, which introduces stochasticity with considerable cost.	Reply	I-Reply	4
[line_break_token]Based on the low rank observation of generated filters, we further propose to decompose filters into bases with stochasticity and deterministic coefficients.	Reply	I-Reply	4
And the decomposition is further supported by Theorem 1, which shows that it suffices to generate bases in order to generate the desired distribution of filters.	Reply	I-Reply	4
[line_break_token]We then provide detail on the process of basis generation, and how we construct the proposed BasisGAN with basis generators.	Reply	I-Reply	5

This paper discusses VQ-VAE for learning discrete latent variables, and its application to NMT with a non-autoregressive decoder to reduce latency (obtained by producing a number of latent variables that is much smaller than the number of target words, and then producing all target words in parallel conditioned on the latent variables and the source text).	Review	O	0
The authors show the connection between the existing EMA technique for learning the discrete latent states and hard EM, and introduce a Monte-Carlo EM algorithm as a new learning technique.	Review	O	0
They show strong empirical results on EN-DE NMT with a latent Transformer (Kaiser et al. (	Review	O	0
2018)).	Review	O	0
[line_break_token][line_break_token]The paper is clearly written (excepting the overloaded appendix), and the individual parts of the paper are interesting, including the link between VQ-VAE training and hard EM, the Monte-Carlo EM, and strong empirical results.	Review	O	0
I'm less convinced that the paper as a whole delivers on what it promises/claims.	Review	O	0
[line_break_token][line_break_token]The first contribution of the paper is that it shows a simple VQ-VAE to work well on the EN-DE NMT task, in contrast to the results by Kaiser et al. (	Review	O	0
2018).	Review	O	0
The paper attributes this to tuning of the code-book, but the results (table 3) seem to contradict this, with a code-book size of 2^16 even slightly better than the 2^12 that is used subsequently.	Review	B-Review	1
The reason for the performance difference to Kaiser et al. (	Review	I-Review	2
2018) remains opaque.	Review	I-Review	2
While interesting, the empirical effectiveness of Monte-Carlo EM is a bit disappointing, achieving +0.3 BLEU over the best configuration for EN-DE (after extensive hyperparameter tuning, seen in table 4), and -0.1 BLEU on EN-FR.	Review	I-Review	2
Monte-Carlo EM also seems very sensitive to hyperparameters, namely the sample size (tables 4,5), contradicting the later claim that EM is robust to hyperparameters.	Review	I-Review	3
The last claimed contribution (using denoising techniques) is hidden in the appendix, an application of an existing technique, and not compared to knowledge distillation (another existing technique).	Review	I-Review	4
[line_break_token][line_break_token]I'd like to see some of the results in the paper published eventually.	Review	O	0
However, the claims need to better match the empirical evidence, and for a paper that has "better understanding" in the title, I'd like to gain a better understanding of the differences to Kaiser et al. (	Review	B-Review	5
2018) that make VQ-VAE fail for them, but not in the present case.	Review	I-Review	5
[line_break_token][line_break_token]+ clearly written paper[line_break_token]+ interesting, novel EM algorithm for VQ-VAE[line_break_token]+ strong empirical results on non-autoregressive NMT[line_break_token][line_break_token]- the strong performance of the VQ-VAE baseline remains unexplained, and the claimed explanation contradicts empirical results.	Review	O	0
[line_break_token]- the new EM algorithm gives relatively small improvements, with hyperparameters that were likely selected based on test set scores .	Review	O	0
[line_break_token]- most of the empirical gain is attributable to knowledge distillation, which is not a novel contribution	Review	O	0
This was an extra review requested after the end of the official review period; now looking at the other reviews and replies, I can see that the question as to whether hyperparameters were optimized on the test set was already addressed.	Reply	O	0
I stand by the comment that obtaining this small improvement required extensive hyperparameter tuning, which devalues it slightly	Reply	B-Reply	2

The authors propose to improve abstractive summarization models by using pretrained embeddings, theme modeling and denoising.	Review	O	0
[line_break_token][line_break_token]They propose a very interesting idea: to leverage the lead bias in news article to build supervized summarization task from 21.4 M of articles.	Review	O	0
Details are given how to produce this supervized data using simple heuristics.	Review	O	0
[line_break_token][line_break_token]The  model is  train with a denoising loss, by introducing 2 types of noise (tokens from other article and sequence shuffle).	Review	O	0
Theme modeling is also introduced as a classification problem  (same as BERT) :  the system must learn to classify pairs of sentences from the same article and pairs from different articles.	Review	O	0
[line_break_token][line_break_token]Experiments are conducted on 3 datasets.	Review	O	0
The proposed model outperforms the other unsupervized abstractive models and provides results closed to unsupervized extractive models, with a metrics which favors extractive models.	Review	O	0
Ablation study shows that pretraining yields most of the impact, whereas improvements due to theme modeling and denoising loss are marginal.	Review	O	0
[line_break_token][line_break_token]In the Article example : [line_break_token]"in the wold"  ?	Review	B-Review	1
[line_break_token][line_break_token]Conclusion : [line_break_token]- dataset-agnostic : I don't see why since the approach take advantage of the lead bias.	Review	O	0
[line_break_token]- "outperforms previous systems by significant margins" : excessive.	Review	O	0
[line_break_token]	Review	O	0
hanks for your comments.	Reply	O	0
Please find our responses below.	Reply	O	0
[line_break_token][line_break_token](1) We have corrected the typo.	Reply	O	0
[line_break_token](2) Sorry for the confusion.	Reply	O	0
We have removed the term ‚Äúdataset-agnostic‚Äù.	Reply	B-Reply	2
We were trying to point out that the pretraining technique generates one single model that achieves consistently good performance across all 3 test datasets.	Reply	I-Reply	2
[line_break_token](3) Thanks for pointing that out.	Reply	O	0
We have changed it to ‚ÄúTED outperforms previous unsupervised abstractive baselines‚Äù.	Reply	B-Reply	3
[line_break_token][line_break_token]Should you have any questions, we are very happy to answer them.	Reply	O	0

First, the bad:[line_break_token][line_break_token]This paper is frustratingly written.	Review	O	0
The grammar is fine, but:[line_break_token] - The first four pages are completely theoretical and difficult to follow without any concrete examples.	Review	O	0
These sections would benefit greatly from a common example woven through the different aspects of the theoretical discussion.	Review	B-Review	1
[line_break_token] - The ordering of the exposition is also frustrating.	Review	O	0
I found myself constantly having to refer ahead to figures and back to details that were important but seemingly presented out of order.	Review	B-Review	2
Perhaps a reordering of some details could fix this.	Review	I-Review	2
Recommendation: give the most naturally ordered oral presentation of the work and then order the paper similarly.	Review	I-Review	2
[line_break_token][line_break_token]Finally, the description of the experiments is cursory, and I found myself wondering whether the details omitted were important or not.	Review	I-Review	3
Including experimental details in a supplementary section could help assuage these fears.	Review	I-Review	3
[line_break_token][line_break_token]The good:[line_break_token][line_break_token]What the paper does well is to gather together past work on novelty generation and propose a unified framework in which to evaluate past and future models.	Review	O	0
This is done by repurposing existing generative model evaluation metrics for the task of evaluating novelty.	Review	O	0
The experiments are basic, but even the basic experiments go beyond previous work in this area (to this reviewer‚Äôs knowledge).	Review	O	0
[line_break_token][line_break_token]Overall I recommend the paper be accepted, but I strongly recommend rewriting some components to make it more digestible.	Review	O	0
As with other novelty papers, it would be read thoroughly by the interested few, but it is likely to fight an uphill battle against the majority of readers outside the sub-sub-field of novelty generation; for this reason the theory should be made even more intuitive and clear and the experiments and results even more accessible.	Review	O	0
[line_break_token]	Review	O	0
We are grateful to the reviewer:[line_break_token]‚ÄúPaper fights a difficult battle to defend and unify novelty generating models.	Reply	O	0
It fights somewhat well.	Reply	O	0
‚Äù[line_break_token]‚Äúthe basic experiments go beyond previous work in this area‚Äù[line_break_token][line_break_token]We think the following points is especially relevant, for this kind of paper:[line_break_token]As with other novelty papers, [...] it is likely to fight an uphill battle against the majority of readers outside the sub-sub-field of novelty generation; [line_break_token][line_break_token]We contend that this is true for many cross-domain, multidisciplinary work.	Reply	O	0
The chance to present the paper in the conference will surely improve future versions and reduce incomprehensions that typically arise in such efforts.	Reply	B-Reply	4
[line_break_token][line_break_token]‚Äúfor this reason the theory should be made even more intuitive and clear and the experiments and results even more accessible.	Reply	O	0
‚Äù[line_break_token][line_break_token]Other reviewers have stated that the paper is well-written and easy to understand for machine learning researchers.	Reply	O	0
Nevertheless, we took into account reviewer 3‚Äôs suggestion: We made some modifications in the paper that will clarify that the readers interested into the metrics and the experiments can jump to the relevant sections	Reply	B-Reply	5

The paper address the problem of detecting if an example is misclassified or out-of-distribution.	Review	O	0
This is an very important topic and the study provides a good baseline.	Review	O	0
Although it misses strong novel methods for the task, the study contributes to the community.	Review	O	0
Thank you	Reply	O	0

The paper proposes a new memory access scheme based on Lie group actions for NTMs.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]* Well written[line_break_token]* Novel addressing scheme as an extension to NTM.	Review	O	0
[line_break_token]* Seems to work slightly better than normal NTMs.	Review	O	0
[line_break_token]* Some interesting theory about the novel addressing scheme based on Lie groups.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]* In the results, the LANTM only seems to be slightly better than the normal NTM.	Review	O	0
[line_break_token]* The result tables are a bit confusing.	Review	O	0
[line_break_token]* No source code available.	Review	O	0
[line_break_token]* The difference to the properties of normal NTM doesn't become too clear.	Review	O	0
Esp it is said that LANTM are better than NTM because they are differentiable end-to-end and provide a robust relative indexing scheme but NTM are also differentiable end-to-end and also provide a robust indexing scheme.	Review	B-Review	4
[line_break_token]* It is said that the head is discrete in NTM but actually it is in space R^n, i.e. it is already continuous.	Review	O	0
It doesn't become clear what is meant here.	Review	B-Review	5
[line_break_token]* No tests on real-world tasks, only some toy tasks.	Review	O	0
[line_break_token]* No comparisons to some of the other NTM extensions such as D-NTM or Sparse Access Memory (SAM) (<a href="https://arxiv.org/abs/1610.09027)."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1610.09027).</a> Although the motivations of other NTM extensions might be different, such comparisons still would have been interesting.	Review	O	0
[line_break_token]	Review	O	0
Thanks for reviewing our paper.	Reply	O	0
[line_break_token][line_break_token]> In the results, the LANTM only seems to be slightly better than the normal NTM.	Reply	O	0
[line_break_token][line_break_token]We disagree with this interpretation of the results.	Reply	B-Reply	1
In most tasks the best LANTM gets almost 100% coarse on generalization, but the corresponding simplified NTM never gets more than 50% coarse on generalization.	Reply	I-Reply	1
[line_break_token][line_break_token]> The result tables are a bit confusing.	Reply	O	0
[line_break_token][line_break_token]Can you clarify this comment?	Reply	B-Reply	2
We closely followed past work in this area when presenting the results.	Reply	I-Reply	2
[line_break_token][line_break_token]> No source code available.	Reply	O	0
[line_break_token][line_break_token]We plan on open sourcing the code and will include a link in the next version.	Reply	B-Reply	3
[line_break_token][line_break_token]> The difference to the properties of normal NTM doesn't become too clear.	Reply	O	0
Esp it is said that LANTM are better than NTM because they are differentiable end-to-end and provide a robust relative indexing scheme but NTM are also differentiable end-to-end and also provide a robust indexing scheme.	Reply	O	0
[line_break_token][line_break_token]Let us reiterate the key motivation of the paper: the set of NTM‚Äôs head movement does *not* compose a group.	Reply	B-Reply	4
[line_break_token][line_break_token]In particular it is not true that every head movement has an inverse movement.	Reply	I-Reply	4
This is briefly explained in footnote 1.	Reply	I-Reply	4
In short, NTM‚Äôs head movement is a Markov kernel, which mixes the probabilities encoded in the NTM‚Äôs head.	Reply	I-Reply	4
Intuitively, a mixture cannot be ‚Äúunmixed‚Äù by mixing further; formally, it can be shown that a Markov kernel does not have an inverse that is a Markov kernel if it is not the delta kernel (all values concentrated at one point).	Reply	I-Reply	4
This problem manifests as the loss of concentration in NTM‚Äôs head after shifting repeatedly.	Reply	I-Reply	4
This was fixed in an ad hoc way in the NTM paper via ‚Äúsharpening coefficients‚Äù that boosts concentration, but they have to be learned.	Reply	I-Reply	4
[line_break_token][line_break_token]> It is said that the head is discrete in NTM but actually it is in space R^n, i.e. it is already continuous.	Reply	O	0
It doesn't become clear what is meant here.	Reply	O	0
[line_break_token][line_break_token]We agree that NTM is continuous.	Reply	B-Reply	5
Our point is that it does not form a group.	Reply	I-Reply	5
[line_break_token][line_break_token]> No tests on real-world tasks, only some toy tasks.	Reply	O	0
[line_break_token][line_break_token]We agree that the tasks used are mainly synthetic, but this is true on most work studying NTMs.	Reply	B-Reply	6
Our tasks capture essential aspects of algorithmic learning, like for loops (repeat copy), sorting (priority sort), and arithmetic.	Reply	I-Reply	6
They are nontrivial, as demonstrated by the gap between baseline performances and LANTM performances.	Reply	I-Reply	6
[line_break_token][line_break_token]> No comparisons to some of the other NTM extensions such as D-NTM or Sparse Access Memory (SAM) (<a href="https://arxiv.org/abs/1610.09027)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1610.09027).</a> Although the motivations of other NTM extensions might be different, such comparisons still would have been interesting.	Reply	O	0
[line_break_token][line_break_token]These are very interesting papers but they target aspects of the NTM that are orthogonal to the topology of addressing schemes.	Reply	B-Reply	7
 [line_break_token]For example, the contributions of the D-NTM paper were mainly Dynamic Least Recently Used (LRU) addressing, regularization methods, and hard addressing using REINFORCE.	Reply	I-Reply	7
In our paper under review here, we argue for a principled way to purpose different manifolds as memory storage and different Lie groups as relative head movement.	Reply	I-Reply	7
In contrast, D-NTM‚Äôs memory is still modeled after a traditional memory array and it does not have relative head movement.	Reply	I-Reply	7
A priori, there is no reason that ideas from both papers cannot be combined in a coherent way.	Reply	I-Reply	7

This paper proposed two novel gates to improve the convergence speed of the learned ISTA (LISTA) algorithm for sparse coding.	Review	O	0
The first gate is designed to address the problem that the output of the LISTA algorithm usually has a lower magnitude compared against the ground-truth.	Review	O	0
To address this, the paper proposed a gain gate to increase the magnitude of a layer in the LISTA algorithm.	Review	O	0
The second gate is designed to further improve the convergence with a technique similar to the momentum but with a time-varying coefficient.	Review	O	0
[line_break_token][line_break_token]This paper provides rigorous theoretical justifications for the observations that motivate the two gates in two propositions.	Review	O	0
It also provides theoretical guarantees for the first gain gate under practical assumptions.	Review	O	0
[line_break_token][line_break_token]Thorough synthetic experiments are conducted to empirically validate the proposals as well as the theorems.	Review	O	0
The effectiveness of the gates is also proved in a real-world computer vision task, photometric stereo.	Review	O	0
[line_break_token][line_break_token]Given the thoroughness of the theoretical and experimental justifications, I strongly recommend the acceptance of the paper.	Review	O	0
[line_break_token][line_break_token]Despite the strength of the paper, I have the following suggestions and questions regarding the two gates proposed by the paper:[line_break_token][line_break_token]1.	Review	O	0
The second proposed gate, the overshoot gate, lacks theoretical justification and is not as well studied as the gain gate.	Review	B-Review	1
The experiments for this gate are not included in the main text but got placed in the appendix.	Review	I-Review	1
I suggest squeezing some of them into the main text to show a complete picture about the overshoot gate.	Review	I-Review	1
If there are more theoretical results about the behavior of the overshoot gate, the author should include it in the paper; otherwise, the author should clearly states this limitation in the main text of the paper.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The author proposed two gates to address two different issues of the original LISTA algorithm.	Review	B-Review	2
However, the two gates are only applied seperately to modify the LISTA algorithm; they have not been integrated into a single concise algorithm.	Review	I-Review	2
It would strengthen the paper if the author could provide a further discussion on how the two gates can be combined to address the two issues in one algorithm.	Review	I-Review	2
[line_break_token]	Review	O	0
hanks for the positive feedback and constructive suggestions.	Reply	O	0
We have revised the paper accordingly.	Reply	O	0
Some overshoot gate related experimental results have been squeezed into Section 4.1 in the main body of the paper.	Reply	B-Reply	1
The effectiveness of a direct combination of the overshoot and gain gates has been highlighted.	Reply	I-Reply	1
Also, the progress and limitation of asymptotic behaviors with overshoots are explained carefully in Section 3.2	Reply	I-Reply	1

We thank all three reviewers for the helpful comments, which enabled us to improve the paper.	Review	O	0
 We have uploaded a revision to the arxiv taking into account the comments, and respond to some specific concerns below.	Review	O	0
[line_break_token][line_break_token]We were unsure as to whether we should make the paper longer by providing more in-line intuition around the steps of the proof of our main results.	Review	O	0
This would address the concerns of Reviewers 6c04 and 51ff, who thought some additional intuition throughout would be helpful, while Reviewer 51ff felt that the paper was perhaps too long as it was.	Review	O	0
 We elected to balance these concerns by making significant changes to improve clarity without greatly expanding the exposition, making a net addition of about a page of text.	Review	O	0
However, by moving some material to the appendix, the main portion of the paper has been reduced in length to 14 pages.	Review	O	0
[line_break_token][line_break_token]Responding to specific comments:[line_break_token][line_break_token]Reviewer 6c04:[line_break_token][line_break_token]> Things I did not understand: [line_break_token]>- Fig.	Review	O	0
1 (as a whole) [line_break_token][line_break_token]We have reworked this figure and improved the explanation in the caption; the intensity of the shading represents the value of log(k), that is the function.	Review	O	0
[line_break_token][line_break_token]>- Last paragraph of 1.1: why is this interesting?	Review	O	0
[line_break_token][line_break_token]Since we are arguing that the sets of probability distributions representable by RBMs and MoPs are quite different, we thought it would be interesting to mention what is known about when these two sets do intersect.	Review	O	0
 We have added a comment about this.	Review	O	0
[line_break_token][line_break_token]>- Fig.	Review	O	0
5 (not clear why it is in some kind of pseudo-3D and what is the meaning of all these lines -- also some explanations come after it is referenced, which does not help) [line_break_token][line_break_token]We have reworked the figure and added additional explanation in the text where the figure is referenced.	Review	O	0
This is a picture of the interior of a 3-dimensional simplex (a tetrahedron with vertices corresponding to the outcomes (0,0), (0,1), (1,0), (1,1)), with three sets of probability distributions depicted.	Review	O	0
The curved set is a 2-dimensional surface.	Review	O	0
The regions at the top and bottom are polyhedra, and the lines in the original figure were the edges of these polyhedra (the edges in back have now been removed to make the rendering clearer).	Review	O	0
Additionally, we linked to an interactive 3-d graphic object of Fig.	Review	O	0
5.	Review	O	0
 Using Adobe Acrobat Reader 7 (or higher) the reader can rotate and slice this object in 3-d.	Review	O	0
[line_break_token][line_break_token]>- '(...) and therefore it contains distributions with (...)': I may be missing something obvious, but I did not follow the logical link ('therefore') [line_break_token][line_break_token]We expanded and rephrased this to hopefully be more clear.	Review	O	0
[line_break_token][line_break_token]>- I am unable to parse Remark 22, not sure if there is a typo (double 'iff') or I am just not getting it.	Review	O	0
 [line_break_token][line_break_token]We rewrote this remark, sorry for the confusion.	Review	O	0
 The meaning was that the three statements (X iff Y iff Z) are equivalent.	Review	O	0
[line_break_token][line_break_token]>Typos or minor points: [line_break_token]> - It seems like Fig.	Review	O	0
3 and 4 should be swapped to match the order in which they appear in the text [line_break_token]>- 'Figure 3 shows an example of the partitions (...) defined by the models M_2,4 and RBM_2,3' -> mention also 'for some specific parameter values' to be really clear [line_break_token]>- Deptartment (x2) [line_break_token]>- Lebsegue [line_break_token]>- I believe the notation H_n is not explicitly defined (although it can be inferred from the definition of G_n) [line_break_token]>- There is a missing reference with a '?'	Review	O	0
on p. 9 after 'm <= 9' [line_break_token]>- It seems to me that section 6 is also related to the title of section 5.	Review	O	0
Should it be a subsection?	Review	O	0
[line_break_token]>- 'The product of mixtures represented by RBMs are (...)': products [line_break_token]>- 'Mixture model (...) generate': models[line_break_token][line_break_token]Thank you, we fixed these.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]Reviewer 51ff:[line_break_token][line_break_token]>In conclusion, this paper tackles a problem which seems to be too contrived to be of general interest.	Review	O	0
Further, it is written in an unfriendly way which makes it more appropriate to a very technical crowd.	Review	O	0
[line_break_token]>- the fact that there are exponentially many inference regions for an RBM whereas there are only a linear number of them for a MoP seems quite obvious, merely by counting the number of hidden states configurations.	Review	O	0
I understand this is far from a proof but this is to me more representative of the fact that one does not want to use the hidden states as a new representation for a MoP, which we already knew.	Review	O	0
[line_break_token][line_break_token]In part this is simply a difference of philosophy.	Review	O	0
 Some place greater emphasis on an intuition or demonstration on a dataset, while others prefer to see a proof.	Review	O	0
 We recognize we may not have a lot to offer those comfortable relying upon their intuitive or empirical grasp of the situation, and instead aim to provide some mathematical proof to back up that intuition and satisfy the second group.	Review	O	0
[line_break_token][line_break_token]In trying to show that one class of models (RBMs or distributed representations) is better than another (here, non-distributed representations or naive Bayes models) at representing complex distributions, one must make a choice of criteria for comparison.	Review	O	0
 One can pick, inevitably arbitrarily, a dataset for comparison and produce an empirical comparison.	Review	O	0
 To provide a proof or theoretical comparison, one must choose a metric of complexity.	Review	O	0
 Of course, we always want larger and more natural datasets and broader metrics, but one must start somewhere.	Review	O	0
 We felt that in measuring the complexity of a distribution, the bumpiness of a probability distribution, or number of local maxima, modes, or strong modes in the Hamming topology was a reasonable place to start.	Review	O	0
 While we examined other metrics of distribution complexity, this was one that provided enough leverage to distinguish the models.	Review	O	0
 In the Discussion section, we talk about why multi-information, for example, is not suitable for making this distinction.	Review	O	0
 Making such a choice of metric is the unfortunate price of theoretical justifications.	Review	O	0
[line_break_token][line_break_token]Additionally, the number of inference regions was not claimed to be new, but part of the exposition about the widespread intuition regarding distributed representations.	Review	O	0
 We have added some exposition to clarify this.	Review	O	0
[line_break_token][line_break_token]Why we chose MoP: we wanted to compare distributed representations with non-distributed representations.	Review	O	0
 Since we are interested in learning representations, these should be two models with hidden variables that hold the representation.	Review	O	0
 For a non-distributed model with hidden variables and the same observables as an RBM, the na'ive Bayes or MoP model is canonical.	Review	O	0
 For example, a k-way interaction model might also be a good comparison, but it lacks hidden nodes.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]>Additionnally, the paper is very heavy on definitions and gives very little intuition about the meaning of the results.	Review	O	0
Theorem 29 is a prime example as it takes a very long time to parse the result and I could really have used some intuition about the meaning of the result.	Review	O	0
This feeling is reinforced by the length of the paper (18 when the guidelines mentioned 9) and the inclusion of propositions which seem anecdotal (Prop.7, section 2.1, Corollary 18).	Review	O	0
[line_break_token][line_break_token]Sorry for the confusion.	Review	O	0
 The introduction, as well as Figure 1 is devoted to explaining and interpreting Theorem 29.	Review	O	0
The statements therein such as 'We find that the number of parameters of the smallest MoP model containing an RBM model grows exponentially in the number of parameters of the RBM for any fixed ratio, see Figure 1' are hopefully more-intuitive corollaries of Theorem 29.	Review	O	0
 The structure of the paper is to try to put the intuitive explanation of the results first, then give the (necessarily technical) proof showing how the results were obtained.	Review	O	0
 We have added a pointer before Theorem 29 to indicate this.	Review	O	0
[line_break_token][line_break_token]In the revision we added explanations providing additional intuition as to why we are making certain definitions, and a road map of how the main results are proved.	Review	O	0
[line_break_token][line_break_token]>Minor comments: [line_break_token]> - Definition 2, you have that C is included in {0, 1}^n.	Review	O	0
That makes C a vector, not a set.	Review	O	0
[line_break_token][line_break_token]No, a subset as we write of the set of (binary) strings of length n is again a set of (binary) strings.	Review	O	0
 One could of course interpret it in terms of a vector of indicator functions, but this is not the approach needed here.	Review	O	0
[line_break_token][line_break_token]> - Proposition 8: I think that G_3 should be G_4.	Review	O	0
[line_break_token][line_break_token]Sorry for the confusion.	Review	O	0
 Again this is correct as is; G_4 would refer to binary strings of length 4, while the Proposition concerns strings of length 3.	Review	O	0
Thanks for the updated version, I've re-read it quickly and it's indeed a bit clearer	Reply	O	0

This paper suggests a new technique to analyze the implicit regularization caused by ReLU activations.	Review	O	0
They bound the generalization error by two terms: 1) one term that represents the distance between the trained network output and a piecewise linear function built based on the set of training points and 2) another term that represents the distance between the piecewise linear approximation and the desired target.	Review	O	0
The first term is bounded using a random walk type of analysis, which to the best of my knowledge is novel.	Review	O	0
[line_break_token]I find this technique rather interesting and technically sound, although I do have a number of concerns and I'm at the moment more on the reject side, although I will re-consider my score if the authors can provide satisfactory answers.	Review	O	0
[line_break_token][line_break_token]Generalization to more complex activation functions[line_break_token]If I understand correctly, the interpolation technique between two points only works for ReLU functions.	Review	O	0
If one were to try to generalize the analysis to more complex non-linear functions by using a more complex interpolation schemes, wouldn‚Äôt you then have a random walk in high-dimensions?	Review	B-Review	1
If so, wouldn‚Äôt that be a problem given the different properties of Brownian motion in high-dimensions?	Review	I-Review	1
[line_break_token][line_break_token]Generalization to smooth activation functions[line_break_token]Another question related to the previous one is whether one could hope to generalize the analysis to smooth activation functions.	Review	O	0
I believe this is also a drawback of combinatorial techniques such as Hanin and Rolnick which have to rely on the discrete nature of the breakpoints.	Review	B-Review	2
[line_break_token][line_break_token]Generalization bound is only derived for 1-d functions[line_break_token]Theorem 2 is derived for each dimension independently while the generalization results in Theorem 4 are for 1-dimensional inputs.	Review	O	0
Where is the difficulty in generalizing these results to higher dimensions?	Review	B-Review	3
[line_break_token][line_break_token]Prior work on generalization of SGD[line_break_token]I was really expecting a discussion about how the generalization bound derived in this paper compares to prior work, e.g.[line_break_token]Hardt, Moritz, Benjamin Recht, and Yoram Singer. "	Review	O	0
Train faster, generalize better: Stability of stochastic gradient descent."	Review	B-Review	4
arXiv preprint arXiv:1509.01240 (2015).	Review	I-Review	4
[line_break_token]Kuzborskij, Ilja, and Christoph H. Lampert. "	Review	I-Review	4
Data-dependent stability of stochastic gradient descent."	Review	I-Review	4
arXiv preprint arXiv:1703.01678 (2017).	Review	I-Review	4
[line_break_token]Brutzkus, Alon, et al. "	Review	I-Review	4
Sgd learns over-parameterized networks that provably generalize on linearly separable data."	Review	I-Review	4
arXiv preprint arXiv:1710.10174 (2017).	Review	I-Review	4
[line_break_token]And many others‚Ä¶[line_break_token]For instance the bound derived in Hardt et al.	Review	I-Review	4
is also of the order O(n^-2).	Review	I-Review	4
The bounds in Kuzborskij are also data-dependent and so are yours since your generalization bound depends on the density of the training points.	Review	I-Review	4
Can you comment on this?	Review	I-Review	4
What specific insights do we gain your analysis?	Review	I-Review	4
[line_break_token][line_break_token]Noise SGD[line_break_token]My understanding is that the authors assume that the noise of SGD is Gaussian.	Review	O	0
Although this is commonly used when analyzing SGD, there is evidence that the noise is actually not Gaussian, see e.g.[line_break_token]Daneshmand, Hadi, et al. "	Review	B-Review	5
Escaping saddles with stochastic gradients."	Review	I-Review	5
arXiv preprint arXiv:1803.05999 (2018).	Review	I-Review	5
[line_break_token]Simsekli, Umut, Levent Sagun, and Mert Gurbuzbalaban. "	Review	I-Review	5
A tail-index analysis of stochastic gradient noise in deep neural networks."	Review	I-Review	5
arXiv preprint arXiv:1901.06053 (2019).	Review	I-Review	5
[line_break_token]I feel this is worth pointing out and one could perhaps also extend this analysis to Heavy-tail noise.	Review	I-Review	5
I would expect that the results would still hold in expectation but perhaps with a slightly worse probability.	Review	I-Review	5
[line_break_token][line_break_token]Influence step size SGD[line_break_token]Using larger step sizes in the SGD updates increase the influence of the noise.	Review	O	0
I was expecting this to somehow be captured in your analysis but I fail to see where it appears.	Review	B-Review	6
Can you comment on this?	Review	I-Review	4
[line_break_token][line_break_token]Proof Lemma 3[line_break_token]The derivation of Eq.	Review	O	0
10 does not seem completely justified in the proof in the appendix.	Review	B-Review	7
The authors essentially prove that the length of the gradient gap is bounded by |S| but why is the coefficient \omega distributed according to a normal distribution.	Review	I-Review	7
It seems to me that you need the noise of SGD to be Gaussian for such statement to hold.	Review	I-Review	7
Can you confirm this?	Review	I-Review	7
If so, I think this needs to be clearly stated as an assumption since -- as pointed out above -- this is not necessarily true in practice.	Review	I-Review	7
[line_break_token][line_break_token]Minor: proof Theorem 2[line_break_token]It seems rather trivial but for completeness, you should write the proof of Eq. (	Review	O	0
6) in Theorem 2.	Review	B-Review	8
[line_break_token][line_break_token]‚ÄúA priori estimates‚Äù[line_break_token]This is a terminology that is often used in the paper but never defined.	Review	O	0
What do you mean by ‚Äúa priori‚Äù in this context?	Review	B-Review	9
[line_break_token][line_break_token]Minor comment[line_break_token]I would move footnote 3 directly in the main step.	Review	O	0
I think it is important to point out that the steps of the random walk correspond to the breakpoints.	Review	B-Review	10
[line_break_token]	Review	O	0
e appreciate your detailed reading of the paper and thoughtful comments.	Reply	O	0
We have responded to these below.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt;&gt; Proof Lemma 3[line_break_token][line_break_token]Let us explain that the coefficient is close to the initial value of the corresponding weight and is not a noise of SGD.	Reply	O	0
[line_break_token][line_break_token]The following is the discussion about-th layer, and we drop the subscript for notational convenience.	Reply	B-Reply	7
[line_break_token] is expressed as Eq. (	Reply	I-Reply	7
44) in p.12.	Reply	I-Reply	7
[line_break_token][line_break_token]We use to denote a weight matrix for-th layer after iterations of SGD.	Reply	I-Reply	7
In Eq. (	Reply	I-Reply	7
46), we define the difference between and initial value as follows:[line_break_token][line_break_token]This is the weight change by SGD, and Theorem 1 guarantees that is small enough.	Reply	I-Reply	7
That is,, where is enough small related to the network width.	Reply	I-Reply	7
[line_break_token][line_break_token]For notational convenience, let be.	Reply	I-Reply	7
We obtain the following upper bounds from Eq. (	Reply	I-Reply	7
58) and Eq. (	Reply	I-Reply	7
56).	Reply	I-Reply	7
[line_break_token][line_break_token]From the above, Eq. (	Reply	I-Reply	7
44) can be expressed as follows:[line_break_token][line_break_token]Each weight value is initialized by He Normal, so.	Reply	I-Reply	7
Thus, because is Gaussian random value and is small enough, the sum of is `Gaussian random walk'.	Reply	I-Reply	7
[line_break_token][line_break_token]From the above discussion, you can see that the coefficient is not a noise of SGD but the initial value of a weight.	Reply	I-Reply	7
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; proof Theorem 2[line_break_token][line_break_token]Thank you for your advice.	Reply	O	0
The output dimension of the last layer is while that of other layers is, so we prove Eq. (	Reply	B-Reply	8
6) by changing inequality in the proof of Eq. (	Reply	I-Reply	8
5).	Reply	I-Reply	8
We already changed the paper, so please confirm.	Reply	I-Reply	8
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; ‚ÄúA priori estimates‚Äù[line_break_token][line_break_token]Thank you for your advice.	Reply	O	0
We have modified our paper to clarify what we wanted to convey by using the terminology "a priori estimates".	Reply	B-Reply	9
[line_break_token][line_break_token]An a priori estimate is used in the theory of partial differential equations, but already used in machine theory for example:[line_break_token]Weinan E et al., "	Reply	I-Reply	9
A Priori Estimates for Two-layer Neural Networks", (arXiv:1810.06397).	Reply	I-Reply	9
[line_break_token][line_break_token]A priori is Latin for "from before" and refers to the fact that the estimate for the solution of minimizing an objective function is derived before the solution is known to exist.	Reply	I-Reply	9
[line_break_token][line_break_token]In other words, we show that in Theorem 2, the difference between the network output function and its linear interpolation is evaluated only from the amount of the weight change.	Reply	I-Reply	9
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt;  footnote 3[line_break_token][line_break_token]Thank you for your advice.	Reply	O	0
We moved footnote 3 in the main step.	Reply	B-Reply	10
Please confirm.	Reply	I-Reply	10

This paper proposes the use of an MLP that predicts both mean and std for predicting the time of a surgical operation.	Review	O	0
[line_break_token]They extend the method also to Laplace distribution.	Review	O	0
[line_break_token]The method is simple, not novel, but the combination of the method and the application is novel.	Review	O	0
[line_break_token]What worries me is the marginal improvements reported in table 1.	Review	B-Review	1
Most of the improvement comes from the use of an MLP, more than the prediction of the variance - see the difference between Gaussian and Gaussian HS, and Laplace and Laplace HS.	Review	O	0
[line_break_token]My conclusion is that the choice of the distribution/loss in conjunction with the use of an MLP is more important than anything else, and in particular, it is more important than predicting variance (which is the main point of the abstract).	Review	B-Review	2
[line_break_token]	Review	O	0
Dear reviewer, [line_break_token][line_break_token]Thanks for taking the time to review our paper.	Reply	O	0
The purpose of estimating the conditional variance is precisely to get *good estimates of the variance*.  [line_break_token][line_break_token]The superiority (in this respect) of the predictions of the heteroscedastic models is born out by figures 1 and 2 which show just how strongly the predicted standard deviations correlate with observed errors.	Reply	O	0
[line_break_token][line_break_token]We realize that some amount of the confusion owes to a bug in our initial reporting.	Reply	B-Reply	1
The initial table 1 had a scaling bug in calculating NLL numbers.	Reply	I-Reply	1
This reporting bug came to light when we were adding late-breaking results on a gamma predictive distribution.	Reply	I-Reply	1
 Thus the original table 1 didn't make it clear just how much the heteroscedastic models improve over their homoscedastic counterparts.	Reply	I-Reply	1
[line_break_token][line_break_token]We've updated the draft with the fixed numbers and it's obvious that the heteroscedastic modeling fits the observed errors dramatically better.	Reply	I-Reply	1
[line_break_token][line_break_token]We also added a line to the results table 1 showing results using a gamma predictive distribution, which slightly outperforms even the best heteroscedastic laplacian regression model.	Reply	I-Reply	2
We hope you'll take the chance to re-assess the review.	Reply	I-Reply	2

EDIT: Updated score to weak Accept in lieu of author's response.	Review	O	0
 See below for more details.	Review	O	0
[line_break_token][line_break_token]The authors propose a GAN architecture that aims to align the latent representations of the GAN with different interpretable degrees of freedom of the underlying data (e.g., size, pose).	Review	O	0
 While the text, motivation, and experiments are fairly clear, there are some spelling/grammar mistakes throughout, and the draft could use a solid pass for overall clarity.	Review	O	0
[line_break_token][line_break_token]While the idea of using the log trace covariance as a regularizer for the manifold is certainly interesting, it seems fairly incremental upon previous work (i.e., DMWGAN).	Review	B-Review	2
 Even modulo the work being incremental, I still have concerns regarding the comparison to baselines/overall impact, and thus I suggest a Weak Rejection.	Review	I-Review	2
[line_break_token][line_break_token]Table 1 seems to indicate that the author's proposed method is on par with or worse than every method compared against except for 3D chair (bright).	Review	I-Review	3
 Additionally, the lack of comparison against DMWGAN for every task (except the first) is a bit concerning, considering its similarity to the proposed method.	Review	I-Review	3
 If the authors could check DMWGAN's performance for all of their tasks and report it, I would be more likely to raise my score.	Review	I-Review	3
hank you for your valuable comments.	Reply	O	0
[line_break_token][line_break_token]We believe your concerns arose mainly from the quantitative results in Table 1.	Reply	B-Reply	2
We would like to resolve the concerns by analyzing Table 1 in detail, but before that, we invite you to see the qualitative results from Figure H.6 in Appendix H for the better discussion.	Reply	I-Reply	2
[line_break_token][line_break_token]By comparing (a) and (c) of Figure J.8, we can clearly see the superior performance of MLA-GAN over DMWGAN (Note the samples are arranged in the same manner as Figure 3.).	Reply	I-Reply	2
Column-wise, we see the samples share the same smooth features (e.g., stroke, slant) in MLA-GAN, but this is not the case at all in DMWGAN.	Reply	I-Reply	2
Row-wise, we see the generators of MLA-GAN present distinct digit manifolds with a clean separation, whereas the generators of DMWGAN present manifolds involving a few crossovers between the digits; this is likely because the generators of MLA-GAN are enforced to share the smooth features, driving more regular manifold structures in all the generators.	Reply	I-Reply	2
[line_break_token][line_break_token]From these clear differences and benefits, we disagree that MLA-GAN is incremental to DMWGAN.	Reply	I-Reply	2
Most of all, our principal objective was not only the multi-manifold learning but also the manifold alignment, but DMWGAN cannot perform the manifold alignment, as illustrated in Figure 1 and discussed in Section 3.	Reply	I-Reply	2
Also, we would like to emphasize that the generalizability of MLA-GAN to an untrained manifold, demonstrated in the style-transfer experiments, is another very distinct property of MLA-GAN over other models.	Reply	I-Reply	2
[line_break_token][line_break_token]That being said, we agree that Table 1 is lacking information about DMWGAN.	Reply	I-Reply	2
We are currently running the experiments, and we assure you that all the unfilled scores will be reported in a couple of days (The reason that we did not report the disentanglement scores at first was that the DMWGAN has almost nothing to do with the manifold alignment).	Reply	I-Reply	2
[line_break_token][line_break_token]Your last concern about Table 1 was that the disentanglement scores of our model are inferior to that of-VAE.	Reply	I-Reply	3
But as we have pointed out in Section 4.2, the manifold learning performance (FID) of-VAE is far worse than our model (see also, Figure J.8 (e) and Figure J.9 (b)).	Reply	I-Reply	3
We emphasize that the FID and the disentanglement scores should be simultaneously considered to evaluate the MLA task, and MLA-GAN is showing the best performance in that regard.	Reply	I-Reply	3
[line_break_token][line_break_token]Typos and grammatical errors: We have fixed the most, if not all.	Reply	I-Reply	1
We will review the text more thoroughly and revise it before submitting the final version.	Reply	I-Reply	1
[line_break_token][line_break_token]== Minor Edit ==[line_break_token]We updated some of the appendix-figure indices in this comment, since they are changed as we add more figures in the revised manuscript.	Reply	O	0

The paper proposes an auxiliary module for GNNs to boost the representation power.	Review	O	0
The new module consists of virtual supernode, attention unit, and gating unit, each of which is demonstrated useful in the experiments.	Review	O	0
The module can be applied to various types of GNNs.	Review	O	0
[line_break_token][line_break_token]This work can be seen as an improvement to previous virtual supernode based methods.	Review	O	0
Adding the attention units and gating units is rational, and the effectiveness is also proved in the ablation studies.	Review	O	0
However, the claimed contribution of improving the representation power may mainly come from the idea of supernodes (instead of the attention and gating).	Review	B-Review	1
This largely reduces the novelty of this paper and make it incremental, because using virtual supernodes is not this paper‚Äôs original idea.	Review	I-Review	1
[line_break_token][line_break_token]The paper is generally well written.	Review	O	0
However, the comparison with previous supernode based models is not described clearly enough.	Review	B-Review	2
The authors listed the difference from (Glimer et al.	Review	I-Review	2
2017) and (Li et al.	Review	I-Review	2
2017) in Table 1, but ignored (Pham et al.	Review	I-Review	2
2017) and (Battaglia et al.	Review	I-Review	2
2018), which were also cited in the related work.	Review	I-Review	2
Moreover, (Li et al.	Review	I-Review	2
2017)‚Äôs method is actually different from the simple supernode baseline, in that it is not a bidirectional message passing between supernode and the main network.	Review	I-Review	2
Table 1 does not contain this property.	Review	I-Review	2
[line_break_token]	Review	O	0
hank you very much for the comments!	Reply	O	0
[line_break_token]While we believe that supernode is an essential component of our invention, we also believe that supernode alone is not sufficient.	Reply	B-Reply	2
[line_break_token]For this claim,  please notice that our method performs much better than the ablation model with no attention/gate mechanism (simple supernode), which is, in essence, the same as an architecture proposed by (Pham et al  2017).	Reply	I-Reply	2
 [line_break_token]In order to make this point more clear, we added explanations and discussions about the relationship of (Pham et al.	Reply	I-Reply	2
2017) and our ablated model (simple supernode) in the updated manuscript (Table1, Sec.	Reply	I-Reply	2
4.4, and the appendix C.6. )	Reply	I-Reply	2
[line_break_token][line_break_token]Also, as far as we understand,  (Battaglia et al 2018) is a survey paper, and that they do not make a proposal for a new algorithm in their work.	Reply	I-Reply	2
[line_break_token]Finally, thank you very much for pointing out our imprecise description of (Li et al 2017).	Reply	I-Reply	2
[line_break_token]We fixed the relevant phrases in Table 1 and Sec 4.4	Reply	I-Reply	2

The authors present a novel architecture of  an implicit unsupervised learning architectures using[line_break_token]a teacher student approach.	Review	O	0
 In particular the main advantage to me seems to be the mode-collapse property,  an important drawback in standard[line_break_token]GAN approaches.	Review	O	0
[line_break_token][line_break_token]The paper is written very well and is easy to follow.	Review	O	0
The methodology is presented in a clear way and the experiments make sense given the research question.	Review	O	0
 I particular like that the authors define clear metrics to evaluate success, which is often the weak point in unsupervised learning problems.	Review	O	0
[line_break_token][line_break_token]I believe the work is interesting, but the results still preliminary and  possibly limited by  scalability.	Review	B-Review	1
 As the authors put it [line_break_token][line_break_token]"The main bottleneck of LBT is how to efficiently solve the bi-level optimization problem.	Review	I-Review	1
On one[line_break_token]hand, each update of LBT could be slower than that of the existing methods because the computational[line_break_token]cost of the unrolling technique grows linearly with respect to the unrolling steps."	Review	I-Review	1
[line_break_token][line_break_token]On the other hand, I appreciate the honesty in discussing possible scalability constraints.	Review	O	0
[line_break_token][line_break_token]I was a bit surprised that the method the authors propose seems to work well in the  "Intra-mode KL divergence".	Review	B-Review	2
 My expectation was  that the main advantage of your method is capturing the global, holistic shape of the distribution[line_break_token]of the data, whereas classical methods would, because of mode collapse, only capture specific  sub-spaces.	Review	I-Review	2
 Therefore, i would expect these classical methods to perform better in intra-mode KL divergence,  which is a metric to measure local[line_break_token], not global, approximation quality.	Review	I-Review	2
[line_break_token][line_break_token]Typos: [line_break_token]-  In practise (Introduction) -> in practice[line_break_token]- 3.1 accent -> ascend[line_break_token]- Conclusion: on one hand / other hand is used for two opposite ways of thinking	Review	O	0
Thank you for your comments.	Reply	O	0
We have addressed these typos in our revised paper.	Reply	B-Reply	3
Besides, we provide further analysis about the advantages of LBT and LBT-GAN over GAN in terms of resisting mode collapse.	Reply	I-Reply	2
Please refer to our posts about two common concerns and the revised paper	Reply	O	0

CONTRIBUTIONS:[line_break_token]C1.	Review	O	0
Simplicialization of attention.	Review	O	0
Interpreting standard attention weights of a head as the model‚Äôs estimate of the probability of an edge = 1-simplex linking the variables encoded by 2 blocks of the Transformer, representing that the blocks stand in a binary relation encoded in the head, a generalization to 2-simplexes is made: now attention also estimates the probability of a 2-simplex indicating that three blocks stand in an arity-3 relation.	Review	O	0
[line_break_token]C2.	Review	O	0
2-simplicial attention.	Review	O	0
The standard query-key matching function, the scalar (dot) product, is related to the area of the 2-simplex determined by the 2 vectors and the origin, and this is generalized to the (unsigned) scalar triple product &lt;a,b,c&gt;, analogously related to the volume of the 3-simplex determined by 3 vectors and the origin.	Review	O	0
This now serves as the matching function between a query and 2 keys.	Review	O	0
Each head in each block generates a value vector u and two key vectors k1, k2 and the weight of attention from block(i) (with query p(i)) to the ordered pair (block(j), block(k)), a(i,j,k), is a softmax over &lt;p(i), k1(j), k2(k)&gt;. Attention returns to block(i) a sum in which a(I,j,k) weights B(u(j)*u(k)), with B a learned linear map and * the tensor product.	Review	O	0
[line_break_token]C3.	Review	O	0
Experimental results applying Transformers T1 (with standard 1-simplicial attention) and T2 (with new 2-simplicial attention) to modeling an agent in bridge BoxWorld, trained with deep RL.	Review	O	0
This game crucially involves 3-way entity interactions, as keys of 2 colors open a box yielding a key of a 3rd color.	Review	O	0
T2 learns significantly faster than T1 (in the sense that the 1-standard-deviation-neighborhood of the learning curve of T2 becomes better than that of T1, plotted against environmental steps: Fig.4, and also essentially so when plotted against time adjusted steps: Fig 5).	Review	O	0
[line_break_token]RATING: Accept[line_break_token]REASONS FOR RATING (SUMMARY).	Review	O	0
Generalizing attention from 2nd- to 3rd-order relations is an important upgrade, and the mathematical context in which this is derived is insightful and may lead to further progress in the development of Transformers capable of constructing still richer structures.	Review	O	0
The experiments yield clear evidence of the value of 3rd-order attention in the context of a game designed to highlight 3rd-order relations.	Review	O	0
[line_break_token]Strengths[line_break_token]The exposition is clear and situated in a rather sophisticated formal setting.	Review	O	0
The connection to Clifford algebras may yield further fruit, besides the scalar triple product that is crucial to the definition of 2-simplicial attention.	Review	O	0
Although I am not an expert in RL, the experiments reported seem sound and the results clear.	Review	O	0
I believe that the strength of the paper justifies its length of 8.5 pages: the exposition of the key ideas, for this reader, hits a sweet spot between overly concise and overly verbose, and the ideas call for the quantity of space devoted to them.	Review	O	0
The decisions of what material to place in the Appendix seem well made.	Review	O	0
Although I have not studied the entire (13-page) Appendix, what I have read is clear and enlightening, another major contribution of the paper.	Review	O	0
[line_break_token]Weaknesses[line_break_token]Future work testing the value of 3rd-order attention in tasks that are less clearly perfectly designed for it will substantially strengthen the case for it.	Review	O	0
But in my view it is right to start testing a new architecture by showing it can indeed do what it is designed to do; further tests showing that what it is designed to do is of general utility are a second step.	Review	B-Review	1
In this case, the first step, including creating of the model itself (consuming 5 non-verbose pages), is substantial enough to warrant publication.	Review	I-Review	1
[line_break_token]In my good-quality printout of the paper, I can‚Äôt see curves for best runs in Fig.	Review	I-Review	2
4.	Review	I-Review	2
[line_break_token]	Review	O	0
hank you for taking the time to review the paper.	Reply	O	0
In order to address other reviewers comments we have uploaded a revision which includes a new Section 6 to the main body explaining how to interpret 2-simplices in bridge BoxWorld.	Reply	B-Reply	3
The resolution of Fig.	Reply	I-Reply	2
4 (now Figure 5) has also been increased.	Reply	I-Reply	2
[line_break_token][line_break_token]As you noted, our paper is a proof of concept and future work should tackle a range of other tasks.	Reply	I-Reply	1
The new Section should help readers decide if the extra 2-simplicial information will bring benefits to their particular learning application.	Reply	I-Reply	1
[line_break_token]	Reply	O	0

This is an interesting paper with a new approach to learn a sparse, positive (and hence interpretable) semantic space that maximizes human similarity judgements, by training to specifically maximize the prediction of human similarity judgements.	Review	O	0
The authors have collected the dataset themselves and have rating of sets of 3 objects from 1854 unique objects.	Review	O	0
They end up with a space (SPoSE) with relatively low dimensionality with respect to usual word embeddings (49 dimension) but perhaps not surprising when considering the small size of the words to embed.	Review	O	0
The authors run a set of experiment to show the usefulness of SPoSE.	Review	O	0
The most interesting one is the prediction of its dimensions by the CSLB features, which reveals a nice clustering in the different SPoSE dimensions.	Review	O	0
Perhaps the results would be a little more convincing if additional common word embeddings were also tested.	Review	B-Review	1
[line_break_token][line_break_token]Due to the different objects used in the different datasets, some of the experiments have a smaller set of words.	Review	I-Review	2
A good extension of this work would be to combine a text-derived embedding  or the synsets to interpolate the SPoSE dimensions for missing words in the original set.	Review	I-Review	2
Or perhaps the object similarity ratings could be used in a semi-supervised setting to inform the learning of a co-occurence word embedding.	Review	I-Review	2
This will allow the model to better describe a larger set of words.	Review	I-Review	2
Another possible extension is to test this larger set of words on a non-behavioral NLP task to show possible improvements that the behavioral data and the interpretable space give.	Review	I-Review	2
[line_break_token][line_break_token]	Review	O	0
We thank the reviewer for their positive evaluation of our study.	Reply	O	0
We agree that the prediction from CSLB features is particularly interesting, and we are currently working on improving this further by interpolating to other objects in a semi-supervised manner (similar to what was proposed by the reviewer).	Reply	B-Reply	1
We also strongly agree that testing additional embeddings would be very interesting!	Reply	I-Reply	1
For the present work, we focused on synset embeddings because they represent a closer match to the meaning of each individual object than word embeddings would and provide a one-to-one match for the meanings.	Reply	I-Reply	1
For example, our list contains four different meanings for the object named by the word ‚Äúbaton‚Äù, referring to (1) an item in relay races, (2) in twirling, (3) a weapon used by police, and (4) an item used by a musical conductor.	Reply	I-Reply	1
Due to the novelty of this line of research, to our knowledge there are no other synset embeddings available than the ones we used, and we included both a 50d dense and a 300d dense version.	Reply	I-Reply	1
In addition, we would have liked to include sparse positive synset embeddings as a reference, however those are currently not available; for that reason, we included NNSE word embeddings instead.	Reply	I-Reply	1
In the future, we would like to add sparse positive synset embeddings and test their interpretability relative to our similarity embedding.	Reply	I-Reply	1
We hope this will underline the unique contribution of a behavior-based similarity embedding presented here.	Reply	I-Reply	1
[line_break_token][line_break_token]In addition, we would like to thank the reviewer for their idea on how to extend the embedding.	Reply	I-Reply	2
Indeed, we are currently working on predicting similarities for other concepts and images from pretrained synset vectors and activations in deep convolutional neural networks.	Reply	I-Reply	2
However, this effort is still in its early stages and beyond the scope of the present work	Reply	I-Reply	2

This work apply the wait-k decoding policy on the 2D CNN-based architecture and transformer.	Review	O	0
 In the transformer-based model the author proposed to recalculate the decoder hidden states when a new source token arrives.	Review	O	0
The author also suggested to train with multiple k at the decoder level with shared encoder output.	Review	O	0
The experiments showed that the transformer model provide the best quality on IWSLT14 En-De, De-En, and WMT15 De-EN.	Review	O	0
[line_break_token][line_break_token]The masking and using causal attention for the transformer has been proposed in previous works.	Review	B-Review	1
The hidden state updates provide some gains for the model but also makes the decoder more expensive.	Review	I-Review	2
The training with multiple k provides similar gain as training with one k larger than the value used at the inference time.	Review	I-Review	3
Overall the contributions are limited.	Review	I-Review	3
[line_break_token][line_break_token]There is quite some room for this paper to improve its clarify, especially in terms of annotations and explaining the proposed ideas.	Review	I-Review	4
egarding "The masking and using causal attention for the transformer has been proposed in previous works."	Reply	O	0
[line_break_token][line_break_token]Uni-directional encoders for online machine translation were previously used with RNN-based architectures, we are not familiar with existing work that uses causal attention for transformer NMT models.	Reply	B-Reply	1
In [1] the encoder was not causal which means that for every time-step the encoder states have to be updated.	Reply	I-Reply	1
It would be great if you could share the references you were thinking about.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Regarding "The hidden state updates provide some gains for the model but also makes the decoder more expensive."	Reply	O	0
[line_break_token][line_break_token]Compared to our model with caching, we agree that the update of the decoder states is expensive.	Reply	B-Reply	2
However if we‚Äôre comparing to [1] we basically re-allocated the cost from updating the encoder states to updating the decoder states instead and we get better performances with this new allocation.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding "The training with multiple k provides similar gain as training with one k larger than the value used at the inference time.	Reply	O	0
Overall the contributions are limited."	Reply	O	0
[line_break_token][line_break_token]Training with a single large k does not improve the performance on smaller values of k.[line_break_token]If we look for example at figure 4.c, for an average lagging of 2, there is a difference of almost 3 BLEU points between the model trained with k=9 and the one trained with k in [1,...,5].[line_break_token][line_break_token]Regarding "There is quite some room for this paper to improve its clarify, especially in terms of annotations and explaining the proposed ideas."	Reply	O	0
[line_break_token][line_break_token]Please let us know if there are any specific annotations or concepts you think need rewriting, we would gladly make it clearer in the updated paper.	Reply	B-Reply	4
[line_break_token][line_break_token][1] Ma et al. ‚	Reply	O	0
ÄúSTACL: Simultaneous Translation with Implicit Anticipation and Controllable Latency using Prefix-to-Prefix Framework."	Reply	O	0
ACL 2019	Reply	O	0

This paper is well written and easy to follow.	Review	O	0
The authors propose pixel deconvolutional layers for convolutional neural networks.	Review	O	0
The motivation of the proposed method, PixelDCL, is to remove the checkerboard effect of deconvolutoinal layers.	Review	O	0
[line_break_token]The method consists of adding direct dependencies among the intermediate feature maps generated by the deconv layer.	Review	O	0
PixelDCL is applied sequentially, therefore it is slower than the original deconvolutional layer.	Review	O	0
The authors evaluate the model in two different problems: semantic segmentation (on PASCAL VOC and MSCOCO datasets) and in image generation VAE (with the CelebA dataset).	Review	O	0
[line_break_token][line_break_token]The authors justify the proposed method as a way to alleviate the checkerboard effect (while introducing more complexity to the model and making it slower).	Review	O	0
In the experimental section, however, they do not compare with other approaches to do so For example, the upsampling+conv approach, which has been shown to remove the checkerboard effect while being more efficient than the proposed method (as it does not require any sequential computation).	Review	B-Review	1
Moreover, the PixelDCL does not seem to bring substantial improvements on DeepLab (a state-of-the-art semantic segmentation algorithm).	Review	I-Review	2
More comments and further exploration on this results should be done.	Review	I-Review	2
Why no performance boost?	Review	I-Review	2
Is it because of the residual connection?	Review	I-Review	2
Or other component of DeepLab?	Review	I-Review	2
Is the proposed layer really useful once a powerful model is used?	Review	I-Review	2
[line_break_token][line_break_token]I also think the experiments on VAE are not conclusive.	Review	I-Review	3
The authors simply show set of generated images.	Review	I-Review	3
First, it is difficult to see the different of the image generated using deconv and PixelDCL.	Review	I-Review	3
Second, a set of 20 qualitative images does not (and cannot) validate any research idea.	Review	I-Review	3
Thank you for your comments!	Reply	O	0
Since our main objective in this paper is to solve the checkerboard problem suffered by deconvolutional layers, the experiments are mainly designed to show the performance improvement compared to traditional deconvolutional layer.	Reply	B-Reply	1
In both segmentation experiments, we use convolutional layer after deconvolutional layer as the baseline setting.	Reply	I-Reply	1
For the training-from-scratch experiments, we use one deconvolutional layer followed by two convolutional layers, which is the default setting in U-Net architecture.	Reply	I-Reply	1
We replace the deconvolutional layer with our PixelDCL with the same number of parameters.	Reply	I-Reply	1
For fine-tuning experiments, each block is composed of one deconvolutional layer followed by one convolution layer.	Reply	I-Reply	1
From the result, we can see the convolutional layer is not powerful enough to remove the checkerboard effect.	Reply	I-Reply	1
At the same time, we want to solve this problem by improving the deconvolution operation itself, without adding more layers.	Reply	I-Reply	1
This has added benefit that the proposed method can be made plug-and-play and becomes a standard layer in common deep learning libraries.	Reply	I-Reply	1
[line_break_token][line_break_token]For the DeepLab model, actually there is no deconvolutional layer involved in the original DeepLab_v2 architecture.	Reply	I-Reply	2
The size of the predictions is (1/8)*(1/8) of that of the labels.	Reply	I-Reply	2
They employed a simple bilinear up-sampling operation on the predictions to have the same size as the labels.	Reply	I-Reply	2
The reason is that for PASCAL VOC dataset, the shapes of most objects in the labels are very regular and down-sampling the labels does not hurt the upper bound of mIoU much (according to Long_2015_CVPR, 100->96.4) .	Reply	O	0
It brings a significant advantage for bilinear interpolation.	Reply	B-Reply	2
For example, if the original label contains a 16*16 square object.	Reply	I-Reply	2
The model only needs to predict a 2*2 square correctly before bilinear up-sampling.	Reply	I-Reply	2
In contrast, a model whose prediction has the same size as the original label needs to get 64 times more outputs correctly.	Reply	I-Reply	2
However, in order to compare deconvolution with our pixel deconvolution, we added three blocks to up-sample the labels to original size.	Reply	I-Reply	2
The results obtained achieve similar performance with the original model.	Reply	I-Reply	2
And in this setting, the proposed layer improved the mIoU. We aimed to prove that our proposed method is better than the deconvolution operation in different models and datasets instead of getting the best result for any specific task.	Reply	I-Reply	2
[line_break_token][line_break_token]The deconvolutional layer sometimes is irreplaceable for some tasks such as generative model, where bilinear interpolating does not help at all.	Reply	I-Reply	3
We didn‚Äôt show too many VAE results in paper due to page limitations.	Reply	I-Reply	3
These images are all generated randomly.	Reply	I-Reply	3
By looking into the details, there are apparent checkerboard artifacts on images generated by original VAE model.	Reply	I-Reply	3
The results of our model effectively remove them without using more parameters.	Reply	I-Reply	3

# Summary[line_break_token][line_break_token]This paper proposes a technique for synthesis of state machine policies for a simple continuous agent, with a goal of[line_break_token]them being generalizable to out-of-distribution test conditions.	Review	O	0
The agent is modeled as a state machine with constant[line_break_token]or proportional actions applied in each node (regime), and switching triggers between the regimes represented as[line_break_token]length-2 boolean conditions on the observations.	Review	O	0
The technique is evaluated on 7 classic control environments, and found[line_break_token]to outperform pure-RL baselines under "test" conditions in most of them.	Review	O	0
[line_break_token][line_break_token]# Review[line_break_token][line_break_token]I am not an expert in RL-based control, although I'm familiar with the recent literature that applies formal methods to[line_break_token]these domains.	Review	O	0
I find the studied settings valuable albeit fairly limited, but the paper's method undeniably shows[line_break_token]noticeable improvement on these settings.	Review	O	0
Inductive generalization is an important problem, and the authors' approach of[line_break_token]limiting the agent structure to a particular class of state-machine policies is a reasonable solution strategy.	Review	O	0
[line_break_token][line_break_token]That said, the complexity of synthesizing a state machine policy clearly caused the authors to limit their supported[line_break_token]action and condition spaces considerably (Figure 6).	Review	B-Review	6
That, I'm assuming, limits the set of applicable control[line_break_token]environments where optimization is still feasible.	Review	I-Review	6
The authors don't provide any analysis of complexity or empirical[line_break_token]runtime of the optimization process.	Review	I-Review	1
Breaking it down for each benchmark would allow me to appreciate the optimization[line_break_token]framework in Section 4 much more.	Review	I-Review	1
As it stands, Section 4 describes a complex optimization process with many moving[line_break_token]parts, some of which are approximated (q* and p(œÑ|œÄ,x‚ÇÄ)) or computed via EM iteration until convergence (œÄ*).	Review	I-Review	1
It is hard[line_break_token]to appreciate all this complexity without knowing where the challenges manifest on specific examples.	Review	I-Review	1
[line_break_token][line_break_token]Section 4.2 needs an example, to link it to the introductory example in Figure 1.	Review	I-Review	2
The "loop-free" policies of the[line_break_token]teacher are, in programmatic terms, _traces_ of the desired state machine execution (if I understand correctly), but[line_break_token]this is not obvious from just the formal definition.	Review	I-Review	2
[line_break_token][line_break_token]The EM optimization for the student policy makes significant assumptions on the action/condition grammars.	Review	I-Review	3
Namely, the[line_break_token]algorithm iterates over every possible discrete "sketch" of every program, and then numerically optimizes its continuous[line_break_token]parameters (Appendix A).	Review	I-Review	3
When the action/condition grammars grow, the number of possible programs there increases[line_break_token]combinatorially.	Review	I-Review	3
Is there a way to adapt the optimization process to handle more complex grammars, possibly with[line_break_token]decomposition of the problem following the program structure?	Review	I-Review	3
[line_break_token][line_break_token]Section 5 needs a bit more details on the Direct-Opt baseline.	Review	I-Review	4
It's unclear how the whole state machine policy (which[line_break_token]includes both discrete and continuous parts) is learned end-to-end via numerical optimization.	Review	I-Review	4
Granted, the baseline[line_break_token]performs terribly, but would be great to understand how it models the learning problem in order to appreciate why it's[line_break_token]terrible.	Review	I-Review	4
[line_break_token][line_break_token]Why were the "Acrobot" and "Mountain car" benchmarks removed from the main presentation of results?	Review	I-Review	5
hank you for thoroughly reading the paper and your valuable comments.	Reply	O	0
We address your concerns below: [line_break_token][line_break_token]**** Complexity of the algorithm limits the set of applicable environments ****[line_break_token][line_break_token]We have added a new, more complex benchmark -- namely, the MuJoCo swimmer (extended to 4 segments instead of 3 to make the task more challenging) -- to our paper.	Reply	O	0
This benchmark has control inputs R^3 and observation space R^10.	Reply	B-Reply	6
The state-machine policy synthesized using our algorithm has 4 different modes. (	Reply	I-Reply	6
Section 5, Figure 10, Figure 20)[line_break_token][line_break_token]Overall, the focus of our paper is on addressing problems where a relatively simple behavior must be repeated a certain number of times to solve the given task.	Reply	I-Reply	6
We believe these problems are pervasive -- for example, many motor tasks such as walking, running, jumping, swimming, etc.	Reply	I-Reply	6
all rely on this kind of a policy.	Reply	I-Reply	6
Yet, neural network policies have difficulty solving these tasks in a generalizable way.	Reply	I-Reply	6
The key premise behind our approach is that compact state-machine policies can represent policies that both have good performance and are generalizable for this class of problems.	Reply	I-Reply	6
Indeed, our algorithm solves all of our benchmarks using state-machine policies with at most 4 modes and switching conditions of depth at most 2.	Reply	I-Reply	6
[line_break_token][line_break_token]For example, consider the autonomous car example in Figure 1.	Reply	I-Reply	6
The task in Figure 1d (i.e. when the gap between cars is very small) is significantly complex that the neural network baseline was not able to solve (even when trained directly on those initial states; see Figure 3 rightmost).	Reply	I-Reply	6
However, a small state-machine policy with only 3 modes was able to solve this task.	Reply	I-Reply	6
[line_break_token][line_break_token]We certainly agree with the reviewer that it will be interesting to see how the algorithm scales for larger state machines.	Reply	I-Reply	6
However, this problem is qualitatively different from the one we are solving, and different algorithms would be needed to solve it.	Reply	I-Reply	6
Overall, we believe that state-machines are most useful when only a few states are required.	Reply	I-Reply	6
When a large number of states are needed, then the number of possible transition structures grows exponentially, making it unlikely that we can learn the ‚Äútrue‚Äù structure without having an exponential amount of both training data and computation time.	Reply	I-Reply	6
For these cases, we believe recurrent neural network policies such as LSTMs may remain the better choice.	Reply	I-Reply	6
[line_break_token][line_break_token]**** Empirical runtime analysis ****[line_break_token][line_break_token]We add runtime analysis in Appendix C.2 and Figure 11 in our paper.	Reply	O	0
We show the synthesis times for various benchmarks, the number of student-teacher iterations, and the time spent by the teacher and the student separately.	Reply	B-Reply	1
We hope this will give the reviewer a better perspective on the different parts of the algorithm[line_break_token][line_break_token]**** Scaling the algorithm with the complexity of the grammar ****[line_break_token][line_break_token]For the action functions, the user decides whether the action functions will be from a constant grammar or a proportional grammar.	Reply	O	0
Furthermore, for proportional grammar, the user specifies which observation the action should be proportional to.	Reply	B-Reply	3
There are no discrete choices in either of these two grammars.	Reply	I-Reply	3
We believe that this is usually not difficult for the user to choose the best grammar to use; for instance, a user can easily say that the control for y-acceleration will be proportional be y-velocity and not x-velocity.	Reply	I-Reply	3
An alternative would be to run the teacher‚Äôs algorithm with many different action function grammars and choose the grammar that resulted in high-reward loop-free policies.	Reply	I-Reply	3
[line_break_token][line_break_token]For the switching conditions, the discrete choices in the grammar will be learned by the synthesis algorithm along with the continuous parameters.	Reply	I-Reply	3
We agree with the reviewer that the discrete enumeration involved here will quickly blow up with the size of the boolean expression.	Reply	I-Reply	3
For this reason, we have a greedy algorithm that scales quadratically with the size of the expression rather than exponentially.	Reply	I-Reply	3
We failed to mention this in the original paper, but updated it now (see Appendix A.3 in our paper for more details).	Reply	I-Reply	3
All the experiments use this greedy algorithm for learning the switching conditions.	Reply	I-Reply	3
[line_break_token][line_break_token]**** Examples of loop-free policy ****[line_break_token][line_break_token]We added two examples of loop-free policies in Figure 13 in the context of the example in Figure 1.	Reply	O	0
We also show visualizations of trajectories learned by the teacher and the student for two different iterations of the algorithm in Figure 12.	Reply	B-Reply	2
[line_break_token]	Reply	O	0

Paper summary.	Review	O	0
[line_break_token]The paper proposes Dreamer, a model-based RL method for high-dimensional inputs such as images.	Review	O	0
The main novelty in Dreamer is to learn a policy function from latent representation-and-transition models in an end-to-end manner.	Review	O	0
Specifically, Dreamer is an actor-critic method that learns an optimal policy by backpropagating re-parameterized gradients through a value function, a latent transition model, and a latent representation model.	Review	O	0
This is unlike existing methods which use model-free or planning methods on simulated trajectories to learn the optimal policy.	Review	O	0
Meanwhile, Dreamer learns the remaining components, namely a value function, a latent transition model, and a latent representation model, based on existing methods (the world models and PlaNet).	Review	O	0
Experiments on a large set of continuous control tasks show that Dreamer outperforms existing model-based and model-free methods.	Review	O	0
[line_break_token][line_break_token]Comments.	Review	O	0
[line_break_token]Efficiently learning a policy from visual inputs is an important research direction in RL.	Review	O	0
This paper takes a step in this direction by improving existing model-based methods (the world models and PlaNet) using the actor-critic approach.	Review	O	0
I am leaning towards weak accepting the paper.	Review	O	0
[line_break_token][line_break_token]I am reluctant to give a higher score due to its incremental contribution.	Review	B-Review	1
Specifically, the policy update in Dreamer resembles that of SVG (Heess et al.,	Review	I-Review	1
2015), which also backpropagates re-parameterized gradients through a value function and a transition model.	Review	I-Review	1
The main difference between Dreamer and SVG is that Dreamer incorporates a latent representation model.	Review	I-Review	1
From this viewpoint, the actor-critic component in Dreamer is an incremental contribution.	Review	I-Review	1
Since the latent models are learned based on existing techniques, the paper presents an incremental contribution.	Review	I-Review	2
[line_break_token][line_break_token]Besides the above comments, I have these additional comments.	Review	O	0
[line_break_token]- Effectiveness on very long horizon trajectories: [line_break_token]Simulating long-horizon trajectories with a probabilistic model is known to be unsuitable for model-based RL due to accumulated errors.	Review	O	0
This is an open issue in model-based RL.	Review	B-Review	3
The paper attempts to solve this issue by backpropagating policy gradients through the transition model, which is known to be more robust against model errors (see e.g., PILCO (Deisenroth et al.,	Review	I-Review	3
2011)).	Review	I-Review	3
However, the issue still exists in Dreamer, since there seems to be an upper limit of effective horizon length (perhaps around 40, according to Figure 4).	Review	I-Review	4
This horizon length is still short compared to the entire horizon length of many MDPs (e.g., 1000).	Review	I-Review	4
I think this point should be discussed in the paper.	Review	I-Review	4
That is, the issue still exists, and Dreamer is less effective with very long horizon.	Review	I-Review	4
[line_break_token][line_break_token]- Inapplicability to discrete controls: [line_break_token]One restriction of re-parameterized gradients is that the technique is not applicable to discrete random variables.	Review	O	0
This restriction exists in Dreamer, and the method cannot be applied to discrete control tasks unless approximation techniques such as Gumbel-softmax are used.	Review	B-Review	5
Still, such approximations would make learning more challenging, especially with long-horizon backpropagation.	Review	I-Review	5
This restriction should be noted in the paper.	Review	I-Review	5
[line_break_token][line_break_token]- There is no mention about variance of policy gradient estimates.	Review	O	0
Dreamer does not use any variance reduction technique, so the gradient estimates could have very large variance.	Review	B-Review	6
[line_break_token][line_break_token]- q_theta was introduced in Eq. (	Review	O	0
8) before it is defined in Eq. (	Review	B-Review	7
11).	Review	I-Review	7
Also, I suggest moving Section 4 to be right after Section 2, since Section 4 presents existing techniques similarly to Section 2, while Section 3 presents the main contribution.	Review	I-Review	7
[line_break_token][line_break_token][line_break_token]Update after authors' response.	Review	O	0
[line_break_token]I read the response.	Review	O	0
The paper is more clear after authors' clarification.	Review	O	0
Though, I still think the contribution is incremental, since back-propagating gradients through values and dynamics has been studied in prior works (albeit with less empirical successes compared to Dreamer).	Review	O	0
Nonetheless, I am keen to acceptance.	Review	O	0
I would increase the rating from 6 to 7, but I will keep the rating of 6 since the rating of 7 is not possible.	Review	O	0
hank you for the review and accurate summary of our submission!	Reply	O	0
[line_break_token][line_break_token]&gt; I am reluctant to give a higher score due to its incremental contribution.	Reply	O	0
Specifically, the policy update in Dreamer resembles that of SVG (Heess et al.,	Reply	O	0
2015), which also backpropagates re-parameterized gradients through a value function and a transition model.	Reply	O	0
[line_break_token][line_break_token]SVG clearly differs from Dreamer in that it only considers 1-step model predictions in SVG(1) or multi-step predictions without value function in SVG(‚àû).	Reply	B-Reply	1
SVG(0) does not use a dynamics model.	Reply	I-Reply	1
In addition, Dreamer propagates gradients through transitions in a learned features, making it effective for high-dimensional control tasks.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; Since the latent models are learned based on existing techniques, the paper presents an incremental contribution.	Reply	O	0
[line_break_token][line_break_token]Besides the important technical difference described above, we highlight the empirical performance of Dreamer.	Reply	B-Reply	2
A conclusion of the SVG paper was that the model did not yield substantial practical benefits beyond 1-step predictions.	Reply	I-Reply	2
We found it important to revisit this topic in the light of recent substantial improvements to dynamics models (see below).	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; Effectiveness on very long horizon trajectories: Simulating long-horizon trajectories with a probabilistic model is known to be unsuitable for model-based RL due to accumulated errors.	Reply	O	0
This is an open issue in model-based RL.	Reply	O	0
[line_break_token][line_break_token]While current dynamics models still cannot accurately predict full episodes, this is rarely needed in practice.	Reply	B-Reply	3
Recent works successfully use learned dynamics for control from both proprioceptive inputs (Chua et al.	Reply	I-Reply	3
2018, Shyam et al.	Reply	I-Reply	3
2019, Wang &amp; Ba 2019) and from images (Hafner et al.	Reply	O	0
2019, Zhang et al.	Reply	B-Reply	3
2019).	Reply	I-Reply	3
[line_break_token][line_break_token]Dreamer shows that the relatively short model predictions (H=20) yield high-quality policy gradients, and that an additional value function in the latent space is effective for solving tasks that require longer-term credit assignment (e.g. with sparse rewards).	Reply	I-Reply	3
Our experiments provide evidence that combination is effective in practice.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; However, the issue still exists in Dreamer, since there seems to be an upper limit of effective horizon length (perhaps around 40, according to Figure 4).	Reply	O	0
This horizon length is still short compared to the entire horizon length of many MDPs (e.g., 1000).	Reply	O	0
I think this point should be discussed in the paper.	Reply	O	0
That is, the issue still exists, and Dreamer is less effective with very long horizon.	Reply	O	0
[line_break_token][line_break_token]We address the challenge of long horizons not using long-term model predictions but by learning a value function that estimates the infinite sum of discounted future rewards.	Reply	B-Reply	4
Figure 4 in our submission shows that this gives Dreamer robustness to the imagination horizon compared to two baselines.	Reply	I-Reply	4
[line_break_token][line_break_token]&gt; Inapplicability to discrete controls:  One restriction of re-parameterized gradients is that the technique is not applicable to discrete random variables.	Reply	O	0
This restriction exists in Dreamer, and the method cannot be applied to discrete control tasks unless approximation techniques such as Gumbel-softmax are used.	Reply	O	0
Still, such approximations would make learning more challenging, especially with long-horizon backpropagation.	Reply	O	0
This restriction should be noted in the paper.	Reply	O	0
[line_break_token][line_break_token]We applied Dreamer to environments with discrete actions using the DiCE estimator (Foerster et al.	Reply	B-Reply	5
2018) locally for the da/dŒº and da/dœÉ derivatives.	Reply	I-Reply	5
This was a drop-in replacement for the reparameterization estimator and slightly outperformed a Gumble-softmax actor.	Reply	I-Reply	5
We find that with this 1 line change, Dreamer solves discrete action tasks of the Atari suite and a 3D DMLab environment.	Reply	I-Reply	5
[line_break_token][line_break_token]&gt; There is no mention about variance of policy gradient estimates.	Reply	O	0
Dreamer does not use any variance reduction technique, so the gradient estimates could have very large variance.	Reply	O	0
[line_break_token][line_break_token]Dreamer uses reparamterization gradients that already have low variance (Kingma &amp; Welling 2013, Rezende et al.	Reply	O	0
2014); although see Miller et al. (	Reply	B-Reply	6
2017).	Reply	I-Reply	6
Learning baselines for variance reduction is common for Reinforce estimators as used in A3C and PPO (Mnih et al.	Reply	I-Reply	6
2016, Schulman et al.	Reply	I-Reply	6
2017) but not for reparameterization estimators as used in Dreamer, SVG, and SAC (Heess et al.	Reply	I-Reply	6
2015, Haarnoja et al.	Reply	I-Reply	6
2018)	Reply	I-Reply	5

This paper deals with improving language models on mobile equipments[line_break_token]based on small portion of text that the user has ever input.	Review	O	0
For this[line_break_token]purpose, authors employed a linearly interpolated objectives between user[line_break_token]specific text and general English, and investigated which method (learning[line_break_token]without forgetting and random reheasal) and which interepolation works better.	Review	O	0
[line_break_token]Moreover, authors also look into privacy analysis to guarantee some level of[line_break_token]differential privacy is preserved.	Review	O	0
[line_break_token][line_break_token]Basically the motivation and method is good, the drawback of this paper is[line_break_token]its narrow scope and lack of necessary explanations.	Review	O	0
Reading the paper,[line_break_token]many questions arise in mind:[line_break_token][line_break_token]- The paper implicitly assumes that the statistics from all the users must[line_break_token]  be collected to improve "general English".	Review	O	0
Why is this necessary?	Review	B-Review	1
Why not[line_break_token]  just using better enough basic English and the text of the target user?	Review	I-Review	1
[line_break_token][line_break_token]- To achieve the goal above, huge data (not the "portion of the general English") should be communicated over the network.	Review	O	0
Is this really worth doing?	Review	B-Review	2
If only[line_break_token]  "the portion of" general English must be communicated, why is it validated?	Review	I-Review	2
[line_break_token][line_break_token]- For measuring performance, authors employ keystroke saving rate.	Review	O	0
For the[line_break_token]  purpose of mobile input, this is ok: but the use of language models will[line_break_token]  cover much different situation where keystrokes are not necessarily [line_break_token]  available, such as speech recognition or machine translation.	Review	B-Review	3
Since this [line_break_token]  paper is concerned with a general methodology of language modeling, [line_break_token]  perplexity improvement (or other criteria generally applicable) is also[line_break_token]  important.	Review	I-Review	3
[line_break_token][line_break_token]- There are huge number of previous work on context dependent language models,[line_break_token]  let alone a mixture of general English and specific models.	Review	O	0
Are there any[line_break_token]  comparison with these previous efforts?	Review	B-Review	4
[line_break_token][line_break_token]Finally, this research only relates to ICLR in that the language model employed[line_break_token]is LSTM: in other aspects, it easily and better fit to ordinary NLP conferences, such as EMNLP, NAACL or so.	Review	I-Review	5
I would like to advise the authors to submit[line_break_token]this work to such conferences where it will be reviewed by more NLP experts.	Review	I-Review	5
[line_break_token][line_break_token]Minor:[line_break_token]- t of in page 2 is not defined so far.	Review	I-Review	6
[line_break_token]- What is "gr" in Section 2.2?	Review	I-Review	6
[line_break_token]	Review	O	0
Thank you for your review!	Reply	O	0
[line_break_token]I would like to make some clarifications and remarks.	Reply	O	0
[line_break_token][line_break_token]You write:[line_break_token]"- The paper implicitly assumes that the statistics from all the users must be collected to improve "general English".	Reply	O	0
Why is this necessary?	Reply	O	0
Why not just using better enough basic English and the text of the target user?"	Reply	O	0
[line_break_token][line_break_token]There is strong evidence that  the language of SMS and/or private messaging is sufficiently different from what we can collect in publicly available resources.	Reply	B-Reply	1
Since language changes constantly we need to update the models and we cannot just make a single fine-tuning of basic LM on device.	Reply	I-Reply	1
On the other hand the data from a single user is not sufficient for model update so we need data from many different users.	Reply	I-Reply	1
The problem is that we cannot (or at least don't want to) collect user data.	Reply	I-Reply	1
 We've proposed a method of continuous update of language models without need to collect private data.	Reply	I-Reply	1
[line_break_token][line_break_token]"- To achieve the goal above, huge data (not the "portion of the general English") should be communicated over the network.	Reply	O	0
Is this really worth doing?	Reply	O	0
If only the portion of" general English must be communicated, why is it validated?"	Reply	O	0
[line_break_token][line_break_token]As we mention in the paper the volume of the user generated data is small.	Reply	B-Reply	2
Actually users generate approx.	Reply	I-Reply	2
600 bytes/day.	Reply	I-Reply	2
In our experiments we proceeded from the assumption that fine-tuning starts as soon as 10 Kb of text data is accumulated on device.	Reply	I-Reply	2
Our experiments showed that random rehearsal with volume of the rehearsal data should be to the volume of the fine-tuning data.	Reply	I-Reply	2
So it is 10 Kb.	Reply	I-Reply	2
This number is very small compared to the volume of model weights which are communicated in Federated Learning algorithms.	Reply	I-Reply	2
We also discussed the communication efficiency in the answers to other reviewers (see above).	Reply	I-Reply	2
[line_break_token][line_break_token]"- For measuring performance, authors employ keystroke saving rate.	Reply	O	0
For the purpose of mobile input, this is ok: but the use of language models will cover much different situation where keystrokes are not necessarily available, such as speech recognition or machine translation.	Reply	O	0
Since this paper is concerned with a general methodology of language modeling, perplexity improvement (or other criteria generally applicable) is also important."	Reply	O	0
[line_break_token][line_break_token]Basically, we agree.	Reply	B-Reply	3
And perplexity is reported in all our experiments.	Reply	I-Reply	3
We just wanted to emphasize that target metrics should also be evaluated in language modeling like it is done in speech recognition (ASR) or machine translation (BLEU).	Reply	I-Reply	3
Also, in (McMahan et al.	Reply	I-Reply	3
2017, <a href="https://openreview.net/pdf?id=B1EPYJ-C-)" target="_blank" rel="nofollow">https://openreview.net/pdf?id=B1EPYJ-C-)</a> word prediction accuracy is evaluated which is relative to KSS.	Reply	O	0
[line_break_token][line_break_token]"- There are huge number of previous work on context dependent language models, let alone a mixture of general English and specific models.	Reply	O	0
Are there any comparison with these previous efforts?"	Reply	O	0
[line_break_token][line_break_token][line_break_token]The term context is a bit vague.	Reply	B-Reply	4
E.g. in (Mikolov, Zweig 2014, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.258.5120&;rep=rep1&type=pdf)" target="_blank" rel="nofollow">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.258.5120&;rep=rep1&type=pdf)</a> term "context" refers to the longer left context which is unavailable to standard RNN.	Reply	O	0
Anyway longer left contexts are reasonably well catched by LSTM.	Reply	B-Reply	4
If "context" refers to the running environment (e.g. application context) it is not the exact scope of our work.	Reply	I-Reply	4
The standard approach to model adaptaion for the user is either model fine-tuning or interpolation with simpler language model (e.g. Knesser-Ney smoothed n-gram).	Reply	I-Reply	4
We tried approaches similar to the proposed in (Ma et al.	Reply	I-Reply	4
2017, <a href="https://static.googleusercontent.com/media/research.google.com/ru//pubs/archive/46439.pdf)" target="_blank" rel="nofollow">https://static.googleusercontent.com/media/research.google.com/ru//pubs/archive/46439.pdf)</a> but they performed significantly worse.	Reply	O	0
[line_break_token][line_break_token]I also would like to draw your attention to the privacy analysys part of the paper which we included in the list of our contributions.	Reply	B-Reply	7
We consider our contribution significant at least for the following reason.	Reply	I-Reply	7
To our knowledge deep neural networks have never been checked for differential privacy coming from the randomness of the training algorithm (combination of SGD, dropout regularization and model averaging in our case).	Reply	I-Reply	7
Existing approaches (e.g. Papernot et al.	Reply	I-Reply	7
2017, <a href="https://arxiv.org/pdf/1610.05755.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1610.05755.pdf)</a> suggest adding random noise at different stages of training leading to the tradeoff between accuracy and privacy.	Reply	O	0
At the same time our experiments show that the differential privacy can be guaranteed even without special treatment of the neural networks at least in some situations	Reply	B-Reply	7

This paper explores the use of Open Bigrams as a target representation of words, for application to handwriting image recognition.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The use of OBs is novel and interesting.	Review	O	0
[line_break_token]- Clearly written and explained.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- No comparison to previous state of the art, only with author-generated results.	Review	O	0
[line_break_token]- More ablation studies needed -- i.e. fill in Table3 with rnn0,1 rnn0,1,2 rnn0,1' etc etc.	Review	O	0
It is not clear where the performance is coming from, as it seems that it is single character modelling (0) and word endings (') that are actually beneficial.	Review	O	0
[line_break_token]- While the use of Open bigrams is novel, there are works which use bag of bigrams and ngrams as models which are not really compared to or explored.	Review	O	0
E.g. <a href="https://arxiv.org/abs/1406.2227" target="_blank" rel="nofollow">https://arxiv.org/abs/1406.2227</a> [1] and <a href="https://arxiv.org/abs/1412.5903" target="_blank" rel="nofollow">https://arxiv.org/abs/1412.5903</a> [2]. Both use bag of ngrams models and achieve state of the art results, so it would be interesting to see whether open bigrams in the same experimental setup as [1] would yield better results.	Review	O	0
[line_break_token]- Why not use a graph-based decoder like in Fig 2 b?	Review	O	0
[line_break_token][line_break_token]Overall an interesting paper but the lack of comparisons and benchmarks makes it difficult to assess the reality of the contributions.	Review	O	0
Thanks for the feedback and relevant comments.	Reply	O	0
[line_break_token][line_break_token]> - No comparison to previous state of the art, only with author-generated results.	Reply	O	0
[line_break_token][line_break_token]No fair comparison is possible since we limited ourselves to ([a-z]+) words.	Reply	B-Reply	1
[line_break_token]Moreover, we don't claim to improve handwriting recognition with this method, but rather to learn a representation of words inspired from neuroscience, and to build a decoder operative on that representation.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]> - More ablation studies needed -- i.e. fill in Table3 with rnn0,1 rnn0,1,2 rnn0,1' etc etc.	Reply	O	0
It is not clear where the performance is coming from, as it seems that it is single character modelling (0) and word endings (') that are actually beneficial.	Reply	O	0
[line_break_token][line_break_token]We will add those experiments and results.	Reply	B-Reply	2
[line_break_token][line_break_token]> - While the use of Open bigrams is novel, there are works which use bag of bigrams and ngrams as models which are not really compared to or explored.	Reply	O	0
E.g. <a href="https://arxiv.org/abs/1406.2227" target="_blank" rel="nofollow">https://arxiv.org/abs/1406.2227</a> [1] and <a href="https://arxiv.org/abs/1412.5903" target="_blank" rel="nofollow">https://arxiv.org/abs/1412.5903</a> [2]. Both use bag of ngrams models and achieve state of the art results, so it would be interesting to see whether open bigrams in the same experimental setup as [1] would yield better results.	Reply	O	0
[line_break_token][line_break_token]I agree, it would be interesting, although the goal of the COGNILEGO project was to "[develop] novel systems for handwriting recognition based on the latest advances in cognitive perception research." (	Reply	B-Reply	3
<a href="http://cognilego.univ-tln.fr/doku.php)."	Reply	O	0
target="_blank" rel="nofollow">http://cognilego.univ-tln.fr/doku.php).</a>[line_break_token]It would be also interesting to see how [1] and [2] perform in our setup.	Reply	O	0
[line_break_token] [line_break_token]> - Why not use a graph-based decoder like in Fig 2 b?	Reply	O	0
[line_break_token][line_break_token]The assumption in the approach is that we only have a set of bigrams.	Reply	B-Reply	4
I don't see a simple and efficient way (compared to the cosine similarity) to build a decoder from the hypothetical graph of Fig.	Reply	I-Reply	4
2b.	Reply	I-Reply	4
[line_break_token]	Reply	O	0

This paper presents a Visual Task Adaptation Benchmark (VTAB) as a diverse and[line_break_token]challenging benchmark to evaluate the learned representations.	Review	O	0
The VTAB judges whether the learned representation is good or not by adapting it to unseen tasks which have few examples.	Review	O	0
This paper conducts popular algorithms on a large amount of VTAB studies by answering questions: (1) how effective are ImageNet representation on non-standard datasets? (	Review	O	0
2) are generative models competitive? (	Review	O	0
3) is self-supervision useful if one already has labels?	Review	O	0
[line_break_token][line_break_token]What is the size of the training dataset in the source domain?	Review	B-Review	1
[line_break_token][line_break_token]The authors need to compare the conclusion obtained with other works.	Review	I-Review	2
It seems that there is no new founding in this paper.	Review	I-Review	2
n our experiments, we train all networks upstream on the standard ILSVRC2012-ImageNet dataset which contains 1.28M images and 1000 classes.	Reply	B-Reply	1
[line_break_token][line_break_token]We motivated our new benchmark in depth, and provided a very large scale analysis of much of the current field.	Reply	I-Reply	2
Could you please be more specific about the aspects that you believe are missing	Reply	I-Reply	2

In this paper, the authors claimed to address a new domain adaptation setting under double blind constraint, to meet the privacy requirement.	Review	O	0
Though the problem itself seems real and interesting, the solution in this work makes the problem quite trivial.	Review	B-Review	1
In fact, any other domain adaptation method can be applied to address the problem, while the authors even did not compare with existing UDA methods which can be intuitively adapted.	Review	I-Review	1
[line_break_token][line_break_token]Pros:[line_break_token]-[tab_token]The problem that this work aims to address, i.e., domain adaptation under privacy constraint, seems reasonable and important.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]-[tab_token]The authors proposed a quite trivial solution to solve this problem, which in turn makes all existing UDA adaptation methods off-the-shelf.	Review	O	0
For example, the most widely accepted DA algorithms, such as MMD and DANN, can be adapted to minimize the distance between the target encoder and the source encoder by training the weights for the target encoder.	Review	B-Review	1
In this case, the aligner introducing more parameters is not even necessary.	Review	I-Review	1
[line_break_token]-[tab_token]The results are not promising and inspiring.	Review	O	0
S(UL), directly applying a model trained on a source dataset, has already achieved as competent results as TAN.	Review	B-Review	2
[line_break_token]-[tab_token]The datasets used are at a toy level from UCI.	Review	O	0
More profound discoveries are expected on DA benchmarks.	Review	B-Review	3
[line_break_token]-[tab_token]The paper needs significant proof-reading, as there are many grammatical errors and typos.	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for the careful reading of the paper and their constructive comments.	Reply	O	0
We would like to answer the reviewer‚Äôs questions as follows:[line_break_token][line_break_token]1.	Reply	O	0
Competitors[line_break_token]We proposed the unsupervised domain adaptation under the double blind setting, where the source and target data cannot be visible in the training process simultaneously.	Reply	O	0
Differently from our setting, the state-of-the-art unsupervised domain adaptation methods, e.g. MMD and DANN, train the model by feeding in the source and target data together.	Reply	B-Reply	1
Thus, those existing methods cannot be used for baselines.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	2
Results [line_break_token]Table 3 compares the accuracy of S(UL) and TAN.	Reply	O	0
The 2.64%~9% of improvements show the superiority of our method.	Reply	B-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Datasets[line_break_token]In this paper, we focused on experimenting with multivariate data.	Reply	O	0
However, domain adaptation benchmarks have more complex data manifolds than multivariate data.	Reply	B-Reply	3
It seems that a more complex architecture is needed to train domain adaptation benchmarks and we leave it as a future work	Reply	I-Reply	3

This paper discusses aligning word vectors across language when those embeddings have been learned independently in monolingual settings.	Review	O	0
There are reasonable scenarios in which such a strategy could come in helpful, so I feel this paper addresses an interesting problem.	Review	O	0
The paper is mostly well executed but somewhat lacks in evaluation.	Review	O	0
It would have been nice if a stronger downstream task had been attempted.	Review	O	0
[line_break_token][line_break_token]The inverted Softmax idea is very nice.	Review	O	0
[line_break_token][line_break_token]A few minor issues that ought to be addressed in a published version of this paper:[line_break_token][line_break_token]1) There is no mention of Haghighi et al (2008) "Learning Bilingual Lexicons from Monolingual Corpora.",	Review	O	0
which strikes me as a key piece of prior work regarding the use of CCA in learning bilingual alignment.	Review	B-Review	1
This paper and links to the work here ought to be discussed.	Review	O	0
[line_break_token]2) Likewise, Hermann & Blunsom (2013) "Multilingual distributed representations without word alignment."	Review	O	0
is probably the correct paper to cite for learning multilingual word embeddings from multilingual aligned data.	Review	B-Review	2
[line_break_token]3) It would have been nicer if experiments had been performed with more divergent language pairs rather than just European/Romance languages[line_break_token]4) A lot of the argumentation around the orthogonality requirements feels related to the idea of using a Mahalanobis distance / covar matrix to learn such mappings.	Review	O	0
This might be worth including in the discussion[line_break_token]5) I don't have a better suggestion, but is there an alternative to using the term "translation (performance/etc.)"	Review	O	0
when discussing word alignment across languages?	Review	B-Review	5
Translation implies something more complex than this in my mind.	Review	I-Review	5
[line_break_token]6) The Mikolov citation in the abstract is messed up	Review	O	0
We would like to thank you for your positive assessment of our work, and of the inverted softmax in particular.	Reply	O	0
[line_break_token][line_break_token]We have realised that our procedure, while very similar to CCA, is not identical.	Reply	O	0
We apologise for this mistake, which we have corrected in the new version.	Reply	O	0
We believe this realisation strengthens the manuscript.	Reply	O	0
We have included additional experiments, and a discussion of the very close relationship between the methods.	Reply	O	0
The two methods have very similar performance, but our approach is numerically cheaper.	Reply	O	0
[line_break_token][line_break_token] In response to your specific comments,[line_break_token][line_break_token]1.	Reply	O	0
[tab_token]We have now cited this work, and briefly discuss it in the text.	Reply	O	0
[line_break_token]2.	Reply	O	0
[tab_token]Similarly, this paper is now cited.	Reply	O	0
We still consider Chandar et al.	Reply	B-Reply	2
the first to obtain bilingual vectors from monolingual corpora and paired sentences, since Hermann and Blunsom cite an early version of Chandar‚Äôs work in their manuscript.	Reply	O	0
[line_break_token]3.	Reply	O	0
[tab_token]We hope to explore additional language pairs in future.	Reply	B-Reply	3
However, we believe that the range of tasks we consider in this manuscript, including a number of new tasks not considered in previous work, does provide a rigorous experimental evaluation.	Reply	I-Reply	3
These new tasks include the pseudo dictionary of identical strings, the phrase dictionary, and sentence retrieval between languages.	Reply	I-Reply	3
One of the goals of this work was to show that offline bilingual vectors can be used in a number of ways not previously considered in the literature.	Reply	I-Reply	3
[line_break_token]4.	Reply	O	0
[tab_token]This is a very interesting point.	Reply	O	0
The Mahalanobis distance is an alternative to the cosine similarity.	Reply	B-Reply	4
Although we do not discuss it in the manuscript, one could devise an alternative alignment procedure, which minimises the Mahalanobis distance of the dictionary rather than maximising the cosine similarity.	Reply	I-Reply	4
I suspect that this relates to the slight difference between our procedure and CCA; but we have been unable to find a reference which discusses this.	Reply	I-Reply	4
[line_break_token]5.	Reply	O	0
[tab_token]We do recognise your concern, but I‚Äôm afraid we couldn‚Äôt come up with an appropriate alternative to ‚Äútranslation‚Äù.	Reply	O	0
[line_break_token]6.	Reply	O	0
[tab_token]We fixed this.	Reply	B-Reply	6

The submission describes a system for applying machine learning to interactive theorem proving.	Review	O	0
The paper focuses on two tasks: tactic prediction (e.g. attempting a proof by induction) and position evaluation (the number of  remaining steps required for a proof).	Review	O	0
Experiments show that a neural model outperforms an SVM on both tasks, using proof states sampled from a proof of the Feit-Thompson theorem as a dataset.	Review	O	0
It's great to see work on applying neural networks to symbolic reasoning.	Review	O	0
The paper is clearly written, and provides helpful background on interactive theorem proving.	Review	O	0
[line_break_token][line_break_token]The main weakness of the paper is the limited experiments, which only really show that neural methods outperform an SVM (with only a high level description of the features) - and only on the proof of a single theorem.	Review	B-Review	1
The paper doesn't explore relevant interesting questions, such as whether the model is helpful for guiding humans or machines in making proofs, or perhaps if the approach can be used to find more human-understandable proofs than those found without training on human data.	Review	I-Review	2
What are the trade-offs in learning from human proofs instead of automated proofs?	Review	I-Review	2
[line_break_token][line_break_token]Overall, the paper explores an interesting direction, but I think the current experiments are too preliminary for acceptance.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
Reviewer 3, [line_break_token][line_break_token]Thank you for your review.	Reply	O	0
Your score is currently the outlier amongst the reviews, which is fine!	Reply	O	0
However, given the substance of the other reviews, the author response below, and the revisions made to the paper, it would be good to get a bit more detail from you.	Reply	O	0
Could you please read the author response and other reviews, as well as revisions made to the paper, and either consider revising your assessment or providing an explanation as to why you stand by your score?	Reply	O	0
[line_break_token][line_break_token]There are a few days left for you to engage in discussion with the authors and fellow reviewers, so you may wish to do that first	Reply	O	0

The paper proposes an imitation learning algorithm that learns from state-only demonstrations and assumes partial knowledge of the transition dynamics.	Review	O	0
The demonstrated states are decomposed into "responsive" and "unresponsive" features.	Review	O	0
The imitation policy is trained in an environment where the responsive state features are simulated and controllable by the agent, and the unresponsive state features are replayed from the demonstrations.	Review	O	0
The agent is rewarded for tracking the responsive state features in the demonstrations.	Review	O	0
[line_break_token][line_break_token]Overall, I was confused by this paper.	Review	B-Review	1
Isn't it problematic that the imitation agent is trained in an environment where unresponsive state features from the demonstrations are replayed and not affected by the agent's actions?	Review	I-Review	1
It would be nice to expand Section 4 to explain why it makes sense to reflect the unresponsive component in the transition kernel.	Review	I-Review	5
It would also be helpful to include some of this information in Section 1.	Review	I-Review	5
[line_break_token][line_break_token]I am also confused by the method.	Review	I-Review	2
What is the purpose of observing unresponsive features, if the reward function for the imitation agent is only defined in terms of the responsive features?	Review	I-Review	2
Is it that the imitation policy is conditioned on the unresponsive features?	Review	I-Review	6
[line_break_token][line_break_token]There are several important experimental details missing from Sections 4 and 6.	Review	I-Review	3
What distance metric was used to define the reward function?	Review	I-Review	3
For example, was it Euclidean distance in pixel space for the Atari games?	Review	I-Review	3
The main experimental results in Figure 2 are difficult to interpret without knowing the how the reward function is defined in the eMDP.	Review	I-Review	3
Could the authors either provide definitions of the reward functions of the eMDPs in the experiments, or measure performance of the imitation agents using more interpretable or standardized metrics (e.g., game score) for the chosen environments?	Review	I-Review	3
[line_break_token][line_break_token]It is also concerning that the Google Drive links to code and supplementary materials aren't anonymized.	Review	I-Review	4
e thank the reviewer for his important comments and apologies for the issue with the link anonymization.	Reply	O	0
Below is our response to the issues raised.	Reply	O	0
[line_break_token][line_break_token]‚Ä¢[tab_token]Q: Isn't it problematic that the imitation agent is trained in an environment where unresponsive state features from the demonstrations are replayed and not affected by the agent's actions?	Reply	O	0
[line_break_token]‚Ä¢[tab_token]A: Yes.	Reply	O	0
Ideally, you would like to use a ‚Äúfull‚Äù simulation to eliminate the problem.	Reply	B-Reply	1
However, most real-world problems do not have a simulator yet.	Reply	I-Reply	1
Our experiments show that even partial interaction of the agent with the environment is better than zero interaction that happens with simulation free methods such as BC.	Reply	I-Reply	1
Moreover, our transition kernel becomes less biased as the agent improves.	Reply	I-Reply	1
[line_break_token][line_break_token]‚Ä¢[tab_token]Q: It would be nice to expand Section 4 to explain why it makes sense to reflect the unresponsive component in the transition kernel.	Reply	O	0
[line_break_token]‚Ä¢[tab_token]A: Yes, we agree.	Reply	O	0
The reflection operator is the transition kernel of BC where the prediction of the agent on a state does not affect the next state.	Reply	B-Reply	5
The eMDP model bridges between BC and contemporary imitation methods by using the BC kernel for features we cant simulate, and the responsive kernel for features we can simulate.	Reply	I-Reply	5
As stated before, the reflection operator also possesses the nice property of being unbiased when pi=pi_E and it requires zero calculations, thus dramatically accelerating training time.	Reply	I-Reply	5
[line_break_token][line_break_token]‚Ä¢[tab_token]Q: What is the purpose of observing unresponsive features, if the reward function for the imitation agent is only defined in terms of the responsive features?	Reply	O	0
[line_break_token]‚Ä¢[tab_token]A: The reward is defined over a) s_r: the responsive features of the agent which are observed in the state space, and b) s_{r,e}: the responsive features of the expert which are unobserved.	Reply	O	0
How can the agent maximize the reward if it depends on unobserved features?	Reply	B-Reply	2
It does so by observing s_u: the unresponsive features, which define (or at least have high mutual information with) s_{r,e}.[line_break_token][line_break_token]‚Ä¢[tab_token]Q: Is it that the imitation policy is conditioned on the unresponsive features?	Reply	O	0
[line_break_token]‚Ä¢[tab_token]A: Yes, of course, the unresponsive features are a part of the state space and the agent and expert share the same state space.	Reply	O	0
Think of Pong for example where the unresponsive features represent the opponent racket and the ball.	Reply	B-Reply	6
The agent can't take actions without having this info.	Reply	I-Reply	6
[line_break_token][line_break_token]‚Ä¢[tab_token]Q: What distance metric was used to define the reward function?	Reply	O	0
[line_break_token]‚Ä¢[tab_token]A: We report the reward defined in Eq.5 (the optimization problem we wish to solve).	Reply	O	0
In words, the reward is a Dirac delta function on the event s_r=s_{r,e}. It is the most restrictive form of similarity and requires zero prior knowledge.	Reply	B-Reply	3
Calculating it requires extracting s_r and s_{r,e} at each step as explained in section 4.	Reply	I-Reply	3
In the Atari games, we do the extraction manually from frame pixels.	Reply	I-Reply	3
However, with access to the game‚Äôs ROM, this can be done much easier.	Reply	I-Reply	3

The paper proposes a set of rules for the design and initialization of well-conditioned neural networks by naturally balancing the diagonal blocks of the Hessian at the start of training.	Review	O	0
Overall, the paper is well written and clear in comparison and explanation.	Review	O	0
However, the reviewer is concerned with the following questions:[line_break_token]Assumption A2 does not make sense in the context.	Review	O	0
In particular, it is not praised to assume it only for the convenience of computation without giving any example when the assumption would hold.	Review	B-Review	1
Also the assumptions are vague and hard to understand, it is better to have concrete mathematical formulation after text description.	Review	I-Review	1
[line_break_token]Are the experiment results sensitive to the choice of different models with different width and layers or different batch sizes?	Review	I-Review	2
Does it have a strong improvement than random initialization?	Review	I-Review	2
It‚Äôs less clear the necessity of guaranteeing well-conditioned at initialization since during the training procedure, the condition number is harder to control.	Review	I-Review	2
[line_break_token]	Review	O	0
hank you for taking the time to review our work.	Reply	O	0
We provide the following replies:[line_break_token][line_break_token]-Our results are quite robust, note that the input and output dimensionality varies across the 27 datasets we compare on, resulting in different layer widths at the beginning and end of the network for every dataset.	Reply	O	0
In addition, the AlexNet we test on has a very different architecture from the other experiments.	Reply	B-Reply	2
[line_break_token][line_break_token]- Thank you for the feedback about assumption A2.	Reply	O	0
Some assumption is needed to control the behavior at the top of the network.	Reply	B-Reply	1
Note that we are talking about the network at initialization, a situation where the assumption is mild.	Reply	I-Reply	1
[line_break_token][line_break_token]Given the extensive theory that results from this simple assumption we believe it is interesting in any case.	Reply	I-Reply	1
In general, developing assumptions that result in fruitful and simple analysis is one of the primary goals of theory, and should not be seen as a weakness.	Reply	I-Reply	1
[line_break_token]We are looking to provide a theory that handles more general cases in future work.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]We hope that Reviewer #3 reconsiders their assessment given the context from other reviewers and our replies above.	Reply	O	0
[line_break_token]	Reply	O	0

This paper attempts to tackle transfer learning and lifelong learning problem by subscribing to knowledge via channel pooling.	Review	O	0
The channel pooling is actually selecting the subsect of the feature map according to the way that prediction accuracy from the delta model can be maximized.	Review	O	0
Experiments show effectiveness of the proposed method.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]Overall, this paper is well written and easy to follow.	Review	O	0
The technique is sound and the problem studied in this paper is significant.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
[tab_token]I do not think that the model proposed in this paper is able to tackle lifelong learning problem.	Review	O	0
The main reason is that lifelong learning basically requires only one model that will continue to learn from new tasks.	Review	B-Review	1
After learning several new tasks, people hope this model can still perform well on the previous tasks as well as the current ones.	Review	I-Review	1
However, in this paper, not only one model is learned.	Review	I-Review	1
Instead, new models appear when new tasks are given, which does not meet the definition or requirement of lifelong learning.	Review	I-Review	1
It only meets the requirement of transfer learning.	Review	I-Review	1
The experimental results also validate my opinion since only one new task is given while in lifelong learning, continuous new tasks will come and the original model should perform well on all of them as well as on the old tasks.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	3
[tab_token]In Figure 4, the legend in the first picture will confuse the readers.	Review	I-Review	2
I suggest the authors put it outside all the figures.	Review	I-Review	2
Besides, the proposed method in the last picture is not the best.	Review	I-Review	2
What do the authors want to convey by this picture?	Review	I-Review	2
[line_break_token][line_break_token]	Review	O	0
C1.	Reply	O	0
We appreciate your comments on SNOW regarding the number of models.	Reply	B-Reply	1
One might assume that SNOW consists of multiple models as it has the source model and the ‚Äúdelta‚Äù models.	Reply	I-Reply	1
But, the term ‚Äúdelta model‚Äù is used for an easier explanation about the expanded parts in the SNOW architecture.	Reply	I-Reply	1
We argue that the entire architecture based on SNOW can be regarded as a single model (which just consists of various modules to deliver multi-task predictions) because a delta model alone is not semantically sufficient for an intended task when there already exists transferability from the source task to the target task.	Reply	I-Reply	1
In fact, the delta and source models must efficiently cooperate as a single-engine to perform target tasks effectively (which is the key difference from a collection of models such as ensemble learning), which is the main contribution in this work.	Reply	I-Reply	1
[line_break_token] [line_break_token]Expanding a single model as in SNOW is becoming a popular approach to address catastrophic forgetting in lifelong learning.	Reply	I-Reply	1
For example, ProgressiveNet (Rusu, 2016) in our experiment can be considered as a single model even though the entire layer pipelines are duplicated for each new task as an expansion.	Reply	I-Reply	1
Other various kinds of expansions have been published in major venues recently for lifelong learning, and we here provide a list of the latest representative publications with short summaries.	Reply	I-Reply	1
[line_break_token] [line_break_token]-Lifelong Learning with Dynamically Expandable Networks [ICLR18][line_break_token]The authors considered lifelong learning simply as a special case of online or incremental learning, in the case of deep neural networks.	Reply	I-Reply	1
The proposed approach in this paper is to partially expand the model capacity with new tasks.	Reply	I-Reply	1
[line_break_token] [line_break_token]-Autonomous Deep Learning: Continual learning approach for dynamic environments [ICDM19][line_break_token]A fully elastic deep neural network (DNN), namely Autonomous Deep Learning (ADL) is proposed where the new hidden layers can be dynamically added under the lifelong learning paradigm.	Reply	I-Reply	1
[line_break_token] [line_break_token]-Scalable Recollections for Continual Lifelong Learning [AAAI19][line_break_token]A small auto-encoder per new task is attached for the experience replay purpose for multi-task lifelong learning (instead of episodic memories).	Reply	I-Reply	1
[line_break_token] [line_break_token]-Continual Palmprint Recognition Without Forgetting [ICIP19][line_break_token]This paper proposes to use reinforcement learning to dynamically expand the neural network when facing newly registered palmprints.	Reply	I-Reply	1
[line_break_token] [line_break_token]-Lifelong Learning Starting from Zero [ICAGI19][line_break_token]This work proposes to add new nodes/neurons for expansion (which adds new nodes to memorize new input combinations) and generalization (which adds new nodes that generalize from existing ones).	Reply	I-Reply	1
[line_break_token] [line_break_token]C2.	Reply	O	0
Thanks for suggestions.	Reply	O	0
We tried to place the legend outside the figures, but the space limitation makes it very hard.	Reply	B-Reply	2
As an alternative solution to prevent any confusion on the readers, we overlay the legend over a gray bounding box which increases the readability as well.	Reply	I-Reply	2
Hope this would work for you and future readers.	Reply	I-Reply	2
[line_break_token]The purpose of the last picture in Fig.	Reply	I-Reply	2
4 is to show that SNOW requires a similar number of epochs for convergence as well.	Reply	I-Reply	2
In the end, what matters most in practice is the wall-clock runtime which is num_epochs X total_samples/throughput.	Reply	I-Reply	2
In some cases, it is possible that a certain approach may have a better throughput but require more epochs for convergence, eventually netting a longer end2end training time.	Reply	I-Reply	2
Here, with the pictures in Fig.	Reply	I-Reply	2
4, we showed that the total training time of SNOW will be superior to PN, FT, MP, because of the same epoch count for convergence (after 60 epochs) and higher throughput.	Reply	I-Reply	2
Note that we simply let all the algorithms run for 200 epochs to ensure that nothing is left for any algorithm.	Reply	I-Reply	2
We have made this point clear in the revision (the last paragraph in Section 3.1)	Reply	I-Reply	2

Summary:[line_break_token]This paper addresses the challenging problem of how to speed up the training of GANs without using large mini-batch sizes and causing significant performance drop.	Review	O	0
To achieve this, the authors propose to use the method of core-sets, mainly inspired by recent use of core-set selection in active learning.	Review	O	0
The proposed method allows us to generate effectively large mini-batches though actually small during the training process, or more concretely, drawing a large batch of samples from the prior and then compress that batch using core-set selection.	Review	O	0
To address the curse of dimensionality issue for high-dimensional data like images, the authors suggest using a low-dimensional embedding based on Inception activations of each training image.	Review	O	0
Regarding the experimental evaluation, it is clearly shown that the proposed core-set selection greatly improves GAN training in terms of timing and memory usage, and allows significantly reducing mode collapse on a synthetic dataset.	Review	O	0
As a by-product, it is successfully applied to anomaly detection and achieves state-of-the-art results.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]The paper is generally well written and clearly presented.	Review	O	0
 As mentioned in the text, the use of core-sets is not novel in machine learning, but unfortunately not yet sufficiently explored in deep learning, and there are still few useful tools available in the literature.	Review	O	0
I believe this work will have a positive impact on the community and especially help establishing more efficient methods for training GANs.	Review	O	0
[line_break_token][line_break_token]Weaknesses:[line_break_token]- Experimental results are indeed very promising, however, GAN implementation details and hyperparameters used for training, such as optimizer and learning rate, do not seem to be mentioned in the text.	Review	O	0
I think this would be helpful for readers to better understand how this all works.	Review	B-Review	1
[line_break_token]- There does not seem to be any discussion on the convergence and stability of GAN training, which should be clarified in the experimental section.	Review	O	0
[line_break_token]- On page 3, in Sect.	Review	O	0
3.2,  I find ‚Äúrandom low dimensional projections of the Inception Embeddings‚Äù is not clear, more technical details should be provided.	Review	B-Review	1
hank you for the review!	Reply	O	0
[line_break_token][line_break_token]We have added details about the experiments, and the hyperparameters used, as well as clarified some details in the text, as suggested by the review.	Reply	B-Reply	1
We have fixed expanded on what we mean by "random low dimensional projections", and how we do that in practice.	Reply	I-Reply	1
We also added results with the ImageNet dataset in the draft	Reply	I-Reply	1

Summary:[line_break_token]This paper proposed a method to generate universal adversarial perturbations without training data.	Review	O	0
This task is timely and practical.	Review	O	0
The proposed method maximizes the norm of the output before nonlinearity at any layer to craft the universal perturbation.	Review	O	0
A sequential dilation algorithm is designed to calculate UAPs.	Review	O	0
The experiments show that the proposed method outperforms GDUAP.	Review	O	0
[line_break_token][line_break_token]My major concern is that there is not much novelty in the proposed method compared with GDUAP.	Review	O	0
The dilate loss function (4) is similar to the objective function (3) in the GDUAP paper.	Review	O	0
This paper provides a theoretical explanation of the dilate loss function and an improvement on the non-linearity function, which, however, is not convincing.	Review	O	0
Equation 10 is derived based on many strong assumptions.	Review	O	0
See the comments below.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]-[tab_token]The theoretical analysis is clear.	Review	O	0
[line_break_token]-[tab_token]The proposed method performs better than GDUAP in the data-free and black-box setting.	Review	O	0
[line_break_token]-[tab_token]The writing is good.	Review	O	0
The paper is easy to follow.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]-[tab_token]The theoretical analysis is based on many strong assumptions/criteria.	Review	O	0
For example:[line_break_token]o[tab_token]To derive equation (5), W1X and W1p must be in the same orthant.	Review	B-Review	1
It is unclear how to satisfy the criteria In the algorithm.	Review	I-Review	1
[line_break_token]o[tab_token]In Lemma 1, problem (5) approximates problem (6) only if x has a very large projection on the first singular vector of W. However, x and W are fixed and independent of p. This assumption largely depends on the dataset and the weights of the model.	Review	O	0
[line_break_token]o[tab_token]It would be better if the authors show that in what cases these assumptions can be satisfied.	Review	B-Review	6
[line_break_token]-[tab_token]Other factors such as batch normalization and max pooling used in Inception v3, may also affect the linearity of the model.	Review	O	0
It would be better if the authors provide theoretical analysis or an ablation study on these factors.	Review	B-Review	2
[line_break_token]-[tab_token]What‚Äôs the design principle behind Algorithm 1?	Review	O	0
Why can this algorithm solve the sub-optimal problem?	Review	B-Review	3
The weights of different layers are not closely related.	Review	I-Review	3
In the initialization part, why can we start learning p from the result of the previous layer?	Review	I-Review	3
Would it be possible that the performance is improved due to the algorithm instead of the dilate loss?	Review	I-Review	3
[line_break_token]-[tab_token]The proposed method performs worse than GDUAP does in some less data settings.	Review	O	0
[line_break_token]-[tab_token]The results in Table 4 and 5 are inconsistent.	Review	O	0
These two experiments use the same dataset (Imagenet) and the same number of images (D=64).	Review	B-Review	5
[line_break_token][line_break_token]	Review	O	0
e thank the Reviewer for the valuable feedback.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	6
Reg.	Reply	I-Reply	1
Equation (5): To derive equation (5), we do not require to be in the same orthant as column vectors of.	Reply	I-Reply	1
In fact, such a almost never exists.	Reply	I-Reply	1
Hence, our approach is to find a that can minimize the error due to the additive approximation of ReLU ).	Reply	I-Reply	1
We linearly relax this criteria and search for a that can bring as close to all the column vectors of.	Reply	I-Reply	1
This is realized through optimization (5) by maximizing the inner product of with all the column vectors of.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Assumption for Lemma 1: Since our method is data-free, there must be an assumption tying data to the learned weights of the network.	Reply	B-Reply	6
We assume that the singular vectors of the weights must have captured the discriminatory modes of data samples while training.	Reply	I-Reply	6
This means that the first singular vector carries the most important features common to most of the data points than the other singular vectors, which translates to the assumption for Lemma 1.	Reply	I-Reply	6
This assumption seems to be required for explaining the high fooling rate our method obtains.	Reply	I-Reply	6
[line_break_token][line_break_token]3.	Reply	O	0
Other nonlinearities in the network: Currently, our theoretical explanation is limited to ReLU nonlinearity, which itself seems sufficient to reason out the high fooling performance.	Reply	B-Reply	2
The effect of other kinds of nonlinearities needs to be studied in future works.	Reply	I-Reply	2
[line_break_token][line_break_token]4.	Reply	O	0
Design of Algorithm 1: Algorithm 1 is designed from problem (10), where it is implemented as a set of sequential optimizations.	Reply	B-Reply	3
We have an ablation in Table 2 with the header 'Ours without accumulation', where we optimize without the 'dilate' loss exactly like as the Reviewer mentioned.	Reply	I-Reply	3
The results clearly evidence the performance boost with the 'dilate' loss.	Reply	I-Reply	3
[line_break_token][line_break_token]5.	Reply	O	0
Results in less data cases: For VGG19 and Inception v1, with more data there is a slight dip in fooling rate.	Reply	B-Reply	4
This seems to be something specific to the networks, but for majority cases the proposed approach beats GDUAP.	Reply	I-Reply	4
[line_break_token][line_break_token]6.	Reply	O	0
Results in Table 4 and 5: For Table 4 experiments, a validation set is used to select the best perturbation.	Reply	B-Reply	5
But in Table 5, in order to compare with Singular Fool method, we do not employ a validation set as mentioned in the text.	Reply	I-Reply	5
The slight difference in fooling rate is due to this fact	Reply	I-Reply	5

This paper proposes guided adaptive credit assignment (GACA) for policy gradient methods with sparse reward.	Review	O	0
[line_break_token][line_break_token]GACA attacks the credit assignment problem by[line_break_token]1) using entropy regularized RL objective (KL divergence), iteratively update prior \bar{\pi} and \pi_\theta;[line_break_token]2) generalizing KL to f-divergence to avoid mode seeking behaviour of KL;[line_break_token]3) using 2 tricks to estimate the gradient of f-divergence to update \pi_\theta, a) modified MAPO (Liang et al.,	Review	O	0
2018) estimator (using two buffers), b) replacing rho_f by the inverse of tail probability (Wang et al.,	Review	O	0
2018).	Review	O	0
[line_break_token][line_break_token]Experiments of program synthesis and instruction following are conducted, to show the proposed GACA outperform competitive baselines.	Review	O	0
[line_break_token][line_break_token]Although the experimental results look promising, I have many concerns with respect to this paper as follows.	Review	O	0
[line_break_token][line_break_token]1.	Review	B-Review	2
The organization is bad.	Review	I-Review	1
The main algorithm has been put into the appendix.	Review	I-Review	1
It should appear in the paper.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	2
There are too many typos and errors in the paper and derivations, which quite affected reading and understanding.	Review	I-Review	2
[line_break_token]For example:[line_break_token]in Eq. (	Review	I-Review	2
6), what is z \sim Z?	Review	I-Review	2
Should be z \in Z?	Review	I-Review	2
It also appears in many other places.	Review	I-Review	2
[line_break_token]in Eq. (	Review	I-Review	2
7), there should not be \sum_{z \in Z} here.	Review	I-Review	2
[line_break_token]Proof for Prop.	Review	I-Review	2
1, I cannot really understand the notations here.	Review	I-Review	2
Please rewrite and explain this proof. (	Review	I-Review	2
I can see it follows Grau-Moya et al.,	Review	I-Review	2
2019, but the notations here are not clear.)	Review	I-Review	2
[line_break_token]in Eq. (	Review	I-Review	2
11), \bar{\pi} / \pi_\theta is used, but in Eq. (	Review	I-Review	2
12), \pi_\theta / \bar{\pi} appeared, which one is correct?	Review	I-Review	2
While in the proof for Lemma 2, it is \bar{\pi} / \pi_\theta.	Review	I-Review	2
And in Alg.	Review	I-Review	2
1 it is \pi_\theta / \bar{\pi}. Please make this consistent.	Review	I-Review	2
[line_break_token]Typos, like "Combining Theorem 1 and Theorem 2 together, we summarize the main algorithm in Algorithm 1."	Review	I-Review	2
in the last paragraph of p6.	Review	I-Review	2
However, they appeared as Prop.	Review	I-Review	2
1 and Lemma 2.	Review	I-Review	2
Please improve the writing.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
The mutual information argument Eq. (	Review	B-Review	6
9) seems irrelevant here. (	Review	I-Review	6
It follows Grau-Moya et al.,	Review	I-Review	6
2019, but the notations in the proof are bad and I cannot understand it).	Review	I-Review	6
Whether the solution is mutual information or not seems not helpful for getting better credit assignment.	Review	I-Review	6
I suggest remove/reduce related arguments around Eq. (	Review	I-Review	6
9) and (10), and make space for the main algorithm.	Review	I-Review	6
[line_break_token][line_break_token]4.	Review	O	0
The entropy regularized objective and the KL is kind of well known.	Review	B-Review	7
Maybe reduce the description here.	Review	I-Review	7
And the key point is Eq. (	Review	I-Review	7
8), which lays the foundation of iteratively update \bar{\pi} and \pi_\theta.	Review	I-Review	7
However, Eq. (	Review	I-Review	7
8) is the optimal solution of KL Eq. (	Review	I-Review	7
7).	Review	I-Review	7
Is it also the optimal solution of f-divergence used in the algorithm?	Review	I-Review	7
If it is, clearly show that.	Review	I-Review	7
If not, then update \bar{\pi} in Alg.	Review	I-Review	7
1 is problematic.	Review	I-Review	7
Please clarify this point.	Review	I-Review	7
[line_break_token][line_break_token]5.	Review	O	0
The 2 tricks used here for estimating the gradient of f-divergence with respect to \pi_\theta, i.e., modified MAPO estimator in Prop.	Review	O	0
2, and inverse tail probability in Wang et al.,	Review	O	0
2018, seems quite important for the empirical performance.	Review	O	0
[line_break_token]However, motivation is not clear enough.	Review	B-Review	4
First, why using two replay buffers "leads to a better approximation"?	Review	I-Review	4
Any theory/intuition or experiment to support this claim?	Review	I-Review	4
Second, why using inverse tail probability "achieve a trade-off between exploration and exploitation".	Review	I-Review	5
It seems not obvious to see that.	Review	I-Review	5
And also, explain why using this trick makes "\pi_\theta adaptively coverage and approximate prior distribution \bar{\pi}".	Review	I-Review	5
[line_break_token][line_break_token]6.	Review	I-Review	2
The claim that GACA recovers all the mentioned methods as special cases are questionable.	Review	I-Review	3
For example, as in E.1, "by simply choosing \rho_f as constant 1", comparing Eq. (	Review	I-Review	3
12) with the gradient of REINFORCE, there is a difference that REINFORCE has a reward term, but GACA does not have.	Review	I-Review	3
Then why GACA reduces to REINFORCE?	Review	I-Review	3
Also in E.5, the RAML objective seems wrong.	Review	I-Review	3
There is no reward term here.	Review	I-Review	3
Please check them.	Review	I-Review	3
[line_break_token][line_break_token]Overall, the proposed GACA method achieves promising results in program synthesis tasks.	Review	O	0
However, there are many concerns with respect to motivation and techniques that should be resolved.	Review	O	0
[line_break_token][line_break_token]=====Update=====[line_break_token]Thanks for the rebuttal.	Review	O	0
I keep my rating since some of my concerns are still not resolved.	Review	O	0
In particular, "Eq. (	Review	B-Review	7
8) is the optimal solution of KL Eq. (	Review	I-Review	7
7).	Review	I-Review	7
Is it also the optimal solution of f-divergence used in the algorithm?"	Review	I-Review	7
Eq. (	Review	I-Review	2
8) looks not the same as the paragraph above Lemma 2 "\bar{\pi} = \pi_\theta" to me.	Review	I-Review	7
If Eq. (	Review	I-Review	7
8) is not the optimal solution of Eq. (	Review	I-Review	7
11), the update in Alg.	Review	I-Review	7
1 is somewhat problematic and other better choices exist.	Review	I-Review	7
Since Algorithm 1 explicitly uses f-divergence, I think at least this point should be clarified by the authors rather than my guess.	Review	I-Review	7
hank you for your time and detailed feedback.	Reply	O	0
[line_break_token]We are happy to hear you found this work valuable, and understand your concerns.	Reply	O	0
We are confident that, following the points of clarification highlighted by you, we can resolve any ambiguities in the paper, and thank you for helping make the paper stronger as a result.	Reply	O	0
We answer most of the said points below.	Reply	O	0
It would be very helpful to hear your thoughts on our responses so that we can make the appropriate modifications to the paper.	Reply	O	0
[line_break_token]We hope that you will be willing to consider revising your assessment in light of the clarifications.	Reply	O	0
[line_break_token][line_break_token][line_break_token]1.	Reply	O	0
Typos in the paper, move algorithm to main paper, and other presentation suggestions[line_break_token][line_break_token][line_break_token]    Thanks for pointing out typos in the submission, we have moved the main algorithm from Appendix to main paper, adjust the organization, and improved the presentation of the paper a lot.	Reply	O	0
The updated version of the paper is available now.	Reply	B-Reply	2
Again, thank you for reading the paper.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
Why using two replay buffers "leads to a better approximation"[line_break_token][line_break_token][line_break_token]    We acknowledge that this sentence is a little bit confusing.	Reply	O	0
What we mean is GACA enables using both high-reward and zero-reward trajectories, which leads to a higher sample efficiency.	Reply	B-Reply	4
While previous methods either only reply on on-policy trajectories(e.g.	Reply	I-Reply	4
REINFORCE, MML, etc), or use a buffer to save high-reward trajectories for replaying(e.g.	Reply	I-Reply	4
MAPO).	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]4.	Reply	O	0
Motivations behind using inverse tail probability to approximate f-divergence [line_break_token][line_break_token][line_break_token]    By using f-divergence, we reveal the connections between various previous credit assignment methods, for example, IML and RAML both minimize a reverse KL-divergence between policy and a target distribution, MAPO minimizes KL-divergence, etc.	Reply	O	0
Different divergence measures lead to a different approximation of policy to target distribution[1], for example, KL-divergence often leads to mode-collapse.	Reply	B-Reply	5
We want the policy distribution to approximate/cover the target distribution as good as possible, thus we utilize inverse tail probability technique which we found performs the best.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]    [1] Yingzhen Li, Richard E. Turner.	Reply	O	0
R√©nyi Divergence Variational Inference.	Reply	O	0
 Advances in Neural Information Processing Systems(NeurIPS), 2016.	Reply	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]5.	Reply	O	0
The claim that GACA recovers all the mentioned methods as special cases are questionable[line_break_token][line_break_token][line_break_token]    Your concern about REINFORCE and RAML as special cases of GACA can be resolved if you recall that for simplicity and without loss of generality, we assumed that reward is 1 for successful task completion trajectories and 0 otherwise, this follows the notations convenience in [1, 2]. In the meanwhile, we do take your suggestions on improving the presentation of the paper that we have updated Appendix E with improved presentation of how does GACA recover existing credit assignment methods.	Reply	O	0
Thank you for reading our Appendix.	Reply	B-Reply	3
[line_break_token][line_break_token][line_break_token]    [1] Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc Le, and Ni Lao.	Reply	O	0
Memory augmented policy optimization for program synthesis with generalization.	Reply	O	0
Advances in Neural Information Processing Systems(NeurIPS), 2018.	Reply	O	0
[line_break_token]    [line_break_token]    [2] Kelvin Guu, Panupong Pasupat, Evan Liu, and Percy Liang.	Reply	O	0
From language to programs: Bridging reinforcement learning and maximum marginal likelihood.	Reply	O	0
In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp.	Reply	O	0
1051‚Äì1062, Vancouver, Canada, July 2017	Reply	O	0

This paper proposes a method for estimating the context sensitivity of paraphrases and uses that to inform a word embedding learning model.	Review	O	0
The main idea and model are presented convincingly and seem plausible.	Review	O	0
The main weaknesses of the paper are shortcomings in the experimental evaluation and in the model exploration.	Review	O	0
The evaluation does not convincingly determine whether the model is a significant improvement over simpler methods (particularly those that do not require the paraphrase database!).	Review	B-Review	1
Likewise, the model section did not convince me that this was the most obvious model formulation to try.	Review	I-Review	1
The paper would be stronger if model choices were explained more convincingly or - better yet - alternatives were explored.	Review	I-Review	1
[line_break_token][line_break_token]On balance I lean towards rejecting the paper and encouraging the authors to submit a revised and improved version at a near point in the future.	Review	O	0
[line_break_token][line_break_token]Detailed/minor points below:[line_break_token][line_break_token]1) While the paper is grammatically mostly correct, it would benefit from revision with the help of a native English speaker.	Review	O	0
In its current form long sections are very difficult to understand due to the unconventional sentence structure.	Review	B-Review	2
[line_break_token]2) The tables need better and more descriptive labels.	Review	O	0
[line_break_token]3) The results are somewhat inconclusive.	Review	O	0
Particularly in the analogy task in Table 4 it is surprising that CBOW does better on the semantic aspect of the task than your embeddings which are specifically tailored to be good at this?	Review	B-Review	4
[line_break_token]4) Why was "Enriched CBOW" not included in the analogy task?	Review	O	0
[line_break_token]5) In the related work section several papers are mentioned that learn embeddings from a combination of lexica and corpora, yet it is repeatedly said that this was the first work of such a kind / that there hasn't been enough work on this.	Review	O	0
That feels a little misleading.	Review	B-Review	6
Hello.	Reply	O	0
Thank you again for your reviews.	Reply	O	0
[line_break_token][line_break_token]We have made some additional revisions as our final version before the decision.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We realized that the benchmarks are testing different aspects of the vectors.	Reply	O	0
We do not think the inconsistency for best parameters is an issue now.	Reply	O	0
We put the changes of the benchmark scores under different vector dimensions from section 3.2 to 3.3 as it is about the effect of vector dimensions.	Reply	O	0
We also revised the title of section 3.2 from "Issues about benchmarks" to "Benchmarks."	Reply	O	0
[line_break_token]2.	Reply	B-Reply	1
We used our proposed model instead of fastText to test the margin of errors for the benchmarks and revised section 3.2.	Reply	O	0
[line_break_token]3.	Reply	O	0
We also revised the discussion on the parameters and gave a more detailed discussion in section 3.	Reply	O	0
[line_break_token]4.	Reply	B-Reply	1
We revised the y labels in the figures to keep the same float format.	Reply	I-Reply	3
[line_break_token]5.	Reply	I-Reply	1
We add an explanation of the transpose mark for Equation (5) in section 2.4.	Reply	I-Reply	1
[line_break_token]6.	Reply	O	0
We add the missed introduction of Figure 2 in section 3.3.	Reply	O	0
[line_break_token]We recheck the misspellings and grammar mistakes.	Reply	B-Reply	2
[line_break_token][line_break_token]Thank you again for spending the time to read our papers and the helpful advice	Reply	O	0

The underlying problem considered in this manuscript is inferring depth from geometry of two dimensional images.	Review	O	0
The novelty here is to integrate a semantic classification model along with depth inference.	Review	O	0
It is a challenging problem and a neat idea to pursue.	Review	O	0
The paper is well-written and easy to follow.	Review	O	0
[line_break_token]However, the empirical work in the paper is not persuasive.	Review	B-Review	2
Table 1 contains results whose significance is hard to judge.	Review	I-Review	2
What does a RMSE difference of 2.3 mean in the context of depth estimation?	Review	I-Review	2
Table 1 carries no uncertainty in results which is just not acceptable in a setting that has several sources of uncertainty.	Review	I-Review	1
Similarly, Fig 4 shows there is advantage in the use of the pre-trained semantic network, it is not clear if this difference is significant.	Review	I-Review	1
And I also think consideration should be given to the fact that in a deployment setting, new objects not previously seen in the semantic categories (UFO) may appear and one ought to understand if the semantic network might decrease performance (because of the unseen class).	Review	I-Review	1
Hence I think which the idea advanced in the paper has merits, the manuscript is not really ready for publication.	Review	I-Review	1
 	Review	I-Review	1
Table 1 contains results whose significance is hard to judge.]	Reply	O	0
[line_break_token][line_break_token]We agree with the reviewer that the standard depth metrics (abs_rel, RMSE, a1, etc) used by the community [1,2,3] can be opaque, making it difficult to correlate a particular metric with performance on a downstream task.	Reply	B-Reply	2
To alleviate this, we propose in our work to also consider a class-specific evaluation, thus allowing further introspection into the performance of our model.	Reply	I-Reply	2
This enables us to see improvements in particular classes, that might be more relevant for particular downstream tasks (i.e. road for ground plane extraction, or cars/pedestrians for object detection).	Reply	I-Reply	2
[line_break_token]As for the metrics commonly used to evaluate depth performance, they are helpful in combination because they evaluate depth performance in different ways: Abs.	Reply	I-Reply	2
Rel (absolute relative error) and a1 (1.25 distance threshold) roughly measure the overall accuracy of depth estimates, while Sq.	Reply	I-Reply	2
Rel. (	Reply	I-Reply	2
square relative error) and RMSE (root mean squared error) focus on the variance of depth estimates, being particularly sensitive to outliers.	Reply	I-Reply	2
A typical year-over-year relative improvement on these metrics is around 5%, while our method improves by 11% over the previously published state of the art [3], and by 6% over the unpublished strong baseline [1]. Our significant improvements on Sq.	Reply	I-Reply	2
Rel.	Reply	I-Reply	2
and RMSE indicate that our proposed semantically-guided framework is particularly robust to appearance-related noise.	Reply	I-Reply	2
It  generalizes better to different object instances thanks to the introduction of semantic guiding information, where this domain gap is less apparent (i.e. all cars should be treated the same way, regardless of color).	Reply	I-Reply	2
This improvement in Sq.	Reply	I-Reply	2
Rel.	Reply	I-Reply	2
and RMSE can also be explained by the generation of sharper boundaries, as discussed in the paper (and shown in Figure 5), so there are fewer outliers that fall between two objects (a.k.a.	Reply	I-Reply	2
the "bleeding" effect).	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token][Table 1 carries no uncertainty in results.]	Reply	O	0
[line_break_token][line_break_token]We agree that, although our trained model is deterministic, there are sources of uncertainty in the proposed approach, as in all learning-based methods.	Reply	B-Reply	1
On Table 1, we did not report uncertainty estimates because that is not a common practice in depth evaluation.	Reply	I-Reply	1
That being said, we agree with the reviewer.	Reply	I-Reply	1
Therefore, we added in Appendix A a study of the main source of uncertainty tied to our major contribution: how different initializations of the semantic network affect the depth fine-tuning process, including semantic training with fewer labels, which results in worse semantic predictions.	Reply	I-Reply	1
These experiments show that our proposed framework is robust to the degradation in semantic predictions, which is in line with expectations since we are not using the final semantic predictions themselves, but only guiding our depth network with features from the decoder of the semantic network.	Reply	I-Reply	1
This is further illustrated in Appendix B, with examples of situations where the semantic network produces erroneous predictions but the semantically-guided depth network is still able to properly reconstruct objects.	Reply	I-Reply	1
This is an indication that the uncertainty encoded in the semantic features is considered within the depth network itself, which learns when semantic information should be used and when it should be discarded to optimize the self-supervised photometric loss.	Reply	I-Reply	1
[line_break_token]In addition, we plan to retrain our whole approach using multiple random seeds to evaluate the end-to-end variance of our method for the final version of the paper, as this takes a significant amount of computational resources and time (hence why no other related work we found does this in practice)	Reply	I-Reply	1

This is a clearly written paper with a nice, if straightforward, result: RNNs can be good predictive models of neuron firing rates in the retina.	Review	O	0
[line_break_token][line_break_token]On the one hand, the primary scientific contribution seems to just be to confirm that this approach works.	Review	B-Review	1
On this particular stimulus locked task the gains from using the RNN seemed relatively modest, and it hasn't yet taught us anything new about the biology.	Review	I-Review	1
[line_break_token][line_break_token]On the other hand, this (along with the concurrent work of McIntosh et al.)	Review	I-Review	2
is introducing neural network modeling to a field that isn't currently using it, and where it should prove very effective.	Review	I-Review	2
[line_break_token][line_break_token]I think it would be very interesting to see the results of applying a framework like this one with LFP and other neurons as input and on a shorter discretization time scale.	Review	I-Review	2
[line_break_token][line_break_token]I suspect followup work building on this proof of concept will be increasingly exciting.	Review	O	0
[line_break_token][line_break_token]Minor comments:[line_break_token]Sec 3.2:[line_break_token]I didn't understand the role of the 0.833 ms bins.	Review	O	0
[line_break_token]Use "epoch" throughout, rather than alternating between "epoch" and "pass through data".	Review	B-Review	4
[line_break_token][line_break_token]Fig.	Review	I-Review	5
4 would be better with the x-axis on a log scale.	Review	I-Review	5
Thanks for the review!	Reply	O	0
While it is possible that there is non-spiking, low-frequency information similar to the cortical LFP, this is not a measurement typically done in the retina, and due to technical reasons these signals are not recorded on our multielectrode array.	Reply	O	0
 As mentioned previously, we plan to incorporate correlations in future work, although doing so using coupling filters from spike trains of neighbouring neurons has not previously had a significant impact on predicting trial-averaged firing rates (Pillow2008, Heitman2016).The 0.833 ms bins were used because a post spike history filter operates on a small time scale so we divided the 8.33 ms bins corresponding to the frame rate by 10.	Reply	O	0
We need small bins for it to capture effects like the refractory period.	Reply	B-Reply	3

This paper seems to be an exposition on the primary performance affecting aspects of generative adversarial networks (GANs).	Review	O	0
 This can possibly affect our understanding of GANs, helping practitioners get the most in their applications, and perhaps leading to innovations that positively affect GAN performance.	Review	O	0
[line_break_token][line_break_token]Normally, expositions such as this I find difficult to recommend for publication.	Review	O	0
In these times, one can find "best practices" with a reasonable amount of rigor on data science blogs and such.	Review	O	0
An exposition that I would recommend for publication, would need to exhibit a high sense of depth and rigor for me to deem it publication worthy.	Review	O	0
This paper, for me, achieves this level of quality.	Review	O	0
[line_break_token][line_break_token]The authors start off by giving a precise, constrained list of hyperparameters and architectural components that they would explore.	Review	O	0
This is listed in the title and explained in detail in the beginning of the paper.	Review	O	0
The authors are right in explaining that they could not cover all hyperparameters and chose what I feel are quite salient ones.	Review	O	0
My one ask would have been a survey of how activations might affect performance.	Review	B-Review	1
I sense that everyone has settled upon LeakyReLUs for internal layers, but a survey of that work and experimentation within the authors' framework would have been nice.	Review	I-Review	1
[line_break_token][line_break_token]The authors then explain the metrics for evaluation and datasets.	Review	O	0
The datasets offered a healthy variety for typical image recognition tasks.	Review	O	0
It would be interesting to see what these metrics would reveal when applied to other types of data (e.g. scientific images).	Review	B-Review	2
[line_break_token][line_break_token]The  authors explain, with graphs, the results of the loss, normalization, and architectures.	Review	O	0
I feel the discussion on loss was rushed, and I gained no insight on what the authors thought was a prominent difference between the three losses studied.	Review	B-Review	3
Perhaps the authors had no salient observations for loss, but explicitly stating such would be useful to the reader.	Review	I-Review	3
The only observation I gained as far as this is that non-saturating loss would possibly be stable across various datasets.	Review	I-Review	3
[line_break_token][line_break_token]Regularization and normalization are discussed in much more detail, and I think the authors made helpful and interesting observations, such as the benefits of spectral normalization and the fact that batch normalization in the discriminator might be a harmful thing.	Review	O	0
These are good takeaways that could be useful to a vast number of GANs researchers.	Review	O	0
[line_break_token][line_break_token]For architectures to be a main pillar of the paper, I feel that this area could have been explored in greater detail.	Review	B-Review	4
I feel that this discussion devolved into a discussion, again, about normalization rather than the architectural differences in performance.	Review	I-Review	4
Unless I am misunderstanding something, it seems that the authors simply tested one more architecture, for the express purpose of testing whether their observations about normalization would hold.	Review	I-Review	4
[line_break_token][line_break_token]As a bonus, the authors bring up some problems they had in making comparisons and reproducing results.	Review	O	0
I think this is an extremely important discussion to have, and I am glad that the authors detailed the obstacles in their journey.	Review	O	0
Hopefully this will inspire other researchers to avoid adding to the complications in this field.	Review	O	0
[line_break_token][line_break_token]The graphs were difficult to parse.	Review	B-Review	5
I was able to make them out, but perhaps separating the top row (FID and diversity graphs) into separate figures, separate lines, or something would have reduced some confusion.	Review	I-Review	5
In addition, different charts presenting only one loss function, with their spectral normalization and gradient penalty variants, would have made the effects of the normalization more obvious on the FID distribution graphs.	Review	I-Review	5
If this can be changed before publication, I would strongly suggest it.	Review	I-Review	5
[line_break_token][line_break_token]I appreciate that the authors provided source code via GitHub.	Review	O	0
However, in the future, the authors should be careful to provide an anonymous repository for review purposes.	Review	B-Review	6
I had to be careful not to allow myself to focus on the author names which are prominent in the repository readme, and one of whom has his/her name in the GitHub URL itself.	Review	I-Review	6
I didn't immediately recognize the names and thus it was easy for me not to retain them or focus on them.	Review	I-Review	6
However, if it had been otherwise, it might have risked biasing the review.	Review	I-Review	6
[line_break_token][line_break_token]In all, I think this is a good and useful paper from which I have learned and to which I will refer in the future as I continue my research into GANs and VAEs.	Review	O	0
I would suggest changing the title to be more appropriate and accurate (the researchers are primarily focused on showing the positive and negative effects of normalization across various loss functions and architectures).	Review	B-Review	7
But altogether, I believe this is a paper worth publishing at ICLR.	Review	I-Review	7
[Q] My one ask would have been a survey of how activations might affect performance.	Reply	O	0
I sense that everyone has settled upon LeakyReLUs for internal layers, but a survey of that work and experimentation within the authors' framework would have been nice.	Reply	O	0
[line_break_token][A] We agree that this is an interesting question in it‚Äôs own right and should and will be explored more rigorously in future work.	Reply	O	0
At this point, it seems like the number of parameters and whether skip-connections are used is much more impactful.	Reply	B-Reply	1
[line_break_token][line_break_token][Q] It would be interesting to see what these metrics would reveal when applied to other types of data (e.g. scientific images).	Reply	O	0
[line_break_token][A] We are aware of several works in the area of scientific images, such as [1] and [2], where GANs were successfully applied on 2D image snapshots from N-body simulations.	Reply	O	0
The main issue for us at this point is having access to such data sets.	Reply	B-Reply	2
Nevertheless, as these data sets become available for public, we will happily include them within our framework and investigate whether the conclusions extend to data sets beyond natural images.	Reply	I-Reply	2
[line_break_token][1] <a href="https://arxiv.org/abs/1702.00403" target="_blank" rel="nofollow">https://arxiv.org/abs/1702.00403</a>[line_break_token][2] <a href="https://arxiv.org/abs/1801.09070" target="_blank" rel="nofollow">https://arxiv.org/abs/1801.09070</a>[line_break_token][line_break_token][Q] I feel the discussion on loss was rushed, and I gained no insight on what the authors thought was a prominent difference between the three losses studied.	Reply	O	0
[line_break_token][A] The theoretical differences between these losses were studied in detail in the corresponding publications.	Reply	O	0
From the practical side, it‚Äôs unclear which statistical divergence to optimize, in particular whether to pick (i) an f-divergence such as Chi-squared implemented by LS-GAN, or (ii) an integral probability metric such as Wasserstein distance, or (iii) a loss function which doesn‚Äôt correspond to any statistical divergence, such as NS-GAN.	Reply	B-Reply	3
Hence, we wanted to provide some insight on how do these perform within different setups, not necessarily the ones used in the original publications.	Reply	I-Reply	3
To this end we uncover that on the considered data sets it's hard to outperform the non-saturating loss combined with regularization and normalization.	Reply	I-Reply	3
Apart from this, the empirical evidence doesn‚Äôt allow us to say more and we will clarify this in the manuscript.	Reply	I-Reply	3
[line_break_token][line_break_token][Q] For architectures to be a main pillar of the paper, I feel that this area could have been explored in greater detail.	Reply	O	0
[line_break_token][A] We agree with this assessment and we are indeed focusing on regularization and normalization.	Reply	O	0
Our main question here was whether swapping Resnet with SNDCGAN leads to the same insights which is indeed the case.	Reply	B-Reply	4
On the other hand, architectures are such a rich area enabling various design choices that they possibly merit a paper on their own.	Reply	I-Reply	4
We will clarify the precise goal of the architecture exploration in this work.	Reply	I-Reply	4
This being said, one major question we wanted to understand is which Resnet tricks from the literature (all 7 of them) are meaningful in practice and we present an ablation in the Section D of the appendix to conclude that the only relevant one is the number of channels which makes sense as it drastically changes the number of trainable parameters.	Reply	I-Reply	4
[line_break_token][line_break_token][Q] The graphs were difficult to parse.	Reply	O	0
I was able to make them out, but perhaps separating the top row (FID and diversity graphs) into separate figures, separate lines, or something would have reduced some confusion.	Reply	O	0
In addition, different charts presenting only one loss function, with their spectral normalization and gradient penalty variants, would have made the effects of the normalization more obvious on the FID distribution graphs.	Reply	O	0
If this can be changed before publication, I would strongly suggest it.	Reply	O	0
[line_break_token][A] What we can do is to separate the top from the bottom figure into separate figures and provide more information in the captions.	Reply	O	0
Furthermore, in Figure 1, for the FID distribution plots, we can group the methods visually (according to the loss function) by drawing a slightly shaded rectangle around results with the same loss (e.g. <a href="https://goo.gl/6YeUL1)."	Reply	O	0
target="_blank" rel="nofollow">https://goo.gl/6YeUL1).</a> If you have a specific proposal we would be happy to consider it and update the submission.	Reply	O	0
[line_break_token][line_break_token][Q] In the future, the authors should be careful to provide an anonymous repository for review purposes.	Reply	O	0
[line_break_token][A] This is a good point and we will address this issue in the future.	Reply	O	0
[line_break_token][line_break_token][Q] I would suggest changing the title to be more appropriate and accurate (the researchers are primarily focused on showing the positive and negative effects of normalization across various loss functions and architectures).	Reply	O	0
[line_break_token][A] Given the architecture discussion stated above, this is a valid point.	Reply	O	0
Our current candidate is:[line_break_token]‚ÄúThe GAN Landscape: The effect of Regularization and Normalization across various Losses and Neural Architectures‚Äù.	Reply	B-Reply	7
However, if you have a specific proposal we would be happy to consider it	Reply	I-Reply	7

[REVISION][line_break_token]The work is thorough and some of my minor concerns have been addressed, so I am increasing my score to 6.	Review	O	0
I cannot go beyond because of the incremental nature of the work, and the very limited applicability of the used continual learning setup from this paper.	Review	B-Review	1
[line_break_token][line_break_token][OLD REVIEW][line_break_token]The paper proposes a novel, regularization based, approach to the sequential learning problem using a fixed size model.	Review	O	0
The main idea is to add extra terms to the loss encouraging representation sparsity and combating catastrophic forgetting.	Review	O	0
The approach fairs well compared to other regularization based approaches on MNIST and CIFAR-100 sequential learning variants.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]Thorough experiments, competitive baselines and informative ablation study.	Review	O	0
[line_break_token]Good performance on par or superior to baselines.	Review	O	0
[line_break_token]Clear paper, well written.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]The approach, while competitive in performance, does not seem to fix any significant issues with baseline methods.	Review	O	0
For example, task boundaries are still used, which limits applicability; in many scenarios which do have a continual learning problem there are no clear task boundaries, such as data distribution drift in both supervised and reinforcement learning.	Review	B-Review	1
[line_break_token]Since models used in the work are very different from SOTA models on those particular tasks, it is hard to determine from the paper how the proposed method influences these models.	Review	I-Review	2
In particular, it is not clear whether these changes to the loss would still allow top performance on regular classification tasks, e.g. CIFAR-10 or MNIST even without sequential learning, or in multitask learning settings.	Review	I-Review	2
[line_break_token][line_break_token]Summary:[line_break_token]Although the work is substantial and experiments are thorough, I have reservations about extrapolating from the results to settings which do have a continual learning problem.	Review	O	0
Although I am convinced results are slightly superior to baselines, and I appreciate the lengthy amount of work which went into proving that, the paper does not go sufficiently beyond previous work.	Review	O	0
[line_break_token]	Review	O	0
We thank AnonReviewer1 for their suggestions and comments.	Reply	O	0
[line_break_token]Note that we revised the paper, and renamed our full model to SLNID.	Reply	O	0
Below are our comments to the main points:[line_break_token][line_break_token]1) Task boundaries are still used, which limits applicability; in many scenarios which do have a continual learning problem there are no clear task boundaries, such as data distribution drift in both supervised and reinforcement learning.	Reply	O	0
[line_break_token][line_break_token] We agree with the reviewer on the importance of the mentioned setting where there are no clear task boundaries and distribution gradually drifts.	Reply	O	0
Although this is orthogonal to the contribution of this work, we tested a setup where the data distribution drifts between tasks.	Reply	B-Reply	1
When evaluating in this setting, we find, interestingly, that our proposed SNLID again works well in this setting compared to the LLL approach MAS (Aljundi et al.	Reply	I-Reply	1
,2017), which benefits from hard task boundaries.	Reply	I-Reply	1
Details can be found in the revised paper in Section 4.2 and Table 3.	Reply	I-Reply	1
We believe this is an interesting setting to study further in future work.	Reply	I-Reply	1
[line_break_token][line_break_token]2) Since models used in the work are very different from SOTA models on those particular tasks, it is hard to determine from the paper how the proposed method influences these models.	Reply	O	0
In particular, it is not clear whether these changes to the loss would still allow top performance on regular classification tasks, e.g. CIFAR-10 or MNIST even without sequential learning, or in multitask learning settings.	Reply	O	0
[line_break_token] Improving the state of the art results on non sequential scenarios is not the aim of this proposed regularizer.	Reply	O	0
Further, the studied setup of LLL where data from previous or future task is not available during the training of a given task is much harder and challenging than joint training or multi task training where all data is available at training time.	Reply	B-Reply	2
 In sec 4.2 Table 2 we compare against and outperform  state of the art LLL methods under the same setting and models used in those methods.	Reply	I-Reply	2
 	Reply	I-Reply	1

[Summary of paper] The paper presents a method for simulating spike trains from populations of neurons which match empirically measured multi-neuron recordings.	Review	O	0
They set up a Wasserstein-GAN and train it on both synthetic and real multi-neuron recordings, using data from the salamander retina.	Review	O	0
They find that their method (Spike-GAN) can produce spike trains that visually look like the original data, and which have low-order statistics (firing rates, correlations, time-lagged-correlations, total sum of population activity) which matches those of the original data.	Review	O	0
They emphasize that their network architecture is 'semi-convolutional', i.e. convolutional in time but not across neurons.	Review	O	0
Finally, they suggest a way to analyse the fitted networks in order to gain insights into what the 'relevant' neural features are, and illustrate it on synthetic data into which they embedded these features.	Review	O	0
[line_break_token][line_break_token][Originality] This paper falls into the category of papers that do a next obvious thing ("GANs have not been applied to population spike trains yet"), and which do it pretty well: If one wants to create simulated neural activity data which matches experimentally observed one, then this method indeed seems to do that.	Review	O	0
As far as I know, this would be the first peer-reviewed application of GANs to multi-neuron recordings of neural data (but see <a href="https://arxiv.org/abs/1707.04582" target="_blank" rel="nofollow">https://arxiv.org/abs/1707.04582</a> for an arxiv paper, not cited here-- should be discussed at least).	Review	O	0
 On a technical level, there is very little to no innovation here -- while the authors emphasise their 'semi-convolutional' network architecture, this is obviously the right architecture to use for multivariate time-series data, and in itself not a big technical novel.	Review	B-Review	16
Therefore, the paper should really be evaluate as an `application' paper, and be assessed in terms of i) how important the application is, ii) how clearly it is presented, and iii) how convincing the results are relative to state of the art.	Review	I-Review	16
[line_break_token][line_break_token]i) [Importance of problem, potential significance] Finding statistical models for modelling and simulating population spike trains is a topic which is extensively studied in computational neuroscience, predominantly using  model-based approaches using MaxEnt models, GLMs or latent variable models.	Review	O	0
These models are typically simple and restricted, and certainly fall short of capturing the full complexity of neural data.	Review	B-Review	1
Thus, better, and more flexible solutions for this problem would certainly be very welcome, and have an immediate impact in this community.	Review	I-Review	1
 However, I think that the approach based on GANs actually has two shortcomings which are not stated by the authors, and which possibly limit the impact of the method: First, statistical models of neural spike trains are often used to compute probabilities e.g. for decoding analyses‚Äî this is difficult or impossible for GANs.	Review	I-Review	1
Second, one most often does not want to simulate data which match a specific recording, but rather which have specified statistics (e.g. firing rates and correlations)‚Äî the method here is based on fitting a particular data-set, and it is actually unclear to me when that will be useful.	Review	I-Review	1
[line_break_token][line_break_token]ii) [Clarity] The methods are presented and explained clearly and cleanly.	Review	O	0
In my view, too much emphasis is given to highlighting the ‚Äòsemi-convolutional‚Äô network, and, conversely, practical issues (exact architectures, cost of training) should be explained more clearly, possibly in an appendix.	Review	B-Review	2
Similarly, the method would benefit from the authors releasing their code.	Review	I-Review	2
[line_break_token][line_break_token]iii) [Quality, advance over previous methods] The authors discuss several methods for simulating spike trains in the introduction.	Review	O	0
In their empirical comparisons, however, they completely focus on a particular model-class (maximum entropy models, ME) which they label being the ‚Äòstate-of-the-art‚Äô.	Review	B-Review	3
This label is misleading‚Äî ME models are but one of several approaches to modelling neural spike trains, with different models having different advantages and limitations (there is no benchmark which can be used to rank them...).	Review	I-Review	3
In particular, the only ‚Äògain‚Äô of the GAN over ME  models in the results comes from their ability of the GAN to match temporal statistics.	Review	I-Review	3
Given that the ME models used by the authors are blind to temporal correlations, this is, of course (and as pointed out by the authors) hardly surprising.	Review	I-Review	3
How does the GAN approach fair against alternative models which do take temporal statistics into account, e.g. GLMs, or simple moment-based method e.g. Krumin et al 2009, Lyamzin 2010, Gutnisky et al 2010‚Äî setting these up would be simple, and it would provide a non-trivial baseline for the ability of spike-GAN to outperform at least these models?	Review	I-Review	3
While it true that GANs are much more expressive than the model-based approaches used in neuroscience, a clear demonstration would have been useful.	Review	I-Review	3
[line_break_token][line_break_token]Minor comments: [line_break_token]  - p.3: The abbreviation ‚Äú1D-DCGAN‚Äù is never spelled out.	Review	O	0
[line_break_token]  - p.3: The architecture of Spike-GAN is never explicitely given.	Review	O	0
[line_break_token]  - p.3: (Sec.	Review	O	0
2.2) Statistic 2) ‚Äúaverage time course across activity patterns‚Äù is unclear to me -- how does one select the activity patterns over which to average?	Review	B-Review	6
Moreover, later figures do not seem to use this statistic.	Review	I-Review	6
[line_break_token]  - p.4: ‚Äúintroduced correlations between randomly selected pairs‚Äù -- How many such pairs were formed?	Review	O	0
[line_break_token]  - p.7 (just above Discussion) At the beginning of this section, and for Figs.	Review	O	0
4A,B, the texts suggests that packets fire spontaneously with a given probability.	Review	B-Review	8
For Figs.	Review	I-Review	8
4C-E, a particular packet responds to a particular input.	Review	I-Review	8
Is then the neuron population used in these figures different from the one in Figs.	Review	I-Review	8
4A,B?	Review	I-Review	8
How did the authors ensure that a particular set of neurons respond to their stimulus as a packet?	Review	I-Review	8
What stimulus did they use?	Review	I-Review	8
[line_break_token]  - p.8 (Fig.	Review	O	0
4E) Are the eight neurons with higher importance those corresponding to the packet?	Review	B-Review	9
This is insinuated but not stated.	Review	I-Review	9
[line_break_token]  - p.12 (Appendix A) [line_break_token]    + The authors do not mention how they produced their ‚Äúground truth‚Äù data. (	Review	O	0
What was its firing rate?	Review	B-Review	11
Did it include correlations?	Review	I-Review	11
A refractory period?)	Review	I-Review	11
[line_break_token]    + Generating samples from the trained Spike-GAN is ostensibly cheap.	Review	O	0
Hence it is unclear why the authors did not  produce a large enough number of samples in order to obtain a 'numerical probability', just as they did for the ground truth data?	Review	B-Review	12
[line_break_token]    + Fig.	Review	O	0
S1B: The figure shows that every sample has the same empirical frequency.	Review	B-Review	13
This indicates more a lack of statistical power rather than any correspondence between the theoretical and empirical probabilities.	Review	I-Review	13
This undermines the argument in the second paragraph of p.12.	Review	I-Review	13
In the other hand, if the authors did approximate numerical probabilities for the Spike-GAN, this argument would no longer be required.	Review	I-Review	13
[line_break_token]  - p.13 Fig.	Review	O	0
S1A,B: the abscissas mention ‚Äúfrequency‚Äù, while the ordinates mention ‚Äúprobability‚Äù[line_break_token]  - p.25 Fig.	Review	O	0
S4: This figure suggests that the first layer of the Spike-GAN critic sometimes recognizes the packet patterns in the data.	Review	B-Review	15
However, to know whether this is true, we would need to compare this to a representation of the neurons reordered in the same way and identified by packet.	Review	I-Review	15
I.e. one expects something something like figure like Fig.	Review	I-Review	15
4A, with the packets lining up with the recovered filters when neurons are ordered the same way.	Review	I-Review	15
[line_break_token]	Review	O	0
Thank you very much for your comments and suggestions.	Reply	O	0
We have tried to address them in the revised manuscript (see also reply to reviewers 1 and 2).	Reply	O	0
Briefly: [line_break_token][line_break_token]We have removed the reference to the ‚Äòsemi-convolutional‚Äô architecture from the tittle and abstract and only mention it in the methods (Section 2.1, second paragraph, last four lines; see also reply to reviewer 1).	Reply	O	0
[line_break_token][line_break_token]We thank you for the reference Arakaki et al.	Reply	B-Reply	3
We now mention it in the Discussion section (second paragraph).	Reply	I-Reply	3
[line_break_token][line_break_token]We have modified Fig.	Reply	I-Reply	5
1 in order to provide all details about the architecture of Spike-GAN.	Reply	I-Reply	5
[line_break_token][line_break_token]We have now compared Spike-GAN with a method that does take into account temporal statistics (Lyamzin et al.	Reply	I-Reply	15
2010) (Section 3.2).	Reply	I-Reply	15
We show in Fig.	Reply	I-Reply	15
3 that this method fits very well the statistics of the retinal data.	Reply	I-Reply	15
However, as the authors mention in their paper, it struggles to fit negative correlations as the ones shown in Fig.	Reply	I-Reply	15
1 (panel F) that are due to the refractory period (Fig.	Reply	I-Reply	15
S6).	Reply	I-Reply	15
This would constitute an important shortcoming if e.g. one wants to fit the activity of a neural population including inhibitory neurons, which will be most likely anti-correlated with other neurons.	Reply	I-Reply	15
[line_break_token][line_break_token]We now comment in the Discussion section (last paragraph) the pros and cons of Spike-GAN in comparison to the MaxEnt and DG models.	Reply	I-Reply	1
[line_break_token][line_break_token]The abbreviation ‚Äú1D-DCGAN‚Äù is now spelled out (Section 2.1, second paragraph).	Reply	I-Reply	4
[line_break_token][line_break_token]Average time courses are the probability of firing in each bin, divided by the bin duration (measured in seconds).	Reply	I-Reply	6
We have tried to clarify the explanation in Section 2.2 (second paragraph).	Reply	I-Reply	6
This statistic is shown in Figs.	Reply	I-Reply	6
2E and 3D.[line_break_token][line_break_token]In Fig.2 there were 8 pairs of correlated neurons.	Reply	O	0
We have now made this information explicit in the text (Section 3.1, first paragraph).	Reply	B-Reply	9
[line_break_token][line_break_token]The idea behind the data shown in 4C-E was to clearly show how Spike-GAN could be used to identify the packets.	Reply	I-Reply	8
Initially Spike-GAN is trained with a dataset in which samples show all packets (Fig.	Reply	I-Reply	8
4A) but disordered and cluttered by background spikes (Fig.	Reply	I-Reply	8
4B).	Reply	I-Reply	8
Then we investigate the capacity of Spike-GAN to detect those packets in a separate simulated dataset in which the neural population responds to a hypothetical stimulus with only one of the packets (Fig.	Reply	I-Reply	8
4C).	Reply	I-Reply	8
We have now tried to clarify the text explaining Fig.4C-E (Section 3.3, third paragraph).	Reply	I-Reply	8
We have also added a new supp.	Reply	I-Reply	8
figure (Fig.	Reply	I-Reply	8
S2) showing a potential application of the importance maps (see also the reply to the other two reviewers).	Reply	I-Reply	8
[line_break_token][line_break_token]We now explicitly state that the eight neurons with higher importance are those corresponding to the packet (Section 3.3, third paragraph).	Reply	I-Reply	9
[line_break_token][line_break_token]As you suggested we obtained a larger dataset from Spike-GAN for Fig.	Reply	I-Reply	13
S1 and compare the probabilities inferred from it with the numerical probabilities.	Reply	I-Reply	13
We have thus simplified Section A1 and Fig.	Reply	I-Reply	13
S1, since we believe the new panel A is enough to show that Spike-GAN is learning the underlying probability distribution.	Reply	I-Reply	13
We have further computed the entropies of the ground truth and generated distributions (as suggested by reviewer 1), to check for the possibility of Spike-GAN producing low entropy samples.	Reply	I-Reply	13
Finally we now specify the parameters used for the data shown in Fig.	Reply	I-Reply	13
S1 (see caption) and changed the label in the abscissas.	Reply	I-Reply	13
[line_break_token][line_break_token]Fig.	Reply	I-Reply	5
S4 (now Fig.	Reply	I-Reply	15
S7) was mainly shown to indicate that Spike-GAN had learned the packet structure.	Reply	I-Reply	15
We realized this was not clear from the text so we have modified it (Section 3.3, first paragraph, last four lines).	Reply	I-Reply	15
[line_break_token][line_break_token]We will make the code available on GitHub upon acceptance of the paper.	Reply	I-Reply	2
[line_break_token][line_break_token]Finally, the main paper got somewhat longer than 8 pages (the recommended length for ICLR submissions), but if so advised by the reviewers we would shorten the paper by moving Fig.	Reply	I-Reply	16
1 to the supplementary material.	Reply	I-Reply	16
[line_break_token][line_break_token]Thank you again for these very useful comments.	Reply	O	0
Please let us know if you have further comments/doubts.	Reply	O	0

This paper proposes an unsupervised training objective based on patch contrasting for visual representation learning using deep neural networks.	Review	O	0
In particular, the feature representations of the patches from the same image are encouraged to be closer than the those from different images.	Review	O	0
The distance ratios of positive training pairs are optimized.	Review	O	0
The proposed method are empirically shown to be effective as an initialization method for supervised training.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token][line_break_token]- The training objective is reasonable.	Review	O	0
In particular, high-level features show translation invariance.	Review	O	0
[line_break_token][line_break_token]- The proposed methods are effective for initializing neural networks for supervised training on several datasets.	Review	O	0
[line_break_token][line_break_token][line_break_token]Weaknesses:[line_break_token][line_break_token]- The methods are technically similar to the ‚Äúexemplar network‚Äù (Dosovitskiy 2015).	Review	O	0
Cropping patches from a single image can be taken as a type of data augmentation, which is comparable to the data augmentation of positive sample (the exemplar) in (Dosovitskiy 2015).	Review	B-Review	1
[line_break_token][line_break_token]- The paper is experimentally misleading.	Review	O	0
[line_break_token]The results reported in this paper are based on fine-tuning the whole network with supervision.	Review	B-Review	2
However, in Table 2, the results of exemplar convnets (Dosovitskiy 2015) is from unsupervised feature learning (the network is not finetuned with labeled samples, and only a classifier is trained upon the features).	Review	I-Review	2
Therefore, the comparison is not fair.	Review	I-Review	2
I suspect that exemplar convnets (Dosovitskiy 2015) would achieve similar improvements from fine-tuning; so, without such comparisons (head-to-head comparison with and without fine-tuning based on the same architecture except for the loss), the experimental results are not fully convincing.	Review	I-Review	2
[line_break_token][line_break_token]Regarding the comparison to ‚ÄúWhat-where‚Äù autoencoder (Zhao et al, 2015), it will be interesting to compare against it in large-scale settings, as shown by Zhang et al, ICML 2016 (Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-Scale Image Classification).	Review	I-Review	3
Training an AlexNet is not very time-consuming with latest (e.g., TITAN-X level) GPUs.	Review	I-Review	3
[line_break_token][line_break_token]The proposed method seems useful only for natural images where different patches from the same image can be similar to each other.	Review	O	0
[line_break_token]	Review	O	0
Thank you for the review, we appreciate your remarks and incorporated them into latest revision.	Reply	O	0
[line_break_token]As you pointed out, this work shares motivation with that of Dosovitskiy, of learning unsupervised representations of images using the spatial invariance properties.	Reply	B-Reply	1
We do how note that this work suggests a novel method of achieving that goal, by explicitly learning features that correspond to the spatial invariance assumptions.	Reply	I-Reply	1
We claim that this method may hold several advantages over that of Dosovitsky, such as removing the need for surrogate classes of augmented images, and being able to apply it in parallel to standard classification objective.	Reply	I-Reply	1
We thus feel that both are viable methods for unsupervised learning on image data.	Reply	I-Reply	1
[line_break_token]We understand your objection to the comparison without fine-tuning the exemplar network model, although we note that both models used exactly the same data in both cases.	Reply	I-Reply	3
We will include a clarifying remark over this issue.	Reply	I-Reply	3
[line_break_token]We thank you for your suggestion for large-scale comparison of this work, and will try to incorporate it into later revision.	Reply	O	0

This paper identifies and investigates three mechanisms of weight decay regularization.	Review	O	0
The authors consider weight decay for DNN architectures with/without BN and different types of optimization algorithms (SGD, Adam, and two versions of KFAC).	Review	O	0
The paper unravels insights on weight decay regularization effects, which cannot be explained only by traditional L2 regularization approach.	Review	O	0
This understanding is of high importance for the further development of regulations techniques for deep learning.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]+ The authors draw connections between identified mechanisms and effects observed in prior work.	Review	O	0
[line_break_token]+ The authors provide both clear theoretical analysis and adequate experimental evidence supporting identified regularization mechanisms.	Review	O	0
[line_break_token]+ The paper is organized and written clearly.	Review	O	0
[line_break_token][line_break_token]I cannot point out any flaws in the paper.	Review	O	0
The only recommendation I would give is to discuss in more detail possible implications of the observed results for new methods of regularization in deep learning and potential directions for future work.	Review	B-Review	1
It would emphasize the significance of the obtained results.	Review	I-Review	1
We thank the reviewer for the positive feedback.	Reply	O	0
[line_break_token][line_break_token]We have revised the conclusion section to discuss the observed results and potential new directions for future work	Reply	B-Reply	1

Authors of this paper present architecture to produce valid Euclidean distance matrices.	Review	O	0
A Wasserstein GAN is then constructed by utilizing a permutation invariant critic network based on the architecture.	Review	O	0
Generating molecular structures in a one-shot fashion is conducted using the produced distance matrices in 3-d embedding.	Review	O	0
[line_break_token][line_break_token]In Section 2, the constraint on L makes M symmetric and positive semi-definite.	Review	B-Review	1
This seems to be equivalent to treating M as a kernel matrix, and D is the pairwise distance between the kernel function induced by M. So, learning a valid Euclidian distance matrix is same as learning a kernel function.	Review	I-Review	1
[line_break_token][line_break_token]Authors need to provide the evidence that Equation (5) holds for all function g, especially for the used softplus activation function.	Review	I-Review	2
As I know, it holds if function g is a polynomial matrix function.	Review	I-Review	2
[line_break_token][line_break_token]In Algorithm 1, what is the meaning of step 14?	Review	I-Review	3
There is no definition or discussion about G and the \nabla L. The construction function is the key contribution of this paper, which is incorporated the existing SchNet, so it is better to show the advantage of the proposed construction method comparing with SchNet.	Review	I-Review	3
[line_break_token][line_break_token]Although this paper is an application-oriented paper, the comparisons with baseline methods are preferred, such as some simple and straightforward baselines.	Review	I-Review	4
Due to the lack of comparisons, it is hard to understand the statement given by authors that ‚Äú the current performance‚Ä¶ is not optimal and can likely be improved by a better hyperparameter selection‚Äù.	Review	I-Review	4
[line_break_token][line_break_token]In Section 4, authors calculate the similarity of generated molecules by the closest respective matches, which is determined by the maximal atomic distance after assignment of atom identities and superposition.	Review	I-Review	5
Is this the standard way to compute the similarity between two graph structures?	Review	I-Review	5
[line_break_token]	Review	O	0
e thank you for your review, questions, and input.	Reply	O	0
In general however we do not think that the rating of "3 - weak reject" is properly motivated.	Reply	O	0
Addressing the points:[line_break_token]- We agree that, since the kernel distance is defined as for a kernel, producing a valid EDM (Eq. (	Reply	O	0
3) in the manuscript) is equivalent to learning the symmetric positive semi-definite (kernel) matrix evaluations.	Reply	B-Reply	1
The rank of corresponds to the embedding dimension.	Reply	I-Reply	1
[line_break_token]- Equation (5) holds whenever the function has a preimage space that contains the eigenvalues.	Reply	O	0
There are different ways to define a matrix function, one of them is via the Jacobi canonical form, which reduces in our case to an eigenvalue decomposition and application of the function on the individual eigenvalues (see, e.g., Higham, N. J. (2008).	Reply	B-Reply	2
Functions of matrices: theory and computation (Vol.	Reply	I-Reply	2
104).	Reply	I-Reply	2
Siam.).	Reply	I-Reply	2
[line_break_token]- Algorithm 1, step 14: It is now noted that G is a neural network.	Reply	O	0
All the steps are differentiable so depending on the optimization objective (for instance in a GAN architecture) backpropagation can yield a target distribution in EDM space (indicated by \nabla L).	Reply	B-Reply	3
SchNet in this case is used as a Critic (or in classical GANs as Discriminator) network but is not strictly required to sample in EDM space.	Reply	I-Reply	3
[line_break_token]- Comparison to simple and straightforward baselines is going to be included in future research.	Reply	O	0
While the GAN implementation of our approach generates substantial diversity in configuration space, the diversity in chemical space is limited, but can be improved by choosing different generative structures, e.g., autoregressive (arXiv 1906.00957).	Reply	B-Reply	4
[line_break_token]- The standard way to compare two structures strongly depends on the considered type of graph.	Reply	O	0
In proteins for example there is a polymeric backbone structure that can be leveraged for identity assignment via the help of sequence alignment.	Reply	B-Reply	5
Since these are small molecules without polymeric structure and finding the right assignment is in principle NP hard, the Hungarian algorithm is often used to tractably find an optimal solution, where optimal refers to the choice of cost matrix	Reply	I-Reply	5

This paper investigates Knowledge Distillation for network compression.	Review	O	0
 In their approach, the authors propose to match feature vector of the sofmax preactivation.	Review	O	0
In addition, they introduce a new loss function for training the teacher, i.e. they add a regularisation term so that class-wise clusters of feature vectors are more dense.	Review	O	0
[line_break_token][line_break_token]Authors evaluate their approach on the CIFAR10 dataset using Resnet for both teacher and student.	Review	O	0
Contrary to previous approaches using Knowledge Distillation, they show that their approach is able to leverage the Teacher to improve the Student performances with such network architectures.	Review	O	0
[line_break_token][line_break_token]Questions:[line_break_token]- What is the performance of the Teacher on CIFAR10?	Review	O	0
[line_break_token]- Did you compare with  knowledge distillation baseline (that matches softmax logits of teacher and student networks) ?	Review	O	0
[line_break_token]- Do you use Batch Normalization in your residual networks?	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The paper is clear an easy to follow[line_break_token]- Authors show that Knowledge Distillation is useful for recent network architecture (Resnets).	Review	O	0
[line_break_token]Con:[line_break_token]- Experiences on only one dataset.	Review	O	0
[line_break_token][line_break_token][line_break_token]I recommend acceptance.	Review	O	0
Thank you for your review.	Reply	O	0
[line_break_token][line_break_token]Questions:[line_break_token]- What is the performance of the Teacher on CIFAR10?	Reply	O	0
[line_break_token] 110-layer 'Baseline' and 'Class-distance loss' resnets in the table 1 refers to the performances of teacher models.	Reply	O	0
[line_break_token][line_break_token]- Did you compare with  knowledge distillation baseline (that matches softmax logits of teacher and student networks) ?	Reply	O	0
[line_break_token] Yes.	Reply	O	0
We couldn't get the error rate go down below 9% by training a student model with traditional cross-entropy transfer[line_break_token] [line_break_token]- Do you use Batch Normalization in your residual networks?	Reply	O	0
[line_break_token] Yes.	Reply	O	0
All resnets are trained with batch normalization.	Reply	B-Reply	3

This paper proposes a novel variant of Q-learning, called Maxmin Q-learning, to address the issue of overestimation bias Q-learning suffers from (variance of the reward of best action leading to overestimated reward).	Review	O	0
[line_break_token]The idea is to keep a number of estimators each estimated using a different sub-sample, and taking the minimum of the (maximum) reward value of each.	Review	O	0
[line_break_token]The paper gives theoretical analyses, in terms of the reduction in the overestimation bias, as well as the convergence of a class of generalized Q-learning methods including Maxmin Q-learning.	Review	O	0
[line_break_token]The experiment section presents a thorough evaluation of the proposed method, including how the obtained rewards vary as a function of the variance of the reward function and as a function of learning steps, as compared to a number of existing methods such as the Double Q-learning method and its variants.	Review	O	0
[line_break_token]The experimental results are quite convincing, and the theoretical analyses seem solid.	Review	O	0
[line_break_token]Overall this is a well balanced paper which proposes a reasonable new idea, simple but effective, backed by sound theoretical analysis and well executed experimental evaluation.	Review	O	0
hank you for your positive comments	Reply	O	0

The paper uses energy-based model interpretation for the logits of standard discriminative neural network models to define a generative model inside a classifier that proves useful in many downstream tasks such as uncertainty quantification, out-of-distribution detection, etc.	Review	O	0
[line_break_token]Although there has been previous work attempting to bridge discriminative classifiers with generative modeling, this work proves to be competitive with both specialized models on discriminative/generative tasks as well as in many downstream tasks such as out-of-distribution detection, calibration, and adversarial robustness.	Review	O	0
The paper provides a clear exposition of the method, succeeds to discuss related work it bases on, conducts a thorough experimental study providing convincing explanations for results and does not hide the limitations of the work (high computational requirements, optimization difficulties connected with training energy-based model and the method used, limited approximation of the true energy).	Review	O	0
Overall, the paper provides a substantial contribution and paves the way for further work improving this joint discriminative - generative setting.	Review	O	0
However, there are points I would like the paper to address for better exposition.	Review	O	0
[line_break_token]1.	Review	O	0
It would benefit the paper showing that samples with higher unnormalized likelihood are visually more compelling than those with lower likelihood.	Review	B-Review	1
[line_break_token]2.	Review	O	0
On CIFAR100 the accuracy drop from the reference value is larger than for datasets with 10 classes, could it be due the logits dimension is higher and challenges optimization?	Review	B-Review	2
[line_break_token]3.	Review	O	0
It would also be helpful to clarify whether application of the proposed method is primarily restricted by the computational complexity or is there any property inherent to energy-based models that makes treating high-dimensional data challenging?	Review	B-Review	3
[line_break_token][line_break_token]Minor remark[line_break_token]- Although the paper doesn't state on which dataset results shown in Table 1 were obtained, I suspect its CIFAR10, please specify this.	Review	O	0
e thank you for your time reviewing our work.	Reply	O	0
We will address your concerns in order:[line_break_token][line_break_token]1) Visual quality is difficult to quantify.	Reply	O	0
Of the known metrics like IS and FID, using samples that have higher p(y|x) values results in higher scores, but not necessary if we use samples with higher p(x).	Reply	B-Reply	1
 However, this is likely because of the downfalls of the evaluation metrics themselves rather than reflecting true sample quality.	Reply	I-Reply	1
 [line_break_token][line_break_token]Based on our analysis of CIFAR10 (below), we find[line_break_token]    -Our p(x) model assigns values that cluster around different means for different classes.	Reply	I-Reply	1
 The class automobiles has the highest p(x).	Reply	I-Reply	1
 Of all generated samples, all top 100 samples are of this class.	Reply	I-Reply	1
[line_break_token]    -Given the class, the samples that have higher p(x) values all have white background and centered object, and lower p(x) samples have colorful (e.g., forest-like) background.	Reply	I-Reply	1
[line_break_token]    -Of all samples, higher p(y|x) values means clearly centered objects, and lower p(y|x) otherwise.	Reply	I-Reply	1
[line_break_token][line_break_token]We completely agree with you that adding these analyese will strengthen the paper, and we have added this discussion with their corresponding images in the revised appendix.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2) On CIFAR10 we see our accuracy drop from 95.2% to 92.9% and on CIFAR100 we see accuracy drop from 74.2% to 72.2%.	Reply	O	0
This is a 2-3% drop on both datasets.	Reply	B-Reply	2
These numbers are from the exact same model with and without JEM training.	Reply	I-Reply	2
In these settings the decrease in accuracy is relatively consistent.	Reply	I-Reply	2
[line_break_token][line_break_token]Perhaps you are referring to the accuracy of our JEM models compared to state-of-the-art discriminative classifiers on these datasets?	Reply	I-Reply	2
Yes, in this setting we have a 2-3% drop from the best wide-resnet classifier with all forms of regularization added.	Reply	I-Reply	2
On CIFAR100 we have approximately a 8% drop compared to the best wide-resnet.	Reply	I-Reply	2
[line_break_token][line_break_token]Our best guess to explain this phenomenon is that competitive accuracy on CIFAR100 is much lower than competitive accuracy on CIFAR10 meaning that much more overfitting is happening on CIFAR100 than CIFAR10 (since all models achieve a training accuracy of 100% at the end of training).	Reply	I-Reply	2
  [line_break_token][line_break_token]In our JEM models we remove two important forms of regularization, batch norm and dropout, which we found to have negligible impact on CIFAR10 but less negligible impact on CIFAR100.	Reply	I-Reply	2
This is backed up by the fact that our baseline classifier with these regularizers removed achieves 74.4% accuracy, closer to that of our JEM model.	Reply	I-Reply	2
[line_break_token][line_break_token]We feel that the removal of these regularizers provides an explanation for the decrease in relative performance.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]3) This is an interesting point.	Reply	O	0
We are very excited about the future of EBMs and we are generally of the belief that the application of EBMs is currently limited by the fragility of the tools we use to train them.	Reply	B-Reply	3
So yes, we do believe if one had access to considerable computational resources then one should be able scale these methods presented to larger datasets, but we do believe there would be considerable engineering cost in doing so.	Reply	I-Reply	3
[line_break_token][line_break_token]We feel the most useful next steps to work on in the EBM-space are more stable and efficient training objectives which will increase the scale of problems to which we can apply these methods.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Minor Remark) Yes you are correct that table presents CIFAR10 results and we did indeed forget to label it as such.	Reply	O	0
This has been changed in our revised version.	Reply	B-Reply	4

This paper introduces the BookTest dataset, which is a huge dataset of reading comprehension questions compared to existing datasets.	Review	O	0
While the paper does not contain any new methodological contributions, the dataset has potential to be extremely valuable to the research community, and as such I hope it is accepted to the workshop.	Review	O	0
The authors perform a human evaluation to show that, unlike the CNN dataset, there is room for models to improve on this larger dataset.	Review	O	0
[line_break_token][line_break_token]With that said, it is interesting that the human performance is actually below that of some of the models; I wonder what types of questions humans are answering incorrectly, especially since human performance on the questions incorrectly answered by ASReader is relatively high.	Review	B-Review	1
 It would be great if the authors could add some discussion on this in future versions of the paper.	Review	I-Review	1
If the types of questions machines struggle with are different than those humans struggle with, this could potentially impact the sorts of architectural decisions made by future researchers to improve accuracy on this task.	Review	I-Review	1
Thank you for your review.	Reply	O	0
[line_break_token]We would like to correct your observation that "human performance is actually below that of some of the models".	Reply	B-Reply	1
[line_break_token]We did human evaluation only on a subset of examples that the machine learning model (ASReader trained on BookTest) could not answer correctly.	Reply	I-Reply	1
Therefore you can't directly compare numbers from Table 2 and Table 3.	Reply	I-Reply	1
[line_break_token]Since we tested humans on examples that were too difficult for the machine learning model  human performance on the whole dataset would be almost certainly even better.	Reply	I-Reply	1

This is an interesting paper I would like to comment on and ask the authors some questions.	Review	O	0
The paper studies auto-encoders where the internal representation is approximated online by a vector whose number of non-vanishing coordinates is restricted (in other words, the internal representation is projected onto the set of all vectors with a certain L0 pseudo-norm).	Review	O	0
The proposed model, 'k-sparse autoencoders', is put in context with Arian Maleki's 'iterative thresholding with inversion' algorithm for inference of sparse code words, and a criterion is given to identify the case when one iteration is enough for perfect inference.	Review	O	0
Experiments on MNIST and small NORB show that superior classification performance (wrt.	Review	O	0
RBMs, dropout, denoising auto-encoders) can be achieved when using the proposed model to generate features and processing them with logistic regression, and that the classification performance is competitive when all the models were additionally fine-tuned.	Review	O	0
This is a cool result, since the only non-linearity used for the features is the projection.	Review	O	0
[line_break_token][line_break_token]We have done something similar, see Section 3 of the paper available at <a href="http://jmlr.org/papers/v14/thom13a.html," target="_blank" rel="nofollow">http://jmlr.org/papers/v14/thom13a.html,</a> by using projections onto sets on which certain sparseness measures (including the L0 pseudo-norm) attain a constant value as neural transfer function in a hybrid of an auto-encoder and an MLP.	Review	O	0
Inference of the internal representation can be understood here as carrying out the first iteration of a projected Landweber algorithm.	Review	O	0
Perhaps the authors would like to discuss the relationship between both approaches?	Review	O	0
[line_break_token][line_break_token]The last sentence in the discussion after the proof of Theorem 3.1 is a bit puzzling.	Review	B-Review	3
The theorem shows that if mu is small, then the supports of z and W^T*x are identical.	Review	I-Review	3
The aforementioned sentence says that these supports are identical, hence mu must be small.	Review	I-Review	3
I believe this is the converse of the theorem's statement and has not been proven, since there may be reasons other than mu being small.	Review	I-Review	3
[line_break_token][line_break_token]The description of the k schedule in Section 4.2.1 is ambiguous.	Review	I-Review	4
Does this mean that when we have 100 epochs, say, that k follows a linear function for epochs 1 thru 50, and then remains at the minimum level for epochs 51 to 100, or does it mean that in each epoch for the first halve of the presented samples k is adjusted and stays at the minimum for the remaining samples of the epoch, and then the schedule starts all over again in the next epoch?	Review	I-Review	4
There are still some dead hidden units in the figures on page 6, even for k = 70 on MNIST.	Review	I-Review	4
Would it help to increase the initial k value in the schedule, or maybe add some small random numbers to z (with some annealed variance) after setting the small entries to zero, such that backprop adjusts all the hidden units?	Review	I-Review	4
[line_break_token][line_break_token]Just a few things I noticed while reading through the manuscript:[line_break_token]  - The formulation of the claim of Theorem 3.1 could be altered to be more succinct, e.g. 'supp_k(z) = supp_k(W^T*x)'.	Review	I-Review	1
In the proof, i should be from {1, ..., k}, since i = 0 doesn't seem to make sense here.	Review	I-Review	1
[line_break_token]  - Typo on page 3, left column: 'tarining'	Review	O	0
I agree on all the points made about Theorem 3.1.	Reply	B-Reply	1
[line_break_token][line_break_token]'supp_k(z) = supp_k(W^T*x)' would be clearer as well as more succinct.	Reply	I-Reply	1
[line_break_token][line_break_token]I also encourage you to put a little box at the end of the proof.	Reply	I-Reply	1
[line_break_token][line_break_token]And If I understand it correctly, you can use a weaker condition, namely:[line_break_token][line_break_token]k*mu < z_k/z_1 (note strict inequality	Reply	O	0

This paper analyzes convergence of asynchronous methods on general non-smooth and non-convex functions (typically arising from deep leaning).	Review	O	0
Stochastic sub-gradient asynchronous methods are of particular challenging when coupled with complicated hardware behavior of modern NUMA architecture.	Review	O	0
To validate the analysis, and study the impact of momentum, variable partitioning, numerical experiments on deep learning training are given.	Review	O	0
[line_break_token][line_break_token]A major concern to me is that the assumptions made in the analyze may be too restrictive.	Review	B-Review	1
For example, Assumption 3.1.1 regarding the unbiasedness of the stochastic sub-gradients may not hold for since the Clarke sub-differentiation is not additive.	Review	I-Review	1
The Clarke sub-differentiation of |x| and -|x| are not included in their average which is zero, therefore the Assumption 3.1.1 is not true for tame functions (as cited in the paper) .	Review	I-Review	1
If this assumption were not true, all the proof arguments based on Martingale differences may not be follow to prove Theorem 3.1.	Review	I-Review	1
[line_break_token][line_break_token]There are a few typos which make the paper hard to understand.	Review	I-Review	2
Is the momentum variable  u_i^kc in Algorithm 1 a central variable, as x_i?	Review	I-Review	2
It seems to be yes since the update needs a lock.	Review	I-Review	2
But why there is an kc on its index, which is not the case for x_i?	Review	I-Review	2
[line_break_token][line_break_token]In terms of numerical results, the system specification is not so clear to me why it includes a diverse asynchronous system settings.	Review	I-Review	3
Even though Figure 1 shows convergence in terms cross-entropy loss, which is not directly related to validate Theorem 3.1 since it is not clear what is going on with x_t.	Review	O	0
[line_break_token][line_break_token]The paper would be of great interest if the global shared memory asynchronous model is made more precise in the main body of the paper.	Review	B-Review	4
At a first glace, it is not clear what is the benefit (or what insights) using this model to analyze these algorithms, compared to simplistic models in literature.	Review	I-Review	4
hanks for your comments.	Reply	O	0
[line_break_token][line_break_token]The convergence behavior of the proposed method over a diverse set of asynchronous system settings provides detailed information to a practitioner about the nuances of the implementation with regards to an end-to-end performance.	Reply	B-Reply	3
 In particular, we aimed to highlight that when asynchrony was reduced and model size increased, the block-partitioned approach, i.e. PASSM, performed at par with a full gradient updating method WIASSM: the case of ResNet50/CIFAR100 over an asynchronous system with 4 processes using a single GPU per process.	Reply	I-Reply	3
Nevertheless, we have now presented another implementation, keeping the system settings and model architecture unchanged, which shows a clear advantage of the proposed method over the compared ones.	Reply	I-Reply	3
Please refer to the "Comments on the experiments" above in rebuttal to Review 2.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Thank you for indicating a need for a highlight on the system specifications.	Reply	I-Reply	3
We have updated the draft clearly marking the specification of the asynchronous shared-memory system: the paragraph "Asynchronous System Specification" in Section 2.	Reply	I-Reply	3

This paper proposes a defense against black box adversarial attack.	Review	O	0
The authors train an ensemble of deep networks, and output a null label when the ensemble disagree.	Review	O	0
Success of adversarial attack is defined as the ensemble outputs an incorrect label that is not null.	Review	O	0
The authors experimentally show improved robustness to adversarial attack.	Review	O	0
[line_break_token][line_break_token]The idea is itself new, but very similar ideas are well known in the literature, and it is difficult to conclude that the proposed approach is superior.	Review	B-Review	1
Several examples are:[line_break_token][line_break_token]Defense by majority vote with ensembles has appeared several times in the literature (e.g. Pang et al 2019).	Review	I-Review	1
The pro is that this paper proposes a novel way to create an ensemble by applying random linear transformations and rescaling to the input.	Review	I-Review	1
But it is not clear this is superior compared to existing methods.	Review	I-Review	1
[line_break_token][line_break_token]Randomized smoothing (Cohen et al, 2019) guarantees smoothness of the classifier (and thus robustness to perturbation attack under certain norms).	Review	I-Review	2
Note that randomized smoothing  provides certified guarantee against a stronger attack model (white box); it also guarantees the size of the margin (or buffer as the authors call it).	Review	I-Review	2
The intuition of this paper is based on similar ideas so it seems necessary to at least compare with randomized smoothing.	Review	I-Review	2
[line_break_token][line_break_token]Outputting a null label is a major workhorse of adversarial defense.	Review	I-Review	3
For example, previous work use a generative model to detect out of distribution samples; use a calibrated classifier to output null when low confidence.	Review	I-Review	3
[line_break_token][line_break_token]Because the idea is only mildly interesting, good experimental support becomes crucial.	Review	O	0
However, I think there are several short-comings with the experiments:[line_break_token][line_break_token]The experiment contains only one (fairly old) attack method.	Review	O	0
Several recent alternatives such as SimBA (Guo et al 2019) can make the experiments more convincing.	Review	B-Review	4
[line_break_token][line_break_token]The architecture is no longer the same for the target model (which is an ensemble with an additional random transformations) and surrogate model.	Review	I-Review	5
It is unclear if the improvement is simply because of the difference in architecture.	Review	I-Review	5
[line_break_token][line_break_token]The comparison to baselines seem unfair because it seems that the compared baselines do not have the option of outputting the null label.	Review	I-Review	6
For example, a simple baseline of randomized smoothing + output the null label if the logit scores are below a threshold can make the story much stronger.	Review	I-Review	6
[line_break_token][tab_token][line_break_token]Minor comments:[line_break_token][line_break_token]Several suggestions on writing: the introduction contains much technical detail and even experimental results, and these are repeated again in later sections.	Review	O	0
The experimental section has many minor implementation details that could go into the appendix.	Review	B-Review	7
[line_break_token]	Review	O	0
The idea is itself new, but very similar ideas are well known in the literature, and it is difficult to conclude that the proposed approach...‚Äù[line_break_token][line_break_token]Answer: Indeed, we are not aware of this paper.	Reply	O	0
In Peng et al.	Reply	B-Reply	1
2019, the authors proposed a defense based on several classifiers.	Reply	I-Reply	1
The good point of this defense is that it has high clean accuracy and has high robustness as shown in the paper.	Reply	I-Reply	1
However, there are several components of the paper which are not completely clear.	Reply	I-Reply	1
From these points it leads us to believe our defense is still a valid contribution.	Reply	I-Reply	1
We list the points related to Peng et al.	Reply	O	0
2019 below: [line_break_token][line_break_token]= White-box attacks: it is not clear to use that from the text that how the authors develop white-box attacks.	Reply	O	0
We assume that the authors may blindly applied the attacks in section 2 to their defense.	Reply	B-Reply	1
Actually, the defense may be vulnerable if we build the white-box attack as follows: given component classifiers F1(x), .., Fk(x), we want to build an objective function which optimizes the noise over F1(x),...,Fk(x) rather than F(x) = 1/k sum_{i=1}^k Fi(x).	Reply	I-Reply	1
With this customized objective function for the attack, we may see that the efficiency of the defense may be reduced.	Reply	I-Reply	1
[line_break_token][line_break_token]= Black-box attacks: the authors did not perform Papernot's black box attack and a pure black attack.	Reply	O	0
For comparison, we focus on CIFAR-10.	Reply	B-Reply	1
First, they verified the transferability between their trained classifiers and from Figure 3 (untargeted attacks), the transferability between them is still very high, i.e.,.	Reply	I-Reply	1
This implies that the success rate of pure black box attacks may be around.	Reply	I-Reply	1
Note that the noise is 0.05 which is much smaller in our case 0.1 for iterative FGSM.	Reply	I-Reply	1
The considered black-box attack on our defense is much stronger, i.e., mixture black-box attack with 10-iteration FGSM with the noise 0.1.	Reply	I-Reply	1
[line_break_token][line_break_token]= In comparison to our work, their clean accuracy is very high in their defense (Table 1) in this case, we can say that there is no drop in the clean accuracy, \gamma = 0.	Reply	O	0
If we use our metric delta, then we will have delta = \gamma + (p-\gamma)*\alpha = 0 + (93.5\%-0)*60\%= 0.56.	Reply	B-Reply	1
This means that this defense is not good against black-box attacks.	Reply	I-Reply	1
[line_break_token][line_break_token] ‚ÄúRandomized smoothing (Cohen et al, 2019) guarantees smoothness ‚Ä¶.‚Äù[line_break_token][line_break_token]Answer: Indeed, we are not aware of this paper.	Reply	O	0
We discuss an implementation of Cohen (Cao and Gang 2017) in Appendix B. Regarding these comments about different possible defenses, they bring up good points for comparison.	Reply	B-Reply	2
However, these comments misunderstand the fundamental goal of this paper.	Reply	I-Reply	2
This paper is designed to provide the first truly secure black-box defense, not evaluate other defenses which did not fully experiment with black-box attacks in their defense.	Reply	I-Reply	2
While other techniques may exist, many of them remain untested.	Reply	I-Reply	2
e.g. the smoothness defense suggested by the reviewer was never tested with Papernot‚Äôs black-box attack.	Reply	I-Reply	2
The goal of our paper is not comparison but creation, the creation of a secure defense with rigorous experimental evidence to back it up.	Reply	I-Reply	2
[line_break_token][line_break_token]‚ÄúOutputting a null label is a major workhorse of adversarial defense‚Ä¶‚Äù[line_break_token][line_break_token]Answer: In terms of the diversity of attacks we consider, C&amp;W, FGSM and IFGSM in conjunction with Papernot‚Äôs black-box attack.	Reply	O	0
To address specific points related to the attacks mentioned by the reviewer: SimBA (Guo et al 2019) does not work with our defense because the attack requires the access to the Softmax layer of the classifier.	Reply	B-Reply	3
However, this is prohibited in our defense.	Reply	I-Reply	3
We did consider the C&amp;W attack, but the performance of this attack is worse than iterative FGSM.	Reply	O	0
Hence, we skipped this attack as mentioned in Section 4 - Experiment Section.	Reply	B-Reply	3
[line_break_token][line_break_token]‚ÄúThe architecture is no longer the same for the target model...‚Äù[line_break_token][line_break_token]Ans: Architecturally diversity does not create a secure defense (it is necessary for our defense but not sufficient).	Reply	O	0
[line_break_token]This was shown in Papernot et al‚Äôs black-box attack paper where the synthetic model is different from the target model but the attack still works well.	Reply	B-Reply	5
In addition we can see architectural diversity does not provide security by looking at different defense in figure 3 with very different architectures than the synthetic model.	Reply	I-Reply	5
 The security reason for our defense is given in Section 3 (security argument).	Reply	I-Reply	5
[line_break_token][line_break_token]‚ÄúThe comparison to baselines seem unfair...‚Äù[line_break_token][line_break_token] Answer: According to our knowledge, there is no defense which produces null output because people do not want to sacrifice clean prediction accuracy for the security.	Reply	O	0
The randomized smoothing with null label as you suggested is vulnerable as we explained in the related work (Appendix B - (Cao&amp;Gong 2017)).	Reply	O	0
If the x+\delta deeply locates in a different region, then the defense should fail.	Reply	B-Reply	6
One important point for your suggested idea is that it is not clear to choose a threshold for that defense.	Reply	I-Reply	6
Note that the original defense does not consider the null output or the usage of threshold because it may make the analysis more complicated for analysis.	Reply	I-Reply	6

This paper proposes to use codes and codebooks to compress the weights.	Review	O	0
The authors also try minimizing the layer reconstruction error instead of weight approximation error for better quantization results.	Review	O	0
[line_break_token]Distillation loss is also used for fine-tuning the quantized weight.	Review	O	0
Empirical results on resnets show that the proposed method has a good compression ratio while maintaining competitive accuracy.	Review	O	0
[line_break_token][line_break_token]This paper is overall easy to follow.	Review	B-Review	1
My main concern comes from the novelty of this paper.	Review	I-Review	1
The two main contributions of the paper: [line_break_token](1) using codes and codebooks to compress weights; and [line_break_token](2) minimizing layer reconstruction error instead of weight approximation error[line_break_token]are both not new.	Review	I-Review	1
For instance, using codes and codebooks to compress the weights has already been used in [1,2].  A weighted k-means solver is also used in [2], though the "weighted" in [2] comes from second-order information instead of minimizing reconstruction error.	Review	I-Review	1
In addition, minimizing reconstruction error has already been used in low-rank approximation[3] and network pruning[4]. [line_break_token]Clarification of the connections/differences, and comparison with these related methods should be made to show the efficacy of the proposed method.	Review	I-Review	1
[line_break_token][line_break_token]It is not clear how the compression ratio in table 1 is obtained.	Review	I-Review	2
Say for block size d=4, an index is required for each block, and the resulting compression ratio is at most 4 (correct me if I understand it wrong).	Review	I-Review	2
[line_break_token]Can the authors provide an example to explain how to compute the compression ratio?	Review	I-Review	2
[line_break_token][line_break_token][1]. Model compression as constrained optimization, with application to neural nets.	Review	O	0
part ii: quantization.	Review	O	0
[line_break_token][2]. Towards the limit of network quantization.	Review	O	0
[line_break_token][3]. Efficient and Accurate Approximations of Nonlinear Convolutional Networks.	Review	O	0
[line_break_token][4]. ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
e thank Reviewer 4 for stating that ‚Äúthe proposed method has a good compression ratio while maintaining competitive accuracy‚Äù.	Reply	O	0
We provide clarification for the two main questions of the Reviewer below.	Reply	O	0
[line_break_token][line_break_token]Novelty of the paper[line_break_token]As we state in our introduction, using codebooks to compress networks is not new, as well as using a weighted k-means technique.	Reply	O	0
However, as we state in the paper: ‚ÄúThe closest work we are aware of is the one by Choi et al. (	Reply	B-Reply	1
2016), but the authors use a different objective (their weighted term is derived from second-order information) along with a different quantization technique (scalar quantization).	Reply	I-Reply	1
Our method targets a better in-domain reconstruction, as depicted by Figure 1‚Äù.	Reply	I-Reply	1
[line_break_token][line_break_token]Note that we already cite two of the suggested references by Reviewer 4, namely ‚ÄúTowards the limit of network quantization‚Äù and ‚ÄúThiNet: A filter level pruning method for deep neural network compression‚Äù in our work.	Reply	I-Reply	1
We will further clarify our positioning in an updated version of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]Compression ratio[line_break_token]We provide an example of the computation of compression ratio in Section 4.1, paragraph ‚ÄúMetrics‚Äù.	Reply	O	0
Let us detail it further here.	Reply	B-Reply	2
The memory footprint of a compressed layer is split between the indexing cost (one index per block indicating the centroid used to encode the block) and the cost of storing the centroids.	Reply	I-Reply	2
Say we quantize a layer of size 128 √ó 128 √ó 3 √ó 3 with 256 centroids and a block size of 9.	Reply	I-Reply	2
Then, each block of size 9 is indexed by an integer between 0 and 255: such integer can be stored using 8 bits or 1 byte (as 2^8 = 256).	Reply	I-Reply	2
Thus, as we have 128 x 128 blocks, the indexing cost is 128 x 128 x 1 byte = 16,384 bytes = 16 kB. Finally, we have to store 256 centroids of dimension 9 in fp16, which represents 256 x 9 floats (fp16) = 256 x 9 x 2 = 4,608 bits = 4.5 kB. The size of the compressed model is the sum of the sizes of the compressed layers.	Reply	I-Reply	2
Finally, we deduce the overall compression ratio which is the size of the compressed model divided by the size of the non-compressed model.	Reply	I-Reply	2

[line_break_token]This paper proposes a framework for meta learning neural acquisition functions for the Bayesian optimization of various underivable functions.	Review	O	0
The neural acquisition functions are learned using proximal policy optimization in an outer loop on different problems on the same domain, and the learned acquisition function can be deployed at test time in a practically vanilla Bayesian optimization procedure.	Review	O	0
The authors demonstrate the performance of the method through benchmarks on four problems.	Review	O	0
[line_break_token][line_break_token]I recommend that this paper be accepted for publication.	Review	O	0
The paper is well written and it proposes a novel direction for research.	Review	O	0
However, I think that the authors should look further inside their newly designed acquisition functions, not merely treat them as black boxes.	Review	B-Review	1
Find below some questions and comments.	Review	O	0
[line_break_token][line_break_token][line_break_token]Due to the inclusion of the sample position x in the state tuple, I am curious as to what the authors think is the difference between their method and a learning-to-learn type of approach.	Review	B-Review	2
Is the acquisition function learning to favor specific zones in the search space based on previous experiments?	Review	I-Review	2
Some more experiments or insights on this would be useful to better understand what makes this method succesful.	Review	I-Review	2
[line_break_token][line_break_token]Why was a categorical distribution used for the policy?	Review	I-Review	3
These samples are located in D, aren't you getting rid of information by assuming they are completely independent?	Review	I-Review	3
Aren't you also biasing the distribution by adding the local maxima to the set of Œæ (Xi)?	Review	I-Review	3
[line_break_token][line_break_token]Also, the right-most block in Figure 1 shows a continuous probability distribution, which is incorrect.	Review	O	0
If the distribution is indeed categorical, there is no continuity between points.	Review	B-Review	4
[line_break_token][line_break_token][line_break_token]Minor mistakes:[line_break_token][line_break_token]- page 5, paragraph 3: "This choice does not penalize explorative evaluations which do not yield and immediate improvement" should read "an immediate improvement"[line_break_token]- Figure 4b, MetaBO-50 is missing[line_break_token][line_break_token]***********[line_break_token]Post rebuttal:[line_break_token]************[line_break_token][line_break_token]I have read the other reviews and the various replies by the authors.	Review	O	0
I'd say you did a good job in answering most questions and added a lot of valuable information in the appendices.	Review	O	0
I maintain my score.	Review	O	0
hanks for your very positive feedback and the acceptance score.	Reply	O	0
We gladly answer the remaining open questions.	Reply	O	0
We highlighted the updated sections in yellow in the updated PDF.	Reply	O	0
[line_break_token][line_break_token]1.)	Reply	O	0
Gain insights into behavior of NAFs[line_break_token]---------------------------------------[line_break_token]We provide new experiments to give more insights into the behavior of our neural acquisition functions (NAFs).	Reply	O	0
The results show that MetaBO's NAFs indeed learn representations that go beyond standard AFs combined with a prior over x. Please refer to Appendix A.1 of the updated PDF for details.	Reply	B-Reply	1
[line_break_token] - We devised two one-dimensional toy problems (Rhino-1 (App.	Reply	I-Reply	1
A.1, Fig.	Reply	I-Reply	1
5), Rhino-2 (App.	Reply	I-Reply	1
A.1, Fig.	Reply	I-Reply	1
6)) to demonstrate that MetaBO learns to use non-greedy evaluations in the beginning of an episode to obtain high information gain (rather than low regret) about the target function.	Reply	I-Reply	1
This results in more efficient search strategies compared to approaches which simply favor specific zones in the search space.	Reply	I-Reply	1
[line_break_token] - Note that this effect can already be observed in the original results in our paper (Fig.	Reply	O	0
2, Fig.	Reply	B-Reply	1
3(a)), where MetaBO starts episodes with evaluations yielding higher regret than other pre-informed AFs (TAF) but quickly surpasses their performance by using the information obtained through these non-greedy evaluations.	Reply	I-Reply	1
[line_break_token] - We further implemented two additional easily-interpretable baseline methods (GMM-UCB, eps-greedy) as proposed by AnonReviewer3 which rely solely on a prior over x. The results (App.	Reply	O	0
A.1, Fig.	Reply	B-Reply	1
7) show that such simple approaches are not able to reach MetaBO's performance, underlining that MetaBO produces more sophisticated search strategies.	Reply	I-Reply	1
[line_break_token][line_break_token]2.)	Reply	O	0
Difference to learning-to-learn[line_break_token]-----------------------------------[line_break_token]Regarding your question of the difference of our approach to a learning-to-learn type approach such as Chen et al. [	Reply	O	0
1], we would like to point you to our answer to AnonReviewer2, where we discuss this question in detail.	Reply	B-Reply	2
[line_break_token][line_break_token]3.)	Reply	O	0
Architecture[line_break_token]----------------[line_break_token]We thank you for the remark that the right-most panel of Fig.	Reply	O	0
1 is inaccurate.	Reply	B-Reply	4
It indeed shows a continuous distribution, while our policy defines a categorical distribution.	Reply	I-Reply	4
However, our NAFs can be evaluated at any point in the domain and our method does indeed use an adaptive grid \xi_t to form this categorical distribution from the AF outputs during training.	Reply	I-Reply	4
We wanted to emphasize this through the shaded area in our figure.	Reply	I-Reply	4
We improved Fig.	Reply	I-Reply	4
1 in the PDF to remove the inaccuracies and extended and improved our description of our architecture in Sec.	Reply	I-Reply	4
4.	Reply	I-Reply	4
We hope that the additional explanations help to clarify your questions.	Reply	I-Reply	4
[line_break_token][line_break_token]4.)	Reply	O	0
Minor mistakes[line_break_token]------------------[line_break_token]We corrected the minor mistake.	Reply	O	0
Furthermore, we explained that we did not carry out expensive hardware experiments for MetaBO-50 because it did not show promising performance in simulation compared to the full version of MetaBO.	Reply	B-Reply	5
[line_break_token][line_break_token]References: [line_break_token][1] Chen et al., "	Reply	O	0
Learning to learn without gradient descent by gradient descent", ICML 201	Reply	O	0

This paper addresses the problem of limited resources that may generally be available at inference time (as compared to the lack of constraints during training time).	Review	O	0
The paper addresses architecture search as well as model compression by simultaneously optimizing all layers/weights/submodules of the network.	Review	O	0
The approach is motivated well in terms of comparisons to other work: Although I am not an expert in this particular area of model compression, the intuitive comparisons and mentions of prior work felt satisfying and informative.	Review	O	0
This problem is definitely timely, and the paper showed results of improved inference speed and memory footprint on both a smaller 10-way classification task as well as a larger 1000-way one.	Review	O	0
[line_break_token][line_break_token]My current decision is a weak accept, for a well-written paper and an interesting problem, but in the presence of some concerns and suggestions as listed below.	Review	O	0
[line_break_token][line_break_token](1) My main concern is that without weight regularization, this optimization problem seems ill-posed.	Review	O	0
Looking at algorithm 1 specifically, consider the case where j=10 and the learned alphas are indeed sparse, like (0.1, 0, 0,‚Ä¶, 0, 0.9).	Review	B-Review	1
The cost of J=0 here might be very high (i.e., large, slow, expensive model) and cost of J=9 might be very low (i.e., small fully-connected network that basically maps to an identity function).	Review	I-Review	1
Here, the cost during optimization could be very low, and the results could be very accurate, but the weights of J=0 may be very high such that the entire work of getting the right answer is from this model.	Review	I-Review	1
More generally, a low alpha can be attained for any model by simply increasing the network weights themselves.	Review	I-Review	1
This doesn‚Äôt seem to be taken care of anywhere in this paper; if not addressed in any way, it would be a large reason for me to suggest rejecting this work.	Review	I-Review	1
[line_break_token][line_break_token](2) For the experiments, both of the chosen tasks were classification.	Review	O	0
Although one was smaller/easier and one was larger/harder, it would serve to be much more convincing if a task requiring regression and/or higher-dimensional output were tested.	Review	B-Review	2
For these classification tasks, I can imagine that for certain model changes, the decision boundaries may remain the same even if the network itself is changing in detrimental ways.	Review	I-Review	2
Thus, a task such as an image-to-image depth perception task (or other tasks in this category) would solidify the results and make it more convincing that DARC does indeed help.	Review	I-Review	2
[line_break_token][line_break_token]Minor: [line_break_token][line_break_token](a) The motivation of going from L0 to L1 for the cost constraint seems relevant also to the choice of h being the convex combination of different models.	Review	O	0
Can the motivation and problem setup address these motivations together, instead of separately?	Review	B-Review	3
 [line_break_token][line_break_token](b) Although this paper defined R(h) and it also defined h=(\sum (alpha_j * h_j), it would still be helpful for the reader if the paper could explicitly define R(\sum (alpha_j * h_j)) somewhere.	Review	O	0
Although I know what was intended was to compose these h_j functions as sequential stages to pass data through, the sum notation seems a bit misleading like you may be averaging the final predictions/outputs from different models and computing the loss on these averaged results.	Review	B-Review	4
[line_break_token]	Review	O	0
ain Comments:[line_break_token][line_break_token]Thank you for your comments and careful review of the paper.	Reply	O	0
We respond to each of your comments below:[line_break_token][line_break_token](1) "[W]ithout weight regularization, this optimization problem seems ill-posed... More generally, a low alpha can be attained for any model by simply increasing the network weights themselves."	Reply	O	0
[line_break_token][line_break_token]Response: We thank the reviewer for this insightful question.	Reply	O	0
We did in fact use weight regularization, and indeed the problem is ill-posed without this.	Reply	B-Reply	1
The reason we did not mention this in the experiments is that, in MXNet, a weight decay parameter (of 10^{-4}) is built into stochastic gradient descent by default, and we did not modify this.	Reply	I-Reply	1
We will add a note under "DARC Training Details" on page 5.	Reply	I-Reply	1
In the theoretical formulation in Sections 2 and 3, the candidate classes \cal{H}_j can be assumed to have bounded L2 norm.	Reply	I-Reply	1
As the reviewer noted, this plays an important role in ensuring that the L1 optimization problem is well-posed, so we will add a sentence to Section 2 clarifying this.	Reply	I-Reply	1
[line_break_token][line_break_token](2) "For the experiments, both of the chosen tasks were classification‚Ä¶ It would serve to be much more convincing if a task requiring regression and/or higher-dimensional output were tested."	Reply	O	0
[line_break_token][line_break_token]Response: The vast majority of prior work on neural network compression (including, e.g., MobileNets, MNasNet, FBNet, ProxylessNAS, etc.)	Reply	O	0
has focused on image classification, and the existence of these baselines for comparison was a major reason for our focus on this task.	Reply	B-Reply	2
However, we agree that applying DARC to neural networks for other tasks is a fruitful direction for future work.	Reply	I-Reply	2
[line_break_token][line_break_token]Minor Comments:[line_break_token][line_break_token](a) The motivation of going from L0 to L1 for the cost constraint seems relevant also to the choice of h being the convex combination of different models.	Reply	O	0
Can the motivation and problem setup address these motivations together, instead of separately?	Reply	O	0
[line_break_token][line_break_token]Response: Thank you for this suggestion.	Reply	O	0
Indeed, both the L1 cost and the convex combination are essentially artifacts of approximating a computationally challenging combinatorial optimization problem with a more tractable continuous relaxation.	Reply	B-Reply	3
We alluded to this in the first paragraph of Section 2, but we can add more detail to make this more concrete.	Reply	I-Reply	3
[line_break_token][line_break_token](b) Although this paper defined R(h) and it also defined h=(\sum (alpha_j * h_j), it would still be helpful for the reader if the paper could explicitly define R(\sum (alpha_j * h_j)) somewhere.	Reply	O	0
Although I know what was intended was to compose these h_j functions as sequential stages to pass data through, the sum notation seems a bit misleading like you may be averaging the final predictions/outputs from different models and computing the loss on these averaged results.	Reply	O	0
[line_break_token][line_break_token]Response: The notation \sum (alpha_j * h_j) is actually meant to denote weighted averaging (convex combination) of the outputs of each candidate.	Reply	O	0
To clarify, the candidates h_1,...,h_J discussed in Section 2 are for a single layer of the network.	Reply	B-Reply	4
During training, DARC replaces each layer of the network with a convex combination of this form.	Reply	I-Reply	4
This extension to multi-layer networks (compositions of layers) is discussed in Section 3 (specifically, Eq. (	Reply	I-Reply	4
2)).	Reply	I-Reply	4
We note that these intermediate layers of the network always output real-valued vectors (for classification, discretization is performed by a softmax layer at the output of the network, as usual in deep networks for classification), so this averaging is well-defined.	Reply	I-Reply	4
[line_break_token][line_break_token]The definition of R(h) should apply for the risk R(\sum (alpha_j * h_j)) of such a convex combination unchanged.	Reply	I-Reply	4
We could, however, expand the formula for R(\sum (alpha_j * h_j)), if the reviewer feels this would help readers	Reply	I-Reply	4

The paper provide an extensive review of current advances in uncertainty estimation in neural networks with the analysis of drawbacks of currently used uncertainty metrics and comparison on scale the recent method to estimate uncertainty.	Review	O	0
The paper covers a lot of uncertainty metrics and a wide range of methods.	Review	O	0
The paper focuses on in-domain uncertainty estimation complementing the recent similar review on out-of-domain uncertainty estimation.	Review	O	0
[line_break_token][line_break_token]It seems that the paper provides the analysis missing in the current literature.	Review	O	0
Whereas as mentioned Yukun Ding in a public comment there is a related work on identifying issues with popular uncertainty metrics, the mentioned paper is missing the through comparison of the methods for estimating uncertainty.	Review	O	0
[line_break_token][line_break_token]Such kind of thorough analysis (especially performed on scale on large datasets) and comparison is of obvious interest to the community as well as objective comparison of the current state-of-the-art.	Review	O	0
[line_break_token][line_break_token]The paper is clearly written and easy to follow.	Review	O	0
[line_break_token][line_break_token]Based on this, I believe this is a strong technical paper and it should be accepted.	Review	O	0
However, the analysis in the paper is not overwhelmingly exhaustive.	Review	O	0
Some of the arguments on that are listed below.	Review	O	0
[line_break_token][line_break_token]Below is the list of comments/thoughts for potential improvement of the paper:[line_break_token]1.	Review	O	0
[tab_token]‚ÄúIn this case, a model is expected to provide correct probability estimates:‚Äù ‚Äì may be not the best choice of words, because for out of domain uncertainty estimation we still expect a model to provide correct probability estimates[line_break_token]2.	Review	O	0
[tab_token]The first paragraph on page 3 seems to better fit in Section 2, for example, on the very beginning of Section 2.	Review	O	0
[line_break_token]3.	Review	B-Review	13
[tab_token]‚ÄúComparison of the log-likelihood should only be performed at the optimal temperature.	Review	I-Review	3
‚Äù and others alike ‚Äì personally, I do not support this kind of formatting for a scientific paper[line_break_token]4.	Review	O	0
[tab_token]‚Äúcan produce an arbitrary ranking of different methods. &	Review	B-Review	4
lt;‚Ä¶&gt; Empirically,‚Äù ‚Äì in the current form it seems that the first statement is somehow theoretically justified and then additionally it is confirmed empirically in this paper.	Review	O	0
I believe that the authors use empirical observation itself as the justification of the first statement, if that the case it should be reworded here.	Review	B-Review	4
For example, ‚Äúcan produce an arbitrary ranking of different methods as we show below/ as we show empirically.	Review	I-Review	4
We demonstrate that the overall ‚Ä¶‚Äù If my belief is incorrect and there are other grounds that justify the first statement that it is required a reference after this statement.	Review	I-Review	4
[line_break_token]5.	Review	I-Review	18
[tab_token]Italic and non-italic LL usage is unclear[line_break_token]6.	Review	O	0
[tab_token]Having ‚ÄúBrier score‚Äù emphasised as a paragraph, it seems that there should be a paragraph log-likelihood as well[line_break_token]7.	Review	O	0
[tab_token]‚ÄúIn that case, both objects and targets of induced binary classification problems remain fixed for all models‚Äù ‚Äì do the authors consider in this case all out-of-domain objects as having a positive class and all in-domain objects as having a negative class?	Review	B-Review	7
Because the models are still going to make individual misclassification mistakes[line_break_token]8.	Review	O	0
[tab_token]Figure 2 ‚Äì legend occupies too much space of the plot occluding almost a third part of the plot.	Review	B-Review	8
Maybe taking the legend out of the plot to the right and squeezing the plot to make a room for the legend would be a better solution[line_break_token]9.	Review	O	0
[tab_token]In eq. (	Review	B-Review	9
4) and (5) subscript DE is not defined[line_break_token]10.	Review	O	0
[tab_token]‚ÄúSSE and cSGLD outperform all other techniques except deep ensembles‚Äù ‚ÄìcSGLD was not applied on ImageNet, therefore this statement is a bit misleading[line_break_token]11.	Review	O	0
[tab_token]Colour of SWAG in Figure 3 is not very clear.	Review	O	0
Only excluding other colours I can determine which line is SWAG.	Review	B-Review	11
Similar to cSGLD, is seems that SWAG was not applied on ImageNet.	Review	I-Review	11
Why is that if that is the case?	Review	I-Review	11
And it should be clearly stated at least in experimental setup in Supplementary  [line_break_token]For colours in general, lines in legends are very thin and it is difficult to assess their colour.	Review	I-Review	11
I appreciate the authors compare a lot of methods and therefore have to use a lot of colours, but it is quite difficult to assess them even on screen not to mention if the paper is printed out.	Review	I-Review	11
Could the authors please use thicker lines in legends at least?	Review	I-Review	11
[line_break_token]12.	Review	O	0
[tab_token]‚ÄúBeing more ‚Äúlocal‚Äù methods‚Äù ‚Äì without any context in the main paper this referral to ‚Äúlocal‚Äù methods is unclear.	Review	B-Review	12
Also it is good to add a reference to Appendix review of the considered methods in the main text.	Review	I-Review	12
[line_break_token]13.	Review	O	0
[tab_token]Missing details of what kind of augmentation is used in Section 4.3.	Review	B-Review	13
Is it the same as training augmentation specified in Supplementary?	Review	I-Review	13
It would require a reference to Supplementary[line_break_token]14.	Review	O	0
[tab_token]‚Äú(Figure 1, Table REF)‚Äù ‚Äì missing number for Table[line_break_token]15.	Review	O	0
[tab_token]‚ÄúOur experiments demonstrate that ensembles may be severely miscalibrated by default while still providing superior predictive performance after calibration.	Review	B-Review	15
‚Äù ‚Äì unclear which experiments demonstrate this and superior in comparison to what[line_break_token]16.	Review	O	0
[tab_token]The issues of uncalibrated log-likelihood and TACE are clearly shown in the paper, whereas the issues with misclassification detection are only verbally discussed.	Review	O	0
An illustrative example, at least a toy thought example, could really improve the paper here[line_break_token]17.	Review	O	0
[tab_token]The chosen main performance metric is not very convincingly motivated.	Review	O	0
It is clear why it is based on calibrated log-likelihood, but it is not very convincing why one cannot just used calibrated log-likelihood as a performance metric, why one should base the metric on deep ensembles instead.	Review	B-Review	17
Also from the long-term perspective, if the community comes up with methods clearly outperforming deep ensembles, the metric would need to be based on one of these new methods [line_break_token]18.	Review	O	0
[tab_token]There is an indirect uncertainty metric that is not mentioned in the paper ‚Äì uncertainty used in active learning (see, e.g., Hern√°ndez-Lobato and Adams, 2015.	Review	B-Review	18
Probabilistic backpropagation for scalable learning of Bayesian neural networks)[line_break_token]19.	Review	O	0
[tab_token]Figures 4 and 5 are too small[line_break_token]20.	Review	O	0
[tab_token]‚Äúthe original PyTorch implementations of SWA‚Äù ‚Äì SWA is not considered in the paper[line_break_token]21.	Review	O	0
[tab_token]‚Äúhidden inside an optimizer ‚Ä¶ The actual underlying optimization problem‚Äù ‚Äì it seems that the ICLR audience should be familiar with ‚Äúactual optimization problems‚Äù rather than using blindly the optimizer.	Review	O	0
It is always good to explicitly write down an equation that is used in a paper, but this wording seems a bit off for ICLR [line_break_token]22.	Review	O	0
[tab_token]‚Äú\hat{p}(y^‚àó_i = j | x_i, w) denotes the probability that a neural network with parameters w assigns to class j when evaluated on object x_i‚Äù ‚Äì it should be \hat{p}(y_i = j | x_i, w), y^*_i is observed[line_break_token]23.	Review	O	0
[tab_token][line_break_token]a.[tab_token]Why was dropout applied only for limited number of architectures and not applied on ImageNet at all?	Review	O	0
[line_break_token]b.[tab_token]Why wasn‚Äôt cSGLD applied on ImageNet[line_break_token]24.	Review	O	0
[tab_token]‚ÄúOn CIFAR-10/100 parameters from the original paper are reused‚Äù ‚Äì it is better to repeat the reference here[line_break_token][line_break_token][line_break_token]Minor:[line_break_token]1.	Review	O	0
[tab_token]Font size in eq. (	Review	O	0
10) should be the same as the rest of the paper[line_break_token]2.	Review	O	0
[tab_token]‚ÄúOr models achived top-1 error of‚Äù: ‚ÄúOr‚Äù - ?, ‚	Review	O	0
Äúachived‚Äù -&gt; achieved [line_break_token]3.	Review	O	0
[tab_token]‚Äúfor a 45 epoch form a per-trained model‚Äù: ‚Äúform‚Äù -&gt; ‚Äúfrom‚Äù?	Review	O	0
gt; 16.	Reply	O	0
[tab_token]The issues of uncalibrated log-likelihood and TACE are clearly shown in the paper, whereas the issues with misclassification detection are only verbally discussed.	Reply	O	0
An illustrative example, at least a toy thought example, could really improve the paper here[line_break_token][line_break_token]AUROC/AUPR for misclassification detection plainly provides numbers that can not be compared across different models.	Reply	O	0
We will try to come up with a convincing illustrative example, but it is not yet clear for us how to make it more convincing than the verbal discussion.	Reply	B-Reply	16
[line_break_token][line_break_token]&gt; 17.	Reply	O	0
[tab_token]The chosen main performance metric is not very convincingly motivated.	Reply	O	0
It is clear why it is based on calibrated log-likelihood, but it is not very convincing why one cannot just used calibrated log-likelihood as a performance metric, why one should base the metric on deep ensembles instead.	Reply	O	0
Also from the long-term perspective, if the community comes up with methods clearly outperforming deep ensembles, the metric would need to be based on one of these new methods [line_break_token][line_break_token]DEE is basically a more convenient way to visualize the calibrated log-likelihood.	Reply	O	0
The calibrated log-likelihood does indeed seem to be a great absolute measure of performance.	Reply	B-Reply	17
However, it is not very convenient if one wants to compare the performance of different ensembling techniques.	Reply	I-Reply	17
Different models and datasets have different base values of calibrated log-likelihood, and its dependence on the number of samples is non-trivial.	Reply	I-Reply	17
DEE is model- and dataset-agnostic and provides some useful insights that can be difficult to visualize using the calibrated log-likelihood alone.	Reply	I-Reply	17
[line_break_token][line_break_token]In the long run, the DEE metric might still be useful and insightful.	Reply	I-Reply	17
While the DEE curve of deep ensembles is an identity function, superior methods would typically result in a higher DEE curve.	Reply	I-Reply	17
We would only run into problems if this new superior method would outperform extremely large deep ensembles (say hundreds or thousands of samples) using just a handful of samples.	Reply	I-Reply	17
However, we do not expect such a drastic gap to appear soon.	Reply	I-Reply	17
[line_break_token][line_break_token]&gt; 18.	Reply	O	0
[tab_token]There is an indirect uncertainty metric that is not mentioned in the paper ‚Äì uncertainty used in active learning (see, e.g., Hern√°ndez-Lobato and Adams, 2015.	Reply	O	0
Probabilistic backpropagation for scalable learning of Bayesian neural networks)[line_break_token][line_break_token]We do mention active learning in the related works section, but this reference is indeed very relevant here.	Reply	O	0
Thank you.	Reply	B-Reply	18
[line_break_token][line_break_token]&gt; 20.	Reply	O	0
[tab_token]‚Äúthe original PyTorch implementations of SWA‚Äù ‚Äì SWA is not considered in the paper[line_break_token][line_break_token]While we do not use SWA in our experiments, our codebase is heavily based on the original implementation of SWA since it allowed to easily reproduce the training of different models and was easy to modify for our needs.	Reply	O	0
We will articulate the reference more clearly in the next revision of the paper	Reply	B-Reply	20

This paper extends Transformer by recursively applying a multi-head self-attention block, rather than stack multiple blocks in the vanilla Transformer.	Review	B-Review	1
An extra transition function is applied between the recursive blocks.	Review	O	0
This combines the idea from RNN and attention-based models.	Review	O	0
But the RNN structure here is not applied to the input sequence, but to the sequence of blocks inside the Transformer encoder/decoder.	Review	O	0
In addition, it also uses a dynamic adaptive computation time (ACT) halting mechanism on each position, as suggested by the previous ACT paper.	Review	B-Review	2
In fact, it can be seen as a memory network with a dynamic number of hops at the symbol level.	Review	O	0
[line_break_token][line_break_token]The paper is well-written and easy to follow.	Review	O	0
The experimental results demonstrate that the proposed model can achieve state-of-the-art prediction quality in several algorithmic and NLP tasks.	Review	O	0
[line_break_token][line_break_token]Pros[line_break_token]1.	Review	O	0
The proposed UT is compatible with both algorithmic and NLP tasks by combining the Transformer with weight sharing of recurrence and dynamic halting.	Review	O	0
In contrast, previous algorithmic and NLP takes can only be solved by more specific neural architectures (e.g., NTM for algorithmic tasks and the Transformer for NLP tasks).	Review	O	0
[line_break_token]2.	Review	O	0
The empirical results verify the effectiveness of the UT on several benchmarks.	Review	O	0
[line_break_token]3.	Review	O	0
The careful experimental analyses not only show the insight of dynamic halting in QA task but demonstrate the ACT is very useful for algorithmic tasks.	Review	O	0
[line_break_token]4.	Review	O	0
The publicly-released codes could make great contributions to the NLP community.	Review	O	0
[line_break_token][line_break_token]Cons[line_break_token]1.	Review	O	0
It proposes an incremental change to the original Transformer by introducing recursive connection between multihead self-attention blocks with ACT.	Review	B-Review	3
The idea behind UT is similar to memory networks and multi-hop reasoning.	Review	I-Review	3
[line_break_token]2.	Review	O	0
The recursive structure is not applied to the input sequence, so UT does not have the advantage of RNN/LSTM on capturing sequential information and high-order features.	Review	B-Review	4
[line_break_token]3.	Review	O	0
Although evaluated on multiple datasets and tasks, they only cover simple QA task and EN-DE translation task.	Review	B-Review	5
Comparing to other papers applying modifications to Transformer, it is better to include at least one heavy task on large/challenging dataset/task.	Review	I-Review	5
 [line_break_token]4.	Review	O	0
On machine translation task, why does the model without dynamic halting achieve the SOTA performance?	Review	B-Review	6
This is in contrast to the claim of the advantage of using dynamic halting.	Review	I-Review	6
[line_break_token]5.	Review	O	0
The ablation studies focus only on the dynamic halting, but what if weight sharing is removed from the UT?	Review	B-Review	7
We thank the reviewer for the thorough review and respond below.	Reply	O	0
We have also updated the paper to address these comments.	Reply	O	0
[line_break_token][line_break_token]>extends Transformer by recursively applying a multi-head self-attention block, rather than stack multiple blocks in the vanilla Transformer.	Reply	O	0
An extra transition function is applied between the recursive blocks[line_break_token][line_break_token]To avoid any potential confusion about the architecture, we note that the {multi-head self-attention + transition}-block is applied recursively *as a whole*. The Transition function is not ‚Äúextra‚Äù, it also exists in the standard Transformer, but the difference is that we apply the same Transition function at every layer / step (by tying the weights).	Reply	O	0
This makes the model recurrent (in ‚Äúdepth‚Äù or in its concurrent processing steps), which then allows us to vary the number of steps and add dynamic halting -- both impossible with the standard Transformer architecture.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token]>it also uses a dynamic adaptive computation time (ACT) halting mechanism on each position, as suggested by the previous ACT paper[line_break_token][line_break_token]ACT was introduced and applied in the context of a sequential RNN model where each symbol is processed one after the other, but with a variable number of steps each.	Reply	O	0
However we apply ACT concurrently to all symbols (i.e. in a parallel-in-time model).	Reply	B-Reply	2
It has the same effect of allowing a variable number of processing steps per symbol, but we want to emphasize that the way it is used in UT is different from the original ACT paper (in depth vs in sequence length / time).	Reply	I-Reply	2
[line_break_token][line_break_token]>1. [...]	Reply	O	0
The idea behind UT is similar to memory networks and multi-hop reasoning.	Reply	O	0
[line_break_token][line_break_token]Yes, indeed, the idea behind UT is related to memory networks.	Reply	B-Reply	3
We mentioned this briefly (last paragraph of Section 4), but have expanded on this in the updated version: In UT, similar to dynamic memory networks, there is an iterative attention process which allows the model to condition its attention over memory on the result of previous iterations.	Reply	I-Reply	3
 As we also show in the visualization of the attention distributions for the bAbI task (Appendix F in the revised paper), we can see that there is a notion of temporal states in UT,  where the model updates the memory (states) in each step based on the output of previous steps, and this chain of updates can indeed be viewed as steps in a multi-hop reasoning process.	Reply	I-Reply	3
[line_break_token][line_break_token]>2.	Reply	O	0
The recursive structure is not applied to the input sequence, so UT does not have the advantage of RNN/LSTM on capturing sequential information and high-order features.	Reply	O	0
[line_break_token][line_break_token]We disagree with this statement: In self-attentive parallel-in-time models (such as Transformer or UT) information is exchanged between symbols (i.e. sequential information) using the self-attention mechanism.	Reply	B-Reply	4
Therefore, in the first step each symbol representation is already conditioned on every other symbol (i.e. includes first-order features).	Reply	I-Reply	4
However, as this process is continued, with each additional processing step UTs are in fact able to capture higher-order features between symbols.	Reply	I-Reply	4

In this paper, the authors provide a theoretical framework for characterizing the approximation guarantees provided by node sampling to estimate embeddings in various GNN architectures.	Review	O	0
In particular, they prove several PAC learning-style bounds on the embedding and gradient estimation when using node sampling approaches.	Review	O	0
They also observe that since the number of nodes selected for sampling is not dependent on the size of the graph, this amounts to a constant time operation for determining embedding and gradient estimates.	Review	O	0
[line_break_token][line_break_token]Importantly, a variety of existing works have already proposed node sampling (‚Äúconstant-time GNNs‚Äù), so the contribution of this work lies in the theoretical bounds.	Review	O	0
A moderate set of experiments suggests the empirical behavior follows the theoretical expectations.	Review	O	0
[line_break_token][line_break_token]Overall (and described in the comments below), I believe this paper provides some interesting theoretical results for an approach that is widely-used in practice.	Review	O	0
However, I believe the title and abstract are misleading; this paper does not suggest some new sampling strategy; it only gives a theoretical approximation error for existing approaches and network architectures.	Review	O	0
[line_break_token][line_break_token]Comments[line_break_token][line_break_token]While the authors do make this clear later in the paper, the contributions of this work are only the theoretical bounds; the node sampling algorithms have been proposed in existing work.	Review	O	0
Both the title and abstract are misleading.	Review	B-Review	1
[line_break_token][line_break_token]Still, the theoretical bounds do provide an interesting understanding of an approach which is commonly used in practice.	Review	O	0
[line_break_token][line_break_token]It would be helpful to give the intuition behind the assumptions and proofs.	Review	B-Review	9
Currently, it is difficult for a non-expert to follow the reasoning and practical implications of much of this work.	Review	I-Review	9
[line_break_token][line_break_token]Currently, it is not clear if these results are ‚Äúconstructive‚Äù, in the sense that they do not obviously suggest some new sampling strategy, etc.	Review	I-Review	3
Of course, it is still interesting to characterize commonly-used practices, but one does wish the theory suggested, say, a better sampling strategy, etc.	Review	I-Review	3
[line_break_token][line_break_token]Typos, etc.	Review	I-Review	4
[line_break_token][line_break_token]‚Äúr‚Äù, the number of sampled nodes, is not defined in the main body of the paper.	Review	I-Review	5
[line_break_token][line_break_token]The text in Footnote 1 is a little confusing, in that the text refers to approximating the embedding, while the text in the footnote describes a prediction problem.	Review	I-Review	6
A reader could easily interpret this to mean that the error on the downstream prediction problem will be bounded (which is not what this work shows).	Review	I-Review	6
[line_break_token][line_break_token]The text mentions that O_G (v,i) refers to the i^th ‚Äúneighborhood‚Äù of v. Presumably, this should be ‚Äúneighbor‚Äù.	Review	I-Review	7
[line_break_token][line_break_token]‚Äúwe take‚Äù -&gt; ‚ÄúWe take‚Äù[line_break_token]	Review	O	0
hank you for your constructive comments.	Reply	O	0
[line_break_token][line_break_token]We changed the title to ‚ÄúOn the approximation errors of node sampling for graph neural networks‚Äù and abstract following your suggestion.	Reply	B-Reply	1
Since we could not change the title on OpenReview at this moment, we will ask the program chairs to change its title after acceptance.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; better sampling strategy, etc.	Reply	O	0
[line_break_token]Our problem setting is general, and we do not make any assumptions about the input graph.	Reply	B-Reply	3
Therefore, in this setting, non-uniform sampling does not work because we allow adversarial inputs.	Reply	I-Reply	3
This is supported by Theorem 3, which shows that the uniform sampling scheme is optimal in terms of query complexity.	Reply	I-Reply	3
This is common with Hayashi and Yoshida‚Äôs constant time algorithms for minimizing quadratic functions [Hayashi and Yoshida, NIPS 2016] and fitting low-rank tensors [Hayashi and Yoshida, NIPS 2017], where they succeeded in providing constant time algorithms using uniform sampling.	Reply	I-Reply	3
If we make task-specific assumptions about the input graph/features (e.g., the input graph is sampled from the stochastic block model, and the features are sampled from i.i.d.	Reply	I-Reply	3
distribution in each cluster), adaptive sampling techniques may work.	Reply	I-Reply	3
[line_break_token][line_break_token]In this paper, we do not consider such task-specific assumptions but use a general and widely-applicable setting because the task-specific assumptions are in general strong and narrow the scope of application.	Reply	I-Reply	3
This is the first work to analyze the theoretical approximation errors of node sampling, and many other task-specific analysis can stem from this work.	Reply	I-Reply	3
Note that if we sample nodes without replacement, the approximation error may decrease in practice, but the theoretical rate does not change.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]&gt; Practical implication of the analysis[line_break_token]The number of samples is usually determined using validation data (e.g., cross-validation) in practice.	Reply	O	0
In contrast, our theory (including our theoretical bounds and inapproximability results) provides theoretical justification for the number of samples needed and helps determine the number of samples without cross-validation for various situations.	Reply	B-Reply	9
[line_break_token][line_break_token]&gt; ‚Äúr‚Äù, the number of sampled nodes, is not defined in the main body of the paper.	Reply	O	0
[line_break_token][line_break_token]We added the description in the revised paper. (	Reply	B-Reply	5
see the third line of Section 4.1)[line_break_token][line_break_token]&gt; The text in Footnote 1 is a little confusing, in that the text refers to approximating the embedding, while the text in the footnote describes a prediction problem.	Reply	O	0
A reader could easily interpret this to mean that the error on the downstream prediction problem will be bounded (which is not what this work shows).	Reply	O	0
[line_break_token][line_break_token]We modified the description following your suggestion.	Reply	B-Reply	6
[line_break_token][line_break_token]Note that our analysis can be applied to the prediction setting by considering the prediction problem as 1-dimensional embedding in [0, 1]. In that case, the prediction with the approximation is correct if the exact computation predicts correctly with margin.	Reply	I-Reply	6
[line_break_token][line_break_token]&gt; The text mentions that O_G (v,i) refers to the i^th ‚Äúneighborhood‚Äù of v. Presumably, this should be ‚Äúneighbor‚Äù.	Reply	O	0
[line_break_token]&gt; ‚Äúwe take‚Äù -&gt; ‚ÄúWe take‚Äù[line_break_token][line_break_token]We fixed typos.	Reply	O	0
Thank you for pointing out them.	Reply	B-Reply	4

**Summary:** The paper contains a method tailored to a certain kind of SOC problems involving multiplicative noise.	Review	O	0
The central idea is to use a recurrent network to transform the observations into a representation that can be used with solvers specifically tailored towards that class of problems.	Review	O	0
[line_break_token][line_break_token]**Decision:** I recommend to accept the paper for publication.	Review	O	0
[line_break_token][line_break_token]**Arguments for decision:** The paper clearly adresses an important problem and poroposes a method capable of solving it.	Review	O	0
The method appears to be theoretically founded and the experimental validation seems solid.	Review	O	0
The relevance of the method is there as the problem class is prevalent in practical applications.	Review	O	0
The venue is a good fit as well, as the focus is the representation of a control problem in a way that allows more efficient solutions.	Review	O	0
[line_break_token][line_break_token]**Feedback for improvement:**[line_break_token][line_break_token]- The type setting could be improved at times.	Review	O	0
E.g. below equation (1).	Review	B-Review	1
[line_break_token]- I feel that the term "exploration" is overloaded.	Review	O	0
While it serves as an explicit mean to reduced the sample complexity of methods in RL, it appears to be about avoiding premature convergence in this work.	Review	B-Review	2
I am too unfamiliar with the relevant SOC literature to judge how well the term fits, but coming from a ML background I stumbled over this expression.	Review	I-Review	2
[line_break_token]- Some of the experimental details, e.g. the exact choice of time discretisation, don't appear motivated well.	Review	O	0
[line_break_token]- The paper needs to respect [1, 2] in the related work and show relations.	Review	O	0
From the perspective of learning state representations for optimal control, both works are relevant.	Review	B-Review	4
[line_break_token]- Is it necessary to start the discussion from the continuous case?	Review	O	0
While I appreciate the elegance of starting out with a continuous problem and then discretising at the last step, it felt like a barrier to understanding in my case, as my understanding of continuous optimal control is limited‚Äìand I feel the audience of ICLR might have the same problem.	Review	B-Review	5
[line_break_token][line_break_token]**References:**[line_break_token][line_break_token][1] Watter, Manuel, et al. "	Review	O	0
Embed to control: A locally linear latent dynamics model for control from raw images." *	Review	O	0
Advances in neural information processing systems*. 2015.	Review	O	0
[line_break_token][2] Banijamali, Ershad, et al. "	Review	O	0
Robust locally-linear controllable embedding." *	Review	O	0
arXiv preprint arXiv:1710.05373*(2017).	Review	O	0
e want to clarify that the main contribution of the paper is the introduction of a recurrent neural network architecture tailored to solve a novel representation (second order FBSDEs with control) of the stochastic optimal control problem involving nonlinear systems wherein noise entering the system has a multiplicative effect with the applied controls.	Reply	B-Reply	4
We work with known dynamics and full state information, hence the papers [1, 2] mentioned by the reviewer are not relevant to the problem we propose.	Reply	I-Reply	4
Our 2FBSDE controller does not extract or rely on a latent representation of the observations.	Reply	I-Reply	4
[line_break_token][line_break_token]Regarding the exact choice of time discretization, the values were hand-tuned until we observed numerical stability, convergence of training (or optimization in case of iLQG) and reasonable task performance.	Reply	I-Reply	3
We would like to reiterate that in the case of iLQG, finer time discretizations were required as compared to FBSDE and 2FBSDE.	Reply	I-Reply	3
As far as the linear system time discretization, we used the same value as in Bakshi et al. (	Reply	I-Reply	3
2017).	Reply	I-Reply	3
[line_break_token][line_break_token]Since our framework relies on the transformation of the HJB PDE to 2FBSDEs which in turn relies on mathematical results from stochastic calculus of continuous time systems, it is therefore necessary to start with the continuous time representation and only discretize the problem at the very end	Reply	I-Reply	5

A new auto-encoder method is proposed.	Review	O	0
Features are learned by minimizing the sum of the square reconstruction error and a penalty on feature dissimilarity weighted according to a variety of criteria.	Review	O	0
The basic idea is to weight more strongly the features that are in the neighborhood of the training sample or based on the class labels.	Review	O	0
[line_break_token]A multi-layer version of the autoencoder is proposed by following the layer-wise training protocol.	Review	O	0
[line_break_token]The method is tested using several metric on a few small datasets.	Review	O	0
[line_break_token][line_break_token]Strengths[line_break_token]The problem is relevant and interesting.	Review	O	0
[line_break_token]The method is technically sound.	Review	O	0
[line_break_token][line_break_token]Weaknesses[line_break_token]The paper lacks clarity.	Review	O	0
It does not read well and the language is often vague (what does it mean ‚Äúrepresent well‚Äù or ‚Äúpositive impact‚Äù or ‚Äúhurt numerical optimization‚Äù?).	Review	B-Review	4
[line_break_token]The paper is also rather incremental.	Review	I-Review	3
The idea is similar to [6] but also related to methods for dimensionality reduction like deep parametric t-sne (see R. Min, L.J.P. van der Maaten, Z. Yuan, A. Bonner, and Z. Zhang.	Review	I-Review	3
Deep Supervised t-Distributed Embedding.	Review	I-Review	3
In Proceedings of the International Conference on Machine Learning (ICML), pages 791-798, 2010 ) and methods like H. Mobahi, R. Collobert, J. Weston.	Review	O	0
Deep Learning from Temporal Coherence in Video.	Review	O	0
ICML 2009.	Review	O	0
[line_break_token]In this light, it would be valuable to add a discussion of the advantages of this method versus [6], for instance.	Review	B-Review	1
The major difference is that the reconstruction error replaces the ‚Äúpull apart‚Äù term in the loss function.	Review	I-Review	1
What‚Äôs the advantage of having an explicit decoder?	Review	I-Review	1
Doesn‚Äôt it introduce even more parameters in the model?	Review	I-Review	1
[line_break_token]Finally, the empirical validation could be more convincing if the authors used larger datasets where many other authors already benchmarked (e.g., cifar, mnist, timit, svhn, to mention a few).	Review	I-Review	2
Thanks for the comments.	Reply	O	0
We have some responses below, and uploaded a new version of paper to clarify some problems.	Reply	O	0
In our new version, we mainly revised Section 1 and Section 2, and we add some experiments at Section 4.1.	Reply	O	0
The experiments we add may give some insights about the comparison to [6] and the meaning of the reconstruction error.	Reply	O	0
[line_break_token]-------------------------------------------[line_break_token]‚Äú‚Ä¶related to methods for dimensionality reduction like deep parametric t-sne‚Ä¶. Deep Supervised t-Distributed Embedding‚Äù[line_break_token]For the similar works ‚ÄòDeep Learning from Temporal Coherence in Video‚Äô and ‚ÄòDeep Supervised t-Distributed Embedding‚Äô mentioned.	Reply	O	0
The inspiration of pairwise constraint is different.	Reply	B-Reply	3
The pairwise constraints in these papers are derived from supervised or human knowledge information while ours, derived from a manifold property, which is more slight and available in an unsupervised work.	Reply	I-Reply	3
[line_break_token]-------------------------------------------[line_break_token]‚ÄúIn this light, it would be valuable to add a discussion of the advantages of this method versus [6], for instance.	Reply	O	0
The major difference is that the reconstruction error replaces the ‚Äúpull apart‚Äù term in the loss function.	Reply	O	0
What‚Äôs the advantage of having an explicit decoder?	Reply	O	0
Doesn‚Äôt it introduce even more parameters in the model?‚Äù[line_break_token]Compared with [6], the convolutional neural network may be a reason, making it can be trained with a single graph loss function.	Reply	O	0
In our case of fully connected neural network, we can‚Äôt minimize the graph regularizer directly, we need layer-wise pre-training.	Reply	B-Reply	1
Furthermore, in our experiment, pre-training with only graph regularization cannot work.	Reply	I-Reply	1
It may give some insights on the reconstruction error term.	Reply	I-Reply	1
[line_break_token]Besides, in supervised learning, one can fine-tune the deep architecture with supervised weight matrix since they have training labels.	Reply	I-Reply	1
However, in unsupervised learning, samples with different labels may be connected in unsupervised weight matrix.	Reply	I-Reply	1
If we fine-tune the deep architecture with unsupervised graph regularization, clustering result might be worse since the wrong information would be fitted better.	Reply	I-Reply	1
So we only use pre-training since the reconstruction error and the graph regularization can interact on each other, and we can find the balance through grid based search so that the local invariants are kept and the effect of wrong information is small.	Reply	I-Reply	1
[line_break_token]-------------------------------------------[line_break_token]‚ÄúFinally, the empirical validation could be more convincing if the authors used larger datasets‚Äù[line_break_token]The datasets we choose are more frequently used for clustering, which is an evaluation method of dimension reduction techniques.	Reply	O	0
We would like to take experiments on large dataset for supervised learning in future work	Reply	B-Reply	2

This paper presents a deep network architecture which processes data using multiple parallel branches and combines the posterior from these branches to compute the final scores; the network is trained in end-to-end, thus training the parallel branches jointly.	Review	O	0
Existing literature with branching architecture either employ a 2 stage training approach, training branches independently and then training the fusion network, or the branching is restricted to local regions (set of contiguous layers).	Review	O	0
In effect, this paper extends the existing literature suggesting end-to-end branching.	Review	O	0
While the technical novelty, as described in the paper, is relatively limited, the thorough experimentation together with detailed comparisons between intuitive ways to combine the output of the parallel branches is certainly valuable to the research community.	Review	O	0
[line_break_token][line_break_token]+ Paper is well written and easy to follow.	Review	O	0
[line_break_token]+ Proposed branching architecture clearly outperforms the baseline network (same number of parameters with a single branch) and thus offer yet another interesting choice while creating the network architecture for a problem[line_break_token]+ Detailed experiments to study and analyze the effect of various parameters including the number of branches as well as various architectures to combine the output of the parallel branches.	Review	O	0
[line_break_token]+ [Ease of implementation] Suggested architecture can be easily implemented using existing deep learning frameworks.	Review	O	0
[line_break_token][line_break_token]- Although joint end-to-end training of branches certainly brings value compared to independent training, but the increased resource requirements may limits the applicability to large benchmarks such as ImageNet.	Review	O	0
While authors suggests a way to circumvent such limitations by training branches on separate GPUs but this would still impose limits on the number of branches as well as its ease of implementation.	Review	B-Review	1
[line_break_token]- Adding an overview figure of the architecture in the main paper (instead of supplementary) would be helpful.	Review	O	0
[line_break_token]- Branched architecture serve as a regularization by distributing the gradients across different branches; however this also suggests that early layers on the network across branches would be independent.	Review	O	0
It would helpful if authors would consider an alternate archiecture where early layers may be shared across branches, suggesting a delayed branching, with fusion at the final layer.	Review	B-Review	3
[line_break_token]- One of the benefits of architectures such as DenseNet is their usefulness as a feature extractor (output of lower layers) which generalizes even to domain other that the dataset; the branched architecture could potentially diminish this benefit.	Review	O	0
[line_break_token][line_break_token]Minor edits: Page 1. '	Review	B-Review	5
significantly match and improve' => 'either match or improve'[line_break_token][line_break_token]Additional notes:[line_break_token]- It would interesting to compare this approach with a conditional training pipeline that sequentially adds branches, keeping the previous branches fixed.	Review	O	0
This may offer as a trade-off between benefits of joint training of branches vs being able to train deep models with several branches.	Review	B-Review	6
[line_break_token]	Review	O	0
Thank you for the review and valuable feedback.	Reply	O	0
Please find our responses to your questions below:[line_break_token][line_break_token]1.	Reply	O	0
Although joint end-to-end training of branches certainly brings value compared to independent training, but the [line_break_token]increased resource requirements may limits the applicability to large benchmarks such as ImageNet.	Reply	O	0
While authors [line_break_token]suggests a way to circumvent such limitations by training branches on separate GPUs but this would still impose [line_break_token]limits on the number of branches as well as its ease of implementation.	Reply	O	0
[line_break_token][line_break_token]Coupled ensemble learning is precisely a way to increase the performance (minimizing the top-1 error rate) for a [line_break_token]given parameter budget (and/or for a given memory budget, see section B) and/or for a given [line_break_token]training time budget (see section G)).	Reply	B-Reply	1
Regarding the training on multiple GPUs, branch parallelism [line_break_token]is a quite natural and efficient way to split the storage and to parallelize the computation but this is not the only [line_break_token]possible one.	Reply	I-Reply	1
Also, our experiments suggest that the network performance does not critically depends on the exact [line_break_token]number of branches.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
Adding an overview figure of the architecture in the main paper (instead of supplementary) would be helpful.	Reply	O	0
[line_break_token][line_break_token]A figure has been inserted in section 3.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token]3.	Reply	I-Reply	2
Branched architecture serve as a regularization by distributing the gradients across different branches; however [line_break_token]this also suggests that early layers on the network across branches would be independent.	Reply	O	0
It would helpful if authors [line_break_token]would consider an alternate architecture where early layers may be shared across branches, suggesting a delayed [line_break_token]branching, with fusion at the final layer.	Reply	O	0
[line_break_token][line_break_token]Thanks for the suggestion.	Reply	B-Reply	3
We planned to investigate this but we did not have enough time before the deadline and [line_break_token]the paper is already quite long.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]4.	Reply	O	0
One of the benefits of architectures such as DenseNet is their usefulness as a feature extractor (output of lower [line_break_token]layers) which generalizes even to domain other that the dataset; the branched architecture could potentially diminish [line_break_token]this benefit.	Reply	O	0
[line_break_token][line_break_token]We see no a priori reason why features extracted by branched architecture should be less efficient than those [line_break_token]extracted from non-branched ones.	Reply	B-Reply	4
We even see no a priori reason either why the benefit they bring in classification [line_break_token]tasks should not be transferred also with the extracted features.	Reply	I-Reply	4
We will conduct such transfer [line_break_token]experiments in the future.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]5.	Reply	I-Reply	4
It would interesting to compare this approach with a conditional training pipeline that sequentially adds [line_break_token]branches, keeping the previous branches fixed.	Reply	O	0
This may offer as a trade-off between benefits of joint training of [line_break_token]branches vs being able to train deep models with several branches[line_break_token][line_break_token]Thanks for the suggestion.	Reply	O	0
We had planned to investigate this but we did not have enough time before the deadline.	Reply	B-Reply	6

This paper studies the mean field models of learning neural networks in the teacher-student scenario.	Review	O	0
The main contributions are summarized in Theorems 2-4, which characterize the stationary distribution of gradient-descent learning [line_break_token]for what are commonly called committee machines.	Review	O	0
Theorem 2 is for a committee of simple perceptrons, whereas Theorem 3 is for what the authors call the ensemble-ResNet, which is in fact a committee of ResNets, and Theorem 4 is for what the authors call the wide-ResNet, which is actually a stacked committees of simple perceptrons.	Review	O	0
[line_break_token][line_break_token]These three theorems are straightforward to derive from differentiation of the expected squared loss E[\rho] with respect to \rho and equating the result with zero.	Review	O	0
The argument in Example 2 in Section 2.1 has flaws.	Review	O	0
The argument on the wide-ResNet is based on the linear approximation, which effectively reduces the stacked committee network to a large committee of simple perceptrons, so that its significance should be quite limited.	Review	O	0
Because of these reasons, I would not be able to recommend acceptance of this paper.	Review	O	0
[line_break_token][line_break_token]The authors do not seem to know the existing literature on analysis of learning committee machines.	Review	B-Review	1
See e.g. [R1] and numerous subsequent papers that cite it.	Review	I-Review	1
[line_break_token][line_break_token]In Example 2, the authors claim that when \sigma is an odd function \rho is a stationary distribution if and only if the difference is an even function.	Review	I-Review	2
This claim is not true in general.	Review	I-Review	2
Consider the case where \sigma is a sign function.	Review	I-Review	2
Then for any function f(\theta) satisfying \int_0^\infty f(\theta) d\theta=0 (such functions are straightforward to construct), let g(\theta)=f(\theta) if \theta\ge0, and g(\theta)=-f(-\theta) if \theta&lt;0.	Review	O	0
Then \int \sigma(x\cdot\theta)g(\theta) d\theta=0 holds, whereas g is an odd function.	Review	B-Review	2
This is a counterexample of the authors' claim here.	Review	I-Review	2
Many more such counterexamples are quite easily constructed on the basis of orthogonal polynomials, demonstrating that the stated stationary condition in Theorem 2 may not be so strong for characterizing the stationary distribution.	Review	I-Review	2
[line_break_token][line_break_token]Page 2, line 30: Given a function (f -&gt; y)[line_break_token]Page 2, line 38: I do not understand what the subscript of the integral sign means.	Review	O	0
[line_break_token]Page 2, line 40: The last term should be squared.	Review	B-Review	3
[line_break_token]Page 3, line 7: Should \theta_j be \theta_j(t)?	Review	I-Review	3
Should \rho(\theta) be \rho(t,\theta)?	Review	I-Review	3
[line_break_token]Page 3: Both \rho(t,\theta) and \rho(\theta,t) appear, which are inconsistent.	Review	I-Review	3
[line_break_token]Page 3, line 16: under (the the) Wasserstein metric[line_break_token]Page 3, line 22: \rho_0(x) should probably read \rho(0,\theta).	Review	I-Review	3
[line_break_token]Page 3, line 26: "should follow normal reflection" I do not understand the reason for it.	Review	I-Review	3
How \theta_i(t) should behave when it hits the boundary depends on how the gradient-descent algorithm is defined in such cases.	Review	I-Review	3
[line_break_token]Page 6, line 7, page 7, line 18: "The GD/SGD algorithm": What is shown here is the GD algorithm and is not the SGD.	Review	I-Review	3
[line_break_token]Page 7, line 14: and (vanishes -&gt; to vanish)[line_break_token][line_break_token][R1] David Saad and Sara A. Solla, "On-line learning in soft committee machines," Physical Review E, volume 52, number 4, pages 4225-4243, October 1995.	Review	O	0
[line_break_token]	Review	O	0
 have read the other review comments as well as the author responses.	Reply	O	0
On the basis of them, I would like to keep my initial rating, since the author responses do acknowledge my concerns but not seem to resolve them	Reply	O	0

The paper aims to develop a deep generative model, which -unlike VAEs or GANs- comprises a hierarchy of latent variables rather than a direct map from the stochastic latent manifold to the observation space.	Review	O	0
To this end, the paper builds a training objective based on nesting the Wasserstein distance between the data distribution and its estimation arbitrarily many times.	Review	O	0
The generated objective corresponds naturally to a deep hierarchical generative model.	Review	O	0
[line_break_token][line_break_token]The principled approach followed to achieve the objective is solid and elegant.	Review	O	0
It is also intuitive and matches nicely with some valid observations highlighted in the paper such as insufficiency of by-passing intermediate latent variables (sentence above the Sec 2.3 title).	Review	O	0
[line_break_token][line_break_token]One major weakness of the paper is that it lacks a sufficient argumentation about how it differentiates from earlier attempts to nest Wasserstein distances.	Review	B-Review	1
For instance,[line_break_token][line_break_token]Y. Dukler et al., "	Review	I-Review	1
Wasserstein of Wasserstein Loss for Learning Generative Models", ICML, 2019[line_break_token][line_break_token]Apart from the theoretical argumentation, the paper should also compare their solution to this prior work on a number of benchmarks.	Review	I-Review	1
[line_break_token][line_break_token]Another major weakness is that the paper lacks a quantitative evaluation scheme for its success.	Review	I-Review	2
The experiments section starts with the claim that the proposed method "significantly" improves on the WAE, which I fail to see on the plots.	Review	I-Review	2
[line_break_token][line_break_token]Lastly, Having said that the proposed method is novel and elegant, it is still a straightforward extension of the existing and well-known Wasserstein Auto-Encoder (WAE) approach.	Review	I-Review	4
It extends WAEs by repetitively applying the tricks proposed by this earlier work, putting aside some minor additional adjustments.	Review	I-Review	4
[line_break_token][line_break_token]Minor on style: The abstract does not give any single hint about the methodological novelty of the work.	Review	O	0
[line_break_token][line_break_token]---[line_break_token]Post-rebuttal: Thanks to authors for their effort for clarifications.	Review	O	0
Yet, I'm afraid the author response does not touch at all to any of the concerns I have raised.	Review	B-Review	5
There are well-known ways to compare the success of generative models, FID being one of them as the authors point out.	Review	I-Review	5
Another could be the test log-likelihood of a synthetic data set the true distribution of which can be predesigned.	Review	I-Review	5
I understand the issues the authors raise about the difficulties in comparing generative models, but I kindly disagree with the attitude that there are no ways to compare, so we are obliged to live with qualitative comparisons.	Review	I-Review	5
If a one-score comparison is not enough, the right way to go is to provide multiple scores.	Review	I-Review	5
If direct metrics are not feasible, one should go for indirect ones, but should still provide outcomes a reader can reproduce.	Review	I-Review	5
e thank the reviewer for their feedback.	Reply	O	0
[line_break_token][line_break_token]The reviewer identified 3 areas on which they felt the draft could be stronger: (i) incrementality versus[1], (ii) quantitative evaluations of Stacked WAE versus other methods, and (iii) purported lack of significance in addition to the standard WAE framework.	Reply	O	0
We believe that, unfortunately, this review has misunderstood our work.	Reply	O	0
In particular:[line_break_token][line_break_token](i) the comparison with [1] misunderstands the difference between our approach to "stacking" WAE losses and the "nesting" of Wasserstein distances in [1],[line_break_token][line_break_token](ii) the lack of quantitative comparisons is a result of our work using a novel non-likelihood based objective, which prohibits natural single-metric comparisons, and[line_break_token][line_break_token](iii) our work is a mathematically clean and qualitatively incremental contribution on top of the existing WAE approach, enabling the training of latent-variable models that the WAE outright fails to train.	Reply	O	0
[line_break_token][line_break_token]We address each of these points in turn.	Reply	O	0
[line_break_token][line_break_token][1] propose to nest Wasserstein distances in the sense that they use the Wasserstein distance in the space of the images pixels as their.	Reply	B-Reply	1
They then use the dual formulation of the 1-Wasserstein distance (in the image space) to derive an adversarial objective for training generative models.	Reply	I-Reply	1
This differs from our work in 2 paradigmatic ways.	Reply	I-Reply	1
Firstly, while [1] use the "nested" Wasserstein distance as their ground metric for the Wasserstein distance, we use the "nested" Wasserstein distance as a regularisation term on the space of latent distributions in the formulation of the WAE objective.	Reply	I-Reply	1
Secondly, the objective in[1] is trained using an adversarial scheme and thus, no encoder network allows for the mapping from the observation space to the latent space.	Reply	I-Reply	1
In our work, we are interested in training deep-hierarchical generative models in the autoencoder framework, with an encoder network allowing us to learn a meaningful latent manifold.	Reply	I-Reply	1
The role of the "nested" Wasserstein distance in these two works is thus only the same in nomenclature: [1] actually a Wasserstein distance in the pixel space as their ground metric, while we a Wasserstein distance as a latent regulariser in the WAE objective.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree with the reviewer that a rigorous comparison with existing methods is important.	Reply	I-Reply	2
That said, the form of the WAE loss makes such a comparison hard.	Reply	I-Reply	2
Indeed, in the WAE, the relaxation of the hard constraint on the coupling of the data distribution and the generative distribution introduces a hyperparameter that will be tuned for each experiments.	Reply	I-Reply	2
Moreover, the WAE objective is a likelihood free method, making it hard to compare with the common likelihood based methods.	Reply	I-Reply	2
A good metric that enables the comparisons between likelihood and non-likelihood methods remains to be discovered.	Reply	I-Reply	2
One attempt at comparing generative models trained with non-comparable objectives is to use sample-based metrics such as the FID score ([2]).	Reply	I-Reply	2
However, given the data sets considered in our work, we felt that such metric would not be relevant.	Reply	I-Reply	2
Despite this, we do perform a qualitative comparison with the original WAE method when training deep hierarchical models.	Reply	I-Reply	2
We intuitively explain why WAEs would fail in training deep hierarchical latent models in section 2.2 (see Equation (7)) and then show empirically in section 3.1 that it is indeed the case (see Figure 4).	Reply	I-Reply	2
While the 5-layer generative model trained as WAE achieved good reconstructions (Figure 4a), the samples are significantly worse than those obtained using our Stacked WAE (Figure 4b versus Figure 2b) and no structure was learnt in the deep latent space (Figure 4c versus Figure 2c).	Reply	I-Reply	2
[line_break_token][line_break_token]Finally, while our Stacked WAE method is indeed built on the well-known WAE objective and consists of stacking WAE modules on the top of each other, the novelty resides in the way we unroll the original WAE objective, using WAEs as latent regularisers at each layer, enabling the hierarchical model to leverage all of its deep layers.	Reply	I-Reply	4
This allows for the propagation of information from the observation space all the way to the deepest latent layer in fully factorised Markov models, and by doing so, it captures the data structure all along the hierarchy.	Reply	I-Reply	4
This result, which we clearly demonstrate, is something that both WAEs and VAEs outright fail at.	Reply	I-Reply	4
In this sense we do not consider our work to be an insignificant contribution on top of the pre-existing WAE framework.	Reply	I-Reply	4
[line_break_token][line_break_token]We hope that this review might either be amended significantly given that it seems to have misunderstood both our work and the relevant literature.	Reply	O	0
[line_break_token][line_break_token][1]: Y. Dukler,  W. Li, A. Lin and G. Montufar.	Reply	O	0
Wasserstein of Wasserstein Loss for Learning Generative Models.	Reply	O	0
In International Conference on Machine Learning, 2019.	Reply	O	0
[line_break_token][2]: M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter.	Reply	O	0
Gans trained by a two time-scale update rule converge to a local nash equilibrium.	Reply	O	0
In Advances in neural information processing systems, 2017.	Reply	O	0

The paper proposes a VAE-style model for identifying motifs from calcium imaging videos.	Review	O	0
As opposed to standard VAE with Gaussian latent variables it relies on Bernouli variables and hence, requires Gumbel-softmax trick for inference.	Review	O	0
Compared to methods based on matrix factorization, the proposed method has the advantage of not requiring any preprocessing on the imaging videos.	Review	O	0
My main comments are as follows:[line_break_token][line_break_token]- How sensitive is the method to the choice of beta and other hyperparameters?	Review	O	0
 Compared to SCC which has fewer hyperparameters, how robust is the method?	Review	B-Review	1
[line_break_token]- How does it perform on real data compared to methods based on spike time matrices?	Review	O	0
Do they generate similar motifs?	Review	B-Review	2
[line_break_token]- The application of the method seems quite limited to calcium imaging videos and it does not provide comparison with other deep generative models for videos.	Review	O	0
Methods such as Johnson et al.	Review	B-Review	3
NIPS 2016 (Composing graphical models with neural networks for structured representations and fast inference) can also be applied to calcium imaging datasets and can potentially infer the motifs.	Review	I-Review	3
[line_break_token][line_break_token]I believe the problem of inferring the neural motifs is an interesting problem; however, I think this paper requires more work to it shows its advantages over other deep generative models for video data and also it‚Äôs performance on real data compared to SCC (or some other matrix factorization based approach).	Review	I-Review	4
[line_break_token]-----------------------------------------------------------------------[line_break_token]The authors have addressed my comments about other deep generative models and hyperparameter sensitivity.	Review	O	0
However, I still think the paper is more suitable for other venues with readers from the neuroscience community.	Review	O	0
Hence, I change my rating to 5.	Review	O	0
We appreciate the reviewers comments and will address them in the following and in the revised version of the manuscript which is already uploaded.	Reply	O	0
[line_break_token][line_break_token]Sensitivity to parameters: [line_break_token]The main parameters that need to be chosen for each dataset individually are the maximum number of motifs and the maximum motif length.	Reply	O	0
In appendix E.1 and E.2 we show the effects of over- and under-estimating these numbers for LeMoNADe and that they can be set to quite liberal values.	Reply	B-Reply	1
Additionally, one of the sparsity parameters beta or √¢ has to be adapted to the dataset.	Reply	I-Reply	1
In appendix E.3 of the revised version we provide examples of different settings of √¢ and beta, showing that they are complementary.	Reply	I-Reply	1
This leaves us with three parameters that have to be adapted to a new dataset.	Reply	I-Reply	1
For SCC also three parameters have to be chosen: number of motifs, motif length, penalty on l_1 norm of the assemblies = sparsity parameter.	Reply	I-Reply	1
[line_break_token]The examples in appendix E.3 also indicate that LeMoNADe's results are robust to small variations of √¢ and beta and the results only change significantly when the parameters are varied by more than one order of magnitude.	Reply	I-Reply	1
Peter et al.	Reply	I-Reply	1
describe a similar sensitivity of SCC to the variation of their sparsity parameter.	Reply	I-Reply	1
[line_break_token]Other hyper parameters of LeMoNADe (e.g. temperatures of the BinConcrete relaxation, learning rate) do not need to be adapted to different datasets.	Reply	I-Reply	1
We found that our default settings worked well for different kinds of data.	Reply	I-Reply	1
[line_break_token][line_break_token]Results on real data compared to SCC results:[line_break_token]In appendix D.3 of the revised version we now show the results obtained with SCC on calcium traces of manually extracted ROIs from one of the datasets discussed in the paper.	Reply	O	0
We also show, using traces extracted from the motif identified with LeMoNADe on the original dataset, that SCC and LeMoNADe find highly similar motifs on real data.	Reply	B-Reply	1
 [line_break_token][line_break_token]Other generative models: [line_break_token]As we mention in the related work section, a few deep generative models exist dealing with video data.	Reply	O	0
However, to the best of our knowledge, none of these models is directly applicable to the task of detecting motifs with temporal structure in calcium imaging data.	Reply	B-Reply	4
 [line_break_token]Indeed, Johnson et al.	Reply	I-Reply	4
present an interesting generative model for the analysis of video data.	Reply	I-Reply	4
However, we consider this model as not being able to identify motifs with temporal structure from calcium imaging data due to two limitations (for the detection of motifs in calcium videos) of the model by Johnson et al.:	Reply	I-Reply	4
[line_break_token]1.	Reply	O	0
Neuronal assemblies are expected to extend over multiple frames (depending on[line_break_token]the frame rate of the recording this could be easily more than 20 frames).	Reply	B-Reply	4
Since in Johnson[line_break_token]et al.	Reply	I-Reply	4
's model the underlying latent process is a relatively simple first-order Markovian (switching) linear process, representing longer-term temporal dependencies will be very hard to achieve due to the usually exponential forgetting in such systems.	Reply	I-Reply	4
In fact, Johnson et al.	Reply	I-Reply	4
's framework would need to be significantly extended, e.g. using LSTM units, to adapt their model for this task, which is a non-trivial task and could be considered to be a paper in its own right.	Reply	I-Reply	4
[line_break_token]2.	Reply	O	0
In the model of Johnson et al.	Reply	B-Reply	4
each frame is generated from exactly one of K latent states.	Reply	I-Reply	4
For calcium imaging, however, most frames are not generated by one of the motifs but from noise.	Reply	I-Reply	4
While LeMoNADe has the chance to set the latent variables for noise frames simply to zero, Johnson et al.	Reply	I-Reply	4
's model would have to choose one motif as responsible for the frame even if it contains only noise.	Reply	I-Reply	4
Moreover, LeMoNADe has the flexibility to also allow the different motifs to temporally overlap.	Reply	I-Reply	4
This is also not possible in the model by Johnson et al.,	Reply	I-Reply	4
since they allow always only exactly one latent state for each frame.	Reply	I-Reply	4
 [line_break_token]For this reason, we cannot compare to Johnson et al.	Reply	I-Reply	4
on the task of detecting motifs in calcium imaging data.	Reply	I-Reply	4
In the revised version of the manuscript we extended our citation of Johnson et al.	Reply	I-Reply	4
with a short explanation why the model is not directly applicable to our setup of motif detection from calcium imaging data.	Reply	I-Reply	4
[line_break_token][line_break_token]The application is limited to calcium imaging data:[line_break_token]The model and network architectures are indeed optimised for the task of detecting motifs in calcium imaging data.	Reply	O	0
This is, however, no downside of the method.	Reply	B-Reply	3
Calcium imaging is a method of first importance in neurophysiology.	Reply	I-Reply	3
It allows the concurrent monitoring of the individual actions of thousands of neurons at the same time.	Reply	I-Reply	3
As explained above, no other method is directly applicable to finding temporal motifs in calcium imaging data and in order to do so we had to adapt our method to the special properties of calcium imaging and neuronal assemblies.	Reply	I-Reply	3
Nevertheless, our approach could also be adapted for detecting spatio-temporal motifs in data from other imaging techniques, such as voltage-sensitive dyes or functional magnetic resonance imaging (fMRI)	Reply	I-Reply	3

Let me first note that I am not very familiar with the literature on program generation, [line_break_token]molecule design or compiler theory, which this paper draws heavily from, so my review is an educated guess.	Review	O	0
[line_break_token][line_break_token]This paper proposes to include additional constraints into a VAE which generates discrete sequences, [line_break_token]namely constraints enforcing both semantic and syntactic validity.	Review	O	0
[line_break_token]This is an extension to the Grammar VAE of Kusner et.	Review	O	0
al, which includes syntactic constraints but not semantic ones.	Review	O	0
[line_break_token]These semantic constraints are formalized in the form of an attribute grammar, which is provided in addition to the context-free grammar.	Review	O	0
[line_break_token]The authors evaluate their methods on two tasks, program generation and molecule generation.	Review	O	0
[line_break_token][line_break_token]Their method makes use of additional prior knowledge of semantics, which seems task-specific and limits the generality of their model.	Review	B-Review	1
[line_break_token]They report that their method outperforms the Character VAE (CVAE) and Grammar VAE (GVAE) of Kusner et.	Review	I-Review	1
al.	Review	I-Review	1
 [line_break_token]However, it isn't clear whether the comparison is appropriate: the authors report in the appendix that they use the kekulised version of the Zinc dataset of Kusner et.	Review	I-Review	1
al, whereas Kusner et.	Review	I-Review	1
al do not make any mention of this.	Review	I-Review	1
[line_break_token]The baselines they compare against for CVAE and GVAE in Table 1 are taken directly from Kusner et.	Review	I-Review	1
al though.	Review	I-Review	1
[line_break_token]Can the authors clarify whether the different methods they compare in Table 1 are all run on the same dataset format?	Review	I-Review	1
[line_break_token][line_break_token]Typos:[line_break_token]- Page 5: "while in sampling procedure" -> "while in the sampling procedure"[line_break_token]- Page 6: "a deep convolution neural networks" -> "a deep convolutional neural network"[line_break_token]- Page 6: "KL-divergence that proposed in" -> "KL-divergence that was proposed in" [line_break_token]- Page 6: "since in training time" -> "since at training time"[line_break_token]- Page 6: "can effectively computed" -> "can effectively be computed"[line_break_token]- Page 7: "reset for training" -> "rest for training"	Review	O	0
Thanks for your effort in providing this detailed and useful review!	Reply	O	0
[line_break_token][line_break_token]We present our clarification in the following:[line_break_token][line_break_token]> Use of data and comparison with baselines:[line_break_token][line_break_token]We would first note that the anonymous accusation was set to ‚Äú17 Nov 2017 (modified: 28 Nov 2017), readers: ICLR 2018 Conference Reviewers and Higher‚Äù.	Reply	O	0
That‚Äôs why it was not visible to us until Nov 28, i.e., the original review release date.	Reply	B-Reply	1
This gives us no chance to clarify anything before the review deadline.	Reply	I-Reply	1
We have replied to it actively since Nov 28.	Reply	I-Reply	1
[line_break_token]**Note the thread is invisible to us again since Dec 2. **	Reply	I-Reply	1
[line_break_token][line_break_token]1) We have experimented both kekulization and non-kekulization for baselines, and have reported the best they can get in all experiments.	Reply	I-Reply	1
For example, in Table 2 the GVAE baseline results are improved compared to what was reported in GVAE paper.	Reply	I-Reply	1
[line_break_token][line_break_token]2) The anonymous commenter is using different kekulization (RDKIT, rather than our used Marvin), different baseline implementation (custom implementation, rather than the public one in GVAE‚Äôs paper) and possibly different evaluation code (since there is no corresponding evaluation online).	Reply	I-Reply	1
For a reproducible comparision, we released our implementation, data, pretrained model and evaluation code at:  <a href="https://github.com/anonymous-author-80ee48b2f87/cvae-baseline" target="_blank" rel="nofollow">https://github.com/anonymous-author-80ee48b2f87/cvae-baseline</a>[line_break_token][line_break_token]3) To make further clarification, we ran our method on the vanilla (non-kekulised) data.	Reply	O	0
Our performance is actually boosted (76.2% vs 72.8% reported in the paper).	Reply	B-Reply	1
[line_break_token]The details of results from these experiments above can be seen in our public reply titled ‚ÄúWe released baseline CVAE code, data and evaluation code for clarification‚Äù and ‚ÄúOur reconstruction performance without kekulization on Zinc dataset‚Äù.	Reply	I-Reply	1
[line_break_token][line_break_token]In either setting still, our method outperforms all baselines on reconstruction.	Reply	I-Reply	1
We are sorry that this may have led to some confusions.	Reply	I-Reply	1
To avoid further possible misunderstandings, we have extensively rerun all experiments involving ZINC dataset.	Reply	I-Reply	1
Though differences are observed, the conclusion in each experiment remains the same.	Reply	I-Reply	1
For example, our reconstruction performance is boosted (76.2% vs 72.8%).	Reply	I-Reply	1
Since we didn‚Äôt address aromaticity semantics by the paper submission deadline, the valid prior fraction drops to 43.5%, but it is still much higher than baselines (7.2% GVAE, 0.7% CVAE).	Reply	I-Reply	1
Please find the updated paper for more details.	Reply	I-Reply	1
[line_break_token][line_break_token]> prior knowledge and limitations  [line_break_token][line_break_token]We are targeting on domains where strict syntax and semantics are required.	Reply	O	0
For example, the syntax and semantics are needed to compile a program, or to parse a molecule structure.	Reply	B-Reply	1
So such prior knowledge comes naturally with the application.	Reply	I-Reply	1
Our contribution is to incorporate such existing syntax and semantics in those compilers, into an on-the-fly generation process of structures.	Reply	I-Reply	1
[line_break_token][line_break_token]In general, when numerous amount of data is available, a general seq2seq model would be enough.	Reply	I-Reply	1
However, obtaining the useful drug molecules is expensive, and thus data is quite limited.	Reply	I-Reply	1
Using knowledges like syntax (e.g., in GVAE paper), or semantics (like in our paper) will greatly reduce the amount of data needed to obtain a good model.	Reply	I-Reply	1
[line_break_token][line_break_token]In our paper, we only addressed 2-3 semantic constraints, where the improvement is significant.	Reply	I-Reply	1
Similarly, in ‚ÄúHarnessing Deep Neural Networks with Logic Rules (Hu et.al, ACL 16)‚Äù, incorporating several intuitive rules can greatly improve the performance of sentiment analysis, NER, etc.	Reply	I-Reply	1
So we believe that, incorporating the knowledge with powerful deep learning achieves a good trade-off between human efforts and model performance.	Reply	I-Reply	1
[line_break_token][line_break_token]> Typos and other writing issue:[line_break_token][line_break_token]We thank you very much for your careful reading and pointing out the typos and writing issues in our manuscript!	Reply	O	0
We have incorporated your suggested changes in the current revision, and are keeping conducting further detailed proofreading to fix as much as possible the writing issues in the future revisions	Reply	B-Reply	2

The paper proposes an uncertainty driven acquisition for MRI reconstruction.	Review	O	0
Contrary to most previous approaches (which try to get best reconstruction for a fixed sampling pattern) the method incorporates an adaptive, on-the-fly masking building (which is similar in spirit to Zhang at al.	Review	O	0
2019).	Review	O	0
The measurements to acquire are selected based on variance/uncertainty estimates coming from a conditional GAN model.	Review	O	0
This is mostly an "application" paper that is evaluated on one dataset.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]- The paper studies an interesting problem of adaptive MRI reconstruction[line_break_token]- The review of MRI reconstruction techniques is well scoped[line_break_token][line_break_token]Weaknesses:[line_break_token]- The evaluation is rather limited and performed on one, proprietary, relatively small sized dataset[line_break_token]- Some simple baselines might be missing[line_break_token][line_break_token][line_break_token]I like the idea of adaptive sampling in MRI.	Review	O	0
However, I'd slightly lean towards rejection of the paper.	Review	O	0
My main concerns are as follows:[line_break_token][line_break_token]The presentation of the paper could be improved.	Review	O	0
At the moment, the Theory section describes background information, related work and problem definition as well as the contribution of the paper.	Review	B-Review	3
Maybe braking the section into related work, background and methodology (where the main contribution is presented) sections would improve the paper readability.	Review	I-Review	3
[line_break_token][line_break_token]The paper uses a conditional GAN model (with a discriminator from Adler &amp; Oktem, 2018 and a generator that is based on Schlemper et al.	Review	O	0
2018).	Review	B-Review	4
Making the methodological contribution to be rather limited.	Review	I-Review	4
 The main difference w.r.t.	Review	I-Review	4
the previous papers seem to be the last paragraph of  section 2.2 - the empirical variance estimation is performed in Fourier space.	Review	I-Review	4
[line_break_token][line_break_token]A simple baseline to compare might be to train a Unet-like model (e. g. Schlemper et al 2018) with a Gaussian observation model (outputting a mean and a variance per each pixel) and train it to minimize Gaussian NLL.	Review	I-Review	2
At the test time, one could simply sample from the Gaussian model instead of taking just the argmax of the output.	Review	I-Review	2
It might be the case that the assumption of gaussian image might be too simplistic, however, it would be interesting to show it experimentally.	Review	I-Review	2
Note that when sampling from such model the empirical variance estimation could be performed is the Fourier space too.	Review	I-Review	2
[line_break_token][line_break_token]The experimental evaluation is rather limited and the dataset used in the experimental section is small.	Review	I-Review	1
Adding another dataset would make the paper stronger.	Review	I-Review	1
[line_break_token][line_break_token]Other comments:[line_break_token][line_break_token]There is a mention on training dataset and testing dataset -- there is no mention on validation set.	Review	O	0
How were the hyperparamenters of the conditional GAN selected?	Review	B-Review	5
[line_break_token][line_break_token]As acknowledged by the authors, this paper bears several similarities with the work of Zhang at al.	Review	I-Review	6
2019.	Review	I-Review	6
However, the approach is not compared to Zhang et al.	Review	I-Review	6
Including this comparison would make the paper stronger.	Review	I-Review	6
[line_break_token][line_break_token]It is interesting to see that CLUDAS outperforms CLOMDAS in terms of SSIM.	Review	I-Review	7
If I understand this part properly, CLOMDAS uses ground truth image to estimate MSE.	Review	I-Review	7
Is it expected that CLUDAS would outperform CLOMDAS?	Review	I-Review	7
[line_break_token][line_break_token]Section 5, Adaptive vs. fixed mask: "We also have a simple generalization bound of the obtained mask, relaying on a simple application of Hoeffding's inequality."	Review	I-Review	8
Could the authors add a citation or explain this part in more detail?	Review	I-Review	8
[line_break_token][line_break_token][line_break_token]Some typos:[line_break_token]"...we aim make a series..."[line_break_token]".. define an closed-loop..."[line_break_token]"We choose adopt a greedy"[line_break_token]"... we we found that..." [line_break_token]	Review	O	0
hank you for your comments, corrections and suggestions.	Reply	O	0
 [line_break_token][line_break_token]*Summary:*[line_break_token]- Adler &amp; √ñktem have a fundamentally different task: sampling the full image space with low SNR vs. subsampling frequencies directly[line_break_token]- MRI technical terms will be clarified/avoided when possible ; presentation will be updated and suggested experiments will be incorporated[line_break_token][line_break_token]*Details:*[line_break_token]We would like to highlight that our contribution lies mainly in the demonstration of a closed-loop system that can adaptively design sampling masks for MRI without requiring access to a ground truth (CLUDAS).	Reply	O	0
 Adler and √ñktem did not at all consider the problem of sampling mask design, as the problem of acceleration by choosing few locations where data are acquired is not present in CT.	Reply	B-Reply	4
Rather, the challenge in CT is linked to obtain images with the lowest dose of radiation (i.e. data is sampled everywhere, but with low SNR).	Reply	I-Reply	4
We also successfully demonstrate that the application of their method to MRI can be efficiently leveraged to provide an alternative to optimizing for MSE when designing sampling masks.	Reply	I-Reply	4
 [line_break_token][line_break_token]The updated version that we will submit by the end of the week should contained a clarified presentation, and a more rigorous introduction of MRI-specific jargon.	Reply	O	0
We will also try to incorporate your suggestion of using a Unet-like mode with a Gaussian observation model, and will also perform experiments on the DICOM dataset used by Zhang et al.	Reply	O	0
However, as mentioned in the general comment, we cannot compare our results with Zhang et al.	Reply	B-Reply	6
directly due to their code not being available, even upon request.	Reply	I-Reply	6

Ullman et al.	Review	O	0
showed that slight changes in location or size of visible regions in minimal recognizable images can significantly impair human ability to recognize objects.	Review	O	0
This paper is a  follow-up of Ullman et al.	Review	O	0
paper, with focus on sensitivity of DNNs to certain regions in images.	Review	O	0
In other words, slight change of such regions‚Äô size or location in the image can significantly affect DNN ability in recognizing them, even-though these changes are not noticeable for humans.	Review	O	0
[line_break_token][line_break_token][line_break_token]Comments and questions:[line_break_token][line_break_token]This paper provides in-depth study of fragile recognition in DNNs.	Review	O	0
[line_break_token][line_break_token]- Visualizing activations of different layers of DNN for Loose shift/shrink FRIs can potentially provide more details on why the final output of DNN is significantly different for two visually similar images.	Review	O	0
  [line_break_token][line_break_token]- Naively augmenting training data with crops of small FRI sizes can potentially harm and confuse DNN in classifying training samples as many small patches in training images are background and they don't contain target object.	Review	O	0
It is interesting to see the sensitivity of DNNs that are trained for the task of object detection to FRIs, like sensitivity of R-CNN to FRIs.	Review	O	0
In this case augmenting training data with crops of small FRI sizes can be properly done since ground-truth bounding boxes can determine which region is foreground and which region is background.	Review	O	0
We thank the reviewer for her/his valuable comments and questions, which we address below.	Reply	O	0
[line_break_token][line_break_token]Reviewer: ‚ÄúVisualizing activations of different layers of DNN for Loose shift/shrink FRIs can potentially provide more details on why the final output of DNN is significantly different for two visually similar images.	Reply	O	0
‚Äù[line_break_token]Authors: We have added visualizations in Figure A.11.	Reply	O	0
As in previous works on adversarial examples, these visualizations do not clarify much beyond that fact that differences are small for the first layers, then are magnified at the later layers.	Reply	B-Reply	1
[line_break_token][line_break_token]Reviewer: ‚ÄúNaively augmenting training data with crops of small FRI sizes can potentially harm and confuse DNN in classifying training samples as many small patches in training images are background and they don't contain target object.	Reply	O	0
‚Äù[line_break_token]Authors: To verify that adding crops in the training set does not harm the accuracy, we added Fig.	Reply	O	0
A.2 in the paper, which shows that the accuracy of the network always improves when adding the crops in the training set.	Reply	B-Reply	2
This may be because in CIFAR the crops are always on the object, as the object is centered and occupies the whole CIFAR image.	Reply	I-Reply	2
For ImageNet, the tested networks add crops in the training set from the interior of the annotated bounding-box.	Reply	I-Reply	2
[line_break_token][line_break_token]Reviewer: ‚ÄúIt is interesting to see the sensitivity of DNNs that are trained for the task of object detection to FRIs, like sensitivity of R-CNN to FRIs.	Reply	O	0
‚Äù[line_break_token]Authors: We added Figure A.12 in the paper to show qualitative examples of FRIs for the YOLO object detector.	Reply	O	0
This result illustrates that object detectors also suffer from FRIs, as they are based on DNNs.	Reply	B-Reply	3
Quantifying how much the accuracy of the detectors is due to FRIs is an interesting follow up of our paper.	Reply	I-Reply	3

Studying the Hessian in deep learning, the experiments in this paper suggest that the eigenvalue distribution is concentrated around zero and the non zero eigenvalues are related to the complexity of the input data.	Review	O	0
I find most of the discussions and experiments to be interesting and insightful.	Review	O	0
However, the current paper could be significantly improved.	Review	O	0
[line_break_token][line_break_token]Quality:[line_break_token]It seems that the arguments in the paper could be enhanced by more effort and more comprehensive experiments.	Review	O	0
Performing some of the experiments discussed in the conclusion could certainly help a lot.	Review	O	0
Some other suggestions:[line_break_token]1- It would be very helpful to add other plots showing the distribution of eigenvalues for some other machine learning method for the purpose of comparison to deep learning.	Review	O	0
[line_break_token]2- There are some issues about the scaling of the weights and it make sense to normalize the weights each time before calculating the Hessian otherwise the result might be misleading.	Review	O	0
[line_break_token]3- It might worth trying to find a quantity that measures the singularity of Hessian because it is difficult to visually conclude something from the plots.	Review	O	0
[line_break_token]4- Adding some plots for the Hessian during the optimization is definitely needed because we mostly care about the Hessian during the optimization not after the convergence.	Review	O	0
[line_break_token][line_break_token]Clarity:[line_break_token]1- There is no reference to figures in the main text which makes it confusing for the reading to know the context for each figure.	Review	O	0
For example, when looking at Figure 1, it is not clear that the Hessian is calculated at the beginning of optimization or after convergence.	Review	B-Review	5
[line_break_token]2- The texts in the figures are very small and hard to read.	Review	O	0
Thank you for the comments and the review.	Reply	O	0
Quantification of singularity is crucial but it may be tricky and even misleading given the degenerate structure, therefore we thought it would be equally important to lay out the observations first, and then as a separate work consider the quantification.	Reply	B-Reply	3
[line_break_token][line_break_token]We revised the paper in an attempt to address most of the issues mentioned above and in other comments.	Reply	O	0
[line_break_token][line_break_token]Also, we will add a comparison with another ML method, very soon.	Reply	O	0

This paper proposes to pre-train a student before training with a teacher, which is easy to understand.	Review	O	0
Although the authors provide extensive empirical studies, I do not think they can justify the claims in this paper.	Review	O	0
[line_break_token][line_break_token][line_break_token]** Argument[line_break_token][line_break_token]One concern is that compared to other baselines such as "Patient knowledge distillation" [1], the proposed method is not consistently better.	Review	O	0
The authors argue that [1] is more sophisticated in that they distill task knowledge from intermediate teacher activations.	Review	B-Review	1
However, the proposed method introduces other extra complexities, such as pre-training the student.	Review	I-Review	1
I do not agree that the proposed method is less elaborate than previous methods.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]Although the investigation on influence of model size and the amount/quality of unlabeled data is interesting in itself, this does not help justify the usefulness of pre-training a student.	Review	I-Review	2
I hypothesize that when considering the intermediate feature maps as additional training signals, randomly initialized students can catch up with pre-trained students.	Review	I-Review	2
[line_break_token][line_break_token]Furthermore, the mixed results shown in Table 3 do not justify the proposed method well enough.	Review	I-Review	3
[line_break_token][line_break_token][1] Patient Knowledge Distillation for BERT Model Compression, <a href="https://arxiv.org/abs/1908.09355" target="_blank" rel="nofollow">https://arxiv.org/abs/1908.09355</a>	Review	O	0
e would like to reiterate the main take-aways of our paper, which are: 1) Pre-trained Distillation (PD) is an effective recipe in the specific setup where there is very little labeled data, but a more significant amount of task unlabeled data, and 2) PD is *just as good* as more elaborate techniques that make restrictive assumptions about the model architecture.	Reply	B-Reply	4
We should have made it clearer that comparison against prior work in Table 3 is for completeness only, and it is not our goal to beat SoTA in the traditional setup; rather, we propose a solution for the case where there is unlabeled task data.	Reply	I-Reply	4
[line_break_token][line_break_token]Comparison to Patient Knowledge Distillation (PKD): PKD requires initialization with a pre-trained Transformer which has the same hidden dimension size and same or larger depth; it also requires that the teacher and student have the same hidden dimension size.	Reply	I-Reply	1
It is possible that transferring intermediate map values will bring improvements on top of our method pre-trained distillation; this would be a possibility in the restricted case that the student and teacher have the same hidden dimension size, limiting the accuracy and efficiency of the compact model.	Reply	I-Reply	1
Our preliminary experiments (not reported in the paper) showed no gains from intermediate map matching objectives when combined with pre-trained distillation but further experiments will be interesting.	Reply	I-Reply	1
[line_break_token][line_break_token]By eliminating the intermediate layer transfer between students and teachers, our method is more *general*, with no architectural restrictions.	Reply	I-Reply	2
For instance, in Table 3, the comparison is limited to 6/768 models because of the extreme restrictions from the baselines.	Reply	I-Reply	2
Also, we disagree that our method is more *elaborate* just because it requires a pre-training step; note that PKD also requires a (deeper) pre-trained Transformer.	Reply	I-Reply	2
Once our pre-trained models are released, future efforts can simply reuse them, the same way PKD reuses a pre-trained Bert checkpoint.	Reply	I-Reply	2
Exploring more flexible intermediate layer knowledge transfer following PKD but generalizing to mismatched dimensionality of student and teacher would be an interesting avenue for future work.	Reply	I-Reply	2
[line_break_token]	Reply	O	0

OVERALL:[line_break_token]I think this paper is worth accepting.	Review	O	0
[line_break_token]All modern semi-supervised learning techniques use consistency regularization somehow,[line_break_token]and this paper shows that you can get away with just using pseudo-labeling combined with some[line_break_token]engineering to route around the main issue with pseudo labeling (which is apparently called confirmation bias,[line_break_token]though I hadn't heard that, and I don't like it as a name because it's confusing).	Review	B-Review	1
[line_break_token][line_break_token]Neither MixUp nor the idea of fixing some number of labeled elements in a minibatch is new,[line_break_token]but that's not the point - we thought one thing, and this paper suggests that[line_break_token]we were wrong about that thing - to me this is exactly the sort of paper it's good to have at conferences.	Review	I-Review	2
[line_break_token][line_break_token]I would change the framing slightly.	Review	I-Review	3
[line_break_token]You're not showing that pseudo-labeling can be useful, because many techniques already incorporate a form of pseudo-labeling.	Review	I-Review	3
[line_break_token]Instead, you're showing you can get away without consistency regularization.	Review	I-Review	3
[line_break_token][line_break_token]A potential improvement:[line_break_token]If you add up this techique with some of the most recent SLL techniques based on consistency regularization somehow,[line_break_token]does it do better, or are they both acting via the same mechanism?	Review	I-Review	4
[line_break_token][line_break_token]DETAILED COMMENTS:[line_break_token]&gt; , contrary to previous evidences on pseudo-labeling capabilities (Oliver et al.,	Review	O	0
2018),[line_break_token]It's not really contrary to the findings of that paper, since you've totally changed the[line_break_token]technique compared to what's evaluated in that paper.	Review	B-Review	9
[line_break_token][line_break_token]&gt; n (Berthelo et al.,	Review	O	0
2019) [line_break_token]It's Berthelot[line_break_token][line_break_token]&gt; and are the mechanisms proposed in Subsection 3.1[line_break_token]Doesn't quite parse[line_break_token][line_break_token]&gt; Network predictions are, of course, sometimes incorrect.	Review	O	0
[line_break_token]This is a great line.	Review	B-Review	12
[line_break_token][line_break_token]&gt; We use three image classification datasets...[line_break_token]Why not use SVHN, which is by now super standard for SSL papers?	Review	O	0
[line_break_token][line_break_token]&gt; , we add the 5K samples back to the training set for comparison[line_break_token]with the state-of-the-art in Subsection 4.4,[line_break_token]This is *allowed* from the perspective of reporting a valid test accuracy,[line_break_token]but if other papers don't do that, it kind of mucks up the comparison, no?	Review	O	0
[line_break_token][line_break_token]Fig 1 is nice, but why does the effect not seem to be symmetric about the[line_break_token]blue and the red blobs?	Review	B-Review	7
[line_break_token][line_break_token]&gt; architecture plays and important role[line_break_token][line_break_token][line_break_token]&gt; However, it is already interesting that...  and that future work should take this into account.	Review	O	0
[line_break_token]This sentence doesn't quite make sense[line_break_token][line_break_token]Re table 4:[line_break_token]I'm curious how e.g. MixMatch would fare w/ the 13-CNN network.	Review	O	0
[line_break_token]I am surprised that the change from WRN -&gt; 13-CNN matters so much.	Review	O	0
[line_break_token]	Review	O	0
- Regarding ‚Äúconfirmation bias‚Äù term[line_break_token][line_break_token]We adopted this term from other papers: Tarvainen &amp; Valpola, 2019 (MT) and Li et al.,	Reply	O	0
2019 (CCL), and note that is also named the noise accumulation problem (Zhang et al.,	Reply	B-Reply	1
2016).	Reply	I-Reply	1
In psychology it is defined as ‚Äúthe tendency to search for, interpret, favor, and recall information in a way that affirms one's prior beliefs or hypotheses‚Äù [1]. In the context of Deep Neural Networks the term can be explained as: ‚Äúthe model is prone to confirm the previous predictions and resist new changes‚Äù (CCL).	Reply	I-Reply	1
Dealing with confirmation bias has been studied in MT and CCL, where they report a behaviour like the one we encounter, but for consistency regularization approaches.	Reply	I-Reply	1
The issue they find is that when increasing the weight of the consistency regularization term, it outweighs the cross-entropy term and prevents the learning of new information (see Figure 1 in MT).	Reply	I-Reply	1
[line_break_token][line_break_token][1] Plous, Scott, 1993, The Psychology of Judgment and Decision Making, p. 233.	Reply	O	0
[line_break_token][line_break_token][line_break_token]- Regarding a slight change in the framing[line_break_token][line_break_token]We have changed the framing slightly following your suggestion to reflect that we show that pseudo-labeling does not need consistency regularization and prevent possible misunderstandings on previous capabilities already shown by pseudo-labeling when combined with consistency regularization.	Reply	O	0
The following changes were made to the manuscript.	Reply	B-Reply	2
[line_break_token][line_break_token]Abstract: ‚ÄúThese results demonstrate that pseudo-labeling can outperform consistency regularization methods, while the opposite was supposed in previous work.	Reply	I-Reply	2
‚Äù[line_break_token][line_break_token]Introduction: ‚ÄúThis paper explores pseudo-labeling for semi-supervised deep learning from the network predictions and shows that, contrary to previous attempts on pseudo-labeling (Iscen et al.,	Reply	I-Reply	2
2019, Oliver et al.,	Reply	I-Reply	2
2018, Shi et al.,	Reply	I-Reply	2
2018), simple modifications to prevent confirmation bias lead to state-of-the-art performance without adding consistency regularization strategies.	Reply	I-Reply	2
‚Äù[line_break_token][line_break_token][line_break_token]- Regarding combination of our approach with consistency regularization[line_break_token][line_break_token]We agree in that consistency regularization might further improve our approach as previous evidence shows that pseudo-labeling and consistency regularization encounter benefits when combined (Iscen et al.,	Reply	O	0
2019, Shi et al.,	Reply	B-Reply	4
2018).	Reply	I-Reply	4
Since pseudo-labeling and consistency regularization represent different forms of leveraging unlabeled data, they might encounter some beneficial complementarity.	Reply	I-Reply	4
However, as we have added to the conclusions section, we leave this for future work as want to stress the potential of pseudo-labeling by itself.	Reply	I-Reply	4
[line_break_token][line_break_token]- Regarding SVHN[line_break_token][line_break_token]We have updated the paper to include results on SVHN dataset in Table 3 and in Appendix A.3 using the 13-CNN network.	Reply	O	0
We have experimented with 250, 500, and 1000 labeled examples and obtained, respectively,  3.66 ¬± 0.12, 3.64 ¬± 0.04, and 3.55 ¬± 0.08 (these are state-of-the-art results on-par with top-performing consistency regularization approaches).	Reply	B-Reply	5
It is important to highlight that to assure convergence to reasonable performance with few labels we had to perform a longer warm-up period (150 epochs) to improve the quality of pseudo-labels in early training epochs (the same modification in CIFAR-10 using 250 labeled examples achieves a similar performance inside the range of error reported in the paper).	Reply	I-Reply	5
[line_break_token][line_break_token]- Regarding the use of the validation set[line_break_token][line_break_token]We decided to adopt the criterion of separating a small validation subset from the training data and then replacing it due to the same approach used in the 2019 ICLR paper by Athiwaratkun et al.. This ensures that 10K samples of the test subset are never seen during hyperparameter tuning and 50K samples are used for training.	Reply	O	0
All numbers reported in the tables were obtained under the same conditions as were used in our experiments, i.e. using 50K training examples and 10K test examples.	Reply	B-Reply	6
The only exception is ICT (Verma et al.,	Reply	I-Reply	6
2019), where they use the labeled samples both with labels and without labels, thus slightly increasing the amount of unlabeled examples above 50K.[line_break_token][line_break_token]- Regarding the toy examples asymmetry[line_break_token][line_break_token]The asymmetry seen in Fig 1 is due to the fact that the samples that have labels do not form a symmetric pattern.	Reply	O	0
These samples more strongly affect the location of the decision boundary than the unlabelled samples.	Reply	B-Reply	7
This observation can be seen as well in figures reported in (Rebuffi et al.,	Reply	I-Reply	7
2019) and (Verma et al.,	Reply	I-Reply	7
2019).	Reply	I-Reply	7
[line_break_token][line_break_token][line_break_token]- Regarding MixMatch (MM) with different architectures[line_break_token][line_break_token]We think that MM is a very powerful approach that would not have issues when run with the 13-CNN layer network.	Reply	O	0
Also, as reported in (Kolesnikov et al.	Reply	B-Reply	8
2019), the network architecture may play a very important role, as shown for self-supervised learning with VGG-type and ResNet-type architectures.	Reply	I-Reply	8
We observed something similar for semi-supervised learning with pseudo-labeling.	Reply	I-Reply	8
Future work should take into consideration that trying multiple architectures might reveal interesting results.	Reply	I-Reply	8

CONTRIBUTIONS:[line_break_token]Topic: Disentangling syntax from semantics in contextualized word representations[line_break_token]C1.	Review	O	0
A method for generating ‚Äòstructurally equivalent‚Äô sentences is proposed, based only on the assumption that maintaining function words, and replacing one content word of a source sentence with another to produce a new grammatical sentence, yields a target sentence that is equivalent to the source sentence.	Review	O	0
[line_break_token]C2.	Review	O	0
The ‚Äòstructural relation‚Äô between two words in a sentence is modeled as the difference between their vector embeddings.	Review	O	0
[line_break_token]C3a.	Review	O	0
The structural relation between a pair of content words in one sentence is assumed to be the same as that between the corresponding pair in an equivalent sentence.	Review	O	0
[line_break_token]C3b.	Review	O	0
The structural relation between any pair of content words in one sentence is assumed to be different from the structural relation between any pair of content words in an inequivalent sentence.	Review	O	0
[line_break_token]C4.	Review	O	0
Given a selected word in a source sentence, to generate an alternative ‚Äòcorresponding‚Äô content word for an equivalent target sentence, BERT is used to predict the source word when it is masked, given the remaining words in the source sentence.	Review	O	0
The alternative corresponding word is randomly selected from among the top (30) candidates predicted by BERT.	Review	O	0
Given a source sentence, the set of target sentences formed by cumulatively replacing content words one at a time in randomly selected positions defines an ‚Äòequivalence set‚Äô in which words in different sentences with the same left-to-right index are corresponding words. (	Review	O	0
To promote the formation of grammatical target sentences, a word is only replaced by another word with the same POS.)	Review	O	0
A pre-defined set of equivalence sets is used for training.	Review	O	0
[line_break_token]C5.	Review	O	0
A metric learning paradigm with triplet loss is used to find a function f for mapping ELMo or BERT word embeddings to a new vector space of ‚Äòtransformed word representations‚Äô.	Review	O	0
Implementing C2 and C3a, given the indices i and i‚Äô of two content words, the triplet loss rewards closeness of the difference D between the transformed embeddings of the pair of words with these indices in sentence S and the corresponding difference D‚Äô for an equivalent sentence S‚Äô.	Review	O	0
Implementing C3b, the triplet loss penalizes closeness between D and D‚Äù, where D‚Äù is the difference between transformed word embeddings of a pair of content words in a sentence S‚Äù that is inequivalent to S. (Eq.	Review	O	0
4).	Review	O	0
[line_break_token]C6. (	Review	O	0
Implementing C5.)	Review	O	0
To form a mini-batch for minimizing the triplet loss, a set of (500) sentences S is selected, and for each a pair of indices of content words is chosen.	Review	O	0
Training will use the difference in the transformed embeddings of the words in S with these indices: call this D, and call the set of these (500) D vectors B. For each sentence S in B, a ‚Äòpositive pair‚Äô (D, D‚Äô) is generated, where D‚Äô is the corresponding difference for S‚Äô, a selected sentence in the equivalence set of S. Closeness of D and D‚Äô is rewarded by the triplet loss, implementing C3a.	Review	O	0
To implement C3b, a ‚Äònegative pair‚Äô (D, D‚Äù), for which closeness is penalized by the loss, is formed as follows.	Review	O	0
D‚Äù is the closest vector in B to D that is derived from a sentence S‚Äù that is not equivalent to S. [line_break_token]C7.	Review	O	0
2-D t-SNE plots (seem to) show that relative to the original ELMo embeddings, the transformed embeddings cluster better by POS (Fig.	Review	O	0
3). (	Review	O	0
No quantitative measure of this is provided, and the two plots are not easy to distinguish.)	Review	O	0
[line_break_token]C8.	Review	O	0
Pairs of closest ELMo vectors share syntactic (dependency parse) properties to a greater degree after transformation than before (Table 1).	Review	O	0
To check that this goes beyond merely POS-based closeness, the syntactic relations that least determine POS are examined separately, and the result remains.	Review	O	0
Furthermore, the proportion of pairs of closest vectors that are embeddings of the same word (in different contexts) drops from 77.6% to 27.4%, showing that the transformation reduces the influence of lexical-semantic similarity.	Review	O	0
Similar results hold for BERT embeddings, but to a lesser degree, so the paper focusses on ELMo.	Review	O	0
[line_break_token]C9.	Review	O	0
Few-shot parsing.	Review	O	0
Two dependency parsers are trained, one on ELMo embeddings, the other on their transformations (under the proposed method).	Review	O	0
In the small-data regime (less than 200 training examples), the transformed embeddings yield higher parser performance, even when the encoding size of the ELMo embeddings is reduced (from 2048 to 75) to match that of the transformed embeddings by either PCA or a learned linear mapping. (	Review	O	0
Fig.	Review	O	0
4) [line_break_token]RATING: Weak accept[line_break_token]REASONS FOR RATING (SUMMARY).	Review	O	0
Using deep learning to create an encoding of syntactic structure with minimal supervision is an important goal and the paper proposes a clever way of doing this.	Review	O	0
The only ‚Äòsupervision‚Äô here comes from (i) the function/content-word distinction (C1 above): two grammatical sentences are structurally equivalent if [but not only if] one can be derived from the other by replacing one content word with another; and (ii) filtering candidate replacement words to match the POS of the replaced word.	Review	O	0
BERT‚Äôs ability to guess a masked word is put to good use in providing suitable content word substitutions.	Review	O	0
The experimental results are rather convincing.	Review	O	0
[line_break_token]REVIEW (beyond the summary above)[line_break_token]C1.	Review	O	0
This assumption is famously not deemed to be true in linguistics, where the structural difference between ‚Äòcontrol‚Äô and ‚Äòraising‚Äô verbs is basic Ling 101 material: see <a href="https://en.wikipedia.org/wiki/Control_(linguistics)#Control_vs._raising."	Review	O	0
target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Control_(linguistics)#Control_vs._raising.</a> This particular structural contrast illustrates how verbs can differ in their argument structure, without there being function words to signal the difference.	Review	O	0
So substituting *verbs* in particular may be non-ideal for the purposes of this work.	Review	B-Review	1
Even the third example given by the authors in Sec.	Review	I-Review	1
3.1 illustrates a related  point, where function words do signal the contrast:  while the meaning of ‚Äòlet‚Äô and ‚Äòallow‚Äô may be very similar, their argument structures differ, so that replacing ‚Äòlets‚Äô with ‚Äòallows‚Äô in the first sentence, or the reverse in the second sentence, produces ungrammatical results: [line_break_token]*their first project is software that *allows* players connect the company ‚Äôs controller to their device[line_break_token]*the city offers a route-finding website that *lets* users to map personalized bike routes[line_break_token]Therefore, contrary to the paper, relative to linguistic syntactic structure, it is not a good result that ‚Äòlets‚Äô in the original version of the first sentence is the closest neighbor in transformed embedding space to ‚Äòallows‚Äô in the second.	Review	I-Review	1
Rather, it is probably meaning, not structure, that makes ‚Äòlet‚Äô and ‚Äòallow‚Äô similar.	Review	I-Review	1
[line_break_token]It would improve the paper to make note of this general concern with C1 and to provide a response.	Review	I-Review	1
[line_break_token]On another point, an important premise of the proposed method (C2 above) is that differences in vector space embeddings encode relations; this has been used by a number of previous authors since the famous Mikolov, Yih &amp; Zweig NAACL2013, and that work should be cited and discussed.	Review	O	0
e appreciate your constructive and detailed review!	Reply	O	0
[line_break_token][line_break_token]Your are right in noting that subtle differences in the surface level can mask substantial differences in the deep argument structure of the sentence, and that verbs are particularly sensitive in this respect.	Reply	B-Reply	1
This is a limitation of the current approach, which we now acknowledge in the paper.	Reply	I-Reply	1
Thanks for pointing this out.	Reply	I-Reply	1
 Indeed, in general we can expect the replacement process to yield a grammatical sentence with equivalent structures only to the extent that BERT implicitly encodes the grammatical restrictions that apply to the masked word (i.e., we can only capture raising vs control distinction to the extent BERT-like LM can captures them).	Reply	I-Reply	1
While BERT is a powerful LM -- and that is the reason we used it rather than simple POS-based replacement -- it may at times violates some of those restrictions.	Reply	I-Reply	1
As you point out, this reasoning behind the substitution process and the premises we made were not clearly stated in the paper, and made it clearer in the revisioned version.	Reply	I-Reply	1
However, we note that the average sentences we generate seem grammatical, and do not diverge much from the structure of the original sentence; we therefore think this method does at least approximate our end goal of generating grammatical sentences of the same structure.	Reply	I-Reply	1
[line_break_token]Moreover, we remind that our method attempts to uncover the structural information that is encoded in the neural LMs.	Reply	I-Reply	1
Thus, we find it reasonable to not capture structural distinctions that are not reflected in current state-of-the-art neural LMs.	Reply	I-Reply	1
[line_break_token][line_break_token]Thank you for pointing out to the works on vector-space arithmetic.	Reply	I-Reply	1
This was our motivation for representing pairs as the difference between the corresponding word vectors, and we will explicitly mention that in the paper.	Reply	I-Reply	1

This paper improves significantly upon the original NPI work, showing that the model generalizes far better when trained on traces in recursive form.	Review	O	0
The authors show better sample complexity and generalization results for addition and bubblesort programs, and add two new and more interesting tasks - topological sort and quicksort (added based on reviewer discussion).	Review	O	0
Furthermore, they actually *prove* that the algorithms learned by the model generalize perfectly, which to my knowledge is the first time this has been done in neural program induction.	Review	B-Review	1
I like this paper as well, and think it is a valuable improvement over the NPI baseline.	Reply	O	0
[line_break_token][line_break_token]However, even on first reading, I was annoyed by the use of the term "prove".	Reply	B-Reply	1
The paper proves that under certain circumstances, _testing_ on a finite set of values is sufficient to establish correctness for whole classes of inputs.	Reply	I-Reply	1
However, this does not amount to a generally applicable proof strategy.	Reply	I-Reply	1
It is only feasible because the input domain is quite simple, and only a handful of cases need to be considered.	Reply	I-Reply	1
However, this quickly becomes problematic when the input domain expands, e.g., when one-hot encodings of digits are replaced by MNIST digits.	Reply	I-Reply	1
I would expect NPI (and the recursive extension presented here) to have no problem to handle this with an appropriately structured domain-specific encoder, but the "proof" strategy described in this paper would not work anymore.	Reply	I-Reply	1
Thus, I am not convinced of the practical value of this part of the contribution, as it seems to be unfeasible for everything but toy paper examples.	Reply	I-Reply	1

This is a strong paper.	Review	O	0
It focuses on an important problem (speeding up program synthesis), it‚Äôs generally very well-written, and it features thorough evaluation.	Review	O	0
The results are impressive: the proposed system synthesizes programs from a single example that generalize better than prior state-of-the-art, and it does so ~50% faster on average.	Review	O	0
[line_break_token][line_break_token]In Appendix C, for over half of the tasks, NGDS is slower than PROSE (by up to a factor of 20, in the worst case).	Review	B-Review	1
What types of tasks are these?	Review	I-Review	1
In the results, you highlight a couple of specific cases where NGDS is significantly *faster* than PROSE‚ÄîI would like to see some analysis of the cases were it is slower, as well.	Review	I-Review	1
I do recognize that in all of these cases, PROSE is already quite fast (less than 1 second, often much less) so these large relative slowdowns likely don‚Äôt lead to a noticeable absolute difference in speed.	Review	I-Review	1
Still, it would be nice to know what is going on here.	Review	I-Review	1
[line_break_token][line_break_token]Overall, this is a strong paper, and I would advocate for accepting it.	Review	O	0
[line_break_token][line_break_token][line_break_token]A few more specific comments:[line_break_token][line_break_token][line_break_token]Page 2, ‚ÄúNeural-Guided Deductive Search‚Äù paragraph: use of the word ‚Äúimbibes‚Äù - while technically accurate, this use doesn‚Äôt reflect the most common usage of the word (‚Äúto drink‚Äù).	Review	O	0
I found it very jarring.	Review	B-Review	2
[line_break_token][line_break_token]The paper is very well-written overall, but I found the introduction to be unsatisfyingly vague‚Äîit was hard for me to evaluate your ‚Äúkey observations‚Äù when I couldn‚Äôt quite yet tell what the system you‚Äôre proposing actually does.	Review	I-Review	3
The paragraph about ‚Äúkey observation III‚Äù finally reveals some of these details‚ÄîI would suggest moving this much earlier in the introduction.	Review	I-Review	3
[line_break_token][line_break_token]Page 4, ‚ÄúAppendix A shows the resulting search DAG‚Äù - As this is a figure accompanying a specific illustrative example, it belongs in this section, rather than forcing the reader to hunt for it in the Appendix.	Review	I-Review	4
[line_break_token][line_break_token]	Review	O	0
Thank you for the constructive feedback!	Reply	O	0
We‚Äôll add more details and clarify the introduction in the next revision.	Reply	O	0
[line_break_token][line_break_token]Q: Which factors lead to NGDS being slower than PROSE on some tasks?	Reply	O	0
[line_break_token]Our method is slower than PROSE when the predictions do not satisfy the requirements of the controller i.e. all the predicted scores are within the threshold or they violate the actual scores in branch and bound exploration.	Reply	B-Reply	1
This leads to NGDS evaluating the LSTM for branches that were previously pruned.	Reply	I-Reply	1
This can be especially harmful when branches that got pruned out at the very beginning of the search need to be reconsidered -- as it could lead to evaluating the network many times.	Reply	I-Reply	1
While evaluating the network leads to minor additions in run-time, there are many such additions, and since PROSE performance is already < 1s for such cases, this results in considerable relative slowdown.	Reply	O	0
[line_break_token][line_break_token]Why do the predictions violate the controller's requirements?	Reply	B-Reply	1
This happens when the neural network is either indecisive (its predicted scores for all branches are too close) or wrong (its predicted scores have exactly the opposite order of the actual program scores).	Reply	I-Reply	1
[line_break_token]We will update the draft with this discussion and present some examples below[line_break_token][line_break_token]Some examples:[line_break_token]A) "41.711483001709,-91.4123382568359,41.6076278686523,-91.6373901367188"  ==>  "41.711483001709"[line_break_token][tab_token]The intended program is a simple substring extraction.	Reply	O	0
However, at depth 1, the predicted score of Concat is much higher than the predicted score of Atom, and thus we end up exploring only the Concat branch.	Reply	B-Reply	1
The found Concat program is incorrect because it uses absolute position indexes and does not generalize to other similar extraction tasks with different floating-point values in the input strings.	Reply	I-Reply	1
[line_break_token]We found this scenario relatively common when the output string contains punctuation - the model considers it a strong signal for Concat.	Reply	I-Reply	1
[line_break_token]B) "type size =  36: Bartok.	Reply	I-Reply	1
Analysis.	Reply	I-Reply	1
CallGraphNode type size =  32: Bartok.	Reply	I-Reply	1
Analysis.	Reply	I-Reply	1
CallGraphNode CallGraphNode"  ==> "36->32"[line_break_token][tab_token]We correctly explore only the Concat branch, but the slowdown happens at the level of the `pos` symbol.	Reply	O	0
There are many different logics to extract the ‚Äú36‚Äù and ‚Äú32‚Äù substrings.	Reply	B-Reply	1
NGDS explores RelativePosition branch first, but the score of the resulting program is less then the prediction for RegexPositionRelative.	Reply	I-Reply	1
Thus, the B&B controller explores both branches anyway and we end up with a relative slowdown caused by the network inference time	Reply	O	0

This paper proposes learning a transition model that takes an action sequence as an input (instead of a single action), and performing model-based planning by using the cross-entropy method.	Review	O	0
[line_break_token][line_break_token]One obvious concern with this is that this produces a sequence of open-loop plans, rather than a closed-loop policies, with all the inherent limitations.	Review	B-Review	1
I could see this working well in practice in problems where anticipating how future decisions will react to state changes is not that important, however the authors should discuss the trade-offs more.	Review	I-Review	1
[line_break_token][line_break_token]A larger concern for me revolves around learning the transition model.	Review	I-Review	2
Taking the action sequence as an input (which is one of the main novelties in the paper) is likely to require a lot of data, and maybe this is fine on relatively simple Mujoco tasks but I see it as a potential issue when trying to expand this to more realistic problems.	Review	I-Review	2
[line_break_token][line_break_token]Finally, I suggest that the authors change the title to something more descriptive of the paper‚Äôs contents, as there is no analysis of asymptotic performance in the paper (as I would have thought from the title).	Review	I-Review	3
I also recommend that they look to see if there is any model-based work in the semi-MDP literature, which could be relevant here.	Review	I-Review	3
[line_break_token]	Review	O	0
‚Äúproduces a sequence of open-loop plans‚Äù: We feel the reviewer may misunderstand how a model-predictive (MPC) controller operates.	Reply	O	0
By replanning at each step, MPC converts an open-loop planner into a closed-loop controller.	Reply	B-Reply	1
Please refer to Section 2.3 and Algorithm 1 of our paper for a more precise description, or see <a href="https://ieeexplore.ieee.org/document/57020," target="_blank" rel="nofollow">https://ieeexplore.ieee.org/document/57020,</a> for example, for more background.	Reply	O	0
[line_break_token][line_break_token]‚Äúlikely to require a lot of data‚Äù: While we agree that our approach does require a significant amount of training data, the main objective of this work is to understand the limitations of existing neural dynamics models rather than to propose a practical new one.	Reply	O	0
[line_break_token][line_break_token]‚Äúchange the title‚Äù: Correspondingly, our paper examines performance in the limit of a very large number of training examples, hence the ‚Äúasymptotic‚Äù in our title.	Reply	O	0
[line_break_token][line_break_token]Thank you.	Reply	O	0
Yes, we will certainly look for related work in the semi-MDP literature	Reply	O	0

Authors present a method to address the problem of underfitting found in sequential neural processes.	Review	O	0
They cover the literature appropriately in regards to neural processes and developments pertaining to tackling the underfitting problem by applying an attention mechanism.	Review	O	0
Although, this has successfully been achieved with Neural Processes, the case is different with sequential neural processes, as they cannot store the past context.	Review	O	0
[line_break_token]Authors addressed this problem by introducing an attention mechanism and model, i.e. Attentive sequential neural processes, which incorporates a memory mechanism of imaginary context.	Review	O	0
This imaginary context is generated through an RNN network and are treated as latent variables.	Review	O	0
[line_break_token]The results presented show some promising improvements over other methods used and more results have been included in the appendix.	Review	O	0
It would be nice to demonstrate the performance in more challenging tasks as well, however the results presented and the new context-imagination introduced are quite promising indeed.	Review	B-Review	1
[line_break_token]I have read the rebuttal carefully.	Review	O	0
I appreciate the extra effort put by the authors to address the issues raised from the other reviewers.	Review	O	0
I think, albeit not ground-breaking research, it could be a good addition to the programme nonetheless.	Review	O	0
hank you for the positive review.	Reply	O	0
Yes, we agree that demonstrating ASNP on more challenging tasks would be a nice and fruitful future work	Reply	B-Reply	1

This paper proposes to use a convolutional neural network, taking program binaries as inputs, to detect malware.	Review	O	0
The results are on par with a network that takes in hand-crafted features, and the hidden layers are shown to be complementary to the hand-crafted features.	Review	O	0
[line_break_token][line_break_token]The paper is well written and easy to follow.	Review	O	0
The descriptions of the experiments are complete.	Review	O	0
One minor thing missing is the learning rate of the Adam optimizer.	Review	O	0
[line_break_token][line_break_token]I have a more fundamental question about the task.	Review	B-Review	1
How much does the model learn to identify parts of the problematic source code?	Review	I-Review	1
How much does the model learn to identify signs unrelated to the source code, such as things in the header?	Review	I-Review	1
I assume that in many cases you can judge whether a piece of binary is malware just by looking at the cosmetics of the program, but these features might not generalize well in the long run.	Review	I-Review	1
I assume it would be much more useful to identify certain sequence of instructions and memory addresses based on cpu architectures.	Review	I-Review	1
It would be great to analyze the CNN to see what it is paying attention to.	Review	I-Review	1
[line_break_token][line_break_token]The other fundamental question about the task is obfuscation.	Review	I-Review	2
On the one hand, in theory there is no universal tool to overcome obfuscation (with the standard crypto assumptions).	Review	I-Review	2
On the other hand, it's probably easy to detect trivial obfuscation, because the resulting program binaries would look significantly different from regular program binaries.	Review	I-Review	2
How often are binaries obfuscated in general?	Review	I-Review	2
How do these affect the model's performance?	Review	I-Review	2
What are the characteristics of regular program binaries?	Review	I-Review	2
[line_break_token][line_break_token]Programs as data are more stringent than natural images and words.	Review	I-Review	3
The CNNs might require a lot of effort just learning the common idioms of programming, such as control flows, loops, from the binaries.	Review	I-Review	3
I think the CNNs might benefit from these high-level constructs/templates when identifying malwares.	Review	I-Review	3
Since CNNs or deep models in general are strong at coping with noise, it might be useful to look at how they behave on mutated malware.	Review	I-Review	3
1) According to the latest experiments with Guided Backpropagation combined with Grad-CAM, we saw no "explanation" based on a machine code (however, the number of manually inspected samples and the time spent have been very limited so far).	Reply	O	0
In this aspect the automatic convolutional features might be very similar to the traditional hand-engineered features which cover mainly the "envelope" of the executable[line_break_token][line_break_token]2) We do think that obfuscation can be overcome in theory, emulation/sandboxing being one (relatively) universal tool.	Reply	O	0
However we do not expect the convnet to do the job.	Reply	B-Reply	2
Because of the type "explanations" we have observed so far, we think that the performance may not be hurt significantly by including obfuscated files (indeed we use fairly simple/imperfect detection of obfuscation and our dataset certainly contains a large portion of obfuscated files already).	Reply	I-Reply	2
Tests on the whole collection will be hopefully ready soon.	Reply	I-Reply	2
[line_break_token]Obfuscation is quite common for the current malware but majority can be reversed by manually crafted "unpackers", that is another option.	Reply	I-Reply	2
[line_break_token][line_break_token]3) We believe that we can force the deep nets to focus on the code itself is by inputting emulation/sandboxing output instead of the file.	Reply	O	0
That is definitely one of the major directions for further research	Reply	B-Reply	3

This article presents an interesting if heuristic approach to source separation, NES, buttressed by the use of GLO masking for initialization, with promising results on data generated from synthetic source mixing.	Review	O	0
[line_break_token][line_break_token]The paper is well written and on the whole clear.	Review	O	0
My main concern with the work is the empirical nature of the NES iterative procedure.	Review	B-Review	1
As far as I can tell there is no guarantee of convergence (nor discussion concerning this point).	Review	I-Review	1
Since i am not familiar with the tasks, it is hard for me to judge the quality of the empirical results -- though the results do seem promising.	Review	I-Review	1
[line_break_token][line_break_token]re: Bags & shoes task / table 1: "...  Finetuning from GLOM, helped NES achieve stronger performance, nearly identical to the fully-supervised upper bound.	Review	O	0
It performed better than finetuning from AM (which achieved 22.5/0.85 and 22.7/0.86)": I can't place the first number in the table, therefore i'm not quite sure what is being pointed out here.	Review	B-Review	2
[line_break_token][line_break_token]re: Music task / table 3: "... GLOM was much better than AM initialization (that achieved 0.9 and 2.9)": I don't see either number in the table.	Review	O	0
I'd assumed that GLOM was used to fine-tune NES, so I was expecting to see the 2.9 under "FT".	Review	B-Review	3
[line_break_token][line_break_token]== [line_break_token][line_break_token]I think the authors' response is reasonable.	Review	O	0
They have added clarifying material to the paper addressing my concerns.	Review	O	0
I have raised my rating from a 5 to a 6.	Review	O	0
We thank the reviewer for the positive review, particularly for commending the ‚Äúinteresting ideas‚Äù, ‚Äúpromising results‚Äù and clarity of the paper.	Reply	O	0
[line_break_token][line_break_token]We are able to theoretically show that the correct separation result is a global minimum of NES, but we are yet unaware of a convergence guarantee.	Reply	B-Reply	1
The same can be said however for most successful deep learning methods.	Reply	I-Reply	1
We establish the good performance of our method via extensive empirical experiments, which the reviewer described as ‚Äúpromising‚Äù.	Reply	I-Reply	1
 We have added this to the discussion.	Reply	I-Reply	1
[line_break_token][line_break_token]Thank you for asking for clarifications on the AM-FT results (different from the AM results).	Reply	I-Reply	3
We did not insert them into the table for space considerations, they only appear in the text.	Reply	I-Reply	3
We changed the text to elucidate this.	Reply	I-Reply	3
[line_break_token][line_break_token]We hope that the reviewer will be able to change the decision to an acceptance given the positive nature of the review.	Reply	O	0

[Summary][line_break_token]This paper proposes an error-free rule update method for graph embedding.	Review	O	0
The authors employ the Hebbian learning concept iteratively using the pre-calculated transition probability.	Review	O	0
They evaluate their model on six benchmark datasets.	Review	O	0
[line_break_token][line_break_token][Pros][line_break_token]- Very simple and fast by using an error-free update rule.	Review	O	0
[line_break_token][line_break_token][Cons][line_break_token]- The introduction is not organized.	Review	O	0
What are the motivation, related work, and contribution?	Review	B-Review	1
[line_break_token]- No comparison with conventional methods such as PageRank and NN-based models such as SEAL [1] and VGAE [2]. Even if this method is not learning-based, the proposed model should be compared.	Review	O	0
[line_break_token]- The authors claimed they applied their model to real recommendation systems.	Review	O	0
But there is no specific information.	Review	B-Review	3
At least, the author describes what is recommended, the data size, how large performance is improved, etc.	Review	I-Review	3
[line_break_token]- It is required to be evaluated on conventional datasets.	Review	O	0
[line_break_token]- Ablation on sigma[line_break_token][line_break_token][1] M. Zhang and Y Chen, Link Prediction Based on Graph Neural Networks, NIPS 2018.	Review	O	0
[line_break_token][2] Thomas N Kipf and Max Welling.	Review	O	0
Variational graph auto-encoders.	Review	O	0
arXiv preprint arXiv:1611.07308, 2016.	Review	O	0
[line_break_token][line_break_token] 	Review	B-Review	1
hank you for the comments!	Reply	O	0
[line_break_token]We have updated the introduction.	Reply	B-Reply	1
[line_break_token]We have added results from other state of the art algorithms like mentioned in [1].[line_break_token]We find that our algorithm is significantly better.	Reply	O	0
[line_break_token]Please see table 1 and table 5 in the modified paper.	Reply	B-Reply	4
[line_break_token][line_break_token][1] Graph embedding techniques, applications, and performance: A surve	Reply	O	0

This paper investigates online and stochastic convex optimization problems in which the objective function is not Lipschitz continuous.	Review	O	0
The originality of this study lies in the use of Riemannian geometry.	Review	O	0
Specifically, the standard condition of Lipschitz continuity is replaced with a more general condition involving Riemannian distances and called Riemann-Lipschitz Continuity (RLC).	Review	O	0
Based on an appropriate definition of Riemannian regularizer and a generalization of Fenchel coupling to Riemannian geometry, the authors provide regret (resp.	Review	O	0
risk) bounds for the online (resp.	Review	O	0
stochastic) mirror descent algorithm, under the Riemann-Lipchitz condition.	Review	O	0
The performance of the algorithm is validated on Poisson inverse problems.	Review	O	0
[line_break_token][line_break_token]Overall, this is a dense, yet interesting, paper.	Review	O	0
I am not an expert in Riemannian geometry but, as far as I could check, the proofs look correct.	Review	O	0
Notably, the analysis of OMD is relatively standard, once we get a bound (Prop B.1) on the Fenchel coupling, using the Riemannian dual norm.	Review	O	0
[line_break_token][line_break_token]I have essentially one main comment.	Review	B-Review	1
Clearly, the concept of ‚ÄúRiemann-Lipschitz continuity‚Äù is different from the notions of ‚Äúrelative continuity‚Äù and ‚Äúrelative smoothness‚Äù that have been recently proposed in the literature.	Review	I-Review	1
But it is not clear that the Riemann-Lipschitz condition can tackle convex optimization tasks in which relative continuity and relative smoothness do not hold.	Review	I-Review	1
In particular, Poisson (linear) inverse problems have already been handled under the relative smoothness condition, using Mirror Descent or Bregman proximal methods (Hanzely and Richtarik, 2018; Hanzely et.	Review	I-Review	1
al.	Review	I-Review	1
2018).	Review	I-Review	1
Thus,[line_break_token]* from a conceptual viewpoint, it would be interesting to provide some applications in which the RLC condition hold, but the relative smoothness condition does not; [line_break_token]* from an experimental viewpoint, in Sec.	Review	O	0
6, it would be legitimate to compare the present ‚ÄúRiemannian Mirror Descent‚Äù algorithm with respect to the APBG method (Hanzely et.	Review	B-Review	2
al.	Review	I-Review	1
2018) and the relSGD method (Hanzely and Richtarik, 2018).	Review	I-Review	2
[line_break_token]	Review	O	0
hank you for your constructive feedback and positive evaluation!	Reply	O	0
Regarding your comments:[line_break_token][line_break_token]1.	Reply	O	0
 We fully agree that the connection between non-Euclidean smoothness/continuity conditions is not always clear.	Reply	O	0
For instance, depending on the choice of regularizer, a convex function which is differentiable on an open domain of could be RL continuous, relatively continuous / smooth, or any combination of the above (or, of course, none).	Reply	B-Reply	1
 In our view, this shows that a judicious choice of regularizer can lead to significant algorithmic performance gains (as different settings have different advantages/disadvantages).	Reply	I-Reply	1
Our primary motivation for introducing the RLC condition (and hence extending the standard bounded gradient regularity assumption) was to focus on online and/or stochastic convex optimization problems where smoothness does not contribute to better regret rates.	Reply	I-Reply	1
Going forward, we believe that a precise characterization of the interplay between the various smoothness/continuity conditions above would be of clear and certain value to the community - but, at the same time, this cannot be attempted within the scope of the current paper.	Reply	I-Reply	1
We've introduced a "concluding remarks" section to discuss precisely this issue.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
 Concerning the papers mentioned: we were not aware of the relSGD paper of Hanzely and Richtarik (2018), many thanks for bringing it to our attention!	Reply	O	0
We have now included this paper in our review of the state of theart in the introduction - thanks again.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token][line_break_token]3.	Reply	O	0
 Regarding the experimental part: since acceleration cannot be achieved in a generic stochastic setting without some variance reduction scheme (such as SVRG or the like), it is not clear how to put the APBG framework of Hanzely et al.	Reply	O	0
on an equal footing with the methods studied in the current paper, so we did not attempt it.	Reply	B-Reply	2
On the other hand, there are indeed several interesting connections with the recent paper of Hanzely and Richtarik (2018), which we detail below:[line_break_token][line_break_token]3a) First, we noticed a typo in p. 18 (now p.19 in Sec.	Reply	I-Reply	2
F.2) of the supplement of our paper: when we referred to the Burg regularizer, we actually gave the definition of the standard (Gibbs-Shannon) entropic regularizer.	Reply	I-Reply	2
That was a mistake, apologies for any confusion caused: the definition should read.	Reply	I-Reply	2
[line_break_token][line_break_token]3b) To connect this with the work of Hanzely and Richtarik (2018), note that relSGD is  the mirror descent method generated by the Burg regularizer above with step-size.	Reply	O	0
[line_break_token][line_break_token]3c) On that account, relSGD is most closely connected with the CMP method of He et al. (	Reply	O	0
2016): CMP is also generated by the Burg entropy, but includes an extra-gradient step. [	Reply	B-Reply	2
In Bregman language, relSGD is stochastic *mirror descent* with Burg regularization while CMP is stochastic *mirror-prox* with Burg regularization][line_break_token][line_break_token]3d) CMP was one of the algorithms that we tested, and it was the second-best to RMD (which is generated by the O(1/x) regularizer of Example 4).	Reply	O	0
[line_break_token][line_break_token]3e) Even though we did not report these results, Burg mirror descent with and without an extra-gradient step (i.e., CMP and relSGD respectively) behave similarly, with the extra-gradient version (CMP) performing slightly better.	Reply	O	0
[line_break_token][line_break_token]Since we are already comparing RMD to CMP (and CMP and relSGD behave similarly), we feel that adding an extra set of experiments would only occlude the discussion.	Reply	B-Reply	2
Because of this, we opted not to present more experiments in the revised version of our manuscript; however, we are including a detailed version of the above discussion in the experimental section (p. 19 in the appendix), and we also discuss relSGD as an example of OMD in Section 4.	Reply	I-Reply	2
[line_break_token][line_break_token]For your convenience, we've outlined all relevant changes in our revision in blue	Reply	O	0

The presented method is a generalization of a number of existing methods, which can be regarded as special cases.	Review	O	0
Overall the method seems to be novel.	Review	O	0
Meanwhile, I have two major questions:[line_break_token]To account for the bias issue, instead of a single DT, ensemble methods such as random forests are the popular choices.	Review	O	0
How ANT could benefit from relying on a single DT instead of a random forest type?	Review	B-Review	1
[line_break_token]The datasets of MNIST and CIFAR-10 are used for many years and the performance is already saturated.	Review	I-Review	2
As presented in Table.3, the performance of the proposed method is also not the best on either of the tested datasets.	Review	I-Review	2
Please clearly elaborate on why and how to address this issue.	Review	I-Review	2
It would be more interesting and meaningful to work with a more recent large datasets, such as ImageNet or MS COCO.	Review	I-Review	2
[line_break_token][line_break_token]The response does not fully address my concerns.	Review	O	0
[line_break_token]In addition to our earlier response, to empirically address your first point, we have now included results from ensembling ANTs (Supp.	Reply	O	0
Sec.	Reply	B-Reply	1
I, page 20), demonstrating improved performance on all 3 datasets, including close to state-of-the-art performance on MNIST [1] with an order of magnitude fewer parameters.	Reply	I-Reply	1
[line_break_token][line_break_token]We have also now included a full set of results on the SARCOS robot inverse dynamics dataset for multivariate regression [2] in Supp.	Reply	I-Reply	1
Sec.	Reply	I-Reply	1
H. (page 19) to demonstrate that our method can work on different domains/tasks.	Reply	I-Reply	1
Using the same training setup we have produced results for ANTs as well as a large variety of baselines.	Reply	I-Reply	1
This is a challenging dataset for standard NNs, with the 3 top-performing methods all being tree-based: SDTs (a specific form of ANTs), GBTs and ANTs.	Reply	I-Reply	1
The best configuration for GBTs requires an order more parameters than the ANT, so taken together, these results (see Tab.	Reply	I-Reply	1
7) show the benefits of both representation learning and partitioning of the data space.	Reply	I-Reply	1
We also perform the same ablation study that we did for MNIST and CIFAR-10, and show that, again, both nonlinear routers and transformers are key components of the ANT algorithm (see Tab.	Reply	I-Reply	1
8).	Reply	I-Reply	1
[line_break_token][line_break_token]As the reviewer points out, experiments on larger datasets (e.g. ImageNet) would be more interesting and useful for showing scalability.	Reply	I-Reply	2
 However, we believe that our results on 2 image datasets (MNIST, CIFAR-10) and 1 non-image dataset (SARCOS) on both classification and regression tasks are sufficiently compelling to motivate such future work.	Reply	I-Reply	2
[line_break_token][line_break_token][1] Sabour, S., Frosst, N., & Hinton, G. E. (2017).	Reply	O	0
Dynamic routing between capsules.	Reply	O	0
In Advances in Neural Information Processing Systems (pp.	Reply	O	0
3856-3866).	Reply	O	0
[line_break_token][2] Vijayakumar, S., & Schaal, S. (2000, June).	Reply	O	0
Locally weighted projection regression: An o (n) algorithm for incremental real time learning in high dimensional space.	Reply	O	0
In Proceedings of the Seventeenth International Conference on Machine Learning (ICML 2000) (Vol.	Reply	O	0
1, pp.	Reply	O	0
288-293)	Reply	O	0

This paper proposes a new type of information measure for positive semidefinte matrices, which is essentially the logarithm of the sum of powers of eigenvalues.	Review	O	0
Several entropy-like properties are shown based on properties of spectral functions.	Review	O	0
A notion of joint entropy is then defined through Hadamard products, which leads to conditional entropies.	Review	O	0
[line_break_token][line_break_token]The newly defined conditional entropy is finally applied to metric learning, leading naturally to a gradient descent procedure.	Review	O	0
Experiments show that the performance of the new procedure exceeds the state of the art (e.g., LMNN).	Review	O	0
[line_break_token][line_break_token]I did not understand the part on infinitely divisible matrices and why Theorem 3.1 leads to a link with maximum entropy.	Review	B-Review	1
[line_break_token][line_break_token]To the best of my knowledge, the ideas proposed in the paper are novel.	Review	O	0
I like the approach of trying to defining measures that have similar properties than entropies without the computational burden of computing densities.	Review	O	0
However, I would have like more discussion of the effect of alpha (e.g., why alpha=1.01 in experiments?	Review	B-Review	2
does it make a big difference to change alpha?	Review	I-Review	2
what does it corresponds to for alpha =2, in particular in relation fo HSIC?).	Review	I-Review	2
[line_break_token][line_break_token]Pros:[line_break_token]-New information measure with attractive properties[line_break_token]-Simple algorithm for metric learning[line_break_token][line_break_token]Cons:[line_break_token]-Lack of comparison with NCA which is another non-convex approach (J. Goldberger, S. Roweis, G. Hinton, R. Salakhutdinov. (	Review	O	0
2005) Neighbourhood Component Analysis.	Review	B-Review	3
Advances in Neural Information Processing Systems.	Review	I-Review	3
17, 513-520.	Review	I-Review	3
[line_break_token]-Too little discussion on the choice of alpha	Review	O	0
This is the same comment from below, we just realized that this is the reply button for your comments.	Reply	O	0
[line_break_token]Dear reviewer, we appreciate the comments and the effort put into reviewing our work.	Reply	O	0
We believe you have made a very valid point by asking us about the role of alpha.	Reply	B-Reply	2
The order of the matrix entropy acts as an Lp norm on the eigenvalues of the Gram matrix.	Reply	I-Reply	2
The larger the entropy the more emphasis on the largest eigenvalues.	Reply	I-Reply	2
This behaviour translates onto our metric learning algorithm as going from multimodal very flexible class structure towards a unimodal more constrained class structure as we increase alpha.	Reply	I-Reply	2
We include an example that illustrates this behaviour.	Reply	I-Reply	2
With respect to HSIC, it is true that for alpha =2 the trace of K^2 shares some resemblance with the criterion.	Reply	I-Reply	2
However there are several differences that makes the connection hard to establish.	Reply	I-Reply	2
First, when dealing with covariance operation it has been already assumed that the mean elements have been removed (covariance operator is centred) .	Reply	I-Reply	2
As we see form the introductory motivation the second order entropy is the norm of the mean vector in the RKHS.	Reply	I-Reply	2
If the mean is removed this vector has zero norm.	Reply	I-Reply	2
We also require our Gram matrix to have non-negative entries so that our information theoretic interpretation makes sense.	Reply	I-Reply	2
We have now included comparisons with NCA	Reply	I-Reply	3

Thanks for addressing most of the issues.	Review	O	0
I changed my given score from 3 to 6.	Review	O	0
[line_break_token][line_break_token]Summary:[line_break_token]This work explores the use of learned compressed image representation for solving 2 computer vision tasks without employing a decoding step.	Review	O	0
[line_break_token][line_break_token]The paper claims to be more computationally and memory efficient compared to the use of original or the decompressed images.	Review	O	0
Results are presented on 2 datasets "Imagenet" and "PASCAL VOC 2012".	Review	O	0
They also jointly train the compression and classification together and empirically shows it can improve both classification and compression together.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]+ The idea of learning from a compressed representation is a very interesting and beneficial idea for large-scale image understanding tasks.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- The paper is too long (13 pages + 2 pages of references).	Review	O	0
The suggested standard number of pages is 8 pages + 1 page of references.	Review	B-Review	1
There are many parts that are unnecessary in the paper and can be summarized.	Review	I-Review	1
Summarizing and rewording them makes the paper more consistent and easier to read:[line_break_token]  ( 1.	Review	O	0
A very long introduction about the benefits of inferring from the compressed images and examples.	Review	B-Review	1
[line_break_token]    2.	Review	O	0
A large part of the intro and Related work can get merged.	Review	B-Review	1
 [line_break_token]    3.	Review	O	0
Experimental setup part is long but not well-explained and is not self-contained particularly for the evaluation metrics.	Review	B-Review	1
[line_break_token]    ‚ÄúPlease briefly explain what MS-SSIM, SSIM, and PSNR stand for‚Äù.	Review	I-Review	1
There is a reference to the Agustsson et al 2017 paper [line_break_token]     ‚Äúscalar quantization‚Äù, which is not well explained in the paper.	Review	I-Review	1
It is better to remove this part if it is not an important part or just briefly but clearly explain it.	Review	I-Review	1
[line_break_token]     4.	Review	O	0
Fig.	Review	B-Review	1
4 is not necessary.	Review	I-Review	1
4.3 contains extra information and could be summarized in a more consistent way.	Review	I-Review	1
[line_break_token]     5.	Review	O	0
Hyperparameters that are applied can be summarized in a small table or just explain the difference between the [line_break_token]      architectures that are used.)	Review	B-Review	1
[line_break_token][line_break_token]- There are parts of the papers which are confusing or not well-written.	Review	O	0
It is better to keep the sentences short and consistent:[line_break_token]E.g: subsection 3.2, page 5: ‚ÄúTo adapt the ResNet ‚Ä¶ where k is the number of ‚Ä¶ layers of the network‚Äù can be changed to 3 shorter sentences, which is easier to follow.	Review	B-Review	5
[line_break_token]There are some typos: e.g: part 3.1, fever ---> fewer, [line_break_token][line_break_token]- As it is mentioned in the paper, solving a Vision problem directly from a compressed image, is not a novel method (e.g: DCT coefficients were used for both vision and audio data to solve a task without any decompression).	Review	O	0
However, applying a deep representation for the compression and then directly solving a vision task (classification and segmentation) can be considered as a novel idea.	Review	B-Review	2
[line_break_token][line_break_token]- In the last part of the paper, both compression and classification parts are jointly trained, and it is empirically presented that both results improved by jointly training them.	Review	I-Review	3
However, to me, it is not clear if the trained compression model on this specific dataset and for the task of classification can work well for other datasets or other tasks.	Review	O	0
 [line_break_token]The experimental setup and the figures are not well explained and well written.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
Thank you for your your review, we have considered your comments in the revised version of the paper.	Reply	O	0
Given the improved paper and positive perspective of the other reviews, we hope you reconsider your rating.	Reply	O	0
[line_break_token][line_break_token]For specific points:[line_break_token][line_break_token]Regarding paper length: since this is a study paper, we felt it benefited from verbosity.	Reply	O	0
However, we have managed to shorten the paper to 9.5 pages, while keeping the original story intact.	Reply	B-Reply	1
We followed most of your suggestions: (1-2) We shortened the introduction and related work; (4) We made Section 4.3 (now Section 4.4) much more concise and moved Figure 4 to the appendix as it did not contain core results of our work. (	Reply	I-Reply	1
3) We added a better description of the compression metrics to the experiments section.	Reply	I-Reply	1
However, we also moved the compression results to the appendix, and added a more detailed explanation of the metrics there. (	Reply	I-Reply	1
5) We also fixed wording in the paper as you suggested and moved hyperparameter settings and details to the appendix, as we felt these details distract from the main message of the paper.	Reply	I-Reply	1
In addition to this, we refined presentation of joint training results using plots rather then presenting them in text.	Reply	I-Reply	1
[line_break_token][line_break_token]As we mention in the paper, learning from DCT (of JPEG) has been done before.	Reply	I-Reply	2
However, our setting of using features from learned compression networks is significantly different.	Reply	I-Reply	2
The DCT of JPEG is simply a linear transform over 8x8 patches, whereas the compressed representation is a feature map from a deep convolutional neural network.	Reply	I-Reply	2
This opens directions such as joint learning of compression and inference (see Section 6) and warrants a full study of the problem.	Reply	I-Reply	2
[line_break_token][line_break_token]To show that the improvement of joint training generalizes to another task, we added an experiment: We take the (jointly trained) classification network and finetune it for segmentation.	Reply	I-Reply	3
The results are shown in Figure 7, where the resulting network significantly outperforms the separately trained network - achieving a significant performance boost of 1.1-1.8% higher mIoU depending on the compression operating point.	Reply	I-Reply	3
See Figure 7 and discussion in Section 6.2 of the revised paper for more details.	Reply	I-Reply	3
[line_break_token]We emphasize that this generalization is also occurring across datasets, from ILSVRC2012 (classification) to PASCAL VOC (segmentation).	Reply	I-Reply	3
[line_break_token][line_break_token]Finally, we made an effort to better clarify and describe the experiments	Reply	I-Reply	4

This paper proposes a new cascaded image-to-image translation method to address the I2I tasks where the domains have exhibit significantly different shapes.	Review	O	0
The proposed method train cycle GAN on different levels of feature extracted by pre-trained VGG and combine the futures with the AdaIN layer to keep the correct shape from the deep features.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
The proposed method seems to work well on different shape I2I datasets without using semantic masks compared to previous works.	Review	O	0
[line_break_token]2.	Review	O	0
The idea of cascaded translators sounds simple and reasonable which can probably benefit other related tasks.	Review	O	0
The way of applying AdaIn to combine features of different levels is also a nice trick to keep the correct shape from deep features.	Review	O	0
[line_break_token]3.	Review	O	0
The paper writing is OK, but some explanation and organization should be improved as mention in cons.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
Some figures are hard to understand without looking at the text.	Review	B-Review	1
For example, in Figure 1, the caption does not explain the figure well.	Review	I-Review	1
What does each image, the order, and the different sizes mean?	Review	I-Review	1
 As to Figure 3, the words ‚Äútop left image‚Äù, ‚Äúright purple arrows‚Äù are a bit confusing.	Review	I-Review	1
[line_break_token]2.	Review	O	0
The ‚ÄúCoarse to fine conditional translation‚Äù section describes the conditional translation in the shallow layers.	Review	B-Review	2
I suggest mentioning it in previous sections for easy understanding.	Review	I-Review	2
[line_break_token]3.	Review	O	0
As to the t-SNE visualization in Figure 9, different methods seem to use different N-D to 2-D mapping functions.	Review	B-Review	3
This may lead to an unfair comparison.	Review	I-Review	3
[line_break_token][line_break_token]Suggestions:[line_break_token]1.	Review	O	0
The authors use the pre-trained classification network VGG for feature extraction and then train dedicated translators based on these features.	Review	B-Review	4
I wonder if the authors also tried finetuning VGG on the two domains or training an auto-encoder on the two domains.	Review	I-Review	4
The domain-specific knowledge may help to improve the results and alleviate the limitations presented in the paper, e.g. background of the object is not preserved, missing small instances or parts of the object due to invertible VGG-19.	Review	I-Review	4
hank you for taking the time to review our paper and for your thoughtful suggestions and questions.	Reply	O	0
[line_break_token][line_break_token]--- Some figures are hard to understand without looking at the text[line_break_token]---The ‚ÄúCoarse to fine conditional translation‚Äù‚Ä¶ I suggest mentioning it in previous sections for easy understanding.	Reply	O	0
[line_break_token]We will revise the captions of Figure1 and Figure3 to be more self-contained.	Reply	B-Reply	1
The translation process is also explained in the introduction and at the beginning of the methods, and we will stress more the coarse to fine conditional translation.	Reply	I-Reply	1
[line_break_token][line_break_token]--- As to the t-SNE visualization in Figure 9, different methods seem to use different N-D to 2-D mapping functions.	Reply	O	0
This may lead to an unfair comparison.	Reply	O	0
[line_break_token]As common for domain adaptation tasks, we calculate the t-SNE based on the source, target and translated features together.	Reply	B-Reply	3
[line_break_token][line_break_token]--- Finetuning VGG on the two domains or training an auto-encoder on the two domains.	Reply	O	0
[line_break_token]Fine-tuning VGG features is an interesting idea, which we did try for some of the datasets.	Reply	B-Reply	4
However, we noticed this to produce slightly visually inferior results.	Reply	I-Reply	4
This might be attributed to fixating on the exact differences between zebra and giraffe: scale, poses, and even the background.	Reply	I-Reply	4
[line_break_token]The use of an autoencoder, while enabling self-supervised semantics extraction, we believe, will struggle to achieve high quality semantics as successfully as VGG pertained on ImageNet.	Reply	I-Reply	4
If requested, we could experiment with an autoencoder based on VGG architecture and report the results.	Reply	I-Reply	4

This paper presents a programming language for building differentiable physics simulators.	Review	O	0
This is a very interesting goal, as differentiable systems are a crucial building block for many deep learning methods and similar optimization techniques.	Review	O	0
[line_break_token][line_break_token]The system presented by the authors is certainly impressive.	Review	O	0
Unfortunately, the paper itself covers a wide range of topics, and consists of an overview of the language with a programming tutorial, a collection of ten results, and a brief discussion of problems when computing gradients.	Review	O	0
[line_break_token][line_break_token]The core of the proposed work, the programming language seems to be quite powerful.	Review	B-Review	1
However, it seems to be built on an existing system, which was published as a programming language for simulation in this years siggraph asia conference (Taichi: A language for high-performance computation on spatially sparse data structures.	Review	I-Review	1
In SIGGRAPH Asia 2019 Technical Papers, pp.	Review	I-Review	1
201.	Review	I-Review	1
ACM, 2019a).	Review	I-Review	1
This ICLR submission seems to extend this system to build and provide gradient information automatically along with the simulation itself.	Review	I-Review	1
There seem to be few technical challenges here, and many aspect discussed in section 2 are shared with the original simulation language.	Review	I-Review	1
[line_break_token][line_break_token]The examples cover a nice range of cases, from simple mass spring systems and a rendering case to complex 3d simulations.	Review	I-Review	2
Here, I was a bit surprised that the paper only compares to autograd, which has been succeeded by jax.	Review	I-Review	2
The latter also provides a compiler backend to produce GPU code with gradients, and as such seems very closely related to the proposed language.	Review	I-Review	2
From the submission, it's hard to say which version has advantages.	Review	I-Review	2
The examples seem to be a sequence of demos of the language, rather than illustrating different technical challenges or improvements for a scientific conference.	Review	I-Review	2
Or at least a discussion of these differences is currently missing in the text.	Review	I-Review	2
[line_break_token][line_break_token]Section four also mostly gives the impression of a loose discussion.	Review	I-Review	3
The gradients for rigid body impacts are interesting, but seem relevant only for a subset of 2D examples shown in the paper.	Review	I-Review	3
The discussion of gradient explosions is quite ad-hoc, and would be stronger with a more detailed analysis.	Review	I-Review	3
[line_break_token][line_break_token]The submission as a whole aims for a very interesting direction, but I think the paper would benefit from focusing on a certain range of problems, such as the rigid body control cases, in conjunction with topics such as the improved gradients.	Review	O	0
Instead, the current version tries to combine this topic with a systems overview, a tutorial and loosely related discussions.	Review	B-Review	4
Combined with the length of 10 pages, I think the work could use a revision rather than being accepted in its current form.	Review	I-Review	4
ear Reviewer 2,[line_break_token][line_break_token]Thank you for the helpful feedback.	Reply	O	0
We have reorganized the paper to make it more focused on the DiffSim automatic differentiation system design alone, instead of multiple topics.	Reply	B-Reply	4
The paper is now 8 pages instead of 10.	Reply	I-Reply	4
[line_break_token][line_break_token]** Building on Top of Taichi**[line_break_token]The main goal of DiffSim is to simplify the process of making existing physical simulators differentiable, and we reuse Taichi because Taichi is very suitable for building forward simulators.	Reply	O	0
We indeed reused some infrastructure of Taichi, but such reuse also poses a unique challenge to redesign a tailored automatic differentiation system for it, which a) does not harm the performance of Taichi programs and b) needs minimal code modification to make a Taichi program differentiable.	Reply	B-Reply	1
To this end, we have developed a tailored two-scale AD system that is high-performance and imposes minimal global data access restrictions to Taichi programs.	Reply	I-Reply	1
Please check out the new section 3 for more details.	Reply	I-Reply	1
[line_break_token][line_break_token]**Comparison with JAX**[line_break_token]We have added JAX with GPU backend to the smoke simulation benchmark, and DiffSim GPU is 1.9x faster than JAX GPU, despite that this grid-based simulation benchmark is slightly biased towards differentiable array programming systems such as Autograd and JAX.	Reply	O	0
The whole program takes 10 seconds to run in DiffSim on a GPU, and 2 seconds are spent on JIT.	Reply	B-Reply	2
JAX JIT compilation takes 2 minutes.	Reply	I-Reply	2
In Appendix A, we also added a table that comprehensively compares DiffSim with 7 other existing systems.	Reply	I-Reply	2
[line_break_token][line_break_token]**Gradient Quality Discussions**[line_break_token]We removed the discussion on gradient explosion, and moved the rigid body gradient issue to the evaluation section along with the rigid body simulator, to limit the scope of this gradient discussion to rigid body simulations.	Reply	O	0
[line_break_token][line_break_token]Please also find the detailed paper change log in our general response to all reviewers.	Reply	O	0
Thank you again for your time and feedback!	Reply	O	0
[line_break_token][line_break_token]Best,[line_break_token]Author	Reply	O	0

The authors propose a method for learning representations for graphs.	Review	O	0
The main purpose is the classification of graphs.	Review	O	0
[line_break_token][line_break_token]The topic is timely and should be of interest to the ICLR community.	Review	O	0
[line_break_token][line_break_token]The proposed approach consists of four parts: [line_break_token][line_break_token]Initial feature transformation[line_break_token]Local features aggregation[line_break_token]Graph pooling[line_break_token]Final aggregator[line_break_token][line_break_token]Unfortunately, each of the part is poorly explained and/or a method that has already been used before.	Review	O	0
For instance, the local feature aggregation is more or less identical to a GCN as introduced by Kipf and Welling.	Review	B-Review	1
There are now numerous flavors of GCNs and the proposed aggregation function in (2) is not novel.	Review	I-Review	1
[line_break_token][line_break_token]Graph pooling is also a relatively well-established idea and has been investigated in several papers before.	Review	I-Review	2
The authors should provide more details on their approach and compare it to existing graph pooling approaches.	Review	I-Review	2
[line_break_token][line_break_token]Neither (1) nor (4) are novel contributions.	Review	I-Review	3
[line_break_token][line_break_token]The experiments look OK but are not ground-breaking and are not enough to make this paper more than a mere combination of existing methods.	Review	I-Review	4
[line_break_token][line_break_token]The experiments do not provide standard deviation.	Review	I-Review	5
Graph classification problems usually exhibit a large variance of the means.	Review	I-Review	5
Hence, it is well possible that the difference in mean is not statistically significant.	Review	I-Review	5
[line_break_token][line_break_token]The paper could also benefit from a clearer explanation of the method.	Review	I-Review	6
The explanation of the core parts (e.g., the graph pooling) are difficult to understand and could be made much clearer.	Review	I-Review	6
[line_break_token]	Review	O	0
First we would like to thank the reviewer for his/her constructive comments.	Reply	O	0
 We thoroughly edited the paper to address the comments.	Reply	O	0
[line_break_token][line_break_token]The paper has an important message.	Reply	O	0
A GNN without an embedding step can be meaningless.	Reply	O	0
We show this fact with synthetic experiments and the experiments with real data.	Reply	O	0
With synthetic data we show that the GNN basically can not learn to perform the given simple tasks.	Reply	O	0
For some of the real data-sets, the improvement is huge.	Reply	O	0
For instance, for the PTC data-set the improvement is 22 % (62 ==> 76).	Reply	O	0
Moreover, a new architecture based on the proposed idea for graph clustering is proposed.	Reply	O	0
[line_break_token][line_break_token]--- Novelty of the presented architecture: In this paper we do not propose a new convolution layer or a new architecture for the GNNs.	Reply	O	0
We employ a simple GNN depicted in Figure 1.	Reply	B-Reply	1
[line_break_token]The main contribution of the paper is twofold.	Reply	I-Reply	1
[line_break_token]First, we make an important point that the GNNs can fail to infer the structure of the unlabeled  graphs.	Reply	I-Reply	1
We show this important point through clear synthetic experiments.	Reply	I-Reply	1
The experiments show that convolutional graph neural networks can fail to learn to perform even simple graph classification tasks.	Reply	I-Reply	1
We argue that similar to the NLP tasks, a GNN requires an embedding step to make the network aware of the differences/similarities between the nodes of the graph.	Reply	I-Reply	1
The embedding step turns the graph analysis task into a point-cloud analysis problem.	Reply	I-Reply	1
[line_break_token]In addition, we showed that although we use a simple GNN, the embedding step can significantly improve the results for many of the real datasets.	Reply	I-Reply	1
For instance:[line_break_token]PTC: 14 % higher accuracy (22 % improvement !)	Reply	I-Reply	1
[line_break_token]MUTAG: 6 % higher accuracy (6 % improvement)[line_break_token]These are significant improvements while we are employing a simple GNN.	Reply	I-Reply	1
[line_break_token]In addition, we have added a small section to the revision to extend the proposed approach to a graph clustering method.	Reply	I-Reply	1
The proposed method leverages the point-cloud representation of the graph.	Reply	I-Reply	1
We have added a new experiment which shows that the conventional GNNs cannot be trained to cluster unlabeled graphs.	Reply	I-Reply	1
[line_break_token][line_break_token]Our second main contribution is the proposed pooling method.	Reply	I-Reply	1
The presented idea is simple.	Reply	I-Reply	1
We merge the joint closest nodes in the feature space because the embedding step provides a spatial representation of the graph.	Reply	I-Reply	1
In contrast to the previous methods, we do not need to run a graph clustering algorithm.	Reply	I-Reply	1
In addition, it can down-sample the graph by a fix predefined factor.	Reply	I-Reply	1
 Moreover, in contrast to the soft pooling method, it is applicable to the sparsely connected graphs and the sparsity of the adjacency is not lost.	Reply	I-Reply	1
[line_break_token] [line_break_token]--- "Graph pooling is also a relatively well-established idea and has been investigated in several papers before.	Reply	O	0
The authors should provide more details on their approach and compare it to existing graph pooling approaches.":	Reply	O	0
[line_break_token]Yes, pooling is an established idea in processing graphs and point-clouds.	Reply	B-Reply	2
In this paper, we propose a novel graph pooling method.	Reply	I-Reply	2
In the proposed approach we do not need to run a graph clustering method and the proposed method uses the spatial distribution of the nodes to perform pooling.	Reply	I-Reply	2
The proposed method merges the joint nodes which are the closest nodes in the spatial domain.	Reply	I-Reply	2
Thus, even if two nodes are far from each other on the graph, they can be merged if they have similar topological roles in the graph.	Reply	I-Reply	2
 In this paper, we are comparing the proposed pooling method with two new deep learning based approaches which employed new graph pooling layers (DGCNN and DIFFPOOL).	Reply	I-Reply	2
[line_break_token] [line_break_token]--- Clarifying the pooling method: In the revised paper, we have edited the pooling method.	Reply	O	0
An example has been added to the revision to explain the proposed method.	Reply	O	0
[line_break_token] [line_break_token]---  "The experiments do not provide standard deviation.	Reply	O	0
Graph classification problems usually exhibit a large variance of the means.	Reply	O	0
Hence, it is well possible that the difference in mean is not statistically significant": Unfortunately some of the deep learning based methods that we are comparing with them did not report the variance.	Reply	O	0
Thus, even if we report the variance, the reader can not make a comparison.	Reply	B-Reply	5
We have added the information about the variance of the proposed approach with the real data-sets to the revised paper.	Reply	I-Reply	5
[line_break_token] [line_break_token]--- "The experiments look OK but are not ground-breaking and are not enough to make this paper more than a mere combination of existing methods.":	Reply	O	0
[line_break_token]We make an important point in this paper that the GNNs can fail to learn to perform even simple graph analysis Tasks.	Reply	B-Reply	4
We provide a clear evidence that message passing without a proper input does not necessarily infer the structure of the graph.	Reply	I-Reply	4
In addition, it is shown that with the embedding step, our GNN can significantly advance the state-of-the-art results on the real data-sets.	Reply	I-Reply	4
For instance, for the PTC data-set, the improvement is more than 22 %.	Reply	I-Reply	4

The paper aims to improve exploration in DRL through the use of planning.	Review	O	0
This is claimed to increase state space coverage in exploration and yield better final policies than methods not augmented with planner derived data.	Review	O	0
[line_break_token][line_break_token]The current landscape of DRL research is very broad, but RRT can only directly be applied in certain continuous domains with continuous action spaces.	Review	B-Review	1
With learned embedding functions, RRT can be applied more broadly (see "Taking the Scenic Route: Automatic Exploration for Videogames" Zhan 2019).	Review	I-Review	5
The leap from RRT-like motion planning to the general topic of "planning" for policy search is not well motivated explained with respect to the literature.	Review	I-Review	5
Uses of Monte Carlo Tree Search (as in AlphaGo) seem obviously related here.	Review	I-Review	5
[line_break_token][line_break_token]This reviewer moves to reject the paper primarily on the grounds of overinterpreting experimental results from a single, extremely simple example RL task.	Review	I-Review	2
In a domain so small, we can't tease out the role of exploration, we aren't engaging with the "deep" of DRL, and we are only considering one specific kind of planning.	Review	I-Review	2
The implicit claims of general improvement to exploration and improved downstream policies are not supported by the experimental results.	Review	I-Review	2
At the same time, no theoretical argument is attempted that would make up for the very narrow nature of the experiments.	Review	I-Review	2
[line_break_token][line_break_token]Questions for the authors:[line_break_token]- If HalfCheetah is used to motivate the work, and it is so easily available in the open source offerings from OpenAI, why isn't one (or many more) tasks of *at least* this complexity considered?	Review	O	0
MountainCar is one of the gym environments with a 2D phasespace compatible with the kinds of plots used in this paper.	Review	B-Review	3
[line_break_token]- Could the authors taxonomize the landscape of planning and provide a specific argument for focusing on RRT? (	Review	O	0
RRT is a fun algorithm, but how will you draw the attention of other researchers who are currently focused on Atari games?)	Review	B-Review	4
Ä¢ Thank you for your review!	Reply	O	0
[line_break_token]‚Ä¢ We eventually want to apply our method on robotics tasks and therefore we focus on continous state/continuous action spaces.	Reply	O	0
[line_break_token]‚Ä¢ The paper by Zhan et al. ‚	Reply	O	0
Äô19 (‚ÄúTaking the scenic route: Automatic exploration for video games‚Äù) shows an interesting idea to extend the use of RRT even to domains like the Atari games: they use features of a neural network as a low-dimensional continuous embedding of an (Atari/similar) game state (i.e. the image).	Reply	B-Reply	5
They use a simplified version of RRT that samples a target point, restores the closest state stored in the tree and tries to reach that target[line_break_token]point.	Reply	I-Reply	5
However usually RRT uses a local steering method to reach that target point ‚Äì while Zhan et al.	Reply	I-Reply	5
use a (random) action sequence irrespective of the target point.	Reply	I-Reply	5
[line_break_token]Since we want to target to robotics tasks, where action and feature spaces are inherently continuous and discretization becomes infeasible, we need to be able to deal with such action spaces.	Reply	I-Reply	5
Moreover and related to the next comment, random steering will often not be beneficial: either it cannot be done at all, or it is too inefficient.	Reply	I-Reply	5
[line_break_token]‚Ä¢ MCTS: Since we want to eventually apply our method on robotic tasks, we are focusing on continuous domains, we focus on planning methods that are able to deal with such domains and therefore sampling based planners.	Reply	O	0
AlphaGo is an impressive showcase of an extended version of MCTS - however MCTS needs extensions to be applicable in continuous domains, such as[line_break_token]for example (but not limited to) HOOT (Mansley et al.	Reply	B-Reply	5
,‚ÄúSample-Based Planning for Continuous Action Markov Decision Processes‚Äù), to be applicable to continuous action domains.	Reply	I-Reply	5
[line_break_token]A second aspect is that MCTS typically does not use the information often available in these continuous domains: the locally linearised dynamics - which the local steering method of RRT exploits.	Reply	I-Reply	5
[line_break_token]We therefore chose RRT as a reasonably effective, yet reasonably simple to implement planning method - although we do not foresee any reason why other planning methods would not work as long as they are applicable to kino-dynamic domains, and produce environment interactions.	Reply	I-Reply	5
[line_break_token]‚Ä¢ We will add more tasks in the next extension	Reply	O	0

The work proposes a structure that mimics progressive nets.	Review	O	0
Maybe the main difference from progressive nets is that backwards connection from the new features to the old features in layer 2 are not 0 out.	Review	B-Review	1
This could cause interference, however is solved by using the task ID to not evaluate those new features when going back to a previous task.	Review	I-Review	1
I think this is a technical detail, that does not provide any explicit advantage or disadvantage over progressive nets.	Review	I-Review	1
[line_break_token][line_break_token]Employing GANs/VAE to predict task id also can be seen as not an ideal choice.	Review	I-Review	2
In particular the GAN network will suffer from catastrophic forgetting, which is solved (if I understood correctly) by training the GAN with data from all tasks.	Review	I-Review	2
Which makes one wonder, if we can affort to access data from all tasks to learn the GAN then why not the classification model too !?	Review	I-Review	2
[line_break_token][line_break_token]I think an alternative might be something like the Forget Me Not Process published and used in the original work with EWC.	Review	I-Review	3
[line_break_token][line_break_token]Unfortunately due to presence of these previous works, lack of more thorough comparison with other existing approaches, the work should not be accepted to ICLR.	Review	I-Review	4
Thank you for the comments and feedbacks.	Reply	O	0
[line_break_token][line_break_token]We think there was a misunderstanding.	Reply	B-Reply	1
Gradients to the old features are 0 out to make sure they do not ruin the trained parameters.	Reply	I-Reply	1
[line_break_token]In the progressive network, each feature is summarized by an additional adapter and passed to the next task network.	Reply	I-Reply	1
Therefore, it is not a typical form of CNN.	Reply	I-Reply	1
Meanwhile, our HCnet takes the form of a regular CNN and just expands the number of filters so that the new information is learned by those additional filters.	Reply	I-Reply	1
That is why we compared our method to the Packnet.	Reply	I-Reply	1
Packnet also divides its capacity into several pieces but has no ability to add more tasks once the network is trained and pruned.	Reply	I-Reply	1
What we wanted to present in this paper was (1) we can retain the properties of the Packnet (2) without using any pruning process which makes the packnet unexpandable, (3) in a typical form of CNN so that it can be easily used in various applications.	Reply	I-Reply	1
[line_break_token][line_break_token]In the case of the GAN/VAE, We do not use the whole datasets for the generative model.	Reply	I-Reply	2
If there are three tasks, the H-Net also has three generative models.	Reply	I-Reply	2
Each generative model is trained only using each task data.	Reply	I-Reply	2
Then, the binary classifier use the three generators for training	Reply	I-Reply	2

This work proposes to a spatiotemporal saliency network that is able to mimic human fixation patterns,[line_break_token]thus helping to prune irrelevant information from the video and improve action recognition.	Review	O	0
[line_break_token][line_break_token]The work is interesting and has shown state-of-the-art results on predicting human attention on action videos.	Review	O	0
[line_break_token]It has also shown promise for helping action clip classification.	Review	O	0
[line_break_token][line_break_token]The paper would benefit from a discussion on the role of context in attention.	Review	B-Review	1
[line_break_token]For instance, if context is important, and people give attention to context, why is it not incorporated automatically in your model?	Review	I-Review	1
[line_break_token][line_break_token]One weak point is the action recognition section, where the comparison between the two (1)(2) and (3) seems unfair.	Review	I-Review	2
[line_break_token]The attention weighted feature maps in fact reduce the classification performance, and only improve performance when doubling the feature and associated model complexity by concatenating the weighted maps with the original features.	Review	I-Review	2
[line_break_token][line_break_token]Is there a way to combine the context and attention without concatenation?	Review	I-Review	3
[line_break_token]The rational for concatenating the features extracted from the original clip,[line_break_token]and the features extracted from the saliency weighted clip seems to contradict the initial hypothesis that `eliminating or down-weighting pixels that are not important' will improve performance.	Review	I-Review	3
[line_break_token][line_break_token]The authors should also mention the current state-of-the-art results in Table 4, for comparison.	Review	I-Review	4
[line_break_token][line_break_token]# Other comments:[line_break_token]# Abstract[line_break_token]- Typo: `mixed with irrelevant ...'[line_break_token]``Time consistency in videos ... expands the temporal domain from few frames to seconds'' - These two points are not clear, probably need a re-write.	Review	O	0
[line_break_token][line_break_token]# Contributions[line_break_token]- 1) `The model can be trained without having to engineer spatiotemporal features' - you would need to collect training data from humans though.. [line_break_token][line_break_token]# Section 3.1[line_break_token]The number of fixation points is controlled to be fixed for each frame - how is this done?	Review	O	0
[line_break_token][line_break_token]In practice we freeze the layers of the C3D network to values pretrained by Tran etal.	Review	B-Review	8
[line_break_token]What happens when you allow gradients to flow back to the C3D layers?	Review	I-Review	8
[line_break_token]Is it not better to allow the features to be best tuned for the final task?	Review	I-Review	8
[line_break_token][line_break_token]The precise way in which the features are concatenated needs to be clarified in section 3.4.	Review	I-Review	9
[line_break_token][line_break_token]Minor typo:[line_break_token]`we added them trained central bias'	Review	O	0
The context and attention parts are capturing slightly different information (as confirmed empirically in our study).	Reply	B-Reply	1
The context features represent the video in its entirety.	Reply	I-Reply	1
Therefore they may contain elements from the background, which may be useful for action categorization but at times also potentially distracting.	Reply	I-Reply	1
Instead, the attention part focuses only on the most salient spatiotemporal volumes in the video.	Reply	I-Reply	1
We agree that there are many other ways to use the saliency maps produced by our model.	Reply	I-Reply	1
For example, the saliency map could be used to sample higher-resolution crops of the frames.	Reply	I-Reply	1
We opted for the simplest model in order to show that what is contributing to the improvement in action categorization is truly coming from the saliency map and not from a more complex model.	Reply	I-Reply	1
[line_break_token][line_break_token]‚ÄúComparison between [(1), (2)] and (3) seems unfair.	Reply	O	0
‚Äù As we mentioned in the pre-review answer ‚ÄúAnswer to few questions, comments‚Äù, we ran an experiment with PCA to yield the same feature dimensionality as (1) in order to have a more fair comparison.	Reply	O	0
The resulting testing mAP of this compressed descriptor (using both context and attention) is 51.82%, which is quite a bit better than method (1) (based on context only), despite having the same dimensionality.	Reply	B-Reply	2
We added this relevant result to the paper (last paragraph in page 8).	Reply	I-Reply	2
[line_break_token][line_break_token]The number of fixations are randomly subsampled (first paragraph, Sec.	Reply	I-Reply	7
3.1) if greater than A. Conversely, they are  randomly duplicated if less than A. [line_break_token][line_break_token]In our experiments, we froze the layers of the C3D. We ran several fine-tuning experiments for action recognition using the Hollywood2 dataset, however we have never obtained any significant improvement.	Reply	O	0
We think that this might be due to the small size of the dataset and to the fact that the C3D features are already representative and general since they were trained on a huge dataset.	Reply	B-Reply	8
This discouraged us to run fine-tuning experiments for saliency prediction.	Reply	I-Reply	8
[line_break_token][line_break_token]About feature concatenation: for each clip, we stacked the d-dimensional context feature vector on top of the d-dimensional attention-based feature vector to form a (2*d)-dimensional descriptor.	Reply	I-Reply	9

In this paper a novel approach for anomaly detection is considered for the task of intrusion detection based on system call sequence.	Review	O	0
[line_break_token]The system call sequence is regarded as a language, and multiple lstm-rnn language models are trained and ensembled.	Review	O	0
[line_break_token]Diversity in the ensemble is achieved by choosing different hyper parameters for each lstm-LM.	Review	O	0
[line_break_token]The combination of the LMs is done by averaging transformations of the likelihoods.	Review	O	0
[line_break_token][line_break_token]I really like the fact that no attack data is used during training, and I like the LM and ensemble approach.	Review	O	0
[line_break_token]The only high level drawbacks I have are the following, which might have a simple answer as I'm not an expert in this field:[line_break_token][line_break_token]- Relaying of system calls seems weak: If the attacker has access to some "normal" sequences of system calls, all she can fool the system by interleaving its malicious system calls with normal ones, in a way that will artificially raise the likelihood of the sequence.	Review	O	0
[line_break_token]- A few lines covering other anomaly detection tasks, where RNNs are used, can be added to the introduction, to give a better idea about the novelty of the approach.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your constructive comments.	Reply	O	0
[line_break_token][line_break_token]The type of attack mentioned in your first comment ("Relaying of system calls ...") is related to the mimicry attack (Wagner and Soto, 2002), which may allow an attacker to cloak the intrusion to avoid detection by intrusion detection systems.	Reply	B-Reply	1
Completely avoiding a general form of mimicry attack remains an open problem, but as we briefly mentioned in the Conclusion section, we are planning to consider the possibility of applying our LSTM-based language modeling approach to such attacks.	Reply	I-Reply	1
Using our LSTM-based method allows us to estimate the likelihood of long system-call sequences, which may be helpful for analyzing the capability of handling mimicry attacks to some extent.	Reply	I-Reply	1
However, there is currently no public benchmark or dataset for testing mimicry attacks, and in-depth analysis of an algorithm to detect mimicry attacks will be very challenging.	Reply	I-Reply	1
In the revision, we will include relevant backgrounds and discussions in the manuscript.	Reply	I-Reply	1
[line_break_token][line_break_token]As you pointed out, there exist RNN-based anomaly detection methods in the literature (e.g., Cannady, 1998; Ryan et al.,	Reply	I-Reply	2
1998; Mukkamala et al.,	Reply	I-Reply	2
2002; Wang et al.,	Reply	I-Reply	2
2010).	Reply	I-Reply	2
Compared with these approaches, the most salient advantage of our approach is the use of a deep learning-based language modeling of system call sequences in combination with ensemble methods for end-to-end learning and robust intrusion detection.	Reply	I-Reply	2
We will include additional contents on related work in the revised manuscript in order to put our approach in a proper context and contrast our method with existing work	Reply	I-Reply	2

Summary:[line_break_token][line_break_token]Stability is one of the important aspects of machine learning.	Review	O	0
 This paper views Jacobian regularization as a scheme to improve the stability, and studies the behavior of Jacobian regularization under random input perturbations, adversarial input perturbations, train/test distribution shift, and simply as a regularization tool for the classical setting without any distribution shifts nor perturbations.	Review	O	0
 There are already several related works that propose to use Jacobian regularization, but previous works didn‚Äôt have an efficient algorithm and also did not have theoretical convergence guarantee.	Review	O	0
 This paper offers a solution that efficiently approximate the Frobenius norm of the Jacobian and also show the optimal convergence rate for the proposed method.	Review	O	0
 Various experiments show that the behavior of Jacobian regularization and show that it is robust.	Review	O	0
[line_break_token][line_break_token]Reasons for the decision:[line_break_token][line_break_token]Positives: The contribution of the paper seems to be two-fold:  First a theoretically guaranteed and efficient method for Jacobian regularizer, and second, intensive experiments to show the robustness of the Jacobian regularizer.	Review	O	0
 Each of these points seem to have important contributions for the field.	Review	O	0
[line_break_token][line_break_token]Negatives:  An issue might be that the latter contribution seems to be orthogonal to the former since there are no experiments comparing with previous methods mentioned in the paper, and it gives the impression that there are two separate stories in one paper.	Review	O	0
 For instance, there are no experiments comparing computational time between Sokolic et al. (	Review	B-Review	1
2017).	Review	I-Review	1
On the other hand, there are only regularization methods (that are not necessarily designed to be robust) used as baselines in the experiments to show robustness, instead of algorithms that are designed to be robust, e.g., domain adaptation methods for Table 2.	Review	I-Review	1
 It would make the paper stronger to combine these two lines of contributions into a single story.	Review	O	0
 For example, it might be better to emphasize more that experiments such as Figure S7 was previously not possible due to inefficient implementation.	Review	B-Review	2
[line_break_token][line_break_token]Minor comment:  It would make the paper stronger to include some of the main related works in the Introduction section.	Review	O	0
[line_break_token][line_break_token][line_break_token]After author response:[line_break_token]Thank you for reading my review and answering the questions.	Review	O	0
 Although I still feel the same for my score (6), in my opinion, the same issues exist for this paper, and the paper can be made stronger on those points.	Review	O	0
hank you for your feedback on our work.	Reply	O	0
We agree with your assessment of our main contributions and also appreciate your suggestions for further improvements.	Reply	O	0
We will take your suggestion to further emphasize the difficulty of producing results like those shown in Fig S7 without an efficient approximate algorithm.	Reply	B-Reply	2
[line_break_token][line_break_token]We agree that the L2 and dropout regularizers are not intended to provide adversarial robustness.	Reply	I-Reply	1
However, Jacobian regularization is similarly a generic regularizer which prioritizes input-output stability.	Reply	I-Reply	1
We believed that a natural comparison between commonly used regularizers to prevent overfitting in deep learning were a useful initial comparison point.	Reply	I-Reply	1
In the majority of our experiments we additionally include a comparison with adversarial training which is specifically designed for defense against the types of attacks we use at test time.	Reply	I-Reply	1
We highlight that Jacobian regularizer is able to improve robustness on par with a method that privileged information (i.e. knowledge of likely test time attacks during learning).	Reply	I-Reply	1
This showcases the general applicability of Jacobian regularizer and makes the ability to scale the approach to large data settings all the more relevant.	Reply	I-Reply	1
[line_break_token][line_break_token]We also want to clarify that our method when applied for a scenario like cross-domain generalization is trained using *only* access to the source domain and is simply applied at test time to target domain.	Reply	I-Reply	1
This does not invalidate the potential use of adaptation approaches in addition to Jacobian regularization should (potentially unlabeled) target data become available during training.	Reply	I-Reply	1
Our goal is to showcase the intrinsic robustness to data shift that arises from optimizing Jacobian regularizer	Reply	I-Reply	1

The paper considers an actor-critic scheme for multiagent RL, where the critic is specific to each agent and has access to all other agents' embedded observations.	Review	O	0
The main idea is to use an attention mechanism in the critic that learns to selectively scale the contributions of the other agents.	Review	O	0
[line_break_token][line_break_token]The paper presents sufficient motivation and background, and the proposed algorithmic implementation seems reasonable.	Review	O	0
The proposed scheme is compared to two recent algorithms for centralized training of decentralized policies, and shows comparable or better results on two synthetic multiagent problems.	Review	O	0
[line_break_token][line_break_token]I believe that the idea and approach of the paper are interesting and contribute to the multiagent learning literature.	Review	O	0
[line_break_token][line_break_token]Regarding cons: [line_break_token]- The critical structural choices (such as the attention model in section 3.2) are presented without too much justification, discussion of alternatives, etc.	Review	O	0
[line_break_token]- The experiments show the learning results, but do not provide a peak "under the hood" to understand the way attention evolved and contributed to the results.	Review	O	0
[line_break_token]- The experiments show good results compared to existing algorithms, but not impressively so.	Review	O	0
Thank you for your comments.	Reply	O	0
With regard to the structural choices of the attention model, our decision was based on a survey of attention-based methods used across various applications and their suitability for our problem setting.	Reply	B-Reply	1
Our mechanism was designed such that, given a set of independent embeddings, each item in the set can be used to both extract a weighted sum of the other items as well as contribute to the weighted sums that other items extract.	Reply	I-Reply	1
When applied to multi-agent value-function approximation, each item can belong to an agent and the separate weighted sums can be used to estimate each agent‚Äôs expected return.	Reply	I-Reply	1
Some other choices of attention mechanisms such as RNN-based ones (widely used in NLP), while interesting, do not naturally extend to our setting as our inputs (ie embeddings from agents) do not form a natural temporal order.	Reply	I-Reply	1
We have updated our draft to provide more insight into our choices.	Reply	I-Reply	1
[line_break_token]We have included a new section 6.3 in the appendix of our revised draft that visualizes the behavior of our attention mechanism, as well as how it evolves over the course of training.	Reply	I-Reply	2
[line_break_token][line_break_token]While our approach does not significantly outperform the best individual baseline in each environment, it consistently performs near the top in all environments --- other methods falter in at least one of the two settings.	Reply	I-Reply	3
Our experiments on Cooperative Treasure Collection demonstrate that the general structure of our attention model (even without considering dynamic attention as in our uniform attention baseline) is able to handle large observation spaces (and relatively larger numbers of agents) better than existing approaches which concatenate observations and actions from all agents together.	Reply	I-Reply	3
Furthermore, our experiments on Rover-Tower demonstrate that the general model structure alone is not sufficient in all tasks, specifically those with separately coupled rewards for groups of agents, and dynamic attention becomes necessary	Reply	I-Reply	3

This paper discusses the hypothesis of the existence of intrinsic tradeoffs between clean accuracy and robust accuracy and corresponding implications.	Review	O	0
Specifically, it is motivated by the tradeoffs between clean accuracy and robust accuracy of adversarially trained network.	Review	O	0
The authors constructed a toy example and proved that any classifier cannot be both accurate and robust at the same time.	Review	O	0
They also showed that regular training cannot make soft-margin SVM robust but adversarial training can.	Review	O	0
At the end of the paper, they show that input gradients of adversarially trained models are more semantically meaningful than regularly trained models.	Review	O	0
[line_break_token][line_break_token]The paper is well written and easy to follow.	Review	O	0
The toy example is novel and provides a concrete example demonstrating robustness-accuracy tradeoff, which was previously speculated.	Review	O	0
Demonstrating adversarially trained models has more semantically meaningful gradient is interesting and provides insights to the field.	Review	O	0
It connects robustness and interpretability nicely.	Review	O	0
[line_break_token][line_break_token]My main concern is on the overclaiming of applicability of the "inherent tradeoff".	Review	B-Review	1
The paper demonstrated that the "inherent tradeoff" could be a reasonable hypothesis for explaining the difficulty of achieving robust models.	Review	I-Review	1
I think the authors should emphasize this in the paper so that it does not mislead the reader to think that it is the reason.	Review	I-Review	1
[line_break_token][line_break_token]On a related note, Theorem 2.2 shows adversarial training can give robust classifier while standard training cannot.	Review	I-Review	2
Then the paper says "adversarial training is necessary to achieve non-trivial adversarial accuracy in this setting".	Review	I-Review	2
The word "necessary" is misleading, here Thm 2.2 showed that adversarial training works, but it doesn't exclude the possibility that robust classifiers can be achieved by other training methods.	Review	I-Review	2
[line_break_token][line_break_token]minor comments[line_break_token]- techinques --> techniques[line_break_token]- more discussion on the visual difference between the gradients from L2 and L_\infty adversarially trained networks[line_break_token]- Figure 5 (c): what does "w Robust Features" mean?	Review	O	0
are these values accuracy after perburtation?	Review	B-Review	3
[line_break_token]	Review	O	0
We thank the reviewer for the kind comments and suggestion.	Reply	O	0
We address concerns raised below:[line_break_token][line_break_token]- We agree with the reviewer that "inherent trade-off" might be perceived incorrectly.	Reply	O	0
We only intended to refer to an inherent tradeoff in *our setting*. While we do argue that this is a reasonable hypothesis for the difficulties we face in practice, we cannot definitively conclude that this is the case.	Reply	B-Reply	1
We have edited the manuscript to reflect this.	Reply	I-Reply	1
[line_break_token][line_break_token]- We agree that alternative methods can be used to obtain robustness in Thm 2.2.	Reply	O	0
We only stated that "adversarial training is necessary" because we wanted to emphasize that simply minimizing the standard loss (ignoring the adversary) will not lead to robustness.	Reply	B-Reply	2
We have edited the manuscript to elaborate on this.	Reply	I-Reply	2
[line_break_token][line_break_token]We thank the reviewer for the other comments.	Reply	O	0
We have edited the manuscript to address them.	Reply	O	0

This manuscript explores the idea of adding noise to the adversary's play in GAN dynamics over an RKHS.	Review	B-Review	1
This is equivalent to adding noise to the gradient update, using the duality of reproducing kernels.	Review	I-Review	1
Unfortunately, the evaluation here is wholly unsatisfactory to justify the manuscript's claims.	Review	I-Review	2
No concrete practical algorithm specification is given (only a couple of ideas to inject noise listed), only a qualitative one on a 2-dimensional latent space in MNIST, and an inconclusive one using the much-doubted Parzen window KDE method.	Review	I-Review	2
The idea as stated in the abstract and introduction may well be worth pursuing, but not on the evidence provided by the rest of the manuscript.	Review	O	0
Thank you for the comments.	Reply	O	0
We hope our further explanations clear any confusion left in the paper.	Reply	O	0
[line_break_token][line_break_token]     -> This manuscript explores the idea of adding noise to the adversary's play in GAN dynamics over an RKHS.	Reply	O	0
This is [line_break_token]     equivalent to adding noise to the gradient update, using the duality of reproducing kernels.	Reply	O	0
[line_break_token][line_break_token]The approach is not equivalent to adding noise to the gradient update.	Reply	B-Reply	1
The introduced stochasticity is the result of the stochastic functions as the adversary‚Äôs strategies.	Reply	I-Reply	1
The introduced approach, however, can be perceived as a mechanism for smoothing the gradients.	Reply	I-Reply	1
This is to mitigate the model collapse issue.	Reply	I-Reply	1
In order to see how DS-AAE can address the mode collapse issue, please consider a case when there is a "hole" in the learned coding space (which would be expected in the course of training - The learned coding space is also visualized in Fig.2a and Fig.	Reply	I-Reply	1
2c after training).	Reply	I-Reply	1
 In such cases, the adversary cannot discriminate against the boundaries around the "hole" properly.	Reply	I-Reply	1
 This is because of the bumpy gradients terms.	Reply	I-Reply	1
This leads to mode collapse issue, discussed at the introduction and is indeed the main motivation for proposing DS-AAE.	Reply	I-Reply	1
The bumpy gradient terms can be avoided using DS-AAE architecture.	Reply	I-Reply	1
This is mathematically explained at the bottom of page 3, right before Theorem 1.	Reply	I-Reply	1
[line_break_token] [line_break_token]    -> No concrete practical algorithm specification is given (only a couple of ideas to inject noise listed), only a qualitative [line_break_token]    one on a 2-dimensional latent space in MNIST, and an inconclusive one using the much-doubted Parzen window KDE [line_break_token]    method.	Reply	O	0
T[line_break_token][line_break_token]Dimensionality of the hidden codes are 6 and 4 for the Fig.2b  and Fig.	Reply	O	0
2d, respectively.	Reply	B-Reply	2
Only figures 2.a and 2.c are on 2-dimensional latent space (for visualization purposes).	Reply	I-Reply	2
More importantly, Fig.	Reply	I-Reply	2
2a shows that the introduced stochastically helps the encoder to recover a mixture of 2D-Gaussians despite having a 2D-Gaussian distribution as prior.	Reply	I-Reply	2
[line_break_token]	Reply	O	0

This paper proposes an improved approach to the "complementary-label" form of weak supervision, in which a label that is *not* the true label is marked.	Review	O	0
Specifically, this paper proposes an unbiased estimator that accepts arbitrary loss functions and models.	Review	O	0
Noting that this proposed estimator can suffer from overfitting due to unbounded negative loss, a lower-bounded estimator is proposed.	Review	O	0
Experiments are then performed on several image classification datasets.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- This paper addresses a creative form of weak supervision, proposed by prior work, in which labels that are *not* the true label are labeled, in a clear fashion.	Review	O	0
[line_break_token][line_break_token]- The first proposed estimator is unbiased, as shown by a proof, and accepts arbitrary losses, an improvement over prior approaches[line_break_token][line_break_token]- The overall presentation is clear and clean[line_break_token][line_break_token]Cons:[line_break_token]- One of the main claims of the paper is the proposal of an unbiased estimator.	Review	O	0
However, this estimator then does not seem to work well enough due to degenerate negative loss.	Review	B-Review	1
 So then a modified version is proposed- which does not appear to be unbiased?	Review	I-Review	1
 Either way, no assertion or proof of it being unbiased is given.	Review	I-Review	1
 So then presumably this also reverses the claim of being able to cross-validate?	Review	I-Review	1
 This seems like a major weakening of the paper's contributions[line_break_token][line_break_token]- Since the unbiased estimator does not appear to work well, two implementations of a corrected one are proposed, using heuristic approaches without explicit theoretical guarantees.	Review	O	0
 This shifts the burden to the experimental studies.	Review	B-Review	2
 These are somewhat thorough, but not extremely so: for example, one set of hyperparameters were used for all of the methods?	Review	I-Review	2
 This seems like it could implicitly handicap / favor some over others?	Review	I-Review	2
[line_break_token][line_break_token]- The proposed estimator is based on the assumption that the probability of classes in the complement set (the set of labels other than the one marked as incorrect) is uniformly distributed (e.g. see beginning of Proof of thm 1).	Review	O	0
 However, this seems like a potentially naive assumption.	Review	B-Review	3
Indeed, in the related work section, it is mentioned that work in 2018 already considered the case where this uniformity assumption does not hold.	Review	I-Review	3
[line_break_token][line_break_token]- More broadly, but following from the above: The paper does not provide any real world examples, real or hypothetical, to give the reader an idea of whether the above uniformity assumption---or really any of these assumptions---are well-motivated or empirically justified.	Review	O	0
 At the bottom of page 3 in the related work, a concrete application used in prior work is mentioned---where crowd workers are shown single labels and vote Y/N, leading to a mix of standard (if Y) and complement-labeled (if N) data---however this mixed setting is not considered explicitly in this paper.	Review	B-Review	4
 So, how is the reader supposed to get any idea of whether the assumed setup is motivated or justified?	Review	I-Review	4
 The experiments do not provide this, because the complementary labels are synthetically generated according to the model assumed in the paper.	Review	I-Review	4
 Additionally, it is briefly mentioned that collecting complementary labeled data is faster, but again no concrete examples are given to support this.	Review	I-Review	4
Thank you very much for the review and for the important questions!	Reply	O	0
[line_break_token][line_break_token]Q) Modified version appears to be biased, and does this reverse the claim of being able to cross-validate?	Reply	O	0
[line_break_token]A) We apologize for the lack of clarity in the paper, but even if our learning objective uses a modified version that can potentially be a biased estimator, we can still use an unbiased version for our cross-validating objective.	Reply	O	0
 We would like to demostrate a very simple example (with a single validation split).	Reply	B-Reply	1
 We report the classification accuracy with Fashion-MNIST with just one trial: Free(proposed):59.06% / gradient-ascent(proposed):79.58% / forward[Xiyu'18]:46.72% / pairwise-comparison[Ishida'17]:76.03%.	Reply	I-Reply	1
 9 hyper-parameter candidate combinations of weight decay (1e-4, 1e-5, 1e-6) and learning rate (1e-4, 1e-5, 1e-6) were used with 150 epochs.	Reply	I-Reply	1
 SGD with momentum 0.9 was used for optimization.	Reply	I-Reply	1
 We reported the test accuracy of the best model based on validation score (calculated from only complementarily-labeled data) from all epochs and all hyper-parameter combinations.	Reply	I-Reply	1
 For forward method [Xiyu'18], we simply used their proposed learning objective for validation criteria.	Reply	I-Reply	1
 The model was multi-layer perceptron with d-50-1 (In Figure 2, d-500-1 was used).	Reply	I-Reply	1
 Due to the time constraint, we were able to only finish a very simple setup with a single trial, with very few hyper-parameters and few candidates for each of them, so our main message here is not the result itself (for example ‚Äúforward‚Äù is too weak and we can guess optimal hyper-parameters were not included), but to show that validation is possible with our unbiased estimator.	Reply	I-Reply	1
 We would like to report results for extensive experiments in the final version.	Reply	I-Reply	1
[line_break_token][line_break_token]Q) The hyper-parameters are fixed.	Reply	O	0
 Will this implicitly handicap / favor some over others?	Reply	O	0
[line_break_token]A) Our motivation of the experiments was to demonstrate the failure of the proposed method based on Theorem 1, and how the two modifications solve the overfitting issues and show test results of all epochs during training.	Reply	O	0
 However, as you point out, this is not a good demonstration of comparing with the best hyper-parameter for each method, so we showed some simple experimental results that tune hyper-parameters with (complementary labeled) validation data in the answer to your previous question.	Reply	B-Reply	2
 We will add more experiments to demonstrate this.	Reply	I-Reply	2
[line_break_token][line_break_token]Q) Uniform assumption is na√Øve.	Reply	O	0
[line_break_token]A) A potentially biased (but consistent) method has already been proposed for a non-uniform assumption [22], but one of our future work is to explore if proposing a non-uniform version of the unbiased estimator is possible or not.	Reply	O	0
[line_break_token][line_break_token]Q) The only justification of the uniform assumption is the mixed setting of crowdsourcing, but there is no mixed setting in experiments.	Reply	O	0
[line_break_token]A) We would like to demonstrate with more experiments using the mixed setting with both ordinary and complementary labels	Reply	O	0

SUMMARY: Unsupervised/Self-supervised generative model for image synthesis using 3D depth and RGB consistency across camera views[line_break_token][line_break_token]CLAIMS:[line_break_token]- New technique for RGBD synthesis using loss in 3D space[line_break_token]- Can disentangle camera parameters from content (I disagree slightly with "disentangle" since you are conditioning on camera parameters in the first place)[line_break_token]- Different generator architectures can be used[line_break_token][line_break_token]METHOD:[line_break_token]Generate RGBD images of 2 different views, have an adversarial loss on the RGB image, have a content loss between RGB1 and warp(RGB2), have a depth loss between D1 and warp(D2)[line_break_token]Equation 5:[line_break_token]- Possibly either "c_{1-&gt;2}" needs to be replaced by "c_{2-&gt;1}", or "G_{RGB}(z, c_1) - warp(G_{RGB}(z, c_2), c_{1-&gt;2})" needs to be replaced by "warp(G_{RGB}(z, c_1), c_{1-&gt;2}) - G_{RGB}(z, c_2)" (or am I missing something?)	Review	O	0
[line_break_token]- Not entirely sure why there is a different "projection" operation, since both "warp" and "projection" are calculated from Equation 3.	Review	O	0
I understand that "warp" is the combined Rt matrix that is estimated using the two views and Equation 3, assuming that the "d"s are correct.	Review	B-Review	2
Not sure what "projection" does though, possibly explain it better?	Review	I-Review	2
[line_break_token][line_break_token]DECISION: Very clearly written paper, simple idea executed well[line_break_token][line_break_token]The paper is clearly written and well organized.	Review	O	0
It uses a simple idea, and performs sufficient number of experiments to explore the idea.	Review	O	0
It is not very novel, but the paper shows its applicability with multiple architectures as a bonus.	Review	O	0
[line_break_token][line_break_token]The figures showed results almost only from their method.	Review	B-Review	3
It would be great to pick one generator architecture, and elucidate more on the differences between not using their 3D loss and using it.	Review	I-Review	3
Good attempt though.	Review	I-Review	3
[line_break_token][line_break_token]ADDITIONAL FEEDBACK:[line_break_token]- Might not be "representation learning", instead it is learning a generative model.	Review	O	0
[line_break_token]- "3 EXPERIMETNS" -&gt; "3 EXPERIMENTS"[line_break_token]- The appendix should have more details on the equations and the specific formulations of warp  and projection operations	Review	O	0
e would like to thank the reviewer for valuable comments. ‚	Reply	O	0
Ä®[line_break_token][line_break_token]Equation 5:[line_break_token]- Figure 3 in [1] shows the detailed illustration of the "warp" operation.	Reply	O	0
First, we calculate the position of pixels in G_{RGB}(z, c_1) when they are viewed from c_2 (c_{1-&gt;2} is used here), and warp G_{RGB}(z, c_2) according to the calculated positions with bilinear interpolation.	Reply	O	0
Therefore, the relative transformation matrix we need is c_{1-&gt;2}. We will add more explanation in the paper.	Reply	O	0
[line_break_token]- Since the depth values in warp(G_{D}(z, c_2), c_{1-&gt;2}) are sampled from the depth values viewed from c_2, to compare G_{D}(z, c_1) with warp(G_{D}(z, c_2), c_{1-&gt;2}), we need to project the depth values of each pixel in G_{D}(z, c_1) to the viewpoint c_2.	Reply	O	0
This is what we call "projection".	Reply	B-Reply	2
We will add the explanation in the paper.	Reply	O	0
[line_break_token][line_break_token]Differences between not using 3D loss and using it[line_break_token]- I will pick one generator and compare the generative results qualitatively in the paper.	Reply	O	0
Because PGGAN and StyleGAN without 3D loss cannot control camera poses, we can only compare the random generation results.	Reply	B-Reply	3
Comparisons on the 3D-latent-feature-based methods are already provided in Figure 4, 5 and Table 1, but we will add more results in the appendix.	Reply	I-Reply	3
[line_break_token][line_break_token]Representation learning[line_break_token]- Learning generative models is often called "representation learning" because it can learn latent representations of the images [2, 3, 4, ...].	Reply	O	0
We will add a discussion about this in the paper.	Reply	B-Reply	4
[line_break_token]‚Ä®[line_break_token][1] Tinghui Zhou, Matthew Brown, Noah Snavely, and David G Lowe.	Reply	O	0
Unsupervised learning of depth and ego-motion from video.	Reply	O	0
In CVPR, 2017.&nbsp;[line_break_token][2] Alec Radford, Luke Metz, and Soumith Chintala.	Reply	O	0
Unsupervised representation learning with deep convolutional generative adversarial networks.	Reply	O	0
In ICLR, 2016.&nbsp;[line_break_token][3] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel.	Reply	O	0
Infogan: Interpretable representation learning by information maximizing generative adversarial nets.	Reply	O	0
In NIPS, 2016.	Reply	O	0
[line_break_token][4] Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, and Yong-Liang Yang.	Reply	O	0
Hologan: Unsupervised learning of 3d representations from natural images.	Reply	O	0
2019.	Reply	O	0

The paper proposes a new approach to explain the effective behavior of SGD in training deep neural networks by introducing the notion of star-convexity.	Review	O	0
A function h is star-convex if its global minimum lies on or above any plane tangent to the function, namely h* >= h(x) + < h'(x), x*-x> for any x. Under such condition, the paper shows that the empirical loss goes to zero and the iterates generated by SGD converges to a global minimum.	Review	O	0
Extensive experiments has been conducted to empirically validate the assumption.	Review	O	0
[line_break_token][line_break_token]The paper is very well organized and is easy to follow.	Review	O	0
The star-convexity assumption is very interesting which provides new insights about the landscape of the loss function and the trajectory of SGD.	Review	B-Review	3
It is in general difficult to theoretically check this condition so several empirical verifications has been proposed.	Review	I-Review	3
My main concern is about these empirical verifications.	Review	I-Review	3
[line_break_token][line_break_token]1) The minimum of the cross entropy loss lies at infinity [line_break_token]The experiments are performed respect to the cross entropy loss.	Review	O	0
However, cross entropy loss violates Fact 1 since for any finite weight, cross entropy loss is always strictly positive.	Review	B-Review	1
Thus the zero is never attained and the global minimum always lies at infinity.	Review	I-Review	1
As a result, the star-convexity inequality h* >= h(x) + < h'(x), x*-x> hardly makes sense since x* is at infinity and neither does the theorem followed.	Review	O	0
[line_break_token]In this case, a plot of the norm of xk is highly suggested since it is a sanity check to see whether the iterates goes to infinity.	Review	B-Review	1
[line_break_token][line_break_token]2) The phenomenon may depend on the reference point, i.e last iterate[line_break_token]Since the minimum is never attained, the empirical check of the star-convexity maybe biased.	Review	O	0
More precisely, it might be possible that the behavior of the observed phenomenon depends on the reference point, i.e. the last iterate.	Review	B-Review	2
Therefore, it will be interesting to see if the observed phenomenon still holds when varying the stopping time, for instance plot the star convexity check using the iterates at 60, 80, 100, 120 epochs as reference point.	Review	I-Review	2
[line_break_token][line_break_token]In fact, the experiments shown in Figure 4 implicitly supports that the behavior may change dramatically respect to different reference point.	Review	O	0
The reason is that the loss in these experiments are far away from 0, meaning that we are far from the minimum, thus checking the star-convexity does not make sense because the star-convexity is only defined respect to the minimum.	Review	O	0
[line_break_token][line_break_token]Overall, the paper provides interesting idea but the empirical results may be biased due to ill-posed problem	Review	O	0
We thank the reviewer for the valuable feedbacks.	Reply	O	0
[line_break_token][line_break_token]This paper aims at reporting an interesting star-convex property of the SGD optimization path that has been observed in training a variety of DL models, including MLP, CNN, residual networks and RNN (verified recently).	Reply	B-Reply	3
Moreover, our theory is motivated by such a common observation and attempts to justify the role of this property plays in determining the convergence of the optimization in DL.	Reply	I-Reply	3
[line_break_token][line_break_token]Our response to the reviewer‚Äôs comments are provided as follows.	Reply	O	0
[line_break_token][line_break_token]1) The minimum of the cross entropy loss lies at infinity.	Reply	O	0
It is a sanity to check whether the iterates goes to infinity.	Reply	O	0
[line_break_token][line_break_token] Response: We thank the reviewer for pointing out this, and we are aware of it.	Reply	O	0
We choose to present the results on cross entropy as it is widely used in DL applications.	Reply	B-Reply	1
In fact, we verified the star-convexity property for training other losses that by nature can achieve zero such as the MSE loss (please see the experiment results that we added in Fig.7 in Appendix D in supplementary).	Reply	I-Reply	1
[line_break_token]Under the cross-entropy loss, we found that after the training loss is very close to zero, the l_2 norm of the corresponding iterate grows only logarithmically.	Reply	I-Reply	1
This can be clearly seen from the experiments that we added in Fig.6 in Appendix D of supplementary.	Reply	I-Reply	1
We further note that such a phenomenon has also been observed and justified in Fig.2 of [1]).	Reply	I-Reply	1
 Thus, empirically, it is reasonable to treat the loss value to be approximately zero (i.e., reaches minimum) with a bounded weight norm.	Reply	I-Reply	1
[line_break_token][1] ``The Implicit Bias of Gradient Descent on Separable Data‚Äô‚Äô, Soundry et al 2018[line_break_token][line_break_token]2) The phenomenon may depend on the reference point, i.e., last iterate[line_break_token]Since the minimum is never attained, the empirical check of the star-convexity maybe biased.	Reply	O	0
More precisely, it might be possible that the behavior of the observed phenomenon depends on the reference point, i.e. the last iterate.	Reply	O	0
Therefore, it will be interesting to see if the observed phenomenon still holds when varying the stopping time, for instance plot the star convexity check using the iterates at 60, 80, 100, 120 epochs as reference point.	Reply	O	0
[line_break_token]In fact, the experiments shown in Figure 4 implicitly supports that the behavior may change dramatically respect to different reference point.	Reply	O	0
The reason is that the loss in these experiments are far away from 0, meaning that we are far from the minimum, thus checking the star-convexity does not make sense because the star-convexity is only defined respect to the minimum.	Reply	O	0
[line_break_token][line_break_token]Response: As can be seen in the experiments that we added in Fig.5 in Appendix D of the supplementary materials, we have checked the star-convex property by taking the reference point at different intermediate iterates (60, 80, 100, 120) as the reviewer suggested.	Reply	O	0
We found that star-convexity still holds under these choices of reference points, and therefore such a property does not depend on the choice of reference point so long as their loss are (nearly) zero.	Reply	B-Reply	2
This observation is common for over-parameterized networks which can achieve near zero loss and therefore can have common global minimum.	Reply	I-Reply	2
[line_break_token]We emphasize that the reference point in our star-convexity must be the minimizer that achieves zero loss.	Reply	I-Reply	2
Hence, in experiments, we must set the reference point at the epochs where the corresponding loss is nearly zero.	Reply	I-Reply	2
The points at intermediate iterates with a high loss value cannot be chosen as reference point of star-convexity, because these points cannot be treated as the common global minimizer.. [line_break_token]Regarding the experiments in Figure 4, they are conducted on under-parameterized networks where (approximate) zero loss cannot be achieved, and the algorithm in fact does not find a common global minimum.	Reply	I-Reply	2
This experiment is to justify the role of the over-parameterization (or the common global minimum) plays in determining the star-convex optimization path.	Reply	I-Reply	2

Summary[line_break_token][line_break_token]This applications paper proposes using a deep neural architecture to do unsupervised anomaly detection by learning the parameters of a GMM end-to-end with reconstruction in a low-dimensional latent space.	Review	O	0
The algorithm employs a tailored loss function that involves reconstruction error on the latent space, penalties on degenerate parameters of the GMM, and an energy term to model the probability of observing the input samples.	Review	O	0
[line_break_token][line_break_token]The algorithm replaces the membership probabilities found in the E-step of EM for a GMM with the outputs of a subnetwork in the end-to-end architecture.	Review	O	0
The GMM parameters are updated with these estimated responsibilities as usual in the M-step during training.	Review	O	0
[line_break_token][line_break_token]The paper demonstrates improvements in a number of public datasets.	Review	O	0
Careful reporting of the tuning and hyperparameter choices renders these experiments repeatable, and hence a suitable improvement in the field.	Review	O	0
Well-designed ablation studies demonstrate the importance of the architectural choices made, which are generally well-motivated in intuitions about the nature of anomaly detection.	Review	O	0
[line_break_token][line_break_token]Criticisms[line_break_token][line_break_token]Based on the performance of GMM-EN, the reconstruction error features are crucial to the success of this method.	Review	O	0
Little to no detail about these features is included.	Review	B-Review	1
Intuitively, the estimation network is given the latent code conditioned and some (probably highly redundant) information about the residual structure remaining to be modeled.	Review	I-Review	1
[line_break_token][line_break_token]Since this is so important to the results, more analysis would be helpful.	Review	I-Review	2
Why did the choices that were made in the paper yield this success?	Review	I-Review	2
How do you recommend other researchers or practitioners selected from the large possible space of reconstruction features to get the best results?	Review	I-Review	2
[line_break_token][line_break_token]Quality[line_break_token][line_break_token]This paper does not set out to produce a novel network architecture.	Review	O	0
Perhaps the biggest innovation is the use of reconstruction error features as input to a subnetwork that predicts the E-step output in EM for a GMM.	Review	O	0
This is interesting and novel enough in my opinion to warrant publication at ICLR, along with the strong performance and careful reporting of experimental design.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
Thanks for your valuable comments to our paper.	Reply	O	0
[line_break_token][line_break_token]For the reconstruction features used in the experiment, we report their details in the first paragraph of Section 4.3.	Reply	B-Reply	1
In the revised paper, we added Appendix D to discuss why reconstruction features are important to anomaly detection and the principles that guide us to find candidate reconstruction features.	Reply	I-Reply	1
[line_break_token][line_break_token]For the question of how to find the set of reconstruction features that deliver the best results, it is important, but non-trivial.	Reply	I-Reply	2
In our study, we discovered the two reconstruction features used in the experiment through a manual data exploration process.	Reply	I-Reply	2
The principles in Appendix D are important guidelines for choosing candidate reconstruction metrics	Reply	I-Reply	2

This paper studies the so called problem of derivative-free optimization, which is relevant for cases when the evaluation function is continuous but access to gradients is not possible.	Review	O	0
The paper improves on top of the stochastic three points method (STP), an existing work (published in arXiv), by proposing adding momentum (SMTP).	Review	O	0
The intuition behind both STP and SMTP is rather straighforward: you sample a random direction s, then given your current position x you check x+as and x-as.	Review	O	0
You then move to the best position from (x, x+as, x_as).	Review	O	0
In a way, this is like computing the numerical derivatives (instead of the gradient) given a random location and its mirror, and then applying gradient descent given the best numerical derivative.	Review	O	0
However, take this analogy with a large grain of salt, as there are many differences with GD.	Review	O	0
The proposed algorithm adds momentum and importance sampling.	Review	O	0
Momentum helps speed up convergence, as the paper shows for non-convex, convex and strongly convex functions.	Review	O	0
All three cases are individually examined and bounds are derived regarding the speed of convergence.	Review	O	0
For the non-convex case the speed of convergence is 1/\sqrt{K}, K being the number of iterations.	Review	O	0
For the convex case it is 1/K. For the strongly convex case the (unrealistic) assumption of knowing the optimal value is removed while maintaining the same speed of convergence.	Review	O	0
 Importance sampling helps computing the derivatives focusing on those coordinate dimensions that are more critical to the objective function f(x), improving the speed of convergence further.	Review	O	0
The importance sampling is proportional to the coordinate-wise Lipschitz constants, assuming that the objective function is coordinate-wise Lipschitz smooth.	Review	O	0
The methods are validated on five different cases of MuJoCo.	Review	O	0
Results seem good when compared to the STP ones.	Review	O	0
Compared to policy gradient methods, the results seem much better.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]+ The paper presents a small but interesting and well-motivated addition to the original algorithm STP.	Review	O	0
I particularly liked how straightforward the final algorithm is: applying momentum and sampling according to the Lipschitz constants.	Review	O	0
[line_break_token][line_break_token]+ At least at a first glance the results look good.	Review	O	0
Compared to STP in figure 1 there is a clear improvement not only in the final optimum but also in the speed of attaining the said optimum.	Review	O	0
[line_break_token][line_break_token]+ I liked a lot the presentation and clarity of writing.	Review	O	0
While quite mathematically dense, it was easy to follow the big story and understand that underlying points.	Review	O	0
[line_break_token][line_break_token]Weaknesses:[line_break_token]+ While interesting and useful, I am not completely convinced whether the added novelty over (Bergou et al, 2019) is significant enough.	Review	O	0
At the end of the day, the final algorithm is the conglomeration of two existing algorithms, that is STP and momentum.	Review	B-Review	1
STP is very similar to the final algorithm, after all it is the basis for it.	Review	I-Review	1
The authors argue that it is not trivial to select the next points under the momentum term.	Review	I-Review	1
To this end, they propose to rely on yet another existing approach, that is the virtual iterates analysis from (Yang et al.	Review	I-Review	1
2016).	Review	I-Review	1
However, it is not clear why these points are "optimal", what is so "non-trivial" about selecting them?	Review	I-Review	1
This is basically skimmed over in two lines.	Review	I-Review	1
[line_break_token][line_break_token]+ In the strongly convex case one assumption (knowing the f(x*) ) is replaced with another assumption, that all points lie on a hypersphere (|s|_2=1).	Review	O	0
I suppose this would assume a spherical normalization of the input space.	Review	B-Review	2
While this is not an unrealistic assumption, it does place a constraint which could be problematic in the case of high dimensions for s?	Review	I-Review	2
In that case the high dimensionality would render distances rather unreliable and in turn could hurt convergence?	Review	I-Review	2
This is also perhaps the reason that only the MuJoCo enviroments were tested?	Review	I-Review	2
In general, I would say that the strongly convex case was discussed less clearly and it is not exactly clear the final result.	Review	I-Review	2
In the end, eq (25) does contain f(x*), whereas in the convex case K does not (K \approx 2 R_0^2 L Œ≥_D/(ŒµŒº_D^2).	Review	I-Review	2
[line_break_token][line_break_token]+ Some statements are unclear.	Review	O	0
[line_break_token]  ++ In p. 2 some symbols are not explained, e.g., Œµ. While it is quite clear for peopled versed in the field, in my opinion it is bad practice to leave notation not explained.	Review	O	0
[line_break_token]  ++ In assumption 3.1 seems rather trivial?	Review	O	0
Wouldn't Œ≥_D by definition be always positive, since is the expectation of a squared norm (always positive)?	Review	B-Review	4
Does this need to be an assumption?	Review	I-Review	4
[line_break_token]  ++ Between eq. (	Review	O	0
11) and (12) there is reference to (35)?	Review	B-Review	5
What is (35)?	Review	I-Review	5
[line_break_token]  ++ It is not clear in practice how the importance sampling is performed.	Review	O	0
In Algorithm 2 the probabilities p_i are defined as function inputs and then never updated.	Review	B-Review	6
Is that true?	Review	I-Review	6
If yes, how is p_i decided in the first place?	Review	I-Review	6
What is the connection to the Lipschitz constants L_i?	Review	I-Review	6
[line_break_token][line_break_token]+ A highly relevant field appears to be Bayesian Optimization, where also one cannot compute gradients and must optimize a black-box function.	Review	O	0
Some relevant recent works are [1] and [2] for continuous and discrete inputs.	Review	B-Review	7
It would be interesting to discuss what are the distinct differences with bayesian optimization methods in [1] and [2].[line_break_token][line_break_token]+ I would say that the paper is rather on the light side regarding experiments.	Review	O	0
Only MuJoCo is used as an experimental setup.	Review	B-Review	8
It would be nice to also report results on synthetic experiments with known functions to better understand the limitations of the algorithm.	Review	I-Review	8
Synthetic and realistic setups can be found in [1] and [2].[line_break_token][line_break_token]What is more, the experimental choices are not entirely clear.	Review	O	0
What is the "predefined reward threshold" and why was that chosen?	Review	B-Review	9
For instance, the leaderboard for "Swimmer" is in: <a href="https://www.endtoend.ai/envs/gym/mujoco/swimmer/." target="_blank" rel="nofollow">https://www.endtoend.ai/envs/gym/mujoco/swimmer/.</a> How does the proposed algorithm fair compared to these works?	Review	O	0
Also, *maybe* it would be interesting to compare even against [1] or [2] (I guess [2] is harder as it is for discete inputs), assuming that a relatively low number of iterations is performed.	Review	B-Review	9
[line_break_token][line_break_token][1] BOCK: Bayesian Optimization with Cylindrical Kernels, C. Oh, E. Gavves, M. Welling, ICML 2018[line_break_token][2] BOCS: Bayesian Optimization of Combinatorial Structures, R. Baptista, M. Poloczek, ICML 2018[line_break_token]	Review	O	0
e thank R2 for their constructive thorough detailed review.	Reply	O	0
Follows our response.	Reply	O	0
All edits are marked in blue in the revised version.	Reply	O	0
[line_break_token][line_break_token] "While interesting and useful, I am not completely convinced whether the added novelty over (Bergou et al, 2019) is significant enough.	Reply	O	0
At the end of the day, the final algorithm is the conglomeration of two existing algorithms, that is STP and momentum.	Reply	O	0
STP is very similar to the ..."[line_break_token][line_break_token][line_break_token]Note that we claim nothing about optimality of our approach in the paper.	Reply	O	0
However, we agree that investigating different approach beyond stochastic three points is an interesting direction of future work.	Reply	B-Reply	1
By non-triviality of our approach we mean that is not a straightforward-like modification of Polyak's method: instead of classical form of the Heavy ball method we use equivalent form from (Yang et al.	Reply	I-Reply	1
2016) and choose next iterate not as argminimum of, but use virtual iterates instead.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token] "In the strongly convex case one assumption (knowing the ) is replaced with another assumption, that all points lie on a hypersphere ).	Reply	O	0
I suppose this would assume a spherical normalization of the input space.	Reply	O	0
While this is not an unrealistic assumption, it does ..."[line_break_token][line_break_token][line_break_token][line_break_token]We do not think that Assumption~3.4 from our paper is unrealistic or restrictive.	Reply	O	0
Indeed, in the case of high-dimensions it can cause additional problems connected with normalization.	Reply	B-Reply	2
However, in the high-dimensional case the method itself works slow which is the common ``disease of DFO methods and additional normalization for this case does not change the situation dramatically.	Reply	I-Reply	2
According your comment about our analysis in the strongly convex case itself -- yes, due to space limitations we do not introduce some classical fact about-strongly convex and-smooth problems.	Reply	I-Reply	2
For example, classical relations and are the answer for your question: in this case and are equivalent up to some constants and it does not play a big role since appears in (25) under the logarithm.	Reply	I-Reply	2
[line_break_token][line_break_token] Defining[line_break_token][line_break_token]We added a definition for the first time it is introduced (Theorem 3.2).	Reply	O	0
[line_break_token] Assumption 3.1[line_break_token][line_break_token]We have restated Assumption 3.1 to address R2's comments.	Reply	B-Reply	4
[line_break_token] "Between eq. (	Reply	O	0
11) and (12) there is reference to (35)?	Reply	O	0
What is (35)?"	Reply	O	0
[line_break_token][line_break_token]Equation (35) is identical to Eq (11) but was rederived in the supplementary material.	Reply	B-Reply	5
We have corrected the reference to Equation (11).	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token] "It is not clear in practice how the importance sampling is performed.	Reply	O	0
In Algorithm 2 the probabilities are defined as function inputs and ..."[line_break_token][line_break_token]That is correct.	Reply	O	0
The probabilities are computed once before the algorithm and never updated and they are a function of.	Reply	B-Reply	6
Table 1 summarizes the choice of.	Reply	I-Reply	6
Note that in the supplementary material, we derive the rates for nonconvex (Theorem E.1), convex (Theorems E.2 and E.3) and strongly convex (Theorems E.4 and E.5) problems as a function of arbitrary sampling probabilities.	Reply	I-Reply	6
We propose the importance sampling strategy (proportional to) as depicted in Table 1, to show that this strategy enjoys better worst complexity rate than uniform sampling.	Reply	I-Reply	6
For non-convex problems of the MuJoCo experiments,s are not known apriori for the reward function.	Reply	I-Reply	6
Thus we follow, section E of Bibi et.	Reply	I-Reply	6
al.	Reply	I-Reply	1
and approximate the objective function with a smooth parametric family of neural networks where we can estimate the smoothness constants.	Reply	I-Reply	6
[line_break_token][line_break_token][line_break_token] "A highly relevant field appears to be Bayesian Optimization, where also one cannot compute gradients and must optimize a black-box function.	Reply	O	0
Some relevant recent ... "[line_break_token][line_break_token][line_break_token][line_break_token]To the best of our knowledge, Bayesian optimization is about global optimization of black box functions where there are no necessary assumptions regarding smoothness.	Reply	O	0
The flavor of our work is slightly different where we have convergence rate while we are not aware of any for Bayesian optimization.	Reply	B-Reply	7
[line_break_token][line_break_token]The most related methods to us from the literature are STP and the methods mentioned in the STP paper (deterministic direct search, random gradient free method, direct search based on random directions).	Reply	I-Reply	7
We had a comparison of STP with them on the STP paper.	Reply	I-Reply	7
STP was outperforming all compared methods and since is outperforming STP, this demonstrates the superiority of our proposed algorithm compared to all methods of the same class	Reply	I-Reply	7

This paper combines ideas from attentive and sequential neural processes to incorporate an attention mechanism to the existing sequential neural process, which results in an attentive sequential neural processes framework.	Review	O	0
[line_break_token][line_break_token]While the idea is somewhat interesting, I think this paper is technically vague and not well-motivated, which makes it hard for me to feel convinced that the problem exists and is non-trivial, and that the proposed solution is significant.	Review	B-Review	1
Let me elaborate on my thoughts below:[line_break_token][line_break_token]First, the authors stated that SNP is subject to the underfitting problem that plagues NP but it is not clear to me why, in the temporal context of SNP, do we need to focus our attention on past contexts, which are no longer relevant.	Review	O	0
Could the authors please motivate this with a concrete application scenario?	Review	B-Review	2
Without a concrete scenario, I do not feel very convinced that the problem exists.	Review	I-Review	2
[line_break_token][line_break_token]Second, the argument that augmenting SNP with an attention mechanism is not trivial is somewhat contrived.	Review	I-Review	3
In particular, the reason for this non-triviality is that (in the authors' own words) SNP assumes that it cannot store the past context as is -- so what if we simply store the past context &amp; condition the representation on the entire history of past context instead?	Review	O	0
[line_break_token][line_break_token]Apparently, this can come across trivially by replacing C_t with both C_&lt;t and C_t in Eq. (	Review	O	0
2).	Review	B-Review	3
This is in fact very similar to what the authors did in Eq. (	Review	I-Review	3
4) which summarizes the generative process of ASNP -- the only difference is the generation of imaginary contexts, whose necessity is again questionable, as I elaborate next.	Review	I-Review	3
[line_break_token][line_break_token]Third, the motivation for imaginary context is pulled from a very distant literature on how a human brain memorizes past experiences in a lossy memory consolidation, which only retains the most important sketches.	Review	I-Review	4
In the context of ASNP, it is not, however, clear to me why this mechanism is necessary given that entire lossless memory can be stored except that without a lot of contexts, there is not a need for an attention component (as implied in first paragraph of Section 3) which is a contrived motivation.	Review	I-Review	4
[line_break_token][line_break_token]Fourth, the technical exposition of this paper is too vague.	Review	I-Review	5
Given that the key contribution here is about an attention component, the background review on ANP is surprisingly informal with no technical detail at all.	Review	I-Review	5
For the other parts, the technical part is also mostly abstracted away -- what is presented is therefore not that much different from a typical generative model with latent variables, which makes it unclear whether there is a technical challenge here.	Review	I-Review	5
[line_break_token][line_break_token]In fact, from what I see, going from Eq. (	Review	I-Review	6
2) to Eq. (	Review	I-Review	6
4) is not much of a conceptual challenge and the execution of Eq. (	Review	I-Review	6
4) (particularly the attention component described in Section 3.2) seems like a bunch of arbitrary engineering ideas which were put together to substantiate Eq. (	Review	I-Review	6
4).	Review	I-Review	6
[line_break_token][line_break_token]Is there a technical challenge in the entire pipeline that should have been highlighted?	Review	I-Review	7
[line_break_token][line_break_token]For the experiment, could the author compare the performance between ASNP and ASNP without the imaginery component (but with the attention mechanism)?	Review	I-Review	8
It would be a good experiment to see if the imaginery component is necessary.	Review	I-Review	8
[line_break_token][line_break_token]To summarize, I believe the paper in its current state is not well-motivated and appears very incremental given the prior works of SNP and ANP.	Review	O	0
Even its imaginery component, which is the key contribution here,  is, if I understand Eq. (	Review	B-Review	9
3) correctly, not much different from context sampling of a NP.	Review	I-Review	9
[line_break_token]	Review	O	0
hank you for the detailed review.	Reply	O	0
With these points, we have revised our paper in numerous ways.	Reply	O	0
We address the raised questions in the following points.	Reply	O	0
[line_break_token][line_break_token]Why attend past contexts:   SNP and ASNP are meta-transfer learning frameworks that require fewer observations from the current contexts because they also simultaneously use the information learned in the past.	Reply	O	0
Although the contexts of the past come from a different stochastic process, they are still related to the current stochastic process through the underlying transition dynamics.	Reply	B-Reply	2
For instance, consider an agent playing soccer.	Reply	I-Reply	2
Its sight is focussed on the ball in the front gathering only a limited observation in the current moment.	Reply	I-Reply	2
But using the past knowledge, the player still maintains a dynamic representation of the entire field and especially of the important information (like the locations of the key players) which is useful for making predictions/actions.	Reply	I-Reply	2
In the additional experiment (see the response to the next question) where we allow SNP to only attend its own time-step (i.e. K=1) and then increase the K to allow it to attend the past, its performance, not surprisingly, improves with increasing K (although still underperforming against ASNP).	Reply	I-Reply	2
So attending to the past contexts is useful.	Reply	I-Reply	2
[line_break_token][line_break_token]Why not attend on the entire history of contexts:  We hypothesize and also empirically show that it is a better design choice to have a sequentially updated memory than a simple memory buffer that stores all the observed context points.	Reply	O	0
A sequentially updated memory has the benefit that the model learns to optimize the memory contents for its usefulness in predictions.	Reply	B-Reply	3
Another benefit is that it requires fewer storage locations as it does not naively store each and every incoming context point.	Reply	I-Reply	3
As mentioned, we compared the proposed ASNP against SNP endowed with attention on lossless memory of all context points gathered in the most recent K time-steps.	Reply	I-Reply	3
Although the performance of the latter improves with increasing K = 1 -&gt; 3 -&gt; 5 -&gt; infinity, it quickly saturates at infinity while still under-performing the proposed ASNP clearly highlighting the benefits of the imaginary context.	Reply	O	0
Another interesting point is that when K=infinity, the lossless memory buffer can collect up to 100 or more context points while ASNP outperforms this by attending only on 25 imaginary context points at any given time-step -- clearly highlighting that the imagined context is more size-efficient.	Reply	B-Reply	3
[line_break_token][line_break_token]Why analogy to the human brain and need for sequentially-updated memory:   We have reduced the emphasis on the brain analogy in the updated manuscript.	Reply	O	0
Our work is inspired by the under-fitting in SNP that hinders its wider usage.	Reply	B-Reply	4
The analogy to the human brain supports our hypothesis that an imagination process for recalling the past is effective and the right way forward to resolve under-fitting.	Reply	I-Reply	4
[line_break_token][line_break_token]Technical exposition is too vague:   Thank you for pointing out.	Reply	O	0
We have worked on making the ANP description and the technical exposition of ASNP clearer (see updated manuscript).	Reply	B-Reply	5
At the same time, due to space limitations, the finer details have been delegated to the appendices.	Reply	I-Reply	5
[line_break_token][line_break_token]The arbitrariness of the design choices: The main idea is in introducing the imaginary context via and our implementation design choices realize that idea -- demonstrated by our better performance on a variety of tasks.	Reply	O	0
The finer design choices are a result of empirical model selection but some broad design choices were hypothesized as follows.	Reply	B-Reply	6
A. Imaginary queries should complement the available real context and therefore should depend on them.	Reply	I-Reply	6
[line_break_token]B. Having imagination-tracker RNNs should be beneficial for prediction using the inferred knowledge of the underlying dynamics.	Reply	I-Reply	6
[line_break_token]C. Attention on the tracker RNN hidden states helps capture the pairwise interactions between the context points and also updates the imagined memory with the more correct information from the real contexts.	Reply	I-Reply	6
[line_break_token][line_break_token]Key technical challenge:    As responded in a previous question, making use of the past contexts is necessary for the attention to operate on.	Reply	O	0
Realizing that a simple memory buffer of the context history is a sub-optimal design choice, developing the idea and the implementation of the imaginary context was the key technical challenge.	Reply	B-Reply	7
[line_break_token][line_break_token]Attention without imaginary context:   As answered in an earlier question, it is possible to truncate the stored contexts to hold the K most recent ones.	Reply	O	0
We have also tested this with K=infinity for the 1D regression tasks as described in the response for all reviewers, we found that our proposed ASNP still outperforms.	Reply	B-Reply	8
[line_break_token][line_break_token]NP/ANP not much different from Eq.3:   We politely disagree.	Reply	O	0
Eq.3 depicts how the imaginary queries and values can be propagated from one time-step to the next and it is implemented using attention mechanisms.	Reply	B-Reply	9
This is clearly different from NP which does not use attention and also different from ANP because it can neither produce nor propagate imaginary contexts	Reply	I-Reply	9

This paper describes a large-scale ECG dataset that the authors intend to publish.	Review	O	0
Along with the to-be-released dataset, the authors also provide some unsupervised analysis and visualization of the dataset.	Review	O	0
[line_break_token][line_break_token]The data is collected using the author‚Äôs company‚Äôs single lead ECG devices.	Review	O	0
The dataset is collected from 11,000 patients and contains over 2.7 billion peaks.	Review	O	0
According to the cited works in section 2, the scale of this proposed dataset is unprecedented and will be beneficial to the ECG community.	Review	O	0
[line_break_token][line_break_token]I think this is an interesting dataset for the ECG machine learning community.	Review	O	0
Some recent advances in this field are based on non-public dataset.	Review	O	0
However, this dataset seems to require additional curation before it is ready.	Review	B-Review	1
[line_break_token][line_break_token][line_break_token][line_break_token]Questions.	Review	O	0
[line_break_token]In section 3, the authors discuss the potential concerns regarding privacy, what are the measures taken by the authors when collecting &amp; distributing this dataset?	Review	O	0
I didn‚Äôt find this question addressed in section 3.	Review	B-Review	2
[line_break_token][line_break_token]Like the authors stated in 2nd paragraph under section 4, this dataset is biased in the sense that it is collected from patients.	Review	I-Review	3
The subjects are in the age group of 62.2 +/- 17.4.	Review	I-Review	3
Do the authors recognized various chronicle conditions that often appear in that age group?	Review	I-Review	3
Is that information part of the to-be-released dataset?	Review	I-Review	3
[line_break_token][line_break_token]Since this work focuses on releasing  a dataset, I find the current experiment section unnecessary &amp; somewhat unrelated.	Review	O	0
What would be interesting to see is whether the authors use ML techniques to facilitate the curation of the dataset.	Review	B-Review	4
For example, in paragraph 3 under section 4, it says each segment data is labeled by 3 technologists.	Review	I-Review	4
How many technologist are involved in total?	Review	I-Review	4
and what measure are taken to address the variances among different technologists?	Review	I-Review	4
[line_break_token]	Review	O	0
t seems that you appreciate this work but decided to reject this paper due to missing details and the inclusion of an experimental section.	Reply	B-Reply	4
Baseline experiments for dataset papers provide a useful benchmark for the community to compare with and guide further work on the topic.	Reply	I-Reply	4
Discussions with cardiologists have guided us to the set of evaluation metrics that we‚Äôve described.	Reply	I-Reply	4
[line_break_token]Existing dataset papers do this (e.g. <a href="https://openreview.net/forum?id=r1lYRjC9F7," target="_blank" rel="nofollow">https://openreview.net/forum?id=r1lYRjC9F7,</a> <a href="https://openreview.net/forum?id=r1l73iRqKm)."	Reply	O	0
target="_blank" rel="nofollow">https://openreview.net/forum?id=r1l73iRqKm).</a> [line_break_token][line_break_token]We have also addressed the issues with missing details below and we hope that you will reconsider your decision.	Reply	O	0
[line_break_token][line_break_token]&gt; this dataset seems to require additional curation before it is ready.	Reply	O	0
[line_break_token]Could the reviewer clarify what additional curation would make the dataset ready?	Reply	B-Reply	1
[line_break_token][line_break_token]&gt; what are the measures taken by the authors when collecting &amp; distributing this dataset?	Reply	O	0
[line_break_token][line_break_token]We‚Äôve anonymised the data to comply with the ethics review board requirements by our university (this was mentioned in the paper).	Reply	B-Reply	2
We have added additional details about the steps we‚Äôve taken to the paper.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; Do the authors recognized various chronicle conditions that often appear in that age group?	Reply	O	0
[line_break_token][line_break_token][line_break_token]That information will not be included in the released dataset.	Reply	B-Reply	3
With regard to chronic conditions, do you mean we should be including the types of chronic conditions for the general population of where the patients come from?	Reply	I-Reply	3
We are unable to include conditions associated with each patient.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; How many technologists are involved in total?	Reply	O	0
and what measure are taken to address the variances among different technologists?	Reply	O	0
[line_break_token][line_break_token]In total there are 20 technologists (we‚Äôve updated the paper to include this).	Reply	B-Reply	4
For each record, three technologists were involved.	Reply	I-Reply	4
For more details see Section 4 paragraph 3.	Reply	I-Reply	4
[line_break_token]We note that the annotations created by these technologists were then used in a medical diagnosis of the patient involved.	Reply	I-Reply	4

This paper proposes an adversarial pNML scheme for adversarial defence and adversarial example detection.	Review	O	0
The idea is very intuitive and pNML is adopted from the literature work for the purpose of adversarial defence.	Review	O	0
[line_break_token][line_break_token]The authors provided some explanation on why the adversarial pNML should work.	Review	O	0
The reasoning is quite intuitive, lacking of thorough justification.	Review	B-Review	1
 The authors may consider using experiments to provide empirical justifications for the explanations.	Review	I-Review	1
[line_break_token][line_break_token]The proposed method is heavily dependent on previous works.	Review	I-Review	2
The section 6 adaptive adversary part is not clear.	Review	I-Review	2
 How to do the adaptive attack based on Eq.(16)?	Review	I-Review	2
Maximizing the loss in Eq.(16)?	Review	I-Review	2
 How to determine the threshold for adversarial example detection?	Review	O	0
[line_break_token][line_break_token]The experimental results in Table 1 seems to be very good.	Review	B-Review	4
However, have the state-of-the-art defence methods been compared?	Review	I-Review	4
[line_break_token]	Review	O	0
hank you for your kind and constructive review.	Reply	O	0
[line_break_token][line_break_token]We would like to address your points in the same order:[line_break_token]1.‚ÄúThe authors provided some explanation on why the adversarial pNML should work.	Reply	O	0
The reasoning is quite intuitive, lacking of thorough justification.	Reply	O	0
The authors may consider using experiments to provide empirical justifications for the explanations. ‚	Reply	O	0
Äú[line_break_token][line_break_token]Answer: We follow your recommendation and add empirical experiments to support the claims made in Section 4 regarding why adversarial pNML should work.	Reply	O	0
[line_break_token]In the provided link <a href="https://imgur.com/a/hcSyx7f" target="_blank" rel="nofollow">https://imgur.com/a/hcSyx7f</a> you would find histograms showing the probabilities difference before and after refinement.	Reply	O	0
The results are calculated over MNIST for a model trained with PGD adversarial samples and tested with PGD adversarial samples.	Reply	B-Reply	1
[line_break_token]We present 3 histograms, one for refinement towards the true label, the second for refinement towards the adversary target label and the third for refinement towards the other labels (see Section 4 for more details):[line_break_token]a.[tab_token]True label ‚Äì The first histograms present the true label probability difference between the refined sample,, and original sample.	Reply	I-Reply	1
We divide the samples into 2 groups, the first where the true label is also the predicted label (Correct ‚Äì True label) and the second where the true label isn‚Äôt the predicted label (Incorrect ‚Äì true label).	Reply	I-Reply	1
We see that the refinement increases the true label probabilities, especially when the true label isn‚Äôt the predicted label.	Reply	I-Reply	1
[line_break_token]b.[tab_token]Adversary Target label ‚Äì The second histogram presents the target label (the label the adversary promotes) probability difference between the refined sample,, and original sample.	Reply	I-Reply	1
We divide the samples into 2 groups, the first where the adversary was unsuccessful (the predicted label is the true label) and the second where the adversary was successful (the predicted label is the adversary target label).	Reply	I-Reply	1
As explained in Section 4 - Refinement towards the adversary target, in case of a strong adversary (which in our case is successful adversary) the loss is already converged to the local-maxima, therefore refinement towards can sometimes decrease the probability as seen in the histogram.	Reply	I-Reply	1
[line_break_token]c.[tab_token]Other label - The first histograms present the true label probability difference between the refined sample,, and the original sample.	Reply	I-Reply	1
We see that the refinement increases the probabilities, but since labels belonging to that category have a low probability, to begin with, this increase in probability won‚Äôt cause misclassification.	Reply	I-Reply	1
[line_break_token]In short, when a successful attack occurs, the refinement increases the probability of the true label much more than the adversarial targeted label which is why adversarial pNML works.	Reply	I-Reply	1
This happens because the loss of a successful adversarial sample is already converged to a local-maxima, therefore refinement towards the adversarial target label won‚Äôt dramatically increase target probability.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
[tab_token]‚ÄúThe section 6 adaptive adversary part is not clear.	Reply	O	0
How to do the adaptive attack based on Eq.(16)?	Reply	O	0
Maximizing the loss in Eq.(16)?‚Äù[line_break_token]Answer: By Maximizing the loss in Eq (16) using an iterative method such as PGD on the end-to-end model we attempt to maximize the loss to cause misclassification while minimizing the regret to avoid detection.	Reply	O	0
The first term in Eq.(16) is responsible for the loss of the end-to-end model and the second term is a regularization over the regret.	Reply	B-Reply	2
[line_break_token][line_break_token]3.‚Äú How to determine the threshold for adversarial example detection?	Reply	O	0
[line_break_token]Answer: We determine the threshold of the detection and the trade-off parameter of the adaptive attack by a min-max game - for each threshold value we test against multiple values, the threshold that gives the best accuracy for the worst-case is selected.	Reply	O	0
[line_break_token][line_break_token]4. ‚	Reply	O	0
ÄúHave state-of-the-art defense methods been compared?‚Äù[line_break_token]Answer: We consider adversarial training with strong adversarial examples (such as PGD) to be a state-of-the-art defense as presented in Madry et al.	Reply	O	0
paper <a href="https://arxiv.org/abs/1706.06083."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1706.06083.</a> This claim is also repeated in the paper reviewer 2 referenced (<a href="https://arxiv.org/abs/1807.06732):" target="_blank" rel="nofollow">https://arxiv.org/abs/1807.06732):</a> ‚ÄúThe current state-of-the-art defense for the standard rules on the MNIST dataset is due to Madry et al.	Reply	O	0
‚Äù[line_break_token][line_break_token][line_break_token]	Reply	B-Reply	4

This paper presents a new regularization technique for VAEs similar in motivation and form to the work on InfoVAE.	Review	O	0
 The basic intuition is to encourage different training samples to occupy different parts of z-space, by maximizing the expected KL divergence between pairwise posteriors, which they call Mutual Posterior-Divergence (MPD).	Review	O	0
 They show that this objective is a symmetric version (sum of the forward and reverse KL) of the Mutual Info regularization used by the InfoVAE.	Review	O	0
 In practice however, they do not actually use this objective.	Review	O	0
 They use a different regularization which is based on the MPD loss but they say is more stable because it's always greater than zero, and ensures that all latent dimensions are used.	Review	O	0
 In addition to the MPD based term, they also add another term which encouraging the pairwise KL-divergences to have a low standard-deviation, to encourge more even spreading over the z-space rather than the clumpy distribution that they observed with only the MPD based term.	Review	O	0
[line_break_token][line_break_token]They show state of the art results on MNIST and Omniglot, improving over the VLAE.	Review	O	0
 But on natural data (CIFAR10), their results are worse than VLAE.	Review	O	0
 [line_break_token][line_break_token]Pros:[line_break_token][tab_token]1.	Review	O	0
The technique has a nice intuitive (but not particularly novel) motivation which is kinda-sorta theoretically motivated if you squint at it hard enough.	Review	O	0
[line_break_token][tab_token]2.	Review	O	0
The results on the simple datasets are solid and encouraging.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][tab_token]1.	Review	O	0
 The practical implementation is a bit ad-hoc and requires turn two additional hyper parameters (like most regularization techniques).	Review	O	0
[line_break_token][tab_token]2.	Review	O	0
The basic motivation and observations are the same as InfoVAE, so it's not completely novel.	Review	B-Review	2
[line_break_token][tab_token]3.	Review	O	0
The CIFAR10 results are bit concerning, and one can't help but wondering if the technique really only helps when the data has simpler shared structure.	Review	B-Review	3
[line_break_token][line_break_token]Overall:  I think the idea is interesting enough, and the results encouraging enough to be just above the bar for acceptance at ICLR.	Review	O	0
[line_break_token][line_break_token]I have the following question for the authors:[line_break_token][line_break_token][tab_token]1.	Review	O	0
Why do you use the truncated pixelcnn on CIFAR10?	Review	B-Review	3
 Did you try it with the more expressive decoder (as was used on the binary images) and got worse results?	Review	I-Review	3
 or is there some other justification for this difference?	Review	I-Review	3
[line_break_token][line_break_token]I would have like to see the following modifications to the paper:[line_break_token][line_break_token][tab_token]1.	Review	O	0
The paper essentially presents two related but separate regularization techniques.	Review	B-Review	1
 It would be nice to have ablation results to show how each of these perform on their own.	Review	I-Review	1
[line_break_token][tab_token]2.	Review	O	0
Bonus points for showing results which combine VLAE (which already has a form of the MPD regularization) with the smoothness regularization.	Review	B-Review	2
[line_break_token][tab_token]3.	Review	O	0
It would be nice to see samples from VLVAE in Figure 3 next to the MAE samples to more easily compare them directly.	Review	B-Review	4
[line_break_token][tab_token]4.	Review	O	0
There are many grammatical and English mistakes.	Review	B-Review	5
 The paper is still quite readably, but please make sure the paper is proofread by a native English speaker.	Review	I-Review	5
[line_break_token]	Review	O	0
Thank you for the insightful comments!	Reply	O	0
[line_break_token][line_break_token]For your questions and concerns about the results on CIFAR-10 with more expressive decoders, please see this post:[line_break_token]<a href="https://openreview.net/forum?id=Hke4l2AcKQ&noteId=BylQ2fjL6X" target="_blank" rel="nofollow">https://openreview.net/forum?id=Hke4l2AcKQ&noteId=BylQ2fjL6X</a>[line_break_token]where we show stronger performance with more expressive decoders for our model.	Reply	O	0
[line_break_token][line_break_token]For your specific questions, [line_break_token]1 & 2.	Reply	O	0
We appreciate your suggestion to perform ablation experiments for the two terms in our regularizer.	Reply	B-Reply	1
Actually, both of the regularization terms play important roles.	Reply	I-Reply	1
Without L_smooth, the model will easily place different posteriors into isolated points far away from each other, obtaining L_diversity close to zero, and the model performance on both density estimation and representation learning is worse than original VLAE without the regularization.	Reply	I-Reply	1
Moreover, removing the L_smooth term, the training of the model becomes unstable.	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
Thanks for your suggestion, we have added samples from VLAE in the updated version.	Reply	B-Reply	4
[line_break_token][line_break_token]4.	Reply	O	0
Thanks for your comment, we have revised the paper to fix the grammatical mistakes.	Reply	B-Reply	5

This paper introduces few-shot graph classification problem and proposes super-class based graph neural network (GNN) to solve it.	Review	O	0
Experiments on two datasets demonstrate that the proposed model outperforms a number of baseline methods.	Review	O	0
Some ablation study and analysis are also provided.	Review	O	0
Followings are my detail review.	Review	O	0
[line_break_token][line_break_token]It is interesting for the authors to introduce few-shot graph classification problem which is meaningful.	Review	B-Review	1
If I understood correctly, the authors use graph spectral distance to find prototype graph of each class, then employ prototype graph clustering to obtain super-classes, which are further fed to GNN as the joint optimization of super-class and regular class prediction.	Review	I-Review	1
To me, the novelty is incremental.	Review	I-Review	1
[line_break_token][line_break_token]The authors use two new datasets for experiments due to the requirement of numerous class labels.	Review	I-Review	2
I concerned about performances of different GNN baseline methods in Letter data due to small graph size (with 4.6 nodes in average).	Review	I-Review	2
The context neighbor information is important for multi-layer GNN.	Review	I-Review	2
Thus I could not fully judge the effectiveness of proposed model in this data.	Review	I-Review	2
[line_break_token][line_break_token]In Table 3, I found performance of proposed model with one super-class is still better than different GNN.	Review	I-Review	3
I did get the point from this result.	Review	I-Review	3
Why there is no performance decrease as all have the same super-class label?	Review	I-Review	3
What is the model performance when removing super-class augmentation?	Review	I-Review	3
I would like to see more discussion or experiment about this.	Review	I-Review	3
[line_break_token][line_break_token]Update: I am satisfied with author's response and raised my score.	Review	O	0
We thank the reviewer for his comments and observations.	Reply	O	0
Following are the answers to each question/comment you have raised.	Reply	O	0
[line_break_token][line_break_token]R3Q1: ‚ÄúIt is interesting for the authors to introduce few-shot graph classification problem which is meaningful.	Reply	O	0
If I understood correctly, the authors use graph spectral distance to find prototype graph of each class, then employ prototype graph clustering to obtain super-classes, which are further fed to GNN as the joint optimization of super-class and regular class prediction.	Reply	O	0
To me, the novelty is incremental.	Reply	O	0
‚Äù[line_break_token]R3A1: Yes, your summary can serve as a high-level coarse overview of our work.	Reply	O	0
Regarding the novelty being incremental, we respectfully disagree due to the following reasons.	Reply	B-Reply	1
[line_break_token]The task of few-shot learning on graphs to begin with is novel (as is also pointed out by you and all the other reviewers) and extremely challenging as there are no previous works in this few-shot setting on graphs.	Reply	I-Reply	1
The introduction of using the-Wasserstein distance between the spectrum of graphs in order to build a supergraph and also cluster class-labels into superclasses is also novel.	Reply	I-Reply	1
We are not aware of any graph NNs that have introduced a graph spectral Wasserstein distance between graphs for classification.	Reply	I-Reply	1
[line_break_token][line_break_token]We believe our superclass construction per batch embodies the ‚Äúfull context embedding‚Äù feature of matching networks [1], which essentially capture a wider context of the support set per batch and not just a single graph and prototype networks [2] by using precomputed Wasserstein prototypes to decide the superclasses that allow information flow between various classes too.	Reply	I-Reply	1
Our architecture that jointly learns the superclass and regular class using two-phase (training and fine-tuning phase) training is also a novel construction.	Reply	I-Reply	1
Finally, we have also shown our method works well in the semi-supervised and adaptive learning setting (Appendix A.5 and A.6).	Reply	I-Reply	1
[line_break_token][1] Vinyals et~al. ‚	Reply	O	0
ÄúMatching Networks for One Shot Learning‚Äú, NIPS 2016[line_break_token][2] Snell et~al. ‚	Reply	O	0
ÄúPrototypical Networks for Few-shot Learning‚Äù, NIPS 2017[line_break_token][line_break_token]R3Q2: Low average number of nodes per graph in the datasets used.	Reply	O	0
[line_break_token]R3A2: Thanks for pointing this out.	Reply	O	0
We found two widely-used graph datasets in graph classification literature with larger average number of nodes, namely Enzymes and Reddit-12K.[line_break_token]We conducted all our experiments (including sensitivity and ablation studies) on both these datasets and the results have been added to the revised paper.	Reply	B-Reply	2
Enzymes has 33 nodes per graph and Reddit-12K has 391 nodes per graph on average.	Reply	I-Reply	2
[line_break_token]Please refer to the table 2 for new results.	Reply	I-Reply	2
We find that our results show a marked improvement on the new datasets as well.	Reply	I-Reply	2
[line_break_token]+-------------------------+-----------------------------------------------------------+-----------------------------------------------------------+[line_break_token]|    Method               |                            Reddit-12K                             |                              Enzymes                               |[line_break_token]+-------------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+[line_break_token]|                                 |       5SHOT     |      10SHOT    |      20SHOT    |       5SHOT     |      10SHOT    |      20SHOT    |[line_break_token]| WL                          | 40.26 +- 5.17 | 42.57 +- 3.69 | 44.41 +- 3.43 | 55.78 +- 4.72 | 58.47 +- 3.84 | 60.10 +- 3.18 |[line_break_token]| Graphlet                | 33.76 +- 6.94 | 37.59 +- 4.60 | 41.11 +- 3.71 | 53.17 +- 5.92 | 55.30 +- 3.78 | 56.90 +- 3.79 |[line_break_token]| AWE                        | 30.24 +- 2.34 | 33.44 +- 2.04 | 36.13 +- 1.89 | 43.75 +- 1.85 | 45.58 +- 2.11 | 49.98 +- 1.54 |[line_break_token]| Graph2Vec            | 27.85 +- 4.21 | 29.97 +- 3.17 | 32.75 +- 2.02 | 55.88 +- 4.86 | 58.22 +- 4.30 | 62.28 +- 4.14 |[line_break_token]| Diffpool                 | 35.24 +- 5.69 | 37.43 +- 3.94 | 39.11 +- 3.52 | 45.64 +- 4.56 | 49.64 +- 4.23 | 54.27 +- 3.94 |[line_break_token]| CapsGNN              | 36.58 +- 4.28 | 39.16 +- 3.73 | 41.27 +- 3.12 | 52.67 +- 5.51 | 55.31 +- 4.23 | 59.34 +- 4.02 |[line_break_token]| GIN                        | 40.36 +- 4.69 | 43.70 +- 3.98 | 46.28 +- 3.49 | 55.73 +- 5.80 | 58.83 +- 5.32 | 61.12 +- 4.64 |[line_break_token]| GIN-k-NN              | 41.31 +- 2.84 | 43.58 +- 2.80 | 45.12 +- 2.19 | 57.24 +- 7.06 | 59.34 +- 5.24 | 60.49 +- 3.48 |[line_break_token]| OurMethod-GCN | 40.77 +- 4.32 | 44.28 +- 3.86 | 48.67 +- 4.22 | 54.34 +- 5.64 | 58.16 +- 4.39 | 60.86 +- 3.74 |[line_break_token]| OurMethod-GIN  | 41.59 +- 4.12 | 45.67 +- 3.68 | 50.34 +- 2.71 | 55.42 +- 5.74 | 60.64 +- 3.84 | 62.81 +- 3.56 |[line_break_token]+-------------------------+-------------------+------------------+-------------------+------------------+-------------------+------------------+	Reply	I-Reply	2

This paper attempts to the solve  data-set coverage issue common with Inverse reinforcement learning based approaches - by introducing a meta-learning framework trained on a smaller number of basic tasks.	Review	O	0
The primary insight here is that there exists a smaller set of unique tasks, the knowledge from which is transferable to new tasks and using these to learn an initial parametrized reward function improves the coverage for IRL.	Review	O	0
With experiments on the SpriteWorld synthetic data-set, the authors confirm this hypothesis and demonstrate performance benefits - showcasing better correlation with far fewer  number of demonstrations.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]+ The solution proposed here in novel - combining meta-learning on tasks to alleviate a key problem with IRL based approaches.	Review	O	0
[line_break_token]The fact that this is motivated by the human-process of learning, which successfully leverages tranferability of knowledges across a group of basic tasks for any new (unseen) tasks, makes it quite interesting.	Review	O	0
[line_break_token]+ Unburdens the needs for extensive datasets for IRL based approach to be effective[line_break_token]+ To a large extent, circumvents the need of having to manually engineered features for learning IRL reward functions[line_break_token][line_break_token]Cons:[line_break_token]- Although the current formulation is novel, there is a close resemblance to other similar approaches  - mainly, imitation learning.	Review	O	0
It would be good if the authors could contrast the differences between the proposed approach and approach based on imitation learning (with similar modifications).	Review	B-Review	1
Imitation learning is only briefly mentioned in the related work (section-2), it would be helpful to elaborate on this.	Review	I-Review	1
For instance, with Alg-1 other than the specific metric used in #3 (MaxEntIRLGrad), the rest seems close similar to what would be done with imitation learning?	Review	I-Review	1
[line_break_token]- One of main contributions is avoiding the need for hand-crafted features for the IRL reward function.	Review	O	0
However, even with the current approach, the sampling of the meta-learning training and testing tasks seem to be quite critical to the performance of the overall solution and It seems like this would require some degree of hand-tuning/picking.	Review	B-Review	2
Can the authors comment on this and the sensitivity of the results to section of meta-learning tasks and rapid adaption?	Review	I-Review	2
[line_break_token]- The results are limited, with experiments using only the synthetic (seemingly quite simple)  SpriteWorld data-set.	Review	O	0
Given the stated objective of this work to extend IRL to beyond simple  cases, one would expect more results and with larger problems/data-sets.	Review	B-Review	3
[line_break_token][tab_token]- Furthermore, given that this work primarily attempts to improve performance with using meta-learned reward function instead of default initialization - it might make sense to also compare with method such as Finn 2017, Ravi & Larochelle 2016.	Review	O	0
[line_break_token][line_break_token]Minor questions/issues:[line_break_token]> section1: Images are referred to as high dimensional observation spaces, can this be further clarified?	Review	O	0
[line_break_token]>  section3: it is not immediately obvious how to arrive at eqn.2.	Review	O	0
Perhaps additional description would help.	Review	B-Review	6
[line_break_token]> section4.1 (MandRIL) meta-training: What is the impact/sensitivity of computing the state visitation distribution with either using the average of expert demos  or the true reward?	Review	O	0
In the reported experiments, what is used and what is the impact on results, if any ?	Review	B-Review	7
[line_break_token]> section4.2: provides an interesting insight with the concept of locality of the prior and establishes the connection with Bayesian approaches.	Review	O	0
[line_break_token]> With the results, it seems like that other approaches continue to improve on performance with increasing number of demonstrations (the far right part of the Fig.4, 5) whereas the proposed approach seems to stagnate - has this been experimented further ?	Review	O	0
does this have implications on the capacity of meta-learning ?	Review	B-Review	9
[line_break_token]> Overall, given that there are several knobs in the current algorithm, a comprehensive sensitivity study on the relative impact would help provide a more complete picutre	Review	O	0
We thank the reviewer for their comments.	Reply	O	0
We have addressed the clarifications requested by the reviewer and added comments regarding requested comparisons.	Reply	O	0
[line_break_token][line_break_token]‚Äúthere is a close resemblance to other similar approaches  - mainly, imitation learning.	Reply	O	0
‚Äù[line_break_token][line_break_token]Behavior cloning is a simple solution, but only tends to succeed with large amounts of data.	Reply	O	0
This is due to the problem of compounding error due to covariate shift which has been studied in prior work (e.g. Ross AISTATS 2010, Ross 2011).	Reply	B-Reply	1
Learning reward functions that reason about outcomes, and prioritize entire trajectories over others, can mitigate this effect by avoiding per time-step fitting.	Reply	I-Reply	1
The difference between these two approaches has been further discussed in prior work in the literature (e.g. MacGlashan et al.	Reply	I-Reply	1
2015) and IRL has been shown to be a better solution in settings where lots of data is not available (e.g. Finn et al.	Reply	I-Reply	1
2016, Fu et al.	Reply	I-Reply	1
2017).	Reply	I-Reply	1
[line_break_token][line_break_token]‚ÄúFurthermore, given that this work primarily attempts to improve performance with using meta-learned reward function instead of default initialization - it might make sense to also compare with method such as Finn 2017, Ravi & Larochelle 2016‚Äù[line_break_token][line_break_token]Thank you for the suggestion.	Reply	O	0
Neither Finn et al.	Reply	B-Reply	4
2017 nor Ravi & Larochelle 2016 actually tackle the inverse reinforcement learning problem, so these methods are not directly applicable.	Reply	O	0
Our method is an extension of Finn et al.	Reply	B-Reply	4
2017 to the IRL setting.	Reply	I-Reply	4
An extension of Ravi & Larochelle is likely also possible, but would itself constitute a novel method.	Reply	O	0
We do compare to an alternative meta-learning approach based on recurrent models, which is somewhat similar to Duan et al.	Reply	B-Reply	4
2017 (see Figure 6 red line), and we find that our approach substantially outperforms this alternative method.	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúThe results are limited, with experiments using only the synthetic (seemingly quite simple) SpriteWorld data-set.	Reply	O	0
Given the stated objective of this work to extend IRL to beyond simple  cases, one would expect more results and with larger problems/data-sets‚Äù[line_break_token][line_break_token]The complexity of the experiments presented in the IRL literature are generally less complex than the RL literatures.	Reply	O	0
Our experiments however are able to scale to high-dimensional image inputs, in contrast to many prior methods in IRL (see below).	Reply	B-Reply	3
The complexity of the experiments should be judged relative to the literature, rather than a different problem formulation.	Reply	I-Reply	3
In the IRL literature, it is not uncommon to report results in domains which we summarize here: Ratliff et al.	Reply	I-Reply	3
ICML '06 consider a discretized driving domain, Ziebart et al.,	Reply	I-Reply	3
AAAI '08 considered a driver route modelling setting with roads featurized by 22 dimensional vectors, Hadfield-Menell et al.	Reply	I-Reply	3
NIPS '16 considered a tabular domain and used a featurized state representation with dimensionality 3 or 10, Hadfield-Menell et al.	Reply	I-Reply	3
NIPS '17 considered 4 variants of a tabular domain with a featurized state representation of 50 dimensions, Malik et al.	Reply	I-Reply	3
ICML '18 considered a tabular domain on the order of a 5 x 5 grid with 4 object classes and 4 objects.	Reply	I-Reply	3
We also emphasize that our domain is more challenging than those in prior work as it requires scaling to high-dimensional observations spaces.	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúImages are referred to as high dimensional observation spaces, can this be further clarified?‚Äù[line_break_token][line_break_token]The observation spaces considered in recent prior IRL work typically operates on features spaces on the order of 10-50 dimensions (e.g. Hadfield-Menell et al.	Reply	O	0
NIPS‚Äô16, Hadfield-Menell el al.	Reply	B-Reply	5
NIPS‚Äô17) or tabular states (e.g. Malik et al.	Reply	I-Reply	5
ICML '18).	Reply	I-Reply	5
In contrast, our reward function is defined directed on image observations, which in the case of our 84 x 84=7056 images is much higher dimensional.	Reply	I-Reply	5

Behaviour Suite for Reinforcement Learning[line_break_token][line_break_token]In this paper the authors provide a set of light-weighted but dedicated designed environments, so that researchers can use the environments as a quick indication of the ability of the proposed (or existing) algorithms.	Review	O	0
[line_break_token]I think the paper is well-written, with the intuition clearly demonstrated.	Review	O	0
[line_break_token][line_break_token]I tend to vote for rejection though, given that the novelty in the project is relatively limited.	Review	O	0
[line_break_token]But I believe in general it is a very valuable project that will be beneficial to future research and I would like to recommend for a workshop publication.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The paper is well written, easy to understand.	Review	O	0
[line_break_token]- Provide an industry level code base that can be used efficiently and easily.	Review	O	0
[line_break_token]The project will be of great value to the research community in the near future.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- The novelty of the project is relatively limited.	Review	O	0
[line_break_token]The proposed and implemented environments have been studied before.	Review	B-Review	1
[line_break_token]- No explicit conclusion from the evaluation.	Review	O	0
[line_break_token]	Review	O	0
hank you very much for your review!	Reply	O	0
[line_break_token][line_break_token]Based on your feedback we have added Section 1.4, which outlines the relation to prior work more explicitly.	Reply	B-Reply	1
[line_break_token]We also hope that this section makes the *novelty* of our project much more clear.	Reply	I-Reply	1
[line_break_token][line_break_token]We believe The Behaviour Suite for Reinforcement Learning offers a complementary approach to existing benchmarks in RL, with several novel components:[line_break_token][line_break_token]- bsuite experiments enforce a specific methodology for agent evaluation beyond just the environment definition.	Reply	I-Reply	1
[line_break_token]This is crucial for scientific comparisons and something that has become a major problem for many benchmark suites (Section 2).	Reply	I-Reply	1
[line_break_token][line_break_token]- bsuite aims to isolate core capabilities with targeted `unit tests', rather than integrate general learning ability.	Reply	O	0
[line_break_token]Other benchmarks evolve by increasing complexity, bsuite aims to remove all confounds from the core agent capabilities of interest (Section 3).	Reply	B-Reply	1
[line_break_token][line_break_token]- bsuite experiments are designed with an emphasis on scalability rather than final performance.	Reply	O	0
[line_break_token]Previous `unit tests' (such as `Taxi' or `RiverSwim') are of fixed size, bsuite experiments are specifically designed to vary the complexity smoothly (Section 2).	Reply	B-Reply	1
[line_break_token][line_break_token]- Our open source code has an extraordinary emphasis on the ease of use, and compatibility with RL agents not specifically designed for bsuite[line_break_token]Evaluating an agent on bsuite is practical even for agents designed for a different benchmark (Section 4).	Reply	O	0
[line_break_token][line_break_token][line_break_token]Overall, we are delighted that you agree:[line_break_token]- The paper is well written, easy to understand.	Reply	O	0
[line_break_token]- Provide an industry level code base that can be used efficiently and easily.	Reply	O	0
[line_break_token]- The project will be of great value to the research community in the near future.	Reply	O	0
[line_break_token][line_break_token]We believe that, following the changes we have made to the paper, there might be good reason for you to change your review to an "accept".	Reply	O	0
[line_break_token][line_break_token]Many thanks	Reply	O	0

The paper proposes a training framework that: [line_break_token](i) can efficiently handle catastrophic forgetting in a large number of tasks[line_break_token](ii) is robust to the ordering of the tasks[line_break_token][line_break_token]The high-level idea is to decompose learning parameters into two sets - one set that depends on the task and one set that is task agnostic.	Review	O	0
Hierarchal clustering is used to improve the efficiency of the training process by considering the decomposition of parameters at multiple levels (and not just 2).	Review	O	0
The paper shows improvements in terms of accuracy, stability, and order-robustness and provides ablation results (for various modifications of their proposed model) and considers a setup with around 100 tasks.	Review	O	0
The paper/idea is quite interesting and the results seem promising:[line_break_token][line_break_token]* The results in figure 5: (d) and (e) are very interesting.	Review	O	0
It seems as if all the "previous" knowledge is being contained in the task-specific parameters.	Review	B-Review	1
In general, I like the idea of being able to "forget" all the previous knowledge.	Review	I-Review	1
I want to clarify one thing here: My understanding is that after training the model on tasks 1 to 5, the weights corresponding to task 1 are dropped (that is just the task-specific parameters tau and not the mask).	Review	I-Review	1
Then before even one gradient update is applied, the model is re-evaluated on task 1.	Review	I-Review	1
Is that correct?	Review	I-Review	1
[line_break_token][line_break_token]* Figure 7 seems to suggest that the drift is reduced by the proposed approach.	Review	O	0
What does the presence of multiple markers (of the same color) mean?	Review	B-Review	2
For example, there are two green triangles in (b).	Review	I-Review	2
[line_break_token][line_break_token]====================[line_break_token][line_break_token]But, many things should be clarified for understanding the paper properly and for making a fair assessment of the claims made in the paper.	Review	O	0
I would be happy to update my score based on the authors' response to the following:[line_break_token][line_break_token]* My biggest concern is the choice of baselines.	Review	O	0
The paper (rightly)  highlights that their work improves over many existing works as they provide a mechanism to "retroactively update task-adaptive parameters" for the previous task.	Review	B-Review	3
But none of their baselines have this mechanism built-in.	Review	I-Review	3
So while there is a clear advantage with the proposed approach, the comparison is unfair and the baselines should have considered approaches like GEM [0[ and A-GEM[1] while also provide a kind-of retrospective mechanism to correct the weights corresponding to the subsequent tasks.	Review	I-Review	3
Without such a comparison, it is difficult to comment on the benefits of the approach.	Review	I-Review	3
[line_break_token][line_break_token]* On page 2, paragraph 3, the paper mentions that "APD does not increase the intrinsic network complexity as existing expansion-based approaches do".	Review	O	0
This claim seems to be loose since a new mask is learned for each task and needs to be persisted for all the subsequent tasks.	Review	B-Review	4
So there is an "expansion"-like step involved.	Review	I-Review	4
The authors should clarify this detail in the context of being memory efficient.	Review	I-Review	4
[line_break_token][line_break_token]* The authors propose a simplistic regularization approach (L2) to ensure that the shared parameters do not share too much across tasks.	Review	O	0
While it is good that a simple approach works so well, it would help if the authors discussed what do they think the reason is.	Review	B-Review	5
EWC [2] and the authors' results indicate that regularization in the parameter space does not work as well as regularization in the function space.	Review	I-Review	5
Thus the L2 regularization approach is not likely to work well.	Review	I-Review	5
[line_break_token][line_break_token]* Some parts of the paper needs to be reworded or clarified more.	Review	O	0
For example, since a per-task mask is being learned, there are two sets of weights being learned per task (the mask and the task-specific parameters).	Review	B-Review	6
So there are more parameters to learn and not just the sparse task-specific parameters.	Review	I-Review	6
[line_break_token][line_break_token]* As I understand, the paper uses "order robustness"  to mean avoiding "concept drift" (or "catastrophic forgetting").	Review	O	0
I might be missing something (in plain sight) but when I think of "order robustness", the order of tasks should not matter.	Review	B-Review	7
This is somewhat different than avoiding concept drift.	Review	I-Review	7
[line_break_token][line_break_token]* Is the hierarchical clustering being done for each neuron (of the given model)?	Review	O	0
If yes, how does this approach scale to large neural nets?	Review	B-Review	8
In general, how does the cost of doing the hierarchical clustering affect the training cost (of the model)?	Review	I-Review	8
[line_break_token][line_break_token]* Metrics: I am a little confused by the definition of the "final task-average performance" metric and could interpret it in at-least two ways.	Review	O	0
Could the authors please clarify this.	Review	B-Review	9
[line_break_token][line_break_token]* I do not understand some of the results in Figures 3 and 7, for the capacity of Progressive Neural Nets (PGNs).	Review	O	0
In general, PGNs add one new column (copy of base model) for each task.	Review	B-Review	10
So the capacity of the PGNs should always be a multiple of intial model capacity.	Review	I-Review	10
The results do not indicate that.	Review	I-Review	10
[line_break_token][line_break_token]* For the STL, the value of AOPD and MOPD suggests there is a good amount of variance when training the models.	Review	O	0
In this context, it would be helpful to know the variance associated with the other reported results as well.	Review	B-Review	11
[line_break_token][line_break_token]* Figure 6 is somewhat misleading as it does not account for the mask parameters that also need to be learned per-task.	Review	O	0
[line_break_token][line_break_token]====================[line_break_token][line_break_token]Things that should be clarified in the paper (but did not impact the score):[line_break_token][line_break_token]* Is the attention (sigma) hard-attention or soft attention?	Review	O	0
[line_break_token][line_break_token]* Is the attention applied per task (ie one scalar value per task) or layer or neuron?	Review	O	0
[line_break_token][line_break_token]* Equation 2 seems to add a lot of complexity to the training mechanism (to correct for the weights of the previous tasks).	Review	O	0
Did the authors consider some other update/corrective mechanism that could be applied once a task has been learned?	Review	B-Review	15
Please note that I am not criticizing the equation because it is complex.	Review	I-Review	15
I am curious about the alternatives that the authors considered.	Review	I-Review	15
[line_break_token][line_break_token]* Are there any kind of mathematical guarantees when using equation 2?	Review	O	0
If not, why should it be a better alternative to approaches like GEM[0]?	Review	B-Review	16
[line_break_token][line_break_token]* Did the authors consider Piggyback like network for the remaining tasks as well?	Review	O	0
[line_break_token][line_break_token]====================[line_break_token][line_break_token]Certain important citations seem to be missing:[line_break_token][line_break_token]* Works like GEM[0] and AGEM[1] fix the problem of "unidirectional" transfer of knowledge to some extent.	Review	O	0
[line_break_token][line_break_token]====================[line_break_token][line_break_token]Some minor corrections for the updated version:[line_break_token][line_break_token]* Typos: eg "catastropihc", [line_break_token]* In the section on Large-scale training, the STL model uses 100 times more params and not 10 times.	Review	O	0
[line_break_token][line_break_token]====================[line_break_token][line_break_token]References:[line_break_token][line_break_token][0]: GEM: <a href="https://arxiv.org/abs/1706.08840" target="_blank" rel="nofollow">https://arxiv.org/abs/1706.08840</a>[line_break_token][1]: A-GEM: <a href="https://openreview.net/pdf?id=Hkf2_sC5FX" target="_blank" rel="nofollow">https://openreview.net/pdf?id=Hkf2_sC5FX</a>[line_break_token][2]: EWC: <a href="https://arxiv.org/pdf/1612.00796.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.00796.pdf</a>[line_break_token][line_break_token]	Review	O	0
5) Equation 2 seems to add a lot of complexity to the training mechanism (to correct for the weights of the previous tasks).	Reply	O	0
Did the authors consider some other update/corrective mechanism that could be applied once a task has been learned?	Reply	O	0
Please note that I am not criticizing the equation because it is complex.	Reply	O	0
I am curious about the alternatives that the authors considered.	Reply	O	0
[line_break_token][line_break_token]- Thanks for the helpful suggestion, but as shown in the experimental results on training time (Figure 3, Table A.3), our update algorithm is already very fast compared to existing expansion-based continual learning approaches.	Reply	O	0
The objective only requires regularization terms for training without multiple steps of training in Dynamically Expandable Networks, or expensive reinforcement learning in Reinforced Continual Learning.	Reply	B-Reply	15
[line_break_token][line_break_token][line_break_token][line_break_token]16) Are there any kind of mathematical guarantees when using equation 2?	Reply	O	0
If not, why should it be a better alternative to approaches like GEM[0]?	Reply	O	0
[line_break_token][line_break_token]-  By introducing a novel regularization terms with additive parameter decomposition we can maintain the original solution on previous tasks without having to preserve their data instances.	Reply	O	0
GEM alleviate the forgetting problem with the use of coreset (episodic memory),  but it still has several intrinsic limitations: it cannot increase the network capacity (limited representation power) and can use only a small fraction of the previous data.	Reply	B-Reply	16
[line_break_token][line_break_token][line_break_token][line_break_token]17) Works like GEM[0] and AGEM[1] fix the problem of "unidirectional" transfer of knowledge to some extent.	Reply	O	0
[line_break_token][line_break_token]- Thank you for the helpful suggestion.	Reply	O	0
We included in discussions about episodic memory/coreset-based continual learning approaches on related work section, although we were mainly comparing against standard continual learning approaches that cannot access samples for the previous tasks.	Reply	B-Reply	18
[line_break_token][line_break_token][line_break_token][line_break_token]18) Typos and corrections[line_break_token][line_break_token]- Thanks for your suggestion, we have corrected them in the revision.	Reply	O	0

This paper tackles the problem of mismatched training/test data by directly modifying the latent representation learned with an auto-encoder.	Review	O	0
The proposed method employs a piece-wise linear function to transform the representation of samples from a source distribution to that of samples from the corresponding target distribution.	Review	O	0
The paper argues that the same transformation can be applied to samples from a distribution that are different from the source/target distributions.	Review	O	0
The method is empirically justified by three different tasks in computer vision and biology.	Review	O	0
[line_break_token][line_break_token]In my opinion, the motivation of the paper is clear and the writing is easy to follow, but one potential limitation is the lack of comparison with recent related work, e.g.,[line_break_token][line_break_token]Generate To Adapt: Aligning Domains using Generative Adversarial Networks[line_break_token]Swami Sankaranarayanan, Yogesh Balaji, Carlos D. Castillo, Rama Chellappa[line_break_token]<a href="https://arxiv.org/abs/1704.01705" target="_blank" rel="nofollow">https://arxiv.org/abs/1704.01705</a>[line_break_token][line_break_token]Deep Transfer Learning with Joint Adaptation Networks[line_break_token]Mingsheng Long, Han Zhu, Jianmin Wang, Michael I. Jordan[line_break_token]<a href="https://arxiv.org/abs/1605.06636" target="_blank" rel="nofollow">https://arxiv.org/abs/1605.06636</a>	Review	O	0
eviewer#3, thank you for your recommendation of accepting our paper, and thank you for the time and energy spent carefully reading it!	Reply	O	0
We are glad that you found our writing clear and a valuable contribution to the literature.	Reply	O	0
[line_break_token][line_break_token]We also appreciate being pointed to these relevant works.	Reply	B-Reply	1
While our technique is different, there are definitely important connections to previous domain adaptation work, and we have used these to better place where neuron editing falls in the landscape of learning transformations that can extrapolate [1, 2]. Domain adaptation seeks to learn a network on some labeled data that can be applied to some unlabeled data.	Reply	I-Reply	1
Almost exclusively, these works consider the task to be *classification*, and labels are the *class labels*, which are known on one dataset and not the other.	Reply	I-Reply	1
Instead, neuron editing considers the task *transformation*, and labels are the *target distribution*, which is known for one dataset and not the other.	Reply	I-Reply	1
Thus, neuron editing is a transformation-learning extension of the existing classification-learning domain adaptation work.	Reply	I-Reply	1
[line_break_token][line_break_token]We had not thought of it in such terms before, but greatly appreciate your recommendation.	Reply	I-Reply	1
Our manuscript is better off for the inclusion, so we thank you again!	Reply	I-Reply	1
[line_break_token][line_break_token][1] Tzeng, Eric, et al. "	Reply	O	0
Adversarial discriminative domain adaptation."	Reply	O	0
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.	Reply	O	0
2017.	Reply	O	0
[line_break_token][2] Ghifary, Muhammad, et al. "	Reply	O	0
Deep reconstruction-classification networks for unsupervised domain adaptation."	Reply	O	0
European Conference on Computer Vision.	Reply	O	0
Springer, Cham, 2016	Reply	O	0

Summary: the paper proposes a method for Deep Neural Networks (DNN) that identifies automatically relevant features of the set of the classes, enriching the predictions made with the visual features that contributed to that class, supporting, thus, interpretation (understanding what the model has learned) and explanation (justification of the predictions/classifications made by the model).	Review	O	0
This scheme does not rely on additional annotations, like earlier techniques do.	Review	O	0
[line_break_token][line_break_token]The contributions of this paper are relevant to, I would say, a large segment of the AI community, since interpretability and explainability of AI (XAI) is the focus of many current works in the area, and there are still many unresolved issues.	Review	O	0
I consider this paper suitable for ICLR 2019, in particular, it fits the call for papers topic ‚Äúvisualization or interpretation of learned representations‚Äù.	Review	O	0
[line_break_token][line_break_token]The authors also present a new dataset (am8Flower) that can be used by the community for future evaluations of explanation methods for DNN.	Review	B-Review	5
From my point of view, this is a significant contribution, since there is a lack of datasets that can be used for evaluation.	Review	I-Review	5
[line_break_token][line_break_token]The authors motivate properly the need for this research/study, addressing the main weakness of the two more common strategies for interpreting DNN, (1) manually inspecting visualizations of every single filter or (2) comparing the internal activations produced by a given model w.r.t.	Review	O	0
a dataset with pixel-wise annotations of possibly relevant concepts.	Review	O	0
[line_break_token][line_break_token]I would encourage the authors to write the limitations and weakness of their proposal w.r.t.	Review	B-Review	1
similar approaches they reviewed.	Review	I-Review	1
I am aware that the space is limited, but in p.8, section 4.3, when Table 1 is introduced and the authors confirm that their proposal has higher IoU than other methods, the authors could explain, in brief, what are the weaknesses of their method w.r.t.	Review	I-Review	1
the other approaches analyzed.	Review	I-Review	1
[line_break_token][line_break_token]Another clarification concerns the initialization of input parameters, such as sparsity; e.g., p.6 sparsity is initialized with 10 for all datasets, why?	Review	I-Review	2
How has this value been selected and how sensitive is the performance regarding variations of this value?	Review	I-Review	2
[line_break_token][line_break_token]Once again, I know that the space is limited, but I would like to be able to see some of the figures better (since this is an essential part of the paper).	Review	I-Review	3
The additional material complements very well the paper and shows larger figures, but I think that the paper itself should be self-sufficient, and figures like Fig.	Review	I-Review	3
5 should be enlarged so it is easier to see some details.	Review	I-Review	3
[line_break_token][line_break_token]Just a concern or something that I quite did not understand about one of the arguments the authors use to justify the evaluation carried out: the authors claim that they want to avoid the subjectivity introduced by humans (citing Gonzalez-Garcia et al.	Review	I-Review	4
2017), and prefer to avoid user studies, presenting a more objective approach in their evaluation.	Review	I-Review	4
Ok, but then, the analysis presented in, for example, page 7, is based mainly in their interpretation of the results, a qualitative analysis of the images (we can see fur patterns, this and that, etc.).	Review	I-Review	4
So aren‚Äôt they interpreting the results obtained as users?	Review	I-Review	4
So after all, aren‚Äôt the visual explanations and feedback intended for users?	Review	I-Review	4
Why should we claim that we want to avoid the subjectivity introduced by humans in the evaluation when the method proposed here is actually going to be used by users ‚Äìwith their inherent subjectivity?	Review	I-Review	4
I do not mean that the evaluation carried out is not interesting per se, but it could be motivated differently, or it could be complemented later on with future user studies (that would make an interesting addition to the paper).	Review	I-Review	4
Moreover, I also wonder whom the authors see as intended users for the proposed scheme.	Review	I-Review	4
[line_break_token][line_break_token]Small comments:[line_break_token]P.1 ‚Äúuseful insights on the internal representations‚Äù ÔÉ† insights into the internal representations.	Review	O	0
[line_break_token]P. 2: space needed in ‚Äúback-propagation methods.	Review	B-Review	6
Third,‚Äù[line_break_token]P. 3: Remove ‚Äús‚Äù in verb (plural authors): ‚ÄúSimilarly, Bach et al. (	Review	I-Review	6
2015) decomposes the classification‚Äù ÔÉ† decompose or decomposed[line_break_token]P.3: n needed ‚ÄúChattopadhyay et al. (	Review	I-Review	6
2018) exteded‚Äù ÔÉ† extended[line_break_token]P.3: ‚ÄúThis saliency-based protocol assume that‚Äù ÔÉ† protocol assumes[line_break_token]P.3: ‚Äúhighlighted by the the explanations‚Äù ÔÉ† remove one ‚Äúthe‚Äù[line_break_token]P. 5: ‚Äúspace.	Review	I-Review	6
As as result we get‚Äù ÔÉ† remove one ‚Äúas‚Äù[line_break_token]P. 5: ‚Äúand compensate this change‚Äù ÔÉ† compensate for this change[line_break_token]P. 6: ‚ÄúIn this experiment we verify‚Äù ÔÉ† In this experiment, we verify[line_break_token]P. 6: ‚ÄúTo this end, given a set of identified features we‚Äù ÔÉ† To this end, given a set of identified features, we[line_break_token]P. 6: ‚ÄúNote that the OnlyConv method, makes the assumption‚Äù ÔÉ† remove ‚Äú,‚Äù after method[line_break_token]P. 7: ‚ÄúIn order to get a qualitative insight of the type of‚Äù ÔÉ† insight into the[line_break_token]P. 7: I would write siamese and persian cat with capital ‚ÄúS‚Äù and ‚ÄúP‚Äù (Siamese, Persian)[line_break_token]P. 7: others/ upper ‚ÄúSome focus on legs, covered and uncovered, while other focus on the upped body part.	Review	I-Review	6
‚Äù ÔÉ† while others focus on the upper body part[line_break_token]P. 7: ‚ÄúThese visualizations answers the question‚Äù ÔÉ† answer[line_break_token]P. 7:  ‚ÄúIn this section we assess‚Äù ÔÉ† In this section, we[line_break_token]P. 7: Plural ‚ÄúWe show these visualization for different‚Äù ÔÉ† these visualizations[line_break_token]P. 7: In ‚ÄúHere our method reaches a mean difference on prediction confidence‚Äù ÔÉ† difference in prediction ‚Ä¶[line_break_token]P. 7: ‚ÄúThis suggest that our method is able‚Äù ÔÉ† This suggests that[line_break_token]P. 8: state-of-the-art[line_break_token]P. 8: ‚Äúhas higher mean IoU‚Äù ÔÉ† has a higher mean IoU[line_break_token]Whole document: when using ‚Äúi.e.	Review	I-Review	6
‚Äù add ‚Äú,‚Äù after: i.e.,[line_break_token][line_break_token]References: Some of the references in the list have very little information to be able to find it/proper academic citation, e.g. , Yosinski et al.	Review	O	0
2015; Vedaldi and Lenc, 2015:[line_break_token][line_break_token]Jason Yosinski, Jeff Clune, Anh Mai Nguyen, Thomas J. Fuchs, and Hod Lipson.	Review	O	0
Understanding neural networks through deep visualization.	Review	O	0
2015.	Review	O	0
[line_break_token][line_break_token]A. Vedaldi and K. Lenc.	Review	O	0
Matconvnet: Convolutional neural networks for matlab.	Review	O	0
In MM, 2015.	Review	O	0
[line_break_token][line_break_token]Ref Doersch et al.:	Review	O	0
What makes paris look like paris?	Review	O	0
ÔÉ† Paris[line_break_token]	Review	O	0
Thanks for the feedback.	Reply	O	0
[line_break_token][line_break_token]We appreciate the reviewer recognizes the relevance that our work can have in the field in general.	Reply	O	0
[line_break_token]We agree with the reviewer on the significance of the contribution given by the proposed an8Flower dataset.	Reply	B-Reply	5
[line_break_token]Although very recently few works (Adebayo et al.	Reply	I-Reply	5
,NIPS'18, Nie et al.,	Reply	I-Reply	5
ICML'18) have proposed means to assess the sanity/reliability of visual explanation methods, no method has been proposed to objectively evaluate the generated explanations themselves.	Reply	I-Reply	5
[line_break_token]Moreover, the proposed an8Flower dataset can be further extended to evaluate different settings of interest, e.g. occurrence of distracting objects, object classes driven by contextual information, fine-grained differences classes, etc.,	Reply	I-Reply	5
and can be used as a sanity check itself to verify whether a proposed explanation method can accurately explain a specific setting of interest.	Reply	I-Reply	5
[line_break_token][line_break_token]Regarding the suggestion of providing a discussion covering the limitations/weaknesses of the proposed method w.r.t.	Reply	I-Reply	1
similar compared methods, e.g. those from Table 1.	Reply	I-Reply	1
[line_break_token]Indeed, there are space limitations in place, as was pointed out by the reviewer.	Reply	I-Reply	1
[line_break_token]However, this is a good suggestion and we believe that adding such discussion would provide further insights on the proposed method, and strengthen the manuscript at the same time.	Reply	I-Reply	1
[line_break_token]Here is a summary of limitations that our method has w.r.t.	Reply	I-Reply	1
similar compared methods:[line_break_token]- Our method requires an additional process, i.e. feature selection via u-lasso, at training time (Sec.	Reply	I-Reply	1
3.1).	Reply	I-Reply	1
[line_break_token]- There is the need to define an additional parameter, i.e \mu, for the feature selection process (Sec.	Reply	I-Reply	1
3.1).	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the sparsity parameter (\mu) used for the feature selection process (u-lasso): increasing the sparsity value \mu in the u-lasso formulation will increase the number of selected features.	Reply	I-Reply	2
[line_break_token]This will allow to the selected filters to focus on more specific/specialized features that can help to handle better outlier/rare instances of the classes of interest.	Reply	I-Reply	2
Please see, Sec.8 and Fig.9 from the supplementary material for an extra analysis on the effect that the \mu value has on the capability of the selected features to serve as indicators of the classes of interest.	Reply	I-Reply	2
[line_break_token]We decided to start from a relatively low value, i.e. \mu=10, in order to focus on a small set of relevant features that can generalize to the classes of interest while, at the same time, keeping the u-lasso optimization with a low computational cost.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding the size of the figures (Fig.5 especially), we totally agree with the reviewer that figures like Fig.	Reply	I-Reply	3
5 should be enlarged so it is easier to see some details.	Reply	I-Reply	3
Despite the space limitations, we are aware that the 8-page length for the manuscript (content only) is not strict, and that authors are allowed to go up to 10 pages.	Reply	I-Reply	3
Having said this, if reviewers and ACs agree on the need for larger figures, we would like to cross the 8-page length and include larger versions of some of the figures that are currently too small to visualize details.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding the question of whether human inspection (or user studies) are necessary for model interpretation/explanation.	Reply	I-Reply	4
[line_break_token]We agree with the observation made by the reviewer regarding the fact that our method still requires some level of human intervention.	Reply	I-Reply	4
Furthermore, we agree that since the proposed method is meant to be used by users, an indication of how "understandable" an explanation is for end users is required.	Reply	I-Reply	4
Having said this, the main goal of our method is to reduce the load on the user side which can introduce bias and noise.	Reply	I-Reply	4
By reducing (and separating) the number of visualizations (i.e. number of features in the explanation visualizations and the relevant set of features learned by the model [interpretation]) to be inspected, we aim at reducing exhaustive inspections that are used in previous works to achieve model interpretation/explanation.	Reply	I-Reply	4
[line_break_token]We admit that in our manuscript, the need for human inspection is understated.	Reply	I-Reply	4
Moreover, we agree that our objective evaluation should be complemented with relatively simpler user studies in order to ensure that the produced explanations are meaningful to the individuals they aim to serve.	Reply	I-Reply	4
We will update the motivation behind our method in order to emphasize further the need of reduced used inspection and the complementary between our evaluation and user studies.	Reply	I-Reply	4

The paper describes the use of FFTs to speed-up the computation during training for convolutional neural networks working on images.	Review	O	0
[line_break_token]Essentially this is presented as a pure speed-up technique and doesn't change the learning algorithm, or (in an interesting way) the representation.	Review	O	0
[line_break_token][line_break_token]The idea of applying FFTs to speed up image processing systems, particularly 'sliding windows' systems, is far from new and there is a large literature on this.	Review	O	0
In particular combining FFTs with Neural networks is not new,[line_break_token]e.g. <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.1967" target="_blank" rel="nofollow">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.1967</a>[line_break_token]Some of this prior literature should be cited.	Review	O	0
[line_break_token][line_break_token]I am not aware of any work that applys the back-propagation in the Fourier domain too.	Review	O	0
[line_break_token][line_break_token]The resulting speed-ups are significant for the scenario the authors are considering, and it is useful to know that the practical implementation delivers these gains.	Review	O	0
As they conclude, these results may change the way such problems are formulated by removing the pressure to use small kernels.	Review	O	0
[line_break_token][line_break_token]Expand the caption for Figure 2.	Review	O	0
Total number of operations for what?	Review	O	0
[line_break_token][line_break_token]Figure 3 needs units for the y axis (text says seconds?),	Review	O	0
and for the x axes - ie areal or linear pixels?	Review	O	0
[line_break_token]Also for each of the 3 sets of graphs, there needs to be an indication of what are the values of the parameters which are  held constant.	Review	O	0
[line_break_token][line_break_token]Please say in the text that all 3 systems (Torch, Authors' and Krizhevsky) were running on the same (which?)	Review	O	0
GPU.	Review	O	0
[line_break_token][line_break_token]Citation for Cooley-Tukey FFT?	Review	O	0
Thank you for the feedback.	Reply	O	0
We posted an updated version of the paper which incorporates these changes	Reply	O	0

This paper presents an approach where the regularisation is used to optimise whether each layer of a DNN is binary or ternary.	Review	O	0
The paper presents an equation for performing this along with two examples of the process in use.	Review	O	0
[line_break_token][line_break_token]The paper is inconsistently written with work described at different levels in different sections and has an inconsistent feeling about it.	Review	O	0
For example the introduction seems to stop abruptly before it describes all the parts of the paper.	Review	O	0
[line_break_token][line_break_token]The paper seems to contain an idea which might have merit.	Review	O	0
However, the idea just does not seem to have been developed enough.	Review	O	0
[line_break_token][line_break_token]Major concerns:[line_break_token]1) The authors claim that this is the first attempt at a training algorithm for mixed precision training.	Review	O	0
However, a simple google search throws up many papers in this area.	Review	B-Review	1
Many of which are not mentioned in the related work.	Review	I-Review	1
[line_break_token][line_break_token]2) Equations are not discussed in enough detail, nor are the parameters defined.	Review	O	0
Or if they are defined they are done so much later in the work.	Review	B-Review	2
[line_break_token][line_break_token]3) There doesn‚Äôt seem to be enough material here to reproduce the work.	Review	O	0
[line_break_token][line_break_token]4) In the results you talk about ‚Äòthe best‚Äô.	Review	O	0
Given that there has been much criticism over the last two years about good academic practice the fact that you don‚Äôt say at least ‚Äòbest out of ‚Ä¶‚Äô is worrying.	Review	B-Review	4
[line_break_token][line_break_token]5) You have magic parameters lambda and gamma.	Review	O	0
You say that these effect the outcome of the work but in your examples you only state values these are set to.	Review	B-Review	5
One would expect to see at least some analysis of how varying these values effect the outcome.	Review	I-Review	5
But better would be to show that you have identified good values for both of these parameters.	Review	I-Review	5
Ideally would be an evaluation of how others could identify the best values.	Review	I-Review	5
[line_break_token][line_break_token]6) Figures 3 and 4 are difficult to interpret.	Review	O	0
They need a clear explanation.	Review	B-Review	6
[line_break_token][line_break_token]Some more generic comments:[line_break_token]- The abstract seems to assume a huge prior knowledge by the reader.	Review	I-Review	7
[line_break_token][line_break_token]- ‚Äò1 bit precision‚Äô - precision seems to have no meaning in this context.	Review	I-Review	7
Surely just ‚Äò1 bit‚Äô[line_break_token][line_break_token]- The related work contains a lot of equations, but no real explanation of what they are.	Review	I-Review	7
[line_break_token][line_break_token]- ‚Äòwe let Œ≤ very per layer‚Äô -&gt; ‚Äòwe let Œ≤ vary per layer‚Äô[line_break_token][line_break_token]- In equation 10 what do I and J represent?	Review	O	0
[line_break_token][line_break_token]- ‚Äô28 √ó 28 gray-scales images‚Äô -&gt; ‚Äô28 √ó 28 gray-scale images‚Äô[line_break_token][line_break_token]- ‚ÄòFor the training session, we pad the sides of the images with 4 pixels, then a 32 √ó 32 crop is sampled, and flipped horizontally at random.	Review	O	0
‚Äô - why?	Review	B-Review	7
[line_break_token][line_break_token]- ‚ÄòAs commonly practiced‚Äô - by whom?	Review	I-Review	7
[line_break_token][line_break_token]- ‚Äòwhich is costly, specially if‚Äô -&gt; ‚Äòwhich is costly, especially if‚Äô[line_break_token]	Review	O	0
)  We believe that the reviewer missed the main point of the paper here.	Reply	O	0
Most of the works that have been published on mixed precision training assumed that the quantization depth is known before training.	Reply	B-Reply	1
Other works that optimize quantization depth use a separate optimizer.	Reply	I-Reply	1
The novelty of our approach lies in the fact that the neural network learns quantization depth for each layer only by a modifed  back-propagation.	Reply	I-Reply	1
We modify back-propagation only by adding a regularization function, and this allows to train weights, and to estimate quantization depth simultaneously.	Reply	I-Reply	1
[line_break_token][line_break_token]2)  We will be looking at parameter definition and interpretation again.	Reply	O	0
We only introduced two new parameters gamma, and beta in which we provided interpretation.	Reply	B-Reply	2
 Other equations are only the definition of regularization function and they are discussed in detail in reference [16].[line_break_token][line_break_token]3) This is a high-level comment.	Reply	O	0
 We did our best to provide enough details to reproduce the work.	Reply	B-Reply	3
We can improve the descriptions if the missing points are pinpointed.	Reply	I-Reply	3
We provide a github code source after acceptance of the paper.	Reply	I-Reply	3
[line_break_token][line_break_token]4) We agree.	Reply	O	0
We must avoid using the word 'the best' in scientific articles as 'the best' may change through time.	Reply	B-Reply	4
We will correct this in the next version.	Reply	I-Reply	4
[line_break_token][line_break_token]5) We appreciate this detailed comment.	Reply	O	0
We will add some studies about varying lambda and gamma parameters in the next version, or on our github codes.	Reply	B-Reply	5
[line_break_token][line_break_token]6) The point of these figures is to see that the weights are indeed pushed on binary or ternary values depending on the shape parameter beta of the regularization function.	Reply	O	0
More clear explanations will be added in the next version of the paper, see reference [16].[line_break_token][line_break_token]Thanks for the generic comments.	Reply	O	0
They will be considered for the revised version	Reply	B-Reply	7

The paper presents an approach to efficiently implement planar and group convolutions over hexagonal lattices to leverage better accuracy of these operations due to reduced anisotropy.	Review	O	0
They show that convolutional neural networks thus built lead to better performance - reduced inductive bias - for the same parameter budget.	Review	O	0
[line_break_token][line_break_token]G-CNNs were introduced by Cohen and Welling in ICML, 2016.	Review	O	0
They proposed DNN layers that implemented equivariance to symmetry groups.	Review	O	0
They showed that group equivariant networks can lead to more effective weight sharing and hence more efficient networks as evinced by better performance on CIFAR10 & CIFAR10+ for the same parameter budget.	Review	O	0
This paper shows G-equivariance implemented on hexagonal lattices can lead to even more efficient networks.	Review	O	0
[line_break_token][line_break_token]The benefits of using hexagonal lattices over rectangular lattices is well known in the signal processing as well as in computer vision.	Review	B-Review	1
For example, see   [line_break_token][line_break_token]Golay M. Hexagonal parallel pattern transformation.	Review	I-Review	1
IEEE Transactions on Computers 1969.	Review	I-Review	1
18(8): p. 733-740.	Review	I-Review	1
[line_break_token][line_break_token]Staunton R. The design of hexagonal sampling structures for image digitization and their use with local operators.	Review	I-Review	1
Image and Vision Computing 1989.	Review	I-Review	1
7(3): p. 162-166.	Review	I-Review	1
[line_break_token][line_break_token]L. Middleton and J. Sivaswamy, Hexagonal Image Processing, Springer Verlag, London, 2005[line_break_token][line_break_token]The originality of the paper lies in the practical and efficient implementation of G-Conv layers.	Review	O	0
Group-equivariant DNNs could lead to more robust, efficient and (arguably) better performing neural networks.	Review	O	0
[line_break_token][line_break_token]Pros[line_break_token][line_break_token]- A good paper that systematically pushes the state of the art towards the design of invariant, efficient and better performing  DNNs with G-equivariant representations.	Review	O	0
[line_break_token][line_break_token]- It leverages upon the existing theory in a variety of areas - signal & image processing and machine learning, to design better DNNs.	Review	O	0
[line_break_token][line_break_token] - Experimental evaluation suffices for a proof of concept validation of the presented ideas.	Review	O	0
  [line_break_token][line_break_token] [line_break_token]Cons[line_break_token][line_break_token]- The authors should relate the paper better to existing works in the signal processing and vision literature.	Review	O	0
[line_break_token][line_break_token]- The results are on simple benchmarks like CIFAR-10.	Review	O	0
It is likely but not immediately apparent if the benefits scale to more complex problems.	Review	B-Review	3
[line_break_token][line_break_token]- Clarity could be improved in a few places[line_break_token][line_break_token]: Since * is used for a standard convolution operator, it might be useful to use *_g as a G-convolution operator.	Review	O	0
[line_break_token][line_break_token]: Strictly speaking, for translation equivariance, the shift should be cyclic etc.	Review	O	0
[line_break_token][line_break_token]: Spelling mistakes - authors should run a spellchecker.	Review	O	0
[line_break_token]	Review	O	0
Dear reviewer,[line_break_token][line_break_token]We thank you for your comments and suggestions.	Reply	O	0
[line_break_token][line_break_token]On hexagonal literature: [line_break_token]We agree that it is important to recognize existing work on hexagonal signal processing, and have added references by Petersen, Hartman and Middleton in the updated paper.	Reply	O	0
[line_break_token][line_break_token]On benefits to scaling:[line_break_token]We agree that CIFAR-10 is a relatively simple benchmark.	Reply	O	0
In our experiments we do show that an identical network architecture where conventional conv layers are replaced by hexagonal g-conv layers, results in consistent improvements on two distinct datasets.	Reply	B-Reply	3
Furthermore, we plan to release our codebase which can help further research to scale these methods to larger problems.	Reply	I-Reply	3
[line_break_token][line_break_token]On the group convolution operator:[line_break_token]We think it is a very good suggestion to change group convolution operators from * to *_g, to clarify what type of convolution is used.	Reply	I-Reply	4
We changed the relevant operators in the updated paper.	Reply	I-Reply	4
[line_break_token][line_break_token]On exact translation equivariance in CNNs: [line_break_token]We agree with the reviewer that in order for equivariance to hold exactly, either:[line_break_token]shifts should be cyclic, or[line_break_token]One should use ‚Äúvalid‚Äù-mode convolutions and consider the input image as a function defined on all of Z^2, where values outside of the original image are zero.	Reply	O	0
[line_break_token]In practice, we use ‚Äúsame‚Äù convolution instead of ‚Äúvalid‚Äù convolution, because the latter would increase the size of the feature maps with each layer.	Reply	B-Reply	4
Thus, a typical convolutional network is not exactly translation equivariant.	Reply	I-Reply	4
We have added a footnote that addresses this detail.	Reply	I-Reply	4
[line_break_token][line_break_token]On spellchecking:[line_break_token]We have run a spellchecker and fixed the spelling mistakes.	Reply	O	0

I find this paper not very compelling.	Review	O	0
 The basic idea seems to be that we can put a fast neighbor searcher into a memory augmented net to make the memory lookups scalable.	Review	O	0
 However, this was precisely the point of Rae et al.	Review	B-Review	1
   There are a  number of standardized neighbor searchers; I don't understand why the authors choose to use their own (which they do not benchmark against the standards).	Review	O	0
  Moreover, they test on a problem where there is no clear need for (vector based) fast-nn, because one can use hashing on the text.	Review	O	0
    I also find the repeated distinction between "mips" and "nns" distracting; most libraries that can do one can do the other, or inputs can be modified  to switch between the problems; indeed the authors do this when they convert to the  "mcss" problem.	Review	B-Review	4
[line_break_token]	Review	O	0
Thanks for your valuable feedback.	Reply	O	0
[line_break_token][line_break_token]> The basic idea seems to be that we can put a fast neighbor searcher into a memory augmented net to make the memory lookups scalable.	Reply	O	0
However, this was precisely the point of Rae et al.	Reply	O	0
[line_break_token][line_break_token]You are correct that the basic idea is to use fast nearest neighbor search and do k-softmax instead of softmax for memory access.	Reply	B-Reply	1
This can be considered as a way of hard attention followed by soft attention and the whole process is still differentiable.	Reply	I-Reply	1
While this is precisely the point of Rae et al.,	Reply	I-Reply	1
2016, we would like to highlight the fact that our work and Rae et al.	Reply	I-Reply	1
‚Äôs work happened around same time independently.	Reply	I-Reply	1
In fact, our arxiv version predates that of Rae et al.	Reply	I-Reply	1
So we feel that it is not fair to discard the main contributions of this paper since it has been proposed in parallel in another independent paper.	Reply	I-Reply	1
[line_break_token][line_break_token]> There are a number of standardized neighbor searchers; I don't understand why the authors choose to use their own (which they do not benchmark against the standards).	Reply	O	0
[line_break_token][line_break_token]While there are several commonly used nearest neighbor searchers like FLANN, we would like to highlight that we have used recent state-of-the-art methods for maximum inner product search.	Reply	B-Reply	2
We chose three algorithms k-means clustering, PCA-Tree, and WTA-Hash each being the current state-of-the-art clustering-based, tree-based, and hashing-based approaches for MIPS respectively.	Reply	I-Reply	2
These have already been benchmarked against standard libraries and hence state-of-the-art.	Reply	I-Reply	2
[line_break_token][line_break_token]> Moreover, they test on a problem where there is no clear need for (vector based) fast-nn, because one can use hashing on the text.	Reply	O	0
[line_break_token][line_break_token]We agree that simple-questions is not a suitable problem for the proposed model.	Reply	B-Reply	3
We in fact state this in the paper and mention that we use this task mainly for demonstration purpose and acknowledge that keyword hashing based approach would perform much better in this task.	Reply	I-Reply	3
Our goal is to design a general memory access mechanism which does not take into account any dataset specific priors (like keyword hashing).	Reply	I-Reply	3
[line_break_token][line_break_token]> I also find the repeated distinction between "mips" and "nns" distracting; most libraries that can do one can do the other, or inputs can be modified to switch between the problems; indeed the authors do this when they convert to the "mcss" problem.	Reply	O	0
[line_break_token][line_break_token]Thanks for this feedback.	Reply	B-Reply	4
We will fix this issue.	Reply	I-Reply	4

This paper adds a spatial regularization loss to the well-known CycleGAN loss for unpaired image-to-image translation (Zhu et al.,	Review	B-Review	1
ICCV17).	Review	I-Review	1
 Essentially, the regularization loss (Eq.	Review	I-Review	1
6) is similar to imposing a CRF (Conditional Random Field) term on the network outputs, encouraging spatial consistency between patches within each generated image.	Review	I-Review	1
[line_break_token][line_break_token]The paper is clear and well written.	Review	I-Review	1
[line_break_token][line_break_token]Unpaired Image-to-Image translation is an important problem.	Review	I-Review	1
[line_break_token][line_break_token]The way the smoothness loss (Eq.	Review	I-Review	1
6) is presented gives readers the impression that spatial pairwise regularization is new, ignoring its long history (e.g., CRFs) in computer vision (not a single classical paper on CRFs is cited).	Review	I-Review	1
Putting aside classical spatial regularization works, imposing pairwise regularization on the outputs of modern deep networks has been investigated in a very large number of works recently, particularly in the context of weakly-supervised semantic CNN segmentation, e.g.,  [Tang et al.,	Review	I-Review	1
On Regularized Losses for Weakly-supervised CNN Segmentation, ECCV 18 ], [Lin et al. :	Review	I-Review	1
Scribblesup: Scribble-supervised convolutional networks for semantic segmentation, CVPR 2016], among  many other works.	Review	I-Review	1
Very similar in spirit to this ICLR submission, these works impose within-image pairwise regularization (e.g., CRF) on the latent outputs of deep networks, with the main difference that these works use CNN semantic segmentation classifiers whereas here we have a CycleGAN for image generation.	Review	I-Review	1
[line_break_token][line_break_token]Also, in the context of supervised CNN segmentation, CRFs have made a significant impact when used as post-processing step, e.g., very well known works such as [DeepLab by Chen et al.	Review	I-Review	1
ICLR15] and [CRFs as recurrent Neural Networks by Zheng et al.,	Review	I-Review	1
ICCV 2015]. [line_break_token][line_break_token]It might be a valid contribution to evaluate spatial regularization (e.g., CRFs losses) on image generation tasks (such as CycleGAN), but the paper really needs to acknowledge very related prior works on regularization (at least in the context of deep networks).	Review	I-Review	1
[line_break_token][line_break_token]There are also related pioneering semi-supervised deep learning works based on graph Laplacian regularization, e.g., [Westen et al.,	Review	I-Review	1
Deep Learning via Semi-supervised embedding, ICML 2008], which the paper does not acknowledge/discuss.	Review	I-Review	1
[line_break_token][line_break_token]The manifold regularization terminology is misleading.	Review	I-Review	1
The regularization is not over the feature space of image samples.	Review	I-Review	1
It is within the spatial domain of each generated image (patch or pixel level); so, in my opinion, CRF (or spatial) regularization (instead of manifold regularization) is a much more appropriate terminology.	Review	I-Review	1
[line_break_token][line_break_token]Also, I would not call this approach HarmonicGan.	Review	O	0
I would call it CRF-GAN or Spatially-Regularized GAN.	Review	O	0
The computation of harmonic functions is just one way, among many other (potentially better) ways to optimize pairwise smoothness terms (including the case of the used smoothness loss).	Review	O	0
And, by the way, I did not get how the loss in (9) gives a harmonic function.	Review	O	0
Could you please clarify and give more details?	Review	O	0
In my understanding, the harmonic solution in [ Zhu and Ghahramani, ICML 2013] comes directly as a solution of the graph Laplacian (and it assumes some labeled points, i.e., a semi-supervised setting).	Review	O	0
Even, if the solution is correct (which I do not see how), I do not think it is an efficient way to handle pairwise-regularization problems in image processing, particularly when matrix  W = [w_{ij}] is dense (which might be the case here, unless you are truncating the Gaussian kernel with some heuristics).	Review	O	0
In this case, back-propagating the proposed loss would be of quadratic complexity w.r.t the number of image patches.	Review	O	0
Again, there is a long tradition in optimizing efficiently pairwise regularizers in vision/learning (even in the case of dense affinity matrices), and one very well-known work, which is currently being used a lot in the context imposing CRF structure on the outputs of deep networks, is  [Krahenbuhl and Koltun, Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials], NIPS 2011.	Review	O	0
This highly related and widely used inference work for dense pairwise regulation is not cited/discussed neither.	Review	O	0
The Gaussian filtering ideas of the work of Krahenbuhl and Koltun, which ease optimizing dense pairwise terms (from quadratic to linear) are applicable here (as a Gaussian kernel is used), and are widely used in computer vision, including closely related works imposing spatial regularization losses on the outputs of deep networks, e.g., [Tang et al.,	Review	O	0
On Regularized Losses for Weakly-supervised CNN Segmentation, ECCV 18], among many others.	Review	O	0
 [line_break_token]  [line_break_token]When using feature from pre-training (VGG) in the CRF loss, the comparison with unsupervised CycleGAN is not fair.	Review	O	0
In Table 2 (Label translation on Cityscapes), CycleGAN outperforms the proposed method in all metrics when only unsupervised histogram features are used, which makes me doubt about the practical value of the proposed regularization in the context of image-translation tasks.	Review	B-Review	2
Having said that, the histogram-based regularization is helping in the medical-imaging application (Table 1).	Review	I-Review	2
By the way, the use of histograms (of patches or super-pixels) as unsupervised features in pairwise regularization is not new neither; see for instance [Lin et al.:	Review	I-Review	2
Scribblesup: Scribble-supervised convolutional networks for semantic segmentation, CVPR 2016]. Also, it might be better to use super-pixels instead of patches.	Review	I-Review	2
[line_break_token][line_break_token]So, in summary, the technical contribution is minor, in my opinion (imposing pairwise regularization on the outputs of deep networks has been done in many works, but not for CycleGAN); optimization of the proposed loss as a harmonic function is not clear to me; using VGG in the comparisons with CycleGAN is not fair; and the long history of closely-related spatial regularization terms (e.g., CRFs) in computer vision is completely ignored.	Review	I-Review	3
[line_break_token][line_break_token]Minor: please use ‚Äòterm‚Äô instead of ‚Äòconstraint‚Äô.	Review	I-Review	4
These are unconstrained optimization problems and there are no equality or inequality constraints here.	Review	I-Review	4
   [line_break_token][line_break_token]	Review	O	0
Q1: This paper adds a spatial regularization loss to the well-known CycleGAN loss for unpaired image-to-image translation (Zhu et al.,	Reply	O	0
ICCV17).	Reply	O	0
 Essentially, the regularization loss (Eq.	Reply	O	0
6) is similar to imposing a CRF (Conditional Random Field) term on the network outputs, encouraging spatial consistency between patches within each generated image.	Reply	O	0
Imposing pairwise regularization on the outputs of modern deep networks has been investigated in a very large number of works recently, particularly in the context of weakly-supervised and supervised CNN segmentation, e.g., Tang et al.,	Reply	O	0
ECCV 18 , Lin et al.	Reply	O	0
CVPR 2016, Chen et al.	Reply	O	0
ICLR 2015 and Zheng et al.,	Reply	O	0
ICCV 2015.	Reply	O	0
Very similar in spirit to this ICLR submission, these works impose within-image pairwise regularization (e.g., CRF) on the latent outputs of deep networks, with the main difference that these works use CNN semantic segmentation classifiers whereas here we have a CycleGAN for image generation.	Reply	O	0
The manifold regularization terminology is misleading.	Reply	O	0
The regularization is not over the feature space of image samples.	Reply	O	0
It is within the spatial domain of each generated image (patch or pixel level); so, in my opinion, CRF (or spatial) regularization (instead of manifold regularization) is a much more appropriate terminology.	Reply	O	0
[line_break_token][line_break_token]A1: There are some fundamental differences between the CRF literature and our work.	Reply	O	0
They differ in output space, mathematical formulation, application domain, effectiveness, and the role in the overall algorithm.	Reply	B-Reply	1
The similarity between CRF and HarmonicGAN lies the adoption of a regularization term: a binary term in the CRF case and a Laplacian term in HarmonicGAN.	Reply	I-Reply	1
The differences are detailed below:[line_break_token][line_break_token]1.	Reply	I-Reply	1
Label space vs. feature space[line_break_token]The key difference is the explicit graph Laplacian adopted in HarmonicGAN on vectorized representation on all pairs vs. a binary term for the neighboring labels on the scalar representation.	Reply	I-Reply	1
[line_break_token][line_break_token]HarmonicGAN is indeed formulated in the feature space, not just limited to patches within the single image.	Reply	I-Reply	1
The CycleGAN implementation by Zhu et al.	Reply	I-Reply	1
happens to include one image only in a batch for computational reason.	Reply	I-Reply	1
We follow the standard pipeline of CycleGAN in HarmonicGAN and might have created a confusion here.	Reply	I-Reply	1
The description has been clarified in the revised text and we have added citations to the mentioned papers.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Mathematical formulation[line_break_token][line_break_token]When learning a CRF model, the objective function often combines a unary term and binary term to minimize[line_break_token]\arg \min_{w,a} - \sum_{i} \log p(y_i|X_i; w) +  \sum_{(i,j) \in Neighborhood} a \log p(y_i, y_j|X_i, X_j; w)[line_break_token]where w and a are the parameters in CRF to be learned, and y_i and y_i are SCALAR \in {1,...,k} for k-class labels.	Reply	O	0
[line_break_token]For HarmonicGAN, the objective function includes bidirectional translation having the unary term (CycleGAN loss) and binary term.	Reply	B-Reply	1
For simplicity we can look at one direction only:[line_break_token]\arg \min_{G,F}  \sum_{i} |F(G(X))_i, x_i| +  \sum_{i,j \in ImageLattice} w_{ij} Dist[F(y)(i), F(y)(j)][line_break_token]where w_{i,j} defines the similarity measure and F(y)(i) computes a feature VECTOR center at i.[line_break_token]The key difference lies in the explicit graph Laplacian defined with w_{ij} for Dist[F(y)(i), F(y)(j)] for all pairs whereas p(y_i, y_j|X_i, X_j; w) is a joint probability for the neighboring pixels i and j.[line_break_token]In both supervised CRF or weakly-supervised CRF, y_i and y_j are scalars, which are not applicable to the general image translation task for non-labeling tasks since the feature vector space is too high for CRF to model.	Reply	I-Reply	1
In addition, the graph Laplacian term in HarmonicGAN is explicitly modeled, which is very different from a joint probability model on the labels (scalar) for the neighboring pixels.	Reply	I-Reply	1
It is true that HarmonicGAN adopts a smoothness term but so do semi-supervised learning, manifold learning, Markov Random Fields, spectral clustering and normalized cuts, and Laplacian eigenmaps.	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
Application domain[line_break_token]CFR models are used in supervised and weakly-supervised image labeling task but HarmonicGAN, like CycleGAN, is applied to the generic image translation tasks where the output is beyond image labels.	Reply	O	0
The reason we show the result on Cityscapes here is twofold: (1) it is shown in the original CyceleGAN paper and we want to have a direct comparison with, and (2) the labeling result can have a quantitative measures since the ground-truth labels are available.	Reply	B-Reply	1
The family of unpaired image translation tasks can be quite broad, as seen in a number of applications following CycleGAN.	Reply	I-Reply	1
[line_break_token][line_break_token](continued below	Reply	O	0

The authors propose a clustering approach for time series that encourages instances with similar time profiles to be clustered together.	Review	O	0
The approach consists of three modules: an encoder, a cluster assigner and a (future outcome) predictor, all specified as neural networks.	Review	O	0
[line_break_token][line_break_token]The objective of the model is to produce cluster embeddings that are as informative of the outcomes as possible, while not being a direct function of covariates.	Review	B-Review	1
Note that (2) may look misleading because it indicates that the outcome is a function of the cluster assignment, however, it does not show that the assignment is indeed a function of the covariates.	Review	I-Review	1
[line_break_token][line_break_token]It is not entirely clear how a patient is assigned to a cluster provided that cluster assignments are a function of time.	Review	I-Review	2
[line_break_token][line_break_token]It is desirable that performance metrics do not seem affected by the unknown number of clusters, however, this makes for difficult to interpret clusters.	Review	I-Review	3
More so in practice when the number of identified clusters is a function of the model architecture and hyperparameters (\alpha and \beta).	Review	I-Review	3
Is the number of clusters selected by cross-validation and if so, what performance metric is used to select the best choice?	Review	I-Review	3
[line_break_token][line_break_token]In Table 3 for UKCF with 3 comorbidities, how are AUROC and AUPRC evaluated provided these are binary predictions?	Review	I-Review	4
e thank the reviewer for the valuable comments.	Reply	O	0
[line_break_token][line_break_token]A1.	Reply	O	0
In the probabilistic definition of the KL-divergence in (2), it is not necessary to explicitly denote the dependency between (i.e., the random variable for cluster assignment at time) and (i.e., the random variable for the input subsequence at time).	Reply	B-Reply	1
Instead, the dependency between the random variables is further specified in (3) in terms of their realizations.	Reply	I-Reply	1
More specifically, in (3) is a function of that is drawn from a categorical distribution whose probability of each category is defined as a function of the input subsequence.	Reply	I-Reply	1
In the revised manuscript, we will clarify the description of the dependency between the two random variables in (2).	Reply	I-Reply	1
[line_break_token][line_break_token]A2.	Reply	O	0
For a run-time (testing) example, suppose that we have a new patient whose time-series observations are given as.	Reply	B-Reply	2
Then, our method assigns cluster to this patient based on the input sequence.	Reply	I-Reply	2
When a new observation on this patient is collected at time, we can update the cluster assignment of this patient to given the input sequence.	Reply	I-Reply	2
[line_break_token][line_break_token]A3.	Reply	O	0
We selected the hyperparameters of our network that give the minimum validation loss in (3).	Reply	B-Reply	3
It is worth highlighting that, given the hyperparameters selected, our method identifies the number of clusters in a data-driven fashion; please refer to A2 to Reviewer #1 to see how the identified number of clusters remains consistent throughout different.	Reply	I-Reply	3
We will clarify this in the revised manuscript.	Reply	I-Reply	3
[line_break_token][line_break_token]A4.	Reply	O	0
In the experiments, we know the ground-truth binary labels of the future outcomes of interest (that is, development of diabetes, ABPA, and intestinal obstruction).	Reply	B-Reply	4
Thus, we can simply compute AUROC and AUPRC using the cluster-wise outcome predictions (i.e.,) and the outcome labels (i.e.,).	Reply	I-Reply	4
The AUROC and AURPC reported in Table 2 are averaged over the three comorbidities.	Reply	I-Reply	4
Similarly, the ground-truth cluster label can be computed as a combination of the three binary outcome labels which makes as described in Section 5.4.	Reply	I-Reply	4
We will clarify the description in the revised manuscript.	Reply	I-Reply	4

This paper defines a goodness of fit measure F for generative networks, that reflects how well a model can generate the training data.	Review	O	0
F allows to detect mode collapse: as long as it is strictly positive, mode collapse is observed as parts of the training data have not been memorized.	Review	O	0
It aims at providing an alternative to the Fr√©chet Inception Distance and the Inception Score that rely on pretrained neural networks (whereas this new measure does not).	Review	O	0
It also provides insight into the DCGAN and WGAN networks in that regard, observing for instance that data subsampling helps decrease F, which motivates the use of a mixture of GANs.	Review	O	0
[line_break_token][line_break_token]This paper brings an interesting contribution to the evaluation of generative networks.	Review	O	0
However:[line_break_token][line_break_token]1.	Review	O	0
[tab_token]The use of the square distance in the image space is not obvious and not justified.	Review	O	0
[line_break_token]2.	Review	O	0
[tab_token]Computation of this metric is not straightforward: there is no theoretical guarantee and it is computationally expensive.	Review	B-Review	2
[line_break_token]3.	Review	O	0
[tab_token]The theoretical properties of this measure and its robustness are not investigated.	Review	B-Review	3
[line_break_token]4.	Review	O	0
[tab_token]Typos are obscuring the reading of the paper.	Review	O	0
[line_break_token][line_break_token]- Post rebuttal: I have read the authors' response and am maintaining my weak reject rating.	Review	O	0
hank you for the feedback on our paper.	Reply	O	0
We address your concerns as follows:[line_break_token][line_break_token]1.	Reply	O	0
Defining a metric between images is a long-standing problem in image processing, because standard p-norms do not capture image structure well.	Reply	B-Reply	1
We use squared distance (2-norm) because it has a long history in not only signal and image processing but beyond.	Reply	I-Reply	1
Nevertheless, other metrics can be used within our framework if there is prior information that implies that a particular metric would be superior to others.	Reply	I-Reply	1
For this reason, we do not claim that the 2-norm is optimal for images.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
We follow standard methods for optimizing over the latent space of a generative network such those from the GLO paper.	Reply	B-Reply	2
This enables us to have a certain confidence in the optimization problem because this method ‚Äú... recovers the true latent vector 100% of the time to arbitrary precision.	Reply	I-Reply	2
‚Äù [1] Although, this is not theoretical guarantees, their empirical performance is a convincing argument for why they should be used for calculating F in practice.	Reply	I-Reply	2
Developing theoretical guarantees for this nonconvex optimization problem is beyond the scope of this paper and would be an interesting paper by itself.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
The robustness of calculating F is measured with different initializations as shown in Figure 6.	Reply	B-Reply	3
If we optimize over the latent space with different initial distributions of z, we find that the statistics of the solution z* are the same.	Reply	I-Reply	3
Hence, the calculation of F is robust to different initial distributions of z, which means that even unlikely z‚Äôs will converge to a z* that has typical statistics.	Reply	I-Reply	3
[line_break_token][line_break_token]Let us know if you have any further concerns about our paper, and thank you for the helpful feedback.	Reply	O	0
[line_break_token][line_break_token][1] Zachary C Lipton and Subarna Tripathi.	Reply	O	0
 Precise recovery of latent vectors from generative adversarial networks.	Reply	O	0
arXiv preprint arXiv:1702.04782, 2017	Reply	O	0

In this paper, authors propose a way to speed up the computation of GNN.	Review	O	0
More specifically, the hierarchically aggregate computation graphs are proposed to aggregate the intermediate node and utilize this to speed up a GNN computation.	Review	O	0
Authors proof that the computation based on HAGs are equivalent to the vanilla computation of GNN (Theorem1).	Review	O	0
Moreover, for sequential aggregation, it can find a HAG that is at least (1-1/e)-approximation of the globally optimal HAGs (Theorem 3).	Review	O	0
These theoretical results are nice.	Review	O	0
Through experiments, the authors demonstrate that the proposed method can get faster computation than vanilla algorithms.	Review	O	0
[line_break_token][line_break_token]The paper is clearly written and easy to follow.	Review	O	0
However, there are some missing piece needed to be addressed.	Review	O	0
[line_break_token]I put 6 (weak accept), since we cannot put 5.	Review	O	0
However, current my intention about the score is slightly above 5.	Review	O	0
[line_break_token][line_break_token]Detailed comments:[line_break_token]1.	Review	O	0
Experiments are only done for computational time comparison.	Review	B-Review	1
In particular, for the sequential one, prediction accuracy can be changed due to the aggregation algorithm.	Review	I-Review	1
Thus, it needs to report the prediction accuracy.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
In GraphSAGE, what is the sampling rate?	Review	B-Review	2
It would be nice to have the trade-off between the sampling rate and the speedup.	Review	I-Review	2
I guess if we sample small number of points in GraphSAGE, the performance can be degraded.	Review	I-Review	2
In contrast, the proposed algorithm can get similar performance with larger sampling rate?	Review	I-Review	2
Related to the question 1, the performance comparison is needed.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Equations are used without not explaining the meaning.	Review	B-Review	3
For instance AGGREGATE function (1), there is no definition how to aggregate.	Review	I-Review	3
[line_break_token]	Review	O	0
e thank the reviewer for a thorough review and valuable questions.	Reply	O	0
The reviewer has concerns about (1) how HAG affects model accuracy and (2) how sampling rate affects the runtime performance.	Reply	O	0
We believe there are a few important misunderstandings, which we address in detail in our response below.	Reply	O	0
We have also updated the paper to further clarify and emphasize these points.	Reply	O	0
[line_break_token][line_break_token]### Need to report the model accuracy[line_break_token]The HAG graph representation achieves the same training and test results as the original GNN-graph representation for each GNN model, even though GNN models with different aggregation methods (i.e., set v.s.	Reply	O	0
sequential) may obtain different accuracy--- this issue is orthogonal to the HAG optimizations.	Reply	B-Reply	1
[line_break_token][line_break_token]Theorem 1 in the paper proves the equivalence of HAG and GNN-graph representations for both training and inference.	Reply	I-Reply	1
This means that HAG performs exactly the same computations as the traditional model training/inference but in a non-redundant way.	Reply	I-Reply	1
This means, that HAG obtains exactly the same model as traditional training (but HAG is much faster).	Reply	I-Reply	1
[line_break_token][line_break_token]To address reviewer‚Äôs comment we have added an experiment to evaluate the training effectiveness of HAG (Figure 6 on page 13), which compares the time-to-accuracy performance between original GNN-graph representation and HAG, and show that HAG can reduce the training time by 1.8x while obtaining the same model accuracy.	Reply	I-Reply	1
[line_break_token][line_break_token]### What is the trade-off between the sampling rate and the speedup[line_break_token]We think there is a misunderstanding here.	Reply	O	0
The reviewer seems to assume that HAG is designed for mini-batch training, probably because we use GraphSAGE as an example to demonstrate different aggregation functions in Table 1.	Reply	B-Reply	2
In fact, HAG is designed for full-batch training, which is also the training method used in most existing GNN models, including GCN (Kipf &amp; Welling, 2016), GIN (Xu et al.,	Reply	O	0
2019), and SGC (Wu et al.,	Reply	B-Reply	2
2019).	Reply	I-Reply	2
We will fix this confusion by emphasizing the full-batch training setting in the introduction and use other GNN models (with full-batch training) as examples in Table 1.	Reply	I-Reply	2
[line_break_token][line_break_token]### Equations are used without explaining the meaning (e.g., AGGREGATE in Equation (1)) [line_break_token]We apologize for the missing explanation in the equations.	Reply	O	0
The AGGREGATE in Equation (1) can be arbitrary associative and commutative operations performed on a set (i.e., invariant to the order in which the aggregations are performed).	Reply	B-Reply	3
We have updated the paper to clarify this.	Reply	I-Reply	3

The authors investigate meta-learning in reinforcement learning with respect to sample efficiency and the necessity of meta-learning an adaptation scheme.	Review	O	0
Based on their findings, they propose a new algorithm 'MQL' (Meta-Q-Learning) that is off-policy and has a fixed adaptation scheme but is still competitive on meta-RL benchmarks (a distribution of environments that differ slightly in their reward functions).	Review	O	0
[line_break_token][line_break_token]They motivate the paper by data-inefficiency of current meta-learning approaches and empirical results suggesting that meta-learning the adaptation scheme is less important than feature reuse.	Review	O	0
[line_break_token][line_break_token]On the other hand, their introduction section would benefit from additional references to the kind of meta-learning they describe.	Review	B-Review	1
In particular, their so-called "definition of meta-learning" is mostly about domain randomization (e.g. Tobin et al.	Review	I-Review	1
2017 <a href="https://arxiv.org/abs/1703.06907)" target="_blank" rel="nofollow">https://arxiv.org/abs/1703.06907)</a> and not about the broader 'learning to learn' RL methodology (in particular Schmidhuber 1994 "On learning how to learn learning strategies").	Review	O	0
[line_break_token][line_break_token]**The authors make the following contributions:**[line_break_token][line_break_token]1.	Review	O	0
They show that Q-Learning trained on multiple tasks with a context variable as an input (an RNN state summarizing previous transitions) is competitive to related work when evaluated on a test task even though no adaptation is performed[line_break_token][line_break_token]2.	Review	O	0
Based on these observations, they introduce a new method for off-policy RL that does not directly optimize for adaptation but instead uses a fixed adaptation scheme[line_break_token][line_break_token]3.	Review	O	0
The new method leverages data during meta-testing that was collected during meta-training using importance weights for increased sample efficiency[line_break_token][line_break_token]**Overall, we believe the contributions are significant and sufficiently empirically justified.**	Review	O	0
[line_break_token][line_break_token]There are strong similarities, however, to parallel work on analyzing whether MAML relies on feature reuse or rapid learning (Raghu et al.	Review	B-Review	2
2019 <a href="https://arxiv.org/abs/1909.09157)."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1909.09157).</a>[line_break_token][line_break_token]This work and the present submission conclude that feature reuse is much more significant than meta-learning an adaptation scheme when evaluated on current meta-RL benchmarks.	Review	O	0
This is a significant result and supports the new method developed in this paper.	Review	B-Review	2
[line_break_token][line_break_token]During meta-training, their proposed method maximizes only the average return across tasks, not the ability to adapt from the resulting parameters.	Review	I-Review	2
[line_break_token][line_break_token]Their method introduces a fixed (non-learned) adaptation scheme that performs favorably compared to certain methods from the existing meta-learning literature and demonstrates that even dropping this adaptation still does well.	Review	I-Review	2
[line_break_token][line_break_token]There are strong similarities to Nichol et al.	Review	I-Review	2
2018 (<a href="https://arxiv.org/abs/1803.02999)."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1803.02999).</a> We encourage the authors to relate this work to Raghu et al.	Review	O	0
2019 and Nichol et al.	Review	B-Review	2
2018.	Review	I-Review	2
[line_break_token][line_break_token]**Despite these interesting results, we strongly disagree with the meta-learning narrative of their new method.**	Review	I-Review	2
[line_break_token][line_break_token]Because the adaptation scheme is no longer optimized directly, instead a fixed adaptation scheme is assumed, hence the approach in this paper is no longer a meta-learning algorithm.	Review	I-Review	2
[line_break_token][line_break_token]Instead, this method has strong similarities with transfer-learning and domain adaptation (first training on one distribution of tasks, then fine-tuning on another task).	Review	I-Review	2
[line_break_token][line_break_token]The authors should discuss the links to these fields of research, and clarify what's really novel, already in the abstract.	Review	I-Review	2
[line_break_token][line_break_token]For example, on page 2 the authors claim that optimizing the multi-task objective (the mean error across tasks) is the simplest form of meta-learning.	Review	I-Review	2
This objective, however, is NOT meta-learning.	Review	I-Review	2
[line_break_token][line_break_token]**Decision.**	Review	O	0
[line_break_token][line_break_token]The submission contains strong empirical results emphasizing the significance of feature reuse and the insignificance of learned adaptation on the tested meta-RL benchmarks.	Review	O	0
[line_break_token][line_break_token]The reuse of experience from meta-training during meta-testing by employing importance weights is also an interesting contribution.	Review	O	0
[line_break_token][line_break_token]In contrast, we are not satisfied with the presentation of their new approach as a meta-learning approach.	Review	B-Review	2
This method should be introduced along the lines of: 'Transfer Learning / Feature Reuse in RL is competitive to meta-learning across similar tasks'.	Review	I-Review	2
[line_break_token][line_break_token]In its current form, we tend to reject the paper because it further obscures what the term meta-learning refers to.	Review	I-Review	2
The authors are confusing it with more limited transfer learning.	Review	I-Review	2
[line_break_token][line_break_token]Additionally, it was not clear to us whether the quadratic penalty they add to their adaptation scheme is only empirically valid or whether there is a theoretical reason.	Review	I-Review	3
[line_break_token][line_break_token]For now, we'd lean towards rejecting this submission, but we might change our minds, provided the comments above were addressed in a satisfactory way - let us wait for the rebuttal.	Review	O	0
[line_break_token][line_break_token]Edit after rebuttal: score increased!	Review	O	0
hank you for your feedback.	Reply	O	0
Please also see the main comment above.	Reply	O	0
The reviewer says, ‚Äúthe contributions of this paper are significant and sufficiently empirically justified‚Äù, ‚Äúthe submission contains strong empirical results emphasizing the significance of feature reuse and the insignificance of learned adaptation on the tested meta-RL benchmarks.	Reply	O	0
‚Äù, ‚ÄúThis is a significant result and supports the new method developed in this paper.	Reply	O	0
‚Äù.	Reply	B-Reply	1
We are extremely puzzled at the low score.	Reply	O	0
We hope you will consider increasing your score after seeing our response.	Reply	O	0
[line_break_token][line_break_token][line_break_token]&gt;&gt; ‚Äúdefinition of meta-learning" is mostly about domain randomization‚Äù, ‚Äúwe are not satisfied with the presentation of their new approach as a meta-learning approach.	Reply	O	0
This method should be introduced along the lines of: 'Transfer Learning / Feature Reuse in RL is competitive to meta-learning across similar tasks‚Äù, ‚ÄúDespite these interesting results, we strongly disagree with the meta-learning narrative of their new method‚Äù, ‚Äúwe tend to reject the paper because it further obscures what the term meta-learning refers to.	Reply	O	0
The authors are confusing it with more limited transfer learning.	Reply	O	0
‚Äù[line_break_token][line_break_token]A meta-learner is an algorithm that has improved efficiency (statistically or computationally) of learning a new task by virtue of having seen related tasks in the past.	Reply	O	0
This is the definition in "On learning how to learn learning strategies" by Schmidhuber 1994, ‚ÄúIs learning the n^th thing any easier than learning the first?‚Äù by Thrun 1996 , ‚ÄúLearning to learn‚Äù by Thrun &amp; Pratt 1996, etc.	Reply	O	0
The improved efficiency of a meta-learner can be the result of two things: (i) a better prior (‚Äúshift its inductive bias‚Äù as Schmidhuber 1994 notes), or (ii) a better learning procedure that starts from the same prior, e.g., ‚ÄúOn the optimization of a synaptic learning rule‚Äù by Bengio et al.,	Reply	B-Reply	1
1992 or ‚ÄúMeta-Learning with Differentiable Convex Optimization‚Äù by Lee et al.,	Reply	I-Reply	1
2019.	Reply	I-Reply	1
The two notions of meta-learning above are complementary to each other and in fact, most recent literature using deep neural networks, e.g., MAML by Finn et al.,	Reply	I-Reply	1
2017, Prototypical Networks by Snell et al.,	Reply	I-Reply	1
2017 etc.	Reply	I-Reply	1
confirms to the first notion of building a better prior.	Reply	I-Reply	1
[line_break_token][line_break_token]Our definition of meta-learning is (i).	Reply	I-Reply	1
The reviewer notes that ‚Äúadaptation scheme is no longer optimized directly‚Äù.	Reply	I-Reply	1
And this is one key point of our paper.	Reply	I-Reply	1
We perform multi-task learning at training time to learn a better prior for adaptation.	Reply	I-Reply	1
More the number of training tasks better the prior and more sample efficient the adaptation.	Reply	I-Reply	1
[line_break_token][line_break_token]The current literature lacks a mathematically rigorous definition of meta-learning and we take the reviewer‚Äôs concerns in the right spirit.	Reply	I-Reply	1
We have added the above comments to the related work in Section 4.4.	Reply	I-Reply	1
[line_break_token][line_break_token]We are at a loss at the connection of other concepts in machine learning with meta-learning by the reviewer.	Reply	I-Reply	1
Domain randomization is a data augmentation technique, it is not meta-learning.	Reply	I-Reply	1
Transfer Learning only adapts from one source task to another target task, it does not start from a family of training tasks; it is not meta-learning.	Reply	I-Reply	1
We do not perform feature reuse in MQL: we update the entire policy using both data from the new task and the meta-training tasks.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt;&gt; During meta-training, their proposed method maximizes only the average return across tasks, not the ability to adapt from the resulting parameters.	Reply	O	0
For example, on page 2 the authors claim that optimizing the multi-task objective (the mean error across tasks) is the simplest form of meta-learning.	Reply	O	0
This objective, however, is NOT meta-learning.	Reply	O	0
[line_break_token]This is a key point of our paper.	Reply	B-Reply	2
Indeed, we perform multi-task learning at training time.	Reply	I-Reply	2
We do not train for the ability to adapt the parameters.	Reply	I-Reply	2
We instead learn a better prior for adaptation.	Reply	I-Reply	2
The multi-task objective is the simplest possible instantiation of meta-training, as suggested by the notion (i) in the previous remark because it provides a better prior than initializing the weights randomly before adaptation.	Reply	I-Reply	2
More the number of tasks during training time better the multi-task learnt prior.	Reply	I-Reply	2
The procedure is also similar to an existing state-of-the-art algorithm meta-learning named PEARL (‚ÄúEfficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables‚Äù by Rakelly et al.,	Reply	I-Reply	2
2019) which trains a value function conditioned on a probabilistic context variable on all the training tasks.	Reply	I-Reply	2
[line_break_token]	Reply	O	0

The overall goal of the paper is to make end-to-end dialogue systems more empathetic, so that they can respond more appropriately and in ways that acknowledge how the users are feeling.	Review	O	0
The authors make two contributions towards that goal: (1) they introduce a crowdsourced dataset (EmpatheticDialogue) annotated with fine-grained emotion labels. (	Review	O	0
2) They show improvements on dialogue generation (in terms of empathy, but also relevance and fluency) using a multi-task objective, ensemble of encoders, and a more ad-hoc technique that consists of prepending inferred emotion labels to the input.	Review	O	0
[line_break_token][line_break_token]In terms of technical novelty, the work is relatively incremental: (A) The use of multi-task objectives in sequence models [1] is relatively common nowadays (there is little mathematical details in the paper, so it‚Äôs hard to see how the approach of the paper really differs from extensive related work.). (	Review	O	0
B) Prepending predictions: prepending class labels to the input is also relatively common (e.g., in multilingual NMT to select a language). [	Review	O	0
2] presents a similar approach for polite response generation, where they prepend a label using a politeness classifier.	Review	B-Review	1
[line_break_token][line_break_token]I also have some doubts about the two claimed contributions of the paper (the authors actually list 3 contributions in the introduction, but for convenience I lump the 2 non-data ones together):[line_break_token][line_break_token](1) Dataset: The dataset was crowdsourced by giving workers an emotion label (e.g., afraid) and asking them to define a situation in which that emotion might occur and inviting them to have a conversation on that situation.	Review	O	0
The problem with prompting workers for specific emotions is that this assumes they are good actors and this is likely to produce exchanges that are rather clich√© and overdone (e.g., Table 1: the label ‚Äúafraid‚Äù yields a situation that is rather spooky and unlikely in the real world, and the conversations themselves are rather clich√© and incorporate little details that would make them sound real).	Review	B-Review	2
 The authors justify this dataset by pointing out that existing real-world datasets underrepresent rare emotions (e.g., afraid), but that‚Äôs just a reflection of how these emotions are distributed in the real world.	Review	I-Review	2
Better subsampling strategies would enable a better balance in the distribution without having to give up on real-world data (filtering using emojis, hashtags, etc.).	Review	I-Review	2
 As the paper shows quantitative gains using this dataset, it is probably ok to use but, qualitatively, this dataset is probably not for everyone working on emotion in NLP.	Review	I-Review	2
[line_break_token][line_break_token](2) Improvement in empathetic dialogue generation: The paper shows improvements across the board compared to a Transformer baseline, but the question the authors do not satisfactorily address is whether their explicit (and I would say sometimes ad-hoc) treatment of empathy (e.g., using emotion classifier, etc.)	Review	O	0
is crucially needed to get better empathetic dialogues, since the authors did not control for training data size and model capacity.	Review	B-Review	3
Indeed, the authors exploited different amounts of data (out of-domain, or both in- and out-of-domain), different model capacities (going from baseline Transformer to model ensembles), and sometimes richer input (e.g., pre-trained emotion classifier).	Review	I-Review	3
The results might only be showing that more data or more model capacity helps, which would of course not be surprising at all.	Review	I-Review	3
The fact that generated outputs improve in all aspects (not only empathy, but in attributes completely unrelated to empathy such as fluency and relevance) suggests that the improvement is due to more data or capacity (e.g., perhaps yielding better encoder).	Review	I-Review	3
 More statistics in the table in terms of number of parameters and amount of in- and out-of-domain data used for each experiment would help draw a clearer picture.	Review	I-Review	3
[line_break_token][line_break_token]About the use of Reddit: this might not be the best background dataset, as it‚Äôs mostly strangers talking to other strangers, presumably causing the baseline to be weak on empathy.	Review	I-Review	4
Twitter or other social-network type datasets (letting you follow people rather topics) *might* be better suited as it comparatively involves more exchanges between people who actually know each other and who are thus more likely to behave empathetically.	Review	I-Review	4
[line_break_token][line_break_token]Overall, the paper doesn‚Äôt really attempt to make major technical contribution, and instead (1) introduces a dataset and (2) makes empirical contributions, but I think there are problems with both.	Review	I-Review	5
[line_break_token][line_break_token]Typos:[line_break_token][line_break_token]Introduction: ‚Äúfro‚Äù[line_break_token]References: Elizaa [line_break_token][line_break_token][1] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, Lukasz Kaiser  [line_break_token]Multi-task Sequence to Sequence Learning[line_break_token]<a href="https://arxiv.org/abs/1511.06114" target="_blank" rel="nofollow">https://arxiv.org/abs/1511.06114</a>[line_break_token][line_break_token][2] Tong Niu and Mohit Bansal[line_break_token]Polite Dialogue Generation Without Parallel Data[line_break_token]<a href="https://arxiv.org/pdf/1805.03162.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1805.03162.pdf</a>	Review	O	0
[line_break_token]‚Äúbut the question the authors do not satisfactorily address is whether their explicit (and I would say sometimes ad-hoc) treatment of empathy (e.g., using emotion classifier, etc.)	Reply	O	0
is crucially needed to get better empathetic dialogues [...]‚Äù: thank you very much for making that point, and making us realize that our experimental results would benefit from disentanglement.	Reply	O	0
As detailed in the response in the general thread, we have extensively reworked the experimental section to make it clear (1) where benefits in empathy from training on our dataset are seen without any increase in model capacity, (2) why we found it valuable to include experiments combining our base model with external classifiers, (3) how capacity came into play, with new experiments with larger models.	Reply	B-Reply	3
Your comments have also led us to downplay the treatment of emotion and add new experiments with topic classifiers, to give a better overall picture.	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúMore statistics in the table in terms of number of parameters and amount of in- and out-of-domain data used for each experiment would help draw a clearer picture.	Reply	O	0
‚Äù We have added a section and table discussing capacity (Table 4) for the crucial experiments.	Reply	O	0
For some of the experiments using a  classifier trained on out-of-domain data, we have clarified our motivation for including them.	Reply	B-Reply	3
We do not claim that it is surprising that it should help, rather we aim to provide empirical confirmation of whether it does, for a variety of different data sources, and by how much, so that practitioners can more easily decide which model or data to adopt.	Reply	I-Reply	3
[line_break_token][line_break_token]‚Äúdoesn‚Äôt really attempt to make major technical contribution‚Äù: we do not argue to the contrary, and it was definitely not how we had tried to cast our contribution.	Reply	O	0
We have updated our manuscript with more citations to previous work, including the ones you provided, to make it even clearer that we claim no innovation on the architecture front -- rather, our goal is to show how existing methods can be used with our dataset, and how they compare	Reply	B-Reply	5

This paper focuses on deep reinforcement learning methods and discusses the presence of inductive biases in the existingRL algorithm.	Review	O	0
Specifically, they discuss biases that take the form of domain knowledge or hyper-parameter tuning.	Review	O	0
The authors state that such biases rise the tradeoff between generality and performance wherein strong biases can lead to efficient performance but deteriorate generalization across domains.	Review	O	0
Further, it motivates that most inductive biases has a cost associated to it and hence it is important to study and analyze the effect of such biases.	Review	O	0
[line_break_token][line_break_token]To support their insights, the authors investigate the performance of well known actor-critic model in the Atari environment after replacing domain specific heuristics with the adaptive components.	Review	O	0
The author considers two ways of injecting biases: i) sculpting agents objective and ii) sculpting agent's environment.	Review	O	0
They show empirical evidence that replacing carefully designed heuristics to induce biases with more adaptive counterparts preserves performance and generalizes without additional fine tuning.	Review	O	0
[line_break_token][line_break_token]The paper focuses on an important concept and problem of inductive biases in deep reinforcement learning techniques.	Review	O	0
[line_break_token]Analysis of such biases and methods to use them judiciously is an interesting future direction.	Review	O	0
The paper covers a lot of related work in terms of various algorithms and corresponding biases.	Review	O	0
[line_break_token]However, this paper only discusses such concepts at high level and provides short empirical evidences in a single environment to support their arguments.	Review	B-Review	1
Further, both the heuristics used in practice and the adaptive counterparts that the paper uses to replace those heuristics are all available in existing approaches and there is no novel contribution in that direction too.	Review	I-Review	1
[line_break_token]Finally, the adaptive methods based on parallel environment and RNNs have several limitation, as per author's own admission.	Review	I-Review	2
[line_break_token][line_break_token]Overall, the paper does not have any novel technical contributions or theoretical analysis on the effect of such inductive biases which makes it very weak.	Review	I-Review	3
Further, there is nothing surprising about the author's claims and many of the outcomes from the analysis are expected.	Review	I-Review	4
The authors are recommended to consider this task more rigorously and provide stronger and concrete analysis on the effects of inductive biases on variety of algorithms and variety of environments.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
In addition to 3 grid-world domains (designed specifically to highlight specific properties of the inductive biases considered in the paper), we also provide extensive experiments at scale on 57 Atari games and 28 continuous control tasks.	Reply	B-Reply	3
This is a larger set of non-trivial environments than in the vast majority of deep RL papers.	Reply	I-Reply	3
Perhaps the reviewer interpreted the Atari experiments (on 57 games) as having been run on a single Atari game	Reply	I-Reply	3

The paper presents a few tricks to compress a wide and shallow text classification model based on n-gram features.	Review	O	0
These tricks include (1) using (optimized) product quantization to compress embedding weights (2) pruning some of the vocabulary elements (3) hashing to reduce the storage of the vocabulary (this is a minor component of the paper).	Review	O	0
The paper focuses on models with very large vocabularies and shows a reduction in the size of the models at a relatively minor reduction of the accuracy.	Review	O	0
[line_break_token][line_break_token]The problem of compressing neural models is important and interesting.	Review	O	0
The methods section of the paper is well written with good high level comments and references.	Review	O	0
However, the machine learning contributions of the paper are marginal to me.	Review	O	0
The experiments are not too convincing mainly focusing on benchmarks that are not commonly used.	Review	O	0
The implications of the paper on the state-of-the-art RNN text classification models is unclear.	Review	O	0
[line_break_token][line_break_token]The use of (optimized) product quantization for approximating inner product is not particularly novel.	Review	B-Review	8
Previous work also considered doing this.	Review	I-Review	8
Most of the reduction in the model sizes comes from pruning vocabulary elements.	Review	I-Review	8
The method proposed for pruning vocabulary elements is simply based on the assumption that embeddings with larger L2 norm are more important.	Review	I-Review	8
A coverage heuristic is taken into account too.	Review	O	0
From a machine learning point of view, the proper baseline to solve this problem is to have a set of (relaxed) binary coefficients for each embedding vector and learn the coefficients jointly with the weights.	Review	B-Review	1
An L1 regularizer on the coefficients can be used to encourage sparsity.	Review	I-Review	1
From a practical point of view, I believe an important baseline is missing: what if one simply uses fewer vocabulary elements (e.g based on subword units - see <a href="https://arxiv.org/pdf/1508.07909.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1508.07909.pdf)</a> and retrain a smaller models?	Review	O	0
[line_break_token][line_break_token]Given the lack of novelty and the missing baselines, I believe the paper in its current form is not ready for publication at ICLR.	Review	B-Review	8
[line_break_token][line_break_token]More comments:[line_break_token]- The title does not make it clear that the paper focuses on wide and shallow text classification models.	Review	O	0
Please revise the title.	Review	B-Review	7
[line_break_token]- The paper cites an ArXiv manuscript by Carreira-Perpinan and Alizadeh (2016) several times, which has the same title as the submitted paper.	Review	O	0
Please make the paper self-contained and include any supplementary material in the appendix.	Review	B-Review	4
[line_break_token]- In Fig 2 does the square mark PQ or OPQ?	Review	O	0
The paper does not distinguish OPQ and PQ properly at multiple places especially in the experiments.	Review	B-Review	5
[line_break_token]- The paper argues the wide and shallow models are the state of the art in small datasets.	Review	O	0
Is this really correct?	Review	B-Review	6
What about transfer learning?	Review	I-Review	6
[line_break_token]	Review	O	0
First, we would like to thank the reviewer.	Reply	O	0
[line_break_token][line_break_token]The main concern stated by Reviewer 3 is the lack of novelty of the paper.	Reply	B-Reply	8
However, we are not aware of previous work using similar techniques for compression of text classification models.	Reply	I-Reply	8
We are happy to examine any paper in that field that the reviewer could refer to.	Reply	I-Reply	8
While we do agree that similar techniques were applied to other domains, such as computer vision, one of the main contributions of this paper is to perform a careful empirical evaluation for text classification.	Reply	I-Reply	8
In particular, we evaluated many different combinations of the methods discussed in the paper, on 9 datasets with different characteristics (see Tables 5, 6, 7, 8 and 9 of the appendix).	Reply	I-Reply	8
[line_break_token][line_break_token]** "From a machine learning point of view, the proper baseline to solve this problem..."[line_break_token][line_break_token]We believe that this approach is more complex that the one described in the paper.	Reply	O	0
Moreover, this technique cannot be used to compress existing models.	Reply	B-Reply	1
Again, a reference providing results comparable to our approach in terms of the performance between compression rate and accuracy would be welcomed.	Reply	I-Reply	1
[line_break_token][line_break_token]** "what if one simply uses fewer vocabulary elements (e.g based on subword units ...)"[line_break_token][line_break_token]We agree that this technique could be used additionally to the ones described in the paper.	Reply	O	0
We actually discuss this in the last paragraph of the ‚ÄúFuture work‚Äù section.	Reply	B-Reply	2
[line_break_token][line_break_token]** "However, the machine learning contributions of the paper are marginal to me."	Reply	O	0
[line_break_token][line_break_token]We do not believe that only the contributions cast as a machine learning objective are of interest to ICLR (see the list of relevant topics, e.g. "Implementation issues, parallelization, software platforms, hardware").	Reply	B-Reply	3
[line_break_token][line_break_token]** "The paper cites an ArXiv manuscript by Carreira-Perpinan and Alizadeh (2016)"[line_break_token][line_break_token]We do not cite any paper by Carreira-Perpinan and Alizadeh.	Reply	O	0
[line_break_token][line_break_token]** "In Fig 2 does the square mark PQ or OPQ?	Reply	O	0
The paper does not distinguish OPQ and PQ properly at multiple places especially in the experiments."	Reply	O	0
and "The use of (optimized) product quantization for approximating inner product is not particularly novel."	Reply	O	0
[line_break_token][line_break_token]As stated in the first paragraph of section 4.1, ‚Äúwe adopt the normalized PQ (NPQ) for the rest of this study.	Reply	B-Reply	5
‚Äù Note, this is a variation that departs from PQ and OPQ by the way we treat the magnitude information, which to the best of our knowledge is new in this context.	Reply	I-Reply	5
[line_break_token][line_break_token]** "The paper argues the wide and shallow models are the state of the art in small datasets."	Reply	O	0
[line_break_token][line_break_token]We make the claim that ‚Äúlinear classifiers remain competitive with more sophisticated, deeper models‚Äù, supported by the results reported by Wang and Manning (2012) and Joulin et al. (	Reply	B-Reply	6
2016)	Reply	I-Reply	6

Summary:[line_break_token]The authors propose a method for training easy-to-quantize models that are quantized after training (post-training quantization).	Review	O	0
They do so by regularizing by the entropy, thereby forcing the weight distribution to be more compressible.	Review	O	0
They further compress the weights using entropy coding.	Review	O	0
[line_break_token][line_break_token]Strengths of the paper:[line_break_token]- The paper presents strong experimental results on ResNet, SqueezeNet VGG and MobileNet architectures and provides the code, which looks sensible.	Review	O	0
[line_break_token][line_break_token]Weaknesses of the paper:[line_break_token]- The authors could have applied CAT to other tasks such as Image Detection, while proving inference times on CPUs.	Review	O	0
Indeed, it is unclear to me what would be the influence of the entropic decoder which is claimed to be fast for "efficient implementations" by the authors.	Review	B-Review	1
[line_break_token]- The idea of regularizing by the entropy is not novel (see for instance "Entropic Regularization", Grandvalet et a.l),  as well as the idea of further encoding the weights using entropic coders (as in "Deep Compression", Han et al.).	Review	O	0
[line_break_token][line_break_token]Justification of rating:[line_break_token]The authors present an intuitive method (yet not novel) for quantizing the weights of a neural network.	Review	O	0
My main concern would be about the inference time but I consider that the experimental results suggest strong evidence that CAT performs well on a wide variety of architectures.	Review	O	0
hank you for your review and your comments.	Reply	O	0
We would like to provide an answer to the issues raised in your review.	Reply	O	0
[line_break_token][line_break_token]Q: The authors could have applied CAT to other tasks such as Image Detection while proving inference times on CPUs.	Reply	O	0
Indeed, it is unclear to me what would be the influence of the entropic decoder which is claimed to be fast for "efficient implementations" by the authors.	Reply	O	0
[line_break_token]A: We have applied the CAT to object detection task (SSD512, Table 3).	Reply	O	0
As we have written in the answer to Reviewer #3, even for naive implementation of Huffman coding, the overhead for GPU-running code is approx.	Reply	B-Reply	1
3-4%.	Reply	I-Reply	1
When considering dedicated hardware implementations, the overhead can be made negligible.	Reply	I-Reply	1
[line_break_token] [line_break_token]Q: The idea of regularizing by the entropy is not novel (see for instance "Entropic Regularization", Grandvalet et al.),	Reply	O	0
as well as the idea of further encoding the weights using entropic coders (as in "Deep Compression", Han et al.).	Reply	O	0
[line_break_token]A: The idea of using entropy regularization, in general, is indeed not novel and we mention relevant works in the Related Work section.	Reply	O	0
However, using a differentiable entropy approximation as a loss term to improve the compressibility of the activations is novel	Reply	B-Reply	2

The paper proposes a new efficient ensembling method that has smaller memory footprint than naive ensembling and allows a simple parallelization on one device.	Review	O	0
The authors‚Äô idea is based on sharing weights between individual ensembling models.	Review	O	0
The weights of each model can be represented as element-wise product of two matrices: shared one and matrix with rank 1 that can be efficiently stored.	Review	O	0
[line_break_token][line_break_token]The idea is quite interesting despite its simplicity.	Review	O	0
The experimental part is quite broad.	Review	O	0
I would like to highlight the lifelong learning as the strongest experimental result achieved by the authors.	Review	O	0
Despite the significant improvement on top of the baselines, this approach has one drawback described by the authors themselves.	Review	O	0
This method is difficult to generalize for the case of very diverse tasks despite its scalability.	Review	B-Review	4
Nevertheless, I would not consider it as a large problem.	Review	I-Review	4
[line_break_token][line_break_token]I have a concern regarding ensembling.	Review	I-Review	1
Do I understand correctly that in Figure 1 the method achieves almost constant test time cost only in the case of one device parallelization?	Review	I-Review	1
If yes, then Figure 1 is slightly misleading and the description of this figure should be improved.	Review	I-Review	1
[line_break_token]In the classification section the authors compare their approach only with MC-dropout.	Review	I-Review	2
I would recommend adding other ensembling methods that have small memory footprint: e.g. [1], and can be better than MC-dropout.	Review	I-Review	2
The same is true for machine translation section.	Review	I-Review	2
[line_break_token][line_break_token]The authors emphasize that their approach is faster than consequently training independent models.	Review	I-Review	3
However,  since these models are independent, it is possible to train them in parallel on multiple devices.	Review	I-Review	3
The restriction to one device during training seems in general a bit artificial.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token][1]  Stefan  Lee,  Senthil  Purushwalkam,  Michael  Cogswell,  David  Crandall,  and  Dhruv  Batra.	Review	O	0
  Whym  heads  are  better  than  one:  Training  a  diverse  ensemble  of  deep  networks.arXiv  preprintarXiv:1511.06314, 2015b[line_break_token][line_break_token][line_break_token]Overall, it is an interesting paper, that has several drawbacks.	Review	O	0
[line_break_token]	Review	O	0
hank you for your careful and insightful feedback.	Reply	O	0
[line_break_token][line_break_token]-&gt; Q: I have a concern regarding ensembling.	Reply	O	0
Do I understand correctly that in Figure 1 the method achieves almost constant test time cost only in the case of one device parallelization?	Reply	O	0
If yes, then Figure 1 is slightly misleading and the description of this figure should be improved.	Reply	O	0
[line_break_token][line_break_token]Figure 1 is supposed to help understanding BatchEnsemble in the matrix element-wise multiplication view.	Reply	B-Reply	1
For efficient computation, we use the vectorized computation.	Reply	I-Reply	1
We will make this clear in the revision.	Reply	I-Reply	1
[line_break_token][line_break_token]-&gt; Q: In the classification section the authors compare their approach only with MC-dropout.	Reply	O	0
I would recommend adding other ensembling methods that have small memory footprint, and can be better than MC-dropout.	Reply	O	0
The same is true for machine translation section.	Reply	O	0
[line_break_token][line_break_token]TreeNet is an ensemble method that is more memory expensive than MC-dropout and BatchEnsemble.	Reply	B-Reply	2
Which layers should be shared among ensemble members in deep network such as ResNet-32 is still unknown and need extra effort to discover.	Reply	I-Reply	2
We will include this work in discussion in the revision and run experiments that compares to it if time permitted.	Reply	I-Reply	2
[line_break_token][line_break_token]-&gt; Q: The authors emphasize that their approach is faster than consequently training independent models.	Reply	O	0
However,  since these models are independent, it is possible to train them in parallel on multiple devices.	Reply	O	0
The restriction to one device during training seems in general a bit artificial.	Reply	O	0
[line_break_token][line_break_token]We don‚Äôt restrict to one device (in fact, experiments (4.1, 4.2) use multiple devices).	Reply	B-Reply	3
Rather, we show that BatchEnsemble can exploit parallel training using both axes (within a device as well as across devices) and this depends on the user.	Reply	I-Reply	3
In the extreme setting benefiting naive ensembles where all parallelism is done across devices, note that the memory cost for parameters still remains smaller for BatchEnsemble (assuming a parameter server).	Reply	I-Reply	3

The paper proposes two extensions to the recent work of (Wang et al.,	Review	O	0
2019) on 3D object detection with pseudo LiDAR data.	Review	O	0
Wang et al.	Review	O	0
showed that 3D object detection using stereo images as inputs can be significantly improved if the depth map is projected to 3D and treated like a LiDAR point cloud (i.e., using methods that utilize the LiDAR point cloud).	Review	O	0
This paper shows that one shortcoming of this approach is given by the fact that the depth uncertainty increases the farther the objects are away.	Review	O	0
To remedy this, the authors propose to train the stereo estimation network (based on Chang &amp; Chen, 2018) directly with depth outputs, instead of disparity values (inverse depth), by rewriting the loss and converting the cost volume.	Review	O	0
This already boosts the performance for far away objects.	Review	O	0
The authors demonstrate that the usage of a (simulated) low-cost 4-beam LiDAR can further facilitate the detection.	Review	O	0
For this purpose a graph diffusion algorithm is listed that aligns the pseudo LiDAR point cloud from the stereo set-up with the depth estimates from the low-cost LiDAR.	Review	O	0
Simulating the low-cost LiDAR on the Kitti benchmarks shows that this approach further increases the performance of the object detection methods.	Review	O	0
[line_break_token][line_break_token]In general, I am in favour of accepting the paper as it shows two orthogonal and interesting additions to the pseudo LiDAR paper of Wang et al.	Review	O	0
that improve its performance.	Review	O	0
However, I would like to see some clarifications in the rebuttal.	Review	O	0
[line_break_token][line_break_token]The proposed stereo network converts a disparity cost volume to a depth cost volume using bilinear interpolation.	Review	O	0
I agree, that the 3D convolutions are more meaningful (given the spacing of the grid cells) on the latter, but why the detour over the disparity cost volume?	Review	O	0
It should be possible to build the depth cost volume directly, which would lead to decreased memory consumption and speed up the method without any loss in accuracy?	Review	B-Review	1
[line_break_token][line_break_token]One assumption of the second contribution (GDC) is that at least one beam of the LiDAR will hit the k-connected local point cloud.	Review	I-Review	2
Can you give some bounds on the likelihood that this happens, especially for far away objects it could be unlikely, although it is most beneficial for those objects.	Review	I-Review	2
[line_break_token]Further, I am missing a details on the optimization of (7) and (8).	Review	I-Review	3
What is meant with slight L2 regularization?	Review	I-Review	4
In the appendix it is also stated that a slightly different objective is optimized?	Review	I-Review	4
[line_break_token]Finally, the notation could also be improved.	Review	O	0
The authors are using L and G for the LiDAR point cloud and PL and Z for the pseudo LiDAR point cloud and then in the Z' is used for both.	Review	B-Review	3
[line_break_token][line_break_token]Fig.	Review	I-Review	5
4 shows the median error in meters for the different variants of the stereo network.	Review	I-Review	5
Why has the median been used?	Review	I-Review	5
Are there severe outliers?	Review	I-Review	5
If yes, it would also be interesting to quantify those and compare them (e.g., box plots).	Review	I-Review	5
[line_break_token][line_break_token]In the abstract and in the discussion the authors oversell their results a bit.	Review	I-Review	6
At the one hand they state that PL++ with GDC performs significantly better than PL++ w/o GDC, on the other hand they also claim that PL++ achieves comparable results to models that have access to the full 64-beam LiDAR data.	Review	I-Review	6
However, if you compare the differences, then the gaps are for several cases almost as big, or bigger as in the former claim.	Review	I-Review	6
[line_break_token][line_break_token]Things to improve the paper that did not impact the score:[line_break_token]- In equation (2) you could replace the x with a . (	Review	I-Review	7
\cdot), or completely remove it[line_break_token]- On page 5: KNN neighbors -&gt; k-nearest neighbors[line_break_token]- Also on page 5: write out W.l.o.g.	Review	O	0
[line_break_token]- In Tab.	Review	B-Review	7
1 it would help to highlight (bold) the best entries per column	Review	I-Review	7
.[detour over the disparity cost volume] Thanks for pointing this out.	Reply	O	0
It is definitely possible to construct the depth cost volume directly, however constructing the disparity cost volume brings us simplicity in implementation and efficiency through utilizing matrix operations.	Reply	B-Reply	1
Although it does require some additional GPU memory, it is on the order of a few hundred megabytes.	Reply	I-Reply	1
In terms of computation, the most costly part of the depth estimation model is 3D convolutions on the depth cost volume.	Reply	I-Reply	1
In comparison, the memory and computation cost of constructing the disparity cost volume first is quite small.	Reply	I-Reply	1
[line_break_token][line_break_token]2.[analysis on GDC] Thanks for mentioning your concern about GDC with regards to lasers missing connected components.	Reply	O	0
In practice, we have not observed that this is a problem, in part because the pseudo-Lidar point cloud is sufficiently dense, and we choose k to be large enough (k=10) that the graph is typically connected (or consists of few large connected components).	Reply	B-Reply	2
We will add a more detailed discussion in the final paper about this issue and provide empirical numbers for various values of k. [line_break_token][line_break_token]3. [	Reply	O	0
notation and optimization on equation (7) and (8)] Thanks for pointing out the notational collisions, we will correct these in the final version.	Reply	O	0
[line_break_token][line_break_token]4. [	Reply	O	0
L2-regularization] The first step of GDC, i.e., equation (7), is an under-constrained problem, with infinitely many solutions.	Reply	O	0
To identify a single solution, we add a small L2 regularization term to the objective (main paper).	Reply	B-Reply	4
In the appendix, we switch the objective with the constraints by minimizing the L2-norm of W and set Z-WZ=0 as a constraint.	Reply	I-Reply	4
These two problems yield identical solutions but we found the first formulation easier to explain (i.e., adding a regularizer to equation (7)) while the second one is easier to solve in practice.	Reply	I-Reply	4
We apologize for the confusion and will clarify our description in the final version.	Reply	I-Reply	4
[line_break_token][line_break_token]5.[median error] Thanks for the suggestion.	Reply	O	0
We re-evaluate depth estimation with mean error and find that it is larger than the median error, which likely results from outliers such as occluded pixels around object boundaries.	Reply	B-Reply	5
We list the mean error and the standard deviation below.	Reply	I-Reply	5
SDN+GDC still achieves the lowest mean error (except for 0-10 meters), followed by SDN and then the vanilla disparity-based PSMNet.	Reply	I-Reply	5
We will include a more detailed box-plot graph in the final version.	Reply	I-Reply	5
[line_break_token]mean\range  0-10   10-20   20-30   30-40   40-50   50-60   60-70[line_break_token]PL         0.176   0.359   0.967   2.023   2.936   4.611   6.025[line_break_token]SDN        0.212   0.352   0.865   1.799   2.668   4.272   5.824[line_break_token]SDN+GDC    0.209   0.345   0.842   1.744   2.590   4.137   5.721[line_break_token][line_break_token]std\range   0-10   10-20   20-30   30-40   40-50   50-60   60-70[line_break_token]PL         0.929   1.200   2.320   4.049   5.641   8.034   10.317[line_break_token]SDN        0.894   1.157   2.310   4.218   6.004   8.776   11.232[line_break_token]SDN+GDC    0.897   1.167   2.338   4.266   6.058   8.852   11.293[line_break_token][line_break_token]6.[Overselling results] We apologize; we did not mean to oversell our results.	Reply	O	0
This is an unfortunate naming conflict.	Reply	B-Reply	6
In the abstract, by PL++ we mean SDN+GDC, while in Table 1, we separate SDN and GDC for analysis but still call them both PL++.	Reply	I-Reply	6
With SDN+GDC, our model can achieve comparable results to models that have access to the full 64-beam LiDAR data on some of the metrics (as mentioned in section 5.2 and the introduction).	Reply	I-Reply	6
We will clarify this in the final version.	Reply	I-Reply	6

This paper studies two objects that quantify the optimization trajectory: the Hessian of the training loss (H) that describes the curvature of the loss surface, and the covariance of gradients that quantifies noise induced by noisy estimate of the full-batch gradient.	Review	O	0
[line_break_token][line_break_token]The authors predict and demonstrate that learning rate and batch size determine H and K and demonstrate that both large learning rate and small batch size results in two effects on K and H along the trajectory: (1) variance reduction and (2) pre-conditioning.	Review	O	0
These effects are observed after the break-even point.	Review	O	0
The further verified these predictions on BN networks.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]Understanding the optimization trajectory is an important topic and this work is one step towards better understanding.	Review	O	0
There are many questions I hope the authors could clarify: [line_break_token][line_break_token]- the concept of break even point, which justify whether the minima is stable or not, is also presented in Wu et al, 2018, including the proof.	Review	O	0
In the introduction of equation 1, the break even point concept seems to be novel in the context of learning trajectory.	Review	B-Review	1
What is the difference with Wu et al, 2018?	Review	I-Review	1
Does this break even point appear only once during training?	Review	I-Review	2
[line_break_token][line_break_token]- What is the practical usage for identifying the break-even point or stable/unstable of the optimizer?	Review	O	0
Does reaching the unstable phase of SGD earlier by large learning rate/small batch size mean better performance?	Review	B-Review	4
[line_break_token][line_break_token]- It seems the author does not apply learning rate decay for all experiments.	Review	O	0
What is the connection with learning rate decay?	Review	B-Review	5
As we often see the training loss and validation error decreases significantly during training in step based learning rate schedule, what is their corresponding change of \lambda_H^1 and \lambda_K^1?	Review	I-Review	5
[line_break_token][line_break_token]- The authors did not mention whether momentum is used or not during training, which is commonly used in training neural nets.	Review	O	0
How would momentum affect the conjectures?	Review	B-Review	6
[line_break_token][line_break_token]- Regarding to conjecture 1 which states that ‚Äúlarger‚Äù learning rate yields lower \lamda_H^1 and \lamda_K^1, is there a limit for the range of learning rate?	Review	O	0
If we use learning rate 10, the training may not even converge.	Review	B-Review	7
The experiments only verifies three learning rate with a maximum value 0.1, which does not cover ‚Äúlarge‚Äù learning rate.	Review	I-Review	7
[line_break_token][line_break_token]- Also as small batch size naturally results in more iterations than large batch given the same number of epochs.	Review	O	0
Comparing small batch and large batch may need to take this into account.	Review	B-Review	8
By reaching the break-even-point ‚Äúearly‚Äù, does it mean less number of epochs?	Review	I-Review	8
I would like to see the comparison in terms of iterations rather than epochs.	Review	I-Review	8
[line_break_token][line_break_token]- In section 4.1, the definition of \alpha* is not clear.	Review	O	0
It was noted in Figure 2 as the width of the loss surface and is defined to be the minimum step size along the adjacent iterate direction to have 20% loss increase.	Review	B-Review	9
What is the unit of t here, is it a batch or epoch?	Review	I-Review	9
[line_break_token]How exactly is \alpha calculated?	Review	I-Review	9
Due to the scale invariance [1,2], this \alpha is not necessarily the true `width` of the loss surface as it could be influenced by the weight norm.	Review	I-Review	9
[line_break_token]Why do different learning rates reach a similar \alpha?	Review	I-Review	9
It would be better to mark the starting point of the trajectory and the ending point of trajectory.	Review	I-Review	9
[line_break_token][line_break_token]- The illustration of Figure 1a is very unclearer.	Review	O	0
What is the x-axis and y-axis?	Review	B-Review	10
Where is exactly the break-even point?	Review	I-Review	10
It would be helpful to mark the starting and ending point of the trajectory.	Review	I-Review	10
Also it would be helpful to have the values marked in the contours or make a separate value bar.	Review	I-Review	10
[line_break_token][line_break_token][line_break_token]- The authors studied whether the conjectures hold for BN networks in section 4.3.	Review	O	0
They only verified learning rate but not batch size.	Review	B-Review	11
Does the batch size part still hold?	Review	I-Review	11
It is known that BN requires larger batch size to work well, which may contradict with the conjecture that smaller batch size works better.	Review	I-Review	11
[line_break_token][line_break_token][line_break_token]Minor:[line_break_token]- I was confused by the Figure 3 where different hyperparameters has different values at epoch 0.	Review	I-Review	12
Does epoch 0 means the first epoch?	Review	I-Review	12
It would be clear to have the same starting point and make epoch 0 as the initialization point.	Review	I-Review	12
 [line_break_token][line_break_token]- The experiments of DenseNet on ImageNet seems incomplete as it is only trained for 10 epochs.	Review	I-Review	12
What is the top-1 error on the validation set?	Review	I-Review	12
[line_break_token][line_break_token][1] <a href="https://arxiv.org/abs/1703.04933" target="_blank" rel="nofollow">https://arxiv.org/abs/1703.04933</a> [line_break_token][2] <a href="https://arxiv.org/abs/1712.09913" target="_blank" rel="nofollow">https://arxiv.org/abs/1712.09913</a>[line_break_token][line_break_token][line_break_token]-----update after rebuttal----------[line_break_token][line_break_token]After reading the response, I think most of my questions are properly answered and corresponding changes are made in the revision.	Review	O	0
I  changed my score to weak accept.	Review	O	0
I would hope the authors could further improve the paper by well organizing the additional experiments and findings.	Review	B-Review	5
Too much experiment variation settings make the paper not easy to follow.	Review	I-Review	5
I hope the authors could make it clear about the practical benefits of identifying the existence of break even point with common experiments settings, e.g., nonzero momentum, weight decay and step based learning rate decay.	Review	I-Review	5
In the new provided experiments about learning rate decay, I did not see the normal abrupt change of validation accuracy.	Review	I-Review	5
More analysis about whether learning rate decay helps reaching break-even point would be great.	Review	I-Review	5
hank you very much for the review!	Reply	O	0
Below are our responses and the results of the additional experiments can be accessed at <a href="https://bit.ly/34K2Qij."	Reply	O	0
target="_blank" rel="nofollow">https://bit.ly/34K2Qij.</a> Please let us know if you have any further comments or questions.	Reply	O	0
[line_break_token][line_break_token](We are sorry the rebuttal is rather long.	Reply	O	0
The experiments in <a href="https://bit.ly/34K2Qij" target="_blank" rel="nofollow">https://bit.ly/34K2Qij</a> are described more concisely, and we include a summary of key changes in the global comment)[line_break_token][line_break_token]&gt;The concept of break even point, which justify whether the minima is stable or not, is also presented in Wu et al, 2018, including the proof.	Reply	O	0
In the introduction of equation 1, the break even point concept seems to be novel in the context of learning trajectory.	Reply	O	0
What is the difference with Wu et al, 2018?	Reply	O	0
[line_break_token][line_break_token]As you mentioned, the main difference between our work and Wu et al‚Äôs is that we focus on the training trajectory, rather than on the properties of the final minimum as Wu et al or [4, 5].[line_break_token][line_break_token]Most importantly, our conjectures *are not* an immediate consequence of Wu et al.	Reply	B-Reply	1
This is most clearly visible in Conjecture 2.	Reply	I-Reply	1
We model and study the evolution of H and K along the training trajectory, while Wu et al focus on the properties of the final minimum.	Reply	I-Reply	1
[line_break_token]From the practical point of view, the effects that the two conjectures describe occur early in training.	Reply	I-Reply	1
On CIFAR-10 that occurs when the model achieves around 50% training accuracy, as shown in (revised, in line with your comments) Figure 1, and influence most of the training trajectory.	Reply	I-Reply	1
[line_break_token][line_break_token]We updated the related work section to clarify these differences.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt;Does this break even point appear only once during training?	Reply	O	0
[line_break_token][line_break_token]In the theoretical model, we defined the break-even as the first time training becomes unstable (stable).	Reply	B-Reply	2
We have clarified this in the paper.	Reply	I-Reply	2
However, the dynamic we identified could repeat itself later in training, and in this sense there could be in principle multiple break-even points during training.	Reply	I-Reply	2
We observe some signs of this happening in the learning rate decay experiment (see our answer later).	Reply	I-Reply	2
 [line_break_token][line_break_token]&gt; What is the practical usage for identifying the break-even point or stable/unstable of the optimizer?	Reply	O	0
[line_break_token][line_break_token]We did not investigate benefits of detecting that a break-even point has been reached.	Reply	B-Reply	3
We demonstrated that reaching it ‚Äúearly‚Äù (i.e. at an iteration where \lambda_K^1 and \lambda_H^1 has not yet reached a large value, see also the answer to the next question) is beneficial for the optimization performance by reducing variance and improving conditioning (Con.1 and Con.	Reply	I-Reply	3
2).	Reply	I-Reply	3
[line_break_token][line_break_token]However, it seems that after reaching the break-even point, the training loss curvature is more predictable from iteration to iteration (due to the more stable evolution of \lambda_K^1 and \lambda_H^1).	Reply	I-Reply	3
In principle, this information could be leveraged in designing second order optimizers.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; Does reaching the unstable phase of SGD earlier by large learning rate/small batch size mean better performance?	Reply	O	0
[line_break_token][line_break_token]Reaching earlier the break-even point, i.e. at an iteration corresponding to a lower spectral norm of K (H) (see also our answer to the question on comparing at the same number of iterations) results in (1) variance reduction, and (2) better conditioning.	Reply	B-Reply	4
[line_break_token][line_break_token]Both effects are desirable from the optimization perspective, and achieving these effects is actually a common goal in the optimization literature.	Reply	I-Reply	4
For instance [1] propose techniques to reduce variance (i.e. Euclidean distance between the mini-batch gradient and the full-batch gradient), and [2] uses the inverse of K to condition training.	Reply	I-Reply	4
To expand on the second, optimizing in a region with more isotropic K means that the SGD step is more similar (in the Euclidean norm, for example) to a step that uses the inverse of K like in [2].[line_break_token][line_break_token]&gt;  It seems the author does not apply learning rate decay for all experiments.	Reply	O	0
What is the connection with learning rate decay?	Reply	O	0
As we often see the training loss and validation error decreases significantly during training in step based learning rate schedule, what is their corresponding change of \lambda_H^1 and \lambda_K^1?	Reply	O	0
[line_break_token][line_break_token]We agree that training loss and validation error tend to change rapidly after changing the learning rate.	Reply	B-Reply	5
As a preliminary study for the effect of learning rate decay, we run the SimpleCNN model from Sec.	Reply	I-Reply	5
4.2 with base learning rate in 0.1 and 0.03, and a step-based learning rate schedule.	Reply	I-Reply	5
[line_break_token][line_break_token]In this case, dropping learning rate reduces \lambda_H^1 and \lambda_K^1.	Reply	I-Reply	5
However, after a while the two quantities can increase, consistently with the experiment in Chen et al [4]. Importantly, the relative ordering of the magnitudes of \lambda_K and \lambda_H predicted in Con.	Reply	I-Reply	5
1 still holds.	Reply	I-Reply	5
In this sense it seems that Con.1 (and Con.	Reply	I-Reply	5
2) can be extended to step-based learning rate schedules.	Reply	I-Reply	5
[line_break_token][line_break_token]It might be also worth mentioning that the common practice of warming up the learning rate is consistent with the conclusion from our Conjectures that it is beneficial to reach early the highest possible learning rate.	Reply	I-Reply	5
[line_break_token][line_break_token]We have include detailed plots in <a href="https://bit.ly/34K2Qij."	Reply	O	0
target="_blank" rel="nofollow">https://bit.ly/34K2Qij.</a	Reply	O	0

Summary: The paper studies the problem of training deep neural networks in the distributes setting while ensuring privacy.	Review	O	0
Each data sample is held by one individual (e.g., on a cell phone), and a central algorithm trains a learning model on top of this data.	Review	O	0
In order to protect the privacy of the individuals, the paper proposes the use of multi-layer encoders (E) over the raw data, and then send them across the server.	Review	O	0
The privacy is ensured by exemplifying the inability to reconstruct the original data from the encoded features, via running a reverse deep model (X).	Review	O	0
The notion of privacy is quantified by the Euclidian distance between the reconstructed vector via the best X and the original feature vector, maximized over E. The overall framework resembles a GAN, and the paper calls it RAN (Reconstructive Adversarial Network).	Review	O	0
[line_break_token][line_break_token]Positive aspects: The problem of training privacy preserving deep models over distributed data has been a significant and important challenge.	Review	O	0
The current solutions that adhere to differential privacy based approaches are not yet practical.	Review	O	0
In my view, it is a very important research question.	Review	O	0
[line_break_token][line_break_token]Negative aspects: One major concern I have with the paper is the notion of privacy considered.	Review	O	0
The notion of privacy considered in the paper makes two assumptions which I am not comfortable with: i) The protection that the notion assures is against reconstruction attacks.	Review	B-Review	1
There has been a large body of work which shows that weaker attacks like membership attacks can be equally damaging, ii) Privacy is a worst-case guarantee.	Review	I-Review	1
I do not see the GAN style approach taken by the paper, ensures this.	Review	I-Review	1
We thank a lot for the comments with cares and insights, and appreciate your efforts in reviewing our paper, which is helpful for improving the quality and readability of our writing.	Reply	O	0
We are also glad that you support our paper.	Reply	O	0
[line_break_token][line_break_token]We agree that it is essential to justify how the reconstruction error works as a measure of privacy in this paper.	Reply	O	0
In the revision, we have added the following justification on privacy quantification in Section 2, Section 4 and Section 5.	Reply	O	0
We also note that the proposed reconstructive adversarial network (RAN), is not an extension of GAN but only borrows GAN‚Äôs thoughts on adversarial training several neural networks, for the data privacy-uniquely problem.	Reply	O	0
[line_break_token][line_break_token]First, there is no single standard definition of data privacy-preserving problems and corresponding adversary attacks.	Reply	O	0
And a fundamental problem in it is the natural tradeoff between privacy and utility, which is affected by different data privacy-preserving methods.	Reply	O	0
Our key contribution in this paper is the RAN framework and the training algorithm, which can accommodate different choices of privacy attackers and privacy quantification.	Reply	O	0
[line_break_token][line_break_token]Second, finding the right measurement for privacy is an open problem in itself.	Reply	O	0
To evaluate RAN, one has to pick some quantifications.	Reply	O	0
In the present paper, we chose the ‚Äúreconstructive error‚Äù as the quantification of privacy because it is the most intuitive one to measure the risk of disclosing sensitive background information in the raw data for the given perturbed data (Encoder output).	Reply	O	0
[line_break_token][line_break_token]Third, in the future, we will evaluate RAN using other quantifications of privacy as well in a definitely defined application.	Reply	O	0
For example, we could measure the privacy by the hidden failure, i.e., the ratio between the background patterns that were discovered based on RAN‚Äôs Encoder output, and the sensitive patterns founded from the raw data, in the object recognition application.	Reply	O	0

This paper presents a novel defense method to make the classification more robust.	Review	O	0
The motivation is based on the observation: the distribution of the soft-max for the cleaned image and its transformed images for one class is similar to the distribution of the soft-max for the adversarial image and its transformed images for the same class, and the distributions of the soft-max for the cleaned image and its transformed images for different classes are different.	Review	O	0
Then, a distribution based method is proposed to classify the distribution of the soft-max for the cleaned (or adversarial) image and its transformed images.	Review	O	0
[line_break_token][line_break_token]After I read the core part several times, finally I understood the paper.	Review	O	0
Overall I think this paper is well motivated, and the empirical results also support the claims/observations.	Review	O	0
But I think this paper could be improved by (1) checking the performance over large datasets (such as ImageNet); (2) providing possible analysis on the observation.	Review	O	0
Otherwise, the readers cannot be fully convinced.	Review	B-Review	2
hank you for your valuable comments and suggestions.	Reply	O	0
[line_break_token]_______________________________________________________________________[line_break_token]‚Äú (1) checking the performance over large datasets (such as ImageNet)‚Äù[line_break_token][line_break_token]Thank you for your suggestion.	Reply	O	0
As ImageNet is the largest dataset among the datasets that we have presented in our paper, it may be difficult but we will try our best to run the experiments and report the results before 15th Nov.[line_break_token]_______________________________________________________________________[line_break_token]‚Äú(2) providing possible analysis on the observation.	Reply	O	0
Otherwise, the readers cannot be fully convinced.	Reply	O	0
‚Äù[line_break_token][line_break_token]Section 3 is dedicated to analysing the effect of image transformations on the distribution of softmax, which motivates our method and supports our experimental findings.	Reply	O	0
Following the suggestion from Reviewer 2, we have also added in additional analysis on the divergence of softmax distributions in Fig.	Reply	B-Reply	2
2b, which we believe has improved the analysis in our paper	Reply	I-Reply	2

This paper propose to study the quantization of GANs parameters.	Review	O	0
They show that standard methods to quantize the weights of neural networks fails when doing extreme quantization (1 or 2-bit quantization).	Review	O	0
They show that when using low-bit representation, some of the bits are used to model extremal values of the weights which are irrelevant and lead to numerical instability.	Review	O	0
To fix this issue they propose a new method based on Expectation-Maximization to quantify the weights of the neural networks.	Review	O	0
They then show experimentally that this enables them to quantize the weights of neural networks to low bit representation without a complete drop of performance and remaining stable.	Review	O	0
[line_break_token][line_break_token]I'm overall in favour of accepting this work.	Review	O	0
The paper is well motivated, the authors clearly show the benefits of the proposed approach compared to other approach when using extreme quantization.	Review	O	0
[line_break_token][line_break_token]Main argument:[line_break_token]+ Great overview of previous methods and why they fail when applying extreme quantization[line_break_token]+ Great study of the influence of the sensitivity to the number of bits used for quantization[line_break_token]- It would have been nice if the author had provided standard deviation for the results by running each method several times.	Review	O	0
In particular figure 2.c seem to show that they might be a lot of variance in the results when using low bit quantization.	Review	B-Review	1
[line_break_token]- I feel some details are missing or at least lack some precision.	Review	O	0
For example are the networks pre-trained with full precision in all experiments ?	Review	B-Review	2
if so can you precise it in section 3.1 also ?	Review	I-Review	2
[line_break_token]- The proposed approach seem very similar in spirit to vector quantization, can the author contrast their method to vector quantization ?	Review	O	0
[line_break_token]- In equation (7) doesn't the constant C also depend on alpha and beta ?	Review	O	0
[line_break_token]- In section 5.1 do you also use the two phase training described in section 4.2 ?	Review	O	0
[line_break_token]- Figure 4.c seems to indicate that quantize the generator only is no more a problem ?	Review	O	0
Can you explain why this figure is very different from figure 2.c [line_break_token]- In table 3 how is the number of bits chosen, did you try several different values and report the best performance ?	Review	O	0
[line_break_token][line_break_token]Minor:[line_break_token]- Some of the notations are a bit confusing.	Review	O	0
You call X the tensor of x, I think it would be more clear to say that X is the domain of x.[line_break_token]- I'm surprised by the results in section 3.1, wouldn't the issue described in this section when training standard neural networks ?	Review	O	0
wasn't this known before ?	Review	B-Review	9
[line_break_token]- There is some typos in the text	Review	O	0
hank you for your valuable comments!	Reply	O	0
[line_break_token][line_break_token]Q1: Standard deviation for results[line_break_token]A1: We add the standard deviation for the results of Minmax-Q and QGAN in Table 2 in Section 5.1.	Reply	O	0
Here we quantize both generators and discriminators, thus the standard deviation is not too large.	Reply	B-Reply	1
Comparing the standard deviation for the results of Minmax-Q and QGAN, we can figure out QGAN is more stable as an additional benefit.	Reply	I-Reply	1
We will add the standard deviation for other results in our paper later.	Reply	I-Reply	1
[line_break_token]----------------------------------------------------------[line_break_token]                             |  Minmax-Q |  QGAN     | [line_break_token]----------------------------------------------------------[line_break_token]1-bit | IS (dev)   | 1.16(0.36)  | 3.32(0.23) |[line_break_token]         | FID(dev) | 407.9(67.4) | 96.7(9.8)  |[line_break_token]----------------------------------------------------------[line_break_token]2-bit | IS (dev)   | 2.65(0.18)  | 4.15(0.21) |[line_break_token]         | FID(dev) | 132.4(26.1) | 54.3(4.9)  |[line_break_token]----------------------------------------------------------[line_break_token]3-bit | IS (dev)   | 4.35(0.31)  | 4.46(0.15) |[line_break_token]         | FID(dev) | 65.1(9.8)    | 51.4(3.9)  |[line_break_token]----------------------------------------------------------[line_break_token]4-bit | IS (dev)   | 4.74(0.11)  | 4.60(0.20) |[line_break_token]         | FID(dev) | 40.3(2.9)    | 39.6(4.7)  |[line_break_token]----------------------------------------------------------[line_break_token][line_break_token]Q2: Details of experiments implementations[line_break_token]A2: In Section 3.1 we also quantize the pre-trained full precision model.	Reply	O	0
We will describe the experimental methods clearly in the paper.	Reply	B-Reply	2
[line_break_token][line_break_token]Q3: Difference with vector quantization[line_break_token]A3: The main difference between VQ and QGAN is the optimization objective.	Reply	O	0
VQ uses k-means to optimize the quantization levels directly, while QGAN adopts an EM algorithm to optimize the coefficient of linear quantization.	Reply	B-Reply	3
[line_break_token][line_break_token]Q4: Question on the Equation(7)[line_break_token]A4: is proportional to, thus, in equation(7), C means the log term for the coefficient, which is a constant.	Reply	O	0
[line_break_token][line_break_token]Q5: Experiments in Section 5.1[line_break_token]A5: In Section 5.1 we only use the EM-based quantization method proposed in Section 4.1.	Reply	O	0
The two-phase training described in Section 4.2 are evaluated in Section 5.2, and Table 3 shows the final results combining the methods proposed in 4.1 and 4.2.	Reply	B-Reply	5
[line_break_token][line_break_token]Q6: Question on Figure 2c and 4c[line_break_token]A6: We show the trend of IS over training epoch in Figure 2c, while in Figure 4c we only draw the best IS that can be obtained for a given number of bits.	Reply	O	0
Therefore, the thrashing is not shown in Figure 4 but still exists.	Reply	B-Reply	6
For example, only quantizing the generator to 4 bits using Log-Q can get IS up to over 4.5 but the lowest is only 1.0 (This case is shown in green line in Figure 2c).	Reply	I-Reply	6
For more precise and clear analysis, we will add standard deviation for results as you suggested later.	Reply	I-Reply	6
[line_break_token][line_break_token]Q7: Results in Table 3[line_break_token]A7: We use the two-phase quantization method proposed in 4.2 to obtain the quantized bits in Table 3, that is to say, we greedily first quantize the discriminator and then quantize the generator.	Reply	O	0
This method reduces search times in the solution space efficiently and finally gives the lowest number of bits needed by the generator to meet the given requirement.	Reply	B-Reply	7
We did traverse all cases in extreme low-bit (&lt;= 4-bit) and verified the bit configurations given by our proposed methods are the best performance.	Reply	O	0
[line_break_token][line_break_token]Q8: Results in Section 3.1[line_break_token]A8: GAN is unstable during training.	Reply	O	0
It is more sensitive to quantized errors, which may result in non-convergence, mode collapse, or other problems during training, which motivates us to develop QGAN that quantizes weights more accurately to reduce errors, ensuring training quantized GAN stably.	Reply	B-Reply	9
[line_break_token][line_break_token]Furthermore, we will modify the typos and notations in our paper later.	Reply	I-Reply	10
Thank you again for your constructive feedback!	Reply	O	0
 	Reply	B-Reply	1

This work proposes to defend against adversarial examples by ‚Äúdenoising‚Äù the input image through an autoencoder (a BiGAN trained similar to InfoGAN) before classifying it with a standard CNN.	Review	O	0
The robustness of the model is evaluated on the L_infinity metric against FGSM and PGD.	Review	O	0
[line_break_token][line_break_token]My main criticism is as follows:[line_break_token]* Novelty: several defences are based on a similar principle and the contributions of this paper are unclear.	Review	O	0
[line_break_token]* Insufficient evidence: The evaluation is minimal (only FGSM and PGD, no decision-, transfer- or score-based attacks) and insufficient to support the claims.	Review	O	0
[line_break_token]* Gradient masking: There is at least one clear sign of gradient masking in the results (FGSM performing better than PGD).	Review	O	0
[line_break_token][line_break_token]### Novelty[line_break_token]The only prior work against which the paper compares is DefenseGAN.	Review	O	0
The only advantage over DefenseGAN being stated is performance (because no intermediate optimisation step is used).	Review	B-Review	1
However, besides DefenseGAN there are several other defences that project the input onto the learned manifold of ‚Äúnatural‚Äù inputs, including (see prior work section in [1] for an up-to-date list):[line_break_token][line_break_token]* Adversarial Perturbation Elimination GAN[line_break_token]* Robust Manifold Defense[line_break_token]* PixelDefend (autoregressive probabilistic model)[line_break_token]* MagNets[line_break_token][line_break_token]### Insufficient evidence[line_break_token]The only attacks employed are two gradient-based techniques (FGSM and PGD).	Review	O	0
It is known that gradient-based techniques may suffer from gradient-masking (see also next point) and that the effectiveness of different attacks various greatly (which is why one should use many different attacks).	Review	B-Review	2
Hence, a full evaluation of the model should include score-based and decision-based attacks.	Review	I-Review	2
[line_break_token][line_break_token]### Gradient masking[line_break_token]In Figure 5 (b) the FGSM attack performs better than PGD for epsilon = 0.05 (66.4% vs 71.5%).	Review	O	0
PGD, however, should be strictly more powerful than FGSM if the gradients and the hyperparameters are ok.	Review	B-Review	3
[line_break_token][line_break_token]Gradient masking is the primary reason for why 95% of all proposed defences turned out to be ineffective, and there are good reasons to believe that the same might affect this defence.	Review	I-Review	3
The robustness evaluation has to be much more thorough and convincing before any substantiated claims about the bidirectional architecture proposed here can be derived.	Review	I-Review	3
In addition, the difference to prior work has to be made much clearer.	Review	I-Review	3
[line_break_token][line_break_token][1] Schott et al. ‚	Review	O	0
ÄúTowards the first adversarially robust neural network model on MNIST‚Äù	Review	O	0
Thanks for your comments.	Reply	O	0
And we really appreciate for your contribution and time.	Reply	O	0
Here are our feedbacks to your concerns:[line_break_token][line_break_token]1. "	Reply	O	0
Novelty: several defences are based on a similar principle and the contributions of this paper are unclear."	Reply	O	0
[line_break_token][line_break_token]At the time we submitted our paper, the only relevant defense mechanism we noticed at that time was DefenseGAN.	Reply	B-Reply	1
There were also some other defense mechanisms which leveraged generative models but none of them attempted to extract semantic codes from the adversarial images, which is the main novelty of our model.	Reply	I-Reply	1
[line_break_token][line_break_token]Our contribuition is as following.	Reply	I-Reply	1
FBGAN is the first model trying to understand the semantic meaning of an adversarial image and using this semantic meaning to reconstruct the original one.	Reply	I-Reply	1
Our model is easily to be applied after training on the original data.	Reply	I-Reply	1
On contrary, for example, defenseGAN, which also leverages the generative capability of GAN, needs to do search in the generated sample space every time it meets a new adversarial sample.	Reply	I-Reply	1
FBGAN is not only faster but also has better performance than other generative model based defense methods.	Reply	I-Reply	1
[line_break_token][line_break_token]2. "	Reply	O	0
DefenseGAN is broken: the most similar work, DefenseGAN, has already been broken by Athalye et al.	Reply	O	0
2018, which is not discussed.	Reply	O	0
The attacks deployed in this paper do not break DefenseGAN."	Reply	O	0
[line_break_token][line_break_token]We are very glad this reviewer mentioned the paper by Athalye et al.	Reply	B-Reply	1
2018.	Reply	I-Reply	1
This work provided a very good method called BPDA which can defeat all seemingly strong methods related to so-called obfuscated gradient in last year‚Äôs ICLR.	Reply	I-Reply	1
However, in that paper, they mentioned that defenseGAN was NOT broken at the time they wrote the paper.	Reply	I-Reply	1
In addition, BPDA is an attack method to deal with those obfuscated gradient masking defend methods, which has nothing to do with DefenseGAN nor our FBGAN.	Reply	I-Reply	1
Nonetheless, we are still happy to provide our defense result against BPDA method in that paper.	Reply	I-Reply	1
Please see the second point in our reply to AnonReviewer1 for experiment details.	Reply	I-Reply	1
[line_break_token][line_break_token]3. "	Reply	O	0
Insufficient evidence: The evaluation is minimal (only FGSM and PGD, no decision-, transfer- or score-based attacks) and insufficient to support the claims."	Reply	O	0
[line_break_token][line_break_token]The evaluation methods used in our work are standard methods which are widely used in all other previous adversarial defense works.	Reply	B-Reply	2
We don‚Äôt think the methods this reviewer mentioned are popular nor necessary to show the effectiveness of our work.	Reply	I-Reply	2
[line_break_token][line_break_token]4. "	Reply	O	0
Gradient masking: There is at least one clear sign of gradient masking in the results (FGSM performing better than PGD)."	Reply	O	0
[line_break_token][line_break_token]The reviewer believes that there exists gradient masking in Figure 5 (b).	Reply	B-Reply	3
However, Figure 5 (b) is the results of gray-box attack, and the gray-box attack is calculated on the original non-robust classifier, so there is no gradient masking at all.	Reply	I-Reply	3
Although the gradient masking may result in the fact that the defense accuracy of PGD is better than the defense accuracy of FGSM, it is not always true to claim that the gradient masking is the only reason that causes this phenomenon.	Reply	I-Reply	3
Also our new experiment shows that BPDA, an attack method that works well on defenses utilizing the gradient masking, fails on our FBGAN (the detailed experiment results is shown under the feedback for AnonReviewer1).	Reply	I-Reply	3
[line_break_token][line_break_token]Thanks again for your feedbacks	Reply	O	0

[line_break_token]Summary [line_break_token]This papers presents a pixel-autoregressive model for video generation, in the spirit of VPN (Kalchbrenner‚Äô16).	Review	O	0
The proposed method uses video transformers and is made computationally efficient by extending block-local attention (Parmar‚Äô18, Chen‚Äô18) and sub-scaling (Menick‚Äô19) to 3D volumes.	Review	O	0
The block-local attention is separable, meaning that in theory it is possible to connect every two pixels through a sequence of block-local layers.	Review	O	0
However, for efficient parallelization implement via masking mechanism it is necessary to ignore certain connections, introducing independence assumptions.	Review	B-Review	1
 The model is shown to substantially exceed state-of-the-art in terms of likelihood as well as quantitative and qualitative visual quality on several datasets, including the very challenging Kinetics-600.	Review	I-Review	1
Interestingly, it is shown that the model with spatiotemporal subscaling is more robust to higher generation temperatures, which could imply robustness to accumulating errors.	Review	O	0
[line_break_token][line_break_token]Decision[line_break_token]The paper proposes a well-motivated method backed by solid state-of-the-art results.	Review	O	0
I recommend accept.	Review	O	0
[line_break_token][line_break_token]Pros[line_break_token]- The proposed method is relevant and well-motivated.	Review	O	0
[line_break_token]- The experimental results are strong.	Review	O	0
[line_break_token][line_break_token]Cons[line_break_token]- The paper novelty is somewhat limited as it is mostly a combination of previously existing techniques.	Review	O	0
[line_break_token]- The paper does not provide code which makes the results not easily reproducible.	Review	O	0
I think a minimal example of the code should be provided that is trainable at least on a simple dataset.	Review	B-Review	3
[line_break_token][line_break_token]Questions[line_break_token]- No videos are provided.	Review	O	0
Please provide an (anonymous immutable) link to video results.	Review	B-Review	4
[line_break_token]- Strong aliasing artifacts can be seen in the supplement on the Kinetics data, such as vegetables becoming increasingly ‚Äúblocky‚Äù as well as general cube-like aliasing artifacts in Fig.	Review	O	0
9.	Review	B-Review	5
This indicates that the introduced independence assumptions are likely hurting the video quality.	Review	I-Review	5
The paper discusses this in the appendix C, stating that there seems to be no remedy for the independence assumptions that does not increase the computational cost.	Review	I-Review	5
However, this is exactly the problem that latent variable models such as variational inference or normalizing flows are designed to address.	Review	I-Review	5
Would a certain combination of latent variable models with the proposed autoregressive approach alleviate these issues?	Review	I-Review	5
[line_break_token][line_break_token]Minor comments[line_break_token]- Contrary to the summary in the related work section, Kumar‚Äô19 does not use variational inference and operates purely on the normalizing flows technique.	Review	O	0
Similarly, Mathieu‚Äô16 and Vondrick‚Äô16 do not use variational inference either instead relying on adversarial techniques.	Review	B-Review	6
The paper correctly states that Lee‚Äô18, Castrejon‚Äô19 use variational inference.	Review	I-Review	6
[line_break_token]- Figure 2 is never referred to in the text.	Review	O	0
[line_break_token]	Review	O	0
e updated our related work section slightly so that it becomes clearer that many of the mentioned works (after discussing VAE based approaches) are actually completely different directions and not additions upon VAEs.	Reply	B-Reply	6
[line_break_token][line_break_token]We added a reference for Figure 2 in section 4.2, paragraph "Qualitative Observations"	Reply	I-Reply	7

# Review for "Neural Belief Representations"[line_break_token][line_break_token][line_break_token][line_break_token]The authors argue in the favor of belief representations for partial observable Markov decision processes.	Review	O	0
The central argument is that uncertainty needs to be represented to make optimal decision making.	Review	O	0
For that aim, three belief representations based on sufficient statistics of the future are evaluated and compared in a set of disective studies.	Review	O	0
Those studies find that predicting the future results in uncertainty being represented in the state representations, although they differ in quality.	Review	O	0
[line_break_token][line_break_token]I found the paper hard to follow for various reasons.	Review	O	0
[line_break_token][line_break_token]- NCE is reviewd, while CPC is not.	Review	O	0
I would have found a review of CPC as well to help my understanding, especially to draw the line between CPC and CPC|Action.	Review	B-Review	1
[line_break_token]- In 2.1.,	Review	O	0
is defined as a probability, while it is the output of a neural network later.	Review	B-Review	2
This is formally incompatible, and I found  the connection not well explained.	Review	I-Review	2
From my understanding, is a vector that represents the sufficient statistics if learning works.	Review	I-Review	2
The probability interpretation is thus stretched.	Review	I-Review	2
[line_break_token]- The architecture description (starting from the second paragraph on page 4) feels cluttered.	Review	O	0
It was clearly written as a caption to Figure 1 and hence should be placed as such.	Review	B-Review	3
Still, stand alone texts are important and in my humble opinion should be augmented with equations instead of drawings.	Review	I-Review	3
While the latter can help understanding, it lacks precision and makes reproduction hard.	Review	I-Review	3
[line_break_token]- The MLP to predict the ground truth is not sufficiently described in the main text.	Review	O	0
I think it needs to go there, as it is quite central to the evaluation.	Review	B-Review	4
[line_break_token][line_break_token]Since the manuscript is half a page under the limit, such improvements would have been feasible.	Review	O	0
[line_break_token][line_break_token]Apart from the quality of the manuscipt, I like the fact that a disective study was done in such a way.	Review	O	0
[line_break_token][line_break_token]However, I would have liked to see more comparisons, e.g. in&nbsp;environments it is also possible to obtain quite good approximations of the true posterior via particle filtering.	Review	O	0
Also, other more straightforward approaches such as MDN-RNNs can represent multiple maxima in the probability landscape; this would have enabled to examine the benefit of conditioning on actions in a different context.	Review	B-Review	5
[line_break_token][line_break_token]Right now, it is unclear what the paper is about.	Review	I-Review	6
On the one hand, it does a focused disective study with well controlled experiments, which would be a good fit if many different models were considered.	Review	I-Review	6
On the other hand, it advertsises CPC|Action; but then it falls short in evaluating the method in more challenging environments.	Review	I-Review	6
[line_break_token][line_break_token]To sum it up, I feel that the paper needs to be clearer in writing and in experimental structure.	Review	O	0
The currently tested hypothesis, "does CPC|Action perform better than CPC and FP in a set of well controlled toy environments" is, imho, not of broad enough interest.	Review	O	0
Thank you for reading and commenting on our work.	Reply	O	0
We address the following main concerns.	Reply	O	0
[line_break_token][line_break_token]The reviewer has raised the issue that the paper is hard to follow and recommends a list of changes to improve the quality of the manuscript.	Reply	O	0
 In the revised manuscript we will have addressed these issues. (	Reply	O	0
Items 1-4 the change list in general response.)	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Little reviewing of CPC, CPC|Action: We will add a more detailed review to address this issue.	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
The probability interpretation for b_t is stretched: We have been imprecise here and we will fix it.	Reply	B-Reply	2
Indeed, b_t is the output of a recurrent neural network.	Reply	I-Reply	2
We want to clarify that the output of the neural network is itself not a probability vector, but just the output of a neural network; however the information contained in this output is quite rich, and our experiments show how this output is encoding various pieces of information about the history, approximating an encoded sufficient statistic of the history.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
The architecture description should be precise: We will fix the presentation accordingly.	Reply	B-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
The MLP to predict the ground truth is not sufficiently described in the main text: We present it as an implementation detail in the appendix, but if after all the other changes there is space left, we will move it to the main text.	Reply	B-Reply	4
In any case we will make sure that the main text clearly points to the implementation details.	Reply	I-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
The reviewer has also raised the concern that our results only  provide evidence for the hypothesis ‚Äúthat CPC|Action performs better than CPC and FP in a set of well controlled toy environments' and  ‚Äòit falls short from evaluating in more challenging environments‚Äô.	Reply	O	0
[line_break_token][line_break_token]    Our goal in this work is to investigate the effectiveness of various unsupervised training schemes to learn belief representations.	Reply	O	0
This paper fits in the literature as a "proof-of-concept" work where we do something non-trivial that has not been done before, and we take a careful look at we have developed to give the community a good understanding of it.	Reply	B-Reply	6
[line_break_token][line_break_token]    Hence, our main purpose was not to find out whether CPC|Action would perform better than CPC/FP, but whether it would be at all possible to learn representations that can encode meaningful beliefs about the environment state.	Reply	I-Reply	6
Part of understanding these belief representations requires measuring performance and comparing different approaches (CPC|Action, CPC and FP in our case), but the message is broader than the outcome of testing whether one method performs better than another one.	Reply	I-Reply	6
[line_break_token][line_break_token]    Our contributions are of broad interest because the task of learning belief representations using unsupervised prediction tasks is more challenging and less demanding than doing so with supervision.	Reply	I-Reply	6
It is worth pointing out that there is no evidence that learn belief representations with supervision on the state is easy, so what we have demonstrated was by no means obvious or easy.	Reply	I-Reply	6
[line_break_token][line_break_token]6.	Reply	O	0
More comparisons, e.g., particle filtering and MDN-RNNs.	Reply	O	0
[line_break_token][line_break_token]    While we recognize that adding these comparisons would strengthen the experimental results, we believe that their absence is not detrimental to the contributions of the paper, taking our goal into consideration.	Reply	O	0
There are some remarks to be made about each of the suggested approaches, and we will add these to the main paper, so that we clarify the role of the experimental study in the paper and in the literature.	Reply	B-Reply	5
[line_break_token][line_break_token]    Particle filtering would presumably give better beliefs, but for a price: It would require more human intervention in the training than the kind of learning regime we are interested in.	Reply	I-Reply	5
We wish learning to be as close to end-to-end as possible.	Reply	I-Reply	5
Nevertheless, the performance of PF would be a good "ceiling line" for the performance of the different end-to-end approaches.	Reply	I-Reply	5
[line_break_token][line_break_token]    We see Mixture Density Networks being used in three places: In the probes (belief decoders), in the CPC variants, or in the frame prediction.	Reply	I-Reply	5
For the first two possibilities, we have already represented the distribution explicitly, which sidesteps the need for networks that can encode probabilities.	Reply	I-Reply	5
For the frame prediction, especially multistep, MDNs and other networks (e.g., VAEs or IQNs) might make a significant difference, especially if we were to consider frame prediction with action-conditioning.	Reply	I-Reply	5
We are considering exploring these in future work, to know how far CPC|Action can go, and whether it can be used to train representations that are as rich as those one could conceivably train with networks that predict distributions.	Reply	I-Reply	5

The paper propose fully parametrizing CNNs with a single, low-rank tensor.	Review	O	0
As compared to the previous work which parametrizing individual layer by tensor representation, this paper combine all parameters from each layers and model them as one tensor.	Review	O	0
This allows to regularize the whole network and drastically reduce the number of parameters by imposing a low-rank structure on that tensor.	Review	O	0
The experiments show higher compression rates with negligible drop in accuracy for human pose estimation.	Review	O	0
[line_break_token][line_break_token]The paper is well written by firstly introducing basic tensor decomposition and operations, then presenting how to use them to parametrizing CNN.	Review	B-Review	1
 However, the concept of using tensor decomposition to parametrize the CNN is known, this paper is an extension by considering all layers together.	Review	I-Review	1
Therefore, the originality is limited and incremental.	Review	I-Review	1
[line_break_token][line_break_token]The parameters from different layers may have very different sizes, which make this method not very practical.	Review	I-Review	2
Although we can manually use the same size of parameters for all layers, the problem of redundant information will become more severe.	Review	I-Review	2
[line_break_token][line_break_token]In general, the parameters in different layers are supposed to be very different and uncorrelated.	Review	I-Review	3
In this paper, the parameters from different layers are put together and low-rank structure is assumed.	Review	I-Review	3
Hence, one question of why this will work well is not clear.	Review	I-Review	3
 Furthermore, there is no theoretical support for the method to obtaining the higher compression.	Review	I-Review	3
[line_break_token][line_break_token]The authors claim Tucker is easy to control the rank thus considered as the most flexible compression method.	Review	I-Review	4
The justification of this claim should be provided, or the detailed experiment comparisons should be given.	Review	I-Review	4
Why Tucker is more flexible is not clear.	Review	I-Review	4
[line_break_token][line_break_token]	Review	O	0
We are glad that the reviewer appreciated the paper and thank them for the feedback.	Reply	O	0
[line_break_token][line_break_token]Regarding the novelty: we detailed the existing work in detail and explicitly detail how ours differs.	Reply	B-Reply	1
To summarise, while parameterizing individual convolutional has been the subject of extensive studies, we are the first to propose an architecture which is jointly parametrized by a single, high-order tensor, allowing for large compression ratios, and performance improvements when comparing to both the baseline or previous methods.	Reply	I-Reply	1
[line_break_token][line_break_token]Indeed we impose that all the parametrized layer have the same kernel size, however we also introduce an architecture that satisfies this and obtains state-of-the-art results for body pose estimation.	Reply	I-Reply	2
This work can be extended to kernels of different sizes but this is outside the scope of this paper.	Reply	I-Reply	2
[line_break_token][line_break_token]The reviewer states that ‚Äúin general, the parameters in different layers are supposed to be very different and uncorrelated‚Äù.	Reply	O	0
This is one of the interesting findings of the paper: there is large amount of redundancy in the network that can be leveraged, as demonstrated by our experimental results.	Reply	B-Reply	3
This is in line with recent findings in the literature (Du & Lee, 2018; Soltanolkotabi et al.,	Reply	O	0
2018) that indicate high level of redundancy in the parameters of deep nets, which makes learning possible.	Reply	B-Reply	3
High order tensor are ideal for leveraging such redundancy.	Reply	I-Reply	3
[line_break_token][line_break_token]About the flexibility of Tucker: this can be readily observed from the mathematical formulation.	Reply	I-Reply	4
We are able to control the size of each mode of the core individually, allowing us to fine-tune the low-rank structure.	Reply	I-Reply	4
Other decompositions such as Canonical-Polyadic or Matrix-Product-State/Tensor-Train assume some specific structure which can be less flexible (i.e. CP is equivalent to Tucker with a super-diagonal core while MPS/TTrain is composed of third order cores).	Reply	I-Reply	4
 We will discuss this in the paper.	Reply	I-Reply	4

1.	Review	O	0
Summary[line_break_token][line_break_token]The authors employ a multi-agent learning approach for learning how to set payoffs optimally for crowdsourcing contests[line_break_token]and auctions.	Review	O	0
Optimality means e.g. incentive alignment (the principal problem) between the principal (e.g. the organizer) and participants (e.g. bidders), assuming e.g. that participants can be strategic about their behavior.	Review	O	0
In this work the principal uses ReLU-log utility.	Review	O	0
[line_break_token][line_break_token]First, the authors use fictitious play and multi-agent RL to train agents on a distribution of payoffs.	Review	O	0
Then, a neural net is fitted to the samples (payyoffs, expected principal utility), and finally iteratively attempts to improve the payoffs using mirror ascent within the convex set of admissable payoffs.	Review	O	0
[line_break_token][line_break_token]The authors compare the payoffs with theoretically known solutions and in situations where the optimal solution is not known.	Review	O	0
[line_break_token][line_break_token]3, 4-agent all-pay auction (Nash eq known).	Review	O	0
[line_break_token]Same as above, but with noise added to bids (Nash eq not known).	Review	O	0
[line_break_token]The authors analyze in some detail how the principal's utility and bidder ranking behave as the participants' bids change.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
Decision (accept or reject) with one or two key reasons for this choice.	Review	O	0
[line_break_token][line_break_token]Reject.	Review	O	0
Although the high-level approach is interesting (use learning to design auctions for cases where no theoretical solution is known), the actual experimental results and methodological improvement over e.g. Dutting 2017 are weak.	Review	B-Review	1
The authors only consider 3, 4-agent auctions.	Review	I-Review	1
There are no other learned baselines (e.g., constrained optimization without neural nets) that the authors could consider.	Review	I-Review	1
[line_break_token][line_break_token]3.	Review	O	0
Supporting arguments[line_break_token][line_break_token]See above.	Review	O	0
[line_break_token][line_break_token]4.	Review	O	0
Additional feedback with the aim to improve the paper.	Review	B-Review	2
Make it clear that these points are here to help, and not necessarily part of your decision assessment.	Review	I-Review	2
[line_break_token][line_break_token]M-EMA and M-EMD: ascent and descent?	Review	I-Review	3
in Algo 1, 2?	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]--- [line_break_token]I've read the rebuttal, but still lean towards reject.	Review	O	0
The scope/analysis of the experiments (e.g. auction type), still seems limited, even though both agents and mechanism are adaptive.	Review	B-Review	1
hank you very much for reviewing our paper and for your feedback.	Reply	O	0
Also, thank you for raising your concerns regarding a comparison of our work to Dutting et.	Reply	B-Reply	1
al.	Reply	I-Reply	1
We mention this work (among others) at the end of the paper, however, maybe it deserves a more pointed comparison.	Reply	I-Reply	1
[line_break_token][line_break_token]Your review calls out the marginal improvement relative to previous work in two main ways: 1) the methodology and 2) the experimental results.	Reply	O	0
[line_break_token][line_break_token]Thank you for identifying these concerns, we will comment on the methodology and experimental results both relative to Dutting et.	Reply	B-Reply	1
al.	Reply	I-Reply	1
specifically and in general.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding methodology, our main contribution is to see both sides of a mechanism (both the auctioneer and the bidders) as adaptive.	Reply	I-Reply	1
Dutting et.	Reply	I-Reply	1
al.	Reply	I-Reply	1
on the other hand uses a dominant strategy incentive compatible argument and models the bidders as truth-tellers -- the bidders are static, i.e., not adaptive learning agents.	Reply	I-Reply	1
To our knowledge, designing mechanisms based on the behavior of adaptive learning agents is novel and more general than previous approaches in the literature.	Reply	I-Reply	1
We did not emphasize this distinction as much as we should in the original submission.	Reply	I-Reply	1
We appreciate you bringing this to our attention.	Reply	I-Reply	1
[line_break_token]As you pointed out, we consider auctions without any known solution.	Reply	I-Reply	1
In contrast, previous approaches including Dutting et.	Reply	I-Reply	1
al.	Reply	I-Reply	1
focus on specific classes of mechanisms where optimal behavior is already known.	Reply	I-Reply	1
Therefore, our approach enables the design of mechanisms for a much wider class of games for which computing equilibrium strategies is intractable.	Reply	I-Reply	1
For example, note that our approach places no restriction on the number of bidders in the auction (as opposed to theoretical analyses).	Reply	I-Reply	1
Again, this is made possible by bringing adaptive learning agents into the pipeline.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding experimental results, your review states that we only considered 3 and 4 bidder auctions, however, we point out that we also presented results for a noisy 10 bidder auction in Figure 6 and Table 1.	Reply	I-Reply	1
We will restructure the paper to avoid confusion and make the noisy 10 bidder auction stand out more.	Reply	I-Reply	1
[line_break_token]We also note that Dutting et al.	Reply	I-Reply	1
considers a different class of auctions (truthful auctions vs allpay auctions in our paper) so our results cannot be readily compared in a quantitative way.	Reply	I-Reply	1
We will highlight this difference in the paper so it is more clear and add a more in depth comparison to that work.	Reply	I-Reply	1
[line_break_token]Regarding learned experimental baselines, we only assume differentiable models.	Reply	I-Reply	1
For example, we could have fit a Gaussian process instead.	Reply	I-Reply	1
We chose neural networks as they are known to be strong function approximators (and generalizers), and we felt they would be most familiar to the ICLR community.	Reply	I-Reply	1
However, our choice of neural networks is not critical to the general applicability of our approach or our novel perspective of both sides of the mechanism as adaptive.	Reply	I-Reply	1
We will include experiments with other differentiable models in the appendix.	Reply	I-Reply	1
[line_break_token]We point out though that Figure 3 and 7 both show the neural network‚Äôs ability to fit the data.	Reply	I-Reply	1
Figure 3 displays a near perfect fit suggesting the MLP model class was sufficient for the noiseless 2 bidder setting.	Reply	I-Reply	1
Figure 7 shows that there is potentially room for improvement in the noisy 10 bidder setting.	Reply	I-Reply	1
We are considering alternative architectures for this setting, but per your suggestion, we will consider other differentiable models as well.	Reply	I-Reply	1
[line_break_token][line_break_token]Lastly, thank you for pointing out the typo in Algorithm 2.	Reply	I-Reply	3
The correct reference should be M-EMA.	Reply	I-Reply	3
[line_break_token][line_break_token]We feel this rebuttal addresses your two concerns in detail: 1) strength of methodology and 2) experimental results.	Reply	O	0
We would appreciate it if you would please consider raising your score	Reply	O	0

This paper analyzes the statistics of activation norms and Jacobian norms for randomly-initialized ReLU networks in the presence (and absence) of various types of residual connections.	Review	O	0
Whereas the variance of the gradient norm grows with depth for vanilla networks, it can be depth-independent for residual networks when using the proper initialization.	Review	O	0
[line_break_token][line_break_token]The main theoretical results stem from a norm propagation duality that allows computations of certain statistics using simplified architectures.	Review	O	0
As far as I know, this is a novel way of analyzing multi-pathway architectures, and the method and the implied results will be of interest to deep-learning theorists.	Review	O	0
[line_break_token][line_break_token]There are two types of empirical results, one to verify the theoretical predictions, and the other to see if those predictions translate into improved generalization performance on some real-world tasks.	Review	O	0
Figures 2 and 3 show good agreement with theory.	Review	O	0
I am less convinced by Fig 4.	Review	B-Review	1
Unless I missed something, I thought the implication from the theoretical analysis was that multi-pathway models should behave better than single-pathway models at large depth, and for single-pathway models concatenated ReLU may have slightly better large-depth behavior than standard ReLU.	Review	I-Review	1
Doesn't this suggest that for large depth DenseNet ~= ResNet &gt; CR &gt; ReLU?	Review	O	0
Is the good performance of CR supposed to be understood as supporting evidence for the theoretical analysis?	Review	B-Review	1
Or is the point more like "the theory suggests CR might be interesting, and indeed it performs well, but we leave the details of generalization performance to a future study"?	Review	I-Review	1
It would be important to specify the desired interpretation here.	Review	I-Review	1
[line_break_token][line_break_token]But I think regardless of the interpretation, the empirical results are not strong enough to stand on their own as support for CR, especially since this type of architecture has been introduced and studied previously (c.f.	Review	I-Review	2
also the looks-linear setup from [1]).	Review	I-Review	2
Therefore my evaluation is mostly based on the theoretical contributions, which I think are themselves are probably sufficient for publication.	Review	I-Review	2
[line_break_token][line_break_token]One main area for improvement is in the related work.	Review	I-Review	3
A significant line of work is omitted that studies higher-order statistics of Jacobian matrices in the large-depth, infinite-width regime [2-8], and while this is at infinite width, it work for any non-linearity, so is an important point for comparison.	Review	I-Review	3
Other kinds of initialization schemes are also relevant for comparison, e.g. [9-10].[line_break_token][line_break_token][1] Balduzzi, David, et al. "	Review	O	0
The shattered gradients problem: If resnets are the answer, then what is the question?."	Review	O	0
Proceedings of the 34th International Conference on Machine Learning-Volume 70.	Review	O	0
JMLR.	Review	O	0
org, 2017.	Review	O	0
[line_break_token][2] Pennington, Jeffrey, Samuel Schoenholz, and Surya Ganguli. "	Review	O	0
Resurrecting the sigmoid in deep learning through dynamical isometry: theory and practice."	Review	O	0
Advances in neural information processing systems.	Review	O	0
2017.	Review	O	0
[line_break_token][3] Pennington, Jeffrey, Samuel Schoenholz, and Surya Ganguli. "	Review	O	0
The emergence of spectral universality in deep networks."	Review	O	0
International Conference on Artificial Intelligence and Statistics.	Review	O	0
2018.	Review	O	0
[line_break_token][4] Hayase, Tomohiro. "	Review	O	0
Almost Surely Asymptotic Freeness for Jacobian Spectrum of Deep Network."	Review	O	0
arXiv preprint arXiv:1908.03901 (2019).	Review	O	0
[line_break_token][5] Tarnowski, Wojciech, et al. "	Review	O	0
Dynamical Isometry is Achieved in Residual Networks in a Universal Way for any Activation Function."	Review	O	0
The 22nd International Conference on Artificial Intelligence and Statistics.	Review	O	0
2019.	Review	O	0
[line_break_token][6] Burkholz, Rebekka, and Alina Dubatovka. "	Review	O	0
Initialization of ReLUs for Dynamical Isometry."	Review	O	0
arXiv preprint arXiv:1806.06362 (2018).	Review	O	0
[line_break_token][7] Xiao, Lechao, et al. "	Review	O	0
Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks."	Review	O	0
International Conference on Machine Learning.	Review	O	0
2018.	Review	O	0
[line_break_token][8] Chen, Minmin, Jeffrey Pennington, and Samuel Schoenholz. "	Review	O	0
Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks."	Review	O	0
International Conference on Machine Learning.	Review	O	0
2018.	Review	O	0
[line_break_token][9]Sutskever, Ilya, et al. "	Review	O	0
On the importance of initialization and momentum in deep learning."	Review	O	0
International conference on machine learning.	Review	O	0
2013.	Review	O	0
[line_break_token][10] Le, Quoc V., Navdeep Jaitly, and Geoffrey E. Hinton. "	Review	O	0
A simple way to initialize recurrent networks of rectified linear units."	Review	O	0
arXiv preprint arXiv:1504.00941 (2015).	Review	O	0
e greatly appreciate pointing us to the missing references.	Reply	B-Reply	3
As pointed out by the reviewer, the missing references analyze properties of the input - output Jacobian of various network architectures at initialization at the regime of infinite width and depth.	Reply	I-Reply	3
Specifically, the mean squared singular value, as well as the entire distribution of squared singular values of this Jacobian are analyzed in pursuit of dynamical isometry, a state in which the squared singular values of the input - output jacobian are concentrated around 1.	Reply	I-Reply	3
Dynamical isometry is indeed a much stronger condition then the Jacobian norm, as it requires access to the entire spectrum.	Reply	I-Reply	3
However, in previous work, this is done using various forms of infinite width approximations.	Reply	I-Reply	3
[line_break_token]Instead, our work focuses on finite depth corrections to the statistics of various quantities concerning the squared Frobenius norm of the full per-layer Jacobian (derivative of the output with respect to the weights).	Reply	I-Reply	3
Our approach can, therefore, be seen as a complementary approach to analyzing the dynamics at the start of training.	Reply	I-Reply	3
We emphasize that our results cannot be obtained using large width approximations, since we seek to characterize the effect of both depth and width on the Jacobian.	Reply	I-Reply	3
[line_break_token]We have updated the manuscript with references to the relevant prior work, as well as added some discussion in order to better position our work in relation to it.	Reply	I-Reply	3
[line_break_token][line_break_token]Indeed supporting CR is only a minor goal of our work.	Reply	I-Reply	1
However, since we demonstrated an advantage of CR layers over standard ReLU layers from the initialization perspective, we felt it would be beneficial to compare these empirically to other methods in settings in which multi pathway architectures are not yet dominant.	Reply	I-Reply	1
Following the feedback from the reviewers, we have decided to move this empirical section to the appendix.	Reply	I-Reply	1

In this paper the authors present a differentiable objective for slow feature analysis, to facilitate end-to-end training.	Review	O	0
  I am not clear on the novelty of this formulation, as it appears to have been proposed in a similar form in previous works (e.g., A maximum-likelihood interpretation for slow feature analysis by Turner and Sahani - Eq., (	Review	B-Review	1
2)) and can probably be considered straightforward.	Review	I-Review	1
 Nevertheless, the approximate whitening layer and the way it is used is a smart approach for this problem.	Review	O	0
 The experiments are interesting and shed light on the properties of the method.	Review	O	0
 In summary, the paper may lack technical novelty in some respect, but the experiments are convincing in terms of proof-of-concept, and the approach is smart.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
Dear Reviewer,[line_break_token][line_break_token]Your intuition is right, the objective function itself is not novel and is indeed straightforward to derive.	Reply	O	0
In fact, it is just an unordered version of the original SFA loss (which is in itself differentiable already).	Reply	B-Reply	1
[line_break_token][line_break_token]The whole novelty lies in the idea of using the described whitening layer, thus, incorporating the constraints in the model rather than the loss function.	Reply	I-Reply	1
The paper you mentioned can be seen as doing the latter.	Reply	I-Reply	1
Thus, we understand it to fall in line with "Bergstra, J. and Bengio, Y. - Slow, decorrelated features for pretraining complex celllike networks" where a penalty term for covariances is included in the loss function.	Reply	I-Reply	1
Futhermore, the probabilistic model by Turner and Sahani is not optimized by gradient-descent, but trained by the Expectation Maximization algorithm.	Reply	I-Reply	1
[line_break_token][line_break_token]We tried to clarify that the derivation of the objective function is not an involved or novel part of our algorithm, e.g., in the description for equation (2).	Reply	I-Reply	1
With the introductory sentence to Section 5 ("The key idea for gradient-based SFA is that a whitening layer can be applied to any differentiable architecture [..] to enforce outputs that approximately obey the SFA constraints while the architecture stays differentiable."),	Reply	I-Reply	1
we hope that this is helps to clearly pinpoint what the original parts of our work are.	Reply	I-Reply	1
[line_break_token][line_break_token]Thank you for taking the time and effort to review our paper!	Reply	O	0
[line_break_token]Hopefully, you find the core idea more unambigiously presented in the current revision.	Reply	O	0
[line_break_token][line_break_token]Respectfully,[line_break_token]the Author	Reply	O	0

This paper proposes a recurrent architecture for simultaneously predicting motion and action states of agents.	Review	O	0
[line_break_token]The paper is well written, clear in its presentation and backed up by good experiments.	Review	O	0
[line_break_token]They demonstrate that by forcing the network to predict motion has beneficial consequences on the classification of actions states,[line_break_token]allowing more accurate classification with less training data.	Review	O	0
[line_break_token]They also show how the information learned by the network is interpretable and organised in a hierarchy.	Review	O	0
[line_break_token][line_break_token]Weaknesses:[line_break_token]- a critical discussion on the interplay between motion an behaviour that is needed to experience the benefits of their proposed model is missing from the paper.	Review	O	0
[line_break_token]- moreover, a discussion on how this approach could scale to more challenging scenarios "involving animals" and visual input for instance and more general "behaviours" is also missing;[line_break_token]The criticism here is pointed at the fact that the title/abstract claim general behaviour modelling, whilst the experiments are focused on two very specific and relatively simple scenarios,[line_break_token]making the original claim a little bit far fetched unless its backed up by additional evidence.	Review	O	0
[line_break_token]Using "Insects", or "fruit flies" would be more appropriate than "animals".	Review	B-Review	2
Thank you for your review.	Reply	O	0
We have added a discussion at the end of the paper about scaling to more complex data.	Reply	B-Reply	2
[line_break_token][line_break_token]Regarding a critical discussion on the interplay between motion and behavior, in the introduction we explain that motion trajectories and actions represent behavior at different levels of timescales, and that actions can be detected from motion trajectories.	Reply	I-Reply	1
If your point refers to a more biological explanation, such as the one we discuss in our global response, I am also happy to add that to the introduction of the paper	Reply	I-Reply	1

Overview:[line_break_token]This paper is dedicated to proposing a self-supervised objective, local prior matching (LMP), for speech recognition.	Review	O	0
This approach can take advantage of vase quantities of unlabeled speech data.	Review	O	0
What' more, the objective is simple to implement and theoretically well-motivated.	Review	O	0
In the paper, based on a supervised pretrained model, it then finetunes 360 hours with unlabeled data and LPM reduces the WER consistently.	Review	O	0
They also conduct extensive ablation experiments to show the effect of their self-supervised approach.	Review	O	0
[line_break_token][line_break_token]Strength Bullets:[line_break_token]1.	Review	O	0
I think this self-supervised learning objective (LMP) is very novel.	Review	O	0
The motivation that the source of indirect supervision on processing unlabeled speech comes from prior knowledge about the world and the context of the speech makes sense to me.	Review	O	0
The author combines the Bayesian method to build the model which is aligned with the motivation.	Review	O	0
They also provide clear and well-organized derivations.	Review	O	0
[line_break_token]2.	Review	O	0
The paper performs extensive ablation studies over all components, including beam size, mixing ratio, LPM weights, model update strategies, model initialization, length filtering and choice of language models.	Review	O	0
It provides convincing evidence of the effect of each component.	Review	O	0
[line_break_token]3.	Review	O	0
It provides interesting experiments results to study the relationship between the amount of unlabelled data for self-supervision and final performance.	Review	O	0
And LPM can surpass the performance of using 360 hours of labeled data by taking advantage of about twice the amount of unlabeled data.	Review	O	0
[line_break_token][line_break_token][line_break_token]Weakness Bullets:[line_break_token]1.	Review	O	0
The paper only evaluates their method on LibriSpeech dataset.	Review	B-Review	1
Although this dataset is popular, one or two more datasets will be more convincing.	Review	I-Review	1
[line_break_token]2.	Review	O	0
For bayesian based methods, it is well known that it performs badly in high dimensional space.	Review	B-Review	2
The reason is that we can not sample enough data points to obtain a good posterior estimation.	Review	I-Review	2
Could you provide more analysis about the quality of posterior with different amount of sampled data?	Review	I-Review	2
[line_break_token]3.	Review	O	0
For the experiment between the amount of unlabelled data for self-supervision and final performance, it would be better the author can provide a curve with more results.	Review	B-Review	3
[line_break_token][line_break_token]Recommendation:[line_break_token]I think it is a good paper.	Review	O	0
The proposed approach is useful.	Review	O	0
This is a weak accept.	Review	O	0
e thank the reviewer for the thoughtful comments.	Reply	O	0
Below are our itemized responses to address the concerns.	Reply	O	0
[line_break_token][line_break_token]Q1: The paper only evaluates their method on LibriSpeech dataset.	Reply	O	0
Although this dataset is popular, one or two more datasets will be more convincing.	Reply	O	0
[line_break_token][line_break_token]A1: We completely agree with the reviewer more datasets would certainly support our claims.	Reply	O	0
However, we are limited by publicly available ASR datasets which are sufficiently large and challenging to demonstrate semi-supervised learning at scale, which is a condition researchers have found difficult to achieve any improvement [1].[line_break_token][line_break_token]We point out that prior work in this domain has used LibriSpeech as a sole benchmark [2; 3; 4; 5]. Also, the improvement from running our algorithm on LibriSpeech is more than 82% WER recovery rate, which is notably larger than prior work.	Reply	B-Reply	1
Finally, we plan to test Local Prior Matching on other datasets and domains in future work.	Reply	I-Reply	1
[line_break_token][line_break_token][1] Drexler, Jennifer, and James Glass. "	Reply	O	0
Combining end-to-end and adversarial training for low-resource speech recognition."	Reply	O	0
2018 IEEE Spoken Language Technology Workshop (SLT).	Reply	O	0
IEEE, 2018.	Reply	O	0
[line_break_token][2] Kahn, Jacob, Ann Lee, and Awni Hannun. "	Reply	O	0
Self-Training for End-to-End Speech Recognition."	Reply	O	0
arXiv preprint arXiv:1909.09116 (2019).	Reply	O	0
[line_break_token][3] Hori, Takaaki, et al. "	Reply	O	0
Cycle-consistency training for end-to-end speech recognition."	Reply	O	0
ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).	Reply	O	0
IEEE, 2019.	Reply	O	0
[line_break_token][4] Liu, Alexander H., Hung-yi Lee, and Lin-shan Lee. "	Reply	O	0
Adversarial training of end-to-end speech recognition using a criticizing language model."	Reply	O	0
ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).	Reply	O	0
IEEE, 2019.	Reply	O	0
[line_break_token][5] Hayashi, Tomoki, et al. "	Reply	O	0
Back-translation-style data augmentation for end-to-end ASR."	Reply	O	0
2018 IEEE Spoken Language Technology Workshop (SLT).	Reply	O	0
IEEE, 2018.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q2: For bayesian based methods, it is well known that it performs badly in high dimensional space.	Reply	O	0
The reason is that we can not sample enough data points to obtain a good posterior estimation.	Reply	O	0
Could you provide more analysis about the quality of posterior with different amount of sampled data?	Reply	O	0
[line_break_token][line_break_token]A2: This is a great question.	Reply	O	0
Unfortunately, since we are working with a real dataset, we do not have access to the ground truth posterior p(y|x) and therefore cannot directly evaluate the quality of our proposed estimator.	Reply	B-Reply	2
However, Table 1 does provide indirect analysis about the quality of the estimator with respect to different amounts of sampled data, with the assumption that the performance should be better if the ASR model distribution is matched to a better posterior estimator.	Reply	I-Reply	2
As discussed in Section 4.1, the estimator usually gets better with more samples.	Reply	I-Reply	2
[line_break_token][line_break_token]We hypothesize that the reason this estimator works well with few samples (from 1 to 16) in this high dimensional text sequence space is because the posterior p(y|x) is extremely spiky with only a few y having non-negligible probability mass.	Reply	I-Reply	2
This assumption is commonly acknowledged and enables estimation of the partition function p(x) = \int_y p(x, y) using beam search hypotheses in many ASR studies [3;4;5].[line_break_token][line_break_token][3] Collobert, R., Hannun, A. &amp; Synnaeve, G.. (2019).	Reply	O	0
A fully differentiable beam search decoder.	Reply	O	0
Proceedings of the 36th International Conference on Machine Learning, 2019.	Reply	O	0
[line_break_token][4] Povey, Daniel, et al. "	Reply	O	0
Boosted MMI for model and feature-space discriminative training."	Reply	O	0
ICASSP, 2008.	Reply	O	0
[line_break_token][5] Povey, Daniel, and Philip C. Woodland. "	Reply	O	0
Minimum phone error and I-smoothing for improved discriminative training."	Reply	O	0
ICASSP, 2002.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q3:  For the experiment between the amount of unlabelled data for self-supervision and final performance, it would be better the author can provide a curve with more results.	Reply	O	0
[line_break_token][line_break_token]A3: We thank the reviewer for the great suggestion, and we are running more experiments varying the amount of unlabeled data at this moment.	Reply	O	0
We will report the numbers once the experiments are finished	Reply	B-Reply	3

This paper develops a theoretical guarantee for the convergence of the training error.	Review	O	0
The result is quite general that covers the training of a wide range of neural network models.	Review	O	0
The key idea of the paper is approximate the training loss by its linear approximation.	Review	O	0
Since its linearity in the variables (thus convex), the authors plug in results that has been developed in the literature of online learning.	Review	O	0
[line_break_token][line_break_token]This paper has good novelty in using the Taylor approximation thus greatly simplifying the analysis of the behaviour of the model.	Review	O	0
However, there are two problems about the main result of this paper, Theorem 2.	Review	B-Review	4
[line_break_token][line_break_token]1.	Review	O	0
It is not clear if the Taylor optimum would converge or not.	Review	B-Review	1
[line_break_token]As noticed by the authors, the upper bound is path dependent.	Review	I-Review	1
Appendix 3 tries to claim that this Taylor optimum indeed converges, but the proof is buggy.	Review	I-Review	1
In the proof of Lemma 2, it is proved that the difference between two sequential Taylor optimum is approaching 0.	Review	I-Review	1
Note that this is actually weaker than being Cauchy sequence and insufficient to guarantee convergence.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	4
The lefthand side of Equation (3) (I will denote it by L3 in this review) is not equivalent to training error.	Review	I-Review	2
[line_break_token]An upper bound on this average error is not sufficient to guarantee the convergence of the training error neither.	Review	I-Review	2
Take the gradient descent for example (thus each minibatch x_0^n is the whole training set), the convergence of the training error should be lim_{n -> \infty} l(f_{w^n}(x_0^n), y^n).	Review	O	0
The convergence of L3 is necessary but not sufficient to imply the convergence of the training error.	Review	B-Review	2
[line_break_token][line_break_token]Another concern about Theorem 2 (but it is minor compared to the two problems mentioned above) is that to achieve the O(1/\sqrt{n}) rate, the algorithm has to pick a particular learning rate.	Review	I-Review	3
Larger or smaller learning rate (in the order of n) will lead to significantly worse regret.	Review	I-Review	3
But in the experiments of the paper, the learning rates are not picked according to the theorem.	Review	I-Review	3
[line_break_token][line_break_token]Overall, this paper has a good motivation and good novelty.	Review	O	0
It could be further developed into a good paper.	Review	O	0
But due to the two problems and a buggy proof mentioned above, I think it is not ready for publish yet.	Review	O	0
[line_break_token]	Review	O	0
We thank the reviewer for their detailed comments.	Reply	O	0
 [line_break_token][line_break_token]First, we emphasize that Theorem 2 is correct as stated.	Reply	O	0
The formulas are correct as is.	Reply	B-Reply	4
However, the underbrace on the LHS of Eq. (	Reply	I-Reply	4
3) has been relabeled ‚Äúrunning average of training errors‚Äù instead of ‚Äútraining error‚Äù.	Reply	I-Reply	4
[line_break_token][line_break_token]The reviewer‚Äôs points concern the ASYMPTOTIC BEHAVIOR of the left and right hand sides of Eq. (	Reply	I-Reply	2
3).	Reply	I-Reply	2
The paper analyses the behavior of gradient descent under a FINITE NUMBER OF ITERATIONS.	Reply	I-Reply	2
The main contribution is to show: [line_break_token]    a) the first convergence rate for rectifier nets[line_break_token]    b) relative to a sequence of convex losses capturing the geometry of backprop[line_break_token]    c) that is meaningful in practice (i.e for finite iterations)[line_break_token]Although asymptotic results are valuable, in practice NNs are trained using a finite number of iterations.	Reply	O	0
[line_break_token][line_break_token]Responses to comments:[line_break_token][line_break_token]1.	Reply	O	0
Convergence of Taylor optimum.	Reply	O	0
[line_break_token]The reviewer is correct.	Reply	B-Reply	1
We showed ||a_n-a_{n+1}|| approaches 0 instead of ||a_n-a_m|| for arbitrary m > n. This was a sloppy mistake made in a rush in response to the reviewer‚Äôs initial question.	Reply	O	0
Fortunately, all that we require is that the Taylor optima are bounded so we have removed the discussion of Taylor optima from the appendix.	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
LHS is not equivalent to training error.	Reply	O	0
[line_break_token]The reviewer is correct.	Reply	B-Reply	1
The LHS is better termed the ‚Äúrunning average of errors during training‚Äù or the ‚Äú(average) cumulative loss‚Äù: it averages the entire loss curve during training rather than the final point on the curve (i.e. the training error of the final weights).	Reply	I-Reply	2
[line_break_token][line_break_token]Analysing the cumulative loss is standard.	Reply	I-Reply	2
The reviewer‚Äôs criticism applies equally to, for example, the theorems provided for AdaGrad by Duchi et al and for Adam by Kingma and Ba in the original papers introducing the respective algorithms.	Reply	I-Reply	2
[line_break_token][line_break_token]Our results have a different flavor from results on stochastic gradient descent where convergence is shown in expectation.	Reply	I-Reply	2
Eq. (	Reply	I-Reply	2
3) is much stronger than a bound that holds in expectation since it always holds as is.	Reply	I-Reply	2
It is for this reason that we (and Duchi and Kingma) use what we are calling the running average of errors.	Reply	I-Reply	2

Summary &amp; Pros[line_break_token]- This paper proposes a few-shot learning method that uses self-supervision as an auxiliary label and trains primary and auxiliary labels via multi-task learning.	Review	O	0
[line_break_token]- This paper provides extensive experiments for analyzing the effect of self-supervision on various few-shot learning settings: (1) self-supervision can improve various few-shot learning algorithms, ProtoNet &amp; MAML; (2) self-supervision with similar samples can provide more improvements.	Review	O	0
[line_break_token][line_break_token]Concerns #1: Novelty of the proposed method[line_break_token]- This paper uses a multi-task learning approach with self-supervision.	Review	O	0
But this approach is already used in various tasks, e.g., domain adaptation, semi-supervised learning, training GANs.	Review	B-Review	1
Thus, the proposed method (in Section 3) using a multi-task learning objective with self-supervised losses seems to be incremental.	Review	I-Review	1
[line_break_token][line_break_token]Concerns #2: Somewhat unsurprising experimental results[line_break_token]- This paper shows various experimental results, but some experiments seem to be trivial.	Review	O	0
For example, the performance gap is typically increased when learning harder tasks, e.g., when the number of training samples is decreasing, the performance gap between methods is typically increasing in a fully-supervised setting.	Review	B-Review	2
Thus I think results in the paragraph "Gains are larger for harder tasks" might be predictable.	Review	I-Review	2
Other examples are Figure 4a and 4b in Section 4.2 because one can easily expect that using training more in-domain samples can provide more performance gain.	Review	I-Review	2
[line_break_token]- In the case of Figure 4d in Section 4.2, the authors claimed that the effectiveness of SSL decreases as the distance from the supervised domain increases.	Review	O	0
However, I think Figure 4d is not matched to the claim.	Review	B-Review	3
For example, in the case of Dogs, better performance is achieved when using a more dissimilar domain for self-supervision except for D_s=D_ss.	Review	I-Review	3
So I wonder how to draw the lines in Figure 4d.	Review	I-Review	3
[line_break_token][line_break_token]Some experimental results provide meaningful messages, e.g., single self-supervision can improve performance significantly while joint self-supervision does marginally.	Review	O	0
However, the contribution of the methodology is limited and some experimental results seem to incremental.	Review	B-Review	4
[line_break_token]	Review	O	0
** Concern 1 about novelty **[line_break_token]Our novelty lies in the result that self-supervised learning improves few-shot learning on small datasets, with state-of-the-art deep networks, and on fine-grained domains.	Reply	O	0
We also systematically estimate the effect of domain shifts through extensive experiments across datasets.	Reply	B-Reply	1
These results are likely of interest to the community.	Reply	I-Reply	1
[line_break_token][line_break_token]** Concern 2 about unsurprising results **[line_break_token]We do think that some of these results are surprising.	Reply	O	0
For example:[line_break_token]- The harder tasks we consider use only 20% of the training data, amounting to only one or two thousand images.	Reply	O	0
It is surprising that SSL is effective with such small-sized datasets since the conventional wisdom is that SSL requires orders of magnitude more data to be effective.	Reply	B-Reply	2
[line_break_token]- Despite numerous advances, SSL still dramatically lags behind supervised learning.	Reply	O	0
Ours is one of the first results showing that SSL provides improvements on top of supervised learning in the few-shot setting.	Reply	B-Reply	2
[line_break_token]- The results in Figure 4a and 4b are perhaps less surprising, but we are not aware of any work that systematically conducted these experiments.	Reply	O	0
For example, more data but from a different domain makes SSL less effective, even worse than no SSL.	Reply	B-Reply	2
Thus simply relying on the few within-domain images is the best strategy for novel domains.	Reply	I-Reply	2
This result is of practical significance for learning in domains where even unlabeled data is hard to obtain.	Reply	I-Reply	2
[line_break_token][line_break_token]Figure 4d is indeed confusing.	Reply	I-Reply	3
The difficulty stems from how to measure the domain distance, which is an open research problem.	Reply	I-Reply	3
The main result still holds, i.e., domain shift makes the SSL less effective (as also seen in Figure 4b), but the right way to measure a domain distance that is predictive of transfer is an open question.	Reply	I-Reply	3
We will remove the trend lines in the figures.	Reply	I-Reply	3
Also see the response to R2.	Reply	I-Reply	3

This paper analyzes some of the optimization challenges presented by a particular formulation of "short-and-sparse deconvolution" and proposes a new general purpose algorithm to try to alleviate them.	Review	O	0
The paper is reasonably clearly written and the experimental results seem impressive (as a non-specialist in this area).	Review	O	0
However the experimental investigation on real data does not compare to a baseline, which seems like an essential part of investigating the proposed method.	Review	O	0
If this were corrected I would recommend an accept.	Review	O	0
[line_break_token][line_break_token]I would like to make it clear that I have little experience in this area and am not familiar with relevant previous literature, so I was only able to roughly judge novelty of the ideas and how the experimental results might compare with existing approaches.	Review	O	0
[line_break_token][line_break_token][line_break_token]Major comments:[line_break_token][line_break_token]For the experimental investigations on real data there was no baseline presented.	Review	O	0
Are there no task-specific algorithms that have previously been developed for deconvolution of calcium signals, fluoresence microscopy and calcium imaging?	Review	B-Review	1
At the very least it would be helpful to compare to one of the other general purpose methods used for figure 6.	Review	I-Review	1
[line_break_token][line_break_token]It seemed like a lot of the paper is taken up with a recap of the results presented in Kuo et al. (	Review	I-Review	2
2019), and it didn't always seem clear exactly what the relevance of these results were to the present paper.	Review	I-Review	2
In particular it seemed strange to me to devote so much space in section 2 to the ABL objective given that it is not used (as far as I can tell) for the proposed algorithm.	Review	I-Review	2
[line_break_token][line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]The abstract says "We leverage... sphere constraints, data-driven initialization".	Review	O	0
Is the effect of these actually investigated experimentally?	Review	B-Review	3
[line_break_token][line_break_token]In the abstract, "This is used to derive a provable algorithm" makes it sounds to me like this will be done in the current paper.	Review	I-Review	4
[line_break_token][line_break_token]In the abstract, a reference for the "due to the spectral decay of the kernel a_0" claim would be helpful.	Review	I-Review	5
[line_break_token][line_break_token]In the notation section, the definition of the Riemannian gradient seems a little sloppy mathematically: strictly f needs to be defined on (or an open subset of containing) in order for the right side of the gradient expression to be defined.	Review	I-Review	6
[line_break_token][line_break_token]At the start of section 2, it would be helpful to give a one-sentence description of the unifying theme of the section.	Review	I-Review	7
[line_break_token][line_break_token]It might be helpful to explicitly state that "coherence" is related to the strength of temporal / spatial correlations to aid developing the reader's intuition for the meaning of.	Review	I-Review	8
[line_break_token][line_break_token]Throughout the paper the problems that multiple equivalent local optima (due to shift symmetry) cause come up repeatedly.	Review	I-Review	9
What happens if this symmetry is removed straightforwardly by adding a term to the cost function to encourage a particular value of to be the largest?	Review	I-Review	9
[line_break_token][line_break_token]In section 2.1, for "It analyzes an ABL...", it's not completely clear what "It" refers to (I presume Kuo et.	Review	I-Review	10
al (2019) from context).	Review	I-Review	10
[line_break_token][line_break_token]Marginalization in my experience refers to a "partial summing" operation, whereas just above (4) it is used to refer to a "partial maximization" operation.	Review	I-Review	11
This seems non-standard to me, but is this usage standard in this field?	Review	I-Review	11
[line_break_token][line_break_token]I didn't understand the relevance of the sentence "Under its marginalization... smaller dimension p &lt;&lt; m." to the present paper.	Review	O	0
The sentence also seemed vague and difficult to understand if you were not already familiar with this result.	Review	B-Review	12
It should also have a reference to justify this claim.	Review	I-Review	12
[line_break_token][line_break_token]It wasn't clear to me whether figure 1 were schematic "rough intuition" diagrams intended merely to be suggestive, or provably showing the type of behavior that happens in all cases.	Review	I-Review	13
Also, what are the axes, generic "parameter space", I guess?	Review	I-Review	13
I also didn't follow why (a) appears projected on to a plane while (b) and (c) appear projected on to a sphere(?)	Review	I-Review	13
[line_break_token][line_break_token]In section 3, under "momentum acceleration", it would be helpful to justify the claim that "In shift-coherent settings, the Hessian... ill-conditioned...".	Review	I-Review	14
[line_break_token][line_break_token]In figure 4, the axis labels are much too small to read.	Review	I-Review	15
In figure 5 (b), the red poorer results obscure the green better results.	Review	I-Review	15
[line_break_token][line_break_token]In figure 4 (d), is it fair to say that the main convergence speed improvement for homotopy-iADM is in going faster from "quite near" the optimum to "really near" it, rather than getting "quite near" it in the first place?	Review	I-Review	16
If so, isn't the latter more often what's relevant in practical applications?	Review	I-Review	16
[line_break_token][line_break_token]In figure 5, it's a little confusing to switch color meanings between (a) and (b).	Review	I-Review	17
[line_break_token][line_break_token]Reweighting seems to have a dramatic positive effect in figure 5.	Review	I-Review	18
Is it worth investigating its effect in the other experiments as well, for example in figure 4?	Review	I-Review	18
[line_break_token][line_break_token]In figure 6 (b), is there any reason not to compare against standard black box optimizers like vanilla SGD, ADAM, etc (possibly with projection to satisfy the sphere constraint if necessary)?	Review	I-Review	19
Would they perform very badly?	Review	I-Review	19
[line_break_token][line_break_token]Typo "Whilst nor" should be "Whilst and".	Review	I-Review	20
[line_break_token][line_break_token]What does the square-boxed convolution operator in (8) mean?	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for the detailed review and constructive comments.	Reply	O	0
[line_break_token][line_break_token]*Comparison on practical problems.	Reply	O	0
As suggested by the reviewer, we have added an experiment that compares the proposed method with state-of-the-art algorithms (in Figure 6a&amp;b) on the task of sparse deconvolution of calcium signals under AR2 model (see Figure 6c).	Reply	O	0
[line_break_token][line_break_token]*Relation to the result of Kuo et al. (	Reply	O	0
2019).	Reply	O	0
The theory in Kuo et al.	Reply	B-Reply	2
is based on an approximation to the Bilinear Lasso (see Appendix A).	Reply	I-Reply	2
These two functions have the same scale-shift symmetry.	Reply	I-Reply	2
On incoherent problems (see definition in (2)), they exhibit similar critical points: minimizers are signed shifts of the ground truth, saddle points occur near superpositions of shifts, with negative curvature in symmetry breaking directions (compare, e.g., the left and center panels of Figure 10 of Appendix A of the submission).	Reply	I-Reply	2
[line_break_token][line_break_token]Despite this similarity, and are not identical, especially for the type of coherent problems encountered in applications in imaging and the sciences (right panel of Figure 10).	Reply	I-Reply	2
The goal of the paper is to leverage intuitions from Kuo et al. (	Reply	I-Reply	2
derived under incoherence assumptions) to build practical methods that can solve these highly coherent problems.	Reply	I-Reply	2
Of course, the theory of Kuo et al.	Reply	I-Reply	2
does not have direct mathematical implications for Bilinear Lasso or for highly coherent problems.	Reply	I-Reply	2
There are a number of roles that theory can play in the computational sciences.	Reply	I-Reply	2
The most direct role is in clarifying fundamental limits and providing performance guarantees.	Reply	I-Reply	2
Another potential role is in providing ways of thinking: models, pictures, intuitions, which can have more practical value than the mathematical theorems themselves.	Reply	I-Reply	2

The focus on novelty (mentioned in both the abstract, and conclusion as a direct claim) in the presentation hurts the paper overall.	Review	O	0
Without stronger comparison to other closely related work, and lack of citation to several closely related models, the claim of novelty isn't defined well enough to be useful.	Review	B-Review	1
Describing what parts of this model are novel compared to e.g. Stochastic WaveNet or the conditional dilated convolutional decoder of "Improved VAE for Text ..." (linked below, among many others) would help strengthen the novelty claim, if the claim of novelty is needed or useful at all.	Review	I-Review	1
Stochastic WaveNet in particular seems very closely related to this work, as does PixelVAE.	Review	I-Review	1
In addition, use of autoregressive models conditioned on (non-variational, in some sense) latents have been shown in both VQ-VAE and ADA among others, so a discussion would help clarify the novelty claim.	Review	I-Review	1
[line_break_token][line_break_token]Empirical results are strong, though (related to the novelty issue) there should be greater comparison both quantitatively and qualitatively to further work.	Review	I-Review	4
In particular, many of the papers linked below show better empirical results on the same datasets.	Review	I-Review	4
Though the results are not always directly comparable, a discussion of *why* would be useful - similar to how Z-forcing was included.	Review	I-Review	4
[line_break_token][line_break_token]In the qualitative analysis, it would be good to see a more zoomed out view of the text (as in VRNN), since one of the implicit claims of the improvement from dense STCN is improved global coherence by direct connection to the "global latents".	Review	I-Review	2
As it stands now the text samples are a bit too local to really tell.	Review	I-Review	2
In addition, the VRNN samples look quite a bit different than what the authors present in their work - what implementation was used for the VRNN samples (they don't appear to be clips from the original paper)?	Review	I-Review	2
[line_break_token][line_break_token]On the MNIST setting, there are many missing numbers in the table from related references (some included below), and the >= 60.25 number seems so surprising as to be (possibly) incorrect - more in-depth analysis of this particular result is needed.	Review	O	0
Overall the MNIST result needs more description and relation to other work, for both sequential and non-sequential models.	Review	B-Review	3
[line_break_token][line_break_token]The writing is well-done overall, and the presented method and diagrams are clear.	Review	O	0
My primary concern is in relation to related work, clarification of the novelty claim, and more comparison to existing methods in the results tables.	Review	O	0
[line_break_token][line_break_token]Variational Bi-LSTM <a href="https://arxiv.org/abs/1711.05717" target="_blank" rel="nofollow">https://arxiv.org/abs/1711.05717</a>[line_break_token][line_break_token]Stochastic WaveNet <a href="https://arxiv.org/abs/1806.06116" target="_blank" rel="nofollow">https://arxiv.org/abs/1806.06116</a>[line_break_token][line_break_token]PixelVAE <a href="https://arxiv.org/abs/1611.05013" target="_blank" rel="nofollow">https://arxiv.org/abs/1611.05013</a>[line_break_token][line_break_token]Filtering Variational Objectives <a href="https://github.com/tensorflow/models/tree/master/research/fivo" target="_blank" rel="nofollow">https://github.com/tensorflow/models/tree/master/research/fivo</a>[line_break_token][line_break_token]Improved Variational Autoencoders for Text Modeling using Dilated Convolutions <a href="https://arxiv.org/abs/1702.08139" target="_blank" rel="nofollow">https://arxiv.org/abs/1702.08139</a>[line_break_token][line_break_token]Temporal Sigmoid Belief Networks for Sequential Modeling <a href="http://papers.nips.cc/paper/5655-deep-temporal-sigmoid-belief-networks-for-sequence-modeling" target="_blank" rel="nofollow">http://papers.nips.cc/paper/5655-deep-temporal-sigmoid-belief-networks-for-sequence-modeling</a>[line_break_token][line_break_token]Neural Discrete Representation Learning (VQ-VAE) <a href="https://arxiv.org/abs/1711.00937" target="_blank" rel="nofollow">https://arxiv.org/abs/1711.00937</a>[line_break_token][line_break_token]The challenge of realistic music generation: modelling raw audio at scale (ADA) <a href="https://arxiv.org/abs/1806.10474" target="_blank" rel="nofollow">https://arxiv.org/abs/1806.10474</a>[line_break_token][line_break_token]Learning hierarchical features from Generative Models <a href="https://arxiv.org/abs/1702.08396" target="_blank" rel="nofollow">https://arxiv.org/abs/1702.08396</a>[line_break_token][line_break_token]Avoiding Latent Variable Collapse with Generative Skip Models <a href="https://arxiv.org/abs/1807.04863" target="_blank" rel="nofollow">https://arxiv.org/abs/1807.04863</a>[line_break_token][line_break_token]EDIT: Updated score after second revisions and author responses	Review	O	0
***Missing citations and novelty claim[line_break_token]We thank the reviewer for useful pointers to additional related papers.	Reply	O	0
In the revised version, we added a more complete related work section.	Reply	B-Reply	1
In particular, we discuss the most closely related Stochastic Wavenet paper in detail.	Reply	I-Reply	1
While SWaveNet and ours combine TCNs with stochastic variables there are important differences in how this is achieved.	Reply	I-Reply	1
Furthermore, we show that these design choices have implications in terms of modelling power and our architecture outperforms SWaveNet despite not having access to future information.	Reply	I-Reply	1
Furthermore, we provide log-likelihood results from Variational Bi-LSTM and Stochastic Wavenet are inserted into the result table.	Reply	I-Reply	1
In order to provide more evidence, we also include experiments on the Blizzard dataset.	Reply	I-Reply	1
[line_break_token][line_break_token]We would like to emphasize that the main difference between our model and the models with autoregressive decoders (i.e., PixelVAE, Improved Variational Autoencoders for Text Modeling using Dilated Convolutions) is the sequential structure of our latent space.	Reply	I-Reply	1
For every timestep x_t we have a corresponding latent variable z_t, similar to stochastic RNNs, which helps modeling the uncertainty in sequence data.	Reply	I-Reply	1
We aim to combine TCNs with a powerful latent variable structure to better model sequence data rather than learning disentangled or interpretable representations.	Reply	I-Reply	1
The updated results show that our design successfully preserves the modeling capacity of TCNs and representation power of latent variables.	Reply	I-Reply	1
[line_break_token][line_break_token]*** Handwriting sample figure.	Reply	O	0
[line_break_token]In order to make a direct comparison, we include a new figure (similar to VRNN) comparing generated handwriting samples of VRNN, Stochastic Wavenet and STCN-dense.	Reply	B-Reply	2
The original figure referred to by the reviewer is now in the Appendix.	Reply	I-Reply	2
[line_break_token][line_break_token]*** MNIST results[line_break_token](Also see the answer to R1) We include a new figure comparing the performance of STCN, STCN-dense and VRNN on single test samples from seq-MNIST.	Reply	O	0
We find that STCN-dense makes very precise probability predictions for the pixel values as opposed to other models, this explains the drastic increase in likelihood performance.	Reply	B-Reply	3
[line_break_token]We include a table providing KL loss per latent variable across the whole dataset.	Reply	I-Reply	3
We also provide a comparison between SKIP-VAE (Avoiding Latent Variable Collapse with Generative Skip Models) and our model.	Reply	I-Reply	3
It shows that STCN-dense effectively uses the latent space capacity (indicated by high KL values) and encodes the required information to reconstruct the input sequence.	Reply	I-Reply	3
We also provide generated MNIST samples in order to show that the discrepancy between the prior and approximate posterior does not degrade generative modeling capacity.	Reply	I-Reply	3
[line_break_token]Finally, in our MNIST experiments, we followed Z-forcing paper‚Äôs instructions.	Reply	I-Reply	3
See reply to R1 for details of the experimental protocol.	Reply	I-Reply	3

The authors detail a set of priors for unsupervised decomposition of individual spectrograms into their component parts.	Review	O	0
The introduce reasonable constraints on temporal coherence (consistency and dynamic shifts) and mask activations (at least one component always activated).	Review	O	0
They also regularize sources to not overlap spectrotemporally.	Review	O	0
Decomposition is performed by training the weights of a U-Net on a single spectrogram as in deep image priors.	Review	O	0
The authors demonstrate quantitative improvements on blind source separation over other data-agnostic techniques, and qualitative use of the model for interactive editing, audio texture synthesis, and audio watermark removal.	Review	O	0
The work also performs an ablation study to qualitatively demonstrate the importance of each element for the prior.	Review	O	0
The experiments are performed well and explained clearly.	Review	O	0
They also introduce a dataset of diverse mixtures for future comparisons.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]* Important motivation for why audio has different properties than images (even if it can be represented as a "image" spectrogram).	Review	O	0
The priors are well-motivated by the dynamics of audio.	Review	O	0
[line_break_token]* Good ablations and quantitative comparisons to baselines.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]* Some details could be better demonstrated / explained (even if only in the appendix).	Review	O	0
For example the paper cites the network architecture, but a local description would be helpful.	Review	B-Review	1
Similarly, the latent dynamics are carefully regularized, so visualizing them would be helpful to understand the dynamics.	Review	I-Review	1
[line_break_token]* The scaling of the technique is not supported by the current experiments.	Review	O	0
The authors claim they have extended to 4 sources, but all experiments in the paper seem to only involve two sources.	Review	B-Review	2
[line_break_token]* More motivation could help in terms of the value of non-amortized methods like deep priors, vs. other approaches such as pretraining or self-supervised methods.	Review	O	0
While it is difficult to get lots of labeled data for a specific task, the argument was not convincingly made that methods like deep priors should outperform methods that use pretrained priors on adjacent tasks (where collecting data is easy).	Review	B-Review	3
We would like to thank the reviewer for the constructive feedback.	Reply	O	0
We address the concerns from the reviewer as follows: [line_break_token][line_break_token]A1: Thanks for the suggestion!	Reply	O	0
We have updated our paper with an appendix to show the used U-net structure (please see Section A.1 and Figure 10) and visualize the results from different training iterations with the proposed dynamic noise inputs to help readers better understand the dynamics (please see Section A.3 and Figure 11).	Reply	B-Reply	1
[line_break_token][line_break_token]A2: By "co-segmentation with 4 sources in total", we refer to the audio watermark removal application.	Reply	O	0
In the application, we successfully separate four different audio sources with co-separation using our deep audio prior network.	Reply	B-Reply	2
We will clarify further this in the revision.	Reply	I-Reply	2
[line_break_token][line_break_token]A3: This is a really good question!	Reply	O	0
We indeed have observed a lot of works on self-supervised audio learning taking the natural audio-visual synchronization as supervision.	Reply	B-Reply	3
The pre-trained models have been proved to be useful in many downstream tasks, such as audio classification, audio event detection, and sounding scene localization.	Reply	I-Reply	3
But when the existing methods want to extract clean audio sources from sound mixtures using the pre-trained models, they usually need to access clean single-source sounds for composing training sound mixtures and then generating ground truth masks for supervised separation learning.	Reply	I-Reply	3
Unlike the existing methods, with the proposed deep audio prior, our network can directly learn from a single sound mixture without requiring clean single-source sounds.	Reply	I-Reply	3
 [line_break_token][line_break_token]Another motivation is to use the individually learned models to distill a more robust combined model.	Reply	I-Reply	3
Since each individual model is cleaner and carries semantic representations (i.e. temporally coherent), in addition to the 4 applications that we showed in the paper, we believe this could have more downstream impact for audio synthesis, audio representation, etc	Reply	I-Reply	3

Overall I like the approach in the paper.	Review	O	0
It proposes a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi-agent systems.	Review	O	0
The parts that a bit lacking with the current version of the paper in this are the evaluation tasks are few and a bit simple and I think there needs to be more discussion on the "coverage" of the intrinsic reward types.	Review	B-Review	17
Are the ones proposed motivated by the tasks in the paper or are they sufficient for tasks in general?	Review	I-Review	15
 Last using a more recent novelty metric could allow the method to work on more interesting/complex tasks.	Review	O	0
[line_break_token][line_break_token]More detailed feedback:[line_break_token]- It would be good to include more learning curves in the main text for the paper.	Review	O	0
[line_break_token]- The fact that applying intrinsic motivation to multi-agent simulations seems like a natural idea would be to convert the problem to a "single" agent problem to compare against the "normal" application of intrinsic rewards.	Review	O	0
This might be another baseline to consider for comparison.	Review	B-Review	2
[line_break_token]- It says that all agents share the same replay buffer.	Review	O	0
Does this also imply that every agent is performing the same task there are just many agents?	Review	B-Review	3
This does not make the problem very multi-agent with different goals.	Review	I-Review	3
Would it affect the algorithm significantly to work on an environment where the agents have various types of goals?	Review	I-Review	3
[line_break_token]- As is noted in the text, this method appears to work well in the centralized training scheme that many have adopted recently.	Review	O	0
However, It makes me wonder if there is a way to employ these exploration schemes in a non-centralized training form.	Review	B-Review	10
The ability to ask other agents in the world about there preferences and novelty of states appears to be a strong assumption, especially in a multi-agent robotics problem.	Review	I-Review	10
[line_break_token]- While the authors note that the intrinsic rewards used in this work are not comprehensive it would be good to note how comprehensive they are.	Review	O	0
Are there a few that were left out on purpose.	Review	B-Review	11
Do the authours believe this set is sufficient.	Review	I-Review	11
This statement makes it seem like the authors just tried a few options and found one that worked.	Review	I-Review	11
It would be good to expand on this discussion more.	Review	I-Review	11
[line_break_token]- More detail for Figure 1 would be helpful to understand the overall network design.	Review	O	0
While that figure it helpful maybe it would be good to include a version that goes into detail for the 2 agent environment.	Review	B-Review	12
Then a more compressed n agent version can also be shown.	Review	I-Review	12
[line_break_token]- The paper describes a policy selector that is a type of high-level policy for HRL.	Review	O	0
This design seems rather unique in that this part of the policy can optimizing for which intrinsic reward to toggle based on the extrinsic rewards observed.	Review	B-Review	13
I like it.	Review	I-Review	13
It is noted that entropy is important for this design.	Review	I-Review	13
Can this be analyzed in an empirical way?	Review	I-Review	13
Is this true for most environments/tasks?	Review	I-Review	13
[line_break_token]- Task 2 seems a bit contrived.	Review	O	0
Is there another instance of this type of task elsewhere in another paper?	Review	B-Review	14
It would be better to use more standard tasks if they are available.	Review	I-Review	14
[line_break_token]- Before section 6.1 the paper is discussing rewards the are received.	Review	O	0
It would be good to more explicit about where these rewards are coming from.	Review	B-Review	4
I think it is meant that these rewards are the extrinsic rewards but it does not say.	Review	I-Review	4
[line_break_token]- As noted just before section 6.1 it seems for the collection of tasks 1-3 it is already obvious what types of intrinsic rewards should be used.	Review	O	0
It would be good to include more tasks where this decision is less obvious.	Review	B-Review	5
[line_break_token]- Why are there "black holes" in the environment?	Review	O	0
Also if an agent steps into a black hole they are crushed never to be seen again.	Review	B-Review	6
What you describe sounds more like a wormhole where one end is non-stationary... Also, can the agents detect the presence of a black hole in some way?	Review	I-Review	6
[line_break_token]- It appears the novel metric is count based.	Review	O	0
While this can work in practice it seems a rather simple metric.	Review	B-Review	7
Is it possible to use something more like ICM or RND that was referenced in the paper?	Review	I-Review	7
Especially for the VizDoom environment?	Review	I-Review	7
[line_break_token]- In table 2 where are some of the numbers bold?	Review	O	0
It would be good to include this information in the caption for the table.	Review	B-Review	8
[line_break_token]- I am not sure if the discussion on the behaviours the intrinsic reward functions result in are very surprising.	Review	O	0
Maybe there is a more interesting behaviour that results from the combination of two intrinsic rewards?	Review	B-Review	9
[line_break_token]	Review	O	0
hank you for the detailed and insightful comments.	Reply	O	0
 We would like first to articulate more clearly the motivation behind the tasks we have used.	Reply	O	0
When we consider the setting of multi-agent systems, we believe the notion of spatial coordination is of natural interest.	Reply	B-Reply	15
In other words, should agents in such environments coordinate their spatial positioning while exploring.	Reply	I-Reply	15
Our tasks are designed to test the extremes of the spectrum of spatial coordination (i.e. close together (task 2) vs. far apart (task 1)).	Reply	I-Reply	15
[line_break_token][line_break_token]When designing intrinsic reward functions, we focus on inducing spatial coordination in a general manner that does not use domain-specific knowledge.	Reply	I-Reply	17
We argue that using these types of rewards for spatially coordinated exploration is generally useful for many problems in multi-agent systems.	Reply	I-Reply	17
 The key contribution of our work is to provide examples which introduce a framework for expressing intrinsic reward functions that induce spatially coordinated exploration.	Reply	I-Reply	17
[line_break_token][line_break_token]Regarding the use of more recent novelty metrics: we *thoroughly* tested Random Network Distillation [2] on the ViZDoom tasks and concluded that RND is unsuitable for the domain.	Reply	O	0
It is especially sensitive to the brightness of the input images, causing heavily visited rooms in the map with brighter walls leading to higher intrinsic rewards than unvisited dark colored rooms.	Reply	B-Reply	16
Image preprocessing techniques (contrast limited adaptive histogram equalization) improved performance somewhat, but the exploration was still highly biased towards specific regions.	Reply	I-Reply	16
We also implemented and tested the Intrinsic Curiosity Module [3] though we have not been able to replicate the results from the original paper and thus, cannot comment on its efficacy within our framework at this time.	Reply	I-Reply	16
[line_break_token][line_break_token]Below we will answer specific questions that were not answered above:[line_break_token][line_break_token]-Comparing to single-agent intrinsic rewards[line_break_token][line_break_token]This is an interesting point, and we have run the appropriate experiments to test its efficacy.	Reply	O	0
We implement an intrinsic reward that considers the joint position of all agents (i.e. the inverse count of all agents being in their combined positions).	Reply	B-Reply	2
Our initial hypothesis is that our intrinsic reward functions provide additional inductive biases which encourage spatial coordination and should outperform this standard centralized intrinsic reward function.	Reply	I-Reply	2
Figures and a description of the implementation of centralized rewards are provided in the Appendix.	Reply	I-Reply	2
We find that across all tasks with 2 agents our approach learns more efficiently than this baseline, confirming our hypothesis.	Reply	I-Reply	2
[line_break_token][line_break_token]-Agents sharing the same replay buffer[line_break_token][line_break_token]We apologize for the confusion.	Reply	O	0
Agents have multiple policy heads for each type of intrinsic reward, and these heads share experiences; however, agents do not share experiences with each other.	Reply	B-Reply	3
[line_break_token][line_break_token]-Is it possible to decentralize training?	Reply	O	0
[line_break_token][line_break_token]This is an interesting question.	Reply	B-Reply	10
One can imagine an adaptation of our method where agents leave ‚Äúmarkers‚Äù of how novel a region is to themselves such that other agents can detect these markers when they enter the region.	Reply	I-Reply	10
In this way, the assumption of communicating the novelty of observations across agents can be removed and our approach can be adapted to a decentralized training regime.	Reply	I-Reply	10
We leave this for future work.	Reply	I-Reply	10
[line_break_token][line_break_token]-Can the importance of entropy in the policy selector be analyzed empirically?	Reply	O	0
[line_break_token][line_break_token]We include experiments of our method run without the entropy bonus on the meta-policy across all tasks with 2 agents in the Appendix.	Reply	B-Reply	13
We find that its removal consistently hurts performance across all settings.	Reply	I-Reply	13
[line_break_token][line_break_token]-Clarifying rewards described before section 6.1[line_break_token][line_break_token]Yes, we are referring to the extrinsic rewards.	Reply	O	0
The text has been modified to make this more clear.	Reply	B-Reply	4
[line_break_token][line_break_token]-Clarifying ‚Äúblack holes‚Äù[line_break_token][line_break_token]These exist in order to make the exploration problem more challenging.	Reply	O	0
Agents are able to detect the probability of any black hole in their immediate vicinity opening at the next time step, and must learn to navigate around them (i.e. wait for the probability of opening to be low).	Reply	B-Reply	6
[line_break_token][line_break_token]-Bolded numbers[line_break_token][line_break_token]The bolded numbers are those where the best mean score falls within one standard deviation of their score distribution.	Reply	O	0
We have added this description to the caption.	Reply	B-Reply	8
[line_break_token][line_break_token][line_break_token][1] Ta√Øga, Adrien Ali, et al. "	Reply	O	0
Benchmarking bonus-based exploration methods on the arcade learning environment."	Reply	O	0
arXiv preprint arXiv:1908.02388 (2019).	Reply	O	0
[line_break_token][2] Burda, Yuri, et al. "	Reply	O	0
Exploration by random network distillation."	Reply	O	0
arXiv preprint arXiv:1810.12894 (2018).	Reply	O	0
[line_break_token][3] Pathak, Deepak, et al. "	Reply	O	0
Curiosity-driven Exploration by Self-supervised Prediction."	Reply	O	0
International Conference on Machine Learning.	Reply	O	0
2017	Reply	O	0

Summary of the paper:[line_break_token][line_break_token]This work presents a novel method for similarity function learning using non-linear model.	Review	O	0
The main problem with the similarity function learning models is the pairwise component of the loss function which grows quadratically with the training set.	Review	O	0
The existing stochastic approximations which are agnostic to training set size have high variance and this in-turn results in poor convergence and generalisation.	Review	O	0
This paper presents a new stochastic approximation of the pairwise loss with reduced variance.	Review	O	0
This is achieved by exploiting the dot-product structure of the least-squares loss and is computationally efficient provided the embedding dimensions are small.	Review	O	0
The core idea is to rewrite the least-squares as the matrix dot product of two PSD matrices (Grammian).	Review	O	0
The Grammian matrix is the sum of the outer-product of embeddings along the training samples.	Review	O	0
The authors present two algorithms for training the model, 1)SAGram: By maintaining a cache of all embedding vectors of training points (O(nk) space)$, whenever a point is encountered it's cache is replaced with it's embedding vector.	Review	O	0
2) SOGram: This algorithm keeps a moving average of the Grammian estimate to reduce the variance.	Review	O	0
Experimental results shows that this approach reduces the variance in the Grammian estimates, results in faster convergence and better generalisation.	Review	O	0
[line_break_token][line_break_token]Review:[line_break_token][line_break_token]The paper is well written with clear contribution to the problem of similarity  learning.	Review	O	0
 My only complain is that, I think the evaluation is a bit weak and does not support the claim that is applicable all kinds of problems e.g. nlp and recommender systems.	Review	B-Review	1
This task in Wikipedia does not seem to be standard (kind of arbitrary) ‚Äî there are some recommendation results in the appendix but I think it should have been in the main paper.	Review	I-Review	1
[line_break_token][line_break_token]Overall interesting but I would recommend evaluating in standard similarity learning for nlp and other tasks (perhaps more than one)[line_break_token][line_break_token]There are specific similarity evaluation sets for word embeddings.	Review	I-Review	2
It can be found in following papers: <a href="https://arxiv.org/pdf/1301.3781.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1301.3781.pdf</a>  [line_break_token]<a href="http://www.aclweb.org/anthology/D15-1036" target="_blank" rel="nofollow">http://www.aclweb.org/anthology/D15-1036</a>	Review	O	0
Thank you for your assessment and your helpful suggestions.	Reply	O	0
[line_break_token][line_break_token]Regarding evaluation: since the focus of the paper is on the design of an efficient optimization method, we wanted to choose an experiment where (i) the evaluation metric is aligned with the optimization objective, and (ii) the vocabulary size is very large (on the order of 10^6 or more), making traditional sampling-based methods inefficient, because they would require too many samples to achieve high model quality.	Reply	O	0
This is why we chose the Wikipedia dataset, which is, to our knowledge, one of the few publicly available datasets of this scale.	Reply	B-Reply	1
It also offers different subsets of varying scale, which allowed us to illustrate the effect of the problem size, suggesting that the benefit of the Gramian-based methods increases with vocabulary size.	Reply	I-Reply	1
We added a note to the revision to comment on our choice.	Reply	I-Reply	1
[line_break_token]We also agree that it will be beneficial to evaluate these method on other applications such as more traditional natural language tasks, and this is something we intend to pursue in future work	Reply	I-Reply	2

==== Review Summary ====[line_break_token][line_break_token]The paper demonstrates an interesting and potentially useful idea.	Review	O	0
 But much of it is poorely explained, and experimental results are not strongly convincing.	Review	O	0
 The only numerical evaluations are on a simple dataset that the autho	Review	O	0
Thank you very much for the constructive comments.	Reply	O	0
We respond to the major comments below.	Reply	O	0
We‚Äôll also update figures, rewrite captions, and clarify notations in our revision.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Dimensionality of the latent variables[line_break_token]We agree that motion has more than one degree of freedom; here, the network learns a mapping from 1-D variable to the motion manifold (similar to GANs that learn to map a 100-D variable to the image manifold).	Reply	O	0
[line_break_token][line_break_token]2.	Reply	O	0
Problem setup and baselines[line_break_token]Our model can be considered as a conditional VAE, and it behaves differently during training and testing.	Reply	O	0
[line_break_token][line_break_token]1) During training, we feed the image of current frame I1 and the flow between current and next frame M = flow(I1, I2) into the model as inputs.	Reply	O	0
Our model tries to reconstruct the flow M and leverages it to synthesis the image of next frame I2.	Reply	O	0
[line_break_token][line_break_token]2) During testing, the model only sees a **single** frame.	Reply	O	0
It samples the latent variable to generate possible motion kernels.	Reply	O	0
It then makes use of the sampled motions to estimate the flow between current and next frame, and leverages the flow to synthesis possible next frames.	Reply	O	0
[line_break_token][line_break_token]During training, we choose not to feed the input flow directly into the image decoder, because the model will have no access to the flow during testing.	Reply	O	0
We will revise our paper to emphasize the different inputs we are using during the training and testing time (in Figure 3).	Reply	O	0
[line_break_token][line_break_token]Our goal is to learn the prior that ties part structure and dynamics to their appearance.	Reply	O	0
Only with the learned prior, our model can segment object parts and synthesize motion from a single image.	Reply	O	0
For example, the ‚Äútorso‚Äù is always the parent of the ‚Äúleg‚Äù, and the motion of the leg is always affected by the motion of the torso.	Reply	O	0
Therefore, in our datasets, parts always have the same hierarchical tree structure.	Reply	O	0
[line_break_token][line_break_token]We agree with the reviewers that it‚Äôd be important to add more baselines on future prediction.	Reply	O	0
Note that our model takes a single image for segmentation and future prediction, while most baselines require multi-frame input (e.g., requiring the previous motion field).	Reply	O	0
We will make a comparison with 3DcVAE [1], which only needs one frame as input.	Reply	O	0
For object segmentation, we have included quantitative results on shapes and digits, and will also include numbers for humans in the revision.	Reply	O	0
[line_break_token][line_break_token]3.	Reply	O	0
Structural descriptor[line_break_token]We study the problem where object parts share the same hierarchical structure (e.g. ‚Äòleg‚Äô is always part of ‚Äòfull torso‚Äô).	Reply	O	0
Therefore in our framework, the structural matrix S is shared across data points.	Reply	O	0
In Equation 3, the binary indicator represents whether is an ancestor of, and we replace this binary indicator with a continuous value to make the entire framework differentiable:, where are trainable parameters.	Reply	O	0
Then, we make use of these relaxed indicators to combine the motion maps using Equation 1-3.	Reply	O	0
During evaluation, we binarize the values of by a threshold of 0.5 to obtain the hierarchical tree structure.	Reply	O	0
We‚Äôll include this in the revision.	Reply	O	0
[line_break_token][line_break_token]4.	Reply	B-Reply	2
Human studies[line_break_token]Thanks for the suggestion.	Reply	O	0
We agree that the experiment is not well explained and will remove it in the revision.	Reply	O	0
[line_break_token][line_break_token]We have also listed all other planned changes in our general response above.	Reply	O	0
Please don‚Äôt hesitate to let us know for any additional comments on the paper or on the planned changes.	Reply	O	0
[line_break_token][line_break_token]Reference:[line_break_token][1] Li, Yijun and Fang, Chen and Yang, Jimei and Wang, Zhaowen and Lu, Xin and Yang, Ming-Hsuan.	Reply	O	0
Flow-Grounded Spatial-Temporal Video Prediction from Still Images.	Reply	O	0
In ECCV, 2018.	Reply	O	0

This paper explores the problem of simultaneous learning for topic modeling and survival prediction.	Review	O	0
 Their contributions are: (1) integrating two different topic modeling approaches with survival models for joint learning and (2) showing results on two medical datasets with some brief analysis of what topics are recovered.	Review	O	0
 This is an interesting task to be using with topic modeling.	Review	O	0
 I appreciate that the approach could be used in medical systems where interpretability of models is very important.	Review	O	0
[line_break_token][line_break_token]I think the high-level idea of the algorithms is fine, but the main drawback is that the experimental section needs to be expanded on, perhaps with larger datasets and more analysis.	Review	O	0
 Unless more experiments are provided, I might lean towards rejection.	Review	O	0
 I think it's ok that some of the empirical results are inconclusive, but it should lead to more quantitative error analysis.	Review	B-Review	2
 I definitely think the smaller size of the datasets could be one factor in the negative results, which is why I think the authors should try experimenting with a larger dataset.	Review	I-Review	2
[line_break_token][line_break_token]More specific comments and suggestions:[line_break_token]- Each dataset is small (371 and 1981 data points respectively).	Review	O	0
 This may be too small to effectively train some of these neural models, which I believe may be one reason why they underperform, especially on the pancreatitis data.	Review	B-Review	1
 In order for the experiments to be more conclusive, maybe you can switch to a different dataset.	Review	I-Review	1
[line_break_token]- Related to the size of the data, I suspect that many of the differences in the table are statistically insignificant.	Review	O	0
 Can the authors please specify which of the results are significantly better than the others?	Review	B-Review	2
[line_break_token]- While I liked the examples in Section F of the appendix, they are difficult to compare between models, and not all of the models are included.	Review	O	0
 More quantitative analysis is needed to really understand how the models‚Äô learned topics differ in terms of coherency, cohesiveness, interpretability, etc.	Review	B-Review	3
 Providing really detailed quantitative comparisons might strengthen the analysis section of the paper.	Review	I-Review	3
[line_break_token]- I liked the preciseness of the descriptions of different algorithms in the background section.	Review	O	0
 They were all explained nicely and easy to understand.	Review	B-Review	4
 However, the background section is a bit too detailed at times.	Review	I-Review	4
 Authors may consider condensing a bit more.	Review	I-Review	4
hanks for the comments and suggestions!	Reply	O	0
[line_break_token][line_break_token]In a future draft of this paper, we will incorporate the bulk of your suggestions:[line_break_token]- We will include more datasets, including ones larger than what we currently consider.	Reply	O	0
[line_break_token]- We will include statistical significance results.	Reply	O	0
We do indeed suspect that our proposed approaches as well as a number of the best performing baselines do not yield dramatically different predictions and thus the differences in the test set c-index values are not statistically significant.	Reply	B-Reply	2
In such a scenario, when a bunch of algorithms are more or less equally good, we suspect practitioners would favor more interpretable models.	Reply	I-Reply	2
[line_break_token]- We will provide more quantitative and qualitative analysis of the topics learned (to gauge topic coherence, interpretability, etc), and also discuss how these compare to the features selected via lasso-regularized Cox proportional hazards.	Reply	O	0
[line_break_token]- To the extent possible, we will try to condense the background material	Reply	O	0

Paper contributions[line_break_token]=================[line_break_token]- This paper proposes a method for constructing representations using a matrix of Wasserstein distances.	Review	O	0
These distances measure the discrepancy between each class and each environment, that is a random combination of some classes.	Review	O	0
[line_break_token]- The paper evaluates this approach on a task of image retrieval.	Review	O	0
[line_break_token][line_break_token]General notes[line_break_token]============[line_break_token]The general idea of measuring the distribution divergence for a set of classes is interesting and seems to be novel.	Review	O	0
But I argue that this representation can be limiting:[line_break_token]- A set of divergences doesn't contain any pixel-level information, only divergences to some predefined classes[line_break_token]- As a consequence, this representation will not be able to discover information that is not covered by the labels[line_break_token]Because of these limitations, it seems that this particular representation may be less useful for some applications than others.	Review	B-Review	1
[line_break_token][line_break_token]I don't follow why the paper proposes to use 'environments'  -- random combinations of classes.	Review	I-Review	2
It seems that a square matrix (n_c x n_c) with all classes should do the same job.	Review	I-Review	2
[line_break_token][line_break_token]The experimentation is very weak and does very little to support the claims.	Review	I-Review	3
The paper considers only one substantial task to test the representation.	Review	I-Review	3
This task is image retrieval by image query.	Review	I-Review	3
The paper doesn't provide any comparison to existing methods or simple baselines.	Review	I-Review	3
[line_break_token][line_break_token]The second contribution that the representations are interpretable and composable is not addressed.	Review	I-Review	4
 I seems that it should be hard to interpret a large vector of distances to randomly chosen subsets of classes.	Review	I-Review	4
There is no experiment demonstrating interpretability of the proposed approach.	Review	I-Review	4
The compositionality is not addressed either.	Review	I-Review	4
The samples provided in the appendix are not convincing.	Review	I-Review	4
[line_break_token][line_break_token]The paper is generally well written and it is easy to follow.	Review	I-Review	5
The literature review can be improved by providing prior work where "approaches use hidden state vector of LSTM" and "features extracted from CNNs" instead of generic references.	Review	I-Review	5
[line_break_token][line_break_token]Some of the claims are vague and excessively broad:[line_break_token]- The proposed technique can be used with any task, but the paper is clearly limited to the retrieval task[line_break_token]- The environments are too vaguely described and can be misinterpreted in the introduction[line_break_token][line_break_token]Conclusion[line_break_token]=========[line_break_token][line_break_token]I recommend to reject on the basis that [line_break_token]- the approach is more limited than the paper advocates[line_break_token]- the experimentation is weak[line_break_token]- some claims are not addressed[line_break_token][line_break_token]Other notes[line_break_token]==========[line_break_token]I recommend using term divergence instead of distance when it is not symmetrical.	Review	O	0
ÄúThe general idea of measuring the distribution divergence for a set of classes is interesting and seems to be novel.	Reply	O	0
‚Äù[line_break_token]Thank you for your review and the effort you put into it.	Reply	O	0
[line_break_token][line_break_token]‚Äú[...][line_break_token]- A set of divergences doesn't contain any pixel-level information, only divergences to some predefined classes[line_break_token]- As a consequence, this representation will not be able to discover information that is not covered by the labels[line_break_token]Because of these limitations, it seems that this particular representation may be less useful for some applications than others.	Reply	O	0
‚Äù[line_break_token]We would argue that, to the contrary, using labeled information is useful and many applications require such representations.	Reply	O	0
Our approach offers an easy method to integrate continuous (images) and discrete (labels) information into one representation which, for instance, offers many possibilities given the current state of object recognizers in computer vision.	Reply	B-Reply	1
In particular, using labeled data to explore both global and local similarities over different classes can be useful in many specialized or critical applications where wrong classification results are highly undesirable (medical diagnosis, robotic automation,...) [line_break_token][line_break_token]‚ÄúI don't follow why the paper proposes to use 'environments' -- random combinations of classes.	Reply	O	0
It seems that a square matrix (n_c x n_c) with all classes should do the same job.	Reply	O	0
‚Äù[line_break_token]Note that the experiments that are detailed in section 4.2 with plot in appendix A.1 experimentally confirm the validity of using random combinations.	Reply	O	0
Results for=1 are indicative of the outcome when using a square matrix, yet the results improve significantly for larger values.	Reply	B-Reply	2
We also explicitly tried using a square matrix which did not work as well.	Reply	I-Reply	2
We have clarified why we use environments in the revised submission (sections 2 and 4.2).	Reply	I-Reply	2
In short, we follow the findings of the work of [1] that apply the theory of Random Feature Approximations [2] which has shown to lead to beneficial shift-invariant properties.	Reply	I-Reply	2
[line_break_token][line_break_token]‚ÄúThe experimentation is very weak and does very little to support the claims.	Reply	O	0
The paper considers only one substantial task to test the representation.	Reply	O	0
This task is image retrieval by image query.	Reply	O	0
The paper doesn't provide any comparison to existing methods or simple baselines.	Reply	O	0
‚Äù[line_break_token]With all due respect, this is not correct on two accounts: first, we perform not only retrieval experiments (section 4.3), but also classification experiments on the obtained representation (4.2).	Reply	O	0
Additionally, for both experiments we provide a comparison to baselines.	Reply	B-Reply	3
For the classification task we provide baselines with three state-of-the-art classification models that employ binary cross-entropy (see table 1, section 4.2), for the retrieval based on modified representations we provide a baseline on the basis of CNN features (see table 2, section 4.3).	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúThe second contribution that the representations are interpretable and composable is not addressed.	Reply	O	0
I seems that it should be hard to interpret a large vector of distances to randomly chosen subsets of classes.	Reply	O	0
There is no experiment demonstrating interpretability of the proposed approach.	Reply	O	0
The compositionality is not addressed either. [...]‚	Reply	O	0
Äù [line_break_token]We respectfully disagree on this account as well.	Reply	O	0
The retrieval experiment in section 4.3 is specifically designed to illustrate the interpretability and composability following the method described in section 3.5.	Reply	B-Reply	4
In that experiment we  compose new representations from existing representations by exploiting the structure of the representations that are interpretable over rows and columns.	Reply	I-Reply	4
We subsequently retrieve images that are similar to the modified representations, which we quantitatively have evaluated in table 2 and qualitatively in figure A2.	Reply	I-Reply	4
Additionally, the ‚ÄòSIM‚Äô retrieval method for this experiment relies on the interpretability of representations over different classes.	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúThe paper is generally well written and it is easy to follow.	Reply	O	0
The literature review can be improved by [...]‚Äù[line_break_token]Thank you, we have improved this section in the revised version by adding several relevant works.	Reply	O	0
[line_break_token][line_break_token]‚Äú- The proposed technique can be used with any task, but the paper is clearly limited to the retrieval task[line_break_token]- The environments are too vaguely described and can be misinterpreted in the introduction‚Äù[line_break_token]Again we note that we implemented both a classification task and retrieval task.	Reply	O	0
We have rephrased and detailed certain parts of the paper.	Reply	B-Reply	6
[line_break_token][line_break_token]‚ÄúI recommend using term divergence instead of distance when it is not symmetrical.	Reply	O	0
‚Äù[line_break_token]Could you specifically refer to a relevant instance?	Reply	O	0
All distance estimates employed in the paper are intended as approximations or estimates of the Wasserstein distance which is a distance between distributions.	Reply	B-Reply	7
The IPM formulation is found to be symmetric and satisfies the triangular inequality when Lipschitz continuous [3].[line_break_token][line_break_token][1] <a href="https://arxiv.org/abs/1811.01713" target="_blank" rel="nofollow">https://arxiv.org/abs/1811.01713</a>[line_break_token][2] <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf" target="_blank" rel="nofollow">http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf</a>[line_break_token][3] <a href="https://arxiv.org/abs/1701.07875" target="_blank" rel="nofollow">https://arxiv.org/abs/1701.07875</a	Reply	O	0

This paper proposed the new approach for feature upsampling called pixel deconvolution, which aims to resolve checkboard artifact of conventional deconvolution.	Review	O	0
By sequentially applying a series of decomposed convolutions, the proposed method explicitly enforces the model to consider the relation between pixels thus effectively improve the deconvolution network with an increased computational cost to some extent.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is clearly written and easy to understand the main motivation and methods.	Review	O	0
However, the checkboard artifact is a well-known problem of deconvolution network, and has been addressed by several approaches which are simpler than the proposed pixel deconvolution.	Review	B-Review	1
For example, it is well known that simple bilinear interpolation optionally followed by convolutions effectively removes checkboard artifact to some extent, and bilinear additive upsampling proposed in Wonja et al.,	Review	I-Review	1
2017 also demonstrated its effectiveness as an alternative for deconvolution.	Review	I-Review	1
Comparisons against these approaches would make the paper stronger.	Review	I-Review	1
Besides, comparisons/discussions based on extensive analysis on various deconvolution architectures presented in Wonja et al.,	Review	I-Review	2
2017 would also be interesting.	Review	I-Review	2
[line_break_token][line_break_token]Wonja et al, The Devil is in the Decoder, In BMVC, 2017[line_break_token]	Review	O	0
Although alternative approaches for upsampling have been developed, we believe our work is the first attempt to improve deconvolution itself.	Reply	B-Reply	1
We do not think other similar approaches are simpler than ours.	Reply	I-Reply	1
Our approach is as simple as the original deconvolutional layer both conceptually and computationally as demonstrated by timing results.	Reply	I-Reply	1
We are aware of Wonja et al.	Reply	I-Reply	2
2017, but it was published after our work was completed.	Reply	I-Reply	2
We will add comparisons and discussions in a revised version of our paper	Reply	I-Reply	2

The paper proposes a technique for doing one-shot learning in computation/memory constrained settings, by taking features from a pre-trained CNN, product-quantizing them (with random anchors) to obtain an alphabet, and linking "words" from this alphabet (the PQ chunk centers comprising used to approximate a given feature vector) with class labels via a binary associative memory.	Review	O	0
[line_break_token][line_break_token]The setting is interesting and basic idea is (to the best of my knowledge) novel and appealing.	Review	B-Review	1
However the experimental results aren't compelling and lack natural baselines.	Review	I-Review	1
At least as a reference, it would have been nice to see the performance of a simple linear classifier trained on the feature vectors, if not a comparison against previous techniques that attempt to learn such linear classifiers incrementally.	Review	I-Review	1
As it is it is hard to judge the merit of the proposed approach relative to the state of the art, and on their own the results are somewhat underwhelming.	Review	I-Review	1
The authors wish to thank the anonymous reviewer for his encouraging feedback on the proposed method.	Reply	O	0
We just uploaded a new version of the paper, in which we provide results from a simple baseline, using a linear softmax classifier (logistic regression) trained on the output of the CNN	Reply	B-Reply	1

The paper proposes a CNN variant tailored for high-resolution[line_break_token]immunofluorescence confocal microscopy data.	Review	O	0
 The authors show[line_break_token]that the method outperforms a human expert.	Review	O	0
[line_break_token][line_break_token]The proposed method is evaluated on benchmark instances[line_break_token]distributed by Cyto Challenge '17, which is presumably the best[line_break_token]data source for the target application.	Review	O	0
 Indeed, the method[line_break_token]performs better than several competitors plus a single human[line_break_token]expert.	Review	O	0
[line_break_token][line_break_token]The paper is well written and easy to follow.	Review	O	0
 I could not spot any[line_break_token]major technical issues.	Review	O	0
[line_break_token][line_break_token]This is an applicative paper targeting a problem that is very[line_break_token]relevant in bioinformatics, but it sports little methodological[line_break_token]innovation.	Review	O	0
 On the biological side, the contribution looks[line_break_token]significant.	Review	O	0
 Why not targeting a bioinformatics venue?	Review	B-Review	1
[line_break_token][line_break_token][line_break_token]Detailed comments:[line_break_token][line_break_token]Papers that stretch multiple fields are always hard to review.	Review	O	0
 On[line_break_token]one hand, having contributions that cross different fields is a[line_break_token]high-risk (but potentially highly rewarding) route, and I applaud[line_break_token]the authors for taking the risk.	Review	B-Review	2
 On the other hand, there's the risk[line_break_token]of having unbalanced contributions.	Review	I-Review	2
[line_break_token][line_break_token]I think that the contribution here is mostly on the bioinformatics[line_break_token]side, not on the deep learning side.	Review	I-Review	1
 Indeed, the method boils[line_break_token]down to a variant of CNNs.	Review	I-Review	1
 I am skeptical that this is enough to[line_break_token]spark useful discussion with practitioners of deep learning[line_break_token](although I could be wrong?).	Review	I-Review	1
[line_break_token][line_break_token]Finally, I am always skeptical of "human-level" performance claims.	Review	I-Review	3
[line_break_token]These are strong claims that are also hard to substantiate.	Review	I-Review	3
 I don't[line_break_token]think that comparing to a *single* expert is quite enough.	Review	I-Review	3
 The fact[line_break_token]that "the human expert stated that he would be capable to localize[line_break_token]proteins with the provided data" doesn't sound quite enough.	Review	I-Review	3
 I[line_break_token]agree that the user study could be biased (and that "It would be[line_break_token]a tremendous effort to find a completely fair experimental[line_break_token]setting"), but, if this is the case, the argument that the method[line_break_token]reaches human-level performance is brittle.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]Other remarks and questions:[line_break_token][line_break_token]- Why wasn't the dataset of Liimatainen et al.	Review	O	0
used for the[line_break_token]comparison?	Review	B-Review	4
[line_break_token][line_break_token]- The authors say that "due to memory restrictions, the smallest[line_break_token]variant of DenseNet was used".	Review	O	0
 How much of an impact could have[line_break_token]this had on performance?	Review	B-Review	5
[line_break_token][line_break_token]- "One random crop per training sample is extracted in every epoch".	Review	O	0
[line_break_token]Doesn't this potentially introduce labeling errors?	Review	B-Review	6
 Did you observe[line_break_token]this to occur in practice?	Review	I-Review	6
[line_break_token][line_break_token]- The authors claim that the method is close to perfect in terms[line_break_token]of AUC.	Review	O	0
 In decision-making applications, the AUC is a very[line_break_token]indirect measure of performance, because it is independent of[line_break_token]any decision threshold.	Review	B-Review	7
 In other words, the AUC does not measure[line_break_token]the yes/no decisions suggested by the method.	Review	I-Review	7
 Why is the AUC[line_break_token]important in the biological application at hand?	Review	I-Review	7
 Why is it important[line_break_token]to the users (biologists, I suppose) of the system?	Review	I-Review	7
[line_break_token][line_break_token]In particular, "our method performs nearly perfect, achieving an[line_break_token]average AUC of 98% and an F1 score of 78%" seems inconsistent[line_break_token]to me---the F1 is indeed "only" 78%.	Review	I-Review	7
[line_break_token][line_break_token]- I would appreciate if there was a thorough discussion of the[line_break_token]failure mode of the expert.	Review	O	0
 What kind of errors did he/she[line_break_token]make?	Review	B-Review	8
 How are these cases handled by the model?	Review	I-Review	8
We thank the reviewer for his encouraging statement about our work.	Reply	O	0
We believe that the results are also relevant for the machine learning community because our architecture tackles the problem of weakly labeled data different than other methods before.	Reply	B-Reply	1
[line_break_token][line_break_token]Ad relevance for deep learning[line_break_token][line_break_token]Our contribution on the Deep Learning side is on the problem of dealing with weakly annotated data.	Reply	O	0
Instead of single instances that are labeled, a set of instances is labeled.	Reply	B-Reply	1
A machine learning method has to collect and combine hints from the instances for accurate predictions.	Reply	I-Reply	1
Many hints across the image have to be collected in order to be able to correctly classify.	Reply	I-Reply	1
This is rather more similar to sentiment detection than to object recognition (MNIST, CIFAR, ImageNet), in which typically a single instance has to be detected.	Reply	I-Reply	1
We think that this problem is occurring in a number of different situations, such that researchers in other machine learning fields might find the GapNet-PL technique highly relevant to their problem, as well.	Reply	I-Reply	1
[line_break_token][line_break_token]Ad comparison with human experts[line_break_token][line_break_token]As the reviewer was skeptical about comparisons with humans, so were the authors.	Reply	O	0
Thus, we have taken efforts to improve the estimates of human performance and of expert performance: We recruited two more human experts to improve the performance estimate of human experts.	Reply	B-Reply	3
We also tested 25 graduate and undergraduate students, we call scholars, with life science background and specific training at this task.	Reply	I-Reply	3
Thus, we can now also provide a reliable estimate for knowledgeable, non-expert human performance.	Reply	I-Reply	3
 [line_break_token]We adapted the respective paragraphs including these new results that provide a better view on human performance at this task.	Reply	I-Reply	3
[line_break_token][line_break_token]Other remarks and questions:[line_break_token][line_break_token]1.)	Reply	O	0
Dataset of Liimatainen et al.	Reply	O	0
[line_break_token][line_break_token]They report the performance on the Challenge test set that has never been released.	Reply	B-Reply	4
Therefore, we had to compare the methods on a different test set.	Reply	I-Reply	4
However, we have now re-implemented the method of Liimatainen et al.	Reply	I-Reply	4
and compared it on our test set, where it had a similar performance (F1 score of 0.50 on our test set and 0.51 on the challenge test set).	Reply	I-Reply	4
Hence, all performance metrics are estimated on the same test set and are comparable.	Reply	I-Reply	4
[line_break_token][line_break_token]2.)	Reply	O	0
DenseNet[line_break_token][line_break_token]Due to computational constraints, the computations for DenseNet were restricted to a single GPU on which we could only fit this variant.	Reply	O	0
We hypothesize that there could be small improvement of performance with larger variants.	Reply	B-Reply	5
[line_break_token][line_break_token]3.)	Reply	O	0
Random crops[line_break_token][line_break_token]In practice, we did not observe that an empty crop is propagated through the network, which empirically confirmed by testing around 100,000 random crops.	Reply	O	0
However, we agree with the reviewer about the labeling problem: the data set can in general be considered as weakly annotated (see answer above) because the whole image and not the individual instances, i.e. cells, are labeled.	Reply	B-Reply	6
[line_break_token][line_break_token]4.)	Reply	O	0
AUC as performance measure[line_break_token][line_break_token]The ranking is important in cases, where multiple proteins are tested and the research team wants to perform subsequent test of all proteins that are only located in, say, the nucleus.	Reply	O	0
In this case they would start with the highest ranked protein and test the following proteins until they have found the one with the desired properties.	Reply	B-Reply	7
[line_break_token][line_break_token]5.)	Reply	O	0
Failure modes of human experts[line_break_token][line_break_token]We now provide a list of images (see Appendix) which were frequently mis-labeled by the human experts and how the CNN handled those images including a thorough discussion.	Reply	O	0

This is a well-written and quite clear work about how a previous work on image compression using deep neural networks can be extended to train representations which are also valid for semantic understanding.	Review	O	0
IN particular, the authors tackle the classic and well-known problems of image classification and segmentation.	Review	O	0
[line_break_token][line_break_token]The work evolves around defining a loss function which initially considers only a trade-off between reconstruction error and total bit-rate.	Review	O	0
The representations trained with the loss function, at three different operational points, are used as inputs for variations of ResNet (image classification) and DeepLab (segmentation).	Review	O	0
The results obtained are similar to a ResNet trained directly over the RGB images, and actually with a slight increase of performance in segmentation.	Review	O	0
The most interesting part is a joint training for both compression and image classification.	Review	O	0
[line_break_token][line_break_token]PROS[line_break_token]P.1 Joint training for both compression and classification.	Review	O	0
First time to the authors knowledge.	Review	O	0
[line_break_token]P.2 Performance on classification and segmentation tasks are very similar when compared to the non-compressed case with state-of-the-art ResNet architectures.	Review	O	0
[line_break_token]P.3 Text is very clear.	Review	O	0
[line_break_token]P.4 Experimentation is exhaustive and well-reported.	Review	O	0
[line_break_token][line_break_token]CONS[line_break_token]C1.	Review	O	0
The authors fail into providing a better background regarding the metrics MS-SSIM and SSIM (and PSNR, as well) and their relation to the MSE used for training the network.	Review	B-Review	1
Also, I missed an explanation about whether high or low values for them are beneficial, as actually results compared to JPEG and JPEG-2000 differ depending on the experiment.	Review	I-Review	1
[line_break_token]C2.	Review	O	0
The main problem is of the work is that, while the whole argument is that in an indexing system it would not be necessary to decompress the representation coded with a DNN, in terms of computation JPEG2000 (and probably JPEG) are much lighter that coding with DNN, even if considering both the compression and decompression.	Review	B-Review	2
The authors already point at another work where they explore the efficient compression with GPUs, but this point is the weakest one for the adoption of the proposed scheme.	Review	I-Review	2
[line_break_token]C3.	Review	O	0
The paper exceeds the recommendation of 8 pages and expands up to 13 pages, plus references.	Review	B-Review	3
An effort of compression would be advisable, moving some of the non-core results to the appendixes.	Review	I-Review	3
[line_break_token][line_break_token]QUESTIONS[line_break_token]Q1.	Review	O	0
Do you have any explanation for the big jumps on the plots of Figure 5 ?	Review	B-Review	4
[line_break_token]Q2.	Review	O	0
Did you try a joint training for the segmentation task as well ?	Review	B-Review	5
[line_break_token]Q3.	Review	O	0
Why are the dots connected in Figure 10, but not in Figure 11.	Review	B-Review	6
[line_break_token]Q4.	Review	O	0
Actually results in Figure 10 do not seem good... or maybe I am not understanding them properly.	Review	B-Review	7
This is related to C1.	Review	I-Review	7
[line_break_token]Q5.	Review	O	0
There is a broken reference in Section 5.3.	Review	B-Review	8
Please fix.	Review	I-Review	8
Thank you for your review.	Reply	O	0
We considered your comments as follows.	Reply	O	0
[line_break_token]C1 We have added definitions and clarification on the metrics to the paper.	Reply	O	0
For all of them high means good.	Reply	B-Reply	1
[line_break_token]C2 We  gave an indexing system as an example application, but the main goal of the paper is to study the interplay between learned compression and inference in general.	Reply	O	0
As mentioned in the paper, classical compression can be much faster than learned one - and our computational gains are relative to a system using learned compression.	Reply	B-Reply	2
While falling back to classical codecs would be cheaper in terms of compute (since classical encoder+decoder is more efficient than the learned encoder), the story is not so simple, since this would come at the expense of transmitting more data for a given target image quality.	Reply	I-Reply	2
 This can be crucial, since for mobile devices, data transmission (I/O) is responsible for most energy usage in common applications  (Pathak et.	Reply	I-Reply	2
al, 2012).	Reply	I-Reply	2
Since learned compression is still at its infancy, we expect the gap in terms of compression performance between learned methods and classical ones to grow.	Reply	I-Reply	2
Furthermore, with the increasing availability of dedicated neural network processing units on devices, deep image compression methods could become as fast as traditional ones.	Reply	I-Reply	2
[line_break_token]C3 We have condensed the paper to remove redundant text and also moved some non-core results to the appendix.	Reply	O	0
[line_break_token][line_break_token]Q1.	Reply	O	0
Yes, the standard learning rate schedule for training the ResNet classification architectures is a constant learning rate divided by factor 10 at fixed points in the training (every 8 epochs for our setting).	Reply	B-Reply	4
At the point when the learning rate is lowered the validation accuracy increases rapidly, and our validation curves show these jumps clearly.	Reply	I-Reply	4
[line_break_token]The jumps/difference between operating points is due to more detail being present in images at higher bitrate (higher bpp) and therefore doing inference on them is easier.	Reply	I-Reply	4
[line_break_token]Q2.	Reply	O	0
Yes we also did experiments for joint training with segmentation that are detailed in the revised version of the paper.	Reply	B-Reply	5
In short, we do not train jointly on the segmentation task but we take the jointly trained classification network (that improves classification) and use that as a starting point for segmentation, showing significant improvement for segmentation.	Reply	I-Reply	5
These results are shown in Figure 7.	Reply	I-Reply	5
[line_break_token]Q3.	Reply	O	0
We have made the style of the plots consistent, connecting the dots for both.	Reply	B-Reply	6
[line_break_token]Q4.	Reply	O	0
Figure 10 (also Figure 10 in the revised edition) shows how the compression metrics change when training jointly compared to training only the compression network.	Reply	B-Reply	7
It can be seen that training jointly improves the perceptual metrics MS-SSIM and SSIM slightly while PSNR gets slightly worse (higher is better for all metrics).	Reply	I-Reply	7
Figure 10‚Äôs main point is that the image compression metrics do not get worse in two out of three metrics as we do joint training.	Reply	I-Reply	7
At the same time, Figure 7 shows that the inference  performance (both segmentation and classification) significantly improves.	Reply	I-Reply	7
See Section 6.2 for a thorough discussion in the revised edition.	Reply	I-Reply	7
As this is not a core result it was moved to the appendix.	Reply	I-Reply	7
[line_break_token]Q5.	Reply	O	0
We have fixed this in the revised edition of the paper.	Reply	B-Reply	8
[line_break_token][line_break_token](Pathak, A., Hu, Y. C., & Zhang, M. (2012, April).	Reply	O	0
Where is the energy spent inside my app?:	Reply	O	0
fine grained energy accounting on smartphones with eprof.	Reply	O	0
In Proceedings of the 7th ACM european conference on Computer Systems (pp.	Reply	O	0
29-42).	Reply	O	0
ACM.	Reply	O	0

The paper proposes a way to pre-train quantized representations for speech.	Review	O	0
The approach proposed is a two-stage process: 1.	Review	O	0
train a quantized version of wav2vec [my understanding is that wav2vec is the same thing as CPC for Audio except for using a binary cross-entropy loss instead of InfoNCE softmax-cross entropy loss]. the authors propose to use gumbel softmax / VQ codebook for the vector quantization.	Review	O	0
[line_break_token]2.	Review	O	0
once you have a discrete representation, you could train BERT (as if it were a seq of language tokens).	Review	O	0
this makes a lot of sense especially given that CPC / wav2vec recovers phonemes and quantizing the phonemes will recover a language-like version of the raw audio.	Review	O	0
And running BERT across those tokens will allow you to capture the dependencies at the phoneme level.	Review	O	0
[line_break_token][line_break_token]After pre-training, the authors use the learned representations for speech recognition.	Review	O	0
They compare this to using log-mel filterbanks.	Review	O	0
[line_break_token][line_break_token]The results (WER / LER) is lower for the proposed pipeline compared to using dense wav2vec representation for n-gram and character LM.	Review	O	0
 It also makes sense that BERT helps for the k-means (vq) setting since the number of codes is large.	Review	O	0
[line_break_token][line_break_token]The authors also cleverly adopt/adapt span-BERT which is more suited to this setting.	Review	O	0
[line_break_token][line_break_token]I think this paper presents a useful contribution as far as improving speech / phoneme recognition using self-supervised learning goes, and also has useful engineering aspects in terms of combining CPC and BERT.	Review	O	0
I would like to see this paper accepted.	Review	O	0
hank you for your comments	Reply	O	0

This paper proposes a new measure of gradient mismatch for training binary networks, and additionally proposes a method for getting better performance out of binary networks by initializing them to behave like a ternary network.	Review	O	0
[line_break_token][line_break_token]I found the new measure of gradient deviation fairly underdeveloped, and I suspect the method of converting ternary activations into binary activations works for a different reason than that proposed by the authors.	Review	O	0
[line_break_token][line_break_token]There were English language issues that somewhat reduced clarity, though the intended meaning was always understandable.	Review	O	0
[line_break_token][line_break_token]Detailed comments:[line_break_token][line_break_token]"Binary Neural Network (BNN) has been gaining interest thanks to its computing cost reduction and memory saving."	Review	O	0
--&gt; "Binary Neural Networks (BNNs) have been garnering interest thanks to their compute cost reduction and memory savings." (	Review	O	0
will stop making English language corrections from here on)[line_break_token][line_break_token]"Therefore, we argue that the sharp accuracy drop for the binary activation stems from the inefficient training method, not the capacity of the model."	Review	O	0
[line_break_token]This could also be due to poor initialization in the binary case.	Review	B-Review	2
e.g., it might make sense to initialize the binary network with bias=-0.5, so that the nonlinearity has a kink at pre-activation=0, rather than pre-activation=0.5.	Review	I-Review	2
[line_break_token][line_break_token]"Unfortunately, it is not possible to measure the amount of gradient mismatch directly because the[line_break_token]true gradient of a quantized activation function is zero almost everywhere. "	Review	I-Review	3
It *is* possible to measure the mismatch to the true gradient exactly.	Review	I-Review	3
One could even train using the true gradient.	Review	I-Review	3
It's just that the true gradient is useless.	Review	I-Review	3
[line_break_token][line_break_token]Fig 1b -- this is a nice baseline.	Review	O	0
[line_break_token][line_break_token]"the steepest descent direction, which is the direction toward the point with the smallest loss at given distance"[line_break_token]This is not the usual definition of steepest descent direction.	Review	B-Review	4
If you're going to redefine this, should do so mathematically and precisely (for instance, you are going to run into trouble with the word "distance", since your coordinate discrete gradient more closely resembles an L\infty-ball perturbation, rather than an L2-ball perturbation.	Review	I-Review	4
[line_break_token][line_break_token]eq.	Review	O	0
3:[line_break_token]Note that this equation is equivalent to taking the true gradient of a function which has been boxcar-smoothed along each parameter.	Review	O	0
This may more closely resemble existing measures of deviation than you like.	Review	B-Review	5
[line_break_token][line_break_token]You should also consider the relationship to an evolutionary strategies style gradient estimate, which similarly provides an unbiased gradient estimate for a smoothed function, and which allows that estimate to be computed with fewer samples (at the cost of higher error).	Review	I-Review	5
[line_break_token][line_break_token]Sec.	Review	O	0
4.2 / Figure 3:[line_break_token]The results in this section will be *highly* sensitive to the choice of epsilon.	Review	O	0
You should discuss this, specify the epsilon used, and experimentally explore the dependence on epsilon.	Review	B-Review	6
[line_break_token][line_break_token]"The results indicate that the cosine similarity between coarse gradient and CDG can explain the relationship between gradient mismatch and performance of model better than previous approaches. "	Review	I-Review	7
[line_break_token]Don't know that I followed this.	Review	I-Review	7
Gradient mismatch is never formally defined, so it's hard to know what this says about its relationship.	Review	I-Review	7
Additionally, CDG sounds more like something which is correlated with, rather than an explanation for, performance.	Review	I-Review	7
[line_break_token][line_break_token]" cosine similarity between coarse gradient and CDG can explain the relationship between gradient mismatch and performance of model better " --&gt; " cosine similarity between coarse gradient and CDG can explain the relationship between gradient mismatch and performance of model better "[line_break_token][line_break_token]"we shift the bias of BN layer which comes right before the activation function layer. "	Review	O	0
[line_break_token]Did you try using these bias values without pre-training as a ternary network?	Review	B-Review	9
I suspect it would work just as well!	Review	I-Review	9
[line_break_token][line_break_token]"Please note that BN layers followed by binary activation layer can be merged to the threshold of the binary activation layer, incurring no overhead at inference stage."	Review	I-Review	10
[line_break_token]Did not understand this.	Review	I-Review	10
[line_break_token][line_break_token]"it is expected that the fine-tuning increases the accuracy even further"[line_break_token]Does it improve the accuracy further?	Review	I-Review	11
Should state this as result, not prediction, and should have an ablation experiment showing this.	Review	I-Review	11
[line_break_token][line_break_token]"Table 2 shows the validation accuracy of BNN in various schemes."	Review	I-Review	12
[line_break_token]Why not test accuracy?	Review	I-Review	12
[line_break_token][line_break_token]Figure 6:[line_break_token]What are the filled circles?	Review	I-Review	13
[line_break_token]What was the sampling grid for the HP search?	Review	I-Review	13
The images have high spatial frequency structure that I suspect is an artifact of the interpolation function, rather than in the data.	Review	I-Review	13
[line_break_token][line_break_token]----[line_break_token][line_break_token]Update post-rebuttal:[line_break_token][line_break_token]The authors have addressed the majority of my concerns, through both text changes and significant additional experiments.	Review	O	0
I am therefore increasing my score.	Review	O	0
Thank you for your hard work!	Review	O	0
hank you very much for your constructive comments.	Reply	O	0
We could improve the quality of our work significantly by responding to your comments.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q1: "Binary Neural Network (BNN) has been gaining interest thanks to its computing cost reduction and memory saving."	Reply	O	0
--&gt; "Binary Neural Networks (BNNs) have been garnering interest thanks to their compute cost reduction and memory savings." (	Reply	O	0
will stop making English language corrections from here on)[line_break_token][line_break_token]A1: Thanks very much for pointing out grammatical errors in our writing.	Reply	O	0
We updated some sentences including the above one  in the revised manuscript.	Reply	B-Reply	1
We will do our best to improve the writing in the final manuscript.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token][line_break_token]Q2: "Therefore, we argue that the sharp accuracy drop for the binary activation stems from the inefficient training method, not the capacity of the model."	Reply	O	0
This could also be due to poor initialization in the binary case.	Reply	O	0
e.g., it might make sense to initialize the binary network with bias=-0.5, so that the nonlinearity has a kink at pre-activation=0, rather than pre-activation=0.5.	Reply	O	0
 [line_break_token][line_break_token]A2:  Per reviewer‚Äôs suggestion, we conducted more experiment on CIFAR-10 dataset by initializing the binary network with bias=0.5 so that the nonlinearity has a kink at pre-activation=0.	Reply	O	0
Please note that bias=0.5 instead of -0.5 needs to be used to make the nonlinearity have a kink at pre-activation=0 for the current activation function because each pre-activation needs to be shifted by 0.5 after the bias value is added.	Reply	B-Reply	2
[line_break_token]We trained four different networks with different width factors (x1, x1.25, x1.5 and x2) and each network was trained for 4 runs and the mean results are reported below.	Reply	I-Reply	2
[line_break_token]---------------------------------------------------------------------------------------[line_break_token]|[tab_token][tab_token]|[tab_token][tab_token][tab_token][tab_token][tab_token]width factor[tab_token][tab_token][tab_token][tab_token][tab_token]|[line_break_token]|   Bias[tab_token]|[tab_token]x1[tab_token][tab_token]|[tab_token]x1.25[tab_token]|[tab_token]x1.5[tab_token][tab_token]|[tab_token]x2[tab_token][tab_token]| [line_break_token]---------------------------------------------------------------------------------------[line_break_token]|     0[tab_token]|[tab_token]89.07[tab_token]|[tab_token]89.22[tab_token]|[tab_token]89.41[tab_token]|[tab_token]89.60[tab_token]|[line_break_token]|     0.5[tab_token]|[tab_token]88.96[tab_token]|[tab_token]89.32[tab_token]|[tab_token]89.58[tab_token]|[tab_token]89.69[tab_token]|[line_break_token]---------------------------------------------------------------------------------------[line_break_token]As shown in the table above, we observe that initializing with bias=0.5 does not significantly improve the results.	Reply	I-Reply	2
[line_break_token]In addition, the sharp accuracy drop for the binary activation was also observed in many previous works where symmetric signum function was used for binary activation function (e.g. ABC-Net as shown in Table 1 in our paper) for which nonlinearity has a kink at pre-activation=0.	Reply	I-Reply	2
Therefore, we believe that using bias value of 0 is not the reason for sharp accuracy drop.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token][line_break_token]Q3: "Unfortunately, it is not possible to measure the amount of gradient mismatch directly because the true gradient of a quantized activation function is zero almost everywhere. "	Reply	O	0
It *is* possible to measure the mismatch to the true gradient exactly.	Reply	O	0
One could even train using the true gradient.	Reply	O	0
It's just that the true gradient is useless.	Reply	O	0
[line_break_token][line_break_token]A3: We agree that it is possible to calculate the true gradient.	Reply	O	0
As the reviewer mentioned, the main point should have been that the measured results will not be ‚Äúuseful‚Äù because the value will be zero almost everywhere.	Reply	B-Reply	3
We replaced the word ‚Äúpossible‚Äù with ‚Äúuseful‚Äù in the revised draft as follows.	Reply	I-Reply	3
[line_break_token]‚ÄúUnfortunately, it is not useful to measure the amount of gradient mismatch directly because the true gradient of a quantized activation function is zero almost everywhere."	Reply	I-Reply	3
[line_break_token] [line_break_token][line_break_token][line_break_token]Q4: Fig 1b -- this is a nice baseline.	Reply	O	0
[line_break_token][line_break_token]A4: Thanks very much for your encouraging comments.	Reply	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]Q5: "the steepest descent direction, which is the direction toward the point with the smallest loss at given distance" This is not the usual definition of steepest descent direction.	Reply	O	0
If you're going to redefine this, should do so mathematically and precisely (for instance, you are going to run into trouble with the word "distance", since your coordinate discrete gradient more closely resembles an L\infty-ball perturbation, rather than an L2-ball perturbation.	Reply	O	0
[line_break_token][line_break_token]A5: To get rid of the confusion over the terminology, we decided not to use the term ‚Äústeepest descent direction‚Äù  and updated the sentence in the revised manuscript as follows.	Reply	O	0
[line_break_token][line_break_token](original) ‚ÄúSince the true gradient of quantized activation network is zero almost everywhere, we cannot use the true gradient to find the steepest descent direction, which is the direction toward the point with the smallest loss at given distance.	Reply	B-Reply	4
‚Äù[line_break_token][line_break_token](revised) ‚ÄúSince the true gradient of quantized activation network is zero almost everywhere, using the value of the true gradient does not provide a useful measure of the gradient mismatch problem.	Reply	I-Reply	4
‚Äú[line_break_token]	Reply	I-Reply	3

** Summary **[line_break_token]In this paper, the authors propose a new variant of Transformer called Tied-multi Transformer.	Review	O	0
Given such a model with an N-layer encoder and an M-layer decoder, it is trained with M*N loss functions, where each combination of the nth-layer of the encoder and the mth-layer of the decoder is used to train an NMT model.	Review	O	0
The authors propose a way to dynamically select which layers to be used when a specific sentence comes.	Review	O	0
 At last, the authors also try recurrent stack and knowledge to further compress the models.	Review	O	0
[line_break_token][line_break_token]** Details **[line_break_token]1.	Review	O	0
[tab_token]The first question is ‚Äúwhy this work‚Äù:[line_break_token]a.[tab_token]In terms of performance improvement, in Table 2, we can see that dynamic layer selection does not bring any improvement compared to baseline (Tied(6,6)).	Review	B-Review	1
When compared Tied(6,6) to standard Transformer, as shown in Table 1, there is no improvement.	Review	I-Review	1
Both are 35.0.	Review	I-Review	1
[line_break_token]b.[tab_token]In terms of inference speed, in Table 2, the method can achieve at most (2773-2563)/2998 = 0.07s improvement per sentence, which is very limited.	Review	I-Review	1
[line_break_token]c.[tab_token]In terms of training speed, compared to standard Transformer, the proposed method takes 9.5 time of the standard Transformer (see section 3.4, training time).	Review	I-Review	1
[line_break_token]Therefore, I think that compared to standard Transformer, there is not a significant difference.	Review	I-Review	1
[line_break_token]2.	Review	O	0
[tab_token] The authors only work on a single dataset, which is not convincing.	Review	O	0
[line_break_token]3.	Review	B-Review	1
[tab_token]In Section 5, what is the baseline of standard RS + knowledge distillation?	Review	O	0
[line_break_token]	Review	O	0
e thank you for your review and for taking the time to read our paper thoroughly.	Reply	O	0
[line_break_token][line_break_token]Our responses to your questions are as follows:[line_break_token][line_break_token]1.	Reply	O	0
You are right that a decoding speed gain of 0.07s per sentence is limited, but this gain is obtained with a system as performant as the multi-tied model without routing at the corpus level (BLEU 35.0).	Reply	B-Reply	1
With non-significant loss in BLEU, i.e. 34.7 for instance, a larger decoding speed gain is measured.	Reply	I-Reply	1
Additionally, for a large pool of data to decode, the gain in decoding time is worthwhile.	Reply	I-Reply	1
The main purpose of the dynamic layer selection approach is to draw attention to the concept of flexible decoding.	Reply	I-Reply	1
One of the results is that, using source sentences only as information given to the classifier, the task is difficult.	Reply	I-Reply	1
Regarding the training time of the tied-multi model, flexibility and hence faster decoding is not possible with a standard transformer.	Reply	I-Reply	1
We will have to train several transformer models with different layer configurations to achieve the level of flexibility reached by the tied-multi model.	Reply	I-Reply	1
While training 36 models takes needs  25.5 times the training time of a 6-6 model, training our flexible model takes only 9.5 times the training time of a 6-6 model.	Reply	I-Reply	1
As such our work does have merit.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
We understand that working on multiple datasets would make our work more convincing but we do not expect our results to be dataset dependent as we make no assumption about the type of data used.	Reply	B-Reply	2
Results on other datasets will be included in future manuscripts.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
We trained the RS+KD model but did not include it in the paper because we considered it fair to compare multilayer softmaxed models only.	Reply	B-Reply	3
Nevertheless the BLEU score of RS+KD is 36.1 which is not statistically significantly different from the best BLEU of 36.3 of the multilayer model.	Reply	I-Reply	3

The paper proposes a measure of difficulty for datasets.	Review	O	0
Prior work in this space has often utilized certain indicators like the overlap of samples across different classes etc. [	Review	O	0
A] While this work defines a model-agnostic error as the measure of difficulty, which should encompass all possible indicators of error.	Review	O	0
Then, the paper provides a lower bound on this error which can be estimated using neural network [B][line_break_token][line_break_token]I am inclined to accept (weak) this paper for the following reasons:[line_break_token]1.	Review	O	0
The paper extends Fano's inequality for the case of real-valued vectors and discrete labels, under the assumption of smoothness of the estimators.	Review	O	0
[line_break_token]2.	Review	O	0
The proposed approach for difficulty measure estimation is simple and clear and primarily based on [B].[line_break_token]3.	Review	O	0
The estimates seem to correlate well with the errors of state of the art models, particularly on sentiment and text classification dataset.	Review	O	0
On the image datasets, it is still reasonably well correlated.	Review	O	0
[line_break_token][line_break_token]Some suggestions for improvement:[line_break_token]1.	Review	O	0
Add prior work on measuring data complexity to the references, e.g. [A, C] etc.	Review	O	0
and add some details contrasting prior work with this paper[line_break_token]2.	Review	O	0
It would also be good to see some correlation numbers like Pearson correlation etc.	Review	O	0
between DIME and SOTA errors.	Review	O	0
[line_break_token][line_break_token][A] Spectral Metric for Dataset Complexity Assessment, CVPR 2019[line_break_token][B] Mutual Information Neural Estimation, ICML 2018[line_break_token][C] Complexity Measures of Supervised Classification Problems, PAMI 2002[line_break_token][line_break_token]---[line_break_token]Update:[line_break_token][line_break_token]Thanking authors for all the thoughtful rebuttal made to other reviewers.	Review	O	0
[line_break_token][line_break_token]Based on the concerns raised by the other reviewers and looking through the comments, I am inclined to lower my scores to a weak reject.	Review	O	0
There is definitely quite a lot of good ideas in this paper and it might just be a matter of bulking up with more analysis at this point as suggested by other reviewers.	Review	O	0
hank you for the comments and suggestions.	Reply	O	0
We will add a discussion on the contrast between prior work and our approach as you suggest.	Reply	O	0
We will also compute the Pearson correlation between DIME and SOTA errors  and add them to the results.	Reply	O	0

This paper is about low-precision training for ConvNets.	Review	O	0
It proposed a "dynamic fixed point" scheme that shares the exponent part for a tensor, and developed procedures to do NN computing with this format.	Review	O	0
The proposed method is shown to achieve matching performance against their FP32 counter-parts with the same number of training iterations on several state-of-the-art ConvNets architectures on Imagenet-1K. According to the paper, this is the first time such kind of performance are demonstrated for limited precision training.	Review	O	0
[line_break_token][line_break_token]Potential improvements:[line_break_token][tab_token][line_break_token]  - Please define the terms like FPROP and WTGRAD at the first occurance.	Review	O	0
[line_break_token]  - For reference, please include wallclock time and actual overall memory consumption comparisons of the proposed methods and other methods as well as the baseline (default FP32 training).	Review	O	0
We would like to thank the reviewer for the comments.	Reply	O	0
[line_break_token][line_break_token]We will shortly update the manuscript to fix the missing definitions for the terms pointed out and also a number of other minor typographical errors that we have identified since submission.	Reply	B-Reply	1
[line_break_token][line_break_token]We intend to also include a more detailed discussion on performance (described in the comment below), in which we also include the baseline FP32 performance, along with a comparison with the INT16 variant in terms of various system aspects (memory footprint, performance profile...	Reply	I-Reply	2

I think learning a deep feature representation that is supervised to group dissimilar views of the same object is interesting.	Review	O	0
The paper isn't technically especially novel but that doesn't bother me at all.	Review	O	0
It does a good job exploring a new form of supervision with a new dataset.	Review	O	0
I'm also not bothered that the dataset is synthetic, but it would be good to have more experiments with real data, as well.	Review	B-Review	1
[line_break_token][line_break_token]I think the paper goes too far in linking itself to human vision.	Review	I-Review	2
I would prefer the intro not have as much cognitive science or neuroscience.	Review	I-Review	2
The second to fourth paragraphs of the intro in particular feels like it over-stating the contribution of this paper as somehow revealing some truth about human vision.	Review	I-Review	2
Really, the narrative is much simpler -- "we often want deep feature representations that are viewpoint invariant.	Review	I-Review	2
We supervise a deep network accordingly.	Review	I-Review	2
Humans also have some capability to be viewpoint invariant which has been widely studied [citations]".	Review	I-Review	2
I am skeptical of any claimed connections bigger than that.	Review	I-Review	2
[line_break_token][line_break_token]I think 3.1 should not be based on tree-to-tree distance comparisons but instead based on the entire matrix of instance-to-instance similarity assessments.	Review	I-Review	2
Why do the lossy conversion to trees first?	Review	I-Review	2
I don't think "Remarkably" is justified in the statement "Remarkably, we found that OPnets similarity judgement matches a set of data on human similarity judgement, significantly better than AlexNet"[line_break_token][line_break_token]I'm not an expert on human vision, but from browsing online and from what I've learned before it seems that "object persistence" frequently relates to the concept of occlusion.	Review	O	0
Occlusion is never mentioned in this paper.	Review	B-Review	3
I feel like the use of human vision terms might be misleading or overclaiming.	Review	I-Review	3
[line_break_token][line_break_token]	Review	O	0
Thank you for your helpful comments and suggestions.	Reply	O	0
[line_break_token][line_break_token]First, the reason we use tree-to-tree distance comparison in 3.1 is that it is hard to obtain the ground truth of human judgment based on the pair-wise similarity judgment.	Reply	B-Reply	1
A hierarchical clustering is easier and more accurate for a human to give his judgment.	Reply	I-Reply	1
[line_break_token][line_break_token]Next, we would like to address reviewer‚Äôs suggestion of tuning down the connection between our work and human vision.	Reply	O	0
[line_break_token][line_break_token]Quoting reviewer 2:[line_break_token]>‚ÄúI think the paper goes too far in linking itself to human vision.	Reply	O	0
I would prefer the intro not have as much cognitive science or neuroscience.	Reply	O	0
The second to fourth paragraphs of the intro in particular feels like it over-stating the contribution of this paper as somehow revealing some truth about human vision.	Reply	O	0
Really, the narrative is much simpler -- "we often want deep feature representations that are viewpoint invariant.	Reply	O	0
We supervise a deep network accordingly.	Reply	O	0
Humans also have some capability to be viewpoint invariant which has been widely studied [citations]".	Reply	O	0
I am skeptical of any claimed connections bigger than that.	Reply	O	0
‚Äù[line_break_token][line_break_token]>‚ÄúI don't think "Remarkably" is justified in the statement "Remarkably, we found that OPnets similarity judgment matches a set of data on human similarity judgment, significantly better than AlexNet"[line_break_token][line_break_token]The motivation of our work articulated in the Introduction (including paragraph 2 and 4) is truly our motivation for starting and doing this project.	Reply	O	0
 Our objective is to investigate what will take for a deep network to develop the ability of similarity grouping and judgment of NOVEL objects or classes of objects not in the training set as in Tenanbaum‚Äôs Science paper, and then we hit on the idea of using Siamnese triplet to evaluate whether the object continuity / object persistence constraint hypothesized by theoretical neuroscientists can lead to network that better approximates the performance of human.	Reply	B-Reply	2
That view-manifold training will lead to similarity perception close to human is a conjecture that we seek to empirically investigate.	Reply	I-Reply	2
Thus, we do find it remarkable that this view-invariant learning allows the network to ‚Äúsee‚Äù the similarity of novel objects in a way that is similar to human (as in Tenenbaum‚Äôs results), which we must say it is rather unexpected.	Reply	I-Reply	2
As we moved on this project, we realized there were similar works in the computer vision works, including those pointed out by reviewer 1 that we were not familiar with at the time, and our work became more technically driven and phrased.	Reply	I-Reply	2
Even though we used the image retrieval task and precision-recall metrics for evaluation, we should not lose sight that our goal is to understand how systems can learn to see similarity in novel objects like human.	Reply	I-Reply	2
[line_break_token][line_break_token]That said, we do agree with reviewer 3, the main evidence that directly supported our conjecture is the correlation with Tenenbaum‚Äôs results on human perceptual similarity grouping, though we assumed different views of the same object, and between objects of the same categories are considered more similar at semantic level (e.g. Erdogen et al.	Reply	I-Reply	3
2014, Goldstone and Day 2013 see references below ).	Reply	I-Reply	3
Nevertheless, we thank the reviewer‚Äôs cautionary note and accordingly tuned down our claim on the possible implications of this work on human similarity judgment particularly in the Final Discussion.	Reply	I-Reply	3
 However, we wish to keep our motivation in the introduction, because (1) that is the motivation of our project, (2) we believe there are some deep links between deep network and human visual system, so it is important to discuss them and explore their interesting connections, particularly in a deep learning conference like ICLR.	Reply	I-Reply	3
[line_break_token][line_break_token][1] Quian Quiroga, R., Reddy, L., Kreiman, G., Koch, C. & Fried, I.&nbsp;&nbsp;Invariant visual representation by single neurons in the human brain.&nbsp;Nature&nbsp; 435, 1102‚Äì1107 (2005).	Reply	O	0
[line_break_token][line_break_token][2]&nbsp; Erdogen G, Yildirim and Jacobs R. (2014) Transfer of object shape knowledge across visual and haptic modalities.	Reply	O	0
<a href="http://www.mit.edu/~ilkery/papers/ErdoganYildirimJacobs_CogSci.pdf&nbsp;" target="_blank" rel="nofollow">http://www.mit.edu/~ilkery/papers/ErdoganYildirimJacobs_CogSci.pdf&nbsp;</a>[line_break_token][line_break_token][3]  Goldstone, R. L., & Day, S. B. (2013). &	Reply	O	0
nbsp;Similarity.	Reply	O	0
In H. Pashler (Ed.)	Reply	O	0
The Encyclopedia of Mind.	Reply	O	0
SAGE Reference: Thousand Oaks, CA.&nbsp;(pp.	Reply	O	0
696-699)	Reply	O	0

This work attempts to experimentally investigate the difference between Conv3Ds and ConvLSTMs with the aid of visualization.	Review	O	0
The visualization focuses on two aspects: (1) Temporal masking for identifying key frames and key segments and (2) GradCAM for spatial saliency.	Review	O	0
Both visualization techniques are illustrated on two public available video classification datasets.	Review	O	0
[line_break_token][line_break_token]This work has some major issues:[line_break_token]1.	Review	O	0
The quantitative results are not very relevant.	Review	B-Review	1
It does not validate any of the following cases: (1) if Conv3Ds are more powerful, one should use the same number of parameters and compare classification results, or (2), in order to achieve the same level of accuracy, one of the two models is more parameter efficient.	Review	I-Review	1
It is not clear which argument Table 1 is validating against if there is any as both parameters and accuracies vary.	Review	I-Review	1
[line_break_token]2.	Review	O	0
Qualitative results from Section 5.2 is not substantiated and underwhelming.	Review	B-Review	2
For instance, it is hard to see why "Conv3Ds has a bias around the center while ConvLSTMs find relevant spatial features in multiple smaller areas".	Review	I-Review	2
This is most likely due to visualization techniques other than the choice of models.	Review	I-Review	2
[line_break_token]3.	Review	O	0
The fundamental issue of this work is that it does not establish a hypothesis from the beginning and design experiments around it.	Review	B-Review	3
Plenty of hand-wavy observations are made without further investigating the root of them, leaving readers unsatisfied, and quite often confused.	Review	I-Review	3
ear reviewer,[line_break_token][line_break_token]Thank you for your valuable feedback.	Reply	O	0
Below, we will address each of your raised issues:[line_break_token][line_break_token]1.	Reply	O	0
Regarding the fairness of the comparison, it is written at the end of section 4.2:[line_break_token][tab_token]‚Äú(...) Also, due to the computational complexity of backpropagation through time (BPTT), the C-LSTM variants were significantly more time demanding to train and evaluate than their I3D counterparts.	Reply	B-Reply	1
With this in mind, in order to make the comparison as fair as possible, eleven classes were chosen for which the performance of the two architectures were similar.	Reply	I-Reply	1
‚Äù[line_break_token]And in Section 5.2:[line_break_token][tab_token]‚ÄúThe chosen classes were as follows (I3D F1/C-LSTM F1): moving something and something away from each other (0.76/0.58), moving something and something closer to each other (0.77/0.57), moving something and something so they pass each other (0.37/0.31), moving something up (0.43/0.4), pretending to take something from somewhere (0.1/0.07), moving the camera down while filming something (0.67/0.56), and moving the camera up while filming something (0.81/0.73).‚Äù[line_break_token]We agree with you that this situation is not ideal since I3D has a slight overhand on the C-LSTM for each class.	Reply	I-Reply	1
Even so, we decided to pursue this track for three reasons:[line_break_token][line_break_token]i. We think that the difference in accuracy per class for the two models is within an acceptable range and judge that they should be at least comparable.	Reply	I-Reply	1
[line_break_token][line_break_token]ii.	Reply	I-Reply	1
3D CNNs clearly represent the current state-of-the-art for action recognition.	Reply	I-Reply	1
Because of this, it is interesting to study what such a model ‚Äî better performing in terms of accuracy ‚Äî  finds, compared to a weaker one (in terms of accuracy), since this reflects a typical real-world situation (where the 3D CNN typically would be the model with highest accuracy).	Reply	I-Reply	1
Furthermore, there is an argument to be made concerning how ‚Äògood‚Äô it is to score a high accuracy on a quite artificial dataset such as Something-something.	Reply	I-Reply	1
See also a slightly longer discussion of this point at the end of our response to Official Blind Review #5 (paragraph starting with ‚ÄúIn the reviewer‚Äôs fourth point,...‚Äù).	Reply	I-Reply	1
[line_break_token][line_break_token]iii.	Reply	I-Reply	1
As you correctly point out, the other alternative would be to compare two models on the basis of having the same number of parameters.	Reply	I-Reply	1
However, this is simply not feasible for the two concerned types of models (C-LSTM and 3D CNN).	Reply	I-Reply	1
I3D has 12 times as many parameters as the C-LSTM, yet the C-LSTM takes roughly 1.5 times longer to train for one epoch (2.2h vs. 1.5h on Something-something).	Reply	I-Reply	1
To train a C-LSTM with the same number of parameters as the I3D would simply take a nonviable amount of time.	Reply	I-Reply	1
It can be noted that the C-LSTM used for these experiments on Something-something was trained for 229 hours (105 epochs) on an Nvidia RTX 2080 TI .	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	I-Reply	1
We are not quite sure what is meant by ‚ÄòThis is likely due to visualization techniques other than the choice of models‚Äô since the exact same visualization technique is applied to the two models.	Reply	I-Reply	2
In what concerns the first comment about our qualitative results being unsubstantiated, we have included more extensive quantitative results in Table 2 of the updated article,  including a global measure of the number of ‚Äòblobs‚Äô (contiguous regions present per frame in the Grad-CAM saliency maps), their average size and distance from the center of the image, average mask length and average difference and ratio for the drop in classification score after freeze and reverse perturbations, respectively.	Reply	I-Reply	2
This analysis was done across a subset of the validation data for each model (see the first two paragraphs in our response to Official Blind Review #5).	Reply	I-Reply	2
The results are in line with our findings concerning the center preference of the focus of I3D compared to the C-LSTM.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Deliberately, we did not want to establish a hypothesis from the beginning, in order to investigate this question in an unbiased manner.	Reply	B-Reply	3
When it comes to investigating the root of some claims made in the discussion section of the original version of the article, we have now substantiated these claims in the new Table 2 of the updated article.	Reply	I-Reply	3
We have also improved the discussion using these results and hope that this altogether can help to diminish the reviewer‚Äôs confusion.	Reply	I-Reply	3
[line_break_token][line_break_token]Please don‚Äôt hesitate to reply to this if you have further questions to us at this point.	Reply	O	0

Summary[line_break_token]-------[line_break_token]This paper describes a model for musical timbre transfer.	Review	O	0
[line_break_token]The proposed method uses constant-Q transform magnitudes as the input representation, transfers between domains (timbres) by a CycleGAN-like architecture, and resynthesizes the generated CQT representation by a modified WaveNET-like decoder.	Review	O	0
The system is evaluated by human (mechanical turk) listening studies, and the results indicate that the proposed system is effective for pitch and tempo transfer, as well as timbre adaptation.	Review	O	0
[line_break_token][line_break_token][line_break_token]High-level comments[line_break_token]-------------------[line_break_token][line_break_token]This paper is extremely well written, and the authors clearly have a great attention to detail in both the audio processing and machine learning domains.	Review	O	0
 Each of the modifications to prior work was well motivated, and the ablation study at the end, while briefly presented, provides a good sense of the contributions of each piece.	Review	O	0
[line_break_token][line_break_token]I was unable to listen to the examples provided by the link in section 6, which requires a Microsoft OneDrive login to access.	Review	B-Review	1
 However, the youtube link provided in the ICLR comments gave a reasonable sample of the results of the system.	Review	O	0
 Overall, the outputs sound compelling, and match my expectations given the reported results of the listening studies.	Review	O	0
[line_break_token][line_break_token]On the quantitative side, it would have been nice to see a measurement of phase retrieval of the decoder component, which could be done in isolation from the transfer components by feeding in original CQT magnitudes.	Review	B-Review	2
 This might help give a sense of how well the model can be expected to perform, particular as it breaks down along target timbres.	Review	I-Review	2
 I would expect some timbres to be easier to model than others, and having a quantitative handle on that could help put the listener study in a bit more perspective.	Review	I-Review	2
[line_break_token][line_break_token]Detailed comments[line_break_token]-----------------[line_break_token][line_break_token]The paper contains numerous typos and grammatical quirks, e.g.:[line_break_token]    - page 5: "GP can stable GAN training"[line_break_token]    - page 7: "CQT is equivalent to pitch"[line_break_token][line_break_token][line_break_token]The reverse-generation trick in section 3.2 was clever!	Review	O	0
[line_break_token]	Review	O	0
Thanks for catching the typos!	Reply	B-Reply	3
They are now fixed.	Reply	I-Reply	3
GP means Gradient Penalty; sorry for not writing down the abbreviation in the first place, it is now fixed.	Reply	I-Reply	3
[line_break_token][line_break_token]As for quantitative measurement of phase retrieval of the decoder component, we will include qualitative comparison of rainbowgram(which encodes phase information with color) of the source audio and the wavenet reconstruction (wavenet(CQT(source audio)) and you can find the samples here:<a href="https://1drv.ms/f/s!ApC93lRyk9iagZ5NBNV_ERqOJFK_3w."	Reply	O	0
target="_blank" rel="nofollow">https://1drv.ms/f/s!ApC93lRyk9iagZ5NBNV_ERqOJFK_3w.</a> The reason why we don‚Äôt think in our particular case that quantitative measurement can provide much insight in this regard is because phase retrieval is neither the focus nor a sub-goal of our work: so if, for example, our system produces an output that's shifted by some number of time steps, it would be a perfectly good output, even though the phases are all completely wrong.	Reply	O	0
 [line_break_token][line_break_token]We apologize for the complexity of listening to samples via OneDrive‚Ä¶ In testing it anonymously in advance, we did not have any of these errors, so we did not anticipate such a problem.	Reply	O	0
We are glad you were able to access the youtube link, and we are in the progress of making a project page for our camera ready version, and by then it should be easier to go through all the samples.	Reply	B-Reply	1
 	Reply	I-Reply	1

This paper studies the problem of learning disentangled representation in a hierarchical manner.	Review	O	0
It proposed a hierarchical disentangle network (HDN) which tackles the disentangling process in a coarse-to-fine manner.	Review	O	0
Specifically, common representations are captured at root level and unique representations are learned at lower hierarchical level.	Review	O	0
The HDN is trained in a generative adversarial network (GAN) manner, with additional hierarchical classification loss enforcing the disentanglement.	Review	O	0
Experiments are conducted on CelebA (attributes), Fashion-MNIST (category), and CAD Cars (category &amp; pose).	Review	O	0
[line_break_token][line_break_token]Overall, this paper‚Äôs contribution seems quite outdated and presentation is not very clear.	Review	B-Review	4
[line_break_token][line_break_token](1) Learning hierarchical representation using GAN has been explored in Kaneko et al.	Review	I-Review	4
2018 but not even mentioned in the paper.	Review	I-Review	4
[line_break_token][line_break_token]Generative Adversarial Image Synthesis with Decision Tree Latent Controller.	Review	I-Review	4
Kaneko et al.	Review	I-Review	4
In CVPR 2018.	Review	I-Review	4
[line_break_token][line_break_token]As far as reviewer understands, the bottomline for publication at ICLR is to demonstrate significant improvement/technical novelty compared to prior art.	Review	I-Review	4
[line_break_token][line_break_token]This paper should also compare against GANs or other state-of-the-art generative models with flat representation (especially on face generation) in terms of SSIM, inception score, and FID score.	Review	I-Review	1
Without such comparisons, it is unclear what is the value of hierarchical representation proposed here.	Review	I-Review	1
[line_break_token][line_break_token]-- Glow: Generative Flow with Invertible 1x1 Convolutions.	Review	I-Review	1
Kingma and Dhariwal.	Review	I-Review	1
In NeurIPS 2018.	Review	I-Review	1
[line_break_token]-- Progressive Growing of GANs for Improved Quality, Stability and Variation.	Review	I-Review	1
Karras et al.	Review	I-Review	1
In ICLR 2018.	Review	I-Review	1
[line_break_token]-- A Style-based Generator Architecture for Generative Adversarial Networks.	Review	I-Review	1
Karras et al.	Review	I-Review	1
In CVPR 2019.	Review	I-Review	1
[line_break_token][line_break_token](2) The interpolation results (see Figure 5) look a bit strange as the transition between last columns are not very smooth.	Review	O	0
Also, please provide details about this experiment: are you applying linear interpolation?	Review	B-Review	2
What‚Äôs the interpolation parameter for each of the column?	Review	I-Review	2
[line_break_token][line_break_token](3) For image retrieval experiment, it is not clear if the proposed method is better than any state-of-the-art generative models with flat representations.	Review	O	0
One strong baseline is to use the latent representation of a pre-trained GAN model as comparison.	Review	B-Review	3
[line_break_token]	Review	O	0
hank you for your constructive comments about our method and experiments.	Reply	O	0
We have considered your comments carefully and respond to them in the following.	Reply	O	0
[line_break_token]1).	Reply	O	0
Compare with GANs: IS, FID, SSIM.	Reply	B-Reply	1
[line_break_token]Since our method belongs to the family of conditional GAN, esp.	Reply	I-Reply	1
for image-to-image translation methods, the image quality is better to general GANs (noise to image).	Reply	I-Reply	1
For a fair comparison, apart from StyleGAN, we compared our method with one popular translation method StarGAN (Yunjey Choi et al.	Reply	I-Reply	1
CVPR 2018).	Reply	I-Reply	1
Besides, recently many GANs find that the Learned Perceptual Image Patch Similarity (LPIPS) (Zhang et al.,	Reply	I-Reply	1
CVPR 2018) is more consistent with human‚Äôs perception than SSIM.	Reply	I-Reply	1
Therefore, we use IS, FID and LPIPS for evaluations.	Reply	I-Reply	1
[line_break_token]Results are shown in Tab.	Reply	I-Reply	1
6 (StyleGAN is time cost, which is on-training and the best results will be added in the final revision).	Reply	I-Reply	1
We can see that our method achieves comparable and even slightly better semantics compared with the state-of-the-art image-to-image translation method, which demonstrates that HDN can not only extract primitives of objects for discriminative tasks but also be applied to such graphical applications[line_break_token][line_break_token]2).	Reply	O	0
About the interpolation in Fig.5.	Reply	B-Reply	2
[line_break_token]We are sorry for the details loss of this result in the main paper.	Reply	I-Reply	2
We adopt the linear interpolation (with 5 equally spaced interpolation coefficients range from 0.1 to 0.9) of disentangled features between the source (first columns in each case) and target (last columns of each case).	Reply	I-Reply	2
The last columns represent the target images, but not generated results.	Reply	I-Reply	2
For clarity, such introductions have been added to our revision.	Reply	I-Reply	2
[line_break_token][line_break_token]3).	Reply	O	0
Image retrieval: use the latent of a pre-trained GAN as the baseline.	Reply	B-Reply	3
[line_break_token]We added the retrieval performance of the pre-trained StarGAN (supervised) and StyleGAN (unsupervised) in Tab.2.	Reply	I-Reply	3
The obvious advantages of our method in this experiment over them can be found, mainly owing to the discriminative disentangling mechanism we proposed.	Reply	I-Reply	3
[line_break_token][line_break_token]4).	Reply	O	0
Relationship with the work of Kaneko et al.	Reply	O	0
2018[line_break_token]Thanks for notifying us of this related work.	Reply	O	0
The work of Kaneko et al.	Reply	B-Reply	4
2018 did a good job to generate an image in a coarse-to-fine manner which is controlled by the disentangled hierarchical representations.	Reply	I-Reply	4
Their experiments also validate that their method can synthesize images with higher quality and controlled the image appearances to be more and more specific.	Reply	I-Reply	4
[line_break_token]Our work has similarities with the work of Kaneko et al.	Reply	I-Reply	4
2018 on motivations.	Reply	I-Reply	4
Both aim to disentangle the variations within data in a hierarchical manner.	Reply	I-Reply	4
[line_break_token]Nevertheless,  the work of Kaneko et al.	Reply	I-Reply	4
2018 is indeed different from ours.	Reply	I-Reply	4
Specifically, the detailed goals of leveraging hierarchical relationships are different.	Reply	I-Reply	4
The work of Kaneko et al.	Reply	I-Reply	4
2018 aims to maximize the mutual information between conditioned representation and data in each level, i.e. study how the appearance of data varies with more and more narrow conditions and thus synthesize data with more fine-grained details.	Reply	I-Reply	4
Our method focuses more on how humans distinguish objects from categories in different hierarchical levels and wish such manner of understanding objects can be applied to the machine, i.e. learn the commonality and individuality of categories in nature.	Reply	I-Reply	4
Therefore, the disentangled features of our method are mainly served for downstream discriminative tasks such as semantic retrieval, open-world unseen category recognition as we have attempted in the experiments.	Reply	I-Reply	4
Besides, thanks to the disentangled commonality, our method can further realize the semantic translations between images by exchanging the individualities, which has been a popular application in the real world.	Reply	I-Reply	4
[line_break_token]We have cited this work and discussed the difference in Sec.3.3 in our revision.	Reply	I-Reply	4
[line_break_token][line_break_token]Ref.	Reply	O	0
[line_break_token]Yunjey Choi, Min-Je Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo.	Reply	O	0
Stargan: Unified generative adversarial networks for multi-domain image-to-image translation.	Reply	O	0
In CVPR 2018.	Reply	O	0
[line_break_token]Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang.	Reply	O	0
The unreasonable effectiveness of deep features as a perceptual metric.	Reply	O	0
In CVPR 2018.	Reply	O	0
[line_break_token]	Reply	O	0

Summary:[line_break_token][line_break_token]In this paper, the authors propose a new method to apply continual learning on sequential data.	Review	O	0
The model is constructed by combining an Autoencoder and LSTM/LMN for each task.	Review	O	0
The experiments on several datasets show the proposed model outperforms basic LSTM/LMN.	Review	O	0
[line_break_token][line_break_token][line_break_token]Strength:[line_break_token][line_break_token]+ Sequential data widely exist in the real world, e.g., text, health records.	Review	O	0
Thus, It is interesting to see that continual learning is used in sequential data.	Review	O	0
[line_break_token][line_break_token]+ The motivation of the proposed model is clear.	Review	O	0
The authors save the learned knowledge in the hidden representation of LSTM/LMN.	Review	O	0
[line_break_token][line_break_token]Weakness:[line_break_token]- In this paper, the model size linearly increases since the number of LSTM/LMN and AE increases when a new task comes in.	Review	O	0
Thus, if the number of tasks is too large, the model size is quite big.	Review	B-Review	1
In traditional continual learning settings, researchers may not always increase the model size for overcoming catastrophic forgetting.	Review	I-Review	1
For example, if task 1 and task 2 sample from the same distribution, they can share the same LSTM/LMN and AE.	Review	I-Review	1
Thus, it would be better if the authors can consider how to reduce the model size in the future version.	Review	I-Review	1
[line_break_token][line_break_token]- In the experiments, the authors only compare the proposed model with simple LSTM or LMN.	Review	O	0
However, most continual learning methods can still be applied in this scenario, at least regularization based methods [1,2] can be simply applied in this scenario.	Review	B-Review	2
The authors may need to compare the proposed method with them in the future version.	Review	I-Review	2
[line_break_token][line_break_token]- It is better to compare it with a larger dataset.	Review	O	0
For example, in the natural language processing field, we can regard sentiment analysis on one language as one task.	Review	B-Review	3
Then, we can construct the continual learning dataset for sentiment analysis.	Review	I-Review	3
[line_break_token][line_break_token]Minor Comments:[line_break_token]It is better to improve Figure 3 by adding the x-axis label and y-axis label.	Review	O	0
[line_break_token][line_break_token][line_break_token][1] Kirkpatrick, James, et al. "	Review	O	0
Overcoming catastrophic forgetting in neural networks."	Review	O	0
Proceedings of the national academy of sciences 114.13 (2017): 3521-3526.	Review	O	0
[line_break_token][2] Zenke, Friedemann, Ben Poole, and Surya Ganguli. "	Review	O	0
Continual learning through synaptic intelligence."	Review	O	0
Proceedings of the 34th International Conference on Machine Learning-Volume 70.	Review	O	0
JMLR.	Review	O	0
org, 2017.	Review	O	0
e agree that the model size is the main limitation GIM.	Reply	B-Reply	1
However, as you say, it is reasonable to assume that the number of hidden units of each module could decrease as the number of modules increases.	Reply	I-Reply	1
Inter-modules connections can foster reuse of previous features, thus reducing the need to learn them from scratch.	Reply	I-Reply	1
As far as we know, our work is the first example of a progressive model + gating AE applied to sequential data.	Reply	I-Reply	1
Therefore, we decided to leave this extension out of the proposed paper, since we prefer to focus more on the benchmark design and the sequential nature of the data rather than the model architecture.	Reply	I-Reply	1
We would like to propose GIM as a simple baseline that can be improved upon in several different directions.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that it would be valuable to compare current CL techniques (e.g EWC) with GIM in order to further assess our approach.	Reply	I-Reply	2
We will integrate some of the main techniques into our analysis and we will highlight the main differences between their application on a computer vision scenario and a sequential data processing scenario.	Reply	I-Reply	2
[line_break_token][line_break_token]We struggle to understand what the use of a larger dataset (e.g. NLP / sentiment analysis) would add to our analysis.	Reply	I-Reply	3
We recognize that it will be an important step in the development of full-fledged CL systems for sequential data processing, but we believe that in this first phase it would be better to focus on task-agnostic benchmarks before moving on to more complex scenarios.	Reply	I-Reply	3
This choice allows us to highlight the CL properties of the model without the need to tailor it on a specific field of application, which often requires a complex preprocessing or the use of intermediate embeddings.	Reply	I-Reply	3
By using simpler benchmarks, we reduce the probability to misinterpretation of results.	Reply	I-Reply	3
This approach also makes it easier for other researchers to compare their results against our benchmark, since we do not require a large computational infrastructure to manage the experiments	Reply	I-Reply	3

I have read the authors' rebuttal and satisfied with their response.	Review	O	0
Novelty is a little on the lower side, but thorough writing, results, and insightful comparisons make up for this in my opinion.	Review	O	0
I have updated my score to 8: Accept.	Review	O	0
[line_break_token][line_break_token]=====[line_break_token][line_break_token]This paper proposes an approach to perform image translation called U-GAT-IT.	Review	O	0
In image translation, the goal is to learn a mapping from images in a source domain to corresponding images in a target domain.	Review	O	0
Contemporary image translation approaches are able to transfer local texture but struggle to handle shape transfer.	Review	O	0
To address this concern, the authors introduce an attention mechanism based on CAM [1] and an adaptive normalization layer into a GAN-based image translation framework.	Review	O	0
Results indicate favorable quantitative and qualitative performance relative to a number of baselines.	Review	O	0
[line_break_token][line_break_token]Specific contributions include:[line_break_token]* Introduction of a normalization layer called AdaLIN that can interpolate between instance normalization and layer normalization based on the input.	Review	O	0
[line_break_token]* Introduction of an attention mechanism based on CAM [1] that allows the model to focus on specific parts of the image when either generating or discriminating.	Review	O	0
[line_break_token]* Collection and release of a selfie-to-anime dataset.	Review	O	0
[line_break_token]* Release of U-GAT-IT code.	Review	O	0
[line_break_token]  [line_break_token]In my opinion this paper is borderline, leaning towards weak accept.	Review	O	0
The experiments are thorough and the paper is well-written.	Review	O	0
I have concerns about the novelty and significance of the work, but overall the paper feels very close to being a finished piece of work in spite of its (relatively minor) flaws.	Review	B-Review	1
[line_break_token]  [line_break_token]Strong points of this work include the writing and experiments.	Review	O	0
The paper is clearly organized and feels polished.	Review	O	0
It cites many relevant works, giving the reader a sense of the contemporary approaches for image translation.	Review	O	0
There is a thorough description of model architecture, dataset and tuning parameters in the appendix.	Review	O	0
In addition, code and the selfie-to-anime dataset have been released by the authors.	Review	O	0
In terms of experiments, the authors provide many qualitative visualizations comparing the proposed model to baselines on various datasets.	Review	O	0
Quantitative evaluation includes KID and a perceptual evaluation on human subjects.	Review	O	0
[line_break_token][line_break_token]Weak points include novelty and significance.	Review	B-Review	1
The proposed approach combines two ideas already applied to image translation (adaptive normalization [3] and attention [4]).	Review	I-Review	1
 It therefore synthesizes these ideas into an effective algorithm rather than directly adding something new.	Review	I-Review	1
It is unclear to me how others can build on top of this work to further advance state-of-the-art in image translation.	Review	I-Review	1
Are more sophisticated normalization and attention mechanisms truly the key to improving image translation in the future?	Review	I-Review	1
[line_break_token][line_break_token]Specific comments:[line_break_token]* The formulation of AdaLIN in Equation (1) is vague.	Review	O	0
The text states "parameters are dynamically computed by a fully connected layer from the attention map", but it's not clear what those parameters are in the equation.	Review	B-Review	2
Explicitly writing \gamma and \beta as functions of the fully-connected layer and \mu_I, \sigma_I, \mu_L, \sigma_L as the corresponding mean and standard deviation expressions would make things more clear.	Review	I-Review	2
[line_break_token]* The motivation for using layer normalization was discussed in 2.1.1 but I still do not understand why it is beneficial.	Review	O	0
[line_break_token]* The term "importance weights" has a specific meaning in the context of Monte Carlo methods.	Review	O	0
I would suggest choosing a different term here.	Review	B-Review	4
[line_break_token][line_break_token]Questions for the authors:[line_break_token]* How does U-GAT-IT compare to TransGaGa [2]?	Review	O	0
One of the stated goals of U-GAT-IT is to better handle shape when performing image translation.	Review	B-Review	5
TransGaGa has a similar motivation and so I would have liked to see an experimental comparison or at the very least a description of how U-GAT-IT differs.	Review	I-Review	5
What sorts of shape transfer could U-GAT-IT handle that TransGaGa couldn't and vice versa?	Review	I-Review	5
[line_break_token]* What are the shortcomings of the model and how could they possibly be addressed?	Review	O	0
[line_break_token]  [line_break_token][1] Zhou, B., Khosla, A., Lapedriza, A., Oliva, A. and Torralba, A., 2016.	Review	O	0
Learning deep features for discriminative localization.	Review	O	0
In Proceedings of the IEEE conference on computer vision and pattern recognition (pp.	Review	O	0
2921-2929).	Review	O	0
[line_break_token][2] Wu, W., Cao, K., Li, C., Qian, C. and Loy, C.C., 2019.	Review	O	0
Transgaga: Geometry-aware unsupervised image-to-image translation.	Review	O	0
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp.	Review	O	0
8012-8021).	Review	O	0
[line_break_token][3] Huang, X. and Belongie, S., 2017.	Review	O	0
Arbitrary style transfer in real-time with adaptive instance normalization.	Review	O	0
In Proceedings of the IEEE International Conference on Computer Vision (pp.	Review	O	0
1501-1510).	Review	O	0
[line_break_token][4] Mejjati, Y.A., Richardt, C., Tompkin, J., Cosker, D. and Kim, K.I., 2018.	Review	O	0
Unsupervised attention-guided image-to-image translation.	Review	O	0
In Advances in Neural Information Processing Systems (pp.	Review	O	0
3693-3703).	Review	O	0
e thank the reviewer for the valuable comments and constructive feedback.	Reply	O	0
 In the revised draft, we mark our major revisions by ‚Äúviolet‚Äù , and would like to answer the reviewer‚Äôs questions as follows: [line_break_token] [line_break_token]*About Novelty:[line_break_token][line_break_token]1.	Reply	O	0
Attention mechanism [line_break_token][line_break_token]Although we proposed similar attention concept, the goal and how to generate are different.	Reply	B-Reply	1
Previous attention-based work [1] do not allow to transform the shape of the instance because of attaching the background to the (translated) cropped instances.	Reply	I-Reply	1
Unlike these works, we assumed that our model will guide to focus on more important regions and ignore minor regions by distinguishing between the target and not-target domains based on the importance map obtained by the auxiliary classifier.	Reply	I-Reply	1
These attention maps are embedded into the generator and discriminator to focus on semantically important areas, thus facilitating the shape transformation.	Reply	I-Reply	1
The attention map in the generator induces focus on areas that specifically distinguish between the two domains.	Reply	I-Reply	1
The attention map in discriminator helps fine-tuning by focusing on the difference between real image and fake image in target domain.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	2
Normalization [line_break_token][line_break_token]AdaLIN tells the model how much it should transform.	Reply	I-Reply	1
Instance Norm (IN) is capable of preserving the characteristics of source image.	Reply	I-Reply	1
Layer Norm (LN) which uses layer-wise feature statistics is better at transforming to target domain.	Reply	I-Reply	1
We found that combining advantages of both IN and LN is beneficial to image-to-image translation task in various datasets by controlling the amount of transform.	Reply	I-Reply	1
Though its idea borrows from previous work [2], the proposed method is the first attempt to combine IN and LN in image-to-image translation task as far as we investigated.	Reply	I-Reply	1
[line_break_token][line_break_token][1] Y. Alami Mejjati, C. Richardt, J. Tompkin, D. Cosker, and K. I. Kim.	Reply	O	0
Unsupervised attention-guided image-to-image translation.	Reply	O	0
In NIPS.	Reply	O	0
2018.	Reply	O	0
[line_break_token][2] H. Nam and H.-E. Kim.	Reply	O	0
Batch-instance normalization for adaptively style-invariant neural networks.	Reply	O	0
In NIPS, 2018.	Reply	O	0
[line_break_token][line_break_token]*Specific Comments:[line_break_token][line_break_token]1.	Reply	O	0
The formulation of AdaLIN in Equation (1)[line_break_token][line_break_token]I agree with the comment from the Reviewer.	Reply	O	0
In the revised draft, I modify like  "parameters, /gamma and /beta are dynamically computed by a fully connected layer from the attention map" in sec 2.1.1.	Reply	B-Reply	2
[line_break_token][line_break_token]2.	Reply	I-Reply	2
 The motivation for using layer normalization [line_break_token][line_break_token]We assumed that optimal stylization method was "whitening and Coloring Transform".	Reply	O	0
However, the computational cost is high due to the calculation of the covariance matrix and matrix inverse.	Reply	B-Reply	3
To compensate between the computational cost and the quality of the result, we borrowed two sub-optimal normalization methods, AdaIN and Layer Normalization.	Reply	I-Reply	3
During stylization, while the AdaIN has the characteristics keeping more contents information, the Layer Normalization tends to make stylization more obvious instead keeping content information less.	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	O	0
The term "important weights"[line_break_token][line_break_token]In the revised draft, we modify it to "the weight of the k-th feature map for the source domain"  in sec 2.1.1.	Reply	O	0
[line_break_token][line_break_token]*Questions for the authors:[line_break_token][line_break_token]1.	Reply	O	0
U-GAT-IT vs TransGaGa[line_break_token][line_break_token]The goal of U-GAT-IT is to change the shape of the foreground while maintaining the content of the background.	Reply	O	0
TransGaGa deal with the geometry and appearance separately and fully converts the appearance of the source domain into that of the target domain without considering the foreground and background.	Reply	B-Reply	5
Therefore, as can be seen from the experimental results, the background of the source image is not maintained at all.	Reply	I-Reply	5
However, U-GAT-IT can maintain or change the contents of the source domain adaptively through attention.	Reply	I-Reply	5
In addition, U-GAT-IT can achieve good results in style transfer as well as shape change through AdaLIN.	Reply	I-Reply	5
Therefore, we think U-GAT-IT is a more generalized version than TransGaGa.	Reply	I-Reply	5
[line_break_token][line_break_token]2.	Reply	I-Reply	2
What are the shortcomings of the model and how could they possibly be addressed?	Reply	O	0
[line_break_token][line_break_token]The shortcomings for our model is "one-to-one mapping".	Reply	B-Reply	6
But we will design UGATIT with our future work to be multi-modal and multi-domain together	Reply	I-Reply	6

This paper aims at developing a better understanding of generalization error for increasingly prevalent non-convex learning problems.	Review	O	0
For many such problems, the existing generalization bounds in the statistical learning theory literature are not very informative.	Review	O	0
To address these issues, the paper explores algorithm-specific generalization bounds,  especially focusing on various types of noisy gradient methods.	Review	O	0
[line_break_token][line_break_token]The paper employs a framework that combines uniform stability and PAC-Bayesian theory to obtain generalization bound for the noisy gradient methods.	Review	O	0
For gradient Langevin dynamic (GLD) and stochastic gradient Langevin dynamics (SGLD), using this Bayes-Stability framework, the paper obtains a generalization bound on the expected generalization error that scales with the expected empirical squared gradient norm.	Review	O	0
As argued in the paper, this provides an improvement over the existing bounds in the literature.	Review	O	0
Furthermore, this bound enables the treatment of the setting with noisy labels.	Review	O	0
For this setting the expected empirical squared gradient norm along the optimization path is higher, leading to worse generalization bound.	Review	O	0
[line_break_token][line_break_token]The paper then extends their results to the setting where an regularization is added to the non-convex objective.	Review	O	0
By using a new Log-Sobolev inequality for the parameter distribution at time t, the paper obtains new generalization bounds for continuous Langevin dynamic (CLD).	Review	O	0
These bounds subsequently provide bounds for GLD as well.	Review	O	0
[line_break_token][line_break_token]The paper demonstrates the utility of their generalization bound via empirical evaluation on MNIST and CIFAR dataset.	Review	O	0
The obtained generalization bounds are informative as they appear to capture the trend in the generalization error.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is very well written with a clear comparison with the existing generalization bounds.	Review	O	0
The results in the paper are interesting and novel.	Review	O	0
That said, the discussion in the introduction and abstract appears a bit misleading as it gives the impression that this is the first paper that combines the ideas from stability and PAC-Bayesian theory to obtain generalization bounds.	Review	B-Review	1
This is not the case, e.g. see [1].[line_break_token][line_break_token]As noted by the authors, some of the bounds obtained in this paper share similarities with one of the bounds in Mou et al.	Review	O	0
 as all these bounds contain the expected empirical squared gradient norm.	Review	B-Review	2
The bound in Mou et al.	Review	I-Review	2
holds with high probability and decays as, whereas the bounds in this paper are on expected generalization error and decay as.	Review	I-Review	2
Could authors comment on extending their results to hold with high probability and how it would affect their bounds?	Review	I-Review	2
[line_break_token][line_break_token][1] Rivasplata et al.,	Review	O	0
PAC-Bayes bounds for stable algorithms with instance-dependent priors.	Review	O	0
[line_break_token][line_break_token][line_break_token]----------------------- Post author response -------------[line_break_token][line_break_token]Thank you for addressing my comments.	Review	O	0
I have decided to keep my original score unchanged.	Review	O	0
hanks for your careful review and insightful comments!	Reply	O	0
[line_break_token][line_break_token]Regarding high-probability bounds, we note that our proof of Theorem 11 can be adapted to recover the previous bound of in (Mou et al.,	Reply	B-Reply	2
2018, Theorem 1), with the expected squared gradient norm term relaxed to, using the uniform stability framework.	Reply	I-Reply	2
Then, applying the recent results of [Feldman and Vondrak, 2019, Theorem 1] gives a generalization error bound of that holds with high probability. (	Reply	I-Reply	2
Here hides some polylog factors.)	Reply	I-Reply	2
Since is typically at least linear in n, this means that the additional term will not be dominating.	Reply	I-Reply	2
[line_break_token][line_break_token]On the other hand, for our new bound, which is derived from Bayes-Stability instead of uniform stability, it remains unknown whether it can be translated into a high-probability bound following a similar approach.	Reply	I-Reply	2
We believe that it is an interesting open problem to prove a similar high-probability bound (with a small overhead) for the Bayes-Stability framework.	Reply	I-Reply	2
[line_break_token][line_break_token]We will include the above discussion into the next version.	Reply	I-Reply	2
[line_break_token][line_break_token]Indeed, [Rivasplata et al.]	Reply	I-Reply	1
also combines ideas from PAC-Bayes and stability.	Reply	I-Reply	1
While their stability is actually the hypothesis stability measured by the distance on the hypothesis space.	Reply	I-Reply	1
And their work stduies the case when the returned hypothesis (model parameter) is randomized by a Gaussian perturbation (i.e., the posterior), which is different from our work.	Reply	I-Reply	1
Thanks for pointing this out.	Reply	I-Reply	1
In the next version, we will discuss their work and modify our descriptions in the introduction and abstract.	Reply	I-Reply	1
[line_break_token][line_break_token]-------------------------------------[line_break_token]Reference[line_break_token][line_break_token]PAC-Bayes bounds for stable algorithms with instance-dependent priors.	Reply	O	0
Rivasplata et al.	Reply	B-Reply	1
[line_break_token][line_break_token]High probability generalization bounds for uniformly stable algorithms with nearly optimal rate.	Reply	O	0
Vitaly Feldman and Jan Vondrak.	Reply	O	0
[line_break_token][line_break_token]Sharper bounds for uniformly stable algorithms.	Reply	O	0
Bousquet et al.	Reply	O	0
[line_break_token][line_break_token]Generalization bounds for uniformly stable algorithms.	Reply	O	0
Feldman et al	Reply	O	0

Summary[line_break_token][line_break_token]It is known that GNNs are vulnerable to the oversmoothing problem, in which feature vectors on nodes get closer as we increase the number of (message passing type graph convolution layers).	Review	O	0
This paper proposed PairNorm, which is a normalization layer for GNNs to tackle this problem.	Review	O	0
The idea is to pull apart feature vectors on a pair of non-adjacent nodes (based on the interpretation of Laplace-type smoothing by NT and Maehara (2019)).	Review	O	0
To achieve this approximately with low computational complexity, PairNorm keeps the sum of distances of feature vectors on all node pairs approximately the same throughout layers.	Review	O	0
The paper conducted empirical studies to evaluate the effectiveness of the method.	Review	O	0
PairNorm improved the prediction performance and enabled make GNNs deep, especially when feature vectors are missing in the large portion of nodes (the SSNC-MV problem).	Review	O	0
[line_break_token][line_break_token][line_break_token]Decision[line_break_token][line_break_token]I want to recommend to accept the paper because, in my opinion, this paper contributes to deepening our understanding of graph NNs by giving new insights into what causes the oversmoothing problem and which types problem (deep) graph NNs can solve.	Review	O	0
[line_break_token]The common myth about graph NNs is that they cannot make themselves deep due to the oversmoothing.	Review	O	0
Therefore, oversmoothing is one of the big problems in the graph NN field and has been paid attention from both theoretical and empirical sides.	Review	O	0
This paper found that the deep structures do help to improve (or at least worsen) the predictive performance when the significant portion of nodes in a graph does not have input signals.	Review	O	0
To the best of our knowledge, this is the first paper that showed the effectiveness of deep structures in citation network datasets (Deep GCNs [Li et al.,	Review	O	0
2019] successfully improved the prediction performance of (residual) graph NNs using as many as 56 layers for point cloud datasets).	Review	O	0
The proposed method is theoretically backboned, easy to implement, and applicable to (theoretically) any graph NNs.	Review	O	0
Taking these things into account, I would like to judge the contribution of this paper is sufficiently significant to accept.	Review	O	0
[line_break_token][line_break_token][line_break_token]Minor Comments[line_break_token][line_break_token][tab_token]- Table 3.	Review	O	0
Remove s in the entry for GAT-t2 Citeseer 0%.	Review	B-Review	1
[line_break_token][line_break_token][line_break_token]Questions[line_break_token][line_break_token][tab_token]- Can we interpret PairNorm (or the optimization problem (6)) from the viewpoint of graph spectra?	Review	O	0
[line_break_token][tab_token]- Although the motivation of Centering (10) is to ease the computation of TPD, I am curious how this operation contributes to performance.	Review	O	0
Since the constant signal does not have information for distinguishing nodes, eliminating it by Centering might result in emphasizing the signal component for nodes classification tasks.	Review	B-Review	3
From a spectral point of view, Centering corresponds to eliminating the lowest frequency of a signal.	Review	I-Review	3
[line_break_token][tab_token]- Figures 3 and 7 have shown that GCN and GAT did not perform well compared to SGC when the layer size increases.	Review	O	0
The authors discussed that this is because GCN and GAT are easier to overfit.	Review	B-Review	4
However, SGC chose the hyperparameter from, whereas the authors examined a single for GCN and GAT.	Review	I-Review	4
Therefore, I think there is another hypothesis that simply the choice was misspecified.	Review	I-Review	4
If this is the case, I am interested in the effect of on predictive performance.	Review	I-Review	4
[line_break_token][line_break_token][Li et al.,	Review	O	0
2018] Li, Qimai, Zhichao Han, and Xiao-Ming Wu. "	Review	O	0
Deeper insights into graph convolutional networks for semi-supervised learning."	Review	O	0
Thirty-Second AAAI Conference on Artificial Intelligence.	Review	O	0
2018.	Review	O	0
hank you very much for reading our paper thoroughly and giving constructive feedback, and we are glad that you found our paper interesting and contributing to a deeper understanding of the field.	Reply	O	0
We respond to your questions one-by-one in the following.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt; Can we interpret PairNorm (or the optimization problem (6)) from the viewpoint of graph spectra?	Reply	O	0
[line_break_token] [line_break_token]That is a great question that we have not thought about before.	Reply	O	0
We are doing new work towards understanding stacking GraphConv operations in the spectral domain, but currently we do not have a complete answer for your question.	Reply	B-Reply	2
To give some initial thought: The operation is working on features directly.	Reply	I-Reply	2
Since it does not change the graph structure, it does not affect the eigenvectors or spectrum of the graph.	Reply	I-Reply	2
However, it will affect the alignment/interaction between structure and features.	Reply	I-Reply	2
Understanding the fusion between graph structure and features in spectral domain should be investigated more carefully.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]&gt;&gt; Although the motivation of Centering (10) is to ease the computation of TPD, I am curious how this operation contributes to performance.	Reply	O	0
[line_break_token][line_break_token]We have tested adding the mean back after Scale operation, and for SGC the performance remained the same.	Reply	B-Reply	3
However for GCN and GAT, because of the activation function there will be a big difference.	Reply	I-Reply	3
Empirically, they have similar performance but sometimes one is better and the other is worse.	Reply	I-Reply	3
One does not seem to dominate the other.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]&gt;&gt;  Therefore, I think there is another hypothesis that simply the choice was misspecified.	Reply	O	0
If this is the case, I am interested in the effect of on predictive performance.	Reply	O	0
[line_break_token][line_break_token]‚Ä®We did several tests using different for the SSNC problem, and we found that does not affect performance much for GCN and GAT.	Reply	O	0
We think this is because the parameter learning has some connection with the scale, so setting different is not that important.	Reply	B-Reply	4
We do not have enough time for doing a thorough testing for all settings, as GCN and GAT are much slower to train than SGC.	Reply	I-Reply	4
To sum up, we think it is not surprising that SGC works very well for these settings, which is also demonstrated in the original SGC paper (Wu et al.,	Reply	I-Reply	4
2019).	Reply	I-Reply	4

The basic premise of this work is that topological operators are increasingly adopted in machine learning models, but the literature lacks of general differentiable topological operators.	Review	O	0
[line_break_token][line_break_token]The main idea proposed in this work is to use the topological signature directly as a loss for autoencoders.	Review	O	0
The general aim is to preserve the topological properties of data while performing dimensionality reduction.	Review	O	0
[line_break_token] [line_break_token]The proposed method computes the persistent homology of the 0-dimensional Vietoris‚ÄìRips by means of persistence diagrams and persistence pairing.	Review	O	0
The additional step is to computes the regularization loss, by posing the constraint that the persistent homology be similar between data space and latent space.	Review	O	0
The empirical analysis investigates the stability property with respect to the mini-batch sampling.	Review	O	0
[line_break_token][line_break_token]The extended experiments don't provide an empirical evidence of the added value of a topological AE.	Review	B-Review	1
The results are quite controversial if we focus our attention on MSE measures.	Review	I-Review	1
AE and TopoAE behave in a similar way and it is not clear whether such a difference is statistically significant.	Review	I-Review	1
[line_break_token][line_break_token]The work is missing a mandatory comparison with Hofer et al. (	Review	I-Review	2
2019b) that proposes a loss very similar to the one presented in Section 3, even though the authors remark that their formulation is more general.	Review	I-Review	2
For example an interesting comparison could have been with the real-case application of classification for the images datasets (e.g. CIFAR, MNIST, ImageNet) where Hofer et al. (	Review	I-Review	2
2019b) proves their claims.	Review	I-Review	2
[line_break_token][line_break_token]The computational issues of the d-dimensional Vietoris-Rips with d &gt; 0, limits the preservation of only simple structures in the point-cloud.	Review	O	0
[line_break_token]	Review	O	0
gt; MSE to compare AE and Topo-AE[line_break_token][line_break_token]We understand the concerns of the reviewer here.	Reply	O	0
To clarify, our method regularises the topology of the latent space as an *additional* objective.	Reply	B-Reply	1
The goal is to obtain a latent space whose topology is similar to that of the input space (as approximated on the level of mini-batches).	Reply	I-Reply	1
Therefore, we consider the small increase in MSE to be the ‚Äòprice to pay‚Äô for obtaining a better (in terms of its topology) latent representation.	Reply	I-Reply	1
To illustrate this point, imposing structural restrictions at the minimal cost of increased reconstruction error is comparable to the relationship between SOM and the standard k-means approach.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; The work is missing a mandatory comparison with Hofer et al. (	Reply	O	0
2019b)[line_break_token][line_break_token]Thank you for pointing this out.	Reply	O	0
While our work is related to Hofer et al. (	Reply	B-Reply	2
2019b) the objective of this work is different.	Reply	I-Reply	2
Hofer et al.	Reply	I-Reply	2
propose regularizing the connectivity of the latent space by itself, whereas our goal is to align input and latent space in terms of connectivity.	Reply	I-Reply	2
In particular Hofer et al.	Reply	I-Reply	2
show that it could be beneficial for some downstream task (such as classification) to enforce certain topological properties in a representation and allow to tune these properties in the latent space.	Reply	I-Reply	2
By contrast, we propose a method for dimensionality reduction which should *preserve* the topology of a data space in the latent space, to allow a better understanding and visualization of the high-dimensional data space.	Reply	I-Reply	2
This is why (in contrast to Hofer et al.)	Reply	I-Reply	2
we refrain from using the latent space as a basis for a classification task as it is not clear why the preserved data space topology would be beneficial for classification (as opposed to e.g. disentangled latent representations).	Reply	I-Reply	2
We make this distinction now more clear in the paper to reduce confusion.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; Computational issues of the-dimensional Vietoris--Rips computation[line_break_token][line_break_token]Thank you for raising this important point.	Reply	O	0
This is a general limitation of persistent homology computations at the moment; it is not a specific limitation of our approach.	Reply	B-Reply	3
However, we expect that forthcoming improvements in implementations (for example, GPU implementations or optimised implementations such as U. Bauer‚Äôs ‚ÄòRipser‚Äô) or in approximation techniques will address this.	Reply	I-Reply	3
As a side-note, we also want to mention that the question of the contribution of higher-dimensional features is not fully answered yet; some papers, such as Hofer et al. (	Reply	I-Reply	3
2017) or ‚ÄòLearning metrics for persistence-based summaries and applications for graph classification‚Äô by Zhao &amp; Wang empirically found that higher-dimensional topological features are not required for tasks like graph classification.	Reply	O	0
[line_break_token][line_break_token]Please let us know if there are any other questions that we can answer for you concerning this paper	Reply	O	0

The paper proposes a simple but effective method for controlling the location of objects in image generation using generative adversarial networks.	Review	O	0
Experiments on MNIST and CLEVR are toy examples but illustrate that the model is indeed performing as expected.	Review	O	0
The experiments on COCO produce results that while containing obvious artefacts are producing output consistent with the input control signal (i.e., bounding boxes).	Review	O	0
It would however have been interesting to see more varied bounding box locations for the same caption.	Review	B-Review	1
[line_break_token][line_break_token]In short, the paper makes an interesting addition to image generation works and likely to be incorporated into future image generation and inpainting methods.	Review	O	0
Dear reviewer,[line_break_token]thank you very much for your review.	Reply	O	0
[line_break_token][line_break_token]We will update our submission with examples of images based on MS-COCO captions in which we vary the location of the various bounding boxes.	Reply	B-Reply	1
[line_break_token][line_break_token]We will work to implement the feedback we got and will post an updated version of our submission by the end of next week (latest on 16.	Reply	O	0
November) and will let you know once the updated version is online	Reply	O	0

This paper studies the role of weight/bias variance of neural network‚Äôs trainability via analyzing large depth behaviour of Neural Tangent Kernels(NTK).	Review	O	0
[line_break_token][line_break_token]Recently NTK has been a popular topic of study in theoretical deep learning as it describes exact gradient descent dynamics of infinitely wide networks.	Review	O	0
Original NTK paper (Jacot et al. (	Review	O	0
2018)) and other follow up papers often gloss over role of weight/bias scales whereas in the setting of signal propagation or NNGP covariance, Schoenholz et al. (	Review	O	0
2017), Lee et al. (	Review	O	0
2018), Novak et al. (	Review	O	0
2019), Hayou et al. (	Review	O	0
2019) have shown understanding initialization scale is quite important as networks becomes deeper.	Review	O	0
This paper brings those analysis for NTK and discovers few interesting results.	Review	O	0
[line_break_token][line_break_token]The good weight/bias initialization scale that propagates signal for very deep network is denoted edge of chaos (EOC).	Review	O	0
The authors show that 1) for fully connected feed forward networks, outside initialization edge of chaos (EOC) the NTK converges exponentially to constant kernel.	Review	O	0
This indicates non-trainability.	Review	O	0
2) With EOC initialization the convergence is polynomial and the NTK remains invertible for very large depth implying trainability.	Review	O	0
3) Certain class of activation function (denoted class S, including ELU/Tanh/Swish) it has even slower convergence(O(log(L)/L)) compare to ReLU (O(1/L)).	Review	O	0
4) Residual FC networks NTK has polynomial convergence for all weight and bias variance.	Review	O	0
[line_break_token][line_break_token]In terms of novelty, the paper is combining existing techniques and objects to study large depth behaviour of NTK.	Review	O	0
However the contribution of the paper is interesting and worth the ICLR audience to know about, especially with the current surge of interest in NTK.	Review	O	0
[line_break_token][line_break_token]One main weakness is that the experiments are weak and have a very weak connection to the early part of the paper.	Review	B-Review	1
Section 5.1 is direct convergence comparison, which provides fair evidence.	Review	I-Review	1
In section 5.2, I‚Äôm not certain whether experiments displayed connects to asymptotic NTK analysis.	Review	I-Review	1
First of all, in order to obtain NTK in the infinite width limit, one has to use `NTK parameterization‚Äô where one scales out 1/sqrt(fan_in) in network definition and not in weight initialization.	Review	I-Review	1
It seems (by mention of He/Glorot init, and choice of learning rate O(1e-3/1e-4)) the authors experimented with standard parameterization.	Review	I-Review	1
In this case the connection to very deep behaviour of NTK is not straightforward to actual network training since the training dynamics will be different.	Review	I-Review	1
 I suggest authors try experiments in NTK parameterization and see if results are similar.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]Few comments:[line_break_token]It should be emphasized that the infinite width is taken first before taking infinite depth limit.	Review	O	0
There are subtle effects when depth/width are taken to infinity at the same time.	Review	B-Review	2
The analysis on asymptotic behaviour of NTK at infinite depth is only valid after width is taken to infinity.	Review	I-Review	2
[line_break_token][line_break_token]First sentence of the abstract is too strong in the sense that NTK has limitations.	Review	I-Review	3
NTK certainly does not work for any kind of network, so I suggest authors to down tone the sentence.	Review	I-Review	3
[line_break_token][line_break_token]P4 paragraph after Lemma1 `'K^L(x, x‚Äô) = cte‚Äô is a typo?	Review	I-Review	4
[line_break_token][line_break_token]In section 5.2, the authors‚Äô claim full batch GD is practically impossible.	Review	I-Review	5
One could accumulate gradients over minibatch to simulate full batch GD.	Review	I-Review	5
[line_break_token][line_break_token]P13 typo in last paragraph, `  NTKl'[line_break_token][line_break_token]EDITS POST AUTHOR RESPONSE:[line_break_token]Regarding point 5) I was referring to solving the memory problem.	Review	O	0
In practice, if one is sampling without replacement, there is no randomness accumulating gradient of the full epoch.	Review	B-Review	5
[line_break_token][line_break_token]I also thank the authors for the clarification.	Review	O	0
My score still remains the same.	Review	O	0
e thank Reviewer 1 for the detailed and insightful feedback.	Reply	O	0
We address them hereafter.	Reply	O	0
[line_break_token][line_break_token]1) ‚ÄúOne main weakness is that the experiments are weak and have a very weak connection to the early part of the paper.	Reply	O	0
Section 5.1 is direct convergence comparison, which provides fair evidence.	Reply	O	0
In section 5.2, I‚Äôm not certain whether experiments displayed connects to asymptotic NTK analysis... ‚Äù[line_break_token][line_break_token]We agree that the dynamics might be slightly different.	Reply	O	0
However, in practice both parametrizations give similar results in terms of Trainability and Training Speed (which are our focus in this paper) since they both have the same EOC (same EOC curve  in (\sigma_b, \sigma_w) plane).	Reply	B-Reply	1
More precisely, the NTK is the same for both parametrization at initialization, and in practice we use small learning rates for standard parametrization (1e-3) compared to the learning rates used with NTK parametrization (to compensate for the scaling), we believe that the resulting training dynamics should not change much, unless we use small learning rates for the NTK parametrization which would result in very slow training.	Reply	I-Reply	1
We added in the appendix (Appendix E) an example of training a network of depth 100 and width 100 with both parametrizations with an EOC initialization (we used ELU in this example), it shows that both parametrizations have similar behaviour on the EOC.	Reply	I-Reply	1
This is also true on the Ordered/Chaotic phase where the model is stuck at the random classifier accuracy ~10% for both parametrizations.	Reply	I-Reply	1
 We will add more experimental results with NTK Parametrization in the appendix of the final version of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]2) ‚ÄúIt should be emphasized that the infinite width is taken first before taking infinite depth limit.	Reply	O	0
There are subtle effects when depth/width are taken to infinity at the same time.	Reply	O	0
The analysis on asymptotic behaviour of NTK at infinite depth is only valid after width is taken to infinity. ‚	Reply	O	0
Äú[line_break_token]We have mentioned that we only deal with the infinite width networks in ‚ÄúMotivation and Related work‚Äù.	Reply	O	0
We have changed it in the revised version to make it clearer that the width is considered infinite before taking the limit of large depth.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token]3)‚ÄùFirst sentence of the abstract is too strong in the sense that NTK has limitations.	Reply	O	0
NTK certainly does not work for any kind of network, so I suggest authors to down tone the sentence. ‚	Reply	O	0
Äù[line_break_token]In the first sentence of the abstract, we are only referring to the exact NTK and not Mean-Field NTK.	Reply	O	0
The Exact NTK is just another formulation of the Gradient Descent optimization problem as a Gradient in the Functional space, the exact NTK changes with training time t. We agree that when considering the Mean-Field NTK, that sentence is no longer correct.	Reply	B-Reply	3
[line_break_token][line_break_token][line_break_token]4) ‚ÄúP4 paragraph after Lemma1 `'K^L(x, x‚Äô) = cte‚Äô is a typo? ‚	Reply	O	0
Äù and ‚ÄúP13 typo in last paragraph, ` NTKl' ‚Äù[line_break_token]Thank you.	Reply	O	0
We have fixed the typos in the revised version[line_break_token][line_break_token][line_break_token]5) ‚ÄúIn section 5.2, the authors‚Äô claim full batch GD is practically impossible.	Reply	O	0
One could accumulate gradients over minibatch to simulate full batch GD. ‚	Reply	O	0
Äù This is a very interesting suggestion.	Reply	O	0
 Just to make sure we understand correctly what you mean: by simulating the GD using minibatch gradients, we will still have some randomness, isn‚Äôt that equivalent to SGD with bigger batchsize ?	Reply	B-Reply	5
Or are you suggesting this could potentially solve the memory cost problem ?	Reply	I-Reply	5

Summary:[line_break_token]This work proposes a method to perform clustering on a time-series data for prediction purposes, unlike the classical clustering where it is done in an unsupervised manner.	Review	O	0
The authors use an encoder (RNN) to process the time-series medical records, a selector to sample the cluster label for each encoding, and a predictor to predict the labels based on the selected cluster centroids.	Review	O	0
Since the sampling process prevents the authors from using back-prop, they employ an actor-critic method.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]- Although some would argue otherwise, patient similarity has some promise to be useful in clinical practice.	Review	O	0
[line_break_token]- The proposed method clearly outperformed various baselines in terms of clustering (Table 1).	Review	O	0
[line_break_token]- Table 3 and Figure 3 show that the proposed method can capture heterogeneous subgroups of the dataset.	Review	O	0
[line_break_token][line_break_token]Concerns:[line_break_token]- I'm not a clustering expert, but I'm skeptical this is the first work to combine clustering and supervised prediction using an RL technique.	Review	O	0
[line_break_token]- It is unclear what it means to train the embedding dictionary.	Review	O	0
Are there trainable parameters in the embedding dictionary?	Review	B-Review	2
It seems that all it does is calculate the mean of the z_t's (i.e. centroid) in each cluster.	Review	I-Review	2
Or do you take the centroid embeddings and put that through a feed-forward network of some sort?	Review	I-Review	2
[line_break_token]- The effect of Embedding Separation Loss (Eq.5) seems quite limited.	Review	O	0
According to Table 2, it doesn't seem to help much.	Review	B-Review	3
And contrary to the authors' claim, using \beta increase the number of activated clusters from 8 to 8.4.	Review	I-Review	3
[line_break_token]- Most importantly, the central theme of this work is combining clustering with prediction labels for the downstream prediction task.	Review	O	0
But the authors do not compare the prediction performance of the proposed method with other clustering method or "patient similarity" methods, or even simple supervised models.	Review	B-Review	4
The only prediction performance metric to be found is Table 2 from the ablation study.	Review	I-Review	4
e thank the reviewer for the valuable comments.	Reply	O	0
[line_break_token][line_break_token]A1.	Reply	O	0
To our best knowledge, this paper is the first to apply reinforcement learning for identifying predictive clusters.	Reply	B-Reply	1
Indeed, there exist some studies that explored clustering with reinforcement learning, such as to select a better initialization for K-means [A] and to design efficient feature space [B]. However, previous works mainly focused on conventional clustering problems without accounting for observed outcome labels of interest.	Reply	I-Reply	1
[line_break_token][line_break_token]A2.	Reply	O	0
The embedding dictionary consists of embedding vectors in the latent space, i.e., where these embedding vectors are updated by minimizing the loss function in (9) based on the stochastic gradient descent method.	Reply	B-Reply	2
This is doable because both terms in (9) are defined as a function of the predictor outputs taking the embedding vectors as input; this makes (9) differentiable with respect to the embedding vectors.	Reply	I-Reply	2
Please refer to Algorithm 1 in Appendix F to see the formal descriptions of how we update the embedding vectors.	Reply	I-Reply	2
[line_break_token][line_break_token]A3.	Reply	O	0
We inadvertently mistyped the values on the number of activated clusters for and; the correct number of activated clusters is 8.4 with and 8 with.	Reply	B-Reply	3
We will correct the typo in Table 2 in the revised manuscript.	Reply	I-Reply	3
Besides, please refer to A2 to Reviewer #1 to see how the embedding separation loss in (5) plays a significant role in identifying the number of clusters in a data-driven fashion.	Reply	I-Reply	3
[line_break_token][line_break_token]A4.	Reply	O	0
As the reviewer suggested, we assessed the prognostic performance of our method and the clustering benchmarks which incorporate the label information during training ‚Äì that are KM-E2P ), KM-E2P ), DCN-E2P, and SOM-VAE-P. For the prognostic performance, we evaluated AUROC and AURPC based on the ground-truth binary outcomes ) and the cluster-specific outcome predictions that are calculated specifically to each clustering method:[line_break_token]    - For KM-E2P ) and DCN-E2P, the cluster-specific outcome predictions are the predictor outcomes taking the average latent representations per cluster (i.e., the K-means centroids in the latent space) as input.	Reply	B-Reply	4
[line_break_token]    - For KM-E2P ), the cluster-specific outcome predictions are the average predictor outcomes per cluster (i.e., the K-means centroids in the outcome space).	Reply	I-Reply	4
[line_break_token]    - For SOM-VAE-P and our method, the cluster-specific outcome predictions are the predictor outcomes (i.e.,) taking the assigned embedding vectors as input.	Reply	I-Reply	4
[line_break_token]Below, we reported the AUROC and AUPRC for UKCF and ADNI; our method outperformed all the tested benchmarks in both performance metrics.	Reply	I-Reply	4
We will update Table 1 in the revised manuscript accordingly.	Reply	I-Reply	4
[line_break_token][line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                       |UKCF                                         | ADNI                                   [line_break_token]Methods       |--------------------------------------------------------------------------------[line_break_token]                       | AUROC          | AUPRC           | AUROC           | AUPRC[tab_token]    [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]KM-E2P(Z)    | 0.726 0.01 | 0.425 0.02 | 0.707 0.01 | 0.509 0.01[line_break_token]KM-E2P(Y)    | 0.807 0.00 | 0.514 0.01 | 0.756 0.04 | 0.503 0.04[line_break_token]DCN-E2P      | 0.772 0.03 | 0.487 0.03 | 0.721 0.03 | 0.509 0.03 [line_break_token]SOM-VAE-P  | 0.754 0.05 | 0.331 0.07 | 0.597 0.10 | 0.376 0.05[line_break_token]Proposed     | 0.843 0.01 | 0.605 0.01 | 0.768 0.02 | 0.515 0.02[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token]References:[line_break_token][A] S. Bose and M. Huber, ‚ÄúSemi-Unsupervised Clustering Using Reinforcement Learning,‚Äù AAAI 2016.	Reply	O	0
[line_break_token][B] W. Barbakh and C. Fyfe, ‚ÄúClustering with Reinforcement Learning,‚Äù IDEAL 2007[line_break_token]	Reply	O	0

This paper studies the role of different hyperparameters in finetuning image recognition models on new target tasks.	Review	O	0
The authors run a large set of experiments and show that, perhaps non-surprisingly, hyperparameters matter.	Review	O	0
In particular, they show that momentum, which is typically ignored in finetuning, is quite important, and that the momentum values  that work well depend on the similarity between the source and target datasets.	Review	O	0
They also show important correlations between momentum, learning rate, and weight decay.	Review	O	0
[line_break_token]Overall, despite some issues detailed below, the paper is clearly written, presents a coherent story, and its conclusions will be useful to the community.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]1.	Review	O	0
My main concern about this paper relates to the importance of momentum.	Review	B-Review	1
The authors argue that this hyperparameter is "critical for fine-tuning performance".	Review	I-Review	1
However, they later show that in fact what matters is the ratio between the learning rate (LR) and the momentum.	Review	I-Review	1
In this case, it might be justified to fix the momentum value and only modify the LR, as often done.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	7
The EMD values of Birds, Cars and Aircrafts are within 0.7 points of each other (while Dogs is much higher and Flowers is quite lower).	Review	I-Review	2
Although I am not too familiar with this method, I find it somewhat hard to believe that these small differences explain the error differences on Table 2.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	7
While the paper is fairly clear in writing, the figures (e.g., fig.	Review	I-Review	4
3 and 4) are extremely hard to read on print, and thus hard to draw conclusions from.	Review	I-Review	4
Figure 4 is confusing also on screen.	Review	I-Review	4
[line_break_token][line_break_token]4.	Review	O	0
To promote reproducibility, it would be better to report in this kind of research validation rather than test results.	Review	B-Review	3
There is some confusion in Figure 4, the axes say validation error, while the caption says test error, but in the other figures test results are reported.	Review	I-Review	3
[line_break_token][line_break_token]Minor:[line_break_token][line_break_token]1.	Review	O	0
The authors say in the intro "Even when there is enough training data, fine-tuning is still preferred as it often reduces training time significantly (He et al.,	Review	B-Review	5
2019).",	Review	I-Review	5
but later make a somewhat contradictory claim: "He et al. (	Review	I-Review	5
2019) questioned whether ImageNet pre-training is necessary for training object detectors.	Review	I-Review	5
They find the solution of training from scratch is no worse than the fine-tuning counterpart as long as the target dataset is large enough.".	Review	I-Review	5
[line_break_token][line_break_token]2.	Review	I-Review	7
A couple of typos around the paper:[line_break_token]- section 2: "However, most of these advances on hyperparameter tuning are designed *from* training from scratch" (should be "for")[line_break_token]- The first sentence of 3.3 is ungrammatical[line_break_token][line_break_token]	Review	I-Review	6
hanks for your positive review!	Reply	O	0
In our revised version, we have fixed the typos and made the figures easier to read and adjusted our narratives.	Reply	B-Reply	6
Below are our response to your questions:[line_break_token][line_break_token]Q1: ‚ÄúMy main concern about this paper relates to the importance of momentum‚Äù[line_break_token][line_break_token]A:  We agree that simply emphasizing the importance of momentum without context may be miss leading.	Reply	O	0
As we agree that learning rate is a ‚Äúcritical‚Äù hyperparameter, the aim of the first part is to show momentum is also an equivalent ‚Äúcritical‚Äù hyperparameter, rather than common belief that the default 0.9 is the best value or there is no effect when momentum is tuned.	Reply	B-Reply	1
We would like to correct the belief that only LR is ‚Äúcritical‚Äù for fine-tuning.	Reply	I-Reply	1
[line_break_token][line_break_token]In fact, as long as the initial learning rate is fixed and small enough, we can always search for the optimal momentum instead.	Reply	I-Reply	1
Momentum acts as a learning rate amplifier, making the ELR larger by a factor of 1/(1-m).	Reply	I-Reply	1
This shares the same spirit as [Smith et al, 2018] where increasing batch size during training has the same effect as decreasing learning rate.	Reply	I-Reply	1
When momentum is fixed, it also determine the search ranges of learning rate.	Reply	I-Reply	1
Tiny changes of momentum from 0.99 to 0.9 will have significant effect on the learning rate search ranges.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: ‚ÄúThe EMD values of Birds, Cars and Aircrafts are within 0.7 points of each other...I find it somewhat hard to believe that these small differences explain the error differences on Table 2‚Äù[line_break_token][line_break_token]A: Though difference of the similarity scores are not dramatic, the relative order is more meaningful.	Reply	O	0
The similarity based on EMD might not be the optimal measurement, but the difference of optimal hyperparameters for those datasets are clearly shown in Figure 4.	Reply	B-Reply	2
In Appendix C of the revised version, we provide the detailed steps for calculating the EMD based domain similarity and provide our scores for all datasets.	Reply	I-Reply	2
The raw EMD for Birds and Cars are 15.08 and 16.82 and their similarity scores after processing are 0.8600 and 0.8452.	Reply	I-Reply	2
As shown in Figure 4(a), the optimal ELR for Birds and Cars are 0.05 and 0.5, respectively.	Reply	I-Reply	2
With the same learning rate 0.01, both momentum 0 and 0.9 has similar performance for Birds as the ELR are all close to the optimal one.	Reply	I-Reply	2
While for Cars dataset, momentum 0.9 makes 0.1 ELR, which is closest to the optimal ELR 0.5.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: ‚Äúit would be better to report in this kind of research validation rather than test results‚Äù[line_break_token][line_break_token]A: We agree.	Reply	O	0
We use the test data of these datasets for validation and report the validation error.	Reply	B-Reply	3
We have corrected the axes in Figure 4 and make them more consistent.	Reply	I-Reply	3
As we noted in section 3.1, our goal is not getting STOA performance on these datasets.	Reply	I-Reply	3
For each trial of hyperparameter configuration, we report the performance of the last epoch after training rather than selecting the best one during training.	Reply	I-Reply	3
The curves are only used for monitoring and comparison.	Reply	I-Reply	3
[line_break_token][line_break_token][1] Smith et al, Don‚Äôt decay the learning rate, increase the batch size, ICLR 2018	Reply	O	0

In this paper, the authors proposed an approach to fit locally constant functions using deep neural networks (DNNs).	Review	O	0
[line_break_token]The idea is based on the fact that DNN consisting of only linear transformations and ReLU activations is piecewise linear.	Review	O	0
[line_break_token]Thus, the derivative of such a network with respect to the input is locally constant.	Review	O	0
[line_break_token][line_break_token]In the paper, the authors focused on connecting the locally constant network with oblique decision trees.	Review	O	0
[line_break_token]Specifically, they proved that these two models are in some sense equivalent, and one can transform one model to another.	Review	O	0
[line_break_token]This connection enables us to train the oblique decision trees by training the locally constant network instead.	Review	O	0
[line_break_token]Because the locally constant network can be trained using the gradient-based methods, it would be much easier to train than the oblique decision trees.	Review	O	0
[line_break_token][line_break_token]I think the paper is well-written and the idea is clear.	Review	O	0
[line_break_token]Connecting the locally constant network with oblique decision trees looks interesting.	Review	O	0
[line_break_token][line_break_token]I have one concern, however.	Review	B-Review	1
[line_break_token]The authors mention that the training of oblique decision trees is difficult, and the use of the locally constant network is helpful.	Review	I-Review	1
[line_break_token]If I understand correctly, oblique decision tree is one specific instance of the hierarchical mixtures of experts.	Review	I-Review	1
[line_break_token]And, [Ref1] pointed out that the hierarchical mixtures of experts can be trained using EM algorithm, which is another type of the gradient-based training.	Review	I-Review	1
[line_break_token]The current paper misses such a prior study.	Review	I-Review	1
[line_break_token]I am interested in to see if the use of locally constant network is truly effective for training oblique decision trees over the algorithms considered in the literatures of hierarchical mixtures of experts.	Review	I-Review	1
[line_break_token][line_break_token][Ref1] Hierarchical mixtures of experts and the EM algorithm[line_break_token][line_break_token][line_break_token]### Updated after author response ###[line_break_token]The authors have successfully demonstrated that the proposed approach is better than the EM-like classical approaches.	Review	O	0
I therefore keep my score.	Review	O	0
e thank the reviewer for the insightful comments and suggestions.	Reply	O	0
[line_break_token][line_break_token]To clarify the concern, there is a fundamental difference between hierarchical mixtures of experts (HMEs) and oblique decision trees.	Reply	B-Reply	1
HMEs use softmax units instead of decision units in non-terminal nodes, so HMEs only approach oblique decision trees in the theoretical limit.	Reply	I-Reply	1
Hence, HMEs realize continuous functions instead of piece-wise constant functions as oblique decision trees.	Reply	I-Reply	1
[line_break_token][line_break_token]There are some practical advantages of using oblique decision trees over HMEs-style (soft) decision trees.	Reply	I-Reply	1
For example, it requires a full tree traversal for HMEs to make a prediction in O(2^M) where M denotes the tree depth, while it only takes O(M) for oblique decision trees to make a prediction.	Reply	I-Reply	1
Moreover, being piece-wise constant allows us to tractably compute some useful inference problems like ‚Äúwhat is the feasible region of input space that leads to a specific prediction value / diagnosis‚Äù.	Reply	I-Reply	1
[line_break_token][line_break_token]Nevertheless, we can still do an empirical comparison with HMEs.	Reply	I-Reply	1
We use the HME implementation with the most stars on GitHub: <a href="https://github.com/AmazaspShumik/Mixture-Models" target="_blank" rel="nofollow">https://github.com/AmazaspShumik/Mixture-Models</a>[line_break_token][line_break_token]Even with parallel computing on 16 CPUs, the implementation is still prohibitively slow due to the inherent complexity of the HME learning algorithm (exponential to tree depth), and we can only obtain some early results on small datasets.	Reply	O	0
The experiment protocol is the same.	Reply	B-Reply	1
We tune the depth in {2,3,...,12} by validation set, and report the testing performance of the tuned model.	Reply	I-Reply	1
[line_break_token][line_break_token]We report (mean ¬± std) of testing AUC score over multiple runs.	Reply	I-Reply	1
[line_break_token]Bace: [line_break_token]HME (4 runs):    0.706 ¬± 0.009[line_break_token]LCN (10 runs):   0.839 ¬± 0.013[line_break_token]ALCN (10 runs): 0.854 ¬± 0.007[line_break_token][line_break_token]Sider:  [line_break_token]HME (1 run):      0.582 ¬± 0.000[line_break_token]LCN (10 runs):   0.624 ¬± 0.044[line_break_token]ALCN (10 runs): 0.653 ¬± 0.044[line_break_token][line_break_token]Empirically, HME performs much worse than the proposed LCN and ALCN models.	Reply	I-Reply	1
[line_break_token][line_break_token]It takes 4.5 hours to train an HME on the Bace dataset with depth = 12, and it takes 42.3 hours on the HIV dataset with depth = 6, so we cannot report the complete experiments for the other datasets during rebuttal.	Reply	I-Reply	1
To see the exponential time complexity:[line_break_token][line_break_token]HMEs training time on the HIV dataset.	Reply	I-Reply	1
[line_break_token]Depth = 3:   5.0 hours[line_break_token]Depth = 4:  11.1 hours[line_break_token]Depth = 5:  23.7 hours[line_break_token]Depth = 6:  42.3 hours	Reply	I-Reply	1

The paper proposes to use Adversarial Auto Encoders in the context of anomaly/novelty detection.	Review	O	0
They explore the use of different priors, semi-supervised learning and using an anomaly class.	Review	O	0
[line_break_token][line_break_token]Although this is the first occurrence of adversarial auto-encoder used for novelty detection, using auto-encoder based approaches for this application is not novel.	Review	B-Review	1
[line_break_token]The description of the experiments and the model seems clear, except some part like defining the novelty rate when using explicit rejection class.	Review	I-Review	2
Claims like "This might be related to the fact that, whatever the used prior distribution, randomly generated images are distributed according to a normal distribution at the center of the feature space (because of the central limit theorem)" needs to be explained if accurate or relevant.	Review	I-Review	3
[line_break_token]The experimental procedure does not compare to simple baseline like mixture of Gaussians.	Review	I-Review	4
Moreover, apart from visualization purpose, restricting the models to a 2D latent space is not well justified for the purpose of novelty detection.	Review	I-Review	5
Using confusion matrices and precision-recall curves might help understand more what is going on.	Review	I-Review	6
[line_break_token][line_break_token]Although the use of adversarial auto-encoder for anomaly detection might be worth exploring, the experimental procedure needs to be more rigorous in order to draw any conclusion.	Review	I-Review	7
Thank you very much for your feedback and recommendations.	Reply	O	0
Here are a few comments and answers to them:[line_break_token][line_break_token]‚ÄúAlthough this is the first occurrence of adversarial auto-encoder used for novelty detection, using auto-encoder based approaches for this application is not novel.	Reply	O	0
‚Äù[line_break_token]‚Üí You are absolutely right.	Reply	O	0
This is precisely the purpose of the paper: showing how the adversarial training can improve the baseline auto-encoder by enforcing a known prior distribution in the latent space.	Reply	B-Reply	1
And we did show in this preliminary study that it can potentially improve a lot.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]‚ÄúThe description of the experiments and the model seems clear, except some part like defining the novelty rate when using explicit rejection class.	Reply	O	0
‚Äù[line_break_token]‚Üí You are right.	Reply	O	0
We forgot to give that precision in the paper.	Reply	B-Reply	2
The novelty rate is defined according to the proportion of noise images added in the training set.	Reply	I-Reply	2
In our experiments, we used as much noisy images as the initial number of images in the training set (60K images).	Reply	I-Reply	2
So that, in Equation 3, we used p(y=0)=0.5 [line_break_token][line_break_token]‚ÄúClaims like "This might be related to the fact that, whatever the used prior distribution, randomly generated images are distributed according to a normal distribution at the center of the feature space (because of the central limit theorem)" needs to be explained if accurate or relevant.	Reply	O	0
‚Äù [line_break_token]‚Üí Let x be the random input image(s) and f_w(x) the activation function of a neuron in the latent space of the auto-encoder.	Reply	O	0
Since the last layer of the encoder is a linear layer, f_w(x) can be re-written as a sum of random variables (the activation values of the previous layer multiplied by a weight).	Reply	B-Reply	3
As these random variables are obtained through a deterministic function of the i.i.d.	Reply	I-Reply	3
random images x given as input of the network, they are themselves i.i.d.	Reply	I-Reply	3
Consequently the central limit theorem applies and the f_w(x)‚Äôs are independently and approximately normally distributed.	Reply	I-Reply	3
Now, we agree that the notion of ‚Äúcenter of the feature space‚Äù is more discutable.	Reply	I-Reply	3
A way to see it is to consider that the set of the real images of the training set is a specific sampling of the random images distribution.	Reply	I-Reply	3
In that case, the mean of the f_w(x)‚Äôs for the real images of the training set can be considered as an estimator of the mean of the normal distribution.	Reply	I-Reply	3
Consequently, the mean of the normal distribution is approximately equal to the mean of the prior distribution (what we call the center of the feature space).	Reply	I-Reply	3
Note that, empirically, if you plot the features of the random images in the 2D latent space, you observe that phenomenon.	Reply	I-Reply	3
[line_break_token]Since, we don‚Äôt have enough place to discuss that point in the paper, we suggest simply removing the sentence and keep this for a further work.	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúThe experimental procedure does not compare to simple baseline like mixture of Gaussians.	Reply	O	0
‚Äù[line_break_token]‚Üí Our goal was to show how the adversarial training can improve the baseline auto-encoder by enforcing a known prior distribution in the latent space.	Reply	O	0
For a full paper submission (and not a 3 page workshop paper), we would surely have explored other baselines (e.g. GMM but also GAN, VAE, DAE, CAE, etc.).	Reply	B-Reply	4
Our opinion is that a workshop track is well adapted to host preliminary studies contrary to conference tracks for which one can be more exigent in terms of experimental load.	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúMoreover, apart from visualization purpose, restricting the models to a 2D latent space is not well justified for the purpose of novelty detection.	Reply	O	0
‚Äù[line_break_token]‚Üí Sure.	Reply	O	0
Our goal was to gain knowledge on the contribution of adversarial learning over a baseline autoencoder, not to win the performance race.	Reply	B-Reply	5
[line_break_token][line_break_token]‚ÄúUsing accuracy as performance is not fully informative and the choice of thresholding remains arbitrary.	Reply	O	0
Using confusion matrices and precision-recall curves might help understand more what is going on‚Äù[line_break_token]‚Üí Actually, we did not use accuracy but Mean Average Precision (as explained in section ‚ÄúProtocol and settings‚Äù).	Reply	O	0
The term ‚Äúaccuracy‚Äù does even not appear in the paper.	Reply	B-Reply	6
Mean Average Precision does not involve any thresholding and is among the most fully informative metric summarizing the precision-recall curve.	Reply	I-Reply	6
Investigating other metrics or plots would not be possible in a 3 pages paper.	Reply	I-Reply	6

=== Overall comments ===[line_break_token]This paper proposes to generalize approaches to physics-based learning (PBL) by performing network architecture search (NAS) over elements from PBL models found in the literature.	Review	O	0
This entails including physical inputs to the network and the incorporation of new operations to the NAS.	Review	O	0
I think the idea has merit and rather like it.	Review	O	0
However, there are several aspects of the work that could be improved.	Review	O	0
The technical novelty is small, as the extension of the  existing NAS models to handle physical inputs and a few new operators is relatively straightforward.	Review	B-Review	1
The experiments, while well designed, only explore uninteresting toy problems.	Review	I-Review	5
While I appreciate the necessity to explore the methods performance in a more controlled setting, a more impactful testbed would be more convincing.	Review	I-Review	5
Another drawback of the evaluation is the lack of a proper statistical analysis of the results, given the small data and model sizes.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token]=== Relevance &amp; Prior Work ===[line_break_token]+ The related work gives a good summary and categorization of prior work in physics-based learning[line_break_token]+ The problem (physics-based learning) is interesting and relevant to the community[line_break_token][line_break_token][line_break_token]=== Novelty &amp; Approach===[line_break_token]+ application of NAS to physics based learning[line_break_token]+ incorporation of physics solutions as inputs into differentiable NAS[line_break_token]+ creation of physics-informed operation sets to merge physical models into network[line_break_token]- technical steps to merge NAS and PBL are relatively straightforward[line_break_token][line_break_token][line_break_token]=== Evaluation ===[line_break_token]Two representative physical simulations were chosen for evaluation, where elements of the physics model are intentionally omitted,  1) estimating trajectory of a ball in presence of wind and air resistance, and 2) a collision speed simulation where two objects collide, where sliding friction is not accounted for in the physics model.	Review	O	0
[line_break_token][line_break_token]The baselines consist of: a 3-layer MLP (data-driven), a 3-layer MLP with Physical Regularization, a 3-layer MLP with residual connection to the physics prediction, an MLP with two input branches, on for the data and one for the physics predictions (Physical Fusion), and the Embedded Physics model which estimates parameters for the physics modelu using a 3-layer MLP.	Review	O	0
[line_break_token][line_break_token]PhysicsNAS can combine elements of the baseline models, but the total number of nodes is limited to 5.	Review	O	0
[line_break_token][line_break_token]+ Experiments testing the dependence of the model on the numbers of samples and the strength of the physical inconsistencies were conducted.	Review	O	0
In both cases, PhysicsNAS outperformed the best specialized physics models.	Review	O	0
[line_break_token][line_break_token]- The chosen testbed tasks are toy problems.	Review	O	0
While these types of experiments are necessary to understand the performance of the model, it would have been interesting to see PhysicsNAS applied to a more impactful task[line_break_token][line_break_token]- Given the size of the networks and the training data, there is no reason why a more sophisticated statistical analysis of the results wasn‚Äôt performed (confidence intervals, t-test, p-value).	Review	O	0
Similarly, a more complete set of experiments with more sample amounts could be provided with little effort.	Review	B-Review	3
[line_break_token][line_break_token][line_break_token]=== Clarity &amp; Other Comments ===[line_break_token]- ‚Äúprecious nodes‚Äù -&gt; previous nodes[line_break_token]	Review	O	0
hank you for your detailed review.	Reply	O	0
[line_break_token][line_break_token]Q1: Technical steps to merge NAS and PBL are relatively straightforward[line_break_token]A1: This point is detailed in the general reply to all reviewers, where we describe in greater detail the non-obvious adaptations we have made to merge NAS with PBL.	Reply	O	0
In the revision, we have experimentally shown in Figure 13 that these physics-specific adaptations boost the result.	Reply	B-Reply	1
[line_break_token][line_break_token]Q2: More ‚Äúimpactful‚Äù physics tasks instead of projectile motion and collisions[line_break_token]A2: We specifically chose widely known physics tasks like projectile motion and collisions.	Reply	O	0
This allows readers to access our paper and improve the algorithms, without the barrier to entry of knowing specialized physics.	Reply	B-Reply	2
Although widely known, these tasks can also be made very challenging as we show in Fig.	Reply	I-Reply	2
4 by adding model mismatch.	Reply	I-Reply	2
In crux, a kinematic equation with an unknown model mismatch can be a harder physics problem than a differential equation that perfectly describes the system.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: Experiments with more sample amounts.	Reply	O	0
[line_break_token]A3: We have added experiments with more training sample amount (1024).	Reply	O	0
The new results are in the revised version of Fig.14.	Reply	B-Reply	3
We find that when the amount of training data surpasses a certain point (like 512, 1024 in tossing task), the performance of PhysicsNAS is no longer better than the MLP method.	Reply	I-Reply	3
This indicates PhysicsNAS is more preferred in fewer-shot learning, where training data are burdensome to acquire due to extreme environments.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4: Statistical analysis.	Reply	O	0
[line_break_token]A4: We have conducted statistical analysis as a reference.	Reply	O	0
[line_break_token]The results are shown below.	Reply	B-Reply	4
Regarding the P-value, PhysicsNAS performs the best.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]              |Naive Network |Physical Fusion | Embedded Physics |  Residual Physics | PhysicsNAS |[line_break_token][line_break_token]P-value|      0.7637         |     0.9721          |        0.8793              |        0.9688           |    *0.9744       | [line_break_token][line_break_token]* denotes the best.	Reply	I-Reply	4

The authors proposed an end-to-end method (E2Efold) to predict RNA secondary structure.	Review	O	0
The method consists of a Deep Score Network and a Post-Process Network (PPN).	Review	O	0
The two networks are trained jointly.	Review	O	0
The score network is a deep learning model with transformer and convolution layers, and the post-process network is solving a constrained optimization problem with an T-step unrolled algorithm.	Review	O	0
Experimental results demonstrate that the proposed approach outperforms other RNA secondary structure estimation approaches.	Review	O	0
[line_break_token][line_break_token]Overall I found the paper interesting.	Review	O	0
Although the writing can be improved and some important details are missing.	Review	O	0
[line_break_token][line_break_token]Major comments[line_break_token]As the authors point out, several existing approaches for unrolling optimization problems have been proposed.	Review	O	0
It would be helpful to clarify the methodological novelty of the proposed algorithm compared to those.	Review	B-Review	1
[line_break_token][line_break_token][line_break_token]Training details and implementation details are missing; these hinder the reproducibility of the proposed approach.	Review	I-Review	2
The author stated pre-training of the score network, how is the PPN and score network updated during the joint training?	Review	I-Review	2
Does the model always converge?	Review	I-Review	2
The authors vaguely mentioned add additional logistic regression loss to Eq9 for regularization.	Review	I-Review	2
What is a typical number of T?	Review	I-Review	2
How does varying T affect the performance, both in terms of training time (and convergence) and in terms of accuracy/F1?	Review	I-Review	2
[line_break_token][line_break_token]Minor comments[line_break_token]The 29.7% improvement of F1 score overstates the improvements compared to non-learning approaches.. This performance was computed on the dataset (RNAStralign) on which E2Efold was trained.	Review	O	0
A fair comparison, as the authors also stated, is on the independent ArchiveII data.	Review	B-Review	3
On this data, E2Efold has F1 score 0.686 versus 0.638 for CONTRAfold.	Review	I-Review	3
The author should report performance improvement under this line.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]It would be helpful to report performance per RNA category, both for RNAstralign data and ArchiveII data, while the ArchiveII data should still remain independent.	Review	I-Review	4
Different models may have their strengths and weaknesses on different RNA types.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token]It is not obvious to me how the proximal gradient was derived to (3)-(5).	Review	I-Review	5
It would be helpful if the authors show some details in the supplements.	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]Why is there a need to introduce an l_1 penalty term to make A sparse?	Review	I-Review	6
[line_break_token][line_break_token][line_break_token]On which data is Table 6?	Review	I-Review	7
[line_break_token][line_break_token]Typos, etc.	Review	I-Review	8
[line_break_token]The references are not consistently formatted[line_break_token]‚Äústructure a result‚Äù -&gt; ‚Äústructure is a result‚Äù[line_break_token]‚Äúa few hundred.	Review	O	0
‚Äù -&gt; ‚Äúa few hundred base pairs.	Review	O	0
‚Äù[line_break_token]‚Äúobjective measure the‚Äù -&gt; ‚Äúobjective measures the‚Äù[line_break_token]‚Äúsection 5‚Äù -&gt; ‚ÄúSection 5‚Äù (in several places)[line_break_token]In the equation above Equation 2, should it be -\rho||\hat{A}||_{1} instead of plus?	Review	O	0
Otherwise, the ‚Äúmax‚Äù could be made arbitrarily large.	Review	B-Review	8
[line_break_token]	Review	O	0
e thank reviewer 1 for careful reading and constructive suggestions for paper refinement!	Reply	O	0
We separate our response to reviewer 1 into two parts.	Reply	O	0
[line_break_token][line_break_token]The first part of reviewer 1‚Äôs comments is about missed important details.	Reply	O	0
We are sorry for the lack of clarity and thank the reviewer for pointing them out!	Reply	O	0
Now the details are included in the revised paper, and we also explained them below:[line_break_token][line_break_token][line_break_token]***Compare to existing approaches for unrolling optimization problems[line_break_token][line_break_token]We explained the novelty/difference of E2Efold compared to the existing approaches below.	Reply	O	0
They are now included in the main text and appendix A.[line_break_token][line_break_token]First, our view of incorporating constraints to reduce output space and to reduce sample complexity is novel.	Reply	B-Reply	1
Previous works [Belanger et al.,	Reply	I-Reply	1
2017; Pillutla et al.,	Reply	I-Reply	1
2018; Ingraham et al.,	Reply	I-Reply	1
2018]  did not discuss these aspects.	Reply	I-Reply	1
The most related work which also integrates constraints is OptNet [Amos &amp; Kolter, 2017], but it‚Äôs very expensive and can not scale to the RNA problem.	Reply	O	0
Therefore, our proposed approach is a simple and effective one.	Reply	B-Reply	1
[line_break_token][line_break_token]Second, compared to [Andrychowicz et al.,	Reply	I-Reply	1
2016, Chen et al.,	Reply	I-Reply	1
2018; Shrivastava et al.,	Reply	I-Reply	1
2019], our approach has a different purpose of using the unrolled algorithm.	Reply	I-Reply	1
Their goal is to learn a better algorithm, so they commonly make the architecture *more flexible* than the original algorithm for the room of improvement.	Reply	I-Reply	1
However, we aim at enforcing constraints.	Reply	I-Reply	1
To ensure that constraints are nicely incorporated, we keep the original structure of the algorithm and only make the hyperparameters learnable.	Reply	I-Reply	1
[line_break_token][line_break_token]Finally, although all works consider end-to-end training, none of them can directly optimize the F1 score.	Reply	I-Reply	1
We proposed a differentiable loss function to mimic the F1 score/precision/recall, which is effective and also very useful when negative samples are much fewer than positive samples (or the inverse).	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]***Details on the unrolling constant T[line_break_token][line_break_token]For the explanation on the choice/effect of unrolling constant T, please kindly refer to our response to this common question posted above.	Reply	O	0
[line_break_token][line_break_token][line_break_token]***Details on the design of the training process[line_break_token][line_break_token]Now all the training details are included in Appendix C of the revised paper.	Reply	O	0
[line_break_token][line_break_token]Connecting the score network and PPN, the whole network is very deep.	Reply	B-Reply	2
Both the pre-training and the augmented loss are the tricks that we use to speed up and stabilize the training process.	Reply	I-Reply	2
[line_break_token]- Pre-train: Since we expect to be higher if are truly paired, we use the true secondary structure to pre-train the score network to quickly get a fairly good U.[line_break_token]- Augmented loss: During joint training, we use (loss in Eq 9) +(logistic regression loss on) where we set.	Reply	I-Reply	2
The second term is estimated at the *intermediate output*. Although this term is optional, we think it can help stabilize the training of the *very deep* network and also make each gradient step more efficient.	Reply	I-Reply	2
[line_break_token][line_break_token]Besides, we‚Äôve submitted a link to our code through a private comment to reviewers.	Reply	I-Reply	2
We will get this code well-organized and released to the public for others to reproduce all the experimental results	Reply	I-Reply	2

The paper reformulates the model-agnostic meta-learning algorithm (MAML) in terms of inference for parameters of a prior distribution in a hierarchical Bayesian model.	Review	O	0
This provides an interesting and, as far as I can tell, novel view on MAML.	Review	O	0
The paper uses this view to improve the MAML algorithm.	Review	O	0
The writing of the paper is excellent.	Review	O	0
Experimental evalution is well done against a number of recently developed alternative methods in favor of the presented method, except for TCML which has been exluded using a not so convincing argument.	Review	B-Review	1
The overview of the literature is also very well done.	Review	I-Review	1
We thank R2 for feedback.	Reply	B-Reply	1
Regarding R2‚Äôs comment on the exclusion of TCML from the miniImageNet results table: Our detailed discussion with an author of TCML is in the OpenReview comment thread (<a href="https://openreview.net/forum?id=BJ_UL-k0b&noteId=r1aR9l5lG)."	Reply	O	0
target="_blank" rel="nofollow">https://openreview.net/forum?id=BJ_UL-k0b&noteId=r1aR9l5lG).</a> In summary, our contribution is to reinterpret MAML as approximate inference in a hierarchical Bayesian model, rather than to provide an exhaustive empirical comparison over neural network architectures (as the choice of architecture is largely orthogonal to the training loss or algorithm).	Reply	O	0
Furthermore, the majority of other prior few-shot learning methods used the smaller architecture, so we felt that standardizing the architecture would provide a more informative comparison.	Reply	B-Reply	1
Since we were able to obtain a number for SNAIL/TCML using the same architecture, we believe that this adequately rounds out the comparisons	Reply	I-Reply	1

Batch active:[line_break_token]This paper proposes a novel approach to active learning in batches.	Review	O	0
Assuming a neural-network architecture, they compute the gradients of each unlabeled example using the last layer of the network (and assuming the label given by the network) and then choose an appropriately diverse subset of these using the initialization step of kmeans++.	Review	O	0
The authors provide intuitive motivation for this procedure, along with extensive empirical comparisons.	Review	O	0
[line_break_token][line_break_token]Overall I thought the paper was well written and proposed a new practical method for active learning.	Review	O	0
There were a few concerns and places where the paper could be clearer.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
The authors keep emphasizing a connection to k-dpp for the sampling procedure emphasizing diversity.	Review	B-Review	1
They provide a compelling argument for the kmeans++ but in Figure 1 it is unclear why k-DPP is the right comparison point.	Review	I-Review	1
For example, you could imagine building a set cover of the data using balls at various radii and then choosing their centers.	Review	I-Review	1
[line_break_token]2.	Review	O	0
The paper emphasizes choosing samples in a way to eliminate pathological batches.	Review	B-Review	2
Considering this is a main motivation, none of the figures really demonstrate that this is what BADGE is doing compared to the uncertainty sampling-based methods tested against.	Review	I-Review	2
Perhaps the determinant of the gram matrix of the batch could be reported for both algorithms?	Review	I-Review	2
 [line_break_token]3.	Review	O	0
While reading the paper, the set of architectures used was hard to find.	Review	B-Review	3
Maybe I just missed it, but it would be useful to have this information.	Review	I-Review	3
In particular, in Figure 3, there are absolute counts, but I wasn‚Äôt sure how many (D,B,A,L) combinations there were.	Review	I-Review	3
[line_break_token]4.	Review	O	0
Finally, recent work in Computer Vision has shown that uncertainty sampling with ensemble-based methods in active learning tends to work well.	Review	B-Review	4
I understand that it is hard to compare to the myriads of active learning algorithms out there, but they deserve a mention.	Review	I-Review	4
See [1] below.	Review	I-Review	4
[line_break_token][line_break_token]Overall I think this paper is a good empirical effort that I recommend for acceptance.	Review	O	0
[line_break_token][line_break_token][1] Beluch, William H., Tim Genewein, Andreas N√ºrnberger, and Jan M. K√∂hler. "	Review	O	0
The power of ensembles for active learning in image classification."	Review	O	0
In&nbsp;Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.	Review	O	0
9368-9377.	Review	O	0
2018.	Review	O	0
hanks for your review.	Reply	O	0
[line_break_token][line_break_token]1-2.	Reply	O	0
The motivation for using a k-DPP is that it will select a batch of samples that are both high magnitude and diverse.	Reply	B-Reply	1
K-means++ has this property too - in particular, if initialized with a high-magnitude point, proceeding samples are likely to be high-magnitude as well.	Reply	I-Reply	1
We show this phenomenon in Figure 2 of the newly-updated paper, and compare it to another method for clustering data.	Reply	I-Reply	1
We also added appendix figures to appendix F, showing that simple uncertainty sampling can lead to batches with Gram determinant zero.	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	I-Reply	3
We used three architectures (ResNet, VGG, and MLP), seven datasets (MNIST, SVHN, CIFAR-10, and four OpenML datasets), and three different batch sizes (100, 1k, and 10k).	Reply	I-Reply	3
We didn‚Äôt use any convolutional architectures with MNIST or non-image datasets, leading to 33 unique combinations of dataset, batch size, and architecture.	Reply	I-Reply	3
As each (dataset, batch size, architecture) combination only contribute to at least a penalty of 1 in the penalty matrix, the largest entry in the penalty matrix is at most 33.	Reply	I-Reply	3
We made that clear in the newly-updated copy.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
Thank you for pointing out this article.	Reply	B-Reply	4
We‚Äôve added it to the related work section.	Reply	I-Reply	4

Summary: In this paper, an unbiased estimator for expectations over discrete random variables is developed based on a sampling-without-replacement strategy.	Review	O	0
The proposed estimator is shown to be a Rao-Blackwellization of three existing unbiased estimators with guaranteed reduction in estimation variance.	Review	O	0
The connections of the method to other gradient estimators are discussed.	Review	O	0
Experimental results on several toy and real-data DL/RL problems are reported to demonstrate the applicability of the proposed estimators in the practice of machine learning.	Review	O	0
[line_break_token][line_break_token]Strong points:[line_break_token][line_break_token]-S1.	Review	O	0
The addressed topic is interesting and timely in deep/reinforcement learning.	Review	O	0
[line_break_token][line_break_token]-S2.	Review	O	0
The numerical results show some promise of the proposed estimator in reducing the gradient estimation variance in practice.	Review	O	0
 [line_break_token][line_break_token]Weak points:[line_break_token][line_break_token]-W1.	Review	O	0
A formal and detailed problem statement is missing.	Review	B-Review	1
The paper quickly jumps from a high-level problem setup description in the introduction section into some technical details in the preliminary &amp; methodology sections, without any formal definition of the so called unordered set policy gradient estimation problem provided.	Review	O	0
What is the input/output of the estimator?	Review	B-Review	1
Why this problem is important and challenging?	Review	I-Review	1
It will be better to provide one or two concrete examples such as those studied in the experiments to give a more complete picture of the problem in study.	Review	I-Review	1
[line_break_token][line_break_token]-W2.	Review	O	0
The motivation of study is not clearly elaborated.	Review	B-Review	2
There are several existing options to reduce the gradient estimation variance via Rao-Blackwellization [see, e.g., Liu et al.	Review	I-Review	2
2019]. In which regimes the current method is more preferable than those prior ones and why?	Review	I-Review	2
The justification of using the without-replacement-sampling strategy so far remains largely unconvincing.	Review	I-Review	2
[line_break_token][line_break_token]-W3.	Review	O	0
The overall novelty of theory is limited.	Review	B-Review	3
It makes sense that gradient estimators based a mini-batch of sample under without-replacement-sampling should tend to have smaller variance than the single-sample stochastic gradient estimation.	Review	I-Review	3
Although a guarantee of variance reduction from the perspective of Rao-Blackwellization looks promising, the proof technique is fairly standard and more importantly, the quantification of such a variance reduction remains largely unaddressed.	Review	I-Review	3
Therefore, the overall degree of novelty in theory is still relatively low.	Review	I-Review	3
[line_break_token][line_break_token]-W4.	Review	O	0
The paper presentation quality can be improved.	Review	B-Review	4
As another consequence of the above mentioned issues with problem statement and motivation, I found the paper a bit hard to follow smoothly.	Review	I-Review	4
Particularly, too much space is spent on presenting the technical details while the principles/intuitions behind these fancy mathematical treatments are lacking in explanation.	Review	I-Review	4
There are three theorems established in the paper, but none of them come up with sufficient discussions on the main messages conveyed by these results.	Review	I-Review	4
[line_break_token][line_break_token]=== update after author response ===[line_break_token][line_break_token]Thank you for your response.	Review	O	0
I find my concerns on motivation and presentation properly addressed in the feedback and the revised paper as well.	Review	O	0
 Concerning the strength of theory, however, I am still not convinced that the current analysis is strong enough to thoroughly justify the benefit of the proposed estimator.	Review	O	0
All in all, the paper is substantially improved in presentation and the proposed gradient estimator seems to be a novel and more attractive alternative to the existing ones in a number of popular DL/RL applications.	Review	O	0
I thus would like to increase the rating to weak accept.	Review	O	0
[line_break_token]	Review	O	0
hank you for your time reviewing our paper and for the feedback!	Reply	O	0
We have used it to update the paper.	Reply	O	0
Please see our detailed reply below:[line_break_token][line_break_token]- W1 problem statement[line_break_token]The problem is gradient estimation of functions over distributions involving discrete variables.	Reply	O	0
This is the same problem that is addressed by the popular Gumbel-Softmax estimator.	Reply	B-Reply	1
Instead of being based on continuous relaxations, which is biased and does not work well in high-dimensional settings, we use the idea of using multiple samples.	Reply	I-Reply	1
By sampling without replacement, we reduce variance compared to sampling with replacement.	Reply	I-Reply	1
We have improved the introduction to give a better problem description and motivation.	Reply	I-Reply	1
[line_break_token][line_break_token]- W2 motivation[line_break_token]The estimator by Liu et al. (	Reply	O	0
2019) only works in low-entropy regimes when significant probability mass is concentrated on just a few categories.	Reply	B-Reply	2
Our estimator has the same effect in the low-entropy regime, but is superior in the high entropy regime, in which case it ties with VIMCO which does not work well in the low-entropy regime (because of the with-replacement sampling strategy).	Reply	I-Reply	2
In Figure 4, our estimator outperforms both VIMCO and Liu et al. (	Reply	I-Reply	2
2019) (sum &amp; sample).	Reply	O	0
[line_break_token][line_break_token]- W3 novelty of theory[line_break_token]To the best of our knowledge, a practical, unbiased estimator under weighted sampling without replacement does not currently exist in the literature (the importance-weighted estimator has high variance).	Reply	O	0
Our contribution is to derive such an estimator, and to connect it theoretically to three different estimators using Rao-Blackwellization, motivating its improvement.	Reply	B-Reply	3
Additionally, we show how to include a built-in baseline while remaining unbiased, which is the key to making the estimator usable for gradient estimation (therefore an alternative to e.g. Gumbel-Softmax), but non-trivial since samples are dependent while baselines should be independent.	Reply	I-Reply	3
We do show reduced variance in our experiments, although indeed it would be interesting to analyze the variance reduction analytically.	Reply	I-Reply	3
[line_break_token][line_break_token]- W4 paper presentation[line_break_token]We may have compromised a bit on this aspect indeed.	Reply	O	0
We have improved the readability of the paper by adding explanations on the implications of the theorems.	Reply	B-Reply	4

* Summary[line_break_token][line_break_token]The authors focus on the problem of uncertainty propagation DNN.	Review	O	0
The authors claim two main contributions: they revisit the assumptions of the feed forward method (proposed by several authors as an inference method for BNNs based on ADF/EP) and proposed a new approximation for argmax/max based functions that allows to propagated the first two moments analytically.	Review	O	0
[line_break_token][line_break_token]* Comments:[line_break_token][line_break_token]The authors claim two main contributions: an analysis for the feed forward method (sections 2 and 3) previously proposed by several authors as an inference method for BNN based on ADF/EP, and a new method to propagate the uncertainty through argmax/max based operations (section 4).	Review	O	0
[line_break_token][line_break_token]Regarding the first contribution, I was expecting some new insights about the method that I did not find.	Review	B-Review	2
I would suggest to focus on the second contribution and refactor this section as a background section.	Review	I-Review	2
I would make it shorter, focusing on the representation of probabilities as latent variables trough a function, which is the important bit to understand the real contribution of the paper described in section 4.	Review	I-Review	2
I would also remove some examples that do not seem critical to understand the rest of the paper and just increase its length.	Review	I-Review	2
[line_break_token][line_break_token]The second contribution is quite novel.	Review	I-Review	3
The authors propose a new approximation of argmax/max operations.	Review	I-Review	3
The firstly proposed an approximation for argmax operations, e.g. latent variable view of the softmax, that avoids resorting to the normal cdf function that has numerical stability issues.	Review	I-Review	3
Secondly, they suggest an approximation for max based operations, e.g. leaky relu, that again, does not depend on the gaussian cdf.	Review	I-Review	3
[line_break_token][line_break_token]In the experimental section, the authors test:[line_break_token]a)[tab_token]The accuracy of the proposed method approximating the posterior of the neurons[line_break_token]b)[tab_token]End-to-end training benefits[line_break_token][line_break_token]In a) they use MC to collect the ground truth statistics and compare the proposed method (AP2) with a classical NN (AP1).	Review	I-Review	4
The analysis is nice but I miss a comparison with other state-of-the-art methods.	Review	I-Review	4
In particular, the authors claim that the novelty of their method compared to other feed-forward methods is that they can propagate the uncertainty through argmax/max operations analytically.	Review	I-Review	4
They do not compare with these other feed forwards methods to show the benefit of this.	Review	I-Review	4
 This is shown in the end-to-end training experiments; however, I would like to see a direct comparison with the classical paper (Hern¬¥andez-Lobato & Adams, 2015).	Review	O	0
Finally, one of the justifications of the approximations that they propose is to avoid the numerical issues of the standard cdf.	Review	B-Review	4
Have the authors compared with this, e.g. eq 18a, 18b?	Review	I-Review	4
Using a robust implementation of the normal cdf/pdf function and further truncating them to avoid negative variances?	Review	I-Review	4
[line_break_token][line_break_token]typo: Shortly before eq.	Review	I-Review	5
12, Should not S_{n-1} be defined as the softmax operation?	Review	I-Review	5
[line_break_token]	Review	O	0
‚ÄúContribution 1: new insights about the method?‚Äù[line_break_token]We mean: 1) a clear self-contained derivation, 2) the latent variable view of sigmoid that later extends to softmax, 3) the connection to standard NNs, 4) possibility to choose the approximating family at each layer in order to simplify the propagation.	Reply	O	0
We believe this is useful and may help understanding by non-experts.	Reply	B-Reply	2
Note that the frequently cited ADF is an incremental method for parameter estimation.	Reply	I-Reply	2
Only example 3 (ReLU) is not directly used in the subsequent constructions.	Reply	I-Reply	2
Do you definitely recommend to shorten this part?	Reply	I-Reply	2
The numerical evaluation of accuracy has not been reported before with such methods.	Reply	I-Reply	2
[line_break_token][line_break_token]‚ÄúContribution 2: an approximation for argmax operations that avoids resorting to the normal cdf function that has numerical stability issues‚Äù[line_break_token]There is likely to be a misunderstanding.	Reply	O	0
The challenge of argmax is that it is a multivariate nonlinear function.	Reply	B-Reply	3
There were no previously proposed analytic approximations using the normal cdf or not.	Reply	I-Reply	3
Furthermore, evaluating the multivariate normal cdf is a hard computational problem.	Reply	I-Reply	3
[line_break_token][line_break_token]To support the utility of the results, let us mention one more paper we discovered that achieved improvements in speech recognition with the uncertainty propagation but explicitly mentions that the approximation for softmax was an unsolved problem and a significant limitation:[line_break_token]Astudillo et al. (	Reply	I-Reply	3
2014) ‚ÄúACCOUNTING FOR THE RESIDUAL UNCERTAINTY OF MULTI-LAYER PERCEPTRON BASED FEATURES‚Äù[line_break_token][line_break_token]‚ÄúA direct comparison with the classical paper (Hern¬¥andez-Lobato & Adams, 2015)‚Äù[line_break_token]This work performs Bayesian learning, which we don‚Äôt do.	Reply	O	0
Our work is related to the paragraph ‚ÄúIncorporating the likelihood factors‚Äù.	Reply	B-Reply	4
They describe the case of ReLU with a numerical fix.	Reply	I-Reply	4
Do you mean specifically comparing this approximation alone against ours?	Reply	I-Reply	4
We do not see any other direct comparison applicable.	Reply	I-Reply	4
The softmax is not considered there (they consider regression problems with fully connected 1-4 layers).	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúComparison with a robust implementation of the normal cdf/pdf‚Äù[line_break_token]According to our experiments, the bottleneck in the accuracy is currently due to the independence assumption.	Reply	O	0
More accurate calculation of the variance as in (Hern¬¥andez-Lobato & Adams, 2015) is possible, but is more computationally costly.	Reply	O	0
Truncation in order to force non-negativity of variance is particularly undesirable.	Reply	B-Reply	4
Because the accumulated scaling in a deep network can lead to all activations being either large or small, a valid asymptotic behaviour is required.	Reply	I-Reply	4
This is particularly important for normalization (Fig.	Reply	I-Reply	4
B1).	Reply	I-Reply	4
We propose that in the context of NNs cheaper approximations with valid asymptotes are more practical.	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúShould not S_{n-1} be defined as the softmax operation‚Äù[line_break_token]We quote the definition by Malik and Abraham.	Reply	O	0
There is indeed relation S_{n-1}(u)  = softmax(0, u_1, ‚Ä¶ u_{n-1}).	Reply	B-Reply	5
Think of the case with two variables X_1, X_2: we have U_1 =X_1 - X_2  and S_{1}(u) = sigmoid(u)	Reply	I-Reply	5

This paper proposes a new step size adaptation in first-order gradient methods.	Review	O	0
The proposed method establishes a new optimization problem with the first-order expansion of loss function and the regularization, where the step size is treated as a variable.	Review	O	0
 ADMM is adopted to solve the optimization problem.	Review	O	0
[line_break_token][line_break_token]This paper should be rejected because (1) the proposed method does not show the convergence rate improvement of the gradient method with other step sizes adaptation methods. (	Review	O	0
2) the linearization of the objective function leads the step size to be small ), which could slow down the convergence in some cases. (	Review	O	0
3) the experiments generally do not support a significant contribution.	Review	O	0
In table 1, the results of the competitor are not with the optimal step sizes.	Review	B-Review	2
The limit grid search range could not verify the empirical superiority of the proposed method.	Review	I-Review	2
[line_break_token][line_break_token][line_break_token]Minor comments:[line_break_token]The y-axis label of (a) panel in each figure is wrong.	Review	O	0
I guess it should be "Training loss ".	Review	B-Review	3
(1, 2) We don't know what you're pointing out.	Reply	O	0
SSO always showed faster convergence speed than RMSProp and Adam.	Reply	B-Reply	1
In addition, SSO consistently showed the performance improvement with relatively large initial learning rate (e.g., 0.5).	Reply	I-Reply	1
Note that RMSProp and Adam commonly use very small initial learning rate (e.g., 0.001`).	Reply	I-Reply	1
Thus, your comments are incorrect.	Reply	I-Reply	1
Furthermore, SSO showed comparable convergence speed with L4-Adam and AdaBound while improving the generalization significantly.	Reply	I-Reply	1
[line_break_token][line_break_token](3) We tuned hyperparameters of the competitors with the grid search and achieved the experimental results similar to other papers and GitHub repositories on CNN and ResNet-18.	Reply	O	0
Especially, for L4-Adam and AdaBound, we used the best hyperparameters suggested in their original papers.	Reply	B-Reply	2
[line_break_token][line_break_token]You should provide clearer and more understandable review	Reply	O	0

A recent paper by Lu et al introduced delusional bias in Q-learning, an error due to the max in the Bellman backup not being consistent with the policy representation implied by the greedy operator applied to the approximated value function.	Review	O	0
That work proposed a consistent algorithm for small and finite state spaces, which essentially enumerates over realizable policies.	Review	O	0
This paper proposes an algorithm for overcoming delusional bias in large state spaces.	Review	O	0
The idea is to add to the Q-learning objective a smooth penalty term that induces approximate consistency, and search over possible Q-function approximators.	Review	O	0
Several heuristic methods are proposed for this search, and results are demonstrated in Atari domains.	Review	O	0
[line_break_token][line_break_token]I found the topic of the paper very interesting - delusional bias is an intriguing aspect of Q learning, and the approach of Lu et al is severely limited to discrete and small state spaces.	Review	O	0
Thus, tackling the large state space problem is worthy and definitely not trivial.	Review	O	0
[line_break_token][line_break_token]The authors‚Äô proposed solution of combining a smooth penalty for approximate consistency and search over regressors makes sense.	Review	B-Review	6
The implementation of the search (Sec 3.4) is not trivial, and builds on a number of heuristics, but given the difficulty of the problem, I expect that the first proposed solution will not be straightforward.	Review	I-Review	6
[line_break_token][line_break_token]I am, however, concerned with the evaluation of the method and its practicality, as reflected by the following issues: [line_break_token]1.	Review	O	0
The method has many hyper parameters.	Review	B-Review	1
The most salient one, \lambda, the penalty coefficient, is changed between 0.25 to 2 on the consistency penalty experiment, and between 1 to 1000 in the full ConQUR experiments.	Review	I-Review	1
I did not understand the order of magnitude change between the experiments, and more importantly, how can one know a reasonable \lambda, and an annealing schedule for it in advance.	Review	I-Review	1
[line_break_token]2.	Review	O	0
I do not understand the statistical significance of the results.	Review	B-Review	2
For example, with the constant \lambda=0.5, the authors report beating the baseline in 11 out of 19 games.	Review	I-Review	2
That‚Äôs probably not statistically significant enough to claim improvement.	Review	I-Review	2
Also, only one run is performed for each game; adding more runs might make the results clearer.	Review	I-Review	2
[line_break_token]3.	Review	I-Review	6
The claim that with the best \lambda for each game, the method outperforms the baseline in 16 out 19 games seems more significant, but testing an optimal hyper parameter for each game is not fair.	Review	I-Review	3
Statistically speaking, *even if the parameter \lambda was set to a constant zero* for the 5 runs that the method is tested on, and the best performing run was taken for evaluation against the baseline, that would have given a strong advantage to the proposed method over the baseline‚Ä¶.[line_break_token]4.	Review	O	0
For the full ConQUR, there are many more hyper parameters, which I did not understand the intuition how to choose.	Review	B-Review	4
Again, I do not understand how the results establish any statistically significant claim.	Review	I-Review	4
For example, what does: ‚ÄúCONQUR wins by at least a 10% margin in 20 games, while 22 games see improvements of 1‚Äì10% and 8 games show little effect (plus/minus 1%) and 7 games show a decline of greater than 1% (most are 1‚Äì6% with the exception of Centipede at -12% and IceHockey at -86%)‚Äù mean?	Review	I-Review	4
How can I understand from this that ConQUR is really better?	Review	I-Review	4
Establishing a clearer evaluation metric, and using well-accepted statistical tests would greatly help the paper.	Review	I-Review	4
At the minimum, add error bars to the figures!	Review	I-Review	4
[line_break_token]5.	Review	O	0
While evaluating on Atari shows applicability to large state spaces, it is hard to understand from it whether the (claimed) advantage of the method is due to the delusional bias effect, or some other factor (like implicit regularization due to the penalty term in the loss).	Review	B-Review	5
In addition, it is hard to understand the different approximations in the method.	Review	I-Review	5
For example, how does the proposed consistency penalty approximate the true consistency?	Review	I-Review	5
These could all be evaluated on the simple MDP example of Lu et al.	Review	I-Review	5
I strongly advise the authors to add such an evaluation, which is easy to implement, and will show exactly how the approximations in the approach deal with delusional bias.	Review	I-Review	5
It will also be easier to demonstrate the effects of the different hyper parameters in a toy domain.	Review	I-Review	5
hank you for the constructive feedback and for the detailed questions regarding our experiments.	Reply	O	0
Some brief responses to each of your numbered points in turn.	Reply	O	0
[line_break_token][line_break_token]1. [	Reply	O	0
WHY ORDER OF MAGNITUDE CHANGE] The key difference between (1) the consistency-penalty experiment and (2) the full ConQUR experiments is that the former maintains a single Q-regressor, while the latter maintains multiple Q-regressors.	Reply	O	0
Thus in setting (1), if one makes strong policy commitments early in training, they cannot be undone (there is no search or ‚Äúbacktracking‚Äù).	Reply	B-Reply	1
In such a case, we want to be less stringent in enforcing policy commitments.	Reply	I-Reply	1
In setting (2), we can be more aggressive in enforcing policy commitments, since if they induce poor performance, alternative hypotheses are in play. (	Reply	I-Reply	1
In principle, with ‚Äúexhaustive‚Äù search, per Lu et al.	Reply	I-Reply	1
2018, this will find the optimal policy-consistent value function.)	Reply	I-Reply	1
Nevertheless, Fig.	Reply	I-Reply	1
11 on p. 20 (Appendix D.3) shows lambda=1, 10 performs the best (or comparably).	Reply	I-Reply	1
Larger lambdas are not necessary.	Reply	I-Reply	1
[line_break_token][line_break_token][SELECTING LAMBDA] Selecting a reasonable fixed lambda is similar to selecting regularization parameters in supervised learning‚Äî-cross-validation or other approaches may be used.	Reply	O	0
[line_break_token][line_break_token]Annealing: lambda is gradually increased from 0 to the final value since we do not wish to over-constrain the Q-regressor with potentially bad policy commitments near the start of training.	Reply	B-Reply	1
We chose a simple schedule: lambda = final_value * step / (step + 200k), which reaches half of the final value at step 200k.	Reply	I-Reply	1
We will elaborate on this in the paper.	Reply	I-Reply	1
Other ways of tuning are of course possible.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
We agree with this point and will make revisions accordingly.	Reply	B-Reply	2
We will update our figures in the revised paper to include the mean score over reruns (most games are re-run with 3-5 random trials) and error bars of the 95% confidence interval. (	Reply	I-Reply	2
An updated version of the main figures can be seen here: <a href="https://tinyurl.com/ryzyhrr" target="_blank" rel="nofollow">https://tinyurl.com/ryzyhrr</a> ).	Reply	O	0
Our conclusions about ConQUR are not impacted by this:[line_break_token][line_break_token]DQN(lambda = 0.5): 10 wins, 3 losses, 6 inconclusive (see dqn_reg_0_5.pdf)[line_break_token]DDQN(lambda = 0.5): 9 wins, 2 losses, 8 inconclusive (see ddqn_reg_0_5.pdf)[line_break_token][line_break_token]This suggests using a single soft-penalty constant generally does not hurt performance and can improve over baseline in a non-trivial fraction of the Atari environments.	Reply	B-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
As discussed in Question 2 above, lambda=0.5 works well across all tested games even without taking the max over runs).	Reply	B-Reply	3
In general, Q-learning (with or without a consistency penalty) behaves differently in different environments, thus games will have their own optimal penalty constants.	Reply	I-Reply	3
Practitioners often select good hyperparameters for their particular task/game (see above comment on selecting hyperparameters), and this is often seen in the literature.	Reply	I-Reply	3
That said, we will make clearer the role/value of using just a single, fixed lambda.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
As above, we agree with this general point on statistical significance (we discuss details below on how we address this).	Reply	O	0
[line_break_token][line_break_token][HYPERPARAMETER TUNING] The full set of ConQUR hyperparameters (fixed across all games) is shown in Table 6, Appendix D. There are 7 additional hyperparameters beyond those used in standard DQN hyperparameters (e.g. eps_train, discount factor, etc.,	Reply	O	0
which we match to standard values used in DQN implementations in the Atari RL literature).	Reply	B-Reply	4
Five of the seven hyperparameters relate to easy-to-understand search tree parameters, including branching factor, etc.	Reply	I-Reply	4
The two remaining hyperparameters (Boltzmann iteration, training calibration parameter for scoring function) will need additional insight and potential tuning (e.g., see our discussion in response to review 2 regarding parameter lambda), but should not be more cumbersome to tune than other deep learning architectures.	Reply	I-Reply	4
Due to GPU resource limitations, we did not explore the full range of hyperparameter combinations.	Reply	I-Reply	4
[line_break_token][line_break_token][DESCRIPTION OF RESULTS] First, one brief clarification: the statements such as ‚ÄúConQUR wins by a 10% margin‚Ä¶‚Äù are not intended to be statistical claims, rather they are descriptions of the larger table of results from the appendix.	Reply	O	0
Per the point raised by reviewer 1, we will attempt to get the full table of results into the main text so some of this descriptive text can be condensed.	Reply	B-Reply	4
[line_break_token][line_break_token][EVALUATION METRICS] Our evaluation metric (game score) is the standard for Atari RL benchmarks.	Reply	O	0
We agree with your point about statistical validity of our conclusions.	Reply	B-Reply	4
We have results evaluated using 5 random seeds per game, and will include the results in the revised paper (3 to 5 random seeds is standard across Atari RL papers.)	Reply	I-Reply	4
The 5-seed results, showing mean and 95% confidence intervals can be seen at: <a href="https://tinyurl.com/yz5xy5ox" target="_blank" rel="nofollow">https://tinyurl.com/yz5xy5ox</a> .	Reply	O	0
We were unable to run on multiple seeds prior to submission due to limited GPU resources, our apologies for that	Reply	B-Reply	4

The paper proposes to use the very standard SVGB in a sequential setting like several previous works did.	Review	O	0
However, they proposes to have a clear state space constraints similar to Linear Gaussian Models: Markovian latent space and conditional independence of observed variables given the latent variables.	Review	O	0
However the model is in this case non-linear.	Review	B-Review	1
These assumptions are well motivated by the goal of having meaningful latent variables.	Review	I-Review	1
[line_break_token]The experiments are interesting but I'm still not completely convinced by the regression results in Figure 3, namely that one could obtain the angle and velocity from the state but using a function more powerful than a linear function.	Review	I-Review	2
Also, why isn't the model from (Watter et al.,	Review	I-Review	2
2015) not included ?	Review	I-Review	2
[line_break_token]After rereading I'm not sure I understand why the coordinates should be combined in a 3x3 checkerboard as said in Figure 5a.	Review	I-Review	3
[line_break_token]Then paper is well motivated and the resulting model is novel enough, the bouncing ball experiment is not quite convincing, especially in prediction, as the problem is fully determined by its initial velocity and position.	Review	I-Review	3
Thank you very much for your feedback.	Reply	O	0
[line_break_token][line_break_token]We would like to address several points raised in your review:[line_break_token]- Linear Regression: As footnote 3 indicates, we did test nonlinear regression via neural networks from inferred latent states to ground truth latents.	Reply	O	0
The result was the same: Angle reconstruction works for both, velocity reconstruction only for DVBF.	Reply	B-Reply	1
[line_break_token]We chose linear regression because a) it allows for looking at and reporting measures such as goodness of fit in a way neural networks cannot, and b) the fact that a simple linear regression allows for perfect recovery indicates the strength of the latent embedding found by DVBF.	Reply	I-Reply	1
[line_break_token][line_break_token]- E2C (Watter et al.,	Reply	O	0
2015): E2C crucially depends on the user stacking data such that all temporal information is present in one sample.	Reply	O	0
While technically working on raw pixels, this enhancement of data significantly simplifies finding temporal derivatives.	Reply	B-Reply	2
E2C requires a qualitatively different data set to work on, to the extent that E2C cannot serve as a fair baseline.	Reply	I-Reply	2
[line_break_token]As stated in our paper, the E2C objective function is not rigorously implemented within the SGVB framework.	Reply	I-Reply	2
It averages two loosely connected lower bounds and adds another KL term with the sole purpose of regularizing the transition.	Reply	I-Reply	2
For DVBF the transition is a natural part of the lower bound, which fixes this theoretical flaw.	Reply	I-Reply	2
[line_break_token]E2C works on data that uniformly samples control *and* state space.	Reply	I-Reply	2
This assumption is very strong in itself.	Reply	I-Reply	2
Moreover, such data acquisition is virtually impossible for any real application as it would require a priori insight into the control of the system.	Reply	I-Reply	2
It has not been shown that E2C works in a more realistic data regime, while DVBF does.	Reply	I-Reply	2
[line_break_token][line_break_token]- Bouncing Ball/Checkerboard: Firstly, please note that there are random control inputs present, so that the trajectory is not fully determined by the initial state.	Reply	O	0
Moreover, there is noise present in the simulator.	Reply	B-Reply	3
Apart from that, our algorithm relies on the system being deterministic up to process noise and given control inputs, and identify the underlying system.	Reply	I-Reply	3
Bouncing Ball is no more or less random than most control problems in, e.g., OpenAI Gym.	Reply	I-Reply	3
[line_break_token]Secondly, the checkerboard is quite a remarkable result.	Reply	I-Reply	3
It is designed to show how well DVBF reconstructs the unknown ground truth: The ground truth position of the ball lies within the 2D unit square, the bounding box.	Reply	I-Reply	3
Again, we wanted to visualize how ground truth reappears in the learned latent states.	Reply	I-Reply	3
To do so, we wanted to show how the ground truth bounding box is warped into the latent space.	Reply	I-Reply	3
To this end, we partitioned (discretized) the ground truth unit square into a regular 3x3 checkerboard with respective coloring.	Reply	I-Reply	3
Remarkably, there is almost no warping present!	Reply	I-Reply	3
That means that DVBF not only learned to extract the 2D position from the 256 pixels, but also aligned them in two dimensions of the latent space almost exactly as they do in the physical system.	Reply	I-Reply	3
The algorithm does the exact same pixel-to-2D inference that a human observer automatically does when we looking at the image---which is why at first glance it seems this would be an easy task, which it isn‚Äôt.	Reply	I-Reply	3

[line_break_token]######### Rebuttal Response:[line_break_token]Thanks for the clarifications and especially for updating the formatting.	Review	O	0
The current state does not convince me to rate the paper as weak accept but I increased my rating to weak reject.	Review	O	0
[line_break_token][line_break_token]"Pereira et.	Review	O	0
al.	Review	B-Review	4
has shown that a recurrent network architecture using LSTM outperforms the fully connected networks at every time step proposed by Han et.	Review	O	0
al.	Review	B-Review	4
in task completion, space and time complexity.	Review	O	0
Therefore, in this paper we choose to use an LSTM-based network architecture."	Review	O	0
[line_break_token][line_break_token]-&gt; Yes it might be true that a recurrent function approximator does in practice perform better than a feed-forward function approximator.	Review	O	0
However, in theory a feed-forward network should be sufficient as the value function does not depend on the previous states.	Review	B-Review	4
Therefore, the question is, why does the LSTM perform better?	Review	I-Review	4
Does the recurrent nature of the LSTM make the predictions smoother compared to a feed-forward network?	Review	I-Review	4
 Can any other regularizing scheme be introduced s.t.	Review	I-Review	4
the feed-forward networks performs equally well?	Review	I-Review	4
[line_break_token][line_break_token]######### Review:[line_break_token][line_break_token]Summary: [line_break_token]The paper builds on the work of Pereira et.	Review	O	0
al.	Review	B-Review	4
and uses forward backward stochastic differential equations to learn the Hessian of the Value function Vxx and \partial _t V_x + 1/2 tr(\partial_{xx} V_x CC^T).	Review	O	0
In contrast to the prior work, this paper introduces multiplicative noise for the control and uses second order optimization.	Review	O	0
The performance is evaluated on different control tasks, e.g., linear system, cartpole, quadcopter &amp; human arm actuated by tendons.	Review	O	0
[line_break_token][line_break_token]Conclusion: [line_break_token]All in all, I like the proposed research of combining theoretical approaches and deep learning to perform trajectory optimization and I would like to see much more of this research like this within the ICLR community.	Review	O	0
Furthermore, I think that the paper has a contribution and that the paper was improved compared to the initial Neurips submission (i.e., adding ILQG as baseline).	Review	O	0
However, the writeup and formatting is still very much sub-standard and must be improved to make this paper worth publishing.	Review	B-Review	5
The current write-up is not accessible for the ICLR community and the understandability must be significantly improved (Details are provided below).	Review	I-Review	5
Therefore, I currently rate this paper as a clear rejection but I am happy to improve the score to 7-8 if the write up is improved during the rebuttal.	Review	O	0
[line_break_token][line_break_token][line_break_token]Theoretical Structure: [line_break_token]I like the introduction, which covers the topic but might be a bit too long.	Review	O	0
Maybe you want to shorten the introduction and add an additional related work section at the end.	Review	B-Review	4
The stochastic control introduction is nice and has the correct level of abstraction for the reader.	Review	I-Review	4
However, the paper introduces many complex concepts which are not essential for understanding the paper (e.g., filtered probability space etc.).	Review	I-Review	4
One might want to trade off understandability vs. mathematical rigor especially, if the paper does not rely on these concepts.	Review	I-Review	4
Furthermore, you might want to make eq 1 more explicit as the multiplicative action noise is not visible from eq 1.	Review	I-Review	4
Section 3 'A FBSDE Solution to the HJB PDE' is the most problematic section of this paper, which is not understandable for the common ICLR reader.	Review	I-Review	4
Eq.	Review	I-Review	4
6, which just appears without any derivation, is not understandable and the reader has no intuition how to derive this eq.	Review	I-Review	4
Furthermore, Eq 6 (page.	Review	I-Review	4
4) uses notations which is only clearly introduced later within the paper or even the appendix (e.g., Y being the propagated value function, Z being the propagated gradient of the value function is only mentioned in the appendix, i.e., page 12.	Review	I-Review	4
\Gamma is only introduced in page 5.	Review	I-Review	4
Yes, Eq.	Review	I-Review	4
7 defines these variables but the style of definition is not standard and one does not expect the variables to be defined in this style.).	Review	I-Review	4
Could the authors please provide an intuitive derivation of these equation and use clearer notation (Why would one want to abstract V, V_x, V_x, \mathcal|{H}(V_x) in the first place as these are intuitive for the ICLR community and sufficiently short?)	Review	I-Review	4
Especially, as this section highlights the difference to the prior works of Pereira et.	Review	I-Review	4
al.,	Review	I-Review	4
this section should be very clear.	Review	I-Review	4
Section 4 is clear but should include the loss function as the loss is not trivial and essential for the optimization.	Review	I-Review	4
Currently, the loss description is buried in the appendix.	Review	I-Review	4
All in all, the theoretical explanation and the bloated notation should be simplified and every equation should be embedded into an intuitive derivation.	Review	I-Review	4
Currently these explanations are not understandable without reading the appendix and prior work.	Review	I-Review	4
 [line_break_token][line_break_token][line_break_token]Experiments:[line_break_token]The experiments apply 2FBSDE to 4 different control tasks (Linear system, quadcopter, cartpole &amp; human arm) and compare the performance to the prior work of FBSDE and iLQG.	Review	O	0
The number of baselines and systems is sufficient.	Review	B-Review	1
However, the paper should provide more evaluations:[line_break_token][line_break_token](1) Plot the histogram of the obtained cost distributions.	Review	I-Review	1
[line_break_token](2) Plot a single state- and action trajectory (and the action distribution).	Review	I-Review	1
Using these plots, the level of noise and smoothness and hence the applicability to physical systems can be evaluated.	Review	I-Review	1
[line_break_token](3) Plot the noise free trajectories and show that these mean trajectories reach the desired solution.	Review	I-Review	1
[line_break_token](4) Specify the exact cost function for every experiment[line_break_token][line_break_token]Further Comments to the individual experiments: [line_break_token][line_break_token]Cartpole:[line_break_token]The Cartpole iLQG seems to perform much better (swing-up the pendulum faster, don't deviate so much from x=0, much more coherent velocity compared to 2FBSDE, FBSDE).	Review	O	0
Could the authors please discuss these aspects in more detail and present experiments with longer time-horizons to check whether the proposed method can stabilize the cart at [0, 0, 0, 0]. The current plots don't reach this target state.	Review	B-Review	2
Your plots also hint that the cartpole does not need to pre-swing the pendulum, which is most likely due to the very low action cost.	Review	I-Review	2
This selection of action cost significantly simplifies the problem.	Review	I-Review	2
Could the authors please include a cartpole with higher action cost and show that 2FBSDE can learn to pre-swing the pendulum.	Review	I-Review	2
[line_break_token][line_break_token]The quadcopter:[line_break_token]Could the authors please specify the exact quadcopter dynamics.	Review	I-Review	2
What kind of abstraction did you model?	Review	I-Review	2
What are the control inputs?	Review	I-Review	2
Furthermore, the citation for the dynamics is wrong and puts the supervisor of the master thesis as first author.	Review	I-Review	2
Furthermore, can the authors please provide longer plots to highlight, which method can stabilize the system.	Review	I-Review	2
[line_break_token][line_break_token]Human Arm:[line_break_token]For the human arm neither iLQG or 2FBSDE reach the desired target location.	Review	I-Review	2
Can you explain why no trajectory optimization does reach the desired position.	Review	I-Review	2
[line_break_token][line_break_token]Formatting:[line_break_token]Please rework the formatting such that the inline math does not cause the formatting issues of different line spacings (e.g., sec.	Review	I-Review	2
2.1, sec.	Review	I-Review	2
5) and irregular whitespaces (e.g., last line of paragraph 2.1 Preliminaries).	Review	I-Review	2
Please remove the color coding of text for the experiments and make sure that the legends are sufficiently large and include all lines.	Review	I-Review	2
Currently the legends are missing the target state.	Review	I-Review	2
You can also extend the figure captions to highlight the conclusion of the plots.	Review	I-Review	2
Please rework the figures such that the figures do not cause so much whitespace (e.g., Figure 3, 4 &amp; 5).	Review	O	0
When reconfiguring the plots, you gain space, which can be used for further explanation of the theory.	Review	B-Review	2
Furthermore, you might want add dotted lines to the confidence intervals as the confidence intervals are important but the differences are not clearly visible from the plots.	Review	I-Review	2
Also, the labelling in figure 3 seems wrong, the axis labeled cart velocity should be pendulum angle and the pendulum angle axis should be cart velocity.	Review	I-Review	2
All in all, the formatting can be significantly improved, which is especially bad as this paper is most likely a resubmission from Neurips.	Review	I-Review	2
 [line_break_token][line_break_token][line_break_token]Minor Comments / Questions:[line_break_token]- 'where l :Rnx√óRnu‚ÜíR+ is the running cost and C1,23 \phi :Rnx‚ÜíR+ is the terminal state cost.'	Review	O	0
Is l and \phi of class C^{1,2} or only one of them?	Review	B-Review	3
The notation is confusing and should be simplified.	Review	I-Review	3
[line_break_token]- Can you comment on how important this multiplicative noise in physical system?	Review	I-Review	3
¬¨¬¨¬¨[line_break_token]- Why are you using a LSTM instead of a simple feed-forward neural network as the ff-nn should be sufficient to model V(x) as the value function is not recurrent.	Review	I-Review	3
Have you tried using a simple ff-nn?	Review	I-Review	3
he control multiplicative noise can be found in bio-mechanical systems [1] and financial problems such as portfolio optimization [2].[line_break_token][line_break_token]Pereira et.	Reply	B-Reply	4
al.	Reply	I-Reply	4
has shown that a recurrent network architecture using LSTM outperforms the fully connected networks at every time step proposed by Han et.	Reply	I-Reply	4
al.	Reply	I-Reply	4
in task completion, space and time complexity.	Reply	I-Reply	4
Therefore, in this paper we choose to use an LSTM-based network architecture.	Reply	I-Reply	4
[line_break_token][line_break_token]After performing the comparison of 2FBSDE and iLQG under different levels of additive and multiplicative noise (results shown in fig.	Reply	I-Reply	1
5), we included the phase plot comparison of the two controllers in the low noise condition (multiplicative noise std = additive noise std = 0.1) in the supplementary materials (fig.	Reply	I-Reply	1
9).	Reply	I-Reply	1
Under this condition, 2FBSDE can perform the task while iLQG diverges.	Reply	I-Reply	1
As the noise level increases, the performance of 2FBSDE deteriorates but still outperforms iLQG.	Reply	I-Reply	1
[line_break_token][line_break_token]Our cost functions for all tasks were quadratic state (both running and terminal) and control costs.	Reply	I-Reply	1
We have added the values of state cost and control cost coefficients for each simulation experiment to the supplementary materials.	Reply	I-Reply	1
All the tasks were reaching tasks meaning that the state costs are squared distances from a target state.	Reply	I-Reply	1
We refer the reviewer to sections E and F of the supplementary materials for the exact values of the parameters used in our experiments.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding suggestions for additional plots and experiments, we have included new plots in the main paper and supplementary materials (see section G).	Reply	I-Reply	2
[line_break_token][line_break_token][1] Todorov, Emanuel. "	Reply	O	0
Stochastic optimal control and estimation methods adapted to the noise characteristics of the sensorimotor system."	Reply	O	0
Neural computation 17.5 (2005): 1084-1108.	Reply	O	0
[line_break_token][line_break_token][2] Davis, Mark, and Sebastien Lleo. "	Reply	O	0
Jump-diffusion risk-sensitive asset management II: jump-diffusion factor model."	Reply	O	0
SIAM Journal on Control and Optimization 51.2 (2013): 1441-1480	Reply	O	0

UPDATE 2 (Nov 19, 2018): The paper has improved very substantially since the initial submission, and the authors have addressed almost all of my comments.	Review	O	0
I have therefore increased my score to an 8 and recommend acceptance.	Review	O	0
[line_break_token]------------------------------------------------------------------------------------------------------------------------------[line_break_token][line_break_token]UPDATE (Nov 16, 2018) : In light of the author response, I have increased my score to a 6.	Review	O	0
[line_break_token]------------------------------------------------------------------------------------------------------------------------------[line_break_token][line_break_token]This paper aims to analyze the extent to which networks learn to correctly classify specific examples and then ‚Äúforget‚Äù these examples over the course of training.	Review	O	0
The authors provide several examples of forgettable and unforgettable examples, demonstrating, among other things, that examples with noisy examples are more forgettable and that a reasonable fraction of unforgettable examples can be removed from the training set without harming performance.	Review	O	0
[line_break_token][line_break_token]The paper is clearly written, and the work is novel -- to my knowledge, this is the first investigation of example forgetting over training.	Review	O	0
There are an interesting and likely important set of ideas here, and portions of the paper are quite strong -- in particular, the experiment demonstrating that examples with noisy examples are more forgettable is quite nice.	Review	O	0
However, there are several experimental oversights which make this paper difficult to recommend for publication in its current form.	Review	O	0
[line_break_token][line_break_token]Major points:[line_break_token][line_break_token]1) The most critical issue is with the measurement of forgetting itself: the authors do not take into account the chance forgetting rate in any of their experiments.	Review	O	0
Simply due to chance, some examples will be correctly labeled at some point in training (especially in the datasets analyzed, which only contain 10 classes).	Review	B-Review	1
This makes it difficult to distinguish whether a ‚Äúforgotten‚Äù example was actually ever learned in the first place.	Review	I-Review	1
In order to properly ground this metric, measurements of chance forgetting rates will be necessary (for example, what are the forgetting rates when random steps are taken at each update step?).	Review	I-Review	1
[line_break_token][line_break_token]2) Were the networks trained on MNIST, permutedMNIST, and CIFAR-10 trained for the same number of epochs?	Review	O	0
Related to point 1, the forgetting rate should increase with the number of epochs used in training as the probability of each example being correctly classified should increase.	Review	B-Review	2
If the CIFAR-10 models were trained for more epochs, this would explain the observation that more CIFAR-10 examples were ‚Äúforgettable.	Review	I-Review	2
‚Äù[line_break_token][line_break_token]3) In the experiment presented in Figure 4b, it is difficult to tell whether the never forgotten set suffers less degradation in the third training regime because the examples were never forgotten or because the model had twice has much prior experience.	Review	O	0
Please include a control where the order is flipped (e.g., forgotten, never forgotten, forgotten in addition to the included never forgotten, forgotten, never forgotten order currently present).	Review	B-Review	3
[line_break_token][line_break_token]4) The visual inspection of forgettable and unforgettable examples in Figure 2 is extremely anecdotal, and moreover, do not even appear to clearly support the claims made in the paper.	Review	O	0
[line_break_token][line_break_token]Minor points:[line_break_token][line_break_token]1) In the discussion of previous studies which attempted to assess the importance of particular examples to classification decisions, a citation to [1] should be added.	Review	O	0
[line_break_token][line_break_token]2) The point regarding similarity across seeds is absolutely critical (especially wrt major comment 1) , and should be included earlier in the paper and more prominently.	Review	O	0
[line_break_token][line_break_token]3) The histograms in Figure 1 are misleading in the cropped state.	Review	O	0
While I appreciate that the authors included the full histogram in the supplement, these full histograms should be included in the main figure as well, perhaps as an inset.	Review	B-Review	7
[line_break_token][line_break_token]4) The inclusion of a space after the commas in numbers (e.g., 50, 245) is quite confusing, especially when multiple numbers are listed as in the first line on page 4.	Review	O	0
[line_break_token][line_break_token][1] Koh, Pang Wei and Percy Liang. ‚	Review	O	0
ÄúUnderstanding Black-box Predictions via Influence Functions.	Review	O	0
‚Äù ICML (2017).	Review	O	0
[line_break_token]	Review	O	0
Dear authors, it is a great work and I am interested in it a lot.	Reply	O	0
[line_break_token][line_break_token]As one offical reviewer mentioned, I am also concerned about the the measurement of forgetting itself. ''	Reply	B-Reply	1
Simply due to chance, some examples will be correctly labeled at some point in training, which makes it difficult to distinguish whether a ‚Äúforgotten‚Äù example was actually ever learned in the first place. "	Reply	I-Reply	1
[line_break_token]I suppose many factors cause this phenomenon happening: the random sampling of SGD, the batch size, the learning rate, initialisation, etc.	Reply	I-Reply	1
[line_break_token][line_break_token]I noticed that the paramters' update order has been studied and added.	Reply	I-Reply	3
[line_break_token]Could you please share more information about other factors, e.g., batch size, learning rate, or initialised by pretrained models etc.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]I am looking forward to your sharing.	Reply	O	0
Thanks very much.	Reply	O	0

[Summary][line_break_token]This paper performs an extensive empirical evaluation of Neural Tangent Kernel (NTK) classifiers---kernel methods that theoretically characterize infinitely wide neural nets---on small-data tasks.	Review	O	0
Experiments show that NTK classifiers (1) strongly resemble the performance of neural nets on small-data tasks, (2) can beat prior benchmark methods such as Random Forests (RF) on classification tasks in the UCI dataset, and (3) can also outperform standard linear SVM on a few-shot learning task.	Review	O	0
[line_break_token][line_break_token][Pros][line_break_token]The question considered in this paper is well motivated, and a very natural extension of Lee et al. (	Review	O	0
2019) and Arora et al. (	Review	O	0
2019a).	Review	O	0
These papers show that NTK performs well on (relatively) large benchmark tasks such as CIFAR-10 but is still a bit inferior to fully trained neural nets.	Review	O	0
On the other hand, for small-data tasks, the relationship is reversed --- neural nets are slightly inferior to more traditional methods such as random forests (e.g. from Fernandez-Delgado et al.	Review	O	0
2014) and Gaussian kernel SVMs.	Review	O	0
As the NTK gives a limiting characterization for wide neural nets, it is a sensible question to test the performance of NTK on these small datasets, and see if they can improve over neural nets and compare more favorably against the traditional methods.	Review	O	0
[line_break_token][line_break_token]The experimental results, in my perspective, is a reasonably convincing evidence that the resemblance between NTK and NN on small-data tasks is stronger than on larger tasks such as CIFAR-10, which agrees with the NTK theory.	Review	O	0
In addition to the UCI datasets, the paper also tries out NTK in a few-shot learning task and show that SVM with the convolutional NTK does better than the linear SVM as the few-shot learner.	Review	O	0
I am less familiar with few-shot learning though so am not entirely sure about the strength of this part.	Review	O	0
[line_break_token][line_break_token]The paper is well-written and delivers its messages clearly.	Review	O	0
The results and discussions are easy to follow.	Review	O	0
[line_break_token][line_break_token][Cons, and suggestions][line_break_token]The message that ‚ÄúNTK beats RF‚Äù seems a bit delicate to me, specifically considering the fact that the average accuracies of (NTK, NN, RF) are all pretty close but the Friedman rank comparison says NTK &gt; RF &gt; NN (somewhat more significantly).	Review	O	0
This implies the difference between all these methods has to be small and it‚Äôs only that NTK happens to win on more tasks.	Review	B-Review	1
In addition, NTK tunes one more parameter (L‚Äô) than NNs, so I guess perhaps NNs can also be tuned to outperform RF in the rank sense if we also tune L‚Äô (by fixing the bottom L‚Äô layers to be not trained) in NNs?	Review	I-Review	2
[line_break_token][line_break_token]Also, it would be better if the authors could provide a bit more background on the metrics used in the UCI experiments -- for example, the Friedman rank is not defined in the paper.	Review	O	0
hank you for your positive review.	Reply	O	0
We have revised our paper according to your suggestion.	Reply	O	0
Regarding your comment ‚ÄúNTK tunes one more parameter (L‚Äô) than NNs‚Ä¶‚Äù: Since training all layers in NN is the standard practice, we did not fix the first layers.	Reply	O	0
Also note that for experiments on UCI, more hyper-parameters do not necessarily give better performance because we used 4-fold cross-validation	Reply	B-Reply	2

This paper considers different methods of producing adversarial examples for generative models such as VAE and VAEGAN.	Review	O	0
Specifically, three methods are considered: classification-based adversaries which uses a classifier on top of the hidden code, VAE loss which directly uses the VAE loss and the "latent attack" which finds adversarial perturbation in the input so as to match the latent representation of a target input.	Review	O	0
[line_break_token][line_break_token]I think the problem that this paper considers is potentially useful and interesting to the community.	Review	O	0
To the best of my knowledge this is the first paper that considers adversarial examples for generative models.	Review	O	0
As I pointed out in my pre-review comments, there is also a concurrent work of "Adversarial Images for Variational Autoencoders" that essentially proposes the same "latent attack" idea of this paper with both L2 distance and KL divergence.	Review	O	0
[line_break_token][line_break_token]Novelty/originality: I didn't find the ideas of this paper very original.	Review	B-Review	1
All the proposed three attacks are well-known and standard methods that here are applied to a new problem and this paper does not develop *novel* algorithms for attacking specifically *generative models*. However I still find it interesting to see how these standard methods compare in this new problem domain.	Review	I-Review	1
[line_break_token][line_break_token]The clarity and presentation of the paper is very unsatisfying.	Review	I-Review	2
The first version of the paper proposes the "classification-based adversaries" and reports only negative results.	Review	I-Review	2
In the second set of revisions, the core idea of the paper changes and almost an entirely new paper with a new co-author is submitted and the idea of "latent attack" is proposed which works much better than the "classification-based adversaries".	Review	I-Review	2
However, the authors try to keep around the materials of the first version, which results in a 13 page long paper, with different claims and unrelated set of experiments. "	Review	I-Review	2
in our attempts to be thorough, we have had a hard time keeping the length down" is not a valid excuse.	Review	I-Review	2
[line_break_token][line_break_token]In short, the paper is investigating an interesting problem and apply and compare standard adversarial methods to this domain, but the novelty and the presentation of the paper is limited.	Review	O	0
Thanks for the review, and for pointing out the NIPS workshop paper.	Reply	B-Reply	1
That work was not known at the time of our submission to ICLR, as their paper was published online one month after our initial ICLR submission, and a couple of weeks after our first major revision.	Reply	I-Reply	1
We have added a paragraph explaining the differences with their paper.	Reply	I-Reply	1
It appears that their paper comes to a different conclusion regarding the L_vae attack -- we find it to be effective on MNIST, SVHN and CelebA, while they say that they couldn‚Äôt get it to work.	Reply	I-Reply	1
We also present a more in-depth study of the topic, which considers more attacks, more generative model architectures, and more datasets (with our addition of CelebA results in the latest draft).	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that ultimately we were able to determine that existing attacks could be modified to apply to the new domain of generative models, and so it may feel self-evident in retrospect.	Reply	I-Reply	1
 However, prior to our work, it was unknown in the literature whether the stochasticity of generative models would confer robustness, or what an attack on a generative model would look like, or even under what scenarios an attacker might want to attack a generative model.	Reply	I-Reply	1
 With our work, the research community knows that generative models are effectively as vulnerable to adversarial examples as deterministic classifiers, and that there are realistic scenarios where such attacks could matter.	Reply	I-Reply	1
 In our opinion, this is an important result, even though it didn‚Äôt require discovering substantially different mathematical approaches (and perhaps it is even more important because the attacks transferred so naturally, underscoring the vulnerability of current architectures).	Reply	I-Reply	1
[line_break_token][line_break_token]It‚Äôs true that we did a lot of work on this paper after the initial deadline.	Reply	I-Reply	2
 ICLR‚Äôs unusual submission and review process permits and encourages authors to continue revising their work after submission, which clearly has some advantages and disadvantages for all parties involved.	Reply	I-Reply	2
 Presumably norms and expectations around how much papers change after submission will become more settled over time.	Reply	I-Reply	2
 Thanks for your patience through the various revisions and additions we have made!	Reply	I-Reply	2
 In this version, we have shortened and streamlined the paper, reducing it to 11 pages while also adding some new results.	Reply	I-Reply	2

The paper considers the problem of distributed multi-arm bandit, where M players are playing in the same stochastic environment.	Review	O	0
The goal of the paper is to have small over-all regret for all the players without a significant amount of communication between the players.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]The main contribution of this paper is obtaining regret ~root(M KT) with ~M bits of communication in MAB, and regret ~d*root(MT) with ~Md bits of communication in linear bandit setting.	Review	O	0
[line_break_token][line_break_token]The main intuition of the algorithms in this paper is to do "best arm identification" with epoching: At every epoch t, the central server sends the set of possible best arms to each player and each player pulls it for 2^t /M times, followed by a communication round.	Review	O	0
Thus, the cumulative regret is comparable to having one player doing this epoch strategy for MT iterations, where the regret follows.	Review	O	0
[line_break_token][line_break_token]The problem considered in this paper is interesting and the result is new, the technique looks simple on paper but it requires a masterful combination of known tricks in (linear) MAB to obtain the best bound.	Review	O	0
 [line_break_token][line_break_token][line_break_token]It seems that in the MAB setting, the lower bound could be further strengthened with a log(K) factor, since removing this factor would ultimately require "dynamic epoching" which is not possible with limited communication.	Review	O	0
This would mostly complete the picture in the distributed MAB regime.	Review	B-Review	1
[line_break_token][line_break_token][line_break_token]Missing citation:[line_break_token]The authors are missing citations relevant to distributed MAB with collisions, see for example [line_break_token]"Non-Stochastic Multi-Player Multi-Armed Bandits: Optimal Rate With Collision Information, Sublinear Without"[line_break_token][line_break_token][line_break_token]After Rebuttal: I have read the authors' responses and acknowledge the sensibility of the statement.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
e thank anonymous reviewer 3 for the review.	Reply	O	0
[line_break_token][line_break_token]Regarding the lower bound: We greatly thank reviewer 3 for the comments on the lower bound.	Reply	O	0
We are considering this and may improve the lower bound in the final version.	Reply	B-Reply	1
[line_break_token][line_break_token]Regarding the missing citation: Thanks for bringing this paper to our attention.	Reply	O	0
We will add it to the references.	Reply	B-Reply	2

The authors consider the problem of re-ranking an initial ranker that doesn‚Äôt consider interactions between items (e.g., a point-wise ranker) with a pointer-network approach that considers these interactions when re-ordering the input ranking.	Review	O	0
Notably, this is performed during decoding as opposed to {pairwise, list-wise} learning to rank approaches that consider interactions during training, but emit an item-wise score during inference.	Review	O	0
Operationally in practice, this has to be trained from click-through data for which the authors consider both a RL approach (Reinforce) and supervised training (a sequence-level hinge loss function) and decoded either with a single-step greedy policy or a sampling procedure.	Review	O	0
Experiments are conducted on learning-to-rank benchmarks where interactions are introduced to test the validity of the method and on a real-world, large-scale recommendation engine ‚Äî showing solid improvements in both cases.	Review	O	0
[line_break_token][line_break_token]From a high-level perspective, the methodological innovation (a pointer-network trained on sequence loss from logged data), setting (re-ranking a slate to consider interactions), and empirical analyses are largely ‚Äòincremental‚Äô ‚Äî although I think non-trivial to put together and the paper itself is well-written and fairly convincing.	Review	O	0
In framing the paper this way, I would have expected some comparison to sub-modular methods on the ‚Äòdiverse-clicks‚Äô generated data for completeness, although I would be surprised if the Seq2Slate method doesn‚Äôt perform better (but all the more reason to conduct).	Review	B-Review	1
In addition to reporting how to resolve some of the details of applying this, the most interesting results may very well be the real-world experiments as the result improvements are fairly impressive (such that I intend to play with this myself).	Review	O	0
Thus, as the focus is on details and empirical results over methodological innovation, this paper reads a bit like an industry-track paper ‚Äî but I find the results interesting overall and am marginally inclined to accept.	Review	O	0
[line_break_token][line_break_token]Evaluating the paper along the requested dimensions:[line_break_token][line_break_token]= Quality: The paper clearly states its motivation, proposes a model, discusses practical issues, and provides convincing experiments (given the constraints of proprietary data, etc.).	Review	O	0
I didn‚Äôt observe any technical flaws and everything was relatively self-contained and easy to read.	Review	O	0
I could think of a few more experiments regarding submodular-based models, possibly different settings of the ‚Äòdiverse-click‚Äô data for a sensitivity analysis, and a more direct comparison to [Ai, et al.,	Review	B-Review	2
SIGIR18], but this isn‚Äôt required to make the results sufficiently convincing. (	Review	I-Review	2
6/10)[line_break_token][line_break_token]= Clarity: The paper is very clearly written. (	Review	O	0
7/10)[line_break_token][line_break_token]= Originality: This is the weakest aspect of the paper from a methodological perspective.	Review	O	0
It is a fairly straightforward application of pointer-networks.	Review	B-Review	3
Even the path forward is fairly straightforward as outlined in the conclusion.	Review	I-Review	3
One additional pointer that is methodologically similar, but for ‚Äòdiscrete choice‚Äô as opposed to re-ranking is [Mottini & Acuna-Agost, Deep Choice Model Using Pointer Networks for Airline Itinerary Prediction; KDD17] (which honestly, is probably a better venue for this specific work).	Review	O	0
Non-trivial and complete, but not particularly innovative. (	Review	B-Review	3
5/10)[line_break_token][line_break_token]= Significance: Methodologically, probably will influence some work regarding re-ranking methodologically.	Review	O	0
From a practical perspective, seems very promising.	Review	O	0
A few more experiments would make this case stronger, but has real-world data. (	Review	O	0
6/10)[line_break_token][line_break_token]=== Pros ===[line_break_token]+ extends a widely used model (pointer-networks) to the re-ranking setting[line_break_token]+ discusses practical issues in getting this to work at scale[line_break_token]+ shows that it works in a real-world setting [line_break_token]+ contextualization within existing research shows good understanding of related work[line_break_token][line_break_token]=== Cons ===[line_break_token]- is a fairly direct application of pointer-networks with the innovation being in the details (i.e., is more of an ‚Äòindustry‚Äô paper)[line_break_token]- additional experiments around ‚Äòdiverse-clicks‚Äô settings (to see how smooth the performance curve) and submodular comparisons may have been interesting[line_break_token][line_break_token]In summary, I think there is room for improvement (some outlined in the conclusion), but is an interesting finding with promise that I plan to try myself.	Review	O	0
Thus, I lean toward an accept.	Review	O	0
Thanks for the valuable feedback.	Reply	O	0
We address specific points here and more general points in the common response.	Reply	O	0
[line_break_token][line_break_token]We certainly believe that the fact that our work has practical applications and demonstrated in a large-scale, real-world system adds to our scientific contribution and should be considered an advantage of our work.	Reply	O	0
That said, we want to emphasize that the scientific contributions discussed in the common response, are critical to its success, broadly applicable and, as mentioned above, well-aligned with ICLR‚Äôs focus on learning representations.	Reply	O	0
We don‚Äôt believe that the paper should be viewed as one intended for an ‚Äúindustry track.	Reply	O	0
‚Äù [line_break_token][line_break_token]Regarding experiments:[line_break_token]* Comparison to sub-modular baseline[line_break_token]We agree that this is an interesting baseline.	Reply	O	0
We are not aware of publicly available code (we would appreciate any pointers in case we missed something), but will work to add such baseline in the revision.	Reply	B-Reply	1
[line_break_token]We emphasize that seq2slate is flexible and data-driven rather than modeling specific types of interactions, which is a key advantage of our approach.	Reply	I-Reply	1
This allows us to avoid strong assumptions regarding the type of interactions between items made by a large number of previous approaches, and lets the model adapt to the type of interactions present in the data.	Reply	I-Reply	1
For example, if one used a specific interaction model for ‚Äòdiverse-clicks‚Äô, then a different model would be required for the ‚Äòsimilar-clicks‚Äô data, a distinction not needed with seq2slate.	Reply	I-Reply	1
[line_break_token]* Different settings of the ‚Äòdiverse-click‚Äô data for sensitivity analysis[line_break_token]We compare ‚Äòdiverse-clicks‚Äô to ‚Äòsimilar-clicks‚Äô in the experiments, which tests a different type of interaction.	Reply	O	0
In our generative model we also had to make sure that the total number of clicks was suitable for training on the benchmark data, which restricted the range of values (see also reply to Reviewer 1 on the choice of \eta).	Reply	B-Reply	2
[line_break_token]* A more direct comparison to Ai, et al.,	Reply	O	0
2018 -- see common reply.	Reply	B-Reply	2
[line_break_token][line_break_token]Thanks for the reference to Mottini & Acuna-Agost, we will include it	Reply	O	0

This paper studies the problem of exploration in reinforcement learning.	Review	O	0
The key idea is to learn a goal-conditioned agent and do exploration by selecting goals at the frontier of previously visited states.	Review	O	0
 This frontier is estimated using an extension of prior work (Pong 2019).	Review	O	0
The method is evaluated on two continuous control environments (2D navigation, manipulation), where it seems to outperform baselines.	Review	O	0
[line_break_token][line_break_token]Overall, I like that the proposed method integrates some notion of novelty with the language of mutual information and density estimation.	Review	O	0
While this idea has been explored in prior work (as noted in the related work section), the proposed idea seems like a useful contribution to the literature.	Review	O	0
The use of convolutions to obtain a lower bound on mutual information seems neat.	Review	O	0
The experimental results are quite strong.	Review	O	0
[line_break_token][line_break_token]My main concern with the paper is a lack of clarity.	Review	B-Review	17
I currently have enough reservations and questions (listed below) about the experimental protocol that I am learning towards rejecting this paper.	Review	I-Review	17
However, if the paper clarified the concerns below, I'd be willing to increase by review.	Review	O	0
[line_break_token][line_break_token]Questions / Concerns:[line_break_token]* "[Prior work on mutual-information cannot] guarantee that the entire state space can be covered" -- In theory, I think these prior methods should cover the entire state space.	Review	O	0
Take the DIAYN objective, I(s, z) = H[s] - H[s | z]. This objective is maximized when p(s) is uniform over the entire state space and p(s | z) is a Dirac.	Review	B-Review	1
[line_break_token]* "It is time consuming to collect enough samples to estimate an accurate state entropy" -- Can you provide a citation/proof for this?	Review	O	0
Why should we expect the proposed method to require fewer samples?	Review	B-Review	2
[line_break_token]* "...entropy itself does not provide efficient information to adjust the action at each step." --	Review	O	0
Can you provide a citation / proof for this?	Review	B-Review	3
Also, what does "efficient information" mean?	Review	I-Review	3
[line_break_token]* It seems like, if S is a finite collection of states in a continuous space, then it has measure zero, so its entropy should be zero.	Review	O	0
Can you explain why this is not the case?	Review	B-Review	4
[line_break_token]* If I'm not mistaken, in equation 2, if we take (say) alpha = -0.5, then w_i is proportional to sqrt(p(s_i)), so w_i is an increasing function in p(s_i), not a decreasing function.	Review	O	0
[line_break_token]* Can you discuss how you might scale a KDE to high dimensions?	Review	O	0
[line_break_token]* "If the distribution has a larger range, the entropy is larger as well." --	Review	O	0
Technically, this is not correct.	Review	B-Review	7
You can construct distributions with larger ranges but smaller entropies.	Review	I-Review	7
[line_break_token]* I think that Equation 3 should be the KL divergence between state marginal distributions, not between trajectories.	Review	O	0
If it were the KL between trajectories, it would include actions and policy terms.	Review	B-Review	8
[line_break_token]* How are w_int and w_ext chosen?	Review	O	0
It seems like the method depends critically on the balance between these hyperparameters.	Review	B-Review	9
Is w_int decayed over time?	Review	I-Review	9
If not, why does the policy stop exploring once it has found the goal?	Review	I-Review	9
[line_break_token]* What policy is used at convergence?	Review	O	0
It seems like the policy is conditioned on Z_t, so how is the Z_t chosen for evaluation?	Review	B-Review	10
[line_break_token]* Fig 5 -- How are entropy and coverage computed?	Review	O	0
What are the maximum possible values for both of these quantities?	Review	B-Review	11
What precisely does the X axis correspond to?	Review	I-Review	11
[line_break_token]* Table 1 -- How did the baseline algorithms perform on this task?	Review	O	0
[line_break_token]* Fig 7 -- How did the baseline algorithms perform on this task?	Review	O	0
If the reward were sparse, shouldn't the Y axis be in the interval [0, 1]?	Review	B-Review	13
[line_break_token]* "using coverage only during training is not suitable" -- Can you provide a citation/proof for this?	Review	O	0
[line_break_token]* "As a consequence, the entropy of the distribution of these points is also maximized" -- I believe that a finite number of points in a discrete space have measure zero, so they have zero entropy, regardless of the position of the points.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]Other comments[line_break_token]* "What is the difference between *S* (in bold) and S_t?	Review	B-Review	16
[line_break_token]* I would recommend using some notation other than p(s) to denote the smoothed/convolved density.	Review	I-Review	16
[line_break_token]* "history states" -- I was confused about what this meant until it was introduced two sections later.	Review	I-Review	16
[line_break_token]* "assimilate the definition of curiosity in psychology" -- I think that others (e.g., Oudeyer 2007, Pathak 2017) have noted the similarities between curiosity in humans and RL agents.	Review	I-Review	16
[line_break_token]* Check for backwards quotes in the related work section.	Review	I-Review	16
[line_break_token]* "Self-Goal Proposing" -- Some more related works are [Florensa 2017, Savinov 2018][line_break_token]* "space associated environment" -- I don't know what this means.	Review	I-Review	16
[line_break_token]* "disc rewards" -- I'd recommend spelling out discounted[line_break_token]* "truncated Gaussian function with a narrow range" -- Can you explain precisely what this is?	Review	I-Review	16
[line_break_token]* In equation 2, I think it'd be clearer to write p^(1+\alpha).	Review	I-Review	16
[line_break_token]* For the experiment on the effect of variance, I'd recommend making a plot instead of just listing the values.	Review	I-Review	16
[line_break_token]* In Section 4.3, it's unclear whether the physical robot was successful at solving the task.	Review	I-Review	16
[line_break_token]* "We rewrite the equation‚Ä¶" -- This paragraph is repeated.	Review	I-Review	16
[line_break_token]* Double check that \citet and \citep are used properly[line_break_token][line_break_token]--------------UPDATE AFTER AUTHOR RESPONSE------------------[line_break_token]Thanks for answering many of my questions.	Review	O	0
This was helpful for clarifying my understanding.	Review	O	0
However, since a large fraction of my concerns were not addressed, so I am inclined with stick with my original vote to reject the paper.	Review	O	0
Nonetheless, I should emphasize that I think this paper is on the right track and the empirical results seems strong.	Review	O	0
With a bit more work on writing, I think it would be a fantastic paper at the next conference.	Review	O	0
hank you for the detailed review.	Reply	O	0
According to your comments and suggestions, we have added references, fixed typos, and removed/revised sentences with confusion or lack of citation/proof.	Reply	B-Reply	16
Below, we address your questions.	Reply	O	0
[line_break_token][line_break_token]--- It seems like, if S is a finite collection of states in a continuous space, then it has measure zero, so its entropy should be zero.	Reply	O	0
Can you explain why this is not the case?	Reply	O	0
[line_break_token][line_break_token]In our formulation, S_t is a finite collection of sampled history states in a continuous space, and S is a random variable with distribution estimated using techniques like weighted KDE from S_t.	Reply	B-Reply	4
[line_break_token][line_break_token]--- If I'm not mistaken, in equation 2, if we take (say) alpha = -0.5, then w_i is proportional to sqrt(p(s_i)), so w_i is an increasing function in p(s_i), not a decreasing function.	Reply	O	0
[line_break_token][line_break_token]The weight w_i does not need to be a decreasing function of p(s_i).In practice, there is a trade-off between exploration efficiency and learning efficiency which is controlled by w_i through parameter alpha.	Reply	B-Reply	5
Proposing states with lower density is important for exploration, however, lower density also indicates that the agent are less trained on those states and may not know how to explore around them.	Reply	I-Reply	5
Depending on the difficulty of the task and the environment, we could adjust alpha to decide how much we would like to emphasize the exploration.	Reply	I-Reply	5
[line_break_token]In our experiments, we set alpha as -1.1.	Reply	I-Reply	5
[line_break_token][line_break_token]--- Can you discuss how you might scale a KDE to high dimensions?	Reply	O	0
[line_break_token][line_break_token]There are two places in our method that need density estimation,1) estimating the density of visited states p(s) to update the novelty frontier, and 2) computing log p_z(s) - log p_\tao(s) as the intrinsic reward.	Reply	B-Reply	6
When we estimate the visited state density, we could replace KDE to other density estimation methods (such as VAE in Skew-Fit or flow-based methods), which scale well to high dimensional inputs.	Reply	I-Reply	6
When we compute the intrinsic reward, we do not need an accurate density estimation.	Reply	I-Reply	6
The key point is to construct an intrinsic reward that encourages the agent to reach the goal state but not staying at the goal state.	Reply	I-Reply	6
[line_break_token]We could apply KDE on the lower-dimensional latent space we obtained while learning p(s).	Reply	I-Reply	6
In this case, the learned distribution N on the raw space may not be a Gaussian distribution, but some other distribution centered at z. However, as long as the learned N has higher variance than the distribution learned with goal-conditioned policy (Dirac delta function), we always gain a positive h(S|Z) - h(Z|S), which gives additional power for exploration.	Reply	I-Reply	6
[line_break_token][line_break_token]--- "If the distribution has a larger range, the entropy is larger as well." --	Reply	O	0
Technically, this is not correct.	Reply	O	0
You can construct distributions with larger ranges but smaller entropies.	Reply	O	0
[line_break_token][line_break_token]This sentence is related to the previous sentence. ‚	Reply	B-Reply	7
ÄúThe entropy of a continuous uniform function is, and if the distribution has a larger range, the entropy is larger as well.	Reply	I-Reply	7
‚Äù As a consequence, the distribution we meant here is continuous uniform distribution.	Reply	I-Reply	7
[line_break_token][line_break_token]--- I think that Equation 3 should be the KL divergence between state marginal distributions, not between trajectories.	Reply	O	0
If it were the KL between trajectories, it would include actions and policy terms.	Reply	O	0
[line_break_token][line_break_token]The equation 3 indicates the KL divergence between the distribution formed by an actual trajectory, and the desired distribution modeled by N. Since we choose N to be a Gaussian distribution centered at a given reference state, we penalize states which are too far from the reference state, or states that the agent has stayed for too long.	Reply	B-Reply	8
[line_break_token][line_break_token]--- How are w_int and w_ext chosen?	Reply	O	0
It seems like the method depends critically on the balance between these hyperparameters.	Reply	O	0
Is w_int decayed over time?	Reply	O	0
If not, why does the policy stop exploring once it has found the goal?	Reply	O	0
[line_break_token][line_break_token]In our experiments, we manually selected w_int and  w_ext to adjust the average intrinsic return to be around 1 and the extrinsic return to be 10.	Reply	B-Reply	9
The w_int and  w_ext are fixed.	Reply	I-Reply	9
[line_break_token]The proposed z only affects the intrinsic reward, however, the overall objective is to optimize the return of the combined reward.	Reply	I-Reply	9
Since the extrinsic return is much larger than the intrinsic return, once the agent has found the state with large extrinsic reward, the policy will eventually ignore the given goal but always go to the state with extrinsic reward.	Reply	I-Reply	9
[line_break_token][line_break_token]--- What policy is used at convergence?	Reply	O	0
It seems like the policy is conditioned on Z_t, so how is the Z_t chosen for evaluation?	Reply	O	0
[line_break_token][line_break_token]In the evaluation, we randomly sample a z from the  Z_t and pass it to the policy.	Reply	B-Reply	10
Since the policy has converged to a solution that always go to the state with extrinsic reward, it does not matter which z we send to the policy.	Reply	I-Reply	10

This paper proposes a new method to normalize activations in neural networks, based on an upper bound of the sliced Wasserstein distance between the empirical activation distribution and a standard Gaussian distribution.	Review	O	0
I think this feels like a "borderline" case to me.	Review	O	0
The paper clearly has merits, at the same time there're some issues to be addressed.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The idea is clearly presented.	Review	O	0
[line_break_token]- Better performance than BN is achieved in many experiments.	Review	O	0
[line_break_token]- Empirical evidence in Section 4.3 looks good, suggesting the proposed method does do the job as expected.	Review	O	0
The means and variances stabilize as training progresses.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- While the method based on sliced Wasserstein distances sounds new, the novelty seems limited since the idea of whitening the activation distribution to unit Gaussian was introduced before as mentioned by the authors.	Review	O	0
The paper claims the random projection may capture ‚Äúinteraction between hidden units‚Äù, but it seems the method proposed in e.g. Huang et.	Review	B-Review	1
al.	Review	I-Review	1
2018 also has projection matrices that might be doing similar things?	Review	I-Review	1
[line_break_token][line_break_token]- I‚Äôm concerned about the actual computation cost of the proposed method.	Review	O	0
Although the method does not introduce any additional parameter compared to BN or VCL, it seems to require multiple random projections for each layer (s=256 in the experiments)?	Review	B-Review	2
This could be much slower than the BN.	Review	I-Review	2
A clarification/comparison of the wall clock running time would be desirable.	Review	I-Review	2
[line_break_token][line_break_token]- In terms of the image experiments, I do expect to see results with larger datasets/models, though not absolutely necessary.	Review	O	0
[line_break_token][line_break_token]Typos:[line_break_token]- Page 5, Eq.	Review	O	0
9, x_i should be h_i instead?	Review	B-Review	4
[line_break_token]- Page 9, beta^l_j = 0 and ??	Review	I-Review	4
^_j = 1	Review	I-Review	4
e appreciate Reviewer 3 for the carefully reading our work and providing valuable comments.	Reply	O	0
We address your cons as follows:[line_break_token][line_break_token][line_break_token]- Difference between PER and Huang et.	Reply	O	0
al.	Reply	B-Reply	1
2018[line_break_token]Yes, it is true that DBN (Huang et.	Reply	O	0
al.,	Reply	B-Reply	1
2018) also captures the interaction between hidden units though whitening.	Reply	I-Reply	1
However, there are many cases PER and DBN have different behavior in making activations to follow the standard normal distribution since PER aims to match the distributions and DBN aims to whiten the activations.	Reply	I-Reply	1
For instance, DBN cannot make change activations from a skewed distribution or a multimodal distribution having zero mean and the identity covariance matrix, unlike PER.	Reply	I-Reply	1
This limitation of DBN can be found in Bilen &amp; Vedaldi (2017) and Deecke et al. (	Reply	O	0
2019) pointing out the inadequacy of normalizing multi-modal distributions by single mean and variance.	Reply	B-Reply	1
To clarify this difference, we added a new figure (Fig.	Reply	I-Reply	1
1) and a new paragraph in P. 2-3 (last paragraph of the section 2) in the revised manuscript.	Reply	I-Reply	1
[line_break_token][line_break_token]-------[line_break_token]Reference[line_break_token][line_break_token]Lei Huang, Dawei Yang, Bo Lang, and Jia Deng.	Reply	O	0
Decorrelated batch normalization.	Reply	O	0
In IEEE Conference on Computer Vision and Pattern Recognition, 2018.	Reply	O	0
[line_break_token]Hakan Bilen and Andrea Vedaldi.	Reply	O	0
Universal representations: The missing link between faces, text, planktons, and cat breeds.	Reply	O	0
arXiv preprint arXiv:1701.07275, 2017.	Reply	O	0
[line_break_token]Lucas Deecke, Iain Murray, and Hakan Bilen.	Reply	O	0
Mode normalization.	Reply	O	0
In International Conference on Learning Representations, 2019.	Reply	O	0
[line_break_token][line_break_token][line_break_token]- Computational cost of PER[line_break_token]Thanks for this great suggestion.	Reply	O	0
As per Reviewer 3 pointed out, PER has non-negligible computational costs in backward pass having O(n d_l s) time complexity while BN has the time complexity of O(n d_l) where b is the size of mini-batch, s is the number of projection, and d_l is the number of hidden units in layer l. In terms of the wall clock running time, a vanilla network, BN, VCL, and PER take 0.071, 0.083, 0.087, and 0.093 seconds for a single forward/backward iteration in 11-layer CNN on a single NVIDIA TITAN X, respectively.	Reply	B-Reply	2
The clarification and comparison of computational costs are added in section 4.3.1 of the revised manuscript.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]- Experiments on larger datasets/models[line_break_token]We appreciate the suggestion from Reviewer 3.	Reply	O	0
As Reviewer 3 suggested, we performed additional experiments on tiny ImageNet (a subset of ImageNet).	Reply	B-Reply	3
It has 2x more training samples, 2x more categories, and 2x bigger image size.	Reply	I-Reply	3
Besides, following the experiment given in VCL, we used 2x more filters in the experiment, i.e., 2x larger model.	Reply	I-Reply	3
As other experiments performed in the original manuscript, we obtained better results than BN, VCL, and a vanilla network, and added the experiment in the revised manuscript.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]- Typos[line_break_token]Thanks for carefully reviewing our manuscript.	Reply	O	0
We modified the typos	Reply	B-Reply	4

This paper tackles the multi-task setting by using modulation connections between three network pipelines, i.e., one bottom-up network to contextualize the problem, one top-bottom network that is conditioned on the tasks, on a last bottom-up network that solves the task.	Review	O	0
[line_break_token]The key contribution of the paper is to introduce a feature-wise and spatial-wise tensor to modulate the different neural pipelines better.	Review	O	0
Finally, they assess the proposed method on three datasets: Multi-MNIST, a yes/no CLEVR, and CUB-200.	Review	O	0
[line_break_token][line_break_token]The abstract, introduction, and related works are pretty clear.	Review	O	0
Figure 1 is also a nice summary that puts the paper architecture in perspective with another approach, and it is a very insightful sketch.	Review	O	0
I appreciate the effort of the authors to release the code with several baselines.	Review	O	0
I also acknowledge the diversity of tasks that are studied.	Review	O	0
[line_break_token][line_break_token]However, I have three concerns that I am willing with the authors.	Review	O	0
[line_break_token][line_break_token]My first concern deals with the method description, which I found a bit misleading.	Review	B-Review	1
Thus, I not sure that I fully got all the subtleties of the proposed method.	Review	I-Review	1
The mathematical notation is misleading: Are Y, and X function of (x,y,ch) or are tensors over x, y, z. Later in the text, W is defined over (ch, t), but it is also mentioned that t is an input.	Review	I-Review	1
Thus, is W \in R^(CxT) or W(t) \in R^(C).	Review	I-Review	1
Besides, the implicit tilling with * makes things even harder to follow.	Review	I-Review	1
On a different side, what do you mean by training the convolution network instead of optimizing W. Is W fixed?	Review	I-Review	1
Do you use simply the feature map after 1x1 conv as mentioned in 4.2?	Review	I-Review	1
How do you embed the task t in general, how do you append it to the feature map of BU1.	Review	I-Review	1
[line_break_token]In the current paper state, I would not be able to reproduce the experiments.	Review	I-Review	1
[line_break_token] [line_break_token]The second concern relies on the results.	Review	O	0
The gap between the methods is tiny, e.g. max 0.5 in 2-MNIST, and may fluctuate a lot from one experiment to another, e.g., it is weird that 3-MNIST is harder than 4-MNIST.	Review	B-Review	2
Note that the same observations can be applied to the CLEVR.	Review	I-Review	2
Therefore, it is hard to assess the method without the std over at least 5 seeds.	Review	I-Review	2
The result only convinces me regarding 4-MNIST without such std.	Review	I-Review	2
[line_break_token][line_break_token]My third concern is about CUB200 experiments.	Review	I-Review	3
The authors used an auxiliary loss on top of TD to help to visualize the network decision.	Review	I-Review	3
As such auxiliary losses provide additional information, I have the following question: did you add the same losses to other baselines?	Review	I-Review	3
Did you use a stop-gradient before decoding the feature-maps?	Review	I-Review	3
Otherwise, the comparison between methods may not be fair[line_break_token][line_break_token][line_break_token]Remarks:[line_break_token] - I am missing some results from external literature.	Review	O	0
For instance, even if I prefer your setting CUB300  over 312 questions, it would have be nice to add such experiments in the appendix. (	Review	B-Review	4
or literature baselines on N-MNIST)[line_break_token] - Please report the original MOO too results in addition to your experiments[line_break_token] - Why ch-mod is missing in 4-CLEVR?	Review	I-Review	4
[line_break_token] - Can you describe how did you pick the CLEVR questions (before/after computing the results)?	Review	I-Review	4
It would have been nice to have experiments that randomly pick K questions (and repeat the process N time + report std), or even dynamically condition on the question at hand.	Review	I-Review	4
[line_break_token] - it took me quite some time to understand the meaning of #P, please make it explicit from the beginning, or add in the caption!	Review	I-Review	4
[line_break_token] - Although releasing the code is good, I also encourage you to put a table in the appendix with the hyper-parameters.	Review	I-Review	4
The paper should be as much self-content as possible.	Review	I-Review	4
It is also hard to evaluate the quality of the training time during the review[line_break_token] - typo: extra parenthesis in Eq 4[line_break_token][line_break_token]In conclusion, the authors give some good intuition about promising methods, but I had some difficulties in understanding all the details of their approaches.	Review	O	0
Besides, I am missing both std and external references to assess the quality of the methods.	Review	O	0
In this current state, I cannot recommend paper acceptance even if I acknowledge several qualities of the paper, but I am open to discussion.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
irst of all, thanks for the helpful review.	Reply	O	0
[line_break_token][line_break_token]We have updated the article and uploaded a revised version based on the reviews,  [line_break_token]Specifically we re-wrote section 3 (Approach).	Reply	B-Reply	1
We find the explanations now clearer.	Reply	I-Reply	1
[line_break_token][line_break_token]One of your major remarks is that it‚Äôs better to assess the quality of the method based on mean+std over several seeds: [line_break_token]We have repeated all our training in the Multi-MNIST experiment 4 more times (to get 5 separate training and evaluation pipeline to every row in the table) and report mean + std, tables 1+2, pages 7-8 in the experiment section).	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the gap between  the 3-MNIST exp and 4-MNIST exp:[line_break_token]Several M-MNIST images are demonstrated in figure 2 in the article.	Reply	O	0
The digits are i.i.d.	Reply	B-Reply	2
between images and between tasks (uncorrelated).	Reply	I-Reply	2
We believe that the gap between the experiments is because the different overlap areas of the digits in those experiments which carry useful information for the classification process.	Reply	I-Reply	2
[line_break_token][line_break_token]You are right that the use of the localization auxiliary loss provides additional information, however:[line_break_token]a.[tab_token]We also run the channel-wise modulation architecture on the CUB200 with the same auxiliary loss (on the top of the BU2 stream).	Reply	I-Reply	3
The results were worse than our architecture.	Reply	I-Reply	3
This experiment is now added to the article, table 4 page 10.	Reply	I-Reply	3
Thank you for arising this point.	Reply	I-Reply	3
[line_break_token]b. Regardless of performance, our goal by using the auxiliary loss was to demonstrate interpretability.	Reply	I-Reply	3
[line_break_token][line_break_token]The ch-mod is now added to the CLEVR experiment.	Reply	I-Reply	3
[line_break_token][line_break_token]The questions in the CLEVR experiment were arbitrarily chosen, simply as it sound.	Reply	I-Reply	3
Your suggestions are correct, but cannot be applied during the review time.	Reply	I-Reply	3
[line_break_token]	Reply	O	0

This paper proposes an efficient method to (differentiably) estimate input-output Jacobian.	Review	O	0
The method is useful for Jacobian regularization.	Review	O	0
The regularization improves robustness and generalization of networks.	Review	O	0
[line_break_token][line_break_token]I tend to vote for rejection.	Review	O	0
There are two concerns.	Review	O	0
1) This paper needs to demonstrate the effectiveness of the input-output Jacobian regularization over the input gradients regularization.	Review	O	0
2) It is doubtful whether the regularizer provides the same benefits mentioned in Experiment 3.1 for other datasets than MNIST.	Review	O	0
[line_break_token][line_break_token]Major comments:[line_break_token]1) This paper needs to demonstrate applications that the regularization of input-output Jacobian is more beneficial than that of input gradients.	Review	O	0
Input gradients regularization has repeatedly appeared in the literature, as the paper mentions.	Review	B-Review	1
For example, [1] regularized input gradients to improve the robustness against adversarial examples.	Review	I-Review	1
The input gradients regularization is computationally more efficient than Varga et al. (	Review	I-Review	1
2017), with which the submitted paper compares the proposed method.	Review	I-Review	1
If input gradients regularization is sufficient, it limits the impact of the submitted paper.	Review	I-Review	1
It is strongly encouraged to demonstrate when and why the input-output Jacobian regularization is preferable.	Review	I-Review	1
[line_break_token]2)  Experimental results on CIFAR10 and ImageNet show accuracy degradation on clean test data.	Review	O	0
It is questionable whether we can reach the same conclusion with the experiments 3.1 on those datasets.	Review	B-Review	2
[line_break_token][line_break_token][1] Andrew Slavin Ross and Finale Doshi-Velez. "	Review	O	0
Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients."	Review	O	0
AAAI 2018[line_break_token][line_break_token]Update =====[line_break_token][line_break_token]Thank you for the authors' response.	Review	O	0
I agree that the regularization of the input-output Jacobian is potentially superior to double back-prop.	Review	O	0
However, as authors are aware of, it needs to be validated experimentally.	Review	B-Review	1
I think this paper should not leave this as a future work, and hence keep the review score.	Review	I-Review	1
hank you for your comments and valuable feedback.	Reply	O	0
We agree that comparison against DoubleBackProp (or the variant by Ross et al.)	Reply	B-Reply	1
would be interesting.	Reply	I-Reply	1
Note, however, that we were inspired by the observation from the 2017 IEEE Security and Privacy paper from Carlini &amp; Wagner which compared a set of potential attacks and found that the strongest attack operated on bare logits instead of softmax values or loss functions (See Table III from their paper and superiority of f_6).	Reply	O	0
As our goal is to enforce robustness against any attack we believe there is value in minimizing the norm of the input-output Jacobian matrix directly instead of minimizing aggregate loss perturbations.	Reply	B-Reply	1
Also note that we do not know a priori which class will be used by adversaries as a fooling target and thus it is best to minimize changes of outputs for all classes.	Reply	I-Reply	1
 Of course, this conjecture needs to be further experimentally validated and we will consider this in future work.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the clean accuracy drop on CIFAR-10 and ImageNet, there is often a fundamental tradeoff between robustness and clean performance which is well documented across the adversarial robustness literature.	Reply	I-Reply	2
In our case, we have the ability to tune the loss weight on the regularizer to choose between more robustness or higher clean performance -- this is demonstrated in Figure S7.	Reply	I-Reply	2
Note that as the Jacobian loss weight is set smaller the resulting model still retains consistently improved robustness over a clean model across multiple attacks, while minimizing the degradation in clean accuracy	Reply	I-Reply	2

The authors here introduces a novel  graph pooling technique called StructPool that uses the underlying graph‚Äôs structural information to behave as a node clustering algorithm and learns a node clustering matrix.	Review	O	0
[line_break_token][line_break_token]Graph level classification requires learning good graph level representation, especially for  aggregating low level information for high .	Review	O	0
Recent work in pooling does not take advantage of important structural information of the relationship between different  nodes.	Review	O	0
Here, the authors formulate  graph pooling as a structured prediction problem, control clique set in the CRFs and use mean filed approximation to calculate assignments.	Review	O	0
[line_break_token][line_break_token]A cluster assignment matrix assigns each node in the original graph to a cluster in the new graph.	Review	O	0
The assignment not only depends on the node features but also on the cluster assignment of the other nodes.	Review	O	0
The authors therefore draw connection with finding the optimal assignment to minimizing the Gibbs energy.	Review	O	0
The authors propose to learn clustering assignment via CRF conditioned on the global feature representation of the nodes.	Review	O	0
[line_break_token][line_break_token]The unary potentials of the cliques are computed used the GCN to measure energy of each node.	Review	O	0
The novelty in accommodating topology information is in using l hop connectivity based on adjacency A to define pairwise cliques thus building pairwise relationship between pairs of nodes thus allowing the Gibbs energy formulation of the cluster assignment thereby using GCN to also compute this pairwise energy.	Review	O	0
[line_break_token][line_break_token]I have  a few questions as below:[line_break_token]I think the authors can better elucidate the motivation for using  the attention matrix over Gaussian kernels to measure pairwise energy in section 3.3; an  empirical experiment for drawing comparison wrt to the computational time and number of feature dimensions on a toy problem seems important.	Review	O	0
[line_break_token]How is the computation  of the unary potential and pairwise energy influenced by the connectivity of the graph G for the datasets considered?	Review	B-Review	3
It would be interesting to see how the pairwise energy, unary energy varies over different layers of GCNs.	Review	I-Review	3
[line_break_token]Further, how is the cluster assignment affected by the l-hop connectivity?	Review	I-Review	3
[line_break_token]Is there a notion of the minimum value of ‚Äòk‚Äô in the context of convergence?	Review	I-Review	4
[line_break_token]What happens in case of very different graph features, or structural assumptions where the cliques are not enforced?	Review	I-Review	5
[line_break_token]Is there a notion of how the method performs on datasets with a high percentage of isomorphism bias: repeating instances or repeating instances with different labels?	Review	I-Review	6
[line_break_token]It will be interesting to see a discussion on how the performance varies with respect to the depth of the overall architecture,  positioning of the structpool and some results on how effective they are on  hierarchical features and multiple pooling ops as in architectures such as Graph UNet.	Review	I-Review	7
[line_break_token]Avoid repetition in 2.2 Related work section and in other sections throughout.	Review	I-Review	1
Otherwise, the paper is rather well written and has clarity.	Review	I-Review	1
hanks for your constructive comments.	Reply	O	0
We have revised our paper and please kindly check it.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We conducted experiments to compare the computational cost for one Gaussian kernel and the attention similarity map.	Reply	B-Reply	2
Given a matrix X containing n examples and each has d dimensional features.	Reply	I-Reply	2
We set and record the computational time for different values for, i.e.. The results are reported as follow.	Reply	I-Reply	2
For each value, we run 1000 times and report the average.	Reply	I-Reply	2
[line_break_token]dimension d   ---- 100      -----     200     -----300   -----400       ------500[line_break_token]Gaussian----------5.84e-4 --   6.62e-4  --6.74e-4   --8.40e-4    --9.57e-4[line_break_token]Attention---------4.89e-5  --   5.15e-5  --5.59e-5   --7.98e-5    --8.68e-5[line_break_token]Overall, employing attention could improve the computational cost significantly.	Reply	I-Reply	2
[line_break_token][line_break_token]2.	Reply	I-Reply	1
The unary energy is directly computed using GCNs from node features, which means the connectivity of G is explicitly incorporated.	Reply	I-Reply	3
In addition, the pairwise is obtained via attention from node features, where we also incorporate the to consider-hop connectivity.	Reply	I-Reply	3
From our experiments, the dense CRF version always leads to very promising performance.	Reply	I-Reply	3
Hence, we believe, generally, increasing can lead to better cluster assignments.	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	I-Reply	7
We conduct experiments to study how different values affect the performance.	Reply	I-Reply	4
We follow the DGCNN paper [1] to select the number of clusters.	Reply	I-Reply	4
Specifically, we use a pooling rate to control.	Reply	I-Reply	4
Then is set to an integer so that of graphs have nodes less than this integer in the current dataset.	Reply	I-Reply	4
As suggested in DGCNN, generally, is a proper choice for bioinformatics datasets and is good for social network datasets.	Reply	I-Reply	4
In addition, we conduct experiments to show the performance w.r.t.	Reply	I-Reply	4
different values.	Reply	I-Reply	4
We set to evaluate the performance on a large-scale social network dataset D&amp;D. The results are reported in Appendix A.4.	Reply	O	0
We observe that the performance drops when is too large or small.	Reply	B-Reply	4
In addition, we expect the model to have competitive performance when is set to a proper range, for example, for dataset D&amp;D.[line_break_token][line_break_token]4.	Reply	O	0
For the case of different graph features and different graph substructures, it depends on how the GNNs learn and make predictions.	Reply	B-Reply	5
It is possible that nodes with different features are clustered in a different way.	Reply	I-Reply	5
For example, for the concept network motifs, the nodes in a network motif can be different, but these nodes are combined together to determine the type of the whole graph.	Reply	I-Reply	5
In MUTAG dataset, network motifs can be carbon rings, NH2, and NO2, and are highly related to the mutagenic property adn can determine graph label.	Reply	I-Reply	5
If the GNNs are trained to make predictions based on network motifs, different nodes in a network motif can be clustered into one cluster.	Reply	I-Reply	5
This is our intuitive thought and we believe GNN interpretation techniques are needed if we wish to fully understand the problem.	Reply	I-Reply	5
[line_break_token][line_break_token]5.	Reply	I-Reply	2
For the case of repeating instances or repeating instances with different labels, it is related to the data quality.	Reply	I-Reply	6
It is a general problem/challenge for all deep models, including our method.	Reply	I-Reply	6
If repeating instances have the same label, it can be understood as the unbalanced data problem.	Reply	I-Reply	6
[line_break_token]We can use data preprocessing, data augmentation, weighted loss, or dropout to train better models.	Reply	I-Reply	6
If the repeating instances are with different labels and data preprocessing cannot solve it, we believe all GNN models will be affected.	Reply	I-Reply	6
[line_break_token][line_break_token]6.	Reply	I-Reply	2
Thanks for the suggestion.	Reply	O	0
We conduct experiments to compare single pooling layer vs multiple pooling layers.	Reply	B-Reply	7
Let‚Äôs define that 1 block contains 2 GCNs and 1 pooling.	Reply	I-Reply	7
Then we compare three different models: 1 block + classifier, 2 blocks + classifier, and 3 blocks + classifier.	Reply	I-Reply	7
We evaluate these three models on a large-scale dataset D&amp;D and a small dataset Proteins.	Reply	O	0
The results are reported in Appendix A.3.	Reply	B-Reply	7
For the dataset Proteins, we observe that the network with one block can obtain better performance than deeper networks.	Reply	I-Reply	7
We believe the main reason is dataset Proteins is a small-scale dataset with an average number of nodes equal to 39.06.	Reply	I-Reply	7
A relatively simpler network is powerful enough to learn its data distribution while stacking multiple GCN layers and pooling layers leads to a serious overfitting problem.	Reply	I-Reply	7
For the dataset D\&amp;D, the network with 2 blocks performs better than the one with 1 block.	Reply	O	0
Since D\&amp;D is relatively large scale, stacking 2 blocks increases the power of the network and hence increases the performance.	Reply	O	0
However, going very deep, e.g., stacking 3 blocks, will cause the overfitting problem.	Reply	B-Reply	7
[line_break_token][line_break_token]7.	Reply	I-Reply	2
Thanks for your suggestion.	Reply	O	0
We rewrote the Section 2.2 to avoid repetition.	Reply	B-Reply	1
[line_break_token][line_break_token][1]. Zhang et al.,	Reply	O	0
An End-to-End Deep Learning Architecture for Graph Classification, AAAI 201	Reply	O	0

Summary:[line_break_token]The paper presents a novel combinatorial search algorithm for the discrete target propagation framework developed in Friesen & Domingos (2018).	Review	O	0
Experiments on small datasets with small models demonstrate some potential for the proposed approach; however, scalability remains a concern.	Review	O	0
[line_break_token][line_break_token]  Pros:[line_break_token]-[tab_token]I like the goal of the work and think that if the targeted problem were to be solved it would be an interesting contribution to the field.	Review	O	0
[line_break_token]-[tab_token]The proposed search algorithm is reasonable and works OK.	Review	O	0
[line_break_token]-[tab_token]The paper is mostly well written and clear.	Review	O	0
[line_break_token]-[tab_token]The experiments are reasonably thorough.	Review	O	0
[line_break_token][line_break_token]  Cons:[line_break_token]-[tab_token]The paper states that it is a feasibility study on search methods for learning hard-threshold networks, however, it only evaluates the feasibility of one combinatorial search method.	Review	O	0
[line_break_token]-[tab_token]It‚Äôs not made clear whether other approaches were also investigated or what the authors learned from their exploration of this approach.	Review	B-Review	20
[line_break_token]-[tab_token]The actual algorithm is not very well explained, despite being the main contribution of the paper.	Review	I-Review	20
[line_break_token]-[tab_token]The datasets and models are small and not necessarily representative of the requirements of the field.	Review	I-Review	20
[line_break_token]-[tab_token]Scalability remains a serious concern with the proposed approach.	Review	I-Review	20
[line_break_token]-[tab_token]It‚Äôs not clear to me that the paper presents a sufficient enough contribution to warrant acceptance.	Review	I-Review	20
[line_break_token][line_break_token]Overall, I like the direction but do not feel that the paper has contributed enough to warrant acceptance.	Review	O	0
The authors should use the experiments they‚Äôve run and also run more experiments in order to fully analyze their method and use this analysis to improve their proposed approach.	Review	O	0
[line_break_token][line_break_token][line_break_token]Questions and comments:[line_break_token][line_break_token]1.	Review	O	0
[tab_token]Did you try alternative local search algorithms or did you just come up with a single approach and evaluate it?	Review	O	0
What did you learn from the experiments and the development of this algorithm that will let you create a better algorithm in the next iteration?	Review	B-Review	1
[line_break_token][line_break_token]2.	Review	O	0
[tab_token]I think that it is unfair to say that ‚Äúit suggests a simpler, independent justification for the performance improvements obtained by their method.	Review	O	0
‚Äù in reference to the work of Friesen & Domingos (2018), given that the straight-through estimator is not well justified to begin with and their work in fact provides a justification for it.	Review	O	0
I do agree that it is important to investigate alternative heuristics and approaches within the discrete target propagation framework, however.	Review	B-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	4
[tab_token]Sections 2 and 3 do not clearly define what L_i is and where it comes from.	Review	I-Review	3
Since these do not normally exist in a deep network they should be clearly defined.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	I-Review	13
[tab_token]‚Äústep 2(b)‚Äù is not well defined in section 3.1.1.	Review	O	0
I assume that this refers to lines 4-8 of Algorithm 1?	Review	B-Review	4
The paper should explain this procedure more clearly in the text.	Review	I-Review	4
Further, I question the locality of this method, as it seems capable of generating any possible target setting as a neighbor, with no guarantee that the generated neighbors are within any particular distance of the uniform random seed candidate.	Review	I-Review	4
Please clarify this.	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	O	0
[tab_token]I believe that a negative sign is missing in the equation for T_i in ‚ÄòGenerating a seed candidate‚Äô.	Review	B-Review	5
For example, in the case where |N| = 1, then T_i = sign(dL/dT_i) would set the targets to attain a higher loss, not lower.	Review	I-Review	5
Further, for |N|=1, this seems to essentially reduce to the heuristic method of Friesen & Domingos (2018).	Review	O	0
[line_break_token][line_break_token]6.	Review	O	0
[tab_token]In the ‚ÄòSetting the probabilities‚Äô section:[line_break_token](a) All uses of sign(h) can be rewritten as h (since h \in {-1, +1}), which would be simpler.	Review	O	0
[line_break_token](b) The paper contradicts itself: it says here ‚Äòflip entries only when sign(dL/dh) = sign(h)‚Äô but Algorithm 1 says ‚Äòflip entries only when sign(dL/dh) !	Review	B-Review	6
= sign(h)‚Äô.	Review	I-Review	6
Which is it?	Review	I-Review	6
[line_break_token](c) What is the value of a_h in the pseudocode? (	Review	I-Review	6
i.e., how is this computed in the experiments)[line_break_token][line_break_token]7.	Review	O	0
[tab_token]In the experiments, the paper says that ‚Äò[this indicates] that the higher dimensionality of the CIFAR-10 data manifold compared to MNIST may play a much larger role in inhibiting the performance of GRLS.‚Äô How could GRLS overcome this?	Review	B-Review	7
Also, I don‚Äôt agree with the claim made in the next sentence ‚Äì there‚Äôs not enough evidence to support this claim as the extra depth of the 4-layer network may also be the contributing factor.	Review	I-Review	7
[line_break_token][line_break_token]8.	Review	O	0
[tab_token]In Table 2, why are some numbers missing?	Review	O	0
The paper should explain what this means in the caption and why it occurs.	Review	B-Review	8
Same for the bolded numbers.	Review	I-Review	8
[line_break_token][line_break_token]9.	Review	O	0
[tab_token]The Loss Weighting, Gradient Guiding, Gradient Seeding, and Criterion Weighting conditions are not clearly defined but need to be to understand the ablation experiments.	Review	O	0
Please define these properly.	Review	B-Review	9
[line_break_token][line_break_token]10.	Review	O	0
[tab_token]The overall structure of the algorithm is not stated.	Review	O	0
Algorithm 1 shows how to compute the targets for one particular layer but how are the targets for all layers computed?	Review	B-Review	10
What is the algorithm that uses Algorithm 1 to set the targets and then set the weights?	Review	I-Review	10
Do you use a recursive approach as in Friesen & Domingos (2018)?	Review	O	0
[line_break_token][line_break_token]11.	Review	O	0
[tab_token]In Figure 2, what dataset is this evaluation performed on?	Review	O	0
It should say in the caption.	Review	B-Review	11
It looks like this is for MNIST, which is a dataset that GRLS performs well on.	Review	I-Review	11
What does this figure look like for CIFAR-10?	Review	I-Review	11
Does increasing the computation for the heuristic improve performance or is it also flat for a harder dataset?	Review	I-Review	11
This might indicate that the initial targets computed are useful but that the local search is not helping.	Review	I-Review	11
It would be helpful to better understand (via more experiments) why this is and use that information to develop a better heuristic.	Review	I-Review	11
[line_break_token][line_break_token]12.	Review	O	0
[tab_token]It would be interesting to see how GRLS performs on other combinatorial search tasks, to see if it is a useful approach beyond this particular problem.	Review	B-Review	12
[line_break_token][line_break_token]13.	Review	O	0
[tab_token]In the third paragraph of Section 4.2, it says ‚ÄòThe results are presented in Table 3.‚Äô I believe this should say Figure 3.	Review	B-Review	13
Also, the ordering of Figure 3 and Table 3 should be swapped to align with the order they are discussed in the text.	Review	I-Review	13
Finally, the caption for Table 3 is insufficiently explanatory, as are most other captions; please make these more informative.	Review	I-Review	13
[line_break_token][line_break_token]14.	Review	O	0
[tab_token]In Section 4.3:[line_break_token](a), the paper refers to Friesen & Domingos (2018) indicating that zero loss is possible if the dataset is separable.	Review	O	0
However, what leads you to believe that these datasets are separable?	Review	B-Review	14
A more accurate comparison would be the loss for a powerful non-binarized baseline network.	Review	I-Review	14
[line_break_token](b) Further, given the standard error of GRLS, it‚Äôs possible that its loss could be substantially higher than that of FTPROP as well.	Review	O	0
It would be interesting to investigate the cases where it does much better and the cases where it does much worse to see if these cases are informative for improving the method.	Review	B-Review	15
[line_break_token][line_break_token]15.	Review	O	0
[tab_token]Why is there no discussion of training time in the experiments?	Review	O	0
While it is not surprising that GRLS is significantly slower, it should not be ignored either.	Review	B-Review	16
The existence of the Appendix should also be mentioned in the main paper with a brief mention of what information can be found in it.	Review	I-Review	16
[line_break_token][line_break_token]16.	Review	O	0
[tab_token]In Algorithm 1, line 2 is confusingly written.	Review	B-Review	17
Also, notationally, it‚Äôs a bit odd to use h both as an element and as an index into T.[line_break_token][line_break_token]17.	Review	O	0
[tab_token]There are a number of capitalization issues in the references.	Review	O	0
[line_break_token][line_break_token]18.	Review	O	0
[tab_token]The Appendix refers to itself (‚Äúadditional hyperparameter details can be found in the appendices‚Äù).	Review	O	0
[line_break_token]	Review	O	0
1.	Reply	O	0
We began with the most basic and general approach to local search for the target setting algorithm, which we present as the ‚Äúnaive‚Äù approach in the paper.	Reply	B-Reply	1
We went through many possible improvements to the method and ultimately presented as GRLS the best alternative we could develop.	Reply	I-Reply	1
In the future we‚Äôll expand on this point in the paper, continue to improve our algorithm (especially to address scalability concerns), and compare with alternative search methods attempted along the way (e.g. a genetic algorithm, and others mentioned by Reviewer #3).	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Perhaps it was unclear, but we did not intend to offer a justification for the straight-through estimator, so much as make it clear where exactly the performance improvements offered by their method originate.	Reply	B-Reply	2
In particular, that their method is ultimately just an improved gradient estimator.	Reply	I-Reply	2
As you mentioned, this serves mainly to motivate the consideration of search methods, rather than going a different direction, and, for example, further improving the gradient estimation approach (although that may still be of interest to others).	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Agreed[line_break_token][line_break_token]4.	Reply	O	0
This is a typo from an earlier iteration of the paper, will be fixed in revision.	Reply	B-Reply	4
With respect to the local nature of the search: when the probability of flipping an entry is low, the expected number of entries in a target vector to be flipped is low and this induces in expectation a local neighborhood around a candidate target vector.	Reply	I-Reply	4
In our experiments we set the flip probabilities to achieve an expectation of about 5% of the target vector flipped.	Reply	I-Reply	4
[line_break_token][line_break_token]6.	Reply	O	0
a) We will make this simplification.	Reply	B-Reply	6
b) this is quite a serious typo.	Reply	I-Reply	6
Algorithm 1 should read ‚Äú=‚Äú, as dictated by the reasoning in the ‚ÄúSetting the probabilities‚Äù section.	Reply	I-Reply	6
[line_break_token][line_break_token]7.	Reply	O	0
We will likely need to address scalability issues of GRLS (as noted by other reviewers) before we can consider how GRLS could overcome this difficulty.	Reply	B-Reply	7
With respect to the claim you mentioned, we offered that claim under the supposition that a search-based method such as GRLS would have more difficulty solving the credit assignment problem at lower layers than FTPROP as the number of layers increases, but you are right that more evidence is needed and this claim could be false.	Reply	I-Reply	7
[line_break_token][line_break_token]8.	Reply	O	0
Missing entries are caused by parameter-experiment combinations that were not tested, but would be included in a revised paper.	Reply	B-Reply	8
Bolded entries indicate the best performing parameter set for the given method on the dataset corresponding to the column the entry lies in.	Reply	I-Reply	8
[line_break_token][line_break_token]9.	Reply	O	0
Indeed we will provide definitions in revisions.	Reply	B-Reply	9
[line_break_token][line_break_token]10.	Reply	I-Reply	11
Algorithm 1 is a proposed alternative to solve the target setting subproblem which occurs at each layer during a single pass of Friesen and Domingos target propagation method.	Reply	I-Reply	10
[line_break_token][line_break_token]11.	Reply	O	0
This was a chart for MNIST.	Reply	B-Reply	11
We will make that clear.	Reply	I-Reply	11
With respect to providing the chart for CIFAR10, our efforts were severely compute-constrained and it would have taken us about 3-4 weeks to generate a comparable chart for CIFAR10.	Reply	I-Reply	11
Surely it is something we can include in the future though.	Reply	I-Reply	11
[line_break_token][line_break_token]12.	Reply	O	0
Quite possibly.	Reply	B-Reply	12
It is outside the scope of this particular paper, but we are actively thinking about other applications.	Reply	I-Reply	12
[line_break_token][line_break_token]13.	Reply	O	0
Yes, we will address these.	Reply	B-Reply	13
[line_break_token][line_break_token]14.	Reply	O	0
a)The datasets are likely not separable.	Reply	O	0
The claim was more to indicate that 0 is the best analytical lower bound we have on the loss.	Reply	B-Reply	14
Indeed the loss on a non-binarized network would provide a better bound.	Reply	I-Reply	14
[line_break_token]b) Yes, we certainly hope to do that in the future.	Reply	O	0
[line_break_token][line_break_token]15.	Reply	O	0
In the appendix we discuss the additional costs to training time of using GRLS.	Reply	B-Reply	16
Perhaps we could afford to specifically measure these during experiments though.	Reply	I-Reply	16
We will make reference to what is contained in the appendices in the main body.	Reply	I-Reply	16
[line_break_token][line_break_token]18.	Reply	O	0
The quoted statement is not false --- but yes, that was a mistake and we will delete that reference.	Reply	B-Reply	19

This paper proposed DSGAN which learns to generate unseen data from seen data distribution p_d and its somehow ‚Äúbroad‚Äù version p_{\hat d} (E.g., p_d convolved with Gaussian).	Review	O	0
The ‚Äúunseen data‚Äù is the one that appears in p_{\hat d} but not in p_d.	Review	O	0
DSGAN is trained to generate such data.	Review	O	0
In particular, it uses samples from p_d as fake data and samples from p_{\hat d} as the real one.	Review	O	0
[line_break_token][line_break_token]Although the idea seems to be interesting, the paper seems to be a bit incremental and is a simple application of existing GAN techniques.	Review	B-Review	1
The paper shows two applications (semi-supervised learning and novelty detection) and it is not clear that the proposed method outperforms existing GAN methods in the classification accuracy in MNIST/SVHN/CIFAR10 (Table 1) and existing sampling methods (Table.	Review	I-Review	1
3).	Review	I-Review	1
It seems that the sampled reconstruction results (Fig.	Review	I-Review	1
8) are not as good as VAE on CIFAR10.	Review	I-Review	1
I would also expect more ablation studies about how to pick p_{\had d}, which seems to be the key of this approach, in MNIST and CIFAR10.	Review	I-Review	1
[line_break_token][line_break_token]In terms of writing, the paper is a bit confusing in terms of motivations and notations.	Review	I-Review	2
[line_break_token][line_break_token]Overall, the method looks incremental and experimental results are mixed on small datasets so I vote for rejection.	Review	O	0
Note that I am not an expert on GAN/VAE so I put low confidence here.	Review	O	0
[tab_token]	Review	O	0
hanks for your comments!	Reply	O	0
First, we have to clarify some misunderstandings.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; it is not clear that the proposed method outperforms existing GAN methods in the classification accuracy in MNIST/SVHN/CIFAR10 (Table 1)[line_break_token][line_break_token]BadGAN has already theoretically proved that complement data are helpful for semi-supervised learning.	Reply	O	0
In this paper, we demonstrate that,  using our unseen data, the proofs in badGAN still can be satisfied but in a more concise way.	Reply	B-Reply	1
Therefore, compared to badGAN that requires extra PixelCNN, DSGAN saves more computational memory and is time-efficienct.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; It seems that the sampled reconstruction results (Fig.	Reply	O	0
8) are not as good as VAE on CIFAR10.	Reply	O	0
[line_break_token][line_break_token]In Novelty detection, we use the reconstruction error as a criterion to determine whether an image comes from seen class or unseen class.	Reply	B-Reply	1
It is expected that images from the seen classes should be reconstructed better than those reconstructed from unseen classes.	Reply	I-Reply	1
However, VAE cannot force the unseen classes with high reconstructed error.	Reply	I-Reply	1
So, we combine DSGAN with VAE to deal with this issue.	Reply	I-Reply	1
Due to the above reason, it is expected that "our sampled reconstruction results are not good as VAE".	Reply	I-Reply	1
Note that the seen class, car, still can be reconstructed well by our method in Fig 8 (at the last row).	Reply	I-Reply	1
The quantitative results in Table 3 further validate our approach.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; I would also expect more ablation studies about how to pick p_{\had d}, which seems to be the key of this approach, in MNIST and CIFAR10.	Reply	O	0
[line_break_token][line_break_token]In fact, how to design depends on applications  instead of datasets, as described in Sec.	Reply	B-Reply	1
4.1 and Sec.	Reply	I-Reply	1
4.2.	Reply	I-Reply	1
Please note that, in Section 5.2.1, we used the same for ALL datasets.	Reply	I-Reply	1
[line_break_token][line_break_token]We also want to clarify the datasets used in our experiments.	Reply	I-Reply	1
In semi-supervised learning, we follow our competitors to conduct experiments on MNIST, SVHN and CIFAR10.	Reply	I-Reply	1
In novelty detection, our method is evaluated on CIFAR10, which is also common in this application.	Reply	I-Reply	1
Furthermore, we also add additional experiments about generating complement data in CelebA, which is a more complex dataset.	Reply	I-Reply	1
We can see from Fig.	Reply	I-Reply	1
10 (Appendix G) that DSGAN can create complement data for complicate images well.	Reply	I-Reply	1

This work first establishes the connection of maximizing the lower bound of accumulated reward and supervised learning on near-optimal policies.	Review	O	0
Then it proposes a general framework for policy learning: during the exploration stage, the agent will collect near-optimal trajectories while in the exploitation stage, the agent will perform supervised learning on the collected data.	Review	O	0
Under this framework, the author argues that the ranking loss could outperform the state-of-the-art on the Atari benchmark.	Review	O	0
[line_break_token][line_break_token]The overall idea is intuitive yet interesting, and the empirical result is quite impressive.	Review	O	0
[line_break_token][line_break_token]Some questions which I think the paper could discuss more:[line_break_token]- In the paper, the near-optimal policy is defined with an absolute threshold, which could be task/environment-specific.	Review	O	0
I am wondering whether the author tried to set the `near-optimal policy` as a relative value (in the current replay buffer).	Review	B-Review	1
Then the hyper-parameter could be shared.	Review	I-Review	1
[line_break_token]- I think some empirical comparisons of the gradient variance (i.e., for Corollary 2) will be more demonstrative, although I could imagine that the near-optimal trajectories will have smaller variance.	Review	O	0
[line_break_token]- The choice of C could be tricky in the method as the whole algorithm is highly depending on it.	Review	O	0
How does the author choose C?	Review	B-Review	3
If C is tuned for each environment, I am not sure whether it is a fair comparison with C51/Rainbow/IQN.	Review	I-Review	3
[line_break_token]- More algorithm training details on the experimental setting (like the hyper-parameters) are needed.	Review	O	0
[line_break_token][line_break_token]======[line_break_token]From eq (7) -&gt; eq (8): Does the Taylor expansion near make sense?	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for his/her review and comments for improving the paper.	Reply	O	0
[line_break_token] [line_break_token]Q1: The choice of trajectory reward threshold C:[line_break_token]C is a task-specific parameter that we choose according to the best performance of state-of-the-art.	Reply	O	0
We strongly agree it would be a meaningful future work to study how to drop C (or using some dynamic strategy) while still maintain a stationary target for off-policy learning that preserves optimality.	Reply	B-Reply	3
However, the usage of C benefits the method in many ways: stable training, unbiasedness, variance reduction.	Reply	I-Reply	3
Additional tuning parameters like C has appeared in many learning approaches, e.g., In entropy regularized RL, the methods can be sensitive to the reward-scale; we also need to tune the extra temperature parameter.	Reply	I-Reply	3
In ridge regression, we need to tune the extra l2 regularization parameter comparing to the linear regression.	Reply	I-Reply	3
We thus believe that, even with C as an additional tuning parameter, it is fair to compare with baselines.	Reply	I-Reply	3
[line_break_token] [line_break_token]Q2: More training details on the experimental setting:[line_break_token]We keep the same hyperparameter setting, network structure as baselines such as batch size 32, update frequency 4, etc.	Reply	O	0
We add sec 9.12 to describe the hyperparameters and more details.	Reply	B-Reply	4
[line_break_token] [line_break_token]Q3: Regarding gradient variance.	Reply	O	0
[line_break_token]Many existing approaches either shape the reward scale (clipping or normalization) and/or clip the gradient norm.	Reply	B-Reply	2
The investigation of the gradient variance of the original algorithm (without these empirical tricks) does not reflect the actual variance they encountered.	Reply	I-Reply	2
The gradient variance of their actual implemented algorithms will be much smaller than the original algorithm.	Reply	I-Reply	2
[line_break_token]In RPG, the trajectory reward is shaped as described in Def 3 and no gradient clipping or other extra trick is needed.	Reply	I-Reply	2
We agree that the investigation of gradient variance is important and it would be an interesting future work while it is not the focus of this work.	Reply	I-Reply	2
[line_break_token] [line_break_token]Q4: From Eq 7 to Eq 8.	Reply	O	0
[line_break_token]We use Taylor expansion to approximate the log(1+e^x) at x = 0.	Reply	B-Reply	5
This approximation would be more accurate if |x| is small.	Reply	I-Reply	5
Since \lambda_ij denotes the relative order of action i and action j, its absolute value is not important.	Reply	I-Reply	5
Therefore we can restrict the range of \lambda_ij to be small.	Reply	I-Reply	5

The authors introduce a new Active Learning setting where instead of querying for a label for a particular example, the oracle offers a partial or weak label.	Review	O	0
This leads to a simpler and more natural way of retrieving this information that can be of use many applications such as image classification.	Review	O	0
[line_break_token][line_break_token]The paper is well-written and very easy to follow.	Review	O	0
The authors first present the overview of the learning scenario and then suggest three sampling strategies based on the existing AL insights (expected information gain, expected remaining classes, expected decrease in classes).	Review	O	0
[line_break_token][line_break_token]As the labels that the algorithm has to then use are partial, they make use of a standard algorithm to learn from partial labels -- namely, minimizing a partial log loss.	Review	B-Review	1
It would be nice to properly reference related methods in the literature in Sec.	Review	I-Review	1
2.1.	Review	I-Review	1
[line_break_token][line_break_token]The way of solving both the learning from partial labels and the sampling strategies are not particularly insightful.	Review	I-Review	2
Also, there is a lack of theoretical guarantees to show value of a partial label as compared to the true label.	Review	I-Review	2
However, as these are not the main points of the paper (introduction of a novel learning setting), I see these as minor concerns.	Review	I-Review	2
[line_break_token][line_break_token]	Review	O	0
We thank the reviewer for their thoughtful feedback and clear recommendation to accept.	Reply	O	0
We were glad to see that you found the paper to be well-articulated and easy to read.	Reply	O	0
[line_break_token][line_break_token]Per your feedback, we will bring up the related work (currently in section 4) and cite it throughout as each prior technical idea is introduced.	Reply	B-Reply	1
Regarding the related work on partial labels are you referring to the three papers we cite later on (Grandvalet & Bengio, 2004; Nguyen & Caruana, 2008; Cour et al.,	Reply	O	0
2011) or others that we missed?	Reply	B-Reply	1
Please let us know if you know of other related references and we‚Äôll be happy to add any missing citations.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that the choice of approaches in this paper is straightforward and meant to emphasize the importance of a novel problem setting as well as compelling experimental results.	Reply	I-Reply	2
We also agree that a great next step for this work would be to establish theoretical guarantees for active learning with partial labels.	Reply	I-Reply	2

The paper describes a method, which learns the hierarchical decomposition of moving objects into parts without supervision, based on prediction of the future.	Review	O	0
A deep neural network is structured into a sequence of encoders and decoders: the input image is decomposed into objects by a trained head, then motion is estimated from predicted convolutional kernels whose model is trained on optical flow; the latent motion output is encoded into separated motion fields for each object and then composed into a global model with a trainable structured matrix which encodes the part hierarchy.	Review	O	0
The latent space is stochastic similar to VAEs and trained with similar losses.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token][line_break_token]The idea is interesting and nicely executed.	Review	O	0
I particularly appreciated the predicted kernels, and the trainable structure matrix.	Review	O	0
Although the field of hierarchical motion segmentation is well studied, up to my knowledge this method seems to be the first of its kind based on a fully end-to-end trainable method where the motion estimators, the decomposition and the motion decoders are learned jointly.	Review	O	0
[line_break_token][line_break_token]The method is evaluated on different datasets including fully synthetic ones with synthetic shapes or based on MNIST; very simple moving humans taken from ATARI games, and realistic humans from two different pose datasets.	Review	O	0
The motion decomposition is certainly not as good as the definition and the output of a state of the art human pose detector; however, given that the decomposition is discovered, the structure looks pretty good.	Review	O	0
[line_break_token][line_break_token]Weaknesses[line_break_token][line_break_token]I have two issues with the paper.	Review	O	0
First of all, although the related work section is rich, the methods based on hierarchical motion decompositions are rarer, although the field is quite large.	Review	O	0
Below are a couple of references:[line_break_token][line_break_token]Mihir Jain, Jan Van Gemert, HerveÃÅ JeÃÅgou, Patrick Bouthemy, and Cees GM Snoek.	Review	O	0
Action localization with tubelets from motion.	Review	O	0
CVPR, 2014.	Review	O	0
[line_break_token][line_break_token]Chenliang Xu and Jason J Corso.	Review	O	0
Evaluation of super-voxel methods for early video processing.	Review	O	0
CVPR, 2012.	Review	O	0
[line_break_token][line_break_token]Jue Wang, Bo Thiesson, Yingqing Xu, and Michael Cohen.	Review	O	0
Image and video segmentation by anisotropic kernel mean shift.	Review	O	0
ECCV, 2004 [line_break_token][line_break_token]Chenliang Xu, Caiming Xiong, and Jason J Corso.	Review	O	0
Streaming hierarchical video segmentation.	Review	O	0
ECCV 2012.	Review	O	0
[line_break_token][line_break_token]Matthias Grundmann, Vivek Kwatra, Mei Han, and Irfan Essa.	Review	O	0
Efficient hierarchical graph-based video segmentation.	Review	O	0
CVPR, 2010.	Review	O	0
[line_break_token][line_break_token]Peter Ochs, Jitendra Malik, and Thomas Brox.	Review	O	0
Segmentation of moving objects by long term video analysis.	Review	O	0
IEEE PAMI, 2014.	Review	O	0
[line_break_token][line_break_token]Discovering motion hierarchies via tree-structured coding of trajectories[line_break_token]Juan-Manuel P√©rez-R√∫a, Tomas Crivelli, Patrick P√©rez, Patrick Bouthemy, BMVC 2016.	Review	O	0
[line_break_token][line_break_token]Samuel J Gershman, Joshua B Tenenbaum, and Frank JaÃàkel.	Review	O	0
Discovering hierarchical motion structure.	Review	O	0
Vision Research, 2015.	Review	O	0
[line_break_token][line_break_token]Secondly, the presentation is not perfect.	Review	B-Review	2
The paper is densely written with lots of information thrown rapidly at the reader.	Review	I-Review	2
Readers familiar with similar work can understand the paper (I needed a second pass).	Review	I-Review	2
But many parts could be better formulated and presented.	Review	I-Review	2
[line_break_token][line_break_token]I understood the equations, but I needed to ignore certain thinks in order to understand them.	Review	I-Review	3
One of them is the superscript in the motion matrices M, which does not make sense to me. ‚	Review	I-Review	3
Äúg‚Äù seems to indicate ‚Äúglobal‚Äù and ‚Äúl‚Äù local, but then again a local parent matrix gets index ‚Äúg‚Äù, and this index seems to switch whether the same node is seen as the current node or the parent of its child.	Review	I-Review	3
[line_break_token][line_break_token]Figure 3 is useful, but it is hard to make the connection with the notation.	Review	I-Review	4
Symbols like z, M etc.	Review	I-Review	4
should be included in the figure.	Review	I-Review	4
[line_break_token][line_break_token]The three lines after equations 2 and 3 should be rewritten.	Review	I-Review	5
They are understandable but clumsy.	Review	I-Review	5
Also, we can guess where the binary constraints come from, but they should be introduced nevertheless.	Review	O	0
[line_break_token][line_break_token]In essence, the paper is understandable with more efforts than there should be necessary.	Review	O	0
[line_break_token][line_break_token][line_break_token]Other remarks:[line_break_token][line_break_token]The loss L_struct is L_2, I don‚Äôt see how it can favor sparsity.	Review	O	0
This should be checked and discussed.	Review	B-Review	6
[line_break_token][line_break_token]A symbolic representation is mentioned in the introduction section.	Review	I-Review	7
I am not sure that this notion is completely undisputed in science, it should at least not be presented as a fact.	Review	I-Review	7
[line_break_token][line_break_token]The ATARI dataset seems to be smallish (a single video and 5000 frames only).	Review	I-Review	8
[line_break_token]	Review	O	0
Thank you very much for the constructive comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	2
Presentation[line_break_token]In the revision, we‚Äôll include a separate paragraph in the related work to discuss hierarchical motion decomposition methods.	Reply	O	0
We‚Äôll revise the method section for a better presentation of the model and the equations.	Reply	B-Reply	2
We‚Äôll also revise sentence about symbolic representation and Figure 3 as suggested.	Reply	I-Reply	2
[line_break_token][line_break_token]2.	Reply	O	0
Structural loss[line_break_token]We apply the structural loss on local motion fields, not on the structural matrix.	Reply	O	0
In this way, the structural loss serves as a regularization, encouraging the motion field to have small values.	Reply	B-Reply	6
This is different from the traditional L1 sparseness loss, which encourages values to be 0.	Reply	I-Reply	6
Following your suggestion, we‚Äôve also experimented with the L1 loss on the shapes dataset, and found that using L1 or L2 structural loss leads to similar results.	Reply	I-Reply	6
We‚Äôll include this discussion into the revision.	Reply	I-Reply	6
[line_break_token][line_break_token]3.	Reply	O	0
Atari dataset[line_break_token]The purpose of the Atari dataset is to demonstrate that our model works well on a different domain and learns to discover interesting structure (the ball belongs to the offensive player).	Reply	O	0
There, as the concepts and structure are relatively simple, we found that 5000 frames are sufficient for our purpose.	Reply	B-Reply	8
[line_break_token][line_break_token]We have also listed all other planned changes in our general response above.	Reply	O	0
Please don‚Äôt hesitate to let us know for any additional comments on the paper or on the planned changes.	Reply	O	0

The paper presents an algorithm to match two distributions with latent variables, named expected information maximization (EIM).	Review	O	0
Specifically, EIM is based on the I-Projection, which basically is equivalent to minimizing the reverse KL divergence (i.e. min KL[p_model || p_data]); to handle latent variables, an upper-bound is derived, which is the corresponding reverse KL divergence in the joint space.	Review	O	0
To minimize that joint reverse KL, a specific procedure is developed, leading to the presented EIM.	Review	O	0
EIM variants for different applications are discussed.	Review	O	0
Fancy robot-related experiments are used to evaluate the presented algorithm.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is in good shape wrt the logic and the writing.	Review	O	0
My main concerns focus on the novelty (compared to existing methods that are similar but not discussed) and the experiments.	Review	B-Review	1
For the former, reverse KL has been exploited before, both in the marginal space [1] and the joint one [2]. Other detailed comments are listed below.	Review	I-Review	1
[line_break_token][line_break_token]As Eq 4 is for matching two joint distributions, discussions/comparisons should be made to reveal the novelty of the presented EIM over existing methods such as [2], etc.	Review	I-Review	1
[line_break_token][line_break_token]In Figure 2 (b), the experimental settings for adversarial learning are not fair, as the discriminator is not fixed there.	Review	I-Review	2
[line_break_token] [line_break_token]In Sec 4.4, it seems EIM is highly overlapped with VIPS.	Review	O	0
So what're the advantages of EIM here?	Review	B-Review	3
[line_break_token][line_break_token]In Figure 3, how many steps for Generator and Discriminator are used for f-GAN?	Review	I-Review	4
Does f-GAN finally converge?	Review	I-Review	4
It would be helpful if some results are given to demonstrate the final state of each method.	Review	I-Review	4
[line_break_token][line_break_token]In Eq.	Review	I-Review	5
9, adding the denominator q(z_i) will change the optimal solution.	Review	I-Review	5
Why only add it to the first term?	Review	I-Review	5
[line_break_token][line_break_token]In Section 5.3 and Figure 5, ‚ÄúSSD‚Äù might be a typo.	Review	I-Review	6
[line_break_token][line_break_token][1] Adversarial Learning of a Sampler Based on an Unnormalized Distribution.	Review	O	0
AISTATS 2018.	Review	O	0
[line_break_token][2] Symmetric Variational Autoencoder and Connections to Adversarial Learning.	Review	O	0
AISTATS 2019.	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewers for their time and valuable feedback.	Reply	O	0
Besides fixing small typos, ambiguities and unclearities we elaborated on the relation and differences to previously existing GAN and VI methods (see in particular section 2).	Reply	B-Reply	7
[line_break_token][line_break_token] Also, we uploaded an implementation of EIM, which can be found at: <a href="https://github.com/eimAuthors/EIM" target="_blank" rel="nofollow">https://github.com/eimAuthors/EIM</a>[line_break_token][line_break_token]We are now going to answer your specific questions:[line_break_token][line_break_token]‚ÄúMy main concerns focus on the novelty‚Äù / ‚ÄúFor the former, reverse KL has been exploited before, both in the marginal space [1] and the joint one [2]. Other detailed comments are listed below.	Reply	O	0
‚Äù / ‚ÄúIn Sec 4.4, it seems EIM is highly overlapped with VIPS.	Reply	O	0
So what're the advantages of EIM here?‚Äù -[line_break_token][line_break_token]Our approach is, to the best of our knowledge, the first approach allowing non-adversarial computation of the I-Projection based solely on samples of the target distribution.	Reply	O	0
[line_break_token][line_break_token]The difference to VIPS and [1]  is that both assume access to the unnormalized (log) density of the target distribution, i.e. are applicable for variational inference.	Reply	B-Reply	1
EIM on the other hand assumes access to samples of the target distribution, i.e. is applicable for density estimation.	Reply	I-Reply	1
[line_break_token][line_break_token]The difference to [1] and [2] is that EIM is not adversarial as pointed out in section 4.3.	Reply	I-Reply	1
[line_break_token][line_break_token]We reworked the related work section to make these important distinctions clearer.	Reply	I-Reply	1
[line_break_token][line_break_token]Furthermore, [2] introduces a bound for the symmetric KL between the joints over x and z (where x is the random variable underlying the target samples and z the latent variable).	Reply	I-Reply	1
The learned discriminator thus needs both x and z as inputs.	Reply	I-Reply	1
In order to infer the latent variable for the target samples an additional variational distribution q(z|x) (i.e. an encoder) needs to be learned.	Reply	I-Reply	1
[line_break_token]EIM does not use the symmetric KL, but the reverse KL.	Reply	I-Reply	1
Furthermore it works with a bound for the KL between the marginals over x, not the joint of x and z. Thus the discriminator only needs to be given x and the latent variable z does not need to be inferred for the training data, i.e., no ‚Äúencoder‚Äù is necessary.	Reply	I-Reply	1
[line_break_token][line_break_token]‚ÄúIn Figure 2 (b), the experimental settings for adversarial learning are not fair, as the discriminator is not fixed there. ‚	Reply	O	0
Äú[line_break_token][line_break_token]The purpose of this figure (and section 4.3 in general) is to provide an illustrative example of the immediate effects and benefits of avoiding the adversarial forumulation [line_break_token][line_break_token]‚ÄúIn Figure 3, how many steps for Generator and Discriminator are used for f-GAN?	Reply	O	0
Does f-GAN finally converge?[...]‚Äù - [line_break_token][line_break_token]Figure 3: As suggested in the f-GAN paper we alternate single generator and discriminator steps.	Reply	O	0
We also evaluated training the discriminator longer without notable changes to the final performance.	Reply	B-Reply	4
The f-GANs do eventually converge and we report the best value achieved on a test set for each run, averaged over 20 runs.	Reply	I-Reply	4
A list of all hyperparameters can be found in the appendix, we added the parameters for the f-GAN training to this.	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúIn Eq.	Reply	O	0
9, adding the denominator q(z_i) will change the optimal solution.	Reply	O	0
Why only add it to the first term?‚Äù -  The notation in this equation was a bit unclear.	Reply	O	0
The denominator is in fact added to both terms, which scales the optimal value but does not change the optimal solution.	Reply	B-Reply	5
We apologize for the unclear notation and adapted the equation to make it clearer.	Reply	I-Reply	5
 [line_break_token][line_break_token]‚ÄúIn Section 5.3 and Figure 5, ‚ÄúSSD‚Äù might be a typo. ‚	Reply	O	0
Äú - Indeed a typo, thanks for pointing it out, we fixed it.	Reply	O	0
[line_break_token][line_break_token]We hope we could clarify and remove some of the remaining doubts in our approach.	Reply	O	0
We invite you to ask additional questions and engage in further discussion if this is not the case.	Reply	O	0

The authors demonstrate that it is possible to transfer across modalities (e.g., image-to-audio) by first abstracting the data with latent generative models and then learning transformations between latent spaces.	Review	O	0
We find that a simple variational autoencoder is able to learn a shared latent space to bridge between two generative models in an unsupervised fashion, and even between different types of models (e.g., variational autoencoder and a generative adversarial network).	Review	O	0
Some detailed comments are listed as follows, [line_break_token]1.	Review	O	0
The technical parts are weak since the authors use the existing method with to some extent evolution.	Review	B-Review	1
[line_break_token][line_break_token]2 The proposed method can transfer the positive knowledge.	Review	O	0
However, for the transfer learning, one concerned and important issue is that some negative knowledge information can be also transferred.	Review	B-Review	2
So how to avoid the negative transferring?	Review	I-Review	2
Some necessary discussions about this should be given in the manuscript.	Review	I-Review	2
[line_break_token][line_break_token]2 There are many grammar errors in the current manuscript.	Review	O	0
The authors are suggested to improve the English writing.	Review	B-Review	3
[line_break_token]	Review	O	0
Thank you for your time and insight in your review.	Reply	O	0
We‚Äôve done our best to address your key points below.	Reply	O	0
[line_break_token][line_break_token]> The technical parts are weak since the authors use the existing method with to some extent evolution.	Reply	O	0
[line_break_token][line_break_token]We would like to highlight that the problem this paper addresses (cross-modal domain transfer) is difficult and, to the best of our knowledge, relatively unexamined in the literature.	Reply	B-Reply	1
We believe it is actually a desirable feature, and not a fault, that the proposed method is fairly straightforward and easy to implement.	Reply	I-Reply	1
From a technical standpoint, the main contribution is not a single new model with which to perform domain transfer, but showing it is possible to ‚Äúglue together‚Äù the plethora of existing (and yet to be invented) models with small, simple, and efficient bridging models.	Reply	I-Reply	1
While we have limited ourselves to several easily quantifiable problems for this paper, nothing about the proposed methods is limited to these models or datasets.	Reply	I-Reply	1
[line_break_token][line_break_token]> The proposed method can transfer the positive knowledge.	Reply	O	0
However, for the transfer learning, one concerned and important issue is that some negative knowledge information can be also transferred.	Reply	O	0
So how to avoid the negative transferring?	Reply	O	0
Some necessary discussions about this should be given in the manuscript.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Thank you for the suggestion.	Reply	B-Reply	2
Transfer learning does indeed share some surface similarities to the proposed work in that it uses pretrained networks.	Reply	I-Reply	2
We would like to highlight, however, that transfer learning is actually quite distinct from domain transfer in that the pretrained networks are used as feature extractors for a new task, while in this work the pretrained networks are used for the same task on which they were trained (generating samples from a given distribution).	Reply	I-Reply	2
Since no information is passing between the pretrained networks, the features learned in one domain are not informing the solution of generation in the other domain.	Reply	I-Reply	2
[line_break_token][line_break_token]> There are many grammar errors in the current manuscript.	Reply	O	0
The authors are suggested to improve the English writing.	Reply	O	0
[line_break_token][line_break_token][line_break_token]We agree with your assessment and apologize for the rushed condition of the initial submission.	Reply	B-Reply	3
You will hopefully find that the updated draft has been extensively revised and restructured to improve the clarity of the writing and the arguments.	Reply	I-Reply	3

Summary:[line_break_token]This paper focuses on lossless source compression with bits back coding for hierarchical fully convolutional VAEs.	Review	O	0
The focus/contribution is three-fold: 1.	Review	O	0
Improve the compression rate performance by adapting the discretization of latent space required for the entropy coder ANS.	Review	O	0
The newly proposed discretization scheme allows for a dependency structure that is not restricted to a Markov chain structure in the encoder model q(z|x) and in the generative part of the model p(x,z).	Review	O	0
This is in contrast with bit-swap[1], which requires a markov chain structure.	Review	O	0
The dependency structure that is allowed in the proposed method is widely known to perform better than a markov chain structure, which can explain why it improves significantly over Bit-swap [1] (another hierarchical VAE compression algorithm that uses bits back coding.)	Review	O	0
2.	Review	B-Review	1
Increasing compression speed by implementing a vectorized version of ANS, and heaving an ANS head in the shape of a pair of arrays matching that of the latent variable and the observed variable.	Review	O	0
The latter allows for simultaneous encoding of the latent with the prior distribution and the image with the decoder distribution.	Review	O	0
3.	Review	B-Review	6
Showing that a model trained on a low-resolution imagenet 32 dataset can generalize its compression capabilities to higher resolution datasets with convincing results.	Review	O	0
[line_break_token][line_break_token]Decision: Accept.	Review	O	0
[line_break_token]This paper is clearly written, makes clear claims and supports these claims with convincing experiments.	Review	O	0
The contributions are of practical use and I expect future work to benefit from this paper.	Review	O	0
[line_break_token][line_break_token][line_break_token]Supporting arguments for decision:[line_break_token]The paper is well motivated; off the shelf compression algorithms such as PNG are also not trained on every dataset separately, and cross-dataset generalization is important if this model should be used in practice for many different images from different datasets and of different resolutions.	Review	O	0
 [line_break_token][line_break_token]The paper clearly supports the main claims.	Review	O	0
It improves upon the previous bits-back coding-based hierarchical VAE [1]. The only hypothesis that is not checked is the one that hypothesizes that the lower bpd for higher resolution images is due to the lower ratio of edge pixels versus non-edge pixels, but this is not a dealbreaker from my point of view.	Review	O	0
[line_break_token][line_break_token]I would like the authors to revise their statement of state of the art compression performance on page 7 directly below table 2. ‚	Review	B-Review	1
ÄúThe fact that HiLLoC achieves state of the art compression rates relative to the baselines even under a change of distribution is striking, and provides strong evidence of its efficacy as a general method for lossless compression of natural images‚Äù.	Review	I-Review	1
This is sentence should be made more nuanced as the proposed model only improves on Bit-Swap, but is still significantly outperformed by Local bits back coding (LBB [2]), and in the case of cifar-10 also by integer discrete flows (IDF [3]).	Review	I-Review	1
On the other hand, it would be useful to still state that LBB is trained on every dataset separately, as well as IDF.	Review	I-Review	1
Note also that in [3], a model that is trained on Imagenet32 and evaluated on the other datasets is also reported (see table 1 in [3]).	Review	I-Review	1
It would be beneficial for the author to include the scores of this model, as the proposed method seems to perform slightly better at generalizing to new datasets.	Review	I-Review	1
[line_break_token][line_break_token]Because of the buffer of initial bits required by bit-back coding, the compression/decompression of several data points has to be sequential if one wants to amortize this cost over several data points.	Review	I-Review	2
Compression methods that don‚Äôt rely on bits-back coding, such as IDF [3], do not have this issue and can compress/decompress data points in parallel.	Review	I-Review	2
Since this influences the practical usability of the model, it would be transparent to mention this.	Review	I-Review	2
[line_break_token][line_break_token]My final main question is on the equivalence of evaluation methods of Bit-Swap and Hilloc on imagenet.	Review	I-Review	3
The Bit-Swap paper states: ‚ÄúFor MNIST, CIFAR-10 and Imagenet (32 √ó 32) we report the bitrates, shown in Table 5, as a result of compressing 100 datapoints in sequence (averaged over 100 experiments)...‚Äù.	Review	I-Review	3
This means that Bit-Swap is not evaluated on the full test set of Imagenet 32 (as this contains 50000 images), as opposed to Hilloc.	Review	I-Review	3
Do the authors think this is a problem?	Review	I-Review	3
[line_break_token]Furthermore, in the case of ‚Äúfull‚Äù Imagenet, Bit-swap uses a subset of 100 images for evaluation and crops them to a multiple of 32 pixels in height and width, so that bit-swap can compress patches and the result is the average of patches for on image.	Review	I-Review	4
Hilloc appears to take 500 random images and does not state anything about cropping.	Review	I-Review	4
Could the authors comment on this?	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]Additional feedback to improve paper (not part of decision assessment):[line_break_token]- In the introduction, first paragraph: ‚Äú the method can achieve an expected message length equal to the variational free energy, often referred to as the evidence lower bound (ELBO) of the model. ‚	Review	O	0
Äú ‚Üí ‚Äú the method can achieve an expected message length equal to the variational free energy, often referred to as the negative evidence lower bound (ELBO) of the model. ‚	Review	B-Review	5
Äú[line_break_token]- Section 3.2, last paragraph: It is not clear if in practice the latent and image are actually encoded in parallel as the author states that this is ‚Äúin theory‚Äù possible.	Review	O	0
[line_break_token]- Page 4: ‚Äú... we found that most of the compute time for our compression was spent in neural net inference, ‚Ä¶‚Äù I assume you mean ‚Äúinference‚Äù in any part of the encoder or decoder, and not specifically approximate inference of the encoder network.	Review	O	0
Perhaps clarify this to avoid confusion?	Review	B-Review	7
[line_break_token]- Section 4: When referring to the ResnetVAE by Kingma et al, it would be appropriate to also cite [4], as this is very similar to resnetVAE‚Äôs and was released earlier.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token][1] F. H. Kingma, P. Abbeel, and J. Ho.	Review	O	0
Bit-Swap: recursive bits-back coding for lossless compression with hierarchical latent variables.	Review	O	0
In International Conference on Machine Learning (ICML), 2019.	Review	O	0
[line_break_token][2] Jonathan Ho, Evan Lohn, and Pieter Abbeel.	Review	O	0
Compression with Flows via Local Bits-Back Coding.	Review	O	0
arXiv e-prints, 2019.	Review	O	0
[line_break_token][3] Emiel Hoogeboom, Jorn W. T. Peters, Rianne van den Berg, and Max Welling.	Review	O	0
Integer Discrete Flows and Lossless Compression.	Review	O	0
arXiv e-prints, 2019.	Review	O	0
[line_break_token][4] C. K. S√∏nderby, T. Raiko, L. Maal√∏e, S. K. S√∏nderby, and O. Winther.	Review	O	0
Ladder variational autoencoders.	Review	O	0
In Advances in Neural Information Processing Systems (NIPS), 2016.	Review	O	0
[line_break_token]	Review	O	0
hank you for your review.	Reply	O	0
To address the points you raised:[line_break_token][line_break_token]&gt;I would like the authors to revise their statement of state of the art compression performance on page 7 directly below table 2. ...	Reply	O	0
It would be beneficial for the author to include the scores of [IDF generalization].[line_break_token][line_break_token]We have revised the statement below Table 2 to more accurately reflect the data in the table.	Reply	O	0
We have also added the results for IDF generalization to the table.	Reply	B-Reply	1
[line_break_token][line_break_token]&gt;Because of the buffer of initial bits required by bit-back coding, the compression/decompression of several data points has to be sequential if one wants to amortize this cost over several data points.	Reply	O	0
Compression methods that don‚Äôt rely on bits-back coding, such as IDF [3], do not have this issue and can compress/decompress data points in parallel.	Reply	O	0
Since this influences the practical usability of the model, it would be transparent to mention this.	Reply	O	0
[line_break_token][line_break_token]We have added mention of these models to the last paragraph of the Discussion section, where we felt this point fitted.	Reply	B-Reply	2
[line_break_token][line_break_token]&gt;My final main question is on the equivalence of evaluation methods of Bit-Swap and Hilloc on imagenet.	Reply	O	0
The Bit-Swap paper states: ‚ÄúFor MNIST, CIFAR-10 and Imagenet (32 √ó 32) we report the bitrates, shown in Table 5, as a result of compressing 100 datapoints in sequence (averaged over 100 experiments)...‚Äù.	Reply	O	0
This means that Bit-Swap is not evaluated on the full test set of Imagenet 32 (as this contains 50000 images), as opposed to Hilloc.	Reply	O	0
Do the authors think this is a problem?	Reply	O	0
[line_break_token][line_break_token]This implies that the Bit-Swap results may be noisier than ours.	Reply	B-Reply	3
They also give ‚Äòaverage net bitrate‚Äô values in tables 2-4, which are close to the values in their table 5.	Reply	I-Reply	3
We presume that the error bounds that they give are 2 standard deviations, from the empirical distribution of the ‚Äò100 experiments‚Äô they ran.	Reply	I-Reply	3
We think it‚Äôs likely that the figures they give are accurate enough to reasonably compare to ours.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt;Furthermore, in the case of ‚Äúfull‚Äù Imagenet, Bit-swap uses a subset of 100 images for evaluation and crops them to a multiple of 32 pixels in height and width, so that bit-swap can compress patches and the result is the average of patches for on image.	Reply	O	0
Hilloc appears to take 500 random images and does not state anything about cropping.	Reply	O	0
Could the authors comment on this?	Reply	O	0
[line_break_token][line_break_token]We have updated our results after benchmarking on a larger subset of 2000 (not 500) images, and have updated the paper to reflect this.	Reply	B-Reply	4
The Bit-Swap result here may be affected by noise due to the smaller scale of their experiment, however again we have assumed that it is accurate enough for comparison.	Reply	I-Reply	4
The BitSwap images are indeed cropped so that the side lengths are multiples of 32.	Reply	I-Reply	4
For HiLLoC this was not necessary.	Reply	I-Reply	4
We think the comparison still makes sense even with this slight difference, and we have added a footnote to explain the difference between our full size ImageNet experiment and the one in Bit-Swap	Reply	I-Reply	4

This paper performs a regret analysis for a new hierarchical reinforcement learning (HRL) algorithm that claims an exponential improvement over applying a naive RL approach to the same problem.	Review	O	0
The proposed algorithm and the regret analysis performed seem rigorous and well-thought out.	Review	O	0
[line_break_token][line_break_token]However, I think that this paper should be rejected because (1) the algorithm does not appear to be a substantial improvement over existing algorithms, (2) the paper makes strong claims about an exponential improvement over standard RL, but doesn't provide a strong benchmark to compare to, and (3) the paper is imprecise and unpolished, with many grammatical errors.	Review	O	0
[line_break_token][line_break_token]I would be open to reconsidering my score if a) the authors submit a revised version with significantly cleaned up text, and b) if the authors could provide more information about how their contribution compares to the existing literature.	Review	O	0
[line_break_token][line_break_token]Main argument [line_break_token][line_break_token]The paper would benefit from establishing stronger context for the central contributions of their paper.	Review	O	0
For instance, the paper begins by contrasting HRL approaches with a number of standard RL algorithms, saying that approaches such as AlphaGo do not require high-level planning.	Review	B-Review	1
This seems surprising; many RL researchers would describe MCTS (the base of the AlphaGo algorithm) as performing planning.	Review	I-Review	1
It would be great if the authors could go into more detail as to what they view as planning, and why AlphaGo does not do so.	Review	I-Review	1
[line_break_token][line_break_token]Additionally, the main comparison the authors seem to make is between HRL and naive RL, which does not provide sufficient context to properly analyse their algorithm.	Review	I-Review	2
Many algorithms are better than applying a classical RL algorithm naively.	Review	I-Review	2
As such, it is not sufficient to show that the algorithm proposed by the authors is stronger than a naive approach; it would be better to compare the algorithm to either a) the state of the art (SOTA) approach, or b) a more credible approach than the naive one.	Review	I-Review	2
Experimental evidence would help.	Review	I-Review	2
[line_break_token][line_break_token]One point of comparison is Fruit et al. (	Review	I-Review	2
2017), which is mentioned as another paper which carries out a regret analysis in a HRL setting.	Review	I-Review	2
Fruit et al. (	Review	I-Review	2
2017) contains a number of simple numerical simulations; a similar effort here would help.	Review	I-Review	2
[line_break_token][line_break_token]Another issue is that the paper is confusing, with systematic grammar errors and typos.	Review	I-Review	3
The paper would benefit significantly with some copy-editing/proofreading by a native English speaker.	Review	I-Review	3
For instance, the title should (presumably) read "Provable Benefits of Deep Hierarchical RL."	Review	I-Review	3
Such errors appear throughout the paper.	Review	I-Review	3
Fixing them would make the paper much easier to understand.	Review	I-Review	3
[line_break_token][line_break_token]Finally, although this did not factor into the score I awarded the paper, the terminology used by the authors is confusing, referring to their setting as "Deep Hierarchical Reinforcement Learning." "	Review	I-Review	4
Deep Reinforcement Learning" is a widely used term in industry, referring to algorithms that apply Deep Learning to RL problems, such as AlphaGo or DeepStack.	Review	I-Review	4
I would encourage the authors to use a different term to describe the setting.	Review	I-Review	4
[line_break_token][line_break_token]Questions to the authors: [line_break_token][line_break_token]1) In what way is AlphaGo not doing planning?	Review	O	0
What is an example of an algorithm that does planning in a standard RL setting?	Review	B-Review	5
e.g. what would planning look like in Go?	Review	I-Review	5
[line_break_token]2) Did you run any experiments/simulations of your work?	Review	O	0
If not, why not?	Review	B-Review	6
[line_break_token]3) Can you elaborate on what a classical RL algorithm would look like that would serve as a proper benchmark to this algorithm?	Review	O	0
[line_break_token]4) In your mind, what is the SOTA algorithm for your setting?	Review	O	0
[line_break_token]5) What are some simple domains that your algorithm would apply to?	Review	O	0
[line_break_token][line_break_token][0]: Moravƒç√≠k, Matej &amp; Schmid, Martin &amp; Burch, Neil &amp; Lis√Ω, Viliam &amp; Morrill, Dustin &amp; Bard, Nolan &amp; Davis, Trevor &amp; Waugh, Kevin &amp; Johanson, Michael &amp; Bowling, Michael. (	Review	O	0
2017).	Review	O	0
DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker.	Review	O	0
Science.	Review	O	0
356.	Review	O	0
10.1126/science.aam6960.	Review	O	0
hank you for the questions and suggestions.	Reply	O	0
[line_break_token]We want to emphasize that our goal is to formalize the deep hierarchical reinforcement learning problem and give a provably efficient algorithm for this setting.	Reply	B-Reply	2
The main focus is theoretical, and we do not claim to beat any SOTA algorithm.	Reply	I-Reply	2

This paper describes a new op: Inner Average Ensemble (IAE).	Review	O	0
This op is constructed by convolution ops followed by an averaging op.	Review	O	0
The author claims using this IAE op is able to improve CNN classification performance.	Review	O	0
The experiments include MNIST and CIFAR-10 with a few network structures.	Review	O	0
[line_break_token][line_break_token]First of all, this new proposed op is not efficient.	Review	B-Review	1
Replace a traditional conv layer with one IAE layer it will introduce times more parameters, while, the performance gain from the authors‚Äô experiment is relatively small, which indicates, most learning capacity is wasted.	Review	I-Review	1
[line_break_token][line_break_token]Secondly, only MNIST and CIFAR-10 is not convincing that this structure change will be widely useful.	Review	I-Review	2
[line_break_token][line_break_token]Thirdly, this work is not practical to apply on real tasks, because it introduced times more computation.	Review	I-Review	3
[line_break_token][line_break_token]Overall, I am not convinced this structure change meets innovation standard.	Review	I-Review	4
[line_break_token][line_break_token]	Review	O	0
We want to thank the reviewer for his review and dedicating time for our work.	Reply	O	0
[line_break_token][line_break_token]> Regards first and second point[line_break_token][line_break_token]For the first and second point we updated our work with extra experiments including CIFAR-10 + and CIFAR-100 + on state of the art methods models like WideResNet and ResNeXt.	Reply	O	0
We show that by adapting IEA into these models, WideResNet trained on CIFAR-100+ is able to improve from 18.85 to 18.03 error rate and with ensemble of IEA models we achieve an error rate of 15.84.	Reply	B-Reply	1
Also, in ResNeXt IEA  trained on CIFAR-100+ achieveses a performance of 17.44 which on par with the mean of 10 runs in their paper valued at 17.44 error rate and when we ensemble IEAs we obtain an error rate of 16.44.	Reply	I-Reply	1
Similar performance weer shown on CIFAR-10.	Reply	I-Reply	1
Please note that we also re-trained normal WideResNet and ResNeXt following each work settings and we obtained a less results than what was in the papers.	Reply	I-Reply	1
Yet, same configurations were used to train the IEA version of these two models and we achieved the aforementioned results.	Reply	I-Reply	1
[line_break_token][line_break_token]> Regards the third point [line_break_token][line_break_token]We understand your concern regards increasing the parameters size times, we highlighted this in our paper and we follow the same lead of MaxOut and other deep models that expands in depth and width and with the current advancements of GPUs and parallelization, computational time is no longer a bottleneck.	Reply	O	0
Also, we computed the inference time of our model for example WideResNet-IEA inference time on GTX1080Ti is 2.36 ms which is on par with a regular DenseNet model on the same GPU with inference time of 2.09 ms.	Reply	B-Reply	3
We also added in our paper the inference time of each model.	Reply	I-Reply	3
[line_break_token][line_break_token]> Conclusion[line_break_token][line_break_token]We hope that our update regards the performance enhancement of our model and the study of inference time accompanied with the unique features generated from the usage of IEA which is shown in the visualization section meets the innovation standard and shows the feasibility of this method.	Reply	O	0
[line_break_token][line_break_token]	Reply	O	0

----I acknowledge that the authors have made improvements to the paper and have increased my score to 6[line_break_token][line_break_token]This is still definitely not my area of expertise and so I am leaving my confidence score low.	Review	O	0
[line_break_token]---[line_break_token][line_break_token]The paper presents an algorithm EDDI that uses a	Review	O	0
Thank reviewer 1 for appreciating and application and the positive results.	Reply	O	0
We have replied the concerns to clarify possible misunderstandings and updated the paper accordingly.	Reply	O	0
The original review is indented using >.	Reply	O	0
[line_break_token][line_break_token]> Review: The paper presents an algorithm EDDI that uses a a partial VAE and does active [line_break_token]> feature selection.	Reply	O	0
The authors show quite a bit of experiments that seem to indicate the [line_break_token]> approach gives positive results.	Reply	O	0
 However, since this is not my main area of expertise I do [line_break_token]> not know if these tasks are standard evaluation for this task.	Reply	O	0
[line_break_token][line_break_token]> For instance in Section 4.3, 4.4 why don't the authors plot accuracy as a function of            [line_break_token]> steps/number of variables observed.	Reply	O	0
That would seem much more useful than log [line_break_token]> likelihood.	Reply	O	0
[line_break_token][line_break_token]Apart from existing results, we have reported test RMSE as suggested in the Appendix.	Reply	O	0
B.2.5 for all UCI experiments in the revised version of the paper.	Reply	O	0
Accuracy in terms of RMSE is consistent with the reported result using predictive log likelihood.	Reply	O	0
Additionally, we would like to clarify that, log likelihood is the common standard when evaluating the performance related to generative models [1,2]. Compared with accuracy metric such as RMSE, log likelihood also account for model uncertainties (of the posterior on latent variable, z), which is very crucial in the practical application of active variable learning.	Reply	O	0
[line_break_token][line_break_token]Reference:[line_break_token][1] Kingma, Diederik P., and Max Welling. "	Reply	O	0
Auto-encoding variational Bayes."	Reply	O	0
arXiv preprint arXiv:1312.6114 (2013).	Reply	O	0
[line_break_token][2] Gregor, Karol, et al. "	Reply	O	0
Draw: A recurrent neural network for image generation."	Reply	O	0
arXiv preprint arXiv:1502.04623 (2015).	Reply	O	0
[line_break_token][3] Kingma, Diederik P., and Prafulla Dhariwal. "	Reply	O	0
Glow: Generative flow with invertible 1x1 convolutions."	Reply	O	0
arXiv preprint arXiv:1807.03039 (2018).	Reply	O	0
[line_break_token][line_break_token]> In general, I found the methodology in the paper to be difficult to understand and not enough background was given.	Reply	O	0
[line_break_token]> I think the paper would be clearer if it was more self-contained.	Reply	O	0
[line_break_token][line_break_token]> For instance, I found much of Section 3 to not have enough background.	Reply	O	0
The authors use [line_break_token]> lots of terminology around VAEs but don't give enough rigorous background so the paper [line_break_token]> doesn't feel self contained.	Reply	O	0
[line_break_token][line_break_token]> The same is true regarding "amortized inference" which I also feel isn't rigorously defined [line_break_token]> anywhere but often discussed.	Reply	O	0
[line_break_token][line_break_token]Thanks for your comment.	Reply	O	0
We have revised the paper and added a paragraph ‚ÄúVAE and amortized inference‚Äù in section 3.2 which is a brief, self-contained introduction to VAEs and amortized inference.	Reply	O	0
[line_break_token][line_break_token]> The task for Section 4.1 (image inpainting) is not quite defined.	Reply	O	0
[line_break_token][line_break_token]We have added a short description in 4.1 to make the task more clarified and well-defined.	Reply	O	0

This paper's contribution is a method for automatically growing the depth of a neural network during training.	Review	O	0
It compares several heuristics that may be used to successfully achieve this goal and identifies a set of choices that work well together on multiple datasets.	Review	O	0
[line_break_token][line_break_token]The paper focuses on CNNs that conform to a popular design pattern where the network is organized into a series of sub-networks, each consisting of a series of sub-modules (sometimes called blocks) operating at the same resolution.	Review	O	0
To be precise, the proposed method aims to learn the length of each series of sub-modules.	Review	O	0
A main contribution of the paper is the demonstration that it is not necessary to train a network until convergence before adding new sub-modules as proposed in past work.	Review	O	0
Instead, it is better to grow the network after training for a short while.	Review	O	0
[line_break_token][line_break_token]My current decision for this paper is a weak rejection due to the points below.	Review	O	0
However, I am open to revising my opinion if these points are addressed satisfactorily.	Review	O	0
[line_break_token][line_break_token]- The growing strategy identified in the paper as a superior alternative seems to be already known and used, at least in the speech recognition community.	Review	O	0
Seide et al. (	Review	B-Review	1
2011) called it Discriminative Pre-training, and showed that it outperforms greedy layer-wise pretraining and DBN pre-training.	Review	I-Review	1
Zeyer et al. (	Review	I-Review	1
2017) reported that a similar method also enables the training of very deep LSTM networks which is otherwise notoriously hard.	Review	I-Review	1
In general, the existence of prior work with the same ideas does not preclude acceptance, but the existence of this work needs to be clearly stated early on and the additional value of the current study sufficiently clarified.	Review	I-Review	1
[line_break_token][line_break_token]- I find it strange that the final networks found by the proposed method usually have the same/similar number of sub-modules per sub-network (Tables 4,5,6) on multiple datasets.	Review	O	0
The only exceptions appear to be Basic4ResNet/CIFAR100 in Table 6 and about 50% of ImageNet results in Table 7.	Review	B-Review	2
This regularity suggests that either A) the proposed algorithm prefers to set same number of sub-modules per sub-network due to its design, or B) datasets except ImageNet have an inherent shared property that produces this result.	Review	I-Review	2
Since option A suggests a bias in the algorithm, this peculiarity of the results needs to be investigated or explained further.	Review	I-Review	2
[line_break_token][line_break_token]- Figure 3 constitutes the main evidence that Autogrow finds approximately optimal depths as compared to manual searching, but it is not clear how the plot for baselines is obtained.	Review	O	0
For any given parameter budget, there are multiple baseline networks possible since the sub-networks can have different number of sub-modules (see previous point).	Review	B-Review	3
This does not appear to be accounted for in Figure 3.	Review	I-Review	3
Further, when dealing with CNNs, it would be more useful to have computation budget on the x-axis instead of the parameter budget.	Review	I-Review	3
This would better account for the difference between increasing depth in an earlier sub-network vs. a later one.	Review	I-Review	3
[line_break_token][line_break_token]- The reported results appear to be for single trials throughout the paper.	Review	O	0
This does not seem sufficient especially for results in Tables 2 and 3 where many differences are rather small, and so drawing conclusions from these tables would be unscientific.	Review	B-Review	4
[line_break_token][line_break_token]References:[line_break_token][line_break_token]Seide, Frank, et al. "	Review	O	0
Feature engineering in context-dependent deep neural networks for conversational speech transcription."	Review	O	0
2011 IEEE Workshop on Automatic Speech Recognition &amp; Understanding.	Review	O	0
IEEE, 2011.	Review	O	0
<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/FeatureEngineeringInCD-DNN-ASRU2011-pub.pdf" target="_blank" rel="nofollow">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/FeatureEngineeringInCD-DNN-ASRU2011-pub.pdf</a>[line_break_token][line_break_token]Zeyer, Albert, et al. "	Review	O	0
A comprehensive study of deep bidirectional LSTM RNNs for acoustic modeling in speech recognition."	Review	O	0
2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).	Review	O	0
IEEE, 2017.	Review	O	0
<a href="https://arxiv.org/abs/1606.06871" target="_blank" rel="nofollow">https://arxiv.org/abs/1606.06871</a>[line_break_token][line_break_token]Update after rebuttal[line_break_token]-----------------------------[line_break_token]I'm sympathetic to the unfortunate situation that the authors are in, since the underlying growing strategy has already been covered by prior work.	Review	O	0
As I mentioned earlier, a sufficient rewrite of the paper can clearly state what has been done already so as not to take credit from the earlier authors.	Review	B-Review	1
A revised version of the paper has not been uploaded; I suggest that the authors do so for the future.	Review	I-Review	1
[line_break_token][line_break_token]I agree that the focus of this paper is learning the 'optimal' depth by using the growing strategy.	Review	I-Review	2
But I am not convinced that the technique indeed finds optimal depths based on the regularity of the sub-network depths mentioned in my review.	Review	I-Review	2
The rebuttal suggests reasons for the obtained regularity, but does not prove that these regular structures obtained are indeed optimal and not an artifact of the algorithm itself.	Review	I-Review	2
The baselines are also using the same regular architectures, which distorts the overall picture because it is possible that a non-regular architecture provides a better trade-off.	Review	I-Review	2
[line_break_token][line_break_token]While my rating doesn't change, I do think that the work is in an interesting direction.	Review	O	0
My final suggestions for the future are:[line_break_token]- Investigate where non-regular architectures (unequal sub-network depths) are in the trade-off between accuracy, flops and parameters.	Review	O	0
[line_break_token]- Investigate whether the proposed algorithm can be modified to easily find non-regular architectures if they can yield equally good performance as regular ones at similar or lower cost.	Review	O	0
[line_break_token]	Review	O	0
hanks for reviewing.	Reply	O	0
[line_break_token][line_break_token]Responses to each item:[line_break_token]- Thanks for pointing us to more related works.	Reply	O	0
We will include them in this paper ASAP.	Reply	B-Reply	1
The similar research in speech recognition community proves that our approach can be generic to other domains, and our research also indicates that their approaches can potentially generalize to computer vision domain.	Reply	I-Reply	1
We quite appreciate similar discoveries of "(1) stopping very early by going through the data only once and (2) using large learning rate" in that paper.	Reply	I-Reply	1
The major difference in this paper is that we are using AutoGrow to find an optimal depth, instead of enabling training deeper networks, which were hard to train but are easily now because of many recent advances such as weight initialization, batch normalization, shortcut paths, just to name a few.	Reply	I-Reply	1
[line_break_token][line_break_token]- We believe that the "regularity" could be because of both.	Reply	O	0
We believe that this is because of the nature of a periodic growing with a short interval and because of the small size of dataset.	Reply	B-Reply	2
AutoGrow will only stop when the whole network saturates in that case.	Reply	I-Reply	2
While in ImageNet, the dataset is larger, therefore, the "regularity" is infrequent.	Reply	I-Reply	2
[line_break_token][line_break_token]- For baselines, we set the numbers of sub-modules (under each resolution) the same (such as K), then we sweep K from 1 to a large number.	Reply	O	0
We list the baselines for Basic3ResNet below and we will include all others in a revision.	Reply	B-Reply	3
We also include the computation in "Flops" below as requested.	Reply	I-Reply	3
We used "Params" as we think the number of layers is more related to the number of parameters, but we will include both in a revision.	Reply	I-Reply	3
[line_break_token]-----------------------------------------------------------------------------[line_break_token]Net                                                 | Flops            | Params       | Accuracy[line_break_token]Basic3ResNet-[3, 3, 3]           41214592       272474            92.96[line_break_token]Basic3ResNet-[5, 5, 5]          69755520        466906            93.44[line_break_token]Basic3ResNet-[7, 7, 7]          98296448        661338            93.68[line_break_token]Basic3ResNet-[9, 9, 9]          126837376      855770            93.88[line_break_token]Basic3ResNet-[24, 24, 24]    340894336      2314010          94.26[line_break_token]Basic3ResNet-[42, 42, 42]    597762688      4063898          94.3[line_break_token]Basic3ResNet-[72, 72, 72]    1025876608    6980378          94.17[line_break_token]-----------------------------------------------------------------------------[line_break_token][line_break_token]- The conclusion holds for each run.	Reply	O	0
We treat both ZeroInit and AdamInit as network morphism and, in table 2, we concluded that ZeroInit and AdamInit were similar and sub-optimal.	Reply	B-Reply	4
[line_break_token]We run the the first setting in Table 2 for three runs, and the accuracy is 92.73%, 92.86%, 92.51%.	Reply	I-Reply	4
[line_break_token]For table 3, we run one more "CIFAR100 constant GauInit", we get 70.83%, and one more "CIFAR100 staircase ZeroInit" and get 70.11%.	Reply	I-Reply	4

This paper proposes two graph-based deep network feature fusion methods with connection constraints for semantic and panoptic segmentation.	Review	O	0
By incorporating additional scribble information to DCNN features, the methods yield improved results over the original network predictions on two popular semantic and panoptic segmentation datasets.	Review	O	0
Through interactively correcting error regions with the scribbles, further performance increase can be obtained.	Review	O	0
[line_break_token][line_break_token]I am not completely convinced by the novelty and experiments.	Review	O	0
[line_break_token](1) First, the idea of smart annotation can be formalized as a weekly supervised segmentation problem where only part of the annotation is available.	Review	O	0
Can the authors justify how your work differs from those works solving the weekly supervised problem and what's your advantages. (	Review	B-Review	1
Seed Expand and Constrain ... Alexander Kolesnikov; STC: A simple to Complex Framework for Weakly... Yunchao Wei; FickleNet Jungbeom Lee; etc..) Or, if possible, could you make a fair comparison with some existed weekly supervised approach on the final (semantic) result.	Review	I-Review	1
Second, Potts model, MRF, K-nearest cut are known approaches.	Review	I-Review	1
Thus I would like to know the deeper contribution of this work other than set constraints and solve ILP.	Review	I-Review	1
[line_break_token](2) The authors did not justify the use of less powerful models (DeepLabV2 and DRN) as both the inputs for l0H and ILP-P and the baseline comparison.	Review	O	0
The authors mentioned the current SOTA model (DeepLabV3+), which has achieved 79.55% mIoU on the CityScapes val set.	Review	B-Review	2
However, they did not perform experiments using its probability map.	Review	I-Review	2
It would be more convincing if the same performance gain can be achieved by using the SOTA model as inputs to the algorithms.	Review	I-Review	2
[line_break_token](3) The argument of achieving competitive results for panoptic segmentation is rather weak.	Review	O	0
To approach the panoptic segmentation problem, the authors essentially used scribbles to separate semantic region predictions into individual instances.	Review	B-Review	3
Since the proposed algorithm requires as many scribbles to be drawn as there are regions, the baseline network only needs to predict semantic classes, and the algorithms uses the provided region IDs from the scribbles to segment individual instances.	Review	I-Review	3
While this still has numerous applications in data annotation, it is somewhat unjust to claim that this method achieves competitive results in panoptic segmentation.	Review	I-Review	3
[line_break_token](4) The artificial scribbles for CityScapes experiments do not resemble human-drawn scribbles.	Review	O	0
Compared to the scribbles data for VOC12, the artificially generated scribbles for CityScapes experiments are visually idealistic.	Review	B-Review	4
Rather than a stroke through the object, the generated is more similar to an outline of the object, which conveys a lot more information than a single line.	Review	I-Review	4
Particularly when applied on super-pixels, it seems that super-pixels can easily be merged together by grouping any super-pixels within a scribble outline.	Review	I-Review	4
[line_break_token]There are some other minor suggestions.	Review	O	0
For example, it might be clearer and easier to read if section 2.2.2 is presented in an algorithm format.	Review	O	0
Some minor typos and grammatical mistakes should also be corrected.	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for the detailed comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	4
Our contribution is the design of a heuristic optimization algorithm and an ILP formulation that enforces connectivity (NP-hard) for interactive panoptic segmentation.	Reply	I-Reply	1
Other than adopting lower level features of any deep learning basenet or its final probability map as input to our algorithms, no learning is evolved in our approach.	Reply	I-Reply	1
Hence, it is not suitable to compare with other weakly supervised learning approach.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Since our contribution lies on the design of the algorithm/formulation, we did not focus on selecting and fine tunning the SOTA deep learning network.	Reply	B-Reply	2
We searched and the networks presented in the paper are the best public available deep nets together with checkpoint on the internet for the time being.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
We agree with the reviewer on this point, and that is why we added a condition on this statement, ‚Äúgiven initial scribbles‚Äù.	Reply	B-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	4
Since the main application of our method is to annotate dataset, we argue that the artificial scribble is realistic for any data annotator.	Reply	I-Reply	4
We tested drawing even more strict (closer to the boundary than the artificial ones) scribbles on Cityscapes, and it only takes on average 2 minutes per image, which is still a dramatic decrease in annotation time compared to 1.5 hours.	Reply	I-Reply	4
On the other hand, by adopting the online available of VOC scribbles, we sort of already validate the robustness of our algorithms (84.6% mIoU and 90.6% after 3 correction scribbles).	Reply	I-Reply	4

In the article, the authors solve the problem of anomaly detection using a fully unsupervised approach.	Review	O	0
They try to deal with the main challenge of anomaly detection: a lack of certainty on what defines normal data and anomaly one.	Review	O	0
For this purpose, the authors iteratively use: 1) autoencoders to learn the representation of the data; 2) applying in the latent space clustering to get a new training set and retrain autoencoders.	Review	O	0
The experimental results show that the author‚Äôs method performed better results than such a baseline model as one-class SVM and one-class NN.	Review	O	0
[line_break_token] [line_break_token]The proposed algorithm looks robust and well-motivated, but the text of the article and the experiments can be improved.	Review	O	0
As the proposed approach is a heuristic, the experiments should be done more persuasively, including more metrics used and more alternative algorithms considered.	Review	B-Review	4
[line_break_token][line_break_token]The key comments are the following:[line_break_token]1.	Review	O	0
The formatting of the article needs to be improved e.g.:[line_break_token]2.	Review	O	0
there is no comma between rows in the equation (1) ;[line_break_token]&lt;&lt;to be accepted into the ‚Äútraining‚Äù set, .&gt;&gt; - there is an extra comma;[line_break_token]3.	Review	O	0
round brackets in the equation (6) should be bigger;[line_break_token]4.	Review	O	0
Table 3 is bigger than the page sizes.	Review	B-Review	1
[line_break_token]5.	Review	O	0
The quality of the pictures should be improved:[line_break_token]- Increase the captions font size in Figure 2;[line_break_token]- The captions and the legends in Figure 3 are practically not visible;[line_break_token]6.	Review	O	0
 Is the DAGMM method SOTA in anomaly detection with deep autoencoder?	Review	O	0
There are many other methods with similar ideas.	Review	B-Review	2
We expect that we should provide a comparison with other methods: [line_break_token]<a href="https://arxiv.org/pdf/1809.02728.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1809.02728.pdf</a> - IGMM-GAN[line_break_token]<a href="https://papers.nips.cc/paper/7915-generative-probabilistic-novelty-detection-with-adversarial-autoencoders.pdf" target="_blank" rel="nofollow">https://papers.nips.cc/paper/7915-generative-probabilistic-novelty-detection-with-adversarial-autoencoders.pdf</a> - GPND AE[line_break_token]6.	Review	O	0
Also, DAGMM works badly according to the experiments in the article with max AUROC in Table 1 only 50.3 (so it seems that it is no better than the coin-flipping)[line_break_token]7.	Review	O	0
Why was the only selected digit for analysis 4?	Review	B-Review	5
Usual for comparison anomaly detection on MNIST dataset apply the following procedure: for each figure in dataset consider corresponded class as anomaly data, and the rest of the digits are used as normal data, e.g.:[line_break_token]<a href="https://arxiv.org/pdf/1802.06222.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.06222.pdf</a>[line_break_token]<a href="https://arxiv.org/pdf/1906.11632.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1906.11632.pdf</a> [line_break_token]8.	Review	O	0
 Class imbalances can affect the value of the AUROC metric.	Review	O	0
Possibly, the other metrics like AUPRC, F1-scores will better reflect the work of the algorithms for comparison.	Review	B-Review	6
Also, AUROC is not representative when it comes to the selection of the threshold for anomaly detection.	Review	I-Review	6
Precision and Recall can help to get more insights.	Review	I-Review	6
[line_break_token]9.	Review	I-Review	2
In Table 3, the result of applying the proposed algorithm presented with standard deviation, but other methods are represented by one metric value.	Review	I-Review	7
Why?	Review	I-Review	7
The explanation is required.	Review	I-Review	7
hank you for your valuable time and comments[line_break_token][line_break_token]1.	Reply	O	0
Comments on formatting and typographical errors.	Reply	O	0
[line_break_token][line_break_token]Thank you for your careful reading.	Reply	O	0
We have revised our paper per your suggestions.	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	2
Is the DAGMM method SOTA in anomaly detection with deep autoencoder?	Reply	O	0
[line_break_token][line_break_token]To our best knowledge, it is the SOTA for UNSUPERVISED anomaly detection.	Reply	B-Reply	2
 We have compared against GAN methods as recommended.	Reply	I-Reply	2
However, available GAN methods, such as IGMM-GAN and GPND mentioned by the reviewer, require labels of normal data for training discriminator.	Reply	I-Reply	2
Our method, despite being fully UNSUPERVISED, performed competitively.	Reply	I-Reply	2
[line_break_token][line_break_token]For IGMM-GAN, unfortunately we did not find publicly available code, so we cannot compare the performance.	Reply	I-Reply	2
[line_break_token][line_break_token] For GPND, when rerun on MNIST dataset with ‚Äò4‚Äô as normal data, we found out that the source code uses training label information to search for the optimal threshold for F1/AUROC calculation, so they can report very good result.	Reply	I-Reply	2
This trick gives the method unfair advantage.	Reply	I-Reply	2
For 20% of anomaly, they achieved F1 score of 0.966 and AUROC score of 0.9737.	Reply	I-Reply	2
For 50% of anomaly, they achieve even higher AUROC of 0.9748.	Reply	I-Reply	2
This makes the GPND results dubious.	Reply	I-Reply	2
[line_break_token][line_break_token] We also evaluate another semi-supervised GAN method done by Zaneti2018*. This paper, is claimed to be the improved version of ‚ÄúEfficient GAN-based anomaly detection(<a href="https://arxiv.org/abs/1802.06222)," target="_blank" rel="nofollow">https://arxiv.org/abs/1802.06222),</a> mentioned by the reviewer.	Reply	O	0
Please note that it is still semi-supervised because it requires training with normal data only.	Reply	B-Reply	2
Their code is publicly available.	Reply	I-Reply	2
The re-run on KDD dataset shows that the best AUC-ROC and AUC-PRC achievable is 0.9925 and 0.9325; whereas for our method, the AU-ROC on KDD dataset is 0.935.	Reply	I-Reply	2
Despite being unsupervised, our method performs competitively.	Reply	I-Reply	2
[line_break_token][line_break_token]*Adversarially Learned Anomaly Detection(Zaneti, ICDM2018) (<a href="https://arxiv.org/abs/1812.02288)" target="_blank" rel="nofollow">https://arxiv.org/abs/1812.02288)</a>    [line_break_token][line_break_token]3.	Reply	O	0
Why was the only selected digit for analysis is 4?	Reply	O	0
 [line_break_token][line_break_token]As 2 of published works*, that  we are comparing with, only use digit 4 (as normal data) for analysis, we believe this is an established benchmark.	Reply	O	0
We therefore follow the protocol specified in Zhou2017 and Chalapathy2018.	Reply	B-Reply	5
We tested our method by replacing digit 4 with other digits and it achieved similar results.	Reply	I-Reply	5
[line_break_token]              [line_break_token] We note that in some literatures, such as ‚ÄúEfficient GAN-based anomaly detection‚Äù(<a href="https://arxiv.org/abs/1802.06222)" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.06222)</a> and ‚ÄúA survey on GANs for anomaly detection‚Äù(<a href="https://arxiv.org/abs/1906.11632)," target="_blank" rel="nofollow">https://arxiv.org/abs/1906.11632),</a> each figure in MNIST dataset is treated as anomaly data, while the rest of the digits are treated as normal ones.	Reply	O	0
We did not adopt this setup, because it is more suitable for semi-supervised methods who are given the labels of normal classes, such that discriminators from normal data can be learned.	Reply	B-Reply	5
In this setup, when there‚Äôs a subset in the test data the network never ‚Äúsees‚Äù, it is deemed ‚Äòanomaly‚Äô.	Reply	I-Reply	5
We do not think it is truly unsupervised.	Reply	I-Reply	5
[line_break_token]   [line_break_token]Therefore, in our evaluation we follow the methodology of the 2 afore-mentioned UNSUPERVISED works, Zhou2017 and Chalapathy2018, for a fairer comparison on the MNIST performance.	Reply	I-Reply	5
[line_break_token][line_break_token]*Anomaly Detection with Robust Deep Autoencoders(Zhou, KDD2017)[line_break_token](<a href="https://www.eecs.yorku.ca/course_archive/2017-18/F/6412/reading/kdd17p665.pdf)" target="_blank" rel="nofollow">https://www.eecs.yorku.ca/course_archive/2017-18/F/6412/reading/kdd17p665.pdf)</a>[line_break_token]*Anomaly Detection using One-Class Neural Networks(Chalapathy, KDD2018)(<a href="https://arxiv.org/pdf/1802.06360v1.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.06360v1.pdf)</a>[line_break_token][line_break_token][line_break_token]4.	Reply	O	0
Other metrics like AUPRC, F1-scores will better reflect the work of the algorithms in comparison.	Reply	O	0
[line_break_token][line_break_token]Thank you for the advice.	Reply	O	0
We have added evaluation based AUPRC metric in our revision.	Reply	B-Reply	6
Please refer to Table 3 in the revision.	Reply	I-Reply	6

The authors propose an approach to augment experience replay buffers with properties that can alleviate issues with catastrophic forgetting.	Review	O	0
The buffers are augmented by storing both new and historical experiences, along with the desired historical policy & value distribution.	Review	O	0
The AC learning now couples two additional losses that ensures the new policy does not drift away from old actor distribution (via KL) and new value does not drift away from old critic distribution (via L2 loss).	Review	O	0
[line_break_token][line_break_token]The authors provided clear experimental evidence that shows how an RL agent that does not use CLEAR will observe catastrophic when we sequentially train different tasks (and it is not due to destructive interference using the simultaneous and separate training/evaluation experiments).	Review	O	0
Author also showed how different replay make ups can change the result of CLEAR (and it's a matter of empirical tuning).	Review	O	0
[line_break_token][line_break_token]The formulation of CLEAR also is simple while delivering interesting results.	Review	O	0
It would have been nice to see how this is used in a practical setting as all these are synthetic environments / tasks.	Review	B-Review	1
The discussion on relationship with biological mechanism also seems unnecessary as it's unclear whether the mechanism proposed is actually what's in the CLS.	Review	I-Review	2
We thank the reviewer for a thoughtful reading and for generally positive comments.	Reply	O	0
As we understand, the reviewer's main concern is that the environments and tasks are synthetic.	Reply	B-Reply	1
We would like to justify why we chose these particular environments and tasks.	Reply	I-Reply	1
Our interest has been in reinforcement learning (RL) because, in the supervised learning case, catastrophic forgetting is generally resolved merely by storing a dataset.	Reply	I-Reply	1
In RL, we view the synthetic problem setting as an absolutely mandatory first step to take before working on an application domain like robotics.	Reply	I-Reply	1
Our experiments are in keeping with the standards in this field: work on continual learning to date in RL has all been on synthetic tasks, and we compare to this work, which allows us to provide effective benchmarks.	Reply	I-Reply	1
The fact that our environments are simulated does not however imply that they are simple: they are state-of-the-art 3D environments, with DMLab introduced earlier this year and currently representing an advanced benchmark for RL systems.	Reply	I-Reply	1
[line_break_token][line_break_token]With respect to potential biological connections, we have devoted only a paragraph to this matter, with the purpose of emphasizing that we think such connections are NOT present, as the reviewer rightly states.	Reply	I-Reply	2
[line_break_token][line_break_token]In the revision, we have included in Appendix B the results of a new experiment, similar to that of the probe task (Figure 5).	Reply	I-Reply	3
 In the new experiment, we show that when using pure off-policy learning (instead of a mixture of on- and off-policy learning, as in CLEAR), the probe task does indeed decrease in performance when other tasks are learned before it.	Reply	I-Reply	3
CLEAR avoids this failure mode by blending new experience with replay.	Reply	I-Reply	3
[line_break_token][line_break_token]We have also, in our revision, added in Appendix C several new visualizations of our main results.	Reply	I-Reply	4
In these figures, we plot the cumulative reward, which captures both performance and resistance to catastrophic forgetting, and we include tables that show the considerable benefit obtained by using CLEAR	Reply	I-Reply	4

This article studies the similarities between the learned representations for different tasks when trained using reinforcement learning algorithms.	Review	O	0
The ultimate question that this study tries to answer is an interesting one.	Review	O	0
Namely, how much can representations learned by training on one task be beneficial for learning other tasks?	Review	O	0
A high interdependence between the representations can lead to a more successful transfer of knowledge between tasks.	Review	O	0
[line_break_token]The authors are further interested in studying the properties that influence this relationship, which depends on the elements of training as well as attributes of the tasks themselves.	Review	O	0
[line_break_token][line_break_token]However, I believe that the results are not strong enough to support the claims that are stated in the paper and the limited scope of the environments tested does not make a convincing case that the results will be generalizable much beyond these scenarios.	Review	B-Review	2
Therefore, in the current state, I think this paper should be rejected.	Review	I-Review	2
[line_break_token][line_break_token]Firstly, the paper states that:[line_break_token]&gt; ".. if the distance between models trained on different tasks is the same as that between models trained on the same task, representations are task-agnostic."	Review	O	0
[line_break_token]This seems to be a key argument in the paper.	Review	B-Review	1
However, I believe that this argument is based on the assumption that representations learned for a single task are indeed highly similar.	Review	I-Review	1
I think this assumption requires some sort of support as reinforcement learning algorithms are known to be highly inconsistent even in reaching similar solutions.	Review	I-Review	1
Therefore, one cannot take for granted that the learned representations would be similar in any way.	Review	I-Review	1
[line_break_token][line_break_token]Second, the authors claim in Section 5 that the random splits have little impact on the learned representation, but in Section 6 claim that the spatially disjoint splits have a noticeable impact on the representations.	Review	I-Review	3
Without any measure of the impact, looking at figures 1b and 3a, I'm not convinced that this distinction is so obvious.	Review	I-Review	3
The situation is worse when looking at the figures in the appendix, namely figures A3 and A5.	Review	I-Review	3
If someone were to swap these two figures, my untrained eye would not be able to tell the difference.	Review	I-Review	3
[line_break_token][line_break_token]I suggest that the authors spend more time explaining their reasoning as to why these results are significant enough to support the claims.	Review	O	0
Also, the text should be improved if it is to be accepted.	Review	O	0
There exist many problems ranging from small typos (simlate -&gt; simulate, reuse-ability -&gt; reusability, and "?."	Review	O	0
-&gt; "?")	Review	O	0
to sentences that need to be reworked.	Review	B-Review	4
Some figure legends/captions can also be improved to include more information, such as explaining what exactly the shaded regions represent (I'm guessing one standard deviation from the mean over some unknown replicates), or in Fig 3b making clear whether "A -&gt; B" is done with "New Policy" or "Fine-tuned Policy".	Review	O	0
I am also curious as to why only one of these scenarios was experimented with in sections 6 and 7.	Review	B-Review	6
gt; This seems to be a key argument in the paper.	Reply	O	0
However, I believe that this argument is based on the assumption that representations learned for a single task are indeed highly similar.	Reply	O	0
I think this assumption requires some sort of support as reinforcement learning algorithms are known to be highly inconsistent even in reaching similar solutions.	Reply	O	0
Therefore, one cannot take for granted that the learned representations would be similar in any way.	Reply	O	0
[line_break_token][line_break_token]Our analysis does not need the models to be identical, but to share a subspace in their representations.	Reply	B-Reply	1
 While it is possible that every model could learn representations with no common subspace, our experiments show that models trained on the same task learn representations with a shared subspace.	Reply	I-Reply	1
 If every model learned a different representation, as the reviewer suggests, we would expect to see very high values for the A and B lines in Figure 1b.	Reply	I-Reply	1
 However, we see values consistently less than 0.5, indicating that while representations are certainly not identical (subject to a linear transform), there certainly exists a shared subspace in the representations which captures much of the variance.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt;  I believe that the results are not strong enough to support the claims that are stated in the paper and the limited scope[line_break_token][line_break_token]While our experiments do have a limit in their scope, we believe they do support the claims within this scope.	Reply	O	0
 Extending the scope of our experiments provides and interesting avenue for future work.	Reply	B-Reply	2
 We also emphasize that, to our knowledge, our work is the first to perform this type of analysis in the context of reinforcement learning in realistic environments.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; Second, the authors claim in Section 5 that the random splits have little impact on the learned representation, but in Section 6 claim that the spatially disjoint splits have a noticeable impact on the representations.	Reply	O	0
Without any measure of the impact, looking at figures 1b and 3a, I'm not convinced that this distinction is so obvious.	Reply	O	0
The situation is worse when looking at the figures in the appendix, namely figures A3 and A5.	Reply	O	0
If someone were to swap these two figures, my untrained eye would not be able to tell the difference.	Reply	O	0
[line_break_token][line_break_token][line_break_token]The differences in figures 1b and 3a may seem minor in scale, but they do have real impact.	Reply	B-Reply	3
 The effect of this difference is pronounced on the transfer experiments (figure 2 vs. figure 3 (right)).	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; Some figure legends/captions can also be improved to include more information, such as explaining what exactly the shaded regions represent (I'm guessing one standard deviation from the mean over some unknown replicates).	Reply	O	0
[line_break_token][line_break_token]We will improve legends/captions.	Reply	B-Reply	5
 The shaded regions represent a bootstrapped 95% confidence interval over 5 replicates.	Reply	I-Reply	5
[line_break_token][line_break_token]&gt; or in Fig 3b making clear whether "A -&gt; B" is done with "New Policy" or "Fine-tuned Policy".	Reply	O	0
I am also curious as to why only one of these scenarios was experimented with in sections 6 and 7.	Reply	O	0
[line_break_token][line_break_token]Fig 3b is done with a New Policy.	Reply	B-Reply	6
 We did not continue to examine the ‚ÄúFine-tuned Policy‚Äù setting in latter experiments as Fig 2 showed that general navigation skills along with visual representations can be transferred between the tasks.	Reply	I-Reply	6
 However, our PWCCA experiments only examine the visual encoder, thus utilizing the ‚ÄúFine-tuned Policy‚Äù to ground PWCCA would introduce an un-accounted for variable.	Reply	I-Reply	6
 We will clarify these points in future revisions.	Reply	I-Reply	6
[line_break_token][line_break_token][line_break_token]&gt; Typos[line_break_token][line_break_token]Thank you for pointing these out!	Reply	O	0
 We will fix them in future revisions.	Reply	B-Reply	4

In this work, the authors propose a network pruning method to learn a pruned network during training.	Review	O	0
Specifically, they add a pruning mask for each layer and induce a sparisity loss on the mask variables during training.	Review	O	0
The pruned network is obtained by applying the learned mask to the networks.	Review	O	0
[line_break_token][line_break_token]The paper seems to be well contained.	Review	O	0
However, my assessment of this paper is weak reject.	Review	O	0
I am mainly concerned with the novelty of this method.	Review	B-Review	1
Also i think some more evaluation is needed to fully understand the effectiveness of this method.	Review	I-Review	2
My questions are summarized as follows:[line_break_token][line_break_token]Q1: In the methods part, the authors said that ‚ÄúPrevious pruning approaches often prune Conv filters with their successive Batch Normalization layer unchanged.	Review	O	0
‚Äù Can the authors give some reference here as to which pruning approaches?	Review	B-Review	3
[line_break_token][line_break_token]Q2: Did the authors compare the proposed approach to training the pruned networks from scratch as done in [1]?	Review	O	0
Also can the authors analyze the sparsity patterns of the pruned networks as done in section G in the appendix of [1]?	Review	B-Review	4
[line_break_token][line_break_token]Q3: What is the difference of your approach to [2]?	Review	O	0
They seem to be very similar.	Review	B-Review	5
I think it is necessary to add some discussion in the related work.	Review	I-Review	5
Is there any experimental results for comparison with [2]?	Review	I-Review	5
[line_break_token][line_break_token][1] Rethinking the Value of Network Pruning.	Review	O	0
Liu et al.	Review	O	0
ICLR 2019[line_break_token][2] AutoPruner: An End-to-End Trainable Filter Pruning Method for Efficient Deep Model Inference.	Review	O	0
Luo et al.	Review	O	0
Arxiv, 2018.	Review	O	0
hank you for reviewing our work.	Reply	O	0
[line_break_token][line_break_token]Q1: In the methods part, the authors said that ‚ÄúPrevious pruning approaches often prune Conv filters with their successive Batch Normalization layer unchanged.	Reply	O	0
‚Äù Can the authors give some reference here as to which pruning approaches?	Reply	O	0
[line_break_token][line_break_token]Most of the train-prune-retrain pruning approaches suffer this issue.	Reply	B-Reply	3
For example, Network Slimming [3] and MorphNet [4] proposed to sparsify BN scale/shift parameters.	Reply	I-Reply	3
However, even though the scale is exactly 0, when they pruned the corresponding filter (i.e. cut down output depth for current Conv layer and input depth for the next Conv layer), the accuracy of the pruned model drops and must be fine-tuned.	Reply	I-Reply	3
According to the appendix section of MorphNet, the BN statistics are disrupted after pruning and must be corrected with several thousand iterations with a tiny learning rate.	Reply	I-Reply	3
[line_break_token]Our method masked the filters of Covn/FC layer and the corresponding BN layer with the same mask vector to condition BN to ignore the masked filters during training, thus avoid the requirement for finetuning.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token][line_break_token]Q2: Did the authors compare the proposed approach to training the pruned networks from scratch as done in [1]?	Reply	O	0
Also can the authors analyze the sparsity patterns of the pruned networks as done in section G in the appendix of [1]?	Reply	O	0
[line_break_token][line_break_token]We added experiments to compare our method with the train-from-scratch method named Soft Filter Pruning (SFP) [5] with ResNet56 v1 on CIFAR10, as also done in the paper ‚ÄúRethinking the value of network pruning‚Äù [1]. SFP pruned all layers in ResNet56 with a pre-defined uniform pruning rate across layers.	Reply	B-Reply	4
For a fair comparison, we trained the masked ResNet56 by masking all the layers in each basic block (residual connection).	Reply	I-Reply	4
Results show that our method and SFP (without fine-tuning) achieves 92.9% and 93.1% accuracy respectively, when both methods prune 30% of the weight parameters. (	Reply	I-Reply	4
Note that our results on ResNet56 are a bit different from the numbers shown in Table 1 in our submission.	Reply	I-Reply	4
For a fair comparison with L1-Pruning [6], we trained ResNet56 without masking the last Conv layer in each basic block, as what L1-Pruning did in the experiments.)	Reply	I-Reply	4
[line_break_token]We also show the sparsity patterns of the pruned networks for VGG19 (pruned 90% of the weight parameters, with accuracy 93.5% on CIFAR10) and ResNet56 (pruned 30% of the parameters, with accuracy 92.9% on CIFAR10).	Reply	I-Reply	4
One can see that the pattern emerged from our method is similar to the pattern observed in the paper ‚ÄúRethinking the value of network pruning‚Äù, e.g. for VGG19, late layers tend to have more redundancy than early layers, and for ResNet56, the pruning ratio tends to be uniform across stages.	Reply	I-Reply	4
[line_break_token][line_break_token]============================================================= ========[line_break_token]Layer-wise sparsity pattern for VGG19 with 90% of weight parameters pruned.	Reply	I-Reply	4
[line_break_token]Layer#[tab_token]Filters ratio to be kept[line_break_token]Conv 1[tab_token]0.734[line_break_token]Conv 2[tab_token]0.984[line_break_token]Conv 3[tab_token]0.961[line_break_token]Conv 4[tab_token]0.992[line_break_token]Conv 5[tab_token]0.914[line_break_token]Conv 6[tab_token]0.758[line_break_token]Conv 7[tab_token]0.617[line_break_token]Conv 8[tab_token]0.520[line_break_token]Conv 9[tab_token]0.250[line_break_token]Conv 10[tab_token]0.172[line_break_token]Conv 11[tab_token]0.127[line_break_token]Conv 12[tab_token]0.115[line_break_token]Conv 13[tab_token]0.146[line_break_token]Conv 14[tab_token]0.145[line_break_token]Conv 15[tab_token]0.160[line_break_token]Conv 16[tab_token]0.361[line_break_token]============================================================= ========[line_break_token]============================================================= ========[line_break_token]Stage-wise sparsity pattern for ResNet56 with 30% of weight parameters pruned.	Reply	I-Reply	4
[line_break_token]Layer#[tab_token]Params ratio to be kept[line_break_token]Stage 1[tab_token]0.783[line_break_token]Stage 2[tab_token]0.681[line_break_token]Stage 3[tab_token]0.878[line_break_token]============================================================= ========[line_break_token][line_break_token][line_break_token]Q3: What is the difference of your approach to [2]?	Reply	O	0
They seem to be very similar.	Reply	O	0
I think it is necessary to add some discussion in the related work.	Reply	O	0
Is there any experimental results for comparison with [2]?	Reply	O	0
[line_break_token][line_break_token]Thanks for pointing us the AutoPruner paper, we will add it to our reference.	Reply	B-Reply	5
Basically, AutoPruner proposed to prune weight by directly masking activation responses, rather than weight filters.	Reply	I-Reply	5
Since activation responses are not learnable parameters, they add a AutoPruner layer to the network architecture.	Reply	I-Reply	5
The AutoPrunner layer takes activation responses as input and the output is an approximate binary code in which zero value indicates the corresponding filter will be pruned.	Reply	I-Reply	5
The AutoPrunner layer composes of average pooling,  max pooling, a fully-connected layer followed by a scaled sigmoid function, which introduces a large number of additional trainable parameters and computational complexity to the network.	Reply	I-Reply	5
[line_break_token]We would like to run AutoPruner experiments for comparisons, unfortunately, we didn‚Äôt find any source codes available on Github or the author‚Äôs website.	Reply	I-Reply	5
We will probably implement the method by ourselves and add comparisons in the near future.	Reply	I-Reply	5

This paper proposed a new method for generating adversarial examples for the task of automatic speech recognition.	Review	O	0
The authors suggest using their method called Iterative Proportional Clipping, which limits the amount of change we allow at every time-step.	Review	O	0
[line_break_token][line_break_token]Overall this paper is an incremental research work.	Review	O	0
The paper is clearly written.	Review	O	0
The idea is intuitive and well presented.	Review	O	0
[line_break_token][line_break_token]I have several questions to the authors: [line_break_token]1) Can the authors provide more details regarding the attack setup?	Review	O	0
Why exactly did you run the attack in two stages?	Review	B-Review	1
What makes the difference between the train and eval modes?	Review	I-Review	1
Only on the batch-norm layers?	Review	I-Review	1
[line_break_token][line_break_token]2) All experiments were conducted in a white-box settings, did the authors try to explore gray/black box settings as well?	Review	O	0
[line_break_token][line_break_token]3) It seems like there are phase mismatch issues in the generated adversarial examples.	Review	O	0
Did the authors try to generate adversarial examples using other approximations besides the MFCC to wav approximator?	Review	B-Review	3
Maybe working at the spectrogram magnitude level?	Review	I-Review	3
[line_break_token][line_break_token]4) Regarding comment (3).	Review	O	0
the underlying assumption of adversarial examples is: "it will not be distinguishable from human ears."	Review	B-Review	4
However, the changes to the signal are highly noticeable.	Review	I-Review	4
Did the authors try to analyze when is it more or less noticeable, under which settings?	Review	I-Review	4
Does it depend on the target text?	Review	I-Review	4
hanks for your comments.	Reply	O	0
Here are our responses.	Reply	O	0
[line_break_token]A1: About the attack setup, we use a ‚Äúcoarse-to-fine‚Äù strategy by executing attacks in two stages to reduce time consumptions.	Reply	O	0
 [line_break_token][line_break_token]The wav2letter system performs decoding with a beamsearch decoder based on a 4-gram language model.	Reply	B-Reply	1
The modified audio will be iteratively fed into our ASR and be decoded during our generation process to check if it can be recognized as the target text.	Reply	I-Reply	1
Note that the iterative decoding process costs much more time than general tensor computation.	Reply	I-Reply	1
Therefore, we split our task of generating adversarial examples into two stages by using a ‚Äúcoarse-to-fine‚Äù strategy.	Reply	I-Reply	1
In stage 1, we decode with a greedy decoder and generate an approximator of the valid adversarial audio.	Reply	I-Reply	1
In stage 2, we continuously modify the audio and iteratively decode with a beamsearch decoder.	Reply	I-Reply	1
In the end, we get our valid adversarial audio with WER of 0%.	Reply	I-Reply	1
[line_break_token][line_break_token]Meanwhile, the differences between the ‚Äòtrain‚Äô and ‚Äòeval‚Äô modes are on the usage of the batch-norm layers and dropout layers.	Reply	I-Reply	1
We set the model in ‚Äòtrain‚Äô mode in stage 1 because we find it helpful in optimizing our CTCLoss more rapidly without a softmax layer.	Reply	I-Reply	1
A normal CTCLoss in ASR train task is minimized in the same manner.	Reply	I-Reply	1
[line_break_token][line_break_token]A2: Our attack can be seen as a black box attack for the following reason:[line_break_token]we use MFCC features through the differentiable feature extraction instead of the log-mel filter bank energy.	Reply	O	0
The feature extraction does not rely on the neural network of ASR systems.	Reply	B-Reply	2
Therefore, our attack is effective against other ASR systems as long as every step in the framework is differentiable.	Reply	I-Reply	2
[line_break_token][line_break_token]A3: The wav2letter has three types of input features: MFCCs, power-spectrum, and raw wave.	Reply	O	0
In our work, we only utilize the differentiable MFCCs as the input.	Reply	B-Reply	3
We believe the other two types of features can also be used.	Reply	I-Reply	3
However, we need to avoid the usage of popular python package ‚ÄúLibrosa‚Äù when processing audio, which blocks the flow of gradient tensor due to the usage of NumPy.	Reply	I-Reply	3
We use ‚Äútorch.rfft‚Äù to convert signal to frequency domain in our work.	Reply	I-Reply	3
[line_break_token][line_break_token]A4: The variable B in Eq.2 stands for the range of the variations of the original signal.	Reply	O	0
First of all, regardless of the target text, a bigger B indicates more noticeable added noise.	Reply	B-Reply	4
That‚Äôs why we propose a small B of 0.2.	Reply	I-Reply	4
In Fig.	Reply	I-Reply	4
5(a), we analyzed the balance between iterations for attack and distortion according to different B values.	Reply	I-Reply	4
[line_break_token]According to the principle of proportional clipping, regardless of the target text, the noise is mostly concentrated in the places where the signal has a high signal intensity.	Reply	I-Reply	4
While the transfer to different target text results in different amounts of noise, whether or not the noise is noticeable mainly depends on the original audio.	Reply	I-Reply	4

The authors propose to use sampling methods in order to apply graph neural networks to large scale knowledge graphs for semantic reasoning.	Review	O	0
To this end induced subgraphs are constructed in a data-dependent way using an attention mechanism.	Review	O	0
This improves the efficiency and leads to interpretable results.	Review	O	0
The experiments show some improvements over path- and embedding-based methods.	Review	O	0
[line_break_token][line_break_token]The paper is partially difficult to read and not well structured (see minor comments below).	Review	B-Review	1
Overall, I think that the proposed GNN architecture is an original and interesting approach for this specific application.	Review	I-Review	1
The experimental evaluation presented in the Section 4 shows clear improvements.	Review	I-Review	1
This, however, is not true for the results presented in the appendix (Table 4).	Review	I-Review	1
I am missing a discussion of the limitations of the proposed approach.	Review	I-Review	1
Moreover, a thorough discussion of the hyper-parameter selection and, if possible, theoretical justification would be highly desirable and could strengthen the paper.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]- Section 2 start with the paragraph 'Notation', but does not contain any other paragraph.	Review	O	0
[line_break_token][line_break_token]- The sampling strategy should not be introduced as part of the section 'problem formulation'.	Review	O	0
[line_break_token][line_break_token]- using standard terms from graph theory for well-known concepts (such as 'induced subgraph') would improve the readability[line_break_token] [line_break_token]----------------------------[line_break_token]Update after the rebuttal: The authors have addressed several of my concerns and improved the manuscript.	Review	O	0
I have raised my score from "3: Weak Reject" to "6: Weak Accept".	Review	O	0
hank you for your valuable suggestions and pointing out my inappropriate word usage.	Reply	O	0
We have replaced some terminology (e.g. using "induced subgraph" in our notation).	Reply	O	0
We sincerely hope that our updated version could deliver a more reader-friendly presentation.	Reply	O	0
We also appreciate that you recognized the originality of our work.	Reply	O	0
[line_break_token][line_break_token]["The paper is partially difficult to read and not well structured (see minor comments below)"][line_break_token][line_break_token]- ["the paragraph 'Notation', but does not contain any other paragraph."]	Reply	O	0
[line_break_token][line_break_token]We feel sorry to make this paper difficult to read.	Reply	B-Reply	1
To make it more concise and well structured, we rewrite some parts, including making other paragraphs in Section 2 have their own paragraph titles.	Reply	I-Reply	1
[line_break_token][line_break_token]- ["The sampling strategy should not be introduced as part of the section 'problem formulation'."]	Reply	O	0
[line_break_token][line_break_token]We realize this problem.	Reply	B-Reply	2
We should not use the section title of "problem formulation" since we intend to explain and address the scale-up problem but not the typical "problem formulation" part in research papers.	Reply	I-Reply	2
We made the correction in the revision by replacing the title with "Addressing the Scale-Up Problem".	Reply	I-Reply	2
[line_break_token][line_break_token]- ["well-known concepts (such as 'induced subgraph') would improve the readability"][line_break_token][line_break_token]We thank you for this suggestion.	Reply	O	0
We used this term in many places in our updated version, which enables us to give a shorter and clearer description for the Notation part in Section 2.	Reply	B-Reply	3
[line_break_token][line_break_token]["The experimental evaluation presented in the Section 4 shows clear improvements.	Reply	O	0
This, however, is not true for the results presented in the appendix (Table 4)"][line_break_token][line_break_token]We feel that we should have given more background explanations on our datasets and why our model neither didn't perform well enough in WN18 as in other datasets, or didn't perform the best in FB15K. First, [1] noted  FB15K and WN18  are not challenging datasets because they contain many reversible triples.	Reply	O	0
So, dataset FB15K-237 and WN18RR are created to serve as realistic KB completion datasets which represent a more challenging learning setting.	Reply	B-Reply	1
However, this less-challenging property favors simple models compared to complex models such as path-based models.	Reply	I-Reply	1
In our paper, we didn't just throw the results but presented them in the appendix.	Reply	I-Reply	1
Though these results show our complex model may lose its advantage in easy datasets, our metric scores attained are still competitive and haven't become worse.	Reply	I-Reply	1
In those challenging datasets, FB15K-237 and WN18RR, our model outperforms the best state-of-the-art significantly.	Reply	I-Reply	1
[line_break_token][line_break_token]["I am missing a discussion of the limitations of the proposed approach."]	Reply	O	0
[line_break_token][line_break_token]This is a really good and useful suggestion.	Reply	B-Reply	1
We have added the discussion of the limitations of our approach in the revision.	Reply	I-Reply	1
We consider the main limitation could be: [line_break_token]"Although DPMPN shows a promising way to harness the scalability on large-scale graph data, current GPU-based machine learning platforms, such as TensorFlow and PyTorch, seem not ready to fully leverage sparse tensor computation which acts as building blocks to support dynamical computation graphs which varies from one input to another.	Reply	I-Reply	1
Extra overhead caused by extensive sparse operations will neutralize the benefits of exploiting sparsity."	Reply	I-Reply	1
[line_break_token][line_break_token]["a thorough discussion of the hyper-parameter selection and, if possible, theoretical justification would be highly desirable"][line_break_token][line_break_token]Our hyper-parameters are listed in Section 8 in Appendix.	Reply	O	0
You can see that main hyper-parameters are "max_attending_from_per_step", "max_sampling_per_node", "max_attending_to_per_step", "n_steps_in_IGNN" and "n_steps_in_AGNN", which define our attending-from, sampling, attending-to, and searching horizons.	Reply	O	0
Then, we conduct a comprehensive ablation study to run many experiments on these hyperparameter selections and provide careful horizon analysis (see Figure 4(C)(D)(E)(F) and Figure 7(C)(D)(E)(F)).	Reply	O	0
For theoretical justification, we only focus on the theoretical analysis to address the scale-up issue.	Reply	O	0
[line_break_token][line_break_token][1] Kristina Toutanova and Danqi Chen.	Reply	O	0
2015.	Reply	O	0
Observed Versus Latent Features for Knowledge Base and Text Inference.	Reply	O	0
In Proceedings of the 3rd Workshop[line_break_token][line_break_token][2] Tim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel.	Reply	O	0
2017.	Reply	O	0
Convolutional 2D Knowledge Graph Embeddings.	Reply	O	0
arXiv preprint abs/1707.01476.	Reply	O	0
on Continuous Vector Space Models and their Compositionality.	Reply	O	0
pages 57‚Äì66	Reply	O	0

In this paper, the authors proposed a fortified network model, which is an extension to denoising autoencoder.	Review	O	0
The extension is to perform the denoising module in the hidden layers instead of input layer.	Review	O	0
The motivation of this extension is that the denoising part is more effective in the hidden layers.	Review	O	0
Overall, this extension is quite sensible, and empirical results justify the utility of this extension.	Review	O	0
The major issue, which was left as an open question in the end of Section 3, is that when and where to use fortified layers.	Review	B-Review	1
The authors discussed this issue, but did not solve this issue.	Review	I-Review	1
Nevertheless, I do believe solving this issue requires a sequence of papers.	Review	I-Review	1
Overall the paper reads very well, but there are a number of minor places to be improved.	Review	O	0
[line_break_token][line_break_token] [line_break_token](1) a grammar error at "provide a reliable signal of the existence of input data that do not lie on the manifold on which it the network trained."	Review	O	0
[line_break_token][line_break_token](2) a grammar error at "This expectation cannot be computed, therefore a common approach is to to minimize the empirical risk"[line_break_token][line_break_token](3) The sentence "For a mini-batch of N clean examples, x(1), ..., x(N), each hidden layer h(1)_k, ..., h(N)_k is fed into a DAE loss" is a little confusing to me. "	Review	O	0
h(1)_k, ..., h(N)_k" is only for one hidden layer, rather than "each hidden layer".	Review	B-Review	4
Right?	Review	I-Review	4
‚ÄúThe major issue, which was left as an open question in the end of Section 3, is that when and where to use fortified layers.	Reply	O	0
The authors discussed this issue, but did not solve this issue.	Reply	O	0
Nevertheless, I do believe solving this issue requires a sequence of papers.	Reply	O	0
Overall the paper reads very well, but there are a number of minor places to be improved.	Reply	O	0
‚Äú[line_break_token][line_break_token]We thank the reviewer for the positive and constructive feedback.	Reply	O	0
[line_break_token][line_break_token]We also like to point out that we‚Äôve conducted new experiments to help to demonstrate that our method isn‚Äôt benefiting from obfuscated gradients and additionally we ran PGD attacks with many more iterations (200) on CIFAR-10 (see the response to reviewer 4).	Reply	B-Reply	5

The authors proposed a method to optimize the topology of neural networks in a soft fashion.	Review	O	0
The main idea is to formulate the network as a complete graph (or a sequence of complete subgraphs), and to optimize the relative importance of each edge using gradient descent.	Review	O	0
The overall approach is similar to differentiable architecture search, except that (1) the continuous architecture is optimized wrt the training set (instead of the validation set), and (2) the learned architecture is never discretized at the end of training.	Review	O	0
[line_break_token][line_break_token]The paper is well-organized and easy to follow.	Review	O	0
The authors have also conducted controlled experiments to convincingly show that the method is leading to improvement.	Review	O	0
[line_break_token][line_break_token]I'm a bit concerned about the technical novelty, however, as the approach can be viewed as an application of (a simplified version of) differentiable NAS to a search space analogous to the one used in [1]. In fact, the notion of soft topology has already been introduced in this prior work (Figure 2 in [1]: "The aggregation is done by weighted sum with learnable positive weights w0, w1, w2"), which was also optimized using gradient descent.	Review	B-Review	1
A difference between this work and [1] is that whether the underlying graph is complete or randomly generated, but such a distinction is minor (we can always get densely connected random graphs by adjusting the hyperparameters of the graph generator).	Review	I-Review	1
[line_break_token][line_break_token]In addition, I'm not sure whether the learned continuous \alpha can be conveniently referred to as "topology".	Review	I-Review	2
Note the mathematical definition of topology is discrete by nature.	Review	I-Review	2
I believe the authors would need to either revise this terminology (e.g., by referring to it as ‚Äúsoft topology‚Äù, as a generalized definition of hard topology), or provide a way to induce discrete subgraphs from the continuous architecture.	Review	I-Review	2
Sparsity regularization alone may not be sufficient as the non-zero \alpha's are still real-valued.	Review	I-Review	2
[line_break_token][line_break_token]Minor issue:[line_break_token]I like Figure 1 a lot.	Review	I-Review	3
However, it seems the equivalence between the 3rd and the 4th sub-figures in Figure 1 can only be established for ResNet-V2 blocks, where there is no ReLU after each addition.	Review	I-Review	3
It is not immediately obvious how this analysis can generalize to ResNet-V1 blocks (which still offers reasonably good empirical performance).	Review	I-Review	3
[line_break_token][line_break_token][1] Xie, Saining, et al. "	Review	O	0
Exploring randomly wired neural networks for image recognition."	Review	O	0
arXiv preprint arXiv:1904.01569 (2019).	Review	O	0
e thank the reviewer for the valuable feedback.	Reply	O	0
In the following, we attempt to address the reviewer's concerns:[line_break_token][line_break_token]A1: About the differences with randomly wired neural networks.	Reply	O	0
[line_break_token]What we are trying to explore is completely different with Randomly Wired Networks.	Reply	B-Reply	1
[line_break_token]Randomly wired networks claimed that random graphs generated by well-defined graph generators are good enough.	Reply	I-Reply	1
To its credit, it provides a good platform to explore more flexible network architectures.	Reply	I-Reply	1
However, its performance is largely affected by randomness as shown in Fig.	Reply	I-Reply	1
3 in their paper.	Reply	I-Reply	1
For the same generator, performances range from 72.6 to 73.4 (ER), 70.7 to 73.2 (BA) and 72.1 to 73.8 (WS).	Reply	I-Reply	1
So hyperparameters of generators need to be searched by trial-and-error.	Reply	I-Reply	1
Particularly, their experiments with ER generators indicate denseness leads to performance degradation, e.g. 72.6(P=0.8), 72.7(P=0.6), 72.8(P=0.4), 73.4(P=0.2).	Reply	I-Reply	1
We also tested ER(P=1.0) (noted Complete with in Tab.	Reply	I-Reply	1
3) in our paper, resulting in 0.40 lower than our optimization method.	Reply	I-Reply	1
These limit the search space in larger ones.	Reply	I-Reply	1
[line_break_token][line_break_token]Starting from the residual connection, we point a new topological view to find the reasons for its success.	Reply	I-Reply	1
It inspires for dense and important connections.	Reply	I-Reply	1
Furthermore, we analyze the influence of different topologies on optimization process, including not just random, but also residual and complete ones.	Reply	I-Reply	1
Searching from the complete graph with sparsity constrain proves topology can be optimized rather than randomly wired.	Reply	I-Reply	1
Our methods also compatible with existing networks.	Reply	I-Reply	1
[line_break_token][line_break_token]We also perform comparision with randomly wired networks as shown in Response to Review #3 A2.	Reply	I-Reply	1
[line_break_token][line_break_token]Topology(ImageNet)[tab_token]Top-1 Acc(%)[line_break_token][line_break_token]ER (P=0.2)[tab_token][tab_token][tab_token]77.76¬±0.23[line_break_token]BA (M=5)[tab_token][tab_token][tab_token]78.08+0.17[line_break_token]WS (K=4, P=0.75)[tab_token][tab_token]78.19¬±0.25[line_break_token]our method[tab_token][tab_token][tab_token]78.60¬±0.06[line_break_token][line_break_token]A2: The definition of topology.	Reply	O	0
[line_break_token]Our definition of topology is consistent with weighted graph in which a number (the weight) is assigned to each edge.	Reply	B-Reply	2
[line_break_token][line_break_token]A3: The generalization of the proposed topological view.	Reply	O	0
[line_break_token]Thank you for your attention to our proposed perspective.	Reply	B-Reply	3
The topological view can be used to represent ResNet, ResNeXt, MobileNet-V2 and other networks with residual connections.	Reply	I-Reply	3
When there is ReLU after addition such as ResNet-V1, it can be merged into the subsequent node with a form of ReLU/Conv/BN, and the edges should conduct additional inplace ReLU.	Reply	I-Reply	3
This transformation is equivalent to original expression, and does not change  the properties of a densely-connect network	Reply	I-Reply	3

The authors propose a method for learning models for discrete events happening in continuous time by modelling the process as a temporal point process.	Review	O	0
Instead of learning the conditional intensity for the point process, as is usually the case, the authors instead propose an elegant method based on Normalizing Flows to directly learn the probability distribution of the next time step.	Review	O	0
To further increase the expressive power of the normalizing flow, they propose using a VAE to learn the underlying input to the "Flow Module".	Review	O	0
They show by means of extensive experiments on real as well as synthetic data that their approach is able to attain and often surpass state of the art predictive models which rely on parametric modelling of the intensity function.	Review	O	0
The writers have put their contributions in context well and the presentation of the paper itself is very clear.	Review	O	0
[line_break_token][line_break_token]Though the final proof is in the pudding, and the addition of the VAE to model the base distribution yields promising results, the only justification for it in the paper is to create a more "expressive" model.	Review	B-Review	1
There are multiple ways of increasing the expressiveness of the underlying distribution: moving from RNNs to GRU or LSTMs, increasing the hierarchical depth of the recurrence by stacking the layers, increasing the size of the hidden state, more layers before the output layer, etc.	Review	I-Review	1
A convincing justification behind using a VAE for the task seems to be missing.	Review	I-Review	1
Also, using the VAE for a predictive task is a little unusual.	Review	I-Review	1
[line_break_token]  [line_break_token]Another, relatively small point which the authors glance over is the matter of efficient training.	Review	O	0
The Neural Hawkes model suffers from slow training because of the inclusion of a sampling step in the likelihood calculation.	Review	B-Review	2
I believe that since the model proposed by the authors allows easy back-propagation, their model ought to be easy and fast to train as well.	Review	I-Review	2
Including the training time for the baselines, as well as the method proposed by the authors, will help settle the point.	Review	I-Review	2
[line_break_token][line_break_token]Minor point:[line_break_token][line_break_token] - The extension of the method to Marked Temporal Point Processes in the Evaluation section seems out of place, esp.	Review	O	0
after setting up the expectation that the marks will not be modelled initially, up till footnote 2 on page 7.	Review	B-Review	3
hank you for your time and review.	Reply	O	0
We would like to clarify main concerns and raised questions.	Reply	O	0
 [line_break_token][line_break_token]C1.	Reply	O	0
Motivation behind VAE[line_break_token][line_break_token]R1.	Reply	O	0
Employing the variational auto-encoder framework in our model plays an important role in helping the flow transformations to better estimate the underlying density.	Reply	B-Reply	1
When using flow techniques for density estimation, the expressiveness of the model is not only limited by the complexity of normalizing flow transformations, but also by the class of base-distributions.	Reply	I-Reply	1
In our proposed framework, the fact that flow transformations are shared across time-steps and the true underlying distribution across time-steps might vary a lot, makes our model more sensitive to the choice of base distribution family.	Reply	I-Reply	1
We believe that, if we choose to model base distributions as Gaussian distributions with deterministic parameters, the bijective transformation might not be able to estimate underlying distributions well, especially when the the ground-truth target distributions varies a lot across time-steps of all the sequences.	Reply	I-Reply	1
 [line_break_token]In order to address this shortcoming, we proposed more flexible base distributions where the parameters are probabilistically modeled using variational auto-encoder framework.	Reply	I-Reply	1
The flexibility comes from the fact that by marginalizing over the latent space of VAE , the base distribution could be highly flexible.	Reply	I-Reply	1
The base distribution of follows different Gaussian distributions conditioned on different samples of.	Reply	I-Reply	1
[line_break_token][line_break_token]To motivate this argument, we designed the following experiment:[line_break_token][line_break_token]Consider a dataset of sequences, where in each sequence, the underlying distribution at each time-step varies from a Gaussian distribution to a mixture of Gaussians where one mode of mixture of Gaussians has the same mean and variance as the other unimodal Gaussian distribution.	Reply	I-Reply	1
 We trained both PPF-D and PPF-P on this synthetic dataset and experimental results show that PPF-D is not able to fully recover the true underlying distribution.	Reply	I-Reply	1
The motivation for this experiment is that, in our example by modelling the base distribution with the deterministic parameters, there could be no one-to-one transformation that can map two Gaussian base distributions exactly into a uni-modal and a multi-modal distribution respectively at the same time.	Reply	I-Reply	1
In other words, if a singular one-to-one mapping can map a Gaussian distribution to the mixture of Gaussian distribution in our example, the inverse mapping of either component of mixture of Gaussians distribution can not be exactly Gaussian.	Reply	I-Reply	1
 This is proved in Proposition 1 in Appendix A.[line_break_token]We visualized  samples generated by both PPF-P and PPF-D for an even and odd time-step.	Reply	I-Reply	1
The results illustrate when the true underlying distribution is a mixture of Gaussians, PPF-D covers both components of the kernels but most of the samples are concentrated in an area of low probability, somewhere in between the means of the two components of mixture distribution.	Reply	I-Reply	1
In contrast, the results show that PPF-P, with a more flexible base-distribution, is much better in estimating the true underlying distribution.	Reply	I-Reply	1
 Most of the data sampled from PPF-P model lie in the high-probability region.	Reply	I-Reply	1
[line_break_token]We reported the log-likelihood of test data for both PPF-P and PPF-D and also reported the difference of log-likelihood under the true distribution and log-likelihood under the learned models (LL score).	Reply	I-Reply	1
 The better estimation of PPF-P is confirmed by having a higher log-likelihood and a lower LL score in comparison to PPF-D. Please see Appendix A for experimental results and more details on this example.	Reply	I-Reply	1
[line_break_token][line_break_token]C2.	Reply	O	0
Comparison of Run-time[line_break_token][line_break_token]R2.	Reply	O	0
We thank the reviewer for suggesting the running-time evaluation experiment.	Reply	B-Reply	2
Here we report the running time of passing a single sequence of IP process with 21 events to different models for both training and inference time.	Reply	I-Reply	2
At inference time of all models, at each time-step,  we sample 1500 inter-arrival times from the predicted distribution.	Reply	I-Reply	2
The reported times are average of execution time for 50 trials.	Reply	I-Reply	2
[line_break_token][line_break_token]                  Training time (s)    Inference Time (s)[line_break_token]PPF-P            0.150244                  0.041857[line_break_token]APP-VAE       0.054544                  0.076158[line_break_token]APP-LSTM    0.054506                  0.037435[line_break_token][line_break_token]We do not report the running time of PPF-D as the code for PPF-D was not fully optimized to get the minimum training time possible.	Reply	I-Reply	2
For the camera-ready version, we will optimize the PPF-D code and the results to the table.	Reply	I-Reply	2

This paper proposed to use graph-based deep learning methods to apply deep learning techniques to images coming from omnidirectional cameras.	Review	O	0
It solves the problem of distorsions introduced by the projection of such images by replacing convolutions by graph-based convolutions, with in particular a combinaison of directed graphs which makes the network able to distinguish between orientations.	Review	O	0
[line_break_token][line_break_token]The paper is fairly well written and easy to follow, and the need for treating omnidirectional images differently is well motivated.	Review	O	0
However, since the novelty is not so much in the graph convolution method, or in the use of graph methods for treating spherical signals, but in the combined application of the particular graph method proposed to the domain of omnidirectional images, I would expect a more thorough experimental study of the merits of the method and architectural choices.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
The projected MNIST dataset looks very localized on the sphere and therefore does not seem to leverage that much of the global connectivity of the graph, although it can integrate deformations.	Review	B-Review	1
Since the dataset is manually projected, why not cover more of the sphere and allow for a more realistic setting with respect to omnidirectional images?	Review	I-Review	1
[line_break_token]More generally, why not use a realistic high resolution classification dataset and project it on the sphere?	Review	I-Review	1
While it wouldn't allow for all the characteristics of omnidirectional images such as the wrapping around at the borders, it would lead to a more challenging classification problem.	Review	I-Review	1
Papers such as [Khasanova & Frossard, 2017a] have at least used two toy-like datasets to discuss the merits of their classification method (MNIST-012, ETH-80), and a direct comparison with these baselines is not offered in this work.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
The method can be applied for a broad variety of tasks but by evaluating it in a classification setting only, it is difficult to have an estimate of its performance in a detection setting, where I would see more uses for the proposed methods in such settings (in particular with respect to rotationally invariant methods, which do not allow for localization).	Review	B-Review	2
[line_break_token][line_break_token]3.	Review	O	0
I fail to see the relevance of the experiments in Section 4.2 for a realistic application.	Review	B-Review	3
Supposing a good model for spherical deformations of a lens is known, what prevents one from computing a reasonable inverse mapping and mapping the images back to a sphere?	Review	I-Review	3
If the mapping is non-invertible (overlaps), then at least using an approximate inverse mapping would yield a competitive baseline.	Review	I-Review	3
[line_break_token]I am surprised at the loss of accuracy in Table 2 with respect to the spherical baseline.	Review	I-Review	3
Can you identify the source of this loss?	Review	I-Review	3
Did you retrain the networks for the different deformations, or did you only change the projection of the network trained on a sphere?	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	I-Review	3
While the papers describes what happens at the level of the first filters, I did not find a clear explanation of what happens in upper layers, and find this point open to interpretation.	Review	I-Review	4
Are graph convolutions used again based on the previous polynomial filter responses, sampling a bigger region on the sphere?	Review	I-Review	4
Could you clarify this?	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	O	0
I would also like to see a study of the choice of the different scales used (in particular, size of the neighborhood).	Review	B-Review	5
[line_break_token][line_break_token]Overall, I find that the paper introduces some interesting points but is too limited experimentally in its current form to allow for a fair evaluation of the merits of the method.	Review	O	0
Moreover, it leaves some important questions open as to how exactly it is applied (impact of sampling/neighborhood size, design of convolutions in upper layer...) which would need to be clarified and tested.	Review	O	0
[line_break_token][line_break_token]Additional small details:[line_break_token]- please do not use notation for the neighborhood, it suggests integers[line_break_token]- p. 4 "While effective, these filters ... as according to Eq. (	Review	O	0
2) filter..." -> article missing for the word "filter"[line_break_token]	Review	O	0
We thank reviewer for the comments.	Reply	O	0
Please find the answer on your questions below:[line_break_token][line_break_token]1.	Reply	O	0
We have experimented with the MNIST dataset to show the ability of our method adapt to different geometries of projective surface.	Reply	B-Reply	1
We have further tried projecting other images on the sphere, but the resulting representations had various unrealistic artifacts on the borders of projected images.	Reply	I-Reply	1
We therefore evaluated our method on a different image compression task, for which we could obtain good quality real omnidirectional images.	Reply	I-Reply	1
We have updated the results section of our paper to include this experiment.	Reply	I-Reply	1
The method further show that our approach is applicable to a wide range of tasks, while the competing method were solely designed for image classification.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
This is a very good point.	Reply	B-Reply	2
Indeed, as we discussed above, we have also experimented with the compression problem and show now the evaluation of our approach in Section 4.3 of the revised manuscript.	Reply	I-Reply	2
Briefly we show that, due to the knowledge of the projective geometry that is encoded in the graph structure, we can easily avoid artifacts in the compressed images that are present when using conventional image coding methods.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Indeed for some of the surfaces it is possible to compute the mapping to the spherical one, however even if a reasonable mapping can be found, the necessity of computing one makes it harder to apply techniques developed for spherical images to other surfaces.	Reply	B-Reply	3
While our method does not need this additional preprocessing step, which makes it readily applicable to different surfaces, as depicted by our experiments in the Results section.	Reply	I-Reply	3
Further the fact that our approach works directly with the given surface allows it to avoid interpolation artifacts, which may be introduced during the interpolation process, when the given surface is mapped to the spherical one.	Reply	I-Reply	3
[line_break_token]In Table 2 we can see that our same algorithm adapts to different surface shapes as they are encoded in the graph structure.	Reply	I-Reply	3
In these experiments, SphericalCNN does  not have the knowledge about the change of the projection, which results in a drop of performance.	Reply	I-Reply	3
Regarding the second part of the question, we would like to clarify that we train separate networks for each of the surfaces.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	2
Thank you for this question, we add the description about this point in Section 4.1 in updated version of the paper.	Reply	I-Reply	4
For all the graph-based approaches we use the graph-based convolutions with stride two on each layer.	Reply	I-Reply	4
This allows to increase the size of the receptive field for the neurons in the deeper layers of the network, similarly to the classic ConvNets.	Reply	I-Reply	4
This in turns allows the network to process the information from the large area on the sphere without increasing the number of parameters.	Reply	I-Reply	4
It is important to note here that having a strided convolution requires building a separate graph for every convolutional layer of the network, which is a subsampled version of the graph from the previous convolutional layer.	Reply	I-Reply	4
[line_break_token]5.	Reply	O	0
Thank you for the comment.	Reply	B-Reply	5
In this paper we mostly focus on the introduction of the generic way of defining an anisotropic graph-based convolutional filter.	Reply	I-Reply	5
We have experimented with some variations of shape and size of the filters, and did not observe significant changes in performance.	Reply	I-Reply	5
Nevertheless, we believe that a complete study of all possible modifications of the of shape and size of the areas on the tangent plane that define the filter is a very interesting direction for the future research.	Reply	I-Reply	5
[line_break_token][line_break_token]We have modified the text of the paper to better focus on the advantages of the proposed technique.	Reply	I-Reply	5
We have further added an evaluation of our approach on a different image compression problem, which shows the generality of the approach with respect to the competing methods.	Reply	I-Reply	5
[line_break_token][line_break_token]We would also like to further thank reviewer for the style suggestion and pointing out the typo.	Reply	I-Reply	7
We updated the text accordingly	Reply	I-Reply	7

The manuscript proposes a generative approach to detect which samples are within vs. out of the sample space of the training distribution.	Review	O	0
This distribution is used to adjust the classifier so it makes confident predictions within sample, and less confident predictions out of sample, where presumably it is prone to mistakes.	Review	O	0
Evaluation on several datasets suggests that accounting for the within-sample distribution in this way can often actually improve evaluation performance, and can help the model detect outliers.	Review	O	0
[line_break_token][line_break_token]The manuscript is reasonably well written overall, though some of the writing could be improved e.g. a clearer description of the cost function in section 2.	Review	O	0
However, equation 4 and algorithm 1 were very helpful in clarifying the cost function.	Review	O	0
The manuscript also does a good job giving pointers to related prior work.	Review	O	0
The problem of interest is timely and important, and the provided solution seems reasonable and is well evaluated.	Review	O	0
[line_break_token][line_break_token]Looking at the cost function and the intuition, the difference in figure 1 seems to be primarily due to the relative number of samples used during optimization -- and not to anything inherent about the distribution as is claimed.	Review	B-Review	1
In particular, if a proportional number of samples is generated for the 50x50 case, I would expect the plots to be similar.	Review	I-Review	1
I suggest the authors modify the claim of figure 1 accordingly.	Review	I-Review	1
[line_break_token][line_break_token]Along those lines, it would be interesting if instead of the uniform distribution, a model that explicitly models within vs. out of sample might perform better?	Review	I-Review	1
Though this is partially canceled out by the other terms in the optimization.	Review	I-Review	1
[line_break_token][line_break_token]Finally, the authors claim that the PT is approximately equal to entropy.	Review	I-Review	2
The cited reference (Zhao et.	Review	I-Review	2
al.	Review	I-Review	2
2017) does not justify the claim.	Review	I-Review	2
I suggest the authors remove this claim or correctly justify it.	Review	I-Review	2
[line_break_token][line_break_token]Questions:[line_break_token] - Could the authors comment on cases where such a strong within-sample assumption may adversely affect performance?	Review	O	0
[line_break_token] - Could the authors comment on how the modifications affect prediction score calibration?	Review	O	0
[line_break_token] - Could the authors comment on whether they think the proposed approach may be more resilient to adversarial attacks?	Review	O	0
[line_break_token][line_break_token]Minor issues:[line_break_token] - Figure 1 is unclear using dots.	Review	O	0
Perhaps the authors can try plotting a smoothed decision boundary to clarify the idea?	Review	B-Review	6
We very much appreciate your valuable comments, efforts and times on our paper.	Reply	O	0
We provide our responses for all questions below.	Reply	O	0
Revised parts in the new draft are colored by blue.	Reply	O	0
[line_break_token][line_break_token]Q1: "About the difference in figure 1."	Reply	O	0
[line_break_token][line_break_token]A1: First, we emphasize that we use the same number (i.e., 100) of training out-of-distribution samples for Figure 1(a)/(b) and 1(c)/(d).	Reply	O	0
As you pointed out, if one increases the number of training out-of-distribution samples for the 50x50 case, Figure 1(b) is expected to be similar to Figure 1(d).	Reply	B-Reply	1
In other words, one needs more samples in order to train confidence classifier if samples are generated from the entire space, i.e., 50x50.	Reply	I-Reply	1
However, as we mentioned, this might be impossible and not efficient since the number of out-of-distribution training samples might be almost infinite to cover its entire, high-dimensional data space.	Reply	I-Reply	1
Therefore, instead, we suggest to sample out-of-distribution close to in-distribution, which could be more effective (given the fixed sampling complexity).	Reply	I-Reply	1
The difference in Figure 1 confirms such intuition.	Reply	I-Reply	1
We clarified this more in the revision (Section 2.1).	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: "Justification of PT."	Reply	O	0
[line_break_token][line_break_token]A2: We agree with you that Zhao et al.	Reply	O	0
did not justify the claim.	Reply	B-Reply	2
But, the PT corresponds to the squared cosine similarity of generated samples, and intuitively one can expect the effect of increasing the entropy by minimizing it.	Reply	I-Reply	2
In the recent work [1], the authors also used PT to maximize the entropy.	Reply	I-Reply	2
However, as we mentioned in A3 for Reviewer_1, after our submission, we actually verified that PT helps, but its gains are relatively marginal in overall.	Reply	I-Reply	2
Since PT increases the training complexity, we decided to remove the PT in the revision and have updated all experimental results without using PT.	Reply	I-Reply	2
Finally, for interested readers, we also report the effects of PT in the Appendix D. We really appreciate your valuable comments.	Reply	I-Reply	2
We updated Section 2.2 and 2.3.	Reply	I-Reply	2
Figure 3, 4 and 5.	Reply	I-Reply	2
Appendix D. accordingly.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: "About cases where such a strong within-sample assumption may adversely affect performance."	Reply	O	0
[line_break_token][line_break_token]A3: As shown in Table 1 and Table 2 (in Appendix C),  splitting in- and out-of-distributions and optimizing the confidence loss (1) does not adversely affect the classification accuracy due to the high expressive power of deep neural networks in all our experiments.	Reply	O	0
We haven't found a case where our proposed method (based on this assumption) leads to adverse performance.	Reply	B-Reply	3
However, more theoretical investigation on whether this assumption guarantees a good performance or whether there is a counterexample would be an interesting future work.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4: "How do the modifications affect prediction score calibration?"	Reply	O	0
[line_break_token][line_break_token]A4: Thank you for your great suggestion.	Reply	O	0
After our submission, we actually verified that our method can improve the prediction score calibration.	Reply	B-Reply	4
For example, the expected calibration error (ECE) [2] of a classifier trained by our method is lower than that of a classifier trained by the standard cross entropy loss.	Reply	I-Reply	4
For interested readers, we reported the corresponding experimental results in the revision (see Appendix C.2).	Reply	I-Reply	4
[line_break_token][line_break_token]Q5: "Whether the proposed approach may be more resilient to adversarial attacks."	Reply	O	0
[line_break_token][line_break_token]A5: This is a very interesting question.	Reply	O	0
We believe our method has some potential for being more resilient to adversarial attacks.	Reply	B-Reply	5
This is because adversarial examples are special types of out-of-distribution samples.	Reply	I-Reply	5
We believe that this should be an interesting future direction to explore.	Reply	I-Reply	5
[line_break_token][line_break_token][1] Shiyu Liang, Yixuan Li, and R Srikant.	Reply	O	0
Principled detection of out-of-distribution examples in neural networks.	Reply	O	0
arXiv preprint arXiv:1706.02690, 2017. (	Reply	O	0
<a href="https://arxiv.org/abs/1706.02690)" target="_blank" rel="nofollow">https://arxiv.org/abs/1706.02690)</a>[line_break_token][2] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger.	Reply	O	0
On calibration of modern neural networks.	Reply	O	0
In ICML, 2017. (	Reply	O	0
<a href="https://arxiv.org/abs/1706.04599)" target="_blank" rel="nofollow">https://arxiv.org/abs/1706.04599)</a> [line_break_token][line_break_token]Thanks,[line_break_token]Authors	Reply	O	0

This paper studies the application of techniques from meta-learning (a method[line_break_token]to train a single model which can then be easily adjusted to perform well on[line_break_token]multiple tasks) to federated learning (the task of distributed training of[line_break_token]models on distributed datasets).	Review	O	0
 The paper notes that standard meta-learning[line_break_token]algorithms are similar to standard federated learning algorithms, and uses[line_break_token]this perspective to produce a merged method and evaluate it empirically.	Review	O	0
[line_break_token][line_break_token]Pros.	Review	O	0
[line_break_token]+ The motivation of the paper is clear and indeed these methods seems similar,[line_break_token] and meta-learning can help with federated learning.	Review	O	0
[line_break_token][line_break_token]Cons.	Review	O	0
[line_break_token]- The resulting method appears somewhat underdeveloped; it is simply to run[line_break_token] some amount of federated learning and then some amount of meta-learning,[line_break_token] whereas the first parts of the paper led me to believe that a single[line_break_token] simultaneous merge of the methods is the way to go.	Review	O	0
 The paper does not[line_break_token] report any fine-grained evaluation of various such choices, thus I don't know[line_break_token] why they did that they did, and thus do not find their choices compelling.	Review	B-Review	1
[line_break_token]- The Reptile method is already presented in the original paper with[line_break_token] a distributed counterpart, so why not just run that?	Review	O	0
 I am not convinced that[line_break_token] some more minor modification of Reptile could not already do well on this[line_break_token] paper.	Review	B-Review	2
[line_break_token]- The empirical evaluation is not very extensive, so I am also not convinced[line_break_token] there, and in particular I need convincing of this type to believe that[line_break_token] regular reptile is beaten by FedAvg+reptile.	Review	O	0
[line_break_token][line_break_token]Minor comments.	Review	O	0
[line_break_token]Page 1, second paragraph, the word "outperform".	Review	B-Review	4
 I'm not sure what the[line_break_token]performance measure is; in federated learning, we care about many things, for[line_break_token]instance privacy, keeping the work on the distributed clients low, etc.	Review	I-Review	4
[line_break_token]Page 2, the "three objectives".	Review	I-Review	5
 I feel meta-learning is doing all three too.	Review	I-Review	5
[line_break_token]Page 3, Algorithm 1.	Review	I-Review	6
 I realize space is a concern, but this was hard to read.	Review	I-Review	6
[line_break_token]Page 4, Algorithm 2.	Review	I-Review	7
 "relatively larger" is vague.	Review	I-Review	7
e thank the reviewer #4 for their time.	Reply	O	0
[line_break_token][line_break_token]We agree that the method we experiment with, Algorithm 2, is not particularly complex or novel.	Reply	B-Reply	7
Note, however, this is not what we present as our main contribution, either.	Reply	I-Reply	7
It is not mentioned in the abstract nor the concluding chapter.	Reply	I-Reply	7
[line_break_token][line_break_token]Re: ‚Äú...to believe that regular reptile is beaten by FedAvg+reptile.	Reply	O	0
‚Äù[line_break_token]Related to the above point, we never make such a claim, or that this would even be our objective.	Reply	O	0
[line_break_token][line_break_token]Let us restate the design objectives from Section 1: (1) good initial global model, (2) good personalized model, and (3) fast convergence.	Reply	B-Reply	3
[line_break_token][line_break_token]In Section 2, we show that FedAvg and Reptile are essentially the same, with the difference being that FedAvg handles different local data size differently, while this was non-existing concern in the setting in which Reptile was introduced.	Reply	I-Reply	3
[line_break_token][line_break_token]Running with FedAvg with large epoch addresses (2) and, mainly (3), but lacks (1).	Reply	I-Reply	3
Then switching to a smaller number of steps, independent of the amount of local data (i.e., Reptile) improves (1), without hurting (2) and not needing many additional iterations (3).	Reply	I-Reply	3
This contrasts with the experiments in the original Reptile paper, where on the Omniglot task, 40,000 iterations are presented - which would be very expensive in the context of FL.	Reply	I-Reply	3
[line_break_token][line_break_token]We also show that (and we don‚Äôt find this intuitively expected) Reptile with different number of steps show quite different performance - using K=1 degrades the personalized performance.	Reply	I-Reply	3
[line_break_token][line_break_token]In summary, our claim is not that one algorithm ‚Äúbeats‚Äù another in a narrow sense, but rather when focusing on the three objectives simultaneously, a combination works better than either of them separately.	Reply	I-Reply	3
Fig 2 then shows that models of similar initial accuracy can have very different capacity to personalize, motivating the case for expanding the scope of MAML algorithms, as suggested in the concluding Section 4.	Reply	I-Reply	3
[line_break_token][line_break_token]---[line_break_token]Re: ‚Äúthe "three objectives".	Reply	O	0
 I feel meta-learning is doing all three too.	Reply	O	0
‚Äù[line_break_token]The problems commonly studied for supervised MAML (random sine wave and Omniglot) do not admit any meaningful notion of initial accuracy - any model is just a random guess.	Reply	O	0
We think this is the main reason why the gap presented in Figure 2 have not been observed before, and that FL applications should become a common part of benchmarks for MAML algorithms.	Reply	B-Reply	5
[line_break_token][line_break_token]Re: Distributed Reptile[line_break_token]We are not sure what you refer to.	Reply	O	0
The paper <a href="https://arxiv.org/pdf/1803.02999.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1803.02999.pdf</a> has only a single short remark (end of Section 3) on anything related to distributed optimziation.	Reply	O	0
[line_break_token][line_break_token]Please also see our shared response to all reviewers.	Reply	O	0

The paper continues the line of work on emergent compositionality in dialogs, and here it is extended to handle groups of interacting agents that pass language in an evolutionary way from one generation to another.	Review	O	0
The key idea is that with group of interacting agents, if some agents are replaced with new ones, then the newbies would learn the same language as the group.	Review	O	0
[line_break_token][line_break_token]General assessment: [line_break_token][line_break_token]The setup of the paper is is interesting, and the paper covers a lot of ground.	Review	O	0
The paper makes bold claims like "cultural transmission induces compositionality" and "Variations in replacement strategy tend to not affect performance".	Review	O	0
Unfortunately, the paper does not systematic provide experimental evidence to adequately support its claims.	Review	B-Review	1
[line_break_token][line_break_token]In my experience, the emergence of compositionality (or lack of) in the setup learned here is very sensitive to various aspects of the learning setup, hence are hard to reproduce.	Review	I-Review	1
Specifically, they the task-and-talk paper by Kottur et al may yield different conclusions, if parameters of the original experiments are modified, even slightly.	Review	I-Review	1
The current paper does improve the evaluation protocol of Kottur 2017 by reporting variance over runs, but does not explore the parameter space more systematically, hence I am concerned that it may suffer from similar fragility.	Review	I-Review	1
[line_break_token][line_break_token]In this light, significantly more evidence should be provided to convince that the experimental results are stable and can be reproduced.	Review	I-Review	1
 First, one needs to show the experiments repeated over the full range of setup parameters.	Review	I-Review	1
Including, the vocabulary sizes V_Q and V_A, the number of tasks, the number of attributes per task, and number of agents etc.	Review	I-Review	1
Similarly, the current paper introduces a new compositional split, generated in one specific way.	Review	I-Review	1
The effect of the split on what aspects of language emerge should be studied systematically, instead of using one "hard" and one random split.	Review	I-Review	1
[line_break_token]The "evolutionary" part has a similar issue.	Review	I-Review	1
The paper draws conclusions from three anecdotal rules for replacing the population.	Review	I-Review	1
There is no systematic analysis of the "evolution" process, not even studying a range of the parameter epsilon, which is set 0.8 (arbitrarily?	Review	I-Review	1
to fit the story?	Review	I-Review	1
we do not know).	Review	I-Review	1
 Drawing conclusions based on anecdotal evidence is bad scientific practice, that ICLR should discourage.	Review	I-Review	1
[line_break_token][line_break_token]While the ideas in this paper are innovative and exciting, the paper promises much more than its analysis supports, and the paper is not ready for publication.	Review	O	0
[line_break_token][line_break_token]Other comments: [line_break_token]-- The paper states that "darker blue bars" in figure 2 are higher.	Review	O	0
The statistical analysis is not well explained, not even in the supplemental, so it is hard to tell which differences are significant.	Review	B-Review	2
If data is paired, it would be useful to view data as a scatter plot, instead of a barplot which hides the pairing.	Review	I-Review	2
BTW, p&lt;0.05 is not a "strong support", but rather is the most permissive threshold.	Review	O	0
The results in the supplemental may be stronger.	Review	B-Review	3
[line_break_token]-- "Variations in replacement strategy tend to not affect performance."	Review	O	0
This is a key result of the paper and mush be quantified and analyzed.	Review	B-Review	1
Authors should define some space of replacements strategies (e.g. in in parametric ways like  how often and how many agents are replaced), then compute performance difference as a function of grid search over the parameter space and show a figure.	Review	I-Review	1
[line_break_token]-- "We stop after 8 generations".	Review	O	0
Justify with data.	Review	B-Review	4
[line_break_token]-- Other parts of the paper make additional claims, that should similarly be systematically analyzed and supported with data-driven evidence.	Review	O	0
[line_break_token]	Review	O	0
hanks for the review.	Reply	O	0
It raises some serious concerns, however we think they can be appropriately addressed and have attempted to do so in our responses below.	Reply	O	0
[line_break_token][line_break_token]__Comment (insufficient experiments)__: ‚ÄúIn my experience, the emergence of compositionality (or lack of) in the setup learned here is very sensitive[...]‚Äù ‚ÄúThe current paper does improve the evaluation protocol[...] but does not explore the parameter space more systematically, hence I am concerned that it may suffer from similar fragility.	Reply	O	0
‚Äù[line_break_token][line_break_token]‚ÄúIn this light, significantly more evidence should be provided to convince that the experimental results are stable and can be reproduced.	Reply	O	0
‚Äù[line_break_token][line_break_token]‚ÄúThe "evolutionary" part has a similar issue.	Reply	O	0
The paper draws conclusions from three anecdotal rules for replacing the population.	Reply	O	0
There is no systematic analysis of the "evolution" process[‚Ä¶] Drawing conclusions based on anecdotal evidence is bad scientific practice, that ICLR should discourage.	Reply	O	0
‚Äù[line_break_token][line_break_token]‚Äú"Variations in replacement strategy tend to not affect performance."	Reply	O	0
This is a key result of the paper and mush be quantified and analyzed.	Reply	O	0
‚Äù[line_break_token][line_break_token]__Response__:[line_break_token]We are also concerned that our experiments may suffer from some fragility, partially because of the fragility we found in the experiments of Kottur et.	Reply	O	0
al.	Reply	B-Reply	1
That is exactly why we extended our experiments to capture much of this variance, as mentioned.	Reply	I-Reply	1
We further agree that our claims should be softer, perhaps changing "cultural transmission induces compositionality" to ‚Äúour replacement strategies increase compositionality.	Reply	I-Reply	1
‚Äù[line_break_token][line_break_token]However, as R3 puts it, in papers like this there are ‚Äúnever-ending experiments‚Äù and the question is whether or not ‚Äúthis paper [has] enough of these never-ending experiments.	Reply	I-Reply	1
‚Äù[line_break_token]We agree with R3 that this paper does have enough of these never ending experiments.	Reply	I-Reply	1
We think Figure 2 and the p values reported in A.3 show a clear increase in compositionality as a result of our replacement strategies and we systematically consider variations in Memory, Vocab Size, Number of Agents, and Replacement Strategy:[line_break_token][line_break_token]Grid search dimensions[line_break_token](Model) Memory: Memory vs No Memory[line_break_token](Model) Vocab Size: Small vs Large/Overcomplete Vocab[line_break_token](Method) Number of Agents: Single vs Multiple Agents[line_break_token](Method) Replacement Strategy: No Replacement vs Random vs Epsilon Greedy vs Oldest[line_break_token][line_break_token]We did search over how often our agents are replaced in our initial experiments and found that replacement every 25000 epochs is a good tradeoff between allowing agents to converge in a generation and enabling us to run multiple generations.	Reply	I-Reply	1
New agents usually converge in this length of time.	Reply	I-Reply	1
Increasing this parameter is expensive because it must be increased for every generation, making each increase 8x more expensive (given our 8 generations).	Reply	I-Reply	1
[line_break_token][line_break_token]We‚Äôd also like to point out that just the experiments we reported in the paper took over 3 GPU months to run.	Reply	I-Reply	1
That‚Äôs a conservative back of the envelope calculation that assumes each single agent model takes 20min to train and each multi-agent model takes 6hr40min to train (about right for our implementation).	Reply	I-Reply	1
This does not include the iterations our models went through before converging on the models presented in the paper, which likely multiply that figure by at least 2x or 3x.	Reply	I-Reply	1
Running the additional experiments would take a long time because they would have to include all of the hyperparameter variations we have already considered.	Reply	I-Reply	1
[line_break_token][line_break_token]Both R4 (‚Äúthe experimental results largely confirm the hypothesis‚Äù) and R3 (‚ÄúThe claim is clear, the hypotheses are well-stated, and the experiments look solid‚Äù) agree that our experiments support our main claim.	Reply	I-Reply	1
Is our main claim invalid without the additional experiments requested here?	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]__Comment__: ‚ÄúThe statistical analysis is not well explained, not even in the supplemental, so it is hard to tell which differences are significant.	Reply	O	0
If data is paired, it would be useful to view data as a scatter plot, instead of a barplot which hides the pairing.	Reply	O	0
‚Äù[line_break_token]__Response__: We pair the 16 different random seed/split variations.	Reply	O	0
We report dependent paired t-test p values between each pair of experiments (114 tests with 16 instances in each case) in appendix A.3.	Reply	B-Reply	2
We‚Äôre not sure we quite understand the plotting suggestion here.	Reply	I-Reply	2
Should we plot model performance with random seed and split values on the x and y axes?	Reply	I-Reply	2
[line_break_token][line_break_token]__Comment__: ‚ÄúBTW, p&lt;0.05 is not a "strong support", but rather is the most permissive threshold.	Reply	O	0
The results in the supplemental may be stronger.	Reply	O	0
‚Äù[line_break_token]__Response__: In almost every case p&lt;0.01 (comparing Replacement and No Replacement models), as reported in A.3.	Reply	O	0
[line_break_token][line_break_token][line_break_token]__Comment__: ‚ÄúOther parts of the paper make additional claims, that should similarly be systematically analyzed and supported with data-driven evidence.	Reply	O	0
‚Äù[line_break_token]__Response__: Could the reviewer point out the specific parts of the paper that make additional claims without evidence	Reply	O	0

This paper improves the robustness of smoothed classifiers by maximizing the certified radius, which is more efficient than adversarially train the smoothed classifier and achieves higher average robust radius and better certified robustness when the radius is not much larger than the training sigma.	Review	O	0
It proposes a novel objective which is derived by decomposing the 0/1 certified loss into the sum of 0/1 classification error and 0/1 robustness error.	Review	O	0
Three conditions are identified to make the optimization doable.	Review	O	0
Two surrogate losses (CE and hinge loss on the certified radius) for the two 0/1 errors are proposed as upper bounds of the 0/1 loss.	Review	O	0
Certified radius is derived as a function of the logits of Soft-RS to make the hinge loss differentiable.	Review	O	0
Numerical stability of the proposed objective is also analyzed by showing its gradient is bounded.	Review	O	0
[line_break_token][line_break_token]In general, the paper is well-written and the proposed objective is novel to my knowledge.	Review	O	0
I tend to accept the paper.	Review	O	0
Still, I am not sure about how much MACER improves upon the baselines, and would like to ask some questions.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
Cross entropy is used as a surrogate for the 0/1 classification error.	Review	B-Review	1
This is true for all cases (including all experiments in this paper) except for binary classification, where the cross entropy is less than 1 when the score on the correct class is around 0.5.	Review	I-Review	1
It is not important but would be better if you could mention this point.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Have you ever tried using a tighter upper bound for the 0/1 classification error, e.g., using cross entropy loss only for the wrongly classified samples?	Review	B-Review	2
How does it affect the results?	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Despite showing better results, MACER seems to be using much more epochs than the two baselines (but the total hrs is smaller than (Salman et al.	Review	B-Review	3
2019)).	Review	I-Review	3
Also, MACER is using a much larger k than (Cohen et al.,	Review	I-Review	3
2019).	Review	I-Review	3
From Figure 3 (a) we can see a larger k improves the result a lot, and from Figure 3 (b) it seems that setting lambda to a non-zero value only improves the accuracy when the radius is large.	Review	I-Review	3
For fair comparisons, could the authors give the ACR with different values of lambda while keeping other hyper parameters unchanged?	Review	I-Review	3
Is Salman's method still not as good when using the same number of epochs?	Review	I-Review	3
[line_break_token]	Review	O	0
ear AnonReviewer1,[line_break_token] [line_break_token]Thank you for carefully reading our paper and offering us insightful suggestions.	Reply	O	0
Here are our responses to your questions and concerns:[line_break_token] [line_break_token][Regarding cross entropy as a surrogate loss][line_break_token] [line_break_token]This is a good catch.	Reply	O	0
In fact, the logistic loss is a valid surrogate loss for binary classification (see e.g. [1]), and it only differs from the cross entropy loss by a constant ln(2) factor.	Reply	B-Reply	1
Therefore, as the reviewer noted, it is not important since we can simply multiply the cross-entropy loss by a constant factor, and the surrogate condition is still satisfied in binary classification up to this constant factor.	Reply	I-Reply	1
[line_break_token] [line_break_token][Regarding using a tighter upper bound for the 0/1 classification error]:[line_break_token] [line_break_token]It is a natural idea to try to use a tighter upper bound for the 0/1 error.	Reply	O	0
However, the main purpose of using surrogate losses is to overcome the non-differentiability and discontinuity of the 0/1 error.	Reply	B-Reply	2
If the cross-entropy loss is only used for incorrectly classified samples, it would still be discontinuous on the decision boundary - the loss is zero for correctly classified samples, but 1 for misclassified ones.	Reply	I-Reply	2
Hence, this approach is conceptually good but ill-posed in terms of optimization, and it indeed degrades the performance of the algorithm according to our preliminary experiments.	Reply	I-Reply	2
[line_break_token] [line_break_token][Regarding the experiments][line_break_token] [line_break_token](a) The number of epochs: First, please note that we are making a fair comparison between MACER and Salman et al.,	Reply	O	0
in the sense that we are comparing **the best performance of both algorithms** (see the footnote on page 9).	Reply	B-Reply	3
Salman et al.	Reply	I-Reply	3
released all checkpoints and their corresponding training logs, and we compare our model with the best of their models for each.	Reply	I-Reply	3
[line_break_token][line_break_token]Second, we follow the reviewer's request to perform experiments on CIFAR-10 using the same number of epochs as Salman et al.	Reply	I-Reply	3
used.	Reply	I-Reply	3
The results are attached below:[line_break_token] [line_break_token]  |Algorithm    | Epochs | 0.00 | 0.25 | 0.50 | 0.75 | 1.00 | 1.25 |  ACR  | Total hrs   |[line_break_token]-------------------------------------------------------------------------------------------------------[line_break_token]  |Salman-0.25  |  150   | 0.74 | 0.67 | 0.57 | 0.47 | 0.00 | 0.00 | 0.538 |    82.92    |[line_break_token]  |MACER-0.25 |  150   | 0.76 | 0.67 | 0.57 | 0.42 | 0.00 | 0.00 | 0.531 |    21.00    |[line_break_token]  |MACER-0.25 |  440   | 0.81 | 0.71 | 0.59 | 0.43 | 0.00 | 0.00 | 0.556 |    61.60    |[line_break_token]-------------------------------------------------------------------------------------------------------[line_break_token]  |Salman-0.50  |  150   | 0.50 | 0.46 | 0.44 | 0.40 | 0.38 | 0.33 | 0.709 |    82.92    |[line_break_token]  |MACER-0.50 |  150   | 0.62 | 0.57 | 0.50 | 0.44 | 0.38 | 0.29 | 0.712 |    21.00    |[line_break_token]  |MACER-0.50 |  440   | 0.66 | 0.60 | 0.53 | 0.46 | 0.38 | 0.29 | 0.726 |    61.60    |[line_break_token] [line_break_token]As the result shows, our models at the 150th epoch achieve comparable performance with Salman et al.	Reply	I-Reply	3
's, while they are trained almost 4x faster since our method does not rely on adversarial training.	Reply	I-Reply	3
This clearly illustrates the efficiency and effectiveness of our algorithm.	Reply	I-Reply	3
We have put these model checkpoints on Github for your reference.	Reply	I-Reply	3
[line_break_token] [line_break_token](b) The number of Gaussian samples (k): We use a larger k due to the fact that we need to estimate the certified radius in the robustness loss accurately.	Reply	O	0
The inverse cdf function (Eqn 16) is sensitive to its input (i.e., the value of the probability).	Reply	B-Reply	3
Using a larger number of Gaussian samples makes a better estimation of the probability and thus stabilizes the training process.	Reply	I-Reply	3
[line_break_token] [line_break_token](c): We did provide the results about the ACRs of the model trained with different values of in the appendix; please see Table 10.	Reply	O	0
The table demonstrates that acts as a tradeoff between accuracy and robustness.	Reply	B-Reply	3
As increases, accuracy at smaller radii drops, while accuracy at larger radii rises.	Reply	I-Reply	3
The optimal (for = 0.25 and 0.50) is between 4.0 and 16.0, where accuracy and robustness are balanced.	Reply	I-Reply	3
[line_break_token] [line_break_token]We hope our responses can address your questions and concerns about the paper.	Reply	O	0
We would also be happy to answer any other questions you may have.	Reply	O	0
[line_break_token] [line_break_token][1] Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe.	Reply	O	0
Convexity, classification, and risk bounds.	Reply	O	0
Journal of the American Statistical Association, 101(473):138‚Äì156, 200	Reply	O	0

This paper introduces a new task that combines elements of instruction following[line_break_token]and visual question answering: agents must accomplish particular tasks in an[line_break_token]interactive environment while providing one-word answers to questions about[line_break_token]features of the environment.	Review	O	0
To solve this task, the paper also presents a new[line_break_token]model architecture that effectively computes a low-rank attention over both[line_break_token]positions and feature indices in the input image.	Review	O	0
It uses this attention as a[line_break_token]common bottleneck for downstream predictors that select actions and answers to[line_break_token]questions.	Review	O	0
The paper's main claim is that this model architecture enables strong[line_break_token]generalization: it allows the model to succeed at the instruction following task[line_break_token]even when given words it has only seen in QA contexts, and vice-versa.	Review	O	0
[line_break_token]Experiments show that on the navigation task, the proposed approach outperforms[line_break_token]a variety of baselines under both a normal data condition and one requiring[line_break_token]strong generalization.	Review	O	0
[line_break_token][line_break_token]On the whole, I think this paper does paper does a good job of motivating the[line_break_token]proposed modeling decisions.	Review	O	0
The approach is likely to be useful for other[line_break_token]researchers working on related problems.	Review	O	0
I have a few questions about the[line_break_token]evaluation, but most of my comments are about presentation.	Review	O	0
[line_break_token][line_break_token]EVALUATION[line_break_token][line_break_token]Is it really the case that no results are presented for the QA task, or am I[line_break_token]misreading one of the charts here?	Review	O	0
Given that this paper spends a lot of time[line_break_token]motivating the QA task as part of the training scenario, I was surprised not to[line_break_token]see it evaluated.	Review	B-Review	1
[line_break_token][line_break_token]Additionally, when I first read the paper I thought that the ZS1 experiments[line_break_token]featured no QA training at all.	Review	I-Review	2
However, your response to one of the sibling[line_break_token]comments suggests that it's still a "mixed" training setting where the sampled[line_break_token]QA and NAV instances happen to cover the full space.	Review	I-Review	2
This should be made more[line_break_token]clear in the paper.	Review	I-Review	2
It would be nice to know (1) how the various models perform[line_break_token]at QA in both ZS1 and ZS2 settings, and (2) what the actual performance is NAV[line_break_token]alone (even if the results are terrible).	Review	I-Review	2
[line_break_token][line_break_token]MODEL PRESENTATION[line_break_token][line_break_token]I found section 2 difficult to read: in particular, the overloading of \Phi[line_break_token]with different subscripts for different output types, the general fact that[line_break_token]e.g. x and \Phi_x are used interchangeably, and the large number of different[line_break_token]variables.	Review	O	0
My best suggestions are to drop the \Phis altogether and consider[line_break_token]using text subscripts rather than coming up with a new name for every variable,[line_break_token]but there are probably other things that will also help.	Review	B-Review	3
[line_break_token][line_break_token]OTHER NOTES[line_break_token][line_break_token]- This paper needs serious proofreading---just in the first few pages the errors[line_break_token]  I noticed were "in 2D environment" (in the title!), "	Review	O	0
such capability", "this[line_break_token]  characteristics", "such language generalization problem", "the agent need to",[line_break_token]  "some early pioneering system", "commands is".	Review	B-Review	4
I gave up on keeping track at[line_break_token]  this point but there are many more.	Review	I-Review	4
[line_break_token][line_break_token]- \phi in Fig 2 should be explained by the caption.	Review	O	0
[line_break_token][line_break_token]- Here's another good paper to cite for the end of 2.2.1:[line_break_token]  <a href="https://arxiv.org/pdf/1707.00683.pdf."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1707.00683.pdf.</a>[line_break_token][line_break_token]- The mechanism in 2.2.4 feels a little like[line_break_token]  <a href="http://aclweb.org/anthology/D17-1015" target="_blank" rel="nofollow">http://aclweb.org/anthology/D17-1015</a>[line_break_token][line_break_token]- I don't think the content on pages 12, 13, and 14 adds much to the[line_break_token]  paper---consider moving these to an appendix.	Review	O	0
Thanks for your comments!	Reply	O	0
They really help a lot.	Reply	O	0
[line_break_token][line_break_token]First, thanks for suggesting adding the results for QA.	Reply	B-Reply	1
Originally we intended to use QA as an auxiliary task to help train NAV.	Reply	I-Reply	1
We didn't think of adding results for it (although we indeed had some records showing how well different methods perform in QA during the training).	Reply	I-Reply	1
In the revised paper, we have included the QA classification accuracies in the normal, ZS1 and ZS2 settings (Figure 6 c, Figure 7 c and f).	Reply	I-Reply	1
We believe that this addition actually demonstrates the generalization ability of our model even better (not only in NAV but also in QA).	Reply	I-Reply	1
Because now we also evaluate QA in the test, we modify all the related paragraphs across the paper to emphasize this addition.	Reply	I-Reply	1
[line_break_token][line_break_token]We believe that the original text already clarifies (section 4.4 when defining ZS1) that ZS1 is about excluding word pairs from both NAV commands and QA questions, but not about training NAV alone.	Reply	I-Reply	1
Note that training both NAV and QA together does not necessarily imply that the sampled NAV and QA instances cover the full space.	Reply	I-Reply	1
For ZS1, a subspace of sentences (containing certain word pairs) is not covered.	Reply	I-Reply	1
For ZS2, a different subspace of sentences (containing certain new words) is not covered.	Reply	I-Reply	1
In other words, our zero-shot setting is not achieved by turning off either NAV or QA, but instead is by excluding certain sentence patterns from the training (for both NAV and QA).	Reply	I-Reply	1
[line_break_token][line_break_token]As requested, we also added the performance of training NAV alone without QA in the normal language setting (Figure 6).	Reply	I-Reply	2
This ablation is called NAVA in the revised experiment section.	Reply	I-Reply	2
An analysis of this ablation was also added (section 4.3).	Reply	I-Reply	2
[line_break_token][line_break_token]Thanks for suggesting citing [de Vries et al 2017] and [Kitaev and Klein 2017]. We find that they are indeed closely related to our work.	Reply	I-Reply	6
We have cited and discussed them at the end of section 2.2.1 (-> 2.2.2) and section 2.2.4 (-> 2.2.5), respectively.	Reply	O	0
[line_break_token][line_break_token]We have simplified the notations in section 2 to keep the presentation concise as suggested.	Reply	B-Reply	8
We moved the content of pages 12, 13, and 14 to Appendix A. We went through a careful round of proofreading of the revised paper.	Reply	I-Reply	8
While we are still trying to get others into the proofreading process, we have uploaded the second version of the paper to facilitate possible discussions on the OpenView.	Reply	I-Reply	8

This paper proposed a novel approach to reformulate the meta-RL problem as model identification with a gradient descent based algorithm.	Review	O	0
Such innovation not only allowed us to perform meta-learning via supervised learning of the model, which is more stable and sample efficient, but also allowed us to leverage off-policy RL to learn the policy instead of meta RL.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
Paper clarity.	Review	O	0
Although the submission had a few typos (I am not a native English speaker, but I'd encourage the authors to polish the writing of the paper), it's a very well-written paper overall.	Review	O	0
The flow and logic of this paper was clean, and the authors stroke a good balance between being focused about the core contribution of the paper, and reviewing related work and introducing sufficient preliminaries.	Review	O	0
As a result, I think this paper was accessible to both domain experts and the broader ICLR community.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
Novelty.	Review	O	0
This paper proposed a novel approach to reformulate the meta-RL problem as model identification with a gradient descent based algorithm.	Review	O	0
To the best of my knowledge, this was the first paper broke the meta-RL problem into a simpler meta supervised learning problem and an off-policy RL learning problem.	Review	O	0
Although each component of the proposed solution was not new, e.g., "relabel" was used in Dyna, MAML was first introduced in 2017, the combination of each component to address the meta-RL problem seemed to the novel to me.	Review	O	0
And I think the idea could be interesting to the ICLR community.	Review	O	0
[line_break_token] [line_break_token][line_break_token]Cons:[line_break_token]It's weak accept rather than accept from me because of how the empirical evaluation were conducted in the paper, and I think the experiments conducted in the paper were a little bit weak (common for most ICLR submissions).	Review	O	0
Examples:[line_break_token][line_break_token]1.	Review	O	0
Number of gradient steps is an important tuning parameter for MAML, it would be interesting to discuss number of gradient steps within the context of MIER.	Review	B-Review	1
[line_break_token]2.	Review	O	0
It might be useful to conduct some qualitative results to understand the model learned with MIER against the baselines, e.g., how well MIER adapt to the out-of-distribution tasks with simulated data points (examples o such qualitative studies could be found, say, in Finn et al.,	Review	B-Review	2
2017).	Review	I-Review	2
[line_break_token]3.	Review	I-Review	6
Given the fact that one major contribution of this paper was reformulating the meta-RL problem as model identification, it would be useful to conduct some quantitative study to help the readers understand the effectiveness of learning the environment model p(s‚Äô, r|s,a) compared to ground-truth, and how the quality of the learned environment model made an impact on the overall performance of the model.	Review	I-Review	3
[line_break_token]4.	Review	O	0
Some implementation details of MIER were missing, I don‚Äôt feel confident about how reproducible this research would be.	Review	B-Review	4
For example, the specification of both environment and policy models were not discussed in the paper.	Review	I-Review	4
[line_break_token]5.	Review	O	0
In general, it would be useful to conduct more experiment results on more diverse data sets, say, in a supplement material.	Review	B-Review	5
[line_break_token][line_break_token][line_break_token]A few questions to the authors:[line_break_token]1.	Review	O	0
Section 3.2: I assume the expectation should be taken w.r.t.	Review	B-Review	6
p‚Äô rather than f?	Review	I-Review	6
[line_break_token]2.	Review	O	0
In Algorithm 1 &amp; 2, how was the adapted context \phi_T used to update policy \psi?	Review	O	0
Was it as input to the model parametrized by \psi?	Review	B-Review	7
It might be useful to make it clearer.	Review	I-Review	7
[line_break_token]	Review	O	0
First we want to thank reviewer #1 for the constructive comments.	Reply	O	0
We have updated the paper to incorporate the reviewer‚Äôs suggestions.	Reply	O	0
[line_break_token][line_break_token]Regarding point #1, as suggested by the reviewer, we have conducted experiments for an ablation study of the algorithm performance vs the number of gradient steps in the half cheetah velocity environments, and the results can be found at <a href="https://imgur.com/a/e6qUNCH" target="_blank" rel="nofollow">https://imgur.com/a/e6qUNCH</a> .	Reply	O	0
We see that there is a trade off between performance improvement and stability when increasing the number of fast adaptation steps.	Reply	B-Reply	1
We will incorporate these results in the final version of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding point #2, as suggested by the reviewer, we will modify the paper to include a point mass toy examples and visualization of the policy behavior.	Reply	O	0
[line_break_token][line_break_token]As for point #3, as suggested by the reviewer, we have conducted experiments for an analysis of model prediction error, and the results can be found at <a href="https://imgur.com/a/5UdqLyp" target="_blank" rel="nofollow">https://imgur.com/a/5UdqLyp</a> .	Reply	O	0
We see that the model loss does decrease during training, which matches the improvement in average return.	Reply	B-Reply	3
We will incorporate these results in the final version of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]For point #4, we have modified the paper to include all the hyperparameter configurations in Appendix A.[line_break_token][line_break_token]For point #5, as suggested by the reviewer, we have conducted additional in-distribution experiments in the ant-direction environment used in other meta-RL papers, and the results can be found at <a href="https://imgur.com/a/F8W37TD" target="_blank" rel="nofollow">https://imgur.com/a/F8W37TD</a> .	Reply	O	0
We have also conducted additional experiments for out-of-distribution tasks in the humanoid direction environment, and the results can be found at <a href="https://imgur.com/a/ZxRRTmd" target="_blank" rel="nofollow">https://imgur.com/a/ZxRRTmd</a> .	Reply	O	0
The x-axis corresponds to different test tasks, where task 0 is the easiest and -5 and 5 are the most out-of-distribution.	Reply	B-Reply	5
We see that for almost all tasks, our methods outperforms PEARL.	Reply	I-Reply	5
We will incorporate these results in the final version of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Answers to questions:[line_break_token]Q1: Section 3.2: I assume the expectation should be taken w.r.t.	Reply	O	0
p‚Äô rather than f?	Reply	O	0
[line_break_token][line_break_token]A1: That‚Äôs indeed a typo.	Reply	O	0
Thanks for pointing it out!	Reply	B-Reply	6
[line_break_token][line_break_token]Q2: In Algorithm 1 &amp; 2, how was the adapted context \phi_T used to update policy \psi?	Reply	O	0
Was it as input to the model parametrized by \psi?	Reply	O	0
It might be useful to make it clearer.	Reply	O	0
[line_break_token][line_break_token]A2: We have 2 phases of improving the policy with the adapted model context.	Reply	O	0
For the first phase, we direct feed the updated model context as part of the input to the policy.	Reply	B-Reply	7
For continual improvement, we use data generated by the model conditioned on the adapted context to continue training the policy.	Reply	I-Reply	7

The paper proposes an algorithm for mental fatigue monitoring, relating a subjects' EEG signals to their reaction time (RT) during a simulated driving task, as an ordinal regression problem.	Review	O	0
The authors argue that RTs could be heavily skewed and/or non-smooth, making traditional regression approaches unstable due to outlier values.	Review	O	0
They propose a brain dynamic ranking algorithm,  BDrank, using a generalized EM algorithm to estimate its parameters, and compare it to support vector regression and Logistic Ordinal Regression, where they show improved performance by accuracy and root mean squared error (RMSE) over a database of 44 subjects.	Review	O	0
[line_break_token][line_break_token]General comments, in no particular order:[line_break_token][line_break_token]1.	Review	O	0
There are some minor grammatical errors throughout.	Review	B-Review	1
The paper could benefit from another read-through to correct these errors.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
It is unclear to me how the model works at test time; as the model is essentially building a relational structure in the data, does the user have to provide multiple EEG trials at time of prediction?	Review	B-Review	2
[line_break_token][line_break_token]3.	Review	O	0
There is notation early on in the paper that doesn't appear to be appropriately defined.	Review	B-Review	3
For example, Equation (1) describes two sets of propositions, with M1 and M2 elements, respectively.	Review	I-Review	3
How is M1 and M2, the total set of propositions, calculated?	Review	I-Review	3
It appears to be all pair-wise comparisons of RTs but then it's unclear why there are two indexes associated with them.	Review	I-Review	3
Also, what does it mean for the orderings to be significant? (	Review	I-Review	4
i.e.: that the "type-1 preference propositions that the orderings between the RTs are significant").	Review	I-Review	4
The authors then switch to a new notation x^1 and x^2 without defining them.	Review	I-Review	5
Notational problems also persist throughout the paper, making it hard to gauge what is being done at each step.	Review	I-Review	5
[line_break_token][line_break_token]4.	Review	O	0
The authors describe using an FFT to transform the EEG data into the frequency domain.	Review	B-Review	6
I'm assuming they are doing the FFT on the entire 10-s interval but the paper does not make this clear.	Review	I-Review	6
Also, the authors state using EEG power between 0-30Hz for their analysis; do they further sub-divide this range (for example, to the standard theta/alpha/beta power ranges) or just use the power across the entire 0-30Hz band?	Review	I-Review	6
[line_break_token][line_break_token]5.	Review	O	0
I am concerned with the relatively sparse set of comparison algorithms the authors use.	Review	B-Review	7
The authors only compare to relatively simple approaches (support vector regression and logistic ordinal regression), yet they cite many previous works in this area but do not compare against them, instead just leaving a pretty generic statement of "The regression assumption of this method between EEG signals and RT is not correct"; they do not elaborate on this aspect.	Review	I-Review	7
[line_break_token][line_break_token] [line_break_token]Overall I think there is limited novelty in the approach; the idea to learn the structure of the data relationally instead of absolutely is pretty straight-forward, and is a standard practice for example in non-parametric statistical modeling.	Review	O	0
I am also not positive that ICLR is the best venue for this work; perhaps a better avenue for this would be in a more BCI/neural engineering-focused venue.	Review	O	0
[line_break_token]	Review	O	0
Thanks for your comments and suggestions regarding our paper.	Reply	O	0
We summarize your comments into the following sub-problems and answer each one separately.	Reply	O	0
[line_break_token][line_break_token]Q1: It is unclear to me how the model works at test time; as the model is essentially building a relational structure in the data, does the user have to provide multiple EEG trials at time of prediction?	Reply	O	0
[line_break_token]A1: Yes, we need to refer to some baseline trials with known RTs when we do prediction.	Reply	O	0
Through the pairwise comparisons with these trials using the learned model, we can get a coarse estimation of the RT.	Reply	B-Reply	2
Furthermore, these baseline trials are easy to access as long as their RTs are diverse enough, e.g. some trails in the training dataset with diverse RTs.	Reply	I-Reply	2
[line_break_token][line_break_token]Q2:  Equation (1) describes two sets of propositions, with M1 and M2 elements, respectively.	Reply	O	0
How is M1 and M2, the total set of propositions, calculated?	Reply	O	0
It appears to be all pair-wise comparisons of RTs but then it's unclear why there are two indexes associated with them.	Reply	O	0
[line_break_token]A2: D1 denotes the type-1 preference propositions that the orderings between the RTs are significant.	Reply	O	0
M1 is the total number of D1; while D2 denotes the type-2 preference propositions that the RTs in each comparison are comparable.	Reply	B-Reply	3
 M2 is the total number of D2.	Reply	I-Reply	3
We use different indexes for D1 and D2 for the convenience of explanation in the optimization part.	Reply	I-Reply	3
[line_break_token][line_break_token]Q3: What does it mean for the orderings to be significant? (	Reply	O	0
i.e.: that the "type-1 preference propositions that the orderings between the RTs are significant").	Reply	O	0
[line_break_token]A3: The word "significant" denotes the difference between RTs is significant, namely RT1 is significantly greater/smaller than RT2, regardless of random unknown noisy introduced by the instrument error.	Reply	O	0
We empirically realize this as RT2 < min (RT2+1, 1.5*RT2) < RT1 in the experiment part.	Reply	O	0
[line_break_token][line_break_token]Q4: The authors then switch to a new notation x^1 and x^2 without defining them.	Reply	O	0
[line_break_token]The pairwise brain dynamics preference (x^1_{n,m}, x^2_{n,m}) is first introduced after Equation 1,  denoting the features recorded within the n-th channel for each preference proposition in D1 or D2.	Reply	B-Reply	5
In Section 2b, we omitted the subscript (n,m) for the sake of simplicity.	Reply	I-Reply	5
[line_break_token][line_break_token]Q5: The authors describe using an FFT to transform the EEG data into the frequency domain.	Reply	O	0
I'm assuming they are doing the FFT on the entire 10-s interval but the paper does not make this clear.	Reply	O	0
Also, the authors‚Äô state using EEG power between 0-30Hz for their analysis; do they further sub-divide this range (for example, to the standard theta/alpha/beta power ranges) or just use the power across the entire 0-30Hz band?	Reply	O	0
[line_break_token]A5: Yes, Your understanding is correct.	Reply	O	0
We do the FFT on the entire 10-s interval.	Reply	B-Reply	6
And we use the power across the entire 0-30Hz band as the feature vector.	Reply	I-Reply	6
[line_break_token]If needed, we can further introduced the group loss on the regression weight w, with each group corresponding to the standard theta/alpha/beta power ranges, respectively.	Reply	I-Reply	6
Let our model to select the most relevant power ranges in a data-driven approach.	Reply	I-Reply	6
[line_break_token][line_break_token]Q6: I am concerned with the relatively sparse set of comparison algorithms the authors use.	Reply	O	0
The authors only compare to relatively simple approaches (support vector regression and logistic ordinal regression), [line_break_token]A6: SVR and LOR are selected with careful consideration.	Reply	O	0
The two baselines are considered to be a strong support for our claims: (1) Ordinal Classification based attempts are more suitable for mental fatigue evaluation, especially with non-smooth response variable (RTs); (2) the channel state indeed affects the performance of the learning model.	Reply	B-Reply	7
[line_break_token][line_break_token]SVR is chosen as the representative for the regression based attempts for the following concerns: (1) SVR is considered to achieve the same performance with the shallow neural networks, while the parameters for SVR are much more easier to tune to the best using cross validation, as we did in the paper. (	Reply	I-Reply	7
2) The number of trials for each participant is about 200, which is too small to train a deep neural network. (	Reply	I-Reply	7
3) As it shown in Figure 3, even the SVR (using 5-fold cross validation) is still easier to overfit due to the non-smooth property of RTs, let alone other neural network based attempts.	Reply	I-Reply	7
[line_break_token][line_break_token]LOR is chosen as the representative for the ordinal classification based attempts due to its simplicity.	Reply	I-Reply	7
LOR is optimized with L-BFGS with the default setting for all participants.	Reply	I-Reply	7
The surprised result of LOR is a strong support to our claim that ordinal classification based attempts are more suitable for mental fatigue evaluation.	Reply	I-Reply	7
 Of course, LOR can be easily replaced to more complex structures, e.g. deep neural network, to achieve more superior performance.	Reply	I-Reply	7
Furthermore, LOR can also be extended to input image data, like fRMI.	Reply	I-Reply	7
Note that our BDrank, introducing a transition matrix on top of LOR, still enjoys the superiority of LOR.	Reply	I-Reply	7
 Those extensions, which are not the focus of this paper, are left for later studies	Reply	I-Reply	7

This paper presents an apparently original method targeted toward models training in the presence of low-quality or corrupted data.	Review	O	0
To accomplish this they introduce a "mixture of correlated density network" (MCDN), which processes representations from a backbone network, and the MCDN models the corrupted data generating process.	Review	O	0
Evaluation is on a regression problem with an analytic function, two MuJoCo problems, MNIST, and CIFAR-10.	Review	O	0
[line_break_token][line_break_token]This paper's primary strength is that the proposed method is a tool quite distinct from recent work, in that it does not use bootstrapping or solely use corruption transition matrices.	Review	O	0
The paper is typeset well.	Review	O	0
In addition to this, the experimentation has unusual breadth.	Review	O	0
[line_break_token][line_break_token]However, the synthetic regression task is a nice proof-of-concept, but thorough regression evaluation could perhaps include the Boston Housing Prices dataset or some UCI datasets.	Review	B-Review	1
[line_break_token][line_break_token]The hamartia of this paper is that it does not provide sufficient depth in its computer vision experiments.	Review	I-Review	2
For one, experimentation on CIFAR-100 would be appreciated.	Review	I-Review	2
[line_break_token]In the CIFAR-10 experiments, they consider one label corruption setting and lack experimentation on uniform label corruptions.	Review	I-Review	3
[line_break_token]The related works has thorough coverage on label corruption, but these works do not appear in the experiments.	Review	I-Review	3
They instead compare their label corruption technique to mixup, a general-purpose network regularizer.	Review	I-Review	3
It is not clear why it is thought the "state-of-the-art technique on noisy labels"; this may be true among network regularization approaches (such as dropout) but not among label correction techniques.	Review	I-Review	3
For this problem I would expect comparison to at least three label correction techniques, but the comparison is to one technique which was not primarily designed for label corruption.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]Nitpicks:[line_break_token]-In the related works we are told that a smaller learning rate can improve label corruption robustness.	Review	O	0
They train their method with a learning rate of 0.001; the baseline gets a learning rate of 0.1.	Review	B-Review	4
[line_break_token]-The larger-than-usual batch size is 256 for their 22-4 Wide ResNets, and at the same time they do not use dropout (standard for WRNs of this width) and use less weight decay than is common.	Review	O	0
Is this because of mixup?	Review	B-Review	5
If so why is the weight decay two orders of magnitude less for your approach compared to the baseline?	Review	I-Review	5
How were these various atypical parameters chosen?	Review	I-Review	5
[line_break_token]-They also use gradient clipping for their method, which is extremely rare for CIFAR-10 classification.	Review	O	0
Why is this necessary?	Review	B-Review	6
[line_break_token]-This document could be cleaner by eschewing the Theorem of this paper, which "states that a correlation between two random matrices is invariant to an affine transform."	Review	O	0
For this audience, I suspect this theorem is unnecessary.	Review	B-Review	7
Likewise the three lines expended for the maths of a Gaussian probability density function could probably be used for other parts of this paper.	Review	I-Review	7
[line_break_token]-"a leverage optimization method which optimizes the leverage of each demonstrations is proposed.	Review	O	0
Unlike to former study," -> "a leverage optimization method which optimizes the leverage of each demonstration is proposed.	Review	O	0
Unlike a former study,"[line_break_token]-"In the followings," -> "In the following,"[line_break_token][line_break_token]Edit: The updated results need consistent baselines.	Review	O	0
For example, the method of [7] should be consistently compared against.	Review	O	0
We thank the reviewer for the helpful comments.	Reply	O	0
Especially, we agree that more in-depth experiments would be helpful for convincing the strength of the proposed method.	Reply	O	0
In this regards, we conducted four additional experiments: a) robust regression experiments using a real-world dataset, b) experiments on NLP tasks, c) more baselines (MentorNet and VAT) on current CIFAR-10 experiments, and d) experiments with both symmetric and asymmetric following the recent work [1].[line_break_token][line_break_token]a).	Reply	O	0
Robust regression experiments: Here, we used the Boston housing price dataset and checked the robustness of the proposed method and compared our method with standard MLPs with four different types of loss functions: standard L2-loss, L1-loss which is known to be robust to outliers, a robust loss function proposed in [2], and a leaky robust function extending [2]. We implement the leaky version in that the Tukey‚Äôs biweight function discards the instances whose residuals exceed a certain threshold.	Reply	B-Reply	1
Two-layer MLPs with 128 units and a relu activation is used for all scenarios.	Reply	I-Reply	1
We vary the outlier ratio from 0% to 40% where the outputs of the outliers are uniformly sampled within the minimum and the maximum values of the training outputs.	Reply	I-Reply	1
The results are as follows:[line_break_token][line_break_token]outlier rate [tab_token]0%    5%    10%   15%   20%    30%    40%    50%[line_break_token]-----------------------------------------------------------------------[line_break_token]ChoiceNet       3.29  3.71  3.99  4.45  4.77   5.94   6.80   9.00[line_break_token]L2 loss         3.22  4.61  5.97  6.65  7.51   9.04   9.88   10.92[line_break_token]L1 loss         3.26  4.36  5.72  6.61  7.16   8.65   9.69   10.33[line_break_token]Robust loss     4.28  4.63  6.36  6.59  8.08   10.54  10.94  11.96[line_break_token]Leaky Robust    3.36  4.51  5.71  6.54  7.08   8.67   9.68   10.46[line_break_token][line_break_token]The proposed method (ChoiceNet) outperforms all compared methods in the presence of outliers and shows a comparable performance without the outlier.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	1
Natural language processing experiments: We used a Large Movie Review Dataset consist of 25,000 movie reviews for training and 25,000 reviews for testing.	Reply	I-Reply	1
Each movie review (sentences) is mapped to a 128-dimensional embedding vector using feed-forward Neural-Net Language Models [3] and we tested the robustness of the proposed method, mix-up [4], VAT [5], and naive MLP baseline by randomly flipping the labels.	Reply	I-Reply	1
In all experiments, we used two-layer MLPs with 128 hidden units and ReLU activations.	Reply	I-Reply	1
[line_break_token][line_break_token]random flip rate    0%      10%     20%     30%     40%[line_break_token]-------------------------------------------------------------[line_break_token]ChoiceNet           79.43%  79.50%  78.66%  77.10%  73.98%[line_break_token]Mix-up              79.77%  78.73%  77.58%  75.85%  69.63%[line_break_token]Baseline (MLP)      79.04%  77.88%  75.70%  69.05%  62.83%[line_break_token]VAT                 76.40%  72.50%  69.20%  65.20%  58.30%[line_break_token][line_break_token]Similar to regression experiments, ChoiceNet shows the superior performance in the presence of outliers where we observe that the proposed method can be used for NLP tasks as well.	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	I-Reply	1
More baselines to current CIFAR-10 experiments: We compared MentorNet [6] and VAT [5] to better evaluate the performance of the proposed method on the current CIFAR-10 setting.	Reply	I-Reply	3
For MentorNet, we compare two methods: MentorNet PD which uses the pre-deÔ¨Åned curriculum to train StudentNet and the other, MentorNet DD, which uses data-driven curriculum to train StudentNet where we use Resent-101 for the StudentNet following the author‚Äôs implementations.	Reply	I-Reply	3
We would like to note that the base networks of the StudentNet are not the same as the one we used for ChoiceNet, but even bigger.	Reply	I-Reply	3
Due to the limited time for tuning the hyper-parameters, we simply used the existing implementations while changing the train and test dataset.	Reply	I-Reply	3
To measure the robustness of compared methods, we vary the corruption probabilities from 20% to 80% and the results are as follows where the results of CN and CN+Mixup are copied from the current manuscript.	Reply	I-Reply	3
We're working on reproducing MentorNet and VAT on the exact same network architecture.	Reply	I-Reply	3
[line_break_token][line_break_token]corruption rate     20%     50%      80%[line_break_token]----------------------------------------------[line_break_token]MentorNet PD        64.0%   49.0%    21.4%[line_break_token]MentorNet DD        62.0%   43.1%    21.8%[line_break_token]VAT                 82.0%   71.6%    16.9%[line_break_token]----------------------------------------------[line_break_token]CN                  90.3%   84.6%    65.2%[line_break_token]CN+Mixup            92.3%   87.9%    75.4% [line_break_token][line_break_token]In all cases, the proposed methods (CN and CN+Mixup) outperforms the baselines.	Reply	O	0

This paper proposes a new type of adversarial attack setting for graphs, namely graph rewiring operation, which deletes an edge in the graph and adds a new edge between one node of the first edge and one of its 2-hop neighbors.	Review	O	0
This new attack is proposed to make the perturbations unnoticeable compared with adding or deleting arbitrary edges.	Review	O	0
To solve this problem, a reinforcement learning based approach is proposed to learn the attack strategy in the black-box manner.	Review	O	0
Experiments conducted on several datasets prove the effectiveness of the proposed with over an existing method and baseline methods.	Review	O	0
[line_break_token][line_break_token]Overall, this paper proposes a new adversarial setting for graphs to make the modifications unnoticeable.	Review	O	0
A reinforcement learning method is proposed to generate adversarial examples under the proposed setting.	Review	O	0
The writing is clear.	Review	O	0
However, I have several concerns about this paper as follows.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
The proposed graph rewiring operation is a special operation of the general adding and deleting operations (i.e., rewiring is operated as deleting an edge and adding a new edge with some constrains).	Review	B-Review	1
The motivation of using rewiring is to make the perturbations unnoticeable.	Review	I-Review	1
Besides presenting the theoretical results on this property of the rewiring operation, it's better to provide some empirical results (e.g., generated adversarial graphs) to prove that the rewiring operation can make the adversarial graphs unnoticeable in practice.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
In Table 1, why are the results of ReWatt better than RL-S2V?	Review	B-Review	2
Since there are more constrains (i.e., smaller action space) in ReWatt than RL-S2V, RL-S2V could be easier to fool GCNs.	Review	I-Review	2
The authors could explain more on the results.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
What are the differences between the proposed attack method based on reinforcement learning and the method in RL-S2V?	Review	B-Review	3
RL-S2V is also based on reinforcement learning.	Review	I-Review	3
The authors should clearly introduce the novelty of the proposed method as well as the contributions.	Review	I-Review	3
hank you for the valuable comments and suggestions.	Reply	O	0
[line_break_token] [line_break_token]We address the concerns from the reviewer as follows:[line_break_token][line_break_token]Q1: The motivation for using rewiring is to make the perturbations unnoticeable.	Reply	O	0
Besides presenting the theoretical results on this property of the rewiring operation, it's better to provide some empirical results (e.g., generated adversarial graphs) to prove that the rewiring operation can make the adversarial graphs unnoticeable in practice.	Reply	O	0
[line_break_token][line_break_token]A1: We have performed empirical investigations of the rewiring operation, which can be found in Appendix C. In summary, the rewiring attack performed by ReWatt does smaller changes to the attacked graph in terms of connectivity and the Laplacian spectrum.	Reply	O	0
Furthermore, as requested by Blind Reviewer #3, we have done some experiments to show the rewiring attack performed by ReWatt also does small changes to the spectrum of the adjacency matrix and distribution of the edge_centrality (please see the responses to Q1 and Q2 of Blind Review #3 ).	Reply	B-Reply	1
[line_break_token][line_break_token]Q2: In Table 1, why are the results of ReWatt better than RL-S2V?	Reply	O	0
Since there are more constraints (i.e., smaller action space) in ReWatt than RL-S2V, RL-S2V could be easier to fool GCNs.	Reply	O	0
The authors could explain more about the results.	Reply	O	0
[line_break_token][line_break_token]A2: We agree that RL-S2V has a larger action space, which means the optimal solution it can achieve is as good or better than the one our method can find.	Reply	O	0
However, both methods are not guaranteed to always find the optimal solution in the given action space.	Reply	B-Reply	2
We list some potential reasons to explain why ReWatt can outperform RL-S2V as follows:[line_break_token]1) When performing an adding/deleting edge action in RL-S2V, it chooses two nodes sequentially.	Reply	I-Reply	2
Then it decides to add an edge between two nodes if they are not connected, otherwise, the edge between them is removed.	Reply	I-Reply	2
Since most graphs are very sparse, the RL-S2V algorithm is, by design, biased to adding an edge.	Reply	I-Reply	2
On the other hand, ReWatt removes an edge and then add another edge.	Reply	I-Reply	2
The adding/deleting edge operations are more balanced.	Reply	I-Reply	2
[line_break_token]2) The reward design in ReWatt is different from RL-S2V. In RL-S2V, a non-zero reward is only given at the end of an attacking session.	Reply	O	0
Specifically, at the end of an attacking session, a positive reward of is given if the attack succeeded, otherwise a negative reward is given.	Reply	B-Reply	2
All the intermediate steps get reward.	Reply	I-Reply	2
In ReWatt, the reward is given after each action.	Reply	I-Reply	2
A positive reward is given once an action leads to a successful attack.	Reply	I-Reply	2
A negative reward is penalized to take each action if it does not directly lead to a successful attack, which encourages the attacker to make as few actions as possible.	Reply	I-Reply	2
Furthermore, we also proposed an adaptive negative reward design, which determines the value of the negative reward according to the size of each graph.	Reply	I-Reply	2
In fact, the design of this adaptive negative reward has shown to be very effective and important to the ReWatt framework.	Reply	I-Reply	2
As shown in Table 1, ReWatt-n (which is a variant of ReWatt without the adaptive negative reward design) performs much worse than ReWatt.	Reply	I-Reply	2
Specifically, if we apply ReWatt-n in the same setting of RL-S2V (with fixed actions), its performance is not as good as RL-S2V in REDDIT-MULTI-12K and REDDIT-MULTI-5K datasets.	Reply	I-Reply	2
The performance of ReWatt-n on REDDIT-MULTI-12K is [11.26%; 14.7%; 18.02] while RL-S2V achieves [9.46; 18.5% 21.1%]. On the REDDIT-MULTI-5K, the performance of ReWatt-n is [4.49%; 5.62%; 6.74%] while RL-S2V archives [4.49%; 16.9%; 18.0%]. Hence, the design of our adaptive negative reward could be an important reason why ReWatt can perform better than RL-S2V.[line_break_token][line_break_token]Q3: What are the differences between the proposed attack method based on reinforcement learning and the method in RL-S2V?	Reply	O	0
RL-S2V is also based on reinforcement learning.	Reply	O	0
The authors should clearly introduce the novelty of the proposed method as well as the contributions.	Reply	O	0
[line_break_token][line_break_token]A3: A major contribution is that we propose to use rewiring to perform the attack.	Reply	O	0
We also show that the rewiring operation is less noticeable both theoretically and empirically.	Reply	B-Reply	3
On the other hand, the architecture of the reinforcement framework of ReWatt is also different from RL-S2V. We have stated the differences in the response to Q2[line_break_token]	Reply	I-Reply	3

The authors present a new method for learning unsupervised embeddings of physiological signals (e.g. time series data) in a healthcare setting.	Review	O	0
The primary motivation of their paper is transfer learning - the embeddings created by their approach are able to generalize to other hospitals and healthcare settings.	Review	O	0
[line_break_token][line_break_token]Overall I did like this paper.	Review	O	0
I found it to be easy to read, well motivated, and addressing an important problem in the healthcare domain.	Review	O	0
As a researcher in this area, it is very true that we are all using our own "siloed" data and do not generally have access to large pre-trained models.	Review	O	0
I hope that others will produce these kinds of models for the community to use.	Review	O	0
The authors do not explicitly state that they plan to release their code and pre-trained models, but I sincerely hope that is there intent.	Review	B-Review	4
If they do not plan to do this, then the impact of this work is dramatically reduced.	Review	I-Review	4
[line_break_token][line_break_token]However, I do have a few concerns about the paper, listed below:[line_break_token][line_break_token]- It might not be fair to truly call this an unsupervised model.	Review	O	0
The labels used for evaluation are thresholds on the signals themselves (e.g. SaO2 < 92%) , so the "unsupervised" model actually receives some form of supervision, at least using the current evaluation method.	Review	O	0
Using a truly different prediction task not directly based on the physiological signals (e.g. mortality, complication during surgery, etc) would provide a cleaner example of unsupervised embeddings that are useful for transfer learning.	Review	B-Review	1
[line_break_token][line_break_token]- Differences between PHASE and EMA are statistically significant but unlikely to be clinically meaningful - the largest absolute difference in AP is 0.04, and most are much smaller than this.	Review	O	0
It's unclear if the performance gains enjoyed by PHASE would meaningfully change clinical decision making in any significant way.	Review	B-Review	2
[line_break_token][line_break_token]- I appreciate the use of XGBoost due to its impressive Kaggle performance, but it strikes me as odd that the authors did not try to fine tune their base model, as that is standard practice for transfer learning.	Review	O	0
The successes they point to in CV and NLP all use a fine tuning approach, so the evaluation seems incomplete without a performance assessment of fine tuning the base model.	Review	B-Review	3
[line_break_token][line_break_token][line_break_token]	Review	O	0
[line_break_token]We would like to thank the reviewers for their careful consideration of this manuscript and many suggestions for improvement.	Reply	O	0
In response to the reviewers‚Äô comments we have made changes that we feel substantially improve the manuscript and address the reviewers‚Äô concerns, which we have responded to point-by-point.	Reply	O	0
[line_break_token][line_break_token]*"The authors do not explicitly state ‚Ä¶ reduced."	Reply	O	0
[line_break_token][line_break_token]We thank the reviewer for the excellent point.	Reply	B-Reply	4
 We intend to release code pertinent to training the LSTM models, obtaining embeddings, predicting with XGB models, and model stacking feature attributions - submitted as a pull request to the SHAP github (<a href="https://github.com/slundberg/shap)."	Reply	O	0
target="_blank" rel="nofollow">https://github.com/slundberg/shap).</a>  We have indicated our intent to do so in the conclusion (Section 5 Paragraph 3).	Reply	O	0
 Additionally, we intend to release our embedding models, which we recommend for use in forecasting "hypo" predictions.	Reply	B-Reply	4
[line_break_token] [line_break_token]*"However, I do have a few concerns about the paper, listed below:[line_break_token]- It might not be fair to truly call this an unsupervised model ‚Ä¶ useful for transfer learning."	Reply	O	0
[line_break_token][line_break_token]We thank the reviewer for the great point.	Reply	B-Reply	1
When we considered prediction problems for our paper, we focused on largely two aspects: (i) clinical importance, and (ii) real-time prediction problems, which are an appropriate evaluation setting for time-series embedding methods.	Reply	I-Reply	1
Although predicting mortality makes PHASE a purely unsupervised method, mortality is neither a real-time outcome nor is it reliably measured in our data set.	Reply	I-Reply	1
The outcomes we considered - hypoxemia, hypotension, and hypocapnia - are representative adverse real-time events caused by surgery complications and are a significant cause of anesthesia-related complications (Barak et al.	Reply	I-Reply	1
Sci.	Reply	I-Reply	1
World.	Reply	I-Reply	1
Journal, 2015; Curley et al.	Reply	I-Reply	1
Crit.	Reply	I-Reply	1
Care.	Reply	I-Reply	1
Med.,	Reply	I-Reply	1
2010).	Reply	I-Reply	1
Predicting these events in advance has been considered a promising approach to enable proactive intervention of these events (Lundberg et al.	Reply	I-Reply	1
Nature BME 2018).	Reply	I-Reply	1
[line_break_token][line_break_token]In order to address the reviewer‚Äôs great point, we create a simulated ‚Äúunsupervised‚Äù setting - when predicting each event, we excluded the corresponding physiological signal from our features.	Reply	I-Reply	1
For example, we assumed that SaO2 is not recorded when predicting hypoxemia.	Reply	I-Reply	1
Under this setting, we must rely on the remaining signals to predict hypoxemia.	Reply	I-Reply	1
 This setting is a more unsupervised evaluation in the sense that our outcome is not derived from a signal we create an embedding for.	Reply	I-Reply	1
As our results show (Section 6.3; Figure 9), PHASE‚Äôs outperformance is consistent in this setting for hypocapnia and hypotension.	Reply	I-Reply	1
For hypoxemia, all representations perform poorly because predicting hypoxemia heavily relies on SaO2, leaving little signal for the remaining features.	Reply	I-Reply	1
[line_break_token][line_break_token]Finally, to further address the reviewer‚Äôs comments, we have mitigated claims of PHASE being unsupervised and instead called our LSTM models ‚Äúpartially supervised‚Äù throughout the entirety of the manuscript.	Reply	I-Reply	2
 We denote ‚Äúpartially supervised‚Äù to mean LSTMs trained with prediction tasks related to the final downstream prediction.	Reply	I-Reply	2
 Furthermore, we have refined the discussion in Sections 4.2.1 and 4.2.2 to emphasize that completely unsupervised LSTMs (e.g., autoencoders) are insufficient for downstream ‚Äúhypo‚Äù predictions, which are clinically important perioperative outcomes.	Reply	I-Reply	2
 In fact, on our datasets, we found that closeness in the LSTM prediction tasks to the ultimate downstream prediction tasks is beneficial to performance as well as transference.	Reply	I-Reply	2
 In order to change the message of our paper, we have added this to our conclusion as well (Section 5 Paragraph 2)	Reply	I-Reply	2

This work proposes Adversarial Reconstruction Network (ARN), a network architecture, and Max-margin Domain-Adversarial Training (MDAT), an objective and training procedure for unsupervised domain adaptation.	Review	O	0
Similar to domain adversarial approaches, the generator aims at finding domain invariant representation while the discriminator now monitors the reconstruction loss of the source and target data using hinge-like lose.	Review	O	0
The method is very similar to some of the existing works in the literature.	Review	O	0
Experiment results on the standard digit datasets and the WiFi gesture recognition dataset show that the proposed method outperforms other alternatives.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The writing is good[line_break_token]- Satisfactory empirical results[line_break_token][line_break_token]Cons:[line_break_token]- The proposed method is very similar to certain methods in the literature[line_break_token][line_break_token]Detail comments:[line_break_token](1) The proposed loss function Eq.(8) is very similar to the contrastive loss proposed by Hadsell et al. (	Review	O	0
2006, Eq.(4)), which is used in Siamese GAN variants (Juefei-Xu et al.	Review	B-Review	1
2018, Hsu et al.	Review	I-Review	1
2019).	Review	I-Review	1
Thus essentially the proposed method is an application of an existing GAN technique.	Review	I-Review	1
Its novelty is limited.	Review	I-Review	1
[line_break_token][line_break_token](2) Experiments[line_break_token]- How are the hyperparameters selected?	Review	O	0
It is essential to specify the selection criteria when labeled target data is not available.	Review	B-Review	2
[line_break_token]- What does the * in DRCN* mean in Table 1?	Review	O	0
[line_break_token]- ARN w.o.	Review	O	0
MDAT may not be the best alternative since the target data is ignored in the reconstruction and the discriminator is not discriminating anymore.	Review	B-Review	4
A more reasonable alternative would be to ignore the margin and minimize L_r(x^s)-L_r(x^t) to see the effect of the margin.	Review	I-Review	4
[line_break_token][line_break_token](3) In Eq.(2), y is said to be the predicted domain label (-1 or +1), which could be not accurate according to the common hinge loss definition.	Review	O	0
[line_break_token][line_break_token]Typos:[line_break_token]- In Eq.(1), there is a missing D in the first term.	Review	B-Review	6
D_s should be \mathcal{D}_s to match previous notation.	Review	I-Review	6
[line_break_token]- In Eq.(2), the "0," is not meaningful given the definition of []^+.	Review	I-Review	6
[line_break_token][line_break_token]Refs[line_break_token]- Hadsell, R., Chopra, S. and LeCun, Y., 2006, June.	Review	O	0
Dimensionality reduction by learning an invariant mapping.	Review	O	0
In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06) (Vol.	Review	O	0
2, pp.	Review	O	0
1735-1742).	Review	O	0
IEEE.	Review	O	0
[line_break_token]- Juefei-Xu, F., Dey, R., Boddeti, V.N. and Savvides, M., 2018.	Review	O	0
RankGAN: A Maximum Margin Ranking GAN for Generating Faces.	Review	O	0
In Asian Conference on Computer Vision (pp.	Review	O	0
3-18).	Review	O	0
Springer, Cham.	Review	O	0
[line_break_token]- Hsu, C.C., Lin, C.W., Su, W.T. and Cheung, G., 2019.	Review	O	0
SiGAN: Siamese generative adversarial network for identity-preserving face hallucination.	Review	O	0
IEEE Transactions on Image Processing, 28(12), pp.6225-6236.	Review	O	0
[line_break_token][line_break_token]# Update after rebuttal[line_break_token][line_break_token]Thank you for the response and additional experiment results.	Review	O	0
I agree that MDAT and SiGAN are not using the contrastive loss in the same way, but claiming that they are "totally different" can be misleading and overstated.	Review	O	0
It would be better if the paper includes proper discussion about the contrastive loss from the literature and distinguish the particularities between MDAT and SiGAN.	Review	B-Review	1
Overall, I think the proposed method shows some prosperity thus I have increased my score accordingly.	Review	O	0
hanks for your constructive comments.	Reply	O	0
We think some of the contents in the paper are misunderstanding, and we hope we can address them as below.	Reply	O	0
[line_break_token][line_break_token](1) Is it similar to SiGAN?	Reply	O	0
[line_break_token]Answer: No.	Reply	O	0
The forms and the objectives of the loss in two papers are totally different.	Reply	B-Reply	1
SiGAN applies a contrastive loss to the reconstruction of the two images, which aims to draw two similar images closer.	Reply	I-Reply	1
In MDAT, we propose a margin loss for the reconstruction of the images from the source domain and the target domain.	Reply	I-Reply	1
Our objective is to leverage the reconstruction network as a domain classifier that can transfer richer information (i.e. pixel-level domain alignment directly in adversarial training) and have better convergence (i.e. more effective gradients), compared with the classifier binary domain classifier, while SiGAN still leverage the classic binary domain discriminator in DCGAN.	Reply	I-Reply	1
SiGAN only regards the contrastive loss as a regularizer during adversarial training, but ours is a new adversarial scheme based on reconstruction.	Reply	I-Reply	1
Also, our loss function is more computational-efficient compared to SiGAN.	Reply	I-Reply	1
[line_break_token][line_break_token](2) Experiments[line_break_token]- How are the hyperparameters selected?	Reply	O	0
[line_break_token]Answer: We obtain the hyperparameters by cross-validation on the small data SVHMNIST, and then apply the same hyperparameters for all the experiments.	Reply	O	0
Note that one important novelty is that MDAT is not sensitive to the hyperparameter.	Reply	B-Reply	2
As shown in Table 3, as long as the margin m&gt;=1.0 &amp; alpha&lt;=0.1, the results are very robust.	Reply	O	0
Moreover, compared to DANN, the MDAT can always converge with the effective gradients by the reconstruction network.	Reply	B-Reply	2
[line_break_token][line_break_token]- What does the * in DRCN* mean in Table 1?	Reply	O	0
[line_break_token]Answer: Sorry, we actually miss some notes here.	Reply	O	0
This means that we reproduce DRCN to fill some results as they do not provide the result for SYN-&gt;SVHN.	Reply	O	0
[line_break_token][line_break_token]- ARN w.o.	Reply	O	0
MDAT may not be the best alternative since the target data is ignored in the reconstruction and the discriminator is not discriminating anymore.	Reply	O	0
A more reasonable alternative would be to ignore the margin and minimize L_r(x^s)-L_r(x^t) to see the effect of the margin.	Reply	O	0
[line_break_token]Answer: Yes.	Reply	O	0
We conduct ARN w.o.	Reply	B-Reply	4
MDAT to verify the efficacy of MDAT in ARN, as an ablation study.	Reply	I-Reply	4
It is a good suggestion to just ignore the margin.	Reply	I-Reply	4
However, in Table 3, we have shown that if the margin is small (m&lt;0.5), the results are very similar to the standard DAT (DANN),which means that when a small margin or no margin is applied, MDAT has the similar mechanism as DANN.	Reply	O	0
We further added the experiments when m=0 as the reviewer suggested, and supplement the results to Table 3, which further prove the effectiveness of the margin.	Reply	B-Reply	4
[line_break_token][line_break_token]m       0       0.1   0.3   0.5   0.7   1.0   2.0   5.0   10.0[line_break_token]acc    64.3  64.5 75.2 90.0 92.6 96.0 97.4 97.7 96.7[line_break_token][line_break_token]-  In Eq.(2), y is said to be the predicted domain label (-1 or +1), which could be not accurate according to the common hinge loss definition.	Reply	O	0
[line_break_token]Answer: Yes.	Reply	O	0
We agree with it.	Reply	B-Reply	5
There is a little difference that we should point out here.	Reply	I-Reply	5
Since we use the hinge loss for domain adaptation, we define the domain label (-1 and +1) in advance that directly confroms with the illustration of the main part (Eq.8).	Reply	I-Reply	5
The intuition is the same as the common hinge loss that tell two categories apart from a margin.	Reply	I-Reply	5
We will add the explanation after Eq.(2).	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]-Typos.	Reply	O	0
[line_break_token]We have revised the typos according to the comments.	Reply	B-Reply	6
[line_break_token][line_break_token]Refs[line_break_token]- Hsu, C.C., Lin, C.W., Su, W.T. and Cheung, G., 2019.	Reply	O	0
SiGAN: Siamese generative adversarial network for identity-preserving face hallucination.	Reply	O	0
IEEE Transactions on Image Processing, 28(12), pp.6225-6236.	Reply	O	0
[line_break_token]- Ghifary, Muhammad, et al. "	Reply	O	0
Deep reconstruction-classification networks for unsupervised domain adaptation."	Reply	O	0
European Conference on Computer Vision.	Reply	O	0
Springer, Cham, 2016	Reply	O	0

Authors proposed a new neural-network based machine translation method that generates the target sentence by generating multiple partial segments in the target sentence from different positions in the source information.	Review	O	0
The model is based on the SWAN architecture which is previously proposed, and an additional "local reordering" layer to reshuffle source information to adjust those positions to the target sentence.	Review	O	0
[line_break_token][line_break_token]Using the SWAN architecture looks more reasonable than the conventional attention mechanism when the ground-truth word alignment is monotone.	Review	O	0
Also, the concept of local reordering mechanism looks well to improve the basic SWAN model to reconfigure it to the situation of machine translation tasks.	Review	O	0
[line_break_token][line_break_token]The "window size" of the local reordering layer looks like the "distortion limit" used in traditional phrase-based statistical machine translation methods, and this hyperparameter may impose a similar issue with that of the distortion limit into the proposed model; small window sizes may drop information about long dependency.	Review	O	0
For example, verbs in German sentences sometimes move to the tail of the sentence and they introduce a dependency between some distant words in the sentence.	Review	O	0
Since reordering windows restrict the context of each position to a limited number of neighbors, it may not capture distant information enough.	Review	O	0
I expected that some observations about this point will be unveiled in the paper, but unfortunately, the paper described only a few BLEU scores with different window sizes which have not enough information about it.	Review	O	0
It is useful for all followers of this paper to provide some observations about this point.	Review	O	0
[line_break_token]In addition, it could be very meaningful to provide some experimental results on linguistically distant language pairs, such as Japanese and English, or simply reversing word orders in either source or target sentences (this might work to simulate the case of distant reordering).	Review	B-Review	1
[line_break_token][line_break_token]Authors argued some differences between conventional attention mechanism and the local reordering mechanism, but it is somewhat unclear that which ones are the definite difference between those approaches.	Review	I-Review	3
[line_break_token][line_break_token]A super interesting and mysterious point of the proposed method is that it achieves better BLEU than conventional methods despite no any global language models (Table 1 row 8), and the language model options (Table 1 row 9 and footnote 4) may reduce the model accuracy as well as it works not so effectively.	Review	O	0
This phenomenon definitely goes against the intuitions about developing most of the conventional machine translation models.	Review	O	0
Specifically, it is unclear how the model correctly treats word connections between segments without any global language model.	Review	O	0
Authors should pay attention to explain more detailed analysis about this point in the paper.	Review	O	0
[line_break_token][line_break_token]Eq. (	Review	B-Review	4
1) is incorrect.	Review	I-Review	4
According to Fig.	Review	I-Review	4
2, the conditional probability in the product operator should be revised to p(a_t | x_{1:t}, a_{1:t-1}), and the independence approximation to remove a_{1:t-1} from the conditions should also be noted in the paper.	Review	I-Review	4
[line_break_token]Nevertheless, the condition x_{1:t} could not be reduced because the source position is always conditioned by all previous positions through an RNN.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
Thank you for your valuable comments.	Reply	O	0
 We address the comments and questions below:[line_break_token]1.	Reply	O	0
The "window size" of the local reordering layer looks like the "distortion limit" used in traditional phrase-based statistical machine translation methods, and this hyperparameter may impose a similar issue with that of the distortion limit into the proposed model.	Reply	O	0
[line_break_token]<Response>: Thanks a lot for your suggestion.	Reply	O	0
We add the reference [Brown 1993] and discussion to the end of Section 2.3.	Reply	B-Reply	1
We believe the limit of local reordering is mitigated by using bidirectional RNN after that.	Reply	I-Reply	1
Thus it is not very clear how to analyze the exact behavior of the local reordering layer.	Reply	I-Reply	1
We are currently actively investigating new ways of doing so.	Reply	I-Reply	1
[line_break_token] [line_break_token]2.	Reply	I-Reply	1
It could be very meaningful to provide some experimental results on linguistically distant language pairs, such as Japanese and English, or simply reversing word orders in either source or target sentences.	Reply	O	0
[line_break_token]<Response>: Thanks a lot for your suggestion.	Reply	O	0
This is definitely one important direction we should investigate in future work.	Reply	B-Reply	2
[line_break_token] [line_break_token]3.	Reply	O	0
Authors argued some differences between conventional attention mechanism and the local reordering mechanism, but it is somewhat unclear that which ones are the definite difference between those approaches.	Reply	O	0
[line_break_token]<Response>: We reiterate and reorganize the important differences here:[line_break_token]First, we do not have a query to begin with as in standard attention mechanisms.	Reply	O	0
Second, unlike standard attention, which is top-down from a decoder state to encoder states, the reordering operation is bottom-up.	Reply	B-Reply	3
Third, the weights {w_i}_{i=0}^{2\tau} capture the relative positions of the input elements, whereas the weights are the same for different queries and encoder hidden states in the attention mechanism (no positional information).	Reply	I-Reply	3
The reordering layer performs locally similar to a convolutional layer and the positional information is encoded by a different parameter w_i for each relative position i in the window.	Reply	I-Reply	3
Fourth, we do not normalize the weights for the input elements e_{t-\tau}, ..., e_t, ..., e_{t+\tau}.  This provides the reordering capability and can potentially turn off everything if needed.	Reply	I-Reply	3
Finally, the gate of any position i in the reordering window is determined by all input elements e_{t-\tau},‚Ä¶, e_t, ‚Ä¶, e_{t+\tau} in the window.	Reply	I-Reply	3
[line_break_token] [line_break_token]4.	Reply	O	0
Equation (1) is incorrect.	Reply	O	0
According to Fig.	Reply	O	0
2, the conditional probability in the product operator should be revised to p(a_t | x_{1:t}, a_{1:t-1}), and the independence approximation to remove a_{1:t-1} from the conditions should also be noted in the paper.	Reply	O	0
Nevertheless, the condition x_{1:t} could not be reduced because the source position is always conditioned by all previous positions through an RNN.	Reply	O	0
[line_break_token]<Response>: We respectfully disagree with this assessment.	Reply	O	0
The Eq. (	Reply	B-Reply	4
1) is not an approximation; it is the way we model the output.	Reply	I-Reply	4
This is motivated by Eqs. (	Reply	I-Reply	4
2) and (3) of the CTC paper [Graves 2006],  p(y_{1:T}|x_{1:T‚Äô}) = sum_{a_{1:T‚Äô}} p(a_{1:T}|x_{1:T‚Äô}) marginalizes over the set of all possible segmentations.	Reply	I-Reply	4
And a_{1:T‚Äô} is a collection of the segments that, when concatenated, leads to y_{1:T}. We also have p(a_{1:T}|x_{1:T‚Äô}) = \prod{t=1}^{T‚Äô} p(a_t|x_t) given the assumption that the outputs at different times are conditional independent given the input state x_t.	Reply	I-Reply	4
Put it in another way, our approach can be described via a fully generative model:[line_break_token][line_break_token]For t=1, T‚Äô:[line_break_token][tab_token]Using x_t as the initial state, sample target words from RNN until we reach the end of segment symbol.	Reply	O	0
This gives us segment a_t.	Reply	B-Reply	4
[line_break_token]Finally, concatenate {a_1, ...a_T‚Äô} to obtain an output y_{1:T}. [line_break_token][line_break_token]Since there are more than one way to obtain the same y_{1:T}, its probability becomes p(y_{1:T}|x_{1:T‚Äô}) = sum_{a_{1:T‚Äô}, where a_{1:T‚Äô}\in S_y} p(a_{1:T}|x_{1:T‚Äô}), the Eq. (	Reply	I-Reply	4
1) in our paper.	Reply	I-Reply	4
This explanation is also added in the updated paper.	Reply	I-Reply	4
[line_break_token][line_break_token][Graves 2006] Graves, Alex, et al. "	Reply	O	0
Connectionist temporal classification: labeling unsegmented sequence data with recurrent neural networks."	Reply	O	0
Proceedings of the 23rd international conference on Machine learning.	Reply	O	0
ACM, 2006.	Reply	O	0
[line_break_token]        [tab_token][line_break_token]5.	Reply	O	0
NPMT achieves better BLEU than conventional methods despite no any global language models (Table 1 row 8), and the language model options (Table 1 row 9 and footnote 4) may reduce the model accuracy as well as it works not so effectively.	Reply	O	0
[line_break_token]<Response>: We also believe this is a super interesting and exciting observation.	Reply	O	0
Our current understanding is that phrases are important building blocks of the whole target sentence and these phrases are relatively independent.	Reply	O	0
With the help of being able to see the entire input sentence through the encoder, the performance can still be quite good without modeling the connection between the phrases.	Reply	O	0
This is exciting because decoding can be done in linear time and can also be parallelized.	Reply	O	0
We also show that adding an n-gram LM during beam search did help improve performance (Table 1 row 9).	Reply	O	0

This paper presents a deep, latent variable model for unsupervised data modeling problems.	Review	O	0
The problem with such latent, deep generative models is that they are difficult to train reliably.	Review	O	0
In this paper, the authors provide an approach based on stacked Wasserstein autoencoders to train deep latent variable models.	Review	O	0
Experimental results are demonstrated on various image datasets and the latent codes are demonstrated to have an interpretable meaning.	Review	O	0
[line_break_token]I like the inference techniques in the paper and like the ideas presented in this paper.	Review	O	0
e thank the reviewer for their positive feedback	Reply	O	0

Summary:[line_break_token]Standard CNN models for MNIST, CIFAR10 and ImageNet are vulnerable with regard[line_break_token]to (adversarial) rotation and translation of images.	Review	O	0
[line_break_token]The paper experimentally examines different ways of formulating attacks[line_break_token](gradient descent, grid search and sampling) and defenses[line_break_token](random augmentation, worst-case out of sample robust training,[line_break_token]aggregated classification) for this class of image transformation.	Review	O	0
[line_break_token][line_break_token]The main results are:[line_break_token]- Gradient descent is not effective at generating worst-case rotations /[line_break_token]translations due to nonconcavity of the adversarial objective[line_break_token]- Grid search is very effective due to low parameter space[line_break_token]- Sampling and pick the worst is also effective and cheap, for similar reasons[line_break_token]- L infinity ball pixel perturbation robustness is orthogonal to the examined[line_break_token]transformations and does not provide good defense mechanism[line_break_token]- Just augmenting data with random translation / rotations is not a strong[line_break_token]defense[line_break_token]- Using a worst-case out of sample of 10 for training with an approximation of[line_break_token]a robust optimization objective combined with an aggregated result for[line_break_token]classification is a stronger defense[line_break_token][line_break_token]Recommendation:[line_break_token]The paper presents a comprehensive study of a relevant class of adversarial[line_break_token]image perturbations for state-of-the-art neural network models.	Review	O	0
[line_break_token]The results are a useful pointer towards future research directions and for[line_break_token]building more robust systems in practice.	Review	O	0
[line_break_token]I recommend to accept the paper.	Review	O	0
[line_break_token][line_break_token]Strong points:[line_break_token]- The paper is well written, has clear structure and is technically easy to[line_break_token]understand.	Review	O	0
[line_break_token]- The question of padding and cropping comes up naturally and is then answered.	Review	O	0
[line_break_token][line_break_token]Open questions (things that could potentially be of interest when added):[line_break_token]- Loss landscapes look like most of the nonconcavity is along the translation[line_break_token]parameter.	Review	O	0
Any idea why?	Review	B-Review	1
[line_break_token]- What mechanisms within CNN models do or do not learn (generalize) rotation[line_break_token]and translation from provided data (including augmentation)?	Review	O	0
[line_break_token][line_break_token]Specific:[line_break_token]- Page 2: perturbrbations (Typo)[line_break_token]- Page 3: witho (Typo)[line_break_token]- Page 3: Constrained optimization problems typically written as[line_break_token]max_{...} \mathcal L(x', y) s.t.	Review	B-Review	3
x' = T(...)[line_break_token](s.t.	Review	I-Review	3
for subject to instead of for) but that's matter of taste I guess[line_break_token]- Page 4: first order -> first-order (consistency)[line_break_token]- Page 4: tyipcally (Typo)[line_break_token]- Page 4: occurs most common(ly)[line_break_token][line_break_token]I am not sufficiently knowledgable about the previous literature to ensure that[line_break_token]the claimed novelty of the paper is truly as novel.	Review	O	0
[line_break_token]	Review	O	0
We thank the reviewer for their kind words.	Reply	O	0
[line_break_token][line_break_token]-- Regarding the loss landscape: it appears that the loss landscape exhibits significant non-concavity in both directions (see page 19 for additional plots).	Reply	O	0
We do agree however that the translation direction is mostly responsible for the loss value (changes along the rotation direction appear jagged and without consistent patterns).	Reply	B-Reply	1
We do not have concrete ideas about why this this happening but we agree that it is an interesting research direction.	Reply	I-Reply	1
[line_break_token][line_break_token]-- Since for vanilla convolutional layers input translation can only lead to output translation, the main mechanisms responsible for translation non-robustness are max-pooling units and strided convolutions.	Reply	O	0
We do not have a similar understanding for the case of rotations.	Reply	B-Reply	2
This is an important direction for future work, but we believe that it goes beyond the scope of the current paper.	Reply	I-Reply	2
[line_break_token][line_break_token]We will update our manuscript to incorporate the typos and fixes pointed out.	Reply	I-Reply	3

This paper proposes a new advantage estimator in reinforcement learning based on importance sampling.	Review	O	0
This form allows for a significantly lower-variance estimator for situations where the current action "stops mattering" to the future state.	Review	O	0
A control variate, as in Grathwohl et al.,	Review	O	0
is used to combine the importance sampling estimator with the "standard" estimator in a way that is always unbiased and attempts to minimize the overall variance.	Review	O	0
[line_break_token][line_break_token]The overall setting makes sense.	Review	B-Review	2
I found your example (in the second paragraph of the introduction) initially somewhat misleading, though: in the setting where a game is composed of fully independent rounds, surely these would simply be modeled as completely separate MDPs.	Review	I-Review	2
Even if not, settings where the rounds are reset after a variable length of time (e.g. the round ends when one player achieves some objective) would *not* fit the exact independence structure you assume at the start of Section 3, if your current action affects when the game will reset.	Review	I-Review	2
But of course your estimator does not rely on actual *independence* (C = 0); it can take advantage of only "weak dependence" (and moreover this dependence need not be pre-specified).	Review	I-Review	2
You might think about emphasizing this a little more in the introduction to emphasize that the estimator is general, and you're looking for one that can take advantage of these kinds of situations.	Review	I-Review	2
[line_break_token][line_break_token]It might be worth noting after (2) that is upper-bounded by, so that the importance sampler is always well-defined and unbiased when action probabilities are nonzero.	Review	I-Review	3
This does raise an issue: a policy which *ever* deterministically avoids an action, i.e. in (13) is 0, will break the method.	Review	I-Review	3
This is worth explicitly stating somewhere.	Review	I-Review	3
[line_break_token][line_break_token]Something worth thinking about a bit: any choice of weights for your control variate provably doesn't affect your estimator in expectation (and you try to decrease its variance), so that bad estimation of e.g. the quantities in (7) won't lead you to being "incorrect," just higher-variance.	Review	I-Review	4
But a bad choice of parameters in your estimator *would* bias your estimates.	Review	I-Review	4
This is in some ways the same as the effect of using a value function or-function approximator, but can we say anything about the ways in which a bad estimator would likely affect the overall optimization process, perhaps in some very simple case?	Review	I-Review	4
Would an unbiased estimator lead to an unbiased advantage estimator? (	Review	I-Review	5
Not that it's clear how to get an unbiased estimator of the ratio in anyway.)	Review	I-Review	5
[line_break_token][line_break_token]Some minor points on notation: Using for the control variate was initially confusing to me, because elsewhere you've used e.g. for the random variable of a state and as the value of that state -- it made me think that was somehow supposed to be the value of a reward.	Review	I-Review	1
Another letter might be better.	Review	I-Review	1
Similarly, of (7) isn't really a value function; it's the difference between the value function and the sum of discounted control variates.	Review	I-Review	1
Also, doesn't estimate: it estimates, so it might make more sense notationally to just subtract one from the definition of.	Review	I-Review	1
[line_break_token][line_break_token]Overall: I think the idea in this paper is sensible, the derivations fairly clear, and it seems to help empirically.	Review	O	0
It does add a lot of "moving parts" to the already-complicated RL setup, though, and I'm not well-versed enough in the RL literature to have much of a sense of how convincing these experiments are; hopefully another reviewer is.	Review	O	0
hank you so much for your supportive comments.	Reply	O	0
In the following sections, we will give response to every question you have.	Reply	O	0
Please let us know if you have any questions in the response.	Reply	O	0
[line_break_token] [line_break_token][Parts of the example in the introduction is misleading][line_break_token] [line_break_token]Firstly, thanks for your advice on the example in the introduction.	Reply	O	0
We have clarified that the time of each round is constant in the updated version of our paper.	Reply	B-Reply	2
Also, it is worth mentioning that when the rounds last a variable length of time, there‚Äôs essentially no way to use independence property unless.	Reply	I-Reply	2
That‚Äôs because the next round will happen in different time intervals, which will make the next round necessary to be considered.	Reply	I-Reply	2
When, there will be ways to utilize independence property when you have variable length of time, but it can be left as future works.	Reply	I-Reply	2
[line_break_token] [line_break_token][The cases where the IS weight is not well defined][line_break_token] [line_break_token]Thanks for the advice and we may add the discussion on the validity of importance sampling, and the bound of importance sampling weight in the camera-ready version.	Reply	O	0
It is true that when, the IS-based advantage estimator on is not properly defined.	Reply	B-Reply	3
However, we will never sample these actions and we will never need to estimate the advantage function on these state-action pairs in policy optimization process, so it won‚Äôt affect the practical performance.	Reply	I-Reply	3
[line_break_token] [line_break_token][How a bad C estimation affects optimization][line_break_token] [line_break_token]It is true that a bad estimation in dependency factor will affect the policy optimization process in some cases; however, we will explain that not all bias in dependency factor estimation will harm the overall optimization process.	Reply	O	0
For instance, we initialize the classifier to have the same output with policy.	Reply	B-Reply	4
When there are not enough data to train the classifier, we will have all dependency factor to be close to zero, and all estimated advantage function becomes zero.	Reply	I-Reply	4
Although certainly there are biases in advantage estimation in this case, it won't hurt the overall optimization process since the policy will remain unchanged.	Reply	I-Reply	4
As there are enough data to train the classifier, the classifier can utilize the data to make more precise estimation, and the bias of advantage estimation will slowly approach to zero as estimation on C get more precise.	Reply	I-Reply	4
 [line_break_token] [line_break_token][Will an unbiased C estimator lead to an unbiased advantage estimator][line_break_token] [line_break_token]In our method, unbiased advantage estimation is based on not only accurate estimation on C, but also the assumption that we are able to draw two samples from the same state: one sample from and one sample from.	Reply	O	0
Empirically, we have to use function approximations to avoid drawing multiple samples from the same state, then there‚Äôre inevitable biases in practice.	Reply	B-Reply	5
[line_break_token] [line_break_token][Confusions in notations][line_break_token] [line_break_token]We agree that these notations are not very clear, and highly appreciate the comments.	Reply	O	0
We have modified these notations in the updated version of our paper.	Reply	B-Reply	1

The paper "OBJECTIVE MISMATCH IN MODEL-BASED REINFORCEMENT LEARNING" explores the relationships between model optimization and control improvement in model-based reinforcement learning.	Review	O	0
While it is an interesting problem, the paper fails at demonstrating really useful effects, and the writting needs to be greatly improved to help reader to focus on salient points.	Review	O	0
[line_break_token][line_break_token]From my point of view, the main problem of this paper is that it is too messy and it is very difficult to understand what authors want to show, as i) there is a very important lack of experimental details (e.g., main aspects of models and controllers should be clearly stated) and ii) analysis is to wordy, authors should emphasize the message in each part.	Review	B-Review	3
From the experiments in 4.1, the only thing that I got is from the last sentence "noisy trend of higher reward with better model loss".	Review	I-Review	4
are these results from LL computed on a validation set ?	Review	I-Review	4
If not, this is not reallly meaningfull since high LL may only indicate overfitting.	Review	I-Review	4
If yes, how was the validation data collected ?	Review	I-Review	4
If the collection is not inline with training it is difficult to understand what we observe since we only need LL to be good on the path from the current to the opitmal policy, not everywhere.	Review	I-Review	4
Even if the validation data is inline with training, there remains the difficulty of over-fitting in the policy area (for the on-policy experiments at least).	Review	I-Review	4
Is there something else ?	Review	I-Review	4
 From 4.2 we observe that it is unsurprisingly better to learn the model from the policy trajectories.	Review	O	0
From 4.3, we observe that an adversarial is able to reduce rewards without losing in LL.	Review	B-Review	1
Ok, the adversarial is able to lock the controler in a sub-optimal area while still being good to model the dynamics elsewhere, but what does it show ?	Review	I-Review	1
 Finally, proposal to cope with the identified mismatch are not clearly explained and not very convincing.	Review	O	0
Is re-weighting helping in collecting higher rewards ?	Review	B-Review	2
[line_break_token][line_break_token]From my point of view, this work is in a too preliminary state to be published at ICLR	Review	O	0
1: From 4.3, we observe that an adversarial is able to reduce rewards without losing in LL.	Reply	O	0
Ok, the adversarial is able to lock the controler in a sub-optimal area while still being good to model the dynamics elsewhere, but what does it show ?	Reply	O	0
 [line_break_token][line_break_token]&gt;&gt; This shows that training a dynamics model to a different local minimum (low NLL) could result in a sub-optimal controller.	Reply	O	0
This effect mirrors the results shown in fig3e where some models with ‚Äúgood‚Äù NLL still achieve low reward.	Reply	B-Reply	1
When training a model with stochastic methods there is no way to secure coverage of a specific area of the state space, so similar effects could be observed.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]R1: Finally, proposal to cope with the identified mismatch are not clearly explained and not very convincing.	Reply	O	0
Is re-weighting helping in collecting higher rewards ?	Reply	O	0
[line_break_token][line_break_token]&gt;&gt; Multiple reviewers have brought this point up, and we will expand it‚Äôs explanation.	Reply	O	0
Re-weighting is helping to get higher rewards in a particular area of interest ‚Äì low data  amounts near the expert trajectory.	Reply	B-Reply	2
In the regime of dataset size of 100 to 1000 points, the re-weighting is able to solve the task for many different epsilons, but the standard training method only does so with the highest end of the dataset size.	Reply	I-Reply	2
This is the region showing the impact of our method, and we included the full picture to show two additional points of interest (best illustrated in the standard training method).	Reply	I-Reply	2
1) data collected too close to expert will not result in a robust controller ‚Äì seen as the dark area at the bottom of both plots and 2) there is a line where data too far from expert no longer is able to solve the task at a set size ‚Äì seen as the diagonal line of high vs low reward in the center of the standard plot.	Reply	I-Reply	2
 	Reply	I-Reply	1

This paper proposes VarPSOM, a method which utilizes variational autoencoders (VAEs) and clustering techniques based on self-organizing maps (SOMs) to learn clustering of image data (MNIST and Fashion MNIST in particular).	Review	O	0
An LSTM-based extension termed VarTPSOM is also evaluated on medical time series data.	Review	O	0
For the most part, the experimental results are promising, and the visualizations are particularly nice.	Review	O	0
[line_break_token][line_break_token]One of my main points of confusion is with the exposition of the method.	Review	B-Review	7
To start, the objective presented in Eq.	Review	I-Review	7
3 is simply a sum of a variational lower bound and the PSOM clustering loss.	Review	I-Review	7
Does this have a probabilistic interpretation, e.g., is it a lower bound for a particular generative model?	Review	I-Review	7
If so, this would be useful to discuss prominently in the paper.	Review	I-Review	7
If not, it is not clear to me what the authors are gaining from the variational framework.	Review	I-Review	7
The paragraph at the bottom of page 4 that discusses the "advantages of a VAE over an AE" is not convincing to me.	Review	I-Review	7
The authors claim that "points with a higher variance in the latent space could be identified as potential outliers and therefore treated as less precise and trustworthy".	Review	I-Review	7
This isn't demonstrated in the experiments, and to the best of my knowledge, this has not been shown in prior work.	Review	I-Review	7
If I am mistaken, a citation would be appreciated and should be included in the paper.	Review	I-Review	7
Additionally, the claim that "the regularization term of the VAE prevents the network from scattering the embedded points discontinuously in the latent space" can also be accomplished with AEs with simple regularization, a standard technique for a wide range of AEs.	Review	I-Review	7
[line_break_token][line_break_token]Similar comments can be made for the VarTPSOM objective in Eq.	Review	I-Review	2
6.	Review	I-Review	2
Prior work in variational inference for time series, e.g., [1, 2] define a probabilistic time series generative model, from which variational inference naturally prescribes a learning objective.	Review	I-Review	2
In my opinion, this stands in stark contrast to this work, which takes the VarPSOM objective and simply adds a time series loss on top.	Review	I-Review	2
This is also a viable approach to building models, but why emphasize variational so much if the method is hardly motivated by anything variational?	Review	I-Review	2
[line_break_token][line_break_token]I believe that the authors need more thorough experimental comparisons if they wish to demonstrate that their method actually benefits from the variational pieces.	Review	I-Review	1
Most obviously, I do not believe that any of the comparisons represent the proposed method but with the VAE swapped out for some type of AE?	Review	I-Review	1
It is my understanding that AE+SOM, SOM-VAE, and DESOM do not represent this exact ablation.	Review	I-Review	1
VarIDEC performing better than IDEC is a data point in support of this hypothesis, however, this is a comparison of a prior method and not the proposed method.	Review	I-Review	1
[line_break_token][line_break_token]The related work section mentions that SOM-VAE and DESOM are "likely limited by the absence of techniques used in state-of-the-art clustering methods".	Review	I-Review	3
Is it possible to address this limitation of prior work?	Review	I-Review	3
If so, how would this approach compare to the proposed method in terms of implementation and performance?	Review	I-Review	3
I am not necessarily interested in an actual empirical evaluation, but including this in the related work section would likely be interesting for the reader.	Review	I-Review	3
[line_break_token][line_break_token]The authors claim in the implementation details that "[s]ince the prior in the VAE enforces the latent embeddings to be compact, it also requires more dimensions to learn a meaningful latent space".	Review	I-Review	4
Is there a citation for this?	Review	I-Review	4
My understanding is that posterior collapse leads to VAEs not using additional dimensions even when they are provided, which seems to contradict this claim.	Review	I-Review	4
[line_break_token][line_break_token]Table 2 seems to have very low NMI numbers across the board, am I reading this incorrectly?	Review	I-Review	5
Are there prior SOTA numbers that can be included?	Review	I-Review	5
[line_break_token][line_break_token]Finally, it seems that some of the ideas and motivation in the paper are related to learning discrete structures with variational approaches, e.g., [3, 4]. If the authors agree, it may be appropriate to include some discussion in related work.	Review	I-Review	6
[line_break_token][line_break_token][1] Johnson et al, "Composing graphical models with neural networks for structured representations and fast inference".	Review	O	0
NIPS 2016.	Review	O	0
[line_break_token][2] Fraccaro et al, "Sequential neural models with stochastic layers".	Review	O	0
NIPS 2016.	Review	O	0
[line_break_token][3] Tomczak and Welling, "VAE with a VampPrior".	Review	O	0
AISTATS 2018.	Review	O	0
[line_break_token][4] Vikram et al, "The LORACs prior for VAEs: Letting the trees speak for the data".	Review	O	0
AISTATS 2019.	Review	O	0
[line_break_token][line_break_token]------[line_break_token][line_break_token]To elaborate on my "Experience Assessment" of "I have read many papers in this area": "this area" in my case refers to amortized variational inference and VAEs, not clustering techniques and SOM.	Review	O	0
hank you for your feedback and the encouraging comments about the results / visualizations.	Reply	O	0
We respond to the different points raised in the review separately below.	Reply	O	0
[line_break_token][line_break_token]Advantages of the Variational framework:[line_break_token]We would like to clarify that our method is not only meant to cluster images, but could be used for various data types relevant in application domains, like images, time series, or others.	Reply	O	0
With respect to our choice of a variational framework, there are various well known advantages of VAEs vs. deterministic AEs.	Reply	B-Reply	1
Firstly, they can be more easily sampled from (which could be important when e.g synthesizing or completing time series traces forward).	Reply	I-Reply	1
Further advantages include the ability to meaningfully interpolate the latent space of VAEs.	Reply	I-Reply	1
Lastly, VAEs feature a more structured/disentangled latent space compared to AEs [3]. In regards to our sentence that ‚Äúpoints with high variance could be treated as outliers‚Äù, the advantages of VAEs vs. AEs for anomaly detection has been noted in prior work (see Section 3.3 of [4], we will add this citation to the manuscript).	Reply	I-Reply	1
It is true that the effect of not scattering points in latent space can also be achieved with a regularized AE, but then we would lose the advantages of VAEs as outlined above.	Reply	I-Reply	1
We thank you for suggesting the additional ablation study.	Reply	I-Reply	1
In response to this comment, we have added a new comparison to Table 1: We introduce the ‚ÄòAEPSOM‚Äô model, which is identical to `VarPSOM` but substitutes the VAE with a regular auto-encoder.	Reply	I-Reply	1
We observed a pronounced performance drop from 0.705 (0.571) NMI on MNIST (Fashion MNIST) to 0.555 (0.493), which suggests that a VAE-based framework has advantages when paired with the PSOM clustering loss.	Reply	I-Reply	1
[line_break_token][line_break_token]Time series prediction/generation:[line_break_token]We would like to emphasize that the main purpose of our model is not to generate time series, hence we did not attempt to compete with complex probabilistic generative models for time series.	Reply	O	0
In our experiments we want to demonstrate how the Variational PSOM, that we show to outperform a large range of baselines in the MNIST experiment, could be further extended for modeling high-dimensional real-world time series.	Reply	B-Reply	2
This suggests that the model encodes information that is helpful for future prediction and thus strengthens the usefulness of the representation.	Reply	I-Reply	2
[line_break_token][line_break_token]Baselines vs. SOTA clustering methods:[line_break_token]We apologize for the lack of clarity in the discussion of the SOM baselines and the state-of-the-art clustering methods.	Reply	O	0
We meant to convey that previous deep SOM methods [1,2] did not offer comparisons to SOTA clustering methods, such as DEC and IDEC, in their respective empirical evaluations and also did not make use of modern ideas in the deep clustering field, such as the clustering assignment hardening loss.	Reply	B-Reply	3
Adding those ideas to the previous approaches would lead to the different ablations of our model that we show in the experiments section (Table 1).	Reply	I-Reply	3
Additionally combining this with our novel PSOM loss and the powerful latent RNN time series model then yields our proposed architecture VarTPSOM.	Reply	I-Reply	3
[line_break_token][line_break_token]Benefits of the VAE prior:[line_break_token]The prior of the VAE leads to a smooth latent space that is shown to ease the clustering task compared to a standard Autoencoders (Table 1).	Reply	O	0
One could argue that there are explicit regularizations that, if applied to a deterministic autoencoder, lead to an equally smooth and meaningful latent space [5]. However, we believe that a variational framework in which a generative model is learned from the data could represent an important step towards a more versatile and reusable framework for interpretable clustering on different types of data.	Reply	B-Reply	4
[line_break_token][line_break_token]SOTA for NMI on ICU time series:[line_break_token]We agree that the NMI values are low compared to for instance the MNIST task.	Reply	O	0
However, it should be noted that the task of assigning a physiology score to a patient is much harder, since the data is noisier and there are more different physiology scores than for instance MNIST digit classes.	Reply	B-Reply	5
Also, physiology scores are naturally ordered and small differences in the score correspond to small differences in severity of physiology.	Reply	I-Reply	5
To the best of our knowledge, the SOM-VAE reported SOTA results on this task [1]. We will also add K-means baseline as a reference to a revised version of our paper, which has lower performance with an NMI of 0.0411 (for APACHE 6) and 0.0384 (for APACHE 12) according to new experiment performed in response to your comment.	Reply	I-Reply	5
To make the results more interpretable, we are also considering to augment them with AUROC performance on the downstream task of dynamic mortality prediction in a future version of the manuscript.	Reply	I-Reply	5

In this paper, the authors proposed an attack scheme to any model that pretrained from a general model.	Review	O	0
The merit comes from that the attacker, by taking advantage of the vulnerability of softmax, has no access to examples from the target task to finetune the model.	Review	O	0
 [line_break_token][line_break_token]Pros:[line_break_token]-[tab_token]The setting where the authors focused on is much more practical, i.e., the attacker is blind to examples in a target task.	Review	O	0
 [line_break_token]-[tab_token]The blackdoor for attack in this work, namely the softmax layer, is novel and interesting to me, at least to my knowledge.	Review	O	0
[line_break_token]-[tab_token]The paper is well written and easy to follow.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]-[tab_token]In the experiments, the authors should still compare one or two black-box attacks which also use model outputs only, to demonstrate the effectiveness/efficiency of the proposed attack scheme.	Review	O	0
[line_break_token]-[tab_token]Considering the design of \gamma and \beta in Eqn. (	Review	O	0
1), it is expected to investigate the influence of both on the performance of the attack, as well as the vanilla version of Eqn. (	Review	B-Review	2
1) by only considering MSE.	Review	I-Review	2
[line_break_token]-[tab_token]Currently, it seems that the authors did not study the influence of different target datasets to finetune.	Review	O	0
It is highly expected that the same adversarial input crafted using Alg.	Review	B-Review	3
1 could fool all networks finetuned using different datasets.	Review	I-Review	3
What if a wildly different dataset is used to finetune the pretrained model?	Review	I-Review	3
.	Reply	B-Reply	1
We compare our attack with a black-box attack, called ZOO, in [A], which the source code is available at <a href="https://github.com/IBM/ZOO-Attack."	Reply	O	0
target="_blank" rel="nofollow">https://github.com/IBM/ZOO-Attack.</a> We use the same settings as in Section 4.2 of [A] with one exception.	Reply	O	0
We do not stop the optimization process when the target class probability becomes higher than other classes because in our attack scenario, instead, we assume that only images with higher than 95% confidence in one of the classes are accepted.	Reply	B-Reply	1
Otherwise, the input is rejected.	Reply	I-Reply	1
So, our attack setting is more restricted and that is the reason their black-box attack performs worse in our setting than in their paper.	Reply	I-Reply	1
We choose a random image and a random target for the attack.	Reply	I-Reply	1
We use the re-trained model on 5 faces as the student model and VGGFace as the teacher model.	Reply	I-Reply	1
We set the hard limit of 5,000,000 queries per image.	Reply	I-Reply	1
The average query is only computed for successful attacks.	Reply	I-Reply	1
In our experiment, the successful rate is 18.2% (in other words, 4 out of 5 attacks fail after 5m attempts).	Reply	I-Reply	1
Among the successful ones, Zoo attack needs 1,036,800 queries to the black-box student model on average.	Reply	I-Reply	1
In comparison, our attack needs 50,000 queries to the teacher model, 1 query to the black-box student model, and the successful rate (effectiveness) is 91.68%.	Reply	I-Reply	1
We need to also emphasize that the number of queries to the teacher model is not critical because the teacher model is publically available and we can download and query the teacher model on a sever of the attacker‚Äôs.	Reply	I-Reply	1
Additionally, since our attack is target-agnostic, the crafted images only depend on the teacher model.	Reply	I-Reply	1
Hence, one can craft a set of potential adversarial images and use it over and over again on multiple student models.	Reply	I-Reply	1
It means that, for example, once the crafted images are available, an attacker can use them without a need to query the teacher model.	Reply	I-Reply	1
In other words, the number of query is essentially 1 to the student model with an effectiveness of 91.68%.	Reply	I-Reply	1
The advantage of using the teacher model gives us enough advantage that no black-box attack without the teacher model can beat us.	Reply	I-Reply	1
[line_break_token][line_break_token]Given the time limitation, this is the only model we can implement.	Reply	I-Reply	1
We think it clearly demonstrates the difference between our model and a black-box model.	Reply	I-Reply	1
If reviewers have specific suggestions on black-box models, we are happy to compare with them further.	Reply	I-Reply	1
[line_break_token][line_break_token][A] Chen, P. Y., Zhang, H., Sharma, Y., Yi, J., &amp; Hsieh, C. J. (2017, November).	Reply	O	0
Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models.	Reply	O	0
In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (pp.	Reply	O	0
15-26).	Reply	O	0
ACM.	Reply	O	0

# Response to rebuttal[line_break_token][line_break_token]I would like to thank their authors for their rebuttal.	Review	O	0
[line_break_token][line_break_token]After reading the other reviews, the author response and the revised manuscript, I have decided to keep my score of weak reject for the time being.	Review	O	0
[line_break_token][line_break_token]In short, while I appreciate the effort the authors put in partly addressing some of the most important comments raised during the review process, I think the paper would greatly benefit from some additional work.	Review	O	0
In particular:[line_break_token][line_break_token](1) Given the emphasis on scalability, I still believe the authors should carry out more thorough experiments to characterize the runtime of their approach with respect to different characteristics of the graphs.	Review	O	0
While the result provided in the response to Reviewer #3 is a first step, I recommend the authors to extend it by (1) varying graph size (in terms of nodes and edges); (2) varying graph type and (3) reporting the speedup with respect to other baselines.	Review	B-Review	4
[line_break_token][line_break_token](2) To the best of my knowledge, the ablation experiment in Section A.7.4 does not provide results for the setting in which no graph attention mechanism is used at all, neither for the case where the graph attention mechanism used is identical to GAT (restricted to 1-step neighbourhoods).	Review	O	0
[line_break_token][line_break_token](3) While NSPDK might be a reasonable choice, I still am of the opinion that the choice of graph kernel for this purpose is highly arbitrary and, thus, should be investigated further.	Review	O	0
Given that such a choice is being used to define a performance metric, which moreover is being highlighted as a contribution, the authors should study the robustness of the metric to the choice of graph kernel, as well as its sensitivity to known perturbations.	Review	B-Review	6
[line_break_token][line_break_token](4) Finally, I did not see any error bars added to the main results in the paper.	Review	O	0
[line_break_token][line_break_token]Despite these shortcomings, I would like to reiterate that I believe the proposed approach is promising and, with some additional work, would be a contribution definitely worth publishing.	Review	O	0
Therefore, I would like to encourage the authors to further revise the manuscript.	Review	O	0
[line_break_token][line_break_token]# Summary[line_break_token][line_break_token]In this paper, the authors propose an auto-regressive deep generative model for graph-structured data, motivated by the goal of scalability with respect to graph size, graph density and sample size.	Review	O	0
[line_break_token][line_break_token]In a nutshell, the approach follows closely the ideas in [1, 2], which model graph generation as an auto-regressive process after fixing or sampling an ordering for the nodes.	Review	O	0
Unlike [1, 2], however, the proposed method makes use of graph convolutions and a graph attention mechanism, closely related to GAT [3], to parametrize the conditional distributions of node/edges given the previously generated graph elements.	Review	O	0
[line_break_token][line_break_token]The performance of the proposed approach is evaluated in comparison to [1, 2] in several synthetic and real-world datasets, using MMD [4] between generated and held-out test graphs as metric.	Review	O	0
Unlike [2], which applies MMD on three graph statistics (degree, clustering coefficient and average orbit counts), this manuscript proposes to evaluate MMD using a graph kernel as well [5].[line_break_token][line_break_token]# High-level assessment[line_break_token][line_break_token]The main contribution in this paper is to combine a graph attention mechanism, which can be seen  as a simplification of GAT [3], with deep autoregressive graph models, such as DeepGMG [1] or GraphRNN [2]. In this way, the manuscript has a large conceptual overlap with the method in [6], which can be nevertheless be regarded as concurrent rather than prior work.	Review	O	0
From a methodological perspective, I believe the contribution is sound and sufficiently novel, although perhaps slightly on the incremental side.	Review	B-Review	1
[line_break_token][line_break_token]However, the current version of the manuscript has shortcomings regarding (i) lack of clarity in the exposition of the method‚Äôs relation to prior work, low-level implementation details and experimental setup and (ii) insufficient experimental results to back up some of the authors‚Äô claims.	Review	O	0
[line_break_token][line_break_token]Nonetheless, I believe the proposed approach is promising, and encourage the authors to address or clarify these issues during the author discussion phase.	Review	O	0
[line_break_token][line_break_token]# Major points / suggestions[line_break_token][line_break_token]1.	Review	O	0
The manuscript presents the proposed approach in a way that does not clearly differentiate between prior work and original contributions.	Review	B-Review	1
[line_break_token][line_break_token]In particular, I believe that the ideas in Section 3.1 and 3.2 are almost identical to those in [1, 2], the graph attention mechanism in Section 3.3 can be seen as a minor modification of GAT [3], and Section 3.4 also has a strong conceptual overlap with [1, 2].[line_break_token][line_break_token]I would encourage the authors to be more clear with respect to what is novel and what is borrowed from prior work.	Review	I-Review	1
Moreover, when slightly departing from prior work (e.g. the modifications applied to the graph attention mechanism in Section 3), I would also encourage the authors to focus on explaining what specifically has changed and what is the rationale behind those design choices, rather than explaining the entire mechanism ‚Äúfrom scratch‚Äù, leaving up to the reader to figure out what is novel.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The paper‚Äôs clarity could be improved, with some parts presented in an unnecessarily complicated manner (e.g. the graph attention mechanism) and others without sufficient detail (e.g. the edge estimator module, the zero-ing heuristic for attention or the generation of graphs based on ‚Äúseed graphs‚Äù, which is only mentioned in the appendix).	Review	B-Review	2
[line_break_token][line_break_token]For example, regarding the graph attention mechanism, I would recommend: (i) explaining more clearly what the ‚Äúfeature vector of node‚Äù is exactly in relation to the notation of Section 3.1; (ii) if the query, key and value matrices are identical, as the text seems to imply, I would rewrite the equations directly in terms of which would simplify the notation significantly; (iii) perhaps most importantly, the bias functions, and should be defined mathematically and discussed in greater detail and (iv) the output FNN should also be described mathematically.	Review	I-Review	2
Finally, as mentioned above, I would emphasise the differences between the proposed attention mechanism and GAT.	Review	I-Review	2
[line_break_token][line_break_token]The edge estimator mechanism is described too imprecisely in Section 3.4.4.	Review	I-Review	2
While Section A.4 definitely helps, I would recommend defining the entire operation mathematically in Section 3.4.4 as well.	Review	I-Review	2
Likewise, a precise mathematical definition of GRAM-A in Section 3.5.2 would also be helpful.	Review	I-Review	2
[line_break_token][line_break_token]Finally, as mentioned in this forum by Prof.	Review	I-Review	2
Ranu prior to this review‚Äôs writing, the graph generation procedure described in Section A.7.2 seems unconventional.	Review	I-Review	2
I would encourage the authors to both clarify what they mean by ‚Äúfor the convenience of implementation‚Äù and to investigate whether the experimental conclusions are affected by this departure from prior practices.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	1
Key details about the experimental setup, such as the hyperparameter selection protocol for the proposed approach and baselines, as well as the resulting architectures, seems to be missing, making it difficult to assess if the experimental setup is ‚Äúfair‚Äù.	Review	I-Review	3
[line_break_token][line_break_token]In particular, all methods should be allowed to use a similar number of parameters or, alternatively, have their hyperparameters tuned equally carefully for each dataset separately.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	I-Review	2
Most importantly, I believe the experimental results are insufficient to back up some of the claims made in the introduction.	Review	I-Review	4
[line_break_token][line_break_token]    4.1.	Review	I-Review	4
Despite the focus on scalability throughout the motivation, there are no experiments systematically exploring how the runtime at train and test time of the proposed approach and the main baselines scales with respect to sample size, number of nodes per graph and graph density.	Review	I-Review	4
Moreover, no results are provided for large graphs (e.g. ~5k nodes as in [6]).	Review	I-Review	4
[line_break_token][line_break_token]    4.2.	Review	O	0
The graph attention mechanism was claimed to be an original contribution.	Review	B-Review	5
However, no results are provided to evaluate its advantages with respect to the different GAT variants nor ablation studies to see its usefulness relative to a variant of the proposed approach using only graph convolutions.	Review	I-Review	5
[line_break_token][line_break_token]    4.3 The idea of using MMD in conjunction with graph kernels as a performance metric is interesting.	Review	O	0
However, there is no investigation of key aspects such as (i) its relation to other metrics and (ii) the impact that the choice of graph kernel, among the many available, and/or of graph kernel hyperparameters has on the resulting metric (see [7] for a comprehensive review on graph kernels).	Review	B-Review	6
[line_break_token][line_break_token]   4.4.	Review	O	0
Finally, the results have been reported without error bars, making it difficult to quantify the statistical significance of the observed performance differences between approaches.	Review	B-Review	7
[line_break_token][line_break_token]# Minor points / suggestions[line_break_token][line_break_token]1.	Review	O	0
I strongly believe the authors should adapt the manuscript to mention [6] and related/concurrent work.	Review	B-Review	8
Ideally, including it as an additional baseline would be even better, but not necessary given the limited rebuttal time.	Review	I-Review	8
Nevertheless, this point was not taken into consideration when scoring the manuscript, given how recent [6] is.	Review	I-Review	8
[line_break_token][line_break_token]# References[line_break_token][line_break_token][1] Li, Yujia, et al. "	Review	O	0
Learning deep generative models of graphs." *	Review	O	0
International Conference on Machine Learning.*	Review	O	0
2018.	Review	O	0
[line_break_token][2] You, Jiaxuan, et al. "	Review	O	0
Graphrnn: Generating realistic graphs with deep auto-regressive models." *	Review	O	0
International Conference on Machine Learning.*	Review	O	0
2018.	Review	O	0
[line_break_token][3] Veliƒçkoviƒá, Petar, et al. "	Review	O	0
Graph attention networks." *	Review	O	0
International Conference on Learning Representations*. 2018.	Review	O	0
[line_break_token][4] Gretton, Arthur, et al. "	Review	O	0
A kernel method for the two-sample-problem."	Review	O	0
Advances in Neural Information Processing Systems.	Review	O	0
2007.	Review	O	0
[line_break_token][5] Costa, Fabrizio, and Kurt De Grave. "	Review	O	0
Fast neighborhood subgraph pairwise distance kernel."	Review	O	0
Proceedings of the 26th International Conference on Machine Learning.	Review	O	0
Omnipress; Madison, WI, USA, 2010.	Review	O	0
[line_break_token][6] Liao, Renjie, et al. "	Review	O	0
Efficient Graph Generation with Graph Recurrent Attention Networks." *	Review	O	0
Advances in Neural Information Processing Systems.*	Review	O	0
2019.	Review	O	0
[line_break_token][7] Kriege, Nils M., Fredrik D. Johansson, and Christopher Morris. "	Review	O	0
A Survey on Graph Kernels." *	Review	O	0
arXiv preprint arXiv:1903.11835* (2019).	Review	O	0
o Reviewer #1[line_break_token][line_break_token]Thank you for the detailed review and helpful suggestions.	Reply	O	0
[line_break_token]Below we answer the clarification points in the review one by one.	Reply	O	0
[line_break_token]We are preparing and conducting additional experiments/analysis now, and we will report the results as soon as ready.	Reply	O	0
[line_break_token][line_break_token][line_break_token]# 1[line_break_token]Thank you for pointing out.	Reply	O	0
As the reviewer mentions, our work shares some points with previous works.	Reply	B-Reply	1
However, we believe it has several different or improved points, which would like to be noted.	Reply	I-Reply	1
Below we list the shared points and different points one by one.	Reply	I-Reply	1
We will specify them on revising as the reviewer pointed out.	Reply	I-Reply	1
[line_break_token][line_break_token]Section 3.1 and 3.2 describe notations and likelihood formulation of graphs.	Reply	I-Reply	1
As they are fundamental for graph generation, these parts certainly have common with previous works [1, 2]. On the other hand, these parts differ from previous works in that we formulated the likelihood of graphs in a general manner assuming node/edge labels, as it is necessary for the following model description.	Reply	I-Reply	1
This is not explicitly included in those previous works.	Reply	I-Reply	1
[line_break_token][line_break_token]Our graph attention shares the basic idea with Compared to GAT [3]: aggregating node features via attention.	Reply	I-Reply	1
On the other hand, GAT only considers 1-step neighbors whereas our graph attention can consider-step neighbors ) and embed relative positional information between nodes.	Reply	I-Reply	1
 We believe it will be one reliable step for future applicabilities of attention mechanisms in graphs.	Reply	I-Reply	1
[line_break_token][line_break_token]The proposed model has in common with previous works [1, 2] in that they generate a graph adding nodes and edges sequentially.	Reply	I-Reply	1
The main point our model differs from them is that it employs graph attention mechanism, which reduces the minimum sequential operations during training to O(1) and enables efficient parallelized training.	Reply	I-Reply	1
In addition, our model can consider node/edge labels, which GraphRNN [2] cannot handle.	Reply	I-Reply	1
We would like it to be noted these points  O(1) minimum sequential operations on training along with the capacity to handle node/edge labels, which are the out of range of prior works.	Reply	I-Reply	1
[line_break_token][line_break_token]# 2.	Reply	O	0
[line_break_token]Thank you for pointing it out.	Reply	B-Reply	2
We will modify the parts as mentioned on revising.	Reply	I-Reply	2
[line_break_token][line_break_token]# 3.	Reply	O	0
[line_break_token]Basically, we used the default parameter setting of the prior works.	Reply	B-Reply	3
For GraphRNN, we modified the model so that it can output node/edge labels and added parameters accordingly.	Reply	I-Reply	3
We will include that on revising.	Reply	I-Reply	3
[line_break_token][line_break_token]# 4.2.	Reply	O	0
[line_break_token]In Section A.7.4, we included an ablation study on the bias terms of our graph attention, which can be considered as a comparison with GAT variants.	Reply	B-Reply	5
We will add some description of that on revising.	Reply	I-Reply	5
[line_break_token]# 4.3.	Reply	O	0
[line_break_token](i) Since it is usually hard to directory determine a projecting function that corresponds to a specific kernel, it would be difficult to directory relate graph kernel MMD with other MMD scores.	Reply	O	0
However, since the used kernel, NSPDK [4] considers low/high-level structures of graphs, the graph kernel MMD score is expected to measure several graph statistics such as degree, clustering coefficient, and orbit count.	Reply	B-Reply	6
[line_break_token][line_break_token]# 4.4.	Reply	O	0
[line_break_token]Thank you for pointing it out.	Reply	B-Reply	2
We will include error bars on revising.	Reply	I-Reply	7
[line_break_token][line_break_token]# Minor 1[line_break_token]Thank you for pointing out.	Reply	O	0
We will include that work in related work.	Reply	B-Reply	8
[line_break_token][line_break_token][line_break_token]# Reference[line_break_token][1] Li, Yujia, et al. "	Reply	O	0
Learning deep generative models of graphs." *	Reply	O	0
International Conference on Machine Learning.*	Reply	O	0
2018.	Reply	O	0
[line_break_token][2] You, Jiaxuan, et al. "	Reply	O	0
Graphrnn: Generating realistic graphs with deep auto-regressive models." *	Reply	O	0
International Conference on Machine Learning.*	Reply	O	0
2018.	Reply	O	0
[line_break_token][3] Veliƒçkoviƒá, Petar, et al. "	Reply	O	0
Graph attention networks." *	Reply	O	0
International Conference on Learning Representations*. 2018.	Reply	O	0
[line_break_token][4] Fabrizio Costa and Kurt De Grave. ‚	Reply	O	0
ÄúFast neighborhood subgraph pairwise distance kernel.	Reply	O	0
‚Äù *International Conference on Machine Learning,* 2010.	Reply	O	0

This paper was an interesting read.	Review	O	0
The idea of this paper is to challenge the use of Laplacian matrix in GCN.	Review	O	0
Indeed, typical GCNs use the same adjacency matrix across different layers.	Review	O	0
In particular, this typically leads in Euclidean case to learning isotropic filters (because the euclidean Laplacian is isotropic).	Review	O	0
Consequently, such filters have no selectivity at all.(in the Euclidean case, that could correspond to the selectivity to orientations - no selectivity would lead to a difference of Gaussians) Furthermore, for non-sparse graphs, computing the iterations of the Laplacian matrix can require a significant computational power.	Review	O	0
[line_break_token][line_break_token]In order to tackle this problem, the authors introduced a diffusion factor to sample a set of nodes to build some GCN filters with finite support.	Review	O	0
At a given layer, the diffusion factors is based on the interaction with other layers of the GCN.	Review	O	0
Then, a layer-wise attention mechanism that will allow to weight the graph connectivity of the sampled nodes is used, which is supervisedly learned.	Review	O	0
Each numerical experiments lead to a significantly better accuracy, while the method trains in reasonable time.	Review	O	0
This is thus numerically convincing.	Review	O	0
Furthermore, this method is, to my knowledge, new.	Review	O	0
[line_break_token][line_break_token]The paper is clearly written, the numerical experiments are convincing and the authors address a difficult problem with a simple method: I'm leaning toward an "Accept".	Review	O	0
[line_break_token][line_break_token]Minor: [line_break_token]- Tables 2/3 are hard to read.	Review	O	0
[line_break_token]- The paper is 10 pages long, yet this was an interesting read.	Review	O	0
[line_break_token][line_break_token]Post-discussion:[line_break_token]The other reviewers have made some good point, and thus I decided to lower my score.	Review	O	0
I still find the paper address an interesting problem.	Review	O	0
hank you very much for your comments.	Reply	O	0
[line_break_token]In the revised manuscript, we adjust the presentation of Table 3 by showing the relative speedups with the results of GCN rather than a long table with numbers, which makes it easier to read.	Reply	B-Reply	1
Moreover, we further polish our manuscript, and try our best to make it more concise.	Reply	I-Reply	2
[line_break_token]Thanks again for your comments.	Reply	O	0

-> Summary[line_break_token][line_break_token]The authors propose to extend the analysis of Shwartz-Ziv & Tishby on the information bottleneck principle in artificial neural network training to realistic large-scale settings.	Review	O	0
They do so by replacing otherwise intractable quantities with t	Review	O	0
Thank you for your review.	Reply	O	0
Minor comments have been accounted for in the amended script.	Reply	O	0
This will be uploaded as a revision shortly.	Reply	O	0
Major comments will be dealt with here.	Reply	O	0
[line_break_token][line_break_token]Regarding missing ablation studies.	Reply	O	0
It takes approximately two weeks to train a single PixelCNN++ model for a single data point in Figures 3c and d. We intentionally chose a PixelCNN++ model and the CINIC-10 dataset to ensure the analysis we undertook was as thorough as possible, and that the bounds on the MI were as tight as possible, given current state of the art research and computational feasibilities for this estimation.	Reply	O	0
Ablations studies are simply computationally infeasible for us.	Reply	O	0
[line_break_token][line_break_token]Regarding the comments on the generated samples.	Reply	O	0
It seems that what is missing from our discussion is the caveat that at convergence the images most resemble the classes they are in.	Reply	O	0
Take Figure 1 for example: you are likely correct that there is more variation at epoch 1 than at epoch 200, but that variation is largely noise related and not necessarily variation in the specific characteristics that would be more natural.	Reply	O	0
At 200 epochs in this figure, consider that the background (both the ground and the sky) are smooth and arguably more realistic looking than at 1 epoch, yet they still vary from sample to sample.	Reply	O	0
A similar argument can be made for the horse itself, in terms of both colour and somewhat in head shape.	Reply	O	0
In the paper itself we said ‚ÄúWhen inspecting the samples of Figure 4 (b) and (f), we see that even though the information content is higher at network initialisation, the sampled images look like poor renditions of their classes.	Reply	O	0
‚Äù[line_break_token][line_break_token]We understand that this is a rather subjective perspective on some generated samples, but we are trying to provide insight based on what is available in this analysis.	Reply	O	0
Attempting to understand information compression in a ResNet on these images is a challenging task, hence we value your perspective and input here.	Reply	O	0
[line_break_token][line_break_token]Regarding the effect of weight decay.	Reply	O	0
We will have to keep this for future work owing to computational constraints.	Reply	O	0
That said, our stance was when where we adopted a modern, well-known, and widely used architecture and training scheme and analysed it as it stood.	Reply	O	0
There are many changes that could be made - removing batch norm, varying the initialisation scheme, weight decay, optimiser preferences, etc. -	Reply	O	0
but these create a scenario where the number of experiments to run becomes combinatorial.	Reply	O	0
Since each PixelCNN++ model takes two weeks to train on a Titan 1080 GPU, compromises were made.	Reply	O	0

This manuscript describes a deep convolutional neural network for[line_break_token]assigning proteins to subcellular compartments on the basis of[line_break_token]microscopy images.	Review	O	0
[line_break_token][line_break_token]Positive points:[line_break_token][line_break_token]- This is an important, well-studied problem.	Review	O	0
[line_break_token][line_break_token]- The results appear to improve significantly on the state of the art.	Review	O	0
[line_break_token][line_break_token]- The experimental comparison is quite extensive, including[line_break_token]  reimplementations of four, competing state-of-the-art methods, and[line_break_token]  lots of details about how the comparisons were carried out.	Review	O	0
[line_break_token][line_break_token]- The manuscript also includes a human-computer competition, which the[line_break_token]  computer soundly wins.	Review	O	0
[line_break_token][line_break_token]- The manuscript is written very clearly.	Review	O	0
[line_break_token][line_break_token]Concerns:[line_break_token][line_break_token]There is not much here in the way of new machine learning methods.	Review	O	0
[line_break_token]The authors describe a particular neural network architecture[line_break_token]("GapNet-PL") and show empirical evidence that it performs well on a[line_break_token]particular dataset.	Review	O	0
 No claims are made about the generalizability of[line_break_token]the particular model architecture used here to other datasets or other[line_break_token]tasks.	Review	O	0
[line_break_token][line_break_token]A significant concern is one that is common to much of the deep[line_break_token]learning literature these days, namely, that the manuscript fails to[line_break_token]separate model development from model validation.	Review	B-Review	2
We are told only[line_break_token]about the final model that the authors propose here, with no[line_break_token]discussion of how the model was arrived at.	Review	I-Review	2
 The concern here is that,[line_break_token]in all likelihood, the authors had to try various model topologies,[line_break_token]training strategies, etc.,	Review	I-Review	2
before settling on this particular setup.	Review	I-Review	2
[line_break_token]If all of this was done on the same train/validation/test split, then[line_break_token]there is a risk of overfitting.	Review	I-Review	2
[line_break_token][line_break_token]The dataset used here is not new; it was the basis for a competition[line_break_token]carried out previously.	Review	I-Review	3
 It is therefore somewhat strange that the[line_break_token]authors chose to report only the results from their reimplementations[line_break_token]of competing methods.	Review	I-Review	3
 There is a risk that the authors'[line_break_token]reimplementations involve some suboptimal choices, relative to the[line_break_token]methods used by the originators of those methods.	Review	I-Review	3
[line_break_token][line_break_token]Another concern is the potential circularity of the labels.	Review	I-Review	4
 At one[line_break_token]point, we are told that "Most importantly, these labels have not been[line_break_token]derived from the given microscopy images, but from other[line_break_token]biotechnologies such as microarrays or from literature."	Review	I-Review	4
 However,[line_break_token]earlier we are told that the labels come from "a large battery of[line_break_token]biotechnologies and approaches, such as microarrays, confocal[line_break_token]microscopy, knowledge from literature, bioinformatics predictions and[line_break_token]additional experimental evidence, such as western blots, or small[line_break_token]interfering RNA knockdowns."	Review	I-Review	4
 The concern is that, to the extent that[line_break_token]the labels are due to bioinformatics predictions, then we may simply[line_break_token]be learning to re-create some other image processing tool.	Review	I-Review	4
[line_break_token][line_break_token]The manuscript contains a fair amount of biology jargon (western[line_break_token]blots, small interfering RNA knockdowns, antibodies, Hoechst staining,[line_break_token]etc.)	Review	I-Review	5
that will not be understandable to a typical ICLR reader.	Review	I-Review	5
[line_break_token][line_break_token]At the end, I think it would be instructive to show some examples[line_break_token]where the human expert and the network disagreed.	Review	I-Review	6
[line_break_token][line_break_token]Minor:[line_break_token][line_break_token]p. 2: "automatic detection of malaria" -- from images of what?	Review	I-Review	7
[line_break_token][line_break_token]p. 2: Put a semicolon before "however" and a comma after.	Review	I-Review	7
[line_break_token][line_break_token]p. 2: Change "Linear Discriminant" to "linear discriminant."	Review	I-Review	7
Also, remove[line_break_token]the abbreviations (SVM and LDA), since they are never used again in[line_break_token]this manuscript.	Review	I-Review	7
[line_break_token][line_break_token]p. 5: Delete comma in "assumption, that."	Review	I-Review	7
[line_break_token][line_break_token]p. 8: "nearly perfect" -> "nearly perfectly"[line_break_token][line_break_token]The confusion matrices in Figure 5 should not be row normalized --[line_break_token]just report raw counts.	Review	O	0
 Also, it would be better to order the classes[line_break_token]so that confusable ones are nearby in the list.	Review	B-Review	7
[line_break_token]	Review	O	0
We thank the reviewer for his/her positive comments.	Reply	O	0
We have implemented and tested another method (of Liimatainen et al.,	Reply	O	0
2018).	Reply	O	0
Furthermore, we have put efforts in improving the human-computer competition by recruiting two additional experts to perform the task and 25 scholars, i.e. graduate undergraduate students with a life science background that were given special training.	Reply	O	0
We found that the performance of experts ranges from an accuracy of 64% to 72% (average: 67%) and the performance of scholars ranges from an accuracy of to 34% to 66% (average: 51%).	Reply	O	0
[line_break_token][line_break_token]Concerns:[line_break_token][line_break_token]1.)	Reply	O	0
Generalizability of the architecture[line_break_token][line_break_token]We thank the reviewer for pointing out his concern.	Reply	O	0
As communicated to the other reviewers, our architecture provides an alternative to ameliorate the problem of weakly labeled data.	Reply	B-Reply	1
Instead of combining hints (pooling) of different instances at representation or prediction level, our network rather combines hints from low-level filter.	Reply	I-Reply	1
We think that this problem is occurring in a number of different situations, such that researchers in other machine learning fields might find the GapNet-PL technique highly relevant to their problem, as well.	Reply	I-Reply	1
[line_break_token][line_break_token]2.)	Reply	O	0
Model development and re-implementation of competing methods[line_break_token][line_break_token]We aimed at using the original implementations of the architectures and only made changes if the original architecture was impossible to run, which could happen if the original architecture was developed on smaller images.	Reply	O	0
Otherwise, we only changed parameters if they led to an improvement of the validation metrics.	Reply	B-Reply	2
[line_break_token]The reviewer is correct that we only use a single train/val/test split, where all hyper-parameter optimization is done on the validation set in order to prevent overfitting.	Reply	I-Reply	2
We also took care that the amount of searched hyper-parameters is similar for all methods (e.g. we tested two different initial learning rates for all competing methods).	Reply	I-Reply	2
[line_break_token]The GapNet architecture was developed on a different data set with similar characteristics (classification task of high-throughput fluorescence microscopy images) and then adapted to this dataset.	Reply	I-Reply	2
We downsized the model slightly as the original task was more complex and then adjusted its most important hyper-parameters (such as learning rate) on the validation set.	Reply	I-Reply	2
We will make this more explicit in the upcoming version of the paper, thanks for pointing this out.	Reply	I-Reply	2
[line_break_token][line_break_token]3.)	Reply	O	0
Circularity of labels[line_break_token][line_break_token]We thank the reviewer for this important comment that led us to dive deeper into the actual annotation process of those images (Thul et al.,	Reply	O	0
2017).	Reply	B-Reply	4
It turned out that the description of the challenge data set was partly lacking with respect to the annotation process.	Reply	I-Reply	4
We updated the respective information in the dataset section of the paper.	Reply	I-Reply	4
[line_break_token][line_break_token]4.)	Reply	O	0
Biology jargon[line_break_token][line_break_token]We improved the introduction section and removed the biology jargon.	Reply	O	0
Additionally, we now provide examples where humans and network disagree.	Reply	B-Reply	5
[line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]Thanks, we corrected as suggested except for the last one.	Reply	O	0
We decided to keep the normalized confusion matrices to be consistent with Esteva et al. (	Reply	B-Reply	7
2017) and also because the visualization (coloring of the cells) is better.	Reply	I-Reply	7

The authors provide a well engineered solution to exploiting sparsity in convolutional layers of a deep network by recasting it as sparse matrix-vector multiplication.	Review	O	0
This leads to very nice speedups and the analysis of when this is possible is also useful for practitioners.	Review	O	0
My main concern with this paper is that the "research" aspect of it seems rather minimal, and it's mostly about performance engineering and comparisons.	Review	B-Review	1
It is upto the area chairs to decide how well such a paper fits in at ICLR.	Review	I-Review	1
We respectfully ask the reviewer to reconsider the assessment that there is a lack of research contribution in the present paper.	Reply	B-Reply	1
It is well accepted that deep learning is enabled by three similarly crucial components ‚Äì algorithm, data, and performance.	Reply	I-Reply	1
Each component benefited from a succession of original research efforts which are still active at present.	Reply	I-Reply	1
These include the invention of back propagation (past) to new optimization algorithms for training (present), the creation of the ImageNet dataset (past) to the Re‚Äôs ‚Äò‚Äôdata programming‚Äù approach (present), the lowering method that transforms convolution to matrix products (past) to computer architecture for special-purpose hardware accelerator (present).	Reply	I-Reply	1
[line_break_token][line_break_token]The present paper belongs to the performance research area of sparsification.	Reply	I-Reply	1
While sparsification has been effective in memory footprint reduction, it has hitherto limited success in inference throughput enhancement.	Reply	I-Reply	1
The greatly enhanced throughput reported here cannot be achieved solely by our direct sparse convolution technique (which is a new fast algorithm by itself).	Reply	I-Reply	1
Preserving inference accuracy is an implicit requirement for all sparsification endeavor.	Reply	I-Reply	1
Sparsification for performance enhancement therefore cannot be successful without understanding where to ‚Äúuse the sparsification budget‚Äù for most effective performance gain.	Reply	I-Reply	1
And a simplistic ‚Äúengineering‚Äù trial-and-error approach is infeasible for the combinatorial number of choices offered by tens of layers and hundreds of channels.	Reply	I-Reply	1
We successfully identified sparsification targets by combining a high-resolution performance model and a sparsity allocation methodology, both of which contain original research that are applicable to performance research in general	Reply	I-Reply	1

This paper proposes to binarize all parameters of a CNN where the binary parameters are generated from another policy neural network (let's call it parameter generator).	Review	O	0
The parameter generator network has a special nested structure to regularize parameters within layers and filters.	Review	O	0
All parameters in CNN and parameter generator network are jointly trained.	Review	O	0
Since the gradient is hard to back propagated through binary variables, the paper adopts reinforcement learning approach to back-propagate rewards to the parameter generator.	Review	O	0
[line_break_token][line_break_token]The experiments look solid.	Review	O	0
The results show that the proposed approach is slightly worse than BinaryConnect (baseline) on MINST, CIFAR10 and CIFAR100, but outperforms BinaryConnect on ImageNet by a large margin.	Review	O	0
The ablation study also verified the need for the proposed nested parameter structure.	Review	O	0
[line_break_token][line_break_token]The paper is well written.	Review	O	0
The proposed method (1) is able to provide the posterior distribution of parameters so that we can use that in other applications such as confidence estimation and model selection (2) is memory and power efficient due to binarization.	Review	O	0
[line_break_token][line_break_token]Having said that, the experimental setting falls short.	Review	B-Review	1
For the proposed method, the paper samples 100 binary networks from the parameter generator and pick the best one, which seems not correct.	Review	I-Review	1
The results of the proposed method should be based on the average of these 100 binary networks, rather than picking the best one, because we won't be able to know which binary network is the best.	Review	I-Review	1
Using the best one seems label leakage to me.	Review	I-Review	1
For now, I'll give the benefit of doubt.	Review	I-Review	1
Please clarify this during the feedback phase.	Review	I-Review	1
We thank R3 for these encouraging feedbacks on the proposed training scheme and the nested structure.	Reply	B-Reply	1
[line_break_token]We want to clarify our results obtained by our sampled binary networks.	Reply	I-Reply	1
For both baseline and our method, we evaluate the model (just sample one binary model at each epoch) on valid-set at the end of each training epoch and report the best one among the results of last 100 training epochs, so it's a fair comparison.	Reply	I-Reply	1
We admit that the experimental methodology is not very convincing in the manuscript.	Reply	I-Reply	1
We will incorporate a systematic evaluation with mean values and variances, in a future version.	Reply	I-Reply	1

Overall an interesting paper, though I wished a more detailed presentation of the reasoning behind the algorithm would have been provided.	Review	O	0
As it stands it feels a bit heuristic.	Review	O	0
[line_break_token][line_break_token]In particular I don't understand the motivation between the switching mechanism.	Review	B-Review	1
Basically it says if the gradients are co-aligned between epochs it means there is not much to learn anymore!?	Review	I-Review	1
Why?	Review	I-Review	1
Intuitively if the gradients would go to 0 or become very small maybe you would want to increase precision.	Review	I-Review	1
Or if you have high variance you could argue that the expected gradient would be 0 and hence you are not really making progress, i.e. you are just moving left-right.	Review	I-Review	1
But if all gradients agree on a moving direction, why is that a bad thing?	Review	I-Review	1
I know the heuristic is borrowed from a different work, but since it feels as such an integral part of MuPPET I think you should explain it better.	Review	I-Review	1
[line_break_token][line_break_token]I guess a few details about the algorithm as well.	Review	I-Review	2
When you say you look at the diversity of the gradients over the epochs, is this the batch gradient !?	Review	I-Review	2
[line_break_token][line_break_token]There are some small typos (e.g. FP23 instead FP32).	Review	I-Review	3
[line_break_token][line_break_token]I find the justification for AlexNet to be adhoc (it switched at the wrong time, but that allowed to take more advantage of computation in the low precision hence it was faster).	Review	I-Review	4
The switching mechanism should only care of when the gradients are not informative anymore, not how much compute you are wasting .	Review	I-Review	4
hank you for your review.	Reply	O	0
Further details on the motivation behind the switching mechanism has been added to Section 3.3 in the revised version of the paper, particularly at the paragraph beginning ‚ÄúThe likelihood of observing r gradients‚Ä¶‚Äù.	Reply	B-Reply	1
[line_break_token]Additionally we would like to state that when the observed p-value is high, this could be due to either true co-alignment of the gradients, or due to information loss from quantisation the gradients appear to be co-aligned.	Reply	I-Reply	1
We find that it is unlikely to observe multiple minibatches across 3 epochs to have similar gradients.	Reply	I-Reply	1
As a result, seeing this behavior would indicate that information is being lost through quantisation producing the observed low gradient diversity.	Reply	I-Reply	1
[line_break_token][line_break_token]The gradients being used are those obtained from the last minibatch of each epoch.	Reply	I-Reply	2
This has been updated in point 1) of Section 3.3.	Reply	I-Reply	2
[line_break_token][line_break_token]It was not our intention in the original version for it to sound as an adhoc justification of MuPPET for AlexNet, more so just an observation of the experiment that we ran.	Reply	I-Reply	4
However, Section 4.4 has been revised with more thorough and appropriate experiments and analysis in the current version of the paper.	Reply	I-Reply	4

This paper introduces smooth market games (SM-games), a class of smooth games characterized by pairwise zero sum interactions, and show SM-games possess a number of appealing properties:[line_break_token]- A fixed point is a local Nash equilibrium iff it is stable[line_break_token]- Local convergence to stable fixed points[line_break_token]- Unstable fixed points are repellent[line_break_token]- Dynamics are bounded, assuming diminishing returns-to-scale for sufficiently large vectors.	Review	O	0
[line_break_token]The need for a class of games with such properties is motivated by a discussion of the pathologies of smooth games under simultaneous gradient ascent.	Review	O	0
[line_break_token][line_break_token]The paper has an extensive literature review, addresses an important problem, and has informative discussions.	Review	O	0
It is well written and there are nice examples to illustrate the central ideas.	Review	O	0
However, I do have some criticisms:[line_break_token][line_break_token]1.	Review	O	0
The writing in this paper is sometimes pompous.	Review	B-Review	1
Quoting James Scott has no added value to this work.	Review	I-Review	1
Reference to Adam Smith‚Äôs invisible hand not only has no added value but is also confusing and detracts from the paper ‚Äî SM-games are not purporting to be real economic models.	Review	I-Review	1
[line_break_token]2.	Review	O	0
Throughout the paper there is a confusing mix between ideas from economics and ideas from accounting.	Review	B-Review	2
For example, it is not correct to say that aggregate revenue is the same as GDP.	Review	I-Review	2
Revenue is an accounting term to show how much benefit you record in a year.	Review	I-Review	2
GDP measures the value of&nbsp;production.	Review	O	0
It would be more accurate to write that aggregate output and GDP are the same.	Review	B-Review	2
But if SM-games are reflecting the perspective of an accountant, as is stated, why is GDP being discussed at all?	Review	I-Review	2
Similarly, the idea of a dummy player with off the book costs is not consistent with an accounting perspective.	Review	I-Review	2
I think that the paper would be clearest if it did not attempt to use terminology from other fields.	Review	I-Review	2
But if it is going to do so, it should make a more substantial effort to do so consistently.	Review	I-Review	2
e thank the reviewer for their time and feedback.	Reply	O	0
We have two responses:[line_break_token][line_break_token]1.	Reply	O	0
Pompous writing.	Reply	O	0
[line_break_token][line_break_token]We agree with R2 and will tone down the writing -- see the next point.	Reply	B-Reply	1
[line_break_token][line_break_token]On the other hand, it‚Äôs worth defending the James Scott quote.	Reply	I-Reply	1
As we see it, overly focusing on (Nash) equilibria has been a major blocker for research on n-player games.	Reply	I-Reply	1
We find the Scott quote inspiring because it suggests to let go of equilibria and instead search for measurements that can be pieced together to provide a synoptic view (a map) of a game.	Reply	I-Reply	1
That is, we don‚Äôt need to find Nash equilibria to understand what is happening or predict what will happen in an interacting population.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
R2 points out that we used a confusing mix of terminology.	Reply	B-Reply	2
We agree.	Reply	I-Reply	2
In particular, the analogy with GDP adds nothing to the paper.	Reply	I-Reply	2
We will edit the paper to make the terminology more clear and consistent.	Reply	I-Reply	2
[line_break_token][line_break_token]	Reply	O	0

This paper presented a jointly learning framework based on GAN for tackling both knowledge graph completion and noise detection simultaneously.	Review	O	0
Existing works only deal with each of task independently and did not investigate the benefits of coping with both tasks together.	Review	O	0
The paper is well motivated.	Review	O	0
In order to achieve them, the paper presented a GAN framework in order to train a noising KG embedding as well the generator and discriminator.	Review	O	0
The key connections between two parts are through the confidence of a noise triple and generation of the negative sample triples.	Review	O	0
The whole framework looks quite interesting and promising.	Review	O	0
The experimental results are provided to validate the effectiveness of the proposed model.	Review	O	0
[line_break_token][line_break_token]There are two key concerns about this paper:[line_break_token][line_break_token]1) It is well known that both GAN and RL are hard to train, not to mention combining them together to joint train in order to deal with data indifferenceability issue of discrete triple generation.	Review	O	0
Are the results easy to reproduce?	Review	B-Review	1
[line_break_token][line_break_token]2) Choosing 10% triples as positive training examples seems very ad-hoc.	Review	O	0
Have you studied the sensitivity of the number of percentage of triples as positive training examples on the system performance?	Review	B-Review	2
[line_break_token][line_break_token]3) I don't know too much about the methods from knowledge graph noise detection so maybe one baseline - CKRL is enough for representing state-of-the-arts.	Review	O	0
However, for knowledge graph completion task, TransE is most simple baseline and they are rich state-of-the-art methods in this line such as [1]. It is not convincing to show the advantages of the proposed NoiGAN without such comparisons.	Review	B-Review	3
[line_break_token][line_break_token][1]  ‚ÄúRotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space.	Review	O	0
‚Äù ICLR'19.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
e thank the reviewer for the constructive reviews.	Reply	O	0
We addressed the questions and concerns of the reviewer accordingly in the following.	Reply	O	0
[line_break_token][line_break_token]1 Using policy gradient to generate discrete data with GAN is first proposed by [7] and [2] and shows great performance in information retrieval in [2]. Afterward, this strategy has been widely adopted to learn graph representation, e.g., [1] and [3]. Following [1], [2], [3], [7],  we adopt the same strategy in our work.	Reply	O	0
We agree that GAN is unstable and hard to train.	Reply	B-Reply	1
Fortunately, in our work, it doesn‚Äôt cause much trouble.	Reply	I-Reply	1
To show that our model is stable and our results are easy to reproduce, we train NoiGAN-RotatE (soft) with the same parameters for 3 times on FB15K-237 with 70% noise and report the results on test dataset as follows:[line_break_token][line_break_token]MRR  HITS@1  HITS@3  HITS@10[line_break_token]0.279   0.179       0.320       0.475[line_break_token]0.279   0.179       0.319       0.477[line_break_token]0.279   0.179       0.319       0.474[line_break_token][line_break_token]We can observe that the results are almost the same, which shows the stability of our model.	Reply	I-Reply	1
[line_break_token][line_break_token](2) To study the effect of the percentage of triples as positive training examples, we also run NoiGAN-RotatE (soft) with the percentage of triples as positive training examples as 10% 20% 40% on FB15K-237 with 70% noise, the result is as follows:[line_break_token][line_break_token]Percentage of triples  MRR  HITS@1  HITS@3   HITS@10[line_break_token]10%                               0.279   0.179       0.320         0.475[line_break_token]20%                               0.278   0.179       0.318         0.473[line_break_token]40%                               0.279   0.180       0.318         0.475[line_break_token][line_break_token]We can observe that the variation among the results is relatively small.	Reply	O	0
It indicates that our NoiGAN is less sensitive to the percentage of triples as positive training examples.	Reply	B-Reply	2
[line_break_token][line_break_token](3) Thanks to the reviewer for pointing out this issue.	Reply	O	0
We have added more baseline methods, including (1) KGE models (e.g., DistMult [5] and RotatE [4]), (2) robust KGE models (e.g., attention based method [6]) and (3) KGE models with GAN (e.g., KBGAN [3]).	Reply	B-Reply	3
In addition, to show that our NoiGAN can be easily generalized to various KGE models, RotatE is also added as score function for NoiGAN.	Reply	I-Reply	3
Please find the results in Table 3 in our latest version of the paper.	Reply	I-Reply	3
The results show that both NoiGAN-TransE and NoiGAN-RotatE consistently and significantly outperform all the baseline methods in terms of robustness.	Reply	I-Reply	3
[line_break_token][line_break_token][1]  ‚ÄúGraphGAN: Graph Representation Learning with Generative Adversarial Nets.	Reply	O	0
‚Äù AAAI'18.	Reply	O	0
[line_break_token][2]  ‚ÄúIrgan: A minimax game for unifying generative and discriminative information retrieval models.	Reply	O	0
‚Äù SIGIR'17.	Reply	O	0
[line_break_token][3]  ‚ÄúKbgan: Adversarial learning for knowledge graph embeddings.	Reply	O	0
‚Äù NAACL‚Äô18.	Reply	O	0
[line_break_token][4]  ‚ÄúRotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space.	Reply	O	0
‚Äù ICLR'19.	Reply	O	0
[line_break_token][5]  ‚ÄúEmbedding Entities and Relations for Learning and Inference in Knowledge Bases‚Äù  ICLR'15.	Reply	O	0
[line_break_token][6]  ‚ÄúLearning Attention-based Embeddings for Relation Prediction in Knowledge Graphs‚Äù, ACL‚Äô19.	Reply	O	0
[line_break_token][7]  ‚ÄúSeqGAN: Sequence Generative Adversarial Nets with Policy Gradient‚Äù, AAAI‚Äô17.	Reply	O	0

This paper describes a (DC)GAN architecture for modeling folk song melodies (Irish reels).	Review	O	0
[line_break_token]The main idea of this work is to exploit the rigid form of this type of music --- bar structure and repetition --- to enable 2-dimensional convolutional modeling rather than the purely sequential modeling that is commonly used in recent (melodic) music generation architectures.	Review	O	0
[line_break_token]The ideas in this paper seem sound, though they primarily consist of recombining known techniques for a specific application.	Review	O	0
[line_break_token]The main weaknesses of this paper are in the evaluation (see below), and while I understand that evaluating generate models for creative applications is difficult and fraught territory, I don't think the efforts taken here are sufficiently convincing.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]Strengths:[line_break_token][line_break_token]- The paper is clearly written, and the authors have taken great care to describe the unique structures of the data they are modeling.	Review	O	0
[line_break_token]- The proposed architecture seems well motivated, and matches to the structure of the data.	Review	O	0
[line_break_token][line_break_token][line_break_token]Weaknesses:[line_break_token][line_break_token]There are three components to the evaluation, and each of them are problematic:[line_break_token][line_break_token]- The first evaluation (Fig 2) compares the average Frechet distance between phrases generated by different models, and within the original dataset.	Review	O	0
 Some brief argument is given for why Frechet is a good choice here, but it still seems quite tenuous: what does this distance intuitively mean in terms of the data?	Review	O	0
 How should the scale of these distances be interpreted / what's a meaningfully large difference?	Review	O	0
 How concentrated are these average distances (ie, please show error bars, variance estimates, or some notion of spread)?	Review	O	0
[line_break_token][line_break_token]- The second evaluation (Fig 3) uses t-SNE to embed the generated melodies into a 2D space to allow visual inspection of the differences between distributions produced by each model.	Review	O	0
 While this might be a reasonable qualitative gut-check, t-SNE is by no means an appropriate tool for quantitative evaluation.	Review	O	0
 The authors at least did multiple runs of t-SNE, but this hardly amounts to compelling evidence.	Review	O	0
 Moreover, combining all data sources into one sample prior to running t-SNE induces dependencies between the point-wise neighbor selection distributions, which seems undesirable if the eventual goal is to determine how similar each model's distribution is to the source data.	Review	O	0
 A better approach might be to create independent plots for each model's output (with the original data), but I'd generally advise against using t-SNE for this kind of analysis altogether.	Review	O	0
[line_break_token][line_break_token]- The third evaluation (Fig 4) measures the amount of divergence from the key (D) in terms of note unigrams.	Review	O	0
 This evaluation is done qualitatively, and the histogram is difficult to read --- it may be easier to read if the octave content was collapsed out to produce pitch classes rather than pitches.	Review	O	0
 If, however, the goal is to actually measure distance from the target key, one could do this quantitatively by comparing histograms to a probe tone profile (or otherwise constructed unigram note model) to more clearly characterise the behaviors of the various models in question.	Review	O	0
[line_break_token][line_break_token][line_break_token]At a higher level, there is no error analysis provided for the model, nor any ablation study to measure the impact of the various design choices taken here (eg dilation patterns in Figure 1).	Review	O	0
[line_break_token]The authors seem to argue that these choices are the main contribution of this work, so they should be explicitly evaluated in a controlled setting.	Review	O	0
[line_break_token]	Review	O	0
hank you for your feedback.	Reply	O	0
We particularly like the suggestion of comparing the different iterations of the models we tried.	Reply	O	0
[line_break_token][line_break_token]As well, when it comes to the T-SNE metric we used, do you have something specific in mind that you feel would be better than it	Reply	O	0

In this paper, the authors introduce a new Monte Carlo Tree Search-based (MCTS) algorithm for computing approximate solutions to the Traveling Salesman Problem (TSP).	Review	O	0
Yet since the TSP is NP-complete, a learned heuristic is used to guide the search process.	Review	O	0
For this learned heuristic, the authors propose a Graph Neural Network-derived approach, in which an additional term is added to the network definition that explicitly adds the metric distance between neighboring nodes during each iteration.	Review	O	0
They perform favorably compared to other TSP approaches, demonstrating improved performance on relatively small TSP problems and quite well on larger problems out of reach for other deep learning strategies.	Review	O	0
[line_break_token][line_break_token]I believe that the paper is built around some good ideas that tackle an interesting problem; the Traveling Salesman Problem and variants are popular and having learning-based approaches to replace heuristics is important.	Review	O	0
In particular, choosing to use an MCTS to tackle this problem feels like a natural approach, and using a GNN as a learning backend feels like a encourage better performance with fewer training samples.	Review	O	0
However, there are too many questions raised by decisions the authors have made to warrant acceptance in the current state; I would be willing to revise my score if some more detailed analysis of these points were included.	Review	O	0
[line_break_token][line_break_token]First, the heuristic value function: this value function h(s) is defined in the appendix but should be motivated and described (in detail) in the text body.	Review	B-Review	1
As written, this information is not included in the main body of the paper yet is critical for the implementation.	Review	I-Review	1
Also, though it is intuitively clear why a random policy is unlikely to result in a poor result, it is never compared against; how does the performance degrade if the heuristic value function is not used?	Review	I-Review	1
Finally, the parameter 'beam width' used in the evaluation of the value function but is only set to 1 in all experiments.	Review	I-Review	1
Some experiments should be included to show how increasing beam width impacts performance (or the authors should provide a reason these experiments were not run).	Review	I-Review	1
Finally, it seems as if there already exists heuristic methods (against which the paper compares performance); could these be used instead of this value function?	Review	I-Review	1
[line_break_token][line_break_token]Additionally, how is the set of Neighbors defined?	Review	I-Review	2
It is suggested in the text that it is not all nodes, but not using all nodes is a limiting assumption.	Review	I-Review	2
Relatedly, it would be helpful if the authors could better motivate their additional term in Eq. (	Review	I-Review	2
2); at the moment, though using the euclidian distance to weight the edges, it is unclear why this function is a better choice than something else, for instance a Gaussian kernel or a kernel with finite support.	Review	I-Review	2
In addition, the authors motivate that the distance between nodes is very important for the performance of the system, yet the coordinates of each vertex are included as part of the input vector so that (in principle) the network could learn to use this information.	Review	I-Review	2
A comparison against a network implemented using the basic GNN model, defined in Eq. (	Review	I-Review	2
1), should be included to compare performance.	Review	I-Review	2
[line_break_token][line_break_token]In summary, there are a few choices that would need to be better justified for me to really support acceptance.	Review	O	0
However, there are some quite interesting ideas underpinning this paper, and I hope to see it published.	Review	O	0
[line_break_token][line_break_token]Minor comments:[line_break_token]- Overall, I like the structure of the paper.	Review	O	0
At the beginning of all major sections there is an overview of what the remainder of the section will contain.	Review	O	0
This helps readability.	Review	O	0
I also like the comparison between the proposed work and AlphaGo, which popularized using deep learning in combination with MCTS; this enhances the clarity of the paper.	Review	O	0
[line_break_token]- The related work section would be more instructive if it also gave some information about the limitations of the alternative deep learning approaches and how the proposed technique overcomes these.	Review	O	0
My assumption is that all approaches discussed in the second paragraph are "greedy" and suffer from the limitations mentioned in the introduction.	Review	B-Review	3
However, I am not sufficiently familiar with the literature to be certain.	Review	I-Review	3
A sentence or two mentioning this or relating that work to the proposed MCTS approach would be informative.	Review	I-Review	3
[line_break_token]- The last paragraph of the Related Work section, discussing the work of Nowak et al 2017 and Dai et al 2017, introduces some numbers with no context: e.g., "optimality gap of 2.7%".	Review	O	0
It is unclear at this stage if this number is good or bad.	Review	B-Review	4
Some more context and discussion of this work might be helpful for clarity, particularly since the Nowak work seems to be the only other technique using GNN.	Review	I-Review	4
[line_break_token]- Some general proofreading for language should be performed, as there are occasionally typos or missing words throughout the paper.	Review	O	0
Some examples: "compute the prior probability that indicates how likely each vertex [being-&gt;is] in the tour sequence"; "Similar to the [implement-&gt;implementation], in Silver..."; "[Rondom-&gt;Random]" in tables.	Review	O	0
[line_break_token]- In Sec.	Review	O	0
4.1, it is unclear what is meant by "improved probability \hat{P} of selecting the next vertex".	Review	B-Review	6
[line_break_token]- I believe there is an inconsistency in the description of the MCTS strategy.	Review	O	0
Though the action value is set to the 'max' during the Back-Propagation Strategy, the value of Q is initialized to infinity.	Review	B-Review	7
[line_break_token][line_break_token]Suggestions for improvement (no impact on review):[line_break_token]- Clarity: the language in the 3rd and 4th paragraphs of the introduction [begins with "In this paper, ..."] could be made clearer.	Review	I-Review	8
[line_break_token]  - The language "part of the tour sequence" is not quite clear, since, when the process is complete, all points will be in the tour.	Review	I-Review	8
It should be made clearer that the algorithm is referring to a "partial tour" as opposed to the final tour.	Review	I-Review	8
This clarity issue also appears later in Sec.	Review	I-Review	8
4.	Review	I-Review	6
[line_break_token]  - "Similar to above-learned heuristic approaches..." It might be clearer if you began the sentence with "Yet," or "However," so that it is more obvious to the reader that you intend to introduce a solution to this problem.	Review	I-Review	8
[line_break_token]- Equation formatting: Please use '\left(' and '\right)' for putting parenthesis around taller symbols, like \sum.	Review	I-Review	8
[line_break_token]- When describing the MCTS procedure, I have seen the word "rollouts" used much more frequently than "playouts".	Review	I-Review	8
Consider changing this language (though the meaning is clear).	Review	I-Review	8
uestion 8: ‚Äú The related work section would be more instructive if it also gave some information about the limitations of the alternative deep learning approaches and how the proposed technique overcomes these.	Reply	O	0
‚Äù[line_break_token]Answer 8: Thank you for the suggestion.	Reply	O	0
We reorganized the related work.	Reply	B-Reply	3
We agree with you that all the approaches discussed in the second paragraph are "greedy" and suffer from the limitations mentioned in the introduction.	Reply	I-Reply	3
What‚Äôs more, we have made more context and discussion of Nowak et al 2017 and Dai et al 2017 and you will see that in the new version.	Reply	I-Reply	3
[line_break_token] [line_break_token]Question 9: typos[line_break_token]Answer 9: We will correct typos in the new version.	Reply	O	0
[line_break_token] [line_break_token]Question 10: The meaning of the "improved probability \hat{P} of selecting the next vertex".	Reply	O	0
[line_break_token]Answer 10: It should be that ‚Äúbased on the improved probability \hat{P} generated by the GNN-MCTS‚Äù.	Reply	O	0
[line_break_token] [line_break_token]Question 11: The value of Q is initialized to infinity.	Reply	O	0
[line_break_token]Answer 11: We are so sorry for our description to confuse you.	Reply	O	0
The Q value only needs to be initialized to a small value, i.e., - infinity.	Reply	B-Reply	7
In our code, we initialize Q value to -5.0 (TSP20), -10.0 (TSP50) and -15.0 (TSP100).	Reply	I-Reply	7
[line_break_token] [line_break_token]Question 12: Suggestions for improvement[line_break_token]Answer 12: We are so grateful for your suggestions and we will adjust the corresponding part in the new version.	Reply	O	0

This paper proposes a new feature selection method by integrating the knockoff procedure and generative models.	Review	O	0
[line_break_token]The paper is clearly written and easy to read.	Review	O	0
However, I have the following concerns:[line_break_token][line_break_token]- The motivation is not clear.	Review	O	0
The advantage of the knockoff procedure is that it can find relevant features (variables) with statistical guarantees such as FDRs, which is clearly discussed in the paper.	Review	B-Review	2
[line_break_token]    However, the objective of this paper is to design a better feature selection method for prediction, where the statistical guarantee is usually not important.	Review	I-Review	2
[line_break_token]    Hence the advantage of using the knockoff procedure is not clear.	Review	I-Review	2
[line_break_token]- In addition to the above issue, the empirical performance of the proposed method is not convincing.	Review	O	0
[line_break_token]    In experiments, Figure 2 shows that the proposed approach does not have significant advantage compared to existing methods.	Review	B-Review	3
[line_break_token]    It seems that this is a natural consequence as the knockoff procedure is not designed for feature selection.	Review	I-Review	3
[line_break_token]    Thus, in its current state, the advantage of the proposed approach is not well presented.	Review	I-Review	3
[line_break_token]- Also, the proposed approach is not theoretically analyzed.	Review	O	0
[line_break_token]    Since the proposed method is based on the knockoff procedure, it would be interesting if there is some statistical guarantee for the selected features.	Review	B-Review	4
[line_break_token][line_break_token]Minor comments:[line_break_token]- P.5, L.-4: "SInce" -&gt; "Since"[line_break_token]	Review	O	0
hank you for your thoughtful comments and careful reading of the manuscript.	Reply	O	0
We have posted a revision to address some of your questions and provide some responses below (matching the order of the comments).	Reply	O	0
[line_break_token][line_break_token]We agree with the reviewer that the statistical guarantees from the original knockoff variable framework from variable selection does not translate to feature selection, because in machine learning it is seldom the case that the label is independent from a large set of entries of the input vector.	Reply	B-Reply	2
Nonetheless, we believe that there is a contribution in applying the knockoff framework to the long-standing feature selection problem in machine learning.	Reply	I-Reply	2
[line_break_token][line_break_token]We relied on datasets and algorithms that have been used in the feature selection literature for the numerical comparison - see the references by J. Li et al.	Reply	I-Reply	2
It is apparent that some of these datasets provide significant challenges to all tested feature selection methods, and it is not surprising to us that in some cases one cannot perform feature selection without undergoing significant loss in performance.	Reply	I-Reply	2
[line_break_token][line_break_token]The typo has been corrected	Reply	I-Reply	1

This paper proposes a new task/dataset for language-based abductive reasoning in narrative texts.	Review	O	0
[line_break_token][line_break_token]Pros: [line_break_token][line_break_token]-[tab_token]The proposed task is interesting and well motivated.	Review	O	0
The paper contributes a dataset (20,000 commonsense narratives and 200,000 explanatory hypotheses).	Review	O	0
The construction of the dataset was performed carefully (e.g., avoiding annotation artifacts).	Review	O	0
 [line_break_token][line_break_token]-[tab_token]The paper established many reasonable baselines.	Review	O	0
[line_break_token][line_break_token]-[tab_token]The paper conducted detailed analysis, which invites more research on this task: despite the strong performance of many existing systems on NLI/RTE, there are larger gaps between the performance of these models and human performance on the proposed task.	Review	O	0
The experiments well support the conclusions made in the paper.	Review	O	0
[line_break_token][line_break_token]-[tab_token]The paper is well structured and easy to follow.	Review	O	0
It is well written.	Review	O	0
[line_break_token][line_break_token]Cons/comments: [line_break_token][line_break_token]-[tab_token]While this is a new and interesting task, the contribution (as discussed above in ‚Äúpros‚Äù above) is somewhat limited.	Review	O	0
I also suggest the paper discusses e-SNLI a bit more.	Review	B-Review	1
[line_break_token][line_break_token]-[tab_token]The paper has a specific form of formulation for abductive reasoning, where there are exactly two observations and one proceeds the other; the explanation happens in between.	Review	O	0
I can see this helps collect and annotate data, but also limit the form of abductive reasoning and how models should be developed.	Review	B-Review	2
[line_break_token][line_break_token]-[tab_token]Should the title of the paper specify the paper is about ‚Äúlanguage-based‚Äù abductive reasoning.	Review	O	0
[line_break_token][line_break_token]-[tab_token]A minor one: ‚ÄúTable 7 reports results on the Œ±NLI task.	Review	O	0
‚Äù Should it be ‚ÄúTable 2‚Äù?	Review	B-Review	4
[line_break_token]	Review	O	0
e thank AnonReviewer1 for their positive comments about the interesting-ness of our proposed abductive reasoning tasks (inference and generation) and the associated benchmark dataset.	Reply	O	0
We address specific concerns individually below:[line_break_token][line_break_token]Discussion about e-SNLI:[line_break_token]A key distinction between e-SNLI and Abductive-NLI is that the explanations in e-SNLI serve the purpose of justifying model decisions.	Reply	O	0
In contrast, the goal of Abductive-NLI and Abductive-NLG is to select or generate explanatory hypotheses for given observations.	Reply	B-Reply	1
Indeed, analogous to e-SNLI for SNLI, Abductive-NLI can be extended to ‚Äúe-Abductive-NLI‚Äù by providing explanations that justify the selected hypothesis.	Reply	I-Reply	1
[line_break_token]Consider the following example that BERT fails to predict correctly:[line_break_token][line_break_token]O1: Chad loves Barry Bonds.	Reply	I-Reply	1
[line_break_token]    H1: Chad got to meet Barry Bonds online, chatting.	Reply	I-Reply	1
[line_break_token]    H2: Chad waited after a game and met Barry.	Reply	I-Reply	1
[line_break_token]O2: Chad ensured that he took a picture to remember the event.	Reply	I-Reply	1
[line_break_token][line_break_token]The e-Abductive-NLI task would require models to generate an explanation for selecting H2.	Reply	I-Reply	1
For the above example, a possible explanation for selecting H2 could be: ‚ÄúPeople need to be physically co-located to take a picture with someone.	Reply	I-Reply	1
Meeting online does not mean two people are physically co-located‚Äù.	Reply	I-Reply	1
[line_break_token]We think generating such justifications is a great next step and hope that our work will foster such interesting future research.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token][line_break_token]Re.	Reply	O	0
somewhat limited contribution: [line_break_token]We appreciate the opportunity to briefly restate our contributions and to discuss its significance.	Reply	O	0
[line_break_token]Abductive Commonsense Reasoning, a critical capability in human reasoning, is relatively less studied in NLP research.	Reply	B-Reply	1
To support this line of research, our work introduces a dataset that focuses explicitly on this important reasoning capability.	Reply	I-Reply	1
Furthermore, several recent works [1,2,3,4] have shown the presence of annotation artifacts in crowdsourced datasets -- which poses a significant challenge for dataset curation.	Reply	I-Reply	1
Our work makes the following contributions: [line_break_token]i) proposes and formalizes two novel tasks of Abductive Inference and Abductive Generation, [line_break_token]ii) presents a new dataset in support of these tasks collected through careful crowdsourcing design and an adversarial filtering algorithm, [line_break_token]iii) establishes strong baselines on the task proving the difficulty of the tasks and[line_break_token]iv) analyses the types of commonsense reasoning that current state of the art models fall short on.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token][line_break_token]Re.	Reply	O	0
limited form of Abductive Reasoning: [line_break_token]The simplifying assumptions, mentioned in the paper, allow us to i) formulate the tasks concretely and ii) curate the dataset and evaluate models viably.	Reply	O	0
We show that in spite of the assumptions, our dataset presents significant challenges for current models.	Reply	B-Reply	2
We totally agree that in its most general form, there should be any number of observations and models should be required to generate explanatory hypotheses in natural language (as in the alpha-NLG task).	Reply	I-Reply	2
We hope our work will lead to this future line of research.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token][line_break_token]Re.	Reply	O	0
the title: [line_break_token]Thanks for the suggestion.	Reply	O	0
We will update the title to reflect that this work is aimed at language-based abductive reasoning.	Reply	B-Reply	3
[line_break_token][line_break_token][line_break_token][line_break_token]Table 7 vs Table2: [line_break_token]Thanks for catching that.	Reply	O	0
We‚Äôve updated the paper with the fix.	Reply	B-Reply	4
[line_break_token][line_break_token][line_break_token][line_break_token][1] Gururangan et al.	Reply	O	0
Annotation artifacts in natural language inference data.	Reply	O	0
[line_break_token][2] Poliak et al.	Reply	O	0
Hypothesis only baselines in natural language inference.	Reply	O	0
[line_break_token][3] Tsuchiya e. al.	Reply	O	0
Performance impact caused by hidden bias of training data for recognizing textual entailment.	Reply	O	0
[line_break_token][4] Sakaguchi et al.	Reply	O	0
WINOGRANDE: An Adversarial Winograd Schema Challenge at Scal	Reply	O	0

The problem of lossy compression of neural networks is essentially important and relevant.	Review	O	0
The paper proposes an interesting usage of Bloomier filters in lossy compression of neural net weights.	Review	O	0
The Bloomier filter is proposed by others.	Review	O	0
It is a data structure that maps from sparse indices to their corresponding values with chances that returns incorrect values for non-existing indices.	Review	O	0
The paper compares its method with two baseline methods (Magnitude and Dynamic network surgery DNS) to demonstrates its performance.	Review	O	0
[line_break_token][line_break_token]I find the paper fairly interesting but still have some concerns in the technical part and experiments.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
The paper seems the first to introduce Bloomier filter into the network compression problem.	Review	O	0
I think its contribution is novel and original.	Review	O	0
The paper may interest those who work in the network compression domain.	Review	O	0
[line_break_token]2.	Review	O	0
The method works well in the demonstrated experimental cases.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
The technical part is partially clear.	Review	B-Review	1
It might be worthwhile to briefly describe the encoding/construction algorithm used in the paper.	Review	I-Review	1
It is recommended to describe a bit more details about how such encoding/decoding methods are applied in reducing neural net weights.	Review	I-Review	1
[line_break_token]2.	Review	O	0
One drawback of the proposed method is that it has to work with sparse weights.	Review	B-Review	2
That requires the method to be used together with network pruning methods, which seems limiting its applicability.	Review	I-Review	2
I believe the paper can be further improved by including a study of the compression results without a pruning method (e.g., comparing with Huffman in table 3).	Review	I-Review	2
[line_break_token]3.	Review	O	0
What is the reason there is no DNS results reported for VGG-16?	Review	B-Review	3
Is it because the network is deeper?	Review	I-Review	3
[line_break_token]4.	Review	O	0
The experimental part can be improved by reporting the compression results for the whole network instead of a single layer.	Review	B-Review	4
[line_break_token]5.	Review	O	0
It seems the construction of Bloomier filter is costly and the proposed method has to construct Bloomier filters for all layers.	Review	B-Review	5
What is the total time cost in terms of encoding and decoding those networks (LeNet and VGG)?	Review	I-Review	5
It would be nice to have a separate comparison on the time consumption of  different methods.	Review	I-Review	5
[line_break_token]6.	Review	O	0
Figure 4 seems a bit misleading.	Review	B-Review	6
The comparison should be conducted on the same accuracy level instead of the ratio of nonzero weights.	Review	I-Review	6
I recommend producing another new figure of doing such comparison.	Review	I-Review	6
[line_break_token]7.	Review	O	0
The proposed idea seems somewhat related to using low rank factorization of weight matrices for compression.	Review	B-Review	7
It might be worthwhile to compare the two approaches in experiments.	Review	I-Review	7
[line_break_token]8.	Review	O	0
I am specifically interested in discussions about the possibility of encoding the whole network instead of layer-by-layer retraining.	Review	B-Review	8
1.	Reply	O	0
The technical part is partially clear.	Reply	O	0
It might be worthwhile to briefly describe the encoding/construction algorithm used in the paper.	Reply	O	0
It is recommended to describe a bit more details about how such encoding/decoding methods are applied in reducing neural net weights.	Reply	O	0
[line_break_token][line_break_token]We have included a brief description of construction in the appendix.	Reply	B-Reply	1
Also, as now mentioned in the paper, we will release an implementation with the publication of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	2
One drawback of the proposed method is that it has to work with sparse weights.	Reply	O	0
That requires the method to be used together with network pruning methods, which seems limiting its applicability.	Reply	O	0
I believe the paper can be further improved by including a study of the compression results without a pruning method (e.g., comparing with Huffman in table 3).	Reply	O	0
[line_break_token][line_break_token]You are correct that sparsity is necessary.	Reply	B-Reply	2
This is also true for competing encoding techniques (namely Deep Compression).	Reply	I-Reply	2
For the large VGG16 fully connected layer we ran Huffman encoding on un-pruned, clustered weights and got an 12.8x compression factor, which is an order of magnitude less than the reported results.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
What is the reason there is no DNS results reported for VGG-16?	Reply	O	0
Is it because the network is deeper?	Reply	O	0
[line_break_token][line_break_token]No, it was because the weights were not made available and were unclear how to tune the DNS hyperparameters to effectively prune the VGG16 weights.	Reply	B-Reply	3
We would like to include a DNS version of VGG16 as the suspected improvement in sparsity would likely significantly improve our results.	Reply	I-Reply	3
We are actively working on more advanced pruning techniques, different model types, and datasets to demonstrate the benefits of lossy encoding.	Reply	I-Reply	3
We feel this paper presents the core technique and benefits of the proposed method over the state-of-the-art.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
The experimental part can be improved by reporting the compression results for the whole network instead of a single layer.	Reply	O	0
[line_break_token][line_break_token]We focused on the largest layers to get the most benefit.	Reply	B-Reply	4
In the final version we can report the overall compression if the reviewers feel it is beneficial.	Reply	I-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
It seems the construction of Bloomier filter is costly and the proposed method has to construct Bloomier filters for all layers.	Reply	O	0
What is the total time cost in terms of encoding and decoding those networks (LeNet and VGG)?	Reply	O	0
It would be nice to have a separate comparison on the time consumption of  different methods.	Reply	O	0
[line_break_token][line_break_token]Construction times for LeNet300-100, LeNet5, and VGG16 are 6 seconds, 23 seconds, and 517 seconds, respectively.	Reply	B-Reply	5
Decoding takes 11, 12, and 505 seconds for each of the aforementioned models.	Reply	I-Reply	5
We believe that these one-time overheads are negligible considering the significant reductions in model size.	Reply	I-Reply	5
[line_break_token][line_break_token]6.	Reply	O	0
Figure 4 seems a bit misleading.	Reply	O	0
The comparison should be conducted on the same accuracy level instead of the ratio of nonzero weights.	Reply	O	0
I recommend producing another new figure of doing such comparison.	Reply	O	0
[line_break_token][line_break_token]Thank you for the suggestion.	Reply	B-Reply	6
We believe that this suggestion can improve the paper.	Reply	I-Reply	6
As a result, we conducted additional experiments on iso-accuracy comparison between Weightless and Deep Compression in Figure 7 (appendix).	Reply	I-Reply	6
[line_break_token][line_break_token]7.	Reply	O	0
The proposed idea seems somewhat related to using low rank factorization of weight matrices for compression.	Reply	O	0
It might be worthwhile to compare the two approaches in experiments.	Reply	O	0
[line_break_token][line_break_token]We believe the benefits of low rank factorization lie in efficient execution by reducing the number of computations requires.	Reply	B-Reply	7
A byproduct of low rank factorization is compression on the order of 50%.	Reply	I-Reply	7
However, when specifically targeting over the wire compression, this is not competitive with existing techniques.	Reply	I-Reply	7
If you feel that this is an important distinction that must be made, we will happily add it in the related work section.	Reply	I-Reply	7
[line_break_token][line_break_token]8.	Reply	O	0
I am specifically interested in discussions about the possibility of encoding the whole network instead of layer-by-layer retraining.	Reply	O	0
[line_break_token][line_break_token]We can encode the whole network by eliminating the retraining steps.	Reply	B-Reply	8
However, this will come at the expense of either model accuracy (if we use the same t value as with retraining) or overall compression (if we increase t).	Reply	I-Reply	8
For example, without retraining, VGG16 can lose 2% absolute accuracy as shown in  Figure 5 (appendix).	Reply	I-Reply	8
Previously, we tried using an auxiliary data structure to fix false positives (called exception lists), this proved to incur significant storage overheads.	Reply	I-Reply	8
 As a result, we strongly believe that retraining is an integral part of mitigating the effects of false positives	Reply	I-Reply	8

This paper presents ReMixMatch an improved version of MixMatch.	Review	O	0
The main contributions are the distribution alignment and the augmentation anchoring.	Review	O	0
Distribution alignment rescales the predictions based on the difference between the model marginals and the ground truth running average estimation.	Review	O	0
Augmentation anchoring instead of computing the guessed probabilities on unlabelled data as the average probabilities on transformed samples (as in MixMatch), it considers as guessed labels the average probabilities obtained from weak transformations (flip+crop) even when using stronger transformations (Autoaugment like).	Review	O	0
[line_break_token][line_break_token]The paper is well written, has interesting experiments and very impressive results.	Review	O	0
[line_break_token]However, there are some negative points that the authors should clarify:[line_break_token]- The final method is a mixup of many different techniques, thus, not a strong contribution, but many smaller contributions.	Review	O	0
[line_break_token]- As shown in the ablation study, the main contribution on the obtained results seems to be the use of stronger transformations than in MixMatch.	Review	O	0
This is not so interesting, even though results are impressive.	Review	B-Review	2
If this is the case, authors should state it more clearly in the paper that a large proportion of the gap in performance between MixMatch and ReMixMatch is the introduction of stronger transformations (Autoaugment style).	Review	I-Review	2
[line_break_token][line_break_token]Overall the paper is well presented and contributes to further improve the performance on semi-supervised learning.	Review	O	0
I there fore recommend it for acceptance.	Review	O	0
However, I would like to see in the paper a more general overview on the fact that strong transformations can further improve semi-supervised methods and ReMixMatch is a way to leverage those transformations.	Review	B-Review	2
[line_break_token][line_break_token][line_break_token]Additional comments:[line_break_token]- Instead of using the rescaling trick for distribution alignment, what about enforcing the marginal distribution on the annotated data and the marginal distribution of the model to be similar with KL divergence?	Review	O	0
Would it be better or worse than the proposed approach?	Review	B-Review	3
.	Reply	B-Reply	1
The final method is a mixup of many different techniques, thus, not a strong contribution, but many smaller contributions.	Reply	O	0
[line_break_token]A: While ReMixMatch comprises many components (some of which are new), we believe our ablation study justifies the reason why each component exists.	Reply	O	0
If there are additional ablation experiments that you think would be helpful for us to run, please let us know.	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
As shown in the ablation study, the main contribution on the obtained results seems to be the use of stronger transformations than in MixMatch.	Reply	O	0
[line_break_token]A: We actually found that using stronger augmentations in MixMatch resulted in divergence.	Reply	O	0
We mention this in the paper ("Since MixMatch uses a simple flip-and-crop augmentation strategy, we were interested to see if replacing the weak augmentation in MixMatch with AutoAugment would improve performance but found that training would not converge.")	Reply	B-Reply	2
but will emphasize this more in the next draft.	Reply	I-Reply	2
We also found in our ablation study that using only strong augmentation (i.e., replacing weak augmentations with strong augmentations) resulted in very poor performance for ReMixMatch, suggesting that anchoring towards a weaker augmentation is important.	Reply	I-Reply	2
We will update the labels in the ablation table to make this more clear.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
What about enforcing the marginal distribution on the annotated data and the marginal distribution of the model to be similar with KL divergence?	Reply	O	0
[line_break_token]A: We tried this approach in initial experiments and found that it performed poorly.	Reply	O	0
Using the KL loss also introduces a scalar multiplier hyperparameter for this loss term.	Reply	B-Reply	3
We spent some time tuning this hyperparameter and were unable to obtain good results, so we chose to use the proposed version which does not introduce such a hyperparameter.	Reply	I-Reply	3
It may be that further investigation into this form of a loss could be fruitful.	Reply	I-Reply	3

The paper proposes the use of Survival Continuous Ranked Probability score instead of maximum likelihood estimation for personalised probabilistic forecasts of time-to-event data, thus estimating a distribution over future time.	Review	O	0
The authors describe the evaluation their method using (1) proper scoring rule objectives; (2) evaluation of calibration using sharpness as a metric; (3) the survival precision recall curve.	Review	O	0
The authors then apply these techniques to predicting time-to-mortality using an RNN that takes EHR patient records to predict the probability of death at a given time point.	Review	B-Review	1
It‚Äôs not clear how this is related to the Survival CRPS model or how this model is incorporated into the RNN.	Review	I-Review	1
[line_break_token]Overall, this is an important framework for estimating personalised predictions of survival events for patients with interval-censored data.	Review	O	0
The authors present a well thought-out paper with clearly and realistically articulated modelling  assumptions.	Review	O	0
The authors also give an excellent critique of the underlying assumptions of current state-of-the-art survival methods.	Review	O	0
The authors are also to be commended for the mathematical elegance [line_break_token]Although the paper is very well written and extremely well structured, I struggled with the lack of experiments available in the paper.	Review	B-Review	2
[line_break_token]The text embedded in Figure 3 is too small.	Review	I-Review	3
[line_break_token]The results section is somewhat sparse.	Review	I-Review	4
Although the mathematical formulation is well-motivated and structured, it‚Äôs not clear what the contribution of this work is.	Review	I-Review	4
The difference between CRPS-INTVL and MLE-INTVL is incremental and it‚Äôs unclear what the significant benefits are of CRPS vs MLE.	Review	I-Review	5
What would the interpretation of these differences in a real-world setting?	Review	I-Review	5
[line_break_token]	Review	O	0
Dear AnonReviewer1,[line_break_token][line_break_token]Thank you for taking the time to review our work and offer constructive feedback.	Reply	O	0
We hope to address some of your concerns in the following reply.	Reply	O	0
[line_break_token][line_break_token]You mention that it‚Äôs unclear how the RNN taking EHR patient records is related to the Survival CRPS scoring rule.	Reply	B-Reply	1
To clarify, we use the same RNN architecture to compare different loss functions: the right-censored and interval-censored versions of the MLE and CRPS scoring rules.	Reply	I-Reply	1
We believe our primary contribution in this work is not the RNN model architecture (which is similar to the WTTE-RNN paper), but a robust proper scoring rule for the survival prediction setting.	Reply	I-Reply	1
[line_break_token][line_break_token]We hope to clarify that the contribution of our work is a framework for building predictive time-to-event models on real-world EHR datasets.	Reply	I-Reply	4
This includes: the Survival-CRPS as a scoring rule, the RNN model architecture, and the Survival-AUPRC metric for evaluation.	Reply	I-Reply	4
[line_break_token][line_break_token]You mention that the interpretation of differences between CRPS and MLE in the real-world setting is unclear.	Reply	I-Reply	5
We hope to clarify that our set of experiments (both in the main text and Appendix-H) are built on real-world EHR datasets, and it is the presence of heavy censoring in these datasets that motivates Survival-CRPS scoring rule as an alternative to MLE.	Reply	I-Reply	5
We observe that our experimental results show that the MLE-INTVL and CRPS-INTVL scoring rules yield statistically significant differences in the sharpness of predicted distributions, particularly as measured by coefficient of variation and Survival AUPRC (Table 1).	Reply	I-Reply	5
[line_break_token][line_break_token]We hope that you would be kind enough to revisit your evaluation based on our reply.	Reply	O	0
Thank you again for your time spent reviewing and constructive feedback on our work.	Reply	O	0

This paper offers 2 contributions: one confirms that zero-shot learning has some practical use for semantic classification.	Review	O	0
The second one, about zero-shot clustering is much more original, but unfortunately less mature.	Review	O	0
[line_break_token]When using deep learning for sentence or document-level classification, it has been observed that discriminantly tuning the word embedding significantly improved performance.	Review	O	0
[line_break_token]This paper does such discriminant tuning *without* labeled data, by assuming that the classifier has been obtained through zero-shot learning.	Review	O	0
They call the method 'zero-shot clustering', and I find it very neat and original.	Review	O	0
[line_break_token][line_break_token]Unfortunately, this paper seems to have been hastily written .	Review	B-Review	1
Explanations  are thought-provoking but very idiosyncratic, thus very hard to follow.	Review	I-Review	1
Experiments  are limited and poorly explained, especially about zero-shot clustering.	Review	I-Review	1
[line_break_token][line_break_token]Section 5: [line_break_token]Zero-shot learning is introduced in section 5, but I had to get back to the ' Zero-Shot Learning with Semantic Output Codes' paper to understand the idea in its full generality.	Review	O	0
In particular, it would be useful to formalize the 'intuition' behind equation (2), which corresponds to the 'knowledge base'.	Review	B-Review	3
[line_break_token][line_break_token]Section 6:[line_break_token]It  is the most interesting: it proposes an excellent, and to my knowledge, novel idea, that I understood as soon as I saw equation (3).	Review	O	0
However, the 3 paragraphs of explanation that precede are so confusing that I nearly suspected deliberate obfuscation of a good idea.	Review	B-Review	4
The discussion starts by assuming we want to build density  model of the data P(X) like in auto-encoder, and then show this is a bad idea: why bother?	Review	O	0
What is proposed here has nothing to do with density estimation.	Review	O	0
This proxy framework is completely cryptic to me: proxy of what?	Review	O	0
P(C|X)?	Review	O	0
[line_break_token][line_break_token]What has this to do with the choice of the entropy (excellent by the way)?	Review	B-Review	5
[line_break_token]The link seems to be in the sentence:[line_break_token]‚ÄúThe better the proxy function hat{f} the better this measure (H(f(X)) - H( hat{f}(X))^2<= K*(f(X) - hat{f}(X))^2 by Lipschitz continuity).‚Äù[line_break_token]What this sentence tells us is that we should get P(C|X) as close as possible to the true posterior to get its entropy close to the true entropy?	Review	O	0
But we are doing the opposite here: minimizing the estimated entropy, which does not even have to be close to the true entropy.	Review	B-Review	5
[line_break_token][line_break_token]Section 7: experiments[line_break_token]The part about how zero shot clustering improves SVM classification is very frustrating to read: results are so promising, but very few details are shared (table 3).	Review	I-Review	6
[line_break_token]-[tab_token]What are the raw features?	Review	I-Review	6
N-grams?	Review	I-Review	6
[line_break_token]-[tab_token]Why only SVMs are tried on the DNN and ZSC embeddings?	Review	I-Review	6
It would make sense to try DNNs or DCNs.	Review	I-Review	6
[line_break_token]-[tab_token]An interesting further experiment would be if discriminant fine tuning of the embedding further improves performance over ZSC.	Review	I-Review	6
In this case, ZSC training would be comparable to semi-supervised training, with a mixture of labelled and unlabeled examples.	Review	I-Review	6
Thanks for your comments.	Reply	O	0
We've significantly updated the paper to give it more polish and to make the explanations less idiosyncratic (see <a href="https://arxiv.org/submit/914938/view)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/submit/914938/view).</a> We've also added more experiments.	Reply	O	0
One of which shows a performance boost by using the ZSC embeddings in the zero-shot setting.	Reply	O	0
[line_break_token][line_break_token]Detailed answers follow:[line_break_token]1. '	Reply	O	0
I had to get back to the ' Zero-Shot Learning with Semantic Output Codes' paper to understand the idea in its full generality'[line_break_token][line_break_token]The paper now contains an overview of zero-shot learning (Section 3).	Reply	O	0
[line_break_token][line_break_token]2. '	Reply	O	0
In particular, it would be useful to formalize the 'intuition' behind equation (2), which corresponds to the 'knowledge base'. '	Reply	O	0
[line_break_token][line_break_token]We've also added Figure 1 to give an intuition behind Equation 2.	Reply	B-Reply	3
[line_break_token][line_break_token]3. '	Reply	O	0
It is the most interesting: it proposes an excellent, and to my knowledge, novel idea, that I understood as soon as I saw equation (3).	Reply	O	0
However, the 3 paragraphs of explanation that precede are so confusing that I nearly suspected deliberate obfuscation of a good idea.'	Reply	O	0
[line_break_token][line_break_token]We've rewritten this section to make it more streamlined and clear.	Reply	B-Reply	4
In particular, we've added a visualization that illustrates what the method does.	Reply	I-Reply	4
[line_break_token][line_break_token]4. '	Reply	O	0
Experiments '[line_break_token][line_break_token]We have clarified our experimental setup in the paper.	Reply	O	0
The raw features are bag-of-words.	Reply	B-Reply	6
We used SVMs because they better show the difference between the feature extractors.	Reply	I-Reply	6
DNNs could be used also, but we initially wanted to focus on better features extraction.	Reply	I-Reply	6
However, we will experiment with more powerful classifiers	Reply	I-Reply	6

This work introduces a framework for learning implicit models that is robust to mode collapse.	Review	O	0
It consists in learning an explicit model of the implicit model through maximum likelihood while the later is used to teach the explicit model to better match the data distribution.	Review	O	0
The resulting bi-level optimization is carried out with truncated unrolled stochastic gradient descent.	Review	O	0
[line_break_token][line_break_token]# Quality[line_break_token][line_break_token]The method combines an interesting set of ideas.	Review	O	0
It is validated on some reasonable experiments.	Review	O	0
[line_break_token][line_break_token]However after reading the paper, I remain with too many unanswered questions:[line_break_token]- Why should the method avoid mode collapse?	Review	O	0
Experiments clearly show that it indeed is resilient to mode collapse, but I have would have been curious in seeing some more discussion regarding this point.	Review	B-Review	1
What is the exact mechanism that solves the issue?	Review	I-Review	1
[line_break_token]- What is the effect of K?	Review	O	0
Is mode collapse solved only because of the unrolled gradients?	Review	B-Review	2
[line_break_token]- What is the effect of M?	Review	O	0
How does the method behave for M=1, as usually done in GANs?	Review	B-Review	3
[line_break_token]- What if the explicit model has not enough capacity?	Review	O	0
[line_break_token]- The original Unrolled GAN paper presents better results for the ring problem.	Review	O	0
Why are results worse in the experiments?	Review	B-Review	5
[line_break_token][line_break_token]More fundamentally what is the main benefit of this approach with respect to models that can be trained straight with maximum likelihood? (	Review	O	0
e.g., flow-based neural generative models; and as required for the explicit model) Is it only to produce generative models that are fast (because they are implicit)?	Review	O	0
Why not training only the explicit model directly on the data?	Review	O	0
[line_break_token][line_break_token]# Clarity[line_break_token][line_break_token]The paper is in general well-written, although some elements could be removed to actually help with the presentation.	Review	O	0
[line_break_token]- The development around influence functions could be removed, as the method ends up instead making use of truncated unrolled gradients.	Review	O	0
[line_break_token]- The theoretical analysis is straightforward and could be compressed in a single paragraph to motivate the method.	Review	O	0
[line_break_token][line_break_token]# Originality[line_break_token][line_break_token]The method makes use of several ideas that have been floating around and proposed in different papers.	Review	O	0
As far as I know, the combination proposed in this work is original.	Review	O	0
[line_break_token][line_break_token]# Significance[line_break_token][line_break_token]Results show clear resistance to mode collapse, which is an improvement for implicit models.	Review	O	0
However, other types of generative models generally do not suffer from this issue.	Review	O	0
Significance is therefore limited.	Review	O	0
[line_break_token]	Review	O	0
Thanks for your valuable comments and questions.	Reply	O	0
Below, we give a further explanation on the mechanism on why LBT can avoid mode collapse, and provide sensitivity analysis on the hyperparameters of and.	Reply	O	0
The questions are answered following the line order.	Reply	O	0
[line_break_token][line_break_token]Q1: Why should the method avoid mode collapse?	Reply	O	0
Experiments clearly show that it indeed is resilient to mode collapse, but I have would have been curious in seeing some more discussion regarding this point.	Reply	O	0
What is the exact mechanism that solves the issue?	Reply	O	0
[line_break_token]A1: Please refer to our post with title ‚ÄúResponse to a common concern: What‚Äôs the mechanism of LBT that solves mode collapse?‚Äù.	Reply	O	0
[line_break_token][line_break_token]Q2: What is the effect of K?	Reply	O	0
Is mode collapse solved only because of the unrolled gradients?	Reply	O	0
[line_break_token]A2: Theoretically, when, the gradients of generator parameters obtained by the unrolling technique are unbiased regardless of the initial point of the estimator.	Reply	O	0
And if the estimator achieves optima, only one step of unrolling, i.e.,, is enough, according to the analysis in Sec.	Reply	B-Reply	2
3.1.	Reply	I-Reply	2
Generally speaking, a larger provides less biased gradients for w.r.t.	Reply	I-Reply	2
the initial point of the estimator, which on the other hand needs more computational resources.	Reply	I-Reply	2
In our experiments, we find is enough to provide valid gradients to the generator.	Reply	I-Reply	2
We verify this argument with sensitivity analysis for in Appendix A of our revised paper and demonstrate that a larger leads LBT to a better optimum.	Reply	I-Reply	2
[line_break_token]For the second question, as mentioned in our post with title ‚ÄúResponse to a common concern: What‚Äôs the mechanism of LBT that solves mode collapse?‚Äù, it is KL divergence rather than the unrolled gradients that solves mode collapse.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: What is the effect of M?	Reply	O	0
How does the method behave for M=1, as usually done in GANs?	Reply	O	0
[line_break_token]A3: We‚Äôd like to clarify that the roles of the hyperparameter in LBT and GAN are different.	Reply	O	0
In LBT, a larger can better approximate the condition in Eqn. (	Reply	B-Reply	3
6) as analyzed in Sec.	Reply	I-Reply	3
3.1 (See Appendix A of the sensitivity analysis.).	Reply	I-Reply	3
In GAN, balances the training of and, which needs to be carefully tuned [1].[line_break_token][line_break_token]Q4: What if the explicit model has not enough capacity?	Reply	O	0
[line_break_token]A4: Please refer to our post with title ‚ÄúResponse to a common concern: Can an estimator with insufficient capability still help the generator to capture the data distribution?‚Äù.	Reply	O	0
[line_break_token][line_break_token]Q5: The original Unrolled GAN paper presents better results for the ring problem.	Reply	O	0
Why are results worse in the experiments?	Reply	O	0
[line_break_token]A5: We produce the results of the ring problem following Unrolled GAN‚Äôs settings except the true data distribution.	Reply	O	0
We use the ring data where the standard deviation (std) of each component is 0.1 and the radius of the ring is 1; In the original Unrolled GAN‚Äôs setting, the std of each component is 0.02 and the radius of the ring is 2.	Reply	B-Reply	5
Note that the ratio of std to radius in our setting is 10 times larger than in the original Unrolled GAN‚Äôs setting, making the ring problem more difficult.	Reply	I-Reply	5
We choose this setting in order to characterize different performance of "Intra-mode KL divergence" clearly.	Reply	I-Reply	5
In fact, we also tried the original Unrolled GAN‚Äôs setting of the ring problem.	Reply	I-Reply	5
We find similar performance of all methods and did not find mode collapse except the vanilla GAN.	Reply	I-Reply	5
We added the discussion about the different settings for the ring problem in Sec.	Reply	I-Reply	5
5.1.	Reply	I-Reply	5
[line_break_token][line_break_token]Q6: What is the main benefit of this approach with respect to models that can be trained straight with maximum likelihood?	Reply	O	0
[line_break_token]A6: Maximum likelihood estimation is applicable to the models with an explicit likelihood.	Reply	O	0
It has been widely shown that implicit models have many attractive properties compared to explicit models, such as the model flexibility and the ability to generate sharp and realistic images [2] efficiently.	Reply	B-Reply	6
Concretely, implicit models can generate realistic images compared to VAEs, and can generate samples efficiently compared to PixelCNN.	Reply	I-Reply	6
Compared to flow-based methods, implicit models can define a more flexible distribution whereas the generator network in flow-based methods has to be invertible which largely limits the capacity.	Reply	I-Reply	6
[line_break_token]Our method proposes a new framework to train implicit models, and bridges the gap between the success of explicit models and the challenge of learning implicit models.	Reply	I-Reply	6
[line_break_token][line_break_token][1] Berthelot, David, Thomas Schumm, and Luke Metz. "	Reply	O	0
BEGAN: boundary equilibrium generative adversarial networks."	Reply	O	0
arXiv preprint arXiv:1703.10717 (2017).	Reply	O	0
[line_break_token][2] Mohamed, Shakir, and Balaji Lakshminarayanan. "	Reply	O	0
Learning in implicit generative models."	Reply	O	0
arXiv preprint arXiv:1610.03483(2016)	Reply	O	0

If the stated revisions are incorporated into the paper, it will be a substantially stronger version.	Review	O	0
I'm leaning towards accepting the revised version -- all my concerns are addressed by the authors' comments.	Review	O	0
[line_break_token]---[line_break_token]The paper uses a Seq2Seq network to re-rank candidate items in an information retrieval task so as to account for inter-item dependencies in a weakly supervised manner.	Review	O	0
The gain from using such a re-ranker is demonstrated using synthetic experiments as well as a real-world experiment on live traffic to a recommender system.	Review	O	0
[line_break_token][line_break_token]Paragraph below eqn2: for *any* fixed permutation.	Review	O	0
Figure1 and notation indicates that, at each step of decoding, the selected input x_j is fed to the decoder.	Review	O	0
The text suggests the embedding of the input e_j is fed to the decoder (which is consistent with "go" being a d-dimensional vector, rather than the dimensionality of x).	Review	B-Review	1
[line_break_token][line_break_token]Single step decoder with linear cost: Is there a missing footnote?	Review	I-Review	2
If not, why call it p^1?	Review	I-Review	2
Simpler notation to just call it p.[line_break_token]Eqn7: Role of baseline.	Review	O	0
In REINFORCE, b(x) is typically action-independent (e.g. approximating the state value function induced by the current policy).	Review	B-Review	3
L_pi(theta) is action dependent (depends on the permutation sampled from P_theta).	Review	I-Review	3
So, I'm unclear about the correctness of Eqn7 (does it yield an unbiased policy gradient?)	Review	I-Review	3
[line_break_token][line_break_token]Eqn5: Expected some discussion about the mismatch between training loss (per-step cross entropy) vs. testing loss (e.g. NDCG@k).	Review	I-Review	4
Does a suitable choice of w_j allow us to recover standard listwise metrics (that capture interactions, e.g. ERR)?	Review	I-Review	4
[line_break_token][line_break_token]Expt implementation: Why was REINFORCE optimizing NDCG@10 not regularized?	Review	I-Review	5
[line_break_token]Expt cascade click model: Expected an even simpler experiment to begin with; [Is the Seq2Slate model expressive enough to capture listwise metrics?]	Review	I-Review	5
Since the relevances are available, we can check if Seq2Slate trained to the relevance labels yields NDCG performance comparable to LambdaMART, and whether it can optimize metrics like ERR.	Review	I-Review	5
[line_break_token][line_break_token]Table1: On the test set, is NDCG&MAP being computed w.r.t the ground truth relevances?	Review	O	0
So, is the claim that Seq2Slate is more robust when clicks are noisy in a one-sided way (i.e. relevant items may not receive clicks)?	Review	B-Review	6
Not clear how much of this benefit comes from a more expressive model to predict relevances (see suggested expt above) vs. Seq2Slate from clicks.	Review	I-Review	6
NDCG & MAP definitely don't account for inter-item dependencies, so unclear what is being tested in this experiment.	Review	O	0
[line_break_token][line_break_token]For diverse-clicks, eta=0 while for similar-clicks, eta>0 (in a dataset dependent way).	Review	O	0
Why?	Review	B-Review	7
Can expt numbers for the 3 choices of eta be added to the appendix? [	Review	I-Review	7
Seems like cherry-picking otherwise][line_break_token][line_break_token]Can Ai et al, 2018 be benchmarked on the current expt setup?	Review	O	0
Is it identical to the single-step decoder proposed in the paper?	Review	B-Review	8
[line_break_token][line_break_token]Comment: Would be more accurate to call seq2slate a re-ranker throughout the text (in the abstract and intro, the claim is seq2slate is a ranker).	Review	O	0
[line_break_token][line_break_token]Expected to see training time and inference time numbers.	Review	B-Review	10
Since Seq2Slate does extra computation on top of, e.g. LambdaMART, it is useful to know how scalable it can be during training, and when the extra perf is worth the O(n^2) or O(n) [for single-step decoding] during inference.	Review	I-Review	10
[line_break_token][line_break_token]General comments:[line_break_token]Clarity: The paper is well written and easy to follow.	Review	O	0
There are a few notation choices that can be improved/clarified.	Review	O	0
[line_break_token]Originality: This work seems closely related to Ai et al, SIGIR 2018.	Review	O	0
Going from a single-shot decoding to sequential decoding is an incremental step; the real-world experiment seemed the most novel and compelling contribution (however, it is unclear how one can reproduce it).	Review	O	0
[line_break_token]Significance: The paper addresses a significant real-world problem.	Review	O	0
Many high-impact applications of ranking rely on being able to model inter-dependencies well.	Review	O	0
[line_break_token]Quality: The paper has interesting contributions, but can be substantially stronger (see some of the specific comments above).	Review	O	0
For instance, A careful study of the computational vs. performance trade-off, fine-grained comparison of different decoding architectures, better understanding of which architectural choices allow us to model any arbitrary ranking metric more effectively vs. which ones are more robust to click noise vs. which ones capture inter-item dependencies.	Review	O	0
[line_break_token]	Review	O	0
Thanks for the valuable feedback.	Reply	O	0
We address specific points here and more general points in the common response.	Reply	O	0
[line_break_token][line_break_token]## is x_j or e_j fed to the decoder?	Reply	O	0
[line_break_token]===[line_break_token]x_j is fed to the decoder.	Reply	O	0
There is a typo in the draft: ‚Äúgo‚Äù is actually an m-dimensional vector.	Reply	B-Reply	1
Thanks for pointing this out, we will fix this.	Reply	I-Reply	1
[line_break_token][line_break_token]## why call it p^1?	Reply	O	0
Simpler notation to just call it p. Is there a missing footnote?	Reply	O	0
[line_break_token]===[line_break_token]We use the notation defined in Eq 2 to refer to the vector of probabilities p^1_i for all items i as p^1.	Reply	O	0
We denote by p the nXn matrix of probabilities for all positions and all items. (	Reply	B-Reply	2
There is no missing footnote, the superscript is intended.)	Reply	I-Reply	2
We‚Äôll verify that the notation is explained clearly and make adjustments as needed.	Reply	I-Reply	2
[line_break_token][line_break_token]## In REINFORCE, b(x) is typically action-independent‚Ä¶ L_pi(theta) is action dependent‚Ä¶ So, I'm unclear about the correctness of Eqn7 (does it yield an unbiased policy gradient?)	Reply	O	0
[line_break_token]===[line_break_token]Notice that in Eq 7 while L depends on \theta, the baseline b depends only on x_k.	Reply	O	0
Here L takes the role of the reward in REINFORCE which is action-dependent.	Reply	B-Reply	3
So this is indeed an unbiased variance reduction.	Reply	I-Reply	3
See also reply to Reviewer 3.	Reply	I-Reply	3
[line_break_token][line_break_token]## Expected some discussion about the mismatch between training loss vs. testing loss‚Ä¶[line_break_token]===[line_break_token]Indeed, the sequence loss in Eq 5 is not exactly the same as the ranking measures used in evaluation.	Reply	O	0
However, notice that any permutation that places the positive labels at the first positions gets 0 loss in all these cases, so in that sense the losses are aligned.	Reply	B-Reply	4
There is no choice of weights w_j that achieves full correspondence.	Reply	I-Reply	4
This is quite common for surrogate losses in machine learning.	Reply	I-Reply	4
We will elaborate and clarify in the revision.	Reply	I-Reply	4
[line_break_token][line_break_token]## Why was REINFORCE optimizing NDCG@10 not regularized?	Reply	O	0
[line_break_token]===[line_break_token]We observed that reinforce training was not prone to overfitting, which is generally expected since the policy gradients are noisy.	Reply	O	0
[line_break_token][line_break_token]## Expected an even simpler experiment to begin with; [Is the Seq2Slate model expressive enough to capture listwise metrics?]	Reply	O	0
[line_break_token]===[line_break_token]The original benchmark data only include per-item relevance scores, without high-order interactions (unfortunately, publicly available data sets with high-order interactions do not seem to exist).	Reply	O	0
In this case, the joint probability in Eq 1 is just p(\pi|x) = \prod_j p(\pi_j|x), and a pointwise ranker is optimal, so there would be no need for seq2slate.	Reply	B-Reply	5
We take learning from click-through logs and modeling high-order interactions to be central to our approach, which in some sense makes this particular experiment less relevant/interesting as a means for evaluating seq2slate.	Reply	I-Reply	5
[line_break_token][line_break_token]## Table1: On the test set, is NDCG&MAP being computed w.r.t the ground truth relevances? ...	Reply	O	0
Not clear how much of this benefit comes from a more expressive model ... NDCG & MAP definitely don't account for inter-item dependencies, so unclear what is being tested in this experiment.	Reply	O	0
[line_break_token]===[line_break_token]All reported test measures are w.r.t.	Reply	O	0
generated click data and not relevance scores.	Reply	B-Reply	6
In terms of model expressivity, we note that some of the baselines (pointwise rankers) use deep neural nets with comparable complexity to seq2slate (in terms of number of layers and parameters), so we attribute the gains to better modeling.	Reply	I-Reply	6
[line_break_token]We disagree with the claim that ‚ÄúNDCG & MAP definitely don't account for inter-item dependencies‚Äù.	Reply	O	0
As a counterexample, consider our ‚Äúdiverse-clicks‚Äù setting, where clicks happen on items that are different from each other.	Reply	B-Reply	6
Placing diverse items at the top positions will result in better NDCG and MAP compared to placing items that are similar to each other in those positions.	Reply	I-Reply	6
We will make a note of this in the revision.	Reply	I-Reply	6
[line_break_token][line_break_token]## For diverse-clicks, eta=0 while for similar-clicks, eta>0 (in a dataset dependent way).	Reply	O	0
Why? ... [	Reply	O	0
Seems like cherry-picking otherwise][line_break_token]===[line_break_token]In diverse-clicks we noticed that if we used \eta>0 there were too many examples with all-zero labels (no clicks), which hindered training (since we cannot learn a good ranking from these examples).	Reply	O	0
We then chose different values of \eta for each dataset such that the percentage of examples with no positive labels (clicks) remained small enough and roughly the same in all datasets:[line_break_token]                           Yahoo                Web30K[line_break_token]Diverse-clicks  1.15%(eta=0)    1.10%(eta=0)[line_break_token]Similar-clicks  1.23%(eta=0.1)  1.14%(eta=0.3)[line_break_token]That was the only criterion used to choose the value of \eta.	Reply	B-Reply	7
We will clarify this in the revision	Reply	I-Reply	7

This paper proposed a new self-supervised learning methods by utilizing contrastive predictive coding technique.	Review	O	0
 The proposed algorithm is more effective than existing self-supervised learning algorithm.	Review	O	0
 The presented results are encouraging.	Review	O	0
 [line_break_token]1.	Review	O	0
In section 3.2,  the authors show that  a large number of views would improve the representation quality.	Review	B-Review	1
However,  multi-views may provide redundancy information.	Review	I-Review	1
What is the core information that affect  the representation quality?	Review	I-Review	1
[line_break_token][line_break_token]In fact,  I am not an expert on self-supervised learning and  contrastive predictive coding,  so my reviewer confidence is low.	Review	I-Review	1
Dear Reviewer 2,[line_break_token][line_break_token]Thank you very much for your review.	Reply	O	0
We would like to explain more about our intuition here.	Reply	O	0
[line_break_token][line_break_token]‚ÄúHowever,  multi-views may provide redundancy information.	Reply	O	0
What is the core information that affect  the representation quality?‚Äù[line_break_token][line_break_token]Our hypothesis is that each view has two parts of information: (a) nuisance factors, like sensor noise, that can not be predictive of other views, and (b) information shared with other views.	Reply	O	0
Our learning objective (see Eq.2 and Eq.6) asks the learned latent representation to focus on part (b) such that mutual information between views gets maximized.	Reply	B-Reply	1
[line_break_token][line_break_token]Moreover, for each view, the information bits in part (b) are not equal.	Reply	I-Reply	1
Some information bits, such as the information of object category (e.g., dog), are shared by many views, while some are shared by only a few.	Reply	I-Reply	1
Therefore, if we contrast one single view with many other views, each bit of part (b) will be ordered by the number of times it is shared with those contrasted views.	Reply	I-Reply	1
Our conjecture is that the category-level semantics tend to be shared across many views, and thus are prioritized by our method.	Reply	I-Reply	1
As a result, the learned representations convey sufficient semantic information.	Reply	I-Reply	1
[line_break_token][line_break_token]Therefore, we are leveraging the redundant information between different views/modalities to educate  or teach each other.	Reply	I-Reply	1
This mechanism actually has been explored in the field of developmental psychology.	Reply	I-Reply	1
One such reference is [a], which argues that human infants utilize the redundancy between the senses in order to build up representations that are mutually predictive of each other.	Reply	I-Reply	1
Indeed, if there is no redundant information across views, we cannot learn a good representation in such a way.	Reply	I-Reply	1
[line_break_token][line_break_token][a] Linda Smith.	Reply	O	0
The Development of Embodied Cognition: Six Lessons from Babies.	Reply	O	0
2005.	Reply	O	0
[line_break_token][line_break_token]Please don‚Äôt hesitate to let us know for any further feedback.	Reply	O	0
Thanks!	Reply	O	0

This paper presents a variation of dropout, where the proposed method drops with higher probability those neurons which contribute more to decision making at training time.	Review	O	0
This idea is evaluated on several standard datasets for image classification and action recognition.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
This paper has interesting idea related to dropout, and shows some benefit.	Review	O	0
[line_break_token]2.	Review	O	0
Paper is well-written and easy to understand.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
There are many variations in dropouts and they all claim superiority to others.	Review	B-Review	1
Unfortunately, most of them are not justified properly.	Review	I-Review	1
Excitation dropout looks interesting and has potential, but its validation is not strong enough.	Review	I-Review	1
Use of Cifar10/100, Caltech256, and UCF 101 may be okay for concept proofing, but not be sufficient for thorough validation.	Review	I-Review	1
Also, the reported results are far from the state-of-the-art performance of each dataset.	Review	I-Review	1
I would recommended to add the idea to the network [line_break_token] to achieve the state-of-the-art performance because it will show real extra benefit of "excitation" dropout.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
There are many variations of dropouts including variational dropout, L0-regularization, and adaptive dropout, and the paper needs to report their accuracy in addition to curriculum dropout.	Review	B-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Dropout does not exist in many modern deep neural networks and its usability is a bit weak.	Review	B-Review	3
It would be better to generalize this idea and make it applicable to ResNet-style networks.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
There is no clear (theoretical) justification and intuition why excitation dropout improves performance.	Review	B-Review	4
More ablation study with internal analysis would be helpful.	Review	I-Review	4
[line_break_token][line_break_token]Overall, this paper has interesting idea but needs more efforts to make the idea convincing.	Review	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Adaptive Dropout (NIPS‚Äô13) reported results on MNIST and NORB, Information Dropout (TPAMI‚Äô18) and Variational Dropout (NIPS‚Äô15) reported results on MNIST and Cifar10, Curriculum Dropout (ICCV‚Äô17) reported results on MNIST, Cifar10/100, and Caltech101/256.	Reply	B-Reply	1
In this work, we present results on the small scale dataset Caltech256 having ~18K images (but 256 classes), the medium scale datasets Cifar10/100 having ~60K images (10/100 classes), and on the larger scale UCF101 dataset which has ~13K videos (101 classes), from which we sample 2M frames.	Reply	I-Reply	1
[line_break_token][line_break_token]Dropout is adopted in WideResNet which is used to obtain state-of-the-art results on Cifar10.	Reply	I-Reply	1
We gladly provide Excitation Dropout performance results for WideResNet (WRN-28-10) on Cifar10: 3.88% test error (vs. 4.17% Zagoruyko et al.	Reply	I-Reply	1
‚Äôs published result, BMVC‚Äô16).	Reply	I-Reply	1
Therefore, Excitation Dropout gives state-of-the-art result on Cifar10.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Comparison against Adaptive Dropout was included in the Appendix (section titled: Least vs. most relevant neurons) of our original submission, and we referred to it in the middle of page 4 of our original manuscript.	Reply	B-Reply	2
In that section we discuss how Adaptive Dropout and Excitation Dropout use opposite strategies of neuron selection: Adaptive Dropout drops with a higher probability the least active neurons, while Excitation Dropout drops with higher probability the most relevant neurons.	Reply	I-Reply	2
We note that Adaptive Dropout was originally introduced for an autoencoder architecture.	Reply	I-Reply	2
[line_break_token][line_break_token]Variational Dropout (NIPS‚Äô15) reports results on MNIST and Cifar10 only.	Reply	I-Reply	2
The best result reported by Variational Dropout on Cifar10 has error ~23%, while Excitation Dropout with a CNN-2 architecture has error ~18% and with a WideResNet architecture has ~4% error.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	1
Dropout is one of the most important regularization techniques for deep learning and it is also adopted in WideResNet.	Reply	I-Reply	3
ResNet and DenseNet architectures do not have dropout layers, and rely on batch normalization for regularization.	Reply	I-Reply	3
Effectiveness of regularization methods for training neural networks is dependent on the architecture and training process, and is still an open problem (e.g., batch normalization cannot handle small batches).	Reply	I-Reply	3
[line_break_token][line_break_token]Moreover, please note how the following dropout papers deal with computationally heavy experiments.	Reply	I-Reply	3
Curriculum Dropout (ICCV‚Äô17) uses  two variants of somewhat shallow networks, LeNet and the deeper version CNN-2 we also use.	Reply	I-Reply	3
Variational Dropout (NIPS‚Äô15) and Dropout (JMLR‚Äô14) use an architecture with 3 hidden layers.	Reply	I-Reply	3
Adaptive Dropout (NIPS‚Äô13) uses a one-hidden-layer autoencoder.	Reply	I-Reply	3
We present experiments on the medium-scale network CNN-2 for datasets trained from scratch, and on the deeper AlexNet, VGG16, and VGG19  for the larger dataset UCF101 where fine-tuning is sufficient.	Reply	I-Reply	3
We also gladly provide results for Cifar10 on WideResNet and for Caltech256 on the deeper AlexNet, VGG16, and VGG19 in the Appendix (section titled: Validation on Multiple Architectures).	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	1
Dropout is a model averaging technique.	Reply	I-Reply	4
Averaging models having less specialized neurons results in higher robustness to information loss.	Reply	I-Reply	4
In Table 2 we demonstrate that Excitation Dropout has less specialized neurons (lower saliency peaks and higher entropy), as compared to Standard and Curriculum Dropout for all datasets considered (Cifar10/100, Caltech256 and UCF101).	Reply	I-Reply	4
In addition, Table 2 presents an internal analysis of the network filters demonstrating that a lower number of stale/conservative filters for Excitation Dropout (as compared to Standard and Curriculum Dropout) is achieved.	Reply	I-Reply	4
These considerations are now better highlighted in the last paragraph of Section 4.3.	Reply	I-Reply	4

Summary: The submission performs empirical analysis on f-VIM (Ke, 2019), a method for imitation learning by f-divergence minimization.	Review	O	0
The paper especially focues on a state-only formulation akin to GAILfO (Torabi et al.,	Review	O	0
2018b).	Review	O	0
The main contributions are:[line_break_token]1) The paper identifies numerical proplems with the output activations of f-VIM and suggest a scheme to choose them such that the resulting rewards are bounded.	Review	O	0
[line_break_token]2) A regularizer that was proposed by Mescheder et al. (	Review	O	0
2018) for GANs is tested in the adversarial imitation learning setting.	Review	O	0
[line_break_token]3) In order to handle state-only demonstrations, the technique of GAILfO is applied to f-VIM (then denoted f-VIMO) which inputs state-nextStates instead of state-actions to the discriminator.	Review	O	0
[line_break_token][line_break_token]Contribution / Significance:[line_break_token]I think that the contributions of the paper are rather marginal.	Review	O	0
I do think that the choice of output activation may have large impact on the performance and it seems that the activation suggested by Ke et al. (	Review	O	0
2019) are somewhat arbitrary.	Review	O	0
However, the activations proposed in the current submission are also seem somewhat arbitrary and are not accompanied by any theoretical analysis.	Review	B-Review	2
[line_break_token]2) and 3) are marginal combinations of existing work that are only insufficiently evaluated and do not seem particular effective.	Review	I-Review	3
[line_break_token]Hence, I think that the current submission is of rather limited interest.	Review	I-Review	3
[line_break_token][line_break_token]Soundness:[line_break_token]The "reparametrization" of f-VIM is motivated based on exploding policy gradients when using unbounded reward functions, especially when minimizing the (R)KL.	Review	O	0
[line_break_token]I am not convinced by this motivation, given that GAIL and AIRL (which approximatly minimizes the RKL) use unbounded reward functions and do not seem to suffer from such problems.	Review	B-Review	4
[line_break_token][line_break_token]Evaluation:[line_break_token]The effect of the "reparametrization" is only evaluated for total variation.	Review	O	0
The regularization loss is only evaluated with a single fixed coefficient of 10 on all experiment.	Review	B-Review	5
I think that a sweep over the coefficient would be mandatory, especially given that current experiments do not show a clear benefit of the regularization loss (the regularized version performs worse on roughly half of the experiments).	Review	I-Review	5
[line_break_token]When learning from observations only, the submission only evaluates the proposed combination of f-VIM and GAILfO. However, it seems like it would be perfectly possible to handle state-only observations by simply making the discriminator independent of the actions, i.e. using D(s,a) = D(s).	Review	I-Review	6
Such technique matches the marginal distributions over states and is commonly applied to GAIL, e.g. by Peng et al. [	Review	I-Review	6
1].[line_break_token]It is not clear whether the reported problems of learning from observations only is really a general problem of the learning setting (as claimed in the submission) or a problem of the proposed method.	Review	O	0
[line_break_token][line_break_token]Clarity:[line_break_token]The paper is well written and easy to follow.	Review	O	0
Using different linestyles to distinguish the learning with regularization versus without regularization would help a lot.	Review	O	0
[line_break_token][line_break_token]Decision:[line_break_token]Due to the marginal contribution and the insufficient evaluation I have to recommend rejection.	Review	O	0
[line_break_token][line_break_token][line_break_token]Question:[line_break_token]I am maily interested in the authors response to my critique, especially regarding[line_break_token]- the choice not to compare with state-only f-VIM, and[line_break_token]- the motivation of the proposed output activations.	Review	O	0
[line_break_token][line_break_token][line_break_token][1] Peng, Xue Bin, et al. "	Review	O	0
Variational discriminator bottleneck: Improving imitation learning, inverse rl, and gans by constraining information flow."	Review	O	0
arXiv preprint arXiv:1810.00821 (2018).	Review	O	0
Äú...the contributions of the paper are rather marginal‚Äù ‚Äî please see the comment made to all reviewers.	Reply	O	0
[line_break_token][line_break_token]‚Äú...the activations proposed in the current submission are also seem somewhat arbitrary and are not accompanied by any theoretical analysis.	Reply	O	0
‚Äù ‚Äî We invite the reviewer to offer concrete suggestions on how to perform the suggested ‚Äútheoretical analysis‚Äù of variational function activation choices when estimating f-divergences.	Reply	O	0
It would no doubt serve as a useful tool for justifying the ‚Äúsomewhat arbitrary‚Äù choices of activation functions offered in the original f-GAN paper (Nowozin et al.	Reply	B-Reply	2
2016) that are widely used in practice.	Reply	I-Reply	2
In the meantime, we assert that the choice of sigmoid activation in this work is no more arbitrary than the variety of reward hacks employed in practice throughout deep reinforcement learning to enforce stability (Henderson et al.	Reply	I-Reply	2
2018).	Reply	I-Reply	2
Analogous to the arbitrary f-GAN activation choices, these heuristic selections are used because of their widespread success in rectifying practical implementation issues; in f-GANs, this is ensuring conformity to the domain of the convex conjugate.	Reply	I-Reply	2
The reason why all of our figures lack plots for these f-GAN activation choices stems directly from the resulting numerical instabilities caused by exploding policy gradients.	Reply	I-Reply	2
Consequently, both our choice and those made throughout the literature were done with the goal of maintaining stability during policy gradient updates where policy returns directly scale the gradient.	Reply	I-Reply	2
Note that this is typically not a concern in the traditional GAN literature that employs standard end-to-end backpropagation for training both the generator and discriminator models.	Reply	I-Reply	2
Our lack of theoretical analysis for reward function choice mirrors the overall lack of a theoretical understanding for reward hacks in general throughout deep reinforcement learning.	Reply	I-Reply	2
[line_break_token][line_break_token]‚Äú2) and 3) are marginal combinations of existing work that are only insufficiently evaluated and do not seem particular effective.	Reply	O	0
‚Äù ‚Äî we ask the reviewer to be precise and specify exactly which aspects of the evaluation are insufficient.	Reply	O	0
As for the effectiveness of our proposed methods, we point to our Figure 4 as but a single example to note that the plots associated with traditional GAIL (top row, blue) do not strictly represent the best performance results across all environments, indicating the effectiveness of 2) and 3).	Reply	B-Reply	3
[line_break_token][line_break_token]‚ÄúI am not convinced by this motivation, given that GAIL and AIRL (which approximatly minimizes the RKL) use unbounded reward functions and do not seem to suffer from such problems.	Reply	O	0
‚Äù ‚Äî the reviewer is correct that GAIL and AIRL do not seem to suffer from this problem; thus, a logical conclusion of the reviewer‚Äôs observation is that not all unbounded reward functions yield exploding policy gradients.	Reply	O	0
When exploding policy gradients do occur, however, we believe the reviewer may agree that having a reparameterization to alleviate the issue would be useful.	Reply	B-Reply	4
If the reviewer could provide a concrete pointer to the connection between AIRL and RKL, that would be much appreciated as we could not find such a connection in the original paper.	Reply	I-Reply	4
Still, our experiments left us unable to run (R)KL experiments to completion on account of exploding policy gradients; in all experiments, the use of (R)KL-VIM(O) is always done with sigmoid rewards to rectify the instability.	Reply	I-Reply	4
Note that a naive, brute-force solution to this problem does exist in the form of grid searching over all possible thresholds for gradient norm clipping of the policy in order to find one that is as large as possible without succumbing to numerical errors; solving this kind of ‚ÄúGoldilocks‚Äù problem would be to accept the problem rather than address it.	Reply	I-Reply	4
Moreover, the computational resources needed for such a search across multiple choices of f-divergence is quite intensive and our reparameterization offers a stable optimization solution without relying on such computational inefficiency, which does constitute an important contribution.	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúThe effect of the "reparametrization" is only evaluated for total variation‚Äù ‚Äî as mentioned in the paper, both KL and RKL lead to numerical instabilities that brought all random trials to a complete halt.	Reply	O	0
Since GAIL and GAIFO are already performant imitation learning algorithms on their own (and we wish to maintain fidelity to the original algorithms as baselines),  we did not examine the effect of reparameterizing with sigmoid rewards on either one.	Reply	B-Reply	5
 [line_break_token]	Reply	I-Reply	1

Summary[line_break_token]The authors study robustness of neural networks for image recognition tasks with respect to geometric transformations in input space.	Review	O	0
The question is posed in an adversarial setting, where the authors exploit that Conv/ResNets are not fully translation and rotation invariant.	Review	O	0
The authors propose three untargeted attacks to increase the classification error of the network: a first-order method, an attack involving random transformations and a grid search of allowed transformations.	Review	O	0
For the random and grid search the worst prediction is considered the outcome of the attack.	Review	O	0
The authors observe that first-order attacks are not very successful in fooling the network compared to the grid search.	Review	O	0
Data augmentation as a counter measure is found to be not sufficient and adversarial (robust) training with respect to the random search attack is proposed in addition.	Review	O	0
[line_break_token][line_break_token]Evaluation[line_break_token]The paper is well written and particularly the empirical part is interesting.	Review	O	0
However, novelty is limited, the best approach boils down to a grid search that tests multiple hypotheses instead of a single one.	Review	O	0
There are some conceptual problems and important aspects like confidences of the classification are not addressed.	Review	O	0
[line_break_token][line_break_token]Novelty:[line_break_token]Many claims and observations appear trivial and well-known.	Review	O	0
E.g.,[line_break_token]- the research question has already been addressed by related work, leaving the proposed attacks trivial given that the attack space (allowed transformations) is specified ad hoc and without a proper measure.	Review	B-Review	1
[line_break_token]- that data augmentation and training with the adversarial loss function (i.e. with the attack scheme in mind) is helpful is straight forward and not surprising[line_break_token][line_break_token]Detailed comments:[line_break_token]The authors study whether neural networks are robust to transformations in input space and resort to a benign adversarial setting.	Review	O	0
I'm wondering whether this allows for an answer regarding general robustness?	Review	B-Review	2
That is, the experiments are conducted wrt the worst case, while the training does not account for an attack setting.	Review	I-Review	2
E.g, it is unclear why the classifier would not involve a pre-processing step to counter transformations in input space, see Rowley et al. (	Review	I-Review	2
1998).	Review	I-Review	2
[line_break_token][line_break_token]Translation and rotation invariance of neural networks has been addressed by many authors, e.g., see Jaderberg et al. (	Review	I-Review	3
2015) and Marcos et al. (	Review	I-Review	3
2017).	Review	I-Review	3
[line_break_token][line_break_token]Adversarial examples are defined to be similar and misclassified with high confidence.	Review	I-Review	4
[line_break_token]The similarity of the transformation is not addressed properly.	Review	I-Review	4
E.g., if the goal of the adversary is to force errors, why not allow for rotations of 180 degrees?	Review	I-Review	4
Pixel-based attacks (Goodfellow et al.,	Review	I-Review	4
2014) are more rigorous in this regard while the cited transformation-based attacks (Kanbak et al.	Review	I-Review	4
2017; Xiao et al.,	Review	I-Review	4
2018) are virtually indistinguishable from the real test cases.	Review	I-Review	4
[line_break_token][line_break_token]The effectiveness of the grid search attack seems to be connected to performing individual tests for each test case where only the worst outcome would count.	Review	I-Review	5
The sheer number should render a misclassification more likely compared to the competitors.	Review	I-Review	5
This is supported by empirical findings showing that only a small subset of transformations per test case accounts for the misclassification on CIFAR10 and ImageNet (Fig.	Review	I-Review	5
10 in the Appendix).	Review	I-Review	5
[line_break_token][line_break_token]Regarding the padding experiments, I wonder whether the network architecture is appropriate for the new input.	Review	I-Review	6
Here, more experimentation is necessary.	Review	I-Review	6
The conclusion with respect to the first-order method remains a conjecture.	Review	I-Review	6
[line_break_token][line_break_token]References:[line_break_token]- Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy.	Review	O	0
Explaining and harnessing adversarial examples.	Review	O	0
arXiv preprint arXiv:1412.6572, 2014.	Review	O	0
[line_break_token]- Max Jaderberg, Karen Simonyan, and Andrew Zisserman.	Review	O	0
Spatial transformer networks.	Review	O	0
In Advances in neural information processing systems, pp.	Review	O	0
2017‚Äì2025, 2015.	Review	O	0
[line_break_token]- Can Kanbak, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard.	Review	O	0
Geometric robustness of deep networks: analysis and improvement.	Review	O	0
arXiv preprint arXiv:1711.09115, 2017.	Review	O	0
[line_break_token]- Diego Marcos, Michele Volpi, Nikos Komodakis, and Devis Tuia.	Review	O	0
Rotation equivariant vector field networks.	Review	O	0
In The IEEE International Conference on Computer Vision (ICCV), Oct 2017.	Review	O	0
[line_break_token]- Henry Rowley, Shumeet Baluja, and Takeo Kanade.	Review	O	0
Rotation invariant neural network-based face detection.	Review	O	0
In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp.	Review	O	0
38.	Review	O	0
sn, 1998.	Review	O	0
[line_break_token]- Chaowei Xiao, Jun-Yan Zhu, Bo Li, Warren He, Mingyan Liu, and Dawn Song.	Review	O	0
Spatially transformed adversarial examples.	Review	O	0
arXiv preprint arXiv:1801.02612, 2018.	Review	O	0
We thank the reviewer for their comments.	Reply	O	0
We will address concerns raised below:[line_break_token][line_break_token]- On the novelty of our approach.	Reply	O	0
We are aware that the robustness of NNs to spatial transformations has already been addressed as a research question.	Reply	B-Reply	1
We cite some of the relevant work (collecting all the citations in a vast field such as deep learning is unfortunately hardly possible) and we plan to add the references pointed out by the reviewer.	Reply	I-Reply	1
However, we believe that our paper contains a number of novel contributions that are not present in prior work (as we outline in our "summary of contributions" section):[line_break_token]a) We evaluate concrete and natural baselines for improving spatial robustness.	Reply	I-Reply	1
While our worst-of-10 training approach is inspired by robust optimization, it has not been applied in this form before (to the best of our knowledge).	Reply	I-Reply	1
[line_break_token]b) We evaluate the robustness of L_inf trained models, as well as combinations of L_inf and spatial attacks.	Reply	I-Reply	1
[line_break_token]c) We provide insights on the performance of first-order methods for this task.	Reply	I-Reply	1
[line_break_token]d) Finally, we point out that a few black-box queries suffice to find misclassifications.	Reply	I-Reply	1
[line_break_token](Please also refer to our response to Reviewer 2 on the same topic.)	Reply	O	0
[line_break_token][line_break_token]- The reviewer mentions multiple times how our results are trivial and not surprising.	Reply	O	0
We believe that when a problem is as fundamental as the one we study, rigorous evaluation of simple baselines is an important contribution.	Reply	B-Reply	1
We were not able to find such a thorough study in prior work.	Reply	I-Reply	1
[line_break_token][line_break_token]- We are aware of the existence of rotation-invariant architectures as well as preprocessing approaches to transformation robustness.	Reply	O	0
Our goal is to understand the spatial robustness of the most popular architectures used for these tasks and challenge the conventional wisdom that these architectures will automatically generalize to naturally occuring transformations.	Reply	B-Reply	3
Regarding the results of Rowley et al. (	Reply	I-Reply	3
1998), we would like to emphasize that rotation-invariant face detection is significantly easier, since faces have a canonical orientations (whereas most CIFAR10 and ImageNet categories do not).	Reply	I-Reply	3
The goal of Marcos et al. (	Reply	I-Reply	3
2017) is to learn models that are *fully* rotation invariant (i.e. 180 degree rotations are acceptable).	Reply	I-Reply	3
This is a fundamentally different task from learning models robust to *small* rotations since the later can still exploit the orientation of the image to some extent.	Reply	I-Reply	3
We will add a discussion of these papers in our manuscript.	Reply	I-Reply	3
[line_break_token][line_break_token]- The definition of adversarial examples we are concerned with is "images with semantically similar content that are classified differently".	Reply	O	0
Arguably, a 30 degree rotation does not change the content of the image to a human (see provided images in the Appendix), so we consider these to be valid adversarial examples.	Reply	B-Reply	4
In contrast, a 180 degree rotation would certainly appear wrong or unnatural to a human, such as a '6' turned into a '9' or an upside-down boat.	Reply	I-Reply	4
We don't view the "high confidence" component of "standard" adversarial examples as very important.	Reply	I-Reply	4
After all, classifiers are evaluated based on their top1 (and sometimes top5) accuracy.	Reply	I-Reply	4
Thus the relevant quantity in our setting is the robust accuracy.	Reply	I-Reply	4
Similarly, we do not view indistinguishability as important, as long as the original and perturbed images have the same content to a human and do not appear clearly transformed.	Reply	I-Reply	4
[line_break_token][line_break_token]- On related work: We want to emphasize that the attack of Xiao et al. (	Reply	O	0
2018) is a complex attack, operating in a much larger perturbation space (the space of smooth deformations) and utilizing *full gradient access* to the target model.	Reply	B-Reply	4
It is natural to expect such an attack to succeed with high confidence with minimal distortion.	Reply	I-Reply	4
At the same time, however, these cannot be seen as "naturally occuring transformations" outside of a security context, in contrast to rotations and translations.	Reply	I-Reply	4
[line_break_token][line_break_token]We do not follow the reviewers‚Äô comments about the transformations of Kanbak et al. (	Reply	I-Reply	4
2018).	Reply	I-Reply	4
The set of transformations from their paper is very similar to ours, differing in only in parametrization.	Reply	I-Reply	4
We also want to emphasize that their paper focuses exclusively on first order methods.	Reply	I-Reply	4
Thus the reliability of their evaluation (compared to the ground-truth gridding that we perform) is questionable given our results about the effectiveness of first-order methods.	Reply	I-Reply	4
We already include a discussion about this paper in our manuscript.	Reply	I-Reply	4
[line_break_token][line_break_token]- We do not understand the reviewer's concern about the amount of grid points used and would be grateful if the reviewer could further elaborate this point.	Reply	O	0
If the loss landscape was as well-behaved as in the case of L_inf perturbations, an attack based on projected gradient descent would clearly match a grid search.	Reply	B-Reply	5
After all, PGD is allowed full access to the gradient of the model (3 real numbers) whereas our grid attack only has access to the output label of the model (a single bit, "classified correctly" or "misclassified").	Reply	I-Reply	5

This paper proposes to use Consistency Regularization for training GANs, a technique known to work well in unsupervised learning.	Review	O	0
The technique consists in applying a transformation to real images and enforcing that the features of the discriminator between the transformed inputs and the original inputs are similar.	Review	O	0
The author show that using this technique enables them to improve the performance of a standard GAN significantly on CIFAR10.	Review	O	0
They also carry an ablation study studying the influence of the different part of the proposed technique.	Review	O	0
[line_break_token][line_break_token]Overall I'm in favor of accepting this paper.	Review	O	0
The paper is well written, with convincing experiments and an interesting ablation study.	Review	O	0
However I have several minor issues that I think could greatly improve the paper if addressed.	Review	O	0
[line_break_token][line_break_token]Minor comments:[line_break_token]- I think an idea which is somewhat related but hasn't been mentioned in the paper, is the idea of adding noise to the input when training GANs [1]. I think this is worth mentioning in the related work.	Review	O	0
[line_break_token][line_break_token]- Related to the previous point, why penalizing features and not directly output ?	Review	O	0
What about also trying to classify the transformed images as real ?	Review	B-Review	2
Also you say that penalizing the last layer, I think including the influence of m (eq 2) in the ablation study would be interesting.	Review	I-Review	2
[line_break_token][line_break_token]- The authors provide some measure of standard deviation on some experiments but not on all of them.	Review	O	0
It would be nice to systematically report the standard deviation for every experiments.	Review	B-Review	3
[line_break_token][line_break_token]- In figure 1 the author make the hypothesis that the discriminator will output very different score to images semantically close together.	Review	O	0
Did the author verify this hypothesis experimentally ?	Review	B-Review	4
[line_break_token][line_break_token]- Also why penalizing only the samples from the real distribution and not from the generator ?	Review	O	0
have you tried both ?	Review	B-Review	5
[line_break_token][line_break_token]- When the test accuracy of the discriminator is low, it could also be that the discriminator is under-fitting, it would be nice to also report the train accuracy for the discriminator.	Review	O	0
[line_break_token][line_break_token]- I think the conclusion about the effect of consistency regularization vs data augmentation is a bit vague since consistency regularization has no sense without data-augmentation.	Review	O	0
[line_break_token][line_break_token]- It's quite interesting but also disappointing that combining transformations doesn't give that much of an improvement.	Review	O	0
Do the author have any intuition why this is the case ?	Review	B-Review	8
and why learning them one after the other would work ?	Review	I-Review	8
[line_break_token][line_break_token]References:[line_break_token][1] Arjovsky and Bottou. "	Review	O	0
Towards Principled Methods for Training Generative Adversarial Networks." (	Review	O	0
ICLR 2017)	Review	O	0
hank you for all the valuable comments.	Reply	O	0
[line_break_token][line_break_token]Q7: Consistency regularization vs data augmentation[line_break_token][line_break_token]We are not sure whether we understood your comments clearly, but here we tried to provide our response with our best attempt to interpret your comments. (	Reply	O	0
Apologizes if we misunderstood your question, and in such a case, we will further appreciate if you can clarify us with further comments/question accordingly).	Reply	B-Reply	7
To be on the same page, we first want to clarify that, by ‚Äúdata augmentation‚Äù, we mean applying transformation to the original real images and treating them as additional data with label ‚Äúreal‚Äù for binary classification task in discriminator training.	Reply	I-Reply	7
In contrast, consistency regularization uses ‚Äúaugmented data‚Äù but uses them differently by enforcing consistency of discriminator output between real image and its transformed image.	Reply	I-Reply	7
In Section 4.1, our goal was to investigate whether our improvement of GAN is due to the fact that we reduce the overfitting of discriminator (in terms of better classifying images into real vs fake) or whether consistency regularization provides a special kind of regularization to the discriminator.	Reply	I-Reply	7
If the reason is the former, simply applying data augmentation should have already provided similar benefits.	Reply	I-Reply	7
However, according to our experiments, it is not the case.	Reply	I-Reply	7
[line_break_token][line_break_token]This suggests an interesting interpretation, which is that the mechanism by which the consistency regularization improves GANs is not simply discriminator generalization (in terms of classifying images into real vs fake).	Reply	I-Reply	7
We believe that the main reason for the impressive gain from the consistency regularization is due to learning more semantically meaningful representation for the discriminator.	Reply	I-Reply	7
More specifically, data augmentation will simply treat all real images and their transformed images with the same label as real without considering semantics, whereas our consistency regularization further enforces learning implicit manifold structure in the discriminator that pulls semantically similar images (i.e., original real image and the transformed image) to be closer in the discriminator representation space.	Reply	I-Reply	7
We will clarify this further in the revision.	Reply	I-Reply	7
[line_break_token][line_break_token]Q8.	Reply	O	0
Combining different transformations[line_break_token][line_break_token]We have two possible reasons that combining augmentations does not give the best result.	Reply	O	0
First,  combining augmentations can be also considered as adding stronger regularization, and stronger regularization only helps the model performance within a certain range.	Reply	B-Reply	8
Second, generator sometimes also generate samples with augmented artifacts (e.g. cutout).	Reply	I-Reply	8
If such artifacts do not exist in the real dataset, it might lead to worse FID performance.	Reply	I-Reply	8
[line_break_token][line_break_token]To be more clear, the goal of this experiment is to show that not all augmentations are useful for consistency regularization for GANs.	Reply	I-Reply	8
We think further study of data augmentation in consistency regularization for GANs will be an interesting direction.	Reply	I-Reply	8
For example, we have seen wide studies about data augmentation for image classification [2][3]. However, different from image classification augmentation, we believe the image augmentation in consistency regularization for GANs needs more careful design to make the resulting image not too far away from real data distribution.	Reply	I-Reply	8
We will revise the section to make it more clear.	Reply	I-Reply	8
[line_break_token][line_break_token][2] Cubuk, Ekin D., et al. "	Reply	O	0
Autoaugment: Learning augmentation policies from data."	Reply	O	0
arXiv preprint arXiv:1805.09501 (2018).	Reply	O	0
[line_break_token][3] Lim, Sungbin, et al. "	Reply	O	0
Fast autoaugment."	Reply	O	0
arXiv preprint arXiv:1905.00397 (2019).	Reply	O	0
[line_break_token]	Reply	O	0

Overview:[line_break_token]This paper is certainly very interesting, unlike other papers and makes some very solid contributions.	Review	O	0
The qualitative results are very impressive.	Review	O	0
Unfortunately, the paper is very poorly written.	Review	B-Review	1
If the authors can address the issues below and improve the quality of the writing, I would recommend that this paper be accepted.	Review	O	0
However, in its current state, I recommend that this paper be rejected.	Review	O	0
[line_break_token][line_break_token]Major:[line_break_token]The claim that ‚ÄúThis is the first unsupervised model that can identify objects in a 3D scene‚Äù is not true.	Review	O	0
There is MONet and Iodine that can identify objects without supervision in 2D projections of 3D scenes.	Review	B-Review	2
This claim should be revised.	Review	I-Review	2
[line_break_token][line_break_token]What is r_C in p(z|c, r_C)?	Review	I-Review	3
[line_break_token][line_break_token]The authors are using non-standard GQN notation and their notion is not consistent.	Review	I-Review	4
The authors should make their notation consistent or use the standard GQN notation.	Review	I-Review	4
Section two would not make sense to people that are not already familiar with GQN.	Review	I-Review	4
[line_break_token][line_break_token]The scene volume map is interesting, the inductive bias preventing two objects being present in the same location is interesting, however one could imagine a case where uncertainty in the model could lead to two objects being represented in the same cell.	Review	I-Review	5
[line_break_token][line_break_token]The terms in Equation 3 should be explained more explicitly.	Review	I-Review	6
The way I understand it p(s_n|z, x) is the view-point dependent representations of the objects and this is why you condition on z, x. Placing p(s_n|z, x) in the text where you talk about s_n being view dependant with some explanation would help.	Review	I-Review	6
[line_break_token][line_break_token]Why do you use a Gaussian distribution for the position?	Review	I-Review	7
Would it not make more sense to use a uniform distribution?	Review	I-Review	7
Could this be related to bias in your data?	Review	I-Review	7
I.e. more objects in the centre of the scene?	Review	I-Review	7
[line_break_token][line_break_token]What happens if object n is not present in the context image, y_c?	Review	I-Review	8
In this case what is s_{c,n}^pos.	Review	I-Review	8
Also, this notation: r_n = f({y_c,n}c)  is a little ambiguous.	Review	I-Review	8
I assume it means that you are applying the function f to the set of all patches in y_c?	Review	I-Review	8
Also, what is the object invariant object encoder?	Review	I-Review	8
A reference to details in the appendix or a footnote would suffice.	Review	I-Review	8
[line_break_token][line_break_token]It‚Äôs great that you are able to exploit the coordinate transform and use it for rendering.	Review	I-Review	9
[line_break_token][line_break_token]The results are very impressive: being able to swap in and out objects in a scene, showing the 2D renderings of single objects from different view-points and the scene decompositions and predicting where the ‚Äúmissing‚Äù object is (Figure 6).	Review	I-Review	10
[line_break_token][line_break_token]Minor:[line_break_token]The introduction could be strengthened with additional references.	Review	O	0
There are claims that object-wise factorisation will help with transfer, it would be good to have references to other work that supports this view.	Review	B-Review	11
Also the claim that humans have 3D representations for objects requires a reference.	Review	I-Review	11
[line_break_token][line_break_token]Typos (there are too many to list here, these are just a few):[line_break_token]* Abstract: and and rendering[line_break_token]* ‚Äúand‚Äùs should be replaced with commas in the second line of the intro.	Review	I-Review	12
[line_break_token]* Generally the paper is not written well.	Review	I-Review	12
[line_break_token]* The GQN, as a conditional ‚Üí is a conditional[line_break_token]* Target observations (in section 2) does not need a capital.	Review	I-Review	12
[line_break_token]* This sentence does not make sense: ‚Äúinstead of encoding compressing the whole scene‚Äù[line_break_token]* Because of intractable posterior[line_break_token][line_break_token]There are many additional grammatical errors.	Review	O	0
[line_break_token][line_break_token][line_break_token]-----------[line_break_token]Edit: Following changes made to the paper, I am now more satisfied.	Review	O	0
The writing should still be improved further and suggest that the authors fully revise the paper before the camera ready version, if the paper is accepted.	Review	O	0
I have increased my score to 6.	Review	O	0
e are very grateful for re-evaluating the paper and adjusting the score.	Reply	O	0
In the revision, we believe that we indeed substantially rewrote many parts of the paper, particularly for the clearer exposition of the technical description.	Reply	B-Reply	1
We hope you to enjoy the revised version.	Reply	I-Reply	1
Thanks	Reply	O	0

My review refers to the most recent arXiv revision (#3) at the time I downloaded papers for review.	Review	O	0
[line_break_token][line_break_token]Summary[line_break_token][line_break_token]This paper applies convolutional neural networks to the task of predicting upper-body keypoints (face, shoulder, elbow, wrist) in static RGB images.	Review	O	0
The approach trains one ConvNet per keypoint (all with the same architecture) for the task of deciding if the center pixel of an image window is the location of the target keypoint.	Review	O	0
A spatial model (a simple chain connecting face-shoulder-elbow-wrist) is estimated to provide a prior between locations of adjacent keypoints.	Review	O	0
At test-time, the ConvNets are run in a multi-scale, sliding-window fashion over the test image.	Review	O	0
The ‚Äúunaries‚Äù from the ConvNet keypoint detectors are then filtered using the prior.	Review	O	0
[line_break_token][line_break_token]Much recent work on pose estimation in static RGB images has focused on combining HOG-based part detectors via a spatial model.	Review	O	0
These models are often enriched with local mixture models.	Review	O	0
Yang & Ramanan and Sapp & Taskar are popular recent examples.	Review	O	0
This is one of the first papers that uses ConvNets within this ‚Äúparts and springs‚Äù paradigm.	Review	O	0
A paper similar in spirit was posted to arXiv slightly before this paper was submitted (‚ÄúDeepPose‚Äù by Toshev and Szegedy <a href="http://arxiv.org/pdf/1312.4659v1.pdf)."	Review	O	0
target="_blank" rel="nofollow">http://arxiv.org/pdf/1312.4659v1.pdf).</a> While too new to require a comparison, I list it here for completeness.	Review	O	0
[line_break_token][line_break_token]Novelty and Quality[line_break_token][line_break_token]While ConvNets have been used for pose estimation in previous work (as properly referenced in this paper), the current generation of ConvNets (following from Krizhevsky et al.	Review	O	0
‚Äôs work) have not been tried on the current generation of human pose datasets (e.g., FLIC).	Review	O	0
While the technique is not very novel, the proposal and investigation are good to see.	Review	B-Review	12
The paper is well written.	Review	I-Review	12
However, the experimental evaluation is confusing (unclear baseline methods, unclear if the subsets of images used are the same across methods) and computation employed for spatial modeling seems odd (more specific comments follow).	Review	I-Review	12
[line_break_token][line_break_token]Pros[line_break_token][line_break_token]+ It‚Äôs good to see an investigation of ConvNets into pose estimation on modern datasets like FLIC.	Review	O	0
[line_break_token]+ The paper is well written and easy to follow.	Review	O	0
[line_break_token]+ The proposed architecture is similar to existing ones based on HOG, but with HOG filters replaced with ConvNets, making for an interesting comparison.	Review	O	0
[line_break_token][line_break_token]Cons[line_break_token][line_break_token]- I found details of the experimental comparison on FLIC lacking (I‚Äôll be specific below).	Review	O	0
[line_break_token]- The abstract and intro lead one to believe that the results on FLIC are going to much, much better than prior work, yet they only look marginally better.	Review	O	0
[line_break_token]- The DPM baseline on FLIC doesn‚Äôt make sense (details below).	Review	O	0
[line_break_token]- The choices made in the spatial model needs to be explained more.	Review	O	0
[line_break_token][line_break_token]Details questions and comments[line_break_token][line_break_token]Sec.	Review	O	0
2: Shakhnarovich et al. [	Review	B-Review	5
37] do not use HOG [12] features.	Review	I-Review	5
Note that [37] predates HOG [12] by a few years.	Review	I-Review	5
[line_break_token][line_break_token]Sec.	Review	I-Review	5
3.1: Please be more specific about the form of LCN used.	Review	I-Review	6
[line_break_token][line_break_token]Footnote 1: ‚Äúthe the‚Äù typo[line_break_token][line_break_token]Unnumbered equation bottom of page 5: I might be confused by the notation and terse explanation, but I think this should be (p_u|i=0 * p_u).	Review	O	0
More generally, the computation needs to be explained/justified more.	Review	B-Review	8
Given a chain like this, one would typically compute the marginal likelihood of a keypoint at each location using dynamic programming (same as sum-product on a tree/chain).	Review	I-Review	8
Here, it seems that when computing the ‚Äúmarginal‚Äù for the shoulder, the wrist is completely ignored.	Review	I-Review	8
This seems very strange and ad hoc--given all of the literature on pictorial structure models, why implement this odd variant?	Review	I-Review	8
[line_break_token][line_break_token]Experimental setup / DPM comparison:[line_break_token][line_break_token]Sec.	Review	O	0
4: ‚ÄúFollowing the methodology of Felzenszwalb et al. [	Review	B-Review	9
16]...‚Äù Felzenszwalb et al.	Review	I-Review	9
does not deal with pose estimation or propose a methodology for this dataset.	Review	I-Review	9
There is some confusion here.	Review	I-Review	9
[line_break_token][line_break_token]If only 351 images were used (instead of 1016) how did you compare with MODEC?	Review	I-Review	10
Eyeballing the plots, they appear to be the same as in the MODEC CVPR 2013 paper, which from what I can tell used all 1016 test images.	Review	I-Review	10
Is this an apples-to-apples comparison?	Review	I-Review	10
[line_break_token][line_break_token]In Figure 6, how is the DPM baseline implemented?	Review	I-Review	11
DPM [16] was not designed to do pose estimation, so how did you modify it to estimate pose in this work?	Review	I-Review	11
What data was it trained on?	Review	I-Review	11
Firstly, thank you for your thoughtful insights and detailed comments.	Reply	O	0
 At a high level, we have made the explanation about the experimental setup and the spatial prior model clearer following your advice.	Reply	O	0
 In particular, we have added a discussion of the choices we made regarding experiments using the FLIC dataset and elaborated on the fairness of our evaluation criteria.	Reply	O	0
[line_break_token][line_break_token]In response to your specific concerns:[line_break_token][line_break_token]‚ÄúShakhnarovich et al. [	Reply	O	0
37] do not use HOG [12] features.	Reply	O	0
Note that [37] predates HOG [12] by a few years. ‚	Reply	O	0
Äú[line_break_token][line_break_token]Sorry for this oversight.	Reply	O	0
 We have corrected this in the latest draft.	Reply	B-Reply	5
[line_break_token][line_break_token]‚ÄúPlease be more specific about the form of LCN used.	Reply	O	0
‚Äù[line_break_token][line_break_token]The LCN normalization was based on standard techniques described by Jarrett et al. (	Reply	O	0
What is the best multi-stage architecture for object recognition?).	Reply	B-Reply	6
 Our LCN is a 2 layer module comprised of a local subtractive normalization followed by a local divisive normalization.	Reply	I-Reply	6
 The local subtractive normalization stage subtracts the local mean value (calculated by convolving the input with a 9x9 Gaussian kernel) from each input pixel.	Reply	I-Reply	6
 Likewise, the local divisive normalization divides each pixel by the standard deviation of the local 9x9 pixel window.	Reply	I-Reply	6
 A divisive threshold of 1e-4 was used to prevent over-emphasis of input noise and division by zero.	Reply	I-Reply	6
 We have added these details to the latest version on Arxiv.	Reply	I-Reply	6
[line_break_token][line_break_token]‚ÄúUnnumbered equation bottom of page 5: I might be confused by the notation and terse explanation, but I think this should be (p_u|i=0 * p_u).‚Äù[line_break_token][line_break_token]Sorry for our overly terse explanation.	Reply	O	0
 We have added a more thorough discussion in the latest version.	Reply	B-Reply	8
[line_break_token][line_break_token]The equation describes standard sum-product belief propagation, however perhaps our notation made this confusing.	Reply	I-Reply	8
 The biggest difference from standard literature is that we don't assume a Gaussian distribution for the pairwise terms, but have more flexible non-parametric representation based on the histograms of relative position occurrences in the training data.	Reply	I-Reply	8
 Furthermore, we formulate these terms as convolutional priors, which avoid having to learn a distribution for every pixel location.	Reply	I-Reply	8
 As indicated in figure 3, we do incorporate message terms from adjacent nodes in the graph (where the likelihood term from the shoulder to face nodes being a notable exception).	Reply	I-Reply	8
 For example, when calculating the marginal for the shoulder term, the wrist location is accounted for in the elbow message.	Reply	O	0
[line_break_token][line_break_token]‚ÄúSec.	Reply	O	0
4: ‚ÄúFollowing the methodology of Felzenszwalb et al. [	Reply	O	0
16]...‚Äù Felzenszwalb et al.	Reply	O	0
does not deal with pose estimation or propose a methodology for this dataset.	Reply	O	0
There is some confusion here. ‚	Reply	O	0
Äù[line_break_token][line_break_token]Sorry for the confusion.	Reply	O	0
 This was actually an typographic error and has been rectified in the latest draft.	Reply	B-Reply	9
 We actually follow the methodology of Sapp et al. [	Reply	I-Reply	9
36], not Felzenszwalb et al as stated.	Reply	I-Reply	9
 In particular we used their error metric, evaluation code and their test-set.	Reply	I-Reply	9
 We deviate from their methodology in one important way: we use a 351 image subset of the test set.	Reply	I-Reply	9
 This subset contains the images that only contain a single person.	Reply	I-Reply	9
 The motivation for doing so follows the fact that our detector will give a positive detection for all persons in the image, while the ground-truth labels exist for only a single person in the image (chosen arbitrarily).	Reply	I-Reply	9
[line_break_token][line_break_token]‚ÄúIf only 351 images were used (instead of 1016) how did you compare with MODEC?	Reply	O	0
Eyeballing the plots, they appear to be the same as in the MODEC CVPR 2013 paper, which from what I can tell used all 1016 test images.	Reply	O	0
Is this an apples-to-apples comparison?‚Äù[line_break_token][line_break_token]We use the same 351 image subset when evaluating all models, including MODEC, and we have made this clear in the latest paper revision.	Reply	O	0
 While the MODEC results appear similar to the CVPR 2013 paper when inspecting the plots, they are actually slightly different.	Reply	B-Reply	10
[line_break_token][line_break_token]‚ÄúIn Figure 6, how is the DPM baseline implemented?	Reply	O	0
DPM [16] was not designed to do pose estimation, so how did you modify it to estimate pose in this work?	Reply	O	0
What data was it trained on?‚Äù[line_break_token][line_break_token]As you correctly pointed out, DPM is designed for detection and so we apply it to detect key-points in the skeleton (the same keypoints used to train our convnet based detector).	Reply	O	0
Furthermore, DPM is trained on exactly same training data as our convnet (3987x2 images) and tested on the same test set; as such we believe that we have directly and fairly compared both keypoint-based detectors.	Reply	B-Reply	11
The use of DPM in this manner is similar to the ICCV‚Äô13 paper of Pishchulin et al. (	Reply	I-Reply	11
Strong Appearance and Expressive Spatial Models for Human Pose Estimation), which uses DPM as a unary likelihood model for keypoint detection	Reply	I-Reply	11

Summary[line_break_token]This paper mention that there are some critical drawbacks existing in IS (Inception Score) and FID (Fr√©chet Inception Distance) which are two popular metrics to measure image generation quality.	Review	O	0
However, IS and FID scores are initially designed for measuring unconditional distribution, which fails to capture the conditional consistency of conditional distribution.	Review	O	0
Thus, the authors propose to concatenate conditioned embedding h(y) with image feature vector f(x) to extend the FID metric.	Review	O	0
The authors also implement the method on a toy dataset to show the sensitivity of FJD on conditional consistency and several popular cGAN models to show the efficiency of FJD on real data.	Review	O	0
[line_break_token]Paper Strengths[line_break_token]  1.	Review	O	0
The method is intuitive and easy to implement.	Review	O	0
[line_break_token][line_break_token]Paper Weaknesses[line_break_token]1.	Review	O	0
Although this paper shows the problem of FID for capturing the conditional consistency sprightly with the toy dataset, however, this problem does not obviously show up on real data.	Review	B-Review	1
Basically, FID can also give a good comparison of the different model as FJD	Review	I-Review	1
hank you for your review.	Reply	B-Reply	1
Since your single concern was shared by the other reviewers, please see our general comment above, where we have addressed it	Reply	I-Reply	1

Post rebuttal: The authors' responses have addressed most of my concerns, and I've raised my rating from 3 to 6.	Review	O	0
[line_break_token][line_break_token]----------------------------------------[line_break_token][line_break_token]Summary:[line_break_token]This paper extends the discriminator of GAN to use a distributional output (multiple scalars) instead of a single scalar.	Review	O	0
As a result, the trained GAN becomes robust to the mode collapse.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The proposed method is clearly written and well-justified (e.g., Theorem 2).	Review	O	0
[line_break_token]- Extension of the relativistic GAN [1] to the proposed setting is interesting.	Review	O	0
[line_break_token]- The authors demonstrate that vanilla DCGAN architecture can generate high-fidelity (1024x1024) images.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]1.	Review	O	0
An ensemble of discriminators?	Review	B-Review	2
[line_break_token][line_break_token]The authors use multiple scalars to consider diverse factors of the realness.	Review	I-Review	2
However, it is simply an ensemble of discriminators [2] in a spirit.	Review	I-Review	2
As each discriminator focus on different factors, it is not surprising that the generator becomes robust to the mode collapse.	Review	I-Review	2
Also, recent work on mode collapse (e.g., [3]) shows better results on the mixture of gaussian experiments even using a single discriminator.	Review	I-Review	2
At least, the authors should compare their method with the ensemble methods and claim the advantage over them.	Review	I-Review	2
[line_break_token][line_break_token]2.	Review	I-Review	1
Choice of the anchor distributions.	Review	I-Review	3
[line_break_token][line_break_token]The choice of anchor distributions A_0 and A_1 are not specified.	Review	I-Review	3
While the authors provide some partial results in Table 2, it would be worthwhile to clarify the experimental details and justify them.	Review	I-Review	3
[line_break_token][line_break_token]3.	Review	I-Review	3
Role of each outcome u_i?	Review	I-Review	4
[line_break_token][line_break_token]The authors claim that each outcome u_i corresponds to the different factors of realness.	Review	I-Review	4
However, the role of learned u_i is not investigated.	Review	I-Review	4
Also, one may enforce u_i to learn different factors by promoting diversity of them, e.g., decrease their cosine similarity [4].[line_break_token][line_break_token]Minor comments:[line_break_token]- The word "support" [5] is misused.	Review	O	0
The support itself means the set of non-zero elements, hence the authors should use the word "outcome" (or "sample") instead of "support".	Review	B-Review	1
[line_break_token]- The notation is not consistent.	Review	I-Review	1
For example, the authors may use "x \sim p_data(x)" (specify variable) or "z \sim p_z" (omit variable), but not both.	Review	I-Review	1
[line_break_token]- Numbering is not consistent.	Review	I-Review	1
For example, "Tab.4.2."	Review	I-Review	1
should be changed to "Tab.2."	Review	I-Review	1
for consistency.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token][1] Jolicoeur-Martineau.	Review	O	0
The relativistic discriminator: a key element missing from standard GAN.	Review	O	0
ICLR 2019.	Review	O	0
[line_break_token][2] Durugkar et al.	Review	O	0
Generative Multi-Adversarial Networks.	Review	O	0
ICLR 2017.	Review	O	0
[line_break_token][3] Xiao et al.	Review	O	0
BourGAN: Generative Networks with Metric Embeddings.	Review	O	0
NeurIPS 2018.	Review	O	0
[line_break_token][4] Elfeki et al.	Review	O	0
GDPP: Learning Diverse Generations Using Determinantal Point Process.	Review	O	0
ICML 2019.	Review	O	0
[line_break_token][5] <a href="https://en.wikipedia.org/wiki/Support_(mathematics)" target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Support_(mathematics)</a>	Review	O	0
hank you for your comments.	Reply	O	0
We address your concerns below and code will be released.	Reply	O	0
Revision in the paper is highlighted in magenta.	Reply	O	0
[line_break_token][line_break_token]**Minor comments**[line_break_token]Thank you for pointing them out.	Reply	O	0
We have revised our paper to fix these errors.	Reply	B-Reply	1
[line_break_token][line_break_token]**An ensemble of discriminators** [line_break_token]EnsembledGAN and RealnessGAN are significantly different both conceptually and technically.	Reply	O	0
[line_break_token][line_break_token]*Conceptually*:  EnsembledGAN aims at balancing n *independent* discriminators.	Reply	O	0
They all treat realness as a scalar, ranging from 0 to 1.	Reply	B-Reply	2
On the contrary, RealnessGAN treats realness as a random variable and use a *single* discriminator to capture the distribution of the variable.	Reply	I-Reply	2
Through the distributional constraint, outcomes of RealnessGAN have semantic meanings, i.e. assessing images from multiple angles.	Reply	I-Reply	2
Such semantics are implicitly constrained in our paper.	Reply	I-Reply	2
And we could also deploy an explicit constraint to enforce this.	Reply	I-Reply	2
Such an updated view on the realness lead to theoretical guarantees on the optimality.	Reply	I-Reply	2
[line_break_token][line_break_token]Conceptually RealnessGAN and EnsembledGAN are orthogonal.	Reply	I-Reply	2
RealnessGAN could serve as one of the discriminators of EnsembledGAN by taking the expectation of estimated realness distribution as its output.	Reply	I-Reply	2
 [line_break_token][line_break_token]*Technically*: EnsembleGAN uses multiple discriminators that could have different architectures and weights.	Reply	O	0
RealnessGAN uses a single discriminator.	Reply	B-Reply	2
While some of the resemblance comes from the fact that we use a discrete distribution to approximate the realness distribution, so that outcomes are discrete, RealnessGAN has the potential to use a continuous distribution to represent the realness distribution, which further distinguishes it from the EnsembledGAN.	Reply	I-Reply	2
Moreover, unlike EnsembledGAN, the outcomes of RealnessGAN  have semantic meanings, we could also extend RealnessGAN to include structures (e.g. grids, 3d lattice, etc) for discrete outcomes or priors on continuous outcomes, further improving RealnessGAN.	Reply	I-Reply	2
 [line_break_token][line_break_token]*Result*: Despite the conceptual differences, we compare RealnessGAN and EnsembledGAN on Cifar10, and the results are:[line_break_token]                                 FID           SWD[line_break_token]RealnessGAN       34.59         22.80[line_break_token]EnsembledGAN   37.76         26.53[line_break_token]where RealnessGAN is shown to outperform EnsembledGAN.	Reply	O	0
EnsembledGAN using DCGAN also fails on FFHQ, which is more challenging.	Reply	B-Reply	2
[line_break_token][line_break_token]**BourGAN**[line_break_token]The work of BourGAN is orthogonal to us.	Reply	O	0
BourGAN provides a technique on the latent space of z to help the standard GAN.	Reply	B-Reply	2
RealnessGAN replaces the estimation of realness with a distributional view.	Reply	I-Reply	2
One could combine BourGAN and RealnessGAN.	Reply	I-Reply	2
[line_break_token][line_break_token]**Choice of the anchor distributions**[line_break_token]In the experiments, we choose A_0 and A_1 to resemble the shape of normal distributions with a positive skew and a negative skew, respectively.	Reply	O	0
  [line_break_token][line_break_token]In the paper, we include several clues on how to choose A_0 and A_1.	Reply	B-Reply	3
1) We show in the theoretical analysis A_0 and A_1 can be chosen flexibly, as long as they satisfy A_0(u) \ne A_1(u) for some outcome u. 2) We also show in Table 2, the KL divergence between A_0 and A_1 is important.	Reply	I-Reply	3
3) To show Table 2 is sufficient to guide how to choose A_0 and A_1, we extend the study in Table 2 to compare pairs of A_0 and A_1 that have different shapes but similar KL divergences, and the results are:[line_break_token]                KL[tab_token]       FID(min)     [line_break_token]Pair1     11.95         29.62[line_break_token]Pair2     11.67         30.12[line_break_token]The results suggest that the major factor we need to care about is the KL divergence between our chosen A_0 and A_1.	Reply	I-Reply	3
[line_break_token][line_break_token]**Role of each outcome u_i**[line_break_token]The role of outcomes are currently implicitly constrained by the distributional view during training.	Reply	O	0
We include a heuristic interpretation on the estimated distributions in Appendix C, where we use the generator of RealnessGAN to produce a set of samples and the discriminator to produce their estimated realness distributions.	Reply	B-Reply	4
Consequently, we have found generated samples that have similar realness distributions have something in common.	Reply	I-Reply	4
[line_break_token]Explicitly adding a regularizer to better disentangle the semantics into different outcomes is possible but we think it is beyond the focus of this paper, we thus leave it as the future work.	Reply	I-Reply	4
[line_break_token][line_break_token]**Extension of the relativistic GAN [1] to the proposed setting**[line_break_token]We would like to clarify that the relativistic loss used here serves as a regularizer, so that the objective is: [line_break_token](objective 1)   min KL(D(x) || D(G(z))) - KL(A_0 || D(G(z)))[line_break_token]We also replace it with an alternative one, so that the objective becomes:[line_break_token](objective 2)    min KL(A_1 || D(G(z))) - KL(A_0 || D(G(z)))[line_break_token]The quantitative results of these objectives on Cifar10 are:[line_break_token]                          FID         [line_break_token]Objective1     34.59  [line_break_token]Objective2     36.21[line_break_token]DCGAN          38.56  [line_break_token]WGAN-GP     41.86[line_break_token]LSGAN           42.01[line_break_token]HingeGAN    42.40[line_break_token]we have also included  in Appendix A the training curves of using objective 1 and objective 2 on CelebA. On both datasets, we can see without the relativistic loss, RealnessGAN can still outperform baselines.	Reply	O	0
We have revised paper to clarify this ambiguity.	Reply	B-Reply	5

Efficient Inference and Exploration for Reinforcement Learning[line_break_token]================================================================[line_break_token][line_break_token]This paper presents a pure-exploration algorithm for reinforcement learning.	Review	O	0
[line_break_token]The approach is based on an assymptotic analysis of the Q-values, and their convergence to central limit distribution.	Review	O	0
[line_break_token]Using this analysis, and under specific assumptions, the algorithm outperforms existing algorithms for exploration.	Review	O	0
[line_break_token][line_break_token][line_break_token]There are several things to like about this paper:[line_break_token]- Many existing analyses for efficient exploration are all based around more-of-the-same concentration bounds, which end up being quite messy and un-elegant.	Review	O	0
This approach based on central limit theorem appears to be more insightful and cleaner and I think there is something nice about that!	Review	O	0
[line_break_token]- The proposed algorithm is reasonable, for the setting in question, and the experimental results show that it outperforms benchmark exploration algorithms in this setting.	Review	O	0
[line_break_token]- The general structure of the paper, quality of writing and technical rigour appears to be of good standard... although I did not check all technical details carefully. [	Review	O	0
The paper is 24 pages long and we have many reviews][line_break_token][line_break_token][line_break_token]However, there are also some significant places where this paper falls short:[line_break_token]- The problem setting that the authors consider is really not typical of the "exploration" problem in RL... I'm not talking about the fact that this is a "pure exploration" algorithm (that's fine), but instead that Assumption 3 is really not a good model for the types of problems that are "hard" for exploration in RL!	Review	O	0
For example, in the RiverSwim problem choosing an exploration policy = 0.8 right is essentially saying that you've already solved the hard part of the problem.	Review	B-Review	2
Note - I am a little bit confused about the experiments in Tables 3 and 4, here it seems that you start with a pi(1|s)=0.6 which again feels like a cheat...[line_break_token]- Would it be possible to compare this algorithm in a more like-for-like standard RL setting, perhaps using the standardised bsuite <a href="https://github.com/deepmind/bsuite" target="_blank" rel="nofollow">https://github.com/deepmind/bsuite</a> (the "deep sea" problems might be of particular interest here.)	Review	O	0
[line_break_token]- Alternatively, I can imagine a future version of the paper being more upfront about this deviation from the "standard" setting and highlighting that this is a special-type of result quite different from typical exploration in RL.	Review	O	0
[line_break_token]- I'm not sure that this sort of paper is well-served by a conference like ICLR... certainly there seems very little of "learning representation" in this discussion of Tabular RL.	Review	O	0
That would sort of be OK if the paper made nods to how these *insights* could carry over the deep learning or at least RL with (linear) function approximation... I don't see much of that.	Review	B-Review	4
[line_break_token][line_break_token][line_break_token]Overall I do think this is an interesting paper, with a novel approach to pure exploration in tabular MDPs under specific assumptions.	Review	O	0
[line_break_token]However, I'm not sure that this paper is well-suited to ICLR and I have some concerns about whether it really does address the sort of "exploration" problem in RL that one might expect.	Review	B-Review	4
Thank you for your comments and suggestions!	Reply	O	0
We would like to reiterate, and as you have kindly pointed out, that our main contribution is to build a framework to tackle pure exploration in RL by developing a set of clean asymptotic results.	Reply	B-Reply	1
To our knowledge, the considered pure exploration problem, even in the tabular MDP setting, has been under-studied yet arises in important applications.	Reply	I-Reply	1
Our current work serves to build a foundational framework that potentially applies to more complex settings in the future, including some that you have suggested.	Reply	I-Reply	1
In fact, in the Appendix, we discuss several possible extensions of our results, most noticeably on approximate value iteration in Appendix A2.	Reply	I-Reply	1
[line_break_token][line_break_token]Below are our point-by-point responses to your comments:[line_break_token][tab_token][line_break_token]1.	Reply	O	0
We would like to clarify that Assumption 3 is in some sense a minimal assumption for the ``correctness" of our framework (though it could be generalized to, say, non-irreducible MDP by suitable modification of our suggested strategy via properly randomized starting/restarting).	Reply	B-Reply	2
On the other hand, we agree very much with you that this assumption does not capture the ``hardness" of the exploration problem.	Reply	I-Reply	2
Rather, our approach is to propose a reasonable strategy backed by the implications and mathematical forms of our new limit theorems, and demonstrate its superiority through numerical experiments.	Reply	I-Reply	2
[line_break_token]    To clarify the specific numerical setup, is used in the first experiment using the RiverSwim example.	Reply	I-Reply	2
The goal here is purely a sanity check of our statistical inference method, i.e., for any data collection mechanism, the 95% confidence interval constructed according to the formula is verified to contain the true value with a 95% chance when the sample size is large enough (asymptotic validity).	Reply	I-Reply	2
We did not use this configuration as an exploration policy -- and we agree with the reviewer that doing so would defy the purpose of exploration.	Reply	I-Reply	2
[line_break_token]    In the second experiment (Table 3 and 4), is used in the first stage to provide a warm start.	Reply	I-Reply	2
The same first-stage data are used for all the methods listed in the table, either in estimating the parameters of the MDP (UCRL, Q-OCBA,-greedy) or setting a good prior distribution for the parameters (PSRL); the pure random strategy RE(0.6) in the table keeps using in the second stage.	Reply	I-Reply	2
We observe in the experiments that using Q-OCBA outperforms (thus improving a naive strategy) and other previous related methods in the literature (thus appearing competitive against existing alternatives; we also provide reasons for this in the numerical section).	Reply	I-Reply	2
 [line_break_token][tab_token][line_break_token]2.	Reply	O	0
Thank you for pointing out the other interesting test problems, which we would investigate in the future.	Reply	B-Reply	3
We have chosen RiverSwim in this paper because it is the example used in the previous PSRL and UCRL papers.	Reply	I-Reply	3
This problem has the specific feature that there are a lot of uncertainty about the transition probability, which elevates the need of exploration and thus we believe it is a good test problem for comparing exploration strategies.	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	O	0
Regarding your last two points, we would definitely clarify our setting and distinguish our framework/results from what was typically considered.	Reply	B-Reply	4
In terms of the implications or generalizations to larger-scale problems, our framework that derives asymptotic results on estimation variance, and uses its mathematical form to formulate tractable optimization to devise good exploration strategies, is potentially applicable to these more sophisticated settings, and we do have them in our mind (e.g., Appendix A2 lists some preliminary results along this direction).	Reply	I-Reply	4
However, a full investigation would require substantial additional analyses, and we would position the current paper as providing the groundwork for these important future generalizations	Reply	I-Reply	4

In this paper, the authors study the behavior of stochastic mirror descent on overparameterized nonlinear models.	Review	O	0
Especially, the authors show that for appropriate initialization, SMO converges to a global minimum with a minimal distance to the initialization.	Review	O	0
The authors also report some experimental results to verify this theory.	Review	O	0
[line_break_token][line_break_token]The implicit regularization of SGD/SMD is widely studied in the literature.	Review	B-Review	1
Although it is claimed that the paper improved existing results by either considering nonlinear models or identify more precise implication regularization, the contribution is a bit minor.	Review	I-Review	1
In particular, the fundamental identity in Lemma 6 is exactly a specific case of Lemma 4 in  Azizan &amp; Hassibi (2018) with no noises.	Review	O	0
Moreover, Azizan &amp; Hassibi (2018) also discussed the implicit regularization of SMD in their Theorem 10 for nonlinear models with some localization arguments.	Review	O	0
This paper considers similar localization arguments with some different assumptions.	Review	B-Review	1
[line_break_token][line_break_token]After rebuttal:[line_break_token]I am sorry to select by mistake a N/A for the correctness of experiments.	Review	O	0
 [line_break_token]I have read the authors' rebuttal and would not like to change my score.	Review	O	0
The fundamental identity in Lemma 6 was already derived in Azizan &amp; Hassibi (2018).	Review	O	0
This paper identifies some assumptions to show the implicit regularization studied in Azizan &amp; Hassibi (2018) with heuristic argument.	Review	O	0
However, these assumptions are very strong and with the assumptions the argument follows similarly to those in Azizan &amp; Hassibi (2018).	Review	O	0
Indeed, as stated in Azizan &amp; Hassibi (2018), the convergence in linear case depends on the non-negativity of.	Review	O	0
In this paper, the authors just assume that this non-negativity holds locally in Assumption 1.	Review	B-Review	1
In my opinion, this seems not a rigorous way to formulate assumptions.	Review	I-Review	1
e thank you for your comments.	Reply	O	0
[line_break_token]We agree that the implicit regularization of SGD/SMD has been studied in the recent literature.	Reply	B-Reply	1
However, we would like to emphasize the following points:[line_break_token][line_break_token]1.	Reply	I-Reply	1
All the results for SMD in the literature (except for [Azizan &amp; Hassibi, 2019], discussed in item 2 below) are for *linear* models.	Reply	O	0
[line_break_token][line_break_token]2.	Reply	O	0
The nonlinear result discussed in Section 5.2 of [Azizan &amp; Hassibi, 2019] is quite informal.	Reply	O	0
The argument for Theorem 10 in that paper is mostly heuristic and the statement of the theorem itself is also somewhat informal.	Reply	B-Reply	1
In the current paper, we have made the statement for the nonlinear case precise: We separately identify the conditions required for convergence (Assumption 1 in Theorem 3) and implicit regularization (Assumption 2 in Theorem 4).	Reply	I-Reply	1
We explicitly give a bound on the step size (requiring the strict convexity of for all, which generalizes the bound for SMD in linear models).	Reply	I-Reply	1
We make the notions of ‚Äúcloseness‚Äù and ‚Äúlocality‚Äù precise in terms of the corresponding Bregman divergence (not in terms of the imprecise notion of distance in Theorem 10 of [AH ‚Äò19]).	Reply	I-Reply	1
And, finally, we have two statements 1 and 2 in Theorem 4, rather than the single statement 2 in Theorem 10 of [AH ‚Äò19].[line_break_token]While the reviewer contends that those improvements are a bit minor, we beg to differ.	Reply	I-Reply	1
Establishing Theorems 3 and 4 took a significant effort and multiple attempts.	Reply	I-Reply	1
However, irrespective of the effort, we believe there is value in rigorously stating and proving the conditions and manner of convergence and implicit regularization for SMD on overparameterized nonlinear models.	Reply	I-Reply	1
[line_break_token]We also consider our experimental results to be a significant contribution of the paper, as detailed next.	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
We should emphasize that none of the papers studying the implicit regularization of SGD/SMD, and in particular [AH ‚Äò19], provide any experimental results.	Reply	B-Reply	1
In fact, to the best of our knowledge, the current paper provides the first experimental results on applying SMD to deep learning.	Reply	I-Reply	1
We provide extensive and systematic experiments on real datasets (both MNIST and CIFAR-10) using standard off-the-shelf architectures (ConvNet and ResNet) for various mirror descent algorithms, various random initializations, and various Bregman divergences.	Reply	I-Reply	1
All these experiments consistently confirmed the predictions of the theory, namely that among all the obtained global minima, the one we reach from a certain initialization and mirror is the one closests to the initialization in the corresponding Bregman divergence.	Reply	I-Reply	1
This is noteworthy in itself.	Reply	I-Reply	1
Furthermore, the histograms of Figure 6 clearly show the effect of the implicit regularization on the distribution of the interpolating weights.	Reply	I-Reply	1
Finally, Figure 7 clearly shows the effect of implicit regularization on the generalization performance of the network and provides some surprising insights.	Reply	I-Reply	1
[line_break_token][line_break_token]In light of these facts, we would like to invite the reviewer to change their rating (as well as to change the N/A assessment for experiments).	Reply	O	0

This paper analyzes ensembling methods in deep learning from the perspective of the loss landscapes.	Review	O	0
The authors empirically show that popular methods for learning Bayesian neural networks produce samples with limited diversity in the function space compared to modes of the loss found using different random initializations.	Review	O	0
The paper also considers the low-loss paths connecting independent local optima in the weight-space.	Review	O	0
The analysis shows that while the values of the loss and accuracy are nearly constant along the paths, the models corresponding to different points on a path define different functions with diverse predictions.	Review	O	0
The paper also demonstrates the complementary benefits of using subspace sampling/weight averaging in combination with deep ensembles and shows that relative benefits of deep ensembles are higher.	Review	O	0
[line_break_token][line_break_token]The paper is well-written.	Review	O	0
The experiments are described well and the results are presented clearly in highly-detailed and visually-appealing figures.	Review	O	0
There are occasional statements which are not formulated rigorously enough (see comments below).	Review	B-Review	3
[line_break_token][line_break_token]The paper presents a thorough experimental study of different ensemble types, their performance, and function space diversity of individual members of an ensemble.	Review	O	0
In my view, the strongest contribution of the paper is the analysis of the diversity of the predictions for different sampling procedures in comparison to deep ensembles.	Review	O	0
However, the novelty and the significance of the other contributions are limited (see comments below).	Review	B-Review	5
Therefore, I consider the paper to be below the acceptance threshold.	Review	I-Review	5
  [line_break_token][line_break_token]Comments and questions to authors:[line_break_token]1) The practical aspects of different ensembling techniques are not discussed in the paper.	Review	O	0
While it is known that deep ensembles generally demonstrate stronger performance [1], there is a trade-off between the ensemble performance and training time/memory consumption.	Review	B-Review	1
The considered alternative ensembling procedures can be favorable in specialized settings (e.g. limited training time and/or memory).	Review	I-Review	1
[line_break_token][line_break_token]2) It remains unclear to me what new insights does the analysis of the low-loss connectors provide?	Review	O	0
It is expected (and in fact can be shown analytically) that if the two modes define different functions then intermediate points on a continuous path define functions which are different from those defined by the end-points of the path.	Review	B-Review	2
This result was also analyzed before from the perspective of the performance of ensembles formed by the intermediate points on the connecting paths (see Fig.	Review	I-Review	2
2 right in [2]).	Review	I-Review	2
[line_break_token]Moreover, I would encourage authors to reformulate the statements on the connectivity in the function space such as: [line_break_token]-- ‚ÄúWe demonstrate that while low-loss connectors between modes exist, they are not connected in the space of predictions.	Review	I-Review	3
‚Äù  (Abstract)[line_break_token]-- ‚Äúthe connectivity in the loss landscape does not imply connectivity in the space of functions‚Äù (Discussion)[line_break_token]In my opinion, these claims are somewhat misleading.	Review	O	0
What does it mean that the modes are disconnected in the function space?	Review	B-Review	4
Neural networks define continuous functions (w.r.t to both the inputs and the weights), and a connector is continuous path in the weight space which continuously connects the modes in the function space (i.e. a path defines a homotopy between two functions).	Review	I-Review	4
It is true that two modes correspond to two different functions.	Review	I-Review	4
However, it is unclear in which sense these functions can be considered to be disconnected.	Review	I-Review	4
[line_break_token][line_break_token][1] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.	Review	O	0
Simple and scalable predictive uncertainty estimation using deep ensembles.	Review	O	0
In NeurIPS, 2017.	Review	O	0
[line_break_token][line_break_token][2] Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry P Vetrov, and Andrew G Wilson.	Review	O	0
Loss surfaces, mode connectivity, and fast ensembling of DNNs.	Review	O	0
In NeurIPS, 2018.	Review	O	0
hank you for your review and the positive comments about our work.	Reply	O	0
[line_break_token]We would like to address the points you brought up.	Reply	O	0
[line_break_token][line_break_token]‚ÄúPractical aspects of ensembling versus different methods of subspace sampling‚Äù:  [line_break_token][line_break_token]The goal of this work is to understand the general question of why ensembles work well and we provide an explanation from the perspective of loss landscapes.	Reply	O	0
In future work, we plan to take these insights to develop better algorithms for specific settings.	Reply	B-Reply	1
[line_break_token]We‚Äôre happy to add a discussion about different regimes (training time constraints, serving time constraints, memory constraints, etc), but it is beyond the scope of this paper to discuss every possible setting in detail.	Reply	I-Reply	1
Some of these solutions are well-known in the literature, cf.	Reply	I-Reply	1
the discussion in (Lakshminarayanan et al.	Reply	I-Reply	1
2017) or the take-home messages in (Ovadia et al.	Reply	I-Reply	1
2019): for instance, distillation is a popular solution when serving time is the primary constraint.	Reply	I-Reply	1
Implicit ensembles (e.g. Monte-Carlo dropout) are popular when memory is the main constraint.	Reply	I-Reply	1
The best method would obviously depend on the specific constraints (as you also point out).	Reply	I-Reply	1
[line_break_token][line_break_token]----------------[line_break_token][line_break_token]‚ÄúIt remains unclear to me what new insights does the analysis of the low-loss connectors provide?‚Äù[line_break_token][line_break_token]We added Section 3.3 in response to feedback on an earlier version of this paper.	Reply	O	0
A couple of folks thought that our results contradicted the results from earlier papers on ‚Äúmode connectivity‚Äù.	Reply	B-Reply	2
We believe this confusion comes down to how folks interpret the word ‚Äúconnectivity‚Äù.	Reply	I-Reply	2
The original papers by (Garipov et al.	Reply	I-Reply	2
2018) and (Draxler et al.	Reply	I-Reply	2
2018) used ‚Äúconnectivity‚Äù to imply continuous map between two functions (the notion you mentioned), but others (not the original authors) seem to have interpreted connectivity as similarity of functions.	Reply	I-Reply	2
[line_break_token]We mainly wanted to convey that identical loss values do not imply identical functions.	Reply	I-Reply	2
That is, loss similarity, which measures if L(f_{theta_1}) and L(f_{theta_2}) are similar, does not measure prediction similarity, which measures if f_{theta_1} and f_{theta_2} are similar.	Reply	I-Reply	2
[line_break_token]While it has been shown that two independently initialized and optimized-to optima can in fact be connected on a low-loss path in the weight space by (Garipov et al.	Reply	I-Reply	2
2018) and (Draxler et al.	Reply	I-Reply	2
2018), the papers do not explicitly discuss how similar the models along such a path are in their predictions, which can be taken as a proxy for their similarity in the space of functions.	Reply	I-Reply	2
[line_break_token]Given that multiple folks raised this point about ‚Äúconnectivity‚Äù, we thought it might be useful to explicitly add a discussion about the distinction between loss similarity and prediction similarity in subsection 3.3.	Reply	I-Reply	2
 [line_break_token][line_break_token]----------------[line_break_token][line_break_token]‚ÄúI would encourage authors to reformulate the statements on the connectivity in the function space‚Äù:[line_break_token][line_break_token]We can rephrase ‚Äúloss connectivity‚Äù and ‚Äúfunction space connectivity‚Äù to ‚Äúloss similarity‚Äù and ‚Äúpredictions similarity‚Äù, would that address your concerns?	Reply	O	0
[line_break_token][line_break_token]----------------[line_break_token][line_break_token]‚ÄúHowever, the novelty and the significance of the other contributions are limited (see comments below).	Reply	O	0
Therefore, I consider the paper to be below the acceptance threshold.	Reply	O	0
‚Äù  [line_break_token][line_break_token]To the best of our knowledge, we are the first to comprehensively investigate deep ensembles vs Bayesian neural nets from loss landscape perspective.	Reply	O	0
We carefully investigated the role of random initialization in deep ensembles, tested the complementary effects of ensembling and subspace methods, and measured diversity of functions.	Reply	B-Reply	5
Aside from earlier results on CIFAR-10 and ImageNet, we have also added new experiments on CIFAR-100 (see Figure S3 in Appendix C) which are consistent with our earlier results.	Reply	I-Reply	5
[line_break_token][line_break_token]I think your own summary highlights a lot of our contributions: ‚ÄúThis paper analyzes ensembling methods in deep learning from the perspective of the loss landscapes.	Reply	I-Reply	5
The authors empirically show that popular methods for learning Bayesian neural networks produce samples with limited diversity in the function space compared to modes of the loss found using different random initializations ... The paper also demonstrates the complementary benefits of using subspace sampling/weight averaging in combination with deep ensembles and shows that relative benefits of deep ensembles are higher. ‚	Reply	I-Reply	5
Äú[line_break_token][line_break_token]We believe these results are both novel and significant, and would be interesting to the ICLR community	Reply	I-Reply	5

This work tackles the difficult RNA design problem, i.e. that of finding a RNA primary sequence that is going to fold into a secondary/tertiary structure able to perform a desired biological function.	Review	O	0
More specifically, it used Reinforcement Learning (RL) to find the best sequence that will fold into a target secondary structure, using the Zuker algorithm and designing a new primary sequence 'from scratch'.	Review	O	0
A new benchmark data set is also introduced in the paper along .	Review	O	0
[line_break_token][line_break_token]Questions/remarks:[line_break_token] - I struggle with your notations as soon as section 2.1.	Review	O	0
What is the star (*) superscript for?	Review	B-Review	1
Was expecting the length of the RNA sequence instead.	Review	I-Review	1
Same on p4, when introducing the notation of your decision process, explicitly introduce all the ingredients.	Review	I-Review	1
[line_break_token] - in Equation (2) on p4, maybe clarify the notation with '.', '('	Review	O	0
and ')' for example as the reader could really struggle.	Review	B-Review	2
[line_break_token] - I didn't really understand the message in Section 4, not being an expert in the field.	Review	O	0
Could you clarify your contribution here?	Review	B-Review	3
[line_break_token] - your 'Ablation study' in Section 5.2; does it correspond to true uncertainty/noise that could be observed in real data?	Review	O	0
[line_break_token] - why a new benchmark data set, when there exist good ones to compare your method to, e.g. in competitions like CASP for proteins?	Review	O	0
[line_break_token] - do you make your implementation available?	Review	O	0
[line_break_token] - quite like the clarification of the relationship of your work to that of Eastman et al.	Review	O	0
2018.	Review	B-Review	7
Could you also include discussions to other papers, e.g. Chuai et al.	Review	I-Review	7
2018 Genome Biol and Shi et al.	Review	I-Review	7
2018 SentRNA on arXiv?	Review	I-Review	7
[line_break_token][line_break_token]Altogether the paper reads well, seems to have adequate references, motivates and proposes 3 variations of a new algorithm for a difficult learning problem.	Review	O	0
Not being an expert in the field, I just can't judge about the novelty of the appraoch.	Review	O	0
Thanks for the suggested improvements, the insightful comments and questions!	Reply	O	0
Thanks also for the positive feedback on the text of the paper, references and motivation.	Reply	O	0
In the following we provide detailed replies:[line_break_token][line_break_token][line_break_token]‚Äú1.	Reply	O	0
 What is the star (*) superscript for?	Reply	O	0
Was expecting the length of the RNA sequence instead.	Reply	O	0
‚Äù[line_break_token][line_break_token]--> Thank you for pointing out this undefined and potentially confusing use of notation.	Reply	O	0
The Kleene Operator (*) applied to a set M yields a set of all finite-length sequences based on M, and we used it since RNA Structures have variable length.	Reply	B-Reply	1
But we do agree that this can be confusing and made changes to talk about a specific structure w and then use N^|w| as you suggested.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]‚Äú2.	Reply	O	0
Same on p4, when introducing the notation of your decision process, explicitly introduce all the ingredients.	Reply	O	0
‚Äù[line_break_token][line_break_token]--> We agree with you and revised the definition of the undiscounted decision process.	Reply	O	0
We now explicitly name the components of the quadruple D_w and also refer to the specifics in the paragraphs following the definition of D_w.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token]‚Äú3.	Reply	O	0
in Equation (2) on p4, maybe clarify the notation with '.', '('	Reply	O	0
and ')' for example as the reader could really struggle.	Reply	O	0
‚Äù[line_break_token][line_break_token]--> We have looked at this again and changed the equation, making it easier to parse for the reader.	Reply	O	0
We have also included a verbatim ‚Äúdot‚Äù and ‚Äúopening bracket‚Äù to not confuse the reader by the notation.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token]‚Äú4.	Reply	O	0
I didn't really understand the message in Section 4, not being an expert in the field.	Reply	O	0
Could you clarify your contribution here?‚Äù[line_break_token][line_break_token]--> Thanks for asking about this!	Reply	O	0
As detailed in our general reply to all reviewers, this section breaks novel ground concerning the joint optimization of neural architectures and hyperparameters, joint search over combinations of recurrent and convolutional layers in the same search space, neural architecture search for RL, and neural architecture search for meta-learning.	Reply	B-Reply	3
In the interest of brevity, we refer to the detailed reply to all reviewers above.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]‚Äú5.	Reply	O	0
your 'Ablation study' in Section 5.2; does it correspond to true uncertainty/noise that could be observed in real data?‚Äù[line_break_token][line_break_token]--> In our ablation study, we disable one functional component of our approach at a time in order to study its influence; incorporating ablations in empirically evaluated work is important to find out whether all proposed components are necessary and contribute to the final performance.	Reply	O	0
Our ablation study is performed on the test split of our introduced dataset, which as we point out in the heading of Section 5 of our initial submission, has been generated from sequences observed in living organisms as listed in the Rfam 13.0 database; it is not used to optimize hyperparameters but is a post hoc evaluation.	Reply	B-Reply	4
[line_break_token][line_break_token][line_break_token]‚Äú6.	Reply	O	0
why a new benchmark data set, when there exist good ones to compare your method to, e.g. in competitions like CASP for proteins?‚Äù[line_break_token][line_break_token]--> We report our results on two widely used benchmarks which were also used in the work we compare to but unfortunately only provide test sets (no training/validation/test split).	Reply	O	0
To the best of our knowledge, we introduce the first benchmark with an explicit training/validation/test split.	Reply	B-Reply	5
The reviewer is right in that there exist other and good data sources, but to the best of our knowledge not in the form of competitions.	Reply	I-Reply	5
To mention two databases by name:[line_break_token][line_break_token]* the STRAND database (<a href="http://www.rnasoft.ca/strand/)" target="_blank" rel="nofollow">http://www.rnasoft.ca/strand/)</a> that currently holds 4666 known RNA secondary structures[line_break_token]* the FRABASE 2.0 database (<a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-11-231)" target="_blank" rel="nofollow">https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-11-231)</a> with 2753 entries of fragments of secondary structures[line_break_token][line_break_token]Both databases have not been used by the publications we compare to and cannot satisfy the size and sequence diversity requirements for our meta-learning approach and future research (especially for methods needing a large training set).	Reply	O	0
The Rfam 13.0 database we use here for generating our new training-, validation- and test set is large enough to yield three distinct datasets of meaningful sizes and diversity.	Reply	B-Reply	5
[line_break_token][line_break_token][line_break_token]‚Äú7.	Reply	O	0
do you make your implementation available?‚Äù[line_break_token][line_break_token]--> Thanks for the question, indeed, we strongly believe in sharing code (as well as data) to reproduce scientific findings.	Reply	O	0
To stand by this opinion, we had included a note in the conclusion of our initial submission that we will make all of our code and data available upon acceptance of our paper.	Reply	B-Reply	6
[line_break_token][line_break_token][line_break_token]‚Äú8.	Reply	O	0
quite like the clarification of the relationship of your work to that of Eastman et al.	Reply	O	0
2018.	Reply	O	0
Could you also include discussions to other papers, e.g. Chuai et al.	Reply	O	0
2018 Genome Biol and Shi et al.	Reply	O	0
2018 SentRNA on arXiv‚Äù[line_break_token][line_break_token]--> Thanks for the positive feedback regarding our discussion of the relationship of our work to that of Eastman et al.	Reply	O	0
2018, and for bringing the related work to our attention.	Reply	B-Reply	7
We included discussions in our related work section.	Reply	I-Reply	7
[line_break_token][line_break_token][line_break_token]Thanks again for all your comments!	Reply	O	0
If we cleared up some of your concerns, we would kindly ask you to update your assessment	Reply	O	0

Summary: Train a multilingual NMT system using the technique of Johnson et al (2017), but augment the standard cross-entropy loss with a distillation component based on individual (single-language-pair) teacher models.	Review	O	0
Periodically compare the validation BLEU score of the multilingual model with that of each individual model, and turn off distillation for language pairs where the multilingual model is better.	Review	O	0
On three different corpora (IWSLT, WMT, TED) with into-English translation from numbers of source languages ranging from 6 (WMT) to 44 (TED), this technique outperforms standard distillation for every language pair, and outperforms the individual models for most language pairs.	Review	O	0
Supplementary experiments justify the strategy of selectively turning off distillation, and quantify the effect using only the top 8 vocabulary items in distillation.	Review	O	0
[line_break_token][line_break_token]The main idea makes sense, and the results are very convincing, especially since it appears that hyper-parameters were not tuned extensively (eg, weight of 0.5 on the distillation loss, for all language pairs).	Review	O	0
Implementation should be very straightforward, especially with the trick of pre-computing top-k probabilities from the teacher model at each corpus position.	Review	B-Review	1
One small barrier to practical application that the authors fail to acknowledge is the requirement to train individual models, which will at least double training time compared to a single multilingual model.	Review	I-Review	1
[line_break_token][line_break_token]The main missing experiment is higher-capacity multilingual models, which Johnson et al show to be beneficial in settings with a large number of language pairs.	Review	I-Review	2
Using a multilingual model of the same (relatively small) size as the individual models as is done here is likely to be suboptimal, especially for the 44-language pair TED setting.	Review	I-Review	2
A related point is that the corpora used seem to be quite small (eg 4.5M and 1M sentences for WMT Czech and German, respectively, while the available training corpora are closer to 15M and 4.5M).	Review	I-Review	2
Although performance relative to individual models is still impressive - and seems to be better than than in previous work - this makes the experiments comparing to the multilingual baseline less meaningful.	Review	I-Review	2
[line_break_token][line_break_token]Also missing are experiments on out-of-English translation, which would establish the viability of the proposed technique for many-to-many translation via bridging.	Review	I-Review	3
Out-of-English is a more difficult problem than into-English.	Review	I-Review	3
I can‚Äôt see any reason the proposed technique wouldn‚Äôt also work in this setting, but this remains to be shown.	Review	I-Review	3
[line_break_token][line_break_token]Although it‚Äôs great that the technique is shown to work without embellishments, there are a few obvious strategies it would have been interesting to explore, such as making the weight on the distillation loss dependent on the difference in performance between the multilingual and individual models; and allowing for the distillation loss to be turned back on if the performance of the multilingual model starts to drift back down for a particular language pair.	Review	I-Review	4
I also wondered about the effect of the gradient accumulation strategy in algorithm 1, where individual batches from each language pair are effectively grouped into one giant batch for the purpose of parameter updates.	Review	I-Review	4
I can see that this could stabilize training, but it would be good to know whether it‚Äôs crucial for success, especially when the number of language pairs is large.	Review	I-Review	4
[line_break_token][line_break_token]Further details:[line_break_token][line_break_token]As aforementioned -> As mentioned[line_break_token][line_break_token](1) 2nd line: Doesn't make sense as written.	Review	O	0
You need to distinguish the gold[line_break_token]y_t from hypothesized ones in the 1() function.	Review	B-Review	5
[line_break_token][line_break_token]Above (2): is served as -> serves as[line_break_token][line_break_token]3.2 First paragraph.	Review	O	0
Since D presumably consists of D^l for all languages l,[line_break_token]L_ALL(D,...) should be a function of teacher parameters theta^l for all[line_break_token]languages l rather than just one as written.	Review	B-Review	7
[line_break_token][line_break_token]In top-K distillation, is the teacher distribution renormalized or simply[line_break_token]truncated?	Review	I-Review	8
[line_break_token][line_break_token]Generalization analysis, pg 8: presumably you are sampling from N(0, sigma^2) -[line_break_token]this should be described as such.	Review	I-Review	9
[line_break_token][line_break_token]Reference: [line_break_token][line_break_token]Johnson et al, ‚ÄúGoogle‚Äôs Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation‚Äù TACL, 2017.	Review	O	0
We thank Reviewer 1 for the reviews and comments!	Reply	O	0
Here are our responses to the comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	2
Regarding the training time[line_break_token]The individual models need to be pre-trained, which will incur additional time.	Reply	I-Reply	1
According to the training time statistics on IWSLT dataset with NVIDIA V100 GPU, it takes nearly 4 hours to train the individual model with 1 GPU.	Reply	I-Reply	1
The total GPU time is 4hours *12 GPUs for 12 languages.	Reply	I-Reply	1
The training time for multilingual baseline is nearly 11hours * 4GPUs, while our method is nearly 13 hours*4GPUs.	Reply	I-Reply	1
Our method only takes extra 2hours*4GPUs for the multilingual training and 4 hours*12GPUs for the individual model pretraining.	Reply	I-Reply	1
Furthermore, we can assume the individual models are pre-given, which is reasonable because the production system usually wants to adapt the already trained individual translation models into multilingual model, at the benefit of saving maintenance cost while with no accuracy degradation or even with accuracy improvement, which is exactly the goal of this work.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	2
Regarding higher-capacity multilingual model[line_break_token]We have trained larger models on the Ted talk dataset.	Reply	O	0
Our method still consistently outperforms the multilingual baseline model and the individual models, as shown in the table below, where ‚ñ≥1 means the BLEU score improvements of our method over the individual models, ‚ñ≥2 means the BLEU score improvements of our method over the multi-baseline model.	Reply	B-Reply	2
[line_break_token]----------------------------------------------------------------------------------------------------------------------------------------[line_break_token]Language | ar-en | bg-en | cs-en | da-en | de-en | el-en | es-en | et-en | fa-en | fi-en | frca-en[line_break_token]‚ñ≥1[tab_token]           | 0.14   | -5.39   | 2.13   | 5.04    | 0.39    | 1.66   |0.69    | 8.46   | 0.32   | 6.78  | 16[line_break_token]‚ñ≥2               | 1.73   | 3.27    | 0.1     | 1.11    | 1.54    | 0.23   | 0.31   | 0.34   | 1.52  | 0.21   | 0.34[line_break_token]----------------------------------------------------------------------------------------------------------------------------------------[line_break_token]Language | fr-en  | gl-en | he-en | hi-en  | hr-en  | hu-en| hy-en| id-en | it-en | ja-en  | ka-en[line_break_token]‚ñ≥1[tab_token]           | 0.37   | 19.38 | -0.17   | 10.49  | 1.64    | 0.35   | 9.59   | 1.58   | 0.19  | 0.14   | 11.59[line_break_token]‚ñ≥2               | 0.87  | 0.2      | 1.71    | 0.48    | 0.57    |  0.4    | -0.12  | 0.66   | 1.23  | 0.49   | 0.12[line_break_token]----------------------------------------------------------------------------------------------------------------------------------------[line_break_token]Language | ko-en | ku-en | lt-en | mk-en | my-en | nb-en | nl-en | pl-en | ptbr-en | pt-en | ro-en[line_break_token]‚ñ≥1               | 0.16   | 7.89    | 4.53  | 10.89   | 8.19     | 14.24  | -0.13  | 1.91   | 0.61       | 8.82   | 0.72[line_break_token]‚ñ≥2               | 1.18   | 0.4      | 0.38  | 0.39     | 0.08     | 0.04     | 0.73   | 0.79   | 0.88       | 1.01   | 0.74[line_break_token]----------------------------------------------------------------------------------------------------------------------------------------[line_break_token]Language | ru-en | sk-en | sl-en | sq-en | sr-en | sv-en | th-en | tr-en | uk-en | vi-en | zh-en[line_break_token]‚ñ≥1               | 1.29   | 4.58   | 11.98 | 5.16   | 1.79   | 2.46   | 1.37    | -0.04 | 2.13    | 0.25  | 6.96[line_break_token]‚ñ≥2               | 0.7     | 0.58   | 0.73   | 0.88   | 0.14   | 0.29    | 0.4     | 1.53   | 0.28    | 0.42  | 0.12[line_break_token]----------------------------------------------------------------------------------------------------------------------------------------[line_break_token][line_break_token]3.	Reply	O	0
Regarding corpora size[line_break_token]There is a typo in Table 9 in the appendix.	Reply	O	0
The training data size for WMT16 En-De is 4.5M bilingual sentence pairs, while for En-Cs is 1M bilingual sentence pairs.	Reply	B-Reply	2
We have corrected it in the new version.	Reply	I-Reply	2
We used 1M training data for En-Cs in order to make the training data on all languages roughly the same.	Reply	I-Reply	2

The authors describe a dataset of proof steps in higher order logic derived from a set of proven theorems.	Review	O	0
The success of methods like AlphaGo suggests that for hard combinatorial style problems, having a curated set of expert data (in this case the sequence of subproofs) is a good launching point for possibly super-human performance.	Review	O	0
Super-human ATPs are clearly extremely valuable.	Review	O	0
Although relatively smaller than the original Go datasets, this dataset seems to be a great first step.	Review	B-Review	1
Unfortunately, the ATP and HOL aspect of this work is not my area of expertise.	Review	I-Review	1
I can't comment on the quality of this aspect.	Review	I-Review	1
[line_break_token][line_break_token]It would be great to see future work scale up the baselines and integrate the networks into state of the art ATPs.	Review	I-Review	1
The capacity of deep learning methods to scale and take advantage of larger datasets means there's a possibility of an iterative approach to improving ATPs: as the ATPs get stronger they may generate more data in the form of new theorems.	Review	I-Review	1
This may be a long way off, but the possibility is exciting.	Review	I-Review	1
We thank the reviewer for the insightful comments.	Reply	O	0
[line_break_token][line_break_token]Indeed the dataset is smaller than that of AlphaGo, as it has been created as a benchmark for machine learning technologies applied to higher-order logic.	Reply	B-Reply	1
The proposed approach can be directly applied to other HOL proof corpora to create a much larger training dataset, which can be used to practically guide ATPs.	Reply	I-Reply	1
We imagine that already with the current accuracy integrating the prediction of usefulness of a statement could help modern ATPs.	Reply	I-Reply	1
And the difference could become more signigicant with further improvements to the proposed baselines.	Reply	I-Reply	1

The authors investigate the problem of training compact pre-trained language model via distillation.	Review	O	0
Their method consists of three steps: [line_break_token]1.	Review	O	0
pre-train the compact model LM[line_break_token]2.	Review	O	0
distill the compact model LM with a larger model (teacher)[line_break_token]3.	Review	O	0
fine-tune the compact model on target task [line_break_token][line_break_token]This idea is not significantly new since it is quite common to apply distillation to compress models, and the results are largely empirical.	Review	O	0
From Table 3 the results on test sets are better than previous works, but not by much.	Review	B-Review	1
The authors spend quite a of space on ablation studies to investigate the contribution of different factors, and on cross-domain transfers.	Review	I-Review	1
They do manage to show that using a teacher for distilling a compact student model does better than directly pre-training a compact model on the NLI* task in section 6.3.	Review	I-Review	1
It would be better if they could show it for other tasks on the benchmark as well.	Review	I-Review	1
[line_break_token][line_break_token]Overall I think this work is somewhat incremental, and falls below the acceptance threshold.	Review	O	0
[line_break_token]	Review	O	0
e believe the reviewer has misunderstood the contribution of the paper: our work does not present technical novelty, but an empirical demonstration that there has been significant overclaiming in the area where pre-training and distillation interact.	Reply	O	0
In particular, multiple papers have advocated for highly restrictive yet complex strategies when more general, simpler baselines shown in our paper are just as effective.	Reply	B-Reply	1
[line_break_token][line_break_token]We argue that the ubiquity of distillation is not a strong enough reason to reject a paper that merely uses it as a tool.	Reply	I-Reply	1
We do not claim novelty for using distillation in the context of building compact models, but rather investigate its interaction with pre-training.	Reply	I-Reply	1
It was not clear a priori that a student with access to a powerful pre-trained teacher can (somewhat redundantly) benefit from its own pre-training.	Reply	I-Reply	1
Prior cited studies initialize their model by truncating taller models, without questioning whether pre-training is necessary, or whether truncation is the best strategy for pre-training.	Reply	I-Reply	1
Our in-depth ablation studies fill this void in the literature.	Reply	I-Reply	1
Indeed, the results are empirical, not unlike the majority of neural network research.	Reply	I-Reply	1

The paper takes seriously the question of having a robotic system learning continuously without manual reset nor state or reward engineering.	Review	O	0
The authors propose a first approach using vison-based SAC, shown visual goals and VICE, and show that it does not provide a satisfactory solution.	Review	O	0
Then they add a random pertubation controller which brings the robot or simulated system away from the goal and a VAE to encode a compressed state, and show that it works better.	Review	O	0
[line_break_token][line_break_token]The paper is a nice read, it contains useful messages thus I'm slightly in favor of accepting it, but I may easily change my mind as it suffers from serious weaknesses.	Review	O	0
[line_break_token][line_break_token]First, and most importantly, the experimental study is very short, the authors have chosen to spend much more space on careful writing of the problem they are investigating.	Review	O	0
[line_break_token][line_break_token]To mention a few experimental weaknesses, in Section 6.2 the authors could have performed much more detailed ablation studies and stress in more details the impact of using the VAE alone versus using the random pertubation controller alone, they could say more about the goals they show to the system, etc.	Review	O	0
There is some information in Figure 7, but this information is not exploited in a detailed way.	Review	B-Review	1
Furthermore, Figure 7 is far to small, it is hard to say from the legend which system is which.	Review	I-Review	1
[line_break_token][line_break_token]About Fig.8, we just have a qualitative description, the authors claim that without instrumenting they cannot provide a quantitative study, which I don't find convincing: you may instrument for the sake of science (to measure the value of what you are doing, even if the real-world system won't use this instrumentation).	Review	I-Review	2
[line_break_token][line_break_token]So the authors have chosen to spend more space on the positionning than on the empirical study, which may speak in favor of sending this paper to a journal or magazine rather than a technical conference.	Review	O	0
But there is an issue about the positionning too: the authors fail to mention a huge body of literature trying to address very close or just similar questions.	Review	B-Review	5
Namely, their concern is one the central leitmotives of Developmental Robotics and some of its "subfields", such as Lifelong learning, Open-ended learning, Continual learning etc.	Review	I-Review	5
 The merit of the paper in this respect is to focus on a specific question and provide concrete results on this question, but this work should be positionned with respect to the broader approaches mentioned above.	Review	I-Review	5
The authors will easily find plenty of references in these domains, I don't want to give my favorite selection here.	Review	I-Review	5
[line_break_token][line_break_token]Knowing more about the literature mentioned above, the authors could reconsider their framework from a multitask learning perspective: instead of a random perturbation controller, the agent may learn various controllers to bring the system into various goal states (using e.g. goal-conditioned policies), and switching from goal to goal to prevent the system fro keeping stuck close to some goal.	Review	I-Review	6
[line_break_token][line_break_token]More local points:[line_break_token][line_break_token]In the middle of page 5, it is said that the system does not learn properly just because it is stuck at the goal.	Review	O	0
This information comes late, and makes the global message weaker.	Review	B-Review	7
[line_break_token][line_break_token]in Fig.	Review	I-Review	3
4, I would like to know what is the threshold for success.	Review	I-Review	3
[line_break_token][line_break_token]	Review	O	0
e thank the reviewer for their detailed, insightful and constructive feedback!	Reply	O	0
We acknowledge a number of clarity issues in the presentation and positioning of our results, which make the actual results somewhat hard to understand.	Reply	O	0
We have updated the paper to make several of the points much more clear and have run additional hardware experiments to address the points raised in the review, as described in detail below: [line_break_token][line_break_token]‚Äúthey could say more about the goals they show to the system, etc.	Reply	O	0
‚Äù[line_break_token]-&gt; We have added some visualizations about goals provided to the system to Appendix C. [line_break_token][line_break_token]‚Äúyou may instrument for the sake of science (to measure the value of what you are doing, even if the real-world system won't use this instrumentation).‚Äù [line_break_token]-&gt; Yes, this is a good point!	Reply	O	0
We have now performed these experiments on the hardware and have included additional comparisons to baselines on hardware in Section 6.3, Fig 8.	Reply	B-Reply	2
We find that the same trends observed in simulation hold on the hardware as well.	Reply	I-Reply	2
[line_break_token][line_break_token]‚ÄúIn Fig.	Reply	O	0
4, I would like to know what is the threshold for success.	Reply	O	0
‚Äù[line_break_token]-&gt; Fig.	Reply	O	0
4 analyzes the sample complexity for the task of valve rotation.	Reply	B-Reply	3
The experiment is considered successful when the learned policy achieves average training performance of less than 0.15 in pose distance (defined in Appendix C.1.3) across 3 seeds.	Reply	I-Reply	3
Fig.	Reply	I-Reply	3
4 has now been updated to clarify this.	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúIn Section 6.2 the authors could have performed much more detailed ablation studies and stress in more details the impact of using the VAE alone versus using the random perturbation controller alone‚Äù[line_break_token]-&gt; We have modified the Figure 7 legend and caption to make it more legible, and a discussion on the effects of the individual components based on these ablation experiments is now included in Section 6.2 in the updated manuscript.	Reply	O	0
We have also updated the results after removing a small visual artifact in the environment, which allows the baselines to perform a bit better, but still maintains the same trends.	Reply	B-Reply	4
We agree that the presentation of data in Figure 7 was hard to parse, and many of the comparisons (including the two requested by the reviewer) that we did actually already perform were hard to discern from the figure.	Reply	I-Reply	4
The methods marked [VAE + VICE] and [RND + VICE] show the performance curves corresponding to the ablations suggested.	Reply	I-Reply	4
A discussion on comparisons to explicit goal-based reset mechanisms and goal-conditioned policies has also been added to Section 6.2.	Reply	I-Reply	4
[line_break_token][line_break_token]‚Äúthere is an issue about the positioning too: the authors fail to mention a huge body of literature trying to address very close or just similar questions...central motives of Developmental Robotics and some of its "subfields" [line_break_token]-&gt; We have expanded our related work with appropriate discussion with respect to the field of developmental robotics.	Reply	O	0
The goal of our work is to enable reinforcement learning systems to handle the practicalities of learning in the real world without human instrumentation or interruption, even for a single task setting, without multi-task considerations.	Reply	B-Reply	5
The insights we make should also be applicable for developmental robotics algorithms!	Reply	I-Reply	5
Though our investigation doesn‚Äôt touch on all aspects of developmental robotics such as lifelong learning, open-ended learning, psychology, cognition etc.,	Reply	I-Reply	5
our proposed work R3L does bear strong relationship with respect to continual learning, intrinsic motivation, perceptual development, and sensory-motor development involving proprioceptive manipulation.	Reply	I-Reply	5
We thank the reviewer for bringing out this interesting connection, and have added appropriate citations in the text.	Reply	I-Reply	5
[line_break_token][line_break_token]‚Äúauthors could reconsider their framework from a multitask learning perspective...agent may learn various controllers to bring the system into various goal states and switching from goal to goal to prevent the system for keeping stuck close to some goal.	Reply	O	0
‚Äù[line_break_token]-&gt; We agree that this is indeed an interesting and valuable perspective on this problem, and we have added some discussion of this to Section 6.2.	Reply	O	0
We found in our experimental study that when we consider the case of using 2 goals, and switching between them (the Eysenbach et al comparison in Fig 7), it was not as effective and robust as using the perturbation controller.	Reply	B-Reply	6
While this scheme chooses between only 2 goal options, and a more involved scheme could be chosen to pick multiple different goals, the performance of such an algorithm is dependent on the specific choice of goals.	Reply	I-Reply	6
We find that the simpler solution via the perturbation controller can be very effective without the need for multiple meaningful alternative goals to be specified, although a better algorithm for self-supervised multi-goal selection is an interesting avenue for future work.	Reply	I-Reply	6

[line_break_token][line_break_token]###Summary###[line_break_token][line_break_token]This paper tackles the transfer learning problem with the double-blind unsupervised domain adaptation, where either the source or the target domain cannot observe the data in the other domain, but data from both domains are used for training.	Review	O	0
The high-level intuition of this paper is based on the observation that in some practical settings, the transferring source data to the target domain is restricted due to the privacy policy.	Review	O	0
The goal is to learn a classifier which performs well in target classification task under double-blind constraint.	Review	O	0
[line_break_token][line_break_token]The setting of this paper is slightly different from the conventional domain adaptation.	Review	O	0
In this paper, the source domain has abundant unlabeled data and a small number of labeled data.	Review	O	0
The target domain only contains a limited number of unlabeled data.	Review	O	0
[line_break_token][line_break_token]The paper proposes a transfer alignment network (TAN) which comprises two autoencoders, one trained on the source domain and one trained on the target domain.	Review	O	0
In the domain adaptation phase, the model leverages an aligner to transfer the output of the target encoder to an aligned latent variable.	Review	O	0
 The aligner is trained to map the target code to source code on the target unlabeled data.	Review	O	0
The objective function is L2 distance between the source code and the mapped target code.	Review	O	0
[line_break_token][line_break_token]The whole pipeline is trained with four steps:[line_break_token]1) The source encoder and source decoder are trained with L2 reconstruction loss.	Review	O	0
[line_break_token]2) The source encoder and source classifier are trained with cross-entropy classification loss.	Review	O	0
[line_break_token]3) The target encoder and target decoder are trained with L2 reconstruction loss.	Review	O	0
[line_break_token]4) Train the aligner to map target code to source code on target unlabeled data with L2 distance loss.	Review	O	0
[line_break_token][line_break_token]The paper proposes to compare the TAN with three baselines: S(UL):  a stack of encoder and a neural network classifier trained using source data and tested on target data without finetuning.	Review	O	0
S(UL)-T(U): a model retrains the S(UL) with the target unlabeled data.	Review	O	0
S(UL)-T(U)-Large: a model which is similar to S(UL)-T(U) but contains more layers and parameters in MLP.	Review	O	0
[line_break_token][line_break_token]The experiments are performed on five multivariate datasets: HIGGS, HEPMASS, SUSY, Sensorless, and Gas.	Review	O	0
[line_break_token][line_break_token][line_break_token]### Novelty ###[line_break_token][line_break_token]The experimental setting proposed in this paper is interesting.	Review	O	0
However, the proposed model is trivial.	Review	B-Review	1
The TAN model is composed of autoencoders and aligner.	Review	I-Review	1
The training losses in the framework are L2 reconstruction loss and L2 distance loss.	Review	I-Review	1
Thus, the novelty of this paper is incremental.	Review	I-Review	1
[line_break_token][line_break_token]The experimental results in this paper are weak.	Review	I-Review	2
First of all, the datasets used in this paper are not standard benchmarks.	Review	I-Review	2
Secondly, the baselines in this paper are too trivial.	Review	I-Review	3
  [line_break_token][line_break_token][line_break_token]###Clarity###[line_break_token][line_break_token]Overall, the paper is well organized and logically clear.	Review	O	0
The images are well-presented and well-explained by the captions and the text.	Review	O	0
[line_break_token][line_break_token]###Pros###[line_break_token][line_break_token]1) The paper proposes an interesting transfer learning framework where either the source or the target domain cannot observe the data in the other domain.	Review	O	0
[line_break_token][line_break_token]2) The paper is applicable to many practical scenarios since the data privacy in the real-world application is critical.	Review	O	0
[line_break_token][line_break_token]3) The paper is overall well-organized.	Review	O	0
The claims of the paper are verified by the experimental results.	Review	O	0
[line_break_token][line_break_token]###Cons###[line_break_token][line_break_token]1) The paper proposes double-blind unsupervised domain adaptation as accessing the source and target domains is restricted in some practical settings.	Review	O	0
However, the source and target domain share the models trained on themselves, as well as the features extracted from the source domain and target domain data.	Review	B-Review	4
The information about the original data can be recovered with the shared features and weights, which violates the settings proposed in this paper.	Review	I-Review	4
[line_break_token][line_break_token]2) The main issue of this paper is the novelty is incremental.	Review	O	0
The proposed model is trivial as it only contains the auto-encoders and L2 loss.	Review	B-Review	1
[line_break_token][line_break_token]3) The experimental part of this paper is weak.	Review	O	0
The datasets used in this paper are not the standard domain adaptation benchmark.	Review	B-Review	2
It would be nice to see how does the proposed model work on standard domain adaptation benchmarks such as Office31, VisDA, Office-Home, DomainNet, etc.	Review	I-Review	2
[line_break_token][line_break_token]VisDA: The Visual Domain Adaptation Challenge[line_break_token]<a href="https://arxiv.org/pdf/1710.06924.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1710.06924.pdf</a>[line_break_token]Office-Home : Deep Hashing Network for Unsupervised Domain Adaptation[line_break_token]<a href="http://hemanthdv.org/OfficeHome-Dataset/" target="_blank" rel="nofollow">http://hemanthdv.org/OfficeHome-Dataset/</a>[line_break_token][line_break_token]The baselines used in this paper is also trivial.	Review	O	0
It is desirable to compare the proposed method with state-of-the-art domain adaptation methods.	Review	B-Review	3
[line_break_token][line_break_token]Based on the summary, cons, and pros, the current rating I am giving now is "reject".	Review	O	0
I would like to discuss the final rating with other reviewers, ACs.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
e thank the reviewer for the careful reading of the paper and their constructive comments.	Reply	O	0
We would like to answer the reviewer‚Äôs questions as follows:[line_break_token][line_break_token]1.	Reply	O	0
Problem setting[line_break_token]Our goal is to improve the performance of the target task by transferring only the trained source model.	Reply	O	0
Our definition of blind setting refers to not seeing the data.	Reply	B-Reply	4
Of course, if we cannot see the model, there should not be anything to transfer.	Reply	I-Reply	4
Transferring only model limits the leakage of privacy.	Reply	I-Reply	4
[line_break_token][line_break_token]2.	Reply	O	0
Novelty[line_break_token]We proposed the unsupervised domain adaptation under the double blind setting, which is a challenging problem as it is difficult to train a target classifier properly only with the transferred source model.	Reply	O	0
The setting is directly applicable to real-world settings due to privacy issues.	Reply	B-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
Datasets[line_break_token]In this paper, we focused on experimenting with multivariate data.	Reply	O	0
However, domain adaptation benchmarks have more complex data manifolds than multivariate data.	Reply	B-Reply	2
It seems that a more complex architecture is needed to train domain adaptation benchmarks and we leave it as a future work.	Reply	I-Reply	2
[line_break_token][line_break_token]4.	Reply	O	0
Competitors[line_break_token]We proposed the unsupervised domain adaptation under the double blind setting, where the source and target data cannot be visible in the training process simultaneously.	Reply	O	0
Differently from our setting, the state-of-the-art unsupervised domain adaptation methods, e.g. MMD and DANN, train the model by feeding in the source and target data together.	Reply	B-Reply	3
Thus, those existing methods cannot be used for baselines.	Reply	I-Reply	3

This paper proposes a hybrid machine learning algorithm using Gradient Boosted Decision Trees (GBDT) and Deep Neural Networks (DNN).	Review	O	0
The intended research direction on tabular data is essential and promising.	Review	O	0
However, the proposed technique does not seem to be handling the problem foundationally well.	Review	O	0
It seems heavily dependent on GBDT.	Review	O	0
It also shows itself in the results that final algorithm is almost indistinguishable from GBDT regarding results.	Review	O	0
Moreover, I  don't think that the data sets in experiments are good enough to cover the importance and the nature of the problem.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]-This is a crucial line of research direction that aims to make DNNs applicable to many real-world problems (beyond speech and vision) in which discrete data and heterogeneous features exist such as engagement prediction, recommendation, and search.	Review	O	0
 [line_break_token]-The starting point of using GBDT seems like a good choice.	Review	O	0
[line_break_token]-The Paper is mostly well written except occasional repetitions and missing acronym definitions.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]-The proposed technique does not seem to be original enough, and it does not handle the problem foundationally well.	Review	O	0
I do not think that there is enough justification/demonstration for the fact that a general NN solution for Tabular Data invented.	Review	B-Review	1
The proposed technique is heavily dependent on GBDT (Indeed the algorithm and the learned trees are used at least three times).	Review	I-Review	1
This shows itself in the results; i.e., the proposed algorithm is either negligibly performing better than GBDT or when  GBDT dependence removed, it performs worse.	Review	I-Review	1
It seems to me that (except the minor small section of streaming data), the paper is more like a proper verification of how tree-based learning algorithms work very well in tabular data--which is far from the basis of the paper and does not make the paper novel enough for ICLR.	Review	I-Review	1
  [line_break_token]-The proposed technique seems to include very heavy feature engineering and several ad-hoc practical steps--that is far from the motivation of using NN in tabular data.	Review	O	0
[line_break_token]-In the provided benchmark data sets the depth of the analysis seems to be enough.	Review	O	0
However, in the proposed domain of tabular data, often data sets are significantly more high dimensional in reality and include at least one set of sparse large dimensional features  (e.g., unstructured raw text for the search queries.)	Review	B-Review	3
In such scenarios, it had been showed that wide-and-deep NNs perform decently.	Review	I-Review	3
However such problems are entirely missing in the results section.	Review	I-Review	3
I also think that this is a lost opportunity for the authors as they could be showing that it is the NN part contributing.	Review	I-Review	3
[line_break_token]Thanks for your efforts in reviewing our paper and the valuable comments, but we have different opinions about your comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Comments about the contributions and novelty[line_break_token][line_break_token]As we emphasized many times in our paper, the success of DNN in domains such as image, speech and text, is built on the comprehensive exploration of the locality-based patterns, which motivates us to first find such patterns of features in tabular data automatically and then build up NN architecture based on these discovered patterns.	Reply	O	0
This is the core idea of this paper.	Reply	B-Reply	1
Thus, GBDT is just a tool we adopt to mine the patterns and do feature grouping since GBDT is an efficient and convenient method for these pre-processing tasks: 1) GBDT is very fast.	Reply	I-Reply	1
In most experiments, the total time cost of GBDT part in TabNN is about several minutes, while the NN part often needs several hours for training.	Reply	I-Reply	1
2) the learning of GBDT is just based on statistical information over full dataset.	Reply	I-Reply	1
Thus, GBDT can learn the stable and robust feature combinations.	Reply	I-Reply	1
[line_break_token]We can definitively replace GBDT with other methods, such as feature correlations, as long as they can achieve better performance then GBDT.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the comments asking for the comparison with GBDT, we consider that they are not comparable since we are not inventing a model to beat GBDT, instead, we are developing a model to cover the scenarios not suitable for GBDT such as some applications need online updating.	Reply	I-Reply	1
This point has also been emphasized in our paper.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
Heavy feature engineering and ad-hoc practical steps[line_break_token][line_break_token]We are not sure why you conclude this point.	Reply	O	0
TabNN is a fully end-to-end learning approach with no need of an extra feature engineering step.	Reply	B-Reply	2
[line_break_token]And as stated in the paper, the design of TabNN follows two principles: \emph{to explicitly leverages expressive feature combinations} and \emph{to reduce model complexity}. We cannot agree there are ad-hoc parts in the proposed model.	Reply	I-Reply	2
Could you explain this with more details?	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]3.	Reply	O	0
Benchmark Dataset and Compared with Deep and Wide (D&W) NNs[line_break_token][line_break_token]As stated in Section 2, D&W NNs and many related models can work well with high dimensional sparse features, which are usually in the form of one-hot encoding converted from categorical features.	Reply	O	0
Actually, these NNs perform very well in such datasets, even better than GBDT.	Reply	B-Reply	3
[line_break_token][line_break_token]In contrast, the proposed TabNN works better on another kinds of tabular data, with numerical features and low-cardinality categorical features.	Reply	I-Reply	3
Since there are many dummy dimensions in one-hot encoding, TabNN is hard to learn the useful features combinations from them.	Reply	I-Reply	3
[line_break_token][line_break_token]Therefore, TabNN and D&W NNs are orthogonal with each other.	Reply	O	0
We can use them independently according to the feature types of data.	Reply	B-Reply	3
And they can be used together for the data with mixed feature types.	Reply	I-Reply	3
[line_break_token][line_break_token]Therefore, we did not conduct any experiment on data with high-cardinality categorical features.	Reply	I-Reply	3
We will state this clearer in the paper	Reply	I-Reply	3

The paper argues that the widest minimum in the loss landscape is not the best in terms of generalization.	Review	O	0
The authors provide theoretical arguments and claim that there exists an optimal width beyond which generalization can be poor.	Review	O	0
Synthetic simulations are presented to support these claims.	Review	O	0
[line_break_token][line_break_token]The authors employ Fisher Information to characterize the optimal width or the curvature around the minimum.	Review	O	0
The fact that the determinant of the Fisher Information Matrix is invariant to parametrization, under certain conditions, serves as the motivation to design an objective Bayesian prior called Jeffrey's prior.	Review	O	0
[line_break_token][line_break_token]The motivation and the theoretical arguments are interesting, but the paper lacks in presentation and sufficient empirical evidence is also lacking to get fully convinced by the claims.	Review	B-Review	1
[line_break_token][line_break_token]The authors should discuss the architecture design choices used for the synthetic data-generating model.	Review	I-Review	2
Why are the last 3 layers of the larger model comprise of linear mappings?	Review	I-Review	3
[line_break_token][line_break_token]Fig 1 is not clear.	Review	I-Review	4
What does n=23 signify in the caption?	Review	I-Review	4
More discussion is needed to describe "intersection of the likelihood values", "Difference in update Step" and "density is placed around 0" in section 5.	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]	Review	O	0
e thank the reviewer for their constructive feedback.	Reply	O	0
[line_break_token][line_break_token]Q1) The authors should discuss the architecture design choices used for the synthetic data-generating model.	Reply	O	0
[line_break_token][line_break_token]A1) In light of the requests of Reviewer #3 we have updated our experimental procedure to be more general and utilize larger networks with more variance in their design.	Reply	O	0
Please see the general comment on our updated experimental procedure above, titled "General Comment on Updated Experimental Procedure", as this was also raised by another reviewer.	Reply	B-Reply	2
We will be more explicit about our design choices in the updated version of the paper and agree that this requires more discussion.	Reply	I-Reply	2
Our aim, however, with the generating model was to create a complicated function for the training network to model.	Reply	I-Reply	2
As a result we began with non-linear sigmoidal layers to create a complex function.	Reply	I-Reply	2
The linear layer in the output on the generating model was then used to obtain the scalar output for the regression task.	Reply	I-Reply	2
In our updated experimental procedure we utilize more general and larger generating networks.	Reply	I-Reply	2
We also discuss this aspect in the general comment on our updated experimental procedure.	Reply	I-Reply	2
[line_break_token][line_break_token]Q2) Why are the last 3 layers of the larger model comprise of linear mappings?	Reply	O	0
[line_break_token][line_break_token]A1) This was merely to over-parametrize the model.	Reply	O	0
Naturally any consecutive linear layers can equally be compressed into a single layer, however, the addition of more linear layers does increase the expressive power of the model and aids in overfitting.	Reply	B-Reply	3
The impact of this design decision on the loss landscape is evident in the work on alpha-scaling [1] in which it is shown that by placing more weight on one layer of linear parameters while proportionally decreasing the weight on the following linear layer it is possible to move to an area in the landscape with different width but without changing the model behaviour.	Reply	I-Reply	3
This is a direct result of the linear layers being over-parametrized and when parameter weight is spread over more linear layers wider landscapes will occur.	Reply	I-Reply	3
In line with our work, we believe the wider areas to overfit more and, thus, the inclusion of more linear layers will help enforce that the training network overfits the training data.	Reply	I-Reply	3
[line_break_token][line_break_token]Q3) Fig 1 is not clear.	Reply	O	0
What does n=23 signify in the caption?	Reply	O	0
[line_break_token][line_break_token]A3) n represents the number of datapoints, separate trainings run, in generating the figure.	Reply	O	0
We will include this in the caption.	Reply	B-Reply	4
[line_break_token][line_break_token]Q4) More discussion is needed to describe "intersection of the likelihood values", "Difference in update Step" and "density is placed around 0" in section 5.	Reply	O	0
[line_break_token][line_break_token]A4) Thank you for pointing this out.	Reply	O	0
We will expand on these points in the paper.	Reply	B-Reply	5
We have elaborated on these points in another general comment above: "General Comment on Previous Experimental Procedure".	Reply	I-Reply	5
In summary, however, we use the phrase "intersection of the likelihood values" to express the point at which the training network has the same error as the true data generating network on the noisy training data.	Reply	I-Reply	5
We believe this to be the point at which the Jeffreys Prior parametrization is found in the loss landscape.	Reply	I-Reply	5
To test our assertion that the Jeffreys Prior parametrization provides the optimal test performance we observe the number of parameter updates between where the Jeffreys Prior parametrization is found and where the minimum test error is found.	Reply	I-Reply	5
We referred to this as the "Difference in update step".	Reply	I-Reply	5
We then plot a histogram and kernel-density estimation (KDE) of the difference in update step from repeated trainings.	Reply	I-Reply	5
We found a significant portion of the KDE was situated around the difference in update step of and said that "the density is placed around 0".	Reply	I-Reply	5
[line_break_token][line_break_token][1] Dinh, Laurent, et al. "	Reply	O	0
Sharp minima can generalize for deep nets."	Reply	O	0
Proceedings of the 34th International Conference on Machine Learning-Volume 70.	Reply	O	0
JMLR.	Reply	O	0
org, 2017	Reply	O	0

This paper presents a classification method when the data consists of few clean labels and many noisy labels.	Review	O	0
The authors propose to construct a graph structure within each class and use graph convolutional network to determine the clean/noisy labels of samples in each class.	Review	O	0
The model is based on a binary cross entropy loss function in each class, which learns the probability of labels to be clean.	Review	O	0
And such "clean" probability is used as the measure of relevance score between the sample different classes.	Review	O	0
[line_break_token][line_break_token]The idea of this paper is straightforward and the experimental results seem promising.	Review	O	0
The authors compare with several related methods and show the proposed method has better performance in few shot learning experiments.	Review	O	0
[line_break_token][line_break_token]For the motivation of this methods, why would the graph be constructed within each class?	Review	B-Review	1
If there is correlation between different classes, how could the model use such class-wise correlation to clean the label?	Review	I-Review	1
[line_break_token][line_break_token]Maybe I missed it, but how is the relevance score / predicted label determined for testing data given the graphs constructed in each class of training data?	Review	I-Review	2
e would like to thank the reviewer for the positive feedback.	Reply	O	0
We reply to the the two questions below.	Reply	O	0
[line_break_token][line_break_token]Q1: For the motivation of this method, why would the graph be constructed within each class?	Reply	O	0
If there is a correlation between different classes, how could the model use such class-wise correlation to clean the label?	Reply	O	0
[line_break_token][line_break_token]R1: The most general graph would be constructed based on image and text similarities combined.	Reply	O	0
Here, we pre-filter with text similarity, i.e., label names, and then build the graph based on visual similarities.	Reply	B-Reply	1
This permits (a) to significantly reduce the size of the graph and hence the complexity and (b) to reduce the noise during the cleaning task.	Reply	I-Reply	1
We agree that operating on the more complex graph could be the subject of future research, but a significantly different method would be required and the gain of the correlation is not granted.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Q2: Maybe I missed it, but how is the relevance score / predicted label determined for testing data given the graphs constructed in each class of training data?	Reply	O	0
[line_break_token][line_break_token]R2: There is no relevance score assigned to the test data.	Reply	O	0
Relevance scores are only used during training.	Reply	B-Reply	2
In particular, we build per-class graphs using the training data, assign each training example a relevance score (Section 4), and train a classifier using the training data and the corresponding relevance scores (Section 5).	Reply	I-Reply	2
Now given a test image, a prediction is simply made by the classifier; no data or relevance scores are used.	Reply	I-Reply	2
See also pseudo-code in response R1 to reviewer 3.	Reply	I-Reply	2

Summary: This paper proposes the concept of buffer zones and suggests to use unanimous voting as a way to induce such buffer zones.	Review	O	0
To widen the buffer zone, they further propose to diversity the model.	Review	O	0
They then proposed a new metric for measuring defense and demonstrated that their method is effective.	Review	O	0
[line_break_token][line_break_token]Decision: Weak Reject.	Review	O	0
This paper is fairly intuitive, but I am not sure about the fairness of the comparisons in the paper, and the level of rigor of the experiments.	Review	B-Review	1
[line_break_token][line_break_token]I think the conjecture that buffer zones are widened when the models are diverse deserve to be empirically tested.	Review	I-Review	2
It is not clear to me a prior how exactly the buffer zones widen (even though the belief that they widen is intuitively appealing).	Review	I-Review	2
I think one way to potentially characterize the buffer zone is by actually performing white-box attack experiments comparing:[line_break_token]White-box attack vulnerability of unanimous voting vanilla models[line_break_token]White-box attack vulnerability of unanimous voting ‚Äúdiversified‚Äù models[line_break_token]I would also encourage the authors to think creatively about other ways to back up the the buffer zone claims put forth in the paper.	Review	I-Review	2
[line_break_token][line_break_token]I am also a little puzzled with the authors‚Äô choice of the diversification procedure.	Review	I-Review	3
The procedure c(x) = Ax + b will only linearly transform each column of the image, but not each row.	Review	I-Review	3
This design choice feels rather ad hoc.	Review	I-Review	3
Why did the authors settle on Ax + b in particular?	Review	I-Review	3
Why not xA + b?	Review	I-Review	3
Or AxC + b?	Review	I-Review	3
[line_break_token][line_break_token]Regarding the fairness of the experiments, do the models that the authors compare against have the luxury of returning a ‚ÄúUndecided‚Äù label?	Review	I-Review	4
If not, then the problem formulation is fundamentally different, and I do not think the comparisons are necessarily fair.	Review	I-Review	4
Are there any papers out there that also allow for an ‚ÄúUndecided‚Äù label?	Review	I-Review	4
If so, they should be the baselines that one compares against.	Review	I-Review	4
I have a rather hard time believing that this is the first paper to try unanimous voting across an ensemble.	Review	I-Review	4
[line_break_token][line_break_token]I am generally inclined to switch to weak accept so long as the other reviewers are willing to accept that the experiments are sufficient and the comparisons are fair.	Review	O	0
I am not opposed to the new problem setting, since I think the setting makes sense.	Review	O	0
I just want to know that the paper is doing due diligence regarding related work in this setting.	Review	O	0
hank you for your comments.	Reply	O	0
Here are our detailed responses.	Reply	O	0
[line_break_token][line_break_token]This paper is fairly intuitive, but I am not sure about the fairness of the comparisons in the paper, and the level of rigor of the experiments.	Reply	O	0
[line_break_token][line_break_token]Ans: in our experiments, we implemented or studied many known defenses and black box attacks on them for  a fair and rigorous comparison (see Table 1) and appendix for related work and experiment.	Reply	O	0
[line_break_token][line_break_token]In experiment, we considered C&amp;W attack and we found that it is not as good as FGSM.	Reply	O	0
Hence, we skip the experiment for C&amp;W.  We also explained why zeroth order black box attack (which is very similar to SimBA) does not work for our defense.	Reply	O	0
  It means we did consider many common attacks for our defense.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token]‚ÄúI think the conjecture that buffer zones are widened when the models are diverse deserve to be empirically tested.	Reply	O	0
It is not clear to me a prior how exactly the buffer zones widen (even though the belief that they widen is intuitively appealing).	Reply	O	0
I think one way to potentially characterize the buffer zone is by actually performing white-box attack experiments comparing:[line_break_token][line_break_token]White-box attack vulnerability of unanimous voting vanilla models[line_break_token][line_break_token]White-box attack vulnerability of unanimous voting ‚Äúdiversified‚Äù models[line_break_token][line_break_token]I would also encourage the authors to think creatively about other ways to back up the the buffer zone claims put forth in the paper.	Reply	O	0
‚Äù[line_break_token][line_break_token][line_break_token]Answer: While we agree with the author that more empirical evidence can be shown for our concept, the fact that increasing the number of networks (equivalent in some sense to increasing the size of the buffer zone) yields less successful adversarial samples that fool the defense (as shown in every experiment we conducted), strongly validates our buffer zone claim.	Reply	O	0
[line_break_token][line_break_token][line_break_token]‚ÄúI am also a little puzzled with the authors‚Äô choice of the diversification procedure.	Reply	O	0
The procedure c(x) = Ax + b will only linearly transform each column of the image, but not each row.	Reply	O	0
This design choice feels rather ad hoc.	Reply	O	0
Why did the authors settle on Ax + b in particular?	Reply	O	0
Why not xA + b?	Reply	O	0
Or AxC + b?‚Äù[line_break_token][line_break_token]Answer: This is done mainly for technical implementation reasons.	Reply	O	0
We make our input X 1D (so that the A and b can be directly implemented as a linear non-learnable layer in a convolutional neural network).	Reply	B-Reply	3
While other combinations are certainly possible, the goal of this paper is not to exhaustively explore every possible defense combination.	Reply	I-Reply	3
Indeed, one could think of a multitude of different ways a transformation could be implemented within a network.	Reply	I-Reply	3
For example, why do we put the transformation at the start instead of the middle of the network?	Reply	I-Reply	3
Why do we use a linear transformation instead of applying non-linear activations in addition to the linear matrix multiplication?	Reply	I-Reply	3
Why use one matrix A instead of multiple matrices?	Reply	I-Reply	3
While these types of questions are all valid, they actually don‚Äôt truly consider the aim of the paper.	Reply	I-Reply	3
The goal of this paper is to provide at least ONE possible concrete secure defense that has strong experimental evidence to back up its security claims.	Reply	I-Reply	3
As long as we have one work defense framework (as given in this paper) the open problem of securing neural networks against black-box style attacks is solved.	Reply	I-Reply	3
Other extensions (based on the working defense presented in this paper) can be considered as future work.	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúRegarding the fairness of the experiments, do the models that the authors compare against have the luxury of returning a ‚ÄúUndecided‚Äù label?	Reply	O	0
If not, then the problem formulation is fundamentally different, and I do not think the comparisons are necessarily fair.	Reply	O	0
Are there any papers out there that also allow for an ‚ÄúUndecided‚Äù label?	Reply	O	0
If so, they should be the baselines that one compares against.	Reply	O	0
I have a rather hard time believing that this is the first paper to try unanimous voting across an ensemble.	Reply	O	0
‚Äù[line_break_token][line_break_token][line_break_token]Answer: To the best of our knowledge, there is no defense producing "undecided" (or bottom) label as in our design.	Reply	O	0
The reason is very simple: people want to maintain high clean accuracy rather than sacrifice it for security.	Reply	B-Reply	4
We develop the metric \delta to show that many existing defenses with high clean prediction accuracy do not have any security as shown in Table 1.	Reply	I-Reply	4
[line_break_token][line_break_token]	Reply	O	0

This paper presents a method for control by estimating the gradient of trajectories w.r.t.	Review	O	0
the policy parameters by fitting a GP to a set of noisy trajectories executing the same controller.	Review	O	0
This is opposed to the majority of current RL methods that either learn a forward model or learn a policy.	Review	O	0
They argue that learning this gradient is a middle step between model-based and model-free RL.	Review	O	0
The method is shown to estimate gradients on simple policies (linear and nonlinear open-loop controllers, and a linear PD controller) for a free-space reaching robot, and update a controller to add a trajectory constraint to pass an intermediate state.	Review	O	0
[line_break_token][line_break_token]The paper does show that they can learn these derivatives on controllers from data, which is a cool proof of concept.	Review	O	0
The method to estimate gradients by ‚Äúshaking‚Äù in a probabilistic way by fitting a GP to noisy trajectories is clever and interesting.	Review	O	0
But there are a few reasons why I believe this work is not ready for publication.	Review	O	0
[line_break_token][line_break_token]The paper only considers free-space reaching as a task, which is not a difficult problem as it does not have contacts.	Review	B-Review	1
The policies considered are also very simple: an affine open-loop controller (U = Wt + B with 6 parameters), a simple nonlinear open-loop controller (U = Asin(wt) with 2 parameters) and a PD controller with 2 parameters.	Review	I-Review	1
The motivation is not too convincing without showing some results on hard tasks: model-based RL methods work great in this setting, and are very likely to outperform the method proposed in the paper.	Review	I-Review	1
The motivation for the proposed method avoids explicit model learning which is a similar motivation as model-free methods, so the paper should at least show that it works as a proof of concept in settings where model-free learning has some advantages, eg.	Review	I-Review	1
environments with contacts.	Review	I-Review	1
The paper should probably also compare to existing methods in those settings, although I understand that it might not outperform existing methods.	Review	I-Review	1
[line_break_token][line_break_token]The results in section 4.4 which is the result of using the model to plan really shows that using the learned model to update the policy is probably not straightforward.	Review	I-Review	2
The parameters of the PD controller that go from x_0 to x* are updated to pass a waypoint x*_t using the learned model.	Review	I-Review	2
But in practice what this is basically doing is changing k_p to introduce a large, possibly inefficient deviation in the path from x_0 to x* that hits x*_t at time t. Directly planning for a path between x_0 to x*_t and then x*_t to x* would probably give a much cleaner path.	Review	I-Review	2
[line_break_token][line_break_token]At a high level, the proposed method is likely to be difficult to apply on real problems because estimating the gradient of T w.r.t.	Review	I-Review	3
pi is probably just much noisier than estimating the forward model directly, which is already a significant challenge.	Review	I-Review	3
Perhaps one useful experiment is to somehow explicitly show how these two methods compare (eg.	Review	I-Review	3
measure the variance of trajectory predictions of this method vs rolling out a learned forward model repeatedly).	Review	I-Review	3
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]Equation 11 and 12 do not make sense/do not use standard notation.	Review	O	0
I suggest defining n (as a signal or a value, it is not clear at the moment) and defining a new output signal y_t instead of the x_t &lt;- ‚Ä¶ notation.	Review	O	0
In particular, the way equation 11 is written seems to say the output x_t is a value-shifted version of the input x_t, NOT a time-shifted one.	Review	B-Review	4
[line_break_token][line_break_token]The preliminaries section 1.1 does not discuss environment dynamics.	Review	I-Review	5
This is significant because the paper seems to assume deterministic dynamics but this is never explicitly stated.	Review	I-Review	5
[line_break_token][line_break_token]Voxelization as a solution to spatial noise is a bit surprising because discretizing the space throws away local gradient information, which seems valuable to the method.	Review	I-Review	6
It would be good to understand the effect of this design decision better with an ablation.	Review	I-Review	6
[line_break_token][line_break_token]Minor comments:[line_break_token]Page 9: [line_break_token]- constrain -&gt; constraint[line_break_token]- Assuem -&gt; Assume[line_break_token]- such controller -&gt; such a controller	Review	O	0
e thank the respected reviewer for the technical comments and detailed reviews.	Reply	O	0
Here, we try to answer the raised points.	Reply	O	0
[line_break_token][line_break_token]Regarding the simplicity of the task:[line_break_token]Our main goal is to show that learning physical derivatives is feasible in practice despite all noises and challenges of real-world systems.	Reply	O	0
We custom built the robot only to be able to safely run perturbation experiments with low cost.	Reply	B-Reply	1
For the purpose of this paper, in total,  we collected around 10k trajectories which are not possible with more complex robots.	Reply	I-Reply	1
Therefore, going to more complex robots and more complex controllers is definitely interesting, but was not the purpose of this paper.	Reply	I-Reply	1
Here we showed the feasibility of computing the physical derivatives such that they generalize well and a proof of concept via a downstream reaching task.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the experiment of section 4.4:[line_break_token]The purpose of this experiment is to show the usefulness of the physical derivative in a downstream task to showcase one of its uses.	Reply	O	0
There might be methods that carry out this certain experiment better and we did not claim that we do it better than alternative methods in every aspect.	Reply	B-Reply	2
In this paper, we introduce the physical derivative quantity as a middle ground between model-free and model-based approaches and address its challenges in a real physical system and that experiment only serves as a complementary example to show that the learned physical derivatives generalize to unseen perturbations.	Reply	I-Reply	2
[line_break_token]Also, we would like to emphasize that the presence of physical derivatives allowed us to compute the desired perturbation in the parameters of the PD controller as simple as evaluating equation (21).	Reply	I-Reply	2
This is a much cheaper computation than planning two paths from x_0 to x*_t and from x*_t to x*. This cheap computation is a payoff we gain for the initial extensive experiments to compute physical derivatives and learn the regressors from parameter perturbations to trajectory deviations.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding the difficulty of computing physical derivatives compared with a forward model:[line_break_token]Yes, we agree that it is difficult to learn the physical derivatives and the main purpose of this paper and ideas that robustify the method against temporal and spatial noise is to combat these difficulties as an initial step towards this unexplored approach.	Reply	O	0
We showed in the paper that using the proposed ideas, the physical derivatives can be learned from a real ‚Äúphysical system‚Äù and it can generalize well.	Reply	B-Reply	3
The main reason that we carry out our experiments directly on the physical system rather than on a simulator was to face these challenges and propose solutions to them.	Reply	I-Reply	3
We think this side of our work has fairly unnoticed in the reviews.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding voxelization and gradient information:[line_break_token]It is an assumption in this work that the change in trajectories caused by inherent noise is less than the change caused by perturbing the parameters of the controller.	Reply	O	0
Hence, by voxelization, even though some local deviations vanish, the remaining deviations are caused by perturbing the parameters of the controller.	Reply	B-Reply	6
This assumption is valid in physical systems (robots) which are built with reasonable accuracy.	Reply	I-Reply	6
If the system exhibits too much noise such that its controller effect is dominated by the noise, the noise must be alleviated at the hardware level.	Reply	I-Reply	6
[line_break_token][line_break_token]	Reply	O	0

Review Summary[line_break_token]--------------[line_break_token]Overall, I'm not quite convinced this method would be worth the trouble to implement.	Review	O	0
On the more realistic benchmarks, they need to keep ~80% of the total dataset size and the claimed "improvement" is rather small (less than 0.6% absolute gain in accuracy, e.g. from 81.86% to 82.37% on CIFAR100 and from 72.33% to 72.78% on ImageNet).	Review	B-Review	1
There is no runtime comparison, there are missing baselines, and most of the method development seems guided by trying out many options instead of taking a principled approach.	Review	I-Review	8
Without these, the paper is just not ready for a top conference like ICLR.	Review	I-Review	8
[line_break_token][line_break_token]Paper Summary[line_break_token]-------------[line_break_token]The paper considers a new take on active learning for image classification: given a large fully labeled dataset, identify a subset of the data that, when training on that subset alone, yields similar performance as training on the (much larger) full dataset.	Review	O	0
The paper focuses on "ensembles" of deep neural network classifiers as the prediction model, following Lakshminarayanan et al. (	Review	O	0
2017).	Review	O	0
[line_break_token][line_break_token]The presented method is summarized in Algorithm 1.	Review	O	0
Given a suitably initialized "acquisition model", the model makes predictions on each example in the full dataset, then ranks examples using an acquisition function to find the subset of size N_s (top N_s examples by rank) where there is most "disagreement" among the model ensemble.	Review	O	0
This subset is then used to train a "subset" model (again, an ensemble of DNNs).	Review	O	0
[line_break_token][line_break_token]Experiments consider several possible initializations, acquisition functions, and ensemble sizes.	Review	O	0
Evaluation is done using the validation sets of three prominent image classification benchmarks: CIFAR10, CIFAR100, and ImageNet (1000 classes).	Review	O	0
[line_break_token][line_break_token][line_break_token]Significance[line_break_token]------------[line_break_token]I don't think a successful case has been made that the proposed solution would generate significant widespread interest, because the gains demonstrated here are too minimal.	Review	O	0
Looking at the primary results in Table 2, it's really only when using 80% of the total images of imagenet or cifar100 (the most realistic benchmarks) that there is a small (&lt;1%) absolute gain in accuracy over the simpler approach of just using the full dataset.	Review	O	0
Thus, the approach is not going to significantly reduce computational burden but adds a lot of complexity.	Review	B-Review	9
[line_break_token][line_break_token]Novelty[line_break_token]-----------[line_break_token]The method seems new to me.	Review	O	0
[line_break_token][line_break_token][line_break_token]Experimental Concerns[line_break_token]---------------------[line_break_token]## E1: Need to consider runtime in evaluation[line_break_token][line_break_token]None of the figures/tables that I can see report elapsed runtimes for the different methods.	Review	O	0
To me this is the fundamental tradeoff: not how many fewer examples can I learn from, but how much faster is the method than the "standard" of using the full dataset?	Review	B-Review	2
Showing curves of validation progress over wallclock time would be a better way to present results.	Review	I-Review	2
[line_break_token][line_break_token]The important thing here is that even *full dataset* makes progress after each minibatch.	Review	I-Review	2
You'd need to show progress at checkpoints for each epoch in  0.2, 0.4, 0.6, 0.8, 1, 1.2, 1.4, .... [line_break_token][line_break_token]## E2: Potential missing baseline: Random subset with balanced classes[line_break_token][line_break_token]When you select a random subset, are you ensuring class balance?	Review	O	0
If not, that seems like a more refined baseline.	Review	B-Review	3
Perhaps won't make too much difference for cifar10, but could be important for ensuring rarer classes in ImageNet are represented well.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]Presentation Concerns[line_break_token]---------------------[line_break_token][line_break_token]## P1: Initialization description confusing[line_break_token][line_break_token]I didn't understand the "build up" method as described in Sec.	Review	O	0
3.	Review	B-Review	4
How large is the subset used at each phase?	Review	I-Review	4
How do you know when to stop?	Review	I-Review	4
This could use a rewrite to improve clarity.	Review	I-Review	4
[line_break_token][line_break_token]## P2: Missing some details for reproducibility[line_break_token][line_break_token]How was convergence assessed for all models?	Review	O	0
How were learning rates set?	Review	B-Review	5
Many of these are crucial to understanding the runtime required for different models. (	Review	I-Review	5
Sorry if these are in the appendix, but some short summary is needed in the main paper)[line_break_token][line_break_token]## P3: Title Change Recommended[line_break_token][line_break_token]I don't think the presented method is really doing a "Distribution Search"... I would suggest "Training Data Subset Selection with Ensemble Active Learning"[line_break_token][line_break_token]Minor Method Concerns[line_break_token]---------------------[line_break_token][line_break_token]## M1: What about regression?	Review	O	0
[line_break_token][line_break_token]Acquisition functions seem specialized to classification.	Review	B-Review	7
What to do for regression or structure learning?	Review	I-Review	7
Any general principles to recommend?	Review	I-Review	7
[line_break_token]	Review	O	0
any thanks to the reviewer for their helpful suggestions.	Reply	O	0
We address the main points brought up in the review as follows:[line_break_token][line_break_token]1.	Reply	O	0
Need to keep ~80% of the dataset size and improvement is rather small.	Reply	O	0
[line_break_token][line_break_token]We would like to highlight the fact that benchmarks such as ImageNet are already highly curated by manual procedures, yet we are still able to remove 280k labeled samples that do not contribute to the performance with the proposed procedure.	Reply	B-Reply	1
Previous attempts such as [1] only show that 10% can be removed, without any improvement.	Reply	I-Reply	1
We demonstrate that our approach can automatically curate large datasets, with limited manual effort of a one-time implementation.	Reply	I-Reply	1
Subsequently, the computation is reduced for any following training experiments that may be needed to run.	Reply	I-Reply	1
We believe this is significant, since there has been a lot of emphasis lately on the financial and environmental costs of large-scale training [2,3].[line_break_token][line_break_token]2.	Reply	O	0
Considering runtime in evaluation.	Reply	O	0
[line_break_token][line_break_token]We now show validation error curves against the number of training iterations for ResNet-18 training  on ImageNet with the full dataset vs. 80% of the data sampled by different initialization.	Reply	B-Reply	2
Please refer to Fig.	Reply	I-Reply	2
2 on Page 13 of the revised draft.	Reply	I-Reply	2
Our AL based sampling leads to better performance with 20% less training time than the full dataset (Full-100 in the plot).	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	5
Potential missing baseline: random subset with balanced classes.	Reply	O	0
[line_break_token][line_break_token]We thank the reviewer for suggesting this baseline.	Reply	B-Reply	3
For CIFAR, we find that standard random sampling maintains class balance.	Reply	I-Reply	3
On ImageNet, since some classes have only ~700 samples, we perform an evaluation of class-balanced random sampling at 10%, 20% and 40% of the data by choosing 128, 256 and 512 samples per class respectively.	Reply	I-Reply	3
Our results are summarized in Table 6 on Page 14 of the revised draft.	Reply	I-Reply	3
We observe no significant difference in performance between standard random sampling and random sampling with class balance.	Reply	I-Reply	3
[line_break_token] [line_break_token]4.	Reply	O	0
Initialization description confusing.	Reply	O	0
[line_break_token][line_break_token]Please refer to Section 2.1 on Page 3 of the revised draft, where we have included additional details regarding our use of the build up initialization scheme as follows:[line_break_token][line_break_token]‚ÄúFinally, in the build up scheme, we follow an iterative AL loop.	Reply	B-Reply	4
Specifically, we start by initializing with a randomly selected subset of the data to train an acquisition model.	Reply	I-Reply	4
After performing acquisition, instead of training a single subset model, we optimize an ensemble of networks.	Reply	I-Reply	4
This ensemble is used as an acquisition model for a subsequent iteration.	Reply	I-Reply	4
Our goal is to finally reach a subset of samples.	Reply	I-Reply	4
As observed by [4], exponentially growing the dataset size offers practical benefits in an AL loop setting.	Reply	I-Reply	4
We therefore follow this approach, by initializing with random samples, and iterating two further times at and samples before obtaining a final subset of size.	Reply	I-Reply	4
‚Äù[line_break_token][line_break_token]5.	Reply	O	0
Description of convergence and learning rates.	Reply	O	0
[line_break_token][line_break_token]As per the recommendation from the reviewer, we have moved the implementation details from the appendix to Section 3.1 on Page 5 of the revised draft.	Reply	B-Reply	5
[line_break_token][line_break_token]6.	Reply	O	0
Title change recommended.	Reply	O	0
[line_break_token][line_break_token]We agree with the reviewer‚Äôs comment regarding the absence of a full ‚ÄòDistribution Search‚Äô in our approach.	Reply	B-Reply	6
We have updated the title to ‚ÄòTraining Data Subset Search with Ensemble Active Learning‚Äô.	Reply	I-Reply	6
[line_break_token][line_break_token]7.	Reply	O	0
Acquisition functions for regression.	Reply	O	0
[line_break_token][line_break_token]We focus on classification in our study due to several popular benchmarks being available in the large-scale setting, as well as existing work on these benchmarks from the active learning community.	Reply	B-Reply	7
For Bayesian uncertainty estimation in the regression setting, acquisition functions that have been applied in the literature include variance and standard deviation [5]. We have added a note regarding this in Page 4 of the revised draft, after Eq.	Reply	I-Reply	7
5.	Reply	I-Reply	7
[line_break_token][line_break_token]References[line_break_token][line_break_token][1] Vighnesh Birodkar, Hossein Mobahi, Samy Bengio.	Reply	O	0
Semantic Redundancies in Image-Classification Datasets: The 10% You Don't Need.	Reply	O	0
arXiv:1901.11409, 2019.	Reply	O	0
[line_break_token][line_break_token][2] Emma Strubell, Ananya Ganesh, Andrew McCallum.	Reply	O	0
Energy and Policy Considerations for Deep Learning in NLP.	Reply	O	0
Association for Computational Linguistics (ACL), 2019.	Reply	O	0
[line_break_token][line_break_token][3] Roy Schwartz, Jesse Dodge, Noah A. Smith, Oren Etzioni.	Reply	O	0
Green AI.	Reply	O	0
arXiv:1907.10597, 2019.	Reply	O	0
[line_break_token][line_break_token][4] Kashyap Chitta, Jose M. Alvarez, Adam Lesnikowski.	Reply	O	0
Large-Scale Visual Active Learning with Deep Probabilistic Ensembles.	Reply	O	0
arXiv:1811.03575, 2018.	Reply	O	0
[line_break_token][line_break_token][5] Evgenii Tsymbalov, Maxim Panov, Alexander Shapeev.	Reply	O	0
Dropout-based Active Learning for Regression.	Reply	O	0
arXiv:1806.09856, 2018	Reply	O	0

*Summary*[line_break_token][line_break_token]The paper proposes a new method to learn data-driven representations, being invariant to some specific nuisance factors which are detrimental for the selected (supervised) classification task.	Review	O	0
[line_break_token]Authors build upon the existing probabilistic framework termed Adversarial Invariant Induction (AII) from (Xie et al.,	Review	O	0
2017).	Review	O	0
[line_break_token][line_break_token]They claim to explore it under a both theoretical and practical point of view, demonstrating the limitations of maximizing a variational upper bound on conditional entropy as a proxy to achieve invariance.	Review	O	0
[line_break_token][line_break_token]Leveraging these observation, authors propose a novel method, called ‚Äúinvariance induction by discriminator matching‚Äù (IIDM) that is based on a regularized classification loss, penalized by a Kullbach-Leibler divergence between conditional distributions of the nuisance factor.	Review	O	0
[line_break_token][line_break_token]Extremely convincing experiments are carried out on a synthetic and a real benchmark in multi-source domain generalization (PACS).	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]*Pros*[line_break_token]1.	Review	O	0
The genesis of the proposed IIDM is extremely paced since smoothly derived from the AII framework.	Review	O	0
[line_break_token]2.	Review	B-Review	5
Experimental results on a synthetic benchmark (a version of rotated MNIST) and on a popular benchmark for domain generalization (PACS) proved the effectiveness of IIDM[line_break_token][line_break_token][line_break_token][line_break_token] *Cons*[line_break_token]1.	Review	O	0
The paper is hard to get, if the reader is not familiar with related literature[line_break_token]2.	Review	O	0
It is not fully clear from the paper which parts are original and which are inherited from prior work.	Review	B-Review	2
[line_break_token]3.	Review	I-Review	6
The structure of the paper needs to be improved (check my comments in the section beneath)[line_break_token]Some of the proposed methodologies are not clear (IIDM+)[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]*Detailed Comments*[line_break_token][line_break_token]The problem considered by authors is surely interesting and addressing a popular topic in computer vision and deep learning.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
Unfortunately, the paper, as it is is hard to get for scholars which are not expert of the AII formalism, which, in my opinion is not enough detailed.	Review	B-Review	4
Therefore, in my opinion clarity is something that authors should try to work hard on: for instance, during the rebuttal time, authors can write from scratch an entire new Section in which they explain in plain terms the main outcomes of their paper, without entering too much into technical details.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token]2.	Review	I-Review	5
Additionally, the structure of the paper needs, in my opinion a major re-styling, still for the sake of better readability:[line_break_token]2.a.	Review	I-Review	5
A visualization of the proposed method (for instance, using flow-diagrams) in comparison with the existing AII should help in rapidly getting the factors of novelty of the proposed IIDM method.	Review	I-Review	5
I would also encourage authors to add a pseudo-code[line_break_token]2.b.	Review	O	0
Since authors claim two major contributions (understanding AII + IIDM), I would like to see those two contributions thoroughly presented and dissected in two separated sections of the paper.	Review	B-Review	5
I am not fully convinced with the actual writing style in which the two contributions seem to be intertwined together.	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]3.	Review	I-Review	6
Although already convincing, the experimental part can be improved:[line_break_token]3.a.	Review	I-Review	6
Instead of a version of rotated-MNIST, authors can test on the ‚Äúdigits-five‚Äù setting (MNIST, MNIST-M, SVHN, UPS, SYN) as done in several works like <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Deep_Cocktail_Network_CVPR_2018_paper.pdf."	Review	O	0
target="_blank" rel="nofollow">http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Deep_Cocktail_Network_CVPR_2018_paper.pdf.</a>[line_break_token]3.b.	Review	O	0
In addition to multi-domain generalization, authors could also have tried more classical unsupervised domain adaptation settings or, even, single-source domain generalization as in <a href="https://papers.nips.cc/paper/7779-generalizing-to-unseen-domains-via-adversarial-data-augmentation."	Review	O	0
target="_blank" rel="nofollow">https://papers.nips.cc/paper/7779-generalizing-to-unseen-domains-via-adversarial-data-augmentation.</a>[line_break_token][line_break_token][line_break_token][line_break_token]*Final Evaluation*[line_break_token][line_break_token]I think that the main aspect that authors should face during the rebuttal is to make the paper more easy to read and better separate the two contributions (understanding AII and IIDM).	Review	O	0
What I am not convinced at all about the writing style of the authors since when reading the paper I am not always capable of understanding what is novel (since proposed by authors) and what is inherited from prior work.	Review	B-Review	5
But, maybe, the reason for this is that I am not an expert of the specific related field - but, even so, I think that the paper needs to be understood from the broadest audience possible.	Review	I-Review	5
[line_break_token][line_break_token]Instead, I am familiar with multi-source/single-source domain generalization (and adaptation) and, after my careful analysis of the experiments, I see a lot of potential in the approach.	Review	O	0
I would me more than interested in checking the performance of the proposed method over some of the novel benchmarks that I have recommended.	Review	B-Review	6
It would be nice if authors add more experiments, but I know that this is always a complicated request during a rebuttal period.	Review	I-Review	6
[line_break_token]Globally, if I were asked to only rate the experimental part, I would have promoted for full acceptance.	Review	I-Review	6
Unfortunately, the theoretical part of the paper is not fully clear to me and, therefore, I am not confident in calling for a full acceptance only based on the experiments.	Review	I-Review	6
[line_break_token][line_break_token]In brief, I would go for a weak reject, looking forward to the authors‚Äô rebuttal and the opinion of the other Fellow Reviewers.	Review	O	0
e thank the reviewer for detailed and encouraging comments.	Reply	O	0
We have been updated the manuscript following the reviewers' comments.	Reply	O	0
Please refer to the thread of "Summary of general updates.".	Reply	O	0
[line_break_token][line_break_token]Below are several clarifications.	Reply	O	0
As the reviewer suggested, we mainly focus on improving the clarity in this rebuttal period.	Reply	O	0
[line_break_token][line_break_token]---- Responses ----[line_break_token]&gt; The paper is hard to get, if the reader is not familiar with related literature[line_break_token][line_break_token]We updated the manuscript to improve clarity.	Reply	O	0
Please refer to the update 1, 2, 3 for more detail.	Reply	B-Reply	1
[line_break_token][line_break_token]&gt; It is not fully clear from the paper which parts are original and which are inherited from prior work.	Reply	O	0
[line_break_token][line_break_token]We made several restructuring.	Reply	B-Reply	2
Specifically, [line_break_token](1) We concentrate the explanation about AII in section 2 to make the paper (and the originality of this work) easy to understand. (	Reply	I-Reply	2
2) Section 3 focuses on analyzing the practical issue of AII, which is the first contribution of this paper. (	Reply	I-Reply	2
3) Section 4 derives a stable variant of AII, which is the second contribution of this paper.	Reply	I-Reply	2
[line_break_token][line_break_token]We also add a flow-diagrams and pseudo-code for a better explanation.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; 3.	Reply	O	0
Although already convincing, the experimental part can be improved: 3.a.	Reply	O	0
Instead of a version of rotated-MNIST, authors can test on the ‚Äúdigits-five‚Äù setting (MNIST, MNIST-M, SVHN, UPS, SYN) as done in several works like <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Deep_Cocktail_Network_CVPR_2018_paper.pdf."	Reply	O	0
target="_blank" rel="nofollow">http://openaccess.thecvf.com/content_cvpr_2018/papers/Xu_Deep_Cocktail_Network_CVPR_2018_paper.pdf.</a> 3.b.	Reply	O	0
In addition to multi-domain generalization, authors could also have tried more classical unsupervised domain adaptation settings or, even, single-source domain generalization as in <a href="https://papers.nips.cc/paper/7779-generalizing-to-unseen-domains-via-adversarial-data-augmentation."	Reply	O	0
target="_blank" rel="nofollow">https://papers.nips.cc/paper/7779-generalizing-to-unseen-domains-via-adversarial-data-augmentation.</a>[line_break_token][line_break_token]As suggested by the reviewer, we agree it would be interesting to see its performance on the other benchmarks.	Reply	O	0
Unfortunately, we do not have much time and computational resources during this rebuttal period.	Reply	B-Reply	6
Of course, we are happy to share the source code for additional tests after the acceptance of the paper.	Reply	I-Reply	6
 [line_break_token]----[line_break_token][line_break_token]We look forward to hearing from you regarding our submission.	Reply	O	0
We would be glad to respond to any further questions and comments that you may have	Reply	O	0

This paper proposes to trained better entity centric text embeddings by switching entities mentioned in the text to some other entities with the same type.	Review	O	0
The target is modeled as a binary classification task, which is trained jointly with the MLM loss.	Review	O	0
The authors do experiments on multiple tasks, and the model shows strong performance on all tasks.	Review	O	0
And the ablation study justifies that "knowledge pre-training" is crucial.	Review	O	0
The idea is novel and the experiment results suggest that the additional "adversarial" target helps.	Review	O	0
The writing is clear in general, but misses some implementation details.	Review	O	0
[line_break_token][line_break_token]A few questions:[line_break_token]1.	Review	O	0
In section 3.1, how do you rank the candidate answers with your model?	Review	B-Review	1
Do you compute the logits in the same way as the baseline models?	Review	I-Review	1
[line_break_token]2.	Review	I-Review	2
In section 3.2.1, why do you use a different split for TriviaQA?	Review	I-Review	2
Do you rerun the baseline models on this new split?	Review	I-Review	2
[line_break_token]3.	Review	I-Review	1
In section 3.2.1, the author claims that most answers in TriviaQA, SearchQA and Quasar-T datasets are entities.	Review	I-Review	3
A interesting metric to evaluate would be how much improvements WKLM obtain on those questions, versus those whose answers are text spans.	Review	I-Review	3
[line_break_token]3.	Review	I-Review	1
In section 3.2.2, the authors mention that they use the CLS token to predict the entity types.	Review	I-Review	4
How do you train the embedding your CLS token?	Review	I-Review	4
[line_break_token]4.	Review	O	0
For the entity typing task in section 3.2.2, do you fine tune your model or it's evaluated in a zero-shot setting?	Review	B-Review	5
[line_break_token][line_break_token]	Review	O	0
hank you for your positive comments.	Reply	O	0
Below are our answers to your questions:[line_break_token][line_break_token]On candidate ranking: During WKLM pretraining, our model learns to predict a probability ) for each entity mention about whether the mention is correct (not replaced) or not (replaced).	Reply	O	0
We directly use these predicted probabilities of entity candidates for ranking.	Reply	B-Reply	1
We have added a description in the revision.	Reply	I-Reply	1
[line_break_token][line_break_token]On TriviaQA experiments: Our TriviaQA splits are consistent with the splits released by DSQA (Lin et al.	Reply	O	0
2018).	Reply	B-Reply	2
 They reused the data processed by R3 (Wang et al.,	Reply	I-Reply	2
2018a) and Evidence Aggregation (Wang et al.,	Reply	I-Reply	2
2018b).	Reply	I-Reply	2
Since the other systems are not open-sourced and the retrieval methods are different, we are not able to rerun those baselines.	Reply	I-Reply	2
[line_break_token][line_break_token]On Entity QA performance: Compared to SQuAD, these open-domain QA datasets are more entity-centric.	Reply	O	0
We already described the ratios of entity answers in the paper.	Reply	B-Reply	3
For SQuAD, our manual inspection on 100 random examples suggests that only around 40% of the answers are actually common entities.	Reply	I-Reply	3
By looking at our model‚Äôs improvements over SQuAD and these open-domain QA datasets, we can see that our model is more effective at entity-centric questions.	Reply	I-Reply	3
[line_break_token][line_break_token]On CLS token: We prepend the [CLS] token to all sentences in the entity typing dataset and the embedding is updated during fine-tuning.	Reply	O	0
[line_break_token][line_break_token]On entity typing experiments: We fine-tune the model using the same training data as used by the compared approaches.	Reply	O	0

The authors propose an approach where they aggregate, for each candidate answer, text from supporting passages.	Review	O	0
They make use of two ranking components.	Review	O	0
A strength-based re-ranker captures how often a candidate answer would be selected while a coverage-based re-ranker aims to estimate the coverage of the question by the supporting passages.	Review	O	0
Potential answers are extracted using a machine comprehension model.	Review	O	0
A bi-LSTM model is used to estimate the coverage of the question.	Review	O	0
A weighted combination of the outputs of both components generates the final ranking (using softmax).	Review	O	0
[line_break_token]This article is really well written and clearly describes the proposed scheme.	Review	O	0
Their experiments clearly indicate that the combination of the two re-ranking components outperforms raw machine comprehension approaches.	Review	O	0
The paper also provides an interesting analysis of various design issues.	Review	O	0
Finally they situate the contribution with respect to some related work pertaining to open domain QA.	Review	O	0
This paper seems to me like an interesting and significant contribution.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your kind review.	Reply	O	0
We have improved the presentation and added new discussions which we hope will further improve.	Reply	O	0

This paper presents a reinforcement learning approach towards using data that present best correlation with a validation set‚Äôs gradient signal.	Review	O	0
The broader point of this paper is that there is inevitably some distribution shift going from train to test set - and the validation set can be a small curated set whose distribution is closer to the testing distribution than what the training dataset's distribution is.	Review	O	0
[line_break_token][line_break_token]The problem setup bears relationship to several areas including domain adaptation/covariate shift problems, curriculum learning based approaches amongst others.	Review	O	0
One assumption that I see which needs to be understood more is equation (6) - wherein, somehow, there is a Markov assumption used to zero out the contribution of the scoring network on parameters unto previous time step.	Review	O	0
Trying to understand the implications of this assumption (how the performance varies with/without this assumption) would be instructive for understanding potential shortcomings of this framework.	Review	O	0
[line_break_token][line_break_token]I think the paper is well written, handles an important question.	Review	O	0
That said, I am not too aware of recent work in this area to make a decisive judgement on this paper‚Äôs novelty/contributions.	Review	O	0
e thank the reviewer for providing the feedback and suggestions.	Reply	O	0
Please see our response to Reviewer #1, question 4).	Reply	O	0
We have also updated the paper to add some clarifications.	Reply	O	0
We would really appreciate if you could check whether our response has cleared your concern, and that you could consider improving the overall assessment.	Reply	O	0
We would love to continue the discussion and make improvements to our paper.	Reply	O	0

Sequential Monte Carlo (SMC) has since its inception some 25 years ago proved to be a powerful and generally applicable tool.	Review	O	0
The authors of this paper continue this development in a very interesting and natural way by showing how SMC can be used to solve challenging planning problems.	Review	O	0
This is a enabled by reformulating the planning problem as an inference problem via the recent trend referred to as "control as inference".	Review	O	0
While there is unfortunately no real world experiments, the simulations clearly illustrate the potential of the approach.	Review	O	0
[line_break_token]While the idea of viewing control as inference is far from new the idea of using SMC in this context is clearly novel as far as I can see.	Review	O	0
Well, there has been some work along the same general topic before, see e.g.[line_break_token]Andrieu, C., Doucet, A., Singh, S.S., and Tadic, V.B. (2004).	Review	O	0
Particle methods for change detection, system identification, and contol.	Review	O	0
Proceedings of the IEEE, 92(3), 423‚Äì438.	Review	O	0
[line_break_token]However, the particular construction proposed in this paper is refreshingly novel and interesting.	Review	O	0
Hence, I view the specific idea put fourth in this paper as highly novel.	Review	O	0
The general idea of viewing control as inference goes far back and there are very nice dual relationships between LQG and the Kalman filter established and exploited long time ago.	Review	O	0
[line_break_token][line_break_token]The authors interprets "control as inference" as viewing the planning problem as a simulation exercise where we aim to approximate the distribution of optimal future trajectories.	Review	O	0
A bit more specifically, the SMC-based planning proposed in the paper stochastically explores the most promising trajectories in the tree and randomly removes (via the resampling operation) the less promising branches.	Review	O	0
Importantly there are convergence guarantees via the use of SMC.	Review	O	0
The idea is significant in that it opens up for the use of the by now strong SMC body of methods and analysis when it comes to challenging and intractable planning problems.	Review	O	0
I foresee many interesting developments to follow in the direction layed out by this paper.	Review	O	0
[line_break_token][line_break_token]When it comes to your SMC algorithm you will suffer from path degeneracy (as all SMC algorithms does, see e.g. Figure 1 in <a href="https://arxiv.org/pdf/1307.3180.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1307.3180.pdf)</a> and if h is large I think this can be a problem for you.	Review	O	0
However, this can easily be fixed via backward simulation.	Review	O	0
For an overview of backward simulation see [line_break_token]Lindsten, F. and Schon, T. "Backward simulation methods for Monte Carlo statistical inference".	Review	O	0
Foundations and Trends in Machine Learning, 6(1):1-143, 2013.	Review	O	0
[line_break_token][line_break_token]I am positive to this paper (clearly reveled by my score as well), but there are of course a few issues as well:[line_break_token]1.	Review	O	0
There are no theoretical results on the properties of the proposed approach.	Review	B-Review	1
However, given the large body of literature when it comes to the analysis of SMC methods I would expect that you can provide some results via the nice bridge that you have identified.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	4
Would this be possible to implement in a real-world setting with real-time requirements?	Review	I-Review	2
[line_break_token]3.	Review	O	0
A very detailed question when it comes to Figure 5.2 (right-most plot), why is the performance of your method significantly degraded towards the end?	Review	B-Review	3
It does recover indeed, but I still find this huge dip quite surprising.	Review	I-Review	3
[line_break_token][line_break_token]Minor details:[line_break_token]* The initial references when it comes to SMC are wrong.	Review	O	0
The first papers are:[line_break_token]N.J. Gordon, D. Salmond and A.F.M. Smith, Novel approach to nonlinear/non-Gaussian Bayesian state estimation, IEE Proc.	Review	B-Review	4
F, 1993[line_break_token]L. Stewart, P. McCarty, The use of Bayesian Belief Networks to fuse continuous and discrete information for target recognition and discrete information for target recognition, tracking, and situation assessment, in Proc.	Review	I-Review	4
SPIE Signal Processing, Sensor Fusion and Target Recognition,, vol.	Review	I-Review	4
1699, pp.	Review	I-Review	4
177-185, 1992.	Review	I-Review	4
[line_break_token] G. Kitagawa, Monte Carlo filter and smoother for non-Gaussian nonlinear state-space models, JCGS, 1996 [line_break_token]* When it comes to the topic of learning a good proposal for SMC with the use of variational inference the authors provide a reference to Gu et al. (	Review	I-Review	4
2015) which is indeed interesting and relevant in this respect.	Review	I-Review	4
However, on this hot and interesting topic there has recently been several related papers published and I would like to mention:[line_break_token]C. A. Naesseth, S. W. Linderman, R. Ranganath, D. M. Blei, Variational Sequential Monte Carlo.	Review	I-Review	4
Proceedings of the 21st International Conference on Artificial Intelligence and Statistics, Lanzarote, Spain, April 2018.	Review	I-Review	4
[line_break_token]C. J. Maddison, D. Lawson, G. Tucker, N. Heess, M. Norouzi, A. Mnih, A. Doucet, and Y. Whye Teh.	Review	I-Review	4
Filtering variational objectives.	Review	I-Review	4
In Advances in Neural Information Processing Systems, 2017.	Review	I-Review	4
[line_break_token]T. A. Le, M. Igl, T. Jin, T. Rainforth, and F. Wood.	Review	I-Review	4
AutoEncoding Sequential Monte Carlo.	Review	I-Review	4
arXiv:1705.10306, May 2017.	Review	I-Review	4
[line_break_token][line_break_token]I would like to end by saying that I really like your idea and the way in which you have developed it.	Review	I-Review	4
I have a feeling that this will inspire quite a lot of work in this direction.	Review	I-Review	4
We would like to thank the reviewer for the encouraging comments and important references.	Reply	O	0
[line_break_token][line_break_token]‚ÄúWhen it comes to your SMC algorithm you will suffer from path degeneracy. [...]	Reply	O	0
However, this can easily be fixed via backward simulation [...]‚Äù[line_break_token][line_break_token]Yes, we thank you for the suggestion.	Reply	O	0
Particle Gibbs with Ancestral Sampling had been also brought to our attention to tackle this issue, but we choose to keep it simple in this work to focus more on introducing the idea rather than on getting the best results.	Reply	O	0
[line_break_token][line_break_token]1) ‚ÄúThere are no theoretical results on the properties of the proposed approach.	Reply	O	0
However, given the large body of literature when it comes to the analysis of SMC methods I would expect that you can provide some results via the nice bridge that you have identified.	Reply	O	0
‚Äù[line_break_token][line_break_token]We believe our method is grounded when p_model = p_env and we have access to the optimal value function.	Reply	O	0
[line_break_token]However in most RL settings, both these assumptions are violated and it lessens the impact of the analysis.	Reply	B-Reply	1
[line_break_token]A very interesting theoretical analysis we wish to make is to look if we can still provide some guarantees when the model and value function are approximately optimal, but a full theoretical study is still upcoming and out of scope of this paper.	Reply	I-Reply	1
[line_break_token][line_break_token]2) ‚ÄúWould this be possible to implement in a real-world setting with real-time requirements?‚Äù[line_break_token][line_break_token]We think it is possible if we replan every few steps instead of every step and keep a reasonable number of particles.	Reply	O	0
Several methods bringing SMC methods to real-time systems exist.	Reply	B-Reply	2
For instance, for embedded systems with real-time constraints, a FPGA implementation of SMC has been proposed (Ndeved et al, 2014, <a href="https://www.sciencedirect.com/science/article/pii/S1474667016429812)."	Reply	O	0
target="_blank" rel="nofollow">https://www.sciencedirect.com/science/article/pii/S1474667016429812).</a>[line_break_token]We also believe that additionally to a good search algorithm, we need to learn good representations (eg if the input is an image) and plan in the latent space.	Reply	O	0
[line_break_token][line_break_token]3) ‚ÄúA very detailed question when it comes to Figure 5.2 (right-most plot), why is the performance of your method significantly degraded towards the end?	Reply	O	0
It does recover indeed, but I still find this huge dip quite surprising.	Reply	O	0
‚Äù[line_break_token][line_break_token]Indeed.	Reply	O	0
We had more time to investigate this during the review period and we realized that some of our jobs were killed around step 40k.	Reply	B-Reply	3
We have since rerun all our experiments and closely monitored that no such thing happened again.	Reply	I-Reply	3
We are now confident our updated results are much stronger and show with high confidence the real performance of our method.	Reply	I-Reply	3

This paper presented an image data that are generated from two variables using some physics law.	Review	O	0
It also proposed a model to identify the causal relationship between the two variables using the image dataset.	Review	O	0
The method, in general, utilize the general idea that the causal direction is easier for the model to describe than the anti-causal direction.	Review	O	0
So the image is fad into a VAE based model in two different ways.	Review	O	0
The one with lower loses represents the correct causal direction.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
Causal discovery is, in general, an interesting problem and causal discovery based on representation learning are of great importance.	Review	O	0
 [line_break_token]2.	Review	O	0
The dataset presented can be used for generic causal discovery evaluation which can be useful for the community.	Review	O	0
[line_break_token][line_break_token]Cons and other details:[line_break_token]1.	Review	O	0
The method assumes that A and B are known and given which is very unrealistic in natural images.	Review	B-Review	1
Also with this assumption, the problem is not much different from causal discovery from measurement data rather than image data.	Review	I-Review	1
[line_break_token]2.	Review	O	0
Based on the previous point, the method, in general, does not match the motivation in the introduction where a causal representation needs to be learned as the images are already separated into different components.	Review	B-Review	2
[line_break_token]3.	Review	I-Review	4
The method cannot be scaled to more than two variables even with all components given as it requires exponentially many trials of the method.	Review	I-Review	3
This setting is not so interesting anymore with image input.	Review	I-Review	3
[line_break_token]4.	Review	O	0
There is much-related work with causality and representation learning also causality with NN or VAE.	Review	B-Review	4
None of these related work has been discussed.	Review	I-Review	4
 for example Leon Bottou <a href="https://arxiv.org/pdf/1907.02893.pdf;" target="_blank" rel="nofollow">https://arxiv.org/pdf/1907.02893.pdf;</a> Many works from Mingming Gong etc[line_break_token]5.	Review	O	0
The math is not very rigorous in general.	Review	B-Review	5
For example, Eq(2) s a valid-loss but not likelihood.	Review	I-Review	5
Also, the work did not say what likelihood under what distribution.	Review	I-Review	5
This is propositional to Gaussian likelihood which may work fine in practice but the math presentation is not rigorous.	Review	I-Review	5
 [line_break_token]6.	Review	O	0
For the method (see figure 2), I did not see why the first part needs to be there as the second part takes the ground truth A as input.	Review	B-Review	6
Using only the second part of the model which tries to see whether A-&gt;B is easier or B-&gt;A is easier is sufficient for the aim of identifying the relationship between given A and B. [line_break_token]7.	Review	O	0
The dataset may be more useful to the causality community if it is released as a simulator rather than the images.	Review	B-Review	7
[line_break_token]	Review	O	0
e are grateful for R2's constructive suggestions and we believe they could greatly improve our paper.	Reply	O	0
[line_break_token][line_break_token]-As your proposition said, though for our dataset the two variables are given, it is quite different from causal discovery from measurement data.	Reply	O	0
Our model fits for high dimensional visual data, which is a main contribution of this work.	Reply	B-Reply	1
[line_break_token][line_break_token]-We separate the image into two part for two reasons:[line_break_token]  1.Reduce the mutual interference between variables.	Reply	O	0
[line_break_token]  2.Our paper is mainly based on the following assumption: The Kolmogorov complexity of conditional and marginal distributions is smaller in causal direction than that in anti-causal direction.	Reply	O	0
In Figure 2, the part I of DO-AE is to estimate K(P_x), the part II is to estimate K(P_{y|x}).	Reply	B-Reply	2
The outputs of these two part make up the whole image, we want to intervene in whole images generation process, so two parts of the DO-AE are indispensable.	Reply	I-Reply	2
[line_break_token][line_break_token]-We will access related work you recommendÔºåand cite the related work about causality with VAE.	Reply	O	0
[line_break_token][line_break_token]Thank you again for your detail comments	Reply	O	0

This paper presents an approach to customize or adapt a text-to-speech synthesis system to a new speaker, given relatively small amount of data from that speaker.	Review	O	0
 It is a very well written paper with rather strong results indicating high quality, naturalness, and similarity with real speech from a speaker can be achieved with the authors' proposed approach.	Review	O	0
 I think the paper should be accepted for presentation at the conference.	Review	O	0
[line_break_token][line_break_token]Few comments:[line_break_token]a) In second equation in Section 2 authors state speaker identity ‚Äús‚Äù is part of conditioning inputs ‚Äúh‚Äù but it is not shown in the Equation where ‚Äúh‚Äù is replaced with ‚Äúl, f_0‚Äù[line_break_token]b) In related work, I think the speaker code work of Abdel-Hamid et al.,	Review	O	0
e.g. Ossama Abdel-Hamid, Hui Jiang, ‚ÄúFast speaker adaptation of hybrid NN/HMM model for speech recognition based on discriminative learning of speaker code,‚Äù ICASSP 2013 is worth citing.	Review	B-Review	2
[line_break_token]c) The result that synthesized speech performs better than real speech in speaker verification task is interesting.	Review	O	0
 To me this points to a potential weakness in the verification methodology.	Review	B-Review	3
 Please comment if this may be the case.	Review	I-Review	3
Thank you for your supportive comments.	Reply	O	0
We‚Äôve submitted a revision following the feedback from all reviewers.	Reply	O	0
Please see our response to your questions below:[line_break_token][line_break_token]a) Conditioning inputs: [line_break_token]Speaker identity is part of h. Because s is used to select the speaker-specific embedding parameter, we include it in the second equation as a subscript in e_s.	Reply	O	0
We have added a note to clarify this in the revision.	Reply	B-Reply	1
[line_break_token][line_break_token]b) Citation to Fast speaker adaptation for speech recognition: [line_break_token]Thanks for bringing this paper to our attention.	Reply	O	0
We‚Äôve included it in the revision.	Reply	B-Reply	2
[line_break_token][line_break_token]c) Synthesized speech outperforms real speech in speaker verification task: [line_break_token]This is a good point.	Reply	O	0
Our experiments suggest that synthesized samples from SEA-ALL on LibriSpeech deviate less from the *centroid* of real utterances than the real samples.	Reply	B-Reply	3
Ideally, when comparing samples of different generative models to real utterances we would like these to match in distribution and not only in terms of scalar point estimates.	Reply	I-Reply	3
In our practical setting, we would like the generated and real samples to have overlapping tSNE projections as in Figure 3, and to have similar DET curves as in Figure 4.	Reply	I-Reply	3
We expanded on this point in the revised version of the paper.	Reply	I-Reply	3

This paper tries to addresses an interesting problem of generating singing voice track under three different circumstances.	Review	O	0
Some of the problems that this paper deals with is a new problem and introduced first in this paper, which could be a contribution as well.	Review	O	0
[line_break_token][line_break_token]Although the paper is fairly well-structured and written, especially in the early sections, I am giving a weak reject due to its weak evaluation.	Review	B-Review	5
Evaluation is almost always difficult when it comes to generative art, but I am slightly more concerned than that.	Review	I-Review	5
The literature review can be, although it is nicely done overall, improved, especially on the neural network based singing voice synthesis.	Review	I-Review	5
[line_break_token][line_break_token]I appreciate the authors tried to find a great problem and provided a good summary of the literature.	Review	O	0
Successfully training this kind of network itself is already tricky.	Review	O	0
It is also nice to see some interesting approaches towards objective evaluation.	Review	O	0
[line_break_token][line_break_token]Below are my comments.	Review	O	0
[line_break_token][line_break_token]&gt; Our conjecture is that, as the output of G(¬∑) is a sequence of vectors of variable length (rather than a fixed-size image), compressing the output of G(¬∑) may have lost information important to the task.	Review	O	0
[line_break_token][line_break_token]I am rather not convinced.	Review	B-Review	1
The difficulty to discriminate them doesn't seem to be (strongly) related to their variable length for me because a lot of papers have, at least indirectly, dealt with such a case successfully.	Review	I-Review	1
[line_break_token][line_break_token]&gt; For data augmentation, we transpose the chord progressions found in Wikifonia to 24 possible keys[line_break_token][line_break_token]What do you mean by 24 keys?	Review	O	0
I think there should be only 12 keys.	Review	B-Review	2
[line_break_token][line_break_token]&gt; Vocalness measures whether a generated singing voice audio sounds like vocals.	Review	O	0
We use the singing voice detection tool proposed by Leglaive et al. (	Review	B-Review	3
2015) and made available by Lee et al.(2018).	Review	I-Review	3
[line_break_token][line_break_token]Actually, the paper (Lee et al.	Review	I-Review	3
2018) suggested that vocal activity detection in the spectrum domain is easily affected by some features such as frequency modulation.	Review	I-Review	3
I am not sure if this feature is suitable as a measure of the proposed vocalness.	Review	I-Review	3
The computed vocalness may provide more information if they are computed on other tracks (e.g., guitar, cello, drums, etc).	Review	I-Review	3
[line_break_token][line_break_token]&gt; Average pitch: We use the state-of-the-art monophonic pitch tracker CREPE (Kim et al.,	Review	O	0
2018)8 to compute the pitch (in Hz) for each frame.	Review	B-Review	4
The average pitch is computed by averaging the pitches of all the frames.	Review	I-Review	4
[line_break_token][line_break_token]I am pretty sure that this is not the right way to evaluate as a metric of generated vocal track.	Review	I-Review	4
CREPE is a neural network based pitch tracker, which means it is probably biased by the training data, where the pitch values mostly range in that of common musical instruments/voices.	Review	I-Review	4
This means, when the F0 of input is not really in the right range, CREPE might incorrectly predict somewhat random F0 within THAT range anyway.	Review	I-Review	4
I'd say the distribution of pitch values can be interesting metric to show and discuss, but not as a metric of vocal track generation.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
hank you for the valuable comments.	Reply	O	0
We address the issues and questions raised by the reviewer in the following comments.	Reply	O	0
[line_break_token][line_break_token] Although the paper is fairly well-structured and written, especially in the early sections, I am giving a weak reject due to its weak evaluation.	Reply	O	0
[line_break_token][line_break_token]Thank you for the comment.	Reply	O	0
That is also the concern of all the reviewers.	Reply	B-Reply	5
We have largely expanded the evaluation to include two types of baselines.	Reply	I-Reply	5
[line_break_token]a. We have included two baseline systems of singing voice synthesis: Sinsy and Synthesizer V.[line_break_token]b. We have also computed the metrics on the training data, so that there are more references for comparison.	Reply	I-Reply	5
[line_break_token][line_break_token] The literature review can be, although it is nicely done overall, improved, especially on the neural network based singing voice synthesis.	Reply	O	0
[line_break_token][line_break_token]We have expanded literature review to include more neural network based methods in Section 5.	Reply	B-Reply	5
[line_break_token][line_break_token] Our conjecture is that, as the output of G(¬∑) is a sequence of vectors of variable length (rather than a fixed-size image), compressing the output of G(¬∑) may have lost information important to the task.	Reply	O	0
[line_break_token][line_break_token]I am rather not convinced.	Reply	O	0
The difficulty to discriminate them doesn't seem to be (strongly) related to their variable length for me because a lot of papers have, at least indirectly, dealt with such a case successfully.	Reply	O	0
[line_break_token][line_break_token]You are right, and we did not mean that the failure of training with the vanilla GAN loss is due to the variable-length sequences in our training set.	Reply	B-Reply	1
In fact, in the training phase, we use fixed-length sequences.	Reply	I-Reply	1
What we want to express is that the compression of a sequence (whether it is variable-length or not) into a single true/false value could be a cause for the failure.	Reply	I-Reply	1
[line_break_token][line_break_token]We have revised the whole paragraph to clarify the description.	Reply	I-Reply	1
We have also added a comparison of training with GAN, LSGAN, and BEGAN in Appendix D.[line_break_token] [line_break_token] Regarding the transposing of Wikifonia chord progressions[line_break_token][line_break_token]Yes, there are only 12 keys.	Reply	O	0
Thank you for spotting the typo.	Reply	B-Reply	2
We have revised it.	Reply	I-Reply	2
[line_break_token][line_break_token] the paper (Lee et al.	Reply	O	0
2018) suggested that vocal activity detection in the spectrum domain is easily affected by some features such as frequency modulation.	Reply	O	0
I am not sure if this feature is suitable as a measure of the proposed vocalness.	Reply	O	0
[line_break_token] [line_break_token]Thank you very much for this comment.	Reply	O	0
Indeed, (Lee et al.	Reply	B-Reply	3
2018) shows that the frequency modulation is an important factor causing high false positive rates when some types of instruments are present in the songs.	Reply	I-Reply	3
However, we compute the vocalness measures on the non-silence part of the generated singing voices only, without the accompaniment, so the effect of frequency modulation might not be as serious as the scenario investigated in (Lee et al.	Reply	I-Reply	3
2018).	Reply	I-Reply	3
[line_break_token][line_break_token]On the other hand, we also agree that there are better ways to compute the vocalness, so we have devised a way to compute the vocalness taking into account both the vocal activation and the singing pitch range.	Reply	I-Reply	3
[line_break_token][line_break_token]For the new vocalness, we use the JDC model (<a href="https://github.com/keums/melodyExtraction_JDC)" target="_blank" rel="nofollow">https://github.com/keums/melodyExtraction_JDC)</a> for it represents the state-of-the-art.	Reply	O	0
In this model, the pitch contour is also predicted in addition to the vocal activation.	Reply	B-Reply	3
If the pitch at a frame is outside a reasonable human pitch range (73~988 Hz defined by JDC), the pitch is set to 0 at that frame.	Reply	I-Reply	3
We consider a frame as being vocal if it has a vocal activation &gt;= 0.5 AND has a pitch &gt;0.	Reply	O	0
Moreover, we define the vocalness of an audio clip as the proportion of its frames that are vocal.	Reply	B-Reply	3
The tool is applied to the non-silence part of an audio.	Reply	I-Reply	3
[line_break_token][line_break_token]We have revised the paper for this modification.	Reply	I-Reply	3
[line_break_token][line_break_token] Average pitch: We use the state-of-the-art monophonic pitch tracker CREPE (Kim et al.,	Reply	O	0
2018) ...[line_break_token][line_break_token]I am pretty sure that this is not the right way to evaluate as a metric of generated vocal track.	Reply	O	0
CREPE is a neural network based pitch tracker, which means it is probably biased by the training data, .... This means, when the F0 of input is not really in the right range, CREPE might incorrectly predict somewhat random F0 within THAT range anyway.	Reply	B-Reply	4
I'd say the distribution of pitch values can be interesting metric to show and discuss, but not as a metric of vocal track generation.	Reply	I-Reply	4
[line_break_token][line_break_token]First of all, we have corrected our description of the ‚ÄúAverage pitch‚Äù to clarify that the ‚ÄúAverage pitch‚Äù is computed over all the frames with confidence value &gt;= 0.5, not over all the frames.	Reply	O	0
Second, we agree that there still could be incorrectly predicted F0 due to the bias of the data used to train CREPE.	Reply	B-Reply	4
In our evaluation in Section 4.3, we use them to show that the two models trained with female vocals and male vocals do exhibit different characterizations in pitch, not as an absolute metric, so we think it is still a valuable metric.	Reply	I-Reply	4
[line_break_token][line_break_token]Furthermore, we add another way of computing average pitch by using JDC, where vocalness is also taken into account to filter out non-vocal frames	Reply	I-Reply	4

The paper attempts multimodal representation of video and text through an attention layer that allows weighted temporal pooling.	Review	O	0
The approach was tested on a collection of datasets including a newly introduced dataset, with the embedding and evaluated on three tasks: zero-shot classification, activity clustering and captioning.	Review	O	0
[line_break_token][line_break_token]The paper is easy to read in general and the approach is scientifically sound.	Review	O	0
The need for an autoencoder in multimodal embedding has been proven for a variety of modalities including image-text, video-text, image-audio and video-audio.	Review	O	0
The contribution here is thus focused on temporal pooling through a learnt attention layer.	Review	O	0
[line_break_token][line_break_token]However, the paper has a mix of tasks (3 tasks tested), without a conclusive understanding of the effect of the various loss functions on the learnt space.	Review	B-Review	1
As the importance of various losses changes per task and dataset, the take-away message from the work is not obvious.	Review	I-Review	1
Additionally, using unpaired data, proposed through a large-scale dataset is not obvious.	Review	I-Review	1
The paper concludes that related data is required but how related data can be collected remains unexplored.	Review	I-Review	1
[line_break_token][line_break_token]The evaluation for the unsupervised discovery seems biased ‚Äì 1NearestNeighbour is used as opposed to the more balanced mAP on ranking all test sequences as opposed to top-1.	Review	I-Review	2
[line_break_token][line_break_token]The collected dataset, which is a contribution of the paper is also poorly explained.	Review	I-Review	3
The authors collect ‚Äòdense annotations‚Äô but it is not clear how many annotators were used, and what instructions they were given.	Review	I-Review	3
The paper does not give examples of the collected annotations and how these differ from previous annotations available with the dataset (Fig 4).	Review	I-Review	3
[line_break_token][line_break_token]Appendix 1 concludes with sentences proposed to annotate UCF.	Review	I-Review	4
These seem to apply per action and it‚Äôs not clear how they scale to the different instances, e.g. Action Surfing (85) is assigned to a male caption ‚Äòa man is‚Äô, action 100 to a woman and action 96 to groups of people ‚Äòpeople are riding‚Äô.	Review	I-Review	4
This distinction is not obvious in all the instances of the dataset and such captioning might have significantly biased the results.	Review	I-Review	4
[line_break_token][line_break_token]Overall, there is little explanation of the decisions made to produce the comparative results.	Review	I-Review	5
The novelty is limited to the attention pooling, which is not evaluated on all the three tasks.	Review	I-Review	5
Thank you for the review, we revised our paper with additional experiments to address your concerns.	Reply	O	0
Please find our detailed answers to your comments below.	Reply	O	0
[line_break_token][line_break_token]- The main contribution of the paper:[line_break_token][line_break_token]We first want to clarify that the use of the attention pooling is not the main novel contribution of the paper.	Reply	O	0
Our primary contribution is the use of unpaired, multimodal data for learning an embedding space that generalizes to unseen actions.	Reply	B-Reply	5
We compare the use of the unpaired data on all tasks and have added a new section comparing different strategies for obtaining unpaired data.	Reply	I-Reply	5
To our knowledge, this is the first paper to explicitly use unpaired examples for multimodal embedding learning for zero-shot action classification.	Reply	I-Reply	5
We changed title of our paper to emphasize this more explicitly.	Reply	I-Reply	5
[line_break_token][line_break_token]- Conclusive findings:[line_break_token][line_break_token]As we illustrate in Tables 1-7, our conclusion is that (1) learning of the shared multimodal embedding becomes possible with our approach, that (2) it allows the embedding to benefit from unpaired data (unlike previous works), and that (3) using all loss functions we introduced jointly benefits the unseen action recognition the most.	Reply	O	0
We revised the paper to make this more explicit.	Reply	B-Reply	6
As we show in Table 1, we report finding on the effect of the loss functions, and we find that the use of unpaired data is beneficial and all the terms are beneficial.	Reply	I-Reply	6
Also note that we added an experimental results testing the use of different amount of unpaired training videos (Section A.2).	Reply	I-Reply	6
[line_break_token][line_break_token]- How do we obtain related vs. unrelated data ?	Reply	O	0
[line_break_token][line_break_token]Basically, related data means that they are the videos from the same context (e.g., baseball), while unrelated data means that they are from very different context (e.g., baseball in MLB-YouTube vs. office activities in Charades) not sharing any similar video segments or text sentences.	Reply	B-Reply	1
In the revised paper, we have added a section and experiments comparing different sources/strategies for obtained unpaired data (Table 4).	Reply	I-Reply	1
We were able to observe that the performance drops when adding unpaired random sentences or random dictionary definitions.	Reply	I-Reply	1
On the other hand, when we only add sentences of 'verb' definitions which are relevant to actions by their nature, there was a gain in performance.	Reply	I-Reply	1
Unpaired videos usually helped since they at least benefit learning better feature representations.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]- New dataset annotation details:[line_break_token][line_break_token]The MLB-YouTube Captions dataset we collected contains annotations that are transcriptions of the *real MLB broadcast* announcers commentary.	Reply	O	0
No additional annotator was used.	Reply	B-Reply	3
Figure 4 contains examples of the annotations.	Reply	I-Reply	3
Previous MLB-Youtube dataset annotations were simply class labels and time intervals (i.e., no text or language data).	Reply	I-Reply	3
We made this more explicitly clear in the revised paper.	Reply	I-Reply	3
[line_break_token][line_break_token]- "The evaluation for the unsupervised discovery seems biased".	Reply	O	0
[line_break_token][line_break_token]Following the suggestion of the reviewer, we added mAP results to the unsupervised activity discovery methods (Table 5).	Reply	B-Reply	2
It confirms similar findings.	Reply	I-Reply	2
[line_break_token][line_break_token]- Biased UCF sentences?	Reply	O	0
[line_break_token][line_break_token]Regarding the activity sentences in the appendix, they are per-action.	Reply	B-Reply	4
The captions were obtained by an annotator writing a sentence for a random video from the dataset.	Reply	I-Reply	4
We conducted additional experiments, and found that the use of ‚Äúman,‚Äù ‚Äúwoman,‚Äù ‚Äúboy,‚Äù ‚Äúgirl,‚Äù ‚Äúperson,‚Äù or ‚Äúpeople‚Äù did not meaningfully impact results.	Reply	I-Reply	4
Specifically, we conducted experiments by randomly replacing those pronouns in the sentences.	Reply	I-Reply	4
We added the results in Table 12 in the appendix.	Reply	I-Reply	4
[line_break_token][line_break_token]We further examined the embedding of the sentences by switching the pronouns, and found that they all were quite close together (average distance of 0.08 for the same sentence with different pronouns, while the average distance of different activity sentences was 0.86 in the embedding space).	Reply	I-Reply	4
We are focusing on the "action recognition" problem where the verbs are the most meaningful information, and we confirm that our CNN embedding learns to ignore the impact of pronoun changes.	Reply	I-Reply	4

The authors study a bandit problem where there are multiple agents (say, M) and each of the agents is playing a multi-armed bandit problem for T rounds.	Review	O	0
The agents can communicate with each other in order to achieve small regret.	Review	O	0
The problem is to design a strategy for arm-playing and communication so that the agents all combined can achieve a small regret w/o communicating a lot.	Review	O	0
The authors study this bandit problem in 2 settings: 1.	Review	O	0
multi-armed bandit setting and 2.	Review	O	0
 bandit linear optimization.	Review	O	0
For both these settings, the authors establish elimination style algorithms with communication.	Review	O	0
upon communication the sub-optimal arms are eliminated and the game continues with the remaining arms.	Review	O	0
[line_break_token]The authors establish regret guarantees as well as communication guarantees.	Review	O	0
The interesting result is that with constant communication the regret scales as if full communication was available.	Review	O	0
 [line_break_token][line_break_token]The results are interesting and I do not have any objections with the paper, except that ICLR might not be the right avenue for such work given that it lacks any ideas regarding representation learning.	Review	O	0
e thank anonymous reviewer 1 for the review.	Reply	O	0
[line_break_token][line_break_token]Regarding the ICLR venue: Our work focuses on parallelization and distributed learning, which is also a research topic in representation learning.	Reply	O	0
We believe our results can bring insight to other distributed learning problems.	Reply	B-Reply	1
Besides, the linear bandit studied in our paper is a special case of contextual bandit.	Reply	I-Reply	1
We notice that several contextual bandit papers have been published on ICLR in the past a few years.	Reply	I-Reply	1
Extending our work to contextual bandit is a future direction.	Reply	I-Reply	1

This paper presents a family of parameterized composite activation functions, and a regularization technique for parameterized activation functions in general.	Review	B-Review	1
While the three sets of experiments show potentially promising results, they aren't able to disambiguate clearly between the effect of the activation function you introduce and the effect of additional parameters in general, or between the effect of the regularization technique you introduce and the effect of regularization in general.	Review	I-Review	1
I would really like to see the kind of carefully baselined, ablated, and hyperparameter-tuned results that would justify adding the techniques introduced to the toolbox of a typical deep learning practitioner.	Review	I-Review	1
[line_break_token][line_break_token]Some feedback:[line_break_token][line_break_token]Typos:[line_break_token]- The formatting is off a bit (shifted horizontally?)	Review	O	0
[line_break_token]- In the abstract: RPeLu -&gt; PReLU[line_break_token]- p. 5: "basement settings"-&gt;baseline, "logarithmic sale"-&gt;scale[line_break_token]- p. 6: basement-&gt;baseline again[line_break_token]- p. 7 etc.:	Review	O	0
trail-&gt;trial[line_break_token][line_break_token]Feedback:[line_break_token]- Intro:[line_break_token]  - Explain why maxout is similar to training piecewise activation functions?	Review	O	0
[line_break_token]  - It's unclear what "making the most of the non-linear properties by introducing adaptation policy on the input" means[line_break_token]  - An "autoencoder" is not an architecture as much as a broad family of architectures coupled with training approaches (I'm guessing you mean a fully-connected autoencoder)[line_break_token]- Methodology:[line_break_token]  - consider using "f" instead of "a" so it's easier to tell apart from alpha?	Review	O	0
[line_break_token]- Experiments:[line_break_token]  - I'm not sure I'm convinced by the statistical tests used on the LSTM results; they demonstrate that your approach, with a few specific sets of hyperparameter settings, does better than the baseline, but not that this represents a valid claim about your activation function's effect on this LSTM model in general.	Review	O	0
[line_break_token]  - The autoencoder experiments are even less convincing, in that they represent two seemingly arbitrary network architectures, with equally arbitrary placement of the activation function in one of them.	Review	O	0
[line_break_token]  - The regularization experiments use LeNet-5, which is not a compelling benchmark architecture with respect to contemporary practice.	Review	O	0
The effects of regularization techniques can be very different in different regimes of dataset and network size.	Review	B-Review	9
[line_break_token]- Code:[line_break_token]  - I'm not sure why you performed backprop by hand for your activation functions and used torch.	Review	O	0
Function, rather than writing them directly as nn.	Review	B-Review	10
Modules that make use of PyTorch autograd[line_break_token]  - There are lots of details in the code that aren't in the paper; in general, papers should aim to be relatively self-contained (although I'm very glad to see your code, and it's pretty simple to follow)	Review	O	0
hanks very much for your time and feedback.	Reply	O	0
[line_break_token][line_break_token]Review:[line_break_token]-[tab_token]We will try to add more experimental results for checking the effects of proposed flexible activation functions by comparing with baseline models.	Reply	O	0
[line_break_token]Typos:[line_break_token]-[tab_token]Thanks for pointing out the typos, we have corrected them in the updated version, which will be uploaded later.	Reply	O	0
[line_break_token][line_break_token]Feedback:[line_break_token]a.[tab_token]Intro[line_break_token]-[tab_token]In the original paper of maxout (Goodfellow et al.	Reply	O	0
2013), the output of each hidden unit with maxout activation is the maximum of k affine feature maps.	Reply	B-Reply	3
In each piece of input space, it takes the affine function with the largest output value, which lead to a convex piece-wise function that can be used to approximate any convex functions.	Reply	I-Reply	3
[line_break_token]-[tab_token]In the original paper (Yang et al.	Reply	O	0
2018), they model the context and the conditional next-token distribution as a softmax function, while the context vector h and word embedding w depend on the input next tokens and context with learnable parameters, which can increase the model capacity to be more adaptive to high rank language models with non-linear properties.	Reply	B-Reply	4
We will try to improve the expression in the updated version.	Reply	I-Reply	4
[line_break_token]-[tab_token]I think we have already used ‚Äúdeep auto-encoder based on neural networks‚Äù and ‚Äúfully connected auto-encoder‚Äù in the first paragraph of section 3.2, but shorten it to ‚Äúauto-encoder‚Äù in later context to reduce the length of the paper.	Reply	O	0
The ‚Äúauto-encoder‚Äù in the abstract has been changed to ‚Äúfully connected auto-encoder‚Äù in the updated version.	Reply	B-Reply	5
[line_break_token]b.[tab_token]Methodology[line_break_token]-[tab_token]We will update the notation ‚Äúa‚Äù in the equations to ‚Äúf‚Äù.	Reply	O	0
[line_break_token]c.[tab_token]Experiments[line_break_token]-[tab_token]In our experiments, we find that in all architectures of multi-layer LSTM being tested, the newly proposed flexible sigmodal activation and its regularized version achieves an improvement, and most of them are statistically significant.	Reply	O	0
As we know, in general the goodness of activation function depends on the learning tasks and the model architectures.	Reply	B-Reply	7
Even PRelu cannot outperform the baseline models with Relu in all image classification tasks with CNNs.	Reply	I-Reply	7
Thus we think if it can provide a significant improvement for a proportion of tasks and architectures, we can consider it as a discrete hyper-parameter in a list with other promising baseline activation functions, which is much more computational efficient than trying a new architecture with hyper-parameter optimization from scratch.	Reply	I-Reply	7
[line_break_token]-[tab_token]We know that LeNet-5 is a relatively small model that does not provide competitive results on CIFAR-10.	Reply	O	0
However, considering our limited computational resources, it seems to be computational expensive and time consuming to train large models such as Resnet for a relatively large number of times for hyper-parameter optimization and statistical test.	Reply	B-Reply	9
We find most related study on flexible activation functions only perform 5-10 runs without statistical test.	Reply	I-Reply	9
[line_break_token]d.[tab_token]Code[line_break_token]-[tab_token]We define an independent function with backward path considering the possibility for introducing non-differentiable components into our flexible activation functions.	Reply	O	0
In fact, the newly proposed flexible sigmodal activation involves a piecewise function, whose derivative may not be calculated with pytorch.	Reply	B-Reply	10
[line_break_token]-[tab_token]We will try to make more explanation for the experimental details in the updated version.	Reply	O	0

This paper proposes to feed the representations of various external "teacher" neural networks of a particular example as inputs to various layers of a student network.	Review	O	0
[line_break_token]The idea is quite intriguing and performs very well empirically, and the paper is also well written.	Review	O	0
 While I view the performance experiments as extremely thorough, I believe the paper could possibly use some additional ablation-style experiments just to verify the method actually operates as one intuitively thinks it should.	Review	O	0
  [line_break_token][line_break_token]Other Comments:[line_break_token][line_break_token]- Did you verify that in Table 3, the p_w values for the teachers trained on the more-relevant C10/C100 dataset are higher than the p_w value for the teacher trained on the SVHN data?	Review	O	0
 It would be interesting to see the plots of these p_w over the course of training (similar to Fig 1c) to verify this method actually operates as one intuitively believes it should.	Review	B-Review	1
[line_break_token][line_break_token]- Integrating the teacher-network representations into various hidden layers of the student network might also be considered some form of neural architecture search (NAS)  (by including parts of the teacher network into the student architecture).	Review	O	0
[line_break_token]See for example the DARTS paper: <a href="https://arxiv.org/abs/1806.09055" target="_blank" rel="nofollow">https://arxiv.org/abs/1806.09055</a>[line_break_token]which similarly employs mixtures of potential connections.	Review	O	0
 [line_break_token]Under this NAS perspective, the dependence loss subsequently distills the optimal architecture network back into the student network architecture.	Review	B-Review	2
[line_break_token][line_break_token]Have you verified that this method is not just doing NAS, by for example, providing a small student network with a few teacher networks that haven't been trained at all? (	Review	I-Review	2
i.e. should not permit any knowledge flow)[line_break_token][line_break_token]- Have the authors considered training the teacher networks jointly with the student?	Review	O	0
This could be viewed as teachers learning how to improve their knowledge flow (although might require large amounts of memory depending on the size of the teacher networks).	Review	B-Review	3
[line_break_token][line_break_token]- Suppose we have an L-layer student network and T M-layer teacher networks.	Review	O	0
[line_break_token]Does this imply we have to consider O(L*M*T) additional weight matrices Q?	Review	B-Review	4
[line_break_token]Can you comment on the memory requirements?	Review	I-Review	4
[line_break_token][line_break_token]- The teacher-student setup should be made more clear in Tables 1 and 2 captions (took me some time to comprehend).	Review	O	0
[line_break_token][line_break_token]- The second and third paragraphs are redundant given the Related Work section that appears later on.	Review	O	0
I would like to see these redundancies minimized and the freed up  space used to include more results from the Appendix in the main text.	Review	B-Review	6
[line_break_token]	Review	O	0
Updated: Changed section numbers to fit latest revision.	Reply	O	0
[line_break_token]---------------------------------------------------------------------------[line_break_token]We thank the reviewer for time and feedback.	Reply	O	0
[line_break_token][line_break_token]Re 1: plot p_w values for C10/C100 dataset.	Reply	O	0
[line_break_token]In the newly added Fig.	Reply	B-Reply	1
4 and the corresponding discussion (Sec.	Reply	I-Reply	1
4.2), we plot the weight (p_w) for teachers and the student in the C10/C100 experiment, where C100 and SVHN experts are teachers.	Reply	I-Reply	1
As expected and intuitively, the C100 teacher should have higher p_w value than the SVHN based teacher, because C100 is more relevant to C10.	Reply	I-Reply	1
The plot verifies this intuition, p_w of the C100 teacher is higher than that of the SVHN teacher during the entire training.	Reply	I-Reply	1
Both teachers‚Äô normalized weights approach zero at the end of training.	Reply	I-Reply	1
[line_break_token][line_break_token]Re 2: verify Knowledge Flow is not just NAS.	Reply	O	0
[line_break_token]As the reviewer pointed out, one key difference between NAS and Knowledge Flow is that a student in Knowledge Flow benefits from teachers‚Äô knowledge.	Reply	B-Reply	2
To verify that the student really benefits from the knowledge of teachers, we conduct the ablation study suggested by the reviewer.	Reply	I-Reply	2
In the newly added experiment, discussed in Sec.	Reply	I-Reply	2
7.3.1 and summarized in Fig.	Reply	I-Reply	2
8, teachers are models that haven‚Äôt been trained at all.	Reply	I-Reply	2
Intuitively, learning with untrained teachers should have worse performance than learning with knowledgeable teachers.	Reply	I-Reply	2
Our experiments verify this intuition.	Reply	I-Reply	2
Considering Fig.	Reply	I-Reply	2
8 (a), where the target task is hero, learning with untrained teachers achieves an average reward of 15934, while learning with knowledgeable teachers (experts of Seaquest and Riverraid) achieves an average reward of 30928.	Reply	I-Reply	2
Consistently with all other experiments we average over five runs.	Reply	I-Reply	2
More results are presented in Fig.	Reply	I-Reply	2
8 (b, c).	Reply	I-Reply	2
The results show that Knowledge Flow achieves higher rewards than NAS in different environments and teacher-student settings.	Reply	I-Reply	2
[line_break_token][line_break_token]Re 3: training teacher networks jointly.	Reply	O	0
[line_break_token]We did try to train teachers jointly with students.	Reply	B-Reply	3
However, as the reviewer mentioned, the memory usage is large and training is very slow.	Reply	I-Reply	3
Up until now we didn‚Äôt observe any improvements.	Reply	I-Reply	3
[line_break_token][line_break_token]Re 4: memory requirement for matrices Q. [line_break_token]The upper bound of the number of Q matrices in our framework is O(L*M*T).	Reply	O	0
In practice, we don‚Äôt link a student‚Äôs layer to every layer of a teacher network.	Reply	B-Reply	4
For example, we observed that linking a teachers‚Äô bottom layer to a student‚Äôs top layer generally doesn‚Äôt yield improvements.	Reply	I-Reply	4
Intuitively, a teachers‚Äô bottom layer features are very likely irrelevant to a student‚Äôs top layer features.	Reply	I-Reply	4
Therefore, in practice, we recommend to link one teacher layer to one or two student layers, in which case the space complexity is O(L*T).	Reply	I-Reply	4
[line_break_token][line_break_token]Re 5: Captions of Table 1 and Table 2.	Reply	O	0
[line_break_token]We updated the caption of Table 1 and Table 2.	Reply	B-Reply	5
[line_break_token][line_break_token]Re 6: Shorten paragraph 2 and paragraph 3.	Reply	O	0
[line_break_token]We felt shortening paragraph 2 and 3 would remove the motivation of this work.	Reply	B-Reply	6
Shortening the related work section wouldn‚Äôt do justice to our peers.	Reply	I-Reply	6
Therefore at this point we prefer to maintain the current writing unless the majority of the reviewers and the AC feel strongly about shortening.	Reply	I-Reply	6

This paper explores the performance-area-energy-model accuracy tradeoff encountered in designing custom number representations for deep learning inference.	Review	O	0
Common image-based benchmarks: VGG, Googlenet etc are used to demonstrate that fewer than1 6 bits in a custom floating point representation can lead to improvement in runtime performance and energy efficiency with only a small loss in model accuracy.	Review	O	0
[line_break_token][line_break_token]Questions:[line_break_token][line_break_token]1.	Review	O	0
Does the custom floating point number representation take into account support for de-normal numbers?	Review	B-Review	1
[line_break_token]2.	Review	O	0
Is the custom floating point unit clocked at the same frequency as the baseline 32-bit floating point unit?	Review	B-Review	2
If not, what are the different frequencies used and how would this impact the overall system design in terms of feeding the data to the floating point units from the memory[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]1.	Review	O	0
I would recommend using the IEEE half-precision floating point (1bit sign, 5bit exponent, and 10bit mantissa) as a baseline for comparison.	Review	B-Review	4
At this point, it is well known in both the ML and the HW communities that 32-bit floats are an overkill for DNN inference and major HW vendors already include support for IEEE half-precision floats.	Review	I-Review	4
[line_break_token]2.	Review	O	0
In my opinion, the claim that switching to custom floating point  lead to a YY.ZZ x savings in energy is misleading.	Review	B-Review	5
It might be true that the floating-point unit itself might consume less energy due to smaller bit-width of the operands, however a large fraction of the total energy is spent in data movement to/from the memories.	Review	I-Review	5
As a result, reducing the floating point unit‚Äôs energy consumption by a certain factor will not translate to the same reduction in the total energy.	Review	I-Review	5
A reader not familiar with such nuances (for example a typical member of the ML community), may be mislead by such claims.	Review	I-Review	5
[line_break_token]3.	Review	O	0
On a similar note as comment 2, the authors should explicitly mention that the claimed speedup is that of the floating point unit only, and it will not translate to the overall workload speedup.	Review	B-Review	7
Although the speedup of the compute unit is roughly quadratic in the bit-width, the bandwidth requirements scale linearly with bit-width.	Review	I-Review	7
As a result, it is possible that these custom floating point units may be starved on memory bandwidth, in which case the claims of speedup and energy savings need to be revisited.	Review	I-Review	7
[line_break_token]4.	Review	O	0
The authors should also comment on the complexities and overheads introduced in data accesses, designing the various system buses/ data paths when the number representation is not byte-aligned.	Review	B-Review	6
Moving to a custom 14-bit number representation (for example) can improve the performance and energy-efficiency of the floating point unit, but these gains can be partially eroded due to the additional overhead in supporting non-byte aligned memory accesses.	Review	I-Review	6
[line_break_token]	Review	O	0
We thank you for your valuable time and comments.	Reply	O	0
[line_break_token][line_break_token]===Denormal floating-point units[line_break_token]Our evaluated floating-point ALUs do not operate on denormal floating-point representations.	Reply	O	0
Aside from minor differences in empirical results that depend on denormal floating-point arithmetic support, we expect that our conclusions hold.	Reply	B-Reply	1
A different design that operates on denormal floating-point representations will, ideally, allow one less bit in the floating-point exponent for the same accuracy, but will be disadvantaged by increased hardware area, circuit delay, and power.	Reply	I-Reply	1
[line_break_token][line_break_token]===Frequency scaling of customized-precision units[line_break_token]We scale the ALU frequency with the inverse of the hardware circuit delay, so each customized-precision design can have a different frequency.	Reply	O	0
[line_break_token][line_break_token]===Frequency of compute compared to storage[line_break_token]Our DRAM memory and compute clocks (frequencies) are different, which is common across almost all hardware designs (e.g., modern CPU/GPU designs).	Reply	O	0
DRAM memory fabrication is primarily optimized for higher transistor density (i.e. memory capacity) rather than higher frequency, which is opposite of computational units.	Reply	B-Reply	5
[line_break_token][line_break_token]===Validity of MAC results[line_break_token]The MAC operations capture the majority of the DNN performance and power breakdown [1]. Other units will scale with the customized-precision design as well, so we expect that a full-system implementation would show benefits very similar to our results.	Reply	O	0
For example, using 84% [1] as the power used by compute, we find our reported 3.4x savings in energy would become 3.15x (time = 0.84/3.4 + 0.16/(32-bit/14-bit from linear scaling) = 0.31 => speedup = 1/0.31 = 3.15x).	Reply	O	0
[line_break_token][line_break_token]===Compute throughput as DNN bottleneck[line_break_token]The DRAM memory bandwidth requirements for DNNs is much lower than its computational requirements [2]. This is due to matrix multiplication, the central DNN computational kernel, requiring roughly N^2 memory operations (i.e. from loop tiling [3]) compared to N^3 arithmetic operations.	Reply	O	0
[line_break_token][line_break_token]===Customized-precision memory access[line_break_token]DRAM memory access can be left unchanged when using customized-precision compute units.	Reply	O	0
Similar to how GPUs do 32-bit computation efficiently when using a 128- to 512-bit memory bus, a single memory access is distributed to multiple compute units.	Reply	B-Reply	6
For example, a 128-bit bus provides data to nine 14-bit compute units.	Reply	I-Reply	6
[line_break_token][line_break_token][1] ShiDianNao: Shifting Vision Processing Closer to the Sensor.	Reply	O	0
ISCA 2015.	Reply	O	0
Zidong Du, et al.	Reply	O	0
[line_break_token][2] DjiNN and Tonic: DNN as a Service and Its Implications for Future Warehouse Scale Computers.	Reply	O	0
ISCA 2015.	Reply	O	0
Hauswald, et al.	Reply	O	0
[line_break_token][3] Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks.	Reply	O	0
FPGA 2015.	Reply	O	0

The paper presents an approach to extract a character from a video and then maneuver that character in the plane, optionally with other backgrounds.	Review	O	0
The character is then redrawn into the background with a neural net, and all of this is done in real time.	Review	O	0
[line_break_token][line_break_token]All in all, this paper was well structured and extensively detailed wrt how it engineered this solution (and why).	Review	O	0
If I had a complaint, it would be that I did not learn anything scientifically from the paper.	Review	B-Review	1
There isn't a tested hypothesis, but rather it's a feat of engineering to get this to work.	Review	I-Review	1
Those are important as well for the field, and I suspect that this direction could be pushed a lot more.	Review	I-Review	1
For example, it's not close to getting realistic spatial movement relative to the plane nor is the control that impressive wrt limbs.	Review	I-Review	1
However, as a next-contribution, this work deserves to be seen more widely.	Review	O	0
[line_break_token][line_break_token]Hence, I rate it as a weak accept.	Review	O	0
e agree with most of the comments	Reply	B-Reply	1

The proposed self supervised loss is formulated using a Siamese architecture and encourages patches from the same image to lie closer in feature space than a contrasting patch taken from a different, random image.	Review	O	0
The loss is very similar in spirit to that of Doersch et al.	Review	B-Review	1
ICCV 2015 and Isola et al.	Review	I-Review	1
ICLR 2016 workshop.	Review	I-Review	1
It seems that the proposed loss is actually a simplified version of Doersch et al.	Review	I-Review	1
ICCV 2015 in that it does not make use of the spatial offset, a freely available self supervised signal in natural images.	Review	I-Review	1
Intuitively, it seems that the self-supervised problem posed by this method is strictly simpler, and therefore less powerful, than that of the aforementioned work.	Review	I-Review	2
I would like to see more discussion on the comparison of these two approaches.	Review	I-Review	2
Nevertheless the proposed method seems to be effective in achieving good empirical results using this simple loss.	Review	I-Review	3
Though more implementation details should be provided, such as the effect of patch size, overlap between sampled patches, and any other important measures taken to avoid trivial solutions.	Review	I-Review	3
Thank you for the review, we appreciate your remarks and incorporated them into latest revision.	Reply	O	0
[line_break_token]We would like to emphasize some difference between our work and that of Doersch 2015.	Reply	B-Reply	1
Although both works used patches from an image to learn unsupervised learning, the method is quite different.	Reply	I-Reply	1
Whereas Doersch used a classification criterion over the spatial location of each patch within a single image, our work is concerned comparing patches from several images to each other using a distance ratio loss.	Reply	I-Reply	1
We claim that this encourage discriminability between images (which we feel to be important aspect of feature learning), and is not an explicit goal in the work of Doersch.	Reply	I-Reply	1
Thus, we feel that both approaches are viable methods for unsupervised learning using samples from spatial data.	Reply	I-Reply	1
We will include this distinction in our revision as well as the implementation details that you indicated missing	Reply	I-Reply	1

1.	Review	O	0
[tab_token]Some motivation of extending the adversarial examples generation on manifold should be there.	Review	O	0
[line_break_token]2.	Review	B-Review	4
[tab_token]Even if \epsilon is small, if x is on a manifold, x+\epsilon may not, so I am not sure about the validity of the definition in Eq. (	Review	O	0
7) and what follows from here.	Review	B-Review	2
One solution is putting the constraint d(x, Exp_x(\epsilon)) \leq \sigma, which implies that g(\epsilon, \epsilon) \leq \sigma.	Review	I-Review	2
[line_break_token]Also, x and \epsilon lies in completely different space, \epsilon should lie on the tangent space at x. So, I don‚Äôt understand why x+\epsilon makes sense?	Review	I-Review	2
It makes the rest of the formulation invalid as well.	Review	I-Review	2
[line_break_token]3.	Review	O	0
[tab_token]I don‚Äôt understand why in Eq. (	Review	O	0
12), d(x, x+\epsilon)^2 = |m(x)|?	Review	B-Review	3
Do authors want it to be equal, otherwise, I can not see why this equality is true.	Review	I-Review	3
[line_break_token]4.	Review	I-Review	5
[tab_token]In Lemma 2.3, please make H in \mathbb{R}^{n\times n} instead of \mathbb{R}^n \times \mathbb{R}^n (same issue for Lemma 2.4), later does not make sense in this context.	Review	O	0
Also, why not write |H|=U|\Sigma|U^T, instead of what you have now.	Review	B-Review	4
[line_break_token]5.	Review	O	0
[tab_token]No need to prove Lemma 2.3 and 2.4.	Review	O	0
These are well-known results in matrix linear algebra.	Review	B-Review	5
[line_break_token]6.	Review	O	0
[tab_token]It‚Äôs nice that the authors generalize to l_p ball and can show FGSM as a special case.	Review	O	0
[line_break_token]7.	Review	B-Review	10
[tab_token]Some explanation of Algo.	Review	O	0
2 should be there in the main paper given that it is a major contribution in the paper and also authors put a paper more than 8 pages long, so as a reader/ reviewer I want more detailed explanation in the main body.	Review	B-Review	7
[line_break_token]8.	Review	O	0
[tab_token]In Algorithm 1, step 7: ‚ÄúUpdate the parameters of neural network with stochastic gradient‚Äù should be updated in the negative direction of gradient.	Review	O	0
[line_break_token]9.	Review	O	0
[tab_token]Algorithm 2 is clearly data driven.	Review	O	0
So, can authors comment on special cases of Algorithm 2 when we explicitly know the Riemannian metric tensor, e.g., when data is on hypersphere.	Review	B-Review	9
[line_break_token]10.	Review	O	0
[tab_token]Can authors comment on the contemporary work <a href="https://arxiv.org/pdf/1807.05832.pdf," target="_blank" rel="nofollow">https://arxiv.org/pdf/1807.05832.pdf,</a> as the purpose is very similar.	Review	O	0
[line_break_token]11.	Review	O	0
[tab_token]The experimental validation is nice and showed usefulness of the proposed method.	Review	O	0
[line_break_token][line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
[tab_token]A framework to show the usefulness of non-Euclidean geometry, specifically curvature for adversarial learning.	Review	O	0
[line_break_token]2.	Review	B-Review	4
[tab_token]Nice set of experimental validation.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
[tab_token]Some theorems statement can be ignored to save space, e.g., Lemma 2.3 and 2.4.	Review	O	0
And instead, need some explanation of Algorithm 2 in the main text.	Review	B-Review	5
Right now, not enough justification of additional page.	Review	I-Review	5
[line_break_token]2.	Review	I-Review	4
[tab_token]Not sure about the validity of the main formulation, Eq. (	Review	O	0
7) and other respective frameworks when data x is on a manifold.	Review	B-Review	2
[line_break_token][line_break_token]Minor comments:[line_break_token]1.	Review	O	0
[tab_token]In page 2, ‚ÄúIn this case, the Euclidean metric would be not rational.	Review	O	0
‚Äù-> ‚ÄúIn this case, the Euclidean metric would not be rational‚Äù.	Review	O	0
[line_break_token]2.	Review	B-Review	4
[tab_token] ‚ÄúHowever, in a geometric manifold, particularly in Riemannian space, the gradient of a loss function unnecessarily presents the steepest direction.	Review	O	0
‚Äù Not sure what authors meant by ‚Äúunnecessarily presents‚Äù[line_break_token]3.	Review	O	0
[tab_token]No need to reprove Lemma 2.2, just give reference to a differential geometry textbook like Chavel or Boothby.	Review	O	0
[line_break_token][line_break_token]I want the authors to specifically address the cons.	Review	O	0
We define the Riemannian manifold with the dimension, where all the data lie on it.	Reply	O	0
Here the low-dimensional is not defined in but in the Riemannian manifold space.	Reply	O	0
Under our assumption, both the natural example and perturbed example are in the-dimensional Riemannian space (not again).	Reply	O	0
One example can be seen in the response to Q9.	Reply	O	0
[line_break_token]When the perturbation is small enough, we can approximate the geodesic distance between and by.	Reply	O	0
Then we can define the ball with metric on the Riemannian space as (15) in the paper.	Reply	O	0
Different from the Euclidean space, we define the ball with the Riemannian metric. (	Reply	O	0
The ball in Euclidean is defined by the Euclidean metric).	Reply	O	0
Our aim is to find the direction in which we move a point on a dimensional manifold with a small constant distance, which can enlarge the loss function the biggest.	Reply	O	0
[line_break_token][line_break_token]To Q1:[line_break_token]On one hand, the Riemannian space is a generalized case of Euclidean space.	Reply	O	0
A study on the generalized case could offer us new perspectives on adversarial examples.	Reply	B-Reply	1
As a matter of fact,[line_break_token]it is quite often that data sit not in a Euclidean space but have a Riemannian metric structure.	Reply	I-Reply	1
In these cases, the ordinary gradient does not lead to a steepest descent direction of the target function.	Reply	I-Reply	1
Therefore, it would be important to extend the adversarial examples generation on manifold which we could adjust to find the steepest direction.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]To Q2:[line_break_token]If natural data are on a low dimensional manifold in, it is true that may be not on the manifold.	Reply	O	0
However, in this paper, we assume all the data are in the-dimensional Riemannian space.	Reply	B-Reply	2
Therefore, the natural example and non-natural example are both on the Riemannian manifold.	Reply	I-Reply	2
 Moreover, the ball on it can be defined by.	Reply	I-Reply	2
[line_break_token][line_break_token]To Q3:[line_break_token]We regret that the expression caused a confusion.	Reply	O	0
We have reformulated this in the revised paper.	Reply	B-Reply	3
We also clarify it here.	Reply	I-Reply	3
First, we derived in Section 2.2 an optimization problem in the general Riemannian manifold space that is exclusively decided by the metric tensor.	Reply	I-Reply	3
In Section 2.3, we then defined a special metric tensor (or special Riemannian manifold space) based on the loss function.	Reply	I-Reply	3
Such special metric tensor is reasonable for adversarial examples, since adversarial examples are closely related to the loss function and classification boundary.	Reply	I-Reply	3
On the other hand, there are also other ways of defining a metric tensor (e.g., the famous fisher information matrix), which could be chosen in practice.	Reply	I-Reply	3
[line_break_token][line_break_token]To Q4, 5, 8:[line_break_token]Following your comments, these have been corrected in the revised submission.	Reply	O	0
[line_break_token][line_break_token]To Q7:[line_break_token]More explanations about Algo.2 have been added in the revised submission.	Reply	O	0
[line_break_token][line_break_token]To Q9:[line_break_token]Algorithm 2 presents the calculation for product of matrix and vector.	Reply	O	0
In this paper, we construct the Riemannian manifold with the metric tensor defined by absolute Hessian matrix.	Reply	B-Reply	9
Therefore, the worst perturbation is approximated as.	Reply	I-Reply	9
For an arbitrary manifold with metric tensor, the steepest direction is.	Reply	I-Reply	9
For example, consider a 2-dimensional manifold defined by a surface (within the 3-dimensional Euclidean space), defined with the metric tensor.	Reply	I-Reply	9
Let the input be and be the loss function of DNN.	Reply	I-Reply	9
Then the steepest direction for Loss function on this surface is.	Reply	I-Reply	9
[line_break_token][line_break_token]To Q10:[line_break_token]This paper has been well noted.	Reply	O	0
Their purposes/motivations are quite different between the paper and ours.	Reply	B-Reply	10
In the mentioned paper, the aim is to exploit the adversarial training to smooth the low dimensional statistic manifold.	Reply	I-Reply	10
In this work, we focus on generating and resisting the adversarial examples through the perspective of the geometry.	Reply	I-Reply	10
These two approaches could even be combined.	Reply	I-Reply	10
[line_break_token]	Reply	O	0

The paper tackles a major issue in distributed learning in general (and not only the federated scheme), which is communication bottleneck.	Review	O	0
[line_break_token][line_break_token]I am not fully qualified to judge and would rather listen to the opinion of more qualified reviewers, I was annoyed by some aspects of the paper:[line_break_token][line_break_token]1) many claims required formal support (proofs), as an example: "more aggressive dropout rates ted to slow down the convergence rate of the model, even if they sometimes result in a higher accuracy" is a statement that would benefit from analyzing the dropout out effect on convergence, something that wouldn't be hard to do given the extensive theoretical toolbox on distributed optimization.	Review	O	0
[line_break_token][line_break_token]2) no comparison with other compression schemes (see e.g. Alistarh et al.	Review	O	0
's ZipML (NIPS or ICML 2017) and followups)[line_break_token][line_break_token]3) proving an unbiased-ness guarantee out of the Probabilistic quantization (section 3.1) would have been a minimal requirement in my opinion.	Review	O	0
[line_break_token][line_break_token]I encourage the authors to further expand those points, but would happily lighten-up my skepticism if more qualified reviewers say that we do not need such guarantees as the one in point 1 and 3. (	Review	O	0
the few compression papers I know provide that)	Review	O	0
We thank the reviewer for their comments and for highlighting the relevance of our work for the broader distributed learning community.	Reply	O	0
We proceed to address the three points you raised:[line_break_token][line_break_token]1) The particular observation you mention is in line with previous empirical observations of the effect of (standard) dropout.	Reply	O	0
We don‚Äôt analyse this effect, however, as we are not aware of any rigorous argument of why standard dropout works in the first place.	Reply	B-Reply	1
We understand dropout as a heuristic that has proven to be incredibly useful and is backed by some interesting intuitions, but not as a principled approach for which we can prove convergence.	Reply	I-Reply	1
[line_break_token][line_break_token]2) The ZipML framework proposes using lower precision at various parts of the training pipeline.	Reply	O	0
Many of these ideas are orthogonal, yet compatible with what we propose.	Reply	B-Reply	2
The parts that can be seen as alternatives to our methods (i.e. compressing gradients) are best summarized in algorithms such as QSGD or Terngrad (also called out by another reviewer).	Reply	I-Reply	2
We copy our response here: [line_break_token][line_break_token]We did not compare with these for two reasons.	Reply	O	0
[line_break_token]a) These methods were proposed for compression of gradient updates.	Reply	B-Reply	2
In particular, the Terngrad paper argues for using the empirical distributions of the coefficients of such gradients.	Reply	I-Reply	2
Even though those arguments would not directly apply to our setting, we could probably still use it for the Client-to-Server compression.	Reply	I-Reply	2
However, we do not see a good reason why the proposal would be useful for compressing the state of the model being trained (i.e. Server-to-Client), which is the central concern of our paper.	Reply	I-Reply	2
[line_break_token]b) We performed a series of preliminary experiments where we compressed a variety of random vectors using QSGD and other techniques.	Reply	O	0
The results of these small experiments suggested that in the tradeoff between accuracy and representation size, (I) uniform quantization was dominated by QSGD, and (II) QSGD was in turn dominated by the combination of Kashin‚Äôs representation and uniform quantization.	Reply	B-Reply	2
[line_break_token][line_break_token]3) The proof of this is elementary, and we do not want to appear to claim it is a novel insight.	Reply	O	0
We are happy to provide explicit reference to an existing, more general argument, e.g., one in Suresh et al.	Reply	B-Reply	3
or in Konecny and Richtarik, both of which we cite.	Reply	I-Reply	3
[line_break_token][line_break_token]If you have other concrete comments on what would strengthen the paper, we will be more than happy to incorporate them.	Reply	O	0

SUMMARY.	Review	O	0
[line_break_token][line_break_token]The paper presents a novel approach to procedural language understanding.	Review	O	0
[line_break_token]The proposed model reads food recipes and updates the representation of the entities mentioned in the text in order to reflect the physical changes of the entities in the recipe.	Review	O	0
[line_break_token]The authors also propose a manually annotated dataset where each passage of a recipe is annotated with entities, actions performed over the entities, and the change in state of the entities after the action.	Review	O	0
[line_break_token]The authors tested their model on the proposed dataset and compared it with several baselines.	Review	O	0
[line_break_token][line_break_token][line_break_token]----------[line_break_token][line_break_token]OVERALL JUDGMENT[line_break_token]The paper is very well written and easy to read.	Review	O	0
[line_break_token]I enjoyed reading this paper, I found the proposed architecture very well thought for the proposed task.	Review	B-Review	1
[line_break_token]I would have liked to see a little bit more of analysis on the results, it would be interesting to see what are the cases the model struggles the most.	Review	I-Review	1
[line_break_token][line_break_token]I am wondering how the model would perform without intermediate losses i.e., entity selection loss and action selection loss.	Review	I-Review	2
[line_break_token]It would also be interesting to see the impact of the amount of 'intermediate' supervision on the state change prediction.	Review	I-Review	2
[line_break_token][line_break_token]The setup for generation is a bit unclear to me.	Review	I-Review	3
[line_break_token]The authors mentioned to encode entity vectors with a biGRU, do the authors encode it in order of appearance in the text?	Review	I-Review	3
would not it be better to encode the entities with some structure-agnostic model like Deep Sets?	Review	I-Review	3
[line_break_token][line_break_token]	Review	O	0
We thank the reviewer for their positive feedback.	Reply	O	0
We share the same excitement about the potential for knowledge-guided architectures that simulate world dynamics.	Reply	O	0
[line_break_token][line_break_token]We‚Äôve edited the paper to show more analysis examples.	Reply	B-Reply	1
We‚Äôd originally shown examples that presented interesting case studies on the model‚Äôs capabilities.	Reply	I-Reply	1
We‚Äôve now added other interesting cases that the model fails to handle, but that future simulators would need to capture to correctly model the domain.	Reply	I-Reply	1
[line_break_token][line_break_token]--- Intermediate Losses for learning with Distant Supervision ---[line_break_token]Thanks for the question about the impact of the intermediate modular loss as that was one of the key investigation points of our work: whether a neural network trained with a single loss (with distant supervision) could learn the internal dynamics of the task, or whether adding additional losses as guides (with additional distant supervision) would promote the architected inductive biases.	Reply	O	0
This investigation point is a direct consequence of the fact that we do not assume a manually constructed dataset that provides sufficient annotated labels that support directly learning implied action dynamics.	Reply	B-Reply	2
Instead, we make use of naturally existing data as is, and investigate the role of the modular architecture and distantly supervised intermediate losses for learning latent structure.	Reply	I-Reply	2
[line_break_token][line_break_token]To provide more detailed comments about the intermediate loss: without the entity selection and the action selection loss, the model would not learn the necessary bias to use the correct actions and entities in predicting the final states.	Reply	I-Reply	2
Pretraining the action selector was also especially useful as it allowed the model to use the correct action embeddings when predicting the state changes that were happening in each step.	Reply	I-Reply	2
This allowed errors in predicting the final states to be backpropagated to the correct action embeddings from the start.	Reply	I-Reply	2
[line_break_token][line_break_token]We also think it‚Äôs an interesting question to see how many examples the model must see during training to learn to select entities and simulate state changes.	Reply	I-Reply	2
We thought about including experiments that randomly dropped a percentage of the training set labels and will add these ablations in the final paper.	Reply	I-Reply	2
[line_break_token][line_break_token]--- Generation Modeling Variations ---[line_break_token]We appreciate the reviewer‚Äôs suggestion for using deep sets to encode the state vectors and agree that it seems like a better modeling fit at an intuitive level.	Reply	O	0
While we did not try deep sets as an encoding method, in our pilot study, we explored several attention mechanisms over both the context words and the entity state vectors, and we found that the simple sequential encoding leads to the best performance, a conclusion that had also been found in prior work (Kiddon et al.	Reply	B-Reply	3
2016).	Reply	I-Reply	3
We will look into deep sets as an encoding mechanism and report it in the final paper if helpful.	Reply	I-Reply	3

The work explores the problem of robustness and adversarial[line_break_token]attacks in NN.	Review	O	0
In a multiclass prediction setting the idea[line_break_token]is to use a taylor expansion of a loss coined CCKL which[line_break_token]is the KL divergence between predictions for pairs of samples[line_break_token]from different classes.	Review	O	0
[line_break_token][line_break_token]The papers seems to find a convoluted route to arrive[line_break_token]to something like this: when the Fisher information matrix[line_break_token]has a strong eigenvalue the model is not robust.	Review	B-Review	4
In other words[line_break_token]it says that if the landscape close to convergence has[line_break_token]valleys, or fast changes, the model is not robust.	Review	I-Review	1
[line_break_token]This appears quite obvious and related to previous similar[line_break_token]studies.	Review	I-Review	1
[line_break_token][line_break_token]This statement is then empirically evaluated on CIFAR-10.	Review	O	0
[line_break_token][line_break_token]The mathematical derivations should be made more rigorous.	Review	B-Review	2
[line_break_token]For example the paragraph on Cramer-Rao bound is very handwavy.	Review	I-Review	2
[line_break_token][line_break_token]Typos[line_break_token][line_break_token]-  is found these  -&gt;  is found that these	Review	O	0
hanks for your efforts in reviewing our work.	Reply	O	0
Unfortunately, we have to point out your misunderstanding in our work.	Reply	B-Reply	4
The main idea of our work is NOT focused on the relation between Fisher's eigen value and robustness.	Reply	I-Reply	4
This relation is simply one bedrock for our conclusion.	Reply	I-Reply	4
[line_break_token][line_break_token]Our main purpose of this work is to reveal the relation between standard performance and adversarial robustness.	Reply	I-Reply	4
It has been observed that an adversarial robust DNNs usually don't have a comparable standard performance with standard DNNs.	Reply	I-Reply	4
However, there is no previous work rigorously showing the underlying reason behind this phenomenon.	Reply	I-Reply	4
In our work, we theoretically reveal this little understood relation by disentangling the non-robust and robust component in a proposed performance metric.	Reply	I-Reply	4
We show that the model could rely on both the non-robust component as well as robust component to boost performance.	Reply	I-Reply	4
And if the model relies heavily on the non-robust component to distinguish data from different categories, it will enjoy a high standard performance, but will also be adversarial vulnerable at the same time.	Reply	I-Reply	4
[line_break_token][line_break_token]In addition, we conducted various experiments to prove our point, such as showing non-robust component will rise drastically during standard training, showing adversarial training will effectively regularize the non-robust component.	Reply	I-Reply	1
Also, based on our theory, we point out the possible direction of achieving simultaneous adversarial robust and decent standard performance, which is enabling the model to rely more on robust component to distinguish data from different categories.	Reply	I-Reply	1
[line_break_token][line_break_token]All these points presented above are actually the central point of our work, and we believe we have stated clearly in our main text.	Reply	I-Reply	1
[line_break_token][line_break_token]Also, we think most of our mathematical derivations are rigorous.	Reply	I-Reply	2
The example you give is only meant to serve as an alternative intuition, and is therefore put in the appendix.	Reply	I-Reply	2
It is not in the main flow of our work	Reply	I-Reply	2

This paper presents a method to speed up the data selection in active learning and core-set learning.	Review	O	0
The authors present a simple idea: instead of using the full model to select data points, they use a smaller model with fewer layers, potentially trained for fewer iterations.	Review	O	0
The authors show that this simple approach is able to speed up the data selection portion of both processes significantly with minimal loss in performance, and also results in significant speedup of the entire pipeline (data selection + training).	Review	O	0
[line_break_token][line_break_token]This paper is timely and important -- there has been a lot of emphasis lately on the environmental costs of training deep learning models (e.g., Strubell et al.,	Review	O	0
ACL 2019; Schwartz et al.,	Review	O	0
2019 arxiv:1907.10597).	Review	O	0
This paper shows that simple, almost trivial techniques can lead to significant runtime benefits for active learning and core-set learning.	Review	O	0
The authors present an extensive set of experiments that validate their hypothesis, and the paper is overall clearly written.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]1.	Review	O	0
The correlation values in Figure 3 are quite diverse.	Review	B-Review	1
It seemed "forgetting events" is much more correlated that the other two approaches.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Why do the authors think that SVP and their baselines failed to outperform random sampling on Amazon Review Full (towards the end of 3.3)?	Review	B-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	2
Table 1 is very hard to interpret.	Review	I-Review	3
I would advise the authors to look for a more succinct way to present their main findings.	Review	I-Review	3
While this might seem contradictory, Figure 2, which is more reader-friendly, is also hard to interpret without the runtime values (nobody said visualization is easy!).	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
One thing that's missing from this paper is training the smaller networks end-to-end.	Review	B-Review	4
What would be the effect of using the proxy network as the main network as well?	Review	I-Review	4
this is likely to lead to very significant runtime savings, and I wonder at what costs.	Review	I-Review	4
[line_break_token][line_break_token]Minor:[line_break_token][line_break_token]1.	Review	O	0
Towards the end of 3.2: I disagree that significant speedups are "uninteresting" if they lead to small reductions in performance.	Review	B-Review	5
hank you for your time and thoughtful feedback!	Reply	O	0
We updated several tables and figures to make the paper more readable.	Reply	B-Reply	3
Table 1, in particular, has been dramatically simplified to showcase the key results.	Reply	I-Reply	3
We also added additional tables and figures to show trade-offs between accuracy and computational complexity better.	Reply	I-Reply	3
Overall, thanks to your suggestions, the paper more clearly states the end-to-end training time savings and in turn, energy savings that can be achieved with a simple change to data selection techniques.	Reply	O	0
[line_break_token][line_break_token]Below we have provided a detailed response to each of your questions	Reply	O	0

SUMMARY: A new modification to the rendering mechanism in a differentiable renderer  to generate 3D images, trained in an unsupervised manner on 2D images of faces[line_break_token][line_break_token]CLAIMS:[line_break_token]- train a generative model in an unsupervised way on 2D face images,[line_break_token]- by generating 3D representation of [shape, texture, background] and feeding that to a differentiable renderer[line_break_token]- modify the rendering mechanism to be differentiable wrt vertices of the triangular mesh (in addition to the texture)[line_break_token]- curb the problems of training by using shape image pyramid, object size constraint[line_break_token][line_break_token][line_break_token]LIT REVIEW:[line_break_token]Well done, sufficient summarization of past work.	Review	O	0
But not "first":[line_break_token]it would be pertinent to mention the ICCV 2019 paper "HoloGAN: UNSUPERVISED LEARNING OF 3D REPRESENTATIONS FROM NATURAL IMAGES" (<a href="https://arxiv.org/abs/1904.01326)," target="_blank" rel="nofollow">https://arxiv.org/abs/1904.01326),</a> which tackles the exact same problem.	Review	O	0
It does not use a triangular mesh representation, or a differentiable renderer, instead it uses a 3D feature representation and a neural renderer.	Review	B-Review	1
However, the problems tackled are very close to avoid mentioning this paper.	Review	I-Review	1
[line_break_token][line_break_token]Hence, it might not be good to claim[line_break_token]- in the abstract: "the first method to learn a generative model of 3D shapes from natural images in a fully unsupervised way",[line_break_token]- in introduction: "For the first time, to the best of our knowledge, we provide a procedure to build a generative model that learns explicit 3D representations in an unsupervised way from natural images",[line_break_token]- and similar claims in other places.	Review	I-Review	1
[line_break_token][line_break_token]Also, Pix2Scene (<a href="https://openreview.net/forum?id=BJeem3C9F7)" target="_blank" rel="nofollow">https://openreview.net/forum?id=BJeem3C9F7)</a> also has similar ideas, although they tackled primitive shapes and not faces.	Review	O	0
[line_break_token][line_break_token]DECISION: This paper has very promising results.	Review	O	0
[line_break_token]Although it is limited to faces, which the community knows is something GANs are good at modeling because of the inherent structure, it is nevertheless a relevant piece of work in modelling 3D scenes in a graphics way and then training using adversarial learning.	Review	O	0
I am particularly impressed by the renderings of the depth and texture, and would be interested to explore that area further.	Review	O	0
[line_break_token][line_break_token]However, it is more pertinent to check how the model performs objects more complicated than faces.	Review	B-Review	2
A very simple experiment is to try this on ImageNet images, which are also centered and aligned.	Review	I-Review	2
This would help investigate the possibility of extending this method to more complicated objects than faces.	Review	I-Review	2
[line_break_token][line_break_token]I would suggest to maybe put more focus on the fact that you have used the traditional graphics pipeline and integrated that into adversarial learning, as opposed to dealing with just weights and biases.	Review	I-Review	3
That is indeed significant (in my opinion).	Review	I-Review	3
[line_break_token][line_break_token]Knowing that most GAN training time is spent in overcoming a lot of failures, it would be great if the authors can summarize the failure cases and elaborate on the experiments performed to overcome those failures.	Review	I-Review	4
This was briefly touched upon in Section 7, but it would be great if they could elaborate more on them possibly in the appendix.	Review	I-Review	4
[line_break_token][line_break_token]It would be great if the authors can share their code, there was no mention of any possibility of this.	Review	I-Review	5
[line_break_token][line_break_token]ADDITIONAL FEEDBACK:[line_break_token]Page 5:[line_break_token]...an added constrain*T* on m in the optimization...[line_break_token]...fooled by an inverted dept*H* image...[line_break_token]page 6:[line_break_token]...rendered &lt;remove&gt;attribute and&lt;/remove&gt; depth, attribute and alpha map...	Review	O	0
 HoloGAN's representation is latent, and not explicit, thus they do not output any 3D surfaces, unlike our model.	Reply	O	0
[line_break_token]- We added results on LSUN categories.	Reply	O	0
[line_break_token]- We added more ablation studies.	Reply	O	0
[line_break_token]- We will share our code upon publicatio	Reply	O	0

Summary of the paper: The authors propose a latent variable model RaDOGAGA, a generative autoencoding model.	Review	O	0
The model is trained via a tradeoff between distortion (the reconstruction error) and the rate (the capacity of the latent space, measured by entropy).	Review	O	0
The paper provides an analysis of theoretical properties of their approach, and presents supporting experimental results.	Review	O	0
[line_break_token][line_break_token]Review tl;dr: weak reject, for three main reasons:[line_break_token](i) While the existing literature around VAEs, beta-VAEs,  and Rate-Distortion theory is mentioned in the related work, the connections are not nearly discussed sufficiently.	Review	O	0
[line_break_token](ii) On top of (i), the derivation of their loss function and architecture is not sufficiently motivated.	Review	O	0
This is in astonishing contrast to 1.5 pages of main text and 8 pages of (much appreciated!)	Review	B-Review	2
analysis of properties.	Review	I-Review	2
[line_break_token](iii) Given the paper is clearly related to existing approaches in the literature, the experiments would require a much more careful comparison to existing models.	Review	O	0
It remains unclear why an interested user should favor your model over conceptually simpler generative models with fewer hyperparameters.	Review	B-Review	3
[line_break_token][line_break_token]Detailed review:[line_break_token][line_break_token]Nota bene: This review is a late reassignment.	Review	O	0
While I reviewed the paper to the best of my ability, time constraints did not allow me to review parts of the paper in depth.	Review	O	0
 I am open to reassess my review during the second stage.	Review	O	0
[line_break_token][line_break_token]Connection to prior art: As a probabilistic, neural autoencoding model, the connections to the family of VAE models are obvious.	Review	B-Review	4
The loss function (eq. (	Review	I-Review	4
4)) still looks very much like the ELBO, where the typical conditional log-likelihood was split into two distortion terms.	Review	I-Review	4
How is this different from e.g. a beta-VAE?	Review	I-Review	4
Particularly, what is the connection between the rate-distortion analysis of beta-VAE by Alemi et al.	Review	I-Review	4
and yours?	Review	I-Review	4
These things need to be discussed explicitly, with more than a sentence or two in the related work section.	Review	I-Review	4
[line_break_token]A lesser, but still important omission in your discussion of prior work: The Jacobian of the generator has also been studied, even for the VAE, cf.	Review	I-Review	4
e.g. [1]. I believe this deserves more attention in your assessment of prior art.	Review	I-Review	4
[line_break_token][line_break_token]Motivation: You use two distortion terms: actual sample vs. undistorted reconstruction.	Review	I-Review	2
Why is that?	Review	I-Review	2
What is the interpretation of the multipliers?	Review	I-Review	2
How do I choose them?	Review	I-Review	2
Why is a large part of your architecture (the pipeline from x to \hat(x)) actually deterministic?	Review	I-Review	2
Why are you using the entropy of the prior over the latents, rather than the KL divergence between encoder and a prior?	Review	I-Review	2
I think an interested reader could learn much more from your paper if you discussed your model embedded in th related work rather than in isolation.	Review	I-Review	2
[line_break_token][line_break_token]Theory: Due to aforementioned time constraints, I was not able to review the extensive theoretical analysis in depth.	Review	O	0
Still, I would strongly recommend structuring the respective sections more clearly.	Review	B-Review	5
Separate model and architecture description from the theoretical analysis; precisely formulate your claims.	Review	I-Review	5
In particular, state your assumptions clearly.	Review	I-Review	5
For instance, you assume "that each function's parameter is rich enough to fit ideally" (and similar e.g. in Appendix A).	Review	I-Review	5
Does this only mean that the true distributions are part of the parametric family?	Review	I-Review	5
What if this is not the case?	Review	I-Review	5
Do your parameters need to be in the optimum for your analysis to hold true?	Review	I-Review	5
[line_break_token][line_break_token]Given that the full 20-page manuscript spends 10 pages on theory, I think this contribution is not given appropriate space in the main text.	Review	I-Review	5
[line_break_token][line_break_token]Experiments: There are three experiments: a simple 3D proof of concept; anomaly detection; analysis of the latent state in CelebA. As mentioned in my review of the methods section, I believe the approach to be very similar to established models.	Review	O	0
None of the experiments provides convincing evidence why I should prefer the new, arguably more complex model.	Review	B-Review	6
[line_break_token]For instance, I would have much preferred that you investigate properties of your model against alternatives over the anomaly detection experiments, which did not further my understanding of the proposed model.	Review	I-Review	6
[line_break_token][line_break_token]Summary: The paper tackles an important problem, namely the lack of control over the latent embedding in autoencoding generative models.	Review	O	0
I believe the author's contribution can be valuable, and I particularly appreciate the effort to investigate theoretical properties.	Review	B-Review	7
As is, the case is not sufficiently convincing to be accepted, but I encourage the authors to improve the paper.	Review	I-Review	7
[line_break_token][line_break_token]Minor comments:[line_break_token]1.	Review	I-Review	8
While I appreciate a pun, I would recommend to rename the model along with the acronym to a more concise name.	Review	I-Review	8
[line_break_token]2.	Review	I-Review	8
Please revise your notation and typsetting.	Review	I-Review	8
Examples: x1 instead of x_1, f of f(\cdot) instead of f(), \log instead of log.	Review	I-Review	8
[line_break_token]3.	Review	I-Review	8
Introduce acronyms before using them (e.g. VAE, MSE, SSIM), even when they seem obvious to you.	Review	I-Review	8
[line_break_token]4.	Review	I-Review	8
Please carefully check the manuscript for typos, missing articles, missing spaces etc.	Review	I-Review	8
[line_break_token]5.	Review	I-Review	8
Your citations are inconsistent, in that they sometimes use first names, sometimes first name initials, and sometimes no first names.	Review	I-Review	8
[line_break_token]6.	Review	I-Review	8
To my knowledge, the term scale function does not have an obvious definition.	Review	I-Review	8
I think you are simply referring to monotonically increasing functions.	Review	I-Review	8
Please clarify!	Review	I-Review	8
[line_break_token]7.	Review	I-Review	8
Your figures should be understandable without too much context, they need more detailed captions.	Review	I-Review	8
[line_break_token][line_break_token][1] <a href="http://proceedings.mlr.press/v84/chen18e.html" target="_blank" rel="nofollow">http://proceedings.mlr.press/v84/chen18e.html</a>	Review	O	0
hank you for your time and valuable comments.	Reply	O	0
[line_break_token]From your comments, we found that our work would be closely related to a practical method of isometric embedding of Riemannian manifold.	Reply	O	0
[line_break_token]Because our background is not only deep autoencoders but also image compression, we have overlooked that there is a gap between image compression and VAE.	Reply	O	0
[line_break_token]Please understand that we revised to some extent in order to respectfully deal with your comments and to make our claim more persuasive.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt;Regarding our motivation and its connection with prior works [line_break_token]We added an explicit discussion about our motivation, idea, and connection among prior works.	Reply	O	0
Figures 1 and 2 give an overview.	Reply	B-Reply	1
Please find the following discussion are added.	Reply	I-Reply	1
[line_break_token]The term ‚ÄúRate-distortion optimization‚Äù or ‚ÄúRDO‚Äù is a method to improve quality in image compression with orthonormal transform coding.	Reply	I-Reply	1
[line_break_token]<a href="https://en.wikipedia.org/wiki/Rate-distortion_optimization" target="_blank" rel="nofollow">https://en.wikipedia.org/wiki/Rate-distortion_optimization</a>[line_break_token]Prior works of deep image compression such as Balle et al.,	Reply	O	0
2018 also used RDO.	Reply	B-Reply	1
We added an overview of RDO and our motivation.	Reply	I-Reply	1
 The derivation of our idea is based on the analogy of orthonormal transform coding.	Reply	I-Reply	1
[line_break_token]We also added the analogy and difference between VAE and our idea.	Reply	I-Reply	1
The summary is as follows.	Reply	I-Reply	1
[line_break_token][line_break_token]According to RDO theory, the condition of optimization in transform coding is that: (i) transform data deterministically using orthonormal basis (orthogonal is not enough) such as DCT, KLT, and so on (ii) quantize by uniform quantizer for all channels which cause uniform noise (iii) assign the optimum entropy code.	Reply	I-Reply	1
[line_break_token]Our intuition is that if the equivalent noise is added to latent variables z and rate-distortion is optimized, z should have orthonormality.	Reply	I-Reply	1
Consequently, Jacobian becomes constant automatically.	Reply	I-Reply	1
[line_break_token]Obeying this flow, z is obtained deterministically and the entropy is used rather than KL divergence between an encoder and a prior.	Reply	I-Reply	1
[line_break_token][line_break_token]Rate-distortion optimization condition for VAE and our model is contrasted as follows.	Reply	I-Reply	1
In VAE, because PDF is fixed as prior, noise should be variable and scaling between data and latent spaces is also variable, meaning Jacobian is inconstant.	Reply	I-Reply	1
In ours, because noise is uniform, PDF should be variable(parametric) and scaling is constant.	Reply	I-Reply	1
 Thus, in our model, there is not fixed prior.	Reply	I-Reply	1
[line_break_token][line_break_token]About the loss function, The second and third terms in eq (5) are an approximate decomposition of D(x, x_\breve) as shown in Rolinek et al.,	Reply	I-Reply	1
2019.	Reply	I-Reply	1
By this decomposition, we can independently control the reconstruction loss and scaling Jacobian and lead to better performance.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt;&gt; Relation to [1] <a href="http://proceedings.mlr.press/v84/chen18e.html" target="_blank" rel="nofollow">http://proceedings.mlr.press/v84/chen18e.html</a>[line_break_token]Thank you for introducing an interesting paper to us.	Reply	O	0
Thanks to your comment, we found that our work, especially Eqs. (	Reply	B-Reply	4
10) and (11), would be related to an isometric embedding of Riemannian manifold where A(x) is a Riemannian tensor.	Reply	I-Reply	4
 In this paper, the authors discussed the distance between two points is the shortest path on a Riemannian manifold induced by the transformation.	Reply	I-Reply	4
Then, the impact on the domain data caused by the variance of latent variables is measured.	Reply	I-Reply	4
This is related to the discussion of Fig.	Reply	I-Reply	4
6 (c) and (d).	Reply	I-Reply	4
While VAE needs to find a winding road in the latent space that corresponds to the shortest path, in our model, a linear path in the latent space expected to be connected to that.	Reply	I-Reply	4
 While we did not include this discussion this time because of page limitation though, this will be our future work.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]&gt;&gt; Do your parameters need to be in the optimum for your analysis to hold true?	Reply	O	0
[line_break_token]Strictly speaking, yes.	Reply	B-Reply	5
Although, as experiment result showed, when parameters are optimized decently, it works almost as in theory even though there remains the left behind margin.	Reply	I-Reply	5

This work proposed a distillation approach which use ASRs to generate hypotheses for unsupervised data, run a LM to get probability for the hypothesis, and perform distillation with the resulting probability.	Review	O	0
The ASRs being used for generating hypotheses can be either a model trained with the supervised data or the student model, and can switch between the two during training.	Review	O	0
In the experiments, ASR models are pre-trained with the subset of Librispeech data and use the rest of Librispeech data as unsupervised data, and the LM is trained with Librispeech LM data.	Review	O	0
The experiments shown the proposed approach improve baseline model trained with the Librispeech subset significantly.	Review	O	0
[line_break_token][line_break_token]The use of LM to provide soft target is a good idea as LMs can utilize unsupervised text data as opposed to the requirement of training a strong teacher model with paired data, and can be easily integrated with existing distillation approaches for ASRs.	Review	O	0
The switching to the student model for generating hypotheses when it outperforms the pre-trained ASR also makes a good sense.	Review	O	0
The overall novelty however is a bit limited compared to the existing work, as the major contribution is to propose to use LMs as teacher rather than ASRs, with the rest of the design to be similar to existing works.	Review	B-Review	1
[line_break_token][line_break_token]The paper relates their method to self-supervised learning, yet I find it having stronger correlation with existing distillation approaches, and can be better understood through the distillation perspective.	Review	I-Review	1
e thank the reviewer for the thoughtful comments.	Reply	O	0
Below are our itemized responses to address the concerns.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q1: The overall novelty however is a bit limited compared to the existing work, as the major contribution is to propose to use LMs as teacher rather than ASRs, with the rest of the design to be similar to existing works.	Reply	O	0
The paper relates their method to self-supervised learning, yet I find it having stronger correlation with existing distillation approaches, and can be better understood through the distillation perspective.	Reply	O	0
[line_break_token][line_break_token]A1: Despite the similarity in the form of the objectives, the proposed LPM method and knowledge distillation are motivated very differently, and therefore differ a lot in their capability as well as theoretical soundness.	Reply	O	0
The two methods are different for the following reasons:[line_break_token][line_break_token]1.	Reply	O	0
We have found that our approach is consistently superior to weak knowledge distillation (Table 1).	Reply	B-Reply	1
When the beam size is set to 1, our approach yields self-training [3; 4; 5], which is identical to weak distillation [1; 2] where the teacher distribution is replaced by its mode.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Unlike knowledge distillation, our approach is Bayesian and derives a tractable posterior estimator.	Reply	B-Reply	1
Compared with the heuristic of weak knowledge distillation, we provide a theoretically well-motivated approach that is simple to implement, but also superior in performance.	Reply	I-Reply	1
 Furthermore, our framework is flexible: the proposal model does not have to be tied to the ASR model, and we can also make the estimator more accurate by adding a TTS component to re-weigh acoustic plausibility.	Reply	I-Reply	1
[line_break_token][line_break_token]We will incorporate the discussion into the paper if the reviewers find it helpful to distinguish knowledge distillation from our proposed approach.	Reply	I-Reply	1
[line_break_token][line_break_token][1] Kim, Yoon, and Alexander M. Rush. "	Reply	O	0
Sequence-level knowledge distillation."	Reply	O	0
arXiv preprint arXiv:1606.07947 (2016).	Reply	O	0
[line_break_token][2] Li, Bo, et al. "	Reply	O	0
Semi-supervised training for End-to-End models via weak distillation."	Reply	O	0
ICASSP (2019).	Reply	O	0
[line_break_token][3] Vesel√Ω, Karel, Luk√°s Burget, and Jan Cernock√Ω. "Semi-Supervised DNN Training with Word Selection for ASR."	Reply	O	0
INTERSPEECH (2017).	Reply	O	0
[line_break_token][4] Manohar, Vimal, et al. "	Reply	O	0
Semi-supervised training of acoustic models using lattice-free MMI."	Reply	O	0
ICASSP (2018).	Reply	O	0
[line_break_token][5] Kahn, Jacob, Ann Lee, and Awni Hannun. "	Reply	O	0
Self-Training for End-to-End Speech Recognition."	Reply	O	0
arXiv preprint arXiv:1909.09116 (2019).	Reply	O	0

The paper considers the idea of projecting samples from an RL task into an intermediate representation before performing TD learning with a neural network.	Review	O	0
 It is demonstrated that the quality of learned value functions depends in part upon this representation, as error propagates along states that are nearby in the chosen representation.	Review	O	0
[line_break_token][line_break_token]It is well-known and -researched that representation and feature selection is an important step in RL.	Review	O	0
 A great deal of prior work is ignored, to the extent that a list would be unwieldy.	Review	B-Review	1
 The paper provides some useful visuals for an introductory discussion on feature selection in RL, but otherwise no real insights or surprises.	Review	I-Review	1
Thanks for your review, despite the rejection.	Reply	O	0
Do you mind sharing just the 3 most relevant related works, in your opinion, that we failed to acknowledge?	Reply	B-Reply	1
We see this as a great opportunity to benefit from your expertise and constructive feedback, which is arguably the best possible outcome of the peer review system.	Reply	I-Reply	1
Greatly appreciated	Reply	I-Reply	1

Summary[line_break_token]This paper proposes an end-to-end learnable  multiview stereo depth estimation network, which is basically very similar to the GCNet (Kendall et.al 2017) or PSMNet (Chang et.al 2018) for stereo estimation.	Review	O	0
The differences are using SPN to warp feature w.r.t RT, adding a multi view averaging cost and a cost aggregation component for final depth regression, which transform the original network to support multi-view stereo, yielding performance boost over other baselines.	Review	O	0
[line_break_token][line_break_token]Technically, I believe it is sound  because cost volume from stereo matching has already been demonstrate very effective in boosting performance because it use underlining geometry constraint.	Review	O	0
 My major concern lies in three aspects.	Review	O	0
[line_break_token][line_break_token]1) Another most recent SOTA algorithm is  MVSNet (Yao et.al ECCV 2018), the paper should be considered for comparison.	Review	O	0
In addition, the structure is even more similar with the proposed network architecture.	Review	B-Review	1
 [line_break_token][line_break_token]2) The evaluation metrics are mostly use for single view depths, it is not consistent with paper of DeepMVS (Tab.	Review	O	0
1) or that from MVSNet.	Review	B-Review	2
Therefore, it might be hard to actual understand whether the numbers are  exactly comparable.	Review	I-Review	2
[line_break_token][line_break_token]3) Since the method largely improved over their baseline algorithms, and the number between different papers are hard to compare.	Review	O	0
In my opinion, to better show the results,  I suggest submitting results to an online benchmark with test data for verifying the results.	Review	B-Review	3
such as ETH3D multi view benchmark, where everything is standardized.	Review	I-Review	3
[line_break_token][line_break_token]I hope the author can make strong feedback for validating the results.	Review	O	0
[line_break_token][line_break_token]####### .	Review	O	0
After rebuttal[line_break_token][line_break_token]The author makes more clear indication of the performance contribution of the completeness of recovery.	Review	O	0
3) Since the method largely improved over their baseline algorithms, and the number between different papers are hard to compare.	Reply	O	0
In my opinion, to better show the results, I suggest submitting results to an online benchmark with test data for verifying the results.	Reply	B-Reply	3
such as ETH3D multi view benchmark, where everything is standardized.	Reply	I-Reply	3
[line_break_token][line_break_token]Different from MVSNet which estimates the full 3D of objects, our DPSNet is inspired by the plane sweeping algorithm which is originally devised for dense depth reconstruction.	Reply	I-Reply	3
That is, DPSNet focuses on estimating the dense depth map.	Reply	I-Reply	3
By your suggestion, we have submitted depth maps from DPSNet to the ETH3D benchmark, but did not receive satisfactory results, with lower ranks on the ‚ÄòF1 score‚Äô metric.	Reply	I-Reply	3
[line_break_token]Method[line_break_token](20cm)[tab_token]low-res many-view[tab_token]indoor[tab_token]outdoor[tab_token]lakeside[tab_token]sand box[tab_token]storage room[tab_token]storage room 2[tab_token]tunnel[line_break_token]DPSNet[tab_token]59.89[tab_token]54.16[tab_token]63.70[tab_token]71.39[tab_token]70.87[tab_token]52.09[tab_token]56.24[tab_token]48.85[line_break_token]MVSNet[tab_token]63.58[tab_token]56.25[tab_token]68.47[tab_token]66[tab_token]71.12[tab_token]48.36[tab_token]64.13[tab_token]68.29[line_break_token][line_break_token]In order to obtain a high score on the accuracy metric, the depth corresponding to unobserved pixels should be removed.	Reply	I-Reply	3
MVSNet performs a depth map filtering to remove outliers, and its multiple observed 3D points merged well to select a correct depth value from multiple observations for a pixel.	Reply	I-Reply	3
However, the outlier rejection and the 3D point merging proces are out of the scope of this paper.	Reply	I-Reply	3
Instead, we demonstrate that DPSNet produces dense depth maps well by achieving higher scores on the ‚ÄòCompleteness‚Äô metric than that of MVSNet on the ETH3D benchmark.	Reply	I-Reply	3
[line_break_token]Method[line_break_token](20cm)[tab_token]low-res many-view[tab_token]Indoor[tab_token]outdoor[tab_token]lakeside[tab_token]sand box[tab_token]storage room[tab_token]storage room 2[tab_token]tunnel[line_break_token]DPSNet[tab_token]58.64[tab_token]47.21[tab_token]66.25[tab_token]72.10[tab_token]77.08[tab_token]48.12[tab_token]46.31[tab_token]49.58[line_break_token]MVSNet[tab_token]47.72[tab_token]40.64[tab_token]52.43[tab_token]49.39[tab_token]55.25[tab_token]33.58[tab_token]47.7 [tab_token]52.66[line_break_token][line_break_token]In conclusion, DPSNet and MVSNet have different goals, and thus different strengths.	Reply	I-Reply	3
In the revised paper, we clarify that our DPSNet aims to infer dense depth maps, to highlight its advantages.	Reply	I-Reply	3
[line_break_token]	Reply	O	0

In this paper, authors explore the problem of generating singing voice, in the waveform domain.	Review	O	0
There exists commercial products which can generate high fidelity sounds when conditioned on a score and or lyrics.	Review	O	0
This paper proposes three different pipelines which can generate singing voices without necessitating to condition on lyrics or score.	Review	O	0
[line_break_token][line_break_token]Overall, I think that they do a good job in generating vocal like sounds, but to me it's not entirely clear whether the proposed way of generating melody waveforms is an overkill or not.	Review	B-Review	1
There is a good amount of literature on generating MIDI representations.	Review	I-Review	1
One can simply generate MIDI (conditioned or unconditioned), and then give the result to a vocaloid like software.	Review	I-Review	1
I am voting for a weak rejection as there is no comparison with any baseline.	Review	I-Review	1
If you can provide a comparison with a MIDI based generation baseline, I can reconsider my decision.	Review	I-Review	1
Or, explain to me why training on raw waveforms like you do is more preferable.	Review	I-Review	1
I think in the waveform domain may even be undesirable to work with, as you said you needed to do source separation, before you can even use the training data.	Review	I-Review	1
This problem does not exist in MIDI for instance.	Review	I-Review	1
[line_break_token]	Review	O	0
hank you for the valuable comments.	Reply	O	0
We address the issues and questions raised by the reviewer in the following comments.	Reply	B-Reply	1
[line_break_token] There is a good amount of literature on generating MIDI representations.	Reply	I-Reply	1
One can simply generate MIDI (conditioned or unconditioned), and then give the result to a vocaloid like software.	Reply	I-Reply	1
I am voting for a weak rejection as there is no comparison with any baseline.	Reply	I-Reply	1
If you can provide a comparison with a MIDI based generation baseline, I can reconsider my decision.	Reply	I-Reply	1
[line_break_token][line_break_token]One of the goals in this paper is to generate singing voice given an accompaniment, but generating a singing melody MIDI given an accompaniment is not a trivial task.	Reply	I-Reply	1
To the best of our knowledge, there are many researches on generating melodies, piano solos, and scores of several instruments, but very few researches, if any, work on generating singing melodies given an accompaniment.	Reply	I-Reply	1
Our model is one way to achieve the goal of generating singing given accompaniment without the intermediate MIDI file.	Reply	I-Reply	1
[line_break_token][line_break_token]As suggested by the Reviewer 1, we have added two synthesis baselines to the paper, and have revised Section 4 accordingly.	Reply	I-Reply	1
The two baselines are based on the well-known singing voice synthesis tools, Sinsy and Synthesizer V, that are publicly accessible.	Reply	I-Reply	1
[line_break_token][line_break_token] Or, explain to me why training on raw waveforms like you do is more preferable.	Reply	I-Reply	1
I think in the waveform domain may even be undesirable to work with, as you said you needed to do source separation, before you can even use the training data.	Reply	I-Reply	1
This problem does not exist in MIDI for instance.	Reply	I-Reply	1
[line_break_token][line_break_token]We believe that our score-lyrics-free approach and the score-lyrics-based (with both score and lyrics) approach are for different situations, so one approach is not preferable than the other in general.	Reply	I-Reply	1
[line_break_token][line_break_token]The differences between these two approaches is in the types of the input conditions.	Reply	I-Reply	1
The score-lyrics-based approach takes scores and lyrics as the condition.	Reply	I-Reply	1
In contrast, our approach can take less strict and more diverse conditions.	Reply	I-Reply	1
In this paper, we have demonstrated models that take no conditions, accompaniment conditions, or chord conditions.	Reply	I-Reply	1
[line_break_token][line_break_token]What we propose in this paper is that the conditions used in the singing voice generation systems do not need to be as strong as the existing systems.	Reply	I-Reply	1
Score-lyrics-based systems are good at synthesizing singing voices when you want the system to synthesize exactly what you want, while our approach would do better when you want the machine to add some singing voices to your composition without designating the strict scores and lyrics.	Reply	I-Reply	1
[line_break_token][line_break_token]We have also revised the Introduction to further discuss the motivations of using our approaches.	Reply	I-Reply	1

This paper proposes a new neural network model for sentence representation.	Review	O	0
This new model is inspired by the success of residual network in Computer Vision and some observation of word morphology in Natural Language Processing.	Review	O	0
Although this paper shows that this new model could give the best results on several datasets, it lacks a strong evidence/intuition/motivation to support the network architecture.	Review	O	0
[line_break_token][line_break_token]To be specific:[line_break_token][line_break_token]- I was confused by the contribution of this paper: character-aware word embedding or residual network or both?	Review	O	0
[line_break_token]- The claim of using residual network in section 3.3 seems pretty thin, since it ignores some fundamental difference between image representation and sentence representation.	Review	O	0
Even though the results show that adding residual network could help, I was still not be convinced.	Review	B-Review	2
Is there any explanation about what is captured in the residual component from the perspective of sentence modeling?	Review	I-Review	2
[line_break_token]- This paper combines several components in the classification framework, including character-aware model for word embedding, residual network and attention weight in Type 1 feature.	Review	O	0
I would like to see the contribution from each of them to the final performance, while in Table 3 I only saw one of them.	Review	B-Review	3
Is it possible to add more results on the ablation test?	Review	I-Review	3
[line_break_token]- In equation (5), what is the meaning of in?	Review	O	0
[line_break_token]- The citation format is impropriate[line_break_token]	Review	O	0
Thanks for your comments!	Reply	O	0
[line_break_token]1.	Reply	O	0
[tab_token]Character-aware word embedding has been utilized by many works before as we mentioned in related work.	Reply	O	0
However we find that by combining character-level embedding and word-level embedding could capture more information for short noisy text and would improve the classification performance.	Reply	B-Reply	1
The contribution in this paper is more on the two types of features, and the first application of residual network on text representation refinement.	Reply	I-Reply	1
There are less information in short noisy text than the other long text and not many works focus on short noisy text classification.	Reply	I-Reply	1
The two types of features proposed in our paper could capture different aspects of information in the text and lead to good performance.	Reply	I-Reply	1
Residual network could further help refine the short text representation and give better result.	Reply	I-Reply	1
[line_break_token]2.	Reply	O	0
[tab_token]As stated in paper, the short text final representation is the concatenation of two types of features which capture different aspects of information and of different scale.	Reply	O	0
To make the representation more consistent, we apply residual network to refine short text final representation.	Reply	B-Reply	2
[line_break_token]3.	Reply	O	0
[tab_token]We add the evaluation for the character-level word embedding and the attention weight for Type 1 feature.	Reply	O	0
Experiment results suggest either part could contribute to better performance.	Reply	B-Reply	3
[line_break_token]4.	Reply	O	0
[tab_token]Sorry for the typo.	Reply	O	0
It should be.	Reply	B-Reply	4
[line_break_token]5.	Reply	O	0
[tab_token]Thanks for the kind reminding on the citation format.	Reply	O	0
We make it the appropriate way.	Reply	B-Reply	5

Summary &amp; Pros[line_break_token]- This paper proposes a well-principled distillation method based on contrastive loss maximizing the mutual information between teacher and student models.	Review	O	0
[line_break_token]- This paper provides extensive experiments that demonstrate the effectiveness of the proposed method.	Review	O	0
The performance gap compared to the existing distillation approaches seem to be significant.	Review	O	0
[line_break_token][line_break_token]Major Concerns:[line_break_token]- The authors claim that "none of the other methods consistently outperform KD on their own".	Review	O	0
I feel that this claim is somewhat aggressive because some of them outperform KD without combining with KD, e.g., Table 1 in FT (Kim et al.,	Review	B-Review	1
2018) and Table 2 in SP (Tung &amp; Mori, 2019).	Review	O	0
Since the distillation (or transfer) methods are typically sensitive to hyperparameters (e.g., architecture types, transfer connections between layers), I also wonder how to set the hyperparameters for baselines, especially in Table 2, because choosing the transfer connections between different architectures is very important when using feature-based methods such as FitNet and AT.	Review	B-Review	1
[line_break_token]- Moreover, the baselines are developed for improving distillation performance, not replacing KD.	Review	O	0
Especially, feature-based methods (e.g., FitNet, NST) are easily combined with logit-based ones (e.g., KD).	Review	B-Review	2
So I think the compatibility between the proposed and exisiting methods should be checked.	Review	I-Review	2
However, in this paper, only Table 4 shows the compatibility with KD (CRD+KD).	Review	I-Review	2
[line_break_token]- The authors compare the proposed method with only KD, AT, FitNet except Table 1-3.	Review	O	0
For example, when evaluating the transferability (Table 4), why other baselines are not compared?	Review	B-Review	3
[line_break_token]- VID also maximizes MI between penultimate layers.	Review	O	0
What is the key difference and why CRD perform better?	Review	B-Review	4
I think detailed verfication should be provided in the paper.	Review	I-Review	4
[line_break_token][line_break_token]Minor Comments[line_break_token]- Comparison with Online-KD is unfair because it does not use pre-trained ResNet32.	Review	O	0
[line_break_token]- Why only use penultimate layers?	Review	B-Review	5
CRD between intermediate layers is also available like VID.	Review	I-Review	5
[line_break_token]- A result in Table 1 is missing (FSP WRN40-2 -&gt; WRN40-1).	Review	O	0
[line_break_token]- In Section 4, both CKD (contrastive knowledge distillation) and CRD (contrastive representation distillation) are used, so one of them should be removed.	Review	B-Review	5
[line_break_token]- In Section 4.1 Transferability paragraph, "Table 3" should be changed to "Table 4".	Review	I-Review	5
[line_break_token]- On page 4, "space" after "before the inner product."	Review	I-Review	5
should be removed.	Review	I-Review	5
[line_break_token][line_break_token]I think the proposed method is well-principled and provides meaningful improvements on various distillation settings, thus this paper seems to be above the borderline.	Review	O	0
It would be better if additional supports for the above concerns is provided in a rebuttal.	Review	O	0
Dear Reviewer 2,[line_break_token][line_break_token]Thank you for the very constructive comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We have revised the contribution section to make it more accurate.	Reply	O	0
[line_break_token][line_break_token]Hyperparameters (architecture types, transfer connections between layers).	Reply	B-Reply	1
For architecture types or student-teach pairs, we just randomly sampled over a candidate pool which contains widely-used networks.	Reply	I-Reply	1
As for the transfer connections for feature based distillation methods, we tried two methods: (1) connect the layers with 0.25, 0.5 and 0.75 depth of the whole network; (2) connect the last layer of each specific spatial size, e.g., the last layers, which have spatial size of 32, 16, 8 and 4, are connected correspondingly.	Reply	I-Reply	1
We found (2) generally works better and stick to it.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that we might achieve higher accuracies if we separately tune hyperparameters for each specific student-teacher pairs.	Reply	I-Reply	1
But on the other hand, we consider it to be more interesting to see how each method can generalize across different architecture types without much tuning.	Reply	I-Reply	1
This is also our motivation of randomly sampling different student-teacher pairs to form the benchmark.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Compatibility.	Reply	O	0
We have included another table in the revised paper (see Sec.	Reply	B-Reply	2
6.6 and Table 6) discussing the combination of different distillation objectives.	Reply	I-Reply	2
We found: (1) other objectives combined with KD still underperform CRD; (2) combining CRD with other objectives, such as KD and PKT, can further improve the performance.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	3
The main reason why we don‚Äôt extensively compare with all other baselines in other Tables is that we have limited resources.	Reply	I-Reply	3
Given such a situation, we are inclined to distribute our resources towards building complete results (Tables 1&amp;2) on the standard CIFAR-100 benchmark, rather than the proof of concept on specific settings, such as Table 5 and Figure 3.	Reply	O	0
[line_break_token][line_break_token]We appreciate the idea of comparing transferability with other methods.	Reply	B-Reply	3
We have included a new table (see Sec 6.7 and Table 7) showing the transferability of all methods with different architectures.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	5
VID also claims to capture the MI between the representations of student and teacher, but their instantiation is very different from ours.	Reply	I-Reply	4
In order to achieve a tractable computation of MI, VID used a Gaussian distribution as a variational approximation of the true conditional distribution.	Reply	I-Reply	4
Our conjecture is that the true conditional distribution is perhaps very different from the Gaussian assumption, and therefore it leads to suboptimal results.	Reply	I-Reply	4
[line_break_token]Other issues:[line_break_token]We have added a note to indicate that Online-kd does not use pre-trained ResNet-34.	Reply	O	0
We can also remove this item if needed.	Reply	B-Reply	5
[line_break_token]We tried CRD on middle layers but only see very marginal improvement, so we opt to keep our methods simpler.	Reply	I-Reply	5
Indeed, only using penultimate layers makes CRD more robust to different architecture types.	Reply	I-Reply	5
[line_break_token]FSP only works for teachers and students with the size of features being equal, so it‚Äôs not available there.	Reply	I-Reply	5
We will mark it as N/A.[line_break_token]The typos have been fixed.	Reply	I-Reply	5
[line_break_token][line_break_token]Please don‚Äôt hesitate to let us know for any additional comments.	Reply	O	0
Thank you!	Reply	O	0

Summary[line_break_token]========[line_break_token]The paper conducts a thorough analysis of existing models for constructing knowledge graph embeddings.	Review	O	0
It focuses on attempting to remove confounding aspects of model features and training regime, in order to better assess the merits of KGE models.	Review	O	0
The paper describes the reimplementation of five different KGE models, re-trained with a common training framework which conducts hyperparameter exploration.	Review	O	0
The results show surprising insights, e.g., demonstrating that a system from 2011, despite being the earliest of the KGE models analyzed, demonstrates competitive results over a more recent (2017) published model.	Review	O	0
[line_break_token][line_break_token]Overall Comments[line_break_token]===============[line_break_token]The paper, and the described software release specifically, represent a solid contribution to the area of knowledge graph embeddings.	Review	O	0
I agree with the basic premise of this paper‚Äôs analysis: in order to accelerate research in a maturing field (like knowledge graphs), it is important to be able to properly compare with older systems, removing artifacts that are due to general improvements in training and optimization techniques, from modeling specific changes.	Review	O	0
The report of the strong results from the RESCAL system, along with others, drive the point through.	Review	O	0
Furthermore, the paper is well-written and easy to follow, and should become a good reference for future works on KGEs.	Review	O	0
[line_break_token][line_break_token]Detailed comments[line_break_token]===============[line_break_token]Below are some detailed comments about specific parts of the paper, in order of importance:[line_break_token][line_break_token]1.	Review	O	0
The paper mentions disregarding ‚Äúmonolithic‚Äù models in the current analysis, primarily due to the expensive training of these models.	Review	B-Review	1
It may, however, be the case that the future state-of-the-art models will be larger and slower to train (and, perhaps, of the monolithic type).	Review	I-Review	1
Are there any limitations to the proposed experimental framework that would prevent running monolithic/large models?	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	2
Regarding the item above, if one were to look at the training curves for the exploration of the current 5 KGE models, is it possible that verify winning hyperparameter configurations earlier than the full training is complete.	Review	I-Review	2
In my experience, it is often the case that with fewer than 1/10th steps of full training (well before convergence), it is possible to compare model configurations (relatively).	Review	I-Review	2
For example, ‚ÄúPopulation-base training‚Äù (<a href="https://arxiv.org/abs/1711.09846," target="_blank" rel="nofollow">https://arxiv.org/abs/1711.09846,</a> <a href="https://arxiv.org/abs/1902.01894)" target="_blank" rel="nofollow">https://arxiv.org/abs/1902.01894)</a> is one framework where fewer training steps are used to quickly learn good hyperparameter configurations.	Review	O	0
I‚Äôm wondering whether the KGE hyperparameter exploration training curves display similar early trends.	Review	B-Review	2
Could a shortened training procedure produce sufficient information for learning good parameters, and potentially deal with larger/slower models?	Review	I-Review	2
 In addition: would adopting population-based training be applicable to the proposed framework?	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	3
In Section 3.2, ‚ÄúLimitations‚Äù, there is a surprising comment that performance can be improved with further hyperparameter tuning.	Review	I-Review	3
It is not clear how the authors found the configurations that produced the improved results.	Review	I-Review	3
It would be helpful to clarify why the hyperparameter exploration proposed in the paper did not discover these improved configurations.	Review	I-Review	3
Were the improved configurations outside of the range of considered values?	Review	I-Review	3
Or would the exploration require more points to find the improved configuration?	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
In Section 3.3 ‚ÄúBest configurations (quasi-random search)‚Äù, specifically Table 3, the paper presents an ablation of independent hyperparameters, over the best configuration for each of the 5 models.	Review	B-Review	4
This is a very interesting section.	Review	I-Review	4
One further suggestion, however, is whether the paper could include the performance of each of the models on the _average_ best configuration.	Review	I-Review	4
Although the paper describes losses for switching individual parameters to their second best values, it is unlikely that the losses are cumulative.	Review	I-Review	4
So, for example, if we can take the average/majority best value for each parameter (embedding size = 512, batch size = 1024, training type = 1vsall, loss = CE, etc.),	Review	I-Review	4
and collect results for that configuration.	Review	I-Review	4
I think it would be interesting to know the difference between a model trained on a ‚Äúcollectively known good‚Äù set of parameters vs. a model and task specific tuned set of parameters.	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	O	0
In Section 2, ‚ÄúEvaluation‚Äù, HITS@k is not formally defined.	Review	B-Review	5
Unfortunately, I have encountered slight variants of this metrics (e.g: (1) given a SINGLE correct label, HITS@k is the average rate of the label being present in the top k scored results, or (2) given ALL possible correct labels, HITS@k is the percentage of correct labels present within the top k scored results, etc.).	Review	I-Review	5
It would be nice to precisely describe HITS@k in this work.	Review	I-Review	5
[line_break_token][line_break_token]6.	Review	O	0
Caption for Table 2 does not contain a description for the ‚ÄúRecent‚Äù super-column.	Review	B-Review	6
[line_break_token][line_break_token]7.	Review	O	0
In Section 3.3 ‚ÄúBest configuration (quasi-random search)‚Äù Space missing at ‚Äú... Tables 6 and 7(in ‚Ä¶‚Äù, between 7 and (.	Review	B-Review	7
[line_break_token]	Review	O	0
e thank you for your feedback and appreciate your support.	Reply	O	0
In what follows, we briefly comment on the points raised in your review.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
There are no such limitations in our experimental framework that we are aware of.	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Good point!	Reply	B-Reply	2
Generally, it may indeed be possible to short-circuit hyperparameter search but that is beyond our current study.	Reply	I-Reply	2
Our framework is extensible, however, so that there shouldn't be any principal limitations in adding other hyperparameter optimization methods (and we'd like to include more).	Reply	I-Reply	2
What we can do for the present study is to include plots that show model performance (e.g., best validation MRR obtained over all hyperparameter configurations) as a function of the epochs each configuration has been trained.	Reply	I-Reply	2
The new plots will give information about how fast models can find good configurations and compare different models along these lines.	Reply	I-Reply	2
Would you consider this helpful?	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Our goal was to have a fair, balanced comparison, but not to find perfect hyperparameters.	Reply	B-Reply	3
For example, the ComplEx result mentioned in the "Limitations" section uses a configuration which is indeed within our search space but was not found during our hyperparameter search.	Reply	I-Reply	3
Of course, the more effort we spend on  hyperparameter search, the better models we may find.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
We consciously did not report performance on an "collectively good configuration".	Reply	B-Reply	4
A key point that we are trying to make is that there is no such configuration: any configuration will be good for some models but bad for others.	Reply	I-Reply	4
The same argument extends to small search grids.	Reply	I-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
Thanks for bringing this to our attention.	Reply	B-Reply	5
We use (1) and will include a formal definition of the metrics in the appendix.	Reply	I-Reply	5
[line_break_token][line_break_token]6.	Reply	O	0
Thanks, added.	Reply	B-Reply	6
[line_break_token][line_break_token]7.	Reply	O	0
Thanks, fixed.	Reply	B-Reply	7

Summary: [line_break_token][line_break_token]This paper proposes using non-parametric filters like Discrete Cosine Transform (DCT) and Discrete Walsh-Hadamard Transform (DWHT) which have been widely used as feature extractors in vision and image processing before deep learning became prevalent as layers especially to replace pointwise convolution (PC) layers in deep network architectures like ShuffleNet-v2 and MobileNet-V1.	Review	O	0
[line_break_token][line_break_token]The motivation is that using such layers can capture cross-channel correlations without addition of extra parameters that need to be learnt and by replacing PC layers which tend to make up the bulk of the parameters in such settings large reduction in number of weights and flops can be achieved with little drop (or even increase) in accuracy.	Review	O	0
[line_break_token][line_break_token]They show experiments on cifar100 datasets.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]- The paper is overall easy to read although the writing and presentation can use some work.	Review	O	0
[line_break_token][line_break_token]- I really enjoyed reading the paper though because it seems in the deep learning era we have a tendency to re-learn what we already know.	Review	O	0
This paper shows that combining our knowledge of image processing and compressed sensing with good function approximation leads to better and more compact representation learning.	Review	O	0
I think these aspects are being generally overlooked currently but wont be surprised to see more of these papers.	Review	O	0
[line_break_token][line_break_token]- While reading section 3.2 it occurred to me that it might be interesting to consider throwing these layers in to a neural architecture search (NAS) algorithm and let it figure out the right architecture. (	Review	O	0
Just a suggestion for future work not asking for this in the rebuttal.)	Review	B-Review	2
[line_break_token][line_break_token]- Overall I am positive about the paper and have no major asks but if time and resources permit perhaps trying out the same experiments on ImageNet to see if the trend holds.	Review	O	0
s a future work, we will indeed research for applying Neural Architecture Search (NAS) in our proposed PC layers.	Reply	B-Reply	2
From a microscopic viewpoint, we expect NAS would help to find new DCT, DWHT blocks rather than just applying our DCT / DWHT on human-designed blocks (ShuffleNet blocks, MobileNet blocks).	Reply	I-Reply	2
These optimal block structures discovered by NAS might enable our DCT / DWHT based PC layers to more sufficiently represent the correlation between the feature maps while taking more advantages of light-weight and low-computational overhead.	Reply	I-Reply	2
Meanwhile from a macroscopic viewpoint, we expect NAS can optimize the network to find the position where the proposed PC layers can be applied under the condition of improving the classification accuracy, which can reduce the time and burden of human researchers to apply our PC layers.	Reply	I-Reply	2
Thus this future work will be valuable for introducing generality of our method.	Reply	I-Reply	2
Additionally, regarding the experiments on ImageNet, we leave them as future works due to the limited time and resources.	Reply	I-Reply	3
We sincerely thank the reviewer for the insightful suggestion and comments	Reply	I-Reply	3

The authors propose a function-space based approach to continual learning problems (CL), wherein a learned embedding[line_break_token][line_break_token]   [line_break_token][line_break_token]is shared between task-specific GPs s.t.	Review	O	0
[line_break_token][line_break_token]   , [line_break_token][line_break_token]where the-th task's covariance is a defined via standard variational inducing points methods.	Review	O	0
CL manifests as KL divergences between tasks' variational posteriors and their respective priors.	Review	O	0
Since the embedding helps define, its parameters are regularized to promote sharing.	Review	O	0
[line_break_token][line_break_token]The work investigates both practical and theoretical implications of this setup.	Review	O	0
On the practical side, the authors discuss enhanced 'on-task' inference via hybridization of function- and weight-space based approaches and, subsequently, strategies for optimizing inducing points.	Review	O	0
Additionally, a novel approach for automatically detect task switching is introduced that exploits the Bayesian aspects of the proposed framework.	Review	O	0
[line_break_token][line_break_token]On the theoretical side, points of (personal) interest revolved around differences between weight- and function-space approaches to CL.	Review	O	0
Here, I think that streamlining the presented argument would go a long ways.	Review	O	0
Paraphrasing, one of the authors' key insights is that:[line_break_token][line_break_token]  1) CL in weight-spaces is hard, since weights' semantics are moving target that change along with shared parameters.	Review	O	0
[line_break_token]  2) CL in function-space is easy, since the functions (i.e. tasks) themselves remain the same.	Review	O	0
[line_break_token][line_break_token]This information is provided in the introduction, but (as a relative newcomer to CL) I failed to connect regularization and rehearsal/replay based methods with the aforementioned spaces.	Review	B-Review	1
It was only upon reading Sect 2.5 that this intuition 'clicked' for me.	Review	I-Review	1
Hence, I suggest making this observation as obvious and intuitive as possible.	Review	I-Review	1
[line_break_token][line_break_token]The provided experiments seem reasonable and do a good job highlighting different facets of the paper.	Review	O	0
Two additional results would be appreciated:[line_break_token][line_break_token]  a) How well calibrated are FRCL-based classifiers?	Review	O	0
[line_break_token]  b) How impactful is the hybrid representation (Sect 2.3) for test-time performance?	Review	O	0
[line_break_token][line_break_token]GP approximations formulated solely in terms of weighted sums of (finitely many) basis functions typically suffer from degradation of predictive uncertainties.	Review	B-Review	3
Since one often motivates use of GPs via a desire for well-calibrated uncertainty, (a) seem quite pertinent.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]Nitpicks, Spelling, &amp; Grammar:[line_break_token]  - Lots of run-on sentences; consider breaking these up.	Review	O	0
[line_break_token]  - Introductory modifying phrases are missing commas.	Review	B-Review	4
[line_break_token]  - Consider citing other recent works that use NN basis functions in conjunction with Bayesian Linear Regression.	Review	I-Review	4
[line_break_token]  - Various missing or superfluous words resulting in some garbled sentences, e.g.:[line_break_token]      - "... our approach looks constraining."	Review	I-Review	4
[line_break_token]      - "The ability to detect changes based on the above procedure comes from that in"[line_break_token]      - "While the task boundary detection results for Omniglot are less strong, which may due to the smaller batch size (32 for Omniglot, ‚â• 100 for the MNIST-versions), resulting a noisier test result."	Review	I-Review	4
[line_break_token]	Review	O	0
hank you for your thoughtful review .	Reply	O	0
Point 1) and 2) describes well the differences between regularising continual learning in the function space rather than on the weight space.	Reply	B-Reply	1
To add to that, the motivation behind our method is that  learning a supervised task corresponds to learning a function, and thus our method tries to ‚Äúremember‚Äù the task by remembering direct posterior estimates over output values of that function at informative inputs.	Reply	I-Reply	1
 The  ‚Äúmoving target‚Äù comment made by the reviewer regarding methods that regularise based on posteriors over weights captures precisely the intuition of what mathematically we analyse in Section 2.5 and we are glad that the reviewer found this useful.	Reply	I-Reply	1
Given that Section 2.5 provides a more technical explanation, we will try to follow reviewer suggestions and provide a more intuitive discussion earlier in the paper.	Reply	I-Reply	1
    [line_break_token][line_break_token][line_break_token]- Robustness on FRCL-based classifiers and impactfulness of hybrid representation for test-time performance:[line_break_token][line_break_token]It is hard to know how well calibrated are the uncertainties of FRCL since we do not know the ground-truth.	Reply	O	0
FRCL is based on a neural network where we do Bayesian inference only over the final layer weights (Usually termed Deep Kernel learning (Wilson et al.,	Reply	B-Reply	2
AISTATS 2016) [<a href="http://proceedings.mlr.press/v51/wilson16.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v51/wilson16.pdf</a> ]).	Reply	O	0
It is encouraging that according to the large scale study in (Riquelme et.	Reply	B-Reply	2
al, 2018 [<a href="https://arxiv.org/abs/1802.09127" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.09127</a> ]) such as (not fully Bayesian approach) is always one of the best techniques among many other methods in contextual bandits applications, where modelling well uncertainties within a Thompson sampling exploration framework is very crucial.	Reply	O	0
The aforementioned work by (Wilson et al.,	Reply	B-Reply	2
AISTATS 2016) also shows that predictive uncertainty can be of high quality.	Reply	I-Reply	2
Regarding b) if we do not apply the hybrid approach where inference over the current task is done in the weight-space, and instead we apply variational sparse GPs for the current task, the performance is significantly worse (we can add a Table for that in the Appendix for completeness).	Reply	I-Reply	2
The reason is that the estimate of the posterior distribution over the inducing values is not accurate enough both in terms of the mean and also in terms of variances (typically underestimation) when compared to obtained by the hybrid approach.	Reply	I-Reply	2
The latest  allows fitting the current task with the tightest possible ELBO and getting the best possible approximate posterior  (i.e. with no additional approximation error due to the inducing points and the variational sparse GP) which leads to better estimate of each and subsequently better regularisation for continual learning.	Reply	I-Reply	2
   [line_break_token][line_break_token]- GP approximations in terms of finitely many basis functions:[line_break_token][line_break_token]The degradation of predictive uncertainties of finite basis functions certainly occurs when the basis function are local, e.g radial basis functions, but typically does not occur for non local basis functions/activation units  as the ones we typically use in neural networks.	Reply	O	0
E.g. when the feature vector  is defined by ReLUs or tanh activation functions, which are non local, the degradation of predictive variances is typically not observed as we move away from the training inputs.	Reply	B-Reply	3
This is to some extent also confirmed by the task-boundary detection results.	Reply	I-Reply	3

The paper proposes a new approach for neural language models based on holographic reduced representations (HRRs).	Review	O	0
The goal of the approach is to learn disentangled representations that separate different aspects of a term, such as its semantic and its syntax.	Review	O	0
For this purpose the paper proposes models both on the word and chunk level.	Review	O	0
These models aim disentangle the latent space by structuring the latent space into different aspects via role-filler bindings.	Review	O	0
[line_break_token][line_break_token]Learning disentangled representations is a promising research direction that fits well into ICLR.	Review	O	0
The paper proposes interesting ideas to achieve this goal[line_break_token]in neural language models via HRRs.	Review	O	0
Compositional models like HRRs make a lot of sense for disentangling structure in the embedding space.	Review	O	0
Some of the experimental results seem to indicate that the proposed approach is indeed capable to discover rough linguistic roles.	Review	O	0
However, I am currently concerned about different aspects of the paper:[line_break_token][line_break_token]- From a modeling perspective, the paper seems to conflate two points: a) language modeling vie role-filler/variable-binding models and b) holographic models as specific instance of variable bindings.	Review	O	0
The benefits of HRRs (compared e.g., to tensor-product based models) are likely in terms of parameter efficiency.	Review	B-Review	1
However, the benefits from a variable-binding approach for disentanglement should remain across the different binding operators.	Review	I-Review	1
It would be good to separate these aspects and also evaluate other binding operators like tensors products in the experiments.	Review	I-Review	1
[line_break_token][line_break_token]- It is also not clear to me in what way we can interpret the different filler embeddings.	Review	O	0
The paper seems to argue that the two spaces correspond to semantics and syntax.	Review	B-Review	2
However, this seems in no way guaranteed or enforced in the current model.	Review	I-Review	2
For instance, on a different dataset, it could entirely be possible that the embedding spaces capture different aspects of polysemy.	Review	I-Review	2
 However, this is a central point of the paper and would require a more thorough analysis, either by a theoretical motivation or a more comprehensive evaluation across multiple datasets.	Review	I-Review	2
[line_break_token][line_break_token]- In its current form, I found the experimental evaluation not convincing.	Review	O	0
The qualitative analysis of filler embeddings is indeed interesting and promising.	Review	B-Review	3
However, the comparisons to baseline models is currently lacking.	Review	I-Review	3
For instance, perplexity results are far from state of the art and more importantly below serious baselines.	Review	I-Review	3
For instance, the RNN+LDA baseline from Mikolov (2012) achieves already a perplexity of 92.0 on PTB (best model in the paper is 92.4).	Review	I-Review	3
State-of-the-art models acheive perplexities around 50 on PTB.	Review	I-Review	3
Without an evaluation against proper baselines I find it difficult to accurately assess the benefits of these models.	Review	I-Review	3
While language modeling in terms of perplexity is not necessarily a focus of this paper, my concern translates also to the remaining experiments as they use the same weak baseline.	Review	I-Review	3
[line_break_token][line_break_token]- Related to my point above, the experimental section would benefit significantly if the paper also included evaluations on downstream tasks and/or evaluated against existing methods to incorporate structure in language models.	Review	O	0
[line_break_token][line_break_token]Overall, I found that the paper pursues interesting and promising ideas, but is currently not fully satisfying in terms of evaluation and discussion.	Review	O	0
(4) ‚Äúthe experimental section would benefit significantly if the paper also included evaluations on downstream tasks and/or evaluated against existing methods to incorporate structure in language models.	Reply	O	0
‚Äù[line_break_token][line_break_token]As for downstream task, due to space limit, it‚Äôs hard to fully investigate the potential benefits besides the decomposed representations which we spent most of our experimental section on.	Reply	O	0
However, we are planning on running a POS tagging task using learned representations as features for a linear classifier.	Reply	B-Reply	4
We are also planning on running the model on SRL task.	Reply	I-Reply	4
We believe these tasks would be good testbeds for our proposed method, and also address your concern here.	Reply	I-Reply	4
[line_break_token][line_break_token]As for comparison against existing methods, we are not aware of any directly applicable approach.	Reply	I-Reply	4
There are certainly many existing methods that try to incorporate structures, but mostly to enhance their representation, not decompose their representation.	Reply	I-Reply	4
Moreover, the unsupervised nature of our approach makes direct comparison even harder.	Reply	I-Reply	4
Of course, we can be totally ignorant, and we would appreciate any advice from you if you are aware of any specific comparable approach that fits the scenario here.	Reply	I-Reply	4
[line_break_token][line_break_token][1] Devlin et al.,	Reply	O	0
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding[line_break_token][2] Peters et al.,	Reply	O	0
Deep contextualized word representations[line_break_token][3] Huang et al.,	Reply	O	0
Tensor Product Generation Networks for Deep NLP Modeling	Reply	O	0

This paper proposes to learn entity representations by matching entities to the context it occurs in.	Review	O	0
It also shows that using these representations is very effective for a wide variety of down-stream entity-centric tasks such as entity typing, linking, and answering entity centric trivia questions.	Review	O	0
They train the model using a corpus of entity linked Wikipedia contexts (sentences unto length 128 tokens).	Review	O	0
The context is encoded with a BERT model and the CLS representation is used as the representation of context.	Review	O	0
After obtaining the representation, they train the entity embedding (present in the sentence) to be similar to the context embedding.	Review	O	0
They test their embeddings on few down-stream entity-centric tasks ‚Äî linking, typing and trivia question answering.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]1.	Review	O	0
They try the entity representations on a wide variety of entity-centric tasks and get reasonable results.	Review	O	0
[line_break_token][line_break_token]Weaknesses:[line_break_token]1.	Review	O	0
The biggest weakness of the paper is wrt novelty.	Review	B-Review	1
Masking out entities and training to context is not a new idea.	Review	I-Review	1
As pointed by the paper, Yamada et al.,	Review	I-Review	1
2017 have a very similar objective and it is not very clear from the paper what is the additional contribution that this paper makes.	Review	I-Review	1
Is using pretrained LMs the major difference?	Review	I-Review	1
If not, it would have been nice to see Yamada et al‚Äôs results with BERT.	Review	I-Review	1
Over all, this paper needs to make its own contribution clear compared to Yamada et al.,	Review	I-Review	1
2017.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	2
The paper needs to be written more clearly at several places.	Review	I-Review	2
Few examples are, even though in entity linking results (Table 1) the model achieves 83.0 with other papers achieving 90.9.	Review	I-Review	2
I didnt see a discussion on how to close the gap.	Review	I-Review	2
Even in the coNLL benchmark, the initial results of the paper is significantly behind.	Review	I-Review	2
Claims like ‚ÄúCoNLL -Aida is known to be restricted and idiotic-synctatic domain‚Äù should be backed by detailed analysis or atleast a citation.	Review	I-Review	2
Even after finetuning on the CoNLL benchmark, the result is 2.2 points behind state of the art and no discussions have been provided.	Review	I-Review	2
As a result, I think the entity linking section needs major re-writing and explanation of the results.	Review	I-Review	2
[line_break_token]3.	Review	I-Review	2
The paper makes an interesting observation that masking of entities is better for typing tasks and it affects linking performance, because spelling features are really important for linking.	Review	I-Review	3
It would be interesting to see a discussion on what could be done to remedy this.	Review	I-Review	3
Because if we have to retrain entity embeddings for different tasks, then it goes against the hypothesis of the paper which is to use entity representations for a wide variety of down-stream tasks.	Review	I-Review	3
[line_break_token]4.	Review	I-Review	4
I found it confusing to read the setup in sec 5.4.	Review	I-Review	4
especially where it says we represent each category with three random exemplars.	Review	I-Review	4
Initially I thought 3 randomly sampled entities formed a category, which didnt make sense, but from figure 3, I think I understood that you first pick a category from Typenet and Wikipedia and then 3 entities are sampled from there.	Review	I-Review	4
Is that correct?	Review	I-Review	4
Regarding the results, can the poor results of Yamada et al.,	Review	I-Review	4
can be understood by the fact that it was trained using smaller number of categories?	Review	I-Review	4
Also, why are the numbers wrt All entities left blank in Table 4.	Review	I-Review	4
Given that your model is similar, I am assuming its easy to retrain Yamada et al and test it on the all entities benchmark?	Review	I-Review	4
hank you for your review and detailed questions.	Reply	O	0
[line_break_token][line_break_token]As discussed in the response to all reviewers, we agree that RELIC's model architecture is not particularly novel.	Reply	B-Reply	1
We believe that this paper's contribution is in the extensive, and novel, experiments that go well beyond previous work in testing the extent to which embeddings learned from textual context can capture the knowledge required for a wide range of entity-centric tasks.	Reply	I-Reply	1
[line_break_token][line_break_token]In response to your questions about our entity linking results we have updated our experiments to be more in line with other entity linking approaches.	Reply	I-Reply	2
First, we have adopted the same CoNLL alias table used by most other recent approaches.	Reply	I-Reply	2
Second, we reduced the TAC-KBP entity candidate set to only those entities in the TAC-KBP knowledge base (a reduction of 5m -&gt; 818k candidates).	Reply	O	0
Third we have updated provided the RELIC model with the start of each document, as well as the immediate context surrounding each entity mention.	Reply	B-Reply	2
[line_break_token][line_break_token]Together, these modifications have brought RELIC's performance up to match the state of the art on CoNLL (94.9%), and second only to DeepType on TAC-KBP (RELIC: 89.8%, DeepType: 90.9%).	Reply	I-Reply	2
DeepType relies on the large Wikidata knowledge base for entity representations and we consider it significant that RELIC can match this system's performance with embeddings learned purely from context.	Reply	I-Reply	2
We discuss our modifications more in the response to all reviewers, as well as the updated paper.	Reply	I-Reply	2
[line_break_token][line_break_token]As well as reporting the performance of the RELIC model that has been tuned toward the entity linking task (CoNLL + Aida tuning), we do still report the performance of the pure RELIC model that has never seen any in-domain data, and which does not have access to any alias table.	Reply	I-Reply	2
As you point out, these results do lag behind the state of the art but we hope that our new experiments show what is responsible for the gap between the pure model's performance, and the state of the art.	Reply	I-Reply	2
[line_break_token][line_break_token]In response to your criticism of our vague characterisation of the CoNLL task, we have rewritten the entity linking section to focus on the specifics of how specialised entity linking approaches differ from the pure RELIC model.	Reply	I-Reply	2
Thank you for this suggestion, we believe that the section is now much more robust and meaningful.	Reply	I-Reply	2
[line_break_token][line_break_token]We are glad that you found our investigation of the masking rates to be interesting and we would like to highlight that, simple as it is, masking mentions is a novelty of this paper not shared by previous work that focused on entity linking.	Reply	I-Reply	3
Thank you also for your observation that RELIC's broad utility is hindered by the different optimum mask rates for entity linking and typing tasks.	Reply	I-Reply	3
We have updated the paper with a discussion of optimum mask rates.	Reply	I-Reply	3
We consider the choosing of an optimum mask rate to be an ongoing research question, and we plan to experiment with variable mask rates that account for variation in entity frequency.	Reply	I-Reply	3
[line_break_token][line_break_token]Finally, in response to your question about section 5.4, we have clarified the contents of Table 4.	Reply	I-Reply	4
There are two settings for both the TypeNet and Wikipedia category completion tasks.	Reply	I-Reply	4
The first contains all entities in each of those domains and the second (Yamada Subset) only contains the entities covered by the embedding table provided by Yamada et.al.	Reply	I-Reply	4
 (<a href="https://github.com/studio-ousia/ntee)."	Reply	O	0
target="_blank" rel="nofollow">https://github.com/studio-ousia/ntee).</a> All of the comparisons between RELIC and Yamada use exactly the same entity and category vocabulary and the row for Yamada et.al.	Reply	O	0
is left blank in the "All Entities" column because their embedding table does not contain all of the entities in this set.	Reply	B-Reply	4
Since we perform a comparison to Yamada et.al.	Reply	I-Reply	4
by using their provided embeddings, on their entity vocabulary, and with no further task specific training for either approach, we believe that this is the cleanest comparison that we can make between the RELIC and Yamada entity embedding tables on an entity typing task	Reply	I-Reply	4

This paper proposes a regularization method for achieving robustness to noisy inputs, with relatively less computation compared to standard data augmentation approaches.	Review	O	0
Specifically, the authors analyze the analytic expression of the loss on the noisy inputs, and using Jensen‚Äôs inequality, propose to minimize a surrogate loss over the expectation of noisy inputs.	Review	O	0
To minimize the loss over the expectation, the authors impose a regularization over the first moment of the network weights.	Review	O	0
The authors validate the model with the proposed regularization technique for its robustness against Gaussian attack and other types of attacks, whose results show that the model is robust.	Review	O	0
[line_break_token][line_break_token]Pros[line_break_token]- The general idea of the regularization that replaces the generation of noisy samples and optimization over it is conceptually appealing and seems practically useful.	Review	O	0
[line_break_token]- The derivation of the moment-based regularization makes sense.	Review	O	0
[line_break_token]- The proposed regularizer seems to be effective to a certain degree, on the sets of experiments done by the authors.	Review	O	0
[line_break_token][line_break_token]Cons[line_break_token]- Experimental validation seems highly inadequate due to lack of baselines.	Review	O	0
Thus it is difficult to assess the degree of robustness the proposed model achieves.	Review	B-Review	1
The authors should perform extensive evaluation against state-of-the-art techniques against multiple types of attacks, in order to demonstrate the effectiveness of the proposed method.	Review	I-Review	1
[line_break_token]- While the authors emphasize the computational efficiency of the method, the authors do not report computational cost or actual runtime.	Review	O	0
 [line_break_token]- The types of non-Gaussian attacks should be better described.	Review	O	0
Which ones use L-infinity attacks and which use L2 attacks?	Review	B-Review	3
[line_break_token]- Figure 3 doesn‚Äôt seem like a very favorable result to the proposed model, since we are generally more concerned with adversarial examples generated with small perturbations, as large perturbations may change the input semantics.	Review	O	0
[line_break_token][line_break_token]In sum, while I like the overall idea and find the work novel and potentially practical, it is difficult to properly evaluate the work due to lack of comparison against state-of-the-art data augmentation methods for achieving robustness.	Review	O	0
Therefore I temporarily give this paper a weak reject, but may change the rating with more experimental results provided in the rebuttal.	Review	O	0
- comparisons[line_break_token]    Due to time constraints, we couldn't compare with other baselines during the rebuttal period.	Reply	O	0
Nevertheless, the main motivation behind this work is to demonstrate the effectiveness of our regularizer as an efficient replacement for data augmentation that works even with a high noise regime on high dimensional data.	Reply	B-Reply	1
The reported robustness improvement is one way to show this.	Reply	I-Reply	1
[line_break_token]- computational cost[line_break_token]    We averaged the time it takes to do 10 training epochs on AlexNet with and without our regularizer.	Reply	O	0
Our method has an overhead that is equivalent to doing data augmentation with.	Reply	B-Reply	2
Of course, this number is inversely proportional to the depth of the network, demonstrating the usefulness of this method.	Reply	I-Reply	2
[line_break_token]- attacks norms[line_break_token]    Every robustness metric can be investigated independently but we should clarify the reported units.	Reply	O	0
Thank you for pointing this out.	Reply	B-Reply	3
[line_break_token]- favorable result[line_break_token]    The x-axis in Figure 3 is for the training noise level.	Reply	O	0
Whereas, the reported robustness is averaged over 30 evenly sampled noise levels in [0, 0.5]. We show in Appendix B examples of different noise levels applied to an MNIST image.	Reply	B-Reply	4
It is indeed favorable, considering how we can achieve a sweet tradeoff between accuracy and robustness	Reply	I-Reply	4

This paper proposes to derive distributional representation for words[line_break_token]that can be used to improve word embeddings.	Review	O	0
Distributional vectors[line_break_token]can present to the neural network that learns embeddings, instead of[line_break_token]presenting one-hot vectors.	Review	O	0
One motivation is that distributional[line_break_token]representation could make the learning task easier for rare words.	Review	O	0
The[line_break_token]authors apply this approach only to rare words since word embeddings[line_break_token]for frequent words is frequently updated and then can be considered as[line_break_token]satisfactory.	Review	O	0
[line_break_token][line_break_token]The idea is nice.	Review	O	0
However, my main concern is about the experimental[line_break_token]part.	Review	B-Review	1
I don't understand the results.	Review	I-Review	1
For the 'WordSim' task, the[line_break_token]paper of E. Huang (ACL2012) exhibits spearman correlation above 50.	Review	I-Review	1
So[line_break_token]wether the results are incredibly below the baseline systems used in[line_break_token]2012 (and thus, what can we conclude from this paper since it is[line_break_token]straightforward to improve a very poor system), or this need[line_break_token]clarification.	Review	I-Review	1
Anyway, baseline exists and should be mentioned.	Review	I-Review	1
[line_break_token][line_break_token]A minor comment about the last paragraph of the introduction.	Review	I-Review	2
The[line_break_token]paper (Hai Son Le et al.	Review	I-Review	2
at EMNLP2010) addressed the issue of the[line_break_token]initialization of word embeddings and this seems to perform quite well[line_break_token]especially for rare words.	Review	I-Review	2
Dear reviewer,[line_break_token]Please, find our reply for your comments below	Reply	O	0

The authors propose to approximate inference in Bayesian neural networks by minimising the KL divergence between the true posterior and the approximating distribution KL(p|q) (rather than the usual VI objective KL(q|p)).	Review	O	0
The objective used (known as EP's KL objective) is known to result in better uncertainty estimates.	Review	O	0
The authors then propose to approximate the resulting intractable expectation over the posterior by Monte Carlo sampling, with samples produced from SGLD.	Review	O	0
This neat idea of summarising MCMC approximations using sufficient statistics originating from a variational approximation has some interesting implications, for example avoiding the memory requirements of storing many samples of the model parameters.	Review	O	0
This technique is then used in outlier detection, and demonstrated to slightly improve over MC sampling with dropout VI, and slightly under-perform compared to full ensembles that replicate many copies of the parameters (requiring much more memory to store the models).	Review	O	0
[line_break_token][line_break_token]My biggest concern with the paper, though, is that the authors don't actually use SGLD in the experiments since they "found [SGLD hyper parameters] hard to tune", and used the Adam optimiser instead.	Review	O	0
This means that the samples accumulated are not from the posterior of the model at question, but just *a* collection of network weights, casting a heavy shade on any possible interpretation of the experiment results.	Review	O	0
[line_break_token][line_break_token]I like the ideas presented in the submission, and would encourage the authors to repeat their experimental evaluation, also comparing their method to more sensible baselines such as fully factorised Gaussian VI inference in Bayesian neural networks (which is closely related to the suggested technique).	Review	O	0
Many thanks for the positive feedback and the suggestions for further comparison and related work.	Reply	O	0
We will take this into account and conduct the additional experiments	Reply	O	0

The paper proposes a new Graph Neural Network (GNN) architecture that uses Feature-wise Linear Modulation (FiLM) to condition the source-to-target node message-passing based on the target node representation.	Review	O	0
In this way, GNN-FiLM aims to allow a GNN's message propagation to "focus on feature that are especially relevant for the update of the target node."	Review	O	0
The authors clearly describe prior GNN architectures, showing that the do not incorporate such forms of message propagation.	Review	O	0
The authors then describe several intuitive ways of adding such a form of message propagation, before describing why those approaches do not work in practice.	Review	O	0
Finally, the authors introduce GNN-FiLM, which is computationally reasonable and works well in practice, as evaluated according to several GNN benchmarks.	Review	O	0
The GNN-FiLM model is also quite simple and elegant, which makes me think it is likely to work on more tasks than the authors experiment on.	Review	O	0
[line_break_token][line_break_token]The paper is clear and easy to follow.	Review	O	0
The authors' description of other GNNs architectures is clear, and their own approach seems well motivated and clearly described in relation to previous GNNs.	Review	O	0
[line_break_token][line_break_token]The authors have released the code for method, where they have also reimplemented several popular GNN methods.	Review	O	0
The open-source codebase also seems to be valuable contribution for future research and reproducibility in work on GNNs.	Review	O	0
[line_break_token][line_break_token]The empirical evaluation seems thorough.	Review	O	0
GNN-FiLM works well on 3 graph tasks (PPI, QM9, VarMisuse) with different properties.	Review	O	0
To compare models, the authors conduct a search of hyperparameter ranges for each model.	Review	O	0
The authors even improve several of the baseline methods, generalizing some approaches to include different edge types and to add self-loops, as well as using better networks (adding dropout and increasing hidden dimensions).	Review	O	0
The paper even finds that one existing/obvious GNN architecture (GNN-MLP) is underrated.	Review	O	0
The paper reads like an honest analysis of existing methods, even though it also introduces its own, new method that works better.	Review	O	0
[line_break_token][line_break_token]Questions:[line_break_token]* Do you have any intuition about why the Eqn.	Review	O	0
5 model is less stable than GNN-FiLM?	Review	B-Review	1
[line_break_token]* On GNN-FiLM's training stability and regularization: I am interested in the negative result described in the following sentence: "Preliminary experiments on the citation network data showed results that were at best comparable to the baseline methods, but changes of a random seed led to substantial fluctuations (mirroring the problems with evaluation on these tasks reported by Shchur et al. (	Review	O	0
2018))" Do the authors have any intuition about why the results are highly dependent on the random seed?	Review	B-Review	2
The results on other tasks seems to not have much variance.	Review	I-Review	2
It could be interesting to try various techniques to stabilize learning on that task.	Review	I-Review	2
A simple approach like gradient clipping might work, or there are perhaps other techniques.	Review	O	0
For example, in "TADAM: Task dependent adaptive metric for improved few-shot learning", the authors find it important to regularize FiLM parameters \gamma and \beta towards 1 and 0, respectively, which may make learning more stable here.	Review	B-Review	4
In general, previous work seems to find it important to regularize the parameters that predict FiLM parameters, which may also fix GNN-FiLM's overfitting on VarMisuse.	Review	I-Review	4
Exploring such approaches could make it easier for future work to use FiLM with GNNs.	Review	I-Review	4
[line_break_token]* On potential related work: GNN-FiLM is a "self-conditioned" model which learns to apply feature-wise transformations based on the activations at the current layer.	Review	O	0
If I am not mistaken, the self-conditioning aspect of GNN-FiLM makes it related to the self-conditioned models described in "Feature-wise Transformations" ([Feature-wise transformations](<a href="https://distill.pub/2018/feature-wise-transformations/))" target="_blank" rel="nofollow">https://distill.pub/2018/feature-wise-transformations/))</a> - for example, see the "Image Recognition" section (Squeeze-and-Excitation Networks and Highway Networks) and the "Natural Language Processing" section (LSTMs, gated linear units, and gated-attention reader).	Review	O	0
Do the authors see a connection with such models?	Review	B-Review	5
If so, it would be interesting to hear these works discussed (in the rebuttal and paper) and the exact connection described.	Review	I-Review	5
hank you for your kind review and your interesting questions!	Reply	O	0
[line_break_token][line_break_token]&gt; * Do you have any intuition about why the Eqn.	Reply	O	0
5 model is less stable[line_break_token]&gt; than GNN-FiLM?	Reply	O	0
[line_break_token][line_break_token]While there are no clean experiments to back this up, the instability seems to have two sources:[line_break_token](1) The computation of takes a state of size and blows it up into a matrix.	Reply	B-Reply	1
Obviously, the values (or worse, outliers) of a single dimension of then affect a number of values in, which are then applied to some.	Reply	I-Reply	1
This blow-up-then-collapse pattern exacerbates the effect of outlier data.	Reply	I-Reply	1
Using squashing activation functions such as sigmoids to limit the range of values helped with this, but seems to have not entirely solved the problem.	Reply	I-Reply	1
[line_break_token](2) Computing by a linear layer from requires careful initialisation of to ensure that is appropriate (e.g., that the sum of each row is near 1, to avoid strong growth / decay in values).	Reply	O	0
This somewhat worked, but some unlucky initializations would still diverge.	Reply	B-Reply	1
Doing a deeper analysis and then apply, for example, appropriate rescaling of weights after init (maybe in the style of Fixup Initialization <a href="https://arxiv.org/pdf/1901.09321.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1901.09321.pdf)</a> could work, but was not explored as the FiLM variant worked well, and the memory and time cost of computing is substantial.	Reply	O	0
[line_break_token][line_break_token]&gt; * On GNN-FiLM's training stability and regularization: I am interested[line_break_token]&gt; in the negative result described in the following sentence:[line_break_token]&gt; "Preliminary experiments on the citation network data showed results[line_break_token]&gt; that were at best comparable to the baseline methods, but changes of a[line_break_token]&gt; random seed led to substantial fluctuations (mirroring the problems[line_break_token]&gt; with evaluation on these tasks reported by Shchur et al. (	Reply	O	0
2018))" Do[line_break_token]&gt; the authors have any intuition about why the results are highly[line_break_token]&gt; dependent on the random seed?	Reply	O	0
The results on other tasks seems to not[line_break_token]&gt; have much variance.	Reply	O	0
It could be interesting to try various techniques[line_break_token]&gt; to stabilize learning on that task.	Reply	O	0
[line_break_token][line_break_token]This seems to be a property of the datasets, see the error bars of the plots in appendix D of Shchur et al. (	Reply	B-Reply	2
2018) (<a href="https://arxiv.org/pdf/1811.05868.pdf)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1811.05868.pdf).</a> [line_break_token][line_break_token]&gt; A simple approach like gradient clipping might work, or there are perhaps[line_break_token]&gt; other techniques.	Reply	O	0
[line_break_token][line_break_token]Gradient clipping is implemented for all evaluated models (with a max grad norm of 1.0, though different clipping values had little influence on results in cursory experiments).	Reply	B-Reply	3
[line_break_token][line_break_token]&gt; For example, in "TADAM: Task dependent adaptive metric for improved[line_break_token]&gt; few-shot learning", the authors find it important to regularize FiLM[line_break_token]&gt; parameters \gamma and \beta towards 1 and 0, respectively, which may[line_break_token]&gt; make learning more stable here.	Reply	O	0
In general, previous work seems to[line_break_token]&gt; find it important to regularize the parameters that predict FiLM[line_break_token]&gt; parameters, which may also fix GNN-FiLM's overfitting on VarMisuse.	Reply	O	0
[line_break_token]&gt; Exploring such approaches could make it easier for future work to use[line_break_token]&gt; FiLM with GNNs.	Reply	O	0
[line_break_token][line_break_token]Using a regularizer to explicitly push to 1 and to 0 sounds like a reasonable idea, which has not been used in the experiments yet.	Reply	B-Reply	4
If time allows, experiments with such a penalty term will be run during the rebuttal period.	Reply	I-Reply	4
[line_break_token][line_break_token]&gt; * On potential related work: GNN-FiLM is a "self-conditioned" model[line_break_token]&gt; which learns to apply feature-wise transformations based on the[line_break_token]&gt; activations at the current layer.	Reply	O	0
If I am not mistaken, the[line_break_token]&gt; self-conditioning aspect of GNN-FiLM makes it related to the[line_break_token]&gt; self-conditioned models described in "Feature-wise Transformations"[line_break_token]&gt; ([Feature-wise[line_break_token]&gt; transformations](<a href="https://distill.pub/2018/feature-wise-transformations/))" target="_blank" rel="nofollow">https://distill.pub/2018/feature-wise-transformations/))</a>[line_break_token]&gt; - for example, see the "Image Recognition" section[line_break_token]&gt; (Squeeze-and-Excitation Networks and Highway Networks) and the[line_break_token]&gt; "Natural Language Processing" section (LSTMs, gated linear units, and[line_break_token]&gt; gated-attention reader).	Reply	O	0
Do the authors see a connection with such[line_break_token]&gt; models?	Reply	O	0
If so, it would be interesting to hear these works discussed[line_break_token]&gt; (in the rebuttal and paper) and the exact connection described.	Reply	O	0
[line_break_token][line_break_token]Yes, GNN-FiLM clearly fits into this general (fairly large) class of self-conditioned works, though it is unclear what direct conclusions to draw from this.	Reply	B-Reply	5
Self-conditioning is clearly a substantial trend at the moment (primarily in the form of attention mechanism), often used as step towards multi-step reasoning (in which results on layer are used to determine computation at layer).	Reply	I-Reply	5
[line_break_token]While a general connection to feature-wise examples of this exists, it does not seem clear how to exploit this for deeper understanding or better results at this time.	Reply	I-Reply	5

This is an interesting and important paper, it emphasizes and analyzes how policy gradient methods modify their objective functions and how this leads to training differences (and often errors w.r.t.	Review	O	0
the true objective).	Review	O	0
I have some minor comments on terminology used that I would like to see properly defined within the paper, but otherwise believe this should be accepted for its useful insights.	Review	O	0
 [line_break_token][line_break_token]Assorted Comments:[line_break_token]+ Maybe I simply have a difference of opinion or have misunderstood, but I am hesitant to agree that the work is comparing the surrogate *reward* function, but rather the surrogate objective.	Review	O	0
You'll notice that in the TRPO paper, it is called a surrogate objective not a surrogate reward: <a href="https://arxiv.org/pdf/1502.05477.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1502.05477.pdf</a> .	Review	O	0
[line_break_token]+ I think better specification of what exactly is being plotted (pointing to an equation) or defining very concretely what is a surrogate reward or true reward (which I suspect is the objective) will make this paper much clearer.	Review	O	0
[line_break_token]+ In fact, it was a bit unclear whether the comparisons were of the sampled/observed reward function R(s,a) (provided by the environment and sampling regime) or the objective function often the advantage A(s,a) (or the surrogate objective, GAE, etc.)	Review	O	0
I assume it should be the latter, but the wording of the paper makes this a bit unclear.	Review	B-Review	2
I suggest discussing things in terms of objectives not rewards -- unless in fact the paper does approximate reward functions in which case this should be specified in much more detail.	Review	I-Review	2
 [line_break_token]+ Also, in a lot of places it seems like there's a mixup between rewards and returns.	Review	O	0
I think typically in the literature reward = r_t and return = V_t (sum of reward).	Review	B-Review	3
Perhaps, in places the paper truly speaks of rewards, but from the context it seems as though it mainly refers to returns.	Review	I-Review	3
Examples: " Evidently (since the agent attains a high reward) these estimates are sufficient to consistently improve reward" " This is in spite of the fact that our agents continually improve throughout training, and attain nowhere near the maximum reward possible on each task"[line_break_token] 	Review	O	0
hank you for your feedback, and we are happy that you enjoyed the paper.	Reply	O	0
[line_break_token][line_break_token]Surrogate objectives/‚ÄùSurrogate rewards‚Äù terminology: we indeed refer to the surrogate objective when we refer to the surrogate reward --- we have corrected this in the revision by replacing all instances of surrogate reward with surrogate objective.	Reply	O	0
The terminology of ‚Äúsurrogate reward‚Äù simply refers to the fact that instead of optimizing over the true rewards, agents optimize over a surrogate function.	Reply	B-Reply	1
To address your point of concretely defining the surrogate objective, we have placed a reference in the main text to the surrogate objective‚Äôs definition (which can be found in the Appendix).	Reply	I-Reply	1
[line_break_token][line_break_token]With respect to our experiments/comparisons, our experiments use the surrogate objective or the true reward information depending on the section.	Reply	I-Reply	2
We measure steps optimizing the surrogate objective in our gradient estimation quality experiments, and plot both the true reward and the surrogate objective in our landscape experiments.	Reply	I-Reply	2
[line_break_token][line_break_token]We agree that it would be an interesting line of work to investigate how the misalignment of the surrogate reward impacts value learning.	Reply	I-Reply	3

This paper studies how to extract/select suitable training data from comparable ‚Äîrather than parallel‚Äî corpora.	Review	O	0
The idea sounds reasonable.	Review	O	0
[line_break_token][line_break_token]My major concern is about the evaluation: it didn't compare with any existing work.	Review	B-Review	1
Actually there quite a few papers  on mining parallel sentences from comparable corpora such as Wikipedia, as shown below.	Review	I-Review	1
Seems the authors are not aware of those works and didn't review and compare with them.	Review	I-Review	1
Without such comparisons, it is difficult to judge the effectiveness of the proposed method and the quality of this work.	Review	I-Review	1
[line_break_token][1] Finding similar sentences across multiple languages in Wikipedia, Proceedings of the Workshop on NEW TEXT Wikis and blogs and other dynamic text sources.	Review	O	0
2006.	Review	O	0
[line_break_token][2] Method for building sentence-aligned corpus from wikipedia, 2008 AAAI Workshop on Wikipedia and Artificial Intelligence (WikiAI08).	Review	O	0
2008.	Review	O	0
[line_break_token][3] Extracting parallel sentences from comparable corpora using document-level alignment, Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics.	Review	O	0
Association for Computational Linguistics, 2010.	Review	O	0
[line_break_token][4] "Improving machine translation performance by exploiting non-parallel corpora."	Review	O	0
Computational Linguistics2006.	Review	O	0
[line_break_token][5] <a href="https://www.aclweb.org/anthology/W04-3208.pdf" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/W04-3208.pdf</a>[line_break_token][6] <a href="https://openreview.net/pdf?id=ryza73R9tQ" target="_blank" rel="nofollow">https://openreview.net/pdf?id=ryza73R9tQ</a>[line_break_token][line_break_token]Minor issues:[line_break_token][tab_token]1. "	Review	O	0
For each language pair, a shared byte-pair encoding (BPE) (Sennrich et al.,	Review	B-Review	2
2016) of 100k merge operations is applied."	Review	I-Review	2
Most papers on neural machine translation don't use such a large BPE size, which is likely to lead to better performance.	Review	I-Review	2
It would be better to use the same setting as previous work for fair comparisons.	Review	I-Review	2
[line_break_token][line_break_token][tab_token]2. "	Review	O	0
In the case of SS-NMT, both tasks ‚Äîdata extraction and learning NMT‚Äî enable and enhance each other, such that this mutual supervision leads to a self-induced curriculum, which is the subject to our analysis."	Review	B-Review	3
Similar idea, mutual boosting between data selection and model training, has been explored in the following paper, although not for machine translation.	Review	I-Review	3
What's the difference between these two papers?	Review	I-Review	3
[line_break_token]Learning to Teach, ICLR 2018.	Review	O	0
ear Reviewer,[line_break_token][line_break_token]thank you very much for your valuable comments.	Reply	O	0
Let us address first your main concern regarding the evaluation:[line_break_token][line_break_token]We are aware of the wide range of prior research that has been done in the field of parallel data mining (e.g. on Wikipedia).	Reply	O	0
However, the SS-NMT method we analyze in this paper does not intend to be a parallel data mining approach.	Reply	B-Reply	1
Instead, it is a data selection method that depends on the models state, and thus may also select non-parallel sentences (i.e. similar pairs) if they are useful for the system.	Reply	I-Reply	1
In this study, we analyze which kind of sentences are selected at different stages during training and we see, for example, that at the beginning of training non-parallel sentences can still be useful for learning.	Reply	I-Reply	1
[line_break_token]Nevertheless, we see the point that SS-NMT can be viewed as a data mining approach in itself.	Reply	I-Reply	1
In order to capture this, we would add a section to the "Related Work" section to address this.	Reply	I-Reply	1
[line_break_token][line_break_token]As for a direct comparison of a data selection method on Wikipedia, we have recently performed experiments on the Wikimatrix corpus in en-{fr, de, es} [1], where a similar extraction method was used.	Reply	I-Reply	1
We would be happy to add this experiment to this paper to compare the Wikimatrix approach to the SS-NMT approach.	Reply	I-Reply	1
Let us report the BLEU scores we get from this experiment, where we trained a supervised NMT system on the corresponding Wikimatrix corpora:[line_break_token][line_break_token]L1-L2        Wikimatrix        SS-NMT[line_break_token]en-fr        33.50        29.48[line_break_token]fr-en        30.12        27.69[line_break_token]en-de        13.22        14.40[line_break_token]de-en        12.17        18.06[line_break_token]en-es        29.60        28.57[line_break_token]es-en        26.63        26.42[line_break_token][line_break_token]Here, Wikimatrx outperformed SS-NMT for en-fr, while SS-NMT is stronger in en-de, while the difference between the two methods is rather small for en-es.	Reply	I-Reply	1
[line_break_token][line_break_token][1] Schwenk et al.	Reply	O	0
2019 "WikiMatrix: Mining 135M Parallel Sentences in 1620 Language Pairs from Wikipedia" <a href="https://arxiv.org/pdf/1907.05791.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1907.05791.pdf</a>[line_break_token][line_break_token]Now to address your minor concerns:[line_break_token][line_break_token]1.)	Reply	O	0
It is true that we use a rather large BPE size.	Reply	B-Reply	2
However, it is the BPE value that was reported in the original SS-NMT paper, which is why we kept it for comparison.	Reply	I-Reply	2
Nevertheless, you are right that BPE size is an interesting value for SS-NMT.	Reply	I-Reply	2
High-resourced supervised NMT tends to performs better with larger BPE sizes, but SS-NMT also depends heavily on homographs during the beginning of training.	Reply	I-Reply	2
Having a smaller BPE size can lead to more tokens being shared between two languages (taken that they are not distant languages, as is the case here for en-{fr, de, es}).	Reply	I-Reply	2
If this decreased BPE size would then lead to a better initialization of SS-NMT and thus improved translation performance, would be something to investigate in future research.	Reply	I-Reply	2
[line_break_token][line_break_token]2.)	Reply	O	0
Thank you for bringing this paper to our attention, which we would like to add to the "Related Work" section.	Reply	B-Reply	3
The main difference between the idea in "Learning to Teach" (LTT) and the SS-NMT approach is that LTT uses two separate models, a "teacher" and a "learner", which in a reinforcement setting mutually boost each other.	Reply	I-Reply	3
However, in SS-NMT the "teacher" and the "learner" are the same model, and the data selection depends on the model state itself.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Best regards,[line_break_token][line_break_token]The Author	Reply	O	0

This paper considered a Q-learning algorithm with UCB exploration policy for infinite-horizon MDP, and derived the sample complexity of exploration bound.	Review	O	0
The bound was shown to improve the existing results and matched the lower bound up to some log factors.	Review	O	0
The problem considered is interesting and challenging.	Review	O	0
However, I have a few major concerns.	Review	O	0
[line_break_token][line_break_token]1.	Review	B-Review	3
Assumptions: The Condition 2 is on the term which is the i-th largest item of the gap (the difference between the value function and the Q function fo the optimal policy).	Review	O	0
How to verify this condition in practice?	Review	B-Review	1
Do you need this condition for all?	Review	I-Review	1
Does this condition depend on the choice of length?	Review	I-Review	1
The conditions are listed without any discussions.	Review	I-Review	1
 [line_break_token][line_break_token]2.	Review	I-Review	3
Algorithm: The Algorithm depends on the choice of the parameter.	Review	O	0
How to choose in practice?	Review	B-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	3
Writing: This paper is not well written.	Review	O	0
There are many typos and grammar errors.	Review	B-Review	3
In addition, the key components Sections 3.3 and 3.4 are very hard to follow.	Review	I-Review	3
For instance, in Section 3.3, the authors first introduced Condition 1 and then Condition 2, and then claimed that Condition 2 implied Condition 1.	Review	I-Review	3
Similarly, in Section 3.4, Lemma 1 was introduced before Lemma 2.	Review	I-Review	3
Then the authors claimed that Lemma 2 implies Lemma 1.	Review	I-Review	3
If would be easier to follow if the authors only introduced the latter result, and then discuss the former result as a remark.	Review	I-Review	3
 [line_break_token][line_break_token]~~~~~~~~~~~~~~~~~~~~~~[line_break_token]After rebuttal: Thanks the authors for addressing my questions.	Review	O	0
My first two major concerns have been nicely addressed.	Review	O	0
Therefore, I would like to increase my rating to 6.	Review	O	0
[line_break_token]	Review	O	0
e thank anonymous reviewer 1 for the review.	Reply	O	0
[line_break_token][line_break_token]Condition 2 is a sufficient condition for near-optimal reward.	Reply	B-Reply	1
Lemma 1 proved that the number of steps violating condition 2 is bounded.	Reply	I-Reply	1
Please note that our algorithm achieves finite sample complexity of exploration in any MDPs, regardless of the suboptimality gap.	Reply	I-Reply	1
[line_break_token][line_break_token]Once the desired performance of our algorithm (namely, epsilon) is determined, can be chosen as	Reply	I-Reply	2

This paper gives an alternative to best-first search ("BFS"), plus heuristics, planning of molecules synthesis.	Review	O	0
It does so by training a policy network on ECFP4 (string encoding) representations of molecules, to predict which (sub)molecule to apply, with rewards +1 when the molecule to synthetize is complete, -1 if this branch of applications is complete and the synthesis failed, 0 otherwise.	Review	O	0
As far as I understood, it is trained in _retro_synthesis (decompose the molecule).	Review	O	0
This policy network is coupled to a search method (BFS of MCTS) both to reduce the branching factor, and to aggressively prune the validation of chemical rules (graph isomorphism).	Review	O	0
[line_break_token][line_break_token]The details about the policy model are almost inexistant.	Review	B-Review	1
The run-time of MCTS seems more than twice longer than that of BFS, so, baring an explanation, it feels like those should be compared in wall clock time.	Review	I-Review	2
The "random" test set selection may be problematic to ensure that the whole model is working properly: you may want to test in generalization, on end-result (==start in retrosynthesis) molecules that are unknown to the policy network.	Review	I-Review	2
[line_break_token][line_break_token]"essentially the complete published knowledge of chemistry":[line_break_token]1) Paywall :([line_break_token]2) maybe you are talking about a specific subset of organic chemistry?	Review	I-Review	3
Even then, I doubt this includes all metabolic pathways and/or protein foldings.	Review	I-Review	3
[line_break_token][line_break_token]The rest of the paper seems reasonable.	Review	O	0
[line_break_token] [line_break_token]This paper seems good enough for a workshop at ICLR, and it could spawn interesting discussions.	Review	O	0
Thanks for your review and your comments!	Reply	O	0
[line_break_token]As your concerns are in line with the other reviewer, we hope that you do not mind that we will keep this reply short.	Reply	O	0
Please have a look at our other reply as well.	Reply	O	0
[line_break_token][line_break_token]We have provided more details about the policy network in the text, and highlighted our previous publication, where the pure policy net is described in all details [Segler, Waller, Chem.	Reply	B-Reply	1
Eur.	Reply	I-Reply	1
J, (2017) DOI: 10.1002/chem.201605499 ].	Reply	I-Reply	1
In short, the molecules get encoded as ECFP4 fingerprints, which are then fed into a 5 layer Highway network, which in turn predicts the probability of the graph transformations.	Reply	I-Reply	1
[line_break_token][line_break_token]We have also adapted the description of the training data in the manuscript.	Reply	I-Reply	3
Our training data are 5.5 million published organic (and many inorganic and organometallic) reactions carried out in synthetic chemistry labs, taken from the Reaxys database.	Reply	I-Reply	3
It does not contain metabolic pathways.	Reply	I-Reply	3
[line_break_token][line_break_token]In the upcoming full paper we are investigating in detail where MCTS and BFS differ in performance.	Reply	I-Reply	2
Initial empirical evidence suggests that for more complex molecules (with a much larger tree), MCTS finds solutions more often.	Reply	I-Reply	2
Our random test set consists of molecules that have not been described in the literature before ‚Äì they were generated by sampling from a charRNN [1] trained on drug-like molecules.	Reply	I-Reply	2
Probably the best way for evaluation would be a time-split approach: Train only on data published before year X, then evaluate on data published after year X.[line_break_token][line_break_token]We are also looking forward to discussions at ICLR, as there are several papers in both the main and the workshop track that address some of our remaining issues!	Reply	O	0
[line_break_token][line_break_token][1] A. Graves, <a href="https://arxiv.org/abs/1308.0850" target="_blank" rel="nofollow">https://arxiv.org/abs/1308.0850</a>	Reply	O	0

Summary:[line_break_token][line_break_token]The paper proposes a novel LSTM architecture that adds several gating mechanism that gates the hidden state and inputs in between the LSTM update.	Review	O	0
The proposed model shows superior performance on smallish datasets including PTB,  Enwick8 and NWC.	Review	O	0
[line_break_token][line_break_token]Comments on the paper:[line_break_token][line_break_token]1.	Review	O	0
The paper proposes an interesting architecture and it seems to show significant improvement in terms of performance for some language datasets.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
The paper is very well written, the motivation and formulation is clear.	Review	O	0
There are many analysis to understand the model (the strength and weaknesses).	Review	O	0
[line_break_token][line_break_token]3.. One thing is that since this could take into account more context,  it seems that this model could potentially generate language / tokens with longer time dependencies.	Review	O	0
I wonder if the authors have performed any experiments on this and if they have seen any improvements on that front.	Review	B-Review	1
[line_break_token][line_break_token]4.	Review	O	0
Also, I am curious about the generalization ability of the model.	Review	B-Review	1
Could the authors train the model on shorter sequences and test for generation with longer sequences and see how this compares with baseline models.	Review	I-Review	1
[line_break_token][line_break_token]5.	Review	O	0
The model seems to be related to Adaptive Computation Time (ACT) from Gaves et al.	Review	B-Review	3
it would be nice to compare to the ACT.	Review	I-Review	3
[line_break_token][line_break_token]6.	Review	O	0
Another slight improvement in writing could be to hightlight the intuition (conclusion in page 8) at the beginning of the paper, this could help in better understanding the motivation of the paper.	Review	B-Review	4
[line_break_token][line_break_token][line_break_token]Minor comments on the paper,[line_break_token][line_break_token]1.	Review	O	0
The link and the self-citations on page 4 are does not seem to be valid links and citations.	Review	B-Review	5
[line_break_token][line_break_token]Overall, a well-written paper, extensive analysis and good experimental result.	Review	O	0
e thank Reviewer #2 for their comments.	Reply	O	0
[line_break_token][line_break_token]&gt; 3.	Reply	O	0
One thing is that since this could take into account more[line_break_token]&gt;    context, it seems that this model could potentially generate[line_break_token]&gt;    language / tokens with longer time dependencies.	Reply	O	0
I wonder if the[line_break_token]&gt;    authors have performed any experiments on this and if they have[line_break_token]&gt;    seen any improvements on that front.	Reply	O	0
[line_break_token]&gt;[line_break_token]&gt; 4.	Reply	O	0
Also, I am curious about the generalization ability of the model.	Reply	O	0
[line_break_token]&gt;    Could the authors train the model on shorter sequences and test[line_break_token]&gt;    for generation with longer sequences and see how this compares[line_break_token]&gt;    with baseline models.	Reply	O	0
[line_break_token][line_break_token]The only relevant bit in the paper is this: "Hypothesis: the benefit[line_break_token]is in handling long-range dependencies better.	Reply	B-Reply	1
Experiments in the[line_break_token]episodic setting (i.e. sentence-level language modelling) exhibited[line_break_token]the same gap as the non-episodic ones."	Reply	I-Reply	1
[line_break_token][line_break_token]Clearly, this does not exactly rule out the possibility of long-range[line_break_token]vs short-range being a factor, but at the same time it sounds somewhat[line_break_token]unlikely to observe improvements of the same magnitude in per-sentence[line_break_token]language modelling.	Reply	I-Reply	1
[line_break_token][line_break_token]Evaluating generated text can be rather subjective though, so we[line_break_token]refrained from that.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; 5.	Reply	O	0
The model seems to be related to Adaptive Computation Time (ACT)[line_break_token]&gt;    from Graves et al.	Reply	O	0
it would be nice to compare to the ACT.	Reply	O	0
[line_break_token][line_break_token]We agree that ACT could be related.	Reply	B-Reply	3
The main difference is that the[line_break_token]mogrifier in its current version performs a fixed number of processing[line_break_token]steps.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; 6.	Reply	O	0
Another slight improvement in writing could be to hightlight the[line_break_token]&gt;    intuition (conclusion in page 8) at the beginning of the paper,[line_break_token]&gt;    this could help in better understanding the motivation of the[line_break_token]&gt;    paper.	Reply	O	0
[line_break_token][line_break_token]Thank you for the suggestion.	Reply	B-Reply	4
We'll consider this.	Reply	I-Reply	4

[Overview][line_break_token][line_break_token]In this paper, the authors proposed a new format of representation called scene programs, to describe the visual scenes.	Review	O	0
To extract the scene programs from scenes, the authors exploited the off-the-shelf object detection and segmentations model, mask r-cnn to extract all objects and the corresponding attributes from the images, and then detect groups for those objects, which are then used to generate the programs which matches the input scenes.	Review	O	0
The experiments are performed on a synthetics datasets which consists of multiple shapes with different attributes.	Review	O	0
The experiments shows that the proposed model can infer more accurate programs from the scenes, and those generated programs can be used to recover the input scenes more accurately.	Review	O	0
Besides, the authors also showed that the generated scene programs can be used for image editing and making visual analogy.	Review	O	0
[line_break_token][line_break_token][Strengthes][line_break_token][line_break_token]1.	Review	O	0
The authors proposed a new representation, called scene programs, to describe the visual scenes with some textual program.	Review	O	0
This is a new scene representation, which could be potentially used in various scenarios, such as the image synthesis in graphics.	Review	O	0
[line_break_token][line_break_token]2.	Review	B-Review	1
The authors proposed a hierarchical method to model the structures in scenes.	Review	O	0
Specifically, the objects in a scene are first extracted and then grouped into multiple clusters, which will be used to guide the scene program synthesis.	Review	O	0
[line_break_token][line_break_token]3.	Review	O	0
The experimental results demonstrate the effectiveness of the proposed method both qualitatively and quantitatively.	Review	O	0
The authors also showed the the programs generated  can be sued for image editing and cross-modality matching.	Review	O	0
[line_break_token][line_break_token][Weaknesses][line_break_token][line_break_token]1.	Review	O	0
It is a bit unfair to compare the proposed method with the two baseline methods listed in Table 2.	Review	B-Review	1
The authors used a pre-trained mask-rcnn to detect all objects and predict the attributes for all objects.	Review	I-Review	1
However, the counterpart methods have no access to this supervision.	Review	I-Review	1
Even in this case, CNN-LSTM seems achieve comparable performance on the first three metrics.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	1
The advantage of scene program compared with scene graph (Johnson et al) are not clear to me.	Review	I-Review	2
Scene graph is also a symbolic representation for images.	Review	I-Review	2
Also, for all the tasks mentioned in this paper, such as image editing and visual analogy, scene graph can probably also complete well.	Review	I-Review	2
The authors should comment about the specific advantages of scene program in comparison with scene graph.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
All the images shown in the paper seems arranged uniformly, which I think contains some bias to the proposed grouping strategy.	Review	B-Review	4
I would like to see more diverse configurations of the foreground objects.	Review	I-Review	4
It would be good to see if the proposed model can describe more complicated scenes.	Review	I-Review	4
[line_break_token][line_break_token][Summary][line_break_token][line_break_token]This paper proposed a novel scene representations, called scene program.	Review	O	0
To extract the scene program, the authors proposed a hieratchical inference method.	Review	O	0
The resulting scene programs based on the proposed model outperforms several baseline models quantitatively.	Review	O	0
The authors also showed the proposed scene program is suitable for image editing and visual analogy making.	Review	O	0
However, as pointed above, there are some unclear points to me, especially the advantages of scene program compared with scene graph, and the representation power of scene program for complicated scenes.	Review	B-Review	5
Thank you for your thoughtful review.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Comparing with baseline methods [line_break_token][line_break_token]We agree on the importance of a fair comparison.	Reply	O	0
We‚Äôd like to clarify that[line_break_token]1) The derender-LSTM baseline requires the same supervision as ours.	Reply	O	0
[line_break_token]2) We acknowledge the fact that our method requires more supervision than the CNN-LSTM baseline method, and will revise the paper to clearly state that.	Reply	O	0
Note the situation is different when we consider generalization to data where program supervision is hard to obtain (e.g. real images).	Reply	B-Reply	1
Because our program synthesizer works on abstract object attribute space, it does not require any fine-tuning to work on real images, where the end-to-end CNN-LSTM approach would require (image, program) pairs.	Reply	I-Reply	1
Disentangling vision recognition and program synthesis is a key to our model‚Äôs success on real images (Fig.	Reply	I-Reply	1
7).	Reply	I-Reply	1
[line_break_token][line_break_token]Our method achieves higher test accuracy and better generalization performance than both baseline, and more importantly, it generalizes better to real images.	Reply	I-Reply	1
As synthetic data can be easily obtained, we believe that the comparison in Table 2 is fairly established.	Reply	I-Reply	1
These results and the experiments on real images demonstrate the significant advantage of our method.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Scene graphs [line_break_token][line_break_token]We thank the reviewer for bringing up scene graphs, which is another important high-level representation of scenes.	Reply	O	0
Here we would like to emphasize that the roles of scene graphs and the proposed scene programs are complementary: scene graphs focus on the pairwise relationships, e.g. an object can be on, in, or under another object; in contrast, scene programs focus on the higher-order, program-like regularity among multiple objects (e.g., repetition).	Reply	B-Reply	2
[line_break_token][line_break_token]Compared with scene graphs, scene programs (i) explicitly capture these regularities, modeling correlations among multiple objects; and (ii) are more efficient in terms of description length.	Reply	I-Reply	2
For tasks such as editing structured images, scene programs are a more suitable representation, because editing can be performed on the program space for higher efficiency, as displayed in Fig.	Reply	I-Reply	2
6.	Reply	I-Reply	2
With scene graphs, we would have to edit each object one by one.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Scene complexity [line_break_token][line_break_token]In our main experiment, we place objects on a grid and then jitter their positions and orientations.	Reply	O	0
Results on these data suggest that scene programs describe these structured images well.	Reply	B-Reply	3
We agree with reviewers on the importance of handling more complex data.	Reply	I-Reply	3
In the revision by Nov. 26, we will add results on scenes where objects are placed at random.	Reply	I-Reply	3
[line_break_token][line_break_token]Please don‚Äôt hesitate to let us know for any additional comments on the paper or on the planned changes.	Reply	I-Reply	3

The paper provides a comprehensive study on the two-tower Transformer models in terms of the impact of its pre-training tasks on large-scale retrieval applications.	Review	O	0
The studies here show that, pre-training with Inverse Cloze Task (ICT) the two-tower Transformer models significantly outperform the widely used BM-25 algorithm for large-scale information retrieval.	Review	O	0
The authors also propose two novel pre-training settings which also show improvement over the baseline BM-25.	Review	O	0
In addition, the authors empirically demonstrate that the token-level masked-LM model used by BERT is not a good choice as pre-training task for the two-tower Transformer when deployed for large-scale information retrieval applications.	Review	O	0
[line_break_token][line_break_token]The paper is well written and easy to follow.	Review	O	0
The Ablation Study of the paper also provides useful insights about the impact of different pre-training schemas on large-scale information retrieval tasks.	Review	O	0
I think the studies here will benefit the communities where large-scale information retrieval is required such as open-domain question answering.	Review	O	0
[line_break_token][line_break_token]The main limitation to me is that, the two novel pre-training tasks proposed in this paper are specific for Wikipedia and they are less effective than the ICT strategy (as shown in Table 5).	Review	B-Review	1
[line_break_token][line_break_token]I hope the authors will release the source codes to the community.	Review	I-Review	2
[line_break_token]	Review	O	0
e thank the reviewer for the comments.	Reply	O	0
[line_break_token][line_break_token]The major contribution of this work is to provide a first comprehensive study of different sentence-level pre-training tasks for the two-tower transformer-based retrieval models.	Reply	B-Reply	1
We believe this paper provides a set of standard baselines that can be helpful for further explorations in the community.	Reply	I-Reply	1
Indeed one of our major findings is that ICT is a very effective sentence-level pre-training task, whereas the masked-LM only provides marginal improvements.	Reply	I-Reply	1
[line_break_token][line_break_token]In addition, for the low-data regime of Table 5, we see a 1.5% absolute improvement of R@100 when comparing ICT+BFS+WLP to ICT.	Reply	I-Reply	1
This reflects that, when there‚Äôs no sufficient downstream training data,  more globally pre-training tasks is beneficial as it encodes multi-hop reasoning priors such as different passages within the same article (BFS) or even going beyond different articles linked by the same entities (WLP).	Reply	I-Reply	1
We will add a discussion in the final version.	Reply	I-Reply	1
[line_break_token][line_break_token]We are working to release our experiment code, pre-trained two-tower transformer models, and downstream evaluation data benchmark.	Reply	I-Reply	2

The paper proposes yet another variant of the celebrated Dropout algorithm.	Review	O	0
Specifically, the proposed method attempts to address the obvious drawbacks of Dropout: (i) the need to heuristically select the Dropout rate; and (ii) the universality of this selection across a layer.	Review	B-Review	1
[line_break_token][line_break_token]As the authors have admitted in the paper (Sec.	Review	O	0
1.2), there is a variety of methods already addressing the same problem.	Review	O	0
They argue that contrary to some of these methods "jumpout does not rely on additional trained models: it adjusts the dropout rate solely based on the ReLU activation patterns.	Review	O	0
Moreover, jumpout introduces negligible computation and memory overhead relative to the original dropout methods, and can be easily incorporated into existing model architectures."	Review	O	0
[line_break_token][line_break_token]However, this is argument is certainly untrue and rather misleading.	Review	B-Review	2
The works of Kingma et al. (	Review	I-Review	2
2015) and Molchanov et al. (	Review	I-Review	2
2017), that the authors cite, does not introduce additional trained models.	Review	I-Review	2
In addition, there is additional related work that the authors do not cite, but ought to: [line_break_token][line_break_token][1] Yarin Gal, Jiri Hron, Alex Kendall, "Concrete Dropout," Proc.	Review	I-Review	2
NIPS 2017.	Review	I-Review	2
[line_break_token][2] Yingzhen Li, Yarin Gal, "Dropout Inference in Bayesian Neural Networks with Alpha-divergences," Proc ICML 2017.	Review	I-Review	2
[line_break_token][3] Harris Partaourides, Sotirios Chatzis, ‚ÄúDeep Network Regularization via Bayesian Inference of Synaptic Connectivity,‚Äù J. Kim et al. (	Review	I-Review	2
Eds.):	Review	I-Review	2
PAKDD 2017, Part I, LNAI 10234, pp.	Review	I-Review	2
30‚Äì41, 2017.	Review	I-Review	2
[line_break_token][line_break_token]These methods also address a similar problem, without introducing extra networks or imposing extra costs art inference time.	Review	I-Review	2
Thus, citing them, as well as COMPARING to them, is a necessity for this paper to be convincing.	Review	I-Review	2
[line_break_token][line_break_token]These crucial shortcoming aside, there are various theoretical claims in this paper that are not sufficiently substantiated.	Review	O	0
To begin with, the arguments used in the last paragraph of page 4 seem at least speculative; then,  the authors proceed to propose a solution to the alleged problem in the beginning of page 5.	Review	O	0
They suggest sampling from a truncated Gaussian, but they do not elaborate on why this selection solves the problem; they limit themselves to noting that other selections, such as the Beta distribution, may also be considered in the future.	Review	B-Review	3
We must also underline that [3] have suggested exactly that; sampling from a Beta.	Review	I-Review	3
[line_break_token][line_break_token]Finally, the last two modifications the authors propose seem reasonable, yet they are extremely heuristic.	Review	O	0
No one knows (which can be guaranteed through theoretical proofs or solid experimental evidence) that without these the method would not work.	Review	B-Review	4
In addition, previous papers, e.g. [1-3] achieve similar goals in a principled fashion (ie by inferring proper posterior densities); without experimental comparisons, nobody knows which paradigm is best to adopt.	Review	I-Review	4
[line_break_token][line_break_token]	Review	O	0
Thanks for your comments!	Reply	O	0
We added the ablation study to demonstrate the effectiveness of every individual modification.	Reply	O	0
We further emphasize that jumpout is not a variational dropout approach, and can scale to very large networks.	Reply	O	0
We also added a comparison with concrete dropout[1] as suggested (Table 3 in Appendix).	Reply	O	0
[line_break_token][line_break_token]Q1: Overview of the paper: "Specifically, the proposed method attempts to address the obvious drawbacks of Dropout: (i) the need to heuristically select the Dropout rate; and (ii) the universality of this selection across a layer."	Reply	O	0
[line_break_token][line_break_token]R1: "(i) the need to heuristically select the Dropout rate" is merely one observation of the paper and 1/3 of the drawbacks we aim to address, and we never attempt to address "(ii) the universality of this selection across a layer", i.e., for all nodes on a layer, jumpout applies the same drop rate.	Reply	O	0
The primary purpose of jumpout is to improve the original dropout performance without introducing extra computational costs.	Reply	B-Reply	1
The truncated Gaussian distribution aims to improve the dropout performance based on the linear model geometry of ReLU networks.	Reply	I-Reply	1
The change of dropout rate based on ReLU pattern tries to address the dropout rate selection problem.	Reply	I-Reply	1
The change of rescaling factor resolves the disharmony between dropout and batchnorm, so for a network with both kinds of layers, the performance gets boosted.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: Comparison to [1],[2] and [3].[line_break_token][line_break_token]R2: We note that jumpout is NOT a variational approach of dropout, which does not require Bayesian training or inference.	Reply	O	0
Jumpout does not introduce extra inference cost, and it also has similar training costs as the original dropout.	Reply	B-Reply	2
Jumpout can therefore work on modern networks with deep and wide structures, whereas the variational approaches [2] and [3] do not scale to the networks we include in the paper.	Reply	I-Reply	2
For [1], we add comparison experiments and show that jumpout significantly outperforms [1]. [line_break_token][1],[2] and [3] tries to address the problem similar to our observation 2, namely, selection of the dropout rate.	Reply	I-Reply	2
Jumpout has 2 other major changes: we choose to impose a truncated Gaussian distribution on the dropout rate based on the linear model geometry of the ReLU network, and we change the rescaling factor to account for the disharmony between dropout and batchnorm.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: They suggest sampling from a truncated Gaussian, but they do not elaborate on why this selection solves the problem.	Reply	O	0
[line_break_token][line_break_token]R3:The truncated Gaussian distribution is a natural choice based on the intuition based on the linear model geometry of ReLU networks.	Reply	O	0
Again, jumpout is not a variational approach, and the truncated Gaussian distribution is not aimed to solve the dropout rate selection problem.	Reply	B-Reply	3
The truncated Gaussian is applied because the original dropout has the uniform preference for both nearby and faraway linear models, while in principle, close linear models should be preferred.	Reply	I-Reply	3
Also, for [3], the beta distribution is selected with no clear reason at all.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4: No one knows without these the method would not work.	Reply	O	0
[line_break_token][line_break_token]R4: We add thorough ablation studies on all combinations of the 3 modifications to show that 1) they all have positive impacts on the performance, and 2) 3 modifications can work together to get the best performance.	Reply	O	0

This work proposes a hybrid model for robot visual navigation in synthetic indoor environments, specifically a combination of a  high-level planning scheme (model-based) with a low-level behavior based approach (model-free) .	Review	O	0
The main contribution is on the high-level based planning that is based on semantic cues from the environment, specifically the construction of a semantic prior about rooms connectivity.	Review	O	0
By using this prior the system is able to generalize to new environments simplifying an initial robot exploration phase.	Review	O	0
[line_break_token][line_break_token]The semantic prior is implemented by the construction of a graph representation that encodes room connectivity.	Review	O	0
Links between rooms (nodes) are given by Bernoulli variables which are inferred by previous experiences and an exploration phase in the current environment.	Review	O	0
 [line_break_token][line_break_token]Results are one of the weaker parts of the paper, success rates are very low, even for short planning horizons (figures 3,4,5).	Review	O	0
 Furthermore, it is not clear the real relevance of the semantic prior because relative performance with respect to baselines is not significant.	Review	O	0
In general, while a room connectivity prior can be of help, I believe is not so critical for indoor robot navigation.	Review	O	0
There are prior works on Robotics that has shown more impact using structural priors, such as, presence of corridors, doors, etc, or "object-room" spatial relations.	Review	O	0
The low success rate is even more critical if one considers that the validation is based on synthetic environments.	Review	B-Review	3
[line_break_token][line_break_token]In general the paper is easy to follow, although, there are some details missing, specially in terms of model description.	Review	I-Review	4
My main concern is that the paper is limited in technical novelty and it suffers from a lack of practical significance.	Review	I-Review	4
> For low success rate:[line_break_token]It is because this semantic navigation task itself is extremely challenging for RL.	Reply	O	0
Therefore we proposed an HRL framework, i.e., a semantic model, to improve performance of general RL methods.	Reply	B-Reply	1
[line_break_token]We emphasize that the low success rate is not training performance.	Reply	I-Reply	1
Instead, it is generalization performance on unseen environments.	Reply	I-Reply	1
Current state-of-the-art results on semantic navigation tasks still suffer from this low success rate (e.g., fig7 in <a href="https://arxiv.org/pdf/1609.05143.pdf," target="_blank" rel="nofollow">https://arxiv.org/pdf/1609.05143.pdf,</a> row 3 in table 1 in <a href="https://arxiv.org/pdf/1810.06543.pdf)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1810.06543.pdf).</a> [line_break_token]Another misunderstood point is that the ‚Äúplanning horizons‚Äù  here are steps in the ‚Äúsemantic model‚Äù, i.e., the number of rooms the agent needs to go through to reach the goal.	Reply	O	0
It is NOT the actual episode length for the agent.	Reply	B-Reply	1
We show the stats of averaged length of ground truth shortest path in Appendix F, where the avg length is 46.86.	Reply	I-Reply	1
 Note the agent has 9 available actions and the environment has strong partial observability (visual signal of different rooms are typically blocked by walls).	Reply	I-Reply	1
The task is indeed challenging.	Reply	I-Reply	1
Moreover, our goal is to improve the performance of model-free RL approaches.	Reply	I-Reply	1
So we believe the relative improvement instead of the success rate itself should be focused more on.	Reply	I-Reply	1
[line_break_token][line_break_token]> Improvement is not significant:[line_break_token]To better illustrate that our method is effective, we illustrate all the success rate in numbers in Figure.5.	Reply	O	0
In all the horizons, LEAPS agents have the best success rates overall and for all targets requiring planning computations (i.e., plan-steps > 1).	Reply	O	0
Particularly, the relative improvements are higher for targets requiring more planning (e.g., plan-steps = 3)[line_break_token]Thanks to the suggestion by Reviewer3, we utilize a better metric, Success weighted by Path Length (SPL), which considers episode length in the evaluation metric.	Reply	B-Reply	2
In SPL, success episodes with faraway targets will be assigned more credits.	Reply	I-Reply	2
We introduce SPL in Sec 6.4 and show the results in Figure 5.	Reply	I-Reply	2
In SPL, our approach overall outperforms all the baselines with significant margins.	Reply	I-Reply	2
More importantly, as more planning computations (longer horizons), the margin becomes increasingly larger.	Reply	I-Reply	2
This again indicates that LEAPS is indeed effective for those faraway targets.	Reply	I-Reply	2
[line_break_token][line_break_token]>  For synthetic dataset:[line_break_token]Sorry for the confusion.	Reply	O	0
We have updated the introduction section accordingly.	Reply	B-Reply	3
We here are refering to environments that resemble the real-world semantic properties.	Reply	I-Reply	3
The houses in House3D are designed by humans and share the same semantic regularities as the real world.	Reply	I-Reply	3

This paper attempts to improve the beta-VAE (Higgins et al, 2017) by removing the trade-off between the quality of disentanglement in the latent representation and the quality of the reconstruction.	Review	O	0
The authors suggest doing so by explicitly modelling the noise of the reconstructed image Gaussian p(x|z).	Review	O	0
The authors assume that VAEs typically model the data using a Guassian distribution with a fixed noise.	Review	B-Review	1
This, however, is not the case.	Review	I-Review	1
Since the authors are trying to address a problem that does not actually exist, I am not sure what the contributions of the paper are.	Review	I-Review	1
[line_break_token][line_break_token]Apart from the major issue outlined above, the paper also makes other errors.	Review	I-Review	2
For example, it suggests using D_KL(q(z)||p(z)) as a measure of disentanglement, with lower values being indicative of better disentanglement.	Review	I-Review	2
This, however, is incorrect, since one can have tiny D_KL by encoding all the information into a single latent z_i.	Review	I-Review	2
Such a representation would be highly entangled while still satisfying all of the conditions the authors propose for a disentangled representation.	Review	I-Review	2
[line_break_token][line_break_token]Given the points outlined above and the fact that the paper is hard to read and is excessively long, I do not believe it should be accepted.	Review	I-Review	3
We thanks the reviewer for their work.	Reply	O	0
However, we're afraid they may have misunderstood the point of our paper and didn't provide fair assessments of our contribution.	Reply	O	0
We hope our responses below and the comments of the other reviewers may help clarify the scope of our work and its significance.	Reply	O	0
[line_break_token][line_break_token]According to your suggestion that paper is too long, we amend the length of our paper from 19 pages to 10.	Reply	B-Reply	3
In order to achieve this and keeping it still comprehensive and informative, we have to weaken the discussion on noise modeling and put more emphasis on the intrinsic properties of VAE.	Reply	I-Reply	3
We hope our amendment can increase the information channel capacity between the proposed ideal and our readers and provide better and more friendly reading experience.	Reply	I-Reply	3
[line_break_token][line_break_token]A.[tab_token]We understand your first consideration that there exist some implementations under other noise assumptions including Bernoulli distribution for two-point valued data and some other more sophisticated ones with specific oriented domain knowledge.	Reply	O	0
Some of them might already enable the parameter of noise to be learned.	Reply	B-Reply	1
However, also in many implementations on real-valued data, many papers just simplified Gaussian assumption to be sigma^2 I where the sigma^2 is either assumed to be known or to be manually tuned.	Reply	I-Reply	1
In particular, the tutorial on VAE(<a href="https://arxiv.org/abs/1606.05908)," target="_blank" rel="nofollow">https://arxiv.org/abs/1606.05908),</a> which is a really respectable work and is also my first contact with VAE model, is also under this noise assumptions.	Reply	O	0
 And we personally believe that we are the first one publicly emphasizes and demonstrates on "noise modeling influences the disentanglement" though we have also shown some other benefit could be induced by noise modeling in our original paper version.	Reply	B-Reply	1
[line_break_token][line_break_token]B.[tab_token]We thank for your intuitive counterexample to our clarification on disentanglement.	Reply	O	0
 We have proved several theorems especially the information conservation theorem[e.g.	Reply	B-Reply	2
two independent Gaussian and one Gaussian cannot be the generating factor set of each other.]	Reply	I-Reply	2
in Intrinsic Dimension issue(section 3 in the latest version) to exclude this counterexample in the idealistic case and our experiment results also turn to support the instruction suggested by the theorem in the real implementation.	Reply	I-Reply	2
In order to theoretically illustrate our perspective regarding the counterexample that review proposed, more compactly and informatively, we also add an auxiliary deduction in the latter comment.	Reply	I-Reply	2
We will be grateful if the reviewer or someone else can further provide some facts and evidence from the theoretical perspective or experimental perspective to show the existence or the probability of the existence of that counterexample in the real situation.	Reply	I-Reply	2
[line_break_token][line_break_token]C.[tab_token]You also mention there might be some other theoretical errors.	Reply	O	0
We are grateful if you can list them.	Reply	B-Reply	2
We are open to the opinion and argument from the other side and believe those arguments can improve the direction of scientific research and accelerate our mission to the AI.	Reply	I-Reply	2
This will be helpful to improve our work but also good for the whole community	Reply	I-Reply	2

Comments: [line_break_token][line_break_token]"This contrasts to adversarial attacks on classifiers, where any inspection of the inputs will reveal the original bytes the adversary supplied,[line_break_token]which often have telltale noise"[line_break_token][line_break_token]Is this really true?	Review	O	0
 If it were the case, wouldn't it imply that training "against" adversarial examples should easily make a classifier robust to adversarial examples (if they all have a telltale noise)?	Review	B-Review	1
 [line_break_token][line_break_token]Pros: [line_break_token]  -The question of whether adversarial examples exist in generative models, and indeed how the definition of "adversarial example" carries over is an interesting one.	Review	O	0
 [line_break_token]  -Finding that a certain type of generative model *doesn't have* adversarial examples would be a really significant result, finding that generative models have adversarial examples would also be a worth negative result.	Review	O	0
 [line_break_token]  -The adversarial examples in figures 5 and 6 seem convincing, though they seem much more overt and noisy than the adversarial examples on MNIST shown in (Szegedy 2014).	Review	O	0
 Is this because it's actually harder to find adversarial examples in these types of generative models?	Review	B-Review	2
 [line_break_token][line_break_token]Issues: [line_break_token]  -Paper is significantly over length at 13 pages.	Review	O	0
 [line_break_token]  -The beginning of the paper should more clearly motivate its purpose.	Review	O	0
 [line_break_token]  -Paper has "generative models" in the title but as far as I can tell the whole paper is concerned with autoencoder-type models.	Review	O	0
 This is kind of annoying because if someone wanted to consider adversarial attacks on, say, autoregressive models, they might be unreasonably burdened by having to explain how they're distinct from a paper called "adversarial examples for generative models".	Review	B-Review	5
 [line_break_token]   -I think that the introduction contains too much background information - it could be tightened.	Review	O	0
 [line_break_token]	Review	B-Review	1
What you say about the telltale noise is correct -- as Goodfellow et al.	Reply	B-Reply	1
2014 show, it is possible to train a network using the adversarial examples and substantially reduce (but not eliminate) the network‚Äôs vulnerability to adversarial examples.	Reply	I-Reply	1
 Additionally, another ICLR submission this year showed a way to train a separate network to classify images as adversarial or non-adversarial with high accuracy.	Reply	O	0
 All that being said, that paragraph is one of the paragraphs that we‚Äôve removed from the new version of the paper in order to reduce the length.	Reply	O	0
 The paper is now 11 pages plus references and includes some new results.	Reply	B-Reply	3
[line_break_token][line_break_token]Since we are the first to study adversarial examples on generative models in depth, we think it is appropriate to use ‚Äúgenerative models‚Äù in the title.	Reply	I-Reply	5
The reason for focusing on VAE-like models is that in the paper we propose a plausible scenario how such a model can be used in a compression scheme, which can then be attacked by an adversary.	Reply	I-Reply	5
To the best of our knowledge, other types of generative models, such as autoregressive models, do not offer such a clear attack scenario, where adversarial examples may be used by an attacker.	Reply	I-Reply	5

[Relevance] Is this paper relevant to the ICLR audience?	Review	O	0
yes[line_break_token][line_break_token][Significance] Are the results significant?	Review	O	0
somewhat[line_break_token][line_break_token][Novelty] Are the problems or approaches novel?	Review	O	0
rather incremental[line_break_token][line_break_token][Soundness] Is the paper technically sound?	Review	O	0
yes[line_break_token][line_break_token][Evaluation] Are claims well-supported by theoretical analysis or experimental results?	Review	O	0
marginal[line_break_token][line_break_token][Clarity] Is the paper well-organized and clearly written?	Review	O	0
okay[line_break_token][line_break_token]Confidence: 2/5[line_break_token][line_break_token]Seen submission posted elsewhere: No[line_break_token][line_break_token]Detailed comments:[line_break_token][line_break_token]In this work, the authors propose an approach to the (hyper-) link prediction problem in both directed and undirected hypergraphs.	Review	O	0
The approach first applies an existing dual transformation to the hypergraph such that the link prediction problem (in the primal) becomes a node classification problem in the dual.	Review	O	0
They then use GCNs to classify the (dual) nodes.	Review	O	0
Experimentally, the proposed approach marginally outperforms existing approaches.	Review	O	0
[line_break_token][line_break_token]=== Major comments[line_break_token][line_break_token]I found the novelty of the proposed approach rather limited.	Review	O	0
The proposed approach essentially just concatenates three existing strategies (dual reformulation from Scheinerman and Ullman, GCNs from Kipf and Welling, and negative sampling which is common in many communities, e.g., Han and Chen, but many others, as well).	Review	B-Review	1
I believe the contribution for link prediction in directed hypergraphs is a more novel contribution, however, I had difficulty following that discussion.	Review	I-Review	1
[line_break_token][line_break_token]It is difficult to interpret the experimental results.	Review	I-Review	2
Tables 3 and 6 do not include a measure of variance.	Review	O	0
Thus, it is not clear if any of the results are statistically significant.	Review	B-Review	3
It is also not clear whether the ‚Äú10 trials‚Äù mentioned in the figure captions correspond to a 10-fold cross-validation scheme or something else.	Review	I-Review	4
It is unclear to me what the random feature matrix for the metabolic network is supposed to me or do.	Review	I-Review	5
It is also unclear to me why ‚Äúfake papers‚Äù are needed for the citation networks; it is clear that ‚Äúfake author lists‚Äù are needed for negative sampling, but it seems they could be attached to existing papers.	Review	I-Review	6
Similarly, it is unclear how the set of candidate edges (\mathcal{E}) was chosen.	Review	I-Review	7
[line_break_token][line_break_token]I appreciate that the authors made the code available.	Review	O	0
I did not run it, but I did have a look, and I believe it could be adapted by others without an unreasonable amount of work.	Review	O	0
[line_break_token][line_break_token]=== Minor comments[line_break_token][line_break_token]This work is very similar to the arXiv submission 1809.09401.	Review	O	0
To the best of my knowledge, though, that work has not yet been published in a peer-reviewed venue, so I do not consider it a problem that it is not cited here.	Review	B-Review	8
[line_break_token][line_break_token]According to Tables 1 and 2, iAF692 and iHN637 datasets are smaller than the other datasets except DBLP; those two are also less dense than DBLP.	Review	I-Review	9
According to Table 3, NHP-U seems noticeably better than SHC and CMM on the, while does not appear very significant in the other cases.	Review	I-Review	9
Is there some relationship between NHP‚Äôs performance and the size/density of the graph?	Review	I-Review	9
or is there some other explanation for this behavior?	Review	I-Review	9
[line_break_token][line_break_token]Related to the above point, Table 3 shows that the performance on the undirected versions for those two datasets is better than on the other two metabolic networks, while Table 6 shows the opposite for the directed versions.	Review	I-Review	10
Is there some explanation for this?	Review	I-Review	10
For example, are there qualitative differences in the size of the hypernodes?	Review	I-Review	10
[line_break_token][line_break_token]The described strategy for negative sampling seems as though it selects ‚Äúeasy‚Äù negative samples, in the sense that they are far away from observed positives; thus, they are also likely far away from any sort of decision boundary.	Review	I-Review	11
How does the performance change if more ‚Äúdifficult‚Äù (or just uniformly random) negative samples are chosen?	Review	I-Review	11
[line_break_token][line_break_token]I believe Recall@100 (or Precision@100, or , etc.)	Review	I-Review	12
is a more meaningful value to report in Tables 4 and 7, rather than the raw number of edges.	Review	I-Review	12
That is, it would be more helpful to report something so that numbers across datasets are at least somewhat comparable.	Review	I-Review	12
[line_break_token][line_break_token]=== Typos, etc.	Review	I-Review	13
[line_break_token][line_break_token]In Equation (4), the ‚Äúk‚Äù index in d_{ijk} is in {1,2}, but in the text, it is in {0,1}.[line_break_token][line_break_token]‚Äútable 2‚Äù -> ‚ÄúTable 2‚Äù, and many other similar examples throughout the paper.	Review	O	0
[line_break_token][line_break_token]‚Äúhigher-order etc.	Review	B-Review	13
‚Äù -> ‚Äúhigher-order, etc.	Review	O	0
‚Äù[line_break_token]‚ÄúGCN based‚Äù -> ‚ÄúGCN-based‚Äù, and similar in several places in the paper[line_break_token]‚Äúa incomplete‚Äù -> ‚Äúan incomplete‚Äù[line_break_token]	Review	O	0
Thanks for the review[line_break_token][line_break_token]On the novelty of our work:[line_break_token]Link prediction in undirected hypergraphs is an underexplored problem and that in directed hypergraphs is an unexplored problem.	Reply	O	0
Our main contribution is a unified framework for both the settings and our proposed solution is conceptually simple, yet effective.	Reply	B-Reply	1
We believe the problem settings are important and interesting (as noted by the other reviewers too), and that this paper will inspire further research in this direction.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token][line_break_token]On the discussion of results for directed hyperlink prediction:[line_break_token]Both NHP-D (joint) and NHP-D (sequential) perform similarly.	Reply	O	0
To appreciate the results, we have added three baselines as suggested by reviewers 2 and 3.	Reply	B-Reply	2
We request the reviewer to see below for a sample of the updated results and the paper for all updated results.	Reply	I-Reply	2
[line_break_token][line_break_token]---------------------------------------------------------------------------------------------------------------------------------[line_break_token]                         dataset[tab_token][tab_token][tab_token][tab_token]  [tab_token]iAF692[tab_token]         iHN637[tab_token]          iAF1260b          iJO1366[line_break_token]---------------------------------------------------------------------------------------------------------------------------------[line_break_token]node2vec + MLP[tab_token][tab_token][tab_token]                      255 +/- 5[tab_token]         237 +/- 5[tab_token]  838 +/- 13[tab_token]   902 +/- 11[line_break_token]---------------------------------------------------------------------------------------------------------------------------------[line_break_token]CMM + MLP    [tab_token][tab_token][tab_token]                     253 +/- 9[tab_token]        241 +/- 11[tab_token]  757 +/- 26[tab_token]   848 +/- 21[line_break_token]---------------------------------------------------------------------------------------------------------------------------------[line_break_token]GCN on star expansion + MLP[tab_token]             242 +/- 5[tab_token]        241 +/- 10[tab_token]   786 +/- 13[tab_token]   852 +/- 11[line_break_token]---------------------------------------------------------------------------------------------------------------------------------[line_break_token][line_break_token]NHP-D (sequential)[tab_token][tab_token][tab_token]             263 +/- 7[tab_token]       221 +/- 10[tab_token]  867 +/- 31[tab_token]   954 +/- 29[line_break_token][line_break_token]NHP-D (joint)[tab_token][tab_token][tab_token][tab_token]            262 +/- 8[tab_token]        236 +/- 8[tab_token]  869 +/- 13[tab_token]   944 +/- 20[line_break_token][line_break_token]---------------------------------------------------------------------------------------------------------------------------------[line_break_token][line_break_token][line_break_token][line_break_token]On variance in the results:[line_break_token]We observed variances of AUC values to be in the third decimal places (i.e., very close to zero).	Reply	O	0
We have reported variances in the number of hyperlinks recovered in all experiments.	Reply	B-Reply	3
These are much more interpretable/statistically significant.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token][line_break_token]On 10 trials:[line_break_token]We report the mean values over 10 different splits of train and test.	Reply	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]On random features:[line_break_token]The feature initialisations are random for metabolic network experiments as we do not have any available features to exploit.	Reply	O	0
We believe the neighbourhood feature aggregation of GCN causes useful node embeddings to be learnt during training.	Reply	B-Reply	5
[line_break_token]We also observe that NHP is competitive with a node2vec baseline (suggested by reviewer 3) which is a featureless approach.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token][line_break_token]On creation of fake papers:[line_break_token]In these experiments, authors correspond to nodes in the (primal) graph, while papers correspond to hyperlinks, i.e., sets of authors.	Reply	O	0
So in this context, fake papers are the same as fake author lists and hence cannot be attached to existing (true) papers.	Reply	B-Reply	6
The set of candidate edges is the set of true papers union the set of fake papers	Reply	I-Reply	6

[Update after rebuttal period][line_break_token][line_break_token]I would like to thank the authors for the detailed response and for addressing the concerns on such a tight schedule.	Review	O	0
[line_break_token][line_break_token]Overall my two concerns appear to have been right: 1.	Review	O	0
The object classification task is not really relevant to elicit the observed behavior and 2.	Review	O	0
Inhibitory neurons are not essential (at least when training with batch norm).	Review	O	0
[line_break_token][line_break_token]Do the conclusions of the paper about understanding of E/I cells in the brain still hold?	Review	O	0
I am not really sure.	Review	O	0
I would like to urge the authors to carefully assess their conclusions again in light of the new evidence and perhaps rephrase abstract, intro and discussion where necessary.	Review	O	0
[line_break_token][line_break_token]Having said that, I still like the paper and its approach.	Review	O	0
I think it provides valuable insights to the field (e.g. neuro-inspired architecture design, concerns regarding training objectives, etc.)	Review	O	0
and important steps in the right direction and could be a valuable contribution even if the original claims are not entirely substantiated.	Review	O	0
[line_break_token][line_break_token][line_break_token][Original review][line_break_token][line_break_token]This paper seeks to understand why excitatory neurons in cortex are more stimulus selective than inhibitory cells and why excitatory cells are more sparsely connected to each other.	Review	O	0
The authors train a recurrent neural network model with a number of biological constraints on CIFAR-10.	Review	O	0
These constraints include Dale's law, an unequal number of E vs. I cells and only excitatory connections between layers (areas) of the network.	Review	O	0
I would summarize the main findings as follows:[line_break_token][line_break_token]- Excitatory principal neurons are more selective and more sparsely connected to each other than local inhibitory neurons, consistent with biology[line_break_token][line_break_token]- Stimulus selectivity and performance depend only on the number of excitatory cells, but neither on the E/I ratio nor the number of I cells[line_break_token][line_break_token]- High selectivity appears to be a general property of principal cells, but does not depend on the sign of local connections, while sparse connectivity is mainly linked to the excitatory local connections[line_break_token][line_break_token][line_break_token]Strengths:[line_break_token]+ Architectural decisions are well motivated from a neuroscientific perspective[line_break_token]+ Provides a hypothesis why certain connectivity and selectivity patterns emerge in the brain by incorporating biological knowledge into neural network models trained on a specific task[line_break_token]+ Well written and clear, logic development of the arguments[line_break_token][line_break_token]Weaknesses:[line_break_token]- Unclear whether classification task is necessary to elicit the authors' observations[line_break_token]- Interneurons seem unnecessary, raising concerns about relevance of results[line_break_token]- Also trains on ImageNet, but only some results are shown; most from CIFAR[line_break_token][line_break_token][line_break_token]Overall I like the paper from the perspective of a neuroscientist, as it provides a kind of normative account of why things in the brain might look the way they do.	Review	O	0
My enthusiasm is somewhat limited, however, because I am not convinced the classification task is actually what drives the authors' observations.	Review	O	0
I am willing to increase my score and argue more strongly for the paper if the authors can address this concern, detailed in the following:[line_break_token][line_break_token]A few observations lead me to believe the classification task the networks are trained may not be important to elicit the observed behavior.	Review	O	0
[line_break_token][line_break_token]1.)	Review	O	0
The emergent properties in stimulus selectivity show up almost immediately after training starts according to Fig.	Review	O	0
5A+B. Performance, on the other hand, takes a few more epochs to pick up according to Fig.	Review	O	0
10.	Review	O	0
[line_break_token][line_break_token]2.)	Review	O	0
The connectivity preferences that emerge in Figure 5C appear at already 50 epochs where CIFAR-10 performance is at 50%.	Review	O	0
To put that into perspective, a linear SVM already achieves 40% on this task, and a one-layer multilayer perceptron with only 100 hidden neurons reaches that performance.	Review	O	0
[line_break_token][line_break_token]3.)	Review	O	0
The results of Fig.	Review	O	0
11 suggest that the number of inhibitory channels is not important.	Review	O	0
Did the authors try a stripped down version with only excitatory cells?	Review	O	0
[line_break_token][line_break_token]I suggest the authors train on CIFAR-10 with shuffled labels on the training set [Zhang et al.	Review	O	0
2016; <a href="https://arxiv.org/abs/1611.03530]." target="_blank" rel="nofollow">https://arxiv.org/abs/1611.03530].</a> Although performance on the test set would be at chance (no object recognition capabilities), it would be interesting to see whether the selectivity and connectivity properties still emerge.	Review	O	0
[line_break_token][line_break_token]Finally, (related to 3.)	Review	O	0
I wonder whether it makes sense to draw conclusions about differences between E and I cells from a model trained on a task where the number of inhibitory cells seems irrelevant.	Review	O	0
Wouldn't one need to have at least both types of neurons to be required for the task in order to draw such conclusions?	Review	O	0
[line_break_token][line_break_token][line_break_token]Minor Comments:[line_break_token][line_break_token]- I sometimes found the nomenclature of the multiple models you tried a bit confusing and hard to follow ‚Äî especially in parts of the Appendix[line_break_token][line_break_token]- The type of operations (convolution, element-wise) in equation 1, together with the meaning of nonlinearities like \sigma_c are only defined one page after, making that section a bit hard to follow.	Review	O	0
e realized that we did not include training accuracy of networks trained on randomly-labeled dataset.	Reply	O	0
We updated our manuscript (Results section and Figure 16) to include these details:[line_break_token][line_break_token]The Shuffled_L2/EI_Shuffled_L2 networks achieve on average 43.9%/24.6% accuracy on the randomly-labeled training set	Reply	O	0

This paper presents a PAC-Bayesian framework that bounds the generalization error of the learned model.	Review	O	0
While PAC-Bayesian bounds have been studied before, the focus of this paper is to study how different conditions in the network (e.g. behavior of activations) generalize from training set to the distribution.	Review	O	0
This is important since prior work have not been able to handle this issue properly and as a consequence, previous bounds are either on the networks with perturbed weights or with unrealistic assumptions on the behavior of the network for any input in the domain.	Review	B-Review	1
[line_break_token][line_break_token]I think the paper could have been written more clearly.	Review	I-Review	2
I had a hard time following the arguments in the paper.	Review	I-Review	2
For example, I had to start reading from the Appendix to understand what is going on and found the appendix more helpful than the main text.	Review	I-Review	2
Moreover, the constraints should be discussed more clearly and verified through experiments.	Review	I-Review	2
[line_break_token][line_break_token]I see Constraint 2 as a major shortcoming of the paper.	Review	I-Review	3
The promise of the paper was to avoid making assumptions on the input domain (one of the drawbacks in Neyshabur et al 2018) but the constraint 2 is on any input in the domain.	Review	I-Review	3
In my view, this makes the result less interesting.	Review	I-Review	3
[line_break_token][line_break_token]Finally, as authors mention themselves, I think conditions in Theorem F.1 (the label should be 4.1 since it is in Section 4) could be improved with more work.	Review	I-Review	4
More specifically, it seems that the condition on the pre-activation value can be improved by rebalancing using the positive homogeneity of ReLU activations.	Review	I-Review	4
[line_break_token][line_break_token]Overall, while I find the motivation and the approach interesting, I think this is not a complete piece of work and it can be improved significantly.	Review	O	0
[line_break_token][line_break_token]===========[line_break_token]Update: Authors have addressed my main concern, improved the presentation and added extra experiments that improve the quality of the paper.	Review	O	0
 I recommend accepting this paper.	Review	O	0
Hi again!	Reply	O	0
[line_break_token][line_break_token]First of all, a quick note: we updated the label of Theorem F.1 to 4.1.	Reply	B-Reply	1
Thanks for your note!	Reply	I-Reply	1
[line_break_token][line_break_token]Next, we'd like to get in touch with you again to know if we clarified your concern regarding Constraint 2. (	Reply	I-Reply	3
By the way, please let us know in case we misunderstood your concern.)	Reply	I-Reply	3
[line_break_token][line_break_token]We'd like to reiterate, like we state throughout the text of the main paper, we do not make any assumption that holds on all input datapoints.	Reply	I-Reply	4
The lack of such an assumption is the main strength/contribution of the paper.	Reply	I-Reply	4
 We'd also like to point out that the mathematical statement of Constraint 2 and the text following it, and the mathematical statements of Theorem 3.1 and 4.1, all reflect this fact!	Reply	I-Reply	4
[line_break_token][line_break_token]In the light of this discussion, we respectfully encourage you to reevaluate the paper & update your score.	Reply	O	0
Thank you	Reply	O	0

Summary:[line_break_token]This paper proposes minimal-entropy correlation alignment, an unsupervised domain adaptation algorithm which links together two prior class of methods: entropy minimization and correlation alignment.	Review	O	0
Interesting new idea.	Review	O	0
Make a simple change in the distance function and now can perform adaptation which aligns with minimal entropy on target domain and thus can allow for removal of hyperparameter (or automatic validation of correct one).	Review	O	0
[line_break_token][line_break_token]Strengths[line_break_token]-  The paper is clearly written and effectively makes a simple claim that geodesic distance minimization is better aligned to final performance than euclidean distance minimization between source and target.	Review	O	0
[line_break_token]- Figures 1 and 2 (right side) are particularly useful for fast understanding of the concept and main result.	Review	O	0
[line_break_token][line_break_token][line_break_token]Questions/Concerns:[line_break_token]- Can entropy minimization on target be used with other methods for DA param tuning?	Review	O	0
Does it require that the model was trained to minimize the geodesic correlation distance between source and target?	Review	B-Review	1
[line_break_token]- It would be helpful to have a longer discussion on the connection with Geodesic flow kernel [1] and other unsupervised manifold based alignment methods [2]. Is this proposed approach an extension of this prior work to the case of non-fixed representations in the same way that Deep CORAL generalized CORAL?	Review	O	0
[line_break_token]- Why does performance suffer compared to TRIPLE on the SYN->SVHN task?	Review	O	0
Is there some benefit to the TRIPLE method which may be combined with the MECA approach?	Review	B-Review	3
[line_break_token][line_break_token][tab_token][tab_token][tab_token][tab_token][tab_token][line_break_token][1] Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman.	Review	O	0
Geodesic flow kernel for unsupervised domain adaptation.	Review	O	0
In CVPR, 2012.	Review	O	0
[line_break_token][tab_token][tab_token][tab_token][tab_token][tab_token][line_break_token][2] Raghuraman Gopalan and Ruonan Li.	Review	O	0
Domain adaptation for object recognition: An unsupervised approach.	Review	O	0
In ICCV, 2011.	Review	O	0
[line_break_token]	Review	O	0
We are thankful for the provided comments and we will respond (A) to each query (Q) in detail.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q 1 - (a) Can entropy minimization on target be used with other methods for DA param tuning?	Reply	O	0
 (b) Does it require that the model was trained to minimize the geodesic correlation distance between source and target?	Reply	O	0
[line_break_token][line_break_token]A 1 - (a) Let us point out that we are not minimizing entropy on the target as a regularizing training loss, as previous works did (Tzeng et al.	Reply	O	0
2015, Haeusser et al.	Reply	B-Reply	1
2017 or Carlucci et al.	Reply	I-Reply	1
2017).	Reply	I-Reply	1
For the latter methods, entropy cannot be used as a criterion for parameter tuning, since it is one of the quantities explicitly optimized in the problem.	Reply	I-Reply	1
Differently, we obtain the minimum of the entropy as a consequence of an optimal correlation alignment.	Reply	I-Reply	1
Such criterion could possibly be used for other methods aiming at source-target distribution alignment. (	Reply	I-Reply	1
b) Alignment does not *explicitly* require a geodesic distance.	Reply	I-Reply	1
However, since the former must be optimal, it cannot be attained with an Euclidean distance, which is the reason why we propose the log-Euclidean one.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Q 2. -	Reply	O	0
It would be helpful to have a longer discussion on the connection with Geodesic flow kernel [1] and other unsupervised manifold based alignment methods [2]. Is this proposed approach an extension of this prior work to the case of non-fixed representations in the same way that Deep CORAL generalized CORAL?	Reply	O	0
 [line_break_token][1] Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman.	Reply	O	0
Geodesic flow kernel for unsupervised domain adaptation.	Reply	O	0
In CVPR, 2012.	Reply	O	0
[line_break_token][2] Raghuraman Gopalan,, Ruonan Li  and Rama Chellappa.	Reply	O	0
Domain adaptation for object recognition: An unsupervised approach.	Reply	O	0
In ICCV, 2011.	Reply	O	0
[line_break_token][line_break_token]A -2 The works [1,2] are kernelized approaches which, by either using Principal Components Analysis [1] or Partial Least Squares [2], a sequence of intermediate embeddings is generated as a smooth transition from the source to the target domain.	Reply	O	0
In [1], such sequence is implicitly computed by means of a kernel function which is subsequently used for classification.	Reply	B-Reply	2
In [2], after the source data are projected on hand-crafted intermediate subspaces, classification is performed.	Reply	I-Reply	2
[line_break_token]In [1] and [2], the necessity for engineering intermediate embeddings is motivated by the need for adapting the fixed input representation so that the domain shift can be solved.	Reply	I-Reply	2
As a way to do it, [1] and [2] follow the geodesics on the data manifold.	Reply	I-Reply	2
[line_break_token]In a very same way, our proposed approach, MECA, follows the geodesics on the manifold (of second order statistics), but, differently, this step is finalized to better guide the feature learning stage.	Reply	I-Reply	2
[line_break_token]For all these reasons, MECA and [1,2] can be seen as different manners of exploiting geodesic alignment for the sake of domain adaptation.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Q 3. -	Reply	O	0
Why does performance suffer compared to TRIPLE on the SYN->SVHN task?	Reply	O	0
Is there some benefit to the TRIPLE method which may be combined with the MECA approach?	Reply	O	0
[line_break_token][line_break_token]A 3 - As we argued in the paper, the performance on SYN to SVHN task is due to the the visual similarity between source and target domain whose relative data distributions are already quite aligned.	Reply	O	0
Also note that TRIPLE already performs better than direct training on the target domain.	Reply	B-Reply	3
This could be interpreted as a cue for TRIPLE to perform implicit data augmentation on the source synthetic data (and, indeed, the same could be done in MECA, trying to boost its performance by means of data augmentation).	Reply	I-Reply	3
However, when more realistic datasets are used as source, such procedure becomes more difficult to be accomplished and that‚Äôs why, on all the other benchmarks, TRIPLE is inferior to MECA in terms of performance	Reply	I-Reply	3

For the task of predicting interaction contact among atoms of protein complex consisting of two interacting proteins, the authors propose to train a Siamese convolutional neural network, noted as SASNet, and to use the contact map of two binding proteins‚Äô native structure.	Review	O	0
[line_break_token]The authors claim that the proposed method outperforms methods that use hand crafted features; also the authors claim that the proposed method has better transferability.	Review	O	0
[line_break_token][line_break_token]My overall concern is that the experiment result doesn‚Äôt really fully support the claim in the two aspects: 1) the SASNet takes the enriched dataset as input to the neural net but it also uses the complex (validation set) to train the optimal parameters, so strictly it doesn‚Äôt really fit in the ‚Äútransfer‚Äù learning scenario.	Review	B-Review	1
Also, the compared methods don‚Äôt really use the validation set from the complex data for training at all.	Review	I-Review	2
Thus the experiment comparison is not really fair.	Review	I-Review	2
2) The experiment results include standard errors for different replicates where such replicates correspond to different training random seeds (or different samples from the enriched set?),	Review	O	0
however, it doesn‚Äôt include any significance of the sampling.	Review	B-Review	3
Specifically, the testing dataset is fixed.	Review	I-Review	3
A more rigorous setting is to, for N runs, each run splitting the validation and testing set differently.	Review	I-Review	3
[line_break_token][line_break_token]Since this paper is an application paper, rather than a theoretical paper that bears theoretical findings, I would expect much more thorough experimental setup and analysis.	Review	I-Review	4
Currently it is still missing discussion such as, when SASNet would perform better and when it would perform worse, what it is that the state of the art features can‚Äôt capture while SASNet can.	Review	I-Review	4
Moreover, it is the prediction performance that matters to such task, but the authors remove the non-structure features from the compared methods.	Review	I-Review	4
Results and discussion about how the previous methods with full features perform compared to SASNet, and also how we can include those features into SASNet should complete the paper.	Review	I-Review	4
[line_break_token][line_break_token]Overall the paper is well written, and I do think the paper could be much stronger the issues above are addressed.	Review	O	0
[line_break_token][line_break_token][line_break_token]Some minor issues:[line_break_token]1)[tab_token]on page 4, Section 3, the first paragraph, shouldn‚Äôt ‚ÄúC_p^{val} of 55‚Äù be ‚ÄúC_p^{test} of 55‚Äù?	Review	O	0
[line_break_token][line_break_token]2)[tab_token]It is not clear what the ‚Äúreplicates‚Äù refer to in the experiments.	Review	O	0
[line_break_token][line_break_token]3)[tab_token]Some discussion on why the ‚ÄúSASNet ensemble‚Äù would yield better performance would be good; could it be overfitting?	Review	O	0
[line_break_token]	Review	O	0
We thank the reviewer for their comments.	Reply	O	0
 We address their comments individually below.	Reply	O	0
[line_break_token][line_break_token]> My overall concern is that the experiment result doesn‚Äôt really fully support the claim in the two aspects: 1) the SASNet takes the enriched dataset as input to the neural net but it also uses the complex (validation set) to train the optimal parameters, so strictly it doesn‚Äôt really fit in the ‚Äútransfer‚Äù learning scenario.	Reply	O	0
[line_break_token][line_break_token]Response: Our work is indeed not classical transfer learning -- it is in fact an even stricter variant.	Reply	O	0
 We do not re-train the parameters of the neural network at all using C_p, which is typically done as a ‚Äúfine-tuning‚Äù step in the transfer learning scenario.	Reply	B-Reply	1
So while we do use C_p^{val} for model selection (i.e., hyperparameter tuning), this is still much less use of the data-poor dataset than in the common transfer learning setting of actually fine-tuning the parameters of the neural network using a subset of the data from the data-poor dataset.	Reply	I-Reply	1
[line_break_token][line_break_token]The use of C_p^{val} for hyperparameter tuning was incidental and not a central point of our paper.	Reply	I-Reply	1
 To really make this clear, we have updated the paper to demonstrate that even if we do not use C_p^{val} for model selection, and instead select from the same class of models we previously generated by using a randomly selected held-out set C_r^{val}, we still obtain state-of-the-art performance (0.892 [0.885 +/- 0.009]).	Reply	I-Reply	1
 In this formulation, C_p is not used at all by our method until test time.	Reply	I-Reply	1
[line_break_token][line_break_token]> Also, the compared methods don‚Äôt really use the validation set from the complex data for training at all.	Reply	O	0
Thus the experiment comparison is not really fair.	Reply	O	0
[line_break_token][line_break_token]The competing models do make use of validation set C_p^{val} from the complex data to select amongst the most important hyperparameters of their model -- which is equivalent to what we did in our initial formulation, and favors the competing methods compared to if we use C_r^{val} for hyperparameter search instead.	Reply	B-Reply	2
[line_break_token][line_break_token]> 2) The experiment results include standard errors for different replicates where such replicates correspond to different training random seeds (or different samples from the enriched set?),	Reply	O	0
however, it doesn‚Äôt include any significance of the sampling.	Reply	O	0
Specifically, the testing dataset is fixed.	Reply	O	0
A more rigorous setting is to, for N runs, each run splitting the validation and testing set differently.	Reply	O	0
[line_break_token][line_break_token]Response: The replicates correspond to different training and validation samples of the enriched set -- we have clarified this in the paper.	Reply	O	0
 While it is true that the hyperparameter validation set was initially fixed, the switch to use C_r^{val} as above resolves this.	Reply	B-Reply	3
The testing data C_p^{test} is that which has been used in the prior works we compare to (Fout et al.	Reply	I-Reply	3
2017; Sanchez-Garcia et al.	Reply	I-Reply	3
2018).	Reply	I-Reply	3
 Furthermore, use of this subset for performance evaluation is justified as as C_p^{test} corresponds to latest released structures in C_p, leading to a more accurate assessment of how such methods would perform on unreleased structures (as they do no sequence identity pruning).	Reply	I-Reply	3
 Thus our experimental set up is rigorous and justified.	Reply	I-Reply	3
[line_break_token][line_break_token]> Since this paper is an application paper, rather than a theoretical paper that bears theoretical findings, I would expect much more thorough experimental setup and analysis.	Reply	O	0
Currently it is still missing discussion such as, when SASNet would perform better and when it would perform worse, what it is that the state of the art features can‚Äôt capture while SASNet can.	Reply	O	0
[line_break_token][line_break_token]Response: As we discuss above, we believe our experimental setup and analysis is sufficient to demonstrate that our atomic representation transfers much better across atomic tasks.	Reply	O	0
 We have also added to our discussion, making clear that our method represents a significant advantage over competing methods when detailed atomic information is available.	Reply	B-Reply	4
 Competitors rely on amino acid-level features that fail to capture specific atomic positions but can be better when the structural is less detailed or accurate	Reply	I-Reply	4

This paper proposes using predicted variables(PVars) - variables that learn[line_break_token]their values through reinforcement learning (using observed values and[line_break_token]rewards provided explicitly by the programmer).	Review	O	0
PVars are meant to replace[line_break_token]variables that are computed using heuristics.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]* Interesting/intriguing idea[line_break_token]* Applicability discussed through 3 different examples[line_break_token][line_break_token]Cons:[line_break_token]* Gaps in explanation[line_break_token]* Exaggerated claims[line_break_token]* Problems inherent to the proposed technique are not properly addressed, brushed off as if unimportant[line_break_token][line_break_token]The idea of PVars is potentially interesting and worth exploring; that[line_break_token]being said, the paper in its current form is not ready for[line_break_token]publication.	Review	O	0
[line_break_token][line_break_token]Some criticism/suggestions for improvement:[line_break_token][line_break_token]While the idea may be appealing and worth studying, the paper does not address several problems inherent to the technique, such as:[line_break_token][line_break_token]- overheads (computational cost for inference, not only in[line_break_token]  prediction/inference time but also all resources necessary to run[line_break_token]  the RL algorithm; what is the memory footprint of running the RL?)	Review	O	0
[line_break_token][line_break_token]- reproducibility[line_break_token][line_break_token]- programming overhead: I personally do not buy that this technique -[line_break_token]  at least as presented in this paper - is as easy as "if statements"[line_break_token]  (as stated in the paper) or will help ML become mainstream in[line_break_token]  programming.	Review	O	0
I think the programmer needs to understand the[line_break_token]  underpinnings of the PVars to be able to meaningfully provide[line_break_token]  observations and rewards, in addition to the domain specific[line_break_token]  knowledge.	Review	B-Review	6
In fact, as the paper describes, there is a strong[line_break_token]  interplay between the problem setting/domain and how the rewards should be[line_break_token]  designed.	Review	I-Review	6
[line_break_token][line_break_token]- applicability: when and where such a technique makes sense[line_break_token][line_break_token]The interface for PVars is not entirely clear, in particular the[line_break_token]meaning of "observations" and "rewards" do not come natural to[line_break_token]programmers unless they are exposed to a RL setting.	Review	O	0
Section 2 could[line_break_token]provide more details such that it would read as a tutorial on[line_break_token]PVars.	Review	B-Review	8
If regular programmers read that section, not sure they[line_break_token]understand right away how to use PVars.	Review	I-Review	8
The intent behind PVars[line_break_token]becomes clearer throughout the examples that follow.	Review	I-Review	8
[line_break_token][line_break_token]It was not always clear when PVars use the "initialization function"[line_break_token]as a backup solution.	Review	I-Review	9
In fact, not sure "initialization" is the right[line_break_token]term, it behaves almost like an "alternative" prediction/safety net.	Review	I-Review	9
[line_break_token][line_break_token]The examples would benefit from showing the initialization of the PVars.	Review	I-Review	10
[line_break_token][line_break_token]The paper would improve if the claims would be toned down, the[line_break_token]limitations properly addressed and discussed and the implications of[line_break_token]the technique honestly described.	Review	I-Review	11
I also think discussing the[line_break_token]applicability of the technique beyond the 3 examples presented needs[line_break_token]to be conveyed, specially given the "performance" of the technique[line_break_token](several episodes are needed to achieve good performance).	Review	I-Review	11
[line_break_token][line_break_token]While not equivalent, I think papers from approximate computing (and[line_break_token]perhaps even probabilistic programming) could be cited in the related[line_break_token]work.	Review	I-Review	12
In fact, for an example of how "non-mainstream" ideas can be[line_break_token]proposed for programming languages (and explained in a scientific[line_break_token]publication), see the work of Adrian Sampson on approximate computing[line_break_token]<a href="https://www.cs.cornell.edu/~asampson/research.html" target="_blank" rel="nofollow">https://www.cs.cornell.edu/~asampson/research.html</a>[line_break_token]In particular, the EnerJ paper (PLDI 2011) and Probabilistic Assertions (PLDI 2014).	Review	O	0
[line_break_token][line_break_token]Update: I maintain my scores after the rebuttal discussion.	Review	O	0
We thank the reviewer for relevant and insightful comments.	Reply	O	0
We provide responses and, when applicable, pointers to the changes we‚Äôve done in the paper aiming to address some of the problems related to the technique we introduced.	Reply	O	0
[line_break_token][line_break_token]- computation overhead[line_break_token]We did not provide an analysis of the computational overhead of our method because we see the three algorithmic problems as tasks to demonstrate that the interface that we provide is expressive and powerful enough to bring ML into normal software development.	Reply	O	0
In many other applications, where predicted variables can be applied, speed is not a relevant metric, e.g user modelling, optimizing UI components, predicting user preference,  systems optimization, or content recommendations.	Reply	B-Reply	4
We acknowledge that our current implementation is probably slower than the original variant - but as we describe above, we don't consider actual runtime to be the relevant metric here.	Reply	I-Reply	4
[line_break_token]Further - we strongly believe that specialized hardware such as GPUs or TPUs are continuously improving the runtime of ML models which will eventually make our proposed implementation practical even for speed sensitive applications (compare also Kraska et al, 2017).	Reply	I-Reply	4
[line_break_token][line_break_token]- reproducibility[line_break_token]We acknowledge that the paper does not provide sufficient data related to reproducibility and we present additional reproducibility experiments in the appendix.	Reply	O	0
Similar to other RL work, there are some problems with reproducibility.	Reply	B-Reply	5
However, for binary search we obtain positive results (negative cumulative regret) with a reproducibility of 85% (Quicksort: 94%).	Reply	I-Reply	5
[line_break_token][line_break_token]- applicability[line_break_token]We assume throughout our work that the developer -- algorithm and problem expert -- has domain-specific knowledge that is relevant for the problem being solved.	Reply	O	0
Therefore our interface enables the developer to make use of their expert knowledge without requiring deep machine learning expertise.	Reply	B-Reply	7
The developer decides what are the most important contextual signals and what metric to optimize for - The API naturally translates these into observations and rewards for the RL methods applied.	Reply	I-Reply	7
[line_break_token][line_break_token]- initial function[line_break_token]We thank the reviewer for pointing out the lack of more detailed explanations.	Reply	O	0
The initial function does not serve only for initialization but it plays two other important roles [line_break_token](1) it generates safe experience trajectories from which the off-policy RL algorithm learns and [line_break_token](2) can be reused as a safety net, should the model performance degrade.	Reply	B-Reply	9
[line_break_token]We have updated our draft to more clearly express this.	Reply	I-Reply	9
[line_break_token][line_break_token]- performance/episodes[line_break_token]We are not 100% sure what the reviewer means with the comment about "performance" - we try to respond to this comment as good as we can.	Reply	O	0
[line_break_token]As we describe in the paper, we measure cumulative regret as our main performance metric.	Reply	B-Reply	11
A negative cumulative regret indicates that the user benefits from using a predicted variable compared to the baseline.	Reply	I-Reply	11
While initially, the predicted variable might perform a bit worse than the baseline, the goal is to outperform the baseline as quickly as possible.	Reply	I-Reply	11
Note also, that the use of the initial function in our setup enables us to ensure a certain safety net in the beginning which helps the method to never perform terribly badly.	Reply	I-Reply	11
[line_break_token][line_break_token]- citations, related work[line_break_token]Thank you for the reference, we have updated our draft to point out work related specifically to approximate computing, as well as for probabilistic programming	Reply	O	0

The paper proposes two ideas: 1) Hamiltonian Generative Networks (HGN) and 2) Neural Hamiltonian Flow (NHF).	Review	O	0
[line_break_token][line_break_token]Hamiltonian Generative Networks are generative models of high-dimensional timeseries which use hamiltonian differential equations to evolve latent variables (~position and ~momentum vectors) through time (using any differentiable integration scheme).	Review	O	0
Given the ~position vector a decoder network generate predictions.	Review	O	0
The initial latent variables are inferred using a VAE style inference network that takes a sequence of images as the input.	Review	O	0
The decoder, inference network and crucially the hamiltonian energy function is learned by minimizing a VAE style ELBO on observed sequences.	Review	O	0
The model induces a strong hamiltonian physics prior and is quite elegant all in all.	Review	O	0
The model is evaluated on 4 simulated physics tasks, and beats the only baseline the Hamiltonian Neural Network (HNN).	Review	O	0
[line_break_token][line_break_token]Neural Hamiltonian Flow notes that hamiltonian dynamics are invertible and volume preserving, which is the properties you need for neural flow models.	Review	O	0
As such it propose to use a series of hamiltonian update steps with multiple learned energy functions as a flexible density estimator.	Review	O	0
The resulting density estimator is subjectively evaluated on three 2d toy density estimation tasks.	Review	O	0
[line_break_token][line_break_token]I propose a weak accept as I think the paper is interesting and well written, but could be much better.	Review	O	0
The paper explains how both HGN and NHF work, but not much more.	Review	O	0
The HGN is only compared to a single other method (the closely related HNN), on four toy benchmarks.	Review	B-Review	1
The NHF is barely evaluated, and not compared to anything.	Review	I-Review	1
[line_break_token][line_break_token]Does the authors actually care about modelling physics and think their method is superior at this?	Review	I-Review	2
If so, they should compare and contrast to some of the many, many papers on modelling physics, e.g. [1,2,3,4] and references herein.	Review	I-Review	2
If not, what do they care about?	Review	I-Review	2
Where do they think this model can be useful?	Review	I-Review	2
Why should anyone use this model over some of the many, many other models one could use?	Review	I-Review	2
[line_break_token][line_break_token]Similarly for the NHF, if I only read this paper I have no idea whether it's better than any of the other flow based models.	Review	I-Review	3
Is it faster (to sample?	Review	I-Review	3
to eval likelihood?)	Review	I-Review	3
is it a better estimator?	Review	I-Review	3
Why should I use it?	Review	I-Review	3
[line_break_token][line_break_token]I think the paper would benefit from being split into two papers, each thoroughly examining one idea.	Review	I-Review	4
[line_break_token][line_break_token]A few questions and minor comments[line_break_token][line_break_token] - While the hamiltonian dynamics expect position and momentum vectors, the neural network is free to use those however it sees fit.	Review	O	0
Actually, if I understand correctly, the position vector must also encode the color of the objects for the 2 and 3 body problem.	Review	B-Review	5
Is that correct?	Review	I-Review	5
It would be interesting if you could examine how predictive the q and p vectors were of the true position and momentum vectors.	Review	I-Review	5
[line_break_token] - Successful experiments with n-body problems with n randomly sampled during training and unseen n used in testing would be very powerful in showing generalization.	Review	O	0
I'm afraid that the current setup doesn't generalize well.	Review	B-Review	6
[line_break_token] - I'm surprised that the generated images start showing artifacts after some time, e.g. pendulum sample 4 and 6 in <a href="https://docs.google.com/presentation/d/e/2PACX-1vRD2FnKgymgR2lU8lE6-XM8Cz-UWLTI6n_Uht3v6Gu4hIyMHmOcNL5D-0eG6Z4WHDAWS4qFosU-lxXP/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.g61bbdf339d_0_426."	Review	O	0
target="_blank" rel="nofollow">https://docs.google.com/presentation/d/e/2PACX-1vRD2FnKgymgR2lU8lE6-XM8Cz-UWLTI6n_Uht3v6Gu4hIyMHmOcNL5D-0eG6Z4WHDAWS4qFosU-lxXP/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.g61bbdf339d_0_426.</a> How can those appear if the hamiltonian dynamics preserve energy?	Review	O	0
[line_break_token] - Equation 3 is given as self evident.	Review	O	0
It's not clear to me why 1) det(I+dt*A) = 1+dt*Tr(A)+O(dt^2).	Review	B-Review	8
Can the authors give a reference?	Review	I-Review	8
Also, doesn't the O(dt^2) term accumulate over multiple timesteps or longer rollouts?	Review	I-Review	8
if so, how can the multiple steps proposed be said to be volume preserving?	Review	I-Review	8
[line_break_token][line_break_token][1] - Battaglia, Peter, et al. "	Review	O	0
Interaction networks for learning about objects, relations and physics."	Review	O	0
Advances in neural information processing systems.	Review	O	0
2016.	Review	O	0
[line_break_token][2] - de Avila Belbute-Peres, Filipe, et al. "	Review	O	0
End-to-end differentiable physics for learning and control."	Review	O	0
Advances in Neural Information Processing Systems.	Review	O	0
2018.	Review	O	0
[line_break_token][3] - Santoro, Adam, et al. "	Review	O	0
A simple neural network module for relational reasoning."	Review	O	0
Advances in neural information processing systems.	Review	O	0
2017.	Review	O	0
[line_break_token][4] - Fraccaro, Marco, et al. "	Review	O	0
A disentangled recognition and nonlinear dynamics model for unsupervised learning."	Review	O	0
Advances in Neural Information Processing Systems.	Review	O	0
2017.	Review	O	0
ear Reviewer, thank you for your thoughtful comments and feedback.	Reply	O	0
[line_break_token][line_break_token][Why is Hamiltonian flow more efficient]: The benefits of the NHF over standard flows, as discussed at the end of section 3.3, are that since the NHF is volume preserving by design we do not need to calculate the standard log determinant of the likelihood, because it is 0.	Reply	O	0
Additionally, similar to Neural ODEs (and RevNets for instance) you do not need to store the forward pass for computing gradients as the model can be directly inverted.	Reply	B-Reply	3
Finally, we can even use simple symplectic integrators, like the leapfrog integrator, when the Hamiltonian is separable, and this defines a valid volume preserving transformation even in the discrete case (e.g. not only in the limit dt-&gt;0).	Reply	O	0
We are also running extra experiments to produce a quantitative comparison between NHF and some of the existing alternatives.	Reply	B-Reply	3
We will include these results in the paper as soon as they are ready.	Reply	I-Reply	3
[line_break_token][line_break_token][Relevance of the model in the context of past work]: Thank you for raising this point and for providing these references.	Reply	O	0
As described in the introduction to our submission, the main goal of our paper is to introduce the Hamiltonian formalism to contemporary machine learning, since it plays a central role in physics, the theory and tools around it have a long history of development and use, and it has properties that many machine learning systems may benefit from, like time reversibility, smooth interpolation in time and conservation of state properties.	Reply	B-Reply	2
Given that this is a relatively new line of work, we start by modelling image sequences with well understood underlying physical dynamics that allow us to evaluate our approach easily.	Reply	I-Reply	2
The  aim of this work is not primarily image sequence modelling.	Reply	I-Reply	2
This is the reason why we do not compare to the large body of literature that uses neural networks to model image sequences, and instead only focus on the most relevant work with the same motivation as us, the Greydanus et al (2019) paper.	Reply	I-Reply	2
[line_break_token][line_break_token]That said, the references you raise are certainly very interesting, despite not being directly comparable to our present work.	Reply	I-Reply	2
Of these four papers, de Avila Belbute-Peres et al [2] is the closest in flavour to our work, as it proposes a model that works from images and that models dynamics. [	Reply	I-Reply	2
2] uses an autoencoder to map images to a latent variable that can be stepped forward in time using a learned physics model.	Reply	I-Reply	2
As such, this model is similar in both design philosophy and architecture to the pixel version of HNN (Greydanus et al, 2019), which, however, is a more direct baseline and which our model consistently outperforms.	Reply	I-Reply	2
Moreover, the model in [2] is trained in a supervised or semi-supervised regime, which makes it difficult to baseline against our model, which is unsupervised.	Reply	I-Reply	2
We agree that this paper provides important context for understanding our contribution, and we have added it to the revised manuscript.	Reply	I-Reply	2
[line_break_token][line_break_token]While Fraccaro et al [4] models image dynamics, it does not focus on modeling systems with unknown Hamiltonian dynamics.	Reply	I-Reply	2
The other two papers are less directly relevant: Battaglia et al [1] operates directly from state and leverages domain-specific knowledge about objects, and as such is not directly comparable to our work, which uses images as input and does not use knowledge about the number or structure of objects in the scene.	Reply	I-Reply	2
Santoro et al [3] is a model of relational reasoning, and is not designed to model physical system dynamics.	Reply	I-Reply	2
The experiments on physical system included probe the model's ability to extract relational information (e.g. classifying the connectivity structure of a set of moving balls), not to model dynamics.	Reply	I-Reply	2

The paper introduces XWORLD, a 2D virtual environment with which an agent can constantly interact via navigation commands and question answering tasks.	Review	O	0
Agents working in this setting therefore, learn the language of the "teacher" and efficiently ground words to their respective concepts in the environment.	Review	O	0
The work also propose a neat model motivated by the environment and outperform various baselines.	Review	O	0
[line_break_token][line_break_token]Further, the paper evaluates the language acquisition aspect via two zero-shot learning tasks -- ZS1) A setting consisting of previously seen concepts in unseen configurations ZS2) Contains new words that did not appear in the training phase.	Review	O	0
[line_break_token][line_break_token]The robustness to navigation commands in Section 4.5 is very forced and incorrect -- randomly inserting unseen words at crucial points might lead to totally different original navigation commands right?	Review	B-Review	1
As the paper says, a difference of one word can lead to completely different goals and so, the noise robustness experiments seem to test for the biases learned by the agent in some sense (which is not desirable).	Review	I-Review	1
Is there any justification for why this method of injecting noise was chosen ?	Review	I-Review	2
Is it possible to use hard negatives as noisy / trick commands and evaluate against them for robustness ?	Review	I-Review	2
 [line_break_token][line_break_token]Overall, I think the paper proposes an interesting environment and task that is of interest to the community in general.	Review	O	0
The modes and its evaluation are relevant and intuitions can be made use for evaluating other similar tasks (in 3D, say).	Review	O	0
Thanks for your comments.	Reply	O	0
[line_break_token][line_break_token]The experiment of robustness is aimed at testing the agent in a[line_break_token]scenario out of our control, such as executing navigation commands[line_break_token]elicited by human after the training is done.	Reply	B-Reply	1
In such case, we simply[line_break_token]assume that the evaluator does not have any knowledge of the training[line_break_token]process.	Reply	I-Reply	1
A natural-language sentence elicited by the human evaluator[line_break_token]might convey a meaning that is similar or same to a sentence generated[line_break_token]by our grammar, however, it might not be that well-formed (e.g.,[line_break_token]containing extra irrelevant words).	Reply	I-Reply	1
One simple way of simulating this[line_break_token]scenario (incompletely) is to insert noisy word embeddings into the original sentence.	Reply	I-Reply	1
[line_break_token][line_break_token]This preliminary experiment serves to provide some numbers to let the[line_break_token]readers have a rough idea about how well the agent will perform in an[line_break_token]uncontrollable setting.	Reply	I-Reply	2
However, because of its minor significance and[line_break_token]a possible misunderstanding, we have removed this section (4.5) from[line_break_token]the original paper.	Reply	I-Reply	2

Review of "Neural Network Cost Landscapes as Quantum States"[line_break_token][line_break_token]Paper summary:[line_break_token][line_break_token]The paper proposes a new algorithm "quantum amplitude amplification"[line_break_token]for training and model selection in binary neural networks. (	Review	O	0
in which[line_break_token]both weights and activations are restricted to the set -1, 1)[line_break_token][line_break_token]Section 2 references related work and gives some motivation, that some[line_break_token]quantum algorithms scale better (in terms of big-O notation) than[line_break_token]classical algorithms.	Review	O	0
[line_break_token][line_break_token]Section 3 explains the basics of quantum computing (qubits and quantum[line_break_token]gates).	Review	O	0
[line_break_token][line_break_token]Section 4 explains the proposed method.	Review	O	0
There are two toy[line_break_token]problems.	Review	O	0
The binary neural network has 8 weight parameters.	Review	O	0
There are[line_break_token]helpful Figures 1-2 which explain the network structure and the[line_break_token]quantum circuit.	Review	O	0
[line_break_token][line_break_token]Section 5 explains the results of using the proposed method in a[line_break_token]quantum computer simulator (not an actual quantum computer).	Review	O	0
On the[line_break_token]two toy problems the paper observes quadratic speedups with respect to[line_break_token]a brute force search.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]A strong point is that the paper is very well-written and easy to[line_break_token]understand.	Review	O	0
[line_break_token][line_break_token]However there are several weak points which should be addressed before[line_break_token]publication.	Review	B-Review	2
Major weak points are (1) only (noiseless?)	Review	I-Review	2
toy data sets[line_break_token]are used, (2) some terms in the paper are unclear/undefined, and (3)[line_break_token]results are unconvincing.	Review	I-Review	2
[line_break_token][line_break_token]It is not clear that this article should be published in the machine[line_break_token]learning literature.	Review	I-Review	3
One of the hallmarks of machine learning is a[line_break_token]focus on algorithms for real data sets / problems.	Review	I-Review	3
In contrast the[line_break_token]focus of this paper is quantum computations on toy data /[line_break_token]problems.	Review	I-Review	3
Maybe this paper would be better suited for publication in[line_break_token]the quantum computation literature?	Review	I-Review	3
[line_break_token][line_break_token]The toy problems are explained in section 4.2.	Review	I-Review	4
Is there any noise or[line_break_token]are these noiseless simulations?	Review	I-Review	4
How does your model/algo perform as a[line_break_token]function of the noise level?	Review	I-Review	4
How many data points did you simulate[line_break_token]from the model? (	Review	I-Review	4
e.g. what is the number of observations in the training set?)	Review	I-Review	4
[line_break_token][line_break_token]The paper uses the terms "cost landscape" and "meta-cost landscape"[line_break_token]without explicitly defining them.	Review	I-Review	5
Equations should be added to clarify[line_break_token]these terms.	Review	I-Review	5
[line_break_token][line_break_token]Results could be made more convincing by[line_break_token]1.	Review	I-Review	6
using a real quantum computer.	Review	I-Review	6
[line_break_token]2.	Review	I-Review	4
using real data rather than toy data.	Review	I-Review	6
[line_break_token]3.	Review	O	0
adding error bars or confidence intervals to Figures 4-5.	Review	B-Review	6
[line_break_token]4.	Review	I-Review	4
using a more appropriate baseline -- why not try the algorithms mentioned in section 2.1?	Review	I-Review	6
[line_break_token][line_break_token]Figure 3 could be clarified by providing ticks and labels on the x[line_break_token]axes.	Review	I-Review	7
[line_break_token][line_break_token]	Review	O	0
We thank the reviewer for the constructive feedback and for recognizing the work as new and the paper as very well written and easy to understand.	Reply	O	0
We have altered the paper to address all points raised by the reviewer.	Reply	O	0
[line_break_token]We thank the reviewer for the opportunity to clarify points in the paper that can be improved to make the manuscript stronger.	Reply	O	0
[line_break_token]1) Noiseless, synthetic datasets, real data/problems as a hallmark of ML.	Reply	O	0
As of today, the available quantum computers are small in size.	Reply	B-Reply	2
It is this small size that restricts the magnitude and characteristics of the data that we can use for training/testing.	Reply	I-Reply	2
For example, it is not physically possible to fit all the data in a single PASCAL VOC Dataset image onto a current quantum computer.	Reply	I-Reply	2
However, larger and larger quantum computers are being commercially built by companies including Google, IBM, Intel and Rigetti.	Reply	I-Reply	2
This restriction on size will disappear in the near future.	Reply	I-Reply	2
[line_break_token]We also argue that synthetic data, noiseless or simplified datasets have played and continue to play a crucial role in the advancement of the field of machine learning and we expect a similar path to be followed for quantum machine learning.	Reply	I-Reply	2
Datasets such as Tic-Tac-Toe Endgame Dataset, Connect-4 Dataset, Iris, NMIST and more recently Atari 2600 games have enable theoretical and experimental advancement in machine learning that reflects the state of currently available hardware.	Reply	I-Reply	2
In this paper we have chosen the largest datasets, given the current restrictions on quantum hardware, in order to open up and explore a new research area.	Reply	I-Reply	2
This is an entirely new paradigm that is developing extraordinarily rapidly.	Reply	I-Reply	2
Such a field requires the foundations to be set through proofs of concept such as these.	Reply	I-Reply	2
Classical machine learning followed the same trend before the widespread availability of computing power; this can be reflected in the conference call for papers which includes theoretical issues in learning.	Reply	I-Reply	2
[line_break_token]Due to the limited size of the problem we investigate, we do not add noise.	Reply	I-Reply	2
However, it is important to consider what noisy data would achieve.	Reply	I-Reply	2
We stress that the quantum neural network simply mimics its classical counterpart with greater parallelisation.	Reply	I-Reply	2
If we are to input noisy data the accuracy that is output would be the exact same as for a classical neural network with the same noisy data, activation function and weights.	Reply	I-Reply	2
The method for generating the landscape state will not change and the quantum search will still have a quadratic speedup over its classical equivalent.	Reply	I-Reply	2
[line_break_token]2) some terms in the paper are unclear/undefined.	Reply	O	0
The paper has been updated and all terms are clearly defined with additional explanations added[line_break_token]3.1) Real quantum computer.	Reply	O	0
At the time of writing several companies are developing commercial quantum computers with a variety of qubits counts.	Reply	B-Reply	6
Rigetti 128, Google 72, IBM 50 and Intel 49, unfortunately these machines are not available to the public.	Reply	I-Reply	6
The largest publically available quantum computers are IBM‚Äôs 20 qubit and Rigetti‚Äôs 19 qubit machines.	Reply	I-Reply	6
These would not be large enough to run our proposed approach however, we expect to be able to do this in the near future.	Reply	I-Reply	6
We agree that this will make the paper stronger.	Reply	I-Reply	6
We perform our experiments in quantum simulations to enable us to explore the theoretical and experimental advancement of this research topic, this is standard practice.	Reply	I-Reply	6
 [line_break_token]3.2) Real data.	Reply	O	0
This has been addressed above[line_break_token]3.3) error bars.	Reply	O	0
These have been added[line_break_token]3.4) baseline.	Reply	O	0
What we have done is taken a classical neural network and created a quantum analogue and taken a classical search method and used a quantum equivalent.	Reply	B-Reply	6
We believe that the most relevant and direct baseline comparison here is the original classical method to our quantum equivalent.	Reply	I-Reply	6
 As for the algorithms mentioned in section 2 ‚Äì our method is underpinned entirely by an adapted version of one of them ‚Äì Grover‚Äôs algorithm.	Reply	I-Reply	6
Many of the others rely on as-yet unfounded assumptions on the data itself, primarily that it will be stored and accessible as quantum amplitudes.	Reply	I-Reply	6
Our primary motivation was to investigate realistic near-term methods that do not rely on these assumptions.	Reply	I-Reply	6

Thanks for submitting your paper.	Review	O	0
It takes a lot of effort and courage to put your ideas out into the world.	Review	O	0
Sometimes the hardest work for researchers is conveying their thoughts to others in a manner in which those ideas can be understood.	Review	O	0
[line_break_token][line_break_token]With that in mind, I had an extremely difficult time following your arguments.	Review	O	0
[line_break_token][line_break_token]I noticed several things:[line_break_token] - There are numerous places in the text that lack proper citation, or are cited improperly.	Review	O	0
[line_break_token][line_break_token] - Why was there not a related methods section?	Review	O	0
I find it hard to believe that all of your ideas have no precursor.	Review	B-Review	2
[line_break_token][line_break_token] - When there are citations, there is usually only one text and it is quite old.	Review	O	0
For example, all of your neuroscience citations reference a work that is almost 40 years old.	Review	B-Review	3
There have been quite a few improvements in our biological understanding as well as theoretical understanding since then. (	Review	I-Review	3
I make this point as a common justification used in the manuscript is that the method describes how synapses function in biology. )	Review	I-Review	3
[line_break_token][line_break_token]- There is a claim regarding how this can be used in fintech.	Review	O	0
This statement doesn't belong in this work.	Review	B-Review	4
[line_break_token][line_break_token] - There are many different equations given throughout the text.	Review	O	0
Some of these equations come from areas like physics or information theory, and others seem to be of your own design.	Review	B-Review	5
Regarding the latter, there is no justification or explanation for the origin of the equations.	Review	I-Review	5
Regarding the former, if you are using equations from lots of different fields, or even field you think part of your audience might not be familiar with, you should, at the very least, include a some description of the algorithm or intuition as to why it is being leveraged.	Review	I-Review	5
[line_break_token][line_break_token] - It wasn't clear from your diagrams or your descriptions what the difference between a synapse and a neuron was in your architecture.	Review	O	0
It seemed like the name was used interchangeably in some areas, but then had a strict definition in others.	Review	B-Review	6
[line_break_token][line_break_token] - I was also not able to understand how the excitatory and the inhibitory connections that were to enter each neuron were connected to the previous layer of the network.	Review	O	0
Is a link between neurons in Figure 2 actually two links?	Review	B-Review	7
If this is the case, then it is a direct violation of Dale's law.	Review	I-Review	7
Again, I only mention this because most arguments seem to be of the form "this is correct because it is how it is done biologically".	Review	I-Review	7
[line_break_token][line_break_token] - There were a few claims made in the paper that were completely unsubstantiated.	Review	O	0
A good example of this was in the conclusion section part ii) where it was stated that "using a large number of synapses and neurons SynaNN can solve the complex problems in the real world."	Review	B-Review	8
[line_break_token][line_break_token]- Also, the last sentence of the conclusion was not discussed anywhere in the rest of the paper.	Review	O	0
Nor was the statement itself supported except with a single citation and no description.	Review	B-Review	9
[line_break_token][line_break_token]Regarding the empirical testing of your algorithm, I was very dissapointed to see that the only dataset it was tested against was MNIST.	Review	I-Review	10
Furthermore there was absolutely no benchmarking against other comparative algorithms.	Review	I-Review	10
At the very least I would have expected a comparison to the perceptron algorithm that you use as inspiration, but that would also still not have been enough.	Review	I-Review	10
[line_break_token][line_break_token]This paper needs heavy amounts of work to make it understandable.	Review	O	0
Once it is understandable an attempt to evaluate the merit of the scientific contribution would then be possible.	Review	O	0
Thanks to your suggestion to do a comparison testing.	Reply	O	0
[line_break_token][line_break_token]We have done two MLP tests in the same configuration of Keras/Tensorflow python code.	Reply	B-Reply	10
[line_break_token]The only difference is to replace Dense layer by Synapse layer in the hidden layer.	Reply	I-Reply	10
 [line_break_token]Both the input layer and output layer are Dense.	Reply	I-Reply	10
[line_break_token][line_break_token]Keras/Synapse: [line_break_token]Test loss: 0.09429045873575433[line_break_token]Test accuracy: 0.9802000087499618[line_break_token][line_break_token]Keras/Dense:[line_break_token]Test loss: 0.09061271685754718[line_break_token]Test accuracy: 0.9830000066757202[line_break_token][line_break_token]The accuracy is not such a disappointment.	Reply	I-Reply	10
Everybody, including us, has thought MLP can achieve 99% in any way.	Reply	I-Reply	10
In our testing, without BatchNormlization, it is even hard to achieve 98%.	Reply	I-Reply	10
This reminds us many disappoint results on MNIST from other models such as Spike Neural Network.	Reply	I-Reply	10
The intrinsic limitation of MLP may be the reason for the poor results.	Reply	I-Reply	10
The model itself is not wrong.	Reply	I-Reply	10
[line_break_token][line_break_token]Below is the configuration.	Reply	I-Reply	10
[line_break_token][line_break_token]Using TensorFlow backend.	Reply	I-Reply	10
[line_break_token]60000 train samples[line_break_token]10000 test samples[line_break_token]_________________________________________________________________[line_break_token]Layer (type)                 Output Shape              Param #[line_break_token]=================================================[line_break_token]dense_1 (Dense)              (None, 300)             235500[line_break_token]_________________________________________________________________[line_break_token]batch_normalization_1 (Batch (None, 300)   1200[line_break_token]_________________________________________________________________[line_break_token]activation_1 (Activation)    (None, 300)           0[line_break_token]_________________________________________________________________[line_break_token]synapse_1 (Synapse)          (None, 300)          90000[line_break_token]_________________________________________________________________[line_break_token]batch_normalization_2 (Batch (None, 300)   1200[line_break_token]_________________________________________________________________[line_break_token]dense_2 (Dense)              (None, 10)                3010[line_break_token]=================================================[line_break_token]Total params: 330,910[line_break_token]Trainable params: 329,710[line_break_token]Non-trainable params: 1,200[line_break_token]_________________________________________________________________[line_break_token]Train on 60000 samples, validate on 10000 samples[line_break_token]Epoch 1/30	Reply	I-Reply	10

I thank the authors for the rebuttal and the additional experiments.	Review	O	0
The additions do partially address my concerns, although not entirely.	Review	O	0
For instance, the experiments on non-face classes are very preliminary and it is unclear if they work at all (no other views shown).	Review	O	0
I hope the authors are right that the method will work on other classes after some tuning, but this is not demonstrated in the paper.	Review	O	0
Overall, I am quite in a borderline mode.	Review	O	0
I think the paper looks promising and after further improving the experimental evaluation it can become a great publication.	Review	O	0
But for now the experiments, especially the new ones, look somewhat incomplete and rushed, more suitable for a workshop paper.	Review	B-Review	5
Therefore, I still lean towards rejection.	Review	O	0
[line_break_token][line_break_token]---[line_break_token][line_break_token]The paper proposes an approach to learning the 3D structure of images without explicit supervision.	Review	O	0
The proposed model is a Generative Adversarial Network (GAN) with an appropriate task-specific structure: instead of generating an image directly with a deep network, three intermediate outputs are generated first and then processed by a differentiable renderer.	Review	O	0
The three outputs are the 3D geometry of the object (represented by a mesh in this work), the texture of the object, and the background image.	Review	O	0
The final output of the model is produced by rendering the geometry with the texture and overlaying on top of the background.	Review	O	0
The whole system can be trained end-to-end with a standard GAN objective.	Review	O	0
The method is applied to the FFHQ dataset of face images, where it produces qualitatively reasonable results.	Review	O	0
[line_break_token][line_break_token]I am in the borderline mode about this paper.	Review	O	0
On one hand, I believe the task of unsupervised learning 3D from 2D is interesting and important, and the paper makes an interesting contribution in this direction.	Review	O	0
On the other hand, the experimental evaluation is quite limited: the results are purely qualitative, on a single dataset, and do not contain much analysis of the method.	Review	B-Review	5
It would be great if the authors could add more experiments to the paper during the discussion phase.	Review	I-Review	5
[line_break_token][line_break_token]More detailed comments:[line_break_token]Pros:[line_break_token]1) The paper is presented well, is easy to read.	Review	O	0
I like the detailed table with comparison to related works, and a good discussion of the limitations of the method and the tricks involved in making it work.	Review	O	0
I also like section 4 clearly discussing the assumptions of the work, although I think it could be shortened quite a bit.	Review	O	0
[line_break_token]2) The proposed method is reasonable and seems to work in practice, judging from the qualitative results.	Review	O	0
[line_break_token][line_break_token]cons:[line_break_token]1) The experiments are limited.	Review	O	0
[line_break_token]1a) There are no quantitative results.	Review	O	0
I understand it is non-trivial to evaluate the method on 3D reconstruction, although one could either train a network inverting the generator, or, perhaps simpler, apply a pre-trained image-to-3D network to the generated images.	Review	B-Review	1
But at least some image quality measures (FID, IS) could be reported.	Review	I-Review	1
[line_break_token]1b) The method is only trained on one dataset of faces.	Review	O	0
It would be great to apply the method to several other datasets as well, for instance, cars, bedrooms, animal faces, ShapeNet objects.	Review	B-Review	2
This would showcase the generality of the approach.	Review	I-Review	2
Otherwise, I am worried the method is fragile and only applies to very clean and simple data.	Review	I-Review	2
Also, if the method is only applied to faces, it makes sense to mention faces in the title.	Review	I-Review	2
[line_break_token]1c) It would be very helpful to have more analysis of the different variants of the method, ideally with quantitative results (again, at least some image quality results).	Review	O	0
Figure 3 goes in this direction, but it is very small and does not give a clear understanding of the relative performance of diferent variants.	Review	B-Review	3
[line_break_token][line_break_token]2) A missing very relevant citation of HoloGAN by Nguyen-Phuoc et al.	Review	O	0
 [1]. It is not yet published, but has been on arXiv for some time.	Review	B-Review	4
I am a bit unsure about the ICLR policy in this case (this page <a href="https://iclr.cc/Conferences/2019/Reviewer_Guidelines" target="_blank" rel="nofollow">https://iclr.cc/Conferences/2019/Reviewer_Guidelines</a> suggests that arXiv paper may be formally considered prior work, in which case it should be discussed in full detail), but at least a brief mention would definitely be good.	Review	O	0
[line_break_token][line_break_token][1] HoloGAN: Unsupervised learning of 3D representations from natural images.	Review	O	0
Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, Yong-Liang Yang.	Review	O	0
arXiv 2019.	Review	O	0
 We provide FID numbers in the revised paper.	Reply	O	0
[line_break_token]- We provide results on LSUN categories.	Reply	O	0
The results are not as good as on the faces, but:[line_break_token][tab_token]- we did not have enough time to tune the algorithm to this new data, [line_break_token][tab_token]  but we believe that eventually it would work well also here as we observe similar [line_break_token]          challenges to the faces dataset at the early stages of the algorithm development[line_break_token][tab_token]- LSUN includes outliers, cropped objects, occlusions, high variation in shape, [line_break_token][tab_token]  position and scale[line_break_token]- We added detailed ablations.	Reply	B-Reply	2
[line_break_token]- We added HoloGAN to the related work (also see my answer to all reviewers and the updated paper)	Reply	O	0

This work proposes a regularization strategy for learning optimal policy for a dynamic control problem in a latent low-dimensional domain.	Review	O	0
The work is based on LCE approach, but with in-depth analysis on how to choose/design the regularization for the \hat{P} operator, which consists of an encoder, a decoder, and dynamics in the latent space.	Review	O	0
In particular, the author argued that three principles (prediction, consistency, and curvature) should be taken into consideration when designing the regularizer of the learning cost function - so that the learned latent domain can serve better for the purpose of optimizing the long-term cost in the ambient domain.	Review	O	0
[line_break_token][line_break_token]The paper is well written and pleasant to read.	Review	O	0
One possible shortcoming is that the notations are a bit dazzling.	Review	B-Review	5
It is almost impossible to follow the notation when first reading this paper.	Review	I-Review	5
The proofs are very lengthy and thus the reviewer did not check in detail.	Review	O	0
[line_break_token][line_break_token]The reviewer has several question:[line_break_token][line_break_token]1) Of course SOC2 makes sense.	Review	O	0
But what if one models the whole problem as an HMM, and perform control algorithms in the hidden domain of the HMM (and the hidden states can be of much smaller alphabets compared to the observable states), will there be any fundamental difference?	Review	B-Review	1
Of course learning an HMM is challenging, but approachable.	Review	I-Review	1
Any comments?	Review	I-Review	1
[line_break_token][line_break_token]2) The three design principles make sense, but may need more elaboration.	Review	O	0
For example, it is a bit unclear why f_Z should be with low curvature -- does it mean that you wish the control problem in the latent domain is more like a linear dynamical system, so that the LLC algorithm works better?	Review	B-Review	2
The argument is a bit unclear, since "locally linear" is not a rigorous term.	Review	I-Review	2
Any smooth function is ``"locally linear".	Review	I-Review	2
Here, how to measure the difficulty of the latent control problem may need more discussion.	Review	I-Review	2
[line_break_token][line_break_token]Minor: btw,  (5) may contain some typos.	Review	I-Review	3
[line_break_token][line_break_token]3) In practice, how to balance the three parameters lambda_p, lambda_c, lambda_cur?	Review	O	0
[line_break_token][line_break_token] 	Review	B-Review	1
e thank the reviewer for useful comments.	Reply	O	0
[line_break_token][line_break_token]1) HMM is definitely an option for learning the latent space.	Reply	O	0
We note that the concepts we highlight in this paper (prediction, consistency, curvature) remain relevant even if the underlying dynamics model of choice is an HMM.	Reply	B-Reply	1
However, since our paper makes the simplifying assumption that the observation space is Markovian, and since training an HMM is generally more challenging than training Markovian dynamics models, we chose not to employ an HMM in our paper.	Reply	I-Reply	1
[line_break_token][line_break_token]2) The three terms in PCC are prediction, consistency, and curvature.	Reply	O	0
For prediction, the goal is to enforce that the process of encoding, transitioning via the latent dynamics, and then decoding, adheres to the true observation dynamics.	Reply	B-Reply	2
For consistency, the goal is to make sure that the latent dynamics is consistent with the encoded trajectory.	Reply	I-Reply	2
Figure 1 clearly shows the relation/difference between the evolution of the system in the latent space and the evolution of the encoded observations.	Reply	I-Reply	2
Finally, for curvature, the goal is to learn a latent space that is suitable for LLC algorithms.	Reply	I-Reply	2
As stated by the reviewer, the main motivation of the curvature term is to ensure that LLC algorithms, such as iLQR, work well.	Reply	I-Reply	2
When the curvature is low, the size of the neighbourhood in which the local linearity assumption holds is large, and thus, LLC algorithms work better.	Reply	I-Reply	2
A more detailed discussion of the relationship between curvature and the performance of LLC algorithms can be found in Appendix A.5, in particular, see Lemma 4.	Reply	I-Reply	2
[line_break_token][line_break_token]3) From Lemma 3, we see that \lambda_p and \lambda_c should be of the same order.	Reply	O	0
In practice, we used this observation and optimized the hyper-parameters \lambda_p, \lambda_c, and \lambda_cur by standard grid-search.	Reply	B-Reply	4
[line_break_token][line_break_token]‚ÄúMinor: (5) may contain some typos‚Äù[line_break_token]You are right.	Reply	O	0
There is a typo in (5) on the 2-norm.	Reply	B-Reply	3
We will fix it in the final version of the paper.	Reply	I-Reply	3

The authors propose an extension of cycle-consistent adversarial adaptation methods in order to tackle domain adaptation in settings where a limited amount of supervised target data is available (though they also validate their model in the standard unsupervised setting as well).	Review	O	0
The method appears to be a natural generalization/extension of CycleGAN/CyCADA.	Review	O	0
It uses the ideas of the semantic consistency loss and training on adapted data from CyCADA, but "fills out" the model by applying these techniques in both directions (whereas CyCADA only applied them in the source-to-target direction).	Review	O	0
[line_break_token][line_break_token]The writing in this paper is a little awkward at times (many omitted articles such as "the" or "a'), but, with a few exceptions, it is generally easy to understand what the authors are saying.	Review	B-Review	1
They provide experiments in a variety of settings in order to validate their model, including both visual domain adaptation and speech domain adaptation.	Review	I-Review	1
The experiments show that their model is effective both in low-resource supervised adaptation settings as well as high-resource unsupervised adaptation settings.	Review	I-Review	1
An ablation study, provided in Section 4.1, helps to understand how well the various instantiations of the authors' model perform, indicating that enforcing consistency in both methods is crucial to achieving performance beyond the simple baselines.	Review	I-Review	1
[line_break_token][line_break_token]It's a little hard to understand how this method stands in comparison to existing work.	Review	I-Review	2
Table 3 helps to show that the model can scale up to the high-resource setting, but it would also be nice to see the reverse: comparisons against existing work run in the limited data setting, to better understand how much limited data negatively impacts the performance of models that weren't designed with this setting in mind.	Review	I-Review	2
[line_break_token][line_break_token]I would've also liked to see more comparisons against the simple baseline of a classifier trained exclusively on the available supervised target data, or with the source and target data together‚Äîin my experience, these baselines can prove to be surprisingly strong, and would give a better sense of how effective this paper's contributions are.	Review	O	0
This corresponds to rows 2 and 3 of Table 1, and inspection of the numbers in that table shows that the baseline performance is quite strong even relative to the proposed method, so it would be nice to see these numbers in Table 2 as well, since that table is intended to demonstrate the model's effectiveness across a variety of different domain shifts.	Review	O	0
[line_break_token][line_break_token]While it's nice that the model is experimentally validated on the speech domain, the experiment itself is not explained well.	Review	B-Review	4
The speech experiments are hard to understand‚Äîit's unclear what the various training sets are, such as "Adapted Male" or "All Data," making it hard to understand exactly what numbers should be compared.	Review	I-Review	4
Why is there no CycleGAN result for "Female + Adapted Male," or "All Data + Adapted Male," for example?	Review	I-Review	4
The paper would greatly benefit from a more careful explanation and analysis of this experimental setting.	Review	I-Review	4
[line_break_token][line_break_token]Ultimately, I think the idea is a nice generalization of previous work, and the experiments seem to indicate that the model is effective, but the limited scope of the experiments prevent me from being entirely convinced.	Review	O	0
The inclusion of additional baselines and a great deal of clarification on the speech experiments would improve the quality of this paper enormously.	Review	O	0
[line_break_token][line_break_token]---[line_break_token][line_break_token]Update: After looking over the additional revisions and experiments, I'm bumping this to a weak accept.	Review	O	0
I agree with reviewer 3 that novelty is not the greatest, but there is a useful contribution here, and the demonstration of its effectiveness on low resource settings is valuable, since in a practical setting it is usually feasible to manually label a few examples.	Review	O	0
[line_break_token][line_break_token]I'm still not convinced by the TIMIT experiments, now that I better understand them, since the F+M baseline is quite strong and very simple to run.	Review	B-Review	5
It simply doesn't seem worthwhile to introduce all of this extra machinery for such a marginal improvement, but the experiment does serve the job of at least demonstrating an improvement over existing methods.	Review	I-Review	5
Comment on ‚Äúlow-resource supervised adaptation, Table 2‚Äù:[line_break_token]To provide more baseline results on low-resource supervised adaptation, we ran additional experiments and replaced table 2 with bar plots in Figure 3.	Reply	O	0
Baselines include classifier trained on low-resource target data, and including source data, with no adaptation.	Reply	B-Reply	1
As shown in Figure 3, Augmented-Cyc algorithm outperforms FADA model and the two baselines.	Reply	I-Reply	1
[line_break_token][line_break_token]Comment on ‚Äúcomparing with existing works on low-resource unsupervised adaptation‚Äù:[line_break_token]We added experiments on low-resource unsupervised adaptation to compare with CyCADA, and the results are shown in Figure 2.	Reply	O	0
This experiment  investigates the effectiveness and robustness of using two cycle with semantic consistency enforced by auxiliary task loss, compared to CyCADA, where semantic consistency is enforced by reconstruction loss.	Reply	B-Reply	2
As shown in Figure 2, CyCADA model fails to learn a good adaptation, where target domain contains few unsupervised data.	Reply	I-Reply	2
Additionally, CyCADA model shows high instability in low-resource situation.	Reply	I-Reply	2
Our model achieves more robust and better performance.	Reply	I-Reply	2
We think this is attributed to proper use of source classifier to enforce consistency and robustness that we get by using two cycles (also shown in ablation study in Table 1).	Reply	I-Reply	2
[line_break_token][line_break_token]Comment on speech domain experiments:[line_break_token] We have edited the speech experiment section for more clarification.	Reply	O	0
To mention some, ‚ÄúAdapted Male‚Äù is changed to ‚ÄúMale-> Female‚Äù to preserve consistency in notation. ‚	Reply	O	0
ÄúAll Data‚Äù refers to ‚ÄúMale+Female‚Äù with no adaption.	Reply	B-Reply	4
CycleGAN results are added for"Female + Adapted Male," or "All Data + Adapted Male,‚Ä	Reply	I-Reply	4

This work addresses the problem of decomposing the observation acquisition from action planning in POMDPs.	Review	O	0
 Unfortunately, the paper has two major weaknesses.	Review	O	0
 First it is hindered by a confusing motivation, and the lack of clarity on the real purpose of the work is a problem throughout.	Review	O	0
Second the experiments are insufficient given current standards in the literature.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
Motivation:  The introduction suggests that the main motivation is to reduce the computational cost of treating all observations within planning (‚Äúone must establish a trade-off between optimality and tractability‚Äù), though later, different reasons are offered (‚Äúpower, processing capability, and cost constraints‚Äù).	Review	O	0
 It seems that each of these poses different constraints, and depending on which we are most concerned with, a different approximation scheme should be selected.	Review	O	0
For example, if the real concern is tractability of the POMDP solution, I don‚Äôt see why it‚Äôs not possible to just acquire all the sensor information, and afterwards decide how to approximate the tracking (this by the way is what most point-based POMDP methods effectively do).	Review	B-Review	1
 For the proposed AP^2-POMDP, possibly a more reasonable motivation is high cost of observation acquisition; a clean argument would have to be made about the class of problems for which this constraint is crucial, why cardinality of sensor is the right way to articulate this constraint.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Experimental results:  The domains selected for the experiments are too simple, given current standards in the literature.	Review	O	0
 Looking at the 1D and 2D domains is fine to illustrate specific properties of your methods.	Review	B-Review	2
 But it does not support the claim that the proposed model is more scalable than standard POMDPs.	Review	I-Review	2
 In such simple domains, why not include results for a point-based method?	Review	I-Review	2
 They should work in the 1D domain, probably also in the 2D domain.	Review	I-Review	2
 Also, the setting for the 1-D domain, with a camera in every cell, seems very artificial.	Review	I-Review	2
 First, if sensors are expensive, why put a camera in every cell?	Review	I-Review	2
 And if they are not expensive, then why do we need to reason about which sensor to use at each step?	Review	I-Review	2
 And why just read from k cameras at every step?	Review	I-Review	2
 These questions point back to the concern regarding what is the real motivation for this work.	Review	I-Review	2
 For the 2D domain, there are not even quantitative results on cumulative reward.	Review	I-Review	2
 To be convincing, the results would need to be on substantially more complex domains; there are several POMDP benchmarks that could be considered, e.g. those in the work of Kurniawati et al.	Review	I-Review	2
[line_break_token][line_break_token]Other comments:[line_break_token]-[tab_token]Assumption 1 states that the observations from sensors are mutually independent give the state and action.	Review	O	0
 Can you explain why this is reasonable?	Review	B-Review	3
 Or whether this is a strong assumption (unlikely to be met in practice)?	Review	I-Review	3
[line_break_token]-[tab_token]Some of the bounds seem like they could be very loose in practice, even (in the worse case) worse than the default bound of (R_max-R_min)/(1-\gamma).	Review	O	0
For example in Thm 3, in the case where the L1 distance between the 2 beliefs is 2, this is worse than the default bound.	Review	B-Review	4
 Did you check what is the bound for the domains in the experiments?	Review	I-Review	4
 Is it tighter than this?	Review	I-Review	4
[line_break_token]-[tab_token]A key statement is on p.8: ‚Äúthis added complexity is significantly lower than concatening the combinatorial perception actions with the planning actions‚Äù.	Review	O	0
  It is important to support this statement, ideally with both a precise complexity analysis, and with empirical results showing the lesser performance of standard point-based methods.	Review	B-Review	5
[line_break_token][line_break_token]Minor comment:[line_break_token]-[tab_token]The referencing style is broken and should be fixed, in particular proper use of Author (year) in the text.	Review	I-Review	6
[line_break_token]-[tab_token]The derivations in the top part of p.4 (Eqn 2-4 & surrounding text) are confusing, given that these apply to a standard POMDP, whereas on the previous page your present the AP^2-POMDP model.	Review	O	0
It might be better in Sec.2 to first (briefly) introduce POMDPs, with Eqn 2-4, then introduce AP^2-POMDP in Sec.3.	Review	B-Review	6
[line_break_token]-[tab_token]P.5: ‚ÄúIt is worth noting that the objective function does not explicitly depend on perception actions‚Äù.	Review	I-Review	6
This is a confusing statement; V depends on observations through b_t.	Review	I-Review	6
 The next sentence clarifies this, but it would be better to avoid the confusing statement.	Review	I-Review	6
[line_break_token]-[tab_token]Alg.2:  Add a reference beside the title (unless you claim it is new).	Review	I-Review	6
 Maybe Pineau et al.	Review	I-Review	6
2003.	Review	I-Review	6
[line_break_token]-[tab_token]P.7: ‚Äúcan be combined with any sampling and pruning method in other solvers‚Äù -> Add references for such sampling & pruning methods.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
We thank the reviewer for the thoughtful and constructive feedback.	Reply	O	0
Please find the authors‚Äô response below .	Reply	O	0
[line_break_token][line_break_token]-----Clarifying motivation[line_break_token][line_break_token]The cost of measurement acquisition and processing in terms of power, communication, and processing computations define the physical constraints on the agent‚Äôs perception.	Reply	O	0
This leads to the definition of problem 1 where we capture these constraints, similar to majority of sensor selection problems, by a cardinality constraint.	Reply	B-Reply	1
As the reviewer correctly points out, some problems may call for different constraints.	Reply	I-Reply	1
For instance, a knapsack constraint can define non-uniform cost over sensors, leading to 0.5 approximation instead of 0.667 when using greedy algorithms.	Reply	I-Reply	1
For homogenous information source, as in the simulations, uniform cost is reasonable.	Reply	I-Reply	1
For heterogenous information sources, a knapsack constraint is a better choice.	Reply	I-Reply	1
[line_break_token][line_break_token]Having defined the problem from physical constraints and demands, now the computational complexity arises from combining the selection actions with planning actions.	Reply	I-Reply	1
This complexity has motivated the proposed solver and the sentence ‚Äúone must establish a trade-off between optimality and tractability‚Äù refers to the defined problem (with cardinality constraint).	Reply	I-Reply	1
Otherwise, if there is no limitation on the number of selected sensors, as the reviewer mentioned, one can use all the measurements, leading to less uncertainty and without the complexity of selection.	Reply	I-Reply	1
[line_break_token][line_break_token]*revision* The reviewer's assessment is completely valid regarding shortcomings in explaining the motivation.	Reply	I-Reply	1
To resolve that, we edited the introduction of the paper to better convey the motivation and remove the ambiguity.	Reply	I-Reply	1
[line_break_token][line_break_token]-----Stronger empirical results[line_break_token][line_break_token]The backup step in almost all the point-based solvers are the same while the sampling and pruning steps rely on efficient heuristics.	Reply	O	0
Therefore, comparing the proposed solver that has a different back-up step and a conventional sampling and pruning would not result in the desired comparison.	Reply	B-Reply	2
We intentionally avoided to use a specific sampling method in order to keep the solver general enough such that it can be combined with any sophisticated sampling (and/or pruning) method.	Reply	I-Reply	2
[line_break_token][line_break_token]The benchmarks in Kurniawati et al.	Reply	I-Reply	2
cannot be used without significant modification since they lack perception actions.	Reply	I-Reply	2
The designed experimental scenarios are based on Satsangi et al. (	Reply	I-Reply	2
2018) and Spaan & Lima (2009) where POMDPs are used for active perception.	Reply	O	0
The authors absolutely agree that more complex and more realistic simulations will better represent the importance of the proposed solver and plan to perform more empirical analysis as part of future work on a swarm of UAVs with tracking tasks and limited communication.	Reply	B-Reply	2
[line_break_token][line_break_token]*revision* The authors included the numerical values for 2-D navigation in a new appendix.	Reply	I-Reply	2
[line_break_token][line_break_token]-----Reason behind assumption 1[line_break_token][line_break_token]Due to assumption 1, the sensors‚Äô measurements only depend on the state and action, therefore eliminating the sensors effect on each other‚Äôs measurement, e.g., through noise from magnetic fields.	Reply	O	0
This assumption is realistic in many practical settings, especially if they are not in small scales, e.g., micro size.	Reply	B-Reply	3
[line_break_token][line_break_token]-----Tightness of bounds[line_break_token][line_break_token]The theoretical analysis for finding the bound follows a similar procedure as that of the classical analysis of point-based methods.	Reply	O	0
The only difference is that the distance appearing between belief points is from the difference between greedy vs. optimal approach, not from the density of points.	Reply	B-Reply	4
As part of future work, the authors aim to refine the bound for special classes of measurement models, e.g., Gaussian measurements with bounded variance.	Reply	I-Reply	4
[line_break_token][line_break_token]-----Supporting computational advantage[line_break_token][line_break_token]*revision* To support the statement ‚Äúthis added complexity is significantly lower than concatenating the combinatorial perception actions with the planning actions‚Äù, the authors added an appendix detailing the complexity and its comparison with standard methods.	Reply	O	0
[line_break_token][line_break_token]-----Minor comments[line_break_token][line_break_token]*revision* The manuscript is revised according to the minor comments.	Reply	O	0

Summary of paper: Builds off work from Trinh et al. (	Review	O	0
2018) that proposed a semi-supervising learning model that combined the main task with an auxiliary task of predicting tokens in the input sequence.	Review	O	0
This paper proposes improving this two-task setup by splitting the hidden representations into two subsets, one for both tasks and one for only the main task.	Review	O	0
They compare against the baseline of Trinh et al. (	Review	O	0
2018), and find small improvements in performance.	Review	O	0
[line_break_token][line_break_token]At it's core, this paper is simply trying to improve multi-task learning.	Review	O	0
Despite the heavy focus on the work of Trinh et al. (	Review	O	0
2018),  fundamentally, what the paper is trying to do is: given multiple tasks, figure out how to effectively model the tasks such that information is shared but the tasks don't harm each other.	Review	O	0
In other words, the authors mark this paper as a semi-supervised learning paper, but it is more of standard multi-task learning setup.	Review	B-Review	1
[line_break_token][line_break_token]However, multi-task learning (MTL) is never once mentioned in the paper.	Review	O	0
This is surprising given that there has been a wealth of literature devoted to tackling exactly this type of problem.	Review	O	0
For example, the usage of different representations for different tasks is a standard trick in MTL (multiple heads).	Review	O	0
The model is also reminiscent of Progressive Networks [1], with one representation feeding to other tasks.	Review	O	0
Unfortunately, the authors do not cite any relevant MTL work, which is a big omission.	Review	O	0
There are also no other MTL baselines in the experiments section.	Review	B-Review	2
[line_break_token][line_break_token]Even when ignoring the previous issue, the gains from the proposed method are consistently small, and explainable by noise.	Review	I-Review	3
Furthermore, in the one experiment that there seems be a nontrivial difference (CIFAR), Table 4 shows that the model is extremely sensitive to the sharing percentage (going from 50% to 30% drops accuracy by 2.1%).	Review	I-Review	4
[line_break_token][line_break_token]To conclude, the authors miss critical discussion and comparison of prior works in MTL, and the experimental results are unconvincing.	Review	I-Review	5
[line_break_token][line_break_token][1] Progressive Neural Networks (<a href="https://arxiv.org/abs/1606.04671)" target="_blank" rel="nofollow">https://arxiv.org/abs/1606.04671)</a>	Review	O	0
We thank the reviewer for taking the time to read our paper in detail, and for providing such extensive comments.	Reply	O	0
We respond to each of the reviewer‚Äôs points below:[line_break_token][line_break_token]> ...the authors mark this paper as a semi-supervised learning paper, but it is more of standard multi-task learning setup.	Reply	O	0
[line_break_token][line_break_token]Though we do admit that our method shares some common features with multi-task learning, we‚Äôd argue that it‚Äôs more of semi-supervised learning method.	Reply	B-Reply	1
First, it only has a supervised and an unsupervised task, and we only care about the supervised task‚Äôs performance.	Reply	I-Reply	1
Second, in Table 5 of the work of Trinh et al. (	Reply	I-Reply	1
2018), the authors also quantitatively study the influence of the unsupervised task over the supervised task by counting the number of reconstructions.	Reply	I-Reply	1
[line_break_token][line_break_token]>  ...There are also no other MTL baselines in the experiments section.	Reply	O	0
[line_break_token][line_break_token]Following the definition of multi-task learning by the reviewer, the method of Trinh et al. (	Reply	B-Reply	2
2018) is a multi-task learning baseline already -- the RNN model learns to do supervised and unsupervised tasks.	Reply	I-Reply	2
[line_break_token][line_break_token]> ...the gains from the proposed method are consistently small, and explainable by noise.	Reply	O	0
[line_break_token][line_break_token]Though the improvements are not mind-blowing, we believe the consistency at which it occurs (along with our analysis) suggests that dividing and specializing the space indeed is helping the supervised task.	Reply	B-Reply	3
[line_break_token][line_break_token]> Furthermore, in the one experiment that there seems be a nontrivial difference (CIFAR), Table 4 shows that the model is extremely sensitive to the sharing percentage (going from 50% to 30% drops accuracy by 2.1%).	Reply	O	0
[line_break_token][line_break_token]We‚Äôd argue that this sharing percentage is a hyper-parameter.	Reply	B-Reply	4
The sensitiveness shows the importance of the sharing proportion control mechanism.	Reply	I-Reply	4

In this paper, the authors present a method for learning a transformation between two distributions and applying it to an out-of-sample extrapolating distribution.	Review	O	0
The method relies on an autoencoder, instead of a GAN, to which neuron-editing is applied.	Review	O	0
A transformation of one of the inner layer is learned using the source and target distributions is estimated and then applied to the extrapolating distribution.	Review	O	0
This leads to better reconstructions than GAN approaches as judged by some visualizations and results.	Review	O	0
The method is also applied to biological datasets and some improvement is shown (accuracy increases on specific prediction tasks).	Review	O	0
[line_break_token][line_break_token]The idea of applying neuron-editing to an autoencoder is pretty interesting.	Review	O	0
It's a simple manipulation that makes a lot of sense and judging by the image transformation examples works well.	Review	O	0
This method also numerically greatly outperforms others on the CelebA extrapolation task so the extrapolation is believable, even though more examples in the appendix would be good.	Review	O	0
The motivation of applying the method to medical data to correct for instrument variability is also very interesting.	Review	O	0
[line_break_token][line_break_token]However I felt that I could not fully see the benefit of the application for medical data because the area, task, datasets etc are not well introduced.	Review	B-Review	1
I think the datasets should be explained better, and examples of the images should be given.	Review	I-Review	1
I understand the gist of Figure 4 but it's not well explained and I do not see why these dimensions were picked.	Review	I-Review	1
I think there is more work to do there.	Review	I-Review	1
I think a more careful introduction to the field, with explanations of the data, why deep methods are applicable there, what people have tried etc are necessary.	Review	I-Review	1
[line_break_token][line_break_token]Also all of the tables in the paper with classification tasks should have sections in the appendix to explain everything about those tasks.	Review	I-Review	2
In general, it seems the main weakness of the paper is in exposing the information/writing.	Review	I-Review	2
[line_break_token][line_break_token]Smaller points:[line_break_token]In section 2, source, target and extrapolation distributions are not introduced properly.	Review	O	0
In equation 1 and the text around it, it's hard to tell that each dimension is edited independently without a couple of reads.	Review	B-Review	3
[line_break_token]" biologicl batch correction" page 6[line_break_token]I think the second paragraph in page 4 ("To apply the learned...") is missing a sentence in the middle about the actual editing step.	Review	I-Review	4
[line_break_token][line_break_token]Perhaps more can be said about multiple extrapolation datasets (measurements from different dates instead of only two), if possible/available.	Review	I-Review	5
eviewer#2, we thank you for the recommendation to accept our paper and are grateful for the time and effort in carefully reading it!	Reply	O	0
We are glad you are able to appreciate the contribution it would make to the discussion regarding generative modeling.	Reply	B-Reply	1
We thank you for your one major critique regarding the clarity of the biological applications.	Reply	I-Reply	1
We have made this explanation much more comprehensive in our revision and will gladly continue to improve it as we receive recommendations.	Reply	I-Reply	1
We have explained more about the particular mass cytometry datasets, the task of batch correction  itself, the most pressing computational problems of existing approaches, and why we believe deep learning is an appropriate tool.	Reply	I-Reply	1
Specifically, we have heavily edited the entirety of Section 1 and the first several paragraphs in both Sections 3.2 and Section 3.3.	Reply	I-Reply	1
As these important applications are a key use of our technique in our actual work, we want to make sure they are motivated and described as clearly as possible!	Reply	I-Reply	1
[line_break_token][line_break_token]To the small points:[line_break_token]‚Äî Specifically, to the figure you mention, Figure 4, this visualization was chosen for a few main reasons.	Reply	O	0
First, biaxial plots are a commonly used way of visualizing cellular (cytometry) data of this kind [1]. Second, viewing the raw data values is important for verifying that neuron editing‚Äôs batch-correction transformations are *biologically sensible*. For example, when defending a biological conclusion based on the batch-corrected data, this visualization would be necessary to justify why interferon-gamma values in the sample were increased (because the technical replicate spike-ins showed that batch measured artificially low interferon-gamma).	Reply	B-Reply	3
[line_break_token]‚Äî Thank you for the notes about the minor edits here and there.	Reply	O	0
[line_break_token]‚Äî The idea of extrapolating to more than just one pair is a very interesting one, and one that we think would be promising future work, that‚Äôs a great insight, which we have included in our final discussion.	Reply	O	0
[line_break_token][line_break_token]Again, thank you for your review and the help improving our manuscript!	Reply	O	0
[line_break_token][line_break_token][1] Korin, Ben, Tania Dubovik, and Asya Rolls. "	Reply	O	0
Mass cytometry analysis of immune cells in the brain."	Reply	O	0
Nature protocols 13.2 (2018): 377	Reply	O	0

The manuscript articulates a problem with earlier solutions to the Collective Matrix Factorization (CMF) problem in multi-view learning formulations and proposes a novel solution to address the issue.	Review	O	0
The concern is that current CMF schemes ignore the potential for view-specific structure or noise by implicitly assuming that structure must be shared among all views.	Review	O	0
The authors solve this problem by putting group-sparse priors on the columns of the matrices.	Review	O	0
This allows private factors that can be specific to one or even a subset of the matrices.	Review	O	0
Also note that the use of variational Bayesian learning by the authors provides a large reduction in computational complexity relative to the MAP estimates used in some of the prior literature.	Review	O	0
[line_break_token][line_break_token]I agree with the importance of the problem being addressed since, clearly, the need to accommodate view- or subset-specific structure is going to be important in many real-world problems.	Review	O	0
Also noted is the elimination of the need for tunable regularization parameters.	Review	O	0
[line_break_token][line_break_token]There are a couple of typos in the first paragraph of section 4.2 (top right of page 4).	Review	O	0
The manuscript is heavily dependent on several of its sources for implementation details of the complete algorithm.	Review	B-Review	2
This isn't a criticism, since the authors should not repeat details available elsewhere, but I think it is important to understand that this is necessitated by the complexity of the method, and this complexity is a small drawback and potentially an area for future improvement.	Review	O	0
[line_break_token][line_break_token]Another issue is that it would be valuable to see the proposed scheme compared to a wider variety of alternatives in the experimental section (mostly for context that elucidates the importance of CMF itself and therefore their improvement of it for certain applications).	Review	B-Review	3
However, given the scope of the paper in general, this is a minor point.	Review	I-Review	3
This is a joint response for both Anonymous 9dec and 75c5, since both  reviews address similar issues.	Reply	O	0
[line_break_token][line_break_token][line_break_token]We thank both reviewers for pointing out the typos, and in particular the sloppy phrase used to describe basics of VB approximation.	Reply	O	0
We have submitted a revised version that fixes these mistakes, as well as addresses the two other issues described below.	Reply	O	0
It should be out by Feb 19th.	Reply	O	0
[line_break_token][line_break_token][line_break_token]1) Regarding complexity: While several recent advances were indeed needed to derive the model, the resulting algorithm is reasonably straightforward.	Reply	O	0
To address this issue we now added more detailed description of the algorithm in the Supplementary material.	Reply	B-Reply	2
Furthermore, we will later add a link to an open source implementation in R (the documentation still needs a bit of polishing).	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]2) Regarding the scale of the experiments: The artificial data experiments are small mainly to emphasize the effects of jointly modelling multiple matrices.	Reply	O	0
Similarly to how e.g. multi-task learning helps most with small sample sizes, properly modeling the private factors is more important when (some of) the entity sets are small -- given enough data even incorrectly specified models often work reasonably well.	Reply	B-Reply	3
Having said that, scalable algorithms are needed especially in settings where we have few examples in important views (i.e. views we want to predict) and many examples for auxiliary data matrices.	Reply	I-Reply	3
[line_break_token][line_break_token]Even though scalability has not been our main focus, the recommender system application in Section 7.3 briefly illustrates the efficiency.	Reply	I-Reply	3
In the revised version we now me mention that both of the recommender system data sets are in the order of 1 million observations and the results were obtained in a few minutes on a laptop; this is comparable to the computation time of the competing convex CMF (CCMF) method for a single set of regularization parameters, but CCMF needs cross-validation over two such parameters do be used in practice.	Reply	I-Reply	3
[line_break_token][line_break_token]We have not tried the algorithm on massive collections, but we expect it could be scaled up fairly nicely with a bit of implementation effort.	Reply	I-Reply	3
The slowest part is the gradient computation that would parallelize easily, and switching to stochastic gradients would also be possible.	Reply	I-Reply	3
Note also that the time complexity of the proposed VB algorithm is effectively the same as the corresponding MAP problem: the small overhead is only due to the computation of the parameters of the diagonal covariance matrices, the updates of the mean being similar to the updates of the MAP algorithm	Reply	I-Reply	3

This paper proposed a GNN to improve an existing search based solver for 2-QBF solvers.	Review	O	0
The neural network is being used to predict the next steps in the search procedure, in this case, assignment to literals of the 2-QBF formula.	Review	O	0
Justifiably, a reinforcement learning formulation is used.	Review	O	0
I thought that the paper was very impressive.	Review	O	0
All necessary concepts were clearly introduced, the claims were very clear and thoroughly validated.	Review	O	0
Limitations of the current approach are also properly discussed.	Review	O	0
[line_break_token][line_break_token]Only comment I have is that using shallow networks with one iteration sounds not enough for a problem like 2-QBF solving.	Review	B-Review	1
I noticed that you have this exploration in the appendix, would recommend moving it to the main paper.	Review	I-Review	1
I would also have liked 2-QBF to be mentioned more explicitly in the abstract and early introduction.	Review	I-Review	1
[line_break_token][line_break_token]Minor errors:[line_break_token]"and" --&gt; "an" in Sec 1[line_break_token]"variale" --&gt; "variable" in Sec 4.2[line_break_token]Reference ?	Review	O	0
in Sec 6	Review	B-Review	2
gt; I would also have liked 2-QBF to be mentioned more explicitly in the abstract and[line_break_token]&gt; early introduction.	Reply	O	0
[line_break_token][line_break_token]We updated the paper to clearly mention 2QBF in the abstract and introduction.	Reply	B-Reply	1
We also fixed the minor errors pointed out in the review.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; Only comment I have is that using shallow networks with one iteration sounds not enough[line_break_token]&gt; for a problem like 2-QBF solving.	Reply	O	0
I noticed that you have this exploration in the[line_break_token]&gt; appendix, would recommend moving it to the main paper.	Reply	O	0
[line_break_token][line_break_token]We fully agree that, intuitively, deeper networks should be better at the task, and we were surprised that the performance-quality tradeoff turned out as it is.	Reply	B-Reply	1
We do not think that the negative result on networks with additional iterations adds actionable insights to the readers and therefore moved it to the appendix.	Reply	I-Reply	1
It is available on arXiv for interested readers	Reply	I-Reply	1

Summary[line_break_token]-------------[line_break_token]This paper proposed to improve existing meta learning algorithms in the presence of task imbalance, class imbalance, and out-of-distribution tasks.	Review	O	0
Starting from the model-agnostic meta-learning (MAML) algorithm (Finn et al.	Review	O	0
2017), to tackle task imbalance, where the number of training examples of varies across different tasks, a task-dependent learning rate decaying factor was learned to be large for large tasks and small for small tasks.	Review	O	0
In this way, the small task can benefit more from the meta-knowledge and the large task can benefit more from task-specific training.	Review	O	0
To tackle class imbalance, a class-specific scaling factor was applied to the class-specific gradient.	Review	O	0
The scaling factor was large for small class and small for large class so that different classes can be treated equally.	Review	O	0
To tackle the out-of-distribution tasks, a task-dependent variables was learned to emphasize meta-knowledge for the test task similar to training tasks.	Review	O	0
Additional model parameters are learned through variational inference.	Review	O	0
Experimental results on benchmark datasets demonstrate the proposed approach outperformed its competing alternatives.	Review	O	0
Analysis of each component confirm they work as expected.	Review	O	0
[line_break_token][line_break_token]Comments[line_break_token]---------------[line_break_token]This paper is well motivated and clearly written.	Review	O	0
The empirical evaluation also support major claims in the paper.	Review	O	0
[line_break_token][line_break_token]Can the author provide more details on the inference of the model?	Review	B-Review	1
In the likelihood term in Eq. (	Review	I-Review	1
7), the task specific parameters \theta^{\tau} was parameterized by Eq. (	Review	I-Review	1
3), which contains K iterative gradient updates.	Review	I-Review	1
How was the gradient w.r.t.	Review	I-Review	1
\theta was computed in this setting?	Review	I-Review	1
[line_break_token][line_break_token]The task-specific learning rate decaying factor was constrained to be between 0 and 1 using the function f().	Review	I-Review	2
The class-specific scaling factor made use of the SoftPlus() function, for the same purpose of scaling learning rate, why do these two different options of functions were applied?	Review	I-Review	2
[line_break_token][line_break_token]For the scaling vector of the initial parameters g(z^{\tau}), for its zero entries, the initialization of the corresponding entries in task-specific parameter \theta would be zero.	Review	I-Review	3
Would it be better to apply a linear interpolation between \theta and a randomly-initialized vector in Eq (2)?	Review	I-Review	3
[line_break_token][line_break_token]Edits after reading the author's rebuttal[line_break_token]==================================[line_break_token]The author's reply well addressed my questions.	Review	O	0
After reading other reviewers' positive comments and the author's thorough reply, I decide to increase my rating to 8: Accept.	Review	O	0
e really appreciate your constructive comments.	Reply	O	0
We respond to each comment as follows.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	3
How was the gradient w.r.t.	Reply	O	0
was computed?	Reply	O	0
[line_break_token][line_break_token]- Basically, computation of gradients w.r.t.	Reply	O	0
initial in our model is exactly the same as the original MAML framework.	Reply	B-Reply	1
Suppose that the number of inner-gradient steps is 5 and k-th inner-gradient update is denoted as a function.	Reply	I-Reply	1
Then, from the initial model parameter, we have[line_break_token][line_break_token]‚Ä¶[line_break_token][line_break_token]Thus it is trivial to compute the gradient of Loss_test w.r.t.	Reply	I-Reply	1
using the chain rule.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	I-Reply	3
Why constrain the task-specific learning rate decaying factor to a value between 0 and 1, while using softplus() that does not have such a constraint for the class-specific scaling factor?	Reply	O	0
[line_break_token][line_break_token]- Note that the task-specific learning rate decays as follows:[line_break_token][tab_token],,,, ‚Ä¶[line_break_token][tab_token][line_break_token]Without such restriction to force it between 0 and 1, the learning rate may largely diverge due to its exponential form.	Reply	O	0
[line_break_token][line_break_token]On the other hand, since the class-specific scaling factor is simply a multiplicative coefficient, there is no such restriction, except for the positivity constraint.	Reply	B-Reply	2
Thus we used softplus function to model the class-specific scaling factor.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]3.	Reply	O	0
Applying a linear interpolation between and a randomly-initialized vector in Eq (2) considering zero-entries caused by.	Reply	O	0
[line_break_token][line_break_token]- Thanks you for your insightful suggestion.	Reply	O	0
As you mentioned, applying to the shared initial parameter may set some of the initial parameters to smaller values.	Reply	B-Reply	3
However, this is not problematic, but rather beneficial since the parameters in the shared that are irrelevant for the given task need to be properly suppressed such that it does not distract the learning on the current task.	Reply	I-Reply	3
[line_break_token][line_break_token]However, the interpolation technique you mentioned, which learns to interpolate between a random weight matrix and , where is element-wise multiplication and is a random weight matrix) may have a similar effect, and we performed experimental validation of it during the rebuttal period.	Reply	I-Reply	3
[line_break_token][line_break_token]Models[tab_token][tab_token][tab_token][tab_token][tab_token]                    Omniglot[tab_token]        MNIST[tab_token][tab_token][line_break_token]Meta-SGD[tab_token][tab_token][tab_token][tab_token]                    98.38+-0.23[tab_token]90.42+-0.28[tab_token][line_break_token]Bayesian g(z) TAML + Interpolation[tab_token]    98.83+-0.08[tab_token]92.03+-0.19[tab_token][line_break_token]Bayesian g(z) TAML[tab_token][tab_token][tab_token]            98.92+-0.30[tab_token]92.06+-0.32[tab_token][line_break_token][line_break_token]The results show that Bayesian TAML with the interpolation technique (Bayesian g(z) TAML + Interpolation) have a very similar performance as the original Bayesian TAML with the masking scheme.	Reply	I-Reply	3
Thus the two techniques seem to have a similar effect, on deciding what to use from the meta-knowledge and what to forget.	Reply	I-Reply	3
[line_break_token][line_break_token]We included these results in Appendix F.	Reply	I-Reply	3

This paper introduces a new synthetic video understanding dataset, borrowing many ideas from the visual question answering dataset CLEVR.	Review	O	0
The new dataset is the first to account for all of the following fundamental aspect of videos: temporal ordering, short- and long term reasoning, and control for scene biases.	Review	O	0
Due to the inherent biases in available action recognition datasets, models that simply averages video frames do nearly as well as models that take temporal dependencies into account.	Review	O	0
In contrast, the authors show that with the proposed dataset, models without spatiotemporal reasoning largely fail.	Review	O	0
[line_break_token][line_break_token]The paper should be accepted as it addresses a major shortcoming of all existing video understanding datasets.	Review	O	0
It does a good job at summarizing the deficiencies in existing datasets, clearly motivating the need for a new dataset.	Review	O	0
The claims are backed up with solid experiments, ablating models and data parameters adequately.	Review	O	0
It is mostly well-written (except for section 4 which would benefit from extensive proofreading) and does a good job at covering relevant work.	Review	O	0
One drawback is of course the synthetic nature and limited domain of objects and actions.	Review	B-Review	6
On the other hand, this makes the setup highly controllable and reliable.	Review	I-Review	6
I like the fact that each task comes both with both static and moving camera.	Review	I-Review	6
[line_break_token][line_break_token]Improvements and Questions:[line_break_token]Some relevant datasets are missing.	Review	O	0
For example, the Moving MNIST and Robot Pushing datasets could be added to Table 1.	Review	B-Review	1
[line_break_token][line_break_token]I suggest having a train / validation / test split (like CLEVR), rather than just a train and validation split.	Review	I-Review	2
[line_break_token][line_break_token]In particular for Task 3 more frames seem to give dramatic improvement.	Review	I-Review	3
Why did you not run with more than 64 frames?	Review	I-Review	3
[line_break_token][line_break_token]Did you consider downsampling the videos to allow running on all the frames?	Review	I-Review	4
[line_break_token][line_break_token]I‚Äôm missing details on the resolution of the generated videos?	Review	I-Review	5
[line_break_token]	Review	O	0
hank you for your time and insightful feedback!	Reply	O	0
We have incorporated the changes into the revised paper, and address the issues in detail here:[line_break_token][line_break_token]- Additional dataset comparisons: Thanks for pointing those out!	Reply	O	0
We have added additional datasets to Table 1.	Reply	B-Reply	1
[line_break_token][line_break_token]- Train-Val-Test set: We will add that to the code release and update the final paper accordingly.	Reply	O	0
[line_break_token][line_break_token]- Running with more frames, downsampling videos, resolution: That‚Äôs a great point!	Reply	O	0
CATER videos are rendered at 320x240px (updated in the paper) to be comparable to existing benchmarks, so standard baselines can be applied directly without significant redesign.	Reply	B-Reply	3
64 frames were the maximum we were able to fit in the GPU memory (at the extreme batch size of 1 per 12GB GPU), so scaling the number of frames beyond that was not possible given our current GPU resources.	Reply	I-Reply	3
While reducing the frame size to fit all 300 frames might be possible, it would require redesigning and tuning the network architectures for the baselines since many hyper-parameters (kernel sizes, number of layers etc) would change for the super low resolution videos.	Reply	I-Reply	4
Perhaps more importantly,  we believe our analysis suggests that in order to enable truly long-term temporal reasoning, one should rely on representations that more efficiently maintain stateful memory, such as recurrent networks / LSTMs.	Reply	I-Reply	4
 	Reply	I-Reply	1

The paper proposes to add a regularizing term to the objective function which penalizes the estimation of distributions with small entropy.	Review	O	0
It is one of these small tricks that were tried out by various groups even though only few people mention it in publications because the changes in performance are small and the additional hyperparameter makes it unattractive.	Review	O	0
This is also reflected in the paper here, as the improvements are very small compared to the baselines and usually vanish if more care is taking w.r.t.	Review	O	0
traditional regularization approaches.	Review	O	0
[line_break_token][line_break_token]Further remarks:[line_break_token][line_break_token]- The evaluation is done on a broad spectrum of tasks, but the selections of the baseline systems is questionable.	Review	O	0
Especially on WSJ, there is no good reason to take an attention based seq2seq model but not also a network trained in a hybrid fashion or with CTC.	Review	B-Review	1
Especially the CTC experiment would have been of great interest since the criterion tends to favor sharp probabilities.	Review	I-Review	1
[line_break_token][line_break_token]- A theoretical perspective on the convergence is not well established and a proper justification why this is should be able to improve neural network training is missing (except for the norms of the gradients on MNIST).	Review	O	0
 If the argument is that gradients saturate too quickly if probabilities go too high then I would like to see an experiment with the squared error criterion as comparison, where this effect is not that large.	Review	O	0
[line_break_token][line_break_token]In total I appreciate the work and broad evaluation but would suggest to include this method in a larger comparison paper that describes several of these tricks.	Review	O	0
The paper is well written and certainly correct, and the required scope is clearly limited within a workshop.	Review	O	0
Yet I would like to see some of the points here addressed before recommending acceptance.	Review	O	0
Thank you for the careful review and helpful feedback.	Reply	O	0
[line_break_token][line_break_token]1) Yes, we agree that in some cases, more competitive baselines exist.	Reply	O	0
There was a tradeoff in implementing state-of-the-art baselines with all of the bells and whistles and trying the technique across multiple domains and different model architectures.	Reply	B-Reply	1
For this workshop submission, we decided it would of more interest to focus on broadly evaluating the technique, but we see the merit of the other approach too.	Reply	I-Reply	1
[line_break_token][line_break_token]Preliminary results of label smoothing with the CTC objective yielded a small improvement when no language model was used.	Reply	I-Reply	1
We smoothed all non-blank tokens at all timesteps using an auxiliary cost function.	Reply	I-Reply	1
However, note that unlike the seq2seq networks that directly output next-token predictions, CTC comes with its own loss function and it is not obvious how to best apply the smoothing - Do you force a smooth distribution of the non-blank tokens?	Reply	I-Reply	1
Do you smooth the blank?	Reply	I-Reply	1
Do you extract alignments and only smooth the emission locations, or you indiscriminately smooth all locations?	Reply	I-Reply	1
Furthermore, CTC needs a language model for optimal decoding.	Reply	I-Reply	1
This will need to be tuned together with smoothing.	Reply	I-Reply	1
Exploring CTC and label smoothing is thus an interesting topic, but may be of more interest to a speech focused venue, and treating it thoroughly exceeds the 3-page limitation of the workshop.	Reply	I-Reply	1
[line_break_token][line_break_token]2) We agree that the theoretical justification is mostly speculative (our primary contribution is the extensive empirical evaluation), however, as you suggest, we hypothesize that it is due to gradients saturating.	Reply	O	0
We notice that once an example is correctly predicted, the only way to increase the log likelihood is to make the prediction sharper.	Reply	B-Reply	2
Hence the outputs become uncalibrated and unless capacity is controlled in some way, the network will put very sharp distributions on its predictions.	Reply	I-Reply	2
These regularizers prevent this behavior.	Reply	I-Reply	2
Moreover, the Inception paper notes that the gradient vanishes on confident correctly predicted samples.	Reply	I-Reply	2
This does not happen with label smoothing and the confidence penalty, which means that we do get some training signal for the lower layers even on correct predictions.	Reply	I-Reply	2
This may improve data efficiency when doing multiple epochs (normally during the later passes only the few samples that the net doesn‚Äôt get confidently have any influence).	Reply	I-Reply	2
This is similar to the trick from Yann LeCun‚Äôs ‚ÄúEfficient Backprop‚Äù in which the hyperbolic tangent was used on the output of the net, but it was scaled to have a range of [-1.1, 1.1], while the targets were +-1.	Reply	I-Reply	2
Thus the net was never driven into saturation.	Reply	I-Reply	2
[line_break_token][line_break_token]Can you clarify the experiment you're suggesting to test this?	Reply	I-Reply	2
Do you mean a regression task or classification with sigmoid outputs and L2 loss?	Reply	I-Reply	2
[line_break_token][line_break_token]A second point is that for misclassified examples, the network can get large gradients which may slow training.	Reply	I-Reply	2
The confidence penalty would encourage the model to place mass on all classes, which would reduce the norm of these gradients, which is confirmed in the plot of the gradient norm.	Reply	I-Reply	2
[line_break_token][line_break_token]Lastly, we can interpret our approach as a regularizer encouraging the predictive distribution to be close to uniform.	Reply	I-Reply	2
So, when the model has little evidence it is regularized to the uniform, however, when sufficient evidence is accumulated, the predictive distribution matches the data.	Reply	I-Reply	2
[line_break_token]	Reply	O	0

The paper proposes a new evaluation platform for what they define 'useful' general AI and the desired characteristics for this kind of system.	Review	O	0
[line_break_token][line_break_token]Pro:[line_break_token](Attempts to) Tackle a very important problem, that has yet to be properly formalized or agreed on by the general community.	Review	O	0
 [line_break_token]It's in line with other efforts, such as openai.com/blog/universe, gvgai.net, github.com/deepmind/lab, to bring forward new and diverse tasks for the community to play with.	Review	O	0
This ultimately pushes us to develop more general learning algorithms that indeed need to "learn to learn" or learn to adapt to different, but related tasks.	Review	O	0
I think that's something that has been more and more important.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]The major problem I have with paper and framework, stems not necessarily from the tasks themselves, but from the identified desiderata.	Review	O	0
It seems to be <very> natural language/text focused.	Review	O	0
This is an on-going debate whether or not that is a crucial component in the development of general AI and how we will interact with AI.	Review	B-Review	1
It seems to me, that most of the effort -- at least computationally -- would be spent modelling the particular structure present in text-like inputs/data and that automatically shifts the focus away from what we should be doing, or what the AIs should be trying to figure out which is more complex tasks, more planning and optimization challenging scenarios.	Review	I-Review	1
[line_break_token]Which brings me to the second point.	Review	I-Review	2
Say you believe in the desiderata outline, the tasks seem to match what was highlighted in the agenda, but the level of complexity it's relatively low.	Review	I-Review	2
That's not to say that these are simple tasks for our learning algorithms to pick up, just the complexity doesn't lie in the task per se, but trying to model the language/syntax.	Review	I-Review	2
I fail to see what succeeding on these tasks, say, in general, about now taking this system and applying it to optimizing energy consumption, or recognizing emotions, or even something domain-related like dialogue systems.	Review	I-Review	2
[line_break_token][line_break_token]To sum: I think the paper addresses a very real problem and, as I said previously, I don't think we don't have the/a right answer or even a satisfactory answer at this point in time.	Review	O	0
I do think though the framework proposed is too limited in scope to claim generality.	Review	O	0
That being said, it might still be 'useful' -- if you agree with the proposed desiderata, it seems like a sensible set of tasks to try out.	Review	O	0
 [line_break_token][line_break_token] [line_break_token]  	Review	O	0
Thanks for your interesting comments.	Reply	O	0
We welcome other views on what are the first skills to focus on in the development of general AI, and we hope our position paper, if published, will stir further discussion of this kind.	Reply	O	0
[line_break_token][line_break_token]Our reason to focus on language is two-fold.	Reply	B-Reply	1
First, we find it hard to conceive that an AI could be useful to human beings if we were not able to communicate with it (to give it instructions and teach it new skills).	Reply	I-Reply	1
Language is by far the easiest and most powerful communication tool that humans can use.	Reply	I-Reply	1
Second, while our tasks are superficially linguistic in nature, for a system to learn how to handle them from scratch would require very powerful learning to learn capabilities (discovering that certain recurrent sequences are meaningful and thus they should be memorized even in the absence of specific reward, the ability to combine skills learned in simpler tasks in order to address more advanced tasks, the ability to find systematic correspondences between signs--the regexps--and their denotation--the strings, etc.).	Reply	I-Reply	1
The minimal setup we are considering should allow researchers to focus on such challenges, rather than on large-scale/noisy data processing issues.	Reply	I-Reply	1
[line_break_token][line_break_token]We are definitely not claiming that a system trained on the specific set of CommAI-mini tasks would then be ready to go out in the world and tackle all sorts of advanced tasks, but we realistically think that a learner that was able to solve these tasks without any ad-hoc hand-coded knowledge would be so general that it should be possible to train it, e.g., to have more general conversations with humans.	Reply	I-Reply	2
Next, the conversational and linguistic skills could be exploited to teach the machine about the domains of interest (e.g., by instructing the machine to study the Wikipedia), and so on and so forth.	Reply	I-Reply	2
We recognize, of course, that we are not there, yet, but we believe that this is an avenue that is worth exploring.	Reply	I-Reply	2
[line_break_token][line_break_token]GoodAI recently announced a challenge based on our CommAI-mini tasks.	Reply	I-Reply	2
We will thus soon be able to ascertain whether there are systems that can solve them, and whether such systems can then scale up to tasks in other domains.	Reply	I-Reply	2

 This paper proposes a novel idea of outputting a quantum state that represents a complete cost landscape of all parameters for a given binary neural network, by constructing a quantum binary neural network (QBNN).	Review	O	0
And then the landscape state is utilized to training the neural network by using the standard quantum amplitude amplification method.	Review	O	0
  [line_break_token][line_break_token]Although this idea is interesting, I trend to reject this submission as I think its presentation is unclear and the technical detail is a little difficult to follow.	Review	O	0
So, the correctness and soundness of this work is difficult to verify.	Review	O	0
I urge the authors to revise their draft to provide more and clearer technical details.	Review	O	0
[line_break_token][line_break_token]Detailed comments and questions:[line_break_token][line_break_token]Could the authors further point out that what the scope of the binary features are, {0, 1} or {-1, +1}?	Review	O	0
To my understanding, it should be {-1, +1}, or the corresponding variables are always +1.	Review	B-Review	1
In addition, the construction of the ‚Äúmultiplying values by binary weights‚Äù module implies that the value should take -1 or +1, rather than 0 or 1.	Review	I-Review	1
However, at the bottom of page 5, the authors claim that the binary values take +1 and 0.	Review	I-Review	1
Could the authors clearly explain the term ‚Äúparameter‚Äù and ‚Äúvalue‚Äù?	Review	I-Review	1
[line_break_token] [line_break_token]Could the author further explain how to construct the majority activation function?	Review	O	0
[line_break_token]In the part of ‚Äúcalculating accuracy‚Äù, the authors mention that ‚Äúrunning the QBNN with the weights in superposition for each point in the training set separately‚Äù and ‚Äúthere are N qubits containing the prediction of the QBNN‚Äù.	Review	B-Review	5
To my understanding, there are 3 qubits representing the 8 weights, several qubits representing the input values, and N qubits representing the predictions.	Review	I-Review	5
But how to construct the final landscape state to be optimized with these qubits?	Review	I-Review	5
[line_break_token] [line_break_token]Could the author explain intuitively the main idea of the amplitude amplification method?	Review	O	0
Specifically, what is the relation between the qubits representing parameters and the qubits presenting prediction results?	Review	B-Review	3
[line_break_token] [line_break_token]During the amplitude amplification process, the probabilities change periodically.	Review	O	0
How to select the best number of steps k in advanced if we do not known the best parameter?	Review	B-Review	4
Or how to judge if the training is success?	Review	I-Review	4
[line_break_token] [line_break_token]Overall speaking, I think this paper is interesting.	Review	O	0
However, the presentation is unclear and I suggest the authors to revise their draft by providing more technical details.	Review	O	0
We thank the reviewer for recognising the work as novel and interesting and for their constructive comments.	Reply	O	0
We have incorporated these into the new version of the paper.	Reply	O	0
A detailed response to the reviews questions is included below.	Reply	O	0
[line_break_token]We acknowledge that verifying the soundness and correctness of a paper is challenging if the paper is a little difficult to follow.	Reply	O	0
We strive to create a paper that is very well written and easy to understand for a wide audience.	Reply	O	0
We have altered the paper to include more technical details and improve the presentation as requested by the reviewer.	Reply	O	0
We thank the reviewer for their comments and believe the paper is now easier to read and stronger as a result of this feedback.	Reply	O	0
 [line_break_token][line_break_token]The qubits are always either in the state |1> or the state |0>, or in superpositions of the two.	Reply	O	0
What these represent changes depending on context.	Reply	B-Reply	1
Most of the time, these represent the numerical values +1/-1 respectively.	Reply	I-Reply	1
The only exception is the register of predictions where qubit states |1>,|0> then represent correct and incorrect classifications respectfully.	Reply	O	0
When representing hyper-parameters, the state |1> and |0> represent the existence, or lack of, a connection within the architecture of the NN.	Reply	O	0
We have amended this in the paper for clarity.	Reply	B-Reply	1
Otherwise they are simply +1/-1.	Reply	I-Reply	1
[line_break_token]The majority activation function simply uses controlled-gates to count the number of 1‚Äôs in a set of inputs to determine if they are in the majority and our quantum circuit does the same.	Reply	I-Reply	2
Intuitively the controlled gates are not unlike AND statements and IF statements.	Reply	I-Reply	2
E.g. if value x and value y are 1 then value z is 1.	Reply	I-Reply	2
 We have given an explicit circuit diagram showing a full quantum neuron explaining every operation and showing what the activation function looks like as a quantum circuit (see figure 2).	Reply	I-Reply	2
[line_break_token]We have made significant amendments to clarify this accuracy calculating issue.	Reply	I-Reply	5
The QBNN circuit applies only for a single datapoint, but is reversible as quantum circuits always are.	Reply	I-Reply	5
Hence the QBNN is applied for datapoint 1, its valued stored onto one qubit in the register and then the other qubits are reset by applying the inverse circuit which is simply the same circuit in reverse order.	Reply	I-Reply	5
We then apply the QBNN for datapoint 2 and store the value in register qubit 2 and so on until all the points have been processed.	Reply	I-Reply	5
This process is easily parallelised given a larger quantum computer and is really just a (common) workaround for small qubit numbers.	Reply	I-Reply	5
[line_break_token]Our end result is 8 weight qubits (one for each binary parameter) and 8 prediction qubits (one for each data point).	Reply	I-Reply	5
This is the landscape state.	Reply	I-Reply	5
The key to this entire process is that these two sets of qubits are quantum entangled.	Reply	I-Reply	5
We use quantum amplitude amplification to search the entire landscape state for the subspace where the 8 prediction qubits are all in state 1 (correctly classified) and then measure out the entire set of 16 qubits.	Reply	I-Reply	5
If the search was a success, the prediction qubits will indeed all be in the state  |1> and, due to entanglement, the weight qubits will themselves be measured in the state that corresponds to this 100% accuracy.	Reply	O	0
[line_break_token]In simpler terms, the QBNN is simply a box that takes in an empty register and a set of weights and outputs the accuracy of each data point onto the register and returns the weights.	Reply	B-Reply	5
Its quantum nature allows a superposition of all possible set of weights to be a valid input and makes its output a superposition of all possible weights entangled with their accuracies.	Reply	I-Reply	5
This is the landscape.	Reply	I-Reply	5
[line_break_token]Searching the landscape for k is an open problem and current approaches use heuristics to give the best results.	Reply	I-Reply	4
However, the proposed approach does not need to find the optimal value of k but rather a value that give a high probability of success.	Reply	I-Reply	4

This paper aims to address the problem of lacking sufficient demonstrations in inverse reinforcement learning (IRL) problems.	Review	O	0
They propose to take a meta learning approach, in which a set of i.i.d.	Review	O	0
IRL tasks are provided to the learner and the learner aims to learn a strategy to quickly recover a good reward function for a new task that is assumed to be sampled from the same task distribution.	Review	O	0
Particularly, they adopt the gradient-based meta learning algorithm, MAML, and the maximal entropy (MaxEnt) IRL framework, and derive the required meta gradient expression for parameter update.	Review	O	0
The proposed algorithm is evaluated on a synthetic grid-world problem, SpriteWorld.	Review	O	0
The experimental results suggest the proposed algorithm can learn to mimic the optimal policy under the true reward function that is unknown to the learner.	Review	O	0
[line_break_token][line_break_token]Strengths: [line_break_token][line_break_token]1) The use of meta learning to improve sample efficiency of IRL is a good idea.	Review	O	0
[line_break_token]2) The combination of MAML and MaxEnt IRL is new to my knowledge.	Review	O	0
[line_break_token]3) Providing the gradient expression is useful, which is the main technical contribution of this paper. (	Review	O	0
But it needs to be corrected; see below.)	Review	O	0
[line_break_token]4) The paper is well motivated and clearly written "in a high level" (see below).	Review	O	0
[line_break_token][line_break_token]Weakness: [line_break_token][line_break_token]1) The derivation of (5) assumes the problem is tabular, and the State-Visitations-Policy procedure assumes the dynamics/transition of the MDP is known.	Review	O	0
These two assumption are rather strong and therefore should be made explicitly in the problem definition in Section 3.	Review	B-Review	1
[line_break_token][line_break_token]2)  Equation (8) is WRONG.	Review	O	0
The direction of the derivation takes is correct, but the final expression is incorrect.	Review	B-Review	2
This is mostly because of the careless use of notation in derivation on p 15 in the appendix (the last equation), in which the subscript i is missed for the second term.	Review	I-Review	2
The correct expression of (8) should have a rightmost term in the form  (\partial_\theta r_\theta) D  (\partial_\theta r_\theta)^T, where D is a diagonal matrix that contains \partial_{r_i} (\E_{\tau} [ \mu_\tau])_i and i is in 1,...,|S||A|. [line_break_token][line_break_token]3) Comparison with imitation learning and missing details of the experiments.	Review	O	0
[line_break_token]a) The paper assumes the expert is produced by the MaxEnt model.	Review	B-Review	3
In the experiments, it is unclear whether this is true or not, as the information about the demonstration and the true reward is not provided.	Review	I-Review	3
[line_break_token]b) While the experimental results suggest the algorithm can recover the similar performance to the optimal policy of the true reward function, whether this observation can generalize outside the current synthetic environment is unclear to me.	Review	O	0
In imitation learning, it is known that the expert policy is often sub-optimal, and therefore the goal in imitation learning is mostly only to achieve expert-level performance.	Review	B-Review	3
Given this, the way this paper evaluate the performance is misleading and improper to me, which leads to an overstatement of the benefits of the algorithm.	Review	I-Review	3
[line_break_token]c) It would be interesting to compare the current approach with, e.g., the policy-based supervised learning approach to imitation learning (i.e. behavior cloning).	Review	O	0
[line_break_token][line_break_token]4) The rigorousness in technicality needs to be improved.	Review	O	0
While the paper is well structured, the writing at the mathematical level is careless, which leads to ambiguities and mistakes (though one might be able to work out the right formula after going through the details of the entire paper).	Review	B-Review	4
Below I list a few points.	Review	I-Review	4
[line_break_token]    a) The meta-training set {T_i; i=1,...,N} and the meta-test set {T_j; i=1,...,M} seems to overload the notation.	Review	I-Review	4
I suppose this is unintentional but it may appear that the two sets share the first T_1,.., T_M tasks, e.g., when N>=M, instead of being disjoint.	Review	O	0
[line_break_token]    b) The set over which the summation is performed in (4) is unclear; alpha in (4) is not defined, though I guess it's a positive step size.	Review	O	0
[line_break_token]    c) On p4, "we can view this problem as aiming to learn a prior over the intentions of human demonstrators" is an overstatement to me.	Review	O	0
At best, this algorithm learns a prior over rewards for solving maximal entropy IRL, not intention.	Review	B-Review	4
And the experiment results do not corroborate  the statement about "human" intention.	Review	I-Review	4
[line_break_token]    d) On p4,  "since the space of relevant reward functions is much smaller than the space of all possible rewards deÔ¨Ånable on the raw observations" needs to be justified.	Review	O	0
This may not be true in general, e.g., learning the set of relevant functions may require a larger space than learning the reward functions.	Review	B-Review	4
[line_break_token]    e) The authors call \mu_\tau the "state" visitation, but this is rather confusing, as it is the visiting frequency of state and action (which is only made clear late in the appendix).	Review	O	0
[line_break_token]    f) On p5, it writes "... taking a small number of gradient steps on a few demonstrations from given task leads" But the proposed algorithm actually only takes "one" gradient step in training.	Review	O	0
[line_break_token]    g) The convention of derivatives used in the appendix is the transpose of the one used in the main paper.	Review	O	0
[line_break_token][line_break_token]Minor points: [line_break_token]1) typo in (2) [line_break_token]2) p_\phi is not defined, L_{IRL} is not defined, though the definition of both can be guessed.	Review	B-Review	5
[line_break_token]3) T^{tr} seems to be typo in (11)[line_break_token]4) A short derivation of (2) in the Appendix would be helpful.	Review	I-Review	5
[line_break_token][line_break_token]	Review	O	0
We thank the reviewer for their comprehensive review.	Reply	O	0
We have addressed the clarification required by the reviewer.	Reply	O	0
We have also requested some important clarifications on certain comments made by the reviewer.	Reply	O	0
[line_break_token][line_break_token]‚ÄúThe paper assumes the expert is produced by the MaxEnt model.	Reply	O	0
‚Äù[line_break_token][line_break_token]We have made the MaxEnt modeling assumption more explicit in the paper (see page 3).	Reply	O	0
In the IRL literature, the MaxEnt model is a standard assumption (Ziebart et al.	Reply	B-Reply	3
2008, Levine et al.	Reply	I-Reply	3
2012, Huang et al.	Reply	I-Reply	3
2014, Ho et al.	Reply	I-Reply	3
2016, Finn et al.	Reply	I-Reply	3
2016, Fu et al.	Reply	I-Reply	3
2017) as it allows for sub-optimal demonstrations and has a connection to maximum likelihood estimation.	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúIn imitation learning, it is known that the expert policy is often sub-optimal, and therefore the goal in imitation learning is mostly only to achieve expert-level performance.	Reply	O	0
Given this, the way this paper evaluate the performance is misleading and improper to me, which leads to an overstatement of the benefits of the algorithm.	Reply	O	0
‚Äù[line_break_token][line_break_token]Can you provide details on how you believe the evaluation should be done?	Reply	O	0
Using value difference to evaluate the quality of the rewards follows prior work in inverse reinforcement learning (Levine et al.	Reply	B-Reply	3
NIPS '11, Wulfmeier et al, 2016, Brown et al.	Reply	I-Reply	3
AAAI 2018), and therefore seemed like the most appropriate evaluation metric.	Reply	I-Reply	3
Value difference measures the difference between the learned policy‚Äôs performance and the expert, which seems to be a good measure of whether the policy achieves expert-level performance.	Reply	I-Reply	3
We would be happy to add some other metric that you might recommend, if you have specific metrics in mind.	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúEquation (8)...‚Äú[line_break_token][line_break_token]We have fixed this.	Reply	O	0
You are correct that there is a missing index over i that was dropped by mistake in the appendix.	Reply	B-Reply	2
Thank you for pointing that out.	Reply	I-Reply	2
[line_break_token][line_break_token]‚Äúa) The meta-training set {T_i; i=1,...,N} and the meta-test set {T_j; i=1,...,M} seems to overload the notation.	Reply	O	0
I suppose this is unintentional but it may appear that the two sets share the first T_1,.., T_M tasks, e.g., when N>=M, instead of being disjoint.	Reply	O	0
‚Äù[line_break_token][line_break_token]We have addressed this in the paper by stating that meta-train and meta-test sets are explicitly disjoint.	Reply	O	0
[line_break_token][line_break_token]‚Äúb) The set over which the summation is performed in (4) is unclear; alpha in (4) is not defined, though I guess it's a positive step size.	Reply	O	0
‚Äù[line_break_token][line_break_token]We have clarified this to indicate that alpha is a step size.	Reply	O	0
[line_break_token][line_break_token]‚Äúc) On p4, "we can view this problem as aiming to learn a prior over the intentions of human demonstrators" is an overstatement to me.	Reply	O	0
At best, this algorithm learns a prior over rewards for solving maximal entropy IRL, not intention.	Reply	O	0
And the experiment results do not corroborate  the statement about "human" intention.	Reply	O	0
‚Äù[line_break_token][line_break_token]We provided this sentence to give some intuition for our approach (the first word in the quoted sentence is ‚ÄúIntuitively‚Äù).	Reply	O	0
We clarified to this sentence to use the word ‚Äúreward‚Äù in place of ‚Äúintentions‚Äù and ‚Äúexpert‚Äù instead of ‚Äúhuman‚Äù.	Reply	B-Reply	4
[line_break_token][line_break_token]‚Äúd) On p4,  "since the space of relevant reward functions is much smaller than the space of all possible rewards deÔ¨Ånable on the raw observations" needs to be justified.	Reply	O	0
This may not be true in general, e.g., learning the set of relevant functions may require a larger space than learning the reward functions.	Reply	O	0
‚Äù[line_break_token][line_break_token]We clarified this sentence in the paper.	Reply	O	0
We are referring to reward functions that can explain a particular behavior.	Reply	B-Reply	4
In this sense, it is a strict subset of the reward functions we can define.	Reply	I-Reply	4
[line_break_token][line_break_token]‚Äúe) The authors call \mu_\tau the "state" visitation, but this is rather confusing, as it is the visiting frequency of state and action (which is only made clear late in the appendix).‚Äù[line_break_token][line_break_token]This terminology comes from the original MaxEnt IRL paper (see Ziebart 2008).	Reply	O	0
We agree however, and have clarified this in the paper.	Reply	B-Reply	4
[line_break_token][line_break_token]‚Äúf) On p5, it writes "... taking a small number of gradient steps on a few demonstrations from given task leads" But the proposed algorithm actually only takes "one" gradient step in training.	Reply	O	0
‚Äù[line_break_token][line_break_token]To clarify, in our experiment, we use one gradients step during meta-training, but up to 20 at meta-test.	Reply	O	0
We discuss this in the paper.	Reply	B-Reply	4
We note that is it is possible to take more than one gradient step at meta-training time although it is computationally more expensive.	Reply	I-Reply	4
[line_break_token][line_break_token]‚Äúg) The convention of derivatives used in the appendix is the transpose of the one used in the main paper.	Reply	O	0
‚Äù[line_break_token][line_break_token]We will correct this.	Reply	O	0
[line_break_token][line_break_token]‚Äú3) T^{tr} seems to be typo in (11)‚Äù[line_break_token][line_break_token]To clarify, this is not a typo.	Reply	O	0
It is consistent with our notation in the preliminary section.	Reply	B-Reply	5
In meta-learning, there is a meta-training and meta-testing dataset which consists of tasks.	Reply	I-Reply	5
For each task, there is T^{tr} and T^{test}, which are training and test points.	Reply	I-Reply	5
It is easy to see that few-shot learning is one such example of this	Reply	I-Reply	5

This paper proposes a data augmentation method that interpolates between two existing methods (Cutout and Gaussian), for training robust models towards Gaussian and naturally occurring corruptions.	Review	O	0
The method is shown to improve robustness without sacrificing accuracy on clean data.	Review	O	0
[line_break_token]Pros:[line_break_token]The proposed method, despite being simple, seems to empirically work well in terms of the mCE criterion evaluated in the experiments.	Review	O	0
This does support the authors‚Äô claim that current methods haven‚Äôt reached the robustness/accuracy tradeoff boundary yet.	Review	O	0
[line_break_token]Cons:[line_break_token]I‚Äôm a bit concerned about the significance of the work though.	Review	O	0
The method is a straight-forward combination of existing methods, so methodologically the novelty is kind of limited.	Review	B-Review	1
Hence, I‚Äôm expecting more insights from the analysis of the results, to gain more understanding of why it works so well.	Review	I-Review	2
However, the presentation of the experiments just seems to aim for the best numbers one can get (I‚Äôm not certain how significant the numbers are to this field though).	Review	I-Review	3
A few examples/pictures of success cases (when the method works) and failure cases (when the method doesn‚Äôt work), may help readers (I‚Äôm not an expert) to better understand the approach and get more intuitions?	Review	I-Review	3
The frequency analysis seems quite intuitive.	Review	I-Review	4
It‚Äôs obvious that Gaussian filter blocks high-frequency components, and Cutout keeps some original parts of the image which allow high-freq details to be captured.	Review	I-Review	4
But, considering CIFAR image size is only 32x32, a patch of size 25 is quite large, how much is the method different from plain whole image Gaussian then?	Review	I-Review	5
[line_break_token]	Review	O	0
e thank the reviewer for the thoughtful comments.	Reply	O	0
We provide some answers to the concerns raised below:[line_break_token][line_break_token]&gt; I‚Äôm a bit concerned about the significance of the work though.	Reply	O	0
The method is a straight-forward combination of existing methods, so methodologically the novelty is kind of limited.	Reply	O	0
[line_break_token][line_break_token]We agree that the method presented is very simple.	Reply	B-Reply	1
However, we‚Äôd like to emphasize that this was done by design.	Reply	I-Reply	1
In showing that such a simple method can be competitive with state-of-the-art methods in the robustness literature, we show that complex training schemes may not be necessary for training models robust to unseen distributions.	Reply	I-Reply	1
This is, we believe, where the significance of the work stems.	Reply	I-Reply	1
Indeed, R1 mentioned that our method ‚Äúcould become one of the standard mechanisms for data augmentation in the toolset of a practical ML engineer,‚Äù especially since it‚Äôs so easy to try.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; I‚Äôm expecting more insights from the analysis of the results, to gain more understanding of why it works so well.	Reply	O	0
[line_break_token][line_break_token]In Section 5.1, we provide an extensive frequency-based analysis and discussion of why Patch Gaussian works well: Patch Gaussian seems to allow high-frequency information through at lower layers, but still encourages relatively lower test error sensitivity at high frequencies.	Reply	B-Reply	2
Indeed, when we measure accuracy on images filtered with a high-pass filter, we see that Patch Gaussian models can maintain accuracy in a similar way to the baseline and to Cutout, where Gaussian fails to.	Reply	I-Reply	2
See Figure 5 for full results.	Reply	I-Reply	2
[line_break_token][line_break_token]We will re-word this section to clarify these insights to future readers.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; A few examples/pictures of success cases (when the method works) and failure cases (when the method doesn‚Äôt work), may help readers (I‚Äôm not an expert) to better understand the approach and get more intuitions?	Reply	O	0
[line_break_token][line_break_token]We thank the reviewer for the suggestion.	Reply	B-Reply	3
We have not examined this but we hope to include it in camera-ready.	Reply	I-Reply	3
In particular, we expect that images with higher Brightness will be among the most common errors, since Patch Gaussian slightly increases error (mCE 0.592) in these corruptions with respect to the Baseline (mCE 0.582). (	Reply	I-Reply	3
see Table 7 in Appendix).	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; It‚Äôs obvious that Gaussian filter blocks high-frequency components, and Cutout keeps some original parts of the image which allow high-freq details to be captured[line_break_token][line_break_token]We agree with the reviewer that these insights make intuitive sense.	Reply	O	0
Our work provides a quantitative evaluation of this phenomenon to confirm this intuition.	Reply	B-Reply	4
Further, through rigorous frequency-based sensitivity analysis we show that Patch Gaussian is able to retain both the high frequency sensitivity of Cutout and robustness gains of Gaussian augmentation.	Reply	I-Reply	4
[line_break_token][line_break_token]&gt; a patch of size 25 is quite large, how much is the method different from plain whole image Gaussian then?	Reply	O	0
[line_break_token][line_break_token]We remind the reviewer that, while the center of the patch needs to be inside the image, the edges can be outside.	Reply	B-Reply	5
This means that, with a patch of size 25, 39.55% of the space is covered in expectation for an image of size 32.	Reply	I-Reply	5
Depending on the location of the patch, 16.50% the space is covered (minimum) and other 61.04% is covered (maximum).	Reply	I-Reply	5
[line_break_token][line_break_token]In addition, our experimental results clearly show that patch Gaussian performs significantly differently from adding Gaussian noise to the whole image.	Reply	I-Reply	5
For example, as shown in Table 1 in our paper, for a Resnet-50 model on ImageNet(-C), Patch Gaussian gets a clean test accuracy of 76% and mCE of 0.714, whereas Gaussian data augmentation gets a clean test accuracy of 75.6% and mCE of 0.739	Reply	I-Reply	5

This paper proposes a low-rank tensor decomposition model (Tensor Train-TT [Oseledets et al, 2011]) to parameterize the embedding matrix in Natural Language Processing (NLP).	Review	O	0
It shows that TT allows for a compression of the network and sometimes even a slight increase of test accuracy.	Review	O	0
The paper is well written and easy to follow.	Review	O	0
[line_break_token]I found the idea as a natural consequence of many recent papers proposing tensor decomposition to parameterize deep learning networks.	Review	O	0
However, I think this is the first time that the concept has been applied to learning an embedding matrix, which is an important problem in the field.	Review	O	0
[line_break_token]The authors reported several experimental results on different tasks and datasets for NLP such as: Sentiment Analysis, Neural Machine Translation and Language Modeling; and an application to the click through rate prediction problem.	Review	O	0
[line_break_token]I think the paper is of limited novelty but includes interesting experimental results that helps to better understand the potential and limitations of tensor decompositions in deep learning architectures.	Review	O	0
[line_break_token]Below, I summarize the issues I found, and I would like the authors to address them in their responses:[line_break_token]Major issues:[line_break_token]-[tab_token]In Page 4 (and Appendix B), the authors show a comparison with Tensor Ring (TR) and conclude that TT marginally outperforms TR in terms of BLEU measure for a fixed number of parameters in both models.	Review	O	0
I found this comparison incomplete, weak and misleading because of the following reasons:[line_break_token]o[tab_token]TR is a more general model including TT as a particular case when the first and last ranks are equal to one (Zhao et al, 2016).	Review	B-Review	1
In fact, in this experiment, the authors chose all intermediate ranks set at the same value R with the first/last ranks set to 1 and R for TT and TR, respectively, which is not a fair comparison.	Review	I-Review	1
Shown results suggest that first/last ranks contain less information than intermediate ranks, but it would be necessary to explore other combinations of rank values without keeping them constant to explore the generalization power of the TR model including TT as a particular case.	Review	I-Review	1
[line_break_token]o[tab_token]The authors compares TT and TR only in case of the NMT, Transformer-big on WMT‚Äò14 English-to-German dataset, where the results are not good for TT and TR.	Review	I-Review	1
It is noted that baseline model (Big) attains a Sacre BLEU = 28.84, TT1 = 28.53 and TR1 = 28.07 and the compression rate is only 210/179=1.17 for TT1 and TR1 and the Iteration time is larger than in the baseline model.	Review	I-Review	1
In this case, there is no a clear advantage of using TT or TR.	Review	I-Review	1
[line_break_token]In my opinion, to improve the paper, I think the authors could:[line_break_token]o[tab_token]To avoid the sentence ‚ÄúIn our experiments, however, the resulting TR embeddings performed slightly worse than TT‚Äìembeddings with the same number of parameters‚Äù unless more conclusive and exhaustive experiments are performed comparing TT and TR.	Review	I-Review	1
[line_break_token]o[tab_token]To add some comparison results between TT and TR for the rest of datasets such as Sentiment Analysis, Language Modeling and the click through rate prediction problem.	Review	I-Review	1
[line_break_token]o[tab_token]Highlight that TT is a particular case of TR so considering the first and last ranks equal to one reduce the number of parameters but can affect the generalization power of the model.	Review	I-Review	1
[line_break_token]-[tab_token]The approach of the paper is mostly intuitive.	Review	O	0
A theoretical result about why the low rank TT is able to catch the useful information of an optimal or suboptimal embedding matrix is missing.	Review	B-Review	2
[line_break_token]Minor issues:[line_break_token]-[tab_token]In last paragraph of section 3.2: The number of parameters is computed on the 3D tensor cores only.	Review	O	0
I think the size of the first/last 2D cores should be added.	Review	B-Review	3
Please revise the equation.	Review	I-Review	3
[line_break_token]-[tab_token]The pseudocode for the mapping one index to multiple indices is trivial and could be avoided.	Review	O	0
If it is kept, I think the reverse operation should be also included, i.e. how to map multiple indices i1, ‚Ä¶., iN to one index i.[line_break_token]-[tab_token]The discussion and Figure 2 about the Gaussianity of the values in the higher order tensor based on Gaussian core tensors is not relevant.	Review	O	0
Maybe, the authors should better motivate why it is important to highlight that the distribution tends to a Gaussian density for increasing ranks.	Review	B-Review	5
[line_break_token]-[tab_token]In page 5, it is mentioned that ‚Äúfactors should be as close to each other as possible‚Äù but there is no a justification for it.	Review	O	0
Could you give some theoretical insight on why it is important to obtain uniform distribution of matrix size?	Review	B-Review	6
[line_break_token]-[tab_token]Section 4.1, reference to the Stanford sentiment treebank (SST) is missing.	Review	O	0
[line_break_token][line_break_token]On Nov 16th: I am satisfied with the responses provided by the Authors who made few changes to solve some identified minor issues.	Review	O	0
Thanks for taking the review report into account.	Review	O	0
I have raised the rating.	Review	O	0
[line_break_token]	Review	O	0
hank you for your time and expertise put into the review!	Reply	O	0
Please, see the answers to your questions below.	Reply	O	0
[line_break_token][line_break_token]Major issues:[line_break_token]1.	Reply	O	0
While TR is more general form of TT with powerful generalization abilities, it might require more intricate optimization to realize its full potential (Section 2.5 in [2]).	Reply	B-Reply	1
We would like to stress that in the paper we do not make a conclusion of TT-embedding superiority over TR.	Reply	I-Reply	1
Our experiments with TR were aimed to show one promising future direction for the work on tensorized embeddings.	Reply	I-Reply	1
While our results suggest that TT-embedding shows better compression-performance trade-off than its TR counterpart on Transformer NMT, much more experimentation is needed to properly compare these two approaches.	Reply	I-Reply	1
Such analysis is computationally heavy and goes beyond the scope of this paper.	Reply	I-Reply	1
[line_break_token]2.	Reply	I-Reply	1
The question of token embeddings optimality is difficult to answer because the very problem of determining optimality as the ability to catch useful information is ill-posed.	Reply	I-Reply	2
When trained jointly in end-to-end manner, we can not separate the embedding and softmax layers from the model backbone (such as LSTM or a stack of Transformer blocks).	Reply	I-Reply	2
There is some empirical evidence that reducing the number of trainable parameters in the core part will force the model to store more information in embeddings and vice versa.	Reply	I-Reply	2
In particular, even models with embeddings initialized randomly and not trained at all might produce good results in some tasks [1].[line_break_token][line_break_token]Minor issues:[line_break_token]1.	Reply	O	0
Thank you for pointing it out, there is indeed an inaccuracy in indexing.	Reply	B-Reply	3
Instead of R_k and R_{k+1} there should be R_{k-1} and R_k.	Reply	I-Reply	3
Note, that the revised equation includes both 2D and 3D cores as R_0=R_N=1 by definition.	Reply	I-Reply	3
[line_break_token]2.	Reply	I-Reply	1
We added the pseudocode for inverse mapping into the Appendix A for completeness.	Reply	I-Reply	4
[line_break_token]3.	Reply	O	0
The rationale behind the discussion of Gaussianity of TT-matrix matrix elements is the following.	Reply	B-Reply	5
Gaussian distribution is de facto the standard way to initialize token embeddings.	Reply	I-Reply	5
It has been extensively studied and experimented with, and we know that it allows to converge to a good model if the variance is properly chosen [1]. We know very little about the right way to initialize tensorized layers, however, Figure 2 (empirically) suggests that the initialization of TT-cores with equation 2 is at least as good as the baseline if TT-rank is sufficiently high.	Reply	I-Reply	5
It also shows that with the decrease of TT-rank, the initialization moves away from Gaussian which might also contribute to performance degradation (in addition to the extreme compression).	Reply	I-Reply	5
We believe that this observation raises an important question and calls for a more thorough analysis of tensorized layers initialization.	Reply	I-Reply	5
[line_break_token]4.	Reply	O	0
Our decision for choosing as uniform shape as possible was motivated by the insights from prior work [3]. First, their big-O estimate of forward and backward passes complexity (Table1) shows that TT-layers of ‚Äúimbalanced‚Äù shape are more expensive to train.	Reply	B-Reply	6
Secondly, their experimental results suggest that uniform shapes perform well in contrast to TT-layers with too small number of values for particular dimensions.	Reply	I-Reply	6
We hypothesize that other non-trivial shape factorizations might work better in terms of compression ratio or metric of interest.	Reply	I-Reply	6
Searching for theoretical justifications of better factorizations or recipes how to choose them for each particular task is important direction for future work.	Reply	I-Reply	6
[line_break_token]5.	Reply	O	0
Thank you for pointing it out, we added missing reference to the updated version of the paper.	Reply	B-Reply	7
[line_break_token][line_break_token][1] T. Kocmi, O. Bojar.	Reply	O	0
An Exploration of Word Embedding Initialization in Deep-Learning Tasks.	Reply	O	0
In ICON, 2017.	Reply	O	0
[line_break_token][2] L. Grasedyck, D. Kressner, C. Tobler.	Reply	O	0
A literature survey of low-rank tensor approximation techniques.	Reply	O	0
CGAMM-Mitteilungen, vol.	Reply	O	0
36, pp.	Reply	O	0
53‚Äì78, 2013.	Reply	O	0
[line_break_token][3] A. Novikov, D. Podoprikhin, A. Osokin, D. Vetrov.	Reply	O	0
Tensorizing Neural Networks.	Reply	O	0
In NIPS 2015	Reply	O	0

This paper presents a technique for encoding the high level ‚Äústyle‚Äù of pieces of symbolic music.	Review	O	0
The music is represented as a variant of the MIDI format.	Review	O	0
The main strategy is to condition a Music Transformer architecture on this global ‚Äústyle embedding‚Äù.	Review	O	0
 Additionally, the Music Transformer model is also conditioned on a combination of both ‚Äústyle‚Äù and ‚Äúmelody‚Äù embeddings to try and generate music ‚Äúsimilar‚Äù to the conditioning melody but in the style of the performance embedding.	Review	O	0
[line_break_token][line_break_token]Overall, I think the paper presents an interesting application and parts of it are well written, however I have concerns with the technical presentation in parts of the paper and some of the methodology.	Review	O	0
Firstly, I think the algorithmic novelty in the paper is fairly limited.	Review	B-Review	1
The performance conditioning vector is generated by an additional encoding transformer, compared to the Music Transformer paper (Huang et.	Review	I-Review	1
al.	Review	I-Review	1
2019b).	Review	I-Review	1
However, the limited algorithmic novelty is not the main concern.	Review	I-Review	1
The authors also mention an internal dataset of music audio and transcriptions, which can be a major contribution to the music information retrieval (MIR) community.	Review	I-Review	1
However it is not clear if this dataset will be publicly released or is only for internal experiments.	Review	I-Review	1
[line_break_token][line_break_token]In terms of technical presentation, I think the authors should clarify how the model is trained.	Review	I-Review	2
It took me a couple of passes and reading the Music Transformer paper to realise that in the melody and performance conditioning case, the aim is to generate the full score (melody and accompaniment) while conditioning on the performance style and melody (which is represented using a different vocabulary).	Review	I-Review	2
This point can be easily clarified in Figure 1, by adding the input to the encoder as input to the decoder for computing the loss.	Review	I-Review	2
Although I understand the need for anonymity and constraints while referring to unreleased datasets, it would still be useful for the reader/reviewer to have some details of how the melody was extracted and represented. ‚	Review	I-Review	2
ÄúAn internal procedure‚Äù is quite mysterious.	Review	I-Review	2
[line_break_token][line_break_token]Measuring music similarity is a difficult problem and the topic has been the subject of at least 2 decades of research.	Review	I-Review	3
I find the description of the ‚Äúperformance feature‚Äù to be lacking in necessary background and detail.	Review	I-Review	3
Firstly, I am not sure what the final dimensionality of the feature vector is.	Review	I-Review	3
Is it real valued?	Review	I-Review	3
The authors mention (Yang and Lerch, 2018) but use a totally different set of attributes compared to that paper.	Review	I-Review	3
I also don‚Äôt see the connection between this proposed feature vector and using the IMQ kernel for measuring similarity.	Review	I-Review	3
This connection is not motivated adequately and after reading (Jitkrittum et.	Review	I-Review	3
al.	Review	I-Review	1
2019) its not obvious to me why this is the most appropriate metric.	Review	I-Review	3
Finally, it would be useful if the authors comment on existing methods for measuring music similarity in symbolic music and how their proposed feature fits into existing work.	Review	I-Review	3
A lot of work has been published on this topic, most recently in the context of Query-by-Humming [1]. [line_break_token][line_break_token]Minor Comments[line_break_token][line_break_token]1. ‚	Review	O	0
Äú...which typically incorporate global conditioning as part pf the training procedure‚Äù Could you elaborate on this point?	Review	B-Review	4
Is the global conditioning the samples from the noise distribution?	Review	I-Review	4
[line_break_token]2.	Review	I-Review	4
Figure 1 should be clarified or another figure should be added to show how the melody conditioning works.	Review	I-Review	4
Maybe a comment on the melody vocabulary or a reference would also be useful.	Review	I-Review	4
[line_break_token]3.	Review	I-Review	4
The MAESTRO dataset is described in terms of the number of performances while the internal dataset is described in terms of the number of hours of audio.	Review	I-Review	4
Its not possible for the reader to get a sense of the relative sizes of the 2 datasets and how the results should be interpreted.	Review	I-Review	4
[line_break_token]4.	Review	I-Review	4
There should be more background and description in Section 4.	Review	I-Review	4
Where does the performance feature come from?	Review	I-Review	4
Why use this feature compared to existing techniques for measuring similarity between symbolic music pieces?	Review	I-Review	4
Is it computational efficiency?	Review	I-Review	4
Why not compare the conditioning melody with the generated performance similar to query-by-humming?	Review	I-Review	4
Where does the IMQ kernel come from?	Review	I-Review	4
What is the size of the feature vector?	Review	I-Review	4
[line_break_token]5.	Review	I-Review	4
In section 5.2, a conditioning sample, a generated sequence and an unconditional sample are used to compute the similarity measure.	Review	I-Review	4
Which terms do these correspond to in the MMD-like term (x,y,y‚Äô)?	Review	I-Review	4
[line_break_token]6.	Review	I-Review	4
I like the experiments performed in Section 5.3 with the linear combination of 2 performance embeddings.	Review	I-Review	4
[line_break_token][line_break_token][1] A Survey of Query-By-Humming Similarity Methods: <a href="http://vlm1.uta.edu/ <a href=" profile?id="~athitsos/publications/kotsifakos_petra2012&quot;" target="_blank">athitsos/publications/kotsifakos petra</a>.pdf" target="_blank" rel="nofollow"&gt;http://vlm1.uta.edu/ <a href="/profile?id=~athitsos/publications/kotsifakos_petra2012" target="_blank">athitsos/publications/kotsifakos petra</a>.pdf[line_break_token]	Review	O	0
n addition to the common concerns as written above, we address Reviewer #3's specific concerns below:[line_break_token][line_break_token]&gt; 1.	Reply	O	0
What does ‚Äútypically incorporate global conditioning‚Äù mean in the Introduction?	Reply	O	0
[line_break_token][line_break_token]The generative models which ‚Äútypically incorporate global conditioning...‚Äù are simply conditional variants of models such as the conditional VAE (Sohn et al.	Reply	B-Reply	4
2015) and conditional GAN (Mizra et.	Reply	I-Reply	4
al 2014) which perform generation by conditioning on a global signal, such as a one-hot encoding of the class label.	Reply	I-Reply	4
[line_break_token][line_break_token]&gt; 2.	Reply	O	0
Need more clarification about ‚Äúinternal dataset‚Äù and ‚Äúpreprocessing procedure‚Äù for melody extraction.	Reply	O	0
[line_break_token]As the reviewer noted, we did our best to anonymize the submission with respect to the dataset and preprocessing techniques used in the paper.	Reply	B-Reply	2
Our internal dataset is comprised of approximately 400K piano performances which comprise the 10,000+ hours of audio.	Reply	I-Reply	2
Due to licensing restrictions we are unable to release the internal piano performance dataset -- however, we will provide pre-trained models based on this dataset for public use.	Reply	I-Reply	2
[line_break_token][line_break_token]For the melody representation (vocabulary), we followed (Waite et.	Reply	I-Reply	2
al 2016) to encode the melody as a sequence of tokens and quantized it to a 100ms grid.	Reply	I-Reply	2
For the melody extraction procedure, we used an algorithm as in the open-sourced code (Anonymous for review), where we use a heuristic to extract the note with the highest in a given performance.	Reply	I-Reply	2
Specifically, we construct a transition matrix of melody pitches and use the Viterbi algorithm to infer the most likely sequence of melody events within a given frame.	Reply	I-Reply	2
We will add additional details regarding the melody extraction and encoding in the Supplement.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt;3.	Reply	O	0
There needs to be additional clarification of how the model is trained.	Reply	O	0
[line_break_token][line_break_token]This is a good point.	Reply	B-Reply	2
As noted by the reviewer, for performance-only conditioning, the decoder is tasked with predicting the same performance that was fed as input to the encoder.	Reply	I-Reply	2
In this way, we encourage the model to learn global representations (the mean-aggregated performance embedding from the encoder) that will faithfully be able to reconstruct the input performance.	Reply	I-Reply	2
For melody &amp; performance conditioning, the Transformer autoencoder is trained to predict a new performance using the combined melody+performance embedding, where the loss is computed with respect to the conditioned input performance that is provided to the encoder.	Reply	O	0
[line_break_token][line_break_token]To make this point more clear, we will update the submission with a new version of Figure 1 with the reviewer‚Äôs suggestions.	Reply	B-Reply	2
We have also added these additional details on the model training procedure in the supplemental materials in the revision.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]References:[line_break_token]Sohn et.	Reply	O	0
al 2015: Learning Structured Output Representation using Deep Conditional Generative Models[line_break_token]Mizra et.	Reply	O	0
al 2014: Conditional Generative Adversarial Nets[line_break_token]Waite et.	Reply	O	0
al 2016: <a href="https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn" target="_blank" rel="nofollow">https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn</a	Reply	O	0

Summary: This paper introduces a simple idea to optimize the weights of a weighted empirical training distributions.	Review	O	0
The goal is to optimize the population risk, and the idea is to optimize a distribution over the training examples to maximize the cosine similarity between training set gradients and validation set gradients.	Review	O	0
The distribution over the training set is parameterized by a neural network taking as arguments the[line_break_token][line_break_token]Strengths:[line_break_token]- The method is quite simple.	Review	O	0
[line_break_token]- The results appear to be strong, although I am less familiar with the NMT baselines.	Review	O	0
The imagenet results seem quite strong to me.	Review	O	0
[line_break_token][line_break_token]Weaknesses:[line_break_token]- I couldn't find a particularly clear description of the scoring networks architecture.	Review	O	0
Given that it observes the whole dataset, this seems like a critical choice that could have a big impact on the complexity of this approach.	Review	B-Review	1
At the very least, this should be clearly reported, and I recommend a more thorough investigation of this choice.	Review	I-Review	1
[line_break_token]- The authors report that their method takes 1.5x to 2x longer to run than the uniform baseline.	Review	O	0
Yet, they ran all methods for the same number of steps / epochs.	Review	B-Review	2
It seems to me that a fairer comparison might be letting all methods enjoy the same total budget measure roughly by wall time.	Review	I-Review	2
[line_break_token][line_break_token]Questions:[line_break_token]- I didn't follow why the computation of the per example gradient grad l(x_i, y_i, theta_t-1) is so onerous.	Review	O	0
Isn't that computed on line 5 already?	Review	B-Review	3
e thank the reviewer for providing many good suggestions and questions.	Reply	O	0
We have addressed your concerns here and updated the paper with some clarifications.	Reply	O	0
We would appreciate if you could check our response and revisions (and if these have indeed clarified the concerns, revise the overall assessment).	Reply	O	0
We would also be happy to continue the discussion and make any additional modifications as deemed necessary.	Reply	O	0
[line_break_token][line_break_token]reviewer #3 question1: scoring network architecture[line_break_token][line_break_token]response:[line_break_token]We are sorry for the lack of clarity with respect to this!	Reply	O	0
This was simply an oversight.	Reply	B-Reply	1
[line_break_token][line_break_token]For image classification, we use an identical network architecture with the main model, but with independent weights and a regressor to predict the score instead of a classifier to predict image classes.	Reply	I-Reply	1
For the multilingual NMT experiments, since we only want to model a simple distribution over n training languages, we use a fully connected 2-layer perceptron network.	Reply	I-Reply	1
For each target sentence and its corresponding source sentences, the input feature is a n-dimensional vector of 0 and 1, where 1 indicates a source language exists for the given target sentence.	Reply	I-Reply	1
We have updated the image classification and NMT instantiation section, as well as the appendix, with clarifications of the network structure, and will release our code once the paper is accepted.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]reviewer #3 question2: The authors report that their method takes 1.5x to 2x longer to run than the uniform baseline.	Reply	O	0
Yet, they ran all methods for the same number of steps / epochs.	Reply	O	0
It seems to me that a fairer comparison might be letting all methods enjoy the same total budget measure roughly by wall time.	Reply	O	0
[line_break_token][line_break_token]response:[line_break_token]The main objective of DDS is to improve model performance, while remaining much simpler and more efficient than other methods that optimize a data selector using reinforcement learning that require multiple independent training runs.	Reply	O	0
For example, in the IMDB movie review experiment in  [1], the data filtering agent is also trained for 200 episode, where each episode uses around 40% of the whole dataset, requiring a total of 80x more training time than a single training run.	Reply	B-Reply	2
Therefore, the 1.5-2x increase in time afforded by DDS is much more manageable.	Reply	I-Reply	2
[line_break_token][line_break_token]For image classification, training the standard baseline for longer does not help, since the main model will start to overfit, which indicates that spending more time on the baseline would not have a positive effect.	Reply	I-Reply	2
[line_break_token][line_break_token]reviewer #3 question3:  I didn't follow why the computation of the per example gradient grad l(x_i, y_i, theta_t-1) is so onerous.	Reply	O	0
Isn't that computed on line 5 already?	Reply	O	0
[line_break_token][line_break_token]response:[line_break_token]In practice, a single gradient is computed with respect to a mini-batch of training data of size n to improve computational efficiency.	Reply	O	0
However, using the per-example gradient requires one to compute the gradient for each example in a batch, which essentially slows down training by a factor of n. Therefore, we propose the simplification in Eqn.	Reply	B-Reply	3
7 to compute the per example gradient.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token][1] Learning what data to learn <a href="https://arxiv.org/pdf/1702.08635.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1702.08635.pdf</a>	Reply	O	0

This paper presents a feature quantization technique for logistic regression, which has already been a common practice in [line_break_token] many finance applications.	Review	O	0
 The text feels rushed.	Review	O	0
From the current presentation, I find it difficult to understand what is the motivation of adopting the proposed relaxation of the optimization method, and how is the neural network-based estimation strategy connected to the logistic regression model.	Review	B-Review	1
It seems the difference lies in the parameterized nonlinear transformation such that the cutting points can be somehow optimized.	Review	I-Review	1
 The quality of the experiments performed is way below the expectation for ICLR.	Review	O	0
Although numerical experiments are performed on both simulated data and credit scoring data, it is still unclear whether the proposed method has superiority over competitors.	Review	B-Review	2
 [line_break_token][line_break_token]Question: In the test phase, how would the proposed method handle features that are not seen in the training phase?	Review	O	0
Thank you for your review.	Reply	O	0
We are aware that the first submitted version has typos and mistakes and have updated the paper accordingly.	Reply	B-Reply	4
We apologize for the inconvenience and hope you might see the revised paper with new eyes.	Reply	I-Reply	4
Moreover, we have addressed your following remarks:[line_break_token][line_break_token]- The motivation behind the relaxation is that it can approximate the discrete quantization functions as now shown on Figure 2.	Reply	O	0
The parameters of this relaxation are easily obtained via a very simple neural network, contrary to a greedy intractable search of the best quantization functions as in Equation (6).	Reply	B-Reply	1
In a way, we use the proposed neural network as a computational graph to get the best quantization through the optimization of the \alpha parameters and the use of fast and standard libraries for deep learning.	Reply	I-Reply	1
[line_break_token][line_break_token]- Regarding the experiments, the simulated data are here only to to show empirically the consistency of the proposed method in various settings.	Reply	O	0
As for real data, we understand the number of datasets on which we compare our proposed method to standard methods was not enough, so that we added 3 portfolios from Cr√©dit Agricole Consumer Finance as well as 6 datasets from the UCI library, some of which also in the field of Credit Scoring.	Reply	B-Reply	2
[line_break_token][line_break_token]In your question, we suppose that by ‚Äúfeatures‚Äù, you meant categorical factor levels (say we have a categorical features with 5 levels of which only the 4 ‚Äòfirst‚Äô are seen during training).	Reply	I-Reply	3
If our interpretation of your question is correct, recall that the neural network is only a proxy: in the end, our method yields a logistic regression, so that we need to estimate a coefficient for each factor level (as in Equation (4)) and p(y|x=5) cannot be calculated.	Reply	I-Reply	3
This is the case for any ‚Äústandard‚Äù supervised classification method to our knowledge.	Reply	I-Reply	3
Missing values in categorical or continuous features can be addressed if there was missing values in these features in the training phase, thus forming a level labelled as ‚Äúmissing‚Äù that can be grouped with other levels / discretization intervals.	Reply	I-Reply	3

This paper proposes a new algorithm for spike-sorting.	Review	O	0
It is implemented by a deep autoencoder with biophysically motivated loss functions.	Review	O	0
The encoder is the main module which conducts the spike-sorting task while the decoder is only used for training the model in an end-to-end fashion.	Review	O	0
[line_break_token][line_break_token]This paper should be rejected due to the following arguments:[tab_token][line_break_token]- The paper lacks a section on literature survey, to let the reader know how/where the proposed method fills the gap in the current state-of-the-art.	Review	O	0
They do compare their results with the KiloSort (Pachitariu et al.,	Review	B-Review	1
2016) algorithms, however, no discussion is provided on how it works and why their method outperforms it.	Review	I-Review	1
[line_break_token]- It is unclear why the reconstruction loss is chosen to be an L4 norm as opposed to L2.	Review	O	0
[line_break_token]- The authors claim that the parsimony loss as defined in Eq. (	Review	O	0
7) forces ‚Äúthe network to be parsimonious with respect to the set of MUAP proposals it uses to explain a given sEMG signal.	Review	B-Review	3
‚Äù My understanding, however, is that the only functionality of the loss defined in Eq. (	Review	I-Review	3
7) is to enforce temporal smoothness.	Review	I-Review	3
More elaborate explanation is needed to support the authors claim.	Review	I-Review	3
[line_break_token]- I could not understand the functionality of the uniqueness loss.	Review	O	0
Specifically, why should ‚Äúthe joint occurrence of the temporal similarity between MU spike trains and the spatial similarity between their MUAP waveforms‚Äù be penalized?	Review	B-Review	4
Isn‚Äôt that the case that same stimuli should result in similar response?	Review	I-Review	4
It is unclear what this has to do with forcing to explain different phenomena.	Review	I-Review	4
[line_break_token][line_break_token]Things to improve the paper that did not impact the score:[line_break_token]- The method (and the paper) is named deep spike ‚Äúdecoder‚Äù (DSD) while in fact the ‚Äúencoder‚Äù part of the learned deep autoencoder actually conducts the spike-sorting task.	Review	I-Review	5
This could be confusing!	Review	I-Review	5
[line_break_token]- Page 2, Sec.	Review	I-Review	5
3.1, line 2: Should use \times in inline equations in Latex for the multiplication symbol, not character x. Fix everywhere in the text.	Review	I-Review	5
[line_break_token]- Page 6, Par.	Review	I-Review	5
-2, line -2: The word ‚Äúreplicate‚Äù is repeated.	Review	I-Review	5
[line_break_token]- Non-legible plots axes.	Review	I-Review	5
[line_break_token][line_break_token]	Review	O	0
hanks a lot for the review.	Reply	O	0
In response to your points:[line_break_token][line_break_token]- We avoided extensive literature review and explanation on KiloSort mostly due to page limitations.	Reply	O	0
In the future revised version of the paper, we‚Äôll try to provide more background information and also include a summary of KiloSort in the appendix.	Reply	B-Reply	1
[line_break_token][line_break_token]- We chose L4 over L2 largely due to ease of hyperparameter tuning purposes.	Reply	O	0
EMG signal contains both action potentials and noise.	Reply	B-Reply	2
Sparsity and reconstruction loss terms, by creating a trade-off, are tuned such that only the signal corresponding to action potentials are reconstructed.	Reply	I-Reply	2
Here, we use the L4 norm because it differentiates between action potential signals from EMG noise more successfully and makes the hyperparameter tuning (see total loss equation) easier.	Reply	I-Reply	2
[line_break_token][line_break_token]- Parsimony loss is based on the L1-L2 norm.	Reply	O	0
The L1-L2 norm (and more generally the L1-Lq norm) is used as a block sparsity inducing penalty in optimization algorithms (see [1]).	Reply	B-Reply	3
The critical part in the parsimony loss function is the tensor partitioning G over which L1 norm (i.e. the sum operation) is performed.	Reply	I-Reply	3
By applying the L1-L2 norm over different partitionings of a tensor, one can induce different patterns of block sparsity.	Reply	I-Reply	3
Here, our partitioning is based on spatial neighborhoods (specified by the number of consecutive electrodes) for each individual motor unit.	Reply	I-Reply	3
This loss then minimizes both the number of motor units and their spatial footprints.	Reply	I-Reply	3
The reason why we apply this loss on the first time-derivative of the spatiotemporal waveforms tensor is to get the temporal smoothness effect as well.	Reply	I-Reply	3
We‚Äôll try to complement our explanation with visualizations in the revised paper.	Reply	I-Reply	3
[line_break_token][line_break_token]- The uniqueness loss (and also refractory period loss) are optional terms we use to tackle particular problems we observed during our experiments.	Reply	O	0
We‚Äôll move the experimentations with these terms to the experiments section and explain them in relation to the particular problems they‚Äôre trying to address.	Reply	B-Reply	4
[line_break_token][line_break_token][1] Francis Bach, Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski, et al.	Reply	O	0
Optimization with sparsity-inducing penalties.	Reply	O	0
Foundations and Trends in Machine Learning, 4(1):1‚Äì106, 2012	Reply	O	0

The paper presents an intuitive architecture for learning cross-lingual sentence representations.	Review	O	0
I see weaknesses and strengths: [line_break_token][line_break_token](i) The approach is not very novel.	Review	O	0
Using parallel data and similarity training (siamese, adversarial, etc.)	Review	B-Review	1
to facilitate transfer has been done before; see [0] and references therein.	Review	I-Review	1
Sharing encoder parameters across very different tasks is also pretty standard by now, going back to [1] or so.	Review	I-Review	1
[line_break_token](ii) The evaluation is strong, with a nice combination of standard benchmark evaluation, downstream evaluation, and analysis.	Review	O	0
[line_break_token](iii) While the paper is on cross-lingual transfer, the authors only experiment with a small set of high-resource languages, where transfer is relatively easy.	Review	O	0
[line_break_token](iv) I think the datasets used for evaluation are somewhat suboptimal, e.g.: [line_break_token]a) Cross-lingual retrieval and multi-lingual STS are very similar tasks.	Review	O	0
Other tasks using sentence representations and for which multilingual corpora are available, include discourse parsing, support identification for QA, extractive summarization, stance detection, etc.	Review	B-Review	4
[line_break_token]b) Instead of relying on Agic and Schluter (2017), why don‚Äôt the authors use the XNLI corpus [2]?	Review	O	0
[line_break_token]c) Translating the English STS data using Google NMT to evaluate an architecture that looks a lot like Google NMT sounds a suspicious.	Review	O	0
[line_break_token](v) While I found the experiment with eigen-similarity a nice contribution, there is a lot of alternatives: seeing whether there is a linear transformation from one language to another (using Procrustes, for example), seeing whether the sentence graphs can be aligned using GANs based only on JSD divergence, looking at the geometry of these representations, etc.	Review	O	0
Did you think about doing the same analysis on the representations learned without the translation task, but using target language training data for the tasks instead?	Review	B-Review	5
The question would be whether there exists a linear transformation from the sentence graph learned for English while doing NLI, to the sentence graph learned for German while doing NLI.	Review	I-Review	5
[line_break_token][line_break_token]Minor comments: [line_break_token]- ‚ÄúTable 3‚Äù on page 5 should be Table 2.	Review	O	0
[line_break_token]- Table 2 seems unnecessary.	Review	O	0
Since the results are not interesting on their own, but simply a premise in the motivating argument, I would present these results in-text.	Review	B-Review	7
[line_break_token][line_break_token][0] <a href="http://aclweb.org/anthology/W18-3023" target="_blank" rel="nofollow">http://aclweb.org/anthology/W18-3023</a>	Review	O	0
Thank you for your comments and thoughtful questions.	Reply	O	0
We address each comment individually below:[line_break_token][line_break_token]Addressing Major Comments[line_break_token](I) Novelty.	Reply	O	0
While we agree that we have not introduced a new architectural component in our cross-lingual multi-task models, we believe that our combination of current SOTA language modeling components and the accompanying analysis still raises interesting questions and demonstrates strong enough results to motivate new research.	Reply	B-Reply	1
[line_break_token][line_break_token](II) Evaluations.	Reply	O	0
Thank you - we also plan to add further evaluations (i.e. comparing to more lightweight encoder architectures such as the Deep Averaging Network of Iyyer et al. (	Reply	B-Reply	2
2015)) to the supplementary material in the next revision of our paper.	Reply	I-Reply	2
[line_break_token][line_break_token](III) Language Pairs.	Reply	O	0
Our main reason for choosing English-Spanish, English-French, and English-German language pairs was the fact that these language pairs had a number of pre-existing evaluations available.	Reply	B-Reply	3
[line_break_token][line_break_token](IV) Datasets.	Reply	O	0
[line_break_token](a) We are in the process of experimenting with further evaluations (paraphrases, summaries) in more languages, and hope to add these evaluations to future revisions of our paper.	Reply	O	0
[line_break_token](b) XNLI was not available at the time we were preparing the initial draft of this paper, but we plan to include evaluations on XNLI in our next revision.	Reply	O	0
We do have some preliminary XNLI results using our trained English-French model, which shows an accuracy of 69% on English and 64.5% on French.	Reply	B-Reply	4
[line_break_token](c) We agree that translated STS is not intended to be a surefire evaluation of STS performance in target languages, but evaluating sentence representations on translated datasets has been considered before (Eriguchi et al.,	Reply	O	0
2018).	Reply	B-Reply	4
Additionally, the Google NMT architecture uses an encoder-decoder structure as opposed to our dual-encoder architecture, so we felt there were sufficient enough differences between our approaches that evaluating on translated data may still provide some insight into STS performance in non-English languages.	Reply	I-Reply	4
[line_break_token][line_break_token](V) Embedding Space Analysis.	Reply	O	0
We absolutely agree that there are a number of interesting and different analyses that can be done on the learned sentence embedding spaces; our reason for using the eigen-similarity analysis was to extend the previous work done for word embeddings.	Reply	B-Reply	5
We did consider other approaches, such as aligning the sentence embeddings, but we ultimately felt that a proper treatment of the many different analyses techniques that are possible for the embedding spaces would be outside of the scope of this work.	Reply	I-Reply	5
We found your suggestion about performing the eigen-similarity analysis without translation data and only the monolingual tasks to be interesting, and an oversight on our part for not including in the initial version of our paper.	Reply	I-Reply	5
We plan to include this evaluation in the next revision of our paper.	Reply	I-Reply	5
[line_break_token][line_break_token]Addressing Minor Comments[line_break_token]*All table numbers should now read correctly.	Reply	O	0
[line_break_token][line_break_token]*We have greatly simplified Table 2 as suggested.	Reply	O	0

The paper introduces a new approach to combine small RBMs that are pretrained in order to obtain a large RBM with good performance.	Review	O	0
This will bypass the need of training large RBMs and suggests to break them into smaller ones.	Review	O	0
The paper then provides experimental evidence by applying the method on "invertible boolean logic".	Review	O	0
MCMC is used to find the the solution to large RBM and compare it against the combined solutions of smaller RBMs.	Review	O	0
[line_break_token][line_break_token][line_break_token]The paper motivates the problem well, however, it is not well-written and at times it is hard to follow.	Review	O	0
The details of the approach is not entirely clear and no theoritcal results are provided to support the approach.	Review	O	0
For instance, in the introduced approach, only an example of combination is provided in Figure 1.	Review	B-Review	1
It is not clear how smaller RBMs (and their associated parameters) are combined to obtain the larger RBM model.	Review	I-Review	1
From the experimental perspective, the experimental evidence on "invertible boolean logic" does not seem to be very convincing for validating the approach.	Review	I-Review	2
Additionally, the details of the settings of the experiments are not fully discussed.	Review	I-Review	2
For example, what are the atomic/smaller problems and associated RBMs?	Review	I-Review	2
what is the larger problem and how is the corresponding RBM obtained?	Review	I-Review	2
Overall, the paper seems to be a report consisting of a few interesting observations rather than introducing a solid and novel contribution with theoretical guarantees.	Review	I-Review	3
[line_break_token][line_break_token]Remark: [line_break_token]The term "Combinatorial optimization", which is used in the title and throughout the body of paper, sounds a bit confusing to the reviwer.	Review	O	0
This term is typically used in other contexts.	Review	B-Review	4
[line_break_token][line_break_token]Typos:[line_break_token]** Page 2 -- Paragraph 2: "Therefore, methods than can exploit..."[line_break_token]** Page 3 -- 2nd line of math: Super-scripts are missing for some entries of the matrices W^A and W^{A+B}[line_break_token]** Page 5 -- Last paragraph: "...merged logical units is more likly to get get stuck in a ..."[line_break_token]** Page 5 -- Last paragraph: "...and combining their distributions using the mulistart heuristic..."[line_break_token]	Review	I-Review	5
Thank you for your comments, we will be responding with specific comments to AnonReviewer3 here, and more general comments to the reviewer above.	Reply	O	0
[line_break_token][line_break_token]R2: For instance, in the introduced approach, only an example of combination is provided in Figure 1.	Reply	O	0
It is not clear how smaller RBMs (and their associated parameters) are combined to obtain the larger RBM model.	Reply	O	0
[line_break_token][line_break_token]As far as explaining the method of combination, and the associated mathematical properties, we have tried to do this in greater detail in section 3 (Approach).	Reply	B-Reply	1
We used Figure 1 and the combination matrices to show what exactly is happening when we combine the models, and how the models mathematically combine.	Reply	I-Reply	1
In our revision we have made an effort to outline this in greater detail.	Reply	I-Reply	1
 [line_break_token][line_break_token]R2: Overall, the paper seems to be a report consisting of a few interesting observations rather than introducing a solid and novel contribution with theoretical guarantees.	Reply	O	0
[line_break_token][line_break_token]In regards to the lack of theoretical guarantees, we have shown that the equilibrium distribution is what we expect it to be, and mathematically have shown that the final distribution of interest has the mode we expect it to.	Reply	B-Reply	3
It has been shown in many texts that Gibbs Sampling converges to this equilibrium distribution at a geometric rate in Markov Random Fields.	Reply	I-Reply	3
 Finding the exact convergence rate involves calculation of the eigenstructure of the markov chain transition matrix, which is in general computationally intractable for RBMs of moderate size [1]. Given this, we have added an extra theorem to show how the upper bounds on convergence rate changes as we merge RBMs, this can be seen in Section 3.1 on ‚ÄúConvergence Rate and MCMC‚Äù.	Reply	I-Reply	3
We show that the rate of convergence of the RBM is geometric in the number of sampling steps, and that the combined RBM will have a convergence rate bounded by the sum of the convergence rates of the individual RBMs.	Reply	I-Reply	3
[line_break_token][line_break_token] If we want to have further theoretical guarantees, we have the ability to exactly set model parameters, as mentioned in section 3.2 to get the exact distribution of interest, and to combine those RBMs with directly calculated parameters.	Reply	I-Reply	3
As mentioned in that section, this is not a data efficient, or computationally efficient method which is why we chose to not pursue it.	Reply	I-Reply	3
[line_break_token][line_break_token][1] Pierre.	Reply	O	0
Bremaud.	Reply	O	0
Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues, volume 1.Springer New York, 1999.	Reply	O	0
ISBN 9781441931313	Reply	O	0

The proposed approach amounts to a non-adversarial way to update the parameters theta of a kernel K_theta(x, y) = k(f_theta(x), f_theta(y)) in an MMD-net, rather than adversarially as in MMD-GANs.	Review	O	0
Avoiding the saddle point problem clearly gives a more stable optimization problem, as shown in Section 3.4, which is very nice.	Review	O	0
[line_break_token][line_break_token][line_break_token]Theory/motivation:[line_break_token][line_break_token]The motivation based on density ratio estimation, however, very much assumes that these densities exist.	Review	O	0
As convincingly argued by Arjovsky and Bottou (ICLR 17, "Towards principled methods for training generative adversarial networks"), the densities p_x, q_x of (4) typically do not exist (w.r.t.	Review	O	0
Lebesgue measure), and moreover the support of the distributions are typically almost disjoint.	Review	O	0
Algorithmically, this doesn't seem to be a major issue for your approach: the estimator (8) corresponds to some kind of smoothing by the kernel.	Review	B-Review	1
But it would be nice from a motivation point of view to have a better understanding of:[line_break_token][line_break_token]- What assumptions exactly does (8) make about the existence of densities?	Review	I-Review	1
For example, in the case of a Gaussian kernel, does it correspond to the distance between distributions convolved with Gaussian noises with a smaller Gaussian kernel?	Review	I-Review	1
Does the algorithm "make sense" when distributions don't exist?	Review	I-Review	1
[line_break_token][line_break_token]- Can we say something about when a density exists for the dimensionality-reduced data f_theta(x) even when it doesn't exist for the data x?	Review	O	0
[line_break_token][line_break_token]- Relatedly, the dimension-reduced Pearson divergence is clearly somehow different from the plain Pearson divergence.	Review	O	0
Can we understand a little bit more how it's different?	Review	B-Review	3
How does the choice of architecture of f_theta affect the distance metric?	Review	I-Review	3
[line_break_token][line_break_token]- Is it the case, as in Arjovsky et al. (	Review	O	0
2017) or in Arbel et al. (	Review	B-Review	4
NeurIPS 2018, "On gradient regularizers for MMD GANs"), that the overall loss function with an optimal f_theta is continuous with respect to the GAN distribution?	Review	I-Review	4
[line_break_token][line_break_token]Certainly not all of these theoretical questions require answers for an initial ICLR paper, but they would be illuminating for understanding the method.	Review	O	0
[line_break_token][line_break_token][line_break_token]Motivating experiments:[line_break_token][line_break_token]- In Figure 2, it seems that except in the first image (h=2) the mapping f_theta becomes essentially the identity.	Review	O	0
Is this expected to be generally true in your 2d cases, because the density ratio can already be well-represented there?	Review	B-Review	5
A more interesting example for this aspect of the model might involve higher-dimensional distributions with some low-dimensional manifold structure; would f_theta pick up some reasonable representation of the manifold in those cases?	Review	I-Review	5
[line_break_token][line_break_token]- Can you plot the density ratio estimate in a simple 2d example like this?	Review	O	0
How does it look visually?	Review	B-Review	6
Is a good estimate necessary for good performance of your generative model?	Review	I-Review	6
[line_break_token][line_break_token][line_break_token]Experiments:[line_break_token][line_break_token]- As shown by Binkowski et al.,	Review	O	0
it's extremely important to specify the sample size for FID scores, which you don't do.	Review	B-Review	7
[line_break_token][line_break_token]- That said, the FID scores of the MMD GAN models of Binkowski et al using DCGAN discriminators (which replace the FSR and AE penalties of Li et al.	Review	O	0
with a single gradient penalty) found substantially smaller penalties for performance of MMD-GANs with using a smaller discriminator (1/4 as many hidden units rather than 1/2 as you use) than you did.	Review	B-Review	8
They also reported substantially better numbers on CelebA than you did.	Review	I-Review	8
If not too difficult code-wise, it might be worth trying either their code or that of the followup Arbel et al. (	Review	I-Review	8
citation above) to compare to your approach.	Review	I-Review	8
[line_break_token][line_break_token]- The results of, for example, Mescheder et al. (	Review	O	0
ICML-18, "Which Training Methods for GANs do actually Converge?")	Review	B-Review	9
and Arbel et al. (	Review	I-Review	9
NeurIPS-18, "On gradient regularizers for MMD GANs") seem to be much better visually with comparably-sized models than the results of Figure 8 (and of course StyleGAN/etc are *far* better but with drastically larger models).	Review	I-Review	9
It would be good to compare empirically to some more recent models than original MMD GANs (whose empirical results were substantially improved with only minor tweaks by Binkowski et al.	Review	I-Review	9
mere months later) or DCGAN, which are fairly old approaches in this space.	Review	I-Review	9
[line_break_token][line_break_token]- Two more extremely relevant methods it would be worth comparing to or at least mentioning:[line_break_token][line_break_token]   - Ravuri et al. (	Review	O	0
ICML 2018, "Learning Implicit Generative Models with the Method of Learned Moments") can be interpreted as learning f_theta for an MMD-net as you do by taking the gradients of an auxiliary classification network.	Review	B-Review	10
Although it is still somewhat "adversarial," they need to update the kernel function extremely rarely (every 2,000 generator update steps) and the optimization seems overall much more stable.	Review	I-Review	10
[line_break_token][line_break_token]   - dos Santos et al. (	Review	I-Review	10
<a href="https://arxiv.org/abs/1904.02762" target="_blank" rel="nofollow">https://arxiv.org/abs/1904.02762</a> "Learning Implicit Generative Models by Matching Perceptual Features") effectively use an MMD-net (with some slight tweaks) with a *fixed* kernel.	Review	O	0
Though results aren't quite as good, it's worth at least mentioning.	Review	B-Review	10
[line_break_token][line_break_token][line_break_token]Minor typos/etc:[line_break_token][line_break_token]- Top of page 3: it is sufficient to choose F a unit ball in an RKHS with a _characteristic_ kernel.	Review	I-Review	11
[line_break_token]- Page 4: "this issue in next."	Review	I-Review	11
[line_break_token]- Figure 1 caption: (both) should probably be (bottom).	Review	I-Review	11
[line_break_token][line_break_token][line_break_token]Overall initial thoughts:[line_break_token][line_break_token]This seems like a nice alternative to adversarial methods, but it does not compare to more recent (last 2 years) models in this space or very thoroughly establish the applicability of its motivation.	Review	O	0
I think it's worthy of a weak accept as is, but could be much more convinced with some additional work.	Review	B-Review	12
.	Reply	B-Reply	1
Theory/Motivation: We do not assume that the data has a density with respect to Lebesgue measure, and indeed we expect in practice that the support of the data distribution is a low dimensional manifold.	Reply	O	0
The reason for this is that MMD (like all the other IPMs, Integral probability metrics, with weaker topological assumptions) is well defined even when the ‚Äúdistributions don‚Äôt exist‚Äù, i.e are supported only over some underlying low-dimensional manifold of the data space (Arjovsky et al.,	Reply	B-Reply	1
2017).	Reply	I-Reply	1
That said, in our work, we additionally project the densities back to the same low dimensional manifold as the noise.	Reply	I-Reply	1
We further provide empirical results on how changing the dimensionality of this manifold affects the generation in Figure 5(c).	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	8
On Pearson Divergence: This divergence uses an MMD-based ratio estimator in its own estimation.	Reply	O	0
Therefore, it depends on the efficiency of the MMD-based density ratio estimator.	Reply	B-Reply	3
Strictly speaking, it is not PD, as the ratio comes from MMD which has different topological assumption than f-divergences.	Reply	I-Reply	3
As a result, this estimator is well defined even when the two densities are not absolutely continuous with respect to each other.	Reply	I-Reply	3
The architecture of f_theta (except for the extreme cases) should not have an impact on the properties of this objective as long as the change of variable that f_theta implies is well defined.	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	O	0
On Figure 2: Can the reviewer please clarify how did they infer from figure 2, as it does not show the projected space?	Reply	O	0
Additionally, Figure 1 (which shows the projected space) confirms that is not learning an identity mapping.	Reply	B-Reply	5
We have added a new experiment, as you asked, where the data lives on a higher/different dimensional space than the projected space in Appendix F (Figure 10) to support our claim.	Reply	I-Reply	5
Please note that training diverges if we attempt the same experiment for MMD-GAN (i.e. projecting to 2D space) as shown in the same appendix in Figure 11.	Reply	I-Reply	5
[line_break_token][line_break_token]4.	Reply	O	0
FID: We used MMD-GAN‚Äôs author‚Äôs original code and used 30000 samples for evaluating FID.	Reply	O	0
[line_break_token][line_break_token]5.	Reply	B-Reply	8
Small Critic Evaluation: Binkowski et al (2018) used several learning rate heuristics.	Reply	I-Reply	8
For example, they adaptively decrease the learning rate using 3-sample test.	Reply	I-Reply	8
Additionally, they employ several regulations (on both, weights and activations) to allow the network to train without diverging.	Reply	I-Reply	8
We chose not to apply any additional tricks (more imp.	Reply	I-Reply	8
no architectural specific regularisations) on any of the methods in order to fairly evaluate them all on exactly the same settings.	Reply	I-Reply	8
As a result of this, MMD-GAN training (with the smaller critic) frequently diverged, leading to the high FID that we reported).	Reply	I-Reply	8
So far we have been able to run their original code on the Cifar10 dataset with the default settings for 24 hours.	Reply	I-Reply	8
After 150000 iterations it achieved an FID of 72.09 and an inception score of 5.02.	Reply	I-Reply	8
[line_break_token]Their celebA preprocessing (scaling/res) is different than the usual (64x64) and they use quite large networks (resnet or 5 layer DCGAN).	Reply	I-Reply	8
As a result, unlike most GAN methods it requires at least 2 GPU (as per original code documentation) to run this experiment and leads to the higher reported FID.	Reply	I-Reply	8
In light of these differences, we‚Äôd be happy to attempt full comparison if it would be useful.	Reply	I-Reply	8
[line_break_token]It is also common to centre-crop the faces in most recent work that removes the background and improves FID.	Reply	I-Reply	8
We do not do this and therefore our samples look different in quality than those generated by newer models.	Reply	I-Reply	8
[line_break_token][line_break_token]6.	Reply	O	0
References: Thanks for the references.	Reply	O	0
We will add them to our revised version.	Reply	B-Reply	10
We did not compare ours to Ravuri et al 2018 since unlike our method, their method relies on labels.	Reply	I-Reply	10
We would like to point out that GRAMnet can be used in a class-conditional setup as well	Reply	I-Reply	10

This paper studies the characteristics of representations and their roles in neural network expressiveness.	Review	O	0
The results  are overall not very impressive.	Review	B-Review	1
[line_break_token][line_break_token]1.	Review	O	0
There are many characteristics of representations such as scaling, permutation, covariance, correlation, sparsity, dead units, rank.	Review	B-Review	2
The papers discusses some (not surprising) theoretical properties relating to scaling, permutation, covariance, correlation, while making less efforts on the more interesting characteristics  sparsity, dead units, rank, mutual information.	Review	I-Review	2
Only some heuristic results are obtained for them without rigorous theory.	Review	I-Review	2
It would be better if these heuristic arguments can be formed as theorems as well.	Review	I-Review	2
[line_break_token][line_break_token]2.	Review	O	0
Probably the most interesting experimental finding of this paper is that the mutual information between z and output is constant, while the one between z and input strongly depends on the regularizers.	Review	B-Review	3
That is, the dependence between z and y does not vary with regularizers but the one between z and x does.	Review	I-Review	3
Is this a coincidence or a general phenomenon?	Review	I-Review	3
Is there a theoretical explanation?	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]3.	Review	O	0
Thanks for your review.	Reply	O	0
The ION theorem is an important part of explaining sparsity, dead units, and rank as well, but perhaps our writing was not clear enough.	Reply	B-Reply	2
We will work on the writing in the future version of this work.	Reply	I-Reply	2
As for the mutual information related comment (#2), the results that you have mentioned are well known from information bottleneck paper or from the following information invariance paper.	Reply	I-Reply	3
[line_break_token][line_break_token]Alessandro Achille and Stefano Soatto.	Reply	O	0
Emergence of invariance and disentangling in deep representations.	Reply	O	0
Journal of Machine Learning Research.	Reply	O	0
2018	Reply	O	0

This paper proposes to introduce randomness in a classifier‚Äôs predictions to mitigate black-box attacks that rely on gradient estimation through finite differences.	Review	O	0
The intuition behind the defense is correct: finite differences rely on the outputs of the neural network being non-deterministic and accurate to estimate gradients near the test points being attacked.	Review	O	0
[line_break_token][line_break_token]However, the threat model chosen in this paper is not well justified: the adversary cannot be forced to use a particular strategy.	Review	B-Review	1
Unlike what is suggested in Section 3, estimating gradients through finite differences is not the only strategy available in the black-box threat model (this is later mentioned in Section 6).	Review	I-Review	1
In this case, the adversary could for instance decide to adapt by instead mounting a black-box attack that relies on transferability.	Review	I-Review	1
Because Figure 2 shows that the defense does not provide robustness in the white-box setting, this suggests that other forms of black-box attacks that either (a) rely on transferability or (b) are label-based only would still evade the model.	Review	I-Review	1
This limitation should be addressed to understand how applicable the defense strategy is in a realistic deployment.	Review	I-Review	1
[line_break_token][line_break_token]Putting this aside, it is not clear from Figure 3 that an adaptive strategy was evaluated in the limited black-box setting that is considered here (the caption of Figure 3.b only describes a ‚Äúwhite-box‚Äù adaptive adversary), or that the defense is effective.	Review	I-Review	2
The attack success rates are high for many graphs and increase as the adversary averages over more runs.	Review	I-Review	2
Moving forward, increasing further the highest number of runs would help appreciate the limitations of the approach: it is currently set to at most 100, which is low.	Review	I-Review	2
[line_break_token][line_break_token]As far as organization is concerned, a lot of real estate is spent on background material, and few experimental results are presented to support claims made in the introduction.	Review	I-Review	3
Addressing the above comments would probably require compressing background material a bit.	Review	I-Review	3
[line_break_token][line_break_token]Page-by-page details:[line_break_token][line_break_token]1/ An attack is always adversarial by definition, ‚Äúadversarial attack‚Äù is a tautology.	Review	O	0
[line_break_token][line_break_token]2 / What do you mean by ‚Äúsuccessful attacks‚Äù?	Review	O	0
[line_break_token][line_break_token]2/ What do you mean by ‚Äústrongest‚Äù loss?	Review	O	0
[line_break_token][line_break_token]2/ Having a perturbation limited to be small does not guarantee it won‚Äôt impact the semantics of the input, even in the vision domain.	Review	O	0
Have you verified that the perturbations that you chose left semantics unperturbed?	Review	B-Review	7
[line_break_token][line_break_token]2/ It is best to avoid making broad statements such as ‚ÄúWe use the l2 perturbation penalty as this type of attack results in the strongest attacks‚Äù because they are unlikely to hold across datasets and models.	Review	O	0
[line_break_token][line_break_token]7/ Figures are difficult to parse (e.g., does T and U stand for targeted and untargeted?)	Review	O	0
[line_break_token][line_break_token]7/ Distillation was already shown to be vulnerable to black-box attacks in [7][line_break_token][line_break_token]8/ Gradient masking was introduced in [7] prior to [25].[line_break_token][line_break_token]8/ It would be good to justify the following statement (see my comment above): ‚ÄúAlthough this is a valid attack vector for even black box models, we do not consider this type of attack in this work‚Äù	Review	O	0
he reviewer brings up a valid point that our proposed defense against finite difference black box attacks do not defend against white-box or transfer-based attacks.	Reply	B-Reply	1
We agree with the reviewers on this point.	Reply	I-Reply	1
Following the advice of [25] and to leave no room for assumptions on the effectiveness of the proposed defense against other attacks, we clearly defined our problem setting to be defense against finite difference attacks. [	Reply	I-Reply	1
25] showed in 2018 that  7 out of 9 papers that proposed defense strategies in ICLR 2018 made false claims and over-promised their effectiveness.	Reply	I-Reply	1
This includes defenses in our related work section, such as [26]. We found our proposed defense against finite difference attacks to be both novel and interesting, but we did not want to over-claim the defense's effectiveness.	Reply	I-Reply	1
We are careful to only claim the defense is effective against (adaptive) finite different black box attacks.	Reply	I-Reply	1
[line_break_token][line_break_token]Indeed we evaluated an adaptive black box attacker, Figure 3b is describing a black box attacker that adopt the same adaptive strategy as the one in Figure 2b.	Reply	I-Reply	2
[line_break_token]In the black box case, we were limited by the available computational budget as increasing the number of samples in the adaptive case past 100 was very slow.	Reply	I-Reply	2
[line_break_token]Page by page responses[line_break_token]2- successful in the sense of satisfying the two conditions mentioned in the next sentence.	Reply	O	0
[line_break_token]2- The authors in [18] consider the given loss function the best for their attack[line_break_token]2 ‚Äì yes we verified the samples produced by the attacks were not semantically unperturbed in most cases[line_break_token]7- Correct, T=targeted and U=untargeted[line_break_token]7- The authors in [7] show defensive distillation is ineffective against a transfer attack, we show it is also ineffective against finite-difference based attacks.	Reply	O	0
We believe the distinction is important and hope the reviewer agrees.	Reply	B-Reply	10
[line_break_token][line_break_token][25] A. Athalye, N. Carlini, D. Wagner. "	Reply	O	0
Obfuscated Gradients give a false sense of security: circumventing defenses to adversarial examples" ICML 2018[line_break_token][26] C. Xie, J. Wang, Z. Zhang, Z. Ren, and A. Yuille, ‚ÄúMitigating Adversarial Effects Through Randomization‚Äù ICLR 2018	Reply	O	0

This is an emergency review.	Review	O	0
[line_break_token][line_break_token]This work proposes a novel method to use pre-trained topic embeddings and pre-trained word embeddings obtained from various corpora in the transfer learning framework.	Review	O	0
[line_break_token][line_break_token]Their model architecture is based on DocNADE, unsupervised neural-network based topic model, and the authors propose two strategies to use pre-trained topic embeddings and pre-trained word vectors.	Review	O	0
[line_break_token]1) Addition of a weighted sum of pre-trained word embeddings and the hidden vector of DocNADE.	Review	O	0
[line_break_token]2) L2-Regularization term between topic embedding of DocNADE and pre-trained topic embeddings.	Review	O	0
They propose to align these two embeddings by multiplying align matrix "A" to the topic embedding of DocNADE.	Review	O	0
[line_break_token][line_break_token]They show the transfer learning performance of their model on various source/target domain datasets, including medical target corpora, and verify that their model outperforms on a short text and small document collection.	Review	O	0
[line_break_token][line_break_token]Strengths.	Review	O	0
[line_break_token]1.	Review	O	0
Comparison with the data augmentation baseline shows the performance gain is not only from bigger training data.	Review	O	0
Even though comparison with the naive baseline (data augmentation) seems too obvious, I think the results clearly show their claim about the importance of using transfer learning in neural topic modeling domain.	Review	O	0
[line_break_token]2.	Review	O	0
As the first approach that introduces a novel transfer learning framework with pre-trained topic embeddings, they show tons of experimental results with various datasets and metrics to show the specification of their method.	Review	O	0
Their experimental setting is well designed.	Review	O	0
[line_break_token][line_break_token]Weaknesses and comments:[line_break_token]Their method to combine pre-trained word embeddings and pre-trained topic embeddings is too simple.	Review	O	0
Since this is the first approach to use topic embedding in the transfer learning field, the simplicity of the proposed method is somewhat necessary.	Review	B-Review	1
However, a weighted sum of pre-trained topic/word vectors seems not enough to transfer multisource knowledge.	Review	I-Review	1
For instance, word vectors obtained from individual training processes do not share embedding vector space.	Review	I-Review	1
As you apply the alignment method to topic embeddings from various sources, you should align word embeddings too.	Review	I-Review	1
hanks for your (emergency) reviews.	Reply	O	0
[line_break_token][line_break_token]Thanks for your positive comments on experimental setup and acknowledging that our transfer learning approaches introduced in neural topic modeling clearly outperform several baselines.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt; "Word Embedding Alignment"[line_break_token]Yes, we do.	Reply	O	0
[line_break_token]Please see section 3, page 6 in "Reproducibility" paragraph (line 3).	Reply	B-Reply	1
Also, mentioned in caption of figure 6 as well as in Appendix C.4 (the last paragraph).	Reply	I-Reply	1
[line_break_token][line_break_token]We perform the word embeddings alignment in all the "+Glove" settings (Table 6) to [line_break_token](1) overcome the DocNADEe (baseline topic model) limitation (word-embedding size must be same as the number of topics), and [line_break_token](2) align vector spaces of word-embeddings obtained from several sources as well as from several different training processes, e.g., from Glove, FastText and word embeddings from topic models.	Reply	I-Reply	1
[line_break_token][line_break_token]The focus of our work is to demonstrate the joint word and topic embeddings transfer in neural topic models from one or many sources.	Reply	I-Reply	1

In this paper the authors propose to use RNNs and LSTMs for channel coding.	Review	O	0
But I have the impression the authors completely miss the state of the art in channel coding and the results are completely useless for any current communication system.	Review	O	0
I believe that machine learning, in general, and deep learning, in particular, might be of useful for physical layer communications.	Review	O	0
I just do not see why it would be useful for channel coding over the AWGN channel.	Review	O	0
Let me explain.	Review	O	0
[line_break_token][line_break_token]If the decoder knows that the encoder is using a convolutional code, why does it need to learn the decoder instead of using the Viterbi or BCJR algorithms that are known to be optimal for sequences and symbols, respectively.	Review	B-Review	5
I cannot imagine an scenario in which the decoder does not know the convolutional code that it is being used and the encoder sends 120,000 bits of training sequence (useless bits from information standpoint) for the decoder to learn it.	Review	I-Review	5
More important question, do the authors envision that this learning is done every time there is a new connection or it is learnt once and for all.	Review	I-Review	6
If it is learnt every time that would be ideal if we were discovering new channel codes everyday, clearly not the case.	Review	I-Review	6
If we learnt it one and for all and then we incorporated in the standard that would only make sense if the GRU structure was computationally better than the BCJR or Viterbi.	Review	I-Review	6
I would be surprise if it is.	Review	I-Review	6
If instead of using 2 or 3 memories, we used 6-8 does 120,000 bits be good enough or we need to exponentially increase the training sequence?	Review	I-Review	6
So the first result in the paper shows that a tailored structure for convolutional encoding can learn to decode it.	Review	I-Review	6
Basically, the authors are solving a problem that does not need solving.	Review	I-Review	6
[line_break_token][line_break_token]For the Turbocodes the same principle as before applies.	Review	I-Review	7
In this case the comments of the authors really show that they do not know anything about coding.	Review	I-Review	7
In Page 6, we can read: ‚ÄúUnlike the convolutional codes, the state of the art (message-passing) decoders for turbo codes are not the corresponding MAP decoders, so there is no contradiction in that our neural decoder would beat the message-passing ones‚Äù.	Review	I-Review	7
This is so true, so I expected the DNN structure to be significantly better than turbodecoding.	Review	I-Review	7
But actually, they do not.	Review	I-Review	7
These results are in Figure 15 page 6 and the solution for the turbo decoders and the DNN architecture are equivalent.	Review	I-Review	7
I am sure that the differences in the plots can be explained by the variability in the received sequence and not because the DNN is superior to the turbodecoder.	Review	O	0
Also in this case the training sequence is measured in the megabits for extremely simple components.	Review	B-Review	4
If the convolutional encoders were larger 6-8 bits, we would be talking about significantly longer training sequences and more complicated NNs.	Review	I-Review	4
[line_break_token][line_break_token]In the third set the NNs seems to be superior to the standard methods when burst-y noise is used, but the authors seems to indicate that that NN is trained with more information about these bursts that the other methods do not have.	Review	I-Review	3
My impression is that the authors would be better of focusing on this example and explain it in a way that it is reproducible.	Review	I-Review	3
This experiment is clearly not well explained and it is hard to know if there is any merit for the proposed NN structure.	Review	I-Review	3
[line_break_token][line_break_token]Finally, the last result would be the more interesting one, because it would show that we can learn a better channel coding and decoding mechanism that the ones humans have been able to come up with.	Review	I-Review	2
In this sense, if NNs can solve this problem that would be impressive and would turn around how channel coding is done nowadays.	Review	I-Review	2
If this result were good enough, the authors should only focus in it and forget about the other 3 cases.	Review	I-Review	2
The issue with this result is that it actually does not make sense.	Review	I-Review	2
The main problem with the procedure is that the feedback proposal is unrealistic, this is easy to see in Figure 16 in which the neural encoder is proposed.	Review	I-Review	2
It basically assumes that the received real-valued y_k can be sent (almost) noiselessly to the encoder with minimal delay and almost instantaneously.	Review	I-Review	2
So the encoder knows the received error and is able to cancel it out.	Review	I-Review	2
Even if this procedure could be implemented, which it cannot be.	Review	I-Review	2
The code only uses 50 bits and it needed 10^7 iterations (500Mbs) to converge.	Review	I-Review	2
The authors do not show how far they are from the Shannon limit, but I can imagine that with 50 bit code, it should be pretty far.	Review	I-Review	2
 [line_break_token][line_break_token]We know that with long enough LDPC codes we can (almost) reach the Shannon limit, so new structure are not needed.	Review	O	0
If we are focusing on shorter codes (e.g. latency?)	Review	B-Review	1
then it will be good to understand why do we need to learn the channel codes.	Review	I-Review	1
A comparison to the state of the art would be needed.	Review	I-Review	1
Because clearly the used codes are not close to state of the art.	Review	I-Review	1
For me the authors either do not know about coding or are assuming that we do not, which explains part of the tone of this review.	Review	I-Review	1
[line_break_token]	Review	O	0
As someone who has worked on coding theory for many years, I would like to add a comment, explaining [line_break_token]why I found this paper very interesting and how it is related to this review.	Reply	O	0
[line_break_token][line_break_token]As mentioned, using density evolution we can design degree sequences for LDPCs that have thresholds that get very close to the Shannon limit.	Reply	B-Reply	1
The only case where we can actually approach arbitrarily close is the erasure channel.	Reply	I-Reply	1
For BIAWGN and BSC we can get quite close (but not actually arbitrarily close).	Reply	I-Reply	1
[line_break_token]However, for slightly more complicated channels we have no idea how to do that or even what the fundamental limits are (e.g. deletion channel).	Reply	I-Reply	1
 I find this paper exciting because it defines a new family of possibilities in code and decoder design.	Reply	I-Reply	1
It took us 50 years to go from Shannon's paper to modern LDPC and Turbo codes.	Reply	I-Reply	1
So we should not expect that this paper beats LDPCs in their own game but rather as opening a new area of investigation.	Reply	I-Reply	1

- Overview: This work presents a benchmark for language understanding centered on understanding pragmatics and discourse, in contrast to existing NLP benchmarks which focus on mostly semantic understanding.	Review	O	0
The stated contributions are[line_break_token]    - The DiscEval benchmark, with some estimates of human performance[line_break_token]    - Baseline performance with state of the art models[line_break_token]    - Comparisons between commonly used supervised training objectives (NLI) and discourse-oriented objectives[line_break_token][line_break_token]- Review: This work offers a complementary evaluation benchmark for NLU systems to what currently exists in the field, and also offers compelling evidence that the current methods used do not provide good signal for learning the types of phenomena assessed in this benchmark.	Review	O	0
I recommend (weak) accept.	Review	O	0
[line_break_token]    - The paper would benefit a lot from having more in-depth explanation of the tasks, what the classes are, and what the classes mean.	Review	O	0
It's not always clear from the examples or the labels in Table 1 what exactly is being tested.	Review	B-Review	1
[line_break_token]        - Additionally, it'd be nice to get the source of the data for each task.	Review	O	0
[line_break_token]    - The rough grouping of tasks in nice.	Review	O	0
[line_break_token]    - I understand that estimates of human performance, especially for tasks with a high number of classes, can be tricky to obtain.	Review	O	0
I do feel that they are especially important to have for this dataset.	Review	B-Review	4
As you said, some of these tasks rely on context that isn't explicitly provided in the utterance, so I wonder if for some of the tasks, there may be insufficient context in just the provided utterances for humans to perform well.	Review	I-Review	4
[line_break_token]        - Additionally, some tasks seem to have quite subjective label definitions.	Review	O	0
For example, "eloquence" and "specificity" in Persuasion; "formality" and "informativeness" in Squinky; etc.	Review	B-Review	5
Validating that humans are consistent on these tasks seems crucial.	Review	I-Review	5
[line_break_token]        - For the estimates you do have, are these expert or lay annotators?	Review	O	0
For some of these annotations, it seems like you'd need trained annotators.	Review	B-Review	6
[line_break_token]    - Have you given any thought to exploitable data artifacts that may occur in these datasets that might be driving the fairly high performance on some of these tasks (e.g. Verifiability)?	Review	O	0
[line_break_token]    - I think it's quite interesting that fine-tuning on MNLI doesn't lead to good performance on DiscEval, as MNLI, as the authors point out, is commonly taken to be a useful pretraining task.	Review	O	0
This discrepancy gives practical weight to the authors' claim that discourse and pragmatic phenomena are not being sufficiently studied or evaluated for in current NLP research, despite the fact that these handling these phenomena will be crucial for NLP systems.	Review	B-Review	8
[line_break_token][line_break_token]- Things to Improve + Questions + Comments[line_break_token]    - I would hope that most people in the NLP community would not say that language understanding is a solved problem, but I agree that putting "universal" in model names and paper titles is a reach-y thing to do.	Review	O	0
[line_break_token]    - Tasks[line_break_token]        - What is the original citation for STAC?	Review	O	0
[line_break_token]    - S4.3, Table 2: [line_break_token]        - Any reason not to try combining all four pretraining/intermediate training tasks in a single model, or at least more combinations of DiscEval with other things?	Review	O	0
[line_break_token]        - Could you comment on the standard deviation of the scores (per task) given that you're averaging 6 runs?	Review	O	0
[line_break_token]    - Table 3[line_break_token]        - "The best overall unsupervised result is achieved with Discovery STILT": what does unsupervised mean here?	Review	O	0
It also doesn't look like BERT+Discovery is the best in any column here.	Review	B-Review	11
[line_break_token]    - Tables 4 and 5 feel like a bit of a dump of numbers.	Review	O	0
It'd be more useful to the readers to extract trends (probably using the groupings and theoretical frameworks introduced earlier).	Review	B-Review	13
The noting of BERT+MNLI being good at predicting absence of relations is nice.	Review	I-Review	13
[line_break_token]    - Typos: There are a noticeable number of typos.	Review	O	0
Here are some I noted:[line_break_token]        - The formatting of the task descriptions in Section 3 is a bit inconsistent and awkward.	Review	B-Review	14
[line_break_token]        - Table 1: "exemple"[line_break_token]        - P4: "We use a custom train/dev validation split"[line_break_token]        - P5: "that help *realize* speech acts' intentions."	Review	I-Review	14
[line_break_token]        - P6: "Prediction of discourse markers based *off* the context clauses..."[line_break_token]	Review	I-Review	14
any thanks for your helpful comments and constructive criticism.	Reply	O	0
[line_break_token][line_break_token]- Additionally, some tasks seem to have quite subjective label definitions.	Reply	O	0
For example, "eloquence" and "specificity" in Persuasion; "formality" and "informativeness" in Squinky; etc.	Reply	O	0
Validating that humans are consistent on these tasks seems crucial.	Reply	O	0
[line_break_token]&gt; Some labels are indeed more subjective than others.	Reply	O	0
The annotations of the tasks you cite were derived from multiple annotations, which was one of our criteria for selecting datasets.	Reply	B-Reply	5
The degrees of agreement are imbalanced but always above chance.	Reply	I-Reply	5
Squinky and Persuasion factors were initially rated with continuous ratings.	Reply	I-Reply	5
The fact that we discretized them and removed the middle quantile should further alleviate the subjectivity problem.	Reply	I-Reply	5
[line_break_token][line_break_token]- Have you given any thought to exploitable data artifacts that may occur in these datasets that might be driving the fairly high performance on some of these tasks (e.g. Verifiability)?	Reply	O	0
[line_break_token]&gt; The CBoW and LSTM baselines should be able to use respectively lexical information and simple structural patterns (e.g. sequence length).	Reply	O	0
The fact that BERT outperforms them with such a margin shows that it is using more than that.	Reply	B-Reply	7
The fact that fine-tuning with DiscEval and with Discovery improves Disceval results shows that there is a common ground between some (but not all) tasks, which indicates either other common artifacts or actual linguistic capabilities, but further work would be needed to really address this problem.	Reply	I-Reply	7
[line_break_token][line_break_token]- Any reason not to try combining all four pretraining/intermediate training tasks in a single model, or at least more combinations of DiscEval with other things?	Reply	O	0
[line_break_token]&gt; Combining DiscEval with datasets like MNLI is possible, but could be tricky because MNLI/Discovery/Dissent are quite large, and our simplistic multi-task setup would either not use the full datasets or overfit the small datasets.	Reply	O	0
Such combinations would be interesting but would involve more complicated setups.	Reply	B-Reply	9
[line_break_token][line_break_token]- Could you comment on the standard deviation of the scores (per task) given that you're averaging 6 runs?	Reply	O	0
[line_break_token]&gt; Most stds are below 1% absolute, so the 6 runs averaging should allow meaningful comparisons[line_break_token][line_break_token] - "The best overall unsupervised result is achieved with Discovery STILT": what does unsupervised mean here?	Reply	O	0
It also doesn't look like BERT+Discovery is the best in any column here.	Reply	O	0
[line_break_token]&gt; The Discovery and Dissent datasets have been obtained without human annotations, hence the term unsupervised; we meant that it was the best according to an average of GLUE and DiscEval.	Reply	O	0
We clarified this in the paper.	Reply	B-Reply	11

Contributions:[line_break_token]1.	Review	O	0
This paper proposes a method to learn disentangled style (artist) and content representations.	Review	O	0
[line_break_token]2.	Review	B-Review	3
By carefully designing two-stage training objectives, the method learns a style-independent content-encoding E at the first stage and the style encoder S and generator G both from the first and the second stage.	Review	O	0
[line_break_token]3.	Review	O	0
Empirical results justify the validity of the method.	Review	O	0
[line_break_token][line_break_token]I think this paper makes a good contribution to disentangle style and content in anime.	Review	O	0
My main concern is the complicated learning procedure design may affect the reproducibility of this method.	Review	B-Review	4
Moreover, I will suggest several points to the authors to clarify in the main text.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
I encourage the authors to release their code when published.	Review	B-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	3
In stage 1 (Style Independent Content-Encoding), the purpose of the classifier C, to my understanding, is to try to classify the generated example G(E(x), S(a')) as the "ground-truth" style (a).	Review	I-Review	2
That is, the classifier C tries to disregard the S(a') when making a decision.	Review	I-Review	2
As an adversarial player, E, G, S will try to fool C by making E(x) to be non-informative regarding the style.	Review	I-Review	2
However, since you are still optimizing G and S, how do you make sure that it is safe to hold E fixed while still changing G and S in the second stage?	Review	I-Review	2
Or more specifically, how do you make sure the style encoding network S preserves a good one in the second stage?	Review	I-Review	2
Aside from that, are you using the trained G, S from the first stage to initialize G, S in the second stage?	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
There are eight different terms in stage 2, so it worth checking the necessity for those terms.	Review	B-Review	3
E.g. what happens if you drop the L_cont term?	Review	I-Review	3
The term L_cont seems to guarantee the validity of E, but E is fixed in step 2.	Review	I-Review	3
t is correct that in stage 1 the classifier tries to disregard and tries to find information about the true author from, and,, and jointly tries to purge style information of from.	Reply	B-Reply	2
[line_break_token][line_break_token]It is true that and are changing in stage 2 while is fixed, but note that and don't change arbitrarily, they are still cooperating with, so they should not make changes that cause the output of to be unsuitable.	Reply	I-Reply	2
Furthermore, it is necessary to fix: if we allow to change and at the same time minimize, then the most obvious way to do so is for to give degenerate output (e.g. encode everything to 0) which renders useless.	Reply	I-Reply	2
[line_break_token][line_break_token]In stage 2 and are initialized from the trained and in stage 1, but this is optional.	Reply	I-Reply	2
It might take longer if and are trained from scratch in stage 2 but the end result should be comparable.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding the necessary of the many loss terms in stage 2: for a class-conditional GAN where the class condition is enforced by an auxiliary classifier in the discriminator, five terms is the bare minimum: discriminator's loss on real and generated samples, classifier's loss on real samples, and generator's loss against the discriminator and the classifier.	Reply	I-Reply	3
[line_break_token][line_break_token]Among the additional terms we added, is necessary.	Reply	I-Reply	3
It is not used to guarantee the validity of.	Reply	I-Reply	3
Instead, it is used ensure that the generator does actually use the content input in the intended manner, that is, it does generate images that has the content represented by the content code.	Reply	I-Reply	3
The effect of dropping it is shown in section C.2 in the appendix.	Reply	I-Reply	3
[line_break_token][line_break_token]The classifier's loss on generated samples is not absolutely necessary, but it changes the behavior of the classifier towards the generated samples from passive to adversarial, which is a qualitative difference from prior works and is one of our contributions.	Reply	I-Reply	3
The effect of dropping it is discussed in detail in section C.2.	Reply	I-Reply	3
[line_break_token][line_break_token]The last term, the KL-divergence loss on the output of, is largely optional.	Reply	I-Reply	3
It tries to constrain the distribution of style code and supposedly could benefit such things as interpolating between two styles.	Reply	I-Reply	3
If this is not a concern, this term can be dropped.	Reply	I-Reply	3
[line_break_token][line_break_token]In short, seven of the eight terms are necessary.	Reply	I-Reply	3
[line_break_token][line_break_token]We have prepared the code and training dataset for this work and we are willing to release them if this work can be published	Reply	I-Reply	1

This paper asks interesting questions and has interesting experimental results.	Review	O	0
The generality of the results could be improved by considering more than one dataset, though.	Review	B-Review	1
[line_break_token][line_break_token]You might want to first fix a typo in Rich's name...[line_break_token][line_break_token]I concur with David Krueger regarding the somewhat misleading statements in the abstract and introduction etc regarding the matching of depth with width (and a LOT more training examples), which does not apply in the case of a convolutional net.	Review	O	0
This really needs to be fixed.	Review	B-Review	3
[line_break_token][line_break_token]My take on the results is however quite different from the conclusions given in the paper.	Review	I-Review	4
The paper makes it sound as if we could find a better way to train shallow nets in order to get results as good as deep nets, as if it was just an optimization issue.	Review	I-Review	4
My interpretation is quite different.	Review	I-Review	4
The results seem more consistent with the interpretation that the depth (and convolutions) provide a PRIOR that helps GENERALIZING better.	Review	I-Review	4
This is consistent with the fact that a much wider network is necessary in the convolutional case, and that in both cases you need to complement the shallow net's training set with the fake/mimic examples (derived from observing the outputs of the deep net on unlabeled examples) in order to match the performance of a deep net.	Review	I-Review	4
I believe that my hypothesis could be disentangled from the one stated in the paper (which seems to say that it is a training or optimization issue) by looking at training error.	Review	I-Review	4
According to my hypothesis, the shallow net's training error (without the added fake / mimic examples) should not be significantly worse than that of the deep net (at comparable number of parameters).	Review	I-Review	4
According to the 'training' hypothesis that the authors seem to state, one would expect training error to be measurably lower for deep nets.	Review	I-Review	4
In fact, for other reasons I would expect the deep net's training error to be worse (this would be consistent with previous results, starting with my paper with Dumitru Erhan et al in JMLR in 2010).	Review	I-Review	4
[line_break_token][line_break_token]It would be great to report those training errors.	Review	I-Review	5
Note that to be fair, you have to report training error with no early stopping, continuing training for a fixed and large number of epochs (the same in both cases) with the best learning rate you could find (separately for each type of network).	Review	I-Review	5
[line_break_token][line_break_token]Finally, the fact that even shallow nets (especially wide ones) can be hard to train (see Yann Dauphin's ICLR 2013 workshop-track paper) also weakens the hope that we could get around the difficulty of training deep nets by better training shallow nets.	Review	I-Review	6
[line_break_token][line_break_token]Several more papers need to be cited and discussed.	Review	I-Review	7
Besides my JMLR 2010 paper with Dumitru Erhan et al (Why Does Unsupervised Pre-training Help Deep Learning), another good datapoint regarding the questions raised here is the paper on Understanding Deep Architectures using a Recursive Convolutional Network, by Eigen, Rolfe & LeCun, submitted to this ICLR 2014 conference.	Review	O	0
Whereas my JMLR paper is about understanding the advantages of depth as a regularizer, this more recent paper tries to tease apart various architectural factors (including depth) influencing performance, especially for convolutional nets.	Review	B-Review	7
Yoshua, thank you for your comments.	Reply	O	0
 We believe you may have read an older draft and hope that most or all of the misleading statements were corrected in the Jan 3 draft.	Reply	O	0
 Nonetheless, many of your comments still apply to the current paper.	Reply	O	0
[line_break_token][line_break_token]We completely agree that generality would be improved with results on additional datasets.	Reply	B-Reply	1
 We submitted a workshop abstract instead of full paper because we only had results for one data set, and are about to run experiments on two other datasets.	Reply	I-Reply	1
[line_break_token][line_break_token]With TIMIT we did not use more training data to train the shallow models than was used to train the deep models.	Reply	I-Reply	6
 We used exactly the same 1.1M training cases used to train the DNN and CNN models to train the SNN mimic model.	Reply	I-Reply	6
 The only difference is that the mimic SNN does not see the original labels.	Reply	I-Reply	6
 Instead, it sees the real-valued probabilities predicted by the DNN or CNN it is trying to mimic.	Reply	I-Reply	6
 In general, model compression works best when a large unlabelled data set is available to be labeled by the ‚Äúsmart‚Äù model so that the smaller mimic model can be trained ‚Äúhard‚Äù with less chance of overfitting.	Reply	I-Reply	6
 But for TIMIT unlabelled data was not available so we used the same data used to train the deep models for compression (mimic) training.	Reply	I-Reply	6
 We believe that the fact that no extra data --- labeled or unlabelled --- was used to train the SNN models helps drive home the point that it may be possible to train shallow models to be as accurate as deep models.	Reply	I-Reply	6
[line_break_token][line_break_token]We agree with your comment that ‚ÄúThe paper makes it sound as if we could find a better way to train shallow nets in order to get results as good as deep nets, as if it was just an optimization issue.	Reply	I-Reply	4
‚Äù, except that we view it more perhaps as an issue of regularization than of just optimization.	Reply	I-Reply	4
 In particular, we agree that depth, when combined with current learning and regularization methods such as dropout, is providing a prior that aids generalization, but are not sure that a similar effect could not be achieved using a different learning algorithm and regularization scheme to train a shallow net on the original data.	Reply	I-Reply	4
 In some sense we‚Äôre making a black-box argument: we already have a procedure that given a training set, yields a shallow net that has accuracy comparable to a deep fully-connected feedforward net trained on the same data.	Reply	I-Reply	4
 If we hadn‚Äôt shown you what the learning algorithm was in our black box would you have been 100% sure that the wizard behind the curtain must have been deep learning?	Reply	I-Reply	4
The real question is whether the black box *must* go through the intermediate step of training a deep model to mimic, or whether there exist other learning and regularization procedures that could achieve the same result without going through the deep intermediary.	Reply	I-Reply	4
 We do not (yet) know the answer to this question, but it is interesting that a shallow model can be trained that is as accurate as a deep model without access to any additional data.	Reply	I-Reply	4
 We certainly agree that it is difficult to train large, shallow nets on the original targets with the learning procedures currently available.	Reply	I-Reply	4
[line_break_token][line_break_token]We agree that looking at training errors can be informative, but they might not resolve the issue in this case.	Reply	I-Reply	5
 If model compression has access to a very large unlabelled data set, if the mimic model has sufficient capacity to represent the deep model, the shallow model will learn to be a high-fidelity mimic of the deep model and will make the same predictions, and the error of the shallow mimic model and deep model on train and test data will be identical as the error of the mimic predictions compared to the deep model is driven to zero.	Reply	I-Reply	5
 This is for the ideal case where we have access to a very large unlabelled data set, which unfortunately we did not have for TIMIT.	Reply	I-Reply	5
 Exactly what training errors do you want to see: the error of the DNN on the original training data vs. the error of the SNN trained to mimic the DNN on the real-valued targets, but measured on the original labels of the training points, or vs. the error of an SNN trained on the original data and labels?	Reply	I-Reply	5
 Early stopping was used when training the deep models, but was not used when training the mimic SNN models.	Reply	I-Reply	5
 In fact we find it very difficult to make the SNN mimic model overfit when trained with L2 loss on continuous targets.	Reply	I-Reply	5
[line_break_token][line_break_token]Thanks for the pointers to other papers we should have cited.	Reply	I-Reply	7
 We‚Äôre happy to add them to the abstract.	Reply	I-Reply	7
 And thanks again for the careful read of our abstract.	Reply	I-Reply	7
 Sorry you had to struggle through the 1st draft	Reply	I-Reply	7

The paper proposes two approaches to boosting generative models, both based on likelihood ratio estimates.	Review	O	0
The approaches are evaluated on synthetic data, as well as on MNIST dataset for the tasks of generating samples and semi-supervised learning.	Review	O	0
[line_break_token]While the idea of boosting generative models and the proposed methods are interesting, the reviewer finds the experiments unconvincing for the following reasons.	Review	O	0
[line_break_token]1.	Review	B-Review	3
The bagging baseline in section 3.1 seems to be just refitting a model to the same dataset, raising the probability to power alpha, and renormalizing.	Review	I-Review	1
This makes it more peaked, but it's not clear why this is a good baseline.	Review	I-Review	1
Please let me know if I misunderstood the procedure.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	7
The sample generation experiment in section 3.2 uses a very slowly converging Markov chain, as can be seen in the similarity of plots c and f, d and g, e and h. It seems unlikely therefore that the resulting samples are from the stationary distribution.	Review	I-Review	2
A qualitative evaluation using AIS seems to be necessary here.	Review	I-Review	2
[line_break_token]3.	Review	I-Review	1
In the same section the choices for alphas seem quite arbitrary - what happens when a more obvious choice of alpha_i=1 for all i is made?	Review	I-Review	3
[line_break_token]4.	Review	O	0
It seems hard to infer anything from the semisupervised classification results reported: the baseline RBM seems to perform as well as the boosted models.	Review	B-Review	4
[line_break_token][line_break_token]The work is mostly clearly written and (as far as the reviewer knows) original.	Review	O	0
Thanks for your helpful comments.	Reply	O	0
Please refer to the common rebuttal posted for response to questions regarding MNIST experiments (points 2 and 3).	Reply	O	0
[line_break_token]1.	Reply	O	0
Yes, the bagging procedure described is correct.	Reply	B-Reply	1
The purpose of including bagging as a baseline was to demonstrate that naively increasing model capacity by adding new models to the ensemble is not very effective in correcting for model misspecification, unlike boosting which involves a reweighting step in the GenBGM version or classifier training for the DiscBGM version.	Reply	I-Reply	1
A similar approach (called bagging) competes with boosting for the supervised case.	Reply	I-Reply	1
For brevity, we have removed this baseline from the latest version.	Reply	I-Reply	1
[line_break_token]4.	Reply	O	0
The experiments on semi-supervised classification have been removed in the latest version since the gain in accuracy with the current algorithm is unconvincing for a few cases.	Reply	B-Reply	4
For completeness, we would like to clarify the purpose of including them earlier was to demonstrate a) the computational gains that boosted generative models can provide on this task (for example, the training time of RBM->RBM was slightly more than half of the baseline RBM model yet it was able to match the performance of the baseline RBM model) b) improving models that are weaker at this task due to different inductive biases (for example, VAE->RBM gives better accuracy than the baseline VAE).	Reply	O	0
Based on our preliminary experiments, we believe this task is an important use case of boosted generative models.	Reply	B-Reply	4
However, in the absence of sufficient empirical evidence, we defer improved algorithms for semi-supervised classification based on the boosting framework to future work.	Reply	I-Reply	4

This paper proposes a multimodal VAE model for the problem of generalized zero shot learning (GZSL).	Review	O	0
In GZSL, the test classes can contain examples from both seen as well as unseen classes, and due to the bias of the model towards the seen classes, the standard GZSL approaches tend to predict the majority of the inputs to belong to seen classes.	Review	O	0
The paper proposes a multimodal VAE model to mitigate this issue where a shared manifold learning learn for the inputs and the class attribute vectors.	Review	O	0
[line_break_token][line_break_token]The problem of GZSL is indeed important.	Review	O	0
However, the idea of using multimodal VAE for ZSL isn't new or surprising and has been used in earlier papers too.	Review	B-Review	1
In fact, multimodal VAEs are natural to apply for such problems.	Review	O	0
The proposed multimodal VAE model is very similar to the existing ones, such as Vedantam et al (2017), who proposed a broad framework with various types of regularizers in the multimodal VAE framework.	Review	B-Review	2
Therefore, the methodological novelty of the work is somewhat limited.	Review	O	0
[line_break_token][line_break_token]The other key issue is that the experimental results are quite underwhelming.	Review	O	0
The paper doesn't compare with several recent ZSL and GZSL approaches, some of which have reported accuracies that look much better than the accuracies achieved by the proposed method.	Review	B-Review	3
The paper does cite some of these papers (such as those based on synthesized examples) but doesn't provide any comparison.	Review	I-Review	4
Given that the technical novelty is somewhat limited, the paper falls short significantly on the experimental analysis.	Review	I-Review	4
Thank you very much for your valuable feedback and sorry for our late response.	Reply	O	0
[line_break_token][line_break_token]> However, the idea of using multimodal VAE for ZSL isn't new or surprising and has been used in earlier papers too.	Reply	O	0
[line_break_token]VZSL (Wang et al.,	Reply	B-Reply	1
2017) cited in our paper is known as an example of a study applying VAE to ZSL, but to the best of our knowledge, there are not many studies applying multimodal VAE to ZSL.	Reply	I-Reply	1
[line_break_token][line_break_token]> The proposed multimodal VAE model is very similar to the existing ones, such as Vedantam et al (2017), who proposed a broad framework with various types of regularizers in the multimodal VAE framework.	Reply	O	0
[line_break_token]As you pointed out, Vedantam et al. (	Reply	B-Reply	2
2017) uses multimodal learning using two modalities, attributes and images, and generates unseen images from corresponding attributes.	Reply	I-Reply	2
However, this work is not intended to solve the problem of zero-shot learning, because it does not predict the class labels of unseen classes.	Reply	I-Reply	2
[line_break_token][line_break_token]In addition, rather than introducing a completely novel model, we showed that manifold learning in shared space using VAEs is effective to resolve a problem of relation-based GZSL.	Reply	I-Reply	2
As written in our paper, the conventional relation-based GZSL had an inherent problem of failing to predict the unseen classes in the test data (please note that this problem only occurs in GZSL, where the test class contains the seen class).	Reply	I-Reply	2
This is because the mapping to the shared space of the unseen classes does not generalize well and overlaps with the seen classes, which we call the biased problem.	Reply	I-Reply	2
In this study, we showed that manifold learning using VAEs can appropriately place unseen classes in shared space by interpolating from seen classes.	Reply	I-Reply	2
[line_break_token][line_break_token]From the results in table 3, the accuracy of the proposed method was improved significantly in the unseen classes while the accuracy does not change very much in the seen classes, which means that that the proposed method resolves the biased problem directly.	Reply	I-Reply	2
To our knowledge, there is no other study showing that this problem in relation-based is improved.	Reply	I-Reply	2
[line_break_token][line_break_token]> The paper doesn't compare with several recent ZSL and GZSL approaches, some of which have reported accuracies that look much better than the accuracies achieved by the proposed method.	Reply	O	0
[line_break_token]As mentioned above, our study focused on the bias problem of relation-based GZSL and proposed MIVAE as a method to solve it, which is the main contribution of this paper.	Reply	B-Reply	3
Therefore, in our experiments, we compared the proposed method with relation-based studies which have the biased problem in order to confirm whether the problem was resolved.	Reply	I-Reply	3
This is the reason why we did not compare it to synthesis-based methods in this paper.	Reply	I-Reply	3
[line_break_token][line_break_token]Furthermore, as we wrote in the section of related works, synthesis-based needs to generate images from attributes, so it might be difficult to improve accuracy if attributes or images become complicated.	Reply	I-Reply	3
On the other hand, the relation-based method (shared representation method in particular) allows us to select class-attributes closest to the given image in the space of shared representation, which means that we can perform ZSL without depending on the complexity of the input information.	Reply	I-Reply	3
[line_break_token]Our method solved the inherent bias problem while maintaining this advantage of relation-based, so we believe that our method is highly extensible	Reply	I-Reply	3

[line_break_token]This paper tackles the problem of generating rationales for text matching problems (i.e., two pieces of text are given).	Review	O	0
The approach is in a similar spirit as (Lei et al, 2016) while the latter mainly focuses on one piece of text for text classification problems and this work focuses on generating pairs of rationales.	Review	O	0
The approach has been evaluated on NLI and QA datasets, which demonstrates that the generated rationales are sensible and comes at a cost of accuracy.	Review	O	0
[line_break_token][line_break_token]The approach employs a generation-encoding-generation schema: it firsts generates the rationale from one side as a sequence tagging problem, re-encodes the rationales and predicts the rationale on the other side as a span prediction problem.	Review	O	0
Leveraging a match-LSTM framework and generated rationales for prediction, the model can be trained using a policy gradient method.	Review	O	0
[line_break_token][line_break_token]Overall, I think this problem is novel and interesting.	Review	O	0
However, I am not fully convinced whether the proposed solution (and its implementation) is the right way to do so.	Review	O	0
Also, the paper writing needs to much improved.	Review	O	0
[line_break_token][line_break_token]First of all, there is certainly a drop in the end task performance while it is unclear whether the derived rationales are really that useful (if the goal is interpretability) in the current evaluation.	Review	B-Review	1
I am not convinced by the noisy SciTrail evaluation for rationales -- the noisy part p‚Äô can be totally irrelevant and assume that the rationale generation component learns some sort of alignment between two parts, so it is not surprising that the model will not select words from p‚Äô and it doesn‚Äôt really show that the rationales are useful.	Review	I-Review	1
I think it is necessary to conduct some human evaluation for generate rationales and also provide some simple baselines for comparison (for example, just converting the soft-attention in math-LSTM to some hard selections) and see if this interpretability (at a cost of task performance) is really worthy or not.	Review	I-Review	1
[line_break_token][line_break_token]Secondly, I am not sure that whether the current way of generating the rationale pairs really makes sense or not.	Review	I-Review	2
[line_break_token]It casts the rationale generation on one side as a tagging problem while the rationale generation on the other side as a span prediction problem.	Review	I-Review	2
Why is that?	Review	I-Review	2
Do you make any assumption that the two pieces of texts are not symmetric (e.g., one side is much longer than the other side like most of the current QA setup)?	Review	I-Review	2
[line_break_token][line_break_token]There is a regularization term for both x and y but it seems that there isn‚Äôt any constraint that the generated rationales on the y side are not overlapping.	Review	I-Review	3
Is it a problem or not?	Review	I-Review	3
I don‚Äôt know how this is dealt with in the implementation.	Review	I-Review	3
[line_break_token][line_break_token]Understanding sec 3 takes some efforts and I think the presentation could be much improved.	Review	I-Review	4
For example, q * {x^k} is not defined -- I assume it means extracting the subset of q based on the 1‚Äôs in {x^k}. The equations in Sec 3.2 can be made clearer.	Review	I-Review	4
[line_break_token][line_break_token]Finally, it is also unclear that how the 3 datasets were chosen.	Review	I-Review	5
There are so many NLI and QA datasets (some of them are more popular and more competitive) at this point.	Review	I-Review	5
Is there a reason that these datasets were chosen?	Review	I-Review	5
There is a setup called ‚Äòno rationalization w/ re-encoding‚Äô which means that the rationale is already provided on one side, but is unclear that whether the OpenIE tuple and the searchQA queries can be used as rationales directly.	Review	I-Review	5
[line_break_token][line_break_token]Minor points:[line_break_token]- Distal supervision -> distant supervision[line_break_token]- The first paragraph of Introduction, ‚Äúabsent attention or rationale mechanisms‚Äù, what does it mean by ‚Äòabsent attention‚Äô?	Review	O	0
Isn‚Äôt it the case that all the models used attention mechanisms?	Review	B-Review	6
[line_break_token]	Review	O	0
Thank you very much for your valuable comments.	Reply	O	0
 We believe there is some misunderstanding in terms of the difference between our rationalization model and attention-based model.	Reply	O	0
 Please refer to the comments to Reviewer 1 for details.	Reply	O	0
  Your other concerns are addressed below.	Reply	O	0
 [line_break_token][line_break_token]1.	Reply	O	0
Adversarial evaluation on SciTail[line_break_token][line_break_token]Intuitively, if the added noise p‚Äô is totally irrelevant to the context of p, the predictive model should not rely on any information from p'.	Reply	O	0
  However, it is very hard to achieve by many conventional models, especially for these based on word-by-word attention.	Reply	B-Reply	1
 For example, consider the Match-LSTM that computes the contextual similarity between each word from both sides of the text.	Reply	I-Reply	1
  And then, it constructs aggregated representations for the final prediction using soft-attentions normalized from the similarities.	Reply	I-Reply	1
 Even the attention scores on p' are small, the aggregated representations cannot eliminate effects from these texts.	Reply	I-Reply	1
   And the worse thing is that often the attention scores on p' are not very small, especially when the same word/entity appears in both q and p' (even the contexts are totally different).	Reply	I-Reply	1
  This is one potential reason why many QA models are vulnerable to adversarial examples by appending noise, which is shown in the paper of "Adversarial Examples for Evaluating Reading Comprehension Systems" by Robin Jia and Percy Liang.	Reply	I-Reply	1
  Of course, not selecting text from p' does not mean the selected rationales are correct.	Reply	I-Reply	1
 However, it at least demonstrates the generated rationales from our model are fairly robust to adversarial noise.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
Tagging v.s.	Reply	O	0
span prediction[line_break_token][line_break_token]Our rationale generation is formulated as a tagging problem on q and span prediction problem (use <start> and <end> tokens) on q.   The reason why we consider a tagging problem on generating rationales of q is that it can easily achieve the need of the variable number of rationales (via petition).	Reply	O	0
 Then, given a rationale from q, we consider the corresponded rationale generation as span prediction is because that the generated rationale is guaranteed to be consecutive, which is much easy to optimize (via policy gradient) compare to sequence tagging with a continuity regularizer.	Reply	B-Reply	2
 [line_break_token][line_break_token][line_break_token]3.	Reply	O	0
 Overlapping y[line_break_token][line_break_token]There is no explicit regulation to enforce each rationale to be mutually exclusive text span.	Reply	O	0
 The selection of y mainly depends on the selected x.  Different x might correspond to the same piece of text.	Reply	B-Reply	3
 On the other hand, the sparsity loss is summed over all different, which is implicitly to avoid overlapping (e.g. prevent the trivial case that all y^k selects the same text that is the entire p).	Reply	I-Reply	3
 [line_break_token][line_break_token]4.	Reply	I-Reply	5
Dataset and OpenIE as the rationale[line_break_token][line_break_token]As discussed in Section 4.1, we choose AskUbuntu because it is the only text matching dataset used in previous literature on (independent) rationale extraction.	Reply	O	0
We choose the other two mainly because they could provide the "Factwise" settings and help better evaluate the "sub-task of generating corresponded rationales from p".	Reply	B-Reply	5
[line_break_token][line_break_token]We agree that it is difficult to tell whether the OpenIE tuples and SearchQA queries can be used as rationales from the linguistic view.	Reply	I-Reply	5
However, first, empirically they provide us reasonable results when the "No Rationalization w/ re-encoding" was applied.	Reply	I-Reply	5
Second and more importantly, for the "Factwise" experiments, i.e., the rationale is already provided on one side, we mainly hope to have a setting on only the sub-task of "generating corresponded rationales from p".	Reply	I-Reply	5
In this way, we have a closer analysis of the performance and difficulties of this sub-task.	Reply	I-Reply	5
This sub-task itself is not studied in previous work.	Reply	I-Reply	5
We believe it is important to provide such results along with the end-to-end results.	Reply	I-Reply	5

This paper is very interesting as it seems to bring the clock back to Holographic Reduced Representations (HRRs) and their role in Deep Learning.	Review	O	0
It is an important paper as it is always important to learn from the past.	Review	O	0
HRRs have been introduced as a form of representation that is invertible.	Review	O	0
There are two important aspects of this compositional representation: base vectors are generally drawn from a multivariate gaussian distribution and the vector composition operation is the circular convolution.	Review	O	0
In this paper, it is not clear why random vectors have not been used.	Review	B-Review	1
It seems that everything is based on the fact that orthonormality is impose with a regularization function.	Review	I-Review	2
But, how can this regularization function can preserve the properties of the vectors such that when these vectors are composed the properties are preserved.	Review	I-Review	2
[line_break_token][line_break_token]Moreover, the sentence "this is computationally infeasible due to the vast number of unique chunks" is not completely true as HRR have been used to represent trees in "Distributed Tree Kernels" by modifying the composition operation in a shuffled circular convolution.	Review	I-Review	3
Thank you for your interest in our work and your kind words regarding the direction our paper takes.	Reply	O	0
We summarize all the concerns raised and provide a point-by-point response below.	Reply	O	0
[line_break_token][line_break_token](1) ‚ÄúIn this paper, it is not clear why random vectors have not been used‚Äù[line_break_token][line_break_token]We have two points to make regarding this comment.	Reply	O	0
First, we did experiment on using fixed random basis embeddings, be it basis role embeddings or basis filler embeddings.	Reply	B-Reply	1
This is denoted by models with names Fixed-* in Table 1.	Reply	I-Reply	1
This is also mentioned in Page 4, right below Figure 1, ‚Äúwe also consider using fixed random vectors for basis embeddings‚Äù.	Reply	I-Reply	1
Second, if you are referring to using random vectors for not just bases, but also other trainable word-embedding related parameters (such as s^w_i), we think it is better to treat them as learnable parameters since random vectors do not cluster together in a meaningful way that corresponds to natural language.	Reply	I-Reply	1
[line_break_token][line_break_token](2) ‚ÄúBut, how can this regularization function preserve the properties of the vectors such that when these vectors are composed the properties are preserved‚Äù[line_break_token][line_break_token]We agree with this characterization.	Reply	O	0
However, we want to remake the point we make in response to reviewer 3 (point 1, reproduced below)[line_break_token][line_break_token]‚Äú...in our case, the decomposed scoring function actually acts as an (soft) enforcer that makes sure decoding works properly.	Reply	O	0
The loss would only go down when the predicted filler embedding (after decoding) is close to the original filler embedding (before encoding).	Reply	B-Reply	2
This is largely mediated by dot product -- the more accurate the decoding is, the bigger the value of dot product is.	Reply	I-Reply	2
‚Äù[line_break_token][line_break_token]Although it is out our intention to design a theoretically complete model that preserves the properties all the way through, we do mean to take advantage of HRR properties, combined with black-box modeling from neural networks.	Reply	I-Reply	2
We believe this is a reasonable approach to take in order to make our model viable in the world of deep learning.	Reply	I-Reply	2
[line_break_token][line_break_token](3) ‚ÄúMoreover, the sentence ‚Äòthis is computationally infeasible due to the vast number of unique chunks‚Äô is not completely true‚Äù[line_break_token][line_break_token]We meant to say that directly extending our word-level model to chunk-level is not plausible, because for word-level model, we designate a learnable vectorial parameter to each word type.	Reply	O	0
By analogy, we would have to use a learnable vectorial parameter for each unique chunk type, which renders it intractable in our case.	Reply	B-Reply	3
It is in this sense that we meant by saying ‚Äúthis is computationally infeasible‚Äù.	Reply	I-Reply	3
[line_break_token][line_break_token]Hopefully these responses address your concerns	Reply	O	0

[line_break_token]Summary:[line_break_token]This paper proposes a training objective for higher quality video generation for the tasks of Video Super Resolution (VSR) and Unpaired Video Translation (UVT) and also two evaluation metrics tOF and tLP.	Review	O	0
They provide a comprehensive ablative study of the proposed method and also show comparisons against baselines for the tasks of VSR and UVT.	Review	O	0
[line_break_token][line_break_token][line_break_token]Pros:[line_break_token]+ Novel video generation method for VSR and UVT.	Review	O	0
[line_break_token]+ Novel metrics[line_break_token]+ Well written paper[line_break_token][line_break_token]Weaknesses / comments:[line_break_token][line_break_token]- Confused about inputs to discriminator (I_{w,g} and I_{w,b})[line_break_token]I am not sure I understand the inputs I_{w,g} and I_{w,b} to the discriminator network.	Review	O	0
Based on the description, I_{w,g} = {W(g_{t-1}, v_t), g_t, W(g_{t+1}, v_t^‚Äô)} = {g_t, g_t, g_t}, assuming v_t^‚Äù means reverse flow.	Review	B-Review	1
A similar process seems to be happening with I_{w,b}. If this is the case, will the discriminator optimally get the same frame concatenated together (i.e. {g_t, g_t, g_t})?	Review	I-Review	1
Now, if that‚Äôs the case, how is the discriminator modeling temporal consistency other than making the generator learn to put pixels forward and back in place since the ‚Äúoriginal triplets‚Äù (real data) are {g_{t-1}, g_t, g_{t+1}} and {b_{t-1}, g_t, g_{t+1}}, respectively.	Review	I-Review	1
This is very confusing to me.	Review	I-Review	1
It would be good if the authors can clarify this in the rebuttal.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]- How do you prevent the zero output in PP loss?	Review	O	0
[line_break_token]The PP-loss compares forward and backward prediction by || g_t - g_t^‚Äô ||. If not careful, the neural network can just learn to output zeros or the same frame for the full video.	Review	B-Review	2
Did the authors see any behavior like this?	Review	I-Review	2
Or did the proposed formulations prevent this?	Review	I-Review	2
Or was there a very small weight applied to this loss?	Review	I-Review	2
[line_break_token][line_break_token][line_break_token][line_break_token]- TecoGAN vs baselines generator parameters (rather than TecoGAN^{-}).	Review	O	0
[line_break_token]Based on the experimental section, it looks like TecoGAN is the main network being compared to the baseline methods.	Review	B-Review	3
TecoGAN has more parameters in the generator compared to TecoGAN^{-}. Did the authors make sure that the generator had the same number of parameters as the other methods?	Review	I-Review	3
The authors mention a performance difference between TecoGAN and DUF due to DUF having more parameters, but what about the other baselines?	Review	I-Review	3
[line_break_token][line_break_token]- Evaluation metric contributions in the supplementary material?	Review	O	0
[line_break_token]The description of the two proposed metrics tOF and tLP have been placed in Appendix B. These are mentioned as contributions of the paper so their description should be in the main text.	Review	B-Review	4
Please make sure that Appendix B is in the main text in future versions of this paper.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token]- UVT task evaluation in the supplementary material?	Review	O	0
[line_break_token]The UVT task is mentioned in the abstract and as a target task in this work, however, the evaluations for this are in the Appendix.	Review	B-Review	5
Please move them to the main text in future versions of this paper.	Review	I-Review	5
Secondary experiments should be in the Appendix but I feel this is primary.	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]- UVT task only evaluated with the proposed evaluations?	Review	O	0
[line_break_token]The UVT evaluation in the Appendix only has the proposed metrics as evaluation.	Review	B-Review	6
I understand that, since it‚Äôs an unpaired video translation task, there is no ground truth to compare against.	Review	I-Review	6
However, a human based study could be done where human raters would judge for the more realistic of N videos.	Review	I-Review	6
[line_break_token][line_break_token][line_break_token]- The same qualitative comparisons in the paper are not in the provided website.	Review	O	0
[line_break_token]The provided website does not have the same qualitative evaluations as the paper does.	Review	B-Review	7
For example: There are 7 methods being compared for the same video in Figure 8 in the supplementary material, but I don‚Äôt see anything like that in the website.	Review	I-Review	7
[line_break_token][line_break_token][line_break_token]- For the UVT task, we omit the DsDtPP model because ‚Ä¶‚Ä¶.[line_break_token]In the paper, the authors mention that they don‚Äôt provide the DsDtPP baselines because it requires a lot of computation.	Review	O	0
However, I feel these missing baselines make the experiments incomplete since it‚Äôs a different task.	Review	B-Review	8
[line_break_token][line_break_token][line_break_token]- Figure 5 has no point of reference with which to compare the frames.	Review	O	0
[line_break_token]Figure 5 points out that the video b) is better than video a).	Review	B-Review	9
While it is true that one seems more noisy than the other, there should be a point of reference for readers to make sure of it.	Review	I-Review	9
[line_break_token][line_break_token][line_break_token]Conclusion:[line_break_token]In conclusion, the paper seems to present a novel method and evaluation metrics but has many issues as stated above.	Review	O	0
It would make the submission better if the authors can address them in the rebuttal.	Review	O	0
7: ‚ÄúFor the UVT task the DsDtPP model was omitted‚Äù[line_break_token][line_break_token]A7: We have included an additional DsDtPP model for comparison.	Reply	O	0
As we mentioned in the main text, it is necessary to find a good balance between the two generators and the four discriminator networks.	Reply	B-Reply	8
By weighting the temporal adversarial losses from Dt with 0.6 and the spatial ones from Ds with 1.0, the DsDtPP model yields similar performance to the Dst model on the smoke dataset.	Reply	I-Reply	8
A result generated with this model can be found on the Rebuttal_R4.html page.	Reply	I-Reply	8
We can include this model in our submission for completeness, but we would like to point out that the proposed Dst architecture is the better choice in practice, as it learns a natural balance of temporal and spatial components by itself and requires fewer resources.	Reply	I-Reply	8
[line_break_token][line_break_token][line_break_token]Q8: Figure 5 has no point of reference with which to compare the frames.	Reply	O	0
[line_break_token]A8: We will include a ground truth image in our revision for comparison.	Reply	O	0
[line_break_token][line_break_token]Thanks again	Reply	O	0

This paper proposes an extension to VAE to model sequential datasets and extract disentangled representations of their evolution.	Review	O	0
[line_break_token]It consists of a straight extension of CCI-VAE (Burgess et al 2018) to accept sequential data, combining it with a Ladder VAE architecture (VLAE, Zhao et al 2017).	Review	O	0
[line_break_token]They show early results on fitting toy domains involving 2D points moving in space (reaching, reaching in sub-sequences with complex dynamics, gripper domain).	Review	O	0
[line_break_token][line_break_token]Overall, I think this is an interesting piece of work, which proposes a good model extension and assessment of its characteristics.	Review	O	0
The model is well presented, the different components are sufficiently motivated and they perform just enough experiments to showcase the effectiveness of their method, although with some reservations.	Review	O	0
[line_break_token][line_break_token]Critics:[line_break_token]1.	Review	O	0
[tab_token]The comparison to Beta-VAE is a straw man, and I‚Äôm not sure it‚Äôs a valid way to introduce your model.	Review	O	0
You are basically saying that treating sequential data as if it was non-sequential is bad, which is clearly not surprising?	Review	B-Review	1
Hence any comparison with Beta-VAE that you show, Figure 1 and Figure 3, are not appropriate (the caption of Fig 1 is particularly bad in that aspect).	Review	I-Review	1
A more correct comparison would be to directly feed x_1:T to a Beta-VAE and see what happens, maybe with a causal time-convolution as well if you want to avoid 3D filters.	Review	I-Review	1
[line_break_token]2.	Review	O	0
[tab_token]You are also not comparing to the FHVAE model you present in your Introduction, which would have been nice to see, given that your model is simpler and requires less supervision.	Review	B-Review	2
Does FAVAE perform better than these?	Review	I-Review	2
[line_break_token]3.	Review	O	0
[tab_token]Section 3 could use a citation to Esmaeili et al 2018, which breaks out the ELBO even further and compares multiple models in a really nice way (e.g. Table A.2).	Review	O	0
Overall Section 2 and 3 feel a bit long and pedantic, you could just point people to the original papers and move some of the justification to Appendix (e.g. the IB arguments are not that required for your model. ). ‚	Review	B-Review	3
Ä®The main point you want to put across is that you want to have your ‚Äúz‚Äù compress a full trajectory x_1:T, under a single KL pressure (i.e. last sentence of Section 4).	Review	I-Review	3
[line_break_token]4.	Review	O	0
[tab_token]Figure 3 was hard to interpret at first, specifically for panels b and c. Maybe if you showed the ‚Äúsampled trajectory‚Äù only once in another plot it would make it clearer.	Review	O	0
[line_break_token]5.	Review	O	0
[tab_token]Time-convolution seems to wrongly be using the opposite indexing?	Review	O	0
With z_tk = \sum_{p=0}^{H} x_{t+p}, you have an anti-causal filter which looks at the future x_t‚Äô for a z_t?	Review	B-Review	5
That does not sound right?	Review	I-Review	5
Also, you should call these ‚Äúcausal convolutions‚Äù, which is the more standard term.	Review	I-Review	5
[line_break_token]6.	Review	O	0
[tab_token]The exact format of the observations was never clearly explained.	Review	B-Review	6
From 7.1 I understood that you input 2D positions into the models, but what about the Gripper? ‚	Review	I-Review	6
Ä®As you‚Äôre aware, Beta-VAE and others usually get RGB images as inputs, hence you should make that difference rather clear.	Review	I-Review	6
This is a much simpler setting you‚Äôre working in.	Review	I-Review	6
[line_break_token]7.	Review	I-Review	6
[tab_token]Did you anneal the C as was originally proposed in Burgess et al 2018?	Review	O	0
With which schedule?	Review	B-Review	7
This was not clear to me.	Review	I-Review	7
The exact choices of C for the different Ladder levels lacked support as well.	Review	I-Review	7
An overall section in the Appendix about the parameter ranges you tried, the architectures, the observation specifications, the optimisation schedule etc etc would be useful.	Review	I-Review	7
[line_break_token]8.	Review	O	0
[tab_token]I appreciate the introduction of the MIE metric, which seems to slightly improve over MIG in a meaningful way.	Review	O	0
However, it would be good to show situations where the two metrics disagree and why MIE is better, because in the current experiments this is unclear.	Review	B-Review	8
[line_break_token]9.	Review	O	0
[tab_token]Overall the Gripper experiments seem to merit a more complete assessment.	Review	O	0
Figure 7 was hard to understand, and I am not sure it shows clearly any disentangled factors.	Review	B-Review	9
Its caption was strange too (what are the ‚Äú(1, 8)‚Äù, ‚Äú(2, 1)‚Äù things referring to?).	Review	I-Review	9
[line_break_token]10.	Review	O	0
[tab_token]I would have liked more interpretation and comments on why the Ladder is needed, and why FAVAE (without Ladder and C) does so badly in Table 1.	Review	B-Review	10
[line_break_token]11.	Review	O	0
[tab_token]It would be good to know if you really find that the different levels of the Ladder end up extracting different time scales, as you originally claim it can.	Review	O	0
There are no results supporting this assumption in the current version.	Review	B-Review	11
[line_break_token]12.	Review	O	0
[tab_token]Figure 4B uses a bad scale, which makes it hard to assess what happens between the two C conditions for Beta \approx 100, where they seem to differ the most in Fig 4A.[line_break_token]13.	Review	O	0
[tab_token]Figure 5 could use titles/labels indicating which ‚Äúgenerative factors‚Äù you think are being represented.	Review	O	0
Just compare them to your Figure 8 in Appendix.	Review	B-Review	13
[line_break_token]14.	Review	O	0
[tab_token]Figure 6 MIE scores look all within noise between models considered.	Review	O	0
How sensitive is the metric to actual differences in the disentanglement?	Review	B-Review	14
[line_break_token][line_break_token]Overall, I think this is an interesting improvement to disentangled representations learning, but suffers a bit from early experimental results.	Review	O	0
I would still like it to be shown at ICLR though as it really fits the venue.	Review	O	0
[line_break_token]I'm happy to improve my score given some improvements on the points mentioned above.	Review	O	0
[line_break_token][line_break_token]References:[line_break_token]-[tab_token]Burgess et al.,	Review	O	0
2018: <a href="https://arxiv.org/abs/1804.03599" target="_blank" rel="nofollow">https://arxiv.org/abs/1804.03599</a>[line_break_token]-[tab_token]Zhao et al.,	Review	O	0
2017: <a href="https://arxiv.org/abs/1702.08396" target="_blank" rel="nofollow">https://arxiv.org/abs/1702.08396</a> [line_break_token]-[tab_token]Esmaeili et al.,	Review	O	0
2018: <a href="https://arxiv.org/abs/1804.02086" target="_blank" rel="nofollow">https://arxiv.org/abs/1804.02086</a> [line_break_token]	Review	O	0
[line_break_token]1) We reply common to all reviewers: comment 1.	Reply	O	0
We show Fig.	Reply	B-Reply	1
1 and 3 to clarify that the FAVAE extract disentangled representations and beta-VAE extract disentangled representations are different.	Reply	I-Reply	1
The baseline model in quantitative evaluation experiment is compared with sequential model(Time convolution AE).	Reply	I-Reply	1
[line_break_token]2) reply common to all reviewers:1.	Reply	O	0
[line_break_token]3) > The main point you want to put across is that you want to have your ‚Äúz‚Äù compress a full trajectory x_1:T, under a single KL pressure (i.e. last sentence of Section 4).	Reply	O	0
[line_break_token][line_break_token]We agree with the advice.	Reply	O	0
We will modify for space.	Reply	O	0
[line_break_token][line_break_token]4) Since sample trajectory is confusing, we will delete it in Fig.	Reply	O	0
3.	Reply	B-Reply	4
[line_break_token]5) Thank you for pointing out the mistake.	Reply	O	0
We modified eq.	Reply	B-Reply	5
15.	Reply	I-Reply	5
Our model does not use causal convolution, 1D convolution is used.	Reply	I-Reply	5
The reason why Causal convolution is not used is because 1D conv is reasonable as it can use the information of the previous and subsequent time steps.	Reply	I-Reply	5
Also we do not need to use x_t for recurrent at generation, so we can use without causal convolution.	Reply	I-Reply	5
[line_break_token][line_break_token]6) We use the value such as position in Gripper dataset, not the image.	Reply	O	0
We added information on Gripper input x to Appendix B.2.	Reply	B-Reply	6
We should clarify that there is a difference between the image and position input, so we added to Sec.	Reply	I-Reply	6
7.3 that we don't use images as input.	Reply	I-Reply	6
[line_break_token]7) Yes, The scheduling c is originally proposed in Burgess et al 2018.	Reply	O	0
We linear scheduling from 0 to target c as [20,1,5] in 10000 step (all experiments same).	Reply	B-Reply	7
We used the same C in the same ladder(e.g.	Reply	I-Reply	7
1st ladder has 8 z dimension, it's c=20.	Reply	I-Reply	7
2nd ladder has 4 z dimension, it's c=1, 3rd ladder has 2 z dimension, it's c=5) [line_break_token]8) We reply common to all reviewers: comment 4.	Reply	O	0
[line_break_token]9) We improve the cation in Fig.	Reply	O	0
7.	Reply	B-Reply	6
[line_break_token]10) C is an indicator of how much information is left when compressing data.	Reply	O	0
Since 2D Reaching was small in dataset information, the optimum value of C was almost 0.	Reply	B-Reply	10
So for simple data FAVAE will be not bad results with C = 0.	Reply	I-Reply	10
[line_break_token]11) We reply common to all reviewers: comment 3.	Reply	O	0
[line_break_token]12) Does it mean that it is easier to understand by plotting in detail about Œ≤ = 100 in Fig.	Reply	O	0
4B?	Reply	B-Reply	12
[line_break_token]13) Added explanation of factor of 2D wavy Reaching dataset in Fig.	Reply	O	0
5.	Reply	B-Reply	5
[line_break_token]14) > Figure 6 MIE scores look all within noise between models considered.	Reply	O	0
How sensitive is the metric to actual differences in the disentanglement?	Reply	O	0
[line_break_token]In Fig.	Reply	B-Reply	14
6, only at higher ladder 1 have large error case (there was a case like loss> 57 although loss = 0.8 in general).	Reply	O	0
We show the average of loss and MIG in each case (7 out of 10 succeeded).	Reply	B-Reply	14
[line_break_token][line_break_token]||loss|MIG|[line_break_token]|:--:|:--:|:--:|[line_break_token]|success(7)|0.85|0.17|[line_break_token]|fail(3)|57.3|0.071239	Reply	O	0

Summary:[line_break_token]The authors of this paper propose a novel approach for symbolic regression.	Review	O	0
The simulation results demonstrate that the proposed approach can find a better function g producing similar results as desired function f by providing the additional information ‚Äì the leading power of function f.[line_break_token][line_break_token]Paper strength:[line_break_token]1.	Review	O	0
[tab_token]The proposed NG-MCTS is elegant to solve the problem of symbolic regression.	Review	O	0
[line_break_token]2.	Review	O	0
[tab_token]Experiment results illustrate the superiority of the proposed approach[line_break_token][line_break_token]Paper weakness:[line_break_token][line_break_token]1.	Review	O	0
[tab_token]I can follow most of the mathematics in the paper.	Review	B-Review	1
But the most confusing part for me is why you feed the random partial sequence for training.	Review	I-Review	1
Besides, how you do inference to generate a sequence of the production rules.	Review	I-Review	1
[line_break_token]2.	Review	O	0
[tab_token]What is the final objective function?	Review	B-Review	2
If I do not misunderstand, it could be the cross-entropy loss between the output of GRU and the next target production rule, RMSE and the error on leading power.	Review	I-Review	2
Then how you optimize it?	Review	I-Review	2
Please describe more details about this.	Review	I-Review	2
[line_break_token]3.	Review	O	0
[tab_token]The authors of this paper introduce more information ‚Äì leading power of desired function for symbolic regression but they incorporate the additional information by introducing a simple loss function term.	Review	B-Review	3
How about the performance of baseline approaches with those kinds of information?	Review	I-Review	3
[line_break_token]4.	Review	O	0
[tab_token]The whole systems seem like very complicate and it would be more interesting if the authors provide sufficient ablations to decompose the complex algorithm.	Review	O	0
[line_break_token]	Review	O	0
hanks for your feedback and questions.	Reply	O	0
We apologize for the confusion on the framing of this work and appreciate the opportunity to clarify.	Reply	O	0
[line_break_token][line_break_token]There are two main components in our framework:[line_break_token][line_break_token]The first component is a neural network that is trained to generate production rules to construct expressions that are consistent with a given pair of leading powers.	Reply	B-Reply	4
This network learns the relation between syntactic structure and semantic prior (leading powers).	Reply	I-Reply	4
Note that the numerical points are not used in this component.	Reply	I-Reply	4
[line_break_token][line_break_token]The second component is the MCTS algorithm that searches for an expression consistent with a given set of input-output numerical points.	Reply	I-Reply	4
This second component uses the neural network from the first component to guide the search process more effectively.	Reply	I-Reply	4
[line_break_token][line_break_token]1.	Reply	I-Reply	3
The neural network does not generate expression directly.	Reply	I-Reply	1
It is used to guide the search algorithm to the subspace with desired property (leading powers in this case).	Reply	I-Reply	1
 The training dataset of (partial sequence, leading power, next production rule) is randomly sampled from the full production rule sequences of 28837 expressions, and contains the relation between syntactic structure and leading powers.	Reply	I-Reply	1
Since we use a small fraction of expressions in the space for training the network, random sampling ensures that we obtain samples that best represent the distributions of possible combinations of (partial sequence, leading power, next production rule).	Reply	I-Reply	1
[line_break_token][line_break_token]For inference, the neural network generates production rules auto-regressively to construct expressions, by predicting a sequence of production rules starting from the start symbol until all the leaf nodes in the constructed parse tree of the expression are terminal (as described in the first paragraph in Section 5.3).	Reply	I-Reply	1
The network favors the subspace of expressions with desired leading powers.	Reply	I-Reply	1
This results in making MCTS more efficient to find expressions that fit the data points and have the desired leading powers.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
For training the neural network, the training objective is minimizing the cross-entropy loss.	Reply	B-Reply	2
We have a training set of (leading powers, expression) dataset, which is used to construct the corresponding dataset of (partial sequence, leading powers, next production rule).	Reply	I-Reply	2
The network takes as input the leading powers and the sequence of production rules corresponding to the partial expression, and learns to generate the next production rule.	Reply	I-Reply	2
It is formulated as a multi-class classification problem.	Reply	I-Reply	2
[line_break_token][line_break_token]After training the neural network, we use MCTS for searching the expression that fits a given set of data points.	Reply	I-Reply	2
It tries to minimize the RMSE on training points and the absolute difference between the desired leading powers and leading powers of the current expression as the objective function.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	3
We agree with the importance of providing a fair set of baselines.	Reply	I-Reply	3
[line_break_token][line_break_token]Table 1 includes baseline approaches with the additional leading power information (MCTS+PW, EA+PW, and GVAE+PW).	Reply	I-Reply	3
NG-MCTS (71.22% solved) significantly outperforms these baselines with the same information: EA+PW (23.27%), MCTS+PW (0.2%) and GVAE+PW (10%) for M[f]&lt;=4, and similarly for other cases with M[f]=5 and M[f]=6.	Reply	O	0
[line_break_token][line_break_token]4.	Reply	O	0
Ablations can provide important insight into how to attribute the improved performance.	Reply	B-Reply	4
We included several ablations in the experiments on the two main components in our framework:[line_break_token][line_break_token]    (a) For the neural network that learns to generate grammar production rules conditioned on leading powers, we evaluate models with No Condition (NNNC), Random, Full History (FH), Full History No Condition (FHNC), Limited History (LH), and Limited History No Condition (LHNC) in Section 5.3.	Reply	I-Reply	4
[line_break_token][line_break_token]    (b) For the MCTS, we compare MCTS with full information (points and leading power) , MCTS with only leading power information (MCTS (PW-only)),  and MCTS with only the data points.	Reply	I-Reply	4
We perform similar ablations for EA and GVAE.	Reply	I-Reply	4
[line_break_token][line_break_token]All these ablations show the importance of training the neural network on leading powers, and the MCTS that is guided by the neural network model.	Reply	I-Reply	4
[line_break_token][line_break_token]We hope the above clarifications addressed your concerns and we will be happy to discuss more if there are more questions or comments.	Reply	O	0

The authors present a study on scheduling multi-agent communication.	Review	O	0
Specifically, the authors look into cases where agents share the same reward and they are in a partially observable environment, each of them with different observations.	Review	O	0
The main contribution of this work is that authors provide a model for communication scheduling for dealing with cases where only a certain number of agents is allowed to communicate.	Review	O	0
[line_break_token][line_break_token]The paper is very clear, positions the work very well in the literature of MARL and communication.	Review	O	0
The authors perform experiments in two environments and include a number of reasonable baselines (e.g., adapted DIAL for top(k))  as well as the full-communication upper bound.	Review	O	0
[line_break_token]The authors moreover provide a nice analysis on the messages in the predator-pray experiment.	Review	O	0
[line_break_token][line_break_token]My only concern is that authors report "DIAL(1) performs worse than SchedNet-Top(1)".	Review	B-Review	1
 However, Figure 3a clearly shows that Dial(1) to be within the variance of Sched-Top(1) -- from this it's not clear that the null hypothesis can be rejected.	Review	I-Review	1
The authors should probably verify this with a statistical test cause at the moment their claim is unsupported.	Review	I-Review	2
Moreover, why Figure 3c does not contain the same models as Figure 3a (e.g., DIAL appears to be missing)?	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]	Review	O	0
Apologies for the delay in response.	Reply	O	0
We would like to thank the reviewers for evaluating our manuscript.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	2
Statistical testing[line_break_token][line_break_token]As the reviewer commented, the experiment results in our submitted version of the paper does not clearly support our claim which is ‚ÄúSchedNet-Top(1) outperforms DIAL(1)‚Äù due to the large variance.	Reply	I-Reply	2
We have toned down the claim as ‚Äúthe average number of steps to capture the prey in DIAL(1) is larger than that of SchedNet-Top(1)‚Äù in Section 4.1.	Reply	I-Reply	2
[line_break_token][line_break_token]For the reviewer‚Äôs convenience, we report a p-value of 0.075 with just 25 samples collected from a comparative simulation analysis of DIAL(1) and Sched-Top(1).	Reply	I-Reply	2
The p-value shows a decreasing tendency with even just 25 samples, thereby tending towards a non-negligible performance gap that is not attributable to random factors alone.	Reply	I-Reply	2
[line_break_token][line_break_token]We comment that the performance comparison with DIAL(1) is not for showing that SchedNet is better than DIAL(1), but mainly for highlighting that scheduling should be considered to get a higher reward.	Reply	I-Reply	2
We comment that SchedNet is not intended for competing with DIAL but a complementary one.	Reply	I-Reply	2
We believe that adding our idea of agent scheduling makes prior works more practical and valuable.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
Baseline comparison[line_break_token][line_break_token]We have updated the results that show the comparison with other baselines in appendix C.3 of our modified manuscript.	Reply	B-Reply	3
The result shows a similar tendency with the result in PP depicted in Figure 3a.	Reply	I-Reply	3
IDQN and COMA in which no communication is allowed, take a longer time to complete the task compared to other baselines with communication.	Reply	I-Reply	3
DIAL works better than SchedNet-Top(1), however, under the contention constraint the average number of steps to complete the task in DIAL(1) is larger than that of SchedNet-Top(1)	Reply	I-Reply	3

This contribution describes a novel approach for implanted brain-machine interface in order to address calibration problem and covariate shift.	Review	O	0
A latent representation is extracted from SEEG signals and is the input of a LTSM trained to predict muscle activity.	Review	O	0
To mitigate the variation of neural activities across days, the authors compare a CCA approach, a Kullback-Leibler divergence minimization and a novel adversarial approach called ADAN.	Review	O	0
[line_break_token][line_break_token]The authors evaluate their approach on 16-days recording of neurons from the motor cortex of rhesus monkey, along with EMG recording of corresponding the arm and hand.	Review	O	0
The results show that the domain adaptation from the first recording is best handled with the proposed adversarial scheme.	Review	O	0
Compared to CCA-based and KL-based approaches, the ADAN scheme is able to significantly improve the EMG prediction, requiring a relatively small calibration dataset.	Review	O	0
[line_break_token][line_break_token]The individual variability in day-to-day brain signal is difficult to harness and this work offers an interesting approach to address this problem.	Review	O	0
The contributions are well described, the limitation of CCA and KL are convincing and are supported by the experimental results.	Review	O	0
The important work on the figure help to provide a good understanding of the benefit of this approach.	Review	O	0
[line_break_token][line_break_token]Some parts could be improved.	Review	B-Review	1
The results of Fig.	Review	I-Review	1
2B to investigate the role of latent variables extracted from the trained autoencoder are not clear, the simultaneous training could be better explained.	Review	I-Review	1
As the authors claimed that their method allows to make an unsupervised alignment neural recording, independently of the task, an experiment on another dataset could enforce this claim.	Review	I-Review	1
We thank the reviewer for a careful reading of our paper and the positive comments about our work.	Reply	O	0
[line_break_token][line_break_token]Q: ‚ÄúSome parts could be improved.	Reply	O	0
The results of Fig.	Reply	O	0
2B to investigate the role of latent variables extracted from the trained autoencoder are not clear, the simultaneous training could be better explained.	Reply	O	0
As the authors claimed that their method allows to make an unsupervised alignment neural recording, independently of the task, an experiment on another dataset could enforce this claim.	Reply	O	0
‚Äù[line_break_token][line_break_token]A: In the revised version of our paper we have clarified the procedure for training the AE.	Reply	O	0
It is based on a loss function that includes not only the unsupervised neural reconstruction loss but also a supervised regression loss that quantifies the quality of EMG prediction (see Eq 1).	Reply	B-Reply	1
This combined training resulted in low-dimensional latent variables that were then used as inputs to a muscle predictor; this predictor performed as well as a muscle predictor based directly on the high-dimensional neural activity.	Reply	I-Reply	1
 [line_break_token]We do agree that additional experiments, both open loop (offline) and closed loop (online), with additional animals, and involving additional tasks, are required to fully validate our results; we are currently in the process of developing and running these experiments.	Reply	I-Reply	1
A vetting of the computational ideas within the machine learning community is crucial before embarking into extremely time-consuming experiments.	Reply	I-Reply	1

This is a very interesting and relevant paper, attempting to prove that[line_break_token]a deep neural net composed of rectified linear units and a linear output[line_break_token]layer is potentially significantly more powerful than a single layer[line_break_token]net with the same number of units.	Review	O	0
[line_break_token][line_break_token]A strength of the paper is its constructive approach, building up[line_break_token]an understanding of the expressiveness of a model, in terms of the[line_break_token]number of regions it represents.	Review	O	0
It is also notable that the authors pull [line_break_token]in techniques from computational geometry for this construction.	Review	O	0
[line_break_token][line_break_token]But there are several problems with the paper.	Review	B-Review	1
 The writing is unclear,[line_break_token]and overall the paper feels like a preliminary draft, not ready for prime [line_break_token]time.	Review	I-Review	1
[line_break_token][line_break_token]The introduction can be tightened up.	Review	I-Review	2
 A more significant comment[line_break_token]concerns the important attempt to give some intuition, at the top of[line_break_token]page 3.	Review	O	0
 The paragraph starting with 'Specifically' doesn't make sense[line_break_token]to me.	Review	O	0
How can all but one hidden unit be 0 for different intervals[line_break_token]along the real line?	Review	O	0
 Each hidden unit will be active above (or below)[line_break_token]its threshold value, so many positive ones will be active at the same[line_break_token]time.	Review	O	0
 We could compose two hidden units to construct one that is only[line_break_token]active within an interval in R, but I don't see how to do this in one[line_break_token]layer.	Review	O	0
 I must be missing something simple here.	Review	O	0
[line_break_token][line_break_token]I think the basic intuition is that a higher-level unit can act as an[line_break_token]OR of several lower level regions, and gain expressivity by repeating[line_break_token]its operation on these regions, is the idea.	Review	B-Review	4
 But the construction is[line_break_token]not clear.	Review	O	0
 Also, one would expect that the ability to represent AND[line_break_token]operations would also lead to significant expressivity gains.	Review	O	0
 Is this[line_break_token]also part of the construction?	Review	B-Review	5
 These basic issues should be clarified.	Review	I-Review	5
[line_break_token][line_break_token]In addition, it would be very helpful to have some concrete example[line_break_token]of a function that can be computed by a deep net of the sort analyzed[line_break_token]here, which cannot be computed by a shallow net of the same size.	Review	I-Review	6
 [line_break_token]As it stands the characterization of the difference between the deep [line_break_token]and equivalent one-layer network is too abstract to be very compelling.	Review	O	0
[line_break_token][line_break_token]I also found the proof of Theorem 8 very hard to understand.	Review	B-Review	7
 This[line_break_token]is not a key problem, as the authors do a good job building up to[line_break_token]this main theorem, in sections 3 and 4.	Review	O	0
 But it does mean that I am[line_break_token]not confident that the proof is correct.	Review	O	0
[line_break_token][line_break_token]Finally, I would recommend exploring the relationship between the ideas[line_break_token]in this paper and the extensive work in circuit complexity that deals [line_break_token]with multi-level circuits, for example the paper by Hajnal et al on 'Threshold circuits of bounded depth'.	Review	B-Review	8
Thank you for your comments Reviewer 67e9.	Reply	O	0
We have carefully considered them and integrated them in the new version of the paper, which is now available on arxiv (v5).	Reply	O	0
In what follows let us answer to some of your concerns.	Reply	O	0
[line_break_token][line_break_token]'But there are several problems with the paper.	Reply	O	0
The writing is unclear, and overall the paper feels like a preliminary draft, not ready for prime time.'	Reply	O	0
[line_break_token][line_break_token]We think the paper has improved steadily since the initial submission and we hope that, in the new version, it is clear and up to ICLR quality standards.	Reply	B-Reply	1
[line_break_token]The paper offers a new perspective on a hard question and we think that the presented ideas can be useful for addressing a variety of related problems.	Reply	I-Reply	1
[line_break_token][line_break_token]'The introduction can be tightened up.'	Reply	O	0
[line_break_token][line_break_token]We shortened the Introduction.	Reply	B-Reply	2
[line_break_token][line_break_token]'A more significant comment concerns the important attempt to give some intuition, at the top of page 3...'[line_break_token][line_break_token]In our attempt to provide a simplest possible example of the mechanism behind our proof, we unfortunately made a mistake.	Reply	O	0
You are right, with a single input unit it is not possible to networks for which distinct units are active at different input intervals in the way that it was claimed in that example.	Reply	B-Reply	3
Thank you for pointing this out.	Reply	I-Reply	3
We fixed the mistake.	Reply	I-Reply	3
Proposition 7 (now Proposition 4) indicates the relevant conditions.	Reply	O	0
[line_break_token][line_break_token]'I think the basic intuition is that a higher-level unit can act as an OR of several lower level regions...'[line_break_token][line_break_token]Exactly, this is the intuition that we were trying to convey in that paragraph.	Reply	O	0
This intuition builds the main mechanism behind our proof of the main theorem.	Reply	B-Reply	4
We hope that with the changes made to the manuscript the construction is now clearer.	Reply	I-Reply	4
[line_break_token][line_break_token]'Also, one would expect that the ability to represent AND operations would also lead to significant expressivity gains. '	Reply	O	0
[line_break_token][line_break_token]The offered proof relies only on the OR operation, but one should be careful about what this means exactly.	Reply	B-Reply	5
[line_break_token]Specifically,  we do not compute the OR between two values and provide the result as output of the layer.	Reply	I-Reply	5
Instead, what this OR operations describes is that some particular output value can be obtained from various inputs input1 OR input2 OR input3, etc.	Reply	I-Reply	5
In this context an AND operation does not make sense.	Reply	I-Reply	5
[line_break_token][line_break_token]What we are describing here is a function that is not injective, i.e., which has distinct domain values that are mapped to the same output value.	Reply	I-Reply	5
Of course, the injectivity is lifted to the level of domain or input regions rather than individual input values.	Reply	I-Reply	5
However you can see how AND becomes impossible to express in these terms.	Reply	I-Reply	5
[line_break_token][line_break_token]'In addition, it would be very helpful to have some concrete example of a function that can be computed by a deep net of the sort analyzed here...'[line_break_token][line_break_token]Thank you for the suggestion.	Reply	O	0
We included a description of more intuitive classes of functions computable by rectifier models in Section 5, together with toy examples with 2-dimensional inputs.	Reply	B-Reply	6
[line_break_token]While Theorem focuses more on the asymptotic regime, the new construction given in Section 5 shows that there are classes of functions that can be computed far more efficiently by deep networks than by shallow ones, even if the number of layers of the deep networks is relatively small, say equal to 3 or 4.	Reply	I-Reply	6
[line_break_token][line_break_token]'I also found the proof of Theorem 8 very hard to understand..'[line_break_token][line_break_token]We completely overworked that proof, putting attention to the consistency of the notation and maintaining the mathematics precise.	Reply	O	0
We extracted parts of the proof into propositions, in order to make the steps clearer.	Reply	B-Reply	7
[line_break_token][line_break_token]'Finally, I would recommend exploring the relationship between the ideas in this paper and the extensive work in circuit complexity... '[line_break_token][line_break_token]Thank you.	Reply	O	0
We will look carefully at that literature.	Reply	B-Reply	8
There might be some interesting connections	Reply	I-Reply	8

<Summary>: This paper presented a method for incorporating binary relationship between objects (relative location, rotation and scale) into single object 3d prediction.	Review	O	0
It is built on top of previously published work of [a] and used same network architecture and loss as of [a] and only added the binary relations between objects for object 3d estimation.	Review	O	0
The results are shown on SUNCG synthetic dataset and only *4 image* instances of NYUv2 dataset which is very small for a computer vision task.	Review	O	0
[line_break_token][line_break_token][a] Shubham Tulsiani, Saurabh Gupta, David Fouhey, Alexei A Efros, and Jitendra Malik.	Review	O	0
Factoring shape, pose, and layout from the 2d image of a 3d scene.	Review	O	0
In CVPR, 2018.	Review	O	0
[line_break_token][line_break_token]<Pros>: The paper tackles a problem of obvious interest to computer vision research community.	Review	O	0
It shows better results compared to previous similar work of [a] without considering binary relation between objects.	Review	O	0
[line_break_token][line_break_token]<Cons>:[line_break_token][line_break_token]*Technical details are missing:[line_break_token][line_break_token]The set of known and unknown variables are not clear throughout the paper:[line_break_token]-The extrinsic camera parameters are known or estimated by the method?	Review	O	0
[line_break_token]-The intrinsic camera parameters are known or estimated by the method?	Review	B-Review	3
[line_break_token]-What are the properties of ground truth bounding boxes in 2D camera frame and 3D space?	Review	O	0
[line_break_token]-What is the coordinate of translation?	Review	O	0
is it in camera coordinate or world coordinate?	Review	B-Review	1
[line_break_token]-What are the variations of camera poses in training and testing for synthetic dataset and how are the samples generated?	Review	O	0
Are the train/test images generated or are rendered images from previously published work of [b] used?	Review	B-Review	2
[line_break_token][line_break_token][b] Yinda Zhang, Shuran Song, Ersin Yumer, Manolis Savva, Joon-Young Lee, Hailin Jin, and Thomas Funkhouser.	Review	I-Review	2
Physically-based rendering for indoor scene understanding using convolutional neural networks.	Review	I-Review	2
In CVPR, 2017.	Review	I-Review	2
[line_break_token][line_break_token]*The proposed method is trained on synthetic dataset of SUNCG and their object relations have biases from scene creators.	Review	O	0
While using binary relation between objects increase the recall in prediction it can also make the predictions bias to the most dominant relations and decrease the precision of detection in rare cases in synthetic dataset.	Review	B-Review	6
Also, such bias can decrease prediction precision in images of real scenes.	Review	I-Review	6
[line_break_token] [line_break_token]*One of the main issues in this paper is that the result of fully automated pipeline versus having ground-truth annotation at test time are mixed up.	Review	O	0
For example, in the teaser figure (Figure 1-b), does the proposed method use ground truth bounding boxes or not?	Review	B-Review	8
It is mentioned in figure caption: ‚Äú(b) Output: An example result of our method that takes as input the 2D image and generates the 3D layout.	Review	I-Review	8
‚Äù.	Review	I-Review	8
Is the input only 2D image or 2D image + ground truth object bounding boxes?	Review	I-Review	8
[line_break_token]In order to make sure that reader understands each qualitative result, there should be a column showing the ‚ÄúInput‚Äù to the pipeline (Not ‚ÄúImage‚Äù).	Review	I-Review	7
For example, in Figure 3 and Figure 4, the image overlaid with input ground-truth bounding boxes should be shown as input to the algorithm.	Review	I-Review	7
[line_break_token][line_break_token][line_break_token]*The experiments and results does not convey the effectiveness of the proposed approach.	Review	O	0
There are major issues with the quality of the experiments and results.	Review	O	0
Here are several examples:[line_break_token][line_break_token]- Missing baseline: Comparison with the CRF-based baseline is missing.	Review	O	0
This statement is not convincing in the introduction: ‚ÄúOne classical approach is to use graphical models such as CRFs.	Review	B-Review	14
However, these classical approaches have usually provided little improvements over object-based approaches.	Review	I-Review	14
‚Äù For a fair comparison with prior works, reporting results on a CRF-based baseline using similar unary predictions is necessary.	Review	I-Review	14
[line_break_token][line_break_token]-The experimental results are heavily based on ground truth boxes for the objects, but it is not clear how/where the ground truth boxes are given at the test time and which part is actually predicted.	Review	O	0
[line_break_token][line_break_token]-If the ground truth boxes are given at the test time, it means that the ground truth binary relations between objects are given and it makes the problem trivial.	Review	O	0
[line_break_token][line_break_token]-It is not clear what is the ground truth box in experimental setup.	Review	O	0
Is it amodal object box or the ground truth box contains only the visible part of the object?	Review	B-Review	2
[line_break_token][line_break_token]-The qualitative results shown in Figure 4 have full objects in voxel space with predicted rotation, scale and translation.	Review	O	0
In the qualitative result of Figure 3 and Figure 5 the voxel prediction is shown as final output.	Review	B-Review	5
Why the result of full object in voxel space with predicted (rotation, scale and translation) is not shown in Figure 3 and Figure 5 and why it is shown in Figure 4?	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]*Very limited results on real images:[line_break_token][line_break_token]-Quantitative result on a dataset of real images is missing.	Review	O	0
The results on synthetic datasets is not a good proxy for the actual performance of the algorithm in real use cases and applications.	Review	B-Review	12
[line_break_token][line_break_token]- The paper only shows few results of NYUv2 on known ground truth boxes.	Review	O	0
The errors in object detection can be propagated to the 3D estimation therefore these qualitative results are not representative of the actual qualitative performance of the proposed algorithm.	Review	B-Review	13
Several randomly selected qualitative results on a dataset of real images ‚Äúwithout ground-truth boxes‚Äù are needed for evaluating the performance of the proposed method on real images.	Review	I-Review	13
[line_break_token][line_break_token]-Reporting variation in all parameters of scale, rotation and translation is necessary in order to find the difficulty of the problem.	Review	O	0
For example, what is the distribution of object scale in different object categories.	Review	B-Review	1
What is the error of scale prediction of we use mean object scale for each object category for all object instance at test set?	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]*Unclear statements and presentation:[line_break_token][line_break_token]- It is mentioned in the paper: ‚ÄúWhile the incorporation of unary and relative predictions can be expressed via linear constraints in the case of translation and scale, a similar closed form update does not apply for rotation because of the framing as a classification task and non-linearity of the manifold.	Review	O	0
‚Äù[line_break_token][line_break_token]-Is it necessary for the relative rotation to be formulated to classification task?	Review	O	0
[line_break_token][line_break_token]-If not the comparison of modeling relative rotation via linear constraints is missing.	Review	O	0
[line_break_token][line_break_token]- In some of the tables and figures the ‚Äúknow ground-truth boxes/detection setting‚Äù are in bold face and in some cases are not.	Review	O	0
This should be consistent throughout the paper.	Review	B-Review	9
[line_break_token]	Review	O	0
We thank the reviewer for the comments.	Reply	O	0
Below we address specific concerns regarding the work.	Reply	O	0
[line_break_token][line_break_token][Missing details][line_break_token]We point out relevant sections in the original submission where we already had mentioned the details.	Reply	O	0
[line_break_token][line_break_token]- Translation in camera vs. world frame: In Section 3.1, we outline the parameterization of the 3D pose in terms of translation, rotation, and scale in the camera frame.	Reply	O	0
[line_break_token]- Rendered images and pose variations: As we mentioned in Section 4.1 (Experimental Setup).	Reply	O	0
We use the rendered images provided by Zhang et al.[1] Their work generated these images with a variety of different camera poses.	Reply	B-Reply	2
We randomly partition this set of images into three splits from different houses - 70% (train), 10% (val) and 20% (test).	Reply	I-Reply	2
[line_break_token]- Extrinsic vs. Intrinsic camera parameters: We estimate the pose of objects in the camera frame we can say that the extrinsics are Identity.	Reply	O	0
Also, we make no assumptions about Intrinsics of the camera.	Reply	B-Reply	3
This is outlined in Section 3.1 (page 3).	Reply	I-Reply	3
[line_break_token][line_break_token]- Properties of ground truth boxes in 2D: In Section 4.2, we explain that we only input the ground truth boxes in 2D. We are unclear on what the reviewer means by ‚Äúproperties‚Äù of bounding boxes in 3D space but would be happy to clarify if the reviewer can elaborate.	Reply	O	0
[line_break_token][line_break_token]- What part is predicted at test time: In Section 4.2, the ground-truth 2D boxes and the image are given as input and the method predicts the 3D pose and shape of each object.	Reply	O	0
In Section 4.3, the image is given as input and the method first detects the objects and then predicts the 3D pose of each object.	Reply	B-Reply	4
We predict the voxel of the object for the experiments on the SUNCG dataset.	Reply	I-Reply	4
[line_break_token][line_break_token]- No voxel output in Figure 4: As we mention in the Figure 4 caption - "We use the ground-truth meshes for visualization due to lack of variability in shape annotations for learning." (	Reply	O	0
We have also described this in section 4.1, NYUv2 setup)[line_break_token] [line_break_token]- "object relations have biases from scene creators" (in SUNCG): We appreciate the concerns about the biases in the synthetic data, but note that we do show results on the real images from the NYUv2 dataset.	Reply	O	0
[line_break_token][line_break_token]Unclear presentation: We thank the reviewer for these suggestions.	Reply	O	0
They will surely help us improve the quality of the paper.	Reply	O	0
[line_break_token]- Set of knowns vs. Unknowns: We will clarify this in the paper.	Reply	O	0
Your suggestion of using "Input" in the figures as opposed to "Image" is a great one and will be incorporated.	Reply	B-Reply	7
[line_break_token]- Figure 1 (b): The input to the method is the 2D image and the associated ground-truth object bounding boxes.	Reply	O	0
The output is the 3D pose and shape for each object.	Reply	B-Reply	8
[line_break_token]- Amodal box vs. full box: We use 2D bounding boxes as is standard in the object detection literature.	Reply	O	0
These boxes are *not* amodal.	Reply	B-Reply	9
[line_break_token]- Relative rotation as classification, and (possible) missing comparison to linear baseline: As quaternion algebra is non-commutative the quaternion "vector" space is not linear.	Reply	O	0
Thus, we formulate relative rotation as a classification problem, and hence there is no linear baseline.	Reply	B-Reply	10
Also, note that previous works have also modeled rotation as a classification problem.	Reply	I-Reply	10
[line_break_token][line_break_token]Incorrect statements by the reviewer[line_break_token]- Ground truth boxes are given implies relations are given: This is incorrect.	Reply	O	0
The boxes are in 2D while the relations we use and predict in the paper are in 3D coordinates.	Reply	B-Reply	11
[line_break_token]- "Quantitative result on a dataset of real images is missing": Please see Table 1 that shows quantitative results on the NYUv2 dataset.	Reply	O	0
[line_break_token]- "*4 image* instances of NYUv2 dataset": This statement is a mis-characterization of our work.	Reply	O	0
We only visualize results of a few images but note that Table 1 reports evaluations using *all* (654)  test set images on NYUv2.	Reply	B-Reply	13
This is explained in Section 4.1.	Reply	I-Reply	13
[line_break_token][line_break_token]Missing baseline[line_break_token]- CRF baseline: While this is an excellent suggestion, there are many practical reasons why it is not straightforward for us to do this.	Reply	O	0
CRF based methods typically rely on class-specific pairwise potentials, and while these can be designed for specific cases (e.g. chair-table), there are numerous non-trivial design decisions that make this not scalable for generic classes e.g. what is the form of potential function, do all (or only nearby) object pairs have an edge between them, do all classes pairs have potential functions etc.	Reply	B-Reply	14
However, if the reviewer has any specific suggestions regarding a CRF baseline that can generically handle 3D pose across classes, we would be happy to compare.	Reply	I-Reply	14
We would also like to point out the GCN baseline, which also does message passing, can be considered as an implicitly learned CRF.	Reply	I-Reply	14

The authors propose several approaches to making a data-to-text generation system more precise, that is, less prone to hallucination.	Review	O	0
 In particular, they propose an attention score, which attempts to measure to what degree the model is relying on its attention mechanism in making a prediction.	Review	O	0
This attention score is used to weight a mixture distribution (a "confidence score") over the generation model's next-word distribution and the next-word distribution of an unconditional language model.	Review	O	0
The learned conditional distribution can then be calibrated to the confidence score.	Review	O	0
The authors also propose a variational-inference inspired objective, which attempts to allow the model to ignore certain tokens it isn't confident about.	Review	O	0
The authors evaluate their approach on the WikiBio dataset, and find that their approaches make their system more precise, at the cost of some coverage.	Review	O	0
[line_break_token][line_break_token]This paper is well motivated, timely, and it presents several interesting ideas.	Review	O	0
However, I think parts of the proposed approach need to be better justified.	Review	O	0
In particular:[line_break_token][line_break_token]-  What justifies defining the attention score A_t in this way?	Review	O	0
First, is there an argument (empirical or otherwise) for using the magnitude of the attention vector (rather than some other statistic)?	Review	B-Review	1
Is it obvious that if the attention vector has a high magnitude then it ought to be trusted?	Review	I-Review	1
Note that this might be a reasonable assumption in the case of a pointer-generator style model, where a single attention vector is used both for attending and for copying, but in a model where attention isn't constrained in this way the magnitude of the attention vector may be misleading.	Review	I-Review	1
[line_break_token][line_break_token]- The variational objective seems difficult to justify.	Review	O	0
First, I don't understand what it means for p(y | z, x) to be assumed to 1.	Review	B-Review	2
Is this for any z (in which case y is independent of z)?	Review	I-Review	2
Otherwise, how can it be removed from the objective? (	Review	I-Review	2
Put another way: Equation (17) is not in general true; it neglects an expected log likelihood term).	Review	I-Review	2
I'm also not entirely clear on how Equation (12) is modeled: do the z's really only rely on the other sampled z's?	Review	I-Review	5
Doesn't that require a different model than the one that calculates P^{\kappa}?	Review	I-Review	6
[line_break_token][line_break_token]- Somewhat minor: the claim that optimizing the joint objective needn't hurt perplexity relies on kappa being 0; have you confirmed empirically that when it isn't zero the perplexity improves over the baseline model?	Review	O	0
[line_break_token][line_break_token]- Finally, I'm not sure I understand why there needs to be a stop-gradient in equation (4).	Review	O	0
It would be nice to also verify empirically that this is important.	Review	B-Review	4
[line_break_token][line_break_token]	Review	O	0
hanks for the detailed review.	Reply	O	0
In addition to the revisions of our paper, we have also empirically investigated perplexity as suggested by the reviewer.	Reply	O	0
[line_break_token][line_break_token]&gt; What justifies defining the attention score A_t in this way?	Reply	O	0
Is it obvious that if the attention vector has a high magnitude then it ought to be trusted?	Reply	O	0
[line_break_token][line_break_token]The attention score A_t measures how much the model actually relies on the source to make a prediction.	Reply	B-Reply	1
Since the context vector v_t is defined as a_t + h_t in Equation (2), defining A_t in this way as a magnitude ratio measures how much a_t affects v_t.	Reply	I-Reply	1
In practice, A_t is usually high (~0.9) when the model is copying from the source (e.g. ‚ÄúCampbell‚Äù in Figure 2), medium (~0.4) when the model is generating based on some information from the source (e.g. ‚Äú&lt;unk&gt;‚Äù in Figure 2), and low (~0.2) when the model is generating template elements (e.g. ‚Äúis‚Äù in Figure 2).	Reply	O	0
More examples are added to our revised paper.	Reply	B-Reply	1
This observation does not immediately mean that a generation with higher attention score should be trusted; whether to trust a token or not is assessed by the confidence score.	Reply	I-Reply	1
We will discuss this next.	Reply	I-Reply	1
[line_break_token][line_break_token]Our confidence score depends on both the attention score and generation probabilities.	Reply	I-Reply	1
The idea of our confidence score was originated from an observation on baseline predictions of Wikibio: Hallucination often occurs when the table lacks some field that usually exists, for example the ‚ÄúOccupation‚Äù field is missing in Figure 1, and the baseline model makes that up.	Reply	I-Reply	1
In such cases, the conditioned generation probability can still be high (e.g. &gt;0.5), so we cannot tell it from the conditioned generation probability alone.	Reply	O	0
But, since some usual field is missing, the attention score as we defined tends to be low, and it might be used to detect such hallucination cases.	Reply	B-Reply	1
However, the attention score is also low for function words and template elements.	Reply	I-Reply	1
Thus, we further incorporate an unconditioned generation probability (base-LM) to detect those cases.	Reply	I-Reply	1
[line_break_token][line_break_token]This motivation is made clearer in our revised paper.	Reply	I-Reply	1
[line_break_token][line_break_token]From a higher point of view, we do not claim that our definition of the confidence and attention scores are optimal; we proposed one way to implement the intuition.	Reply	I-Reply	1
We have demonstrated several pieces of evidence that this implementation works: Figure 2 qualitatively demonstrates that the scores match human intuition; experiments regarding thresholding and ablation, etc.	Reply	I-Reply	1
We believe they are all firm justifications for our model design.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding design details, we have tried several other variations of the attention score, the base-LM input-feeding, and the confidence score.	Reply	I-Reply	1
The current implementation is selected based on PARENT F1 and manually investigating the learned scores.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; what it means for p(y | z, x) to be assumed to 1[line_break_token][line_break_token]Intuitively, we are assuming an oracle that can always recover the original target sequence y from its subsequence z; this is reasonable during training because we always know the gold reference for each training example.	Reply	O	0
Technically, we note that p(y | z, x) is part of the model rather than the data.	Reply	B-Reply	2
So this is just a modeling assumption that simplifies the formula.	Reply	I-Reply	2
We assume p(y | z, x) to be a probability distribution over all possible target sequences, such that the probability is 1 for the gold reference and 0 otherwise.	Reply	I-Reply	2
Yes, this distribution is the same for all z, as long as z is a subsequence taken from y. We don‚Äôt see any issue here.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; how Equation (12) is modeled: do the z's really only rely on the other sampled z's?	Reply	O	0
[line_break_token][line_break_token]Yes.	Reply	B-Reply	5
[line_break_token][line_break_token]&gt; Doesn't that require a different model than the one that calculates P^{\kappa}?	Reply	O	0
[line_break_token][line_break_token]No, we don‚Äôt need a different model.	Reply	B-Reply	6
We are treating z as if z is the gold reference, and train our model to target this confident subsequence.	Reply	I-Reply	6
This way, the generation model actually learns to skip unconfident tokens. (	Reply	I-Reply	6
Reviewer #1 raised concerns about this setting that it might cause disfluent generations; the fact that it does not is also a surprise for us.	Reply	I-Reply	6
Please see the discussions there.)	Reply	I-Reply	6
[line_break_token][line_break_token]&gt; have you confirmed empirically that when it isn't zero the perplexity improves over the baseline model?	Reply	O	0
[line_break_token][line_break_token]This is an interesting question.	Reply	B-Reply	3
First, we note an issue with perplexity on the WikiBio dataset: there are noisy tokens in the data whose log-likelihood converge to -inf.	Reply	I-Reply	3
In our implementation, we set the smallest log-likelihood to log(2^{-100})=-69.3.	Reply	I-Reply	3
Then, we compare the Pointer-Generator baseline with our No-variational model because the variational loss introduces random sampling into the training process.	Reply	I-Reply	3
We report the log-perplexity as follows:[line_break_token][line_break_token]No-variational, kappa learned: 31.19 (Train)  39.24 (Valid)[line_break_token]No-variational, kappa=0:   31.21 (Train) 39.08 (Valid)[line_break_token]Pointer-Generator:   32.41 (Train) 40.14 (Valid)[line_break_token][line_break_token]So, compared to kappa=0, using learned kappa indeed improves training perplexity, but the validation perplexity gets worse.	Reply	I-Reply	3
On the other hand, calibration improves the perplexity over the Pointer-Generator baseline, on both training and validation sets.	Reply	I-Reply	3

This paper embraces the idea that better multi-task/lifelong learning can be achieved if tasks produce gradients that are orthogonal to the gradients produced by other tasks.	Review	O	0
The authors propose an approach to regularizing learning in order to incentivize this to happen.	Review	O	0
However, as they mention themselves, the regularized loss is computationally intractable in general and they only apply it to a subset of their network as a result.	Review	O	0
Given the computational scalability concerns, it is natural to wonder why researchers in the community would adopt this approach rather than other approaches that also aim to make gradients orthogonal.	Review	O	0
[line_break_token][line_break_token]The idea of producing orthogonal gradients across tasks or examples is not new in the context of lifelong/multi-task learning.	Review	B-Review	1
In fact, just to name a few, [1] demonstrated that noise alone can lead to orthogonal gradients, [2] demonstrated that modular neural network architectures can lead to orthogonal gradients and less interference.	Review	I-Review	1
Additionally, sparsity naturally leads to orthogonal gradients as does the recent approach in [3].  These approaches achieve orthogonal gradients without adding a significant computational burden to learning.	Review	I-Review	1
This paper can be greatly improved by discussing past approaches to producing orthogonal gradients and why they are theoretically / empirically worse than CosReg.	Review	I-Review	1
[line_break_token][line_break_token][1] "A theory for how sensorimotor skills are learned and retained in noisy and nonstationary neural circuits".	Review	O	0
Robert Ajemian, Alessandro D‚ÄôAusilio,  Helene Moorman, and  Emilio Bizzi.	Review	O	0
PNAS'13.	Review	O	0
[line_break_token][line_break_token][2] "Routing Networks: Adaptive Selection of Non-linear Functions for Multi-Task Learning".	Review	O	0
Clemens Rosenbaum, Tim Klinger, and Matthew Riemer.	Review	O	0
ICLR'18.	Review	O	0
[line_break_token][line_break_token][3] "Meta-Learning Representations for Continual Learning".	Review	O	0
Khurram Javed and Martha White.	Review	O	0
2019.	Review	O	0
[line_break_token][line_break_token]Additionally, despite much past work, I tend to think that the entire quest for orthogonal gradients is not particularly well motivated as it is missing half of the story.	Review	B-Review	2
Orthogonal gradients only address the problem of interference during learning, but don't help maximize transfer during learning.	Review	I-Review	2
In fact, intuitively Figure 2 showcases that CosReg diminishes transfer during learning in comparison to baselines.	Review	I-Review	2
Some recent work, such as [4] and [5], argues that what we really want is to maximize the dot product of gradients i.e. their alignment.	Review	I-Review	2
This perspective achieves the best of both worlds as it incentivizes orthogonality to address interference while also incentivizing positive transfer.	Review	I-Review	2
I wonder how the authors would position their work relative to the body of work that optimizes for the gradient dot product.	Review	I-Review	2
Why would we like gradients to be orthogonal if there would otherwise be transfer?	Review	I-Review	2
Why focus on the cosine rather than the dot product, which naturally comes out of the first order Taylor expansion derivation for each task?	Review	I-Review	2
[line_break_token][line_break_token][4] "On First-Order Meta-Learning Algorithms".	Review	O	0
Alex Nichol, Joshua Achiam, John Schulman.	Review	O	0
2018.	Review	O	0
[line_break_token][line_break_token][5] "Learning to Learn without Forgetting by Maximizing Transfer and Minimizing Interference".	Review	O	0
Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, and Gerald Tesauro.	Review	O	0
ICLR'19.	Review	O	0
[line_break_token][line_break_token]Given my major concerns about the theoretical motivation and comparisons to past work, I do not find the experiments comprehensive enough to prove the value of the proposed approach to the community.	Review	B-Review	3
At the very least, I would be interested in comparison with additional very relevant baselines and in experiments with more tasks.	Review	I-Review	3
 [line_break_token][line_break_token]Update After Author Feedback: [line_break_token][line_break_token]While I really appreciate the authors providing some context about the references, I still feel like the paper would benefit from increased empirical comparison with these past approaches.	Review	O	0
Unfortunately, I don‚Äôt really follow the point they are making about why it is better to produce orthogonality vs. high dot products.	Review	B-Review	2
 I agree that catastrophic forgetting is more of a problem related to continual learning, but I am not sure why we wouldn't want to maximize transfer even if there was no forgetting or interference.	Review	I-Review	2
  Given my continued concerns, I am inclined to keep my score the same.	Review	I-Review	2
e thank the reviewer for the feedback and for pointing out related work we have missed.	Reply	O	0
[line_break_token][line_break_token][line_break_token]1.	Reply	O	0
Cited papers related to orthogonal gradients.	Reply	O	0
[line_break_token][line_break_token][1] focuses on the stability-plasticity dilemma in hyper-plastic noisy networks.	Reply	B-Reply	1
The point they are making is that under conditions of large redundancy, extreme noise and high learning rates a multi-task network can still reach a dynamic equilibrium.	Reply	I-Reply	1
They state that this is possible because at the point of convergence the solution will have orthogonal task gradients.	Reply	I-Reply	1
As far as we can assess they don't make any reference to the orthogonality of task gradients during training.	Reply	I-Reply	1
Furthermore, their theory is in line with our observations that in later stages of training the variance of the gradient distribution decreases as the cosine converges to 0.	Reply	I-Reply	1
Our contribution however, lies in obtaining orthogonality throughout training which obtains competitive multi-task solutions.	Reply	I-Reply	1
[line_break_token][line_break_token][2] propose a method for dynamically assigning parameters, or functional blocks, depending on the input and task.	Reply	I-Reply	1
Their contribution is an architecture focused approach that is closely related to the soft parameter sharing paradigm.	Reply	I-Reply	1
Our method on the other hand is a loss focused method suited exclusively for hard parameter sharing models.	Reply	I-Reply	1
Consequently they achieve non interference by using different parameter partitions for different tasks, while we achieve this by regularizing gradients that affect the same set of parameters for all tasks.	Reply	I-Reply	1
While both methods reduce task interference, the nature of the models they are designed for is entirely different.	Reply	I-Reply	1
[line_break_token][line_break_token][3] devise a meta-learning algorithm that reduces task interference in a continual learning setting.	Reply	I-Reply	1
Their method nudges learning of representations that are robust to interference, which turn out to be sparse.	Reply	I-Reply	1
We agree that having sparse representations reduces task interference, and in a way it is related to our motivation behind CosReg - to force the optimizer to update parameters differently for each task during an iteration.	Reply	I-Reply	1
Our method however doesn't directly induce sparsity constraints, which means it is less invasive on how the network should learn its representations.	Reply	I-Reply	1
Future work can however investigate the learned representations.	Reply	I-Reply	1
[line_break_token][line_break_token]With respect to computational tractability - the execution time increases with the number of layers used for the gradient computation.	Reply	I-Reply	1
Preliminary results seem to suggest however that CosReg is most effective on the layers closer to the encoders, which incur only a limited computational overhead.	Reply	I-Reply	1
We will further quantify the performance when using gradients of different sizes and at varying positions.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Using the dot product as a penalty term.	Reply	O	0
[line_break_token]We believe there is a distinction to be made between training interference/transfer and overall performance in a MTL setting.	Reply	B-Reply	2
Transfer is indeed maximized when gradients are pointing in the same direction but it is unclear whether this would also lead to a better performing solution in a multi-task setting.	Reply	I-Reply	2
Standley et al.	Reply	I-Reply	2
seem to make such a finding when analyzing what tasks can be learned together and our recent results on the SUN RGB-D dataset agree.	Reply	I-Reply	2
Furthermore, the cited papers are in the domain of continual learning for which the main problem is catastrophic forgetting.	Reply	I-Reply	2
In that setup it makes sense to have gradients of new tasks align with those of previous tasks.	Reply	I-Reply	2
In a multi-task setting however there is no risk of forgetting as data from all tasks are available at all times.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Refs:[line_break_token]Which Tasks Should Be Learned Together in Multi-task Learning?	Reply	O	0
Standley 201	Reply	O	0

 This work presents an encoder-decoder network architecture that is conditioned on the high-level representation of a person‚Äôs facial image for face de-identification that enables fully automatic video modification.	Review	O	0
The effectiveness of the proposed method is verified qualitatively and quantitatively.	Review	O	0
Although the novelty of the method is not impressive, the proposed method seems to be useful for face-related applications and the experimental results are convincing to me.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- This method is simple, apparently effective and is a nice use of adversarial encoder-decoder for a practical task.	Review	O	0
The paper is written clearly and the English is fine.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- My main concern with this paper is regarding the novelty.	Review	O	0
The authors seem to claim a novel GAN architecture by using an auto-encoder-based network architecture with a pre-trained face recognition network and multi-image perceptual loss.	Review	B-Review	1
However, it is not clear to me what aspect of their GAN is particularly new.	Review	I-Review	1
[line_break_token][line_break_token]- Missing experimental comparisons with state-of-the-arts.	Review	O	0
The most recent work that compared in the Experiment section is the work of Samarzija & Ribaric (2014).	Review	O	0
Detailed experimental comparisons with more recent state-of-the-arts are needed to justify the superiority of the proposed method.	Review	B-Review	2
[line_break_token][line_break_token]- Missing ablation study and more in-the-wild comparisons in the Experiment section.	Review	O	0
The proposed framework contains several modules, an ablation study is needed to verify the separate contribution of each component.	Review	B-Review	3
Moreover, more in-the-wild qualitative and quantitative experiments on recent benchmarks with large facial variations (e.g., expression, occlusion, blur, etc.)	Review	I-Review	3
are needed to verify the efficacy of the proposed method.	Review	I-Review	3
[line_break_token][line_break_token]Additional comments:[line_break_token]- How did authors update each component and ensure stable yet fast convergence while optimising the whole GAN-based framework?	Review	O	0
[line_break_token][line_break_token]- How did authors choose the value of \alpha in Eq. (	Review	O	0
2-4)?	Review	B-Review	5
Thank you for your comments.	Reply	O	0
[line_break_token][line_break_token]Novelty:[line_break_token]The main novel aspects are:[line_break_token]1.	Reply	O	0
The concatenation of an independent face-recognition network descriptor into the latent space.	Reply	B-Reply	1
[line_break_token]2.	Reply	I-Reply	1
The use of a distancing loss to define the target image and the real-time control it enables over the perceived identity.	Reply	I-Reply	1
[line_break_token]3.	Reply	I-Reply	1
The partition of a multi-level perceptual loss into sub-domains (distancing the high-levels, while bringing the low/medium-levels closer).	Reply	I-Reply	1
[line_break_token]4.	Reply	I-Reply	1
Various masking techniques.	Reply	I-Reply	1
[line_break_token][line_break_token] These technical novelties translate to the following application novelties in the field of image and video translation:[line_break_token]1.	Reply	O	0
Domain translation networks are commonly re-trained for every pair of domains (specifically in the case of face translation).	Reply	B-Reply	1
In our case, the output domain is the same as the input domain.	Reply	I-Reply	1
[line_break_token]2.	Reply	I-Reply	1
Our network is trained once and can then be applied universally to any face, and in real-time,  without adaptation to the new face.	Reply	I-Reply	1
[line_break_token]3.	Reply	I-Reply	1
Previous work mainly relied on face-swapping for the task of de-identification (i.e. rely on other identities for this task), while our network depends solely on the identity of interest.	Reply	I-Reply	1
[line_break_token]4.	Reply	I-Reply	1
Previous works were not able to maintain the expression, pose, illumination conditions and handle occlusions over the source image/frame - hence our work is the first to address de-identification in video.	Reply	I-Reply	1
[line_break_token]5.	Reply	I-Reply	1
We handle varying backgrounds, considerable scene motion, and occlusions without difficulty.	Reply	I-Reply	1
[line_break_token][line_break_token]State-of-the-art comparisons:[line_break_token][line_break_token]For our comparison, we selected the literature work that presented results with the highest quality (Samarzija & Ribaric, '14).	Reply	O	0
More recent de-identification works (Jourabloo et al., '	Reply	B-Reply	2
15; Wu et al., '	Reply	I-Reply	2
18) present lower quality results (only black and white images, low resolution).	Reply	I-Reply	2
Following the review, we tried to extract from their figures face images in order to perform this comparison, but the quality is too low to handle and the crops of the input faces are such that we would need to do special adjustments.	Reply	I-Reply	2
[line_break_token][line_break_token]More generally, we detail the advantages of each work in Tab.	Reply	I-Reply	2
1.	Reply	I-Reply	1
As can be seen, the literature methods, including the latest ones, are not-competitive (regardless of our improved quality, a larger diversity of output, much-reduced runtime) due to the fact that they do not preserve expression and pose.	Reply	I-Reply	2
[line_break_token][line_break_token]Ablation study:[line_break_token][line_break_token]We present an ablation study in Fig.	Reply	O	0
7.	Reply	B-Reply	3
The 6 ablation results presented were selected both due to their corresponding components importance and due to the results visibility in images.	Reply	I-Reply	3
For example, result (c) emphasizes the importance of the masking component for handling occlusion and seamlessly blend between the source and generated image, and can be easily observed in images.	Reply	I-Reply	3
On the other hand, we omitted the ablation on the edge-preserving losses since they do not result in lower quality output.	Reply	I-Reply	3
However, in our experience, they are important for fast convergence.	Reply	I-Reply	3
[line_break_token][line_break_token]More in-the-wild comparisons:[line_break_token][line_break_token]Our experiments were done both on images and videos.	Reply	O	0
The images used in our experiments were specifically selected to provide challenging scenarios (e.g. the subset of images from the NIST Face recognition challenge known to be the most difficult, which include challenging illumination conditions and blurriness).	Reply	B-Reply	3
The images use to compare with other methods also present challenging pose and expression.	Reply	I-Reply	3
[line_break_token][line_break_token]For video samples, we selected challenging videos with a large amount of motion and sizable intra-video variation in the expression, pose, occlusion and illumination conditions.	Reply	I-Reply	3
[line_break_token][line_break_token]We provide a host of qualitative and quantitative experiments, all on real-world images and challenging videos.	Reply	I-Reply	3
The qualitative results are presented as sample images and videos, while the quantitative results are presented in term of MOS, confusion matrices, automated identity ranking and pixel-level similarity vs. perceived identity distance.	Reply	I-Reply	3
There are no controlled images or videos -- it is all ‚Äúin the wild‚Äù.	Reply	I-Reply	3
The specific ‚Äúlabeled faces in the wild‚Äù dataset is part of the training dataset and cannot be used for testing.	Reply	I-Reply	3
However, the images we use, and especially the videos, are just as challenging if not more.	Reply	I-Reply	3
[line_break_token][line_break_token](continued below	Reply	O	0

The paper proposes a capsule-network-based architecture for predicting program properties and is evaluated on three tasks for predicting an algorithm from a code snippet.	Review	O	0
[line_break_token][line_break_token]Technically, the paper aims to transfer the idea of convolution from images and apply it to abstract syntax trees of programs.	Review	O	0
To do this, two dimensions describing the position of a node in a tree position are used - the depth of a node in a tree and its index in the list of children of its parent.	Review	O	0
This choice, however, is similar to image convolutions only at a very artificial level and drops significant amount of semantically-interesting information for programs from the index of the node at the parents, while keeping the total depth (which rarely matters in programs, as code is usually semantically similar no matter how nested in other code it is).	Review	B-Review	1
[line_break_token][line_break_token]The experiments are small (on two small and one slightly larger dataset) and inconclusive:[line_break_token]1) Given the number of experiments done for tuning parameters on Dataset B (with ~640 examples), it is not clear that we are not observing some trivial case of overfitting.	Review	O	0
The improvement over GGNN is quite small and mostly due to ensembles.	Review	B-Review	2
[line_break_token]2) The problem of small evaluation datasets make the results inconclusive.	Review	O	0
Only Dataset C is sufficiently large, if I assume no optimization like for Dataset B was performed.	Review	B-Review	3
[line_break_token]3) Furthermore, it looks like the considered tasks are may be better handled by models such as code2vec or code2seq than by GGNN.	Review	O	0
The paper needs to include stronger baselines.	Review	B-Review	4
[line_break_token]	Review	O	0
e would like to thank the reviewer for his valuable time, helpful feedback and insightful suggestions to further improve our study.	Reply	O	0
[line_break_token][line_break_token]Q1-1: Convolutions may drop significant amount of semantically-interesting information[line_break_token][line_break_token]Response:[line_break_token][line_break_token]We acknowledge the reviewer‚Äôs concern that the Tree-convolutions may drop significant amount of semantically-interesting information.	Reply	O	0
We adopted the approach proposed by Mou et al. (	Reply	B-Reply	1
2016), since we believe to the best of our knowledge that it is the most effective tree-convolution technique in the literature.	Reply	I-Reply	1
Improving the tree-convloution technique was not in the scope of this study.	Reply	I-Reply	1
However, we agree that a careful modification to the existing approach, or investigating a novel approach to preserve semantically interesting information in tree-convolution would certainly be a very interesting study, and would improve the performance of tree-convolution based networks.	Reply	I-Reply	1
[line_break_token][line_break_token]On the other hand, we hypothesis that TreeCaps can still learn relevant useful dependency/semantic relationships among program elements that are not spatially co-located while the network is training, without explicitly providing additional information or constraints.	Reply	I-Reply	1
[line_break_token][line_break_token]Q1-2: Experiment Results[line_break_token][line_break_token]Response:[line_break_token][line_break_token]We acknowledge the reviewer‚Äôs concern with respect to the experimental results.	Reply	O	0
[line_break_token][line_break_token]1) The results presented in Section 6.3 were intended as an ablation study, to demonstrate the effects of different aspects of TreeCaps such as the proposed variable to static algorithm and the dimensionality of the classification capsule output.	Reply	O	0
Apart from the experiments with varying dimensionalities of the code capsule output (which was intended as a demonstration of under or redundant latent representation), we did not conduct any dataset-specific hyperparameter tuning to improve the performance.	Reply	B-Reply	2
Each result shown consist of the mean and the standard deviation of 3 independent trials with random initialization.	Reply	I-Reply	2
Thus, we do not believe that the gains are due to a trivial case of overfitting.	Reply	I-Reply	2
[line_break_token][line_break_token]2) As the reviewer has presumed correctly, we did not conduct any optimization for Dataset C. We used these datasets due to the limited availability of suitable datasets. (	Reply	O	0
with respect to resource constraints, etc.)	Reply	B-Reply	3
As the reviewer has kindly suggested, we intend to conduct further experiments to establish the robustness of TreeCaps with other large datasets in our future studies.	Reply	I-Reply	3
[line_break_token][line_break_token]3) We plan to conduct additional experiments and compare TreeCaps performance with other existing approaches such as code2vec and code2seq	Reply	O	0

This paper studied learning unsupervised node embeddings by considering the structural properties of networks.	Review	O	0
Experimental results on a few data sets prove the effective of the proposed approaches over existing state-of-the-art approaches for unsupervised node embeddings.	Review	O	0
[line_break_token][line_break_token]Strength:[line_break_token]- important problem and interesting idea[line_break_token]- the proposed approach seems to be effective according to the experiments[line_break_token]Weakness:[line_break_token]- some parts of the paper are quite unclear[line_break_token]- the complexity of the proposed algorithm seems to be very high[line_break_token]- the data sets used in the experiments are very small[line_break_token][line_break_token]Details:[line_break_token]-In the introduction, "it is in general impossible to find an embedding in R^d such that ...", why do we have to make v and v'(and u, and u') far from each other?	Review	O	0
[line_break_token]- In Equation (2), How is P_ij defined exactly, are they parameters?	Review	O	0
I am quite confused about this part[line_break_token]- In Equation (6), the posterior distribution should be P(X|G) since X is the latent variable to be inferred, rightÔºü[line_break_token]- In Table 2 and 3, how are the degree and block information leveraged into the model?	Review	O	0
[line_break_token]	Review	O	0
We thank the reviewer for the thoughtful review.	Reply	O	0
[line_break_token][line_break_token]Responses:[line_break_token]- We clarified the unclear parts, and will upload the revised version asap. (	Reply	O	0
Also see below for specific responses.)	Reply	B-Reply	1
[line_break_token]- It is unclear to us if the reviewer thinks the computational complexity is high, or the mathematical complexity.	Reply	O	0
[line_break_token]With regards to mathematical complexity, we believe the model is actually rather simple (see also other reviews).	Reply	B-Reply	2
[line_break_token]Thus, we assume computational complexity is meant.	Reply	I-Reply	2
Computational complexity is discussed in detail in the manuscript though, and is certainly not higher than competing methods (in part thanks to the low mathematical complexity of the model).	Reply	I-Reply	2
See also next point.	Reply	I-Reply	2
[line_break_token]- The datasets we used are as large as the datasets used in other related work in the area.	Reply	O	0
To demonstrate CNE's superior scalability, we included another network with around 200.000 nodes and around 1.000.000 edges (<a href="http://snap.stanford.edu/data/loc-Gowalla.html)," target="_blank" rel="nofollow">http://snap.stanford.edu/data/loc-Gowalla.html),</a> run on a basic single CPU laptop.	Reply	O	0
Again, CNE outperforms all other methods in accuracy by a wide margin, and is substantially faster as well.	Reply	B-Reply	3
The results are included in the revised manuscript.	Reply	I-Reply	3
[line_break_token][line_break_token]Detailed comments:[line_break_token][line_break_token]- "In the introduction, "it is in general impossible to find an embedding in R^d such that ...", [...]?"	Reply	O	0
[line_break_token]We apologize for having been a bit brief here, we will clarify this in the revision (uploaded asap).	Reply	B-Reply	4
We meant to say that in network embedding methods that aim to model first-order proximity (where proximity in the embedding space implies a higher probability of being linked), this is a requirement (otherwise, proximity of v and v' would imply they are likely to be linked).	Reply	I-Reply	4
Thus our argument only applies to such first-order proximity methods.	Reply	I-Reply	4
Methods that aim to model second-order proximities (where proximity in the embedding space implies a greater overlap between the sets of adjacent nodes), however, are similarly vulnerable.	Reply	I-Reply	4
For example, there can be a 50% overlap (which is highly significant in sparse networks) between the neighborhoods of nodes A and B, as well as between the neighborhoods of nodes B and C, but zero overlap between the neighborhoods of nodes A and C. This would mean that nodes A and B need to be embedded close to each other, nodes B and C as well, but nodes A and C distant from each other.	Reply	I-Reply	4
The triangle inequality makes this hard.	Reply	I-Reply	4
Finally, these are but examples of how a Euclidean embedding on its own lacks representational power.	Reply	I-Reply	4
We believe that our empirical results also demonstrate this without having to refer to easy-to-identify problematic situations for pure embedding-based methods.	Reply	I-Reply	4
[line_break_token][line_break_token]- "In Equation (2), How is P_ij defined exactly [...]?"	Reply	O	0
[line_break_token]They are not parameters: they are numbers between 0 and 1 representing the prior probability of a link between nodes i and j (i.e. prior to seeing the embedding).	Reply	B-Reply	5
These numbers are such that the prior knowledge of the types described are satisfied in expectation.	Reply	I-Reply	5
In other words, they are implied and can be computed automatically and highly efficiently based on prior work, after one has decided on which prior knowledge to use.	Reply	I-Reply	5
[line_break_token]For details about how P_ij are fitted given such prior knowledge constraints, and how they can be represented efficiently, we have to refer to Adriaens et al. (	Reply	I-Reply	5
2017) and van Leeuwen et al. (	Reply	I-Reply	5
2016).	Reply	I-Reply	5
We have however summarized the relevant aspects: the fact that all probabilities P_ij, although there are n^2 of them, can be represented using much fewer parameters, and the fact that they can be fitted highly efficiently (in our experiments, even on the largest networks, this always took only a tiny proportion of the total computation time).	Reply	I-Reply	5
In the new version to be uploaded soon, this will be further clarified.	Reply	I-Reply	5
[line_break_token][line_break_token]- "In Equation (6), the posterior distribution should be P(X|G) [...]?"	Reply	O	0
[line_break_token]No, the equation is correct as stated.	Reply	B-Reply	6
Footnote 2 warned the reader about this, as we know it is unusual.	Reply	I-Reply	6
The posterior is a distribution for the network, such that finding the best embedding is indeed a maximum likelihood problem (not a maximum a posteriori problem), even though the likelihood function is computed as a posterior given a prior for the network and a conditional for the embedding given the network.	Reply	I-Reply	6
We suspect that it is this unusual aspect of the CNE formulation that makes it original with respect to the state-of-the-art.	Reply	I-Reply	6
[line_break_token][line_break_token]- "In Table 2 and 3, how are [...]?"	Reply	O	0
[line_break_token]Equation (6) defines the posterior of the network given the embedding, which we maximize w.r.t.	Reply	B-Reply	7
the embedding.	Reply	I-Reply	7
It explicitly depends on the prior probabilities P_ij, which are computed based on the prior knowledge about the degrees or about the block density structure of the adjacency matrix.	Reply	I-Reply	7
Thus, this information is brought into the model by considering the posterior distribution for the network, where the prior models the degrees of the nodes, or the block structure	Reply	I-Reply	7

This paper presents a reinforcement learning based approach to learn context-free[line_break_token]parsers from pairs of input programs and their corresponding parse trees.	Review	O	0
The main[line_break_token]idea of the approach is to learn a neural controller that operates over a discrete[line_break_token]space of programmatic actions such that the controller is able to produce the[line_break_token]desired parse trees for the input programs.	Review	O	0
The neural controller is trained using [line_break_token]a two-phase reinforcement learning approach where the first phase is used to find[line_break_token]a set of candidate traces for each input-output example and the second phase is [line_break_token]used to find a satisfiable specification comprising of 1 unique trace per example[line_break_token]such that there exists a program that is consistent with all the traces.	Review	O	0
The [line_break_token]approach is evaluated on two datasets comprising of learning parsers for an [line_break_token]imperative WHILE language and a functional LAMBDA language.	Review	O	0
The results show that[line_break_token]the proposed approach is able to achieve 100% generalization on test sets with [line_break_token]programs upto 100x longer than the training programs, while baseline approaches [line_break_token]such as seq2seq and stack LSTM do not generalize at all.	Review	O	0
[line_break_token][line_break_token]The idea to decompose the synthesis task into two sub-tasks of first learning[line_break_token]a set of individual traces for each example, and then learning a program consistent[line_break_token]with a satisfiable subset of traces is quite interesting and novel.	Review	O	0
The use of [line_break_token]reinforcement learning in the two phases of finding candidate trace sets with [line_break_token]different reward functions for different operators and searching for a satisfiable [line_break_token]subset of traces is also interesting.	Review	O	0
Finally, the results leading to perfect [line_break_token]generalization on parsing 100x longer input programs is also quite impressive.	Review	O	0
[line_break_token][line_break_token]While the presented results are impressive, a lot of design decisions such as [line_break_token]designing specific operators (Call, Reduce,..) and their specific semantics seem[line_break_token]to be quite domain-specific for the parsing task.	Review	B-Review	1
The comparison with general [line_break_token]approaches such as seq2seq and stack LSTM might not be that fair as they are [line_break_token]not restricted to only those operators and this possibly also explains the low [line_break_token]generalization accuracies.	Review	I-Review	1
Can the authors comment on the generality of the [line_break_token]presented approach to some other program synthesis tasks?	Review	I-Review	1
[line_break_token][line_break_token]For comparison with the baseline networks such as seq2seq and stack-LSTM, what [line_break_token]happens if the number of training examples is 1M (say programs upto size 100)?	Review	I-Review	2
[line_break_token]10k might be too small a number of training examples and these networks can [line_break_token]easily overfit such a small dataset.	Review	I-Review	2
[line_break_token][line_break_token]The paper mentions that developing a parser can take upto 2x/3x more time than [line_break_token]developing the training set.	Review	I-Review	3
How large were the 150 examples that were used for[line_break_token]training the models and were they hand-designed or automatically generated by a[line_break_token]parsing algorithm?	Review	I-Review	3
Hand generating parse trees for complex expressions seems to[line_break_token]be more tedious and error-prone that writing a modular parser.	Review	I-Review	3
[line_break_token][line_break_token]The reason there are only 3 to 5 candidate traces per example is because the training[line_break_token]examples are small?	Review	I-Review	4
For longer programs, I can imagine there can be thousands of bad[line_break_token]traces as it only needs one small mistake to propagate to full traces.	Review	I-Review	4
Related to this[line_break_token]question, what happens to the proposed approach if it is trained with 1000 length programs?	Review	I-Review	4
[line_break_token][line_break_token]What is the intuition behind keeping M1, M2 and M3 constants?	Review	I-Review	5
Shouldn‚Äôt they be adaptive[line_break_token]values with respect to the number of candidate traces found so far?	Review	I-Review	5
[line_break_token][line_break_token]For phase-1 of learning candidate traces, what happens if the algorithm was only using the [line_break_token]outside loop (M2) and performing REINFORCE without the inside loop?	Review	I-Review	6
[line_break_token][line_break_token]The current paper presentation is a bit too dense to clearly understand the LL machine [line_break_token]model and the two-phase algorithm.	Review	I-Review	7
A lot of important details are currently in the[line_break_token]appendix section with several forward references.	Review	I-Review	7
I would suggest moving Figure 3 [line_break_token]from appendix to the main paper, and also add a concrete example in section 4 to [line_break_token]better explain the two-phase strategy.	Review	I-Review	7
[line_break_token][line_break_token]	Review	O	0
Thank you for your review!	Reply	O	0
[line_break_token][line_break_token]About the generality of our approach, we would like to mention that CALL, RETURN and FINAL instructions are general and used in the design of non-differentiable machines for a wide range of different programs, e.g., in Neural Programmer-Interpreter (NPI).	Reply	B-Reply	1
The unique instructions of the LL machine are SHIFT and REDUCE, which are two fundamental operations to build a parser, and they are also used in Shift-Reduce machines proposed in NLP field.	Reply	I-Reply	1
Although these two instructions are for parser per se, we would like to emphasize that the LL machine is generic enough to handle a wide spectrum of grammars.	Reply	I-Reply	1
We will revise our paper to make this point clearer.	Reply	I-Reply	1
[line_break_token][line_break_token]For baseline models, we will train them on datasets with 1M samples including longer inputs.	Reply	I-Reply	2
We may not be able to finish training on inputs of length 100 due to our hardware limitation, but will at least train on inputs of length 20, and we will update the results once we finish our experiments.	Reply	I-Reply	2
However, we would like to point out that for some baseline models, it is already hard to fit to current training set with 10K samples.	Reply	I-Reply	2
For example, the training accuracies of Stack-LSTM and DeQue-LSTM on LAMBDA dataset are below 3%, and the training accuracies of seq2seq on the two standard training sets are below 95%.	Reply	I-Reply	2
We will open-source our code for replication after the double-blind review period.	Reply	I-Reply	2
The code can also replicate the experiments in the original papers of the baseline models.	Reply	I-Reply	2
[line_break_token][line_break_token]For the training curriculum, the average lengths of training samples are 5.6 (Lambda) and 9.3 (WHILE), which are not long.	Reply	I-Reply	3
Training samples in the curriculum are manually generated, which are used to test our manually written parser.	Reply	I-Reply	3
The reason why generating a small set of training samples is faster than writing a parser is twofold.	Reply	I-Reply	3
First, debugging the parser takes a long time, and it could take longer without the help of the training curriculum.	Reply	I-Reply	3
Second, there are only a few samples in the curriculum, and these samples are short, thus it does not take long to generate them.	Reply	I-Reply	3
[line_break_token][line_break_token]Meanwhile, as we mentioned in our paper, our model relies heavily on the training curriculum to find the correct traces.	Reply	I-Reply	4
In order to fit to longer samples, we need to train the model to fit to all samples in previous lessons with shorter samples first.	Reply	I-Reply	4
At the beginning, the model can only find traces for the simplest input samples, e.g., x + y. Then the model gradually learns to fit to samples of length 5, 7, etc.,	Reply	I-Reply	4
in the training curriculum.	Reply	I-Reply	4
If we randomly initialize the model and then train it directly on samples of length 1000, then our model will completely fail to find any trace that leads to the correct output parse tree.	Reply	I-Reply	4
We will update our paper to explain more about the curriculum as well.	Reply	I-Reply	4
[line_break_token][line_break_token]The choice of hyper-parameters M1, M2 and M3 is based on our empirical results.	Reply	I-Reply	5
Their values are not adaptively tuned to make sure that the training algorithm can search for candidate traces for enough time.	Reply	I-Reply	5
For example, we can not simply stop the algorithm after finding 3 candidate traces, because we are not sure whether it can still find the 4th trace or more.	Reply	I-Reply	5
[line_break_token][line_break_token]For the training algorithm, without the inner loop in phase 1, the model will trap into a local minimum without finding the whole set of traces.	Reply	I-Reply	6
Most likely, the traces found in this case are wrong ones.	Reply	I-Reply	6
[line_break_token][line_break_token]Thank you for your advice on writing!	Reply	I-Reply	7
We defer these details to the Appendix to shorten the main body of our paper.	Reply	I-Reply	7
Following your suggestions, we will add a section to include some running examples, and provide more descriptions of our training algorithm.	Reply	I-Reply	7
Also, we will move some important details in the Appendix to the main body of the paper	Reply	I-Reply	7

This paper proposes locally constant network (LCN), which is implemented via the gradient of piece-wise linear networks such as ReLU networks.	Review	O	0
The authors built the equivalence between LCN and decision trees, and also demonstrated that LCN with M neurons has the same representation capability as decision trees with 2^M leaf nodes.	Review	O	0
The experiments conducted in the paper disclose that training LCN outperforms other methods using decision trees.	Review	O	0
[line_break_token][line_break_token]The detailed comments are as follows:[line_break_token][line_break_token]1) The idea of LCN is very interesting, and the equivalence to decision trees is also very valuable, as it provides interpretability and shines light on new training algorithms.	Review	O	0
[line_break_token][line_break_token]2) The derivation of LCN and the equivalence is clear.	Review	O	0
The analysis based on the shared parameterization in Section 3.5 is helpful to understand why LCN with M neurons could be of equal capability to decision trees with 2^M leaf nodes.	Review	O	0
[line_break_token][line_break_token]3) One weakness is that the performance of ELCN seems to be very close to RF, as shown in Table 2.	Review	O	0
[line_break_token][line_break_token]I am not sure whether some similar ideas to LCN have been explored in the literature.	Review	O	0
But the topic studied in this work is very valuable, which connects deep neural networks and decision trees.	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for the insightful comments and suggestions.	Reply	O	0
Please see our response to a common comment above	Reply	O	0

This paper proposes to incorporate relational information in metric learning, and experiments on MovieLens show that using both label and relational information can outperform that using only one single component in a K-NN classification setting.	Review	O	0
[line_break_token][line_break_token]I am not an expert in metric learning, but I find it really difficult to evaluate the effectiveness of the proposed approach given the results presented in the paper.	Review	B-Review	1
I also feel that the paper writing is not clear enough and some details are missing.	Review	I-Review	1
[line_break_token][line_break_token]First, I am not surprised that both entity (features of movies) and association (user ratings) information do help in predicting the type of the movies.	Review	I-Review	2
But there aren‚Äôt any comparisons to other approaches or even discussions about related work.	Review	I-Review	2
[line_break_token][line_break_token]Equation (1) only measures the link strength between two entities.	Review	I-Review	3
For your Labels + Relations experiment, it is unclear how you put both constraints in Algorithm 1.	Review	I-Review	3
[line_break_token][line_break_token]I think it is also necessary to specify what features (attributes) you used exactly.	Review	I-Review	4
How many of them are numerical and how many are categorical (otherwise why set gamma = 0.5)?	Review	I-Review	4
Also how do you pick the #constraints (13680, 36594)?	Review	I-Review	4
Need to clarify.	Review	I-Review	4
Thank you for the feedback on our paper.	Reply	O	0
[line_break_token]>First, I am not surprised that both entity (features of movies) and association (user ratings) information do help in predicting the type of the movies.	Reply	O	0
But there aren‚Äôt any comparisons to other approaches or even discussions about related work.	Reply	O	0
[line_break_token]This is the objective of the paper to show that this intuition is true.	Reply	B-Reply	2
A number of approaches are considering whether the structural (links) information, or the feature information, but few on both.	Reply	I-Reply	2
Such works are mostly focusing on graph clustering and community detection.	Reply	I-Reply	2
[line_break_token]One can find such work (for graphs, not multi-relational data) in e.g. [1], [2] and references therein.	Reply	I-Reply	2
Due to page limitation, it was difficult to provide a discussion on this aspect, but we are aware that it would deserve a deeper description.	Reply	I-Reply	2
[line_break_token]Considering both structural and feature information of multi-relational data for metric learning has never been considered, to the best of our knowledge.	Reply	I-Reply	2
[line_break_token]> Equation (1) only measures the link strength between two entities.	Reply	O	0
For your Labels + Relations experiment, it is unclear how you put both constraints in Algorithm 1.	Reply	O	0
[line_break_token][line_break_token]Algorithm 1 is only concerned with constraints obtained from the structure of the data.	Reply	B-Reply	3
Label constraints are obtained exactly the same way as almost every metric learning algorithm, i.e. by considering that similar objects are objects having the same label (and dissimilar objects have different labels)[line_break_token][line_break_token][line_break_token]> I think it is also necessary to specify what features (attributes) you used exactly.	Reply	O	0
How many of them are numerical and how many are categorical (otherwise why set gamma = 0.5)?	Reply	O	0
Also how do you pick the #constraints (13680, 36594)?	Reply	O	0
Need to clarify.	Reply	O	0
[line_break_token][line_break_token]The link strength is computed with association information, in the case of MovieLens, there is only one numerical attribute, the value of the rating.	Reply	B-Reply	4
The value of gamma is not changing the link strength ordering in this case.	Reply	I-Reply	4
[line_break_token][line_break_token]The number of constraints was mainly constrained by the number of possible pairs.	Reply	I-Reply	4
There is no rule of thumb in metric learning community for this, but a commonly used one is to set it as function of squared number of different labels (as in ITML).	Reply	I-Reply	4
[line_break_token][line_break_token][1] Yang, J., McAuley, J., & Leskovec, J. (2013, December).	Reply	O	0
Community detection in networks with node attributes.	Reply	O	0
In Data Mining (ICDM), 2013 IEEE 13th international conference on (pp.	Reply	O	0
1151-1156).	Reply	O	0
IEEE.	Reply	O	0
[line_break_token][2] Smith, L. M., Zhu, L., Lerman, K., & Percus, A. G. (2016).	Reply	O	0
Partitioning Networks with Node Attributes by Compressing Information Flow.	Reply	O	0
ACM Transactions on Knowledge Discovery from Data (TKDD), 11(2), 15	Reply	O	0

A new version (v3) of the paper will be available at Tue, 18 Feb 2014 01:00:00 GMT.	Review	B-Review	1
The revised paper is now available	Reply	B-Reply	1

This paper proposes  an adaptation technique for TTS using wavenet as the speech backend, with the adaptation carried out on small data.	Review	O	0
The work is extremely significant in that speech data is hard to produce  (we need many hours of speaker data), and techniques to adapt (transfer learning?)	Review	O	0
data from large networks would be quite valuable.	Review	O	0
The main idea is that we train a network containing a large amount of data, and (assuming that we have a trained model), we adapt this network to the task of generating speech from text for a much smaller dataset.	Review	O	0
[line_break_token][line_break_token]In general (insofar as we can use that term), one trains such a network using <text/speech> pairs,  with speaker conditioning as added input so as to produce voice from a given speaker.	Review	O	0
The input text is converted to linguistic features in the ‚Äòfront end‚Äô, which is then injected with voice features to be synthesized into a voice output in the backend.	Review	O	0
More recent efforts in speech modeling have used RNN or wavenet based systems to carry out these transformations in the front/backends.	Review	O	0
The present work seems to use an SPSS technique (Zen et al 2016) to generate the linguistic features, while the task of converting to voice is carried out by a Wavenet.	Review	O	0
[line_break_token][line_break_token]The work is quite (conceptually) similar to "Neural voice cloning with a few samples" (Arik et al, <a href="https://arxiv.org/abs/1802.06006)" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.06006)</a> in proposing techniques for few shot adaptation described below but with the significant difference that the latter used autoregressive DNNs (loosely speaking, seq2seq a la Tacotron) for the task in both the front and back ends, while in the current work, the linguistic features are computed with SPSS as in Zel et al (2016).	Review	O	0
[line_break_token][line_break_token]The paper proposes three quite related techniques for adaptation as shown clearly in Figure 2 of the paper.	Review	B-Review	2
These techniques are again ‚Äòroughly‚Äô analogous to those described in the Baidu work ‚ÄúNeural Voice Cloning with a few samples‚Äù, with the difference in front and backend setups noted in the previous paragraph.	Review	I-Review	2
[line_break_token][line_break_token]We take as text as input, and convert them to a representation for linguistic features as described in Zen et al (2016).	Review	O	0
To this, we now add the fundamental frequency F_0 for the sample voice.	Review	O	0
The key piece needed is the speaker embeddings (a vector), which is to be obtained by training.	Review	O	0
In addition to all this, we also have available the weights of a trained wavenet network (probably quite large) trained on many speakers, which we will modify (or not) using the strategies outlined for the few data dataset.	Review	O	0
[line_break_token][line_break_token]SEA-EMB - Train embeddings, but not the network.	Review	O	0
We expect this to be ‚Äòfast‚Äô, but not particularly accurate.	Review	O	0
[line_break_token]SEA-ALL - Train embeddings, and network.	Review	O	0
This would be a much more accurate, if slower task.	Review	O	0
The authors note that since we train a very large network in this case, it could be prone to overfitting.	Review	O	0
They employ early stopping (as a practitioner, I would make note of the issue) with 10 % of the dataset being held out.	Review	O	0
Additional ideas such as initializing the emeddings - possibly with those that SEA-EMB calculates - are also stated to be useful.	Review	O	0
[line_break_token]SEA-ENC - In this third version, they predict speaker embeddings from the trained larger network (the recipe is provided in the appendix).	Review	O	0
This task of predicting speaker embeddings is one of training a classifier.	Review	O	0
[line_break_token][line_break_token][line_break_token]Results[line_break_token]The paper presents evaluations conducted with subjective, MOS based enrolment and with an evaluation metric from TI-SV d-vectors.	Review	O	0
Comparisons are made for all three models with human evaluated MOS scores, and it is seen that SEA-ALL outperforms the other two models, while performance in SEA-EMB depends on the amount of data used.	Review	O	0
Nevertheless, humans are still able to detect the difference between synthetic voices and real samples.	Review	O	0
[line_break_token][line_break_token]The TI-SV evaluations from Wan et al show t-SNE embeddings of ‚Äòclusters‚Äô of d-vectors for human and synthetic voices, where it is seen that inter-cluster distance (i.e. between different speakers) is high, showing that the model is able to discern speakers, and the intra-cluster distance (i.e. between real and synthetic voices) is low, showing that synthetic voices are ‚Äòsimilar‚Äô to real voices.	Review	O	0
In addition, three other measures - cosine similarity, and statistical measures for detection error trade off, ROC curves and cosine similarity measures are also presented, which show that that the adaptation models perform quite well.	Review	O	0
[line_break_token][line_break_token][line_break_token]Clarifications and comments:[line_break_token][line_break_token]Have there been efforts to compare this model (with the SPSS based frontend) with seq2seq (Bahdanau/transformer) DNN based systems as in ‚ÄúNeural Voice cloning with few samples‚Äù?.	Review	O	0
How do they compare (is it even a valid comparison?)?	Review	B-Review	1
[line_break_token][line_break_token]I think the model for computing linguistic features could be elaborated upon further.	Review	I-Review	3
[line_break_token][line_break_token]Representations: I assume that the output audio representation is an audio waveform[line_break_token][line_break_token]Typo 1 (minor): The reference  for ‚ÄúBornschein et al‚Äù in section 4 ‚ÄúRelated work‚Äù[line_break_token]‚ÄúVariable inference for memory addressing‚Äù.	Review	O	0
[line_break_token]Correction ‚ÄúVariational memory addressing in generative models‚Äù[line_break_token][line_break_token]Typo 2 (minor): Figure 6: Lower curve indicate that the verification system is having a harder time distinguishing real from generated samples.	Review	B-Review	5
[line_break_token]Correction (minor): Lower curve ‚Äúindicates‚Äù ...[line_break_token][line_break_token]Summary[line_break_token]-------------[line_break_token]In summary, I am in favor of accepting this paper as it proposes a solution to adapt a trained network to one with has limited number of samples.	Review	O	0
A big issue in speech modeling is that datasets are tiny, and it is difficult to obtain good quality data at reasonable cost.	Review	O	0
It would be extremely useful to have a trained network that we can adapt for our own experiments.	Review	O	0
The related paper by Arik et al (Neural Voice cloning with a few samples) also operates with similar strategic aims, but uses a a different methodology using attention based DNNs.	Review	O	0
The paper under review should be a good addition to the toolbox of few shot adaptation/transfer learning for speech with much potential for practical use.	Review	O	0
Thanks a lot for your terrific summary of our paper.	Reply	O	0
We‚Äôve submitted a revision following the feedback from all reviewers.	Reply	O	0
Please see our response to your questions below:[line_break_token][line_break_token]- Comparison between SPSS based frontend and seq2seq models:[line_break_token]There are pros and cons to both approaches.	Reply	O	0
On the one hand, SPSS+WaveNet obtains a natural decomposition of prosody (pace, intonation, etc) and vocal tract properties (more relevant to speaker identity) of a voice, something that is still difficult to do with seq2seq [1]. On the other hand, seq2seq models overcome the need of hand-crafted linguistic features and could be easily applied to different languages.	Reply	B-Reply	1
[line_break_token][line_break_token]We compare the performance of our model with seq2seq models in terms of sample naturalness and voice similarity in Tables 1 and 2.	Reply	I-Reply	1
However, as explained in our paper, we report the numbers of the closest experimental setup.	Reply	I-Reply	1
Without access to the original code and all the dataset-specific hyper-parameters it is difficult to reproduce other works exactly.	Reply	I-Reply	1
[line_break_token][line_break_token]Listening to the generated samples on our demo webpage is another way to qualitatively compare the approaches.	Reply	I-Reply	1
[line_break_token][line_break_token]- Linguistic features:[line_break_token]Please refer to our response to question 1 of Reviewer 3 for details.	Reply	O	0
In short, we have added an additional appendix to the paper elaborating on the linguistic features.	Reply	B-Reply	3
[line_break_token][line_break_token]- Representations:[line_break_token]Correct, the output is an audio waveform.	Reply	O	0
[line_break_token][line_break_token]Thanks for pointing out the typos.	Reply	O	0
[line_break_token][line_break_token]References:[line_break_token][1]: Skerry-Ryan, R. J., et al. "	Reply	O	0
Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron."	Reply	O	0
arXiv preprint arXiv:1803.09047 (2018).	Reply	O	0

*Summary:*[line_break_token][line_break_token]The authors propose to tackle the associative memory problem by recasting read/write operations to read/write by optimizing the parameters/input of an energy based model.	Review	O	0
Writing is reformulated as training a parametric energy model (EBMM) to have local minima of energy w.r.t.	Review	O	0
the parameters at memorized data points.	Review	O	0
Reading is performed by performing (projected) gradient descent on the corrupted/incomplete input to minimize the energy.	Review	O	0
To ensure the operations are fast (read and write with minimal gradient steps), the authors propose to take inspiration from modern meta-learning literature and learn initialization parameters of the energy model (and other hyperparameters for GD during read/write) from which writing is fast while ensuring reading is also fast, since the models are trained to maximize read/write performance within a constrained number of gradient steps.	Review	O	0
 Experimentally, the authors show that EBMM reading performs similar to baseline methods (but better across many memory sizes) on the standard Omniglot task.	Review	O	0
On CIFAR-10 and downsized ImageNet, they show much better L2 reconstruction error of corrupted images.	Review	O	0
They also show that the learnt energy [line_break_token][line_break_token]*Recommendation:*[line_break_token][line_break_token]I believe this is a very neat idea, and utilizes large parametric models for "smart" overfitting and compression of data for the associative memory task.	Review	O	0
The proposed meta-learning approach to training the model seems to perform well across multiple simple and challenging datasets, and therefore I would recommend accept.	Review	O	0
My current recommendation is very borderline (weak accept) because of a lack of some experimental rigour (which I would love clarifications on), and missing related work, which I mention below.	Review	O	0
[line_break_token][line_break_token]*Discussion Points and Concerns from the Reviewer:*[line_break_token][line_break_token]- Dataset / batching details [line_break_token]Please mention how the datasets were split for training and testing the models.	Review	O	0
How much training data is utilized to meta-learn the EBMM initialization?	Review	B-Review	2
How is batching performed?	Review	I-Review	2
I believe these details are very important to mention in the paper for reproducibility of results.	Review	I-Review	2
[line_break_token][line_break_token]Are there any correlations in the batch selection?	Review	I-Review	3
Can you evaluate how good the associative memory performs across different correlation levels in the batch (A well learnt algorithm should demonstrate better reconstruction at lower memory levels for correlated batches).	Review	I-Review	3
[line_break_token][line_break_token]- Experiments across multiple SNR and generalization on noise patterns[line_break_token]The authors mention at the beginning of Section 4 that a random block is corrupted, but in the end the experiments are done on a constant corruption size on the CIFAR and ImageNet images.	Review	O	0
How do the models perform across different signal-to-noise ratios?	Review	B-Review	4
Similarly, the model is trained on simple noise patterns [line_break_token][line_break_token]- Missing related work[line_break_token]There is related work [1] in learning in Hopfield Networks using the implicit function theorem and finding stationary points of the dynamics.	Review	O	0
This work is not mentioned in the paper, and is a valid baseline for this paper as well.	Review	B-Review	5
[line_break_token][line_break_token]- Mentioning Appendix D in the main paper[line_break_token]Appendix D is not mentioned in the main paper and has a short discussion on the mismatch between the reading process and the writing loss during meta-training.	Review	O	0
It also mentions additional tricks required for the training, and I believe it should be mentioned in the main paper like other sections are appropriately referenced.	Review	B-Review	6
[line_break_token][line_break_token]- Large batch sizes for ImageNet[line_break_token]Work from [2] can be utilized to backpropagate through very long optimization sequences and therefore can be utilized to train with larger batch sizes in the ImageNet example.	Review	O	0
It is important to see how the small model utilized for ImageNet works to compress higher batch sizes, as that is one of the major practical issues with the algorithm.	Review	B-Review	7
[line_break_token][line_break_token]- Related paper at NeurIPS this year [line_break_token][3] is a related paper from Neurips this year, which the authors could consider adding as contemporary work[line_break_token][line_break_token]- Comments on scalability[line_break_token]The associative memory papers have often been criticized for lack of scalability, and I think the authors make progress towards making this better with the use of unconstrained energy models in the learning process.	Review	O	0
It would be nice to have a discussion of the scalability from the authors, highlighting issues in the current model and future directions[line_break_token][line_break_token]References:[line_break_token][1] Reviving and Improving Recurrent Back-Propagation, ICML '18[line_break_token][2] Gradient-based Hyperparameter Optimization through Reversible Learning, Maclaurin et al.	Review	O	0
ICML '15[line_break_token][3] Metalearned Neural Memory, Munkhdalai et al.	Review	O	0
NeurIPS '19	Review	O	0
gt; Experiments on correlated batches[line_break_token][line_break_token]We display results for randomly chosen images within the test set.	Reply	O	0
If storing very similar images this can actually make correct reconstruction more difficult, as there is more ambiguity in locating the original image from the occluded query image.	Reply	B-Reply	3
We found that if the model was not trained on correlated batches, it does not benefit from them at the test time.	Reply	I-Reply	3
However, when trained and tested on batches of 2 Omniglot classes, EBMM achieves significantly lower reconstruction error.	Reply	I-Reply	3
Please see the new Appendix A.7 for details.	Reply	I-Reply	3
We will be able to provide a comprehensive study for the final version of the paper	Reply	I-Reply	3

This work proposes a new translation model that combines translation models in two directions and language modelss in two languages by sharing a latent semantic representation.	Review	O	0
The basic idea to joint modeling of translations conditioning on the latent representations and the parameters are learned by generating pseudo translations in two directions.	Review	O	0
Decoding is also carefully designed by interchanging sampling in two directions in a greedy fashion.	Review	O	0
Empirical results show consistent gains when compared with heuristic methods to generate pseudo data, e.g., back translation.	Review	O	0
[line_break_token][line_break_token]It is an interesting work on proposing a unified framework to translation by conditioning on a shared latent space in four models.	Review	O	0
It is not only rivaling heuristic methods to generate pseudo data, but surpassing competitive Transformer baselines.	Review	O	0
[line_break_token][line_break_token]Other comment:[line_break_token][line_break_token]- It is a bit confusing that MGNMT was not experimented with Transformer, though the paper and appendix describe that it is easy to use the Transformer in the MGNMT setting.	Review	O	0
hanks very much for your comments!	Reply	O	0
[line_break_token][line_break_token]Q1: About experimenting MGNMT with Transformer[line_break_token]A1: All experimental results in the experiment section are implemented based on Transformer.	Reply	O	0
We also give results implemented on RNMT, which are listed in the Appendix.	Reply	B-Reply	1
We will make it clearer in the revision.	Reply	I-Reply	1
Sorry for the confusion.	Reply	I-Reply	1

The rebuttal did not address my concerns convincingly.	Review	O	0
There were also simple fixes that the authors could have implemented but they decided not to update the paper.	Review	O	0
I will keep my original assessment.	Review	O	0
[line_break_token][line_break_token]--------------[line_break_token][line_break_token]The premise of the work is very interesting: RNNs that are permutation-invariant.	Review	O	0
Unfortunately, the paper seems rushed and needs a better justification for not having a RNN memory that is associative.	Review	B-Review	1
It also should cast the contributions in light of other existing work (not cited).	Review	I-Review	1
The paper says "In this section and the remainder of the paper, we focus on the latter [commutative RNN memory operator], namely introducing a constraint (or equivalently, regularizer) that is commutative", but it never talks about the impact of a RNN memory using a non-associative operator.	Review	I-Review	1
Being commutative is easy, isn't Equation (2.4) commutative if \Theta = W?	Review	I-Review	1
Being associative is hard, since non-linear activations are not easily amenable to associativity.	Review	I-Review	1
[line_break_token][line_break_token]Section 4: "The above example demonstrates that RNNs can in some cases be a natural computational model for permutation invariant functions."	Review	O	0
=&gt; Janossy pooling (Murphy et al.,	Review	O	0
2019) gives an alternative way to use RNNs, with a way to make their method tractable.	Review	B-Review	2
Actually, my guess to why the RNNs experiments work well, even without an associative memory, is because the training examples come in multiple permuted forms, which is the data-augmentation version of the pi-SGD optimization described in Janossy pooling.	Review	I-Review	2
[line_break_token][line_break_token]On page 1, "consider the problem of computing the permutation invariant function f(x_1, . . . ,	Review	I-Review	3
x_n) = max_i x_i", what follows is not a proof of necessity.	Review	I-Review	3
It is an informal argument that either should be made formal or should be described as informal.	Review	I-Review	3
[line_break_token][line_break_token]There is a lot of missing related work for sets:[line_break_token]Murphy, Ryan L., Balasubramaniam Srinivasan, Vinayak Rao, and Bruno Ribeiro. "	Review	I-Review	4
Janossy pooling: Learning deep permutation-invariant functions for variable-size inputs."	Review	I-Review	4
ICLR 2019.	Review	I-Review	4
[line_break_token]Wagstaff, Edward, Fabian B. Fuchs, Martin Engelcke, Ingmar Posner, and Michael Osborne. "	Review	I-Review	4
On the limitations of representing functions on sets."	Review	I-Review	4
ICML 2019.	Review	I-Review	4
[line_break_token]Lee, Juho, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee Whye Teh. "	Review	I-Review	4
Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks."	Review	I-Review	4
ICML 2019.	Review	I-Review	4
[line_break_token][line_break_token]Also missing related work for graphs:[line_break_token]Bloem-Reddy, Benjamin, and Yee Whye Teh. "	Review	I-Review	4
Probabilistic symmetry and invariant neural networks."	Review	I-Review	4
arXiv:1901.06082 (2019).	Review	I-Review	4
[line_break_token]Murphy, Ryan L., Balasubramaniam Srinivasan, Vinayak Rao, and Bruno Ribeiro. "	Review	I-Review	4
Relational Pooling for Graph Representations."	Review	I-Review	4
ICML 2019.	Review	I-Review	4
[line_break_token][line_break_token]The paper has an interesting question but needs to build on prior work.	Review	I-Review	5
As of now, I am unconvinced that not having an associative operator for the RNN memory will lead to a good nearly permutation invariance function (unless there is data augmentation, per Janossy pooling).	Review	I-Review	5
[line_break_token]	Review	O	0
e thank the reviewer for their detailed feedback and insights as well as the important remarks regarding prior work which we did not cite.	Reply	O	0
Below we add clarifications to each point raised by the reviewer.	Reply	O	0
[line_break_token][line_break_token](1) The authors focus on commutative without clear justification - We identify commutativity and associativity as two components of permutation invariance.	Reply	O	0
In the paper we show how to regularize towards commutativity and show this is empirically effective for achieving permutation invariance.	Reply	B-Reply	1
Indeed we will add quantitative evaluation to show that associativity is also achieved in these cases.	Reply	I-Reply	1
Regarding setting \Theta=W, this leads to a permutation invariant network (i.e., it is associative not only commutative), but one which is less expressive and may require more parameters to fit a given function.	Reply	I-Reply	1
[line_break_token][line_break_token](2) Jannosy pooling gives an alternative way to use RNNs -  Indeed Janossy gives another approach to permutation invariance using RNNs via canonical representations or sampling.	Reply	O	0
We expect our approach to outperform it when sampling has high variance or the canonical representation is hard for the RNN to classify.	Reply	B-Reply	2
[line_break_token][line_break_token](3) The proof of f(x_1,...,x_n)=max_i x_i does not show necessity and is informal - We will clarify this.	Reply	O	0
[line_break_token][line_break_token](4) Missing work: We will add the reference and discuss relation to our approach.	Reply	O	0
[line_break_token][line_break_token](5) Concerns regarding the operator not being associative - We will add an empirical evaluation of the associativity of the network as a function of its commutativity	Reply	O	0

The authors attempt to propose an alternative explanation for the effect of dropout in a neural network and then present a technique to improve existing activation functions.	Review	O	0
[line_break_token][line_break_token]Section 3.1 presents a experimental proof of higher co-adaptation in presence of dropout, in my opinion this is an incorrect experiment and request authors to double check.	Review	O	0
In my experience, using dropout results in sparse representations in the hidden layers which is the effect decreased co-adaptions.	Review	O	0
Also, a single experiment with MNIST data-set cannot be a proof to reject a theory.	Review	O	0
[line_break_token][line_break_token]Section 3.2 Table 2 presents a comparison between average gradient flow through layers during training where flow with dropout is higher.	Review	O	0
This is not very surprising, in my opinion, given the variance of the activation of a neuron in presence of dropout the network tries to optimize the classification cost while trying to reduce the variance.	Review	O	0
The experimental details are almost nil.	Review	O	0
[line_break_token][line_break_token]The experiments section 5 presents very weak results.	Review	O	0
Very little or no improvement and authors randomly introduce BatchNorm into one of the experiment.	Review	O	0
Since the authors did not address the concerns in my review directly.	Reply	O	0
I choose to stick to the given rating.	Reply	O	0

