Following recent work on Hindsight Experience Replay (Andrychowicz et al.	Review	O	0
2017), the authors extend the idea to policy gradient methods.	Review	O	0
They formally describe the goal-conditioned policy gradient setup and derive the extensions of the classical policy gradient estimators.	Review	O	0
Their key insight to deriving a computationally efficient estimator is that for many situations, only a small number of goals will be "active" in a single trajectory.	Review	O	0
Then, they conduct extensive experiments on a range of problems and show that their approach leads to improvements in sample efficiency for goal-conditioned tasks.	Review	O	0
[line_break_token][line_break_token]Although the technical novelty of the paper is not high (many of the estimators follow straightforwardly from previous results, however, the goal subsampling idea is a nice contribution), the paper is well written, the topic is of great interest, and the experiments are extensive and insightful.	Review	B-Review	1
I expect that this will serve as a nice reference paper in the future, and launching point for future work.	Review	I-Review	1
[line_break_token][line_break_token]The only major issue I have is that there is no comparison to HER.	Review	I-Review	2
I think it would greatly strengthen the paper to have a comparison with HER.	Review	I-Review	2
I don't think it diminishes their contributions if HER outperforms HPG, so I hope the authors can add that.	Review	I-Review	2
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]In Sec 6.1, it seems surprising that GCPG+B underperforms GCPG.	Review	O	0
I understand that HPG+B may underperform HPG, but usually for PG methods a baseline helps.	Review	B-Review	3
Do you understand what's going on here?	Review	I-Review	3
[line_break_token][line_break_token]In Sec 6.2, it would be helpful to plot the average return of the optimal policy for comparison (otherwise, it's hard to know if the performance is good or bad).	Review	I-Review	4
Also, do you have any explanations for why HPG does poorly on the four rooms?	Review	I-Review	4
[line_break_token][line_break_token]====[line_break_token][line_break_token]Raising my score after the authors responded to my questions and added the HER results.	Review	O	0
Thank you very much for the time that you have dedicated to evaluate our work.	Reply	O	0
We are glad that you believe that our paper is well written and of great interest, that our experiments are extensive and insightful, and that our contribution has the potential to become a reference and starting point for future work.	Reply	O	0
[line_break_token][line_break_token]You are absolutely correct in noting that the fact that only active goals need to be considered is crucial to the feasibility of the proposed estimators.	Reply	B-Reply	1
This result is very specific to this application of importance sampling, which also leads to other remarkable properties (as discussed in Section 5).	Reply	I-Reply	1
However, we disagree with the claim that the technical novelty of our paper is not high.	Reply	I-Reply	1
Firstly, our technical approach to hindsight is radically different from previous work.	Reply	I-Reply	1
Secondly, the exact formulation of the hindsight policy gradient, its relationships with value functions, and the feasibility of the corresponding estimators are only clear in hindsight.	Reply	I-Reply	1
Finally, although apparently simple by analogy, several results require proofs that are elementary but involved (for an example, see Theorem 4.2).	Reply	I-Reply	1
[line_break_token][line_break_token]It is indeed very interesting that including a value function baseline seems more harmful than helpful according to our experiments.	Reply	I-Reply	3
After careful investigation, we have concluded that the value function baseline is often poorly fit by the time that the policy exhibits desirable behavior, which is probably due to the fact that the value function baseline is not trained using hindsight.	Reply	I-Reply	3
This is particularly evident in the bit flipping environments, the most extreme examples of sparse-reward environments that we consider, where both HPG+B and GCPG+B exhibit unstable behavior (although GCPG+B only ever reaches a good performance for k=8 and a batch of size 16).	Reply	I-Reply	3
Although our preliminary experiments in using hindsight to fit a value function baseline have been successful, this may be accomplished in several ways, and requires a careful study of its own.	Reply	I-Reply	3
[line_break_token][line_break_token]We believe that the poor performance of every technique in the four rooms environment could be addressed by well-known policy gradient tricks (e.g., entropy bonuses, reward scaling, learning rate annealing, simple statistical baselines), which we have avoided in order to reduce confounding factors in our experiments.	Reply	I-Reply	4
The stark state information and the layout that offers a single door between adjacent rooms make this environment surprisingly difficult, but it is probably within reach of agents trained with either HPG or GCPG.	Reply	I-Reply	4
Indeed, plotting the average return of the optimal policy would be helpful for inspecting results.	Reply	I-Reply	4
We can easily include that in the final version of the paper.	Reply	I-Reply	4
[line_break_token][line_break_token]We completely understand your interest in a direct comparison with hindsight experience replay, although we are glad that you agree that our contribution would not be diminished if hindsight experience replay were more sample efficient at this stage.	Reply	I-Reply	2
Because this comparison was a common request among reviewers, we are currently working on it.	Reply	I-Reply	2
We will provide an updated version of the paper including the corresponding results before the end of the rebuttal period (ideally by 21/11).	Reply	I-Reply	2
[line_break_token][line_break_token]Nonetheless, we would like to briefly explain why we did not include such a comparison in the current version of the paper.	Reply	I-Reply	2
Firstly, hindsight experience replay is an approach that can be applied to any reinforcement learning technique that relies on experience replay.	Reply	I-Reply	2
Besides the choices required to implement hindsight experience replay itself (such as the goal sampling strategy and number of hindsight transitions per observed transition), each of these techniques potentially has several important hyperparameters.	Reply	I-Reply	2
Instead of comparing HPG to one of these techniques, we preferred to focus on a rigorous comparison with GCPG, its most natural counterpart.	Reply	I-Reply	2
The similarities between both methods allow for a highly systematic comparison that minimizes confounding factors.	Reply	I-Reply	2
Secondly, note that we have not used tricks that are known to increase the performance of policy gradient methods, once again in order to avoid introducing confounding factors.	Reply	I-Reply	2
Because hindsight experience replay is directly applicable to state-of-the-art techniques, this would lead to an unbalanced comparison.	Reply	I-Reply	2
Finally, it should be clear that our work can probably benefit from being extended to state-of-the-art policy gradient approaches.	Reply	I-Reply	2
However, once again, such extensions are likely to introduce confounding factors that we would prefer to avoid in our fundamental work.	Reply	I-Reply	2
[line_break_token][line_break_token]We hope that these clarifications and the additional experimental content to be released before the rebuttal deadline will allow you to reconsider the rating given to our submission	Reply	O	0

This paper presents a VAE architecture that separates a fixed content representation and time varying features of an image, that can be used to learn a representation of image transformations in a temporal setting.	Review	O	0
[line_break_token][line_break_token]The paper is well written and the ideas presented are interesting, but in my opinion not novel enough or thoroughly demonstrated to justify acceptance:[line_break_token][line_break_token]- there is a very relevant work that is not mentioned by the authors and that can be seen as a generalization of the model presented in this paper: "Disentangled Sequential Autoencoder" by Li and Mandt (ICML 2018), which introduces a model that is also disentangling a content and a temporal representation of sequential data.	Review	O	0
This is basically the more general model introduced by the authors of this submission in the beginning of section 2, without all the assumptions made in the rest of section 2.	Review	B-Review	1
A comparison with this related work would help assess the differences in terms of modelling power and in performances.	Review	I-Review	1
[line_break_token][line_break_token]- The assumptions made in this work are fairly strong for most interesting applications, in particular the fact that the content cannot change across time steps.	Review	O	0
[line_break_token][line_break_token]- To me, the issue with the novelty of this model would not be a big problem if the authors focused more on showing its usefulness in different applications (e.g. medical domain or RL as mentioned in the conclusions).	Review	O	0
However, the authors only demonstrate the TEVAE on relatively simple experiments that are only tailored to simple image transformations.	Review	B-Review	3
[line_break_token]	Review	O	0
hanks for the review and the reference which we will cite and discuss in the paper.	Reply	B-Reply	1
Indeed the underlying generative model we start up with is the same as (1) in the reference.	Reply	I-Reply	1
However, the main purpose of the paper is that we argue against modeling z_t directly and instead propose our generative model (1) which focuses on the differences between the time-steps.	Reply	I-Reply	1
You are right that our model has stronger assumptions insofar that we do not model constant features directly ( c in our paper or f in the reference) and therefore need to assume that c/f and z_t can be correctly estimated from the previous image.	Reply	I-Reply	1
[line_break_token][line_break_token]In our paper, we focused on tasks that are simple enough to illustrate the differences in modelling of z_t and \dot{z_t}. We are confident that we could apply it to experiment 4.1 in the reference, which would amount to learning the actions without learning the appearance.	Reply	I-Reply	1
However, this task, while looking more fancy, would be easier, because the action-space is discrete(the frame number in the animation) and there is no difficult topology to learn - a flat topology would suffice.	Reply	I-Reply	1
In this case, modeling z_t and \dot{z}_t would be equivalent.	Reply	I-Reply	1
The experiment 4.3 also sounds very interesting and would require an extension of the model to encode transitions p(\dot{z}_{t+1}|\dot{z}_t, x_t) for the forward-prediction task (to model the elastic collisions).	Reply	I-Reply	1
Still, the \dot{z} space would probably be simpler compared to what we consider in our experiments, since movement of the ball is just learning position/velocity, which is a flat space.	Reply	I-Reply	1
[line_break_token][line_break_token]In our experiments on MNIST, focusing on scaling and rotation reveals that it is difficult for a VAE to learn an encoding that is compatible with the normal prior and can not be described as disentangled.	Reply	I-Reply	1
This is very important, because even if models in Figure 5 e/f/ would produce better visual results, sampling z_t or \dot{z}_t from the prior would not lead to good samples since the true learned encoding lies on a curved manifold.	Reply	I-Reply	1
Also, since the manifold changes depending on object symmetry(and involves a twist in 2d space), recent approaches like manifold-based priors are not easy to adapt to this.	Reply	I-Reply	1
When enforcing a flat manifold that is consistent with the prior (figure h/l) we obtain that the model fails at reconstructing roughly half of the rotation-space, except when learning a model where the encoder has enough information to perform the parallel transport of the tangent space (Figure g/k).	Reply	I-Reply	1
So we claim that the model in Figure g/k is the only one that actually solves the task.	Reply	I-Reply	1
[line_break_token][line_break_token]I think the most important result is the carracing task where the z-model fails to learn the translation direction.	Reply	I-Reply	1
This is kind of obvious because here it is impossible to disentangle "content" from "position" (without observing x_t there is no valid coordinate system to define position on and movement is the relative shift of all content in the image).	Reply	I-Reply	1
The only way to define translation using z_t coordinates would be to treat all "constant/slow changing" features c/f as changing variables z and define translation based on this high level image description of the whole content.	Reply	I-Reply	1
This is probably what the encoder in the \dot{z}-model does.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding content: while this is true for the registration model, this is not true for a general NN approach.	Reply	O	0
It is just very difficult to find a proper architecture for that.	Reply	B-Reply	2
since changing content is a varying variable, it would be modeled via z_t/\dot{z}_t.	Reply	I-Reply	2
E.g. in a video game the only truely constant feature would be "which level am I in".	Reply	I-Reply	2
 In our paper, we had to change the loss-function on the carracing task to ignore the borders, otherwise we would have needed a much larger feature space to model all content in the image(or at least the borders).	Reply	I-Reply	2
[line_break_token][line_break_token]Final words:[line_break_token]I agree with your review that our model has its limits.	Reply	O	0
We don't model higher order time-dependencies (which is a simple extension that is only relevant for n-step (n&gt;1) prediction tasks) and we don't model c. This is not a simple extension because (c, \dot{z}_t) is not a complete description of the state and we would also need to model z_t somehow.	Reply	O	0
[line_break_token][line_break_token]In the end, ICLR is about learning representations and we learn a representation for \dot{z} that is meaningful and minimal.	Reply	B-Reply	3
One might debate whether this is enough or not, but this might be standpoint specific.	Reply	I-Reply	3
We definitely have not answered all questions (e.g. how to get a neural network in the MNIST task to learn the flat manifold as in Figure 5c), but we think there are a lot of tasks out there were our current results are important(e.g.	Reply	I-Reply	3
modeling progression of diseases)	Reply	I-Reply	3

Pros: This seems like very competent and important work in an under-served area: Doing the mapping (or "entity linking") of chemical names to their standardized systematic forms.	Review	O	0
It's not my area, but I was frankly surprised when the paper said there was only one relevant prior piece of work, but having searched for a few minutes on Google Scholar, I'm at least inclined to believe that the authors are (approximately) right on that one. (	Review	O	0
This stands in stark contradistinction to the large quantity of biomedical entity recognition and linking work.)	Review	O	0
So, it's valuable to have work in this area, and the approach and application are sensible.	Review	O	0
In one sense, this gives the work significance and originality (as to domain).	Review	O	0
The paper is also clearly written, and certainly sufficiently accessible to an ML reader.	Review	O	0
[line_break_token][line_break_token]Cons: Unfortunately, though, I just don't think this qualifies for acceptance at ICLR.	Review	O	0
It's application of known techniques, and lacks any ML novelty or sufficient ML interest.	Review	B-Review	1
It would only be appropriate for an "ML applications" track, which ICLR does not have.	Review	I-Review	1
And while its performance is _way_ better than that of the only previous work on the topic that they know, accuracy of mapping non-systematic chemical terms (54.04%) is still low enough that this technique doesn't seem ready for prime time.	Review	I-Review	1
[line_break_token][line_break_token]Other comments: In table 5, you show that a prior pipeline stage of spelling correction is definitely useful in your system (table 5).	Review	I-Review	2
And yet, given the power of deep learning seq2seq transductions, and the potential to use them for spelling correction, one might wonder whether this prior step of spelling correction is really necessary.	Review	I-Review	2
It might be interesting to explore further where it helps and whether the gains of spelling correction might be obtainable in other ways such as using data augmentation (such as spelling error insertion) in the seq2seq training data.	Review	I-Review	2
The Golebiewski bib entry is lacking any information as to where it is published, which seems especially bad for the key citation to prior work of the whole paper.	Review	I-Review	2
In general, the bibliography has issues: non-ASCII characters have been lost (you either need to LaTeX-escape them or to load a package like utf8, and capitalization of acronyms, etc.	Review	I-Review	2
should be improved with curly braces.	Review	I-Review	2
Please refer to our comments to AnonReviewer3 about our contribution and the role of this work.	Reply	O	0
[line_break_token]Here we want to add facts about the performance.	Reply	B-Reply	1
According to our industrial partner,  the largest chemical database maybe only contains 2% chemical names appearing in all the chemical literature just because of the name obstacle.	Reply	I-Reply	1
So, when an accuracy of about 60% is argued, we'd better look backwards.	Reply	I-Reply	1
Only several percents of extraction accuracy has supported all the existing chemical database building for a broad range of practical application, while our system boosts nearly 10 times accuracy improvement compared to previous state-of-the-art.	Reply	I-Reply	1
Just imagine how a new world we open for the community of CIP through this work.	Reply	I-Reply	1
[line_break_token]Please keep it in mind that even 6% extraction accuracy (ChemHits) can effectively and well serve all CIP work so far	Reply	I-Reply	1

Summary[line_break_token]This paper introduced a parameterized image processing technique to improve a robustness of visual recognition systems against noisy input data.	Review	O	0
The proposed method is composed of two components; a denoising network that suppresses the noise signals in an image, and gating network that predicts whether to use the original input image or the one produced by the denoising network.	Review	O	0
The proposed idea is evaluated on three tasks of object detection, tracking and action recognition.	Review	O	0
[line_break_token][line_break_token]Originality and significance:[line_break_token]The originality of the paper is very limited since the paper simply combines the existing image denoising technique with the idea of gating.	Review	O	0
The practical significance of the work is also limited since the model is trained and evaluated with only synthetically generated noise patterns; it is not surprising that the proposed method (both denoising and gating networks) works under this setting, as the noise is created synthetically under the same setting in both training and testing.	Review	B-Review	1
To demonstrate the practical usefulness, it would be great if the model is evaluated with the actual source of noises (e.g. noises from input sensors, distortion by image compression, etc).	Review	I-Review	1
 [line_break_token][line_break_token]Clarity:[line_break_token]I think the title of the paper is misleading; the proposed model is actually not a mixture of preprocessing units, as it combines *a* denoising unit together with identity mapping.	Review	O	0
The gating network is also not designed to incorporate a mixture of more than two preprocessing units, as it outputs only ‚Äúon/off switches‚Äù instead of weights for K mixture components (K>2).	Review	O	0
[line_break_token][line_break_token]Minor comments:[line_break_token]1) the paper argued the importance of lightweight preprocessing but have not provided analysis on computation costs.	Review	O	0
From the current results, I don‚Äôt see the clear benefit of the proposed method (denoising network) over the average filtering considering the tradeoff between computation vs. performance.	Review	B-Review	3
[line_break_token]2) In Figure 5, I suggest highlighting the differences among the examples for clarity.	Review	O	0
[line_break_token]	Review	O	0
Thank you for the valuable reviews.	Reply	O	0
[line_break_token][line_break_token]Q1 ‚Äì Originality and significance:[line_break_token][line_break_token](Ans) In contrast to many other DL works focused on denoising or image classification on noisy images [1-2], the main contribution of this paper is to enhance the performance of object detection and its related other tasks (multiple object tracking and activity recognition) under ‚Äúboth‚Äù noisy/clean condition with ‚Äúlimited overhead‚Äù in terms of memory/computation (table 5).	Reply	O	0
Also, we have discovered that adding average filter and U-net [3] like skip connection are beneficial for denoising.	Reply	B-Reply	1
[line_break_token]For the practical usefulness, it would be great if we can incorporate those actual noises as a future work.	Reply	I-Reply	1
Thanks for your feedback.	Reply	I-Reply	1
[line_break_token][line_break_token][1] P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, P.-A. Manzagol, "Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion", J. Mach.	Reply	I-Reply	1
Learn.	Reply	I-Reply	1
Res.,	Reply	I-Reply	1
vol.	Reply	I-Reply	1
11, no.	Reply	I-Reply	1
11, pp.	Reply	I-Reply	1
3371-3408, 2010.	Reply	I-Reply	1
[line_break_token][2] S. Diamond, V. Sitzmann, S. Boyd, G. Wetzstein, and F. Heide.	Reply	I-Reply	1
Dirty pixels: Optimizing image classification architectures for raw sensor data.	Reply	I-Reply	1
arXiv preprint arXiv:1701.06487, 2017.	Reply	I-Reply	1
[line_break_token][3] Olaf Ronneberger, Philipp Fischer, and Thomas Brox.	Reply	I-Reply	1
U-net: Convolutional networks for biomedical image segmentation.	Reply	I-Reply	1
In MICCAI (3), volume 9351 of Lecture Notes in Computer Science, pp.	Reply	I-Reply	1
234‚Äì241.	Reply	I-Reply	1
Springer, 2015.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2 ‚Äì Clarity:[line_break_token](Ans) We think that the title of the paper is valid.	Reply	O	0
It is true, in this paper, we have used identity mapping for the clean and low-resolution images as a preprocessing.	Reply	B-Reply	2
This was the result from our experiments, not necessarily obvious one.	Reply	I-Reply	2
There could be better preprocessing for low-resolution images that we haven‚Äôt explored.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3 - lightweight preprocessing[line_break_token](Ans) Please see the table 5.	Reply	O	0
Also, it is obvious that average filter requires less computation than the denoise net since denoise net includes average filter as a part (Please see the section 3.2 Pre-processing for the noisy images).	Reply	B-Reply	3
[line_break_token][line_break_token]Q4 - Figure 5:[line_break_token](Ans) We have changed the figure.	Reply	O	0

This paper presents an empirical study on the effect of pruning to the model performance on each class and example, which leads to a novel finding that it has disparate effects to each sample.	Review	O	0
Specifically, the authors have found out that examples that are affected the most by pruning are more difficult to classify even for the non-pruned network, due to low image quality, mislabeling, or being atypical from the class prototype, and performed a further human study to analyze the source of difficulty.	Review	O	0
Moreover, the authors performed an additional experiment, which shows that the sparse models are brittle against natural adversarial examples.	Review	O	0
[line_break_token][line_break_token]Pros[line_break_token]- The paper provides a novel insight on the effect of pruning at the class and the example level, which could lead to a more effective pruning approach that exploit this findings.	Review	O	0
[line_break_token][line_break_token]Cons[line_break_token][line_break_token]- The paper only provides a novel finding but not the solution on how to tackle this problem, and thus the paper looks incomplete.	Review	O	0
After section 3.3, I was expecting to see some approaches to tackle this problem but the paper abruptly ended.	Review	B-Review	1
[line_break_token][line_break_token]- The effect of pruning could largely differ from one method to another, but the authors do not experimentally compare the effects of different pruning methods.	Review	O	0
Also, it is highly likely that the findings discussed in the paper may be only true for input-independent pruning approaches, and may not generalize to input-dependent pruning method.	Review	B-Review	2
The authors need to perform extensive study of both input-dependent and input-independent pruning approaches to validate their points.	Review	I-Review	2
[line_break_token][line_break_token]In sum, the paper provides a novel insight on how pruning affects the performance at the example level, but does not provide a solution, and the current set of experiments is insufficient to validate that the empirical findings that the authors report generalize to other types of pruning approaches, such as input-dependent pruning.	Review	O	0
Thus I believe that the paper is not ready for publication yet, and vote for rejecting this paper in its current form.	Review	O	0
[line_break_token]	Review	O	0
e thank R1 for their feedback, and acknowledge that we do not propose a new method to solve the non-uniform impact of model pruning on different classes and images.	Reply	B-Reply	1
We believe our contribution is none the less of value to the ICLR community, because to our knowledge we are the first work to propose a formal framework for measuring the per-class and image impact of pruning deep neural networks.	Reply	I-Reply	1
We consider an unexplored and timely question given the widespread use of pruning as a compression technique in many sensitive domains.	Reply	I-Reply	1
[line_break_token][line_break_token]Our conclusion, that a small subset of classes and images bear the brunt of pruning, has wide ranging implications for the use of pruned models in sensitive domains.	Reply	I-Reply	1
The introduction of pruning may be at odds with fairness objectives to treat certain protected attributes uniformly and/or AI safety objectives to preserve human welfare when predictions by guaranteeing a certain level of recall for certain classes.	Reply	I-Reply	1
[line_break_token][line_break_token]Our contribution illustrates that top-1 accuracy alone tells a painfully incomplete picture, and that for these sensitive domains additional measures of model generalization are certainly needed.	Reply	I-Reply	1
We propose such formal measures of generalization difference in this manuscript.	Reply	I-Reply	1
We will update our manuscript to make this motivation and the scope of our contributions more clear.	Reply	I-Reply	1
[line_break_token][line_break_token]"The effect of pruning could largely differ from one method to another, but the authors do not experimentally compare the effects of different pruning methods."	Reply	O	0
[line_break_token][line_break_token]R1 is correct that the results that we report (while consistent across datasets) are only for a single pruning method.	Reply	B-Reply	2
We were restricted in our choice of pruning method by the need to pre-specify the final level of sparsity to allow for clean comparison across trained models.	Reply	I-Reply	2
We also note that magnitude pruning is a widely used (open source and integrated into the tensorflow library) and considered to be state of art (Gale et al.	Reply	I-Reply	2
2019).	Reply	I-Reply	2
 [line_break_token][line_break_token]We agree that a consideration of additional methods would be of value, and have committed to open sourcing our code so that we are not the bottleneck for further reproducibility.	Reply	I-Reply	2
We note that our methodology is pruning method agnostic, and can easily be extended to other method.	Reply	I-Reply	2
[line_break_token][line_break_token]We wanted to seek clarification on what R1 means by input-independent pruning approaches?	Reply	I-Reply	2
Can R1 reference an open source implementation of such an approach or prior work to help clarify the use of this terminology	Reply	I-Reply	2

The paper propose a new quantization-friendly network training algorithm called GQ (or DQ) net.	Review	O	0
I addresses the existing issues in the common paradigm, where a floating-point network is trained first, followed by a second-phase training step for the quantized version.	Review	O	0
It is a well-written paper.	Review	O	0
Concepts were clearly explained and easy to follow.	Review	O	0
Below I present my comments about some details in the paper that were not entirely clear for me.	Review	O	0
[line_break_token][line_break_token]- The two loss terms conflict each other.	Review	O	0
If the training algorithm focuses too much on the first term, it will make the network less friendly to the quantization process.	Review	B-Review	1
On the other hand, the second one is going to enforce too much emphasis on the accuracy from the quantized network.	Review	I-Review	1
It is natural to involve some hyperparameter search to find the balance between the two blending parameters.	Review	I-Review	1
The paper suggests a strategy as to how to handle this issue, but it is not comprehensive, and rather controversial.	Review	I-Review	1
I think the paper will benefit from a more in-depth discussion and analysis on this regularization issue.	Review	I-Review	1
[line_break_token][line_break_token]- The schedule for the loss term blending parameters looks drastic to me.	Review	O	0
It‚Äôs more like ‚Äútrain the floating point net first, and then train the quantized one, and then revisit the floating point one, and so on.	Review	B-Review	2
‚Äù I know I simplified, because the floating point network never stops getting updated as it‚Äôs \omega_f is always 1.	Review	I-Review	2
However, it seems to me that this drastic scheduling strategy sounds like very similar to the traditional approach that trains the floating point network first and then finetune the quantized one, except for the fact that this proposed algorithm repeats this process a few times.	Review	I-Review	2
Hence, I think the authors‚Äô argument about the supremacy of the proposed method to the two-step finetuning approach is not clearly supported.	Review	I-Review	2
[line_break_token][line_break_token]- The exponentially decaying learning rate scheduling looks like the one from ResNet.	Review	O	0
I‚Äôm wondering if it should be the best, especially with the drastic introduction and omission of the second loss.	Review	B-Review	3
[line_break_token][line_break_token]- In the ablation studies, it seems that some of the suggested training options are conflicting each other and the clear winner seems to be the multi-domain BN.	Review	O	0
I cannot conclude anything from this analysis as to which one is more important than the other one, except for the Alt{W,\theta} case.	Review	B-Review	4
[line_break_token][line_break_token]Some minor things:[line_break_token][line_break_token]- What‚Äôs the name of the proposed network?	Review	O	0
Is it GQ or DQ?	Review	B-Review	5
[line_break_token] 	Review	I-Review	1
 appreciate the authors' responses that clarified some of my questions.	Reply	O	0
The responses elaborated the arguments made in the original draft, while they do not fully resolve the fundamental issues.	Reply	B-Reply	1
For example, the I wouldn't say the gradient from the first loss term is more accurate, as it's using full precision, which is "different" from the test environment where reduced precision has to be used.	Reply	I-Reply	1
They also suggest a few potential solutions, while the revised version doesn't really contain those ideas.	Reply	I-Reply	1

*Summary*[line_break_token]This paper describes DiffSim, a differentiable programming system for learning with physical simulation.	Review	O	0
The system (built on the Taichi system) allows users to specify a forward simulation in a Python-like syntax, after which the program is compiled and iteratively run in both forward-mode and gradients computed for system parameters and controllers, as desired.	Review	O	0
A variety of simple simulations are included, demonstrating that the automatically generated CUDA code runs as fast as hand-written CUDA code (and noticeably faster than TensorFlow or PyTorch implementations), while requiring far fewer lines of code.	Review	O	0
The final section details two issues--time of  impact errors due to discrete time intervals and gradient explosions with long time horizons--and some potential solutions.	Review	O	0
[line_break_token][line_break_token]*Rating*[line_break_token]The paper is interesting and easy to read.	Review	O	0
While some part of the underlying functionality of DiffSim is directly derived from previous work (Taichi), the paper does describe a non-trivial contribution.	Review	O	0
[line_break_token][line_break_token]I lack the background to comment constructively about expectations for these simulations or the fidelity of the methods in this paper.	Review	B-Review	1
What evidence can you offer regarding the physical fidelity achievable and how that relates to issues of scalability, gradient behavior, size of time steps, code complexity, etc.?	Review	I-Review	1
For a sense of context, what might be needed to simulate a 7 DoF robotic arm and learn a controller that would reasonably transfer to a real robot?	Review	I-Review	1
[line_break_token][line_break_token]Overall, I'm optimistic about this paper, and would tend to vote for acceptance.	Review	O	0
[line_break_token][line_break_token]*Notes*[line_break_token]pg3: define k (spring stiffness?)	Review	B-Review	2
[line_break_token]pg4: what is the value of 'mass' for this simulation?	Review	I-Review	2
[line_break_token]Fig 8: what is the x-axis in the two right plots?	Review	I-Review	2
initial height?	Review	I-Review	2
[line_break_token]Fig 10: right plot title should probably be "Gradient Explosion with Damping"	Review	I-Review	2
ear Reviewer 3,[line_break_token][line_break_token]Thank you for the positive feedback.	Reply	O	0
The question about simulation fidelity is very interesting.	Reply	B-Reply	1
DiffSim is as expressive as traditional languages such as C++/Fortran in building physical simulators, so it can achieve the fidelity level of previously build simulators.	Reply	I-Reply	1
In order to simulate a 7-DoF robotic arm, a differentiable rigid body simulator written in DiffSim should be used to train the controller, but transferring the controller to a real robot would face a sim2real gap, just as physical simulators written in any other language.	Reply	I-Reply	1
DiffSim does not directly address this gap, but it does significantly reduce code complexity and would allow researchers to develop more realistic simulators with the same amount of work.	Reply	I-Reply	1
Similarly, DiffSim does not resolve the numerical accuracy issue caused by a finite time step size, but it does improve the program performance to allow users to run simulations with smaller time step sizes and higher spatial resolution and thereby smaller discretization errors.	Reply	I-Reply	1
[line_break_token][line_break_token]We have also fixed the minor issues in the revision:[line_break_token]   -   (Page 3) k is spring stiffness.	Reply	I-Reply	2
[line_break_token]   -   (Page 4) We used mass = 1 throughout the mass-spring simulation.	Reply	I-Reply	2
[line_break_token]   -   (Fig.	Reply	I-Reply	2
8) The x-axes are initial height.	Reply	I-Reply	2
[line_break_token]   -   (Fig.	Reply	I-Reply	2
10) Thanks for pointing out the typo in ‚ÄúGradient Explosion with Damping‚Äù.	Reply	I-Reply	2
As suggested by reviewer 2, we have removed the discussion on gradient explosion.	Reply	I-Reply	2
[line_break_token][line_break_token]Please also find the detailed paper change log in our general response to all reviewers.	Reply	O	0
Thank you again for your time and feedback.	Reply	O	0
[line_break_token][line_break_token]Best,[line_break_token]Author	Reply	O	0

The paper introduces a method for online adaptation of a model that is expected to adapt to changes in the environment the model models.	Review	O	0
The method is based on a mixture model, where new models are spawned using a Chinese restaurant process, and where each newly spawned model starts with weights that have been trained using meta-learning to quickly adapt to new dynamics.	Review	O	0
The method is demonstrated on model-based RL for a few simple benchmarks.	Review	O	0
[line_break_token][line_break_token]The proposed method is well justified, clearly presented, and the experimental results are convincing.	Review	O	0
The paper is generally clear and well written.	Review	O	0
The method is clearly most useful for situations where the environment suddenly changes, which is relevant in some real-world problems.	Review	O	0
As a drawback, using a mixture model (that also grows with time) for such modelling can be considered quite heavy in some situations.	Review	B-Review	1
Nevertheless, the idea of combining a spawning process with meta-learned priors is neat, and clearly works well.	Review	O	0
[line_break_token][line_break_token]Minor comments:[line_break_token]- Algorithm 1: is the inequality correct, and is T* supposed to be an argmin instead of argmax?	Review	O	0
Thank you for your review.	Reply	O	0
We have corrected the typo in both places of Algorithm 1: it should indeed have been the opposite inequality sign, and argmin instead of argmax.	Reply	B-Reply	2
[line_break_token][line_break_token]We definitely agree with your comment that a mixture model that grows with time can sometimes be considered quite heavyweight.	Reply	I-Reply	1
This is precisely where we plan to focus the efforts of our future work, by introducing a refreshing scheme where an offline retraining step can periodically condense the mixture model into fewer components (perhaps in a batch-mode training setting, so not all past data needs to be saved).	Reply	I-Reply	1
We are also interested in goals such as making this mixture only as big as the agent ‚Äúneeds‚Äù it to be, allowing for better and more compressed sharing and organization of seen data.	Reply	I-Reply	1
The performance of this current method makes us hopeful and excited to work toward such future work in this area	Reply	I-Reply	1

This paper jointly trains a sentiment classifier with a sentiment and domain-aware embedding[line_break_token]model, using both labeled and unlabeled data.	Review	O	0
When sentiment label is observed, this model is trained[line_break_token]with the usual cross entropy and maximum likelihood objectives; for unlabeled data, it uses pseudo[line_break_token]labels produced by the sentiment classifier with variational Bayes objective.	Review	O	0
This idea is not novel but the authors report that there is no previous work that jointly trains sentiment aware embeddings with a sentiment classifier specifically, and makes use of an unlabeled corpus to improve both.	Review	B-Review	1
However, there are general and broader methods such as 'Toward Controlled Generation of Text' by Hu et al that apply semi-supervised techniques for generation (not classification) with specific constraints (sentiment, domain, etc).	Review	I-Review	2
There are other recent methods such as 'Improving Language Understanding by Generative Pre-Training' by Redford et al that use the idea of generative pre-training with discriminative fine-tuning that are task-agnostic and achieve very good performance - how does the paper compare to this approach?	Review	I-Review	3
[line_break_token]The experiments and analysis is very well written in the paper.	Review	O	0
Table 4 also shows very interesting, somewhat surprising results in the paper.	Review	O	0
The authors say that they will release the code and data for this technique which will be useful for the sentiment analysis research community.	Review	O	0
 [line_break_token]	Review	B-Review	1
Thanks for the informative comment.	Reply	O	0
Hu et al.	Reply	B-Reply	2
‚Äôs ICML2017 paper is especially a very interesting read.	Reply	I-Reply	2
It is not directly comparable to this paper because, as the reviewer already pointed out, Hu et al.	Reply	I-Reply	2
‚Äôs is about (sentence) generation but this paper is about (document) classification.	Reply	I-Reply	2
Nevertheless, let‚Äôs have a deep discussion about these two papers.	Reply	I-Reply	2
[line_break_token][line_break_token]First, Hu et al.	Reply	I-Reply	2
‚Äôs is insightful in that it models different semantic attributes as independent factors which control generation; our paper shares a very similar spirit by learning a disentangled sentiment part and a domain specific part for word embeddings.	Reply	I-Reply	2
When the data is unlabeled, both papers use discriminators to produce pseudo-labels for training the generative model.	Reply	I-Reply	2
[line_break_token][line_break_token]But then, Hu et al.	Reply	I-Reply	3
‚Äôs model propagates gradients of the discriminator directly back to the generator, using softmax annealing to circumvent the discreteness of text data; this technique is unnecessary in our setting, because the classifier in our model uses word embeddings (rather than words themselves) as input, and the embeddings are shared between classifier and the generative model.	Reply	I-Reply	3
In other words, Hu et al.	Reply	I-Reply	3
‚Äôs approach uses the discriminator to train the generator, whereas in our model the two are jointly trained.	Reply	I-Reply	3
[line_break_token][line_break_token]On the other hand, Hu et al.	Reply	I-Reply	4
achieve semi-supervised learning of the discriminator by synthesizing data samples from the generator, whereas we use a variational Bayes objective on unlabeled data.	Reply	I-Reply	4
Synthesized data only work if one has a good generator; we know that LSTM is a good generator for short sentences, but things are less clear for other types of objects, such as lengthy documents.	Reply	I-Reply	4
Therefore, I would not say which one is more general and broader method; both Hu et al.	Reply	I-Reply	4
‚Äôs and our work are meaningful extensions/applications of Kingma‚Äôs variational Bayes framework.	Reply	I-Reply	4
[line_break_token][line_break_token]From a broader perspective, there is no doubt that combining generative and discriminative models is a promising methodology toward semi-supervised learning, and we are interested in this direction because there are plenty of potential applications in Natural Language Processing.	Reply	I-Reply	3
For example, one could combine parser and sentence generator, by parsing the generated sentences back to semantic structures to check if intended meanings are conveyed.	Reply	I-Reply	3
This idea dates back to old days such as in Duan and White (ACL2014), and is still very active such as in Konstas et al. (	Reply	I-Reply	3
ACL2017).	Reply	I-Reply	3
Domain adaptation of sentiment classifiers is just another, simple but important application task, and there is novelty in applying variational Bayes methods here.	Reply	I-Reply	3
We believe the knowledge obtained here will be helpful to other tasks as well.	Reply	I-Reply	3
We will modify Related Works to discuss this broader point, including Hu et al.	Reply	I-Reply	3
and Redford et al.,	Reply	I-Reply	3
as is also suggested by AnonReviewer1.	Reply	I-Reply	3
[line_break_token][line_break_token]As for Redford et al.	Reply	I-Reply	3
‚Äôs in-progress work, we believe it belongs to the realm of pretraining unsupervised language models in order to enhance a wide range of classification tasks.	Reply	I-Reply	3
We have already compared with one of its state-of-the-art, ELMo, and shown that we can outperform ELMo in this task, with much smaller unlabeled data.	Reply	I-Reply	3
The big difference here, is that the representation learned by our generative model is aware of task-specific latent labels (i.e. sentiment), thus it is more task-oriented; in contrast, representations learned by pretraining unsupervised language models are task-agnostic.	Reply	I-Reply	3
Our ablation tests clearly show that more task-oriented representations can improve performance on that task	Reply	I-Reply	3

The paper proposes to learn representations by using Krein inner products which are generalizations of standard inner products in Hilbert spaces.	Review	O	0
[line_break_token]A Krein inner product can be formulated as the difference between two inner products, each in a Hilbert space.	Review	O	0
[line_break_token]Although the paper mentions three main contributions, the contributions of the papers are mainly:[line_break_token]- 1.	Review	O	0
using Krein distances instead of Hilbert distances to compare examples[line_break_token]- 2.	Review	O	0
better empirical performance on some datasets[line_break_token][line_break_token]The paper is clear in general, and maybe provides too many details on standard linear algebra (about 3 pages to explain the eigendecomposition of symmetric matrices).	Review	O	0
[line_break_token]My main concern is about novelty.	Review	O	0
The proposed method has already been published in the literature but never been called "representation in a Krein space" (see Novelty point).	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
Motivation:[line_break_token][line_break_token]It is already known in the literature that Hilbert spaces are limited for certain tasks, non-Euclidean distances have then been used to compare examples.	Review	O	0
[line_break_token]For instance, based on the work of [A], some works have proposed to learn deep representations exploiting hyperbolic distances to represent data with hierarchical structure [B].[line_break_token]The motivation of the superiority of Krein representations is not clear in the paper.	Review	O	0
In what specific contexts is it better to use Krein spaces?	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
Novelty:[line_break_token][line_break_token]The authors take the example of Mahalanobis-like distance metric learning where a distance function parameterized by a symmetric matrix usually constrained to be positive semi-definite (PSD) is learned.	Review	O	0
The paper argues that constraining the matrix to be PSD limits the expressiveness of the model as the negative spectrum is also meaningful.	Review	O	0
[line_break_token]If the PSD constraint is removed, the problem simply corresponds to learning a symmetric matrix.	Review	O	0
Indeed, by definition, symmetric matrices have real eigenvalues which can be either non-negative or negative.	Review	O	0
The PSD constraint enforces the eigenvalues to be non-negative.	Review	O	0
If the PSD constraint is removed, then the symmetric matrix can be indefinite, which corresponds to the proposed representation in Krein space.	Review	O	0
[line_break_token][line_break_token]Some papers have already proposed to remove the PSD constraint (e.g. [C], Section 2.3) when learning a distance parameterized by a symmetric matrix, which corresponds to the proposed model.	Review	O	0
However, they did not sell the relaxation of the PSD constraint as a contribution.	Review	O	0
[line_break_token][line_break_token]3.	Review	O	0
Experiments:[line_break_token][line_break_token]The experimental section is weak as it provides a simple experiment on a toy dataset, and quantitative results on 4 datasets only for one optimization problem and one specific network architecture.	Review	O	0
[line_break_token]Since the theoretical aspect of the paper is weak, I would expect more comparisons by replacing standard deep metric learning formulations (that use the squared Euclidean distance) with the proposed Krein distance.	Review	O	0
For instance, the submission cites (Oh Song et al.),	Review	O	0
and (Schroff et al.)	Review	O	0
as deep metric learning approaches.	Review	O	0
How would the proposed Krein distance perform in the contexts considered in those references?	Review	O	0
[line_break_token][line_break_token]Demonstrating that the Krein distance also outperforms the squared Euclidean distance in that case would strengthen the experimental aspect of the paper.	Review	O	0
[line_break_token][line_break_token][line_break_token]In conclusion, the theoretical and experimental aspects of the paper are weak.	Review	O	0
[line_break_token][line_break_token][line_break_token][A] Gromov, Hyperbolic groups, 1987[line_break_token][B] Ganea et al, Hyperbolic Neural Networks, NIPS 2018[line_break_token][C] Guillaumin et al.,	Review	O	0
Is that you?	Review	O	0
Metric learning approaches for face identification, ICCV 2009	Review	O	0
We thank the reviewers for investing time and effort to provide us with constructive feedback.	Reply	O	0
We take on board the reviewer comments to improve our future work	Reply	O	0

This paper presents a rotation-equivariant model for use with point-clouds.	Review	O	0
 Capsule networks with activation and rotation pose estimate in the form of a quaternion are applied to local patches of 3D points, and combined up through progressively more coarser receptive fields.	Review	O	0
 Rotation equivariance is obtained by looking for agreement between input point frames (or capsules), by iteratively clustering using the quaternion mean.	Review	O	0
 The method is evaluated on ModelNet40, obtaining much improved results in the case where rotation orientation is arbitrary.	Review	O	0
[line_break_token][line_break_token]Unfortunately, I found too many important parts of the method difficult to understand, enumerated below, and am also not very clear on the details of how they fit together.	Review	O	0
 At a high level, the approach of aggregating pose agreement with quaternion averages makes intuitive sense, the quaternion average step itself is described well, and the experimental results seem to corroborate this (results on NR/AR condition are very good, and also near identical to NR/NR condition, a major verification of the method).	Review	B-Review	6
 However, the rest of the pieces of the method still leave me guessing too much.	Review	I-Review	6
[line_break_token][line_break_token]*  It isn't clear what computes the activations alpha.	Review	O	0
 I don't see a description for how to compute activations alpha that are the input to Alg.	Review	B-Review	1
1, unless these are simply the activations of the previous layer's capsules, and constant for the initial point frames?	Review	I-Review	1
[line_break_token][line_break_token]*  Likewise, the transform t() could use more description.	Review	O	0
 Sec 3.2 says it is R3-&gt;R4, indicating that the input to t() is a single point.	Review	O	0
 Does this mean that the mere presence of a point in a location R3 (relative to a mostly-canonicalized pose) counts as a vote for a rotation pose?	Review	B-Review	2
 And if so, how does does this work?	Review	I-Review	2
 Or does the regressor actually take multiple points as input?	Review	I-Review	2
 According to the picture in Fig.	Review	I-Review	2
1, it looks like it takes all points in the local patch as input.	Review	I-Review	2
[line_break_token][line_break_token]*  Algorithm 1 outer for loop for i doesn't seem quite right.	Review	O	0
 It suggests that the body is performed either independently or in sequence for each i.  I believe what may actually be intended, is that all i are used at once in parallel, so that the v_ij votes assignment is found for *all* i in order to use in finding the cluster mean for each j.  That is, "v_i,j = Q_i * t_i,j for all i", rather than having the outermost loop over i.  Is this correct?	Review	B-Review	3
[line_break_token][line_break_token]*  Much space is dedicated to background explanations of quaternions, geodescic distance, etc.	Review	O	0
 Given my difficulty in understanding much of the system, it seems like some of could be shortened or put into the appendix, and more of the main text devoted to more detailed explanations of each component in the system (e.g. alpha and t), and how the capsule agreement step (QE DR) makes use of these.	Review	B-Review	4
[line_break_token][line_break_token][line_break_token]Also, some more detailed comments/suggestions:[line_break_token][line_break_token]* Alg.1:  output alpha^hat_K, seems K should be M here?	Review	O	0
[line_break_token]* Table 1:  "Right hand side denotes symmetric objects" seems it actually shoudl be in the caption for Table 2.	Review	B-Review	5
[line_break_token]	Review	O	0
e thank the reviewer for the specific comments and acknowledging the improved results we achieve in the paper.	Reply	O	0
Please find our responses below.	Reply	O	0
[line_break_token][line_break_token]1. ‚	Reply	O	0
ÄúThe activation‚Äù: It is true that the update of alpha is only included in the algorithm as it is a standard result from previous works [Sabour et al.	Reply	O	0
2017a, Lenssen et al.,	Reply	B-Reply	1
2018]. The input to Alg 1.	Reply	I-Reply	1
are the alphas of the previous layer and we set the initial activations to 1.	Reply	I-Reply	1
We have now clearly indicated that in the last paragraph of Sec.3.2.	Reply	I-Reply	1
[line_break_token][line_break_token]2. ‚	Reply	O	0
ÄúThe transform t()‚Äù: We have significantly increased our explanation and reworked the formalization of the transform network in the paper.	Reply	O	0
The t() network does not directly compute the vote.	Reply	B-Reply	2
It is merely producing the transformation, on which the input pose is applied to produce the vote: v = q t().	Reply	I-Reply	2
It is the continuous analogue to the approach in the original capsule networks by Sabour et al.	Reply	I-Reply	2
There, those transformations lie in a discrete kernel window and are directly optimized like weights for convolution.	Reply	I-Reply	2
 Here, we train a continuous kernel function instead, given that input capsules are attached to points that lie in continuous space and not on a fixed grid.	Reply	I-Reply	2
The function t() is shared for all input points and produces transformations for all combinations of input capsules from the respective point and output capsules, which we clarified in the first paragraph of Sec.3.2.	Reply	I-Reply	2
Additionally, we added specific details of the architecture with pseudocode in Alg.3.	Reply	I-Reply	2
[line_break_token][line_break_token]3.‚ÄùLoop in Alg.1‚Äù: Thank you for making us aware of this error.	Reply	O	0
We fixed the algorithm in the updated version.	Reply	B-Reply	3
[line_break_token][line_break_token]4.‚ÄùLimited space for explanation‚Äù: We have now shortened the background section to give room for further explanations.	Reply	O	0
The paper is also slightly longer.	Reply	B-Reply	4
As mentioned above, we have added more explanation of the network architecture in Sec.3.2 (added alpha and t), Sec.4 and appendix(Alg.3).	Reply	I-Reply	4
In Alg.3, we explain the details of the QE-net with pseudocode, included the ‚Äút(.)‚Äù and how the DR is used after we got the transformations.	Reply	I-Reply	4
[line_break_token][line_break_token]5.‚Äù more detailed comments‚Äù:  Thanks for those corrections.	Reply	O	0
We have now incorporated them.	Reply	B-Reply	5

This paper tackles the problem of navigating scenes to find objects which are potentially not included in the training phase.	Review	O	0
To find an unseen object from a scene, the proposed model incorporates an external knowledge graph as an augmented input of the actor-critic model.	Review	O	0
To construct a knowledge graph, entities in a scene are identified by ResNet and then the link structure between entities are extracted from VIsual Genome dataset.	Review	O	0
Through the ablation study, it is shown that using the knowledge graph helps to track and identify unseen objects during training.	Review	O	0
[line_break_token][line_break_token]- The original knowledge graph (KG) has relation labels (such as next to, on in figure 3) between different objects, however, GCN does not take into account the relations between objects.	Review	O	0
Only co-occurrence patterns will be encoded into the KG constructed from an image.	Review	B-Review	1
There are more complex graph convolutional models modelling relations between nodes such as [1]. Have you considered adding explicit relations between entities?	Review	I-Review	1
will it increase the navigation performance?	Review	I-Review	1
if not why?	Review	I-Review	1
[line_break_token]- It is unclear how many objects are used to construct a KG from an image.	Review	O	0
For example, are top-k objects identified by ResNet used to construct a KG?	Review	B-Review	2
[line_break_token]- Description of the reward is a bit unclear as well, especially when the model is trained without stop action.	Review	O	0
From the text, the agents receive a positive reward when it is close to the target (within a certain number of steps).	Review	B-Review	3
Does this mean that the agent gets a positive reward on every step near the target while it's not in the final state?	Review	I-Review	3
[line_break_token]- This might be a trivial question, but I couldn't find it from the text.	Review	O	0
Can you find all object from AI2-THOR in the categories of ImageNet and of Visual Genome?	Review	B-Review	4
is there any information loss while constructing a KG from the classification result?	Review	I-Review	4
What is the average number of nodes of a KG?	Review	I-Review	5
and is there any correlation between the size of KG and the result?	Review	I-Review	5
[line_break_token]- Why are the performances of the models is unstable with Bedroom dataset (in terms of variance)?	Review	O	0
[line_break_token]- The input feature of GCN is a combination of word feature and image feature.	Review	O	0
It is clear that there is a corresponding word embedding for each of the identified objects, but it is unclear what is the corresponding image feature.	Review	B-Review	7
If two objects are identified in the same frame, do input features of these two objects share the same image features from Resnet?	Review	I-Review	7
[line_break_token][line_break_token][1] Schlichtkrull, Michael, et al. "	Review	O	0
Modeling relational data with graph convolutional networks."	Review	O	0
European Semantic Web Conference.	Review	O	0
Springer, Cham, 2018.	Review	O	0
[line_break_token]	Review	O	0
Thank you for the valuable comments and clarifying questions.	Reply	O	0
Please find the responses to your questions and comments below.	Reply	O	0
[line_break_token][line_break_token]- Have you considered adding explicit relations between entities?	Reply	O	0
will it increase the navigation performance?	Reply	O	0
if not why?	Reply	O	0
[line_break_token][line_break_token]Answer: Yes, we used the explicit relations but it did not improve the results (we briefly mention that towards the end of Section 5.2).	Reply	O	0
That is probably due to overfitting since we have few examples for each type of relation.	Reply	B-Reply	1
[line_break_token][line_break_token]- It is unclear how many objects are used to construct a KG from an image.	Reply	O	0
For example, are top-k objects identified by ResNet used to construct a KG?	Reply	O	0
[line_break_token][line_break_token]Answer: The number of nodes is fixed and it is not image dependent.	Reply	O	0
We are considering 53 objects of THOR so our graph has 53 nodes (Section 5.1).	Reply	B-Reply	2
[line_break_token][line_break_token]- The agents receive a positive reward when it is close to the target (within a certain number of steps).	Reply	O	0
Does this mean that the agent gets a positive reward on every step near the target while it's not in the final state?	Reply	O	0
[line_break_token][line_break_token]Answer: In the scenario that we use the termination action, the agent should say ‚Äústop‚Äù when it observes the target object to get the reward.	Reply	O	0
Otherwise, it will not receive the reward.	Reply	B-Reply	3
In the scenario that we do not have the termination action, the agent might receive the positive reward at multiple points since we reward the agent if the target is within the cone of visibility and within 1 meter from the agent.	Reply	I-Reply	3
Once it receives the reward the episode is finished.	Reply	I-Reply	3
[line_break_token][line_break_token]- Can you find all object from AI2-THOR in the categories of ImageNet and of Visual Genome?	Reply	O	0
is there any information loss while constructing a KG from the classification result?	Reply	O	0
[line_break_token][line_break_token]Answer: About half of the object categories are not in ImageNet.	Reply	O	0
However, all of them appear in Visual Genome.	Reply	B-Reply	4
[line_break_token][line_break_token]- What is the average number of nodes of a KG?	Reply	O	0
and is there any correlation between the size of KG and the result?	Reply	O	0
[line_break_token][line_break_token]Answer: We use 53 nodes.	Reply	O	0
In Table 3 of the original submission (Table 4 of the revised version), we show how the performance degrades as we remove nodes and relations from the graph.	Reply	B-Reply	5
[line_break_token][line_break_token]- Why are the performances of the models is unstable with Bedroom dataset (in terms of variance)?	Reply	O	0
[line_break_token][line_break_token]Answer: One run got stuck in a bad local minima and that caused a large variance.	Reply	O	0
We have multiple runs with different random initialization.	Reply	B-Reply	6
[line_break_token][line_break_token]- It is unclear what is the corresponding image feature.	Reply	O	0
If two objects are identified in the same frame, do input features of these two objects share the same image features from Resnet?	Reply	O	0
[line_break_token][line_break_token]Answer: Yes, that is right.	Reply	O	0
We use image-level features (as opposed to object-level features).	Reply	B-Reply	7
Some of our object categories are novel and unseen so we cannot train supervised detectors for them.	Reply	I-Reply	7

This paper proposes to detect inputs that are from a slightly shifted distribution (eg images of houses in CA instead of KY) or from a very shifted distribution (eg imagenet images) by fitting a density model to the last layer h(x) of an MLP trained with squared error, and using the likelhiood score p(h(x)) as a metric.	Review	O	0
This is a reasonable idea.	Review	O	0
However, it is not novel eg Aigrain'19 did essentially the same thing for classification models. (	Review	B-Review	1
The difference between classification and regression is a trivial change to the loss function, and does not change the fundamental idea.)	Review	I-Review	1
[line_break_token][line_break_token]In addition to lack of novelty, the experimental methodology is very weak.	Review	I-Review	2
First, the toy 2d example is too trivial to be informative, since there is essentiallly no overlap between the two distributions of features, p(x) and q(x) - even a density model on input space could detect this.	Review	I-Review	2
More importantly, the results on the two image datasets are suspect.	Review	I-Review	2
First, it seems that using the predictive variance sigma(x) as the reliability metric (the "var" method) - which is totally standard approach known as 'heteroskedastic regression'. -	Review	I-Review	2
works very well in several cases.	Review	I-Review	2
I suspect when it fails it is due to  implementation problems (eg trying to predict sigma instead of log(sigma)).	Review	I-Review	2
Also ensembles are known to be very robust to distribtution shift (see eg Ovadia'19), so  I am surprised at their poor performance.	Review	I-Review	2
Another problem is that the datasets used are not standard, so it is impossible to compare to other papers.	Review	I-Review	3
Finally, no error bars are reported, so it is hard to know if any of the results are statistically significant.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]J. Aigrain and M. Detyniecki, ‚ÄúDetecting Adversarial Examples and Other Misclassifications in Neural Networks by Introspection,‚Äù in ICML Workshop on Uncertainty and Robustness in Deep Learning, 2019 [Online]. Available: <a href="http://arxiv.org/abs/1905.09186" target="_blank" rel="nofollow">http://arxiv.org/abs/1905.09186</a>[line_break_token][line_break_token][line_break_token]Y. Ovadia et al., ‚	Review	O	0
ÄúCan You Trust Your Model‚Äôs Uncertainty?	Review	O	0
Evaluating Predictive Uncertainty Under Dataset Shift,‚Äù arXiv [stat.	Review	O	0
ML], 06-Jun-2019 [Online]. Available: <a href="http://arxiv.org/abs/1906.02530" target="_blank" rel="nofollow">http://arxiv.org/abs/1906.02530</a>[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
.R.T. novelty: Thank you for making us aware of Aigrain et al.	Reply	O	0
‚Äôs work.	Reply	B-Reply	1
However, we strongly disagree that our proposed method is ‚Äúessentially the same thing.	Reply	I-Reply	1
‚Äù Aigrain et al.	Reply	I-Reply	1
‚Äôs method requires 1) generating adversarial inputs and artificial OOD inputs and 2) trains a neural network (a supervised method) on the logits to identify OOD inputs.	Reply	I-Reply	1
Our method on the other hand 1) does not require any OOD inputs at training time (real or artificial) and 2) models the distribution of in-distribution features with a simple Gaussian Mixture Model.	Reply	I-Reply	1
We believe that this makes our method substantially different and a novel contribution.	Reply	I-Reply	1
[line_break_token][line_break_token]W.R.T. the performance of heteroskedastic regression and ensembles: you note that these baseline methods ‚Äúwork very well in several cases.	Reply	O	0
‚Äù Our experiments indeed confirm this: the ‚Äúvar‚Äù (heteroskedastic) model and the ensemble both achieve an AUROC of &gt;90% on most of our experiments, making these methods strong baselines and not ‚Äúpoor‚Äù performers.	Reply	O	0
At the same time, we do not find it surprising that our proposed method outperforms them.	Reply	B-Reply	2
The predicted variance from a heteroskedastic model (which we did in fact parameterize logarithmically) is a reduction of the feature space down to a single dimension.	Reply	I-Reply	2
Likewise, an ensemble reduces predictions down to a handful of dimensions (one for each model in the ensemble).	Reply	I-Reply	2
These reductions would be prone to the curse of dimensionality argument that we outline in Section 3.	Reply	I-Reply	2
Our proposed method on the other hand uses all &gt;1000 dimensions of the feature space to determine if inputs are OOD.	Reply	O	0
[line_break_token][line_break_token]W.R.T the datasets: We chose to focus on image datasets which are the most common datasets for OOD and domain adaptation datasets.	Reply	O	0
This is likely because it is easy to generate images which are ‚Äúout of distribution‚Äù (i.e. use images from an unrelated dataset), whereas it would be more difficult to generate OOD data for e.g. tabular datasets.	Reply	B-Reply	3
[line_break_token][line_break_token]We introduced new datasets because we were not aware of any image datasets used for regression.	Reply	I-Reply	3
We view this as a contribution in its own right, as future regression-OOD research can utilize these datasets/baselines for evaluation.	Reply	I-Reply	3
[line_break_token][line_break_token]W.R.T. error bars: we will update our results table with multiple runs of our experiments	Reply	O	0

[line_break_token][line_break_token]First, I would like to note that the claim that SGD with momentum is a special case of Adam with large epsilon is technically wrong because Adam also includes the bias-corrected momentum estimates which SGD with momentum does not consider.	Review	O	0
It might seem like a small difference, however it is a form of learning rate schedule which most users of Adam are not aware of.	Review	O	0
In practice, however, Adam with large epsilon can approximate SGD with momentum.	Review	O	0
Just don't claim the equivalent since it is not there.	Review	O	0
[line_break_token][line_break_token]I have some difficulties understanding the contribution of the paper.	Review	B-Review	1
For example [line_break_token]"When tuning all available metaparameters under a realistic protocol at scales common in deep learning,[line_break_token]we find that more general update rules never underperform their special cases."	Review	I-Review	1
[line_break_token]In practice you do adjust hyperparameter search spaces to fit your conclusions, e.g., "We found that searching over (epsilon, alpha0/epsilon) was more efficient than searching over (epsilon, alpha)."	Review	I-Review	2
Again, this alone invalidates your experimental setup since you biased it in order to fit your conclusion: "was more efficient" was found after running some prior experiments.	Review	I-Review	2
[line_break_token]Another situation where your experimental setup is unfairly tuned is when you used different hyperparameter ranges for similar hyperparameter, e.g. see D.2 for ResNet-32 on CIFAR-10 where 6 orders of magnitute difference was used for the initial learning of Momentum and 3 orders of magnitude difference for the initial learning rate of Adam.	Review	I-Review	3
Similarly, there is a difference of 10x for ImageNet experiments.	Review	I-Review	3
[line_break_token][line_break_token]The paper suggests that 16 experiments is enough to produce good results.	Review	I-Review	4
First, one should not forget the  special arrangements (see above) done for hyperparameter search space.	Review	I-Review	4
Second, for any person working in black-box optimization it is clear that 16 experiments is next to nothing.	Review	I-Review	4
It should give you something good in 1D, possibly in 2D if your search range is narrow.	Review	I-Review	4
This is absolutely nothing in larger dimensions (providing that your benchmark in not super trivial and your hyperparameter search space is not absolutely boring when you already narrowed it around the optimum).	Review	I-Review	4
After 16 evaluations you get pretty bad settings for most algorithms.	Review	I-Review	4
[line_break_token][line_break_token]Update: [line_break_token][line_break_token]The paper uses a naive hyperparameter optimizer and runs it for a very small budget.	Review	O	0
The latter likely affects the conclusion of the paper that different training algorithms perform similarly.	Review	O	0
The authors seem to accept it by mentioning that this is the case for their tuning protocol/budget.	Review	O	0
[line_break_token][line_break_token]If we would like to compare different training algorithms, we should optimize them on a set of problems using 2-3 state-of-the-art hyperparameter optimizers.	Review	B-Review	5
Then, we should study how the best seen solutions so far and their robustness  change as a function of the computation budget (the maximum budget should be large enough).	Review	I-Review	5
Then, one would see that the results are not that different for small budgets (a boring result) and somewhat different for larger budgets.	Review	I-Review	5
Showing only the boring part seems more misleading than useful.	Review	I-Review	5
[line_break_token][line_break_token]Update#2:[line_break_token]As I mentioned in my review, Adam with large epsilon is not equivalent to momentum SGD but only approximates the latter.	Review	O	0
This is because the original Adam has a bias correction term and even if the same *global* learning rate schedule is used both for Adam with large epsilon and momentum SGD, they are not equivalent.	Review	B-Review	6
In order to obtain the exact equivalence, one would need to either[line_break_token]1) drop the bias correction term of Adam and thus modify the algorithm in order to satisfy the claimed equivalence[line_break_token]or [line_break_token]2) set a particular learning rate *for each batch pass* of Adam to simulate the effect of the bias correction term, this leads to a large number of hyperparameters - as many as the number of batch passes, this is intractable (the setup of the authors does not optimize such batch-wise hyperparameters, they are defined by a global scheduler as a function of batch/epoch index).	Review	O	0
 [line_break_token]If you avoid these modifications, then you can't claim the equivalence but only an approximation.	Review	B-Review	6
If you don't have the equivalence of the two approaches and so momentum SGD is not a particular case of Adam, then the following sentence from the abstract is false: " As tuning effort grows without bound, more general optimizers should never underperform the ones they can approximate (i.e., Adam should never perform worse than momentum)".	Review	I-Review	6
Again, strictly speaking, it is false that "Adam should never perform worse than momentum" because momentum SGD is not a particular case of the original Adam *unless* you drop the bias correction term or simulate it with tons of hyperparameters, one learning rate value per batch pass.	Review	I-Review	6
Any global learning rate schedule *used for both* algorithms will not solve the issue because the bias correction term will remain.	Review	I-Review	6
If you don't modify the learning rate schedule of Adam but only of momentum SGD, then you basically adjust your SGD by moving some part of Adam in it to claim the equivalence of the two, such actions can make pretty much every second algorithm equivalent to another.	Review	I-Review	6
[line_break_token][line_break_token]My main concern is described in the first Update.	Review	O	0
It is trivial that a more general optimizer is capable to perform at least as good as its particular case.	Review	B-Review	5
What is not trivial is to clarify the interplay of computational budgets spent on hyperparameter tuning vs number of hyperparameters vs performance over time.	Review	I-Review	5
 	Review	I-Review	1
o facilitate discussion, we have responded to the three paragraphs of review 1 in separate threads.	Reply	O	0
The 2nd paragraph seems to contain the reviewer‚Äôs primary concerns, so we focus on that first.	Reply	O	0
Our latest revision should resolve the other issues mentioned by the review.	Reply	O	0
[line_break_token][line_break_token]- - - Summary - - - [line_break_token][line_break_token]1.	Reply	O	0
We do not think the concerns raised in the 2nd paragraph are reasonable, nor is it reasonable to accuse us of acting in bad faith after we exceeded the standards of transparency and care in the literature (e.g. by reporting preliminary search spaces as well as final ones).	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
The reviewer was concerned that search spaces with nominally larger learning rate ranges for SGD and Momentum might be unfair relative to Adam, even though Adam faces a higher dimensional search problem.	Reply	B-Reply	3
[line_break_token]‚óè Although part of the point of our work is that we don't think any search spaces are completely fair, we do not think our original search spaces were unreasonable or biased our conclusions.	Reply	I-Reply	3
Nevertheless, we ran additional experiments on CIFAR10 designed to, if anything, give non-adaptive optimizers an advantage and confirmed that using the "same" ranges wouldn't change our conclusions.	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	O	0
The reviewer was concerned that because we decided to search (epsilon, alpha0/epsilon) instead of searching (epsilon, alpha), we somehow unfairly penalized the non-adaptive optimizers because the former parameterization of the search space is more efficient for Adam in our experience.	Reply	B-Reply	2
[line_break_token]‚óè Our choice here is akin to log-transforming 1-momentum when tuning Momentum or log transforming learning rate.	Reply	I-Reply	2
Only the adaptive optimizers *have* an epsilon parameter that needs to be searched, so this cannot be unfair to SGD or Momentum since they already benefit from not having to tune the hyperparameter at all.	Reply	I-Reply	2
[line_break_token][line_break_token]- - - Full response - - - [line_break_token][line_break_token]One of the central points of our paper is that any empirical comparison of optimizers depends on the tuning protocol.	Reply	O	0
No protocol we are aware of can guarantee fairness between optimizers with incommensurate search spaces -- and yet, empirical optimizer comparisons are crucial for developing new optimizers and guiding practitioners training neural networks.	Reply	B-Reply	4
To our knowledge, no other study has highlighted how these comparisons are sensitive to the tuning protocol and which hyperparameters are tuned.	Reply	I-Reply	4
Regarding our own results, we make clear in Section 5 that we should only expect our detailed findings to hold for similar workloads under similar protocols.	Reply	I-Reply	4
[line_break_token][line_break_token]Although it is always difficult to guarantee fairness when tuning over optimizers with incommensurate search spaces, this is still true for protocols that attempt to use the "same" search space for Adam and Momentum (Adam‚Äôs learning rate parameter is more closely related to (learning rate)/(1 - momentum), so the optimal ranges are almost always different between the two optimizers).	Reply	I-Reply	4
Why should practitioners tie one hand behind their backs and only search a set of alpha values when tuning Adam that are the same as the set of learning rate values they search when tuning SGD?	Reply	I-Reply	4
Given the importance of tuning protocols, practitioners must decide which protocol most closely captures their own when deciding which optimizer comparison is most relevant to them.	Reply	I-Reply	4
Since our protocol produces results that exceed the performance from other optimizer comparisons in most cases (see Figures 3 and 4), we expect that readers will prefer using something similar to our tuning protocol.	Reply	I-Reply	4
[line_break_token][line_break_token]In light of reviewer 1‚Äôs concerns about our CIFAR-10 experiments, and to further support our claim that all optimizers were well tuned, we ran additional experiments with ResNet-32 on CIFAR-10.	Reply	I-Reply	4
We ran an experiment with SGD, Momentum, and Nesterov with a search space where all learning rate and momentum ranges had the same width as the ranges for Adam's similar hyperparameters (ignoring that they are not necessarily the same units).	Reply	I-Reply	4
We centered these new ranges on the best points from the original search, making the new comparison, if anything, unfair to the adaptive methods.	Reply	I-Reply	4
Although further narrowing the search space about the best validation error reduces the mean validation error, our conclusions do not change from what was reported in the paper.	Reply	I-Reply	4
Taking the process yet further, we doubled the trial budget for all optimizers and re-ran these equal-width-search-space experiments.	Reply	I-Reply	4
Again, although the best validation error improved slightly for all optimizers, test error did not change much, and we see no clear evidence that the inclusion relationships are violated.	Reply	I-Reply	4
See imgur.com/a/j38e1HP.	Reply	I-Reply	4
[line_break_token][line_break_token]Ultimately, it is extremely difficult to judge whether one of two incommensurate search spaces provides some sort of advantage -- again, a key point in our paper -- but we firmly believe our results are robust and that our protocol did not unrealistically bias our conclusions in favor of any one optimizer over another	Reply	I-Reply	4

This paper presents a JavaScript framework including WebCL components for training and deploying deep neural networks.	Review	O	0
The authors show that it is possible to reach competitive speeds with this technology, even higher speed than a compiled application with ViennaCL on AMD GPUs.	Review	O	0
While remaining a little more than factor three slower than compiled high performance software on NVIDIA GPUs, it offers compelling possibilities for easily deployable training and application settings for deep learning.	Review	O	0
[line_break_token][line_break_token]My main points of criticism are:[line_break_token]1.	Review	O	0
In Tab.	Review	B-Review	1
4 different batch sizes are used.	Review	I-Review	1
Even if this is due to technical limits for the Javascript library, it would only be fair to use the smaller batch sizes for the other frameworks as well (on the GPUs probably in favor of the presented framework).	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
In Fig.	Review	B-Review	2
6, why not include more information in the graphs?	Review	I-Review	2
Especially, as stated in the question, why not include the node.js values?	Review	I-Review	2
While I do see the possible application with one server and many "low performance" clients, the setting of having a few dedicated high performance servers is quite likely.	Review	I-Review	2
Even if not, these are good values to compare with.	Review	I-Review	2
For the sake of consistency, please include in both subfigures Firefox, Chrome, node.js.	Review	I-Review	2
[line_break_token][line_break_token]Apart from these points, well-written, understandable and conclusive.	Review	O	0
Thank you for the review.	Reply	O	0
[line_break_token]In Table 4 (speed comparison between our system and Caffe using single computer), we measured the speed with same batch size for all software and updated the table.	Reply	B-Reply	1
[line_break_token]In Figure 6 (speed of distributed computing), we experimented with the situation in which node.js is the computing client as well as Firefox and updated the chart	Reply	I-Reply	2

This paper is about a self-supervised video representation with a multi-modal learning process that the authors then use for performance on a variety of tasks.	Review	O	0
The main contribution of the paper is a successful effort to incorporate BERT-like models into vision tasks.	Review	O	0
As is detailed in the related work, the field has been inching towards this but without as much success as this paper has.	Review	O	0
[line_break_token][line_break_token]My main criticism of the paper is that it feels like there is everything and a bag of chips happening; It's exceptionally hard to tease apart what is the main contribution to its success.	Review	B-Review	1
I mostly came away from the paper thinking that it was good to see an existence proof of successfully incorporating the result, but not having really understood anything more wrt why or how this works.	Review	I-Review	1
Other than it being a good idea to have a bigger model and more varied types of gradients, it's unclear what this model does that distinguishes it from other approaches.	Review	I-Review	1
[line_break_token][line_break_token]On a more specific critique level, why use COIN?	Review	I-Review	2
And why compare on a frame accuracy metric?	Review	I-Review	2
The comparison to Ding &amp; Xu seems a bit odd given that they don't assume access to annotations but rather to video transcripts.	Review	O	0
There are other datasets that you could make use of here that are more applicable, like Thumos14 or ActivityNet.	Review	B-Review	2
I understand that this is a small section, but arguably the paper would be stronger if more time was spent on the main result than on this sidebar.	Review	I-Review	2
[line_break_token][line_break_token]Overall, I'm giving it a weak accept because I do think that the community should be aware of this paper's result.	Review	O	0
hank you for your positive feedback!	Reply	O	0
[line_break_token][line_break_token]In the following we summarize our main contributions: [line_break_token]1.	Reply	O	0
CBT objective for self-supervised visual representation learning.	Reply	B-Reply	1
We study the impact of the CBT objective, which uses long temporal information as self-supervision, in Table 1.	Reply	I-Reply	1
We observe that CBT outperforms alternative training objectives based on local spatial (3DRotNet) and temporal (Shuffle&amp;Learn) objectives significantly, when they were pre-trained on the same Kinetics data with the same backbone ConvNet (Table 1 left).	Reply	O	0
Our CBT method also outperforms the state of the art (Table 1 right).	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
CBT and cross-modal objectives for temporal representation learning.	Reply	B-Reply	1
In Table 2 (left) and Table 4 (left) we compare our method with VideoBERT, which applies vector quantization on visual features.	Reply	I-Reply	1
We found CBT outperforms VideoBERT significantly.	Reply	I-Reply	1
In Table 3 (left), we observe that the cross-modal objective further improves the performance on action anticipation tasks.	Reply	I-Reply	1
[line_break_token][line_break_token]Choice of datasets:[line_break_token][line_break_token]The action segmentation accuracy metric, along with the baselines we compare with, were quoted from Table 3 of the COIN dataset paper.	Reply	O	0
We note that their fully-supervised baseline (Tang et al.	Reply	B-Reply	2
2019) performed worse than the weakly-supervised baseline (Ding &amp; Xu 2018).	Reply	O	0
We will make the supervision type clear in the final version.	Reply	B-Reply	2
[line_break_token]Besides the COIN dataset, we do provide ActivityNet evaluations in Table 2&amp;3, along with other benchmarks such as HMDB (Table 1), UCF (Table 1), Breakfast (Table 2&amp;3) and YouCook (Table 4).	Reply	O	0
This range of datasets helps us understand the performance of CBT in diverse visual domains.	Reply	B-Reply	2

# Summary[line_break_token][line_break_token]This submission proposes a method to combine the benefits of model-based RL and Imitation Learning (IL) for navigation tasks.	Review	O	0
The key idea is to i) learn a prior over trajectory distributions from a fixed dataset of demonstrations, and ii) use this learned dynamical model for path planning via probabilistic inference.	Review	O	0
Reaching target waypoints is done by maximizing the trajectory likelihood conditioned on the planning goal.	Review	O	0
The prior is learned using R2P2 on LIDAR features and past positions.	Review	O	0
Experiments using the CARLA driving simulator show that this method can outperform standard control, IL, and model-based RL baselines, while flexibly incorporating test-time goals and costs thanks to its probabilistic formulation.	Review	O	0
[line_break_token][line_break_token][line_break_token]# Strengths[line_break_token][line_break_token]The method is an elegant way to get the best of both worlds in RL and IL, leveraging the recent R2P2 work to estimate a powerful sequential model used for planning via probabilistic inference.	Review	O	0
The flexibility of the method in considering test-time cost maps and user-defined goals (e.g. to avoid potholes) is appealing, especially since it does not require on-policy data collection.	Review	O	0
[line_break_token][line_break_token]The proposed planning-as-inference method can in theory handle the multi-modality present in human demonstrations by using a probabilistic model of the observed behaviors as prior over undirected expert trajectories.	Review	O	0
[line_break_token][line_break_token]The approach seem to outperform both model-based and imitation learning baselines on a simplified version of the CARLA benchmark, including on interesting fine-grained metrics (e.g., comfort based).	Review	O	0
[line_break_token][line_break_token][line_break_token]# Weaknesses[line_break_token][line_break_token]The main weakness of this submission lies in its experimental evaluation, especially the absence of any dynamic objects in the tested environment ("static world CARLA", section 1).	Review	O	0
It is unclear how this approach would generalize beyond just staying on the road.	Review	B-Review	1
How would it handle traffic lights, pedestrians, other drivers, weather variations, and more complex driving tasks than waypoint following by traversing mostly free space?	Review	I-Review	1
How does the prior generalize to more complex behaviors (e.g, by using more contextual information \phi)?	Review	I-Review	1
How robust is the method to noise in the demonstrations, i.e. non-expert or suboptimal behavior?	Review	I-Review	1
It seems that estimating the generative prior on human behavior might suffer from the same issues as behavior cloning, e.g., the sample inefficiency due to the combinatorial explosion of causal factors explaining complex human behaviors.	Review	I-Review	1
It might be in fact even harder to estimate that generative model than use a direct discriminative approach (e.g., a modular pipeline), at the cost of reduced flexibility at test time of course.	Review	I-Review	1
The currently reported sample efficiency (7000 training samples) and near perfect success rate seem to suggest that this (non-standard) version of the CARLA benchmark is too simple (no weather variations, no dynamic obstacles).	Review	I-Review	1
Comparison to the state of the art (beyond the baselines implemented here) on the original CARLA benchmark seems needed (especially in the "Nav.	Review	I-Review	1
dynamic" task).	Review	I-Review	1
[line_break_token][line_break_token]The method is only described very succinctly in section 2.	Review	I-Review	2
I do not believe there are enough details (especially around the learning algorithm, hyper-parameters, and other important technical elements) for reproducibility at this stage.	Review	I-Review	2
Section 2.1 is also quite dense for people not familiar with the R2P2 paper.	Review	I-Review	2
As the main contribution of the paper is to leverage that model for planning and control, it would be great to maybe discuss a bit deeper.	Review	I-Review	2
Finally, the input modalities are not clear, especially for the baselines: the proposed method is using LIDAR and localization whereas the IL baseline seems to use vision (while the others just use the trajectory).	Review	I-Review	2
This makes the fairness of the comparison really unclear (LIDAR is a much stronger signal for just staying on the road).	Review	I-Review	2
[line_break_token][line_break_token]Minor remarks:[line_break_token]- Why use a proportional controller as a baseline instead of the standard PID one?	Review	O	0
[line_break_token]- Section 2.3 seems like it's missing the extension of equation 2 to the multi-goal case?	Review	O	0
[line_break_token]- Typos in section 3 ("trail-and-error"), section 4 ("autonmous", "knowledge to")[line_break_token][line_break_token][line_break_token]# Recommendation[line_break_token][line_break_token]Although the theoretical benefits of the method are well-motivated and clear (off-policy learning, probabilistic model, flexibility at test time), the experimental evaluation (custom simple CARLA test, unclear comparison to baselines) and lack of details impeding reproducibility seems to suggest that this submission needs a bit more work.	Review	O	0
First, adding more details as suggested above and clarifying the experimental protocol seem like a must, but can be easily addressed by an update to the text.	Review	O	0
Second, it would be ideal to evaluate the approach on the standard CARLA benchmark in order to compare fairly to the prior art.	Review	O	0
This is much more involved.	Review	O	0
[line_break_token][line_break_token]I personally like the approach, so although I think it is marginally below the acceptance threshold in its current form, I reserve my judgement for the time being and look forward to the authors' reply.	Review	O	0
[line_break_token][line_break_token][line_break_token]# Update[line_break_token][line_break_token]The submission has been drastically rewritten (the diff is massive) and I think it is in much better shape, answering some of my concerns around reproducibility and generalization.	Review	O	0
Furthermore, it reinforces the strengths of the approach (esp.	Review	O	0
around its flexibility).	Review	O	0
[line_break_token][line_break_token]I am willing to recommend acceptance, but I have some further questions (hence I have only updated my score to a 6 for now).	Review	O	0
They are mostly related to the comparison with IL (important to validate the claim in the paper that the proposed approach is quantitatively better than both existing IL and RL methods).	Review	O	0
See discussion below for details.	Review	O	0
Thank you for your helpful feedback.	Reply	O	0
[line_break_token][line_break_token]Q1: ‚ÄúUnclear how this approach would generalize beyond just staying on the road‚Äù[line_break_token]We agree that there are more sophisticated settings that could be used to test different generalization aspects of our method.	Reply	O	0
In theory, expert behaviors could be modelled in such settings by including the relevant information in the context, as noted by the reviewer.	Reply	B-Reply	1
However, we designed our original experiments to reduce the number of uncontrolled variables, in order to clearly isolate the benefits of our approach.	Reply	I-Reply	1
In order to test other generalization capabilities, we have since conducted additional experiments in several settings: obstacles in the road that were unseen in the demonstrations (i.e. simulated potholes), and noise in the waypoints provided to the controller, which could occur in a real-world setting due to noisy localization.	Reply	I-Reply	1
In the pothole experiment, we found that our model was able to navigate around simulated potholes by including them in the cost map, and compared it to our model that was not provided with a cost map of the potholes.	Reply	I-Reply	1
This navigation demands the model generalize its planning to situations not observed in the training data, specifically, when the car must partially enter the opposing lane in order to avoid the obstacle.	Reply	I-Reply	1
In the noisy waypoint experiment, we tested two different types of noise: high bias, low variance noise, and low bias, high variance noise.	Reply	I-Reply	1
In the high variance setting, ‚Äúdecoy‚Äù waypoints are added to the set of possible waypoints.	Reply	I-Reply	1
The decoys are obtained by significantly perturbing the original waypoints with Gaussian noise, sigma=8 meters.	Reply	I-Reply	1
Successful navigation in this setting required the model‚Äôs ability to score its plans by  likeliest under the estimated expert‚Äôs distribution of behavior.	Reply	I-Reply	1
In the high bias setting, all waypoints were provided on the wrong side of the road, which is modelled with a small amount of observation noise.	Reply	I-Reply	1
We found that these waypoints were still sufficient to communicate high-level navigation directions, and that the model usually produced plans on the correct side of the road (where all expert demonstrations occurred).	Reply	I-Reply	1
Please see the updated results for quantitative (Tables 2, 3) and qualitative comparisons (Figures 7, 8).	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: ‚ÄúComparison to the state of the art (beyond the baselines implemented here) seems needed‚Äù[line_break_token]A2: Our problem motivation is, instead, that of completely offline learning, but state-of-the-art CARLA results require trial-and-error based data collection online (Codevilla, et al.	Reply	O	0
2018).	Reply	B-Reply	1
Additionally, navigation performance isn‚Äôt the sole goal of our method; we also show that our model has flexibility to different test-time queries that require behavior not seen in the training data.	Reply	I-Reply	1
However, we have since implemented the ‚Äúbranched‚Äù architecture of Codevilla, et al.	Reply	I-Reply	1
2018, and trained it with the same inputs and data used to train our method.	Reply	I-Reply	1
 We found this approach to slightly outperform the original IL baseline we included in our paper, but underperform the MBRL comparison and our proposed method.	Reply	I-Reply	1
Please see the updated results for our quantitative comparison (Table 1).	Reply	I-Reply	1
[line_break_token][line_break_token]Q3: ‚ÄúThe method is only described very succinctly in section 2‚Äù[line_break_token]We have included many more details about the method and the implementation in our updated version.	Reply	O	0
Please see Section 2, and Section 2.2 in particular.	Reply	B-Reply	2
[line_break_token][line_break_token]Q4: ‚Äúthe input modalities are not clear, especially for the baselines‚Äù[line_break_token]The input modalities are identical for all methods: they all receive the same waypoints, and observe the same LIDAR and past trajectory.	Reply	O	0
We clarified this in the updated paper.	Reply	B-Reply	2
[line_break_token][line_break_token]Q5: ‚ÄúWhy use a proportional controller as a baseline instead of the standard PID one?	Reply	O	0
[line_break_token]We tested added I+D terms, replacing the P-controller with a PID controller, and found no significant change -- the PID controller fundamentally cannot handle faraway waypoints.	Reply	B-Reply	3
[line_break_token][line_break_token]Q6: ‚ÄúSection 2.3 seems like it's missing the extension of equation 2 to the multi-goal case?‚Äù[line_break_token]We have generalized the mathematical explanation, from which all of our inference procedures can be derived.	Reply	O	0
This includes the multigoal case, in Section 2.1 in the updated version.	Reply	B-Reply	4
Additionally, we‚Äôve included a qualitative demonstration of planning to sequential multi-goals (Figure 3).	Reply	I-Reply	4

This paper tries to improve exploration performed by alphazero in a game of tic-tac-toe using MCTS.	Review	O	0
The paper proposes to use master game tree (which is MCTS as well) to control the generation of episodes when solving a game using MCTS.	Review	O	0
[line_break_token]This is a clear case of less than half-baked paper.	Review	B-Review	1
The paper does not cite any previous research (no references) and is poorly written.	Review	I-Review	1
I believe this is sufficient ground for not recommending accept.	Review	I-Review	1
I would suggest the authors to re-submit when the paper is complete, maybe, start with related work and references.	Review	I-Review	1
hank you deeply for your reviewing my paper.	Reply	O	0
[line_break_token]I didn't know how to use .bib file, then I had no choice but to remove all references.	Reply	B-Reply	1
[line_break_token]I would like to improve my paper writing skills and to do more research on this topic	Reply	I-Reply	1

The paper proposes new bounds on the misclassification error.	Review	O	0
The bounds lead to training classifiers with an adaptive loss function, and the algorithm operates in successive steps: the parameters are trained by minimizing the log-loss weighted by the probability of the observed class as given by the parameters of the previous steps.	Review	O	0
The bound improves on standard log-likelihood when outliers/underfitting prevents the learning algorithm to properly optimize the true classification error.	Review	O	0
Experiments are performed to confirm the therotical intuition and motivation.	Review	O	0
They show different cases where the new algorithm leads to improved classification error because underfitting occurs when using standard log-loss, and other cases where the new bounds do not lead to any improvement because the log-loss is sufficient to fit the dataset.	Review	O	0
[line_break_token][line_break_token]The paper also discusses the relationship between the proposed idea and reinforcement learning, as well as with classifiers that have an "uncertain" label.	Review	O	0
[line_break_token][line_break_token]While the paper is easy to read and well-written overall, in a second read I found it difficult to fully understand because two problems are somewhat mixed together (here considering only binary classification for simplicity): [line_break_token](a) the optimization of the classification error of a *randomized* classifier, which predicts 1 with probability P(1|x, theta), and [line_break_token](b) the optimization of the deterministic classifier, which predicts sign(P(1|x, theta) - 0.5), in a way that is robust to outliers/underfitting.	Review	O	0
[line_break_token][line_break_token]The reason why I am confused is that "The standard approach to supervised classification", as is mentioned in the abstract, is to use deterministic classifiers at test time, and the log-loss (up to constants) is an upper bound on the classification error of the deterministic classifier.	Review	B-Review	3
However, the bounds discussed in the paper only concern the randomized classifier.	Review	I-Review	3
[line_break_token][line_break_token]=== question:[line_break_token]In the experiments, what kind of classifier is used?	Review	O	0
The randomized one (as would the sentence in the first page suggest "Assuming the class is chosen according to p(y|X, Œ∏)"), or the more standard deterministic classifier argmax_y P(y|x, theta) ?	Review	B-Review	4
[line_break_token][line_break_token]As far as I can see, there are two cases: either (i) the paper deals with learning randomized classifiers, in which case it should compare the performances with the deterministic counterparts that people use in practice, or (ii) the paper makes sense as soon as we accept that the optimization of criterion (a) is a good surrogate for (b).	Review	I-Review	5
In both cases,  I think the write-up should be made clearer (because in case (ii) the algorithm does not minimize an upper bound on the classification error, and in case (i) what is done does not correspond to what is usually done in binary classification).	Review	I-Review	5
[line_break_token][line_break_token]=== comments:[line_break_token]- The section "allowing uncertainty in the decision" may be improved by adding some references, e.g. Bartlett & Wegkamp (2008) "Classification with a Reject Option using a Hinge Loss" or Sayedi et al. (	Review	O	0
2010) "Trading off Mistakes and Don‚Äôt Know Predictions".	Review	B-Review	6
[line_break_token][line_break_token]- there seems to be a "-" sign missing in the P(1|x, theta) in L(theta, lambda) in Section 3.	Review	O	0
[line_break_token][line_break_token]- The idea presented in the paper is interesting and original.	Review	O	0
While I give a relatively low score for now, I am willing to increase this score if the clarifications are made.	Review	B-Review	8
[line_break_token][line_break_token]Final comments:[line_break_token]I think the paper is clear enough in its current form, even though there should still be improvement in the justification of why and to what extent the error of the randomized classifier is a good surrogate for the error of the true classifier.	Review	O	0
While the "smoothed" version of the 0/1 loss is an acceptable explanation in the standard classification setup, it is less clear in the section dealing with an additional "uncertain" label.	Review	B-Review	9
I increase my score from 5 to 6.	Review	O	0
Thank you for your review and comments.	Reply	O	0
I apologize if some parts were unclear and will modify the paper accordingly.	Reply	O	0
[line_break_token][line_break_token]- In the experiments, the deterministic classifier is used.	Reply	O	0
Interestingly, in the iterative scheme, the randomized classifier converges to the deterministic one, something which is not true in general.	Reply	O	0
[line_break_token][line_break_token]You are right that, in the deterministic case (the one studied), the algorithm does not minimize an upper bound on the classification error but rather an upper bound on a smooth version of that error (replacing the step function with a sigmoid).	Reply	B-Reply	1
I will make this clearer.	Reply	I-Reply	1
[line_break_token][line_break_token]I will also read your additional references and update the paper accordingly.	Reply	O	0
[line_break_token][line_break_token]I hope this clarifies any misunderstandings you might have had	Reply	O	0

Summary: [line_break_token]Training RNNs on long-sequences is a challenging task as gradients tend to explode or vanish.	Review	O	0
One way to mitigate this problem to some extent is to use semi-supervised learning in which objective function consists of unsupervised and supervised loss functions.	Review	O	0
Even though the contribution of unsupervised loss function can be controlled by a coefficient in the objective function, the unsupervised loss term can cause important information about the supervised task to be degraded or erased.	Review	O	0
This paper proposed a method to mitigate the problem of training of RNNs on long sequences by coordinating supervised and unsupervised loss functions.	Review	O	0
More specifically, they use two RNNs in which RNNs have a shared feature space for both supervised and unsupervised tasks and allow one of RNN to have a private space dedicated for the supervised task.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]+ The idea of dividing the hidden states into two parts is interesting as it helps the model to control the effect of unsupervised loss on main supervised task.	Review	O	0
[line_break_token]+ Shared and private spaces visualization are very informative.	Review	O	0
[line_break_token]+ This model shows better results on MNIST and CIFAR-10 in compared with previous methods.	Review	O	0
[line_break_token]Weaknesses:[line_break_token]- Paper writing is good until section 3.1.	Review	O	0
This section is very confusing.	Review	B-Review	1
I read it multiple times until understood what is happening.	Review	I-Review	1
Lots of details are missing in sections 3.2 about how this model forces to not mix up the gradients for shared and private hidden units.	Review	I-Review	1
[line_break_token]- There are quite similarities between Trinh et al.,	Review	O	0
2018 and this paper.	Review	B-Review	2
The only main difference is dividing the hidden state into shared and private ones.	Review	I-Review	2
[line_break_token]- Is there any reason why StanfordDogs and DBpedia are not used in this paper?	Review	O	0
Given the close relationship between Trinh et al.,	Review	B-Review	3
2018 and this paper, it would have been better to have some results for these sets.	Review	I-Review	3
[line_break_token]- The paper claims that their model trains and evaluates faster.	Review	O	0
Rather than an argument about fewer parameters for auxiliary tasks, I don't see any justification.	Review	B-Review	4
Fewer parameters don't necessarily lead to faster training or test time.	Review	I-Review	4
[line_break_token][line_break_token]Comments and Questions[line_break_token]- Is vanilla RNN used for the experiments?	Review	O	0
GRU is mentioned but my understanding is that it is only used for auxiliary loss.	Review	B-Review	5
[line_break_token]- There should be some detail about model architectures and training e.g. hidden units size, learning rate, dropout if any, etc.	Review	O	0
[line_break_token]- It mentions that the model uses different time-scale updating operations of distinct RNNs with different representational spaces, I don't see how.	Review	O	0
Can you elaborate?	Review	B-Review	7
[line_break_token]	Review	O	0
We thank the reviewer for taking the time to read our paper in detail, and for providing such extensive comments.	Reply	O	0
We respond to each of the reviewer‚Äôs points below:[line_break_token][line_break_token]> Is there any reason why StanfordDogs and DBpedia are not used in this paper?	Reply	O	0
Given the close relationship between Trinh et al.,	Reply	O	0
2018 and this paper, it would have been better to have some results for these sets.	Reply	O	0
[line_break_token][line_break_token]Due to some difficulties of preprocessing, we instead use IMDB dataset.	Reply	B-Reply	3
However, we test the baseline methods on the new dataset.	Reply	I-Reply	3
[line_break_token][line_break_token]> Is vanilla RNN used for the experiments?	Reply	O	0
GRU is mentioned but my understanding is that it is only used for auxiliary loss.	Reply	O	0
[line_break_token][line_break_token]We should have made it more clear: all RNNs used in experiments are GRUs.	Reply	B-Reply	5
[line_break_token][line_break_token]> There should be some detail about model architectures and training e.g. hidden units size, learning rate, dropout if any, etc.	Reply	O	0
[line_break_token][line_break_token]We will include them in the future version.	Reply	B-Reply	6

[line_break_token]In this paper, the authors proposed an interesting algorithm for learning the l1-SVM and the Fourier represented kernel together.	Review	O	0
The model extends kernel alignment with random feature dual representation and incorporates it into l1-SVM optimization problem.	Review	O	0
They proposed algorithms based on online learning in which the Langevin dynamics is utilized to handle the nonconvexity.	Review	O	0
Under some conditions about the quality of the solution to the nonconvex optimization, they provide the convergence and the sample complexity.	Review	O	0
Empirically, they show the performances are better than random feature and the LKRF.	Review	O	0
[line_break_token][line_break_token]I like the way they handle the nonconvexity component of the model.	Review	O	0
However, there are several issues need to be addressed.	Review	O	0
[line_break_token][line_break_token]1, In Eq. (	Review	O	0
6), although due to the convex-concave either min-max or max-min are equivalent, such claim should be explained explicitly.	Review	B-Review	1
[line_break_token][line_break_token]2, In the paper, there is an assumption about the peak of random feature "it is a natural assumption on realistic data that the largest peaks are close to the origin".	Review	O	0
I was wondering where this assumption is used?	Review	B-Review	2
Could you please provide more justification for such assumption?	Review	I-Review	2
[line_break_token][line_break_token]3, Although the proof of the algorithm relies on the online learning regret bound, the algorithm itself requires visit all the data in each update, and thus, it is not suitable for online learning.	Review	O	0
Please clarify this in the paper explicitly.	Review	B-Review	3
[line_break_token][line_break_token]4, The experiment is weak.	Review	O	0
The algorithm is closely related to boosting and MKL, while there is no such comparison.	Review	B-Review	4
Meanwhile, Since the proposed algorithm requires extra optimization w.r.t.	Review	I-Review	4
random feature, it is more convincing to include the empirical runtime comparison.	Review	I-Review	4
[line_break_token][line_break_token]Suggestion: it will be better if the author discusses some other model besides l1-SVM with such kernel learning.	Review	O	0
[line_break_token]	Review	O	0
[line_break_token]@1: We mention the minimax theorem in the proof, in the appendix.	Reply	O	0
We can add a brief clarification in the main paper.	Reply	B-Reply	1
[line_break_token][line_break_token]@2: The only assumption (for the theorems to hold) is that Algorithm 1 finds an eps-approximate global maximum.	Reply	O	0
Our discussion on band-limitedness of real-world data is simply to argue that this non-convex problem is plausibly easy on realistic optimization landscapes: low-frequency features (on the same scale as the RBF bandwidth parameter; see Appendix A.1) are informative.	Reply	B-Reply	2
[line_break_token][line_break_token]@3: That‚Äôs correct, just as in boosting.	Reply	O	0
We are happy to find a way to further emphasize the distinction, to reduce confusion.	Reply	B-Reply	3
[line_break_token][line_break_token]@4:[line_break_token]- As mentioned in the paper, MKL methods take >100 times longer on datasets as large as CIFAR-10.	Reply	O	0
[line_break_token]- Unlike the selling point of methods such as LKRF and Quasi-Monte Carlo, our method has much greater expressivity (thus evidently saturates at a much higher accuracy).	Reply	O	0
Hence, the value of a quantitative wall clock time comparison is unclear.	Reply	B-Reply	4
We believe that the existing discussion (primal like RF; parallelizable; reasonable wall clock time in practice) suffices to address qualitative questions on efficiency as compared to other paradigms.	Reply	I-Reply	4
[line_break_token]- Is there a specific boosting method the reviewer believes to be related enough, so as to require an end-to-end comparison?	Reply	O	0
We found that it‚Äôs unclear how to choose an ensemble in boosting for fair comparison with learning an optimal translation-invariant kernel (an infinite-dimensional continuous family).	Reply	B-Reply	4
As far as we know, though our theoretical analysis bears a strong relationship to boosting, the end-to-end methodology is somewhat dissimilar.	Reply	I-Reply	4
[line_break_token][line_break_token]@Suggestion: We agree that considering state-of-the-art settings and applications is an important and interesting direction (as we note in the conclusion).	Reply	O	0
As we mentioned in another review, any convex kernel machine admitting a dual could fit in our min-max formulation, while the min-max SVM objective captures the structure of learning a kernel for any such kernel machine.	Reply	B-Reply	5

This paper proposes a so called self-supervised method for learning from time series data in healthcare setting.	Review	O	0
Specifically, here self-supervision is achieved via designing auxiliary tasks based on data's internal structure to create more labeled auxiliary training tasks.	Review	O	0
[line_break_token][line_break_token]From both perspectives of methods and applications, the proposed model has very limited novelty.	Review	B-Review	1
It is just one application of multitask learning.	Review	I-Review	1
Also very similar idea has been implemented by [1]. In [1], the authors learn multi-level embedding to make disease/risk prediction, where the embedding was jointly trained by performing auxiliary prediction tasks that rely on this inherent EHR structure.	Review	I-Review	1
The authors need to state what is the novelty of the proposed method compared with [1].[line_break_token][line_break_token]In addition, the performance evaluation missed many baselines.	Review	O	0
Table 1 seems more like a ablation study rather than a performance comparison.	Review	B-Review	2
You need to compare with all state-of-the-art models in computational phenotyping in order to show the performance advantage brought by the proposed mode design.	Review	I-Review	2
[line_break_token][line_break_token][1] Edward Choi, Cao Xiao, Walter Stewart, Jimeng Sun, MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare,  NeuRIPS, 2018[line_break_token][line_break_token] 	Review	O	0
hank you for your thorough review.	Reply	O	0
[line_break_token][line_break_token]In response to your concerns:[line_break_token][line_break_token]- Novelty of the proposed method compared with [1]:[line_break_token]Limited self-supervision uses a multitask framework that, critically, requires no external labels to improve accuracy on a single task.	Reply	O	0
Most applications of multitask learning require additional ‚Äòexternal‚Äô labels, but our method is applicable even in situations where such labels aren‚Äôt available, hence its novelty.	Reply	B-Reply	1
[line_break_token][line_break_token]Although [1] also proposes a limited self-supervised framework, their method is applicable only in the EHR setting, since it requires additional labels from diagnosis and treatment codes.	Reply	I-Reply	1
Still, we agree this is related, and have updated Section 2 to include a discussion of it.	Reply	I-Reply	1
The relative novelty of our work is to examine limited self-supervision on general time-series tasks with a variety of different auxiliary tasks.	Reply	I-Reply	1
In particular, we examine the relative merits of different auxiliary tasks, propose a novel auxiliary task (PLAE), and show the importance of including multiple forms of auxiliary supervision.	Reply	I-Reply	1
[line_break_token][line_break_token]- Insufficient baselines:[line_break_token]Our main goal was not to obtain state-of-the-art results on computational phenotyping tasks, but to investigate the utility of a limited self-supervision framework to sequence classification.	Reply	O	0
To this end we compared to a fully supervised network (our baseline), and ran experiments investigating different types of auxiliary tasks.	Reply	B-Reply	2
In order to present this frameworks applicability to a broader array of datasets, we have added an analysis of 7 datasets from the UCR repository (see Section A3 in the supplement).	Reply	I-Reply	2
We showed that the addition of self-supervised auxiliary tasks offered sizable improvements over our baseline architecture on most datasets.	Reply	I-Reply	2
Although we achieved state-of-the-art level performance on only one dataset,  we find the consistent improvement in performance over the baseline indicates the general promise of this approach.	Reply	I-Reply	2
[line_break_token]	Reply	O	0

This paper proposes a method to impose linear inequality constraints on neural network activations.	Review	O	0
The method is implemented at initialization (by converting the H-representation to the V-representation) and during training (by modifying the network architecture).	Review	O	0
Experiments on two setups (projection and VAE+projection on a checkerboard pattern on MNIST) demonstrate a 2-orders of magnitude speed-up with respect to test-time projection (computed with OSQP).	Review	O	0
[line_break_token][line_break_token]The contributions claimed are:[line_break_token]* Novel technique to impose inequality constraints on neural network activations.	Review	O	0
[line_break_token]* Significant speed-up w.r.t.	Review	O	0
other techniques (at test time).	Review	O	0
[line_break_token][line_break_token]Overall, the approach is well motivated, and well-placed in the literature.	Review	O	0
However, the experimental analysis does not support all the claims made by the authors as it focuses on a single dataset (i.e., MNIST) and single constraint (i.e., checkerboard pattern).	Review	O	0
Additionally, while the authors argue that there is no manual trade-off between constraint satisfaction and data representation, the experiment in Fig.	Review	O	0
3 appears to show that there is some manual trade-off (using box delay).	Review	O	0
As such, I am currently inclined to give a "weak reject" score.	Review	O	0
[line_break_token][line_break_token]The method is clear and the idea of using softmax to get a convex combination of the vertices of the V-representation to guarantee constraint satisfaction is reasonable.	Review	O	0
[line_break_token][line_break_token]1) The softmax used to satisfy the constraints is preceded by a batch normalization layer.	Review	O	0
I would expect batch normalization to interfere with the ability to saturate the softmax activation and thus prevent the network from reaching optimality.	Review	B-Review	1
Could the authors provide experiments that justify the use of the batch normalization layer?	Review	I-Review	1
[line_break_token][line_break_token]2) An important factor that is unexplored in this manuscript is the softmax temperature.	Review	O	0
A good scheduling of that temperature could help the optimization.	Review	B-Review	2
Have authors tried different temperature values?	Review	I-Review	2
[line_break_token][line_break_token]3) The use of softmax and the integration of the constraints as a network layer seem to create some difficulty during training (even with the rather simple checkerboard pattern used in the experiment).	Review	O	0
The loss appears to reach some plateau (9% from optimal) and, thus, there appears to be some trade-off between reconstruction and projection.	Review	O	0
The authors should provide more experiments to explain that trade-off.	Review	B-Review	3
That trade-off is also visible on Fig.	Review	I-Review	3
5 (the zero has a significantly different shape).	Review	I-Review	3
[line_break_token][line_break_token]4) The method is solely compared to test time projection.	Review	O	0
Could the authors implement other techniques (if feasible)?	Review	B-Review	4
e.g., OptNet.	Review	I-Review	4
Overall, it would helpful to add more setups and different types of constraints (other than a last-layer projection; e.g., monotonicity).	Review	I-Review	4
e agree that generally speaking a comparison with more methods is desirable.	Reply	B-Reply	4
However, as pointed out in the paper, the methods mentioned in the related work section don‚Äôt scale well and hence a comparison with our method is futile.	Reply	I-Reply	4
Once the V-representation is computed prior to training, the subsequent training and inference phases have no significant overhead, whereas the other methods solve a sub-optimization problem at training time.	Reply	I-Reply	4
[line_break_token][line_break_token]While the softmax is indeed a sensible choice for general linear inequalities, the homogeneous case presented in this paper in fact does not use a softmax.	Reply	I-Reply	2
Since the feasible set for homogeneous linear inequalities is a polyhedral cone, all we need is a function that maps to positive values, which we can then use as conic combination parameters.	Reply	I-Reply	2
We use the absolute value function for that purpose.	Reply	I-Reply	2
[line_break_token][line_break_token]You are right about pointing out that there is an implicit trade-off between constraint satisfaction and data representation in the box delay experiments (Sec.	Reply	I-Reply	3
4.1).	Reply	I-Reply	3
We will remove the statement in a final version	Reply	I-Reply	3

***Score updated to weak accept after the rebuttal.***	Review	O	0
[line_break_token][line_break_token]Straight-Through is a popular, yet not theoretically well-understood, biased gradient estimator for Bernoulli random variables.	Review	O	0
The low variance of this estimator makes it a highly useful tool for training large-scale models with binary latents.	Review	O	0
However, the bias of this estimator may cause divergence in training, which is a significant practical issue.	Review	O	0
The paper develops a Fourier analysis of the Straight-Through estimator and provides an expression for the bias of the estimator in terms of the Fourier coefficients of the considered function.	Review	O	0
Motivated by this expression, the paper proposes two modifications of Straight-Through which may reduce the bias of the estimator, at the cost of the variance.	Review	O	0
The experimental results show advantage of this improved estimator over Gumbel-Softmax and DARN estimator.	Review	O	0
[line_break_token][line_break_token]While I really like the premise of the paper, I feel that it needs a significant amount of additional work.	Review	B-Review	9
The text is currently fairly hard to read.	Review	I-Review	9
The theoretical part of the paper does not quantify the variance of the estimator.	Review	I-Review	9
The experiments are a bit unfinished and do not include ablations of the proposed modifications of Straight-Through.	Review	I-Review	9
Most importantly, I think that in the current form the theoretical and the empirical parts of the papers are not well-connected.	Review	I-Review	9
Because of this, I believe that the paper should currently be rejected, but I encourage the authors to continue this line of work.	Review	I-Review	9
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
Theoretical analysis and empirical improvement of the Straight-Through estimator is an important avenue of work.	Review	O	0
[line_break_token]2.	Review	O	0
The paper makes a solid contribution of deriving the Fourier expansion of the Straight-Through estimator bias.	Review	O	0
[line_break_token]3.	Review	O	0
Based on this expansion, the paper proposes an algorithm with reduced bias.	Review	O	0
The algorithm is simple to implement, practical and appears to work slightly better than DARN.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
The key weakness of the theoretical part of the paper is that it focuses on the bias of the estimator, but does not quantify the variance, especially after the modifications.	Review	B-Review	1
If reducing the bias was the only goal, one could use unbiased (but high-variance) estimators such as REINFORCE or VIMCO.	Review	I-Review	1
[line_break_token]2.	Review	O	0
The final algorithm appears to be the DARN estimator combined with relaxation by uniform noise (‚ÄúBernoulli splitting uniform‚Äù) and scaling.	Review	B-Review	2
The paper does not have an ablation showing how the uniform noise and scaling perform on their own.	Review	I-Review	2
[line_break_token]3.	Review	O	0
There are a few incorrect statements that I‚Äôve noticed.	Review	B-Review	3
[line_break_token]* ‚ÄúAs a side contribution, we show that the gradient estimator employed with DARN (Gregor et al.,	Review	I-Review	3
2013), originally proposed for autoregressive models, is a strong baseline for gradient estimation.	Review	I-Review	3
‚Äù - MuProp paper compared to this estimator under the name 1/2-estimator[line_break_token]* In Lemma 1 the ‚ÄúREINFORCE gradient‚Äù is just the exact gradient of the expectation, not a stochastic REINFORCE gradient.	Review	O	0
[line_break_token]* ‚Äú To the best of our knowledge, FouST is the first gradient estimate algorithm that can train very deep stochastic neural networks with Boolean latent variables.	Review	O	0
‚Äù This paper uses up to 11 latent variable layers, while [1] has trained models with &gt;20 latent variable layers (although their ‚Äúlayers‚Äù have just one unit).	Review	O	0
[line_break_token]4.	Review	B-Review	6
The derivation of ‚ÄúBernoulli splitting uniform‚Äù trick is confusing and contains a lot of typos.	Review	I-Review	4
For instance, the text before eqn. (	Review	I-Review	4
14) implies that the distribution of u_i is U[-1, 1], which cannot be right and does not correspond to Algorithm 1.	Review	I-Review	4
The statement that this trick does not lead to a relaxation is odd, since the function is being evaluated at non-discrete points.	Review	I-Review	4
[line_break_token]5.	Review	O	0
There are generally many typos and some poor formatting in the math.	Review	B-Review	5
For example, in eqn. (	Review	I-Review	5
6) the coefficients are off by one: it should be c0 + c1 z1 + c2 z2^2 + ‚Ä¶ .	Review	I-Review	5
The equations (10) and (11) are poorly formatted.	Review	I-Review	5
The notation \partial_z1 f(u_1, u_2) in eqn. (	Review	I-Review	5
14) is strange.	Review	I-Review	5
In many places p^{i-&gt;¬Ω} is denoted as p^{1-&gt;¬Ω}.[line_break_token]5.	Review	O	0
I don‚Äôt think I understood the idea of representation scaling (Section 4.4).	Review	B-Review	6
The eqn. (	Review	I-Review	6
16) would suggest that the scaling should optimally be set to zero, which is just saying that the gradient is unbiased when the model does not use the latents.	Review	I-Review	6
There is no other practical guidance on choosing this coefficient.	Review	I-Review	6
Furthermore, one can always absorb the global scaling factor into the succeeding weights layer of the model, so this trick can probably be replaced by a modification of the weights initialization.	Review	I-Review	6
[line_break_token]6.	Review	O	0
The experiments are missing a comparison to the Straight-Through Gumbel-Softmax estimator, introduced in the original Gumbel-Softmax paper.	Review	B-Review	7
This is a popular biased estimator for Bernoulli latents, e.g. used in [1] [2]. Another interesting comparison would be [3] which proposes a lower-bias version of Gumbel-Softmax.	Review	I-Review	7
[line_break_token]7.	Review	O	0
Figure 2 is missing the line for REBAR, even though this line is referred to on Page 8.	Review	B-Review	8
Figure 2 and Figure 4 are both labeled as training ELBOs, despite the plots being different.	Review	I-Review	8
[line_break_token][line_break_token][1] Andreas Veit, Serge Belongie ‚ÄúConvolutional Networks with Adaptive Inference Graphs‚Äù ECCV 2018[line_break_token][2] Patrick Chen, Si Si, Sanjiv Kumar, Yang Li, Cho-Jui Hsieh ‚ÄúLearning to Screen for Fast Softmax Inference on Large Vocabulary Neural Networks‚Äù ICLR 2019 <a href="https://openreview.net/forum?id=ByeMB3Act7" target="_blank" rel="nofollow">https://openreview.net/forum?id=ByeMB3Act7</a>[line_break_token][3] Evgeny Andriyash, Arash Vahdat, Bill Macready ‚ÄúImproved Gradient-Based Optimization Over Discrete Distributions‚Äù <a href="https://arxiv.org/abs/1810.00116" target="_blank" rel="nofollow">https://arxiv.org/abs/1810.00116</a>	Review	O	0
 would like to thank the authors for their detailed reply to my review.	Reply	O	0
The paper can certainly be improved, but, with the added ablations and clarifications, I feel that it would find its audience at ICLR.	Reply	O	0
Hence, I am increasing my score to weak accept.	Reply	O	0
However, I encourage the authors to work more on the text to increase the paper's impact.	Reply	O	0
[line_break_token][line_break_token]Comments on the response:[line_break_token][line_break_token]&gt; As opposed to classical high-variance estimators such as REINFORCE, (high) variance is not essential to our estimator.	Reply	O	0
[line_break_token][line_break_token]This claim is false in general.	Reply	B-Reply	1
One can easily construct a function for which the REINFORCE gradient will have exactly zero variance, while the estimator you propose will have a non-zero variance.	Reply	I-Reply	1
Consider univariate case and set f(z) = 1 / g_REINFORCE(z).	Reply	I-Reply	1
Hence, you either have to prove that the method has lower variance, or demonstrate that the variance is empirically lower in the experiments.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; uniform sampling is the only extra source of variance[line_break_token][line_break_token]This is also not true in general, as importance sampling can also increase the variance of the estimator if the proposal distribution is not optimal.	Reply	O	0
[line_break_token][line_break_token]&gt; This is a valid concern and we have added ablation experiments to the paper (see appendix D.2, page 14).	Reply	O	0
[line_break_token][line_break_token]Thank you, this ablation is very informative!	Reply	B-Reply	2
[line_break_token][line_break_token]&gt; DARN estimator[line_break_token]&gt; ‚ÄúFouST is the first gradient estimate algorithm that can train very deep stochastic neural networks with Boolean latent variables‚Äù[line_break_token][line_break_token]I agree with the revised/toned down version of your statements.	Reply	O	0
[line_break_token][line_break_token]&gt; The statement that this does not lead to a relaxation (of the sort in Gumbel-Softmax) refers to the fact that we still have a hard binary decision.	Reply	O	0
[line_break_token][line_break_token]I still disagree: your method is clearly a relaxation since it evaluates the function at non-discrete points.	Reply	B-Reply	4
What you are saying is that one can recover the hard sample from the relaxed sample.	Reply	I-Reply	4
It is a good property, yet the networks can certainly exploit the extra noise injected by your method.	Reply	I-Reply	4
This is especially misleading because you state in the introduction that ‚ÄúWe resort to the term Boolean instead of binary to emphasize that we work directly on the Boolean space {‚àí1, +1}, without any continuous relaxations or quantizations.	Reply	I-Reply	4
‚Äù[line_break_token][line_break_token]Related question to the authors: do you compute the ELBO in Table 1 and Figures 2-3 with Boolean samples?	Reply	I-Reply	4
It is possible that the models are exploiting the extra Uniform noise.	Reply	I-Reply	4
[line_break_token][line_break_token]&gt;      a. There is no typo in equation 6.	Reply	O	0
It gives the expression for the Fourier coefficient in terms of the Taylor coefficients rather than the Taylor expansion of f.[line_break_token]&gt;      d. The p^{1-&gt;¬Ω} is used in section 4.3 in the illustration of a bivariate function.	Reply	O	0
Here we take the gradient relative to the first variable and i is 1.	Reply	O	0
[line_break_token][line_break_token]Agreed, there are indeed no typos there.	Reply	B-Reply	5
Thanks for the clarification.	Reply	I-Reply	5
[line_break_token]  [line_break_token]&gt; we have added comparisons to Straight-Through Gumbel in the updated paper (see figure 2 on page 8).	Reply	O	0
Our results support the ones from the original paper that Gumbel-Straight Through performs worse in terms of the optimization objective than Gumbel Soft-max.	Reply	B-Reply	7
[line_break_token]&gt; REBAR[line_break_token][line_break_token]Thank you for adding this comparison and the clarifications	Reply	O	0

The authors present a quantum algorithm for approximating the forward pass and gradient computation of a classical convolutional neural network layer with pooling and a bounded rectifier activation.	Review	O	0
This algorithm has complexity bounds that would open up (for instance) the possibility of exponentially large filter banks, and the authors show through a simple, classical simulation approach that the resulting network is also likely to be trainable.	Review	O	0
[line_break_token][line_break_token]Feedback:[line_break_token][line_break_token]A few typos/formatting issues:[line_break_token]- The title accidentally includes "Conference Submissions"[line_break_token]- The in-text citation format frequently has the parentheses in the wrong place; this is surprisingly distracting!	Review	O	0
[line_break_token][line_break_token]Preliminaries:[line_break_token]- Maybe explain what the ith vector in the standard basis is in terms of |0&gt; and |1&gt;?	Review	O	0
I assume the answer is along the lines of |000&gt;, |001&gt;, |010&gt;, etc.?	Review	O	0
[line_break_token][line_break_token]Main results:[line_break_token]- The sentence "a speedup compared to the classical CNN for both the forward pass and for training using backpropagation in certain cases" is ambiguous; does "in certain cases" qualify only training speed or also forward pass speed?	Review	O	0
[line_break_token][line_break_token]- There's a clear separation of background (which is concise and well explained) and contributions, but maybe it would be worth connecting the introduced algorithm more closely to existing work in non-convolutional quantum neural networks?	Review	O	0
[line_break_token][line_break_token]- Can you briefly justify (or cite) the claim that "most of the non linear functions in the machine learning literature can be implemented using small sized boolean circuits"?	Review	O	0
[line_break_token][line_break_token]- I'm a little confused about the discussion of quantum importance sampling on page 4.	Review	O	0
Could you give some intuition for the relationship between eta and the fraction of output values that are on average flushed to zero (is this 1 minus sigma?),	Review	B-Review	3
and perhaps connect this to the literature about activation pruning and sparse NNs?	Review	I-Review	3
[line_break_token][line_break_token]- Maybe define what you mean by "tomography" for ML folks without the quantum background?	Review	O	0
[line_break_token][line_break_token]- I'm convinced by the simulations, even though I shouldn't really be convinced by anything on MNIST... It just seems like the perturbations you're applying are all things that modern neural networks take in stride.	Review	O	0
[line_break_token][line_break_token]- The discussion of using a sigma-based classical sampling rather than the eta-based quantum importance sampling mentions a "Section C.1.15" which does not exist (I think you mean the end of Section C.1.5).	Review	O	0
[line_break_token][line_break_token]- Re: "We will use this analogy in the numerical simulations (Section 6) to estimate, for a particular QCNN architecture and a particular dataset of images, which values of œÉ are enough to allow the neural network to learn."	Review	O	0
My understanding is that you're getting empirical estimates of which values of sigma are enough; it would be valuable to convert those to estimates of which values of eta would be enough (given quantum networks of the size used in the classical simulation experiment, or given larger networks).	Review	B-Review	11
[line_break_token][line_break_token]- The sampling procedure based on sigma might be inefficient in your PyTorch implementation, but it's certainly something that GPUs are fairly well suited to computing.	Review	O	0
There might be other PyTorch operators that would help here (perhaps Bernoulli sampling?)	Review	B-Review	2
or if nothing else you could write a small custom CUDA kernel.	Review	I-Review	2
e thank the reviewer for the appreciation of the paper and insightful comments.	Reply	O	0
[line_break_token][line_break_token]- The reviewer is right concerning the meaning of the quantum state being the vector in the standard basis.	Reply	O	0
If accepted, we will make the effort of introducing basic concepts of quantum computing to allow a clearer understanding of our work to the audience.	Reply	B-Reply	8
As well, we will introduce more intuitively the concept of quantum tomography, namely the family of procedures that allow to retrieve a classical description of a quantum state by repeated measurements (and infer the values of the quantum amplitudes from the resulting distribution).	Reply	I-Reply	9
[line_break_token][line_break_token]- Our work in quantum deep learning is indeed related to previous works in quantum neural network cited in our paper, in particular the fully connected quantum neural network of Allcock et al. (	Reply	O	0
2018).	Reply	B-Reply	7
Their layer method is similar to ours and indeed could be explained in the appendix.	Reply	I-Reply	7
 [line_break_token][line_break_token]- The speedup ¬´&nbsp;in certain cases&nbsp;¬ª concerns indeed both the forward pass and the whole training.	Reply	O	0
We will change this sentence and be more explicit.	Reply	B-Reply	6
[line_break_token][line_break_token]- Applying a non linearity (as ReLu activation function) in a quantum circuit is a difficult challenge.	Reply	O	0
In our solution, once the value is encoded as a bit string in a quantum register, we can apply a non linearity on it.	Reply	B-Reply	5
The circuit that modifies the value accordingly depends on the non linearity considered.	Reply	I-Reply	5
For ReLu or other positive simple rules (piecewise linear functions, indicator functions), one could imagine a simple circuit involving few gates to act on the bit strings.	Reply	I-Reply	5
Most importantly, the size of such circuits will have a constant depth that doesn‚Äôt depend on the algorithm parameters.	Reply	I-Reply	5
In our sentence, ¬´&nbsp;boolean&nbsp;¬ª refers to a classical and explicit series of gates.	Reply	O	0
Note however that implementing more complex non linearities such as tanh could imply a taylor decomposition of the function in order to approximate it with a small number of gates.	Reply	B-Reply	5
This explains our choice of the ReLu function.	Reply	I-Reply	5
[line_break_token][line_break_token]- Our ¬´&nbsp;quantum importance sampling&nbsp;¬ª can be parametrized in two manners: that relates to the precision of the tomography, or that corresponds to the ratio of elements sampled (the others being set to zero).	Reply	O	0
The relation between the two approaches is given in Appendix, Section C.1.5, namely we have where is the size of the output image.	Reply	B-Reply	4
We agree that the explanations could be clearer and we will make the effort to present it better.	Reply	I-Reply	4
In our opinion, the Sigma perspective is more intuitive when considering image processing (as shown in Figure 1), and more explainable than Eta which implicitly depends on the size.	Reply	I-Reply	4
[line_break_token][line_break_token]- This particular sampling described above is purely a quantum effect and has no known classical usage or reason to be.	Reply	O	0
In a way, it can be seen to a non deterministic activation function.	Reply	B-Reply	4
It is reducing the number of non zero values in the layers themselves, and not (directly) in the weights of the kernels.	Reply	I-Reply	4
Therefore it might, or not, be related to pruning, drop out or sparse NN.	Reply	I-Reply	4
We appreciate this comment and will research on that analogy.	Reply	I-Reply	4
[line_break_token][line_break_token]- We thank the reviewer for the advice concerning the PyTorch implementation.	Reply	O	0
We will certainly use this to perform further simulations on different and larger datasets.	Reply	B-Reply	2
This could help us save a lot of time.	Reply	I-Reply	2
[line_break_token][line_break_token]- All remarks concerning typos and formatting will be taken into account in the final version.	Reply	O	0

The paper presents some new approaches for communication efficient Federated Learning (FL) that allows for training of large models on heterogeneous edge devices.	Review	O	0
In FL, heterogeneous edge devices have access to potentially non-iid samples of data points and try to jointly learn a model by averaging their local models at a parameter server (the cloud).	Review	O	0
As the bandwidth of the up/downlink-link may be limited communication overheads may become the bottleneck during FL.	Review	O	0
Moreover, due to the heterogeneity of the hardware, large models may be hard to train on small devices.	Review	O	0
Due to that, there are several recent approaches that aim to minimize communication via methods of quantization, which also aim to allow for smaller models via methods of compression and model quantization.	Review	O	0
[line_break_token][line_break_token]In this paper, the authors suggest a combination of two methods to reduce communication and allow for large model training by 1) using a lossy compressed model when that is communicated from the cloud to the edge devices, and 2) subsampling the gradients, a form of dropout, at the edge device side that allows for an overall smaller model update.	Review	O	0
The novelty of either of those techniques is quite limited as individually they have been suggested before, but the combination of both of them is interesting.	Review	O	0
[line_break_token][line_break_token]The paper is overall well written, however there are two aspects that make the contribution lacking in novelty.	Review	B-Review	1
First of all, the presented methods are a combination of existing techniques, that although interesting to combine together, are neither theoretically analyzed nor extensively tested.	Review	I-Review	1
The model/update quantization technique has been used in the past extensively [eg 1-3]. Then, the ‚Äúfederated dropout‚Äù can be seen as a ‚Äúcoordinate descent‚Äù type of a technique, i.e., randomly zeroing out gradient elements per iteration.	Review	I-Review	1
[line_break_token][line_break_token]Since this is a more experimental paper, the setup tested is quite limited in its comparisons.	Review	I-Review	2
For example, one would expect to see extensive comparisons with methods for quantizing gradients, eg QSGD, or Terngrad, and combinations of that with DeepCompression.	Review	I-Review	2
Although the authors do make an effort to experiment with a different set of hyperparameters (dropout probability, quantization levels, etc), a comparison with state of the art methods is lacking.	Review	I-Review	2
[line_break_token][line_break_token]Overall, although the combination of the presented ideas has some merit, the lack of extensive experiments that would compare it with the state of the art is not convincing, and the overall effectiveness of this method is unclear at this point.	Review	I-Review	3
[line_break_token][line_break_token][1] <a href="https://arxiv.org/pdf/1510.00149.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1510.00149.pdf</a>[line_break_token][2] <a href="https://arxiv.org/pdf/1803.03383.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1803.03383.pdf</a>[line_break_token][4] <a href="https://arxiv.org/pdf/1610.05492.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1610.05492.pdf</a>	Review	O	0
We thank the reviewer for their thorough review and for highlighting that the paper is well written.	Reply	O	0
However, we think the review does not fully recognize the challenges of FL, and consequently misunderstands the nature (and therefore novelty) of our techniques.	Reply	O	0
Please see a detailed explanation below.	Reply	O	0
[line_break_token][line_break_token]The first point we want to address is the (reported lack of) novelty of the following two contributions:[line_break_token]1) The lossy compression of the model sent from server to clients (the review points to other related works).	Reply	B-Reply	1
[line_break_token]2) Federated Dropout, which the review mentions can be seen as a ‚Äú‚Äòcoordinate descent‚Äô type of a technique‚Äù.	Reply	I-Reply	1
[line_break_token][line_break_token]Let us address the two in turn:[line_break_token]1) We are not aware of previous work (and please correct us if we have missed something) that compresses the *state of a model* being trained when such compression has to be done repeatedly throughout the iterative training procedure and in a data-independent fashion.	Reply	O	0
Techniques such as DeepCompression modify the whole training procedure, are data dependent, and produce one final compact model (i.e. compression is performed once).	Reply	B-Reply	1
As such, not only do they become infeasible in the setting of FL (no data is available on the server), but they are not directly comparable with our method.	Reply	I-Reply	1
Note that we do call this out in the last paragraph of Section 2 in the original submission, and highlight it could be *compatible* with the overall objective of FL.	Reply	I-Reply	1
A proper exploration of such an idea, however, would likely deserve a complete paper.	Reply	I-Reply	1
[line_break_token]Furthermore, the idea of using Kashin‚Äôs representation can be of independent interest.	Reply	I-Reply	1
We are not aware of any example of this idea being practically used in Machine Learning and, in the Appendix, we show its relationship to some recent theoretical results.	Reply	I-Reply	1
[line_break_token][line_break_token]2) Claiming that Federated Dropout can be seen as coordinate descent, or that it can be reduced to subsampling gradients, is incorrect.	Reply	O	0
In each client, we are not computing partial derivatives of the global model, but the full gradients of a smaller, and different, model.	Reply	B-Reply	1
Furthermore, several SGD steps are taken for each local model.	Reply	I-Reply	1
The facts that (a) by design of the procedure, we can then map these updates to the larger global model, and that (b) performing training this way leads to savings both in communication and local computation, are our key insights.	Reply	I-Reply	1
We are not aware of this conceptual idea being addressed in previous literature.	Reply	I-Reply	1
Finally, we do (optionally) use subsampling to further compress the final learned updates (together with basis transform and quantization), but this is complementary to (and not equivalent to) Federated Dropout.	Reply	I-Reply	1
[line_break_token][line_break_token]In summary, we believe that not only is the combination of our techniques interesting (as the reviewer points out), but that each individual technique does indeed bring novel ideas that address challenges where there is no state of the art at all.	Reply	I-Reply	1

The paper introduces a model trained for video prediction hierarchically: a series of significant frames called ‚Äúkeyframes‚Äù in the paper are first predicted and then intermediate frames between keyframes couples are generated.	Review	O	0
The training criterion is maximum likelihood with a variational approximation.	Review	O	0
Experiments are performed on 3 different video datasets and the evaluation is performed for 3 tasks: keyframe detection, frame prediction and planning in robot videos.	Review	O	0
[line_break_token]The idea of generating an abstraction or a summary of a video via a sequence of important frames is attractive and could probably be used in different contexts.	Review	O	0
The proposed model is new and the authors introduce some clever ideas in order to train it.	Review	O	0
The evaluation work is important and the authors propose different settings for this evaluation.	Review	O	0
[line_break_token]The paper also present weaknesses.	Review	O	0
First the motivation for keyframes generation should be better developed: the model does not perform better than baselines for video frames prediction so that keyframes generation should be motivated by other applications.	Review	B-Review	1
Planning as proposed by the authors could be one, but in this case it should be more developed.	Review	I-Review	1
The main weakness is however the technical presentation which is painful to follow.	Review	I-Review	2
When it is possible to get a general picture of what is done, it is quite difficult to figure out exactly how the model works.	Review	I-Review	2
A global rewriting and maybe a better focus are required for publication.	Review	I-Review	2
The probabilistic model (section 3.1) is relatively clear, even if it could be improved.	Review	I-Review	2
It seems that the generation of a keyframe and the prediction of the corresponding time (tau^n)  are independent (eq.	Review	I-Review	2
3).	Review	I-Review	2
This could be commented.	Review	I-Review	2
Also it seems that in eq.	Review	I-Review	2
3 the log(K|z..) term should be inside an expectation.	Review	I-Review	2
Section 4 was difficult to decipher for me.	Review	I-Review	2
My understanding is that instead of sampling from a multinomial during training, you bypass this non differentiable operation by using what you call ‚Äúsoft targets‚Äù thus obtaining a differentiable objective (eq.	Review	I-Review	2
4).	Review	I-Review	2
Is that true?	Review	I-Review	2
In any case, the procedure should be made a lot clearer.	Review	I-Review	2
The ‚Äúintermediate frame‚Äù passage also remained confuse for me.	Review	I-Review	2
[line_break_token]Considering the experiments, the authors make an important effort in order to evaluate different aspects of their model.	Review	I-Review	3
In a fisrt step, they evaluate the ability of the model to generate significant keyframes using a detection setting.	Review	I-Review	3
 It is not clear how they define ground truth frames for this evaluation.	Review	I-Review	3
Those ground truth frames are defined as the frames where the movement in the image changes, which is easy on the Brownian movement dataset but what about the others?	Review	I-Review	3
Also the baselines used in this comparison are weak.	Review	I-Review	3
In the paper of Denton, they suggest some way to detect surprise and apparently this is not what you used.	Review	I-Review	3
This should be justified/ commented.	Review	O	0
For keyframe modeling the proposed model behaves similarly to the baselines and even performs worse than the simpler ‚Äújumpy‚Äù model.	Review	B-Review	4
Concerni g the paragraph about the selection of the number of predicted keyframes, it is not clear what is the reference (ground truth) number of target keyframes.	Review	I-Review	4
[line_break_token] The planning experiments are interesting, but difficult to follow at least from the main text.	Review	O	0
[line_break_token]Overall, I think that there are several interesting ideas and realizations.	Review	O	0
They should be better put in perspective and explained.	Review	O	0
[line_break_token][line_break_token]----- post rebuttal -----------[line_break_token][line_break_token]Thanks for the detailed answer.	Review	O	0
The paper is largely improved both for the style and the comparisons.	Review	O	0
But still requires further improvements.	Review	O	0
I will keep my score.	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for the helpful comments and suggestions.	Reply	O	0
We have made several changes to the presentation of the technical section as well as the description of the experiments and results to address the reviewer's concerns (updates in red).	Reply	O	0
We have also added comparisons to alternative ‚Äúsurprise‚Äù baselines as well as experiments on keyframe modeling.	Reply	O	0
We hope the responses below address the reviewer‚Äôs concerns and we are happy to make additional changes if those are required.	Reply	O	0
[line_break_token][line_break_token]== Motivation should be better developed ==[line_break_token]We thank the reviewer for pointing out a possible confusion about the motivation of the paper.	Reply	O	0
We tried to highlight in the original submission that the goal of this work is not to improve video prediction quality but instead to discover meaningful temporal structure in sequences.	Reply	B-Reply	1
As the reviewer notes, one possible application for the temporal structure discovered by our model is predicting subgoals for efficient long-horizon planning, and we now expanded the introduction to discuss this.	Reply	I-Reply	1
We note that planning is known to be a challenging task [1-4] and we show that our model is able to outperform strong baselines using the learned temporal abstraction.	Reply	I-Reply	1
[line_break_token][line_break_token]== Keyframe detection baseline weak, use Denton&amp;Fergus‚Äô18 ==[line_break_token] We thank the reviewer for proposing this alternative comparison.	Reply	O	0
In the original submission we used a measure of surprise based on the KL divergence (see Sec.	Reply	B-Reply	3
6.3, details in appendix, Sec.	Reply	I-Reply	3
F).	Reply	I-Reply	3
To support the strength of this baseline we have now added two baseline evaluations using alternative definitions of surprise.	Reply	I-Reply	3
The first uses the method of Denton&amp;Fergus‚Äô18 that the reviewer proposed.	Reply	O	0
The second uses the lower bound on the log-likelihood -log(p) instead of just the KL divergence to measure surprise.	Reply	B-Reply	3
In Tab 3,4, we find that the KL-based baseline reported in the submission consistently performs on par with these alternative formulations, and that our method outperforms all baselines.	Reply	I-Reply	3
[line_break_token][line_break_token]== No performance gain on keyframe modeling ==[line_break_token]We understand that the reviewer is referring to the results evaluating image sequence prediction quality (as opposed to keyframe prediction quality).	Reply	O	0
It is true that our method does not improve performance on video modeling, but we emphasize that it is able to perform on par with recent work (Denton&amp;Fergus‚Äô18) while additionally discovering the keyframe structure of the sequence.	Reply	O	0
Please refer to our answer to the first question about motivation.	Reply	B-Reply	4
We additionally performed an experiment showing that our model‚Äôs ability to model keyframes (i.e. the most important frames) is superior to the baseline methods that do not discover temporal structure in Tab.	Reply	I-Reply	4
6.	Reply	I-Reply	3
We further clarified the emphasis of the paper with an additional sentence in Sec 6.2.	Reply	I-Reply	4
[line_break_token][line_break_token]== Soft targets for obtaining differentiable objective?	Reply	O	0
==[line_break_token] This interpretation is correct: we introduce the relaxed formulation to bypass the sampling step from p(tau|z,I_co) and make the formulation fully differentiable.	Reply	O	0
The original submission stated this in Sec.	Reply	B-Reply	2
4.	Reply	I-Reply	2
We thank the reviewer for pointing out the need for further clarifications.	Reply	I-Reply	2
We restructured Sec.	Reply	I-Reply	2
4 to more clearly motivate and derive the soft relaxation objective.	Reply	I-Reply	2
We additionally improved Fig.	Reply	I-Reply	2
3 to better illustrate the procedure.	Reply	I-Reply	2
[line_break_token][line_break_token]	Reply	O	0

The authors formulate the credit assignment method as minimizing the divergence between policy function and a learned prior distribution.	Review	O	0
Then they apply f-divergence optimization to avoid the model collapse in this framework.	Review	O	0
Empirical experiments are conducted on the program synthesis benchmark with sparse rewards.	Review	O	0
[line_break_token][line_break_token]The main contribution of this paper is applying f-divergence optimization on the program synthesis task for credit assignment.	Review	O	0
[line_break_token][line_break_token]+ One of my concerns is that the experiment section is in a limited domain to argue it is a broad algorithm for credit assignment.	Review	O	0
The paper will be stronger if the comparison is applied in a distant domain like goal-based robot learning etc.	Review	B-Review	1
With some experiments on a different domain, the paper will be more convincing.	Review	I-Review	1
[line_break_token][line_break_token]+ The improvement/margin in program synthesis task needed to be explained well, is the margin significant enough?	Review	O	0
 [line_break_token][line_break_token]+ The paper could discuss more on related papers on program synthesis in the related work section as the main experiment is in this work.	Review	O	0
[line_break_token][line_break_token]+ The authors claim that the two-buffer estimation is better and lead to better gradient estimation, but it is not demonstrated empirically or theoretically.	Review	O	0
It could be better if the ablation study is conducted in the experiment.	Review	B-Review	4
Or the author could provide a theoretical analysis of why equation (13) is better.	Review	I-Review	4
Moreover, the investigation of different choices of and is necessary.	Review	I-Review	4
 [line_break_token][line_break_token]+ Another study needed is the investigation of different divergences; the work will be stronger if a KL divergence version is compared.	Review	O	0
Otherwise, it is not clear how much the f-divergence will contribute to the performance.	Review	B-Review	5
[line_break_token]	Review	O	0
hank you for your time and detailed feedback.	Reply	O	0
[line_break_token]We are glad to hear you found this work interesting and valuable, and understand your concerns.	Reply	O	0
We are confident that, following the points of clarification highlighted by you, we can resolve any ambiguities in the paper, and thank you for helping make the paper stronger as a result.	Reply	O	0
[line_break_token]We answer most of the said pints below.	Reply	O	0
It would be very helpful to hear your thoughts on our responses so that we can make the appropriate modifications to the paper.	Reply	O	0
[line_break_token]We hope that you will be willing to consider revising your assessment in light of the clarifications.	Reply	O	0
[line_break_token][line_break_token][line_break_token]1.	Reply	O	0
Evaluation of the proposed method on other domains[line_break_token][line_break_token]      We would like to point out GACA can be useful in other challenging tasks such as combinational optimization and structured prediction where credit assignment from binary feedback remains a major challenge.	Reply	O	0
We want emphasize that one of the main purposes of this paper is to introduce the method of guided adaptive credit assignment.	Reply	B-Reply	1
As such, the purpose of this paper is not to beat every single benchmark but to show the benefit of this framework.	Reply	I-Reply	1
In particular, we demonstrate the effectiveness of GACA on two challenging program synthesis benchmarks, to our best knowledge, this work is the current state-of-the-art method that uses only binary supervision and outperforms previous methods by a large margin.	Reply	I-Reply	1
We leave the investigation of our method on other domains for future work.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
Results explanation/significance[line_break_token][line_break_token][line_break_token]    GACA outperforms recent state-of-the-art methods MeRL, BoRL, and MAPO by a large margin, on a variety of tasks‚Äîincluding the challenging WikiSQL and WikiTable,  as shown in Table 1, 2, 3.	Reply	O	0
To our best knowledge, GACA is by far the state-of-the-art method on these benchmarks using only binary feedback.	Reply	B-Reply	2
GACA is easy to implement and is a generalization of various credit assignment methods(MAPO MML, EML, RAML, and REINFORCE), we want to emphasize that GACA is general and can be further improved by combining it with techniques in other methods to further boost performance, such as meta-learning proposed in MeRL.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token][line_break_token]3.	Reply	I-Reply	2
More related work on program synthesis[line_break_token][line_break_token][line_break_token]    We have included several program synthesis papers in related work.	Reply	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]4.	Reply	O	0
Why use two-buffer estimation in Eq.	Reply	O	0
13[line_break_token][line_break_token][line_break_token]    Because GACA enables reusing all the past trajectories while previous methods only use high-reward trajectories, two-buffer estimation naturally arises here as a result of using stratified sampling to obtain unbiased and low variance gradient.	Reply	O	0
w_b and w_c are calculated via stratified sampling, refer to Eq(13) for details.	Reply	B-Reply	4
[line_break_token][line_break_token][line_break_token]5.	Reply	O	0
What‚Äôs the performance of GACA if f-divergence is replaced with KL-divergence?	Reply	O	0
[line_break_token][line_break_token][line_break_token]    If KL-divergence is used, then GACA reduces to GACA w/o AG which means GACA without adaptive gradient estimation.	Reply	O	0
From experimental results(e.g.	Reply	B-Reply	5
Table 1), we can see that GACA w/o AG greatly outperforms baselines on both benchmarks	Reply	I-Reply	5

The paper presents a generalization of the Adagrad type methods using a min-max formulation and then presents two alternate algorithms to solve this formulation.	Review	O	0
[line_break_token][line_break_token]It is unclear to me that much extra generalization has been achieved over the original AdaGrad paper.	Review	B-Review	1
That paper simply presents the choice of hyperparameters as an optimal solution to a proximal primal dual formulation.	Review	I-Review	1
The formulation presented here appears to be another form of the proximal mapping formulation, and so it is unclear what the advance here is.	Review	I-Review	1
The AdaGrad paper used a particular Bregman divergence, and different divergences yield slightly different methods, as is observed here by the authors when they use different divergence measures.	Review	I-Review	1
[line_break_token][line_break_token]The Bregman divergences do make sense from a primal pual proximal formulation point of view, but why do you use a discrepancy function in your min-max formulation that comes from the \phi - divergence family?	Review	I-Review	2
Why not consider an L_p normalization of the discrepancy?	Review	I-Review	2
[line_break_token][line_break_token]The difference between formulations (5) and (6) is not clearly specified.	Review	I-Review	3
Did you mean to drop the constraints that \beta \in \cal{B}_t ?	Review	I-Review	3
Otherwise, why is (6) , which looks to be a re-write of (5), unconstrained and hence separable?	Review	I-Review	3
[line_break_token][line_break_token]The authors claim that the method is free of parameter choices, but the initial \beta_0 seems to be a crucial parameter here since it forms both a target and a lower bound for subsequent \beta_t's.	Review	I-Review	4
How is this parameter chosen and what effect does it have on convergence?	Review	I-Review	4
From the results (Figs in Sec 5), this choice does significantly impact the final test loss obtained.	Review	I-Review	4
[line_break_token]    [line_break_token]I could not find a proof for Thm 6 in the appendix.	Review	O	0
Did I over look it or is there a typo?	Review	B-Review	5
1) Our main contribution (or focus) of this paper is to propose a framework for adjusting learning rate adaptively.	Reply	O	0
We offer a novel viewpoint different from previous main approaches like line search and approximate second-order methods (BBstep, Adagrad, etc.).	Reply	B-Reply	1
[line_break_token]2) Compared with Bregman divergence, \phi-divergence naturally imposes nonnegative constraint about \beta and \eta_t, which is necessary for learning rates, while the L_p normalization still can‚Äôt guarantee nonnegative condition for learning rate.	Reply	O	0
[line_break_token]3) Equation (6) is equivalent to (5).	Reply	O	0
We just want to rewrite (5) to a more clear scheme.	Reply	B-Reply	3
[line_break_token]4) In the classical gradient descent algorithm formulated as x_{t+1} = x_t - g_t / \beta, for small \beta, more precisely for \beta < 2 / L, the algorithm has no guarantee for convergence.	Reply	O	0
Our framework gives a upper bound for runtime (O(1 / \varepsilon)) or regret (O(\sqrt(T))) for arbitrary \beta_0.	Reply	B-Reply	4
Moreover, like Adagrad or gradient descent, algorithms derived from our framework also can be suggested a best initial learning rate for optimization ( based on our regret bounds).	Reply	I-Reply	4
[line_break_token]5) The proof of Theorem 6 can be found in the proofs of Theorems 21, 22, and 23	Reply	O	0

(This delayed review is based on the deadline version of the paper.)	Review	O	0
[line_break_token][line_break_token]This paper proposes to learn by RL a reset policy at the same time that we learn the forward policy, and use the learned reset Q-function to predict and avoid actions that would prevent reset ‚Äî an indication that they are "unsafe" in some sense.	Review	O	0
[line_break_token][line_break_token]This idea (both parts) is interesting and potentially very useful, particularly in physical domains where reset is expensive and exploration is risky.	Review	O	0
While I'm sure the community can benefit from ideas of this kind, it really needs clearer presentations of such ideas.	Review	B-Review	10
I can appreciate the very intuitive and colloquial style of the paper, however the discussion of the core idea would benefit from some rigor and formal definitions.	Review	I-Review	10
[line_break_token][line_break_token]Examples of intuitive language that could be hiding the necessary complexities of a more formal treatment:[line_break_token][line_break_token]1.	Review	O	0
In the penultimate paragraph of Section 1, actions are described as "reversible", while a stochastic environment may be lacking such a notion altogether (i.e. there's no clear inverse if state transitions are not deterministic functions).	Review	B-Review	1
[line_break_token][line_break_token]2.	Review	O	0
It's not clear whether the authors suggest that the ability to reset is a good notion of safety, or just a proxy to such a notion.	Review	B-Review	2
This should be made more explicit, making it clearer what this proxy misses: states where the learned reset policy fails (whether due to limited controllability or errors in the policy), that are nonetheless safe.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
In the last paragraph of Section 3, a reset policy is defined as reaching p_0 from *any* state.	Review	B-Review	3
This is a very strong requirement, which isn't even satisfiable in most domains, and indeed the reset policies learned in the rest of the paper don't satisfy it.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	I-Review	5
What are p_0 and r_r in the experiments?	Review	I-Review	4
What is the relation between S_{reset} and p_0?	Review	I-Review	4
Is there a discount factor?	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	O	0
In the first paragraph of Section 4.1, states are described as "irreversible" or "irrecoverable".	Review	B-Review	5
Again, in a stochastic environment a more nuanced notion is needed, as there may be policies that take a long time to reset from some states, but do so eventually.	Review	I-Review	5
[line_break_token][line_break_token]6.	Review	O	0
A definition of a "hard" reset would make the paper clearer.	Review	B-Review	6
[line_break_token][line_break_token]7.	Review	O	0
After (1), states are described as "allowed".	Review	B-Review	7
Again, preventing actions that are likely to hinder reset cannot completely prevent any given state in a stochastic environment.	Review	I-Review	7
It also seems that (2) describes states where some allowed action can be taken, rather than states reachable by some allowed action.	Review	I-Review	7
For both reasons, Algorithm 1 does not prevent reaching states outside S*, so what is the point of that definition?	Review	I-Review	7
[line_break_token][line_break_token]8.	Review	O	0
The paper is not explicit about the learning dynamics of the reset policy.	Review	B-Review	8
It should include a figure showing the learning curve of this policy (or some other visualization), and explain how the reset policy can ever gain experience and learn to reset from states that it initially avoids as unsafe.	Review	I-Review	8
[line_break_token][line_break_token]9.	Review	O	0
Algorithm 1 is unclear on how a failed reset is identified, and what happens in such case ‚Äî do we run another forward episode?	Review	B-Review	9
Another reset episode?	Review	I-Review	9
Thank you for the comments!	Reply	O	0
It seems that all the concerns have to do with the writing in the paper and are straightforward to fix.	Reply	O	0
We have addressed all the concerns raised about the paper in this review.	Reply	O	0
Given that all issues have been addressed, we would appreciate if the reviewer could take another look at the paper.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	9
We have clarified our definition of reversible action in Section 1 paragraph 4.	Reply	I-Reply	1
For deterministic MDPs, we say an action is reversible if it leads to a state from which there exists a reset policy that can return to a state with high density under the initial state distribution.	Reply	I-Reply	1
For stochastic MDPs, we say an action is reversible if the probability that an oracle reset policy that can reset from the next state is greater than some safety threshold.	Reply	I-Reply	1
Note that definition for deterministic MDPs is a special case of the definition for stochastic MDPs.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	4
The ability of an oracle reset policy to reset is a good notion of safety.	Reply	I-Reply	2
In our algorithm, we approximate this notion of safety, assuming that whether our learned reset policy can reset in N episodes is a good proxy for whether an oracle reset policy can reset.	Reply	I-Reply	2
We have clarified Section 1 paragraph 4 to make this distinction clear.	Reply	I-Reply	2
We also added Appendix B to discuss handling errors in Q value estimation.	Reply	I-Reply	2
In this section, we describe how Leave No Trace copes with overestimates and underestimates of Q values.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
We have corrected this technical error in Section 3 paragraph 2 by redefining the reset policy as being able to reach p_0 from any state reached by the forward policy.	Reply	B-Reply	3
That our learned reset policy only learns to reset from states reached by the forward policy is indeed a limitation of our method.	Reply	I-Reply	3
However, note that early aborts help the forward policy avoid visiting states from which the reset policy is unable to reach p_0.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	1
For the continuous control environments, the initial state distribution p_0 is uniform distribution centered at a ‚Äústart pose.	Reply	I-Reply	4
‚Äù  We use a discount factor \gamma = 0.99.	Reply	I-Reply	4
Both details have been noted in Appendix F.3 paragraph 2.	Reply	I-Reply	4
The reset reward r_r is a hand-crafted approximation to p_0.	Reply	I-Reply	4
For example, in the Ball in Cup environment, r_r is proportional to the negative L2 distance from the ball to the origin (below the cup).	Reply	I-Reply	4
For cliff cheetah, r_r includes one term that is proportional to the distance of the cheetah to the origin, and another term indicating whether the cheetah is standing.	Reply	I-Reply	4
S_{reset} is the set of states where r_r(s) is greater than 0.7 (Appendix C.3 paragraph 2)[line_break_token][line_break_token]5.	Reply	O	0
We have clarified Section 4.1 paragraph 1 to explain how our proposed algorithm handles both cases: states from which it is impossible to reset and states from which resetting would take prohibitively many steps.	Reply	B-Reply	5
In both cases, the cumulative discounted reward (and hence the value function) will be low.	Reply	I-Reply	5
By performing an early abort when the value function is low, we avoid both cases.	Reply	I-Reply	5
[line_break_token][line_break_token]6.	Reply	O	0
We added a definition of ‚Äúhard reset‚Äù to Section 4.2 paragraph 1: A hard reset is an action that resamples that state from the initial state distribution.	Reply	B-Reply	6
Hard resets are available to an external agent (e.g. a human) but not the learned agent.	Reply	I-Reply	6
[line_break_token][line_break_token]7.	Reply	O	0
We acknowledge that the proposed algorithm does not guarantee that we never visit unsafe states.	Reply	B-Reply	7
In Appendix A, we have added a proof that Leave No Trace would only visit states that are safe in expectation if it had access to the true Q values.	Reply	I-Reply	7
Appendix A.3 discusses the approximations we make in practice that can cause Leave No Trace to visit unsafe states.	Reply	I-Reply	7
Finally, Appendix B discusses how Leave No Trace handles errors incurred by over/under-estimates of Q values.	Reply	I-Reply	7
[line_break_token][line_break_token]8.	Reply	O	0
Newly added Appendix D visualizes the training dynamics by plotting the number of time steps in each episode before an early abort.	Reply	B-Reply	8
Initially, early aborts occur near the initial state distribution, so the forward episode lengths are quite short.	Reply	I-Reply	8
As the reset policy improves, early aborts occur further from the initial state, as indicated by longer forward episode lengths.	Reply	I-Reply	8
Newly added Appendix B discusses how Leave No Trace handles errors incurred by over/under-estimates of Q values.	Reply	I-Reply	8
It describes how Leave No Trace learns that an ‚Äúunsafe‚Äù state is actually safe.	Reply	I-Reply	8
[line_break_token][line_break_token]9.	Reply	I-Reply	4
We detect failed resets in line 12 of Algorithm 1.	Reply	I-Reply	9
We have added a comment to help clarify this.	Reply	I-Reply	9
When a failed reset is detected, a hard reset occurs (line 13)	Reply	I-Reply	9

In this manuscript, the authors borrow the idea of "optimism" from the online learning literature and apply it to two frequently used methods for neural network training (AMSGrad and ADAM).	Review	O	0
More or less, replicating the theory known in the literature, they give a regret analysis.	Review	O	0
The manuscript ends with a comparison of the optimistic methods against their plain counterparts on a set of test problems.	Review	O	0
[line_break_token][line_break_token]This is a well-written paper filling a gap in the literature.	Review	O	0
Through the contribution does not seem significant, the results do support that such extensions should be out there.	Review	O	0
In addition to a few typos, some clarification on several points could be quite useful:[line_break_token][line_break_token]1) It is not clear why the authors use this particular extrapolation algorithm?	Review	O	0
[line_break_token][line_break_token]2) If we have the past r+1 gradients, can we put them into use for scaling the next direction like in quasi-Newton methods?	Review	O	0
[line_break_token][line_break_token]3) The following part of the sentence is not clear: "... the gradient vectors at a specific time span is assumed to be captured by (5)."	Review	O	0
[line_break_token][line_break_token]4) \nabla is missing at the end of the line right after equation (6).	Review	O	0
[line_break_token][line_break_token]5) The second line after Lemma 2 should be "... it does not matter how..." (The word 'not' is missing.)	Review	O	0
[line_break_token]	Review	O	0
Thank you for the comments and identifying the typos.	Reply	O	0
We have fixed them.	Reply	O	0
Please find as follows our response.	Reply	O	0
[line_break_token]We've updated the new version accordingly.	Reply	O	0
[line_break_token][line_break_token]== The extrapolation algorithm == [line_break_token]We choose the particular algorithm by (Scieur et al.	Reply	O	0
2016) because it has good empirical performance[line_break_token]in practice. (	Reply	B-Reply	1
Scieur et al.	Reply	I-Reply	1
2016) shows that using the last few updates of an optimization algorithm,[line_break_token]the method can predict a point that is much closer to the optimum than the last update of the optimization algorithm.	Reply	I-Reply	1
[line_break_token][line_break_token]== Scaling the next direction ==[line_break_token]This may be a good idea.	Reply	O	0
We leave it as a future work.	Reply	B-Reply	2
[line_break_token][line_break_token]== "... the gradient vectors at a specific time span is assumed to be captured by (5)."	Reply	O	0
==[line_break_token]We elaborate it in the new version accordingly.	Reply	O	0
[line_break_token]We want to have a good prediction of by using the past few gradients.	Reply	B-Reply	3
[line_break_token]If the past few gradients can be modeled by the equation approximately, then[line_break_token]the method should predict the gradient well	Reply	I-Reply	3

The authors propose to apply generative adversarial imitation learning to multi player Markov games.	Review	O	0
[line_break_token][line_break_token]My opinion is that the studied cases are the most simple cases in multi-agent problems.	Review	B-Review	1
Rewards are either the same for every agents (collaborative) or opposite (zero-sum) or agents are totally independent.	Review	I-Review	1
Therefore there is little challenge for imitation learning as in the two first cases, there is only one reward function to learn and in the third, each agent can be imitated independently from the others.	Review	I-Review	1
[line_break_token][line_break_token]As the authors say, the computation of the advantage function assumes that other agents are just part of the environment which makes the problem much simpler.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
Thank you for your comment!	Reply	O	0
To clarify some of your concerns:[line_break_token][line_break_token]- One challenge to inverse reinforcement learning is the ill-defined nature of the problem.	Reply	O	0
Even in single agent settings there are multiple solutions to the IRL problem (for example, set zero reward everywhere).	Reply	B-Reply	1
This is even worse in the multi-agent case because there could be several Nash equilibria.	Reply	I-Reply	1
If we do not make any assumptions to simplify the problem, it is highly possible to learn many rewards that explain the demonstrated behavior.	Reply	I-Reply	1
If we merely learn a new set of policies from any set of rewards, we may land into another Nash equilibrium that do not reflect the expert policies	Reply	I-Reply	1

The authors present HPG, which applies the hindsight formulation already applied to off-policy RL algorithms (hindsight experience replay, HER, Andrychowicz et al.,	Review	O	0
2017) to policy gradients.	Review	O	0
[line_break_token]Because the idea is not new, and formulating HPG from PG is so straightforward (simply tie the dynamical model over goals), the work seems incremental.	Review	O	0
Also, going off policy in PG is known to be quite unstable, and so I'm not sure that simply using the well known approach of normalized importance weights is in practice enough to make this a widely useful algorithm for hindsight RL.	Review	O	0
[line_break_token][line_break_token][line_break_token]Evaluation      3/5 How does HPG compare to HER?	Review	O	0
The only common experiment appears to be bit-flipping, which it appears (looking back at the HER paper, no reference to HER performance in this paper) to signifcantly underperform HER.	Review	B-Review	1
In general I think that the justification for proposing HPG and possible advantages over HER need to be discussed: why should we generalize what is considered an on-policy algorithm like PG to handle hindsight, when HER seems ideally suited for such scenarios?	Review	I-Review	1
Why not design an experiment that showcases the advantages of HPG over HER?	Review	I-Review	1
[line_break_token]Clarity              4/5 Generally well explained.	Review	O	0
[line_break_token]Significance    3/5 The importance of HPG relative to off-policy variants of hindsight is not clear.	Review	O	0
Are normalized importance weights, a well established variance reduction technique, enough to make HPG highly effective?	Review	B-Review	2
Do we really want to be running separate policies for all goals?	Review	I-Review	2
With the practical need to do goal sub-sampling, is HPG really a strong algorithm (e.g. compared to HER)?	Review	I-Review	2
Why does HPG degrade later in training sometimes when a baseline is added?	Review	I-Review	2
This is strange, and warrants further investigation.	Review	I-Review	2
[line_break_token]Originality     2/5 More straightforward extension of previous work based on current presentation.	Review	O	0
[line_break_token][line_break_token]Overall I feel that HPG is a more straightforward extention of previous work, and is not (yet at least) adequately justified in the paper (i.e. over HER).	Review	O	0
Furthermore, the experiments seem very preliminary, and the paper needs further maturation (i.e. more discussion about and experimental comparision with previous work, stronger experiments and justification).	Review	B-Review	4
[line_break_token]Rating          5/10 Weak Reject[line_break_token]Confidence      4/5[line_break_token][line_break_token]Updated Review: [line_break_token][line_break_token]The authors have updated the appendix with new results, comparing against HER, and provided detailed responses to all of my concerns: thank you authors.	Review	O	0
[line_break_token][line_break_token]While not all of my concerns have been addressed (see below), the new results and discussion that have been added to the paper make me much more comfortable with recommending acceptance.	Review	O	0
The formuation, while straightforward and not without limitations, has been shown in preliminary experiments to be effective.	Review	O	0
While many important details (e.g. robust baselines and ultimate performance) still need to be worked out, HPG is almost certainly going to end up being a widely used addition to the RL toolbox.	Review	O	0
Good paper, recommend acceptance.	Review	O	0
[line_break_token][line_break_token]Evaluation/Clarity/Originality/Significance: 3.5/4/3/4[line_break_token][line_break_token]Remaining concerns: [line_break_token]- The poor performance of the baselines may indeed be due to lack of hindsight, but this should really be debugged and addressed by the final version of the paper.	Review	O	0
[line_break_token]- Results throughout the paper are shown for only the first 100 evaluation steps.	Review	O	0
In many of the figures the baselines are still improving and are highly competitive... some extended results should be included in the final version of the paper (at least in the appendix).	Review	B-Review	6
[line_break_token]- As pointed out, it is difficult to compare the HER results directly, and it is fair to initially avoid confounding factors, but Polyak-averaging and temporal difference target clipping are important optimization tricks.	Review	O	0
I think it would strengthen the paper to optimize both the PG and DQN based methods and provide additional results to get a better idea of where things stand on these and/or possibly a more complicated set of tasks.	Review	B-Review	7
[line_break_token][line_break_token][line_break_token]	Review	O	0
Thank you very much for the time that you have dedicated to evaluate our work.	Reply	O	0
We are glad that you found our ideas generally well explained.	Reply	O	0
[line_break_token][line_break_token]Regarding your summary of our contribution, although we agree that hindsight is not an original idea in reinforcement learning, it was introduced only recently and has attracted significant interest, as evidenced by the fact that the work of Andrychowicz et al. (	Reply	B-Reply	2
2017) has received more than one hundred citations in less than two years, when it first appeared as a technical report.	Reply	I-Reply	2
[line_break_token][line_break_token]While we agree that tying the dynamics model over goals is straightforward, that is just one of many steps required to derive our approach, which has importance sampling at its core.	Reply	I-Reply	2
Importance sampling is indeed the natural choice to enable using off-policy data in policy gradients.	Reply	I-Reply	2
Nonetheless, the exact formulation of the hindsight policy gradient, its relationships with value functions, and the feasibility of the corresponding estimators are only clear in hindsight.	Reply	I-Reply	2
For instance, note that we are able to derive an estimator that can be effectively computed for environments of interest even though it seems to require an expectation over all possible goals.	Reply	I-Reply	2
Although apparently simple by analogy, several results require proofs that are elementary but involved (for an example, see Theorem 4.2).	Reply	I-Reply	2
Our technical approach to hindsight is radically different from previous work, which is why we strongly disagree with the claim that our work is incremental.	Reply	I-Reply	2
[line_break_token][line_break_token]The reviewer is correct in noting that employing importance sampling to compute gradients can in general be unstable, which motivates the empirical study presented in Section 6 and the supplementary empirical study of likelihood ratios presented in Appendix E.3.6.	Reply	I-Reply	2
We believe that our experiments on a diverse selection of sparse-reward environments conclusively answer the question of whether weighted importance sampling is effective.	Reply	I-Reply	2
In addition to such substantial empirical evidence, it is crucial to note that we apply importance sampling in a very specific setting, leading to estimators that have remarkable properties that differentiate them from previous estimators for off-policy learning.	Reply	I-Reply	2
We mention several of these properties in Section 5, in the paragraph before the last.	Reply	I-Reply	2
[line_break_token][line_break_token]On a related subject, we vehemently disagree with the claim that our experiments are preliminary.	Reply	I-Reply	4
Note that Reviewer #2 refers to our experiments as extensive and Reviewer #4 believes that our experiments are well designed and that our analysis is thorough and rigorous.	Reply	I-Reply	4
[line_break_token][line_break_token]We completely understand your interest in a direct comparison with hindsight experience replay.	Reply	I-Reply	8
Because this comparison was a common request among reviewers, we are currently working on it.	Reply	I-Reply	8
We will provide an updated version of the paper including the corresponding results before the end of the rebuttal period (ideally by 21/11).	Reply	I-Reply	8
[line_break_token][line_break_token]Nonetheless, we would like to briefly explain why we did not include such a comparison in the current version of the paper.	Reply	I-Reply	8
Firstly, hindsight experience replay is an approach that can be applied to any reinforcement learning technique that relies on experience replay.	Reply	I-Reply	8
Besides the choices required to implement hindsight experience replay itself (such as the goal sampling strategy and number of hindsight transitions per observed transition), each of these techniques potentially has several important hyperparameters.	Reply	I-Reply	8
Instead of comparing HPG to one of these techniques, we preferred to focus on a rigorous comparison with GCPG, its most natural counterpart.	Reply	I-Reply	8
The similarities between both methods allow for a highly systematic comparison that minimizes confounding factors.	Reply	I-Reply	8
Secondly, note that we have not used tricks that are known to increase the performance of policy gradient methods (e.g., entropy bonuses, reward scaling, learning rate annealing, simple statistical baselines), once again in order to avoid introducing confounding factors.	Reply	I-Reply	8
Because hindsight experience replay is directly applicable to state-of-the-art techniques, this would lead to an unbalanced comparison.	Reply	I-Reply	8
Finally, it should be clear that our work can probably benefit from being extended to state-of-the-art policy gradient approaches.	Reply	I-Reply	8
However, once again, such extensions are likely to introduce confounding factors that we would prefer to avoid in our fundamental work.	Reply	I-Reply	8
[line_break_token][line_break_token](Part 1/2	Reply	O	0

This paper proposes a GCN variant that addresses a limitation of the original model, where embedding is propagated in only a few hops.	Review	O	0
The architectural difference may be explained in the following: GCN interleaves the individual node feature transformation and the single-hop propagation, whereas the proposed architecture first transforms the node features, followed by a propagation with an (in)finite number of hops.	Review	O	0
The propagation in the proposed method follows personalized PageRank, where in addition to following direct links, there is a nonzero probably jumping to a target node.	Review	O	0
[line_break_token][line_break_token]I find the idea interesting.	Review	O	0
The experiments are comprehensive, covering important points including data split, training set size, number of hops, teleport probability, and ablation study.	Review	O	0
Two interesting take-home messages are that (1) GCN-like propagation without teleportation leads to degrading performance as the number of hops increases, whereas propagation with teleportation leads to converging performance; and (2) the best-performing teleport probability generally falls within a narrow range.	Review	O	0
[line_break_token][line_break_token]Question: The current propagation approach uses the normalized adjacency matrix proposed by GCN, which is, strictly speaking, not the transition matrix used by PageRank.	Review	O	0
What prevents from using the transition matrix?	Review	B-Review	1
Note that this matrix naturally handles directed graphs.	Review	I-Review	1
[line_break_token]	Review	O	0
Thank you for your review and feedback!	Reply	O	0
[line_break_token][line_break_token]You are right, nothing prevents the model from using the standard transition matrix.	Reply	B-Reply	1
During model development, however, we have found that the added self-loops of the GCN-matrix are beneficial to performance.	Reply	I-Reply	1
The symmetrical normalization actually doesn't make any difference in the limit k->infinity.	Reply	O	0
However, we found this style of normalization to be beneficial for the finite-step approximation.	Reply	B-Reply	1

This paper proposes an end-to-end trainable attention module, which takes as input the 2D feature vector map and outputs a 2D matrix of scores for each map.	Review	O	0
The goal is to make the learned attention maps highlight the regions of interest while suppressing background clutter.	Review	O	0
Experiments conducted on image classification and weakly supervised segmentation show the effectiveness of the proposed method.	Review	O	0
[line_break_token][line_break_token]Strength of this paper:[line_break_token]1) Most previous work are all implemented as post-hoc additions to fully trained networks while this work is end-to-end trainable.	Review	O	0
Not only the newly added weights for attention will be learned, so are the original weights in the network.	Review	O	0
[line_break_token]2) The generalization ability shown in Table 3 is very good, outperforming other existing network by a large margin.	Review	O	0
[line_break_token]3) Visualizations shown in the paper are convincing.	Review	O	0
[line_break_token][line_break_token]Some weakness:[line_break_token]1) Some of the notations are unclear in this paper, vector should be bold, hard to differentiate vector and scalar.	Review	O	0
[line_break_token]2) In equation (2), l_i and g should have different dimensionality, how does addition work?	Review	O	0
Same as equation (3)[line_break_token]3) The choice of layers to add attention modules is unclear to me.	Review	O	0
The authors just pick three layers from VGG to add attention, why picking those 3 layers?	Review	B-Review	3
Is it better to add attention to lower layers or higher layers?	Review	I-Review	3
Why is it the case that having more layers with attention achieves worse performance?	Review	I-Review	3
[line_break_token]	Review	O	0
We thank the reviewer for the comments.	Reply	O	0
[line_break_token][line_break_token]1) notation: We have updated the paper, in particular Section 3, to represent the vectors in bold to differentiate them from scalars.	Reply	O	0
[line_break_token][line_break_token]2) potential for differing dimensionalities of l_i and g: There is some discussion of this in the second paragraph of Sec.	Reply	O	0
3.1.	Reply	B-Reply	2
We propose the use of one fully connected layer for each CNN layer s, which projects the local feature vectors of s to the dimensionality of g. These linear parameters are learned along with all other network parameters during end-to-end training.	Reply	I-Reply	2
There is an implementation detail, though, which we had neglected to mention: in order to limit the network parameters at the classification stage, we actually project g to the lower-dimensional space of the local features l_i.	Reply	I-Reply	2
A note of clarification on this has been added to the first paragraph of Sec.	Reply	I-Reply	2
4.	Reply	I-Reply	2
[line_break_token][line_break_token]3) selection of layers for attention: A brief discussion on the choice of adding attention to higher layers as opposed to the lower ones was included in Sec.	Reply	O	0
3.3.	Reply	B-Reply	3
We have now augmented this discussion, in place, with further clarification on the specific layers that we choose for estimating the attention.	Reply	I-Reply	3
[line_break_token]For l_i and g to be comparable using the proposed compatibility functions, they should be mapped to a common high-dimensional space.	Reply	I-Reply	3
In other words, the effective filters operating over image patches in the layers s must represent relatively ‚Äòmature‚Äô features that are captured in g for the classification goal.	Reply	I-Reply	3
We thus expect to see the greatest benefit in deploying attention relatively late in the pipeline to provide for the learning of these features in l_i.	Reply	I-Reply	3
In fact, att2 architectures often outperform their att3 counterparts, as can be seen in Tables 1 and 2.	Reply	I-Reply	3
[line_break_token]Further, different kinds of class details are more easily accessible at different scales.	Reply	I-Reply	3
Thus, in order to facilitate the learning of diverse and complementary attention-weighted features, we propose the use of attention over different spatial resolutions.	Reply	I-Reply	3
The combination of the two factors stated above results in our deploying the attention units after the convolutional blocks that are late in the pipeline, but before their corresponding max-pooling operations, i.e. before a reduction in the spatial resolution	Reply	I-Reply	3

This paper proposes a learning strategy to precondition gradients for meta-learning.	Review	O	0
I really enjoyed reading the paper though I admit that I couldn't fully grasp all the details yet (paper is dense).	Review	O	0
My comments below are mostly to improve the readability of the paper for readers like me (knowing a thing or two in optimization and meta-learning)[line_break_token][line_break_token][line_break_token][line_break_token]1- The authors emphasize on the method being trajectory-agnostic.	Review	O	0
Can you explain why this is very important?	Review	B-Review	1
What methods are not trajectory-agnostic?	Review	I-Review	1
[line_break_token][line_break_token]2 - Also in various places, the authors claim the method does not suffer from vanishing/exploding gradients and credit-assignment problem.	Review	O	0
This needs to be properly verified (and explained as I do not see the connections clearly)[line_break_token][line_break_token]3- Some claims are based on the Omniglot experiments (eg.,	Review	O	0
the effect of the stop-gradient).	Review	B-Review	3
It would be good if this can be done on Mini-imagenet instead.	Review	I-Review	3
[line_break_token][line_break_token]4- I am not sure I understand the stop-gradient operator, can you be more explicit there?	Review	O	0
[line_break_token][line_break_token]5- I read the conversation regarding linear units on openreview and I disagree with your statement.	Review	O	0
A cascade of linear layers does not necessarily match one linear layer unless some constraints on the rank of layers are envisaged, a bottleneck in the middle ruin everything.	Review	B-Review	5
[line_break_token]	Review	O	0
ear R1, [line_break_token][line_break_token]Thank you for your thorough review and constructive feedback, we will incorporate these when updating the manuscript to make it as accessible as possible!	Reply	O	0
[line_break_token][line_break_token]1 - This is a great point, it is indeed important and we will make sure to emphasise this in the revised manuscript.	Reply	O	0
A meta-learner that is *not* trajectory agnostic has a meta-objective that is a function of the entire trajectory, and hence needs to backpropagate through the entire trajectory, such as MAML-based meta-learners.	Reply	B-Reply	1
This limits their scalability and makes meta-optimization challenging (see Eq.	Reply	I-Reply	1
1 and following discussion).	Reply	I-Reply	1
In contrast, WarpGrad is a trajectory-agnostic meta-learner.	Reply	I-Reply	1
We use trajectories to form an empirical distribution from which we sample individual steps that we optimise independently.	Reply	I-Reply	1
Because the objective is point-wise, we avoid backpropagation through the trajectory, which is what makes WarpGrad competitive even for very long trajectories: the meta-objective scales with at most linear complexity in trajectory length and does not suffer numerical instability as trajectories become long.	Reply	I-Reply	1
[line_break_token][line_break_token]2 - Thank you for the constructive feedback as this too is a central aspect of WarpGrad.	Reply	O	0
To clarify the connection, MAML backpropages through the adaptation trajectory, which is essentially an RNN-like backpropagation through time operation.	Reply	B-Reply	2
Hence it suffers from the same exploding/vanishing gradients and credit assignment problems that RNNs struggle with, which has been observed empirically [e.g. 1]. More specifically, because the MAML meta-gradient is a product of Hessian matrices, high or low curvature during task adaptation has a multiplicative effect on the meta-gradient (the product of many values much greater or much lower than 1 will cause gradients to explode or vanish, respectively).	Reply	I-Reply	2
In contrast, WarpGrad avoids these specific issues by design as it does not backpropagate through adaptation trajectories and instead learns to optimize each gradient step individually.	Reply	I-Reply	2
[line_break_token][line_break_token]3 - While we appreciate the sentiment, tieredImageNet, miniImagenet and Omniglot are structurally similar benchmarks in that they are image classification tasks over homogenous image domains (natural images and hand-drawn characters, respectively).	Reply	O	0
Hence the added benefit of running the same ablations on miniImagenet would be limited and given space as well as time constraints we have refrained from doing so.	Reply	B-Reply	3
In terms of the first-order approximation (Eq.	Reply	I-Reply	3
12), our claim is that it is a useful approximation over longer adaptation processes, as in the Omniglot and RL experiment, where first-order effects tend to dominate.	Reply	I-Reply	3
Hence we evaluate this approximation on these experiments.	Reply	I-Reply	3
[line_break_token][line_break_token]4 - A stop-gradient operator is an operation that prevents gradients from flowing through a variable during backpropagation.	Reply	O	0
We use it in Eq.	Reply	B-Reply	4
12 to make the same approximation as in the first-order approximation of MAML [2], where the stop-gradient operator prevents the meta-gradient from backpropagating through the inner task adaptation step.	Reply	I-Reply	4
That way, the meta-gradient avoids computing second-order derivatives (that is, it renders the meta-gradient Hessian-free).	Reply	I-Reply	4
[line_break_token][line_break_token]5 - As R1 correctly points out, we are making an implicit full-rank assumption.	Reply	O	0
The public comment was concerned with potentially unfair comparisons in the case that warp layers increase model capacity.	Reply	B-Reply	5
Our reply was directed towards this concern.	Reply	I-Reply	5
While linear layers cannot add capacity, they can reduce it.	Reply	I-Reply	5
This would not make comparisons to baselines unfair, though potentially unfavorable (hence our results are erring on the side of caution) for WarpGrad.	Reply	I-Reply	5
Note that all baselines are tuned for model capacity through conv-layer filter sizes.	Reply	I-Reply	5
[line_break_token][line_break_token][1] Finn et.	Reply	O	0
al.	Reply	O	0
Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.	Reply	O	0
2017.	Reply	O	0
[line_break_token][2] Antoniou et.	Reply	O	0
al.	Reply	O	0
How to train your MAML.	Reply	O	0
2019	Reply	O	0

*Edit: original score was a weak reject (3), updating to a weak accept (6) in light of revisions.*	Review	O	0
[line_break_token][line_break_token]This work implements a hierarchical control scheme for a high-dimensional control problem (locomotion using a humanoid body).	Review	O	0
 The hierarchy consists of a high-level module that plans in an abstract space of "intention", and the intention variables serve as inputs, along with state, to a low-level controller that actually executes the movements.	Review	O	0
 The premise is that a lower-level controller should be usable for multiple tasks, and should be able to be commanded by a lower-dimensional intention input.	Review	O	0
 I find the basic ideas presented clear, the literature reviewed reasonably well, and the motivation and setting to be very interesting.	Review	O	0
 The video summary is valuable.	Review	O	0
[line_break_token][line_break_token]My main concerns have to do with presentation, but I think they are relatively significant concerns.	Review	B-Review	1
 As the draft currently stands, I would, somewhat regrettably, be inclined to reject the submission (marginally).	Review	I-Review	1
 I think revisions could seriously improve this paper and incline me towards acceptance.	Review	O	0
[line_break_token][line_break_token]Algorithm 1 indicates that the learning of the low-level controller will be done jointly with the learning of the latent model and planning using the high-level, learned intention space.	Review	B-Review	2
 In the experiment, it is indicated that the low-level controller is pretrained.	Review	I-Review	2
 This points to a couple issues that are not clear in the draft:[line_break_token](1) Presumably this pretraining is necessary and things do not work without it.	Review	O	0
 Indeed, it is hard to imagine that the movements will be well grounded to human motion capture movements without this pretraining.	Review	B-Review	2
 Does the algorithm work as written or is pretraining a fundamentally essential step?	Review	I-Review	2
 There are no settings, even toy settings, where the algorithm as written is shown to be effective.	Review	I-Review	2
[line_break_token](2) The authors should be clearer how they conduct the pretraining which involves learning the low-level controller.	Review	O	0
 [line_break_token](3) I'm not clear how updating the low-level controller is effective in the algorithm.	Review	O	0
 While I understand why it makes sense to plan in the intention space of the pre-trained controller, and I understand why learning a model is a core part of planning, it would seem like fine-tuning the low-level controller could make the movements deviate considerably from the initial movement space and maybe even eliminate the ability of the low-level policy to express movements that are not used early in training.	Review	B-Review	2
So essentially, while the planning in the low-D space makes sense and the learning of the model makes sense, the low-level controller update seems possibly to not make sense, and there aren't experiments showing that step helps.	Review	I-Review	2
[line_break_token][line_break_token]Is it just a coincidence that the intention space (h) is one-of-three and the low-d state space (z) is 3-dimensional as well?	Review	I-Review	3
 Or are these both selected with sort of going straight vs turning left or right in mind?	Review	I-Review	3
[line_break_token][line_break_token]The experiment section is generally very unclear, though details are made a little clearer from the video.	Review	I-Review	4
 In the paper, there are a few points that need to be clearer: [line_break_token](1) "ref", "plan", and  "true" are not well defined and it is unclear what these distances in Table 1 refer to precisely.	Review	I-Review	4
 Clearly introduce what each of these refers to.	Review	I-Review	4
 The authors simply say that there are imitation tasks but do not walk through what these terms refer to.	Review	I-Review	4
[line_break_token](2) In 4.1, the different structures are not adequately introduced.	Review	O	0
 The pointers to the figure 2 diagrams are essential, but there is no pointer for zaz', the pointers are only in the table (not in the text), there are grammar issues in the text and the text could be verbally clearer about the variants.	Review	B-Review	4
[line_break_token](3) shs' setting is a bit unclear.	Review	O	0
Basically, clarify briefly how planning is performed in this case.	Review	B-Review	4
  Is a forward model still trained, but the model opperates with the full state space?	Review	I-Review	4
 If so, presumably the forward model is much worse and then the planning approach is correspondingly bad, hence the poor rollouts?	Review	I-Review	4
[line_break_token](4) 4.2 is I think obviously inadequately described in the text and I can only assume was the result of rushing for the deadline?	Review	O	0
 The second experiment is essentially not presented in the text all aside from a still image.	Review	B-Review	4
 [line_break_token](5) And for all of the experiments that rely on planning with a particle filter, details such as how reliable the filter is in generating useful control, how many samples are required, and possibly elements of compute speed would make much clearer how well the approach actually works.	Review	O	0
 Does the choice of planner matter at all?	Review	B-Review	4
 A common, albeit relatively weak, baseline planning approach is CEM...would CEM work here?	Review	I-Review	4
 I'd like to understand if the choice of particle filter is the author's default choice, which is fine if so, or if there is a positive assertion being made that the particle filter is particularly valuable.	Review	I-Review	4
[line_break_token][line_break_token]I hope the authors will generally improve the exposition in the experiment section (4) during the revisions.	Review	I-Review	5
[line_break_token][line_break_token]Overall, I find the paper well motivated in framing the problem (i.e. using model-based approaches to control the latent space of a low-level controller).	Review	O	0
 I also appreciate the scale of the problem (humanoid control is challenging, so this is not a toy problem).	Review	O	0
 I find the results a bit unclear, perhaps due to hurriedness in writing, so I find them a bit difficult to fully appreciate.	Review	B-Review	6
 Nevertheless, the core contribution that I take away from this work is that there is a value to learning the low-dimensional state representation (z, via the LVM), relative to planning using a forward model on the full state (?...	Review	I-Review	6
I'm still unclear on the presentation of this result, due to unclear exposition).	Review	I-Review	6
Slightly more broadly, this is a good demonstration of using a planner jointly with a learned high-level command/intention representation, for a high-dimensional problem.	Review	I-Review	6
[line_break_token][line_break_token]If I've understood this correctly, I'd be reasonably interested in this result.	Review	I-Review	6
If the authors can both clarify the core results and communicate that the choices made in the algorithm are well thought through, I would be happy to adjust my score.	Review	I-Review	6
[line_break_token][line_break_token][line_break_token]Relatively minor:[line_break_token][line_break_token]Abstract says 90-dimensional humanoid system, but later it is stated "34 degrees of freedom,[line_break_token]197 state features, and 36 action parameters".	Review	I-Review	7
Where the 90 dimensions comes from is unclear.	Review	I-Review	7
 Often people refer to number of actuators or DoFs.	Review	I-Review	7
 Please adjust this or be more explicit.	Review	I-Review	7
[line_break_token][line_break_token]In equation 9, f() is not very clearly specified.	Review	I-Review	7
Is f() a nonlinear function (e.g. a neural network) or is it a linear function?	Review	I-Review	7
It seems like it might as well be a linear function, since the authors propose to learn a latent dynamics model that is nonlinearly related to the state.	Review	I-Review	7
[line_break_token][line_break_token]Typos in Fig 3 caption.	Review	I-Review	7
[line_break_token]	Review	O	0
s of the revision visible at the present moment, I remain not entirely happy with the presentation of the experiments, but these concerns are now essentially just issues related to what I believe to be clear writing.	Reply	B-Reply	4
 I encourage a few more read-throughs by the authors with an eye towards editing for clarity.	Reply	I-Reply	4
 In particular, I still think the authors don't clearly define their setting succinctly at the beginning of the "Experiment" section.	Reply	I-Reply	4
 And in the subsections of that section, they should open by very briefly defining the tasks.	Reply	I-Reply	4
 The appendices provide additional information, but they should be more explicitly referenced, with an indication of what they contain.	Reply	I-Reply	4
[line_break_token][line_break_token]The above comments notwithdstanding, the authors have made meaningful revisions, and the content required to fully interpret the results is now present.	Reply	I-Reply	8
 I think this work is both interesting and contains valuable contributions.	Reply	I-Reply	8
 So I will update my score to a weak accept (6).	Reply	I-Reply	8
 Ultimately, the novel contributions of this work involve the ability to perform planning using the low-dimensional space to reuse the humanoid motor skills, and these contributions warrant acceptance to the conference.	Reply	I-Reply	8
 This is a challenging problem, so this work does provide a somewhat satisfying demonstration.	Reply	I-Reply	8
 The ablation experiments make the work valuable to build upon.	Reply	O	0

This paper investigates the question of identifying concise equations from data to understand the functional relations.	Review	O	0
In particular, a set of base functions are given in hand and the goal is to obtain the right composition of these functions which fits the target function.	Review	O	0
The main contribution of the paper is to introduce a selection layer, which enhances sparse connections in the network.	Review	O	0
Several experiments are conducted to show the effectiveness of the method.	Review	O	0
[line_break_token][line_break_token]My main concern of the paper is about the novelty and the lack of comparison of existing methods.	Review	B-Review	1
The framework of finding functional relations is set up in [1,2], the main contribution of the paper is a refine architecture with the introduction of the selection layer.	Review	I-Review	1
However, this selection layer is nothing but incorporating a softmax function.	Review	I-Review	1
The idea of combining softmax functions in the hidden layers is not novel neither, which could be found in [3,4]. As a result, I find the contribution of the paper very limited, which could be summarized as applying an existing technique on a specific problem.	Review	I-Review	1
Moreover, in the experimental section, there is a lack of comparison with existing methods such as EQL[1,2] and I consider it a major omission.	Review	I-Review	2
[line_break_token][line_break_token]Overall, due to the novelty concern and the lack of comparison, I do not support publication of the paper.	Review	O	0
[line_break_token][line_break_token][1] Sahoo et al.	Review	O	0
 Learning Equations for Extrapolation and Control[line_break_token][2] Martius et al.	Review	O	0
Extrapolation and learning equations[line_break_token][3] Graves et al.	Review	O	0
 Neural turing machines[line_break_token][4] Graves et al.	Review	O	0
 Hybrid computing using a neural network with dynamic external memory	Review	O	0
e thank you for your valuable comments.	Reply	O	0
[line_break_token][line_break_token]As you said we combine function block activation with selection layer drawn from softmax layer with temperature.	Reply	B-Reply	1
Actually, we tried many different ways including the softmax layer, for example, we tried a power method as NTM [3] does, we also used a probabilistic method like gumbel softmax, and tried RL to learn the path.	Reply	I-Reply	1
Among them, softmax with low temperture and softmax with learning temperature give the best performances in our experiments.	Reply	I-Reply	1
[line_break_token]Furthermore, we find out that we have to restrict l1 norm of W (the matrix before going through softmax), otherwise the network often falls deep into a local minimum.	Reply	I-Reply	1
Also we use curriculum learning since above restriction can be the obstacle after the network finds a right order.	Reply	I-Reply	1
So we reduces the regression constant during the training task and this helps network to find out the right ordering to obtain the function composition.	Reply	I-Reply	1
[line_break_token][line_break_token]As for your comments on the experiments, we will try to compare our methods with existing ones such as EQL since those networks also target finding a right equation including extrapolation.	Reply	I-Reply	2
We will try to make an experiment comparing with EQLs not only focusing on the error but also on the resulting objective function form.	Reply	I-Reply	2
Thank you again for the comments.	Reply	I-Reply	2
[line_break_token][line_break_token][1] Sahoo et al.	Reply	O	0
 Learning Equations for Extrapolation and Control[line_break_token][2] Martius et al.	Reply	O	0
Extrapolation and learning equations[line_break_token][3] Graves et al.	Reply	O	0
 Neural turing machines[line_break_token][4] Graves et al.	Reply	O	0
 Hybrid computing using a neural network with dynamic external memor	Reply	O	0

This paper investigates a so-called "compressive transformer" approach.	Review	O	0
The idea is to compress distant past memories into a coarse-grained representation while keeping a fine-grained representation for close past memories.	Review	O	0
 A variety of compression techniques and training strategies have been investigated in the paper and verified using tasks from multiple domains including language modeling, speech synthesis and reinforcement learning.	Review	O	0
Particularly, the authors propose a new benchmark PG-19 for long-term sequence modeling.	Review	O	0
 [line_break_token][line_break_token]Overall, I found the work interesting and experiments are thorough and strong.	Review	O	0
  It is always great to see a new benchmark released to the community.	Review	O	0
 That being said, I have concerns regarding the paper.	Review	O	0
 The authors put huge amount of effort into the experiments but only describe the proposed technique in a very rough and abstract way, lacking necessary technical details to formulate the technique.	Review	B-Review	1
What is the mathematical formulation of the problem?	Review	I-Review	1
 How exactly the compression is carried out on various network architectures is not clear after reading the paper.	Review	I-Review	1
 Also, I guess many readers including me do not have a perfect understanding of Fig.	Review	I-Review	1
1 although it shows something intuitively. (	Review	I-Review	1
What is the difference between different colors?	Review	I-Review	1
What is the difference between sequence, memory, and compressed memory?	Review	I-Review	1
 What do the arrows mean?	Review	I-Review	1
There is no explanation whatsoever either in the figure or in the caption).	Review	I-Review	1
 This is the major concern I have regarding the paper.	Review	I-Review	1
 Despite of the strong experimental presentation, lacking the technical details has significantly hurt the quality of the paper.	Review	I-Review	1
 [line_break_token][line_break_token]P.S.  Thanks for the rebuttal.	Review	O	0
 I have lifted my score.	Review	O	0
e completely agree that the model could be described more explicitly. *	Reply	B-Reply	1
We are updating the paper with more mathematical details and an algorithm box to make things more explicit*. We originally wrote this paper to convey the key components of the model for those familiar with TransformerXLs, with the idea that all of the fine details are better represented in the code --- however we realize this was not the best strategy.	Reply	I-Reply	1
We will still open-source the code so people can use the model and be certain of every detail, but we are completely re-writing the model section with the inclusion of an algorithm box.	Reply	I-Reply	1
As pseudo-code here, the compression mechanism is really just passing memories that would otherwise be forgotten through a conv1d compression network:[line_break_token][line_break_token]compression_rate &lt;- 3[line_break_token]old_memory  &lt;- memory[:-seq_size]  # the memories to be forgotten[line_break_token]compression_fn &lt;- conv_1d(kernel_size=compression_rate, stride=compression_rate)[line_break_token]new_cm &lt;- compression_fn(old_memory )  # new compressed memories[line_break_token][line_break_token]Then for attention, before in the TransformerXL one would compute[line_break_token]attention(seq, [memory, seq])[line_break_token]whereas here we compute[line_break_token]attention(seq, [compressed_memory, memory, seq])[line_break_token][line_break_token]Before in the TransformerXL one would update memory by concatenating the sequence and truncating the oldest memories (to keep the memory fixed-size):[line_break_token]memory &lt;- concat_and_truncate(memory, sequence)[line_break_token][line_break_token]where 'concat_and_truncate' refers to:[line_break_token]def concat_and_truncate(old_state, new_state):[line_break_token]    new_state_size &lt;- new_state.shape[1]  # time dimension[line_break_token]    return concat([old_state, new_state])[new_state_size:]  [line_break_token][line_break_token]Now we update both the memory and compressed_memory:[line_break_token]memory &lt;- concat_and_truncate(memory, sequence)[line_break_token]compressed_memory &lt;- concat_and_truncate(compressed_memory, new_cm)[line_break_token][line_break_token]In Figure 1 we kept the sequence and memory the same colour, as these hidden activations represent information for a single time-step in the transformer.	Reply	O	0
We use an arrow to indicate that we map a set of memories to a smaller set of compressed memories.	Reply	B-Reply	1
We chose a different colour for the compressed memories (and made the ticks more frequent) to indicate that these represent information over multiple time-steps.	Reply	I-Reply	1
We are updating the figure and caption with more details such that this is clearer.	Reply	I-Reply	1
[line_break_token][line_break_token]If there is anything else that is unclear, feel free to give us feedback!	Reply	O	0

In this work the authors point out an issue related to graph neural networks.	Review	O	0
Specifically, if two nodes, that may be far apart in the graph, may be represented as (almost) the same vector.	Review	O	0
This is simply because when no features/labels are associated with nodes, and the local structure around those two nodes is very similar then the local aggregation of information will result in a similar representation.	Review	O	0
 Therefore the authors introduce an embedding first of the graph in the Euclidean space using DeepWalk and then use this embedding in combination with the design of a CNN.	Review	O	0
The authors propose a pooling method that outperforms several state-of-the-art pooling techniques on real data.	Review	O	0
Overall, the empirical results are supportive of the fact that the proposed method can help improve the performance of GNNs.	Review	O	0
[line_break_token][line_break_token]Overall I found the results of this paper to be weak, but nonetheless the paper is well-written and contains some interesting ideas.	Review	O	0
Hence my rating.	Review	O	0
Some questions follow.	Review	O	0
[line_break_token][line_break_token]- While the authors call this as an "issue" it is more like a feature of these methods.	Review	O	0
 For instance, in "RolX: Structural Role Extraction &amp; Mining in Large Graphs" by Henderson et al.	Review	O	0
this "issue" could turn out to be an interesting feature of the GNNs in the sense that these nodes may have a similar (structural) role.	Review	B-Review	5
 It would be nice to have a short discussion related to this line of research in social networks' analysis.	Review	I-Review	5
[line_break_token]-  Some components of the CNN (e.g., node sampling) could be done using  well-developed tools for sampling matrices from numerical linear algebra, or by introducing some randomness when sampling a node as in kmeans++.	Review	O	0
[line_break_token]- Graph downsampling appears to be an expensive operation.	Review	O	0
Can you please comment on the running times?	Review	B-Review	3
The issue of scalability is not discussed, and the reader cannot easily infer to what sizes this method can scale up to.	Review	I-Review	3
[line_break_token]- Using other graph tasks, that are classical but also more challenging (e.g., learning 2-connected components of a graph just to mention something that comes up) would be interesting to see in Section 5.2.	Review	O	0
[line_break_token]-  It would have been interesting to see the effect of the embedding step on the accuracy on the real data.	Review	O	0
E.g., using node2vec or standard spectral embeddings.	Review	B-Review	4
[line_break_token][line_break_token][line_break_token][Edit: The authors have replied to my comments, and the other reviewers' comments in great detail.	Review	O	0
Therefore I upgrade my score.]	Review	O	0
e thank the reviewer for the comments.	Reply	O	0
[line_break_token][line_break_token]1- ‚ÄúOverall I found the results of this paper to be weak‚Äù:[line_break_token][line_break_token]Table 1 and Table 2  indicate that the improvements in the results are significant for both real and synthetic data.	Reply	O	0
[line_break_token][line_break_token]2- ‚ÄúSome components of the CNN (e.g., node sampling) could be done using  well-developed tools for sampling matrices from numerical linear algebra, or by introducing some randomness when sampling a node as in kmeans++‚Äù: [line_break_token][line_break_token]Thanks for this suggestion.	Reply	O	0
We are well aware of column/row sampling techniques and we considered several sampling methods as our candidates including the one used in K-means++ and SRS [arXiv:1705.03566]. The farthest data point sampling method used in our pooling method (which is very similar to the sampling techniques used in K-means ++) ensures that the sampled embedding vectors cover the spatial distribution of all the embedding vectors and this is all we expect the sampling method to do.	Reply	B-Reply	2
[line_break_token][line_break_token]3- ‚ÄúGraph downsampling appears to be an expensive operation.	Reply	O	0
‚Äù[line_break_token]The complexity of the sampling method is linear with the number of sampled embedding vectors (O(m*n*de) where m is the number of sampled vectors and de is the dimension of the embedding vectors).	Reply	O	0
In addition, different from node classification, in the graph classification task, we mostly do not have large graphs (mostly less than 100 nodes).	Reply	B-Reply	3
In the revised paper, we described the computation complexity of the node sampling method.	Reply	I-Reply	3
[line_break_token][line_break_token]4- ‚ÄúIt would have been interesting to see the effect of the embedding step on the accuracy on the real data.	Reply	O	0
E.g., using node2vec or standard spectral embeddings.	Reply	O	0
‚Äù[line_break_token][line_break_token]ŸëIn our initial experiments, we used other embedding methods such as [arXiv:1710.02971] but the results were not much different.	Reply	O	0
In the final version, we will report the results with several different embedding methods.	Reply	B-Reply	4
[line_break_token][line_break_token]5- ‚ÄúWhile the authors call this as an "issue" it is more like a feature of these methods.	Reply	O	0
 For instance, in "RolX: Structural Role Extraction &amp; Mining in Large Graphs" by Henderson et al.	Reply	O	0
this "issue" could turn out to be an interesting feature of the GNNs in the sense that these nodes may have a similar (structural) role.	Reply	O	0
‚Äù[line_break_token][line_break_token]It depends on the application that we deal with.	Reply	O	0
In the graph classification problem , we clearly showed that it is not a desirable feature and this feature can make the GNN unable to extract discriminative features.	Reply	B-Reply	5
[line_break_token]Moreover, our approach addresses another problem of GNNs raised by (Xu et al. (	Reply	I-Reply	5
ICLR 2019)): GNNs can map even different local structures to same feature vectors.	Reply	I-Reply	5
[line_break_token]Since we include the information about the location of the nodes, we help the GNN to distinguish both similar and different local structures.	Reply	I-Reply	5
[line_break_token]We cited ‚ÄúRolX: Structural Role Extraction &amp; Mining in Large Graphs‚Äù and clarified that the point that in some applications mapping node with similar local structures to similar feature vectors can be desirable.	Reply	O	0
[line_break_token][line_break_token]We would like to reiterate that our paper is the first work which address this problem and the presented results (Table 1 and Table2) clearly show how effective is the presented solution.	Reply	B-Reply	5
 	Reply	I-Reply	1

This paper studies the implicit regularization phenomenon.	Review	O	0
More precisely, given separable data the authors ask whether homogenous functions (including neural networks) trained by gradient flow/descent converge to the max-margin solution.	Review	O	0
 The authors show that the limit points of gradient descent are KKT points of a constrained optimization problem.	Review	O	0
[line_break_token][line_break_token]-I think that the topic is important and the authors clearly made some interesting insights.	Review	O	0
[line_break_token]-The main results of this paper (Theorem 4.1 and Theorem 4.4) require that assumption (A4) is satisfied.	Review	O	0
Assumption (A4) essentially means, that gradient flow/descent is able to reach weights, such that every data x_n is classified correctly.	Review	B-Review	2
To me this seems to be a quit restrictive assumption as due to the nonconvexity of the neural net there is a priori no reason to assume that such a point is reached.	Review	I-Review	2
In this sense, the paper only studies the latter part of the training process.	Review	I-Review	2
[line_break_token][line_break_token]I feel that Assumption (A4) clearly weakens the strength of the main results.	Review	I-Review	2
However, because the topic studied by the paper is interesting and the authors have obtained some interesting insights, I decided to rate the paper as a weak accept.	Review	O	0
[line_break_token][line_break_token]Typos:[line_break_token]-p.	Review	B-Review	1
4: "Very Recently"[line_break_token]-p.	Review	I-Review	1
7 and p. 9: "homogenuous" (instead of "homogeneous")[line_break_token][line_break_token]----------[line_break_token][line_break_token]I want to thank the authors for their response.	Review	O	0
However, I will stand by me evaluation and will not change it.	Review	O	0
[line_break_token]I agree though that assumption (A4) is indeed reasonable, although of course very strong.	Review	O	0
 [line_break_token]	Review	B-Review	1
hanks for your reviews and for pointing out the typos!	Reply	B-Reply	1
[line_break_token][line_break_token]We admit that (A4) may not hold for all neural networks and all datasets.	Reply	I-Reply	2
Indeed, the loss of a neural network is highly non-convex and (A4) seems to be a quite strong assumption.	Reply	I-Reply	2
However, it is known that sufficiently overparameterized neural networks can fit the training set through (stochastic) gradient descent.	Reply	I-Reply	2
As we discussed in the introduction of our paper, state-of-the-art neural networks are typically overparameterized, and they can perfectly fit not only normal data but also randomly labeled data easily in image classification tasks (Zhang et al.,	Reply	I-Reply	2
2017).	Reply	I-Reply	2
Theoretically, (Allen-Zhu et al.,	Reply	I-Reply	2
2019; Du et al.	Reply	I-Reply	2
2018; Zou et al.,	Reply	I-Reply	2
2018) showed that gradient descent can achieve 100% training accuracy if the width is large enough.	Reply	I-Reply	2
Given the evidence from both theory and practice, we believe (A4) is a reasonable assumption (at least for many DL tasks)	Reply	I-Reply	2

(Please find my response to the rebuttal and updated version in a comment below)[line_break_token]The paper analyses latent-variable modeling from a rate-distortion point-of-view in a novel and interesting fashion, highlighting important fundamental connections.	Review	O	0
In particular, the paper presents a novel theorem (inspired by how the rate-distortion function is computed) that gives a lower bound on the negative log likelihood.	Review	O	0
This lower bound allows to quantify by how much a latent-variable model could be improved by either modifying the prior or the likelihood function.	Review	O	0
The latter is important, since the paper shows a duality between improving one while keeping the other fixed and vice versa.	Review	O	0
Finally, the paper derives a practical implementation/approximation (founded on solid theoretical analysis) of quantifying the improvement potential of a latent-variable model.	Review	O	0
These, so called ‚Äúglossy statistics‚Äù are quantitatively analyzed in a set of experiments with different variational autoencoder architectures (various likelihood models and priors) on a number of datasets.	Review	O	0
[line_break_token][line_break_token]The main contribution of this paper is to provide novel proofs and theoretical analysis that connect latent-variable modeling with rate-distortion on a very fundamental level.	Review	O	0
While similar attempts have been reported in the recent literature (perhaps a bit more focused on the empirical aspects), the analysis and results in the paper follow a very fundamental treatment of rate-distortion theory and in particular of computation of the rate-distortion function.	Review	O	0
The central idea underlying rate-distortion, i.e. lossy compression by discarding irrelevant information, seems very suitable as a guiding principle for representation learning.	Review	O	0
In particular, learning representations that generalize well is essentially another instance of a lossy compression problem.	Review	O	0
The paper thus addresses an important and timely topic which should be of broad interest to the representation learning community.	Review	O	0
The paper is well written and mathematically rigorous.	Review	O	0
I have checked most parts of the proofs, though there still is a chance that I missed something.	Review	O	0
I am not entirely convinced by the practical impact of the experimental section of the paper (though the experiments are beyond toy-level and I do not doubt the results), but I also believe that this is not the main contribution of the paper, which is rather laying the mathematical groundwork for future work.	Review	O	0
I vote and argue for accepting the paper for presentation at the conference.	Review	O	0
My criticism below is aimed at giving some pointers for potentially improving the paper.	Review	O	0
[line_break_token][line_break_token]1) As the paper acknowledges, there is a risk of overfitting when improving likelihood functions under fixed priors (and vice versa).	Review	O	0
While the glossy statistics certainly allow making approximate statements of whether the model can be improved further or not, there is no ‚Äúthreshold value‚Äù or other guideline that would indicate a modeling expert that they are entering an over-fitting regime if the model-class is further enriched.	Review	B-Review	1
Therefore, I am not sure about the practical impact of the experiments: the glossy statistics seem to be indicative of the margin for improvements in the negative log-likelihood - but whether all of these improvements are really desirable is unclear.	Review	I-Review	1
To test this, one might resort to tasks other than generative modeling, such that models that overfit can easily be ‚Äúspotted‚Äù (by degrading test-set performance).	Review	I-Review	1
[line_break_token][line_break_token]2) Rate-Distortion can be ‚Äúmade more robust‚Äù against overfitting by different choices of \alpha (essentially limiting channel capacity).	Review	O	0
Maybe I am missing something, but shouldn‚Äôt the \alpha carry over into the computation of the ratios for c(z)?	Review	B-Review	2
Was it just assumed to be 1?	Review	I-Review	2
The same question for Theorem 2 and the equation just above Theorem 2 - does the alpha drop (is it absorbed into the likelihood) or was it set to one?	Review	I-Review	2
It might be interesting to see how the glossy statistics behave if \alpha is considered a hyper-parameter of the model, e.g. under ‚Äúlow capacity‚Äù do the glossy statistics ‚Äúflatten out‚Äù very early?	Review	I-Review	2
[line_break_token][line_break_token]3) I would have been excited to see how the glossy statistics evolve during training of a model - it would be interesting to show that the statistics initially predict a large margin of improvement that reduces and slowly flattens out as training converges.	Review	O	0
[line_break_token][line_break_token]4) In the paragraph after Eq.	Review	O	0
14: the argument hinges on the possibility of having an invertible (and continuously differentiable) g(z).	Review	B-Review	4
To me it is not straightforward that a neural network would necessarily implement such a function (particularly the invertibility might be problematic).	Review	I-Review	4
Is this just a technical condition required for the formal statement, or do you think that this issue could become problematic in practice as well such that the duality between improving prior and likelihood does not hold any longer?	Review	I-Review	4
[line_break_token][line_break_token]Minor:[line_break_token]5) I think the Alemi et al.	Review	O	0
reference (first reference) has been published under a different name (Fixing a Broken ELBO) at this years‚Äô ICML.	Review	B-Review	5
[line_break_token][line_break_token]6) Consider calling the quantity l(x|z) below Eq.	Review	I-Review	5
1 ‚Äúthe likelihood of the latent variable given the data‚Äù (since the data is given, even though the data is not in the conditional, which is why it is a likelihood function).	Review	I-Review	5
[line_break_token][line_break_token]7) Rather than using ‚Äúthe KL divergence between‚Äù, use ‚Äúthe KL divergence from ‚Ä¶ to‚Äù which nicely reflects its asymmetry.	Review	I-Review	5
[line_break_token][line_break_token]8) Page 4, last Equation: square brackets for E_X missing[line_break_token]	Review	I-Review	5
1) On overfitting - In the experimental setup, we let the training of the models proceed until the log likelihood on a validation data set shows no sign of improvement for a given number of epochs, and then revert back to the best model found during the training.	Reply	O	0
We then calculate the glossy statistics based on such best model.	Reply	B-Reply	1
If the glossy statistics indicate that it is becoming harder to improve the model, then we have "the best of both worlds" - a model that is not overfitting that is also becoming harder to improve.	Reply	I-Reply	1
If the glossy statistics suggest that it is still possible to improve the model, then we agree that it is possible that the improvement is undesirable as it could lead to overfitting.	Reply	I-Reply	1
Still, we believe that the glossy statistics do tell something interesting to the statistician in this case.	Reply	I-Reply	1
We believe that a good statistician should be able to spot when it is that her model is likely to overfit, based on experience (observing how a model overfits when the model allows too much freedom), and should be able to interpret the glossy statistics in this case.	Reply	I-Reply	1
[line_break_token][line_break_token]We note that in the experiments, we always posted the best model obtained during training in the sense of the procedure involving the validation data set described above (this is, we believe that the models we are posting results for are not overfit).	Reply	I-Reply	1
We also believe that the experiments show usefulness of the lgossy statistics.	Reply	I-Reply	1
[line_break_token][line_break_token]We have updated the text of the paper to clarify the procedure involving the validation data set.	Reply	O	0
[line_break_token][line_break_token]2) For the log likelihood expression to be a true log likelihood, we need to set, otherwise the statistics and the lower bound are referring to an expression where the likelihood function is raised to the power of.	Reply	O	0
Since this is a paper devoted to generative models, we chose to simplify to when we presented the main results - we have now clarified this in the text.	Reply	B-Reply	2
Rate-distortion theory of course applies to the entire distortion regime which means it gives results for as well (and there is a corresponding variation for in that case).	Reply	I-Reply	2
We believe the reviewer is correct in his intuition that by using a different, the training can be made more robust against overfitting, in fact in our experiments (not currently in the paper as submitted) we saw small anecdotal evidence that by setting an that is close to, but not exactly 1, the resulting model had a slightly improved test data performance.	Reply	I-Reply	2
We did not believe the results to be significant enough to be presented as research results at this point.	Reply	I-Reply	2
We note that even if we train with, the correct way to interpret the results is to then take the resulting model and plug it into our lower bound and glossy statistics with, so that we can obtain a statement for the straight generative model problem.	Reply	I-Reply	2
[line_break_token][line_break_token]3) We have now added in the appendix what the reviewer is asking for.	Reply	O	0
The effect being sought is indeed present.	Reply	B-Reply	3
[line_break_token][line_break_token]4) We have now eliminated the restriction for the mapping to be invertible and continuously differentiable.	Reply	O	0
The result holds under general conditions - we only require to be a measurable function.	Reply	B-Reply	4
In our initial submission we didn't have enough time to convince ourselves that this was true, but now our Appendix contains a proof of this fact.	Reply	I-Reply	4
However, we point out if the starting distribution is discrete, or has some discrete portions (as it is obviously the case when the alphabet \mathcal{Z} is finite), it isn't clear that such a mapping can be found.	Reply	I-Reply	4
We do give examples in the paper of common settings where this mapping is guaranteed to exist.	Reply	I-Reply	4
[line_break_token][line_break_token]5-8) All suggestions taken	Reply	O	0

This paper introduces a model that blends ideas from generative topic models with those from recurrent neural network language models.	Review	O	0
The authors evaluate the proposed approach on a document level classification benchmark as well as a language modeling benchmark and it seems to work well.	Review	O	0
There is also some analysis as to topics learned by the model and its ability to generate text.	Review	O	0
Overall the paper is clearly written and with the code promised by the authors others should be able to re-implement the approach.	Review	O	0
I have 2 potentially major questions I would ask the authors to address:[line_break_token][line_break_token]1 - LDA topic models make an exchangability (bag of words) assumption.	Review	O	0
The discussion of the generative story for TopicRNN should explicitly discuss whether this assumption is also made.	Review	B-Review	1
On the surface it appears it is since y_t is sampled using only the document topic vector and h_t but we know that in practice h_t comes from a recurrent model that observes y_t-1.	Review	I-Review	1
Not clear how this clean exposition of the generative model relates to what is actually done.	Review	I-Review	1
In the Generating sequential text section it‚Äôs clear the topic model can‚Äôt generate words without using y_1 - t-1 but this seems inconsistent with the generative model specification.	Review	I-Review	1
This needs to be shown in the paper and made clear to have a complete paper.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]2 -  The topic model only allows for linear interactions of the topic vector theta.	Review	O	0
It seems like this might be required to keep the generative model tractable but seems like a very poor assumption.	Review	B-Review	2
We would expect the topic representation to have rich interactions with a language model to create nonlinear adjustments to word probabilities for a document.	Review	I-Review	2
Please add discussion as to why this modeling choice exists and if possible how future work could modify that assumption (or explain why it‚Äôs not such a bad assumption as one might imagine)[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]Figure 2 colors very difficult to distinguish.	Review	O	0
Thanks for your questions.&nbsp;[line_break_token][line_break_token]1.	Reply	O	0
We believe there was a misunderstanding of our proposed model.&nbsp;Unlike LDA, TopicRNN is a sequential model&nbsp;(as expressed in the generative process in the middle of page 4) and as such does not make the exchangeability assumption.&nbsp;[line_break_token]The inference network that produces the topic vector \theta used as bias takes as input Xc which is a bag of words representation of the document.&nbsp;Xc excludes stop words just as done in topic modeling.	Reply	O	0
This is where exchangeability is needed and maybe where the confusion is coming from.	Reply	B-Reply	1
But this is the inference network for \theta, not the actual generative model.	Reply	I-Reply	1
[line_break_token]&nbsp;[line_break_token]2.	Reply	O	0
There are three main reasons behind our choice of using the topic vector as bias instead of passing it into the hidden states of the RNN.&nbsp;[line_break_token][line_break_token]a) First, this enables us to have a clear separation of the contributions of global semantics and those of local dynamics.	Reply	O	0
The global semantics come from the topics which are meaningful when stop words are excluded.&nbsp;However, these stop words are needed for the local dynamics of the language model.	Reply	O	0
We hence achieve this separation of global vs local via a binary decision model for the stop words.	Reply	B-Reply	2
It is unclear how to achieve this if we pass the topics to the hidden states of the RNN.	Reply	I-Reply	2
This is because the hidden states of the RNN&nbsp;will account for all words (including stop words) whereas topics exclude stop words.&nbsp;Passing the topics through the hidden states of the RNN violates this.	Reply	O	0
[line_break_token][line_break_token]b) Second, we show empirical evidence that our approach does better than&nbsp;previous ways of integrating topic models into RNNs.&nbsp;This modeling choice also allows discovering interpretable topics within a single model.&nbsp;[line_break_token][line_break_token]c) Finally, this modeling choice allows easier end-to-end training of the model.&nbsp;And we argue that although we do not have the topics directly&nbsp;going into the hidden states, they will affect the whole trained model, including the hidden states&nbsp;due to our end-to-end training approach (unlike the previous work that use pre-trained topic models).	Reply	O	0
[line_break_token][line_break_token]We added this note on page 4 of the manuscript	Reply	O	0

This paper is built on a simple but profound observation: Frey's bits-back coding algorithm can be implemented much more elegantly when replacing arithmetic coding (AC) with asymmetric numerical systems (ANS), a much more recent development not known at the time, simply due to the fact that it encodes symbols in a stack-like fashion rather than queue-like.	Review	O	0
[line_break_token][line_break_token]This simple observation makes for an elegantly written paper, with promising results on MNIST.	Review	O	0
I truly enjoyed reading it, and I'm convinced that it will spark some very interesting further work in the field of compression with latent-variable models.	Review	O	0
[line_break_token][line_break_token]Having said that, I would like to point out some possible limitations of the proposed approach, which I hope the authors will be able to address/clarify:[line_break_token][line_break_token]1.	Review	O	0
At the beginning of section 2.1, the authors define the symbols as chained conditionals prod_n p(s_n | s_1 ... s_n-1), which is generally permissible in AC as well as ANS, as long as the decoding order is taken into account.	Review	B-Review	1
That is, in AC, the symbols need to be encoded starting with the first symbol in the chain (s_1), while in ANS, the symbols must be encoded starting with the last symbol in the chain, because the decoding order is inverted.	Review	I-Review	1
[line_break_token][line_break_token]In their description of BB-ANS, the authors omit the discussion of conditional chains.	Review	I-Review	1
It is unclear to me if a conditioning of the symbols is feasible in BB-ANS due to the necessity to maintain a strict decoding order.	Review	I-Review	1
It would be very helpful if the authors could clarify this, and update the paper accordingly, because this could present a serious limitation.	Review	I-Review	1
For instance, the authors simply extrapolate the performance of their method to PixelVAE; however, this model is autoregressive, so a conditioning of symbols seems necessary.	Review	I-Review	1
Similarly, in appendix A, the authors mention the work of Minnen et al. (	Review	I-Review	1
2018), where the same situation would apply, albeit one probabilistic level higher (on encoding/decoding the latents with an autoregressive prior).	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	1
Furthermore, in both cases (PixelVAE and Minnen et al.),	Review	I-Review	2
the symbols (s) and latents (y) are defined as jointly conditioned on each other (i.e., computing the posterior on one element of y requires knowledge of all elements of s, and computing the likelihood on one element of s requires knowledge of all elements of y).	Review	I-Review	2
This seems to imply that all operations pertaining to one data vector (i.e. to one image) would have to be done in a monolithic fashion, i.e.: first sample all elements of y from the stack, then encode all elements of s, and then encode all elements of y. Hence, if the goal is to compress only one image, the algorithm would never get to the point of reusing the "bits back", and the overhead of BB-ANS would be prohibitive.	Review	I-Review	2
It seems that in the MNIST experiments, the authors avoid this problem by always encoding a large number of images at a time, such that the overhead is amortized.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Similarly, although the compression of continuous-valued variables up to arbitrary precision is an exciting development and I do not wish to undermine the importance of this finding, it should be noted that the finer the quantization gets, the larger the potential overhead of the coding scheme will grow.	Review	B-Review	3
In practice, this would make it necessary to encode more and more images together, in order to still benefit from the method.	Review	I-Review	3
This would be a good point to make in the discussion.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
The authors state in the appendix that learned compression methods like Ball√© et al. (	Review	B-Review	4
2018) and Minnen et al. (	Review	I-Review	4
2018) could be improved by using BB-ANS.	Review	I-Review	4
The potential gain of BB-ANS for these models seems rather small, though, as the entropy of y must be larger or equal to the entropy of y conditioned on s: H[y] >= H[y|s], the latter of which should represent the potential coding gain.	Review	O	0
Ball√© et al. (	Review	B-Review	4
2018), however, found that the bits used to encode the hierarchical prior (i.e. H[y]) is only a small fraction of the total bitrate, thus upper bounding the potential gains for this type of model.	Review	I-Review	4
[line_break_token][line_break_token]Overall, I think this is a well-written, important and elegant paper, and I would like to see it accepted at this conference.	Review	O	0
If the authors can satisfactorily address some of the above potential limitations, it might turn out to be even better.	Review	O	0
[line_break_token]	Review	O	0
> 2.	Reply	O	0
Furthermore, in both cases (PixelVAE and Minnen et al.),	Reply	O	0
the symbols (s) and latents (y) are defined as jointly conditioned on each other (i.e., computing the posterior on one element of y requires knowledge of all elements of s, and computing the likelihood on one element of s requires knowledge of all elements of y).	Reply	O	0
This seems to imply that all operations pertaining to one data vector (i.e. to one image) would have to be done in a monolithic fashion, i.e.: first sample all elements of y from the stack, then encode all elements of s, and then encode all elements of y. Hence, if the goal is to compress only one image, the algorithm would never get to the point of reusing the "bits back", and the overhead of BB-ANS would be prohibitive.	Reply	O	0
It seems that in the MNIST experiments, the authors avoid this problem by always encoding a large number of images at a time, such that the overhead is amortized.	Reply	O	0
[line_break_token][line_break_token]2. (	Reply	O	0
RESPONSE) The point you make here is correct.	Reply	O	0
When there is no 'other information' to communicate, and only a single sample, or a very small number of i.i.d.	Reply	B-Reply	2
samples are to be compressed, our method is sub-optimal, and we should certainly have highlighted this limitation in our paper.	Reply	I-Reply	2
We have extended the first paragraph of Section 2.5 of our paper, emphasizing this point .	Reply	I-Reply	2
We have also renamed Section 2.5 to "Issues affecting the efficiency of BB-ANS".	Reply	I-Reply	2
[line_break_token][line_break_token]Nevertheless, we believe there are common use cases where a large enough number of (roughly) i.i.d.	Reply	I-Reply	2
samples need to be coded, one example being a person's photo library, stored on their computer or smartphone.	Reply	I-Reply	2
It is also possible that file meta-data could be used as a source of extra information.	Reply	I-Reply	2
We have yet to investigate whether there is sufficient information in typical real world meta-data to resolve this issue.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token][line_break_token]> 3.	Reply	O	0
Similarly, although the compression of continuous-valued variables up to arbitrary precision is an exciting development and I do not wish to undermine the importance of this finding, it should be noted that the finer the quantization gets, the larger the potential overhead of the coding scheme will grow.	Reply	O	0
In practice, this would make it necessary to encode more and more images together, in order to still benefit from the method.	Reply	O	0
This would be a good point to make in the discussion.	Reply	O	0
[line_break_token][line_break_token]3. (	Reply	O	0
RESPONSE) This is a good point, which is definitely worth mentioning.	Reply	O	0
We have added an extra paragraph discussing this point, near the end of Section 2.5.1.	Reply	B-Reply	3
We also mention that we found that increasing the precision past around 16 bits yielded no measurable gains in compression rate.	Reply	I-Reply	3
We think this is because the models we used (like most machine learning implementations) operated at 32 bit floating point precision.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token][line_break_token]> 4.	Reply	O	0
The authors state in the appendix that learned compression methods like Ball√© et al. (	Reply	O	0
2018) and Minnen et al. (	Reply	O	0
2018) could be improved by using BB-ANS.	Reply	O	0
The potential gain of BB-ANS for these models seems rather small, though, as the entropy of y must be larger or equal to the entropy of y conditioned on s: H[y] >= H[y|s], the latter of which should represent the potential coding gain.	Reply	O	0
Ball√© et al. (	Reply	O	0
2018), however, found that the bits used to encode the hierarchical prior (i.e. H[y]) is only a small fraction of the total bitrate, thus upper bounding the potential gains for this type of model.	Reply	O	0
[line_break_token][line_break_token]4. (	Reply	O	0
RESPONSE) Thanks a lot for pointing that out.	Reply	O	0
The paragraph in question here is not central to our paper.	Reply	B-Reply	4
However we feel that in spite of the limited gains in compression rate from BB-ANS in the case of the two papers mentioned, it's still worth us including this paragraph, particularly because it's quite possible that in future work similar to the two papers mentioned the gain from getting the bits back could be more significant.	Reply	I-Reply	4
We've reworded the paragraph, incorporating the bound which you mention.	Reply	I-Reply	4
[line_break_token][line_break_token]References[line_break_token]---------------[line_break_token][1] Johnson, M., Duvenaud, D., Wiltschko, A., Datta, S. and Adams, R. (2016).	Reply	O	0
Composing graphical models with neural networks for structured representations and fast inference.	Reply	O	0
In Advances in Neural Information Processing Systems (NIPS)	Reply	O	0

This work targets learning flow fields for two-dimensional Rayleigh-Benard convections inspired by hybrid RANS-LES turbulence models.	Review	O	0
[line_break_token][line_break_token]Internally, the approach employs three U-nets which are each trained to predict a 32 dimensional feature space from three variants of filtered velocity fields.	Review	O	0
These three feature spaces are (probably) concatenated and translated to an output velocity via a fourth U-net.	Review	O	0
While the overall architecture is intuitive, details are missing in the text.	Review	O	0
[line_break_token][line_break_token]I also assume that the network outputs w for timestep t+1, which is the sole input for the next evaluation of the network?	Review	B-Review	1
A regular flow solver is not used in conjunction with this network, but the results (i.e. sequences) shown are purely inferred by the network? (	Review	I-Review	1
I guess G2 uses multiple frames - what is used for T here, btw.?)	Review	I-Review	1
[line_break_token][line_break_token]These details, plus specifics of each layer should be written out (e.g. in the appendix), together with operations such as the merging of the three encoder outputs to make the work reproduicble.	Review	I-Review	2
I hope the authors can also clarify these points in the rebuttal.	Review	I-Review	2
[line_break_token][line_break_token]For a future version, I'd also recommend to rephrase equations (2) and (3).	Review	I-Review	3
The split into w, w-bar and w-tilde is not compatible with figure 2.	Review	I-Review	3
The figure uses the split from equations (6,7), so it would be good to make this clear via the notation.	Review	I-Review	3
[line_break_token][line_break_token]As training data, the model uses single RBC data set produced with a lattice boltzmann method.	Review	O	0
It's a pity only a single case is shown, as the method claims to learn a general turbulence model.	Review	B-Review	5
Do the authors have a second data set on which they could demonstrate the method?	Review	I-Review	5
This would show help to show generality of the approach.	Review	I-Review	5
[line_break_token][line_break_token]The RBC test case is used to train a nice range of different methods, from a simple ResNet to approaches from previous work, and the results are evaluated with a good range of turbulence metrics.	Review	O	0
These evaluations show nice improvements, e.g., the RMSEs over time in figure 4 are consistently lower.	Review	O	0
Unfortunately, it's not made clear which data is evaluated - is this a single training case, or e.g. averaged for the whole test set?	Review	B-Review	4
Likewise for figure 6 and 7.	Review	O	0
[line_break_token][line_break_token]Very minor, but I'd recommend to rephrase the last sentence of the fluid animation discussion.	Review	B-Review	6
Those works are part of computer science, which arguably also counts as science.	Review	I-Review	6
[line_break_token][line_break_token]Overall, I found the split into temporally and spatially filtered components of the flow field is an interesting one, and it's nice to see how well this seems to work.	Review	O	0
The paper certainly does not aim for new insight for deep learning methods in general, but provides an interesting application for turbulent flows that is evaluated with a nice amount of detail.	Review	O	0
If the authors can address the unclear points mentioned above, and maybe include a second test case that is evaluated on a subset of the different models, I think this paper could be included in the ICLR program.	Review	O	0
[line_break_token]	Review	O	0
hanks so much for your detailed comments.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt;&gt; I also assume that the network outputs w for timestep t+1, which is the sole input for the next evaluation of the network?	Reply	O	0
A regular flow solver is not used in conjunction with this network, but the results (i.e. sequences) shown are purely inferred by the network? (	Reply	O	0
I guess G2 uses multiple frames - what is used for T here, btw.?)	Reply	O	0
[line_break_token]Answer: Yes, for all CNN based models included in our paper, we make predictions in an autoregressive manner.	Reply	O	0
Suppose V is the Velocity field, N is the number of input frames and T is the timestamp for the last input frame.	Reply	B-Reply	1
The models took N initial frames V(T-N+1,..,T) as input to make the first prediction for the next step(T+1), then we feed the prediction at (T+1) back to the input V(T-N+2,..,T+1) to make predictions for time step T+2, and repeat for 60 times.	Reply	I-Reply	1
 \bar{w} is a weighted average, T here is the moving average window size.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt;&gt;&gt; These details, plus specifics of each layer should be written out (e.g. in the appendix), together with operations such as the merging of the three encoder outputs to make the work reproducible.	Reply	O	0
I hope the authors can also clarify these points in the rebuttal.	Reply	O	0
[line_break_token]Answer:  The detailed numbers of each layer are shown in Figure 2.	Reply	O	0
The merging of the three encoder outputs is simply summation.	Reply	B-Reply	2
We will open source our implementation in the final version.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt;&gt;&gt; For a future version, I'd also recommend to rephrase equations (2) and (3).	Reply	O	0
The split into w, w-bar and w-tilde is not compatible with figure 2.	Reply	O	0
The figure uses the split from equations (6,7), so it would be good to make this clear via the notation.	Reply	O	0
[line_break_token]Answer: Thanks for pointing it out.	Reply	O	0
We modified those two equations in the updated version.	Reply	B-Reply	3
[line_break_token][line_break_token]&gt;&gt;&gt; Unfortunately, it's not made clear which data is evaluated - is this a single training case, or e.g. averaged for the whole test set?	Reply	O	0
Likewise for figure 6 and 7.	Reply	O	0
[line_break_token]Answer: All evaluation metrics are averaged over the whole test set.	Reply	O	0

&gt; What is the specific question/problem tackled by the paper?	Review	O	0
[line_break_token]This paper tackles a restricted multi-task setting where the task is known.	Review	B-Review	1
The main contribution is a new architecture for training a task conditional model.	Review	I-Review	1
The new architecture is reminiscent of an encoder-decoder-classifier with ladder (latent) connections, the decoder is conditioned on task ID.	Review	I-Review	1
The claim is this is a type of modulation, it is unclear.	Review	I-Review	1
Results on three multi-task datasets show that the proposed method is slightly better than compared methods and single task learning.	Review	I-Review	1
There is no theory or loss function to analyze.	Review	I-Review	1
[line_break_token][line_break_token]&gt; Is the approach well motivated, including being well-placed in the literature?	Review	O	0
[line_break_token]In my opinion, this is lacking.	Review	B-Review	2
The assumption that task ID is known is fairly severe.	Review	I-Review	2
Unfortunately the prior works cited also have this restriction, whereas few papers under the topic of continual learning have removed this limitation.	Review	I-Review	2
This assumption/drawback needs to be clearly mentioned in the paper and discussed if it is realistic?	Review	I-Review	2
A related shortcoming is that the training data simultaneously comes from all the tasks, whereas prior work has looked at the more interesting setup where tasks arrive sequentially and incrementally.	Review	I-Review	2
[line_break_token]- Reference [1] seems relevant and should be cited as it shows context dependent gating of tasks / modulation as well.	Review	I-Review	2
Other missing references e.g. learning without forgetting (LwF) [2] and [3]. [line_break_token]- There is not a clear explanation to think that this is modulation since the result is only passed through a residual connection.	Review	I-Review	2
More importantly there is no discussion on these important issues.	Review	I-Review	2
I found the writing to be brief and sketched.	Review	I-Review	2
[line_break_token]- in the introduction, it would be good to define multi-task learning with the assumption made clear.	Review	I-Review	2
It would be good to introduce what you mean by TD and BU clearly[line_break_token]- Another drawback is assuming the tasks being encoded as integers, whereas there might be a continuous task space with interpolation, or hierarchical task structure.	Review	I-Review	2
[line_break_token]- "However, all of these works modulate the recognition network[line_break_token]channel-wise, using the same modulation vector for all the spatial dimension of the feature-maps." -	Review	I-Review	2
why is this not enough?	Review	I-Review	2
A nontrivial explanation or discussion is needed.	Review	I-Review	2
Simply extending to W(t, y, x, ch) would increase performance by a little.	Review	I-Review	2
[line_break_token]- how is the proposed model different from a conditional model like a task conditional classifier?	Review	I-Review	2
Also in experiments.	Review	I-Review	2
[line_break_token]- How is the proposed model different from an encoder-decoder?	Review	I-Review	2
The impact of "modulation" is not clear.	Review	I-Review	2
[line_break_token]- "We can scale the number of tasks with no additional layers." -	Review	I-Review	2
task conditional classifier can also scale in this way to the number of tasks.	Review	I-Review	2
This claim is not valid.	Review	I-Review	2
[line_break_token]- Page 3: "uncorrelated gradients from the different tasks" - need not be uncorrelated, but still can be interfering[line_break_token]- next about Kendall (2018) and Sener (2018) - need to compare and contrast to them.	Review	I-Review	2
[line_break_token]- Last para on page 3 seems not relevant.	Review	I-Review	2
[line_break_token]- Modulation equations: this seems specific to CNNs.	Review	I-Review	2
How would you extend this technique to beyond CNNs to recurrent units or even simpler MLPs?	Review	I-Review	2
Modulation as a technique has been successfully applied in these architectures as well.	Review	I-Review	2
[line_break_token]- "added to the input tensor X through a residual connection" - this is not clear at all.	Review	I-Review	2
Are the residual connections not shown in Fig 1(d)?	Review	I-Review	2
[line_break_token]- "it to be unfeasible due to their large dimensions" - can you explain please?	Review	I-Review	2
later you say "To avoid the unfeasible computation burden of directly optimizing W"[line_break_token]- Fig 1d, would be good to mark the modulation arrows in a different color[line_break_token][line_break_token]&gt; Does the paper support the claims?	Review	O	0
This includes determining if results, whether theoretical or empirical, are correct and if they are scientifically rigorous.	Review	B-Review	3
[line_break_token]Having said that, I like the experimental section even in the restricted setup.	Review	I-Review	3
But a lot of details are missing.	Review	I-Review	3
It is not surprising that there is slight increase in performance over channel modulation due to the increase expressivity.	Review	I-Review	3
[line_break_token]- table 1: why is there degradation in the LL task across all methods?	Review	I-Review	3
the introduction of an additional task seems to bring the performance back up.	Review	I-Review	3
It seems to be a weakness of your method.	Review	I-Review	3
Please improve the discussion.	Review	I-Review	3
I'm inclined to think that the tasks are not uncorrelated, as claimed by the authors.	Review	I-Review	3
[line_break_token]- table 1: how did you arrive at the number of parameters like 1.12x?	Review	I-Review	3
Doesn't the separate BU and TD nets mean you have at least 2x parameters compared to single task?	Review	I-Review	3
It seems the larger number of params in single task is mainly coming from the hidden layers?	Review	I-Review	3
[line_break_token]- table 1: it would be fair for the comparison methods to have equal number of parameters as the proposed method.	Review	I-Review	3
[line_break_token]- Missing experimental comparison to Kendall et.	Review	I-Review	3
al.	Review	I-Review	3
2018[line_break_token]- Missing details about reproduction of results from Sener (2018)[line_break_token]- An important baseline would be to show image sensitive full tensor modulation without the new architecture.	Review	I-Review	3
Similar to XdG.[line_break_token]- Another baseline should be a task-conditional classifier that takes task as input along with the image.	Review	I-Review	3
[line_break_token]- ablation study: what are the auxiliary losses?	Review	I-Review	3
I could not find any details.	Review	I-Review	3
[line_break_token]- The third experiment with CUB seems to use a different loss function that the other methods.	Review	I-Review	3
This is somewhat hard to evaluate.	Review	I-Review	3
[line_break_token]- number of parameters are not reported for the CUB experiment[line_break_token]- "where only a single pixel is labeled as foreground, blurred by a Gaussian kernel" needs more details about the smoothing[line_break_token]- In the CUB experiment, due to lateral connections, the top-down result 224x224 image is not the only input to the BU2 classifier, the interpretability argument is weak.	Review	I-Review	3
[line_break_token]- Why did you choose these 4 questions from CLEVR?	Review	I-Review	3
There are many interesting types of questions that can be handled.	Review	I-Review	3
[line_break_token][line_break_token]	Review	O	0
irst of all, thanks for the thoughtful review.	Reply	O	0
[line_break_token][line_break_token]Regarding your general concern about the scope of the paper (known task-ID is a severe condition, continual learning is more interesting).	Reply	O	0
[line_break_token]We agree that there are other realistic setting but we also follow an interesting, realistic and an active line of research.	Reply	B-Reply	2
References [1], [2], [3], [4] all uses a setting similar to ours (modulation networks with a known task-ID).	Reply	I-Reply	2
Reference [4] is interesting in this aspect as it applies channel-wise modulation networks with a given task-ID to continual learning applications.	Reply	I-Reply	2
We, on the other hand, continue this line of research by extending channel-wise modulation tensor-modulation ...[line_break_token][line_break_token][1]  A Modulation Module for Multi-task Learning with Applications in Image Retrieval, ECCV 2018[line_break_token][2]  Attentive Single-Tasking of Multiple Tasks, CVPR 2019[line_break_token][3] Many Task Learning with Task Routing, arxiv preprint[line_break_token][4] Superposition of many models into one, arxiv preprint[line_break_token][line_break_token]Request - you gave several reference numbers in the review, but the references were not listed.	Reply	O	0
can you add them?	Reply	O	0
[line_break_token][line_break_token]We next go through specific comments:[line_break_token][line_break_token]A major remark was to justify and quantify our main technical contribution (adding 1.	Reply	B-Reply	2
spatial-wise and 2, image-aware modulation to the existed channel-wise modulation architectures.	Reply	I-Reply	2
We motivated our contribution in the introduction (page 2, paragraph 2) and now added to specifically quantify the contribution of each of our additions, summarized in table 2a, section 4.3.2.	Reply	I-Reply	2
[line_break_token][line_break_token]We rewrote section 3 (Approach) to better explain our modulation scheme.	Reply	I-Reply	2
We treat it as a modulation because adding the residual connections change x*w to x*(w+1).	Reply	I-Reply	2
Following your question, we have also explained why a naive extension of [1] is infeasible (briefly, the number of parameters to optimize is to large and depend on H, W and the number of tasks - it cannot be applied to large images and is not scalable with the number of tasks).	Reply	I-Reply	2
[line_break_token][line_break_token]We added an appendix with a calculation of the number of parameters.	Reply	I-Reply	2
Briefly, for K tasks ‚Äì a single task networks use one separate network for each task (K times the number of parameters found in a single base network), Multi-branched architectures add several branches on a common backbone (one backbone + the number of parameters within a branch times K), our architecture uses only one branch and our TD usually has much less parameters than the BU backbone (because if a convolutional stage uses a series of convolutions like (256-&gt;512, 512-&gt;512) we use (512-&gt;256, 256-&gt;256)).	Reply	O	0
[line_break_token][line_break_token]We reproduced the results of Sener(2018) from their official github code.	Reply	B-Reply	2
      [line_break_token][line_break_token]Regarding the reduced performance on the LL digit:[line_break_token]Several M-MNIST images are demonstrated in figure 2 in the article.	Reply	O	0
The digits are i.i.d.	Reply	B-Reply	3
between images and between tasks (uncorrelated).	Reply	I-Reply	3
We believe that the degradation of the LL task accuracy is because the specific overlap areas of this task/location carry useful information for the classification process.	Reply	I-Reply	3
[line_break_token][line_break_token]We have updated the article and uploaded a revised version based on the reviews	Reply	O	0

This paper presents learning a spatio-temporal embedding for video instance segmentation.	Review	O	0
With spatio-temporal embedding loss, it is claimed to generate temporally consistent video instance segmentation.	Review	O	0
The authors show that the proposed method performs nicely on tracking and segmentation task, even when there are occlusions.	Review	O	0
[line_break_token][line_break_token]Overall, this paper is well-written.	Review	B-Review	1
Section 3 clearly explains the loss functions.	Review	I-Review	1
The main idea is not very complex, but generally makes sense.	Review	I-Review	1
The authors mention that scenes are assumed to be mostly rigid, and appearance change is mostly due to the camera motion.	Review	I-Review	1
I would like to see more argument about this, as there are cases if this is obviously not true; for instance, human changes pose significantly.	Review	I-Review	1
If we limit the range of discussion to some narrow domain, such as self-driving, this might be more valid, but we may want to see some discussion about validity of this assumption.	Review	I-Review	1
[line_break_token][line_break_token]Some modules are not full explained in detail.	Review	I-Review	2
For example, what is the background mask network?	Review	I-Review	2
Which model was used, and how was it trained?	Review	I-Review	2
[line_break_token][line_break_token]In experiment, the proposed method shows nice score on MOTSA and sMOTSA, but all other metrics, it is on the worse side.	Review	I-Review	3
The authors are encouraged to discuss more about the metrics and experimental results with the other metrics as well.	Review	I-Review	3
Other than these, the experiment was well-designed and conducted.	Review	I-Review	3
any thanks for the feedback.	Reply	O	0
Here‚Äôs our answer to the concerns you have raised:[line_break_token][line_break_token]1. ‚	Reply	O	0
ÄúThe authors mention that scenes are assumed to be mostly rigid, and appearance change is mostly due to the camera motion.	Reply	O	0
I would like to see more argument about this, as there are cases if this is obviously not true; for instance, human changes pose significantly.	Reply	O	0
If we limit the range of discussion to some narrow domain, such as self-driving, this might be more valid, but we may want to see some discussion about validity of this assumption.	Reply	O	0
‚Äù[line_break_token][line_break_token]Our model learns depth in a self-supervised way using a photometric reconstruction loss, which operates under the assumption of a moving camera and a static scene.	Reply	O	0
When this hypothesis does not hold true, for example when the camera is stationary or some scene objects are in motion, performance can rapidly deteriorate.	Reply	B-Reply	1
During test time, objects that are typically seen in motion during training are then assigned an infinite depth value.	Reply	I-Reply	1
To overcome this problem, we simply mask during training the pixels that do not change appearance from frame to frame (details in Appendix A.1).	Reply	I-Reply	1
Since these pixels are often associated with objects moving at the same velocity as the camera, or to scenarios when the camera stops moving, this masking approach effectively removes the pixels that violates the rigid scene assumption.	Reply	I-Reply	1
[line_break_token][line_break_token]During inference however, our model is able to correctly predict the depth maps of moving objects: see some examples here <a href="https://drive.google.com/open?id=1u-kGxQEWIoC6FguUiXFHyxUcOiG2iIIf" target="_blank" rel="nofollow">https://drive.google.com/open?id=1u-kGxQEWIoC6FguUiXFHyxUcOiG2iIIf</a> [line_break_token][line_break_token]2. "	Reply	O	0
Some modules are not full explained in detail.	Reply	O	0
For example, what is the background mask network?	Reply	O	0
Which model was used, and how was it trained?"	Reply	O	0
[line_break_token][line_break_token]The background mask network is described in Appendix A.1: it is a ResNet network with a U-net structure and was trained on KITTI.	Reply	B-Reply	2
[line_break_token][line_break_token]3. "	Reply	O	0
In experiment, the proposed method shows nice score on MOTSA and sMOTSA, but all other metrics, it is on the worse side.	Reply	O	0
The authors are encouraged to discuss more about the metrics and experimental results with the other metrics as well."	Reply	O	0
[line_break_token][line_break_token]Please refer to the general response (point 3)	Reply	B-Reply	3

This work is motivated by the widely recognized issue of over-parameterization in modern neural nets, and proposes a clever template sharing design to reduce the model size.	Review	O	0
The design is sound, and the experiments are valid and thorough.	Review	O	0
The writing is clear and fluent.	Review	O	0
[line_break_token][line_break_token]The reviewer is not entirely sure of the originality of this work.	Review	O	0
According to the sparse 'related work' section, the contribution is novel, but I will leave it to the consensus of others who are more versed in this regard.	Review	O	0
[line_break_token][line_break_token]The part that I find most interesting is the fact that template sharing helps with the optimization without even reducing the number of parameters, as illustrated in CIFAR from Table 1.	Review	O	0
The trade-off of accuracy and parameter-efficiency is overall well-studied in CIFAR and ImageNet, although results on ImageNet is not as impressive.	Review	O	0
[line_break_token][line_break_token]Regarding the coefficient alpha, I'm not sure how cosine similarity is computed.	Review	B-Review	1
I have the impression that each layer has its own alpha, which is a scalar.	Review	I-Review	1
How is cosine similarity computed on scalars?	Review	I-Review	1
[line_break_token][line_break_token]In the experiments, there's no mentioning of the regularization terms for alpha, which makes me think it is perhaps not important?	Review	I-Review	2
What is the generic setup?	Review	I-Review	2
[line_break_token][line_break_token]In summary, I find this work interesting, and with sufficient experiments to backup its claim.	Review	O	0
On the other hand, I'm not entirely sure of its novelty/originality, leaving this part open to others.	Review	B-Review	3
With respect to novelty, we do not believe there is any existing work that utilizes a parameter sharing scheme toward the objective we accomplish here: training a deep network and then folding it into a recurrent form.	Reply	B-Reply	3
 Please also see our detailed reply to AnonReviewer2.	Reply	I-Reply	3
[line_break_token][line_break_token]1- Regarding the coefficient alpha, I'm not sure how cosine similarity is computed.	Reply	O	0
I have the impression that each layer has its own alpha, which is a scalar.	Reply	O	0
How is cosine similarity computed on scalars?	Reply	O	0
[line_break_token][line_break_token]Each layer i has its own alpha parameter, denoted by alpha^(i) in the manuscript (refer to equation 1 on page 3), but each alpha is a k-dimensional vector, where k is the number of templates to which that layer has access.	Reply	B-Reply	1
For the SWRN-L-w-k models we use in the experiments, the same k denotes the number of templates each layer can use, so the dimensionality of each alpha ranges from 1 (in this case it‚Äôs just a scalar) to 6 in our experiments.	Reply	I-Reply	1
[line_break_token][line_break_token]We made alpha bold in the current version of the manuscript to clarify that it is a vector (except when k=1).	Reply	O	0
[line_break_token][line_break_token]2 - In the experiments, there's no mentioning of the regularization terms for alpha, which makes me think it is perhaps not important?	Reply	O	0
What is the generic setup?	Reply	O	0
[line_break_token][line_break_token]We tried applying L2 regularization to the alpha parameters in our initial experiments, but observed a performance drop, so all reported experiments have no regularization on the alphas.	Reply	B-Reply	2
[line_break_token][line_break_token]As for the recurrence regularizer described in the end of Section 3.2, where we regularize the Layer Similarity Matrix, it was only used for the experiments in Section 4.4 -- more specifically, the ‚ÄúSCNN, lambda_R = 0.01‚Äù model depicted in Figure 5.	Reply	I-Reply	2
It was not used for any other experiments, meaning that the observed patterns (e.g. the Layer Similarity Matrices in Figure 4) emerge naturally during optimization, where neither the alphas nor the LSMs had any regularization	Reply	I-Reply	2

*Summary*[line_break_token]This paper leverages the piecewise linearity of predictions in ReLU neural networks to encode and learn piecewise constant predictors akin to oblique decision trees (trees with splits made on linear combinations of features instead of axis-aligned splits).	Review	O	0
The core observation is that the Jacobian of a ReLU network is piecewise constant w.r.t to the input.	Review	O	0
This Jacobian is chosen to encode the hard splits of a decision tree.	Review	O	0
The paper establishes an exact equivalence between decision trees and a slightly modified form of the locally constant networks (LCN).	Review	O	0
The LCN used for experiments is slightly relaxed to allow for training, including "annealing" from a the softplus nonlinearity to ReLU during training, adding one or more output layers to perform the final prediction, and training with connection dropout.	Review	O	0
Experiments show LCN models outperform existing methods for oblique decision trees, but ensembles are often matched or outperformed by random forests.	Review	O	0
[line_break_token][line_break_token]*Rating*[line_break_token]Perhaps the greatest attribute of decision trees is utter simplicity. (	Review	O	0
The second best attribute the out-of-the-box competitive accuracy of tree ensembles on a wide variety of problems.)	Review	O	0
An argument to be made for this paper is that it leverages the machinery of learning DNNs to learn more powerful, oblique tree-like models.	Review	O	0
The counterpoint is that despite the added complication, it's still often beaten by ensembles of CART trees.	Review	O	0
Overall, the idea is clever, the presentation could be improved slightly, and the experiments raise existential questions for this kind of work.	Review	O	0
My current rating is weak reject.	Review	O	0
[line_break_token][line_break_token](1) It's difficult to know how LCNs should be compared to traditional decision trees, with accuracy, number of parameters, prediction speed, and training time/parallelism as viable components.	Review	O	0
The paper focuses almost exclusively on accuracy, while cross-validating over model sizes and other hyperparameters.	Review	B-Review	1
This is a reasonable choice, though a discussion of model size and prediction speed would be welcome.	Review	I-Review	1
I do have two significant questions about the experiments:[line_break_token][line_break_token](2) It seems unfair that LCN has access to one or more hidden layers between the splits and the final output, denoted g_\phi.	Review	O	0
Would competing decision tree models improve with such a layer learned and appended to the final tree?	Review	B-Review	2
Would LCN suffer from using a tabular representation like the others?	Review	I-Review	2
[line_break_token][line_break_token](3) Despite the assertion that these are datasets that necessitate tree-like predictors, the LLN method outperforms LCN and the trees on 4/5 datasets and is competitive with ensemble methods.	Review	O	0
While not explicitly stated, am I correct that LLN is essentially a traditional ReLU-network?	Review	B-Review	3
If high accuracy is the goal, then why should I go to the trouble of training LCN when a traditional DNN is better.	Review	I-Review	3
And if a tree is needed, then LCNs should be evaluated on more than just accuracy.	Review	I-Review	3
[line_break_token][line_break_token](4) LCNs seem to present a less bulky alternative to e.g. Deep Neural Decision Trees (<a href="https://arxiv.org/abs/1806.06988)," target="_blank" rel="nofollow">https://arxiv.org/abs/1806.06988),</a> but that work should be cited and discussed[line_break_token][line_break_token](5) The proof sketch in Section 3.6 of the equivalence between the "standard architecture" and decision trees is difficult to understand and not convincing. (	Review	O	0
On second reading I noticed the subtle vector "\mathbf 0" indicating that all entries of "\grad_x a^i_1" are zero.	Review	B-Review	5
Some further exposition and enumeration of steps would clear up confusion.)	Review	I-Review	5
[line_break_token][line_break_token](6) Overall the presentation is reasonable, other than the notes below.	Review	O	0
I did find myself searching back over the (dense) notation section and following sections looking for definitions of variables and terms used later.	Review	B-Review	6
Consider better formatting (e.g. more definitions in standalone equations), strategic pruning of some material to make it less dense, and repeating some definitions in line (e.g. see below for "p7:... remind the reader").	Review	I-Review	6
[line_break_token][line_break_token]*Notes*[line_break_token](Spelling typos throughout; most are noted below)[line_break_token]p3: clarify in 3.1/3.3 that L is the number of outputs[line_break_token]p4: "interpred"[line_break_token]p5: "aother"[line_break_token]p5: Theorem 2 proof: note that the T/T' notation is capturing left/right splits[line_break_token]p5: "netwoworks"[line_break_token]p5: "Remark 5 is important for learning shallow...": should "shallow" be "narrow" instead?	Review	I-Review	6
[line_break_token]p7: in the first paragraph, remind the reader of the definitions of √µ^M and J_x √£^M[line_break_token]p7: "Here we provide a sketch of [the] proof"[line_break_token]p7: "unconstraint" should be "unconstrained"[line_break_token]p7: "...can construct a [sufficiently expressive] network g_\theta"[line_break_token]p7: "simlify"[line_break_token]p9: Table 2: instead of "2nd row", ..., use "1st section", ...; also consider noting which methods are introduced in this paper[line_break_token]p9: Figure 2: text is too small[line_break_token]	Review	I-Review	6
2) In short, we have the following ordering of expressiveness *given a fixed depth*: oblique decision trees &gt; canonical (tabular) LCNs &gt;= standard LCNs.	Reply	O	0
[line_break_token][line_break_token]Note that each activation pattern of f yield a *constant* Jacobian, so we can write the Jacobian as Jacobian(o(x)), where o is the activation pattern of x. [line_break_token][line_break_token]Then, standard LCNs can be written as the mapping: [line_break_token]        g_\phi(Jacobian(o(x))).	Reply	B-Reply	2
[line_break_token]In contrast, canonical (tabular) LCNs yield the mapping:[line_break_token][tab_token]g(o(x)).	Reply	I-Reply	2
[line_break_token]Hence, the tabular case cannot be less powerful than using embeddings (Jacobians), since we can always set the table as g(  ) = g_\phi(Jacobian(  )).	Reply	I-Reply	2
[line_break_token][line_break_token]By the proof of Theorem 3, we can again transform such tabular LCN to a decision tree with the same depth, so the canonical LCNs are not more powerful than oblique decision trees.	Reply	I-Reply	2
Furthermore, due to how the locally linear regions of f can be partitioned, canonical LCNs are strictly less powerful than oblique decision trees given a fixed depth M as proved in Sec.	Reply	I-Reply	2
3.5.	Reply	I-Reply	2
[line_break_token][line_break_token]Hence, we obtain the claimed ordering.	Reply	I-Reply	2
In fact, by Theorem 8 (updated, originally given as a sketch of proof), we can even prove standard LCNs = canonical LCNs.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token](3) Yes, LLNs are ReLU networks.	Reply	O	0
The point of including LLN is to compare it with ALCN, since both are continuous functions and thus much more powerful than tree methods.	Reply	B-Reply	3
We show that ALCN often outperforms LLN.	Reply	I-Reply	3
[line_break_token][line_break_token]If high accuracy is the only goal, currently random forests work well for these chemical/tabular data, outperforming neural networks with ReLU activations by a large margin.	Reply	I-Reply	3
However, please see our general response above for why LCN still provides new insights in this setting.	Reply	I-Reply	3
[line_break_token][line_break_token]If a tree model is needed, clearly LCNs are much better than traditional oblique decision trees: we can often get 10% absolute improvements in testing AUC.	Reply	I-Reply	3
Since LCN can always be explicitly converted to an oblique decision tree, the only difference *in testing time* between oblique decision trees and LCNs is the accuracy.	Reply	I-Reply	3
Other factors are discussed in (1).	Reply	I-Reply	3
[line_break_token][line_break_token](4) Thank you for the reference.	Reply	O	0
It seems a relevant paper that also uses deep networks to learn decision trees.	Reply	B-Reply	4
The paper focused on axis-parallel decisions (traditional decision trees), while we work on oblique decisions.	Reply	I-Reply	4
We will cite and discuss the paper in the camera-ready version.	Reply	I-Reply	4
[line_break_token][line_break_token](5) Thank you for the feedback.	Reply	O	0
The sketch of the proof is now replaced by a formal theorem with proof in Appendix A.2.	Reply	B-Reply	5
[line_break_token][line_break_token](6) and *Notes*: Thank you for the comments.	Reply	O	0
The typos have been addressed, and we will improve the other presentation issues in later revision.	Reply	B-Reply	6
[line_break_token][line_break_token]Re "Remark 5 is important for learning shallow..." Thank you for pointing this out.	Reply	O	0
Here we meant that given a fixed number of neurons, the one neuron per layer setting is the most powerful architecture.	Reply	B-Reply	6
[line_break_token][line_break_token]Minor technical clarification: we ‚Äúanneal‚Äù LCNs during training, but the LCNs used in testing time are indeed piece-wise constant (not relaxed).	Reply	I-Reply	6
Adding any number of layers mapping from the Jacobian to the prediction does not affect the piece-wise constant nature.	Reply	I-Reply	6

This paper presents an improved formulation of CNN, aiming to separate geometric transformation from inherent features.	Review	O	0
The network can estimate the transformation of filters given the input images.	Review	O	0
[line_break_token][line_break_token]This work is based on a solid technical foundation and is motivated by a plausible rationale.	Review	O	0
Yet, the value of this work in practice is subject to questions:[line_break_token][line_break_token](1) It relies on the assumption that the input image is subject to a transformation on a certain Lie group (locally).	Review	O	0
Do such transformations constitute real challenges in practice?	Review	B-Review	1
State-of-the-art CNNs, e.g. ResNet, are already quite resilient to such local deformations.	Review	I-Review	1
What such components would add to the state of the art?	Review	I-Review	1
Limited experiments on Cifar-10 does not seem to provide a very strong argument.	Review	I-Review	1
[line_break_token][line_break_token](2) The computational cost is not discussed.	Review	O	0
Thank you very much for your comments and questions.	Reply	O	0
[line_break_token][line_break_token]The main goal of the Cifar10 experiments was to show, that one can replace the pixel-basis with a frame that has additional desirable properties like the steerability without decreasing performance.	Reply	O	0
Additionally, we were able to show that steerable frames can consistently increase the performance of SOTA networks given they are suitable for natural image data.	Reply	O	0
Note that we have added SOTA Densenet models to table 2, in which we were able to improve performance by substituting the pixel-basis with frames as well as in the Resnet models, substantiating the generality of our observations.	Reply	O	0
[line_break_token][line_break_token](1) Do such transformations constitute real challenges in practice?	Reply	O	0
What such components would add to the state of the art?	Reply	O	0
[line_break_token][line_break_token]Being able to replace the pixel-basis by steerable frames leads us to our proposed Dynamic Steerable Frame Networks (DSFNs), a method that continuously transforms filters conditioned on the input.	Reply	B-Reply	1
DSFNs are locally adaptive, interpretable and data-efficient.	Reply	I-Reply	1
We compare our DSFNs to other adaptive methods.	Reply	I-Reply	1
In this domain Dynamic Filter Networks (DFNs) and Spatial Transformer Networks (STNs) constitute the state of the art.	Reply	I-Reply	1
[line_break_token][line_break_token]Dynamic Filter Networks learn location varying filters in an unconstrained manner and generate any type of filter kernel for each location in the input, this approach is very data-inefficient as it has many unconstrained parameters and the transformations have no clear geometrical meaning.	Reply	I-Reply	1
Spatial Transformer Networks transform the whole feature stack globally under predefined geometrical parameters.	Reply	I-Reply	1
The method regularizes the additional parameters introduced by it effectively and achieves global transformation invariance.	Reply	I-Reply	1
[line_break_token][line_break_token]STNs are not locally adaptive, thus they fail in many cases where it is not beneficial to transform the image globally as it would destroy discriminative information (deformable objects, many objects, dynamic movements) or where global registration is anyway performed as a standard preprocessing step (medical imaging data).	Reply	I-Reply	1
The hand-gesture experiment is an example of a whole range of tasks where STNs fail, as they are not suitable for moving deformable objects.	Reply	I-Reply	1
[line_break_token][line_break_token]DFNs are black boxes and not data-efficient.	Reply	I-Reply	1
They introduce many unconstrained parameters and are thus not suited for limited-data scenarios.	Reply	I-Reply	1
At the same time, it is not possible to check if the model converges or does something meaningful.	Reply	I-Reply	1
Such a behavior is undesirable when data is limited and interpretability is key, like in medical imaging.	Reply	I-Reply	1
Further, they fail to generate very fine-grained local adaption as can be achieved with a well-regularized DSFN, illustrated with the edge-detection experiment.	Reply	I-Reply	1
This makes them inferior for tasks like segmentation, even in unlimited data scenarios.	Reply	I-Reply	1
[line_break_token][line_break_token]Our proposed DSFNs transform filters locally in a continuous manner.	Reply	I-Reply	1
This allows the model to precisely adapt filters to local features in the image.	Reply	I-Reply	1
It can do so in a data-efficient manner.	Reply	I-Reply	1
One learned filter can be applied to all its transformations, alleviating the necessity to learn one filter for each orientation or each different scale, effectively representing infinitely many geometrical variants of the same filter.	Reply	I-Reply	1
[line_break_token][line_break_token]In both experiments, our proposed method substantially outperform DFNs and STNs and we are able to explain why this is the case.	Reply	I-Reply	1
In conclusion, our proposed Dynamic Steerable Frame Networks are able to fill the gap between adaptive state-of-the-art Dynamic Filter Networks and Spatial Transformer Networks.	Reply	I-Reply	1
[line_break_token][line_break_token](2) The computational cost is not discussed.	Reply	O	0
[line_break_token][line_break_token]Frame-based CNNs have the same runtime as vanilla CNNs.	Reply	B-Reply	2
The Dynamic Steerable Frame Networks have the same runtime as vanilla Dynamic Filter Networks.	Reply	I-Reply	2
Besides that, there is a whole body of research on how to speed up convolution with analytic frame functions, with strategies like recursive filtering, showing promise to potentially decrease runtime.	Reply	I-Reply	2
[line_break_token][line_break_token]Thank you once again for your review, we have updated the manuscript to include our answers.	Reply	O	0
[line_break_token][line_break_token]Let us know if this answers your questions	Reply	O	0

This paper proposes semi-structured neural filter composed of structured Gaussian filters and the usual structure-agnostic free-form filters found in neural networks.	Review	O	0
They are optimized using end-to-end training.	Review	O	0
Effectively, this lead to increased receptive field size and shape with just few additional parameters.	Review	O	0
Further, this module is architecture agnostic and can also be integrated with any dynamic inference models.	Review	O	0
Specifically, when applied on deformable convolutional filters, the deformation at each input can be structured using gaussian filters.	Review	O	0
Empirical experiments suggest that when integrated with state-of-the-art semantic segmentation architectures, the absolute accuracy on Cityscapes improves by 2%.	Review	O	0
Large improvement in seen on naive / sub-optimal architectures for segmentation.	Review	O	0
[line_break_token][line_break_token]Given that this is first work which demonstrates the efficient composition of classic structured filters with neural layer filters, I believe that research community will benefit to good extent if this paper is accepted.	Review	O	0
[line_break_token][line_break_token]Clarification:[line_break_token]1.	Review	O	0
I note that single gaussian is shared across different free-form filters.	Review	B-Review	1
Is same gaussian also shared across input channels ?	Review	I-Review	1
[line_break_token]2.	Review	O	0
For dynamic inference, what is the sampling resolution used ?	Review	B-Review	2
How is it related to diagonal elements of covariance ?	Review	I-Review	2
2\sigma ?	Review	I-Review	2
[line_break_token]3.	Review	O	0
In case of blurring and resampling, does the model learn another filter for sampling ?	Review	B-Review	3
To me, sampling seems similar to dynamic inference operation but with static parameters.	Review	I-Review	3
[line_break_token]4.	Review	O	0
As noted in paper, blurring is fundamental hwen dilating.	Review	B-Review	4
Does DRN-A and DLA-34 models used for comparison in Table 1 includes blurring prior to dilation ?	Review	I-Review	4
[line_break_token][line_break_token]Additional experiment:[line_break_token]1.	Review	O	0
Does improved receptive field size and shape also lead to improvement in other downstream tasks such as classification, object detection, depth estimation etc. ?	Review	B-Review	5
[line_break_token]2.	Review	O	0
Table 4 shows that the networks with reduced depth when integrated with composed filters can perform as well as large networks.	Review	B-Review	6
Does this holds true when extended to above tasks ?	Review	I-Review	6
[line_break_token]3.	Review	O	0
I note that in all the presented results, the composed filters are only included at the last few layers.	Review	B-Review	7
How the results prunes out when included at the lower as well as at the intermediate layers ?	Review	I-Review	7
Please include a plot of accuracy vs depth (at which it is included).	Review	I-Review	7
[line_break_token]4.	Review	O	0
I am glad to note that Gaussian deformable models performs as good as free-form deformable models with largely reduced parameters.	Review	B-Review	8
Can you please add total network parameters comparison in Table 5 ?	Review	I-Review	8
Further, are these also included only at the top few layers ?	Review	I-Review	8
[line_break_token]5.	Review	O	0
In Table 1, DLA-34 + DoG ?	Review	B-Review	9
hank you for your feedback, and the precise clarification questions, which we address point-by-point:[line_break_token][line_break_token]&gt;  single gaussian is shared across different free-form filters.	Reply	O	0
Is same gaussian also shared across input channels ?	Reply	O	0
[line_break_token][line_break_token]The Gaussian is shared across all input and output channels of a layer.	Reply	B-Reply	1
In effect, this lets a layer learn/adapt a shared scale for all of its filters.	Reply	I-Reply	1
Not sharing the Gaussians, for channel-wise scaling, is an extension for future work.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; For dynamic inference, what is the sampling resolution used ?	Reply	O	0
[line_break_token][line_break_token]We experimented with setting the sampling rate to 2*sigma, as we did for static filtering, but found a constant sampling rate (as shown in Figure 6) to suffice in our experiments.	Reply	B-Reply	2
That said, we expect that more extreme ranges of scale would require setting the resolution as a function of sigma, or else the sampling could be too sparse.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; In case of blurring and resampling, does the model learn another filter for sampling ?	Reply	O	0
To me, sampling seems similar to dynamic inference operation but with static parameters.	Reply	O	0
[line_break_token]This is exactly right.	Reply	B-Reply	3
The sampling coordinates and the blurring filter are determined by the same covariance.	Reply	I-Reply	3
This is analogous to smoothing and decimation when forming a pyramid: only smoothing would merely blur, but gaussian filtering then resampling/dilating the following filter instead changes scale.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; blurring is fundamental when dilating.	Reply	O	0
Does DRN-A and DLA-34 models used for comparison in Table 1 includes blurring prior to dilation ?	Reply	O	0
[line_break_token][line_break_token]Yes, but results with these architectures were not sensitive to this, since the dilation rates (2, 4) are not so large.	Reply	B-Reply	4
The effect of blur was stronger for ASPP and CCL (Table 3) with larger rates (6, 12, 18)	Reply	I-Reply	4

[ EDIT: Thanks for the response.	Review	O	0
I still believe the paper is not ready for publication, so I'll keep my rating unchanged.	Review	O	0
But as I said before, this is a really interesting research direction and I hope the authors will continue this work to collect more results and re-submit it. ]	Review	O	0
[line_break_token][line_break_token]The paper proposes learning a policy for selecting a pivoting rule to apply at each iteration of the Simplex algorithm for linear programming.	Review	O	0
Several pivoting rules have been proposed in the optimization literature, and different rules work better than others on different instances.	Review	O	0
By learning a policy that switches among the existing rules at each step of the Simplex algorithm, it may be possible to construct a pivoting rule that outperforms existing ones.	Review	O	0
The paper considers learning to switch between the Dantzig rule and the steepest edge rule as an RL problem.	Review	O	0
Results on 5-city TSP instances show that the learned policy can outperform both rules on a test set with respect to number of iterations.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The problem is very interesting and definitely should be explored further.	Review	O	0
Learning could potentially help combine rules in an instance distribution-specific manner to construct better pivoting rules.	Review	O	0
[line_break_token]- The paper made a reasonable attempt to provide sufficient background to understand the problem.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- The results on the 5-city synthetic TSP instances are not sufficient.	Review	O	0
While I understand the motivation for considering small problems to measure the best possible strategy‚Äôs performance and to learn on Q* values, I‚Äôm not convinced that the insights from such small synthetic problems would necessarily transfer to larger LPs for which the solve time is large enough to be able to afford the overhead of neural network inference to try to reduce it.	Review	B-Review	5
The learning challenges will likely be very different, and the tradeoff between the inference cost of the neural network and the savings from reducing iterations will also likely be different.	Review	I-Review	5
Scaling up and neural network inference cost are briefly mentioned in the conclusion, but I believe those are the main challenges.	Review	I-Review	5
[line_break_token]- Presentation of the results need to be improved significantly.	Review	O	0
Figures 2 and 3 need to be annotated properly and explained more clearly so that they are easy to understand.	Review	B-Review	3
[line_break_token][line_break_token]Additional comments:[line_break_token]- Although I‚Äôm recommending rejection, the problem is interesting and I hope the authors will continue working on it to develop the ideas further and collect results on larger scale problems.	Review	O	0
[line_break_token]- For permutation invariance and ability to handle variable-sized inputs, a graph neural network would be a better architecture (see, e.g., Gasse et al.,	Review	O	0
NeurIPS‚Äô19).	Review	B-Review	1
[line_break_token]- It would be helpful to give further details on how the best possible strategy is computed, perhaps as part of an appendix.	Review	O	0
[line_break_token]- Another baseline to compare against is the performance of an oracle that makes the best possible choice of the pivoting rule per problem instance.	Review	O	0
This will indicate how well a fixed choice per instance can work if that choice is made as well as possible, compared to switching among choices at each iteration.	Review	B-Review	2
[line_break_token]- ‚ÄúTo our knowledge, this is one of the first studies to report improvements via learning for combinatorial algorithms.	Review	O	0
‚Äù This sentence needs to be clarified because a literal interpretation of it is not true, as shown by, e.g., Bengio et al.	Review	B-Review	6
<a href="https://arxiv.org/abs/1811.06128."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1811.06128.</a>	Review	O	0
e thank the reviewer for the helpful comments and suggestions.	Reply	O	0
[line_break_token][line_break_token]We added a general response to the scalability concerns.	Reply	B-Reply	4
[line_break_token][line_break_token]We are thankful for the graph neural network suggestion.	Reply	I-Reply	1
We will implement different architectures in the future to compare performance, including the graph neural network.	Reply	I-Reply	1
[line_break_token][line_break_token]We will create a new section that will analyze the learned pivoting rule to gain insights on how the neural network decides one rule over the other.	Reply	I-Reply	2
[line_break_token][line_break_token]We will revise our figures to improve their clarification	Reply	I-Reply	3

The paper proposes a method for selecting a subset of a large dataset to reduce the computational costs of deep neural netwoks.	Review	O	0
The main idea is to train a proxy model, a smaller version of the full neural network, to choose important data points for active learning or core-set selection.	Review	O	0
Experiments on standard classification tasks demonstrate that this approach can yield substantial computational savings with only a small drop in accuracy.	Review	O	0
 [line_break_token][line_break_token]This paper is well-written and was easy to follow, with a clear motivation.	Review	O	0
The paper does good job of demonstrating that the proposed algorithm is effective through a comprehensive set of experiments.	Review	O	0
Overall, I favor acceptance and would be willing to increase my score if the following are addressed:[line_break_token][line_break_token]1) Training for a smaller number of epochs was mentioned as a possibility to save computation.	Review	O	0
In the experiments, this was only done for one of the settings.	Review	B-Review	1
Is this because models trained for fewer epochs are ineffective for data selection?	Review	I-Review	1
[line_break_token]Looking at Fig.	Review	I-Review	1
5b, it seems like the error drops significantly around 14 min before plateauing.	Review	I-Review	1
In practice, for a new dataset, it could be difficult (or impossible) to know when to stop training a proxy a priori so that it achieves good performance relative to a larger model.	Review	I-Review	1
It could be interesting to look at the effectiveness of a proxy at various points during training to see if the benefits are sensitive to the training time.	Review	I-Review	1
[line_break_token][line_break_token]2) For the active learning experiments, how many data points were added to the training set in each round?	Review	O	0
I could not find this number in the paper.	Review	B-Review	2
Also, how many rounds of data selection were there?	Review	I-Review	2
[line_break_token][line_break_token]3) Is there an explanation why in Fig.	Review	O	0
2b and Fig.	Review	B-Review	3
7c, the resnet20 proxy performs better than the larger (and more accurate) models?	Review	I-Review	3
In particular, it even outperforms the 'oracle' baseline, which I find surprising.	Review	I-Review	3
[line_break_token][line_break_token]4) On a similar note, in Fig.	Review	O	0
7, for small subsets (30%), the random baseline outperforms all of the SVP settings.	Review	B-Review	4
Why is SVP ineffective in this case?	Review	I-Review	4
[line_break_token][line_break_token]Minor comments/suggestions:[line_break_token]- In the abstract: "improvement in data selection runtime" Is this "data selection runtime" different from the total runtime?	Review	I-Review	5
If not, it could be clearer to simply state it as the "total runtime (including the time to repeatedly train and select points)".	Review	I-Review	5
I was unsure if this was a different measure.	Review	I-Review	5
[line_break_token][line_break_token]- Did the authors try further reducing the model capacity?	Review	I-Review	5
With the success of the smaller models, it seems natural to try pushing further in this direction.	Review	I-Review	5
[line_break_token][line_break_token]- Since one of the findings was that models with similar architectures were effective as proxies but not models with different ones, perhaps there could be even higher correlation if the proxies were initialized with the exact same weights as a subset of the full model.	Review	I-Review	5
[line_break_token][line_break_token]- The writing in Table 1 (and the ones in the appendix) is a bit small.	Review	I-Review	5
[line_break_token][line_break_token]	Review	O	0
hank you for your time and thoughtful feedback!	Reply	O	0
 We ran additional experiments to explore the effectiveness of training for fewer epochs in a variety of settings.	Reply	O	0
We also created more plots to explain how the rankings from proxies compared to the larger target model.	Reply	B-Reply	1
These results show that the underlying selection method plays an essential role in the effectiveness of SVP.	Reply	I-Reply	1
Notably, the rankings from forgetting events are much more stable because the model‚Äôs uncertainty is effectively averaged throughout training rather than a single snapshot at the end, like entropy or greedy k-centers.	Reply	I-Reply	1
Based on your questions and the points you raised, the paper more clearly presents the underlying dynamics that affect performance.	Reply	I-Reply	1
[line_break_token][line_break_token]Below we have provided a detailed response to each of your questions.	Reply	O	0

Review of ‚ÄúPrincipled Weight Initialization for Hypernetworks‚Äù[line_break_token][line_break_token]There has been a lot of existing work on neural network initialization, and much of this work has made large impact in making deep learning models easier to train in practice.	Review	O	0
There has also been a line of work on indirect encoding of neural works (i.e. HyperNEAT work of Stanley, and more recent Hypernetworks proposed by Ha et al) which showed promising results of training very large networks (in the case of Stanley), or have network weights that can adapt to the training data (in the case of Hypernetworks), and these approaches have been shown to be useful in applications such as meta-learning or few-shot learning (i.e. [1]).	Review	O	0
However, as far as I know, there hasn't been any work that looks at a principled way of initializing the weights of a weight-generating network, which this work tries to explore.	Review	O	0
[line_break_token][line_break_token]Making the observation (and claim) that traditional init methods don't init hypernetworks properly, they propose a few techniques to initialize hypernetworks ("Hyperfan"-family), which are justified in a similar way as original classical init techniques (i.e. preserving variance like in Xavier init), and they demonstrate that their method works well for feed forward networks on MNIST, CIFAR-10 tasks compared to traditional classical init methods, as well for a continual learning task.	Review	O	0
[line_break_token][line_break_token]I liked the paper as they identified a problem that hasn't been studied, and proposed a reasonable method to solve it.	Review	O	0
Their method may be able to make Hypernetworks accessible to many more researchers and practitioners, the way classifical init techniques have made neural net training more accessible.	Review	O	0
[line_break_token][line_break_token]There are a few things that could improve the paper (and get an improvement score from me).	Review	O	0
The authors don't have to do all of these, but just a few suggestions:[line_break_token][line_break_token]1) The experiments, to my understanding, are all feed forward networks.	Review	O	0
How about RNNs or LSTMs?	Review	B-Review	1
[line_break_token][line_break_token]2) Are there any (interesting) tasks that use Hypernetworks that are not trainable with existing methods, but made trainable using this proposed scheme?	Review	O	0
[line_break_token][line_break_token]3) Would this method also work with HyperNEAT [2] or Compressed Network Search [3]? (	Review	O	0
probably should cite that line of work too).	Review	B-Review	3
In [3], a research group at IDSIA used DCT compression to compress millions of weights into a few dozen parameters, so would be interesting if the approach will work on similar "learn-from-pixels" RL experiments.	Review	I-Review	3
[line_break_token][line_break_token]I'm assigning a score of 6 (it's currently like a "really good" workshop paper, but a normal conf paper IMO), but I like this paper and would like to see the authors make an attempt to improve it, so I can improve the score to see it get accepted with a higher certainty.	Review	O	0
[line_break_token][line_break_token]Good luck!	Review	O	0
[line_break_token][line_break_token][1] i.e. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6519722/" target="_blank" rel="nofollow">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6519722/</a> <a href="https://arxiv.org/pdf/1710.03641.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1710.03641.pdf</a> <a href="https://arxiv.org/pdf/1703.03400.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1703.03400.pdf</a>[line_break_token][line_break_token][2] <a href="http://eplex.cs.ucf.edu/hyperNEATpage/" target="_blank" rel="nofollow">http://eplex.cs.ucf.edu/hyperNEATpage/</a>[line_break_token][line_break_token][3] <a href="http://people.idsia.ch/~juergen/compressednetworksearch.html" target="_blank" rel="nofollow">http://people.idsia.ch/~juergen/compressednetworksearch.html</a>[line_break_token][line_break_token]*** Revised Score ***[line_break_token][line_break_token]Nov20: Upon reading the other reviews, and looking at the changes to the paper with the extra citations, I'm improving the score to 8. (	Review	O	0
For the record, if this was a 1-10 scale, I would have liked my score to be a 7).	Review	O	0
e would like to thank the reviewer for his thoughtful feedback on our work.	Reply	O	0
[line_break_token][line_break_token]Regarding the reviewer‚Äôs questions:[line_break_token][line_break_token]1) Variance analysis does not extend to RNNs and LSTMs even in the classical setting without the use of hypernetworks.	Reply	O	0
We believe this is an important open problem that deserves attention and we leave it for future work.	Reply	B-Reply	1
[line_break_token][line_break_token]2) Hypernetworks are a natural choice for enabling Bayesian neural networks, because they can be used to simulate an expressive prior distribution.	Reply	O	0
This is useful for improving model calibration, providing uncertainty estimation, and doing approximate Bayesian inference or regularization. [	Reply	B-Reply	2
1] demonstrated a method to build a Bayesian network using a hypernet, but they mentioned having to use a heuristic method to initialize the weights of their hypernetwork in order to prevent losses from diverging.	Reply	I-Reply	2
[line_break_token][line_break_token][1]‚Äôs implementation was unfortunately not publicly available so we could not try our approach on their exact settings.	Reply	I-Reply	2
We introduced a similar experiment in Section 5.4 that differed with [1]‚Äôs in terms of residual connections in the mainnet.	Reply	I-Reply	2
 While all initializations led to trainable networks in this case, our proposed initialization gave superior performance compared to the default initialization in PyTorch.	Reply	I-Reply	2
We are confident that an extension of our approach to hypernetworks with residual mainnets should be able to resolve [1]‚Äôs initializations issues.	Reply	I-Reply	2
This work is an important stepping stone towards this direction.	Reply	I-Reply	2
[line_break_token][line_break_token]3) Non-hypernetwork methods like HyperNEAT or Compressed Network Search that generate the weights of some target network would probably also do well to consider if their generated weights might result in exploding activations.	Reply	O	0
Because most of this line of work was done before the advent of deep learning, the networks considered were most likely not deep enough to have caused an issue.	Reply	B-Reply	3
We hope that our paper will drive new progress in this line of research as well.	Reply	I-Reply	3
We have cited the papers mentioned, thanks for pointing them out.	Reply	I-Reply	3
[line_break_token][line_break_token][1] Hypernetwork-based Implicit Posterior Estimation and Model Averaging of Convolutional Neural Networks.	Reply	O	0
Ukai et al.	Reply	O	0
ACML 2018.	Reply	O	0

This paper revisits the way RL algorithms are typically evaluated on the ALE benchmark, advocating for several key changes that contribute to more robust and reliable comparisons between algorithms.	Review	O	0
It also brings the following additional contributions: (1) a new measure of comparison to human performance based on actual human world records (which shows that RL algorithms are not as ¬´ super-human ¬ª as is generally believed), and (2) an evaluation (based on the proposed guidelines) of Rainbow as well as a Rainbow-IQN variant (replacing the C51 component of Rainbow with Implicit Quantile Networks), showing that the latter brings a significant improvement upon the original Rainbow algorithm.	Review	O	0
[line_break_token][line_break_token]Overall I am leaning towards acceptance as I believe that such papers encouraging better benchmarking practice on Atari are definitely needed.	Review	O	0
Even if the technical contribution is limited, this paper could have a positive impact on the field by providing a clearer picture of the current state of deep RL algorithms on Atari (assuming that other researchers start following these recommendations -- and if that is not the case at least it will highlight issues with the way evaluation is currently done).	Review	O	0
[line_break_token][line_break_token]I do have a few concerns / questions though:[line_break_token][line_break_token]1.	Review	O	0
[tab_token]I am not convinced by the recommendation to use performance during training for evaluation purpose.	Review	B-Review	1
In Machado et al. (	Review	I-Review	1
2018) it is argued that ¬´ this better aligns the performance metric with the goal of continual learning ¬ª, but most deep RL algorithms trained on Atari games have not been intended to be used in a continual learning setting.	Review	I-Review	1
It definitely has the advantage of being simple, but it seems to me that it can cause some issues, like making it difficult to compare different exploration techniques for off-policy learning (the exploration may cause poor behavior during training even if it helps the agent learn a better greedy policy), and more generally not being representative of the common practical use case where the goal is to obtain the best agent possible to use in production (with no further learning).	Review	I-Review	1
Finally, it could make results even harder to reproduce due to the potential high variance of an agent‚Äôs performance at a fixed # of timesteps (vs. considering the max performance it can reach over the whole period).	Review	I-Review	1
As a result, I am currently reluctant to see the proposed performance measure become the standard evaluation metric on ALE, and I would appreciate some additional justification from the authors on this point.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
[tab_token]Why not suggest to remove reward clipping in the recommendations?	Review	O	0
As mentioned in Section 6, reward clipping can prevent RL algorithms from properly playing some games, and thus in my opinion should be removed if the goal is to reach the highest score possible on all games.	Review	B-Review	2
It seems to me that the choice of clipping the reward should be part of the algorithm (if it is not able to handle the high variety of ¬´ raw ¬ª rewards) and not of the benchmark environment, thus enabling further advancements towards algorithms that are robust to a wide range of rewards.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
[tab_token]Why bother to keep the mean performance when, as mentioned, it is highly sensitive to outliers compared to the median?	Review	O	0
[line_break_token][line_break_token][line_break_token]Additional remarks:[line_break_token]‚Ä¢[tab_token]I might have missed it but I do not see the link to the source code.	Review	O	0
Am I correct to assume it will be released, to help with reproducibility?	Review	B-Review	4
[line_break_token]‚Ä¢[tab_token]It is not clear, when reading the paper, that the distributed version of Rainbow is actually constrained to mimic a single agent sequential algorithm in the experiments.	Review	O	0
I would suggest to remove mentions of the distributed version in the main text to avoid confusion, and mention it only in the Appendix section where it is used.	Review	B-Review	5
[line_break_token]‚Ä¢[tab_token]The ¬´ infinite reward loop ¬ª point at the end of Section 6 does not seem relevant in the list of reasons why Deep RL algorithms are far from the best human performance, since with infinite playtime and an infinite reward loop, the algorithm should be guaranteed to outperform humans.	Review	O	0
[line_break_token]‚Ä¢[tab_token]I would have appreciated an evaluation of Rainbow-IQN with the current most commonly used evaluation schemes (e.g. the one used in the original Rainbow paper), for comparison purpose (even if such an evaluation has flaws, it is often the only performance measure available for existing deep RL algorithms)[line_break_token][line_break_token]Review update: thank you for the response, I am currently keeping my "Weak accept" rating because I agree it is important to highlight and (try to) fix the problems with the way algorithms are currently evaluated on ALE, in spite of the limited technical contributions (and the fact that I remained unconvinced regarding #1)	Review	O	0
hank you for your comments and feedback.	Reply	O	0
We will try to answer to all your questions and remarks in the following.	Reply	O	0
[line_break_token][line_break_token]1) Concerning the recommendation of reporting performance during training, we will base our argument on Machado et al.	Reply	O	0
paper where they specifically speak about "Evaluation after learning" and "Evaluation of the best policy" (page 8).	Reply	B-Reply	1
First we think that evaluating the best policy after learning hides both the data efficiency and the stability of the algorithm.	Reply	I-Reply	1
Indeed most paper actually do not mention when the best results were encountered.	Reply	I-Reply	1
Finally as stated in Machado et al.	Reply	I-Reply	1
we think that "the best score achieved across training is a statistically biased estimate of an agent‚Äôs best performance".	Reply	I-Reply	1
However, it could be interesting to report training performance along with a re-evaluation of the best model encountered while training.	Reply	I-Reply	1
[line_break_token][line_break_token]2) We think that finding algorithms capable of managing high variety of rewards is still an open problem and most of algorithms are yet not suited to this.	Reply	O	0
And as you mentioned clipping reward is an algorithmic choice, so we estimate it is out of scope of the recommendations of SABER.	Reply	B-Reply	2
We think games on which reward clipping actually leads to sub-optimal policy are an important margin of improvement for algorithms trying to handle highly variable rewards.	Reply	I-Reply	2
[line_break_token][line_break_token]3) We kept mean performance as most of previous works were reporting both median and mean.	Reply	O	0
However, we think this is of limited interest and that is why all our graphics just plot the median normalized score.	Reply	B-Reply	3
[line_break_token][line_break_token]Additional remarks:[line_break_token]‚Ä¢[tab_token]The source code is currently available here: <a href="https://anonymous.4open.science/r/728e379d-4d38-49e2-9dd8-bf2fb4bd4844/" target="_blank" rel="nofollow">https://anonymous.4open.science/r/728e379d-4d38-49e2-9dd8-bf2fb4bd4844/</a>[line_break_token]‚Ä¢[tab_token]We mentioned our distributed version of Rainbow as we think this give a good value on our source code even if like you mentioned we constrained it to mimic a single agent version in our experiments.	Reply	O	0
[line_break_token]‚Ä¢[tab_token]We have reformulate this "Infinite reward loop" section in the revision we just submitted.	Reply	O	0
The idea we wanted to highlight there was that agents are often stuck in a loop which in many cases is a sub-optimal behavior (in fact most of Atari games incorporate a timeout when not moving along the game and Elevator Action was the only one we found with an infinite reward loop).	Reply	B-Reply	6
[line_break_token]‚Ä¢[tab_token]Unfortunately, we did not have time nor computational resources to run Rainbow-IQN following commonly used evaluation schemes	Reply	O	0

Summary: This well written paper presents an effective way to remove outliers for deep generative models, provided examples are ranked along their centrality.	Review	O	0
One question I have is how exactly this centrality is measured[line_break_token][line_break_token]The word ‚Äòcurriculum‚Äô has become a terminology used to describe a wide variety of totally different algorithms.	Review	O	0
While the authors provide an excellent introduction to this diversity and clearly differentiate their own flavor of ‚Äòcluster curriculum‚Äô, I am wondering if they would not have been better off by describing the proposed approach in terms of outlier removal, especially has it has very little in common with the original idea of curriculum, which is a learning progression designed by the teacher.	Review	B-Review	1
[line_break_token][line_break_token]Nevertheless, the paper is very clearly written and reads well in the present form.	Review	O	0
I am especially impressed about the clarity of the rather technical part on percolation.	Review	O	0
[line_break_token][line_break_token]In terms of outlier removal, this could be interpreted as the following constructive algorithm:[line_break_token]‚Ä¢[tab_token]Examples are ranked along their centrality measure [line_break_token]‚Ä¢[tab_token]One identify the critical point in percolation for a starting point where too many examples are removed[line_break_token]‚Ä¢[tab_token]More examples are added until a minimum is found on validation data[line_break_token]This process can be made faster as:[line_break_token]‚Ä¢[tab_token]The optimum can happen very soon after the critical point[line_break_token]‚Ä¢[tab_token]Otherwise, an active set algorithm can be used to control the size of the training set.	Review	B-Review	1
[line_break_token][line_break_token]While my recent expertise has been more NLP than Vision, I think this algorithm is original, and could have a significant impact as it can be extended beyond GANs.	Review	O	0
The technical presentation is excellent.	Review	O	0
[line_break_token][line_break_token]One puzzling issue is the computation of the centrality measure: all I could find in Appendix A1.	Review	B-Review	2
and A.3 is that it is directly measured on the raw image (RGB pixels?)	Review	I-Review	2
by taking some distance, which I assume is Euclidean?	Review	I-Review	2
My experience in image classification suggests such a distance is meaningless, so I may be missing something.	Review	I-Review	2
I looked for a Github pointer, but none was provided.	Review	I-Review	2
[line_break_token][line_break_token]The English is OK, but there are missing words and strange constructions:[line_break_token]‚Ä¢[tab_token]Page 1:  ‚ÄúDeep generative models HAVE piqueD researchers‚Äô interest in the past decade‚Äù[line_break_token]‚Ä¢[tab_token]Page 4: ‚ÄúThe training of many loops will lead to time-consuming (MISSING WORD)‚Äù[line_break_token][line_break_token]In particular, the usage of ‚Äúthe‚Äù, for instance in pages:[line_break_token]‚Ä¢[tab_token]7 ‚ÄúTherefore, a fast learning strategy can be derived from THE percolation process.	Review	O	0
‚Äù[line_break_token]‚Ä¢[tab_token]7 ‚ÄúTraining may begin from the curriculum‚Äù[line_break_token]‚Ä¢[tab_token]8 ‚ÄúCluster curriculum is proposed for robust training of generative models.	Review	B-Review	3
‚Äù[line_break_token]	Review	I-Review	3
Q1:  ‚ÄúI am wondering if they would not have been better off by describing the proposed approach in terms of outlier removal.	Reply	O	0
‚Äù[line_break_token]A1: Indeed, outlier removal is more clear and easier to understand.	Reply	O	0
But we use ‚Äúclustering‚Äù to emphasize the dynamic process when using cluster curriculum for training generative models.	Reply	B-Reply	1
[line_break_token][line_break_token]Q2:  ‚ÄúOne puzzling issue is the computation of the centrality measure.	Reply	O	0
‚Äù[line_break_token]A2: We used ResNet34 to extract 512-dimensional features for each image.	Reply	O	0
 The pre-trained model on ImageNet is available at[line_break_token][line_break_token]ResNet34[line_break_token]<a href="https://github.com/qubvel/classification_models" target="_blank" rel="nofollow">https://github.com/qubvel/classification_models</a>[line_break_token][line_break_token]Then the graph is constructed by Algorithm 3 presented in the following NeurIPS paper[line_break_token][line_break_token]Cyclizing Clusters via Zeta Function of a Graph[line_break_token]<a href="https://papers.nips.cc/paper/3412-cyclizing-clusters-via-zeta-function-of-a-graph" target="_blank" rel="nofollow">https://papers.nips.cc/paper/3412-cyclizing-clusters-via-zeta-function-of-a-graph</a>[line_break_token][line_break_token]In this paper, the authors validated the effectiveness of using graphs for clustering complex data.	Reply	O	0
We will make this clear in the revised version.	Reply	B-Reply	2
[line_break_token][line_break_token]We will polish our paper according to your advice on writing.	Reply	I-Reply	3
Thank you for your careful review and insightful comments on our work.	Reply	I-Reply	3
We appreciate them very much.	Reply	I-Reply	3

This paper proposes MaskGAN, a GAN-based generative model of text based on[line_break_token]the idea of recovery from masked text.	Review	O	0
[line_break_token]For this purpose, authors employed a reinceforcement learning approach to[line_break_token]optize a prediction from masked text.	Review	O	0
Moreover, authors argue that the [line_break_token]quality of generated texts is not appropriately measured by perplexities,[line_break_token]thus using another criterion of a diversity of generated n-grams as well as[line_break_token]qualitative evaluations by examples and by humans.	Review	O	0
[line_break_token][line_break_token]While basically the approach seems plausible, the issue is that the result is[line_break_token]not compared to ordinary LSTM-based baselines.	Review	B-Review	1
While it is better than a [line_break_token]conterpart of MLE (MaskedMLE), whether the result is qualitatively better than[line_break_token]ordinary LSTM is still in question.	Review	I-Review	1
[line_break_token][line_break_token]In fact, this is already appearent both from the model architectures and the[line_break_token]generated examples: because the model aims to fill-in blanks from the text[line_break_token]around (up to that time), generated texts are generally locally valid but not[line_break_token]always valid globally.	Review	O	0
This issue is also pointed out by authors in Appendix[line_break_token]A.2.	Review	O	0
[line_break_token]While the idea of using mask is interesting and important, I think if this[line_break_token]idea could be implemented in another way, because it resembles Gibbs sampling[line_break_token]where each token is sampled from its sorrounding context, while its objective[line_break_token]is still global, sentence-wise.	Review	B-Review	2
As argued in Section 1, the ability of [line_break_token]obtaining signals token-wise looks beneficial at first, but it will actually[line_break_token]break a global validity of syntax and other sentence-wise phenoma.	Review	I-Review	2
[line_break_token][line_break_token]Based on the arguments above, I think this paper is valuable at least[line_break_token]conceptually, but doubt if it is actually usable in place of ordinary LSTM[line_break_token](or RNN)-based generation.	Review	O	0
[line_break_token]More arguments are desirable for the advantage of this paper, i.e. quantitative[line_break_token]evaluation of diversity of generated text as opposed to LSTM-based methods.	Review	B-Review	3
[line_break_token][line_break_token]*Based on the rebuttals and thorough experimental results, I modified the global rating.	Review	O	0
Thank you for your review and comments!	Reply	O	0
[line_break_token][line_break_token]We reiterate your two primary concerns as the following:[line_break_token]1.	Reply	O	0
 A standard LSTM-baseline of a non-masked task should be included.	Reply	O	0
[line_break_token]2.	Reply	O	0
The MaskGAN algorithm is enforcing only local consistency within text, but does not aid with global consistency.	Reply	O	0
 [line_break_token][line_break_token]*Standard Baselines*[line_break_token]To address your first concern, we added a thorough human evaluation of a language model (LM) LSTM baseline.	Reply	O	0
 We use the samples produced from our Variational Dropout-LSTM language model and evaluate the resulting sample quality for both the PTB and IMDB datasets using Amazon Mechanical Turk.	Reply	B-Reply	1
 You can see these results updated in our paper in Table 7 and Table 8.	Reply	I-Reply	1
 We demonstrate that the MaskGAN training algorithm results in improvements over both the language model and the MaskMLE benchmarks on all three metrics: grammaticality, topicality and overall quality.	Reply	I-Reply	1
In particular, MaskGAN samples are preferred over LM LSTM baseline samples, 58.0% vs 15.7% of the time for IMDB reviews.	Reply	I-Reply	1
[line_break_token][line_break_token]*Local vs. Global Consistency*[line_break_token]In regards to your comment on Gibbs sampling, we do agree that this would likely be a valid and helpful technique for inference.	Reply	O	0
 In our paper, we in-fill our samples autoregressively from left to right, as is conventional in language modeling.	Reply	B-Reply	2
 (This approach allows for fast unconditional generation as with the LM baseline and is what our human evaluation is targeted at).	Reply	I-Reply	2
 This autoregressive process relies on the attention module of our decoder in order to provide full context during the sampling process.	Reply	I-Reply	2
 For instance, when the decoder is producing the probability distribution over token x_t, it is attending over the future context to create this distribution.	Reply	I-Reply	2
 If the subject of the sentence is known to be a female leader and the model is generating a pronoun, the model has the ability to attend to the future context and select the correct gender-matched pronoun.	Reply	I-Reply	2
 If the model fails to do this, a well-trained discriminator will ascribe a low reward to this pronoun selection which in turn will generate useful gradients through the attention mechanism.	Reply	I-Reply	2
 We have observed this behaviour during preliminary experiments.	Reply	I-Reply	2
 We argue that global consistency is built into this architecture but to solve the boundary problems in appendix C.2, allowing the autoregressive model decide when to stop instead of forcing it to output a fix number of words may resolve some of the syntactic issues.	Reply	I-Reply	2
[line_break_token][line_break_token]We also expand table 6 to show the diversity of the generated samples compared to a standard LM-LSTM	Reply	I-Reply	3

This paper investigates stopping criteria for training of RBMs by contrastive[line_break_token]divergence (CD).	Review	O	0
Traditional reconstruction error is compared to a ratio of[line_break_token]probabilities, namely the probabilities of the training data divided by the[line_break_token]probabilities of an equal number of sampled points (with two variants of the[line_break_token]sampling strategy).	Review	O	0
By dividing probabilities, the partition function cancels[line_break_token]out, which makes computations tractable.	Review	O	0
Experiments on two toy datasets show[line_break_token]that the two proposed variants are overall more useful than reconstruction[line_break_token]error to identify the point of maximum likelihood on training data, even though[line_break_token]they do not work on all cases investigated here.	Review	O	0
[line_break_token][line_break_token]The problem of early stopping of RBM training is definitely a relevant one,[line_break_token]since the intractability of the partition function prevents properly monitoring[line_break_token]the likelihood.	Review	O	0
The approach suggested here, however, lacks in both theoretical[line_break_token]motivation and empirical evaluation, thus in my opinion is not quite ready for[line_break_token]publication.	Review	B-Review	10
[line_break_token][line_break_token]On the theoretical side, the proposed criterion (eq.	Review	I-Review	1
8) is only heuristicallymotivated.	Review	I-Review	1
Note in particular that a model might be able to reach an arbitraryhigh value of this criterion if P(y_i) -> 0 for some y_i, regardless or howbadly it may perform on the training x_i's.	Review	O	0
I'm also not sure why one would[line_break_token]necessarily take N y_i's: why not generalize it to M y_i's, using Pi_i[line_break_token]P(y_i)^(N/M), so as to be able to choose the sample size based on available[line_break_token]computational resources?	Review	B-Review	2
Finally, I am not convinced by the choice of y_i's:[line_break_token]first, the sampling rules (random h or '1 - h_i') are not well motivated (there[line_break_token]is no guarantee that we will not sample training points), second, since they[line_break_token]are defined from the model parameters they lead to a set of y_i's that evolves[line_break_token]during training (thus the criterion may be unstable), third the y_i's are[line_break_token]expectations and there is no explanation on whether it makes sense for binary[line_break_token]RBMs.	Review	O	0
[line_break_token][line_break_token]On the empirical side, my first concern is that experiments are performed[line_break_token]on low-dimensional toy datasets, and there is nothing to tell us that [line_break_token]behavior observed on such datasets will actually translate into higher[line_break_token]dimensional tasks.	Review	B-Review	6
In particular, sampling-based methods tend to behave rather[line_break_token]nicely in low dimension, but may break horribly as the dimension increases...[line_break_token]Thus it would have been good to add experiments in high dimension, for instance[line_break_token]using AIS to estimate the partition function.	Review	O	0
My second concern is that only[line_break_token]training errors are reported: although they are definitely interesting to[line_break_token]monitor, someone using reconstruction error as a stopping criterion will always[line_break_token]use a validation set for this, and will hope to stop at a point where validation[line_break_token]log-likelihood is maximized.	Review	B-Review	8
The comparisons in the paper are thus, for the[line_break_token]most part, uninformative, since they only use the training data.	Review	O	0
[line_break_token][line_break_token]A few more minor points:[line_break_token]- Eq.	Review	B-Review	9
5 is missing some characters[line_break_token]- The number of hidden units is not mentioned in the experiments[line_break_token]- Plots show 'reconstruction error' as something that is better when it increases,[line_break_token]  which is counter-intuitive for an error[line_break_token]- Something potentially worth discussing is that RBMs are often used for[line_break_token]  pre-training purpose in deep networks, and it is not clear that better[line_break_token]  likelihood => better pre-training (if there is work on this topic, it should[line_break_token]  be cited, as it is important to motivate this direction of research)[line_break_token]- Another application worth mentioning to this kind of technique is model[line_break_token]  selection (which RBM is best?)	Review	O	0
=> the proposed criterion may require a bit[line_break_token]  of tweaking to answer this kind of question (common y_i's are needed)	Review	O	0
> On the theoretical side, the proposed criterion (eq.	Reply	O	0
8) is only [line_break_token] > heuristically motivated.	Reply	O	0
Note[line_break_token] > in particular that a model might be able to reach an arbitrary high [line_break_token]value of this criterion if[line_break_token] > P(y_i) -> 0 for some y_i, regardless or how badly it may perform on [line_break_token]the training x_i's.	Reply	O	0
[line_break_token][line_break_token]In our mind we implicitely assume CD_1 is leading to the right place [line_break_token]starting from[line_break_token]weights initialized at random.	Reply	B-Reply	1
if that does not hold, it would lead to [line_break_token]trouble no matter[line_break_token]what the stopping criteria you use.	Reply	I-Reply	1
[line_break_token]under our assumptions, the situation you point out should not happen, [line_break_token]hopefully.	Reply	I-Reply	1
[line_break_token]Our experiments seem to back up our line of reasoning, although we agree [line_break_token]the criteria should[line_break_token]be contrasted against other problems :)[line_break_token][line_break_token] > I'm also not sure why one would[line_break_token] > necessarily take N y_i's: why not generalize it to M y_i's, using Pi_i[line_break_token] > P(y_i)^(N/M), so as to be able to choose the sample size based on [line_break_token]available[line_break_token] > computational resources?	Reply	O	0
[line_break_token][line_break_token]We don't say that N_i should be equal to M_i: we just use the proposed [line_break_token]estimator,[line_break_token]but of course it could happen that enhanced versions of it leads to [line_break_token]better results.	Reply	B-Reply	2
[line_break_token]Still, we are confident the proposed criteria works well.	Reply	I-Reply	2
[line_break_token][line_break_token] > Finally, I am not convinced by the choice of y_i's:[line_break_token] > first, the sampling rules (random h or '1 - h_i') are not well [line_break_token]motivated (there[line_break_token] > is no guarantee that we will not sample training points)[line_break_token][line_break_token]Our belief is that at the very beginning of the training process the [line_break_token]proposed[line_break_token]sampling does lead to states that are far away from the training set, [line_break_token]just because[line_break_token]the RBM has been initialized to random weights and bias, which are [line_break_token]*very* different[line_break_token]from the ones one will get at the optimal point of the learning stage.	Reply	O	0
[line_break_token]of course the criteria gets worse when you surpass that point.	Reply	B-Reply	3
But that [line_break_token]is precisely our main message:[line_break_token]this does not happen while the system is learning and weights are still [line_break_token]non-optimal.	Reply	I-Reply	3
[line_break_token][line_break_token] > second, since they are defined from the model parameters they lead to [line_break_token]a set of[line_break_token] > y_i's that evolves during training (thus the criterion may be unstable)[line_break_token][line_break_token]We agree that on general grounds, any procedure that changes with model [line_break_token]parameters could be[line_break_token]dynamically unstable, even standard CD_k could suffer from this problem.	Reply	O	0
[line_break_token]However we have not seen anything like that in the problems analyzed.	Reply	B-Reply	4
[line_break_token]In the present case, the size of the spaces studied, despite large, are [line_break_token]small enough[line_break_token]to compute the likelihood and to exhaustively explore all possible [line_break_token]states.	Reply	I-Reply	4
While[line_break_token]doing so, we have not encountered any of the problems mentioned here.	Reply	I-Reply	4
[line_break_token][line_break_token] > third the y_i's are[line_break_token] > expectations and there is no explanation on whether it makes sense [line_break_token]for binary[line_break_token] > RBMs.	Reply	O	0
[line_break_token][line_break_token]We have seen that using average values reduces noise.	Reply	B-Reply	5
That makes the [line_break_token]algorithm more stable,[line_break_token]although not using expectations leads to the same statistical solutions.	Reply	I-Reply	5
[line_break_token][line_break_token] > On the empirical side, my first concern is that experiments are performed[line_break_token] > on low-dimensional toy datasets, and there is nothing to tell us that[line_break_token] > behavior observed on such datasets will actually translate into higher[line_break_token] > dimensional tasks.	Reply	O	0
In particular, sampling-based methods tend to [line_break_token]behave rather[line_break_token] > nicely in low dimension, but may break horribly as the dimension [line_break_token]increases...[line_break_token][line_break_token]We are aware that we have to do a more exhaustive study on the scaling [line_break_token]properties[line_break_token]of the method, and we are currently working on that.	Reply	O	0
However, we know [line_break_token]stochastic sampling techniques[line_break_token]are best suited for large scale problems.	Reply	B-Reply	6
In fcat, when the [line_break_token]dimensionality of the space increases,[line_break_token]stochastic methods are essentially the only ones that provide reliable [line_break_token]results on a general[line_break_token]ground.	Reply	I-Reply	6
For instance, in numerical simulations of quantum many-body [line_break_token]systems of strongly[line_break_token]interacting partcicles, Monte Carlo methods are known to be the only [line_break_token]ones that are able to provide[line_break_token]exact statistical solutions to the Schrodinger equation.	Reply	I-Reply	6
We are [line_break_token]confident the same applies in the[line_break_token]present case.	Reply	I-Reply	6
[line_break_token][line_break_token] > Thus it would have been good to add experiments in high dimension,[line_break_token] >  for instanceusing AIS to estimate the partition function.	Reply	O	0
[line_break_token][line_break_token]We agree that it is interesting to explore the scalability with the [line_break_token]system size.	Reply	B-Reply	7
However[line_break_token]in order to check against exact results (computation of the likelihood) [line_break_token]one is restricted[line_break_token]to medium or small spaces.	Reply	I-Reply	7
Furthermore we are also aware that AIS may [line_break_token]also fail[line_break_token]in some cases (we already mention that in our paper and refer to [line_break_token]reference Schult et al.	Reply	I-Reply	7
2010).	Reply	O	0
[line_break_token][line_break_token] > My second concern is that only[line_break_token] > training errors are reported: although they are definitely interesting to[line_break_token] > monitor, someone using reconstruction error as a stopping criterion [line_break_token]will always[line_break_token] > use a validation set for this, and will hope to stop at a point where [line_break_token]validation[line_break_token] > log-likelihood is maximized.	Reply	O	0
The comparisons in the paper are thus, [line_break_token]for the[line_break_token] > most part, uninformative, since they only use the training data.	Reply	O	0
[line_break_token][line_break_token]In general we agree that using part of the examples as a training set [line_break_token]and the rest as a[line_break_token]validation set is a good way to proceed.	Reply	B-Reply	8
However in the studied data [line_break_token]sets that separation[line_break_token]would lead to significant information loss that may lead to  wrong results[line_break_token](for instance in the bars and stripes problem one'd better show the [line_break_token]network all[line_break_token]possible instances).	Reply	I-Reply	8
[line_break_token][line_break_token] > A few more minor points:[line_break_token] > - Eq.	Reply	O	0
5 is missing some characters[line_break_token] > - The number of hidden units is not mentioned in the experiments[line_break_token] > - Plots show 'reconstruction error' as something that is better when [line_break_token]it increases,[line_break_token] > which is counter-intuitive for an error[line_break_token] > - Something potentially worth discussing is that RBMs are often used for[line_break_token] > pre-training purpose in deep networks, and it is not clear that better[line_break_token] > likelihood => better pre-training (if there is work on this topic, it [line_break_token]should[line_break_token] > be cited, as it is important to motivate this direction of research)[line_break_token] > - Another application worth mentioning to this kind of technique is model[line_break_token] > selection (which RBM is best?)	Reply	O	0
=> the proposed criterion may require [line_break_token]a bit[line_break_token] > of tweaking to answer this kind of question (common y_i's are needed)[line_break_token][line_break_token]We thank for these suggestions, and will try to accomodate them in the [line_break_token]next revision	Reply	O	0

[line_break_token]The paper applies conditional GAN to the HRED model [Serban et al.,	Review	O	0
2016] for dialogue response generation, showing improvements in terms of informativeness and diversity compared to HRED and VHRED [Serban et al.,	Review	O	0
2017].[line_break_token][line_break_token]The paper is technically solid and relatively easy to follow and the results are good, but comparisons with previous work (descriptive and experimental) are rather weak.	Review	O	0
[line_break_token][line_break_token]- Related work is incomplete: The paper specifically argues for the use of GAN to improve diversity in dialogue response generation, but this is not the first paper to do so. [	Review	O	0
Xu et al.,	Review	B-Review	1
2017] presents a GAN-like setup that targets exactly the same goal, but that work is not cited in the paper.	Review	I-Review	1
Same for [Zhang et al.,	Review	I-Review	1
2018], but the latter work is rather recent (it still should probably be cited).	Review	I-Review	1
[line_break_token][line_break_token]- Evaluation: There is no evaluation against Xu et al.,	Review	O	0
which targets the same goal.	Review	B-Review	2
The authors didn‚Äôt even compare their methods against baselines used in other GAN works for diverse response generation (e.g., MMI [Xu et al.;	Review	I-Review	2
Zhang et al.],	Review	I-Review	2
Li et al.	Review	I-Review	2
‚Äôs GAN approach [Xu et al.]),	Review	I-Review	2
which makes it difficult to draw comparisons between these related methods.	Review	I-Review	2
As opposed to these other works, the paper doesn‚Äôt offer any human evaluation.	Review	I-Review	2
[line_break_token][line_break_token]- It would have been nice to include an LSTM or GRU baseline, as these models are still often used in practice and the VHRED paper suggests [Serban et al.,	Review	O	0
2016; Table 1] that LSTM holds up quite well against HRED (if we extrapolate the results of VHRED vs. LSTM and VHRED vs. HRED).	Review	B-Review	3
The ablation of GAN and HRED would help us understand which of the two is more important.	Review	I-Review	3
[line_break_token][line_break_token]In sum, the work is relatively solid, but considering how much has already been done on generating diverse responses (including 3 other papers also using GAN), I don‚Äôt think this paper is too influential.	Review	O	0
Its main weakness is the evaluation (particularly the lack of human evaluation.)	Review	B-Review	11
[line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]- Introduction: ‚Äúdiversity promoting training objective but their model is for single turn conversations‚Äù.	Review	O	0
[line_break_token]If these were ‚Äúsingle turns‚Äù, they wouldn‚Äôt really be called conversations; that objective has been used with 3+ turn conversations.	Review	B-Review	4
It can actually be applied to multi-turn dialogue as with any autoegressive generative models.	Review	I-Review	4
For example, it has been exploited that way as a baseline for multi-turn dialogue [Li et al.	Review	I-Review	4
2016](‚ÄúDeep Reinforcement Learning for Dialogue Generation‚Äú).	Review	I-Review	4
Note it is not a ‚Äútraining objective‚Äù, but only an objective function at inference time, which is a more valid reason to criticize that paper.	Review	I-Review	4
[line_break_token][line_break_token]- ‚ÄúWe use greedy decoding (MLE) on the first part of the objective.	Review	O	0
‚Äù Doesn‚Äôt that hurt diversity because of MLE?	Review	B-Review	5
what about using sampling instead (maybe with temperature)?	Review	I-Review	5
[line_break_token][line_break_token]- Algorithm 1: the P_theta_G don‚Äôt seem to match the text of section 2.	Review	O	0
h_i is in sometimes written in bold and sometimes not (see also Eq 12 for comparison.)	Review	B-Review	6
[line_break_token][line_break_token]- End of section 2.1: There are multiple Li et al.;	Review	O	0
specify which one.	Review	B-Review	7
[line_break_token][line_break_token]- End of section 2.2 and 2.4: extra closing parenthesis after N(0, ‚Ä¶))[line_break_token][line_break_token]- Figures are too small to read the subscripts.	Review	O	0
[line_break_token][line_break_token][Xu et al.	Review	B-Review	1
2017]: Zhen Xu, Bingquan Liu, Baoxun Wang, Sun Chengjie, Xiaolong Wang, Zhuoran Wang, and Chao Qi.	Review	O	0
Neural response generation via gan with an approximate embedding layer.	Review	O	0
EMNLP 2017.	Review	O	0
[line_break_token][line_break_token][Zhang et al.	Review	B-Review	1
2018]: Zhang, Yizhe & Galley, Michel & Gao, Jianfeng & Gan, Zhe & Li, Xiujun & Brockett, Chris & Dolan, Bill. (	Review	O	0
2018).	Review	O	0
Generating Informative and Diverse Conversational Responses via Adversarial Information Maximization.	Review	O	0
Thank you for your review.	Reply	O	0
We will soon post a more detailed explanation and new results with human evaluation but we want to quickly address some of the other concerns raised in your review.	Reply	O	0
[line_break_token][line_break_token]Thank you for pointing out those additional three papers that we missed in our discussion of the previous works.	Reply	O	0
We will give a detailed explanation of how our work relates to them in the final version.	Reply	O	0
[line_break_token][line_break_token]--Uniqueness and Influence[line_break_token]As you have also pointed out, we believe that our work is very unique.	Reply	O	0
We also believe that it will be very influential for future work in this area in that we specifically investigate an end-to-end adversarial learning framework  for multi-turn dialogue.	Reply	B-Reply	10
First, most of the works on adversarial dialogue response generation in the literature use ses2seq generator which has limited capacity for multi-turn dialogue history encoding.	Reply	I-Reply	10
 It is computationally not feasible to always re-encode the entire conversation history at each turn.	Reply	I-Reply	10
Hence, the need for the HRED generator.	Reply	I-Reply	10
[line_break_token]Also, in our adversarial framework, our discriminator is also multi-turn and compliments the generator at each turn.	Reply	I-Reply	10
Hence, the shared dialogue history encoding which is also unique to out work.	Reply	I-Reply	10
[line_break_token]Furthermore, to achieve end-to-end differentiation, we also share the word embedding between the generator and discriminator.	Reply	I-Reply	10
As at the time of this work,  we were not aware of the approximate embedding layer in Xu et al.	Reply	I-Reply	10
2017 and Zhang et al.	Reply	I-Reply	10
2018.	Reply	I-Reply	10
However, during our study (in 2017) we took a similar approach by replacing the one-hot decoder output by the softmax probability output (with no temperature) but still with shared word embedding.	Reply	I-Reply	10
We however did not see any appreciable improvement in the model performance despite the huge computational burden due to the large vocabulary size.	Reply	I-Reply	10
So we decided to stick with the one-hot output and only share the word embedding.	Reply	I-Reply	10
The shared embedding still allows us to achieve end-to-end differentiability.	Reply	I-Reply	10
This contribution is also unique to our work.	Reply	I-Reply	10
[line_break_token]Finally, the adversarial response scoring by our jointly trained discriminator is calibrated based on adversarial training, whereas the scores from MMI-antiLM and MMI-bidi [Li et al. (	Reply	I-Reply	10
2016)] are not.	Reply	I-Reply	10
Additional learning is still required during inference to properly calibrate them.	Reply	I-Reply	10
[line_break_token][line_break_token]--‚ÄúWe use greedy decoding (MLE) on the first part of the objective.	Reply	O	0
‚Äù Doesn‚Äôt that hurt diversity because of MLE?	Reply	O	0
what about using sampling instead (maybe with temperature)?	Reply	O	0
[line_break_token]It is true that MLE sampling would ordinarily hurt diversity but with noise injection, we are able to perturb the output distribution.	Reply	B-Reply	5
In fact, the exploration factor, alpha helps us to control the diversity (much smoother than categorical sampling).	Reply	I-Reply	5
We noted in our experiment that increasing alpha actually increases the likelihood of high scoring by the discriminator.	Reply	I-Reply	5
This makes us to believe that the generator has mapped high probability samples to high probability noise samples which the discriminator in turn mapped to low discriminator score.	Reply	I-Reply	5
This shows that the rearer the noise samples, the more diverse the generator samples and the higher the discriminator score.	Reply	I-Reply	5
We however, also note that very high alpha values results to low discriminator scores.	Reply	I-Reply	5
Looking at these responses shows that they are less grammatical even though they are obviously diverse.	Reply	I-Reply	5
Hence the decision to limit the range of alpha values.	Reply	I-Reply	5
            [line_break_token][line_break_token]--Typos[line_break_token]We appreciate your pointing out some minor typos.	Reply	O	0
All those are now fixed and will be included in the final version.	Reply	B-Reply	8
[line_break_token][line_break_token]--Additional Evaluation[line_break_token]We have crowdsourced the human evaluation and we will be reporting the results here soon.	Reply	O	0
[line_break_token]-- Additional Previous Work[line_break_token]The three additional references provided shall be added to our citation and discussed under the previous work section.	Reply	O	0
[line_break_token][line_break_token]Let us know if you have additional questions while we collate and analyze the human evaluation results.	Reply	O	0

This paper re-organized the high dimensional 1-D raw waveform as 2-D matrix.	Review	O	0
This method simulated the autoregressive flow.	Review	O	0
Log-likelihood could be calculated in parallel.	Review	O	0
Autoregressive flow was only run on row dimension.	Review	O	0
The number of required parameters was desirable to synthesize high-fidelity speech with the speed faster than real time.	Review	O	0
Although this method could not achieve top one in ranking in every measurements, the resulting performance was still obtained with the best average results.	Review	O	0
[line_break_token][line_break_token]In general, this paper is clearly written, well organized and easy to follow.	Review	O	0
The authors carried out sufficient experiments and analyses, and proposed some rules of thumb to build a good model.	Review	O	0
On one hand, we may catch the contributions.	Review	O	0
But, on the other hand, the contributions were not clearly explained.	Review	O	0
The results were averaged but were not clearly explained.	Review	O	0
[line_break_token][line_break_token]The authors suggested to specify a bigger receptive field than the squeezed height.	Review	O	0
The property of getting better performance using deeper wavenet was "not" clearly explained and investigated.	Review	O	0
In the experiments, a small number of generative steps was considered.	Review	O	0
This is because short sequence based on autoregressive model was used.	Review	O	0
[line_break_token][line_break_token]This paper mentioned that using convolution queue could improve the synthesis speed.	Review	B-Review	1
But, the synthesis speed has been fast enough because it is almost 15 times faster than real time.	Review	I-Review	1
In practical applications, 100x faster is almost the same as 15x faster for humans.	Review	I-Review	1
But, the task isn‚Äôt interacted with human.	Review	I-Review	1
It is suggested to focuse on reducing the number of parameters or enhancing the log likelihood.	Review	I-Review	1
any thanks for your review; the feedback is helpful to improve our paper.	Reply	O	0
[line_break_token][line_break_token]** After the submission, we have made two improvements: 1) We find that the split &amp; reverse operations for stacking multiple flows are more effective than reverse-only operations (see details in Section 3.4 in our revision).	Reply	O	0
Our small-footprint WaveFlow now obtains larger test likelihood (see Table 3 in the revision) and improved speech fidelity (see Table 5 in the revision).	Reply	B-Reply	1
  2) We implement convolution queue (Paine et al.,	Reply	I-Reply	1
2016), which brings additional 3x to 5x speedup for WaveFlow models.	Reply	I-Reply	1
 As a result, our small-footprint WaveFlow (5.91M parameters) can now generate 22.05kHz high-fidelity speech (MOS: 4.32) more than 40x faster than real-time (faster than WaveGlow), which provides a promising neural vocoder.	Reply	I-Reply	1
We also recommend setting h = 16 for neural vocoding task, because it provides better speech fidelity and its synthesis speed is only marginally slower than h = 8 with the help of convolution queue. **	Reply	O	0
[line_break_token][line_break_token]We will address your comments in the following.	Reply	O	0
[line_break_token][line_break_token]- ‚ÄúOn one hand, we may catch the contributions.	Reply	O	0
But, on the other hand, the contributions were not clearly explained.	Reply	O	0
The results were averaged but were not clearly explained.	Reply	O	0
‚Äù[line_break_token]* We can summarize our contributions in two points: [line_break_token](1) We propose a novel and unified framework for constructing likelihood-based generative models for raw audio, which includes previous approaches (WaveNet and WaveGlow) as special cases.	Reply	O	0
We demonstrate the trade-off between memory footprint, generation speed and audio fidelity within the framework.	Reply	O	0
[line_break_token](2) The resulting small WaveFlow is a compelling neural vocoder.	Reply	O	0
In comparison with WaveGlow, it requires much fewer parameters (5.91M vs. 87.88M) to generate high fidelity speech (MOS: 4.32 vs. 4.34).	Reply	O	0
Its synthesis speed is also slightly faster (42.60x vs. 34.69x).	Reply	O	0
 In comparison with WaveNet, WaveFlow models are significantly faster at synthesis.	Reply	O	0
[line_break_token][line_break_token]- ‚ÄúThe property of getting better performance using deeper wavenet was "not" clearly explained and investigated.	Reply	O	0
‚Äù [line_break_token]* We only test 30-layer WaveNet in the paper.	Reply	O	0
We think this question was perhaps raised for flow-based models.	Reply	O	0
In Table 4, we investigate WaveFlow with 6x8 = 48 and 8x8 = 64 layers (e.g., row-(l) vs. row-(m)), and WaveGlow with 6x8 = 48 and 12x8 = 96 layers (e.g., row-(e) vs. row-(f)), respectively.	Reply	O	0
The models stacked with larger number of flows (i.e., deeper layers) consistently provide better likelihood.	Reply	O	0
This property is also well known in normalizing flow literature (e.g., [1]).	Reply	O	0
We have added details in Section 5.1.	Reply	O	0
[line_break_token][line_break_token][1] Rezende and Mohamed.	Reply	O	0
Variational inference with normalizing flows.	Reply	O	0
ICML, 2015.	Reply	O	0
[line_break_token][line_break_token]- ‚ÄúThis paper mentioned that using convolution queue could improve the synthesis speed.	Reply	O	0
But, the synthesis speed has been fast enough because it is almost 15 times faster than real time.	Reply	O	0
In practical applications, 100x faster is almost the same as 15x faster for humans.	Reply	O	0
But, the task isn‚Äôt interacted with human.	Reply	O	0
It is suggested to focus on reducing the number of parameters or enhancing the log likelihood.	Reply	O	0
‚Äù[line_break_token]* From human perceptual perspective, 15x faster and 40x faster (our new result)  than real-time has minor difference.	Reply	O	0
However, the convolution queue removes redundant calculation at synthesis, which will also improve system throughput in practical applications.	Reply	O	0
We do agree on that reducing parameters or enhancing the log likelihood is very important for flow-based models.	Reply	O	0
The previously mentioned split &amp; reverse operation is a new endeavor after the submission.	Reply	O	0
Note that, there is still significant likelihood gap that has so far existed between autoregressive models and flow-based models [2]. Our proposed model can close the gap with larger squeezing factor h (e.g., h = 64 in Table 4), or increased model size.	Reply	O	0
[line_break_token][line_break_token][2] Ho et al.	Reply	O	0
Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design.	Reply	O	0
ICML 2019	Reply	O	0

[line_break_token][line_break_token]This paper claims to propose an extension of the Transformer architecture specialized for the mobile environment (under 500M Mult-Adds).	Review	O	0
[line_break_token]The authors propose their method called "Long-Short Range Attention (LSRA)," which separates the self-attention layers into two different purposes, where some heads focus on the local context modeling while the others capture the long-distance relationship.	Review	O	0
[line_break_token]They also demonstrate consistent improvement over the transformer on multiple datasets under the mobile setting.	Review	O	0
[line_break_token]It also surpasses the recently developed comparative method called "Evolved Transformer" that requires a far costly architecture search under the mobile setting.	Review	O	0
[line_break_token] [line_break_token]This paper is basically well written and easy to follow what they have done.	Review	O	0
[line_break_token]The experimental results look good.	Review	O	0
[line_break_token] [line_break_token]However, I have several concerns that I listed as follows.	Review	O	0
[line_break_token] [line_break_token]1,[line_break_token]I am not sure whether my understanding is correct or not, but it seems that the proposed method, LSRA, is not a method specialized for mobile computation.	Review	O	0
[line_break_token]In fact, in the paper, they say, "To tackle the problem, instead of having one module for "general" information, we propose a more specialized architecture, Long-Short Range Attention (LSRA), that captures the global and local information separately."	Review	B-Review	1
[line_break_token] [line_break_token]There is no explicit discussion that LSRA is somehow tackling the mobile setting.	Review	I-Review	1
[line_break_token]There is a large mismatch (gap) between the main claim and what they have done.	Review	I-Review	1
[line_break_token]In other words, LSRA can be simply applied to standard-setting (non-mobile setting).	Review	I-Review	1
Is there any reason that the proposed method cannot be applied to the standard-setting?	Review	I-Review	1
[line_break_token]If my understanding is correct, the paper must be revised and appropriately reorganized to clear this gap.	Review	I-Review	1
[line_break_token] [line_break_token]2,[line_break_token]I am not convinced of the condition of the so-called "mobile setting (and also extremely efficient constraint)."	Review	O	0
[line_break_token]Please provide a clear justification for it.	Review	B-Review	2
[line_break_token] [line_break_token]	Review	I-Review	1
hank you very much for your constructive comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Specialization for mobile setting[line_break_token]As mentioned in Section 4, the original multi-head self-attention captures ‚Äòglobal‚Äô and ‚Äòlocal‚Äô information in a single module.	Reply	B-Reply	1
This unified design is not efficient especially when the computation budget is very limited (i.e., under the mobile setting).	Reply	I-Reply	1
We need to make the module more specialized so that it can capture the context in a more efficient way.	Reply	I-Reply	1
To this end, we proposed LSRA that captures the short-range information by convolution and the long-range information by attention.	Reply	I-Reply	1
As shown in Figures 4 and 5, our LSRA achieves more improvements when the computation constraint is tighter.	Reply	I-Reply	1
This is because the redundancy of the unified design is more severe under the mobile setting.	Reply	I-Reply	1
[line_break_token][line_break_token]We also conducted experiments under the standard setting on the WMT En-Fr dataset.	Reply	I-Reply	1
Our Mobile Transformer still outperforms the vanilla Transformer under the standard setting:[line_break_token]Base Transformer:                   40.0 BLEU @ 1336M Mult-Adds[line_break_token]Mobile Transformer (Ours):   40.6 BLEU @ 1328M Mult-Adds[line_break_token][line_break_token]2.	Reply	O	0
Clarification of mobile settings[line_break_token]We defined our mobile setting based on the real-world requirements for mobile applications and the conventions in the computer vision community.	Reply	O	0
Please refer to our general response for more information.	Reply	B-Reply	2
We revised our paper accordingly in Section 5.	Reply	I-Reply	2
[line_break_token][line_break_token]We have also listed all other changes in our general response above.	Reply	I-Reply	2
Please don‚Äôt hesitate to let us know for any additional comments on the paper	Reply	I-Reply	2

This submission explores whether the formulation of attention proposed in "Using Fast Weights to Attend to the Recent Past" paper is applicable to LSTM.	Review	O	0
The associative memory bit is applied to the proposed input (often denoted by "j") before it's gated ("i") and added to the gated state ("f*c_{t-1}").	Review	O	0
[line_break_token][line_break_token]The experiments are done on a simple associative retrieval task and a new, harder variant of the same.	Review	O	0
The results indicate that the fast weight LSTM improves on both the plain LSTM and the fast weight RNN.	Review	O	0
It is unclear how trustworthy these results are since the experimental setup (especially hyperparameter tuning) is not described in much detail.	Review	B-Review	1
[line_break_token][line_break_token]The proposed model is simple, the experiments are a good start, but even for a workshop paper, I feel more convincing ones are necessary.	Review	O	0
Dear Reviewer 3,[line_break_token][line_break_token]Thank you for taking the time to review our work.	Reply	O	0
[line_break_token][line_break_token]We believe there is a misunderstanding related to our description of the experimental setup since we have exhaustively described the setup in the paper.	Reply	B-Reply	1
We indeed did a systematic grid search to optimize hyperparameters, to which the entire Appendix is dedicated.	Reply	I-Reply	1
Additionally, as mentioned in the paper, with the intended release of the code, our results will be transparent and reproducible, significantly mitigating any uncertainty.	Reply	I-Reply	1
[line_break_token][line_break_token]We believe our results, despite simplicity due to usage of toy examples, are categorical in that they demonstrated a task which two existing models utterly failed to learn, but can be almost perfectly solved when the two mechanisms were combined.	Reply	I-Reply	1
 This has never been reported before.	Reply	I-Reply	1
 [line_break_token][line_break_token]Regard	Reply	O	0

This paper describes a BERT-based pre-training for source code related task.	Review	O	0
By pre-training on BERT-like models on source code and finetuning on a set of 5 tasks, the authors show good performance improvements over non-pretrained models.	Review	O	0
The authors make a series of ablation studies showing that pre-training is indeed useful.	Review	O	0
[line_break_token][line_break_token]Overall, I find this work relevant and interesting, albeit somewhat unsurprising.	Review	O	0
Nevertheless, I see no reason to reject this paper.	Review	O	0
To make my "weak accept" to a "strong accept" I would like to see experiments on more tasks, preferably more complex tasks.	Review	B-Review	1
For example, such tasks could include (a) variable naming (b) method naming (c) docstring prediction/summarization (d) language modeling/autocompletion.	Review	I-Review	1
I believe it's unclear to the reader if pre-training is also helpful for any of those tasks too and adding such experiments would significantly strengthen the paper.	Review	I-Review	1
[line_break_token][line_break_token]Some clarifications comments/questions to the authors:[line_break_token][line_break_token]* I would insist that the authors rename the "Variable Misuse" task to "Variable Misuse Localization".	Review	O	0
To my understanding the current model points to the misused variable (if any), but does not attempt to suggest a fix.	Review	B-Review	2
This tackles only a part of the task discussed in Vasic et al. (	Review	I-Review	2
2019), Allamanis et al (2018) and this might confuse readers who want to compare with those works.	Review	I-Review	2
[line_break_token][line_break_token]* For the Function-Docstring Mismatch task (Section 3.4):[line_break_token]    * It's unclear to me which dataset is used.	Review	O	0
Is it the Py150 dataset or the Barone &amp; Sennrich (2017)?	Review	O	0
[line_break_token]    * I believe that the citations [a], [b] would be appropriate here.	Review	B-Review	3
[line_break_token][line_break_token]* Overall, for the all the tasks except from "Exception Type", there is a replicability issue: Since the authors manually mutate the code (e.g. introduce a variable misuse, swap an operand), for anyone to compare directly, they would need access to the mutated samples.	Review	O	0
I would strongly encourage the authors to provide more details on how they create mutated samples and (eventually) the source code that achieves that.	Review	B-Review	5
[line_break_token][line_break_token]* For the Variable Misuse, Wrong Binary Operator, Swapped Operand tasks.	Review	O	0
There are a few things that need to be clarified:[line_break_token]   * How long is each code snippet?	Review	B-Review	4
One would expect that the longer the code snippet the harder the task.	Review	I-Review	4
Do the authors pass a whole function?	Review	I-Review	4
[line_break_token]   * What is the proportion of positive/negative examples in each task?	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token][a] Cambronero, Jose, et al. "	Review	O	0
When Deep Learning Met Code Search."	Review	O	0
arXiv preprint arXiv:1905.03813 (2019).	Review	O	0
[line_break_token][b] Louis, Annie, et al. "	Review	O	0
Deep learning to detect redundant method comments."	Review	O	0
arXiv preprint arXiv:1806.04616 (2018).	Review	O	0
e thank the reviewer for the helpful comments and suggestions.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt; Addition of more complex task[line_break_token][line_break_token]We have now added a more complex task (Section 4.7), that of joint classification, localization and repair of variable misuse errors as proposed in Vasic et al. (	Reply	O	0
2019).	Reply	B-Reply	1
This requires learning two pointers for localization and repair of variable misuse bugs, and is an extension of the variable misuse classification task we have already considered.	Reply	I-Reply	1
[line_break_token][line_break_token]We had considered the variable and method naming tasks as candidate finetuning tasks.	Reply	I-Reply	1
The masked language modeling (MLM) pre-training task works by masking/replacing tokens (Section 3.5) and training the network to predict them.	Reply	I-Reply	1
Variable and method naming tasks would be very similar to MLM (wherein we mask the names and ask the network to predict the masked tokens) and hence, we decided not to include them in this submission.	Reply	I-Reply	1
[line_break_token][line_break_token]Since CuBERT produces only a pre-trained encoder, the docstring prediction and language modeling/autocomplete tasks would require learning a decoder from scratch.	Reply	I-Reply	1
A recent work on transfer learning (‚ÄúExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer‚Äù, <a href="https://arxiv.org/abs/1910.10683)" target="_blank" rel="nofollow">https://arxiv.org/abs/1910.10683)</a> recasts the BERT pre-training objective into a text-to-text setting, wherein both Transformer encoder and decoder are pre-trained.	Reply	O	0
We consider this reformulation of BERT to be a great future avenue to enable direct finetuning for generative tasks like docstring prediction and autocompletion.	Reply	B-Reply	1
[line_break_token][line_break_token]&gt;&gt; Renaming the Variable Misuse task[line_break_token][line_break_token]The task we had described was a classification task where the model needs to identify if any of the variables in a function body is misused.	Reply	O	0
To avoid any misunderstanding, we have now renamed it to ‚ÄúVariable Misuse Classification‚Äù.	Reply	B-Reply	2
To also match the full task from Vasic et al. (	Reply	I-Reply	2
2019), we now also have the ‚ÄúVariable Misuse Localization and Repair‚Äù task (Section 4.7).	Reply	I-Reply	2
[line_break_token][line_break_token]&gt;&gt; Dataset for the Function-Docstring Mismatch task and related references[line_break_token][line_break_token]The Py150 dataset is used in this task (and all other fine-tuning tasks).	Reply	O	0
We have updated the writeup to make this clear.	Reply	B-Reply	3
Thank you for the references, we have discussed them in the writeup now.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt;&gt; Details on reproducibility[line_break_token][line_break_token]We have added an appendix (Appendix A) with the details of the dataset generation for the finetuning tasks, including a discussion of the careful use of pseudorandomness to ensure reproducible dataset generation.	Reply	O	0
In addition, we plan to release the datasets for public use.	Reply	B-Reply	5
[line_break_token][line_break_token]&gt;&gt; Details on data generation and proportion of positive/negative examples[line_break_token][line_break_token]We have included these details in Appendix A in the revised version.	Reply	O	0

This paper presents DeepAGREL, a framework for biologically plausible deep learning that is modified to use reinforcement learning as a training mechanism.	Review	O	0
This framework is shown to perform similarly to error-backpropagation on a set of architectures.	Review	O	0
The idea relies on feedback mechanism that can resemble local connections between real neurons.	Review	O	0
[line_break_token][line_break_token]This paper is an interesting approach to provide a reinforcement learning paradigm for training deep networks, it is well written and the experiments are convincing, although more explanation about why these specific architectures were tested would be more convincing.	Review	O	0
I also think the assumptions about feedback connections in real neurons should be visited and more neuroscientific evidence from the literature should be included in the paper.	Review	B-Review	2
Do we expect feedback to happen at each level of a neuron-neuron interaction and between each pair of connected neurons?	Review	I-Review	2
Is there a possibility that feedback is more general to sets of neurons, or skips entire layers of neurons?	Review	I-Review	2
I think more neuroscience background would help this paper (and others on the topic).	Review	I-Review	2
Nonetheless, I think the paper does offer an interesting proposal of a more biologically plausible form of deep learning.	Review	I-Review	2
[line_break_token]	Review	O	0
e selected the same architectures as in [Amit2018] as they were tested on another rule with biologically plausible components, we added this as a reference in the text.	Reply	B-Reply	1
[line_break_token]Regarding feedback connections, for reasons of space, we point to the elaborate review paper by Roelfsema and Holtmaat (2018); we also added a reference to the very recent Richards et al. (	Reply	I-Reply	2
2019) paper.	Reply	I-Reply	2
The point about the specificity of forward and backward connections however deserves more study.	Reply	I-Reply	2
We would argue that given reciprocal learning and weight decay, as argued by Akrout et al. (	Reply	I-Reply	2
2019), specificity will emerge.	Reply	I-Reply	2
We added this point (and citation) to the discussion.	Reply	I-Reply	2
[line_break_token][line_break_token]Richards, Blake A., et al. "	Reply	O	0
A deep learning framework for neuroscience.	Reply	O	0
"&nbsp;Nature neuroscience&nbsp;22.11 (2019): 1761-1770.	Reply	O	0
[line_break_token]Akrout, M. M., Wilson, C., Humphreys, P., Lillicrap, T., &amp; Tweed, D. (2019).	Reply	O	0
Deep learning without weight transport	Reply	O	0

(emergency review)[line_break_token][line_break_token]This paper demonstrates that a left-to-right language model suffers a high entropy rate when generating a long-term sequence of words.	Review	O	0
Then the authors claim that this is because of entropy rate amplification, which could be mitigated by 'calibration'.	Review	O	0
With local entropy rate calibration, a language model could achieve lower perplexity generating shorter and concise sequences of words.	Review	O	0
[line_break_token][line_break_token]The proposed technique (local entropy rate calibration) is straightforward to implement, and empirically shown to be effective.	Review	O	0
This would be easily applied to the decoder in many seq2seq models, expected to improve various language generation tasks.	Review	O	0
However, other language models that use bi-directional connections (BERT, RoBERTa, ALBERT) or GAN based language generation models are omitted, and I think these models should be considered to make this work have more impact.	Review	B-Review	1
[line_break_token][line_break_token]	Review	O	0
hanks for the encouraging review.	Reply	O	0
[line_break_token][line_break_token]@Bidirectional models: The trouble with applying our methods to these non-autoregressive language models is that there isn‚Äôt a single probabilistic model to improve.	Reply	O	0
For example, under different masking patterns, there is no guarantee that BERT outputs conditional probabilities consistent with a single distribution over sequences.	Reply	B-Reply	1
Indeed, it remains an open line of research to extract probabilistic models from these non-autoregressively-factorized models (see, e.g. [1]).	Reply	I-Reply	1
We've revised the manuscript with a few citations and a small note about these.	Reply	I-Reply	1
[line_break_token][line_break_token][1] BERT has a mouth, and it must speak: BERT as a markov random field language model.	Reply	O	0
Wang &amp; Cho ‚Äò19	Reply	O	0

This this exciting submission presents a new proof of Leshno's version of the universal approximation property (UAP) for neural networks  -- one of the foundational pillars of our understanding of neural networks.	Review	O	0
The new proof provides new insights into the universal approximation property.	Review	O	0
I consider these the main contribution of the paper.	Review	O	0
Specifically, the authors[line_break_token]- provide an upper bound on the required width for the neural network[line_break_token]- show that the approximation property still holds even if strong further requirements are imposed on the weights of the first or last layer.	Review	O	0
[line_break_token][line_break_token]I rate this submission a weak accept.	Review	O	0
It‚Äôs a very good paper.	Review	O	0
The work makes useful contributions that should and will be of interest to many in the field.	Review	O	0
The paper is generally well-written.	Review	O	0
[line_break_token][line_break_token][line_break_token]Some remarks:[line_break_token][line_break_token]- Being somewhat long, the ‚ÄúProof of Theorem 3.1‚Äù would be a much better read if the authors prefixed it  with an outline of the strategy that the proof takes.	Review	O	0
[line_break_token][line_break_token]- The authors point out that the lack of dependence of Theorem 3.1 on epsilon is surprising, and cite Lin‚Äôs work from 2017 who previously found such an independence.	Review	O	0
Lin‚Äôs derivation of the epsilon-independent UAP is much more intuitive than that of this submission, in which the epsilon independence really pops out somewhat magically and for me only made sense when I read the paper again.	Review	B-Review	2
I would encourage the authors to add to Lin‚Äôs paper‚Äôs citation sentence that this paper motivates the epsilon independence well.	Review	I-Review	2
Alternatively, the authors could add a few sentences to their paper to provide intuition on how the epsilon-independence comes about in their line of argument.	Review	I-Review	2
[line_break_token]	Review	O	0
hank you very much for appreciating our work!	Reply	O	0
[line_break_token][line_break_token]Following your suggestion, we have prefixed the "Proof of Theorem 3.1" with an "Outline of strategy for proving Theorem 3.1".	Reply	B-Reply	1
We hope that the new outline helps improve clarity, and hopefully captures the underlying intuition of our proof.	Reply	I-Reply	2
In particular, we have highlighted (at least an important part of) the underlying intuition for why our upper bound is independent of epsilon	Reply	I-Reply	2

Traditional open-domain QA systems typically have two steps: passage retrieval and aggregating answers extracted from the retrieved passages.	Review	O	0
 This paper essentially follows the same paradigm, but leverages the state-of-the-art reading comprehension models for answer extraction, and develops the neural network models for the aggregating component.	Review	O	0
 Although the idea seems incremental, the experimental results do seem solid.	Review	O	0
 The paper is generally easy to follow, but in several places the presentation can be further improved.	Review	O	0
[line_break_token][line_break_token]Detailed comments/questions:[line_break_token]  1.	Review	O	0
In Sec.	Review	B-Review	2
2.2, the justification for adding H^{aq} and \bar{H}^{aq} is to downweigh the impact of stop word matching.	Review	I-Review	2
 I feel this is a somewhat indirect and less effective design, if avoiding stop words is really the reason.	Review	I-Review	2
 A standard preprocessing step may be better.	Review	I-Review	2
[line_break_token]  2.	Review	O	0
In Sec.	Review	B-Review	2
2.3, it seems that the final score is just the sum of three individual normalized scores.	Review	I-Review	3
It's not truly a "weighted" combination, where the weights are typically assumed to be tuned.	Review	I-Review	3
[line_break_token]  3.	Review	O	0
Figure 3: Connecting the dots in the two subfigures on the right does not make sense.	Review	B-Review	4
 Bar charts should be used instead.	Review	I-Review	4
[line_break_token]  4.	Review	O	0
The end of Sec.	Review	B-Review	5
4.2: I feel it's a bad example, as the passage does not really support the answer.	Review	I-Review	5
The fact that "Sesame Street" got picked is probably just because it's more famous.	Review	I-Review	5
[line_break_token]  5.	Review	O	0
It'd be interesting to see how traditional IR answer aggregation methods perform, such as simple classifiers or heuristics by word matching (or weighted by TFIDF) and counting.	Review	B-Review	6
 This will demonstrates the true advantages of leveraging modern NN models.	Review	I-Review	6
[line_break_token][line_break_token]Pros:[line_break_token]  1.	Review	O	0
Updating a traditional open-domain QA approach with neural models[line_break_token]  2.	Review	O	0
Experiments demonstrate solid positive results[line_break_token][line_break_token]Cons:[line_break_token]  1.	Review	O	0
The idea seems incremental[line_break_token]  2.	Review	O	0
Presentation could be improved[line_break_token]	Review	B-Review	7
Thank you for your feedback and thorough review.	Reply	O	0
We have revised the paper to address the issues you raised  and fixed the presentation issues.	Reply	O	0
[line_break_token][line_break_token]ABOUT THE NOVELTY: [line_break_token][line_break_token]Although traditional QA systems also have the answer re-ranking component, this paper focuses on a novel problem of ``text evidence aggregation'': Here the problem is essentially modeling the relationship between the question and multiple passages (i.e., text evidence), where different passages could enhance or complement each other.	Reply	O	0
For example,  the proposed neural re-ranker models the complementary scenario, i.e., whether the union of different passages could cover different facts in a question, thus the attention-based model is a natural fit.	Reply	B-Reply	1
[line_break_token][line_break_token]In contrast, previous answer re-ranking research did not address the above problem: (1) traditional QA systems like (Ferrucci et al.,	Reply	I-Reply	1
2010) used similar passage retrieval approach with answer candidates added to the queries.	Reply	I-Reply	1
However they usually consider each passage individually for extracting features of answers, whereas we utilize the information of union/co-occurrence of multiple passages by composing them with neural networks. (	Reply	I-Reply	1
2) KB-QA systems (Bast and Haussmann, 2015; Yih et al.,	Reply	I-Reply	1
2015; Xu et al.,	Reply	I-Reply	1
2016) sometimes use text evidence to help answer re-ranking, where the features are also extracted on the pair of a question and a single-passage but ignored the union information among multiple passages.	Reply	I-Reply	1
[line_break_token][line_break_token]We have added the above discussion to our paper (Page 11).	Reply	O	0
[line_break_token][line_break_token]RESPONSE TO THE DETAILED QUESTIONS:[line_break_token][line_break_token]Q1: In Sec.	Reply	O	0
2.2, the justification for adding H^{aq} and \bar{H}^{aq} is to downweigh the impact of stop word matching.	Reply	O	0
 I feel this is a somewhat indirect and less effective design, if avoiding stop words is really the reason.	Reply	O	0
 A standard preprocessing step may be better.	Reply	O	0
[line_break_token] [line_break_token]A1: We follow the model design in (Wang and Jiang 2017).	Reply	O	0
The reason for adding H^{aq} and \bar{H}^{aq} is not only to downweigh the stop word matching, but also to take into consideration the semantic information at each position.	Reply	B-Reply	2
Therefore, the sentence-level matching model (Eq. (	Reply	I-Reply	2
5) in the next paragraph) could potentially learn to distinguish the effects of the element-wise comparison vectors with the original lexical information.	Reply	I-Reply	2
We‚Äôve clarified this on Page 5.	Reply	I-Reply	2
[line_break_token] [line_break_token]Q2: In Sec.	Reply	O	0
2.3, it seems that the final score is just the sum of three individual normalized scores.	Reply	O	0
It's not truly a "weighted" combination, where the weights are typically assumed to be tuned.	Reply	O	0
[line_break_token][line_break_token]A2: We did tune the assigned weights for the three types of normalized scores on the dev set.	Reply	O	0
The tuned version gives some improvement on dev and results in slightly better test scores, compared to simply summing up the three scores.	Reply	B-Reply	3
[line_break_token] [line_break_token]Q3: Figure 3: Connecting the dots in the two subfigures on the right does not make sense.	Reply	O	0
 Bar charts should be used instead.	Reply	O	0
[line_break_token] [line_break_token]A3: We have changed the subfigures to bar charts in the updated version.	Reply	O	0
[line_break_token] [line_break_token]Q4: The end of Sec.	Reply	O	0
4.2: I feel it's a bad example, as the passage does not really support the answer.	Reply	O	0
The fact that "Sesame Street" got picked is probably just because it's more famous.	Reply	O	0
[line_break_token] [line_break_token]A4: We agree that the passages in Table 6 do not provide full evidence to the question (unlike the example in Figure 1b where the passages fully support all the facts in the question).	Reply	O	0
However, the ‚ÄúSesame Street‚Äù got picked not because it is more famous, but because it has supporting evidence in the form of the  "award-winning" and "children's TV show" facts, while the candidate "Great Dane" only covers "1969".	Reply	B-Reply	5
[line_break_token][line_break_token]We selected this example in order to show another common case of realistic problems in Open-Domain QA, where the question is complex and the top-K retrieved passages cannot provide full evidence.	Reply	I-Reply	5
In this case, our model is able to select the candidate with evidence covering more facts in the question (i.e. the candidate that is more likely to be approximately correct).	Reply	I-Reply	5
[line_break_token][line_break_token] [line_break_token]Q5: It'd be interesting to see how traditional IR answer aggregation methods perform, such as simple classifiers or heuristics by word matching (or weighted by TFIDF) and counting.	Reply	O	0
 This will demonstrate the true advantages of leveraging modern NN models.	Reply	O	0
[line_break_token] [line_break_token]A5: Thank you for the valuable advice!	Reply	O	0
We‚Äôve added a baseline method with BM25 value to rerank the answers based on the aggregated passages, together with the analysis about it in the current version.	Reply	B-Reply	6
In summary, the BM25 model improved the F1 scores but sometimes caused a decrease in the EM scores.	Reply	I-Reply	6
 This is mainly for two reasons: (1) BM25 relies on bag-of-word representation, so context information is not taken into consideration.	Reply	I-Reply	6
Also it does not model the phrase similarities. (	Reply	I-Reply	6
2) shorter answers are preferred by BM25.	Reply	I-Reply	6
For example when answer candidate A is a subsequence of B, then according to our way of collecting pseudo passages, the pseudo passage of A is always a superset of the pseudo passage of B. Therefore F1 scores are often improved while EM declines.	Reply	I-Reply	6

This is an excellent analysis paper of a very interesting phenomenon in deep neural networks.	Review	O	0
[line_break_token][line_break_token]Quality, Clarity, Originality:[line_break_token]As far as I know, the paper explores a very relevant and original question -- studying how the learning process of different examples in the dataset varies.	Review	O	0
In particular, the authors study whether some examples are harder to learn than others (examples that are forgotten and relearned multiple times through learning.)	Review	O	0
We can imagine that such examples are "support vectors" for neural networks, helping define the decision boundary.	Review	O	0
[line_break_token][line_break_token]The paper is very clear and the experiments are of very high quality.	Review	O	0
I particularly appreciated the effort of the authors to use architectures that achieve close to SOTA on all datasets to ensure conclusions are valid in this setting.	Review	O	0
I also thought the multiple repetitions and analysing rank correlation over different random seeds was a good additional test.	Review	O	0
[line_break_token][line_break_token]Significance[line_break_token]This paper has some very interesting and significant takeaways.	Review	O	0
[line_break_token]Some of the other experiments I thought were particularly insightful were the effect  on test error of removing examples that aren't forgotten to examples that are forgotten more.	Review	O	0
In summary, the "harder" examples are more crucial to define the right decision boundaries.	Review	O	0
I also liked the experiment with noisy labels, showing that this results in networks forgetting faster.	Review	O	0
[line_break_token][line_break_token]My one suggestion would be to try this experiment with noisy *data* instead of noisy labels, as we are especially curious about the effect of the data (as opposed to a different labelling task.)	Review	B-Review	1
[line_break_token][line_break_token]I encourage the authors to followup with a larger scaled version of their experiments.	Review	I-Review	2
It's possible that for a harder task like Imagenet, a combination of "easy" and "hard" examples might be needed to enable learning and define good decision boundaries.	Review	I-Review	2
[line_break_token][line_break_token]I argue strongly for this paper to be accepted to ICLR, I think it will be of great interest to the community.	Review	O	0
Thank you for your review and suggestions.	Reply	O	0
[line_break_token][line_break_token]We performed two additional experiments in CIFAR-10 and have presented the results in the updated supplementary.	Reply	B-Reply	2
We are happy to include any parts that the reviewer finds helpful in the main paper.	Reply	I-Reply	2
[line_break_token][line_break_token]1.	Reply	I-Reply	2
We corrupt all training images with additive Gaussian noise with mean 0 and increasing standard deviation (std 0.5, 1, 2, 10), and track the forgetting events during training as usual.	Reply	I-Reply	2
Note that we add the noise after a channel-wise standard normalization step of the training images (zero mean, unit variance).	Reply	I-Reply	2
Therefore, noise with standard deviation of 2 has twice the standard deviation of the unperturbed training data.	Reply	I-Reply	2
[line_break_token][line_break_token]We present the results in Figure 11 in Appendix 10.	Reply	I-Reply	2
 We observe that adding increasing amount of noise decreases the amount of unforgettable examples and increases the amount of examples in the second mode of the forgetting distribution.	Reply	I-Reply	2
[line_break_token][line_break_token]2.	Reply	O	0
We follow the label noise experiments presented in Figure 3, and augment only random 20% of the training data with additive Gaussian noise (mean 0, std 10).	Reply	B-Reply	1
We present the results of comparing the forgetting distribution of the 20% of examples before and after pixel noise was added in Figure 12 (Left) in Appendix 10.	Reply	I-Reply	1
We observe that the forgetting distribution under pixel noise resembles the one under label noise.	Reply	I-Reply	1
It is a very interesting observation that we plan to investigate in the future.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that it is important to follow-up with a dataset like Imagenet and will pursue this direction in our future work	Reply	O	0

This paper proposes a model for point processes using normalizing flows.	Review	O	0
The conditional distributions of next inter-arrival times are modeled as normalizing flows with base distributions conditioned on the history.	Review	O	0
Continuous-time flow based on neural ODE was employed.	Review	O	0
[line_break_token][line_break_token]Overall I find this paper incremental.	Review	B-Review	1
There have been several works using deep generative models to temporal data, and the proposed method is a simple combination of well-established existing works without problem-specific adaptation.	Review	I-Review	1
[line_break_token][line_break_token]I don‚Äôt get the point of using VAE in the likelihood estimation.	Review	I-Review	2
The model (PPF-D) already defines a flexible conditional distribution.	Review	I-Review	2
The only reason I can imagine to introduce VAE type model is when the dimension of the latent variables (which should be strictly the same as the observed variable) is too large to model directly.	Review	I-Review	2
In such case one may choose to optimize a lower bound computed from the variational distribution defined over the lower-dimensional latent spaces.	Review	I-Review	2
Hence in case of temporal point processes where the dimension is one, I see no point of doing VAE.	Review	I-Review	2
The authors stated that VAE based model (PPF-P) performs better than ordinary flow model (PPF-D) because PPF-P has more flexible base distribution.	Review	I-Review	2
My guess is that PPF-P has one more stochastic layer so the architecture itself is more expressive than PPF-D. PPF-D with more complex structure (e.g., more layers in base distribution parameter network) may result in a similar performance.	Review	I-Review	2
[line_break_token][line_break_token]The authors stated in coclusion section that ‚ÄúThe proposed PPF can be optimized by maximizing the exact likelihood‚Äù, which is not true for PPF-P optimizing the lower bound.	Review	I-Review	2
hank you for your time and review.	Reply	O	0
We would like to clarify main concerns and raised questions.	Reply	O	0
 [line_break_token][line_break_token]C1.	Reply	O	0
Overall I find this paper incremental.	Reply	O	0
There have been several works using deep generative models to temporal data, and the proposed method is a simple combination of well-established existing works without problem-specific adaptation.	Reply	O	0
[line_break_token][line_break_token]R1.	Reply	O	0
We would like to clarify our contribution and the importance of employing each technique in modeling point process distributions.	Reply	B-Reply	1
[line_break_token]In this paper, we proposed a new perspective on modelling point process distributions which directly estimates the density of conditional point process distribution by utilizing normalizing flow.	Reply	I-Reply	1
The main advantage of this method in comparison to the intensity-based methods is that we are able to model arbitrary complex point process distributions without making any parametric assumption on the functional form of the distribution while being able to evaluate the likelihood.	Reply	I-Reply	1
[line_break_token]In order to make our model more expressive and flexible, we proposed to have base-distributions with probabilistic parameters by utilizing variational auto-encoder paradigm.	Reply	I-Reply	1
When using flow techniques for density estimation, the expressiveness of the model is not only limited by the complexity of normalizing flow transformations, but also by the class of base-distributions.	Reply	I-Reply	1
In our proposed framework, the fact that flow transformations are shared across time-steps and the true underlying distribution across time-steps might vary a lot, makes our model more sensitive to the choice of base distribution family.	Reply	I-Reply	1
We believe that, If we choose to model base distributions with Gaussian distribution with deterministic parameters, the bijective transformation might not be able to estimate underlying distributions well, especially when the the ground-truth target distributions vary a lot across time-steps of all the sequences.	Reply	I-Reply	1
 We further support our claim by proving Proposition 1 in Appendix A which, intuitively speaking, says more flexible base-distribution yields more expressive model.	Reply	I-Reply	1
[line_break_token]In order to address this shortcoming, we proposed more flexible base distributions where the parameters are probabilistically modeled using variational auto-encoder framework.	Reply	I-Reply	1
The flexibility comes from the fact that by marginalizing over the latent space of VAE , the base distribution could be highly flexible.	Reply	I-Reply	1
The base distribution of follows different Gaussian distributions conditioned on different samples of.	Reply	I-Reply	1
[line_break_token][line_break_token]To demonstrate the power of our proposed probabilistically modeled base-distribution , we designed a synthetic experiment as follows:[line_break_token][line_break_token]-     We construct a dataset of sequences, where in each sequence, the underlying distribution at each time-step varies from a unimodal Gaussian distribution (at odd time steps) to a bimodal Gaussian distribution (at even time steps).	Reply	I-Reply	2
[line_break_token]-    We chose one mode (N(4,1)) to be the same between even and odd time steps.	Reply	O	0
[line_break_token]-     The motivation for this experiment is as follows.	Reply	O	0
For PPF-D, by modelling the base distribution with the deterministic parameters , in our example there is no one-to-one transformation that can map two Gaussian base distributions exactly into a uni-modal and a multi-modal distribution respectively at the same time.	Reply	B-Reply	2
In other words, if a singular one-to-one mapping can map a Gaussian distribution to the mixture of Gaussian distribution in our example, the inverse mapping of either component of the mixture of Gaussians can not be a Gaussian.	Reply	I-Reply	2
Please see  Preposition 1 and its proof that are provided in Appendix A. [line_break_token]-     On the contrary, PPF-P, with a more flexible base-distribution, should be able to better estimate the true distribution.	Reply	O	0
[line_break_token]-     We visualized  samples generated by both PPF-P and PPF-D for an even and odd time-step.	Reply	O	0
The results illustrate when the true underlying distribution is mixture of Gaussians, PPF-D covers both components of the kernels but most of the samples are concentrated in an area of low probability, somewhere in between the means of components of mixture distribution.	Reply	B-Reply	2
In contrast, the results show that PPF-P, with a more flexible base-distribution is much better in estimating the true underlying distribution.	Reply	I-Reply	2
 Most of the data sampled from PPF-P model lie in the high-probability region.	Reply	I-Reply	2
[line_break_token]-    We reported the log-likelihood of test data for both PPF-P and PPF-D and also reported the difference of log-likelihood under the true distribution and log-likelihood under the learned models (LL score).	Reply	O	0
 The better estimation of PPF-P is confirmed by having a higher log-likelihood and a lower LL score in comparison to PPF-D. [line_break_token][line_break_token]Please see Appendix A for experimental results and more details on this example.	Reply	O	0
[line_break_token]	Reply	O	0

The authors present an in-depth study of discretizing / quantizing the input as a defense against adversarial examples.	Review	O	0
The idea is that the threshold effects of discretization make it harder to find adversarial examples that only make small alterations of the image, but also that it introduces more non-linearities, which might increase robustness.	Review	O	0
In addition, discretization has little negative impact on the performance on clean data.	Review	O	0
The authors also propose a version of single-step or multi-step attacks against models that use discretized inputs, and present extensive experiments on MNIST, CIFAR-10, CIFAR-100 and SVHN, against standard baselines and, on MNIST and CIFAR-10, against a version of quantization in which the values are represented by a small number of bits.	Review	O	0
[line_break_token][line_break_token]The merits of the paper is that the study is rather comprehensive: a large number of datasets were used, two types of discretization were tried, and the authors propose an attack mechanism better that seems reasonable considering the defense they consider.	Review	O	0
The two main claims of the paper, namely that discretization doesn't hurt performance on natural test examples and that better robustness (in the author's experimental setup) is achieved through the discretized encoding, are properly backed up by the experiments.	Review	O	0
[line_break_token][line_break_token]Yet, the applicability of the method in practice is still to be demonstrated.	Review	B-Review	1
The threshold effects might imply that small perturbations of the input (in the l_infty sense) will not have a large effect on their discritized version, but it may also go the other way: an opponent might be able to greatly change the discretized input without drastically changing the input.	Review	I-Review	1
Figure 8 in the appendix is a bit worrysome on that point, as the performance of the discretized version drops rapidly to 0 when the opponents gets a bit stronger.	Review	I-Review	1
Did the authors observe the same kind of bahavior on other datasets?	Review	I-Review	1
What would the authors propose to mitigate this issue?	Review	I-Review	1
To what extend the good results that are exhibited in the paper are valid over the wide range of opponent's strengths?	Review	I-Review	1
[line_break_token][line_break_token]minor comment:[line_break_token]- the experiments on CIFAR-100 in Appendix E are carried out by mixing adversarial / clean examples while training, whereas those on SVHN in Appendix F use adversarial examples only.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your feedback!	Reply	O	0
[line_break_token][line_break_token]> ...the performance of the discretized version drops rapidly to 0 when the opponents gets a bit stronger.	Reply	O	0
[line_break_token][line_break_token]We observe this behavior on the datasets we tested on, which were MNIST and CIFAR. (	Reply	B-Reply	1
CIFAR does not drop all the way to 0, but does drop sharply.)	Reply	I-Reply	1
We believe that this is an expected result, stemming from the intuition that the relationship between the input and the loss is highly nonlinear.	Reply	I-Reply	1
When presented with an input which it has never been exposed to (i.e. a pixel has been moved into a bucket that is beyond the adversarial training threshold), the effect on the loss is highly random.	Reply	I-Reply	1
Many of these perturbed inputs will increase the loss, and it is therefore easy to find an adversarial example.	Reply	I-Reply	1
[line_break_token][line_break_token]Controlling for the wide range of opponent‚Äôs strengths is an important issue, one which is endemic to adversarial defenses in general.	Reply	I-Reply	1
The ‚Äústandard setting‚Äù for the adversarial example problem (in which we constrain the L-infinity norm of the perturbed image to an epsilon ball around the original image) was designed to ensure that any adversarially-perturbed image is still recognizable as its original image by a human.	Reply	I-Reply	1
However, this artificial constraint excludes many other potential attacks that also result in human-recognizable images.	Reply	I-Reply	1
State-of-the art defenses in the standard setting can still be easily defeated by non-standard attacks; for recent examples of this, see ICLR submission ‚ÄúAdversarial Spheres‚Äù (appendix A), as well as ‚ÄúAdversarial Patch‚Äù by Brown et.	Reply	I-Reply	1
al (<a href="https://arxiv.org/abs/1712.09665)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1712.09665).</a>[line_break_token][line_break_token]With this in mind, we believe that the fact that the performance of thermometer-encoded models degrades more quickly than that of vanilla models beyond the training epsilon is a weakness, but no worse in practice than other defenses.	Reply	O	0
A ‚Äúlarger epsilon‚Äù attack is just one special case of a ‚Äúnon-standard‚Äù attack; there are an enormous number of other non-standard attacks, some of which are more effective against vanilla models, some of which are more effective against thermometer encodings, and some of which are devastating to both.	Reply	B-Reply	1
If we permit non-standard attacks, a fair comparison would show that all current approaches are easily breakable.	Reply	I-Reply	1
There is nothing special about the ‚Äúlarger epsilon‚Äù attack that makes a vulnerability to this non-standard attack in particular more problematic than vulnerabilities to other non-standard attacks, in practice.	Reply	I-Reply	1
[line_break_token][line_break_token]Additionally, on the CIFAR dataset, we found that even though discretized inputs are impacted much more severely by examples perturbed by more than the training threshold, the discretized models are sufficiently strong to begin with that they still outperform real-valued models even after this vulnerability has been exploited. (	Reply	I-Reply	1
See updated Figure 8b.)	Reply	I-Reply	1
CIFAR is more reflective of real-world datasets, so even with this weakness, thermometer-encoded models may outperform real-valued models in practice.	Reply	I-Reply	1
[line_break_token][line_break_token]Based on your feedback, we updated our submission to include this discussion in Appendix G, and added Figure 8b showing the CIFAR results.	Reply	I-Reply	1
Also, we discovered a bug which caused the unquantized attack in Figure 8 to be too weak; essentially, we were using a fixed step size of 0.01 for 40 steps which caused the perturbation to never hit the boundary for epsilon > 0.4.	Reply	O	0
We have updated the figure to reflect the correct values. (	Reply	B-Reply	1
The fixed results are qualitatively equivalent, so this change does not affect the conclusions.)	Reply	I-Reply	1

The paper proposed a problem that most prior methods overlooked the underlying dependency of classes on domains, namely p (y|d) \= p(y).	Review	O	0
  Figure 1 is used to illustrate this issue.	Review	O	0
[line_break_token][line_break_token]If the conditional probability of source domain and target domain is not equal (i.e., p(y|x_S) \= p(y|x_T)  ), the optimal invariance can lead the same generalization problem.	Review	O	0
  Unfortunately, a lot of works has been done [1,2] in matching domain classifier or conditional probability.	Review	O	0
 It is desirable to discuss the difference between these two problems and compared with the missing references in experiments.	Review	O	0
[line_break_token][line_break_token]It is also suggested to conduct the analysis of why the datasets satisfy the assumption of the dependence of class and domains.	Review	O	0
[line_break_token][line_break_token]Reference:[line_break_token][1] Flexible Transfer Learning under Support and Model Shift, NIPS 2014.	Review	O	0
[line_break_token][2]Conditional Adversarial Domain Adaptation, NIPS 2018	Review	O	0
Thank you for your critical feedback.	Reply	O	0
[line_break_token]We hope to clarify and address your concerns and questions.	Reply	O	0
[line_break_token]We respond in detail to each comment below.	Reply	O	0
[line_break_token][line_break_token][line_break_token]### Reply to ‚Äúit is desirable to discuss the difference between these two problems‚Äù[line_break_token][line_break_token]In our understanding, your main concern is the novelty of our problem setting, i.e., ‚Äúis domain generalization under domain-class dependency (p(y|d) \neq p(y)) is different from domain adaptation under p(y|x_S) \neq p(y|x_T) ?‚	Reply	O	0
Äù[line_break_token]We acknowledge that we lack the discussion about the difference between these two (though they are indeed considerably different problems), so we have added the below discussion to the paper and emphasized the novelty of our problem setting.	Reply	B-Reply	1
[line_break_token][line_break_token]Firstly, the paper addresses {\em domain generalization}, not domain adaptation, as noted in abstract, Sec.1, etc.	Reply	I-Reply	1
[line_break_token]These two have different assumptions and purposes.	Reply	I-Reply	1
[line_break_token]Concretely, domain adaptation methods require either labeled or unlabeled data from the target domain at training time.	Reply	I-Reply	1
[line_break_token]In contrast, domain generalization methods do not require any data from target domains during training but instead, require labeled data from several source domains.	Reply	I-Reply	1
[line_break_token]Then the methods collectively exploit them so that the trained system can handle new domains without any adaptation step.	Reply	I-Reply	1
[line_break_token][line_break_token]Due to the difference, domain adaptation methods are not always applicable to domain generalization.	Reply	I-Reply	1
[line_break_token]For example, Wang+2014, which you suggested for us, transform unlabeled target data so that they can correct distributional shift, but in domain generalization, target data are unavailable.	Reply	I-Reply	1
[line_break_token]Also, please note that we care about the shifts within source domains, because domain generalization methods are agnostic on the target domain.	Reply	I-Reply	1
[line_break_token]So we think p(y|x_S) \neq p(y|x_T) should be rewritten as p(y|x, d) \neq p(y|x) (we call it conditional probability shift) in domain generalization, so that clarify we focus on the shift within source domains (not between S and T).	Reply	I-Reply	1
[line_break_token][line_break_token]Secondly, conditional probability shift (p(y|x, d) \neq p(y|x)), which is often caused by the causal structure y -> x, is not a sufficient condition for p(y|d) \neq p(y).	Reply	O	0
[line_break_token]While conditional probability shift was previously addressed by Li+2018 in domain generalization context, domain-class dependency has been overlooked.	Reply	B-Reply	1
[line_break_token]The relation between these two problems is illustrated in Figure 1 in our updated paper.	Reply	I-Reply	1
[line_break_token][line_break_token]Thirdly and most importantly, in domain generalization, conditional probability shift does not cause the trade-off problem as long as the domain-class dependency does not exist.	Reply	I-Reply	1
[line_break_token]In other words, p(y|x, d) \neq p(y|x) is not a root cause of the trade-off problem, but domain-class dependency is, so it is essential to consider and address domain-class dependency problem.	Reply	I-Reply	1
[line_break_token]Again the relation between these two problems is illustrated in Figure 1 in our updated paper.	Reply	I-Reply	1

The authors proposed a new method to learn streaming online updates for neural networks with meta-learning and applied it to multi-task reinforcement learning.	Review	O	0
Model-agnostic meta-learning is used to learn the initial weight and task distribution is learned with the Chinese restaurant process.	Review	O	0
It sounds like an interesting idea and practical for RL.	Review	O	0
Extensive experiments show the effectiveness of the proposed method.	Review	O	0
[line_break_token][line_break_token]The authors said that online updating the meta-learner did not improve the results, which is a bit surprised.	Review	B-Review	1
Also how many data are meta-trained is not clearly described in the paper.	Review	I-Review	2
Maybe the authors can compare the results with less data for meta-training.	Review	I-Review	3
[line_break_token]	Review	O	0
Thank you for your review.	Reply	O	0
We added an appendix to the paper that addresses your question, and we have also added this information (as well as illustrative videos) to the project website.	Reply	O	0
To illustrate results with less meta-training data, we have evaluated the test-time performance of models from various meta-training iterations, showing that performance does indeed improve with more meta-training data.	Reply	B-Reply	3
To clarify, this statement of performance improving with meta-training data is different from the statement in the text regarding online updating the meta-learner not improving results.	Reply	I-Reply	3
We meant that incorporating the EM weight updates during meta-training did not improve results, but we did not mean that additional meta-learning was harmful.	Reply	I-Reply	3
We added text at the end of section 5 in the updated paper to reduce the potential for confusion.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding the amount of data used, the number of datapoints used during metatraining on each of the agents in our experiments is 382,000: This is 12 iterations of alternating model training plus on-policy rollouts, where each iteration collects data from 16 different environment settings, and each setting consists of 2000 datapoints.	Reply	I-Reply	2
At a simulator timestep of 0.02sec/step, this sample complexity converts to around only 2 hours of real-world data	Reply	I-Reply	2

This paper studies the issue of truncated backpropagation for meta-optimization.	Review	O	0
Backpropagation through an optimization process requires unrolling the optimization, which due to computational and memory constraints, is typically restricted or truncated to a smaller number of unrolled steps than we would like.	Review	O	0
[line_break_token][line_break_token]This paper highlights this problem as a fundamental issue limiting meta-optimization approaches.	Review	O	0
The authors perform a number of experiments on a toy problem (stochastic quadratics) which is amenable to some theoretical analysis as well as a small fully connected network trained on MNIST.	Review	O	0
 [line_break_token][line_break_token](side note: I was assigned this paper quite late in the review process, and have not carefully gone through the derivations--specifically Theorems 1 and 2).	Review	O	0
[line_break_token][line_break_token]The paper is generally clear and well written.	Review	O	0
[line_break_token][line_break_token]Major comments[line_break_token]-------------------------[line_break_token]I was a bit confused why 1000 SGD+mom steps pre-training steps were needed.	Review	O	0
As far as I can tell, pre-training is not typically done in the other meta-optimization literature?	Review	B-Review	1
The authors suggest this is needed because "the dynamics of training are different at the very start compared to later stages", which is a bit vague.	Review	I-Review	1
Perhaps the authors can expand upon  this point?	Review	I-Review	1
[line_break_token][line_break_token]The conclusion suggests that the difference in greedy vs. fully optimized schedule is due to the curvature (poor scaling) of the objective--but Fig 2.	Review	I-Review	2
and earlier discussion talked about the noise in the objective as introducing the bias (e.g. from earlier in the paper, "The noise in the problem adds uncertainty to the objective, resulting in failures of greedy schedule").	Review	I-Review	2
Which is the real issue, noise or curvature?	Review	I-Review	2
Would running the problem on quadratics with different condition numbers be insightful?	Review	I-Review	2
[line_break_token][line_break_token]Minor comments[line_break_token]-------------------------[line_break_token]The stochastic gradient equation in Sec 2.2.2 is missing a subscript: "h_i" instead of "h"[line_break_token][line_break_token]It would be nice to include the loss curve for a fixed learning rate and momentum for the noisy quadratic in Figure 2, just to get a sense of how that compares with the greedy and optimized curves.	Review	O	0
[line_break_token][line_break_token]It looks like there was an upper bound constraint placed on the optimized learning rate in Figure 2--is that correct?	Review	B-Review	5
I couldn't find a mention of the constraint in the paper. (	Review	I-Review	5
the optimized learning rate remains at 0.2 for the first ~60 steps)?	Review	I-Review	5
[line_break_token][line_break_token]Figure 2 (and elsewhere): I would change 'optimal' to 'optimized' to distinguish it from an optimal curve that might result from an analytic derivation. '	Review	I-Review	6
Optimized' makes it more clear that the curve was obtained using an optimization process.	Review	I-Review	6
[line_break_token][line_break_token]Figure 2: can you change the line style or thickness so that we can see both the red and blue curves for the deterministic case?	Review	I-Review	7
I assume the red curve is hiding beneath the blue one--but it would be good to see this explicitly.	Review	I-Review	7
[line_break_token][line_break_token]Figure 4 is fantastic--it succinctly and clearly demonstrates the problem of truncated unrolls.	Review	I-Review	8
I would add a note in the caption to make it clear that the SMD trajectories are the red curves, e.g.: "SMD trajectories (red) during meta-optimization of initial effective ...".	Review	I-Review	8
I would also change the caption to use "meta-training losses" instead of "training losses" (I believe those numbers are for the meta-loss, correct?).	Review	I-Review	8
Finally, I would add a colorbar to indicate numerical values for the different grayscale values.	Review	I-Review	8
[line_break_token][line_break_token]Some recent references that warrant a mention in the text:[line_break_token]- both of these learn optimizers using longer numbers of unrolled steps:[line_break_token]Learning gradient descent: better generalization and longer horizons, Lv et al, ICML 2017[line_break_token]Learned optimizers that scale and generalize, Wichrowska et al, ICML 2017[line_break_token]- another application of unrolled optimization:[line_break_token]Unrolled generative adversarial networks, Metz et al, ICLR 2017[line_break_token][line_break_token]In the text discussing Figure 4 (middle of pg.	Review	O	0
8) , "which is obtained by using..." should be "which are obtained by using..."[line_break_token][line_break_token]In the conclusion, "optimal for deterministic objective" should be "deterministic objectives"	Review	O	0
Q1: Why 1000 SGD+mom steps pre-training steps were needed?	Reply	O	0
[line_break_token]We want to choose a setting that our observation is less sensitive to which part of training.	Reply	B-Reply	1
If we always start looking ahead at zeroth step, then there is a higher chance that the optimal hyperparameter is only fitted to the beginning; whereas if we start at some pre-trained steps, e.g. 1000, then the optimal hyperparameter is more likely to generalize to, say 500 or 5000 steps.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: Which is the real issue, noise or curvature?	Reply	O	0
[line_break_token]The problem will arise if you have both noise in the objective and different curvature directions.	Reply	B-Reply	2
We showed that in a deterministic problem, the greedy optimal learning rate and momentum is optimal as it is essentially doing conjugate gradient, regardless of how many different curvature directions you have.	Reply	I-Reply	2
We also showed in theorem 3 that the greedy learning rate is optimal if the curvature is spherical.	Reply	I-Reply	2
 On the other hand, if there‚Äôs noise in the objective, and there are many different curvature directions the problem will arise.	Reply	I-Reply	2
This is because, the noise in the objective forbids one to completely get rid of the loss on a particular direction.	Reply	I-Reply	2
Hence, one should always first remove the loss on low curvature directions and then move onto high curvature directions.	Reply	I-Reply	2
But short-horizon objective encourages the opposite because high curvature directions gives most rapid decrease in loss.	Reply	I-Reply	2
Therefore, both noise in the objective and different curvature directions cause the problem.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: Figure 2: 1.	Reply	O	0
Show fixed learning rate.	Reply	O	0
2.	Reply	O	0
Thickness of the red curve.	Reply	O	0
3.	Reply	O	0
Upper bound.	Reply	O	0
[line_break_token]Figure 2 is edited as reviewer suggests.	Reply	B-Reply	7
Also the reviewer is correct that we upper bounded the learning rate to avoid the loss on any curvature direction becoming larger than its initial value, so as to assure the quadratic assumption.	Reply	I-Reply	7
We added the description in the revised version.	Reply	I-Reply	7
[line_break_token][line_break_token]Q4: Figure 4: 1.	Reply	O	0
Add a color bar to indicate numerical values for the different grayscale values.	Reply	O	0
[line_break_token]Thanks for the suggestion.	Reply	B-Reply	8
We will add it in the next version of our paper.	Reply	I-Reply	8
[line_break_token][line_break_token]Q5: Citations:[line_break_token]We added those citations reviewer mentioned.	Reply	O	0

This paper studies the problem of part segmentation in objects represented as a point cloud.	Review	O	0
The main novelty is in the fact that the proposed method uses a bottom-up iterative merging framework inspired by perceptual grouping and finds that it transfers better to unseen categories.	Review	B-Review	7
In zero-shot transfer experiments, the proposed method performs better than all four other baselines compared; but is worse than Mo et al. (	Review	I-Review	1
2019) in known categories.	Review	I-Review	1
[line_break_token][line_break_token]The paper hypothesizes that top-down approaches do not generalizes well to new categories because they end up overfitting to the global context.	Review	O	0
While this is reasonable, I find that the experiments are not sufficient to validate this claim (please see questions below).	Review	B-Review	6
Evaluation on unseen object categories is an underexplored topic, and the paper is generally well written.	Review	I-Review	6
I think the submission can be an above-threshold paper if the questions are addressed.	Review	I-Review	6
[line_break_token][line_break_token]- I‚Äôd like to see some evidence for the claim that classic segmentation methods "can perform much better for unseen object classes" (last paragraph of page 1), and see how the proposed method compares to those baselines.	Review	O	0
[line_break_token][line_break_token]- If my understanding of Table 3 is correct, "PartNet-InsSeg" (Mo et al.	Review	O	0
2019) is a top-down approach yet it performs better than SGPN which is a bottom-up grouping method (as summarized on page 7) in novel categories.	Review	B-Review	3
If so, can it be explained in a way that is consistent with the paper's findings?	Review	I-Review	3
[line_break_token][line_break_token]- Table 4 shows some ablation study in an attempt to justify the proposed design, but I think it should be more thorough.	Review	O	0
e.g. it is not immediately obvious why the authors did not included a baseline that consists only of the rectification module with a termination threshold (seems like the most basic design that doesn't have the large-part bias or explicitly require a termination module).	Review	B-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]Typos:[line_break_token][line_break_token]psilon-greedy   (page 6 paragraph 2)[line_break_token]backpropogation  (page 6 under training losses)[line_break_token]In consequences (page 5 under termination network)[line_break_token]epilson  (page 5, under network training)	Review	O	0
e thank Reviewer #2 for the feedback and suggestions.	Reply	O	0
The suggestions are helpful, and we are open to further discussions.	Reply	O	0
[line_break_token][line_break_token]From the comments, we infer that Reviewer #2 assumes our claim to be that top-down approaches perform worse than bottom-up approaches in terms of generalization abilities.	Reply	B-Reply	7
This is not exactly our view.	Reply	I-Reply	7
Here, we precisely lay out our argument: Using features with the global context may hurt part segmentation performance in unseen categories.	Reply	I-Reply	7
In most top-down pipelines and some bottom-up pipelines, the features extracted for each point to be fed to the classifier would include the global context.	Reply	I-Reply	7
This point will be further discussed when addressing specific concerns.	Reply	I-Reply	7
[line_break_token][line_break_token][line_break_token][Regarding ‚ÄúPartNet-InsSeg‚Äù outperforms ‚ÄúSGPN‚Äù in novel categories][line_break_token]Both ‚ÄúPartNet-InsSeg‚Äù (top-down) and the ‚ÄúSGPN‚Äù (bottom-up) involve global context to learn point features and make decisions, thus give inferior segmentation results on unseen categories.	Reply	O	0
This is consistent with our conclusions.	Reply	B-Reply	3
We are happy to make this point crystally clear in the revised version.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token][line_break_token][Regarding the performance of the tradition segmentation methods and the proposed method][line_break_token]WCseg is one of the most feasible traditional segmentation methods, whose results are provided in Table 1.	Reply	O	0
Compared to the learning-based methods, It champions 6 out of 21 unseen categories.	Reply	B-Reply	2
Also, we have added more qualitative results to Appendix C.3, which demonstrates the performance of both the traditional segmentation method and the proposed method.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token][line_break_token][Regarding the ablation studies][line_break_token]Thanks for pointing this out, and we made the ablation studies more thorough in revision, including the effects of involving more context on both seen and unseen categories, more components analysis, and qualitative results of the rectification module.	Reply	O	0
 Please refer to Appendix B for details.	Reply	B-Reply	4
[line_break_token][line_break_token]Since the policy scores sum to one overall pairs of sub-parts, there is no explicit signal from the policy network whether the pair should be grouped.	Reply	I-Reply	4
 We therefore introduce the termination module to verify whether we should group the pair of sub-parts, selected based on the score from the policy module.	Reply	I-Reply	4
We noticed that the name of ‚Äútermination module‚Äù may have confused reviewers, so we would rename it as ‚Äúverification module‚Äù.	Reply	I-Reply	4
Also, there is indeed a cascaded structure where the termination module will focus on the samples selected by the policy module.	Reply	I-Reply	4
This serves as a kind of hard example mining and complements the policy module, which needs to recognize so many samples.	Reply	I-Reply	4
We will make the related descriptions clearer in revision.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token][line_break_token][Regarding the proposed method performs worse than Mo et al. (	Reply	O	0
2019) in seen categories][line_break_token]With involved limited context only for seen categories, our proposed method further improves the performance in seen categories.	Reply	O	0
Please refer to Table 1,6 for new results and Appendix B.1 for details.	Reply	B-Reply	1

To achieve the state-of-the-art on the CLEVR and the variations of this, the authors propose a method to use object-based visual representations and a differentiable quasi-symbolic executor.	Review	O	0
Since the semantic parser for a question input is not differentiable, they use REINFORCE algorithm and a technique to reduce its variance.	Review	O	0
[line_break_token][line_break_token]Quality: [line_break_token]The issue of invalid evaluation should be addressed.	Review	O	0
CLEVR dataset has train, validation, and test sets.	Review	B-Review	1
Since the various hyper-parameters are determined with the validation set, the comparison of state-of-the-art should be done using test set.	Review	I-Review	1
As the authors mentioned, REINFORCE algorithm may introduce high variance, this notion is critical to report valid results.	Review	I-Review	1
However, the authors only report on the validation set in Table 2 including the main results, Table 4.	Review	I-Review	1
For Table 5, they only specify train and test splits.	Review	I-Review	1
Therefore, I firmly recommend the authors to report on the test set for the fair comparison with the other competitive models, and please describe how to determine the hyperparameters in all experimental settings.	Review	I-Review	1
[line_break_token]   [line_break_token]Clarity:[line_break_token]As mentioned above, please specify the experimental details regarding setting hyperparameters.	Review	O	0
[line_break_token]In Experiments section, the authors used less than 10% of CLEVR training images.	Review	B-Review	2
How about to use 100% of the training examples?	Review	I-Review	2
How about to use the same amount of training examples in the competitive models?	Review	I-Review	2
The report is incomplete to see the differential evident from the efficient usage of training examples.	Review	I-Review	2
[line_break_token][line_break_token]Originality and significance:[line_break_token]The authors argue that object-based visual representation and symbolic reasoning are the contributions of this work (excluding the recent work, NS-VQA < 1 month).	Review	O	0
However, bottom-up and top-down attention work [1] shows that attention networks using object-based visual representation significantly improve VQA and image captioning performances.	Review	B-Review	3
If the object-based visual representation alone is the primary source of improvement, it severely weakens the argument of the neuro-symbolic concept learner.	Review	I-Review	3
Since, considering the trend of gains, the contribution of the proposing method seems to be incremental, this concern is inevitable.	Review	I-Review	3
To defend this critic, the additional experiment to see the improvement of the other attentional model (e.g, TbD, MAC) using object-based visual representations, without any other annotations, is needed.	Review	I-Review	3
[line_break_token][line_break_token]Pros:[line_break_token]- To confirm the effective learning of visual concepts, words, and semantic parsing of sentences, they insightfully exploit the nature of the CLEVR dataset for visual reasoning diagnosis.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- Invalid evaluation to report only on the validation set, not test set.	Review	O	0
[line_break_token]- The unclear significance of the proposed method combining object-based visual representations and symbolic reasoning[line_break_token]- In the original CLEVR dataset paper, the authors said "we stress that accuracy on CLEVR is not an end goal in itself" and "..CLEVR should be used in conjunction with other VQA datasets in order to study the reasoning abilities of general VQA systems."	Review	O	0
Based on this suggestion, can this work generalize to real-world settings?	Review	B-Review	4
This paper lacks to discuss its limitation and future direction toward the general problem settings.	Review	I-Review	4
[line_break_token][line_break_token]Minor comments:[line_break_token]In 4.3, please fix the typos, "born" -> "brown" and "convlutional" -> "convolutional".	Review	O	0
[line_break_token][line_break_token][line_break_token][1] Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., & Zhang, L. (2018).	Review	O	0
Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering.	Review	O	0
IEEE Computer Vision and Pattern Recognition (CVPR'18).	Review	O	0
Thank you very much for the constructive comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Train/test split[line_break_token]Our evaluation is valid and fair, because all previous papers have also reported results only on the validation set, and we follow the tradition in this paper.	Reply	B-Reply	1
They did this because there are no ground-truth labels or evaluation servers provided for the CLEVR test split.	Reply	I-Reply	1
Evaluation on the test split is therefore impossible.	Reply	I-Reply	1
We agree that it‚Äôs important to ensure all evaluation valid, and we‚Äôll include this clarification into the revision.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Object-based representations and baselines[line_break_token]Thanks for the suggestion.	Reply	O	0
We‚Äôll cite and discuss the paper that used object-based visual representation.	Reply	B-Reply	3
We will also add additional experiments that incorporate object-based representations into TbD/MAC: Instead of the image feature extracted from a ResNet, we change the input visual feature to the reasoning neural architecture to be an object-based representation as in [1]. Please let us know if you have any suggestion regarding the comparison.	Reply	I-Reply	3
[line_break_token][line_break_token]We also want to clarify that the object-based representation alone is not the main contribution of the paper.	Reply	I-Reply	3
Instead, our key contribution is the integration of object-based representations and symbolic reasoning.	Reply	I-Reply	3
Such combination helps us disentangle visual concept learning and language understanding, and has three advantages over alternatives, as explored in the paper:[line_break_token][line_break_token]1) Executing symbolic programs on object-based representations naturally facilitates complex reasoning that includes quantities (counting), comparisons, and relations.	Reply	O	0
It also brings combinatorial generalization by design (Sec.	Reply	B-Reply	3
4.4): for example, trained on scenes with <= 6 objects, our model (but not the baselines) can also perform counting on scenes with 10 objects.	Reply	O	0
[line_break_token][line_break_token]2) It fully disentangles the visual concept learning and reasoning: once the visual concepts are learned, they can be systematically evaluated (Sec.	Reply	O	0
4.1) and deployed in any visual-semantic applications (such as image caption retrieval, as shown in Sec.	Reply	B-Reply	3
4.5).	Reply	I-Reply	3
In contrast, earlier methods like IEP, TbD, and MAC learn visual concepts and reasoning in an entangled manner and cannot be easily adapted to new problem domains (e.g., show in Table 6, VQA baselines are only able to infer the result on a partial set of the image-caption data).	Reply	I-Reply	3
[line_break_token][line_break_token]3) Symbolic execution over the object space brings full transparency.	Reply	O	0
One can easily trace back the error answer and even detect adversarial (ambiguous or wrong) questions (please refer to Appendix.	Reply	B-Reply	3
E for some examples).	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	O	0
Limitation and future work[line_break_token]We‚Äôd like to clarify that we are not targeting at a specific application such as VQA; instead, we want to build a system that learns accurate (Sec.	Reply	O	0
4.1), interpretable (Sec.	Reply	B-Reply	4
4.2), and transferrable (Sec.	Reply	I-Reply	4
4.5) concepts from natural supervision: images and question-answer pairs.	Reply	I-Reply	4
To achieve this, we propose a novel framework that 1) disentangles the learning of both, but 2) bridges them with a reasoning module and 3) lets them bootstrap the learning of each other.	Reply	I-Reply	4
[line_break_token][line_break_token]Toward concept learning from realistic images and complex language, the current model design suggest multiple research directions.	Reply	I-Reply	4
First, our model relies on object-based representations; constructing 3D object-based representations for realistic scenes (or videos) needs further exploration [1,2]. Second, our model assumes a domain-specific language for a formal description of semantics.	Reply	I-Reply	4
The integration of formal semantics into the processing of complex natural language would be meaningful future work [3,4]. We hope our paper could motivate future research in visual concept learning, language learning, and compositionality.	Reply	I-Reply	4

This paper presents a novel layer-wise optimization approach for learning CNN with piecewise linear nonlinearities.	Review	O	0
 The proposed approach trains piecewise linear CNNs layer by layer and reduces the sub-problem into latent structured SVM, which has been well-studied in the literature.	Review	O	0
In addition, the paper presents improvements of the BCFW algorithm used in the inner procedure.	Review	O	0
Overall, this paper is interesting.	Review	O	0
However, unfortunately, the experiment is not convincing.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]- To my best knowledge, the proposed approach is novel, and the authors provide nice theoretical analysis.	Review	O	0
[line_break_token]- The paper is well-written and easy to follow.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]- Although the proposed approach can be applied in general structured prediction problem, the experiments only conduct on a simple multi-class classification task.	Review	O	0
This makes this work less compelling.	Review	B-Review	1
[line_break_token][tab_token][line_break_token]- The test accuracy performance on CIFAR-10 reported in the paper doesn't look right.	Review	O	0
The accuracy of the best model reported in this paper is 70.2% while existing work often reports 90+%.	Review	B-Review	2
For example, <a href="https://arxiv.org/pdf/1412.6806.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1412.6806.pdf</a> showed an accuracy of 91% without data augmentation.	Review	O	0
Also, CIFAR-10 is a relatively small dataset, [line_break_token][line_break_token]Other comments:[line_break_token][line_break_token]- If I understand correctly, BCFW only guarantees monotonically increasing in the dual objective and does not have guarantees on the primal objective.	Review	O	0
Especially, in practice, the inner optimization process often stops pretty early (i.e., stops when duality gap is still large).	Review	B-Review	3
Therefore, when putting them together, the CCCP procedure may not monotonically decrease as the inner procedure is only solved approximately.	Review	I-Review	3
The authors should add this note when they discuss the properties of their algorithm.	Review	I-Review	3
[line_break_token]	Review	O	0
We thank the reviewer for his comments, which we discuss below:[line_break_token][line_break_token]Comment: ‚ÄúAlthough the proposed approach can be applied in general structured prediction problem, the experiments only conduct on a simple multi-class classification task.	Reply	O	0
‚Äù[line_break_token][line_break_token]Response: In principle the architectures used on ImageNet (such as VGG-16, ResNets etc.)	Reply	O	0
can be treated like the models used in our experiments, and we expect to obtain similar results on these.	Reply	B-Reply	1
In addition to the current results, we are currently evaluating our method on CIFAR-100 and ImageNet, which are more challenging multi-class classification tasks.	Reply	I-Reply	1
We do take note that it would be interesting to test the method on structured prediction tasks as well.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Comment: ‚ÄúThe test accuracy performance on CIFAR-10 reported in the paper doesn't look right.	Reply	O	0
The accuracy of the best model reported in this paper is 70.2% while existing work often reports 90+%.‚Äù[line_break_token][line_break_token]Response: The best score of 70% is obtained with a network which does not use batch normalization, which makes an important difference.	Reply	O	0
The results with batch-normalization in the revised version of the paper reach around 78% testing accuracy.	Reply	B-Reply	2
Taking into account the reviewer‚Äôs comments, we are currently running experiments with deeper architectures to improve this score.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Comment: ‚ÄúIf I understand correctly, BCFW only guarantees monotonically increasing in the dual objective and does not have guarantees on the primal objective.	Reply	O	0
In practice, the inner optimization process often stops pretty early (i.e., stops when duality gap is still large).	Reply	O	0
Therefore, when putting them together, the CCCP procedure may not monotonically decrease as the inner procedure is only solved approximately.	Reply	O	0
The authors should add this note when they discuss the properties of their algorithm.	Reply	O	0
‚Äù[line_break_token][line_break_token]Response: The reviewer is correct that during the inner optimization, only the dual objective is guaranteed a monotonic improvement.	Reply	O	0
In practice, we do run BCFW with a sufficient number of iterations to yield a very small duality gap.	Reply	B-Reply	3
Therefore the method provides a monotonic decrease in practice.	Reply	I-Reply	3
To illustrate this, we have plotted the training objective and the dual gap for an experiment presented in the paper (Adadelta with batch-norm + LW-SVM, Figure 3 in the revised paper): <a href="https://drive.google.com/file/d/0BxXMf_vDT8vCSFQwOWl0aldzeWs/view?usp=sharing" target="_blank" rel="nofollow">https://drive.google.com/file/d/0BxXMf_vDT8vCSFQwOWl0aldzeWs/view?usp=sharing</a> (one data point at the end of each inner iteration of the CCCP).	Reply	O	0
We will add a note about these points in the future revision of the paper	Reply	B-Reply	3

Some minor points / comments / questions:[line_break_token]- "As Neural Networks cannot directly model multiplicative interactions of their inputs": Why not?	Review	O	0
Isn't that a standard gating mechanism?	Review	B-Review	1
[line_break_token]- "model parameters were instead obtained using the Normal Equation": That is unclear to me.	Review	O	0
What is the "Normal Equation"?	Review	B-Review	2
In the next line, there is "X", but you never define what "X" is.	Review	I-Review	2
The same for "R" and "C".	Review	O	0
[line_break_token]- The section about the arithmetic unit is very much too short.	Review	O	0
I don't really understand how it works.	Review	B-Review	3
E.g. how do you perform the loop with repeated additions?	Review	I-Review	3
How do you decide when to stop?	Review	I-Review	3
That could work for integer values, but how does that work for float values?	Review	I-Review	3
And how do you define it in a way that it is differentiable?	Review	I-Review	3
Or is the arithmetic unit not differentiable w.r.t.	Review	I-Review	3
its inputs?	Review	I-Review	3
[line_break_token]- The question about differentiability should also be answered for all the other variables / intermediate values.	Review	O	0
[line_break_token]- The PC, I guess that is the address of the ARM code?	Review	O	0
I guess your branch instructions are conditional jumps, which will conditionally set the PC?	Review	B-Review	5
How do you do that?	Review	I-Review	5
Esp.,	Review	I-Review	5
how can that be differentiable?	Review	I-Review	5
Or is it not differentiable?	Review	I-Review	5
If it is not differentiable, how can you do training of the controller?	Review	I-Review	5
[line_break_token]- You also don't really explain how you train the controller.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- Some parts are unclear, very much too short.	Review	O	0
[line_break_token]- Experiment section very much too short.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- Very nice idea and work.	Review	O	0
[line_break_token]- Open source implementation.	Review	O	0
[line_break_token][line_break_token]I really like the idea and the direction of this work but I think it needs some more improvements.	Review	O	0
[line_break_token]	Review	O	0
Thank you for the review!	Reply	O	0
[line_break_token][line_break_token]A large portion of the feedback stems from the fact that the sections detailing each architectural element are too short.	Reply	O	0
Unfortunately so, given the stringent 3 page limit, it was impossible to fit in any more detail, and hopefully our responses are adequately able to address your questions.	Reply	O	0
[line_break_token] [line_break_token]1.	Reply	B-Reply	4
Since Feed-Forward Neural Networks compute a linear combination of their inputs (W1*x1 + W2*x2) followed by a nonlinearity, they cannot directly model multiplicative interactions.	Reply	I-Reply	1
As an alternative, we chose to model multiplication as repeated addition, but we do agree that we could alternatively create an arbitrary computational graph with multiplication as a gate (with errors flowing back as a gradient switch) for this task.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	3
Normal equation is an analytical procedure used to obtain optimal parameters for a linear problem.	Reply	I-Reply	2
If we define Y = W.X, we can find the optimal weight W by (X^-1)*Y. We used the pseudoinverse and found the parameter W. Here X contains our input samples (Each sample having the 2 operands) and Y is the expected result.	Reply	I-Reply	2
Following Neural Programmer [1], we perform all 3 operations (Addition, subtraction and multiplication) and take the weighted sum based on the confidence predicted by the neural network where R is the vector with the result of all three operations and C is confidence vector.	Reply	I-Reply	2
Taking a distribution over the three results allows the AU to learn which operation needs to be performed, and predict the confidence scores accordingly.	Reply	O	0
[line_break_token][line_break_token]3.	Reply	O	0
The arithmetic unit also predicts a stopping value at each timestep.	Reply	B-Reply	3
We stop when this value is 0.	Reply	I-Reply	3
In this use case, we were able to model multiplication as repeated addition, as ARM does not support floating point numbers.	Reply	I-Reply	3
However this would still work as long as the multiplier (Number of time steps) is a whole number.	Reply	I-Reply	3
The AU itself was a feed-forward Neural Network, trained using the normal equations as described in 2.	Reply	I-Reply	3
However, we could alternatively keep "add", "sub" and "mul" as primitive  operations, as is done in Neural Programmer [1]. [line_break_token][line_break_token]4.	Reply	O	0
Similar to ARM, we have one register which acts as the PC.	Reply	B-Reply	4
The controller reads the value of this register at each timestep and the corresponding instruction.	Reply	I-Reply	4
It uses that as the encoding and updates the PC after every instruction.	Reply	I-Reply	4
The reading and writing to PC happens exactly like the other registers as described in Neural Turing Machine [2].[line_break_token][line_break_token]5.	Reply	O	0
Our Controller is a One-Many LSTM.	Reply	B-Reply	5
It uses the encoding to generate the list of steps to execute.	Reply	I-Reply	5
The controller outputs 2 distributions at every time-step.	Reply	I-Reply	5
One over all the smaller operations to perform and another over the operands.	Reply	I-Reply	5
We trained the controller using Back-Propagation with the stack-trace generated for every instruction.	Reply	I-Reply	5
The training is similar to the procedure followed by the Neural Program Interpreter [3]. We also introduced random noise in the gradient to make the training procedure more robust [4].[line_break_token][line_break_token]We are glad that you appreciated our idea and our work, and are mindful of the improvements that need to be made.	Reply	O	0
Being an active area of research, we are taking steps in this direction.	Reply	O	0
Some improvements that we have made over the months include using our system to execute recursive algorithms such as finding the factorial of the number, using our memory as a stack, with one of the registers acting as the stack pointer, and deploying the same architecture to generalize beyond ARM to MIPS as well (another RISC architecture.)	Reply	O	0
Since Workshop papers favor late breaking developments and works in progress, we sought to develop on this nascent field of research by getting invaluable feedback through reviews, such as the one you have given, alongside fruitful discussions at the workshop.	Reply	O	0
Unfortunately, due to lack of space we were unable to have an extensive results section within the paper, but we have made the full stack trace as well as the values of the registers and relevant memory locations at each timestep available on our GitHub website <a href="https://neu0.github.io" target="_blank" rel="nofollow">https://neu0.github.io</a>[line_break_token][line_break_token][line_break_token][1] Le, Q.V., Neelakantan, A., & Sutskever, I. (2015).	Reply	O	0
Neural Programmer: Inducing Latent Programs with Gradient Descent.	Reply	O	0
CoRR, abs/1511.04834.	Reply	O	0
[line_break_token][line_break_token][2] Danihelka, I., Graves, A., & Wayne, G. (2014).	Reply	O	0
Neural Turing Machines.	Reply	O	0
CoRR, abs/1410.5401.	Reply	O	0
[line_break_token][line_break_token][3] Freitas, N.D., & Reed, S.E. (2015).	Reply	O	0
Neural Programmer-Interpreters.	Reply	O	0
CoRR, abs/1511.06279.	Reply	O	0
[line_break_token][line_break_token][4] Kaiser, L., Kurach, K., Le, Q.V., Martens, J., Neelakantan, A., Sutskever, I., & Vilnis, L. (2015).	Reply	O	0
Adding Gradient Noise Improves Learning for Very Deep Networks.	Reply	O	0
CoRR, abs/1511.06807	Reply	O	0

The authors propose a novel joint optimisation framework that attempts to optimally trade-off between accuracy and fairness objectives, since in its general formal counterfactual fairness is at odds with classical accuracy objective.	Review	O	0
To this end, the authors propose optimising a Pareto front of the fairness-accuracy trade-off space and show that their resulting method outperforms an adversarial approach in finding non-dominated pairs.	Review	O	0
[line_break_token][line_break_token]As main contributions, the paper provides:[line_break_token]* A Pareto objective formulation of the accuracy fairness trade-off[line_break_token]* A new causal fairness objective based on the existing Weighted Average Treatment Effect (WATE) and Average Treatment Effect for the Overlap Population (ATO)[line_break_token][line_break_token]Overall, I think the paper makes an interesting contribution to the field of fairness and that the resulting method seems quite attractive for a real-world practitioners.	Review	O	0
However, I found the writing / notation imprecise at times and the experimental section too small (lacking an extensive set of baselines, and only on two datasets).	Review	O	0
For these reasons, I give it a Weak Accept.	Review	O	0
[line_break_token][line_break_token]Some feedback on notation / writing:[line_break_token]* Typo on page 2, the loss L should be defined on X x Y and not Y x Y[line_break_token]* In page 5, h is being used without being introduced first [line_break_token]* the justification for using ATO in the internal layers of the network is a bit insufficient[line_break_token][line_break_token]In terms of suggestions, I think the experimental section needs to be extended and that the various modelling choices need to be explored and/or be further justified.	Review	O	0
e thank the reviewer for their careful reading and feedback.	Reply	B-Reply	1
We have combed through our original submission to fix imprecision in writing and notation, including the specific points raised above. (	Reply	I-Reply	1
Actually, regarding the loss, this is not a typo but really what we mean‚Ä¶).	Reply	I-Reply	1
[line_break_token][line_break_token]We have also added better explanation of why we penalise the average treatment effect for the overlap population (ATO) in the internal layers.	Reply	I-Reply	2
Basically, we believe that the best safeguard against unfairness in a neural net classifier is to constrain the network to learn fair intermediate representations.	Reply	I-Reply	2
This is because internal representations of neural networks are commonly assumed to contain useful information and may be subsequently employed in transfer learning.	Reply	I-Reply	2
Therefore it would be important to constrain internal layers of the neural network to be fair as well.	Reply	I-Reply	2
Our experimental results include a setup where all intermediate layers are penalised and a setup where only the next-to-last layer is penalised.	Reply	I-Reply	2
The former makes the training more difficult although the estimated Pareto front is still reasonable.	Reply	I-Reply	2
We will investigate in future work how to train this setup in a better way.	Reply	I-Reply	2
Nonetheless in both setups it is interesting that only constraining intermediate representations to be fair is sufficient to obtain fairness on the final prediction.	Reply	I-Reply	2
 [line_break_token][line_break_token]We acknowledge the limitations of our current experimental section.	Reply	O	0
We recently became aware of the AI Fairness 360 Tool, a Python package that includes a convenient interface to seven popular datasets in the fairness literature.	Reply	B-Reply	3
In the original submission we analysed two of the datasets contained therein ‚Äî the Adult Census Income and the ProPublica Recidivism dataset.	Reply	I-Reply	3
Unfortunately there is not enough time during this discussion phase to run our proposed methodology on the other five datasets provided in AI Fairness 360, but we will do this for the final version of the paper.	Reply	I-Reply	3
[line_break_token][line_break_token]In the meantime, we were able to add some additional visualisation (Figures 2-4) in the experimental section which shows the visual effect of dialling between 0 and 1.	Reply	I-Reply	3
Namely, for several values of the penalty parameter, we plot the distribution of the final prediction broken down by true class membership and sensitive attribute.	Reply	I-Reply	3
In addition to reporting the ATO measure of fairness, we also indicate other non-causal fairness metrics including Equalised Odds, Equal Opportunity, and Demographic Parity.	Reply	I-Reply	3

This paper proposes a representation learning algorithm for RL based on the Information Bottleneck (IB) principle.	Review	O	0
This formulation leads to the observed state X being mapped to a latent variable Z ~ P(Z | X), in such a way that the standard loss function in actor-critic RL methods is augmented with a term minimizing the mutual information between X and Z (which can be seen as a form of regularization).	Review	O	0
This results in a loss that is difficult to optimize directly in the general case: the authors thus propose to approximate it through a variational bound, using Stein variational gradient descent (SVGD) for optimization, which is based on sampling multiple Z_i‚Äôs for a given state X, so as to compute an approximate gradient for the parameters of the function mapping X to Z. Experiments show that when augmenting the A2C algorithm with this technique, (1) the mutual information I(X, Z) decreases more quickly (better ¬´ compression ¬ª of the information), and (2) better sample efficiency is observed on 5 Atari games (with also encouraging results with PPO on 3 Atari games).	Review	O	0
[line_break_token][line_break_token]In spite of the interesting theoretical contributions, I have to recommend rejection as the current empirical evaluation of the proposed approach is extremely limited, making it difficult to assess its benefits over more straightforward algorithms.	Review	O	0
[line_break_token][line_break_token]On the positive side, the authors derive a sensible approach to IB representation learning in RL, and provide solutions to the optimization challenges it leads to.	Review	O	0
I did not have time to check all the maths in the Appendix (I only went through the derivations in A.1 and A.2), but they seem to make sense overall (though it is unclear to me if the new algorithm proposed in A.5 is a practical one, so I am not taking it into account in this evaluation).	Review	O	0
[line_break_token][line_break_token]The key negative point is definitely the weak empirical evaluation.	Review	O	0
The main results are from a limited sample of 5 Atari games, when the full Atari benchmark has 10x more games and is known to exhibit high variance among games when comparing RL algorithms (the additional results from the Appendix on 3 additional games also show situations where the proposed method does not seem to help much, confirming that larger scale experiments are needed for a proper evaluation).	Review	B-Review	1
In addition it seems like each algorithm is run only once (instead of using multiple seeds) and only over ~200K timesteps, which is three orders of magnitude lower than results typically reported on Atari.	Review	I-Review	2
Another issue is that there is no comparison to other representation learning techniques (like those mentioned in the related work section, or the recent "Unsupervised State Representation Learning in Atari"), nor to a natural and more straightforward variant of the proposed method where Z would simply be sampled from a (learned) Gaussian distribution Z ~ N(mu(X), var(X)), which at first sight seems like an easier-to-optimize objective (using the reparameterization trick)‚Ä¶ I may be wrong, but then this should probably be explained in the paper (I realize that the proposed approach is more general, but then it should be shown how this extra flexibility can lead to improved results).	Review	I-Review	3
Finally, the impact on runtime performance is not analyzed: how much slower do A2C / PPO become when optimizing the mutual information term with SVGD?	Review	I-Review	3
Overall it is really unclear that better RL results can be obtained through this technique.	Review	I-Review	3
[line_break_token][line_break_token]Another important issue is that I found the paper rather difficult to follow, due to some inconsistent / unclear notations or equations.	Review	I-Review	4
Here are the main ones I noted:[line_break_token]‚Ä¢[tab_token]The discount factor is not accounted for in the derivation of the objectives in eq.	Review	I-Review	4
1-2 (I know this is often the case in practice, but the reason for dropping it should at least be mentioned)[line_break_token]‚Ä¢[tab_token]The jump from V^pi(X) to V^pi(Z) at the end of Section 3 is explained too succintly.	Review	I-Review	4
It suggests that V^pi(Z) must be constant (equal to V^pi(X)) over all values of Z that may be sampled from X, which as far as I can tell is not the case in the rest of the paper.	Review	I-Review	4
It is also unclear whether pi depends on Z or X. And the notation J(Z) makes it look like J does not depend on X, but it seems like it does because even if pi depends only on Z, by its definition V^pi(Z) actually still depends on X (this also leads to weird equations like eq.	Review	I-Review	4
33 where X does not appear in the right-hand side).	Review	I-Review	4
Overall this is rather confusing.	Review	I-Review	4
[line_break_token]‚Ä¢[tab_token]The ¬´ for every X ¬ª at the top of p. 4 does not make sense to me, due to the term I(X, Z) in eq.	Review	I-Review	4
3 where X is a random variable and thus does not take a specific value.	Review	I-Review	4
[line_break_token]‚Ä¢[tab_token]The paragraph below eq.	Review	I-Review	4
4 is a bit confusing.	Review	I-Review	4
It looks like it amounts to saying that Y is a Gaussian around V(Z)?	Review	I-Review	4
[line_break_token]‚Ä¢[tab_token]Eq.	Review	I-Review	4
5 suggests that R depends on Z, but shouldn‚Äôt it depend on X?	Review	I-Review	4
If it depended on Z, then wouldn‚Äôt it influence the optimization since by modifying P(Z|X) we can control the distribution on Z and thus the distribution on R?	Review	I-Review	4
[line_break_token]‚Ä¢[tab_token]In eq.	Review	I-Review	4
10 it is unclear whether L1 and L2 contain the expectation, also L2 is defined as a function of both theta and phi but seems to depend only on theta[line_break_token]‚Ä¢[tab_token]Below eq.	Review	I-Review	4
15 it is said that ¬´ P is the distribution of Z ¬ª but P does not appear in eq.	Review	I-Review	4
15[line_break_token]‚Ä¢[tab_token]In eq.	Review	I-Review	4
16 should the phi on the left hand side be phi* as in eq.	Review	I-Review	4
15?	Review	I-Review	4
[line_break_token]‚Ä¢[tab_token]Below eq.	Review	I-Review	4
16 it is said ¬´ Notice that C has been omitted ¬ª, but it is unclear whether it was not included to alleviate notations or because it disappears naturally in the mathematical derivation of eq.	Review	I-Review	4
16[line_break_token]‚Ä¢[tab_token]The motivation for introducing zeta below eq.	Review	I-Review	4
17 is unclear, especially since it seems to play an important role considering that zeta = 0.005 &lt;&lt; 1 is used in the experiments (with no explanation as to how this specific value was selected)[line_break_token]‚Ä¢[tab_token]\hat{L}(Z_i, theta, phi) (between eq.	Review	O	0
17 and 18) does not seem to be defined[line_break_token]‚Ä¢[tab_token]What is the motivation for using the Gaussian U(Z) as described in Section 5?	Review	B-Review	4
In particular I find it weird that it depends on X_i, while U(Z) is supposed to replace the marginal P(Z) and not the conditional P(Z | X)[line_break_token][line_break_token]Minor points:[line_break_token]‚Ä¢[tab_token]In the definition of Y_t = R_t = sum_i=0^n-2 ‚Ä¶ above eq.	Review	O	0
4, I think the sum should be up to n-1 for an n-step return[line_break_token]‚Ä¢[tab_token]Eq.	Review	B-Review	4
4 uses R_t on the right hand term instead of Y_t which looks weird[line_break_token]‚Ä¢[tab_token]Theorem 1 states ¬´ Assume that for any epsilon &gt; 0, ‚Ä¶ ¬ª: ¬´ for any ¬ª should probably be ¬´ there exists ¬ª, since if the inequality was true for any epsilon, it would imply both mutual informations are equal (also the formulation of the theorem does not make it clear that the last inequality is the main result)[line_break_token]‚Ä¢[tab_token]Footnote 1 p. 4: I(X, Y) should be I(X, Z)[line_break_token]‚Ä¢[tab_token]In eq.	Review	O	0
15 the phi below the argmax should be in bold[line_break_token]‚Ä¢[tab_token]Please add a reference that the reader can refer to in order to understand where eq.	Review	B-Review	4
20 is coming from[line_break_token]‚Ä¢[tab_token]¬´ Apparently ¬ª is used in a couple of places but should probably be replaced with another word[line_break_token]‚Ä¢[tab_token]When U is uniform, how do you choose its support?	Review	I-Review	4
[line_break_token]‚Ä¢[tab_token]After ¬´ median of pairwise distances between the particles ¬ª, I think i=1 should be j=1[line_break_token]‚Ä¢[tab_token]It is unclear to me what ¬´ A2C with noise is ¬ª: it is said that the same phi(X, epsilon) is used ¬´ as A2C with our framework ¬ª, but is it the same phi as A2C with uniform SVIB or A2C with Gaussian SVIB?	Review	I-Review	4
And whichever it is, how does it differ from the one it is equal to?	Review	I-Review	4
[line_break_token]‚Ä¢[tab_token]¬´ we add 21 to all four curves in order to make exponential moving average ¬ª: I do not understand that sentence[line_break_token]‚Ä¢[tab_token]¬´ we set the number of samples as 26 for the sake of computation efficiency ¬ª: I fail to see how going from 32 to 26 is going to make a major difference in computational efficiency[line_break_token][line_break_token]Update: thank you for your response, but in the absence of a revised version addressing my concerns (as well as those from the other reviewers), I cannot increase my rating	Review	O	0
hanks for your detailed reviews!	Reply	O	0
Due to recent bussiness, we are not able to respond all the concerns.	Reply	O	0
Yet we will augment our paper both on experiments and notations based on your detailed and careful advice.	Reply	O	0
Again many thanks to your careful reading.	Reply	O	0
Here are responses to some main concerns.	Reply	O	0
[line_break_token][line_break_token]1.About seeds[line_break_token]Due to the limitations of compution resources and time, we are only able to run 1 seed for each game before submission.	Reply	O	0
Yet these days we are working on adding multi-seeds experiments(3 seeds specifically), now we have the results that our algorithm performs better than original A2C in five games(Pong, Assault, BeamRider, Qbert, AirRaid), more games are running now.	Reply	B-Reply	2
[line_break_token]2.About timesteps[line_break_token]We are not sure about if we are wrong: Since our batchsize is 64, our total frames ought to be 200k * 64 * 4 = 51,200,000 frames.	Reply	O	0
This is the same setting as openai-baselines.	Reply	B-Reply	2
Emmm, do you think these timesteps are still not enough for evaluation?	Reply	I-Reply	2
[line_break_token]3.About assuming representation variable Z as Gaussian.	Reply	O	0
[line_break_token]The reason why we didn't take this into consideration at first is because that in the original paper of MINE, using MINE to optimize the information bottleneck in supervised learning has already outperformed the variational bottleneck(assuming Z as a Gaussian).	Reply	B-Reply	3
Yet in reinforcement learning(Atari games), MINE did not even converge in our experiments.	Reply	I-Reply	3
You can see appendix A.5 for detailed descriptions.	Reply	I-Reply	3
So we suspect that directly using variational bottleneck might even hurt the performance.	Reply	I-Reply	3
But you are definitely right, we should add the experiments to verify the performance of variational bottleneck in reinforcement learning.	Reply	I-Reply	3
[line_break_token][line_break_token]We are really grateful that you can give us the directions to augment our experiments.	Reply	I-Reply	4
Your advice of notation is also valuable.	Reply	I-Reply	4
After we finish the current bussiness, we will make a more rigorous correction on the notations	Reply	I-Reply	4

The paper proposed a scheme to detect the presence of anomalous inputs, such as samples designed adversarially for deep learning tasks, that is based on a "subset scanning" approach to detect anomalous activations in the deep learning network.	Review	O	0
The paper is considering a very interesting problem and provides the suitable application of an approach previously developed for pattern detection.	Review	O	0
The approach is motivated by p-value statistics of the activation patterns in the deep learning network under the "null hypothesis" of a non-anomalous input.	Review	O	0
[line_break_token][line_break_token]My rating is "weak reject" because the explanation of the subset scanning approach is not clear.	Review	B-Review	1
The paper describes two functionals F and G that are defined over subsets of the data and activations.	Review	I-Review	1
Section 2.2 mentions a method that maximizes F over data and activation subsets by maximizing F over the data subsets under a fixed activation subset and vice versa, and iterating over these two.	Review	I-Review	1
The section also discusses the function G that measures the priority of an image, but does not describe how the priority is known to provide an optimal solution for the former optimization over F. Another function with the same name is defined to measure the priority of an activation node, and again it is not clear why this will provide an optimal solution for the latter optimization.	Review	I-Review	1
It would have been helpful to establish (or at least instantiate) the optimality results for this approach; only a citation is provided.	Review	I-Review	1
[line_break_token][line_break_token]The applicability of the approach is limited to the requirement that multiple adversarial samples be present for accurate detection.	Review	I-Review	2
It would appear that other approaches to anomaly detection do not require this condition, particularly if they are designed to operate on individual samples.	Review	I-Review	2
Furthermore, the requirement for the "same system" to design the anomalous samples limits the applicability of the anomaly detection approach to cases like the single adversarial design detection setting studied here.	Review	I-Review	2
[line_break_token][line_break_token]Some questions for the authors:[line_break_token]Is there a reason why the figures (Fig.	Review	O	0
2) show results only for a single class?	Review	B-Review	3
[line_break_token]Is there a reason why no other anomaly detection algorithms for the activation patterns were used in comparisons?	Review	I-Review	4
How about other adversarial noise detection algorithms?	Review	I-Review	4
[line_break_token]Is there intuition behind the difference in performance when all target classes vs. a single target class is used?	Review	I-Review	5
Does this mean that a multi-class adversary generation would be too diverse for the proposed approach to detect it effectively?	Review	I-Review	5
[line_break_token][line_break_token]Minor comments[line_break_token]"Weird together" - is too informal, and it's not clear why this phrasing is needed.	Review	I-Review	6
Consider replacing or explaining.	Review	I-Review	6
[line_break_token]Typos "anomlaous" multiple times.	Review	I-Review	6
hank you for taking the time to review our work!	Reply	O	0
[line_break_token][line_break_token]Allow us to take some more page-space here in the comments with a longer prose form of the optimality of each individual maximization step.	Reply	B-Reply	1
 (The convergence of these individual steps to a global maximum is addressed in a larger, top-level comment).	Reply	I-Reply	1
[line_break_token][line_break_token]Recall the function G as a priority function which ranks elements under consideration.	Reply	I-Reply	1
 When optimizing over images for a fixed set of nodes the elements are the images.	Reply	I-Reply	1
 The priority function is the number of node activations created by the image that are less than a threshold level alpha; the higher number of these nodes, the higher priority of the image.	Reply	I-Reply	1
 [line_break_token][line_break_token]Now, lets consider the subset of images formed exactly by the 1st, 2nd, and 4th highest priority images.	Reply	I-Reply	1
 (Note the 3rd priority image is missing).	Reply	I-Reply	1
 The LTSS property allows us to guarantee that this subset (1st, 2nd, and 4th) is suboptimal.	Reply	I-Reply	1
 This is because the score of this subset can be improved by either a) removing the 4th priority image form the subset or b) adding the 3rd priority image to the subset.	Reply	I-Reply	1
 In other words,[line_break_token][line_break_token]F(1,2,4) &lt;= F(1,2) OR F(1,2,3,4)   (where 1,2,3,4 are the priority rankings of images provided by G).	Reply	O	0
[line_break_token][line_break_token]Therefore we know there are at most LINEARLY many subsets of images to consider and those subsets all have the form of the top-k priority images for some k between 1 and n.  Any subset not meeting this form does not need to be considered.	Reply	B-Reply	1
 This drastic reduction of the search space allows us to score only the necessary subsets while guaranteeing that the highest scoring one will be one of them.	Reply	I-Reply	1
 [line_break_token][line_break_token](Another version of this same logic can be summarized as:   If the kth highest priority image is a part of the highest scoring subset then we know all images with a higher priority than the kth must also be included.)	Reply	I-Reply	1
[line_break_token][line_break_token]Proving that the scoring functions used in this current work satisfy the LTSS property is more involved and is shown on page 1541 here, <a href="http://www.jmlr.org/papers/volume14/mcfowland13a/mcfowland13a.pdf."	Reply	O	0
target="_blank" rel="nofollow">http://www.jmlr.org/papers/volume14/mcfowland13a/mcfowland13a.pdf.</a>  It comes down to the non-parametric scan statistics being monotonically increasing with the number of p-values less than a threshold alpha.	Reply	O	0
[line_break_token][line_break_token]re: Multiple samples being required.	Reply	O	0
[line_break_token] The philosophy of subset scanning is that it is important to leverage a larger, group structure to identify a pattern that may not be noticeable in individual elements.	Reply	B-Reply	2
 In the adversarial noise detection scenario, this boils down to caring more about detecting a coordinated attack on the system as compared to a more random (chaotic neutral) actor who may be motivated to alter a single image to a random new class (a single, un-targeted attack).	Reply	I-Reply	2
[line_break_token][line_break_token]However, we do not completely ignore the individual image detection power of the method.	Reply	I-Reply	2
 These are reported in the first column on the large table of results and can be thought of as an effective floor for detection power when moving into group scanning.	Reply	I-Reply	2
 [line_break_token][line_break_token]Adversarial noise is not the only scenario where multiple examples of a similar anomalous pattern may be present.	Reply	I-Reply	2
 We've also considered the 'new class label' problem where a network may have been trained on cats and dogs, but now houses are becoming more frequent in the data stream.	Reply	I-Reply	2
 Detecting a single house may be difficult, but detecting a dozen houses (among hundred+ cats and dogs) is more reasonable.	Reply	I-Reply	2
 This type of formulation also has implications for detecting data-drift over time as well.	Reply	I-Reply	2
 In these settings a single one-off anomalous example is not enough to declare a larger shift in the data being processed.	Reply	I-Reply	2
 [line_break_token][line_break_token][line_break_token]Class 0 was simply chosen because it was the first class.	Reply	O	0
 Those images are more intended to demonstrate to readers how we calculated AUC's coming from the scores generated by tests sets containing ALL clean images compared to the scores generated by evaluating tests sets that contain some group of noised images.	Reply	B-Reply	3
[line_break_token][line_break_token]We've added a top-level comment under this review for why many comparisons across networks, noise types, detection algorithms, data sets, etc.	Reply	I-Reply	4
were left out.	Reply	I-Reply	4
 The short summary is we believe the idea of detecting out-of-distribution samples by leveraging a common anomalous pattern that is present across those samples is more relevant to the larger body of work then another SOTA claim (which at the current rate of arxiv submissions is fleeting at best).	Reply	I-Reply	4
 [line_break_token][line_break_token]The lower detection power when noised examples in the test set are coming from different classes is a noteworthy result.	Reply	O	0
 This suggests that the power of detecting from a single class is truly leveraging a persistent pattern.	Reply	B-Reply	5
 It is not simply doing a good job on individually anomalous images and then cleverly combining them.	Reply	I-Reply	5
 If it was doing that, then detection power should also be high when the images had different targets	Reply	I-Reply	5

The paper investigates methods to train neural networks so the final network has sparse weights, both in convolutional layers and in fully connected layers.	Review	O	0
In particular, the paper focuses on modifying the training so that the network is first trained without sparsification for a certain number of epochs, then trained to be increasingly sparse, and then fine-tuned with a fixed sparsity pattern at the end.	Review	O	0
[line_break_token][line_break_token]While I find the overall approach of the paper interesting, currently the experiments are not systematic enough to derive clear insights from the paper.	Review	O	0
Hence I unfortunately recommend rejecting the paper at this point.	Review	O	0
I hope the authors find time to conduct more systematic experiments for a future version of the paper.	Review	B-Review	10
[line_break_token][line_break_token]Concretely, the following would be interesting experiments / questions:[line_break_token][line_break_token]- How effective is the proposed training method on architectures other than ResNets?	Review	O	0
[line_break_token][line_break_token]- What happens if the "pruning era" is made longer, started substantially earlier, or started substantially later?	Review	O	0
Currently it is not clear if the epoch 30 - 50 pruning era is (approximately) optimal and how much performance varies with begin and end of the pruning era.	Review	B-Review	2
[line_break_token][line_break_token]- Due to the small variation between some of the methods, it would be good to investigate how robust the ordering is when the experiment is re-ran with different random seeds etc.	Review	O	0
[line_break_token][line_break_token][line_break_token]In addition, I have the following suggestions:[line_break_token][line_break_token]- The authors may want to remove or enhance the adversarial robustness evaluation.	Review	O	0
Currently the authors only evaluate robustness against FGSM, but it is well known that iterative attacks such as PGD are more effective.	Review	B-Review	4
[line_break_token][line_break_token]- Instead of "intra-epoch pruning" or "intra", the name "combined" may be more clear for the combined method.	Review	O	0
[line_break_token][line_break_token]- In the description of the experimental setup, it could be good to specify what GPUs were used (since this lead to the smaller batch size).	Review	O	0
[line_break_token][line_break_token]- It could be helpful for the reader to discuss how predictive results on Tiny-ImageNet are for results on ImageNet.	Review	O	0
[line_break_token][line_break_token]- In Table 2, it would be good to add context by comparing to prior work with sparsity level 60% and some of the compression-focused methods from Table 4.	Review	O	0
[line_break_token][line_break_token]- In the comparison to Mao et al. (	Review	O	0
2017), it could be good to clarify that they also work with ResNet models on ImageNet.	Review	B-Review	9
[line_break_token]	Review	O	0
1) Our argument for only using one architecture is that Resnet networks are the benchmark for MLPerf and the hardest/longest networks to train.	Reply	O	0
All other recent work on CNNs use Resnet, on Imagenet and some smaller datasets, as well.	Reply	B-Reply	1
However, to address this concern we will add experiments on VGG.	Reply	I-Reply	1
[line_break_token] [line_break_token](2) The main goal of this approach is to restrict the pruning era to reduce complexity especially on accelerators.	Reply	O	0
We also aimed to reach a fixed sparsity mask as early as possible.	Reply	B-Reply	2
Keeping the above goal in mind, we did perform sensitivity analysis (shown in Table 1) keeping the final convergence accuracy as high as possible.	Reply	I-Reply	2
We demonstrated that shrinking the pruning era damages the accuracy.	Reply	I-Reply	2
On top of that we moved the pruning era 10 epochs earlier or later in training and studied wider pruning schedules.	Reply	I-Reply	2
[line_break_token] [line_break_token](3) This is a good suggestion; however, what prevented us from doing this is that these experiments we demonstrated each take several days of training per data point.	Reply	O	0
To just perform the sensitivity analysis on the width of the pruning era it took us several months.	Reply	B-Reply	3
We can definitely perform these analysis for smaller networks and datasets.	Reply	I-Reply	3
[line_break_token] [line_break_token](4) Thanks for the suggestion regarding adversarial attacks.	Reply	O	0
We will investigate PGD.	Reply	B-Reply	4
However, we believe that finding that structured sparse training is robust for FGSM is still valuable as other work show.	Reply	I-Reply	4
[line_break_token] [line_break_token](5) Thanks we will fix the name of intra-epoch pruning to combined method to improve clarity.	Reply	O	0
[line_break_token] [line_break_token](6) We used RTX2080 instances.	Reply	O	0
We will add that to the paper.	Reply	B-Reply	6
[line_break_token] [line_break_token](7) Very valid point regarding the productivity of the Tiny-Imagenet results.	Reply	O	0
We will add this.	Reply	B-Reply	7
[line_break_token] [line_break_token](8) Regarding Table2, compression focused methods take around 180 epochs of training if aiming for levels of accuracy that reported.	Reply	O	0
If not, they have much worse accuracy numbers without providing structured sparsity and without the potential of computation savings during training.	Reply	B-Reply	8
So, we chose to only compare with sparse training methods.	Reply	I-Reply	8
[line_break_token] [line_break_token](9) Thanks, we will clarify that Mao et al. (	Reply	O	0
2017) worked with Resnet/Imagenet.	Reply	B-Reply	9

This paper derives a formula for finding the minimum and maximum clipping values for uniform quantization which minimize the square error resulting from quantization, for either a Laplace or Gaussian distribution over pre-quantized value.	Review	O	0
This seems like too small a contribution to warrant a paper.	Review	O	0
I wasn't convinced that appropriate baselines were used in experiments.	Review	O	0
There were a number of statements that I believed to be technically slightly incorrect.	Review	O	0
There were also some small language problems (though these didn't hinder understanding).	Review	O	0
[line_break_token][line_break_token]more specific comments:[line_break_token][line_break_token]abstract:[line_break_token]"derive exact expressions" -- these expressions aren't exact.	Review	O	0
they turn out to be based on a piecewise zeroth order Taylor approximation to the density.	Review	B-Review	1
[line_break_token][line_break_token]main paper:[line_break_token]"allow fit bigger networks into" -> "allow bigger network to fit into"[line_break_token]"that we are need" -> "that need"[line_break_token]"introduces an additional" -> "introduces additional"[line_break_token]clippig -> clipping[line_break_token][line_break_token]it's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.	Review	O	0
[line_break_token][line_break_token]"distributions of tensors" -> "distribution of tensor elements"[line_break_token]this comment also applies in a number of other places, where the writing refers to the marginal distribution of values taken on by entries in a tensor as the distribution over the tensor.	Review	O	0
note that a distribution over tensors is a joint distribution over all entries in a tensor.	Review	B-Review	4
e.g. it would capture things like eigenvalues, entry-entry covariance, rather than just marginal statistics.	Review	I-Review	4
[line_break_token][line_break_token]"than they could have by working individually" -> "than could have been achieved by each individually"[line_break_token][line_break_token]Why the focus on small activation bit depth?	Review	O	0
I would imagine weight bit-depth was more important than activation bit depth.	Review	B-Review	6
Especially since you're using ?	Review	I-Review	6
32-bit?	Review	I-Review	6
precision in the weight/activations multiplications, so activations are computed at a high bit depth anyways.	Review	I-Review	6
[line_break_token][line_break_token]Table 1: Give absolute accuracies too!	Review	I-Review	7
Improvement relative to what baseline?	Review	I-Review	7
[line_break_token][line_break_token]sec 2:[line_break_token]sufficeint -> sufficient[line_break_token]\citep often used when it should instead be \citet.	Review	O	0
[line_break_token]"As contrast" -> "In contrast"[line_break_token][line_break_token]section 3:[line_break_token]uniformity -> uniformly[line_break_token][line_break_token]I don't believe the notion of p-value is being used correctly here w.r.t.	Review	O	0
the Kolmogorov-Smirnov test.	Review	B-Review	10
[line_break_token][line_break_token]Figure 1: The mean square error should never go to 0.	Review	I-Review	11
This suggests something is wrong.	Review	I-Review	11
If it's just a scaling issue, consider a semilogy plot.	Review	I-Review	11
[line_break_token][line_break_token]Figure 2: I'm unclear what baseline (no clipping) refers to in terms of clipping values.	Review	I-Review	12
For uniform quantization there needs to be some min and max value.	Review	I-Review	12
The paper indeed provides a formula for optimal quantization when the distribution of tensor elements is either laplace or gauss.	Reply	O	0
The paper also shows the relevance of these derivations to a very attractive use-case i.e., the conversion of full precision network to low precision network without time-consuming re-training or the availability of the full datasets.	Reply	O	0
Our approach is shown to have significant advantages over previous approaches (as summarized in Table 1).	Reply	O	0
[line_break_token] [line_break_token]Response to more specific comments:[line_break_token]Language problems: We have incorporated all typos and paraphrasing suggestions[line_break_token][line_break_token]1.‚Äúit's not clear a-priori that information loss is the property to minimize that maximizes performance of the quantized network.	Reply	O	0
‚Äù  The connection between quantization error and classification accuracy has been investigated through the preservation of the direction of the quantized tensor.	Reply	O	0
See for example here:[line_break_token]         a.[tab_token]<a href="https://arxiv.org/pdf/1805.11046.pdf#page=9&zoom=100,0,96" target="_blank" rel="nofollow">https://arxiv.org/pdf/1805.11046.pdf#page=9&zoom=100,0,96</a> (section 5.1)[line_break_token]         b.[tab_token]<a href="https://arxiv.org/pdf/1705.07199.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.07199.pdf</a> (section 3.1)[line_break_token]We have added a detailed explanation about the connection between power of the quantization error and accuracy drop (see paragraph #5 in the introduction).	Reply	O	0
[line_break_token][line_break_token]2.‚ÄúGive absolute accuracies too!	Reply	O	0
Improvement relative to what baseline?‚Äù We now provide the baselines we use in our experiments (see Table 1).	Reply	O	0
 [line_break_token][line_break_token]3. ‚	Reply	O	0
ÄúThe mean square error should never go to 0.	Reply	O	0
This suggests something is wrong.	Reply	O	0
If it's just a scaling issue, consider a semilogy plot.	Reply	O	0
‚Äù: This was indeed a scale issue only.	Reply	O	0
It is not relevant anymore (the figure was removed and replaced by the synthetic experiments showing that analysis and simulations are in a good agreement).	Reply	B-Reply	11
[line_break_token][line_break_token]4.	Reply	O	0
[tab_token]‚ÄúI'm unclear what baseline (no clipping) refers to in terms of clipping values.	Reply	O	0
For uniform quantization there needs to be some min and max‚Äù: we improved the explanation of this issue in the introduction (see beginning of paragraph 9), where we explain that the traditional method that avoids clipping uniformly quantize the values between the largest and smallest tensor elements.	Reply	O	0
 	Reply	B-Reply	3

The current paper proposes using Graph Convolutional Networks (GCN) to explicitly represent and use relational data in dialog modeling, as well an attention mechanism for combining information from multiple sources (dialog history, knowledge base, current utterance).	Review	O	0
The work assumes that the knowledge base associated with the dialog task has en entity-to-entity-relationship format and can be naturally expressed as a graph.	Review	O	0
The dependency tree of dialog utterances can also be expressed as a graph, and the dialog history as a set of graphs.	Review	O	0
To utilize this structure, the proposed method uses GCNs whose lowest layer embeddings are initialized with the entity embeddings or via outputs of standard RNN-like models.	Review	O	0
The main claim is that the proposed model outperforms the current state-of-the-art on a goal-oriented dialog task.	Review	O	0
[line_break_token][line_break_token]The idea of explicitly modeling the relational structure via GCNs is interesting.	Review	B-Review	1
However, the use of GCNs independently per sentence and per knowledge-base is a bit disappointing, since it does not couple these sources of information in a structured way.	Review	I-Review	1
Instead, from my current understanding, the approach merely obtains better representations for each of these sources of information, in the same way it is done in the related language tasks.	Review	I-Review	1
For instance, have you considered passing information across the trees in the history as well?	Review	I-Review	1
Or aligning the parsed query elements with the KB elements?	Review	I-Review	1
[line_break_token][line_break_token]The results are very good.	Review	I-Review	2
That said, a source of concern is that the model is only evaluated as a whole, without showing which modification brought the improvements.	Review	I-Review	2
The comparison between using/not using RNNs to initiate the first GCN layer is promising, but why not compare to using only RNN also?	Review	I-Review	2
Why not compare the various encoders within an established framework (e.g. without the newly introduced attention mechanism)?	Review	I-Review	2
Finally, the attention mechanism, stated as a contribution, is not motivated well.	Review	I-Review	2
[line_break_token][line_break_token]Clarity:[line_break_token]The notation is described well, but it's not terribly intuitive (the query embedding is denoted by c, the history embedding by a, etc.),	Review	O	0
making section 4.4.	Review	B-Review	3
hard to follow.	Review	I-Review	3
A figure would have made things easier to follow, esp.	Review	I-Review	3
due to the complexity of the model.	Review	I-Review	3
A clearer parallel with previous methods would also improve the paper: is the proposed approach adding GCN on top of an established pipeline?	Review	I-Review	3
Why not?	Review	I-Review	3
[line_break_token][line_break_token]More discussion on code-mixed language, e.g. in section 4.6, would also improve clarity a bit (make the paper more self-contained).	Review	I-Review	4
While the concept is clear from the context, it would be helpful to describe the level of structure in the mixed language.	Review	I-Review	4
For instance, can dependency trees not be obtained code-mixed languages?	Review	I-Review	4
Is there any research in this direction? (	Review	I-Review	4
or is the concept very new?)	Review	I-Review	4
Maybe I am just missing the background here, but it seems helpful in order to asses how appropriate the selected heuristic (based on the co-occurence matrix) is.	Review	I-Review	4
[line_break_token][line_break_token]Relevant Reference:[line_break_token]Learning Graphical State Transitions, Johnson, ICLR 2017 also uses graph representations in question answering, though in a somewhat different setting.	Review	O	0
[line_break_token][line_break_token]Typos:[line_break_token]Section 4: "a model with following components"[line_break_token]Section 5: "the various hyperparameters that we conisdered"	Review	B-Review	6
We would like to thank you for some great suggestions on strengthening the paper.	Reply	O	0
We must confess that while we had some of these on our to-do list, there were a few that we hadn't actually thought of.	Reply	O	0
We have now been able to add these experiments and we believe it has definitely helped us improve the quality of the paper.	Reply	O	0
Below we give a pointwise update about the new experiments.	Reply	O	0
[line_break_token][line_break_token]1)Passing information across the KB tree and query/history tree by aligning query/history elements with the KB elements: We were able to implement this and did a thorough hyperparameter tuning across all languages.	Reply	O	0
We have included these results in the paper (RNN+CROSS-GCN-SeA in Tables 1, 2) but the short summary is that there was not much change in the BLEU, ROUGE and per response accuracy and only a marginal improvement in the Entity F1-score for En-DSTC2 and Ta-DSTC2.	Reply	B-Reply	1
We had expected the entity F1-score to improve significantly across all languages since we are explicitly linking entities in the KB with entities in the query/history but unfortunately this was not the case.	Reply	I-Reply	1
Initial analysis suggests that given that the task is relatively simple, even the base model, which does not explicitly pass information across the trees, is still able to capture the relevant information.	Reply	I-Reply	1
[line_break_token][line_break_token]2)Ablation tests including comparisons with basic RNN based models and basic attention models: This was a bad miss on our part but now we have been able to do a thorough ablation study with the following experiments where we try to evaluate the (i) need for GCNs (ii) need for our sequential attention mechanism and (iii) need for combining RNNs with GCN:[line_break_token][line_break_token]a)RNN with attention (the basic seq2seq+attention model of Bahdanau et.	Reply	O	0
al.	Reply	B-Reply	2
2015)[line_break_token]b)GCN with Bahdanau attention [does not use RNN or our sequential attention][line_break_token]c)RNN+GCN with Bahdanau attention [does not use our sequential attention][line_break_token]d)RNN with our sequential attention [does not use GCNs][line_break_token]e)RNN+GCN with our sequential attention [Our Final Model][line_break_token][line_break_token]We have included these results for all languages in the updated version of the paper (see Table 8 in Appendix D and ‚ÄúAblations‚Äù part of Section 6) and the main observations are summarized below:[line_break_token][line_break_token]i)GCNs do not outperform RNNs independently: In general, the performance of GCN-Bahdanau attention < RNN-Bahdanau attention[line_break_token]ii)Our sequential attention outperforms Bahdanau attention:  In general, the performance of GCN-Bahdanau attention < GCN-our_seq_attention, RNN-Bahdanau attention < RNN-our_seq_attention and RNN+GCN-Bahdanau attention < RNN+GCN-our_seq_attention.	Reply	O	0
However, note that RNN-Bahdanau attention < RNN-our_seq_attention holds for BLEU and all ROUGE metrics but not for Entity F1 and exact match accuracy.	Reply	O	0
We are analyzing this further and will hopefully be able to add some insights in the final version of the paper.	Reply	B-Reply	2
[line_break_token]iii)Combining GCNs with RNNs helps: In general, RNN-our_seq_attention < RNN+GCN-our_seq_attention[line_break_token][line_break_token]Overall, the best results are always obtained by our final model which combines RNN, GCN and sequential attention.	Reply	O	0
Also, the code for our model and these ablation studies will be made publicly available.	Reply	B-Reply	2
[line_break_token][line_break_token]3)Motivation behind attention: The motivation behind using a sequential attention mechanism was as follows: The current utterance which we refer to as query sets the stage for what comes next (the response).	Reply	O	0
Hence we use this query to attend to only important parts in the history (essentially, the history can be long and we just want to focus on things which are relevant for the last utterance).	Reply	B-Reply	2
Once, we have identified relevant portions of the history and computed an attention weighted representation for the history we are now ready to identify the important concepts from the KB.	Reply	I-Reply	2
To achieve this effect we use the sequential attention mechanism.	Reply	I-Reply	2
[line_break_token][line_break_token]4)GCN on top of an established pipeline: experiment c in point 2 above.	Reply	O	0
[line_break_token][line_break_token]5)Better notations and figures: Indeed, in hindsight, we agree that some of our choices were not very intuitive.	Reply	O	0
We have added 2 diagrams which hopefully makes things clear.	Reply	B-Reply	3
It would be great if you can give us a feedback on the diagrams.	Reply	I-Reply	3
[line_break_token][line_break_token]6)Clarity on code-mixing: The statistics about the level of code mixing, level of structure, etc are mentioned in the original paper (Banerjee et.	Reply	O	0
al.	Reply	B-Reply	2
2018) which introduced the dataset.	Reply	I-Reply	4
As suggested, to make the paper self-contained we have added the important statistics in this paper and some examples of code mixed conversations from the dataset (Appendix A).	Reply	I-Reply	4
Note that there is a lot of work on processing code mixed text (for example, POS tagging of code mixed text, sentiment analysis of code mixed text, information retrieval using code mixed queries, etc).	Reply	I-Reply	4
However, there is not much work on code mixed dialogues because this dataset was only released recently (COLING 2018).	Reply	I-Reply	4
To the best of our knowledge, there is no work on building parsers for code mixed languages which produce parse trees.	Reply	I-Reply	4
[line_break_token][line_break_token]7)We have fixed the typos and added the relevant reference	Reply	O	0

This paper presents a joint learning framework for document ranking and query suggestion.	Review	O	0
It introduces the session embeddings to capture the connections between queries in a session, and potential impact of previous queries in a session to the document ranking of the current query.	Review	O	0
I like the idea in general.	Review	O	0
[line_break_token][line_break_token]However, I have a few comments as follows:[line_break_token][line_break_token]- Multi-task Match Tensor model, which is important in the experiments (best results), is only briefly introduced in Section 3.4.	Review	O	0
It is not very clear how to extend from match tensor model to a multi-task match tensor model.	Review	B-Review	1
This makes me feel like this paper is not self-contained.	Review	I-Review	1
The setting for this model is not introduced either in Section 4.2.	Review	I-Review	1
[line_break_token][line_break_token]- Section 3 is written mostly about what has been done but not why doing this.	Review	O	0
More intuition should be added to better explain the idea.	Review	B-Review	2
[line_break_token][line_break_token]- I like the analysis about testing the impact of the different model components in Section 4.4, especially analyzing the impact of the session.	Review	O	0
It would be nice to have some real examples to see the impact of session embeddings on document ranking.	Review	B-Review	3
One more related question is how the clicked documents of a previous query in the same session influence the document ranking of this current query?	Review	I-Review	3
Would that be feasible to consider in this proposed framework?	Review	I-Review	3
[line_break_token][line_break_token]- Session seems to play an important role in this multi task learning framework.	Review	O	0
This paper used the fixed 30 minute window of idle time to define a session.	Review	B-Review	4
It would be nice to know how sensitive this model is to the definition / segmentation of sessions.	Review	I-Review	4
[line_break_token]	Review	O	0
We thank the reviewer for recognizing our contribution to multi-task learning and giving suggestions to improve the writing.	Reply	O	0
We have revised our paper accordingly and respond to the major concerns here.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We have added a figure of the Multi-task Match-Tensor model in the appendix (see figure 4 in the revised version of the paper).	Reply	B-Reply	1
We adapt multi-task learning in Match-Tensor model by adding the session encoder and the query decoder and keeping the other part of the model as it is.	Reply	I-Reply	1
More details of this procedure are explained in the revised paper Section 3.4.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	3
We have revised the section 3 of our paper by adding more details about the motivation and design of every component in our proposed framework.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	1
We did the experiment to verify the impact of session embeddings on document ranking and result is reported in Table 4 of our revised paper.	Reply	I-Reply	3
The row labeled with ‚ÄúM-NRF‚Äù resembles the model without considering the session embeddings in document ranking, where we observed a 2.8% drop in MAP.	Reply	I-Reply	3
As the session encoder is designed to capture the search context carried till the current query, it provides an important signal for ranking documents under the current/reformulated queries.	Reply	I-Reply	3
 It would be great if we could summarize what kind of queries/sessions benefit from this session recursion (i.e., where does that 2.8% drop in MAP come from).	Reply	I-Reply	3
[line_break_token][line_break_token]In our current model, we do not model the click sequence, and multiple clicks under the same query are assumed to be governed by the same query and session representation.	Reply	I-Reply	3
As a result, the session recursion is not directly/immediately influenced by the click sequence.	Reply	I-Reply	3
However, we do appreciate the great suggestion, and we believe adding another layer of session recursion at click sequence level would enable us to better capture this influence.	Reply	I-Reply	3
And we will list this as a top priority in our future work.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	1
We appreciate the suggestion.	Reply	I-Reply	4
We followed the most commonly used threshold to define the session in IR literature.	Reply	I-Reply	4
In our future work, we will study the sensitivity of the segmentation of sessions	Reply	I-Reply	4

This paper develop a path-based encoding scheme to featurize the neural architectures that are used to train the neural network model, and design a NAS algorithm that performs Bayesian optimization using a neural network model.	Review	O	0
The experiments show the priority of the proposed method.	Review	O	0
[line_break_token][line_break_token]In general, this paper is easy to follow, but the contribution is limited.	Review	B-Review	1
The author did not give a clear explanation of why does this method work.	Review	I-Review	1
There are several problems that exist in the paper:[line_break_token][line_break_token]1.	Review	I-Review	1
[tab_token]The paper introduced a path-based encoding scheme, which seems have nothing different from enumerating all possible paths.	Review	I-Review	1
Any additional operations should be clarified in the paper.	Review	I-Review	1
[line_break_token]2.	Review	O	0
[tab_token]The method retains new architectures with high UCB value.	Review	B-Review	2
However, the author did not prove that a higher UCB value leads to a better architecture.	Review	I-Review	2
Eq.(1) trained several different networks to predict the accuracy.	Review	I-Review	2
However, when using early stop stragegy, the intermediate accuracy is not convincing, and the new architecture selected based on UCB may not perform well when training with full epochs.	Review	I-Review	2
If early stop is not used, there is no need  to predict the accuracy with different networks.	Review	I-Review	2
[line_break_token]3.	Review	O	0
[tab_token]In my opinion, Algorithm 1 is a simplified traditional Evolutionary Algorithm, which only have mutation operation and do not have selection and crossover operation, and has limited novelty.	Review	B-Review	3
[line_break_token][line_break_token]	Review	O	0
hank you for your comments.	Reply	O	0
We discuss them below.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Yes, the path-based encoding scheme is enumerating all possible paths, with no additional operations.	Reply	B-Reply	1
As we show in Table 1 and Figures 2 and 4, using a path-based encoding is extremely effective for predicting the accuracy of neural architectures.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
We do not optimize UCB to choose an architecture.	Reply	B-Reply	2
We are optimizing the validation accuracy and only use UCB as an acquisition function to choose subsequent queries.	Reply	I-Reply	2
This is the standard formulation for Bayesian optimization.	Reply	I-Reply	2
In Bayesian optimization literature, UCB is a well-known acquisition function that has been used for efficient global optimization.	Reply	I-Reply	2
In the NASBench experiments, there is no early stopping at all.	Reply	I-Reply	2
Every architecture is trained for 108 epochs.	Reply	I-Reply	2
In the DARTS experiments, every architecture is trained to 50 epochs (due to the large cost of training).	Reply	I-Reply	2
Then at the very end of our algorithm, we take the architecture with the best validation accuracy and train it to 600 epochs.	Reply	I-Reply	2
This method works well in practice.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Our method is completely different from an evolutionary algorithm.	Reply	B-Reply	3
Our algorithm follows a standard Bayesian optimization procedure, which is a different class of strategies.	Reply	I-Reply	3
In fact, we compared our algorithm to an evolutionary algorithm in Figure 2, and our algorithm performs much better.	Reply	I-Reply	3
The only similarity is that we use a mutation function to optimize the acquisition function.	Reply	I-Reply	3
Note that in the ablation study (Figure 3), we removed the mutation function (using random sampling instead), and our algorithm still significantly outperforms the evolutionary algorithm.	Reply	I-Reply	3
There is no overlap between the two algorithms other than the mutation function.	Reply	I-Reply	3
For example, our algorithm predicts the performance of unseen neural architectures, and there is no part of an evolutionary algorithm that makes predictions	Reply	I-Reply	3

This work proposes to use visualization of gradients to further understand the importance of features (i.e. pixels) for visual classification.	Review	O	0
Overall, this presented visualizations are interesting, however, the approach is very ad hoc.	Review	B-Review	1
The authors do not explain why visualizing regular gradients isn't correlated with the importance of features relevant to the given visual category and proceed to the interior gradient approach.	Review	I-Review	1
[line_break_token][line_break_token]One particular question with regular gradients at features that form the spatial support of the visual class.	Review	I-Review	2
Is it the case that the gradients of the features that are confident of the prediction remain low, while those with high uncertainty will have strong gradients?	Review	I-Review	2
[line_break_token][line_break_token]With regards to the interior gradients, it is unclear how the scaling parameter \alpha affects the feature importance and how it is related to attention.	Review	I-Review	3
[line_break_token][line_break_token]Finally, does this model use batch normalization?	Review	I-Review	4
We thank the reviewer for the review.	Reply	O	0
[line_break_token] [line_break_token]Regarding ‚Äúauthors do not explain why visualizing regular gradients isn't correlated with the importance of features relevant‚Äù.	Reply	O	0
[line_break_token][line_break_token]We do think we discuss this.	Reply	B-Reply	1
Notice that Section 2.1 (‚ÄúGradients do not reflect feature importance‚Äù) gives examples of gradients not reflecting feature importance, and Section 2.2 (‚ÄúSaturation‚Äù) discusses why to an extent.	Reply	I-Reply	1
[line_break_token][line_break_token]The thesis proposed by the reviewer ‚ÄúIs it the case that the gradients of the features that are confident of the prediction remain low, while those with high uncertainty will have strong gradients‚Äù seems plausible empirically.	Reply	O	0
For instance, see this GIF for the label ‚Äúdrilling platform‚Äù obtained by combining the visualizations of interior gradients at various scaling intensities <a href="https://github.com/ankurtaly/Attributions/blob/master/Visualizations/Gifs/6717aba6a10b230f.gif)."	Reply	O	0
target="_blank" rel="nofollow">https://github.com/ankurtaly/Attributions/blob/master/Visualizations/Gifs/6717aba6a10b230f.gif).</a> Gradients at lower intensities seem to emphasize prominent features while those at higher intensities emphasize less important ones (peripheral?).	Reply	O	0
Notice also that ablating the gradient at the image often does not change the prediction, another data point toward the thesis that they are unimportant (see Section 2.1 for an example).	Reply	B-Reply	2
 [line_break_token][line_break_token]One exercise is we plan to carry out is to find the set of neurons that contribute to the gradient (and via Proposition 1 to the final prediction), at lower values of the scaling parameter (alpha)---these gradients look to us like they capture meaningful features and therefore the neurons through which they flow seem critical.	Reply	O	0
We could check whether these critical neurons remain saturated at higher alpha, including for alpha=1.	Reply	B-Reply	3
This exercise serves to connect the apparent variation in the interior gradients as alpha increases to the operation of important neurons within the network.	Reply	I-Reply	3

Summary:[line_break_token][line_break_token]The paper proposes an autoencoder-based initialization for RNNs with linear memory.	Review	O	0
The proposed initialization is aimed at helping to maintain longer-term memory and instability during training such as  exploding gradients (due to linearity).	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]1.	Review	O	0
The paper is well written, the motivation and methods are clearly described.	Review	O	0
[line_break_token][line_break_token]Cons.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
The authors claimed the proposed method could help with exploding gradient  in training the linear memories.	Review	B-Review	1
It would be helpful to include some experiments indicating that this was the case (for the baseline) and that this method does indeed help with this problem.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The experiments on the copy task only showed results for length upto 500, which almost all baseline models are able to solve.	Review	B-Review	2
I am not too sure how the proposed initialization helps in this case.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
TIMNIT is a relatively small speech recognition dataset.	Review	B-Review	3
The task/ dataset does not require long-term memorization.	Review	I-Review	3
It is nice to see that the initialization helps in this case.	Review	I-Review	3
However, it is still a little how this experiment corresponds to the messsage that the authors are attempting to deliver at the end of the introduction.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
In general, it seems that the experiments could be more carefully designed to reflect the contributions of the proposed method.	Review	B-Review	1
Some suggestions for future edits are, more analysis on gradients, maybe more experiments on the stability of training such as gradients could help.	Review	I-Review	1
[line_break_token][line_break_token]Minor:[line_break_token][line_break_token]1.	Review	O	0
There are some confusions, on P2 "we can construct a simple linear recurrent model which uses the autoencoder to encode the input sequences within a single vector", I think the authors meant encode the input sequences into a sequence of vectors?	Review	B-Review	5
Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence).	Review	I-Review	5
[line_break_token][line_break_token]2.	Review	O	0
Although the copy task was used in ((Arjovsky et al.,	Review	B-Review	4
2015), I believe the original task was proposed in the following paper and hence this citation should properly be the correct one to cite here,[line_break_token][line_break_token]Hochreiter, Sepp and Schmidhuber, J√ºrgen.	Review	I-Review	4
Long short-term memory.	Review	I-Review	4
Neural computation, 9(8):[line_break_token]1735‚Äì1780, 1997.	Review	I-Review	4
[line_break_token][line_break_token]	Review	O	0
&gt;&gt;&gt; 1.	Reply	O	0
The authors claimed the proposed method could help with exploding gradient  in training the linear memories.	Reply	O	0
It would be helpful to include some experiments indicating that this was the case (for the baseline) and that this method does indeed help with this problem.	Reply	O	0
[line_break_token]&gt;&gt;&gt; 4.	Reply	O	0
In general, it seems that the experiments could be more carefully designed to reflect the contributions of the proposed method.	Reply	O	0
Some suggestions for future edits are, more analysis on gradients, maybe more experiments on the stability of training such as gradients could help.	Reply	O	0
[line_break_token][line_break_token]We agree that this are interesting experiments.	Reply	B-Reply	1
We believe that it is especially useful to study the effect on the gradient and training stability when combined with the truncated backpropagation (e.g. as done in the LSTM paper).	Reply	I-Reply	1
Unfortunately, we still do not have the final results on these experiments.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; 2.	Reply	O	0
The experiments on the copy task only showed results for length upto 500, which almost all baseline models are able to solve.	Reply	O	0
I am not too sure how the proposed initialization helps in this case.	Reply	O	0
[line_break_token] [line_break_token]We used the experiments on the copy tasks to show that the LMN architecture learns the copy task with a saturating nonlinearity (tanh).	Reply	O	0
As far as we know, this is the only architecture that can do it, while most of the other models use variations of ReLUs.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; 1.	Reply	O	0
There are some confusions, on P2 "we can construct a simple linear recurrent model which uses the autoencoder to encode the input sequences within a single vector", I think the authors meant encode the input sequences into a sequence of vectors?	Reply	O	0
Equation 1 and 2 suggest that there is a vector m^t per timestep (as oppose to having 1 for the entire sequence).	Reply	O	0
[line_break_token] [line_break_token]The state vector of the LAES m^t can be used to reconstruct the entire input sequence x^1, ‚Ä¶ x^t.	Reply	O	0
Therefore, each vector m^t encodes the entire subsequence x^1, ‚Ä¶, x^t.	Reply	B-Reply	5
We will update the paper to make this point clearer.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]&gt;&gt;&gt; 2.	Reply	O	0
Although the copy task was used in ((Arjovsky et al.,	Reply	O	0
2015), I believe the original task was proposed in the following paper and hence this citation should properly be the correct one to cite here[line_break_token] [line_break_token]Thank you for noticing this, we will add the reference.	Reply	O	0

*Summary of paper*[line_break_token]This paper investigates the use of random perturbations applied to a robotic policy to learn a local gradient useful for policy optimization.	Review	O	0
The method aims to learn a policy directly on a real physical robotic system, bypassing both simulation models and model-free RL.	Review	O	0
Training pairs are gathered by perturbations of a starting policy, and the "gradient" is captured in a probabilistic model learned from the training data.	Review	O	0
The paper includes experiments on a custom 3-DOF robotic platform.	Review	O	0
[line_break_token][line_break_token]*Decision*[line_break_token]I vote for rejecting this paper.	Review	O	0
While the idea is interesting, the paper lacks precision in key areas and the method is not placed in context among related work.	Review	B-Review	1
Further, it fails to communicate key ideas (particularly in the experiments) to a non-robotics reader.	Review	I-Review	1
Without sufficient clarity and background, it is not suited to a general machine learning conference.	Review	I-Review	1
[line_break_token][line_break_token]- Lemma 3, which attempts to justify the use of voxelization, and its proof are both imprecise and inadequate.	Review	O	0
To improve precision, please define "error causes by voxelization" in mathematical terms, e.g. ||c_i - x_i||. Also, while the statement of the lemma un-intuitively implies that larger voxels introduce smaller errors, the proof seems to say that larger errors will result for smaller gradients if larger voxels are used.	Review	B-Review	1
[line_break_token]- Related work: How does this work relate to random search/evolutionary computation?	Review	O	0
How does it compare to performing those methods or a model-free RL method directly on the robot?	Review	B-Review	2
How does it compare to learning using an inaccurate model for robot dynamics?	Review	I-Review	2
Presumably there are numerous methods that have been tried in this area, so further context is needed.	Review	I-Review	2
[line_break_token]- The evaluation is unclear, at least to a non-expert in robotics.	Review	O	0
A lack of quantitative evaluation further exacerbates this issue: nearly all experiments, even those with associated plots, are characterized qualitatively and without reference the performance of related methods.	Review	B-Review	3
[line_break_token][line_break_token]- In addition to addressing the limitations above, I would encourage the authors to consider the use of experiments in simulation to thoroughly and quantitatively investigate the convergence/bias/variance of the gradient model w.r.t. #	Review	O	0
DoF of the robot, length of the trajectory, voxelization, # sampled trajectories, perturbation sampling method, and robot reliability/reproducibility[line_break_token][line_break_token]*Additional feedback*[line_break_token]- spelling errors throughout; please check thoroughly[line_break_token]- the captions/labels/etc.	Review	O	0
in most figures is far too small to read in a printed copy of the paper[line_break_token]- What is the intuition for the "empirical distribution p_e(T|\pi) = ..." on page 2?	Review	O	0
Is it counting the exact matches between the trajectory T and the M observed trajectories? (	Review	B-Review	7
This may be more clear in the context of voxelization introduced later.)	Review	I-Review	7
[line_break_token]- Figure 3: what are the units for \gamma?	Review	O	0
what is the time step?	Review	B-Review	8
[line_break_token]- many of the figures are out of order w.r.t.	Review	O	0
their introduction in the text	Review	B-Review	9
e thank the respected reviewer and try to answer the comments in the following.	Reply	O	0
[line_break_token][line_break_token]Regarding the use of simulation:[line_break_token]Even though working with a simulator was much easier than building a physical robot and experimenting on it, we intentionally went for a real robot since the results of the simulator were not reliable.	Reply	O	0
For example, the separation between spatial and temporal noise was not known for us prior to running experiments on the real robot.	Reply	B-Reply	4
Real challenges of the problem are not visible before doing real experiments on real robots.	Reply	I-Reply	4
[line_break_token][line_break_token]Regarding the empirical distribution on page 2:[line_break_token]It the sum of delta functions located on some trajectories in the dataset	Reply	O	0

This paper introduces the General Language Understanding Evaluation (GLUE) benchmark and platform, which aims to evaluate representations of language with an emphasis on generalizability.	Review	O	0
This is a timely contribution and GLUE will be an impactful resource for the NLP community.	Review	O	0
This is mitigated, perhaps, somewhat by the recent release of decaNLP.	Review	O	0
But, as discussed the authors, this has a different focus (re-framing all tasks as QQ) and further does not feature the practical tools released here (leaderboard, error analysis) that will help drive progress.	Review	O	0
[line_break_token][line_break_token]Some comments below.	Review	O	0
[line_break_token][line_break_token]- The inclusion of the small diagnostic dataset was a nice addition and it would be nice if future corpora included similar.	Review	O	0
[line_break_token][line_break_token]- Implicit in this and related efforts is the assumption that parameter sharing ought to be possible and fruitful across even quite diverse tasks.	Review	O	0
While I do not object to this, it would be nice if the authors could make an explicit case here as to why should we believe this to be the case.	Review	B-Review	2
[line_break_token][line_break_token]- The proposed platform is touted as one of the main contributions here, but not pointed to -- I assume for anonymity preserving reasons, but still would have been nice for this to be made explicit.	Review	O	0
[line_break_token][line_break_token]- I would consider pushing Table 5 (Appendix) into the main text.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your review!	Reply	O	0
[line_break_token][line_break_token]We agree that the diagnostic data is a key contribution of our work.	Reply	B-Reply	1
We wanted to not only have an application-driven measure of progress, but also a targeted measure of performance on specific natural language phenomena that we would expect a general-purpose NLU model to handle well.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding parameter sharing, our intent was to include tasks with very little training data such that automated systems could not do well learning on just those tasks‚Äô data.	Reply	I-Reply	2
Competitive systems, then, would need to include some form of knowledge-sharing from outside data.	Reply	I-Reply	2
 In only requiring model predictions to evaluate on test, we wanted to avoid restricting future research to any particular paradigm of knowledge sharing.	Reply	I-Reply	2
We use multi-task learning and parameter sharing because it is a straightforward baseline with lots of precedent (GenSen, Collobert and Weston, etc.),	Reply	I-Reply	2
so we thought it necessary to include.	Reply	I-Reply	2
[line_break_token][line_break_token]Could you please clarify how a small *test* set would encourage few-shot learning?	Reply	I-Reply	2
To the best of our knowledge, few-shot learning is when you have a small *training* set for the target task.	Reply	I-Reply	2
[line_break_token][line_break_token]Re: table 5, we agree!	Reply	O	0
We‚Äôll post an updated version of the paper shortly.	Reply	B-Reply	4

[line_break_token][Summary][line_break_token]This paper studies the relationship between gradient clipping in stochastic gradient descent and robustness to label noise.	Review	O	0
Theoretical results show that gradient clipping in general is not robust to symmetric label noise.	Review	O	0
The paper then proposes a variant of gradient clipping (cl-clipping) that induces label noise robustness.	Review	O	0
Experiments support these claims on synthetic datasets and typical classification benchmarks.	Review	O	0
[line_break_token][line_break_token][Decision][line_break_token]The first contribution, that gradient clipping does not induce robustness to label noise, is an important negative result given the prominence of gradient clipping and datasets with noisy labels.	Review	O	0
The second contribution, cl-clipping, amounts to minimizing a non-convex loss with saturating regions but, as far as I know, these properties are necessary for robustness to label noise.	Review	O	0
Theoretical results are limited to SGD with mini-batch size 1 but the insights carry over to larger mini-batches in the experiments.	Review	B-Review	1
Overall, I recommend acceptance.	Review	O	0
[line_break_token][line_break_token][Comments][line_break_token]The parameter tau controls robustness, and a higher noise level requires a higher tau.	Review	O	0
There is little discussion on how this parameter is chosen in the experiments.	Review	B-Review	1
On the synthetic dataset, the Huberized loss uses tau=1 and the partially Huberized loss uses tau=2.	Review	I-Review	1
How are these values chosen?	Review	I-Review	1
Did the authors observe a U-shaped curve when sweeping over tau?	Review	I-Review	1
On the real-world datasets, tau is fixed for each method across different noise levels.	Review	I-Review	1
Does this mean that a single value of tau worked best regardless of the noise level, or was it tuned for a particular noise level?	Review	I-Review	1
[line_break_token][line_break_token]Proposition 4 shows that symmetric noise breaks down the clipping method in Eq (7) which can be seen as a special case of gradient clipping.	Review	I-Review	2
I might be missing something here, but it is not obvious to me that, when the norm of x is constant across the samples, Eq (7) is equal to gradient clipping.	Review	I-Review	2
[line_break_token]	Review	O	0
hanks for the feedback!	Reply	O	0
[line_break_token][line_break_token]We have updated the draft to include a discussion on the choice of œÑ in Section 5.	Reply	B-Reply	1
This is a tuning parameter that can be set by the user, similar to the q parameter from generalised cross-entropy, or noise estimates in loss-correction techniques.	Reply	I-Reply	1
[line_break_token][line_break_token]In our experiments, we chose œÑ so as to maximise accuracy on a set of (noisy) validation samples for the setting of noise rate œ± = 0.6.	Reply	I-Reply	1
We did not tune œÑ for each noise rate, since this value of œÑ worked well for lower noise rates as well.	Reply	I-Reply	1
Of course, there is no conceptual issue with tuning œÑ for each value of œ±, although there is a slight computational cost.	Reply	I-Reply	1
[line_break_token][line_break_token]For the range of œÑ, we found that values of œÑ = { 2, 10 } ‚Äî which correspond to clipping at probability values less than 0.5 and 0.1 respectively ‚Äî generally gave good performance for the datasets considered.	Reply	I-Reply	1
In general, one can certainly expand this range, again with a slight computational cost.	Reply	I-Reply	1
[line_break_token][line_break_token]We indeed observe a U-shaped curve in general.	Reply	I-Reply	1
Note also that as œÑ gets closer to 1, we essentially reduce to the original loss (e.g., log-loss).	Reply	I-Reply	1
As œÑ gets larger, we essentially reduce to the linear loss.	Reply	I-Reply	1
As shown in Table 2, intermediate values of œÑ yield better performance than either extreme under label noise.	Reply	I-Reply	1
We have made a comment on this following the discussion of how œÑ is chosen.	Reply	I-Reply	1
[line_break_token][line_break_token]Proposition 4 indeed concerns loss-based gradient clipping, i.e., Equation 7.	Reply	I-Reply	2
Per the discussion following Lemma 1, this is not exactly the same as gradient clipping in general.	Reply	I-Reply	2
However, note that for linear models, the term ‚àámŒ∏(x, y) = ||x||2, so if this is constant then Equations 6 and 7 will coincide.	Reply	I-Reply	2
We have added some clarifying text after Equation 7	Reply	I-Reply	2

This paper presents an approach to multi-modal imitation learning by using a variational auto-encoder to embed demonstrated trajectories into a structured latent space that captures the multi-modal structure.	Review	O	0
This is done through a stochastic neural network with a bi-directional LSTM and mean pooling architecture that predicts the mean and log-variance of the latent state.	Review	O	0
This is followed by a state and action/policy decoder (both LSTMs) that recursively generate trajectories from latent space samples.	Review	O	0
The entire model is trained by optimising the ELBO on a set of pre-specified expert demonstrations.	Review	O	0
At test time, samples are generated from the latent space and recursively decoded to generate state and action trajectories.	Review	O	0
The method is tested on three low-dimensional continuous control tasks and is able to learn structured latent spaces capturing the modes in the training data as well as generating good trajectory reconstructions.	Review	O	0
[line_break_token][line_break_token]Learning from multi-modal demonstration data is an important sub-area in imitation learning.	Review	B-Review	1
As the paper pointed out, there has been a lot of recent work in this area.	Review	I-Review	1
A lot of the ideas in this paper are similar to those proposed in prior work -- the network for embedding the trajectory is similar to the ones from Wang et al & Co-Reyes et al with the major difference being in the structure of the action decoder (and what inputs to encoder).	Review	O	0
Also, prior work has dealt with problems that are high-dimensional (Wang et al) and has shown results when operating directly on visual data (InfoGAIL).	Review	B-Review	1
Comparatively, the results in this paper are on toy problems.	Review	I-Review	1
[line_break_token][line_break_token]As there is no direct comparison to prior work provided in the paper, it is hard to quantify how much better the proposed approach is in comparison to prior work.	Review	I-Review	2
For example, the "2D Circle Example" was taken from the InfoGAIL paper.	Review	I-Review	2
It would have been good to use that as a baseline example to compare those two methods and highlight the advantages of the proposed approach -- did it require less data?	Review	I-Review	2
fewer environment interactions?	Review	I-Review	2
etc.	Review	I-Review	2
[line_break_token][line_break_token]The results on the Zombie Attack Scenario seem poor.	Review	I-Review	3
Specifically, in the avoid scenario, the approach seems to fail almost half the time.	Review	I-Review	3
It would be good if the authors spend more time on this -- again, a comparison to prior work would establish some baselines and give us a good idea of the expected performance on this scenario.	Review	I-Review	3
The videos show a single representative example for the "Attack" and "Avoid" scenarios.	Review	I-Review	3
More examples including failures need to be included so that the distribution of results can be captured.	Review	I-Review	3
[line_break_token][line_break_token]There is little in terms of generalisation or ablation studies in the paper.	Review	I-Review	4
For example, in the Zombie Attack Scenario one could generate data with different zombie behaviours and measure performance on held out behaviours.	Review	I-Review	4
Similarly, as an ablation, the authors could look at directly predicting actions instead of states & actions (states could be generated through a pre-trained dynamics model).	Review	O	0
[line_break_token][line_break_token]Figure 6.	Review	B-Review	5
is hard to parse and could be explained better.	Review	I-Review	5
No details are provided on the network architecture (number/size of the LSTM/fully connected layers), number of demonstrations used, training algorithm, hyper-parameters etc.	Review	I-Review	5
[line_break_token][line_break_token]Few typos in the paper: [line_break_token]  Page 6 - between the animation links 'avoiding' 'region'[line_break_token]  Fig 7 caption - the zombie but are not in attacking range -> but the zombies are not in the attacking range,[line_break_token][line_break_token]Relevant citations that can be added:[line_break_token]1) Hausman, K., Chebotar, Y., Schaal, S., Sukhatme, G., & Lim, J. J. (2017).	Review	O	0
Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets.	Review	B-Review	7
In Advances in Neural Information Processing Systems (pp.	Review	I-Review	7
1235-1245).	Review	I-Review	7
[line_break_token]2) Tamar, A., Rohanimanesh, K., Chow, Y., Vigorito, C., Goodrich, B., Kahane, M., & Pridmore, D. (2018).	Review	O	0
Imitation Learning from Visual Data with Multiple Intentions.	Review	B-Review	7
[line_break_token][line_break_token]Overall, I find the paper to be incremental and lacking good experimental results and comparisons.	Review	O	0
The strengths of the paper are not clear and need to be explained and evaluated well.	Review	O	0
Substantial work is needed to significantly improve the paper before it can be accepted.	Review	O	0
Our model differs from Wang et al in the sense that our VAE is on the trajectory level, which enables it to better identify the latent variable that differentiates different behaviors from the whole trajectory.	Reply	B-Reply	1
 Co-Reyes et al  also uses a trajectory-level VAE, but our work differs from theirs in that our model is fully probabilistic and consistent.	Reply	I-Reply	1
Therefore no extra penalty term is needed as in Co-Reyes et al to force the state decoder to be consistent with the action decoder.	Reply	I-Reply	1
[line_break_token][line_break_token]Thank you for the suggestions for the ablation studies.	Reply	I-Reply	4
We will conduct a comprehensive analysis on the impact of the state decoder/policy decoder.	Reply	I-Reply	4
[line_break_token][line_break_token]We will fix the typos, add the references and clarify experiment setup in a revision.	Reply	I-Reply	6

This paper presented a dialog response generation method using adversarial learning framework.	Review	O	0
[line_break_token]The generator is based on previously proposed hierarchical recurrent encoder-decoder network (HRED), and the discriminator is a bidirectional RNN.	Review	O	0
[line_break_token]Noise samples are introduced in generator for response generation.	Review	O	0
[line_break_token]They evaluated their approach on two datasets and showed mostly better results than the other systems.	Review	O	0
[line_break_token][line_break_token]The novelty of the paper is limited.	Review	O	0
[line_break_token]Modeling longer dialog history (beyond the current turn) is not new, this has been used in different tasks such as dialect act classification, intent classification and slot filling, response generation, etc.	Review	B-Review	1
[line_break_token]The generator is based on previous HRED.	Review	I-Review	1
[line_break_token]Adding noise to generate responses is somewhat new, but that doesn‚Äôt seem to be well motivated or justified.	Review	I-Review	1
[line_break_token]Why adding Gaussian noise improves the diversity or informativeness of the responses is not explained.	Review	I-Review	1
[line_break_token]The idea of discriminator has been widely used recently for language generation related tasks.	Review	I-Review	1
 What is new here?	Review	I-Review	1
Is it the word-based metric?	Review	I-Review	1
Sharing the context and word information with generator?	Review	I-Review	1
 It would be helpful if the authors can clarify their contribution.	Review	I-Review	1
[line_break_token]  [line_break_token]Regarding using MLE to first generate multiple hypotheses in generator, how is the quality of the n-best responses?	Review	O	0
[line_break_token]Is there a way to measure the goodness of the responses in some kind of reranking framework, not necessarily discriminator?	Review	B-Review	2
[line_break_token][line_break_token]The results in the table showed the proposed method outperforms the others in terms of those objective metrics.	Review	I-Review	3
I feel some subjective evaluations are needed to strengthen the paper.	Review	I-Review	3
[line_break_token]From the samples responses in the table, it doesn‚Äôt look like the new method generates very good responses.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]Detailed comments: [line_break_token]- Sec 2, before 2.1, last paragraph, ‚ÄúWith the GAN objective, we can match the noise distribution, P(Z_i) to the distribution of the ground truth response, P(X_i+1|X_i).	Review	O	0
 This needs clarification.	Review	B-Review	4
[line_break_token]- Figure 1: caption, ‚Äúleft‚Äù and ‚Äúright‚Äù are misplaced.	Review	O	0
[line_break_token]- sec 2.1, last paragraph, without Z_i, the net could still learn a mapping from X_i to Y_i, but would produce deterministic outputs.	Review	O	0
 I think the authors mean that the system generates a probability distribution P(Y_i|X), the output is the most likely one from that.	Review	B-Review	6
However, if the output is a distribution, the system can also do some sampling and not necessarily output the top one.	Review	I-Review	6
 This is not that different from adding noise in the history ‚Äî if that‚Äôs based on some distribution, then it may still be deterministic.	Review	I-Review	6
[line_break_token]	Review	O	0
Thank you for your review.	Reply	O	0
We will soon post a more detailed explanation and new results with human evaluation but we want to quickly address some of the other concerns raised in your review.	Reply	O	0
[line_break_token][line_break_token]Novelty and Significance:[line_break_token][line_break_token]Our work employs a similar approach as the VHRED which applies variational approach to improve the HRED.	Reply	O	0
One could argue that HRED and variational bayes already exists independently, but VHRED shows the impact of variational training on the HRED generator.	Reply	B-Reply	1
In the same vein, we also examine the impact of adversarial training on the HRED generator since both the variational and adversarial approaches are very competitive for training generative models.	Reply	I-Reply	1
That's why we compare hredGAN, VHRED and HRED in our evaluation.	Reply	I-Reply	1
In summary, our work shows that our proposed adversarial training performs better than the variational training in VHRED.	Reply	I-Reply	1
[line_break_token][line_break_token]Our other contributions relate more with the actualization of the adversarial training.	Reply	I-Reply	1
To achieve an end-to-end gradient flow from the discriminator to the generator, we share the word embedding and context information between the generator and discriminator as you have rightly mentioned.	Reply	I-Reply	1
The alternative would be either using a policy gradient method (REINFORCE) or passing the softmax output instead of the argmax output to the discriminator, both of which did not perform better than the embedding sharing in our experiments.	Reply	I-Reply	1
  On the choice of the discriminator, we found the aggregated word-level metric to be much better than the utterance-level metric so we propose a word-level metric as you have rightly mentioned.	Reply	I-Reply	1
[line_break_token][line_break_token]Detailed Comments:[line_break_token]We have corrected the misplaced caption in Fig.	Reply	O	0
1.	Reply	B-Reply	5
[line_break_token][line_break_token]Your explanation of "sec 2.1, last paragraph" is spot on.	Reply	I-Reply	6
We opted to sample a latent and much smoother noise distribution, P(Z_i) while keeping the output as the most likely from P(Y_i|X, Z_i) instead of sampling P(Y_i|X) discretely.	Reply	I-Reply	6
Whereas the discrete sampling of  P(Y_i|X) does not work well in practice due the large vocabulary size, our latent sampling, P(Y_i|X, Z_i)P(Z_i) allows us to control the diversity of the output from the variation of the noise sample via the parameter \alpha.	Reply	I-Reply	6
Therefore, we are able to generate a much more coherent samples than possible with discrete sampling of P(Y_i|X).	Reply	I-Reply	6
[line_break_token][line_break_token]Let us know if you have additional questions as we collate and analyze the human evaluation results.	Reply	O	0
We will be posting the new results in the next few days	Reply	O	0

This work proposes a new method of stabilizing GAN training and encouraging the generator to cover the data distribution better (i.e. less mode dropping).	Review	O	0
 As I understand it they do so by gradually annealing the data distribution so that it initially has high entropy and gradually move towards the true distribution.	Review	O	0
[line_break_token][line_break_token]While this approach is potentially promising, the paper in its current form lacks and discussion of its relation to other approaches to stabilizing GANs.	Review	B-Review	1
I think this method needs to be placed in context to be better understood.	Review	I-Review	1
[line_break_token][line_break_token]Finally, I have one question: in algorithm 1, the generator network is written as a function of beta, but as I understand it only the data distribution is annealed, not the generator distribution?	Review	O	0
Please explain.	Review	B-Review	2
Thank you for your comments.	Reply	O	0
We added the discussion section to the paper clarifying our formulation in relation to other related works that have addressed stabilization of GAN training.	Reply	B-Reply	1
[line_break_token][line_break_token]Regarding the question:  Both and depend on beta implicitly, since the generator and the discriminator are trained while the data distribution is being annealed.	Reply	O	0
The notation in Algorithm 1 emphasizes this implicit dependence	Reply	B-Reply	2

This paper proposes a unified architecture in the context of multi-task learning where they demonstrate that training four tasks (with a variety of modalities like image, text, and videos) together results in about three times compressed model, while maintaining the performance similar to their respective individually trained models.	Review	O	0
The major components of this archtiecutre are (1) peripheral networks: used to encode the domain specific input into feature representations. (	Review	O	0
2) central neural processor: a fully attention based encoder-decoder model similar to the Transformer networks which encodes the spatio-temporal information.	Review	O	0
Further, this paper suggests that their unified architecture enables to perform decent on unseen tasks during its training.	Review	O	0
In this paper they test such scenarios on video captioning and video question answering.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is clear to read and thorough in its experiments, with the caveat that its missing many multi-task paper references and the ideas are not much novel.	Review	O	0
However, I would say the setup is well engineered.	Review	O	0
[line_break_token][line_break_token]Arguments:[line_break_token][line_break_token]1) There are many works in multi-task learning after Luong et al.,	Review	O	0
2016, please refer them in the related work section (this section is very short!)	Review	B-Review	1
and discuss on the differences of your model w.r.t.	Review	I-Review	1
previous work (this is completely missing in the paper).	Review	I-Review	1
I am pointing to some references below.	Review	I-Review	1
[line_break_token][line_break_token]2) Statistical significance tests are missing to show that MULT-3 or MULT-4 are able to ‚Äúmaintain‚Äù the performance w.r.t.	Review	O	0
IND.	Review	B-Review	2
[line_break_token][line_break_token][line_break_token][1] Latent Multi-task Architecture Learning, Ruder et al.,	Review	O	0
2019[line_break_token][2] A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks, Hashimoto et al.,	Review	O	0
2017[line_break_token][3] Multi-Task Video Captioning with Video and Entailment Generation, Pasunuru &amp; Bansal, 2017[line_break_token]	Review	O	0
e thank the reviewer for encouraging feedback and comments.	Reply	O	0
As suggested, we will add a  discussion on multi-tasking literature in the final version of the paper.	Reply	B-Reply	1
 We are in the process of hyper-parameter optimization as pointed by Reviewer#1 and will perform the detailed statistical significance tests for comparison of MULT-3 and MULT-4 with IND.	Reply	O	0
We will add these results as well to the final version of the paper.	Reply	B-Reply	2
[line_break_token]	Reply	O	0

Summary:[line_break_token]The authors analyze the bias in the straight-through gradient estimator using the framework of harmonic analysis of boolean functions.	Review	O	0
Based on this analysis, they propose three methods to reduce the bias of the straight-through estimator, resulting in a less-biased estimator that is the same computational complexity as the original.	Review	O	0
They evaluate this estimator on a series of generative modeling tasks where they demonstrate improvements over existing methods, including the ability to train a very deep stochastic network.	Review	O	0
[line_break_token][line_break_token]I enjoyed this paper -- the exposition is clear, the ideas are (to my knowledge) novel and make sense, and the experimental evaluation is thorough and convincing.	Review	O	0
I recommend an accept.	Review	O	0
[line_break_token][line_break_token]I skimmed through the proofs in the appendix so cannot with absolute confidence vouch for their correctness.	Review	O	0
[line_break_token][line_break_token]One small piece of feedback: I found the most confusing part of the paper was the section on the 'bernoulli splitting trick'.	Review	O	0
It might be helpful to pull some of the appendix material into this section to make it a little less sparse.	Review	B-Review	1
[line_break_token]	Review	O	0
e thank the reviewer for the encouraging review and for appreciating the novelty and thoroughness of the experiments.	Reply	O	0
With regard to the suggestion of clarifications in section 4.3, we have incorporated this in the updated version (section 4.3, page 5).	Reply	B-Reply	1
We hope to have made the matter clearer	Reply	I-Reply	1

[line_break_token]Summary:[line_break_token][line_break_token]The paper proposes to use the same language model to learn multiple tasks and also to generate pseudo-samples for these tasks which could be used for rehearsal while learning new tasks.	Review	O	0
The authors demonstrate that this idea works well compared to other SOTA lifelong learning methods for learning various NLP tasks using a single model.	Review	O	0
[line_break_token][line_break_token][line_break_token]My comments:[line_break_token][line_break_token]1.	Review	O	0
Please change the title!	Review	B-Review	1
Language modeling is NOT all you need for lifelong language learning.	Review	I-Review	1
Also, not every NLP task is a QA task.	Review	I-Review	1
I do not want more papers to over-trivialize NLP by following Bryan McCann and Socher, 2018.	Review	I-Review	1
I will not increase my scores until the title is changed.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	11
A relevant model architecture based method is Sodhani et al.	Review	I-Review	2
2018 (Towards Training Recurrent Neural Networks for Lifelong Learning) who use Net2Net to do zero-shot expansion of the model parameters.	Review	I-Review	2
[line_break_token]3.	Review	I-Review	3
Section 3.2 - you mention that any pseudo-example which does not have only one ANS token is discarded.	Review	I-Review	3
Can you comment on how much discarding is needed to generate the required number of pseudo-samples?	Review	I-Review	3
[line_break_token]4.	Review	O	0
Why is it that every task was trained only for 9 epochs?	Review	B-Review	4
[line_break_token]5.	Review	O	0
On page 5, you mention k=20.	Review	B-Review	5
What is k?	Review	I-Review	5
Where is this introduced?	Review	I-Review	5
[line_break_token]6.	Review	O	0
On page 5, you mention that MTL is used to determine whether forgetting is caused by a lack of model capacity.	Review	B-Review	6
I am not sure if it is correct.	Review	I-Review	6
Can you explain?	Review	I-Review	6
[line_break_token]7.	Review	O	0
Why not compare the approach with models like GEM?	Review	B-Review	7
Keeping very few examples is ok.	Review	I-Review	7
Even though you don‚Äôt beat GEM, it is good to see the comparison.	Review	I-Review	7
[line_break_token]8.	Review	I-Review	1
Page 7: Is there any reason why you choose to go from large to small tasks?	Review	I-Review	8
I feel like this is a favorable order.	Review	I-Review	8
I would like to see how the model performs if you do the reverse order.	Review	I-Review	8
[line_break_token]9.	Review	O	0
Please remove the last line.	Review	B-Review	9
[line_break_token]10.	Review	O	0
I assume that the authors will release the code upon acceptance of the paper.	Review	B-Review	10
[line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]1.	Review	I-Review	11
Page 2, 4th contribution: check the spelling for ‚Äúpseudo-samples‚Äù[line_break_token]2.	Review	I-Review	11
Page 2, 5th last line: ‚ÄúAfter a completing a task‚Äù - fix it.	Review	I-Review	11
[line_break_token]3.	Review	I-Review	3
Table 1: I think the description is not correct.	Review	I-Review	11
1fEM is for wikiSQL, not WOZ.	Review	I-Review	11
Also, it is better if you can describe these metrics in detail in the appendix.	Review	I-Review	11
[line_break_token][line_break_token]==================================[line_break_token][line_break_token]After rebuttal:[line_break_token][line_break_token]I am happy with the authors' response and name change.	Review	O	0
I am increasing my score.	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for the review, comments, and constructive feedback.	Reply	O	0
We provide answers to the comments below.	Reply	O	0
[line_break_token][line_break_token]Q1: Please change the title!	Reply	O	0
[line_break_token][line_break_token]A1: We understand our title over-trivialized NLP tasks, so we changed it to: "LAMOL: LAnguage MOdeling for Lifelong Language Learning".	Reply	O	0
We change the title in the revised PDF but we can't change the title on OpenReview for now.	Reply	B-Reply	1
We also rephrase the paper to show that we merely use the datasets and metrics from decaNLP.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: A relevant model architecture based method is Sodhani et al.	Reply	O	0
2018.	Reply	O	0
[line_break_token][line_break_token]A2: Thank you for your reminder.	Reply	O	0
We added the following paragraph to Section 2.2:[line_break_token]Training Recurrent Neural Networks for Lifelong Learning (Sodhani et al.,	Reply	B-Reply	2
2018) unifies Gradient episodic memory (Lopez-Paz et al.,	Reply	I-Reply	2
2017) and Net2Net  (Chen et al.,	Reply	I-Reply	2
2015a).	Reply	I-Reply	2
Using the curriculum-based setting, the model learns the tasks in easy-to-hard order.	Reply	I-Reply	2
The model alleviates the forgetting problem by GEM method, and if it fails to learn the current task and has not been expanded yet, the model will expand to a larger model by the Net2Net approach.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: Can you comment on how much discarding is needed to generate the required number of pseudo-samples?	Reply	O	0
[line_break_token][line_break_token]A3: After 9 epochs of training for each task, the discarding happens for only 0.5% to 1% of all generated examples.	Reply	O	0
[line_break_token]We added this information to Section 3.2 the last line of the first paragraph.	Reply	B-Reply	3
[line_break_token][line_break_token]Q4: Why is it that every task was trained only for 9 epochs?	Reply	O	0
[line_break_token][line_break_token]A4: There are two reasons.	Reply	O	0
First, we want to compare our method to multitasking in a fair manner, so the total update steps on each example in each task should be exactly the same.	Reply	B-Reply	4
If we train multitask for epochs, then in LLL, we should train each task for the same number of epochs.	Reply	I-Reply	4
Secondly, we find that epochs were enough for every task we chose to converge to a satisfying performance, as shown in Table 2, the single task performance.	Reply	I-Reply	4
Some tasks may have slightly higher performance if trained for more epochs, but we only have limited computational resource so we think is a good balance.	Reply	I-Reply	4
[line_break_token][line_break_token]Q5: What is k?	Reply	O	0
Where is it introduced?	Reply	O	0
[line_break_token][line_break_token]A5: It is the of the top sampling, introduced in Section 3.2.	Reply	O	0
We made it clearer in Section 4.2 paragraph 2: In all experiments, in top sampling and for weight of the LM loss.	Reply	B-Reply	5
[line_break_token][line_break_token]Q6: On page 5, you mention that MTL is used to determine whether forgetting is caused by a lack of model capacity.	Reply	O	0
Can you explain?	Reply	O	0
[line_break_token][line_break_token]A6: In many papers (for example: Learning without Forgetting), the performance of MTL is viewed as an upper bound of the performance of lifelong learning because MTL has access to old data while lifelong learning can only access current data.*	Reply	O	0
Therefore, we assumed if we could not get acceptable performance on MTL, we don‚Äôt even need to consider the model‚Äôs capability in lifelong learning.	Reply	B-Reply	6
[line_break_token][line_break_token]* Sometimes other methods of training multiple tasks may have better overall performance than MTL.	Reply	I-Reply	6
This is because (1) training all tasks together can make optimization much harder and (2) if there are unbalanced datasets, multitasking may ignore smaller datasets during training; however when we are averaging the final scores of all tasks, the weight of every task is the same.	Reply	I-Reply	6
[line_break_token][line_break_token]Q7: Why not compare the approach with models like GEM?	Reply	O	0
[line_break_token][line_break_token]A7: We added the comparison to GEM in Section 5.2 for the SST, QA-SRL, and WOZ tasks.	Reply	O	0
The results are updated in the paper in Table 3 (<a href="https://drive.google.com/file/d/15S0qtl7TeR_a4dTvuYEa6qrWY-c8qp9f/view?usp=sharing)" target="_blank" rel="nofollow">https://drive.google.com/file/d/15S0qtl7TeR_a4dTvuYEa6qrWY-c8qp9f/view?usp=sharing)</a>[line_break_token]and Figure 5 in Appendix B (<a href="https://drive.google.com/file/d/1NE3r_wlvsKQ-IW4mC1Awa9-o-YiLVpME/view?usp=sharing)."	Reply	O	0
target="_blank" rel="nofollow">https://drive.google.com/file/d/1NE3r_wlvsKQ-IW4mC1Awa9-o-YiLVpME/view?usp=sharing).</a>[line_break_token]The performance of GEM is only slightly better than fine-tuned, which is similar to that of EWC and MAS.	Reply	O	0
[line_break_token]We do not run GEM on larger datasets because it is too time-consuming to solve the Quadratic Programming.	Reply	B-Reply	7
[line_break_token][line_break_token]Q8: Is there any reason why you choose to go from large to small tasks?	Reply	O	0
How about other orders?	Reply	O	0
[line_break_token][line_break_token]A8: On the five DecaNLP tasks, with a limited computational resource, we decided to explore this order at first.	Reply	O	0
On the three small tasks SST, QA-SRL, and WOZ, we compared all 6 orders as shown in Table 3.	Reply	B-Reply	8
[line_break_token]Now, we also completed the reversed order (WOZ ‚Üí QA-SRL ‚Üí SST ‚Üí WikiSQL ‚Üí SQuAD) experiments using following methods: (1) Fine-tuned, (2) MAS, (3), (4), (5), (6), (7), and (8).	Reply	I-Reply	8
Again, because it is too time-consuming for solving the Quadratic Programming, we did not run GEM.	Reply	I-Reply	8
[line_break_token]The results are shown in Appendix C (<a href="https://drive.google.com/file/d/1Y9ACQIAMH8tXFrS-ezLjmAIo1gHDvYDl/view?usp=sharing)."	Reply	O	0
target="_blank" rel="nofollow">https://drive.google.com/file/d/1Y9ACQIAMH8tXFrS-ezLjmAIo1gHDvYDl/view?usp=sharing).</a>[line_break_token]We can clearly see that our method performs much better than Fine-tuned and MAS.	Reply	O	0
In this case, even performs better than multitasking, possibly due to the reason stated in the annotation in A6.	Reply	B-Reply	8
[line_break_token][line_break_token]---- to be continued ----	Reply	O	0

The authors propose a method for lossless image compression based on using[line_break_token]fully convolutional VAE models.	Review	O	0
These models are shown to generalize well when[line_break_token]they are trained on small images (e.g. 32x32 and 64x64) and then applied to[line_break_token]much larger images.	Review	O	0
The method is based on a fully vectorized implementation of[line_break_token]bits back with asymetric numeral systems coding which is much faster than[line_break_token]previous non-vertorized implementations.	Review	O	0
An improvement with respect to similar[line_break_token]methods is to use a dynamic discretization of the latent variables which avoids[line_break_token]having to callibrate a static discretization (as in previous methods).	Review	O	0
[line_break_token]Finally, the authors initialize the bis back process with information about a[line_break_token]few initial images which are coded using a different codec.	Review	O	0
 The experiments[line_break_token]performed illustrate the gains of the method in terms of compression ratio and[line_break_token]speed.	Review	O	0
[line_break_token][line_break_token]Clarity:[line_break_token][line_break_token]The paper is extremelly well writen and it is very easy to read.	Review	O	0
The athors[line_break_token]indicate that they will release open-source code to implement all their[line_break_token]results, which is very wellcome to improve reproducibility.	Review	O	0
However, I have to[line_break_token]say that the part describing the vectorized implementation of their method was[line_break_token]rather confusing and the paper could benefit a lot from clarifying this part.	Review	B-Review	1
[line_break_token][line_break_token]Quality:[line_break_token][line_break_token]The experiments performed are sound and illustrate the gains produced by their[line_break_token]method (although they do not achieve state of the art results).	Review	O	0
In particular,[line_break_token]the experiments show the speed up gain by the proposed vectorization and the gains[line_break_token]produced by the dynamic discretization.	Review	O	0
The experiments also show how the methods[line_break_token]trained on smaller images generalize well to larger images.	Review	O	0
[line_break_token][line_break_token]Novelty:[line_break_token][line_break_token]The proposed approach is novel up to my knowledge.	Review	O	0
Although the methodological[line_break_token]innovations are not that advanced, the vectorization in the specific[line_break_token]application considered is novel, as well as the dynamic discretization.	Review	O	0
[line_break_token][line_break_token]Significance:[line_break_token][line_break_token]The proposed contributions are significant in my opinion.	Review	O	0
The vectorization[line_break_token]approach can be very useful in practice and the dynamic discretization can also[line_break_token]be useful as shown by the experiments.	Review	B-Review	2
One criticism could be that the authors[line_break_token]do not achieve state of the art results, but I consider this a minor thing.	Review	I-Review	2
hank you for your review.	Reply	O	0
We address the following point:[line_break_token][line_break_token]&gt; However, I have to say that the part describing the vectorized implementation of their method was rather confusing and the paper could benefit a lot from clarifying this part.	Reply	O	0
[line_break_token][line_break_token]It‚Äôs difficult to give a proper description of this without going into a lot more detail about ANS implementation.	Reply	B-Reply	1
To aid readers who are confused and/or curious, we‚Äôve added a recommendation, in the second paragraph of Section 3.2, to refer to our code and to Giesen (2015) for more detail	Reply	I-Reply	1

This paper presents a novel method to extract cross-modal text-visual embeddings on the HowTo 100M corpus.	Review	O	0
The core idea is to extend previous work on clip-level embeddings (e.g. the max-margin ranking loss proposed for HowTo 100M) to a transformer architecture which takes into account the entire context of a video, which should lead to better learned representations and improved performance in downstream tasks.	Review	O	0
In addition, the max-margin loss is replaced by noise contrastive estimation.	Review	O	0
[line_break_token][line_break_token]The paper is well written and explains the main problem well, however I do have a few questions:[line_break_token]- I do not understand the sentence "However, for images and videos, the inputs are real-valued vectors." (	Review	O	0
Section 3.2) - Transformers are being used for speech recognition or speech translation - the input features are not the problem.	Review	B-Review	1
The outputs are assumed to be discrete (in the original formulation)[line_break_token]- Why not directly compare your approach to the approach presented in (Miech, 2019c) - it would be interesting to see a direct comparison, but as far as I can tell, there is no overlap in tasks?	Review	O	0
[line_break_token]- What is the influence of adding punctuation to the ASR output, how good is it, and how good is the underlying ASR?	Review	O	0
Why did you not use the original text annotations provided by HowTo 100M, but run the audio through Google ASR (again?)	Review	B-Review	3
It would be good to know how good the ASR is, and if adding in punctuation post-hoc works well, and how this influences your use with a pre-trained BERT model.	Review	I-Review	3
My guess is that the BERT model will be happy as long as it sees a "."	Review	I-Review	3
at the end?	Review	I-Review	3
[line_break_token]- Also, would it be possible to compare the results of your work with some of the work in (Miech, 2019c) - it almost seems that your work avoids comparing your results to this previous work.	Review	O	0
[line_break_token]	Review	O	0
hank you for your positive feedback.	Reply	O	0
[line_break_token][line_break_token]Comparison to HowTo100M:[line_break_token][line_break_token]Although we use the HowTo100M dataset for pre-training, there are key differences to (Miech, 2019c):[line_break_token]1.	Reply	O	0
Miech et al.	Reply	B-Reply	5
improve text-video embedding by training on HowTo100M and show the gain by transferring it to the text to video retrieval task.	Reply	I-Reply	5
In comparison, CBT focuses on learning generic visual and temporal features, with or without using text-video correspondences.	Reply	I-Reply	5
We show that CBT can be transferred to various downstream tasks, such as classification, anticipation, segmentation and captioning.	Reply	I-Reply	5
[line_break_token]2.	Reply	O	0
Miech et al.	Reply	B-Reply	5
assume the visual features to be pre-trained and fixed, while CBT can be applied for self-supervised visual representation learning, as shown in Table 1.	Reply	I-Reply	5
[line_break_token][line_break_token]Direct comparison to (Miech2019c):[line_break_token]We evaluate our cross-modal model pre-trained on HowTo100M with the same preprocessing as in (Miech2019c), i.e. with short clips.	Reply	O	0
We evaluate on the MSR-VTT clip retrieval benchmark (zero-shot settings) and can observe that we outperform their approach, see below.	Reply	B-Reply	2
We will add this results to the final version of the paper if accepted.	Reply	I-Reply	2
[line_break_token]HowTo100M (table 6):    R@1: 7.5   R@5: 21.2   R@10: 29.6   median R: 38[line_break_token]Ours:                                 R@1: 8.3   R@5: 23.3   R@10: 33.2   median R: 30[line_break_token][line_break_token]‚ÄúThe inputs are real-valued vectors‚Äù:[line_break_token]Thank you for pointing this out, we will clarify in the final version.	Reply	O	0
[line_break_token][line_break_token]Influence of ASR and punctuation:[line_break_token]The video clips and speech released by HowTo100M were preprocessed and broken into short segments.	Reply	O	0
To learn long-term temporal features with the transformer, our approach requires longer input clips.	Reply	B-Reply	3
Hence, we re-extract the ASR with the same algorithm as HowTo100M and run punctuation to get longer semantic coherent text segments (sentences).	Reply	I-Reply	3
Furthermore, we concatenate several consecutive sentences to obtain even longer sequences of video-ASR training data.	Reply	I-Reply	3

In this paper, the authors tackle the problem of multi-modal image-to-image translation by pre-training a style-based encoder.	Review	O	0
The style-based encoder is trained with a triplet loss that encourages similarity between images with similar styles and dissimilarity between images with different styles.	Review	O	0
The output of the encoder is a style embedding that helps differentiates different modes of image synthesis.	Review	O	0
 When training the generator for image synthesis, the input combines an image in the source and a style embedding, and the loss is essentially the sum of image conditional GAN loss and perceptual loss.	Review	O	0
Additionally, the authors propose a mapping function to sample styles from a unit Gaussian distribution.	Review	O	0
[line_break_token][line_break_token]I think the idea of pre-training a style-based encoder is straightforward.	Review	O	0
I am mainly concerned about the performance of the presented approach.	Review	O	0
First, there are no many visual comparisons in the paper.	Review	B-Review	1
The only visual comparison is in Figure 8, but results are only limited to faces.	Review	I-Review	1
The visual results in Figure 5 do not look appealing to me.	Review	I-Review	1
The change in the style mainly comes from the global change in color: no much change in the texture or local color.	Review	I-Review	2
The "night2day" results look poor to me.	Review	I-Review	2
 I am concerned about the diversity of the styles learned in the model.	Review	I-Review	2
[line_break_token][line_break_token]On the other hand, I am convinced that the proposed model is better than BicycleGAN, and the approach is somehow novel.	Review	I-Review	3
The user study in Table 5 suggests that the proposed method is somehow better than BicyleGAN in visual quality on one task.	Review	I-Review	3
My overall rating is borderline.	Review	I-Review	3
[line_break_token][line_break_token]Minor comments:[line_break_token]- In the first sentence of Section 3.2, I do not think "one-to-one correspondence" is the right description.	Review	I-Review	4
The encoder is not expected to be invertible.	Review	I-Review	4
[line_break_token]- In Equation (3), "e_i" is a little bit misleading.	Review	I-Review	4
It does not mean the i-th element in {"e_j"}. You may want to replace "e_i" with "s_i" to avoid confusion.	Review	I-Review	4
[line_break_token]- The explanation of ours v1, v2, v3, v4 is not clear.	Review	I-Review	4
It is also difficult to find its definition.	Review	I-Review	4
hank you for reviewing our paper!	Reply	O	0
Please find responses to your points/questions below:[line_break_token][line_break_token]Visual comparisons: Figure 2 in the paper shows qualitative comparisons, not just figure 8.	Reply	O	0
Also, Table 5 shows results of a user study which compared the quality of 50 different outputs of our method against the BicycleGAN-based baselines.	Reply	B-Reply	1
[line_break_token][line_break_token]Diversity comes from global change in color: we would like to highlight that there is plenty of evidence in the paper that the diversity doesn‚Äôt come from just the global color change.	Reply	I-Reply	2
For example:[line_break_token]- Figure 5 (style sampling):[line_break_token]    - Space needle: results show clear weather changes, such as cloudy vs sunny, change in cloud patterns and even sampling foggy weather which was present in some images in the training set.	Reply	I-Reply	2
[line_break_token]    - Maps dataset: the existence and/or density of bushes clearly varies between different sampled styles.	Reply	I-Reply	2
[line_break_token]    - Edges2handbags: the texture of the bag varies clearly between smooth and rough leather (better seen in zoom).	Reply	I-Reply	2
[line_break_token]- Figure 4 (style interpolation):[line_break_token]    - The smooth change from cloudy to sunny weather including the change in lighting and cloud patterns.	Reply	I-Reply	2
[line_break_token]- Figure 3 (style transfer):[line_break_token]    - Space needle: the output style clearly copies the weather condition.	Reply	I-Reply	2
We show sunset, sunny, foggy and cloudy weather.	Reply	I-Reply	2
[line_break_token]    - Night2day: variation in lighting conditions can be clearly seen including transferring whether the surface is sunlit or not, as well as different cloud patterns and clear skies.	Reply	I-Reply	2
[line_break_token]    - Edges2handbags: the output texture varies (most clear in the third image with the dark pink color).	Reply	I-Reply	2
Figure best seen in zoom.	Reply	I-Reply	2
[line_break_token]- Figure 2 (qualitative comparison):[line_break_token]    - Our approach matches the GT texture better than the baselines (most obvious in the left column - first and third rows) ‚Äî figure best seen in zoom.	Reply	I-Reply	2
[line_break_token]Also, we quantitatively measure the output diversity in both style transfer and style sampling setups in Table 5.	Reply	I-Reply	2
[line_break_token][line_break_token]Quality of results:[line_break_token]We recommend looking at the figures in zoom to better appreciate the quality.	Reply	O	0
The night2day and labels2facades datasets are particularly smaller than the other datasets, as night2day has only 100 unique scenes in the training set, while the labels2facades trainset contains only a few hundred images.	Reply	B-Reply	3
We observed that our models overfits the training set if we trained with full capacity like the larger datasets.	Reply	I-Reply	3
While we used the same hyper-parameters for all datasets, the change we made for training on the night2day and labels2facades datasets is to use a smaller model (i.e reduce the number of convolution filters), and train for shorter (i.e early stopping).	Reply	I-Reply	3
[line_break_token][line_break_token]Minor comments: thank you for the suggestions.	Reply	I-Reply	4
We will adopt the suggested changes, and include a clear definition for the different versions of our method, and we will submit a revised version of our paper by Friday.	Reply	I-Reply	4

The goal of this work is to best understand the performance and benchmarking of continual learning algorithms when applied to sequential data processing problems like language or sequence data sets.	Review	O	0
The contributions of the paper are 3 fold - new benchmarks for CL with sequential data for RNN processing, new architecture introduced for more effective processing and a thorough empirical evaluation.	Review	O	0
[line_break_token][line_break_token]Introduction: [line_break_token]I think a little more insight into why the sequential data processing CL scenario is any different than the vision scenario would be quite helpful.	Review	O	0
Specifically, it would be quite impactful to tell us more about what the additional challenges with RNNs for CL vs feedforward for CL are in the intro.	Review	B-Review	1
[line_break_token][line_break_token]The paper is written as if the benchmark is the main contribution and the architecture improvement is just a delta on top of this, but it gets confusing when the methods section starts off with just directly stating the new architecture.	Review	I-Review	2
[line_break_token][line_break_token]The algorithm seems like a straightforward combination of recurrent progressive nets and gated autoencoders for CL.	Review	I-Review	3
Can the authors provide more justification if that is the contribution or there is more to the insight than has been previously suggested in prior work?	Review	I-Review	3
[line_break_token][line_break_token]Figure 1 has a very uninformative caption.	Review	I-Review	4
It also doesn‚Äôt show how modules feed into one another properly.	Review	I-Review	4
[line_break_token][line_break_token]The motivation for why one needs GIM after one already has A-LSTM or A-LMN is not very clear?	Review	I-Review	5
[line_break_token][line_break_token]Overall the contribution does seem a bit incremental based on prior work and the description lacks enough detail to properly indicate why this is a very important contribution?	Review	I-Review	6
[line_break_token][line_break_token]Experiments:[line_break_token]What does it mean to be application agnostic but restricted to particular datasets and losses?	Review	O	0
This doesn‚Äôt quite parse to me.	Review	B-Review	7
[line_break_token][line_break_token]The description of the tasks is very informal and hard to follow.	Review	I-Review	8
It‚Äôs not clear what exactly the tasks and datasets look like [line_break_token][line_break_token]‚Äúusing morehidden units can bridge this gap‚Äù -&gt; why not just do it?	Review	O	0
Its a benchmark after all.	Review	B-Review	8
[line_break_token][line_break_token]Overall the task descriptions should be in a separate section where the setup is described in a lot of detail and motivated properly.	Review	I-Review	9
[line_break_token][line_break_token]The results in the experiments section are very hard to parse.	Review	I-Review	10
The captions need much more detail for eg Table 2.	Review	I-Review	10
[line_break_token][line_break_token]Could we also possibly have more baselines from continual learning?	Review	I-Review	11
For instance EWC (Kirkpatrick) or generative replay might be competitive baselines.	Review	I-Review	11
[line_break_token][line_break_token]Overall I think that the GIM and A-LMN and A-LSTM methods are reasonable although somewhat incremental.	Review	I-Review	12
But the proposed benchmarks are pretty unclear and the results are a bit hard to really interpret well.	Review	I-Review	12
It would also be important to run comparisons with more baselines and to provide more ablation/analysis experiments to really see the benefit of GIM/A-LMN or A-LSTM.	Review	I-Review	12
I also think that the task descriptions should be much earlier in the paper and desribed in much more rigorous detail.	Review	I-Review	12
[line_break_token]	Review	O	0
he main difference between the sequential data processing scenario and the vision scenario is related to the fact that sequential processing requires the use of a memory that embeds the history of past inputs.	Reply	B-Reply	1
Such memories have to be appropriately learned and preserved, making the sequential processing tasks clearly different than the vision tasks.	Reply	I-Reply	1
When it comes to CL, drifts in the input distribution could affect the hidden memory of RNNs.	Reply	I-Reply	1
Additional works will be needed in order to clarify this phenomenon.	Reply	I-Reply	1
We will clarify this point in the Introduction.	Reply	I-Reply	1
[line_break_token][line_break_token]The main concern of this work was to provide a set of common benchmarks for CL in sequential domains that are independent of domain-specific applications (e.g. NLP) against which existing and future models can compare their performances.	Reply	I-Reply	2
We will better describe the experimental settings, reserving a specific section to the description of the tasks and datasets.	Reply	I-Reply	2
Since they are the main contribution of this work, we agree that they should be better highlighted.	Reply	I-Reply	2
[line_break_token]In addition, we extend the progressive approach and the gating autoencoder to the recurrent domain.	Reply	I-Reply	2
At the best of our knowledge, no previous work proposed these two extensions for recurrent neural networks, nor they combine both into one end-to-end model.	Reply	I-Reply	2
[line_break_token][line_break_token]The reason why the Augmented models need the autoencoders (e.g. from A-LSTM to GIM-LSTM) is that without the autoencoders is not possible to avoid the use of task labels at inference time.	Reply	I-Reply	5
GIM architectures can detect the correct module for inference, while Augmented modules alone only allow the transfer of useful, learned features from one module to the others.	Reply	I-Reply	5
[line_break_token][line_break_token]The experimental protocol is task-agnostic in the sense that we do not restrict the choice of datasets to a particular application (e.g. NLP), but instead, we proposed a set of general datasets (Copy and SSMNIST) that do not require any domain-specific technique.	Reply	I-Reply	7
Using this benchmarks, we can evaluate CL models while eliminating the idiosyncrasies of specific application domains.	Reply	I-Reply	7
[line_break_token][line_break_token]In future versions, we will extend standard CL techniques to the RNN scenario and we will compare their performances against both naive RNNs and GIM.	Reply	I-Reply	1
[line_break_token]We will also provide ablation studies highlighting the effects that autoencoders and inter-modules connections have on the overall performance of GIM	Reply	I-Reply	12

This paper proposes a new variational recurrent model for learning sequences.	Review	O	0
Comparing to existing work, instead of having latent variables that are dependent on the neighbors, this paper proposes to use independent latent variables with observations that are generated from multiple latent variables.	Review	O	0
[line_break_token]The paper further combined the proposed method with multiple existing ideas, such as the shared/prviate representation from VAE-CCAE, adding the hierarchical structure, and prior updating.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]The proposed method seems technical correct and reasonable.	Review	O	0
[line_break_token]There are many extensions which are potentially useful for many applications [line_break_token]There are many experimental results showing promising performance.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]The framework is very incremental.	Review	O	0
It is novel but limited.	Review	B-Review	1
[line_break_token]The paper claim that the main point to use the simpler variations distribution is to speed up the inference.	Review	I-Review	2
But no speed comparisons are shown in the experiments section.	Review	I-Review	2
[line_break_token]The evaluation shows that prior updating (one extension) seems contributes to the biggest performance gain, not the main proposed method.	Review	I-Review	3
[line_break_token][line_break_token]	Review	O	0
Thank you for pointing out the missing speed comparison.	Reply	B-Reply	1
 RecRep is roughly twice faster in our implementation than StocCon when using batch size 4.	Reply	I-Reply	1
 We will include this in a revision.	Reply	I-Reply	1
 Regarding the degree of novelty, our main contribution is a practical approach to representation learning for sequences that improves performance on multiple downstream tasks.	Reply	O	0
 While prior work has largely focused on measuring the quality of recurrent models for generation, we focus on making them useful for representation learning	Reply	B-Reply	1

This work proposed a mask based approach for instance-level unsupervised content transfer, which is an extension of the disentanglement work in (Press et al.,	Review	O	0
2019) and the attention guided translation (Chen et al.,	Review	O	0
2018, Mejjati et al.,	Review	O	0
2018).	Review	B-Review	1
Unlike the disentanglement work, the introduced mask allows the adaptation to focus on the relevant content which substantially reduce the complexity of the generation.	Review	O	0
On the other hand, the proposed method extends the attention guided translation from the domain level to the instance level which allows more specific and diverse translations.	Review	O	0
Experiments on benchmark data shows both improved qualitative and quantitative results comparing to existing methods.	Review	O	0
It is really nice that the authors also considered the situation of generalization to out of domain images.	Review	O	0
[line_break_token][line_break_token]However, I would encourage the authors to spend more discussion on the "Method" and "Ablation Analysis" sections to give a better illustration.	Review	B-Review	1
First is the choice of the L2 norm in all the reconstruction losses, which is different from L1 norm used in both (Press et al.,	Review	I-Review	1
2019) and (Mejjati et al.,	Review	I-Review	1
2018).	Review	I-Review	1
What is the advantage of using L2 instead of L1 norm here?	Review	I-Review	1
Does it work better with the mask generation?	Review	I-Review	1
Second, the domain confusion loss.	Review	I-Review	1
The presence of both equation (3) and (4) are quite confusing and the domain confusion loss (3) seems different from traditional ones.	Review	I-Review	1
In Table 7, it shows that the learned mask is empty without any of the losses (3), (5), (7).	Review	I-Review	1
But only loss (7) is directly related to the mask generation.	Review	I-Review	1
How does the loss (3) or (5) impact the mask learning?	Review	I-Review	1
It is also unclear why the losses introduced in (8) would encourage the mask to be minimal despite the quantitative results shown in Table 7.	Review	I-Review	1
Actually, I am very curious about the performance of the loss introduced in (Press et al.,	Review	I-Review	1
2019) on top of the network introduced in Figure 2.	Review	I-Review	1
[line_break_token][line_break_token]Other comments:[line_break_token]- It would be nice to see the out of domain transfer in the "attribute" domain.	Review	O	0
Ideally, the network should be able to detect "difference" in the image from domain B and apply it to the image from domain A. For example, the model is trained on faces without and with glasses, but applied to faces without and with facial hair.	Review	B-Review	2
Indeed, the introduction of mask alleviates the decoder to learn the attribute itself, and provides the ability to locate the place of difference.	Review	I-Review	2
[line_break_token]- Please unify the citation style: there are both Press et al. (	Review	O	0
2019) and (Press et al.,	Review	B-Review	3
2019) used.	Review	I-Review	3
[line_break_token]- In Section 2 under "Mask Based Approaches", the authors argued that the existing attention guided translation "does not allow for the adaptation of the image information in the masked area".	Review	O	0
I do not think this is the case.	Review	B-Review	4
The existing work also introduced adaptation of the image information in the masked area.	Review	I-Review	4
For example, the equation (1) in (Mejjati et al.,	Review	I-Review	4
2018).	Review	I-Review	1
[line_break_token]- How is the binarized mask generated in inference?	Review	O	0
Specifically, how to determine the threshold?	Review	B-Review	5
[line_break_token]- In Section 4.1, the authors argued that "without L_{Cycle} the masks produced include larger portions of the face".	Review	O	0
But this actually produces the second smallest mask in Table 7.	Review	B-Review	6
[line_break_token]- What is the "L2 reg" in Table 7?	Review	O	0
[line_break_token]- It would be good to show the sensitivity of the lambdas in the overall loss.	Review	O	0
ith regards to the sensitivity of the lambda coefficients in our loss, the values of the coefficients were set early on in the development process in a way that reflects the relative importance we attributed to each component and the observed trade-offs.	Reply	B-Reply	8
For example, if the mask obtained was too large we would increase (Eq.	Reply	I-Reply	8
8).	Reply	I-Reply	8
As illustrated in Fig.	Reply	I-Reply	8
39, our network is not overly sensitive to the choice of these values.	Reply	I-Reply	8
For example, for (Eq.	Reply	I-Reply	8
8) loss each value in the range 0.4-1.0 results in a similar output and for (Eq.	Reply	I-Reply	8
5) each value in the range 3.0-7.0 results in a similar output	Reply	I-Reply	8

The authors propose a framework for combining value function factorization and communication learning in a multi-agent setting by introducing two regularizers, one for maximizing mutual information between decentralized Q functions and communication messages and the other for minimizing the entropy of messages between agents.	Review	O	0
The authors also discuss a method for dropping non-informative messages.	Review	O	0
They illustrate their approach on sensor and hallway tasks and evaluate their method on the decentralized StarCraft II benchmark.	Review	O	0
The paper addresses an interesting problem, and the authors show that their approach gives good performance compared to alternative approaches even when a large percentage of communication is cut off between the agents.	Review	O	0
[line_break_token][line_break_token]Questions/Comments:[line_break_token]- Implementation details (e.g., hyper-parameters, model size) are missing from the paper.	Review	O	0
[line_break_token]- The results are average over only 3 seeds, is this enough to compare different algorithms?	Review	O	0
[line_break_token]- How should beta should be determined?	Review	O	0
[line_break_token]- The authors present results when 80% of messages are cut off.	Review	O	0
What is the performance of the model when all communication is cut off for comparison?	Review	B-Review	4
[line_break_token]- How does the approach work in competitive environments?	Review	O	0
[line_break_token]- The experimental results section is not well organized.	Review	O	0
The authors mention five question on page 6, but it is not very clear with examples/set of experiments address which question.	Review	B-Review	6
[line_break_token]- There are many spelling/grammar errors in the paper.	Review	O	0
hanks for your comments.	Reply	O	0
Here we provide explanations to clarify your questions.	Reply	O	0
In addition, please feel free to refer to our response to reviewer #1, which summarizes novelties of our paper.	Reply	O	0
[line_break_token] [line_break_token]Q: Implementation details (e.g., hyper-parameters, model size) are missing from the paper.	Reply	O	0
[line_break_token]A: These details were described in Appendix B of our original submission because of the space limitation.	Reply	O	0
[line_break_token] [line_break_token]Q: The results are average over only 3 seeds, is this enough to compare different algorithms?	Reply	O	0
[line_break_token]A: We have run all the SC2 experiments with more random seeds and found that the variances of learning curves are similar and the performance comparison results do not change.	Reply	O	0
We have shown learning curves averaged over 5 different random seeds in Fig.	Reply	B-Reply	2
7, 8, and 10 in the updated version of our paper.	Reply	I-Reply	2
                                                                                                                                                         [line_break_token]                                                                                                                                  [line_break_token]Q: How beta should be determined?	Reply	O	0
[line_break_token]A: is used to trade off communication costs and communication effects.	Reply	O	0
We have studied how affects the message embedding on the task sensor, as shown in Fig.3 on page 6.	Reply	B-Reply	3
We also find that the performance of our method is robust across all the tested environments when.	Reply	I-Reply	3
Therefore, we recommend that a in this region being tried first on new tasks and some fine-tuning may improve the performance further.	Reply	I-Reply	3
[line_break_token] [line_break_token]Q: The authors present results when 80% of the messages are cut off.	Reply	O	0
What is the performance of the model when all communication is cut off for comparison?	Reply	O	0
[line_break_token]A: We have shown the performance comparison when all communication is cut off, which is illustrated by Fig.	Reply	O	0
10 on page 16 of our original submission.	Reply	B-Reply	4
[line_break_token] [line_break_token]Q: How does the approach work in competitive environments?	Reply	O	0
[line_break_token]A: Our approach is designed for a team of agents to learn to effectively collaborate and coordinate.	Reply	O	0
These cooperative scenarios are common in the field of MARL [Foerster et al.,	Reply	B-Reply	5
AAAI 2018, Rashid et al.,	Reply	I-Reply	5
ICML 2018]. Of course, such a team of agents can compete against another opponent team in competitive settings.	Reply	I-Reply	5
[line_break_token] [line_break_token]In mixed cooperative-competitive tasks, our method is readily combined with IC3Net [Singh et al.,	Reply	I-Reply	5
ICLR 2019], learning gates to cut off messages sent to the opponents.	Reply	I-Reply	5
It will be the same as how TarMAC [Das et al.,	Reply	I-Reply	5
ICML 2019] is adapted to mixed environments.	Reply	I-Reply	5
However, this setting is not the focus of this paper, and we will explore it in the future.	Reply	I-Reply	5
[line_break_token] [line_break_token]Q: The experimental results section is not well organized.	Reply	O	0
The authors mention five questions on page 6, but it is not very clear which examples/set of experiments address which question.	Reply	O	0
[line_break_token]A: Performance comparison and visualization results of didactic experiments can clarify all the questions.	Reply	O	0
Our SC2 experiments further prove that the miscoordination problem of full decomposition methods is quite common and that our method can outperform QMIX and a state-of-the-art attentional communication algorithm.	Reply	B-Reply	6
[line_break_token] [line_break_token]We hope that our clarifications can address your questions.	Reply	O	0
Please let us know if you have any other questions.	Reply	O	0
[line_break_token] [line_break_token][Foerster et al.,	Reply	B-Reply	5
AAAI 2018] Foerster, J.N., Farquhar, G., Afouras, T., Nardelli, N. and Whiteson, S., 2018, April.	Reply	O	0
Counterfactual multi-agent policy gradients.	Reply	O	0
In Thirty-Second AAAI Conference on Artificial Intelligence.	Reply	O	0
[line_break_token][line_break_token][Rashid et al.,	Reply	O	0
ICML 2019] Rashid, T., Samvelyan, M., Witt, C.S., Farquhar, G., Foerster, J. and Whiteson, S., 2018, July.	Reply	O	0
QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning.	Reply	O	0
In International Conference on Machine Learning (pp.	Reply	O	0
4292-4301).	Reply	O	0
[line_break_token] [line_break_token][Singh et al.,	Reply	B-Reply	5
ICLR 2019] Singh, A., Jain, T. and Sukhbaatar, S., 2019.	Reply	O	0
Learning when to communicate at scale in multiagent cooperative and competitive tasks.	Reply	O	0
In International Conference on Learning Representations.	Reply	O	0
[line_break_token] [line_break_token][Das et al.,	Reply	B-Reply	5
ICML 2019] Das, A., Gervet, T., Romoff, J., Batra, D., Parikh, D., Rabbat, M. and Pineau, J., 2019, May. TarMAC: Targeted Multi-Agent Communication.	Reply	O	0
In International Conference on Machine Learning (pp.	Reply	O	0
1538-1546)	Reply	O	0

This paper extends the work of TT-RRN [Khrulkov et al.,	Review	O	0
2018] to further analyze the connection between RNN and TT decomposition by incorporating generalized nonlinearity, i.e., RELU, into the network architectures.	Review	O	0
Specifically, the authors theoretically study the influence of generalized nonlinearity on the expressivity power of TTD-based RNN, both theoretical result and empirical validation show that generalized TTD-based RNN is more superior to CP-based shallow network in terms of depth efficiency.	Review	O	0
[line_break_token]Pros:[line_break_token]1.	Review	O	0
This work is theoretically solid and extend the analysis of TT-RNN to the case of generalized nonlinearity, i.e. ReLU.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
The paper is well written and organized.	Review	O	0
[line_break_token] [line_break_token]Cons:[line_break_token]1.	Review	O	0
The contribution and novelty of this paper is incremental and somehow limited, since the analysis TT-RNN based on the product nonlinearity already exists, which make the contribution of this paper decreased.	Review	B-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The analysis is mainly on the particular case of rectifier nonlinearity.	Review	B-Review	2
I wonder if the nonlinearities other than the RELU hold the similar properties?	Review	I-Review	2
The proof or discussion on the general nonlinearities is missing.	Review	I-Review	2
[line_break_token][line_break_token]Other comments:[line_break_token]1.	Review	O	0
The authors said that the replacement of standard outer product with its generalized version leads to the loss of conformity between tensor networks and weight tensors, the author should clarify this in a bit more details.	Review	B-Review	3
[line_break_token][line_break_token]2.	Review	O	0
The theoretical analysis relies on grid tensor and restricts the inputs on template vectors.	Review	B-Review	4
It is not explained why to use and how to choose the those template vectors in practice?	Review	I-Review	4
[line_break_token][line_break_token]3.	Review	O	0
A small typo: In Figure 2, ‚Äòm' should be ‚ÄòM'	Review	B-Review	5
Thank you for your comments!	Reply	O	0
Please, see the answers to your questions below.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
The detailed proof we provide in the paper indeed refers to the ReLU nonlinearity only.	Reply	B-Reply	2
Due to the constructive nature of our proof, it is not easily generalized to the arbitrary associative and commutative binary operator, and we highly doubt that it will work in general.	Reply	I-Reply	2
However, even without solid theoretical justification, we can implement generalized tensor networks with various nonlinearities and compare them empirically, which we do in Section B of the appendix.	Reply	I-Reply	2
As we can see, the right choice of nonlinearity for particular dataset may lead to boost in the performance and it will be interesting direction of research to analyze them more rigorously from both theoretical and practical viewpoints.	Reply	I-Reply	2
[line_break_token][line_break_token]2.	Reply	I-Reply	3
Before introducing the concept of generalized tensor networks, we had full correspondence between the score functions of scalar product form (equation 2) and the score functions of tensor decomposition form (equations 6 and 8).	Reply	I-Reply	3
It ensures that tensor networks are universal function approximators and allows us to focus on another important properties, such as expressivity.	Reply	I-Reply	3
However, after replacing the outer product with different operator and declaring the expressions from equations 14 and 16 to be the score functions, we can no longer state that they can be represented in a form of equation 2.	Reply	I-Reply	3
Specifically, we can no longer guarantee the existence of corresponding weight tensor W (and, thus, universality), the existence of which was trivial in the case of standard tensor networks with multiplicative nonlinearity.	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	O	0
The use of template vectors is motivated by the discussion in [1]. In order to be able to achieve zero classification error for the model under analysis, the data has to satisfy two assumptions: label has to be completely determined by the instance, and the input vectors may be quantized into one of the M templates.	Reply	B-Reply	4
The assumption that natural images possess these properties is based on various empirical studies.	Reply	I-Reply	4
For example, it was shown in [2] that small image patches of sizes 2x2, 4x4, 8x8, 16x16, and so on, can be effectively modeled by a GMM of size 64.	Reply	I-Reply	4
We believe that similar properties also hold for sequential data appearing in NLP tasks, however, this assumption requires further investigation.	Reply	I-Reply	4
[line_break_token][line_break_token][1] N. Cohen, O. Sharir, A. Shashua.	Reply	O	0
On the expressive Power of Deep Learning: A Tensor Analysis.	Reply	O	0
In Conference on Learning Theory, pp.	Reply	O	0
698 - 728, 2016.	Reply	O	0
[line_break_token][2] D. Zoran, Y. Weiss.	Reply	O	0
Natural images, Gaussian Mixtures and Dead Leaves.	Reply	O	0
In Advances in Neural Information Processing Systems, pp.	Reply	O	0
1745 - 1753, 2012	Reply	O	0

The authors improve a retriever-reader architecture for open-domain QA by iteratively retrieving passages and tuning the retriever with reinforcement learning.	Review	O	0
They first learn vector representations of both the question and context, and then iteratively change the vector representation of the question to improve results.	Review	O	0
I think this is a very interesting idea and the paper is generally well written.	Review	O	0
[line_break_token][line_break_token]I find some of the description of the models, methods and training is lacking detail.	Review	B-Review	1
For example, their should be more detail on how REINFORCE was implemented; e.g. was a baseline used?	Review	I-Review	1
[line_break_token][line_break_token]I am not sure about the claim that their method is agnostic to the choice of machine reader, given that the model needs access to internal states of the reader and their limited results on BiDAF.	Review	I-Review	2
[line_break_token][line_break_token]The presentation of the results left a few open questions for me:[line_break_token][line_break_token]  - It is not clear to me which retrieval method was used for each of the baselines in Table 2.	Review	O	0
[line_break_token]  - Why does Table 2 not contain the numbers obtained by the DrQA model (both using the retrieval method from the DrQA method and their method without reinforcement learning)?	Review	O	0
That would make their improvements clear.	Review	B-Review	4
[line_break_token]  - Moreover, for TriviaQA their results and the cited baselines seem to all perform well below to current top models for the task (cf.	Review	O	0
<a href="https://competitions.codalab.org/competitions/17208#results)."	Review	O	0
target="_blank" rel="nofollow">https://competitions.codalab.org/competitions/17208#results).</a>[line_break_token]  - I would also like to see a better analysis of how the number of steps helped increase F1 for different models and datasets.	Review	O	0
The presentation should include a table with number of steps and F1 for different step numbers they tried. (	Review	B-Review	6
Figure 2 is lacking here.)	Review	I-Review	6
[line_break_token]  - In the text, the authors claim that their result shows that natural language is inferior to 'rich embedding spaces'.	Review	O	0
They base this on a comparison with the AQA model.	Review	B-Review	7
There are two problems with this claim: 1) The two approaches 'reformulate' for different purposes, retrieval and machine reading, so they are not directly comparable.	Review	I-Review	7
2) Both approaches use a 'black box' machine reading model, but the authors use DrQA as the base model while AQA uses BiDAF.	Review	I-Review	7
Indeed, since the authors have an implementation of their model that uses BiDAF, an additional comparison based on matched machine reading models would be interesting.	Review	I-Review	7
[line_break_token]- Generally, it would be great to see more detailed results for their BiDAF-based model as well.	Review	O	0
[line_break_token]	Review	O	0
We sincerely thank you for your insightful comments and we‚Äôre glad that you found our approach interesting.	Reply	O	0
Based on your comments, we have significantly improved the writing of the paper with more details and have added more evaluation.	Reply	O	0
Below we address your concerns point-by-point.	Reply	O	0
[line_break_token][line_break_token]- I find some of the description of the models, methods and training is lacking detail.	Reply	O	0
For example, their should be more detail on how REINFORCE was implemented; e.g. was a baseline used?	Reply	O	0
[line_break_token][line_break_token]We have significantly updated the model section of our paper to include more details about methods and training (Sec 2 & 3).	Reply	O	0
To answer your specific question about use of variance reduction baseline with REINFORCE -- In question answering settings, it has been noted by previous work such as  Shen et al., (	Reply	B-Reply	1
2017) that common variance reduction techniques don‚Äôt work well.	Reply	I-Reply	1
We also tried experimenting with a commonly used baseline - the average reward in a mini-batch, but found that it significantly degrades the final performance.	Reply	I-Reply	1
[line_break_token][line_break_token]I am not sure about the claim that their method is agnostic to the choice of machine reader, given that the model needs access to internal states of the reader and their limited results on BiDAF.	Reply	O	0
[line_break_token][line_break_token]We agree with you and based on your comments we have made this absolutely clear in the paper.	Reply	B-Reply	2
Our method needs access to the internal token level representation of the reader model in order to construct the current state.	Reply	I-Reply	2
The current API of machine reading models only return the span boundaries of the answer, but for our method, it needs to return the internal state as well.	Reply	I-Reply	2
What we wanted to convey is, our model does not depend/need any neural architecture re-designing to an existing reader model.	Reply	I-Reply	2
To show the same, we experimented and showed improvements with two popular and widely used reader architectures - DrQA and BiDAF.	Reply	I-Reply	2
[line_break_token]Regarding results of BiDAF -- During submission we ran out of time and hence we could not tune the BiDAF model.	Reply	I-Reply	2
But now the results of BiDAF have improved a lot and as can be seen from (Table 2, row 9), the results of BiDAF are comparable to that of DrQA.	Reply	I-Reply	2
[line_break_token][line_break_token]It is not clear to me which retrieval method was used for each of the baselines in Table 2.	Reply	O	0
[line_break_token][line_break_token]We report the best performance for each of our baseline that is publicly available.	Reply	B-Reply	3
Most of the results for the baseline (except DS-QA) are taken as reported in the R^3 paper.	Reply	I-Reply	3
We briefly describe the retrieval method used by the baselines below:[line_break_token](a) R^3 and DS-QA, like us, has a trained retriever module.	Reply	I-Reply	3
R^3 retriever is based on the Match-LSTM model and DS-QA is based on DrQA model (more details in the respective papers).	Reply	I-Reply	3
However, their retrievers compute query dependent para representation and hence don‚Äôt scale as we experimentally demonstrate in Fig 2.	Reply	I-Reply	3
[line_break_token](b) AQA, GA and BiDAF lack an explicit retriever module.	Reply	I-Reply	3
They concatenate all paragraphs in the context and feed it to their respective machine reading module.	Reply	I-Reply	3
Since the reader has to find the answer from possible very large context (because of concatenation), these models have lower performance as can be seen from Table 2.	Reply	I-Reply	3
[line_break_token][line_break_token]Why does Table 2 not contain the numbers obtained by the DrQA model (both using the retrieval method from the DrQA method and their method without reinforcement learning)?	Reply	O	0
That would make their improvements clear.	Reply	O	0
[line_break_token][line_break_token]Thanks for suggesting this experiment!	Reply	B-Reply	4
We ran the experiment and results are in (Table 2, row 7).	Reply	I-Reply	4
We trained a DrQA baseline model and the results indeed suggest that multi-step reasoning give uniform boost in performance across all datasets	Reply	I-Reply	4

The authors present a framework for testing a set of structured hypotheses about environment dynamics by learning an exploratory policy using Reinforcement Learning and a evaluator through supervised learning.	Review	O	0
They propose a formulation that decomposes environment hypotheses into sets of pre-conditions, required actions, and post-conditions.	Review	O	0
They then exploit this decomposition to (a) decouple the problem into both RL and supervised learning, and (b) provide localised pre-training to make the problem more tractable.	Review	O	0
[line_break_token][line_break_token]Overall, I really wanted to like this paper.	Review	O	0
The problem is interesting, and it certainly provides a great venue for interesting and impactful research in RL, language-conditioned decision making, structured / symbolic learning, and so on.	Review	O	0
However, I've found it relatively difficult to understand good parts of the methods and part of the experimental section, due to missing or misleading details.	Review	O	0
[line_break_token][line_break_token]In particular:[line_break_token][line_break_token]1.	Review	O	0
the justification for splitting the problem in a _exploratory_ / verification policy and a predictor is sound in principle, however it's unclear to me whether the problem is after all that intractable.	Review	O	0
In the experiment section a "RL Baseline" is mentioned in principle, however (1) it is unclear whether it was pre-trained similarly to the proposed methods, and (2) if the policy has learnt enough about the problems that its poking methodology provides enough signal to the predictor, I would expect the same policy to be able to learn the same function given enough memory and training steps.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
I'm confused by the way the authors decomposed the action space for the policy and the predictor in section 3.1.	Review	B-Review	3
Does the policy use ans_T and ans_F at any point during training?	Review	I-Review	3
Does the actor effectively decide (i.e. by choosing "ans") when to query the prediction network?	Review	I-Review	3
[line_break_token][line_break_token]3.	Review	I-Review	3
The way the authors split the templates is confusing to me.	Review	I-Review	5
Up to section 3.3.1 (and - really - until I read the appendix...), the writing sort of led me to assume that (1) the "(pre-condition, action sequence) -&gt; post-condition" split was a fairly standard manner of compose a hypothesis, and that (2) the templates were mostly symbolic.	Review	O	0
However after reading the appendix, I found the imposed structure to be fairly arbitrary, and the usage of natural language overkill and not necessarily well justified.	Review	O	0
Ideally, I would like to see some comparisons between this type of hypothesis and other decompositions used in previous literature, since it seems like the method exploits this particular structure quite heavily and I don't quite understand how it generalises to other tasks.	Review	B-Review	4
[line_break_token][line_break_token]4.	Review	O	0
The environments seem to be all fairly similar, both in terms of overall complexity, size, and features.	Review	B-Review	7
It would have been better to also present problems with fairly different settings (e.g. much different - sparser and/or denser - types of reward function), rather than evaluating multiple times on effectively the same grid-world.	Review	I-Review	7
I was though encouraged to see that one of the environment seemed to require slightly different setting in the pre-training reward setup, however the authors didn't follow up with some analysis on why there was such a difference.	Review	I-Review	7
[line_break_token][line_break_token]5.	Review	O	0
I'm confused by how the pre-training is done.	Review	B-Review	6
I understand that R_{pre} is used by itself in one environment, but I couldn't figure out whether it's both reward functions at the same time that are used in the rest of them, or just R_{ppost}. Looking at the scale of the (average?)	Review	I-Review	6
reward, the former seems to be the case, but it would be good to be certain about such things.	Review	I-Review	6
[line_break_token][line_break_token]6.	Review	O	0
The final accuracy of all the experiments are shown using the max of top-5, however appendix D shows quite a significant variance for the methods.	Review	B-Review	8
Thus I'm not sure the analysis and final considerations are reasonable.	Review	I-Review	8
What happens if the methods are trained on more seeds?	Review	I-Review	8
[line_break_token][line_break_token]6. [	Review	O	0
nit] the title is somewhat misleading: in the introduction, a scientist is defined as being both a proposer and a verifier of hypotheses, which is a reasonable, however the authors fundamentally propose to solve only arguably the more straightforward of the two problems.	Review	O	0
A less _flashy_ title would go a long way towards providing reasonable expectations for the reader.	Review	B-Review	9
[line_break_token][line_break_token][line_break_token]To improve this paper, I would like to see:[line_break_token][line_break_token]- Better clarity on how the hypothesis setup stands to previous literature.	Review	O	0
[line_break_token]- The difference in performance on each environment with different pre-training reward function (only one in show in the paper right now)[line_break_token]- At least one more environments with significantly different dynamics, or an explanation of how the existing settings differ in qualitative terms.	Review	O	0
[line_break_token]- A baseline employing some form of memory (such as heavy usage of frame stacking or recurrency), to attempt at figuring out whether it's really not reasonable to learn the whole problem simply using RL, with ablation of pre-training (which I suspect might make a significant difference).	Review	O	0
[line_break_token][line_break_token]At this point, I cannot recommend the article for acceptance, but I'd be willing to change my rating if the authors were to address some of the above points.	Review	O	0
hank you for your helpful comments and suggestions.	Reply	O	0
We have updated the paper and made some general comments above.	Reply	O	0
We will now answer your specific concerns and suggestions.	Reply	O	0
[line_break_token][line_break_token]‚ÄúThe environments seem to be all fairly similar‚Ä¶would have been better to also present problems with fairly different settings (e.g. much different - sparser and/or denser - types of reward function)‚Äù: [line_break_token]We agree and have now included new experiments that explore different forms of pre-training (something that was possible to do in the rebuttal period), which adds to the diversity of experiments presented.	Reply	O	0
More generally, we are working to demonstrate our approach on a broader set of environments, which we hope to include in a future update of the paper.	Reply	B-Reply	7
[line_break_token][line_break_token]‚Äúa "RL Baseline" is mentioned in principle, however (1) it is unclear whether it was pre-trained similarly to the proposed methods‚Äù: [line_break_token]Pre-training was not used for the RL baseline, but the deep network structure and fine-tuning procedures were the same as our approach.	Reply	O	0
[line_break_token][line_break_token]‚Ä¶ ‚ÄúI would expect the same policy to be able to learn the same function given enough memory and training steps.	Reply	O	0
‚Äù: [line_break_token]‚ÄúA baseline employing some form of memory (such as heavy usage of frame stacking or recurrency), to attempt at figuring out whether it's really not reasonable to learn the whole problem simply using RL‚Äù[line_break_token]Our revised paper includes new experiments that ran the RL baseline for longer (Appendix H), and another experiment that gave the RL baseline more ‚Äúmemory‚Äù (Appendix I).	Reply	O	0
These show that the extra training did not help, except for the pushblock task where some limited performance was achieved, although still not as much as our methods.	Reply	B-Reply	2
See those appendices for figures and more analysis.	Reply	I-Reply	2
[line_break_token][line_break_token]For clarity, all methods already keep a state memory.	Reply	I-Reply	2
In all original experiments, the policy and hypothesis predictor get the last N=5 states.	Reply	I-Reply	2
In Appendix I we show that increasing N furtehr does not improve performance.	Reply	I-Reply	2
[line_break_token][line_break_token]Also, as mentioned to R1, and as we show in Appendix G: when we have an oracle hypothesis verification predictor, the RL baseline with its stacked observations can pretty easily solve the problem.	Reply	I-Reply	2
So we don‚Äôt believe that the use of memory stacking to sidestep the partial observability is the main difficulty of this problem.	Reply	I-Reply	2
[line_break_token][line_break_token]‚ÄúI'm confused by the way the authors decomposed the action space for the policy and the predictor in section 3.1.	Reply	O	0
Does the policy use ans_T and ans_F at any point during training?	Reply	O	0
Does the actor effectively decide (i.e. by choosing "ans") when to query the prediction network?‚Äù[line_break_token]We apologize for the confusion.	Reply	O	0
The policy does not use ans_T and ans_F, it has a single ans action which then lets the actor query the prediction network.	Reply	B-Reply	3
We will make this more clear on revision.	Reply	I-Reply	3
[line_break_token][line_break_token]‚ÄúBetter clarity on how the hypothesis setup stands to previous literature‚Äù... [line_break_token]‚ÄúIdeally, I would like to see some comparisons between this type of hypothesis and other decompositions used in previous literature, since it seems like the method exploits this particular structure quite heavily‚Äù: [line_break_token]As far as we are aware, ours is the first attempt to decompose a hypothesis in this fashion for the purposes of facilitating ML based approach, thus there is no previous literature with which a comparison can be made.	Reply	O	0
However, if R2 knows of any relevant works we would be most interested.	Reply	B-Reply	4
[line_break_token][line_break_token]As requested by R3, we have added new experiments to the paper that explores different forms of decomposition, by adjusting the type of intrinsic motivation used.	Reply	I-Reply	4
These experiments that the original form of factorization chosen is more effective than other types.	Reply	I-Reply	4
See Appendix F for figures and details.	Reply	I-Reply	4
[line_break_token][line_break_token]‚Äúthe usage of natural language overkill and not necessarily well justified‚Äù: [line_break_token]We agree that for the experiments reported, we could have used simpler symbolic representations.	Reply	O	0
 It is not clear that these would actually be more convenient, and they would be less general.	Reply	B-Reply	5
 More importantly, we choose templated language because we believe it is scalable in the sense that it allows extension to more complicated and richer hypotheses.	Reply	I-Reply	5
 In our view the combinatorial nature of the hypotheses is an important feature of our framing.	Reply	I-Reply	5
 [line_break_token][line_break_token]‚Äúconfused by how the pre-training is done‚Äù: [line_break_token]Apologies for the confusion.	Reply	O	0
We will make this clearer in the next revision.	Reply	B-Reply	6
When we use both pre and prepost reward functions (which we do on pushblock and crafting) they are added.	Reply	I-Reply	6
Your interpretation here was indeed correct	Reply	I-Reply	6

This paper proposed the concept of "property signatures" , which are learned to represent programs.	Review	O	0
The property signatures are essentially some key attributes that one may summarize from a given set of input-output pairs, which the target function has.	Review	O	0
Then a program can be generated by evaluating these property signatures vectors (which is simply a bag-of-word representation with only 0 or 1 as each element).	Review	O	0
Much discussions have been given to discuss why and how these properties may be useful and very little real experiments are conducted quantitatively compared with existing works.	Review	O	0
Although this paper is quite interesting, I think this paper is in its very early stage and there are a lot of serious concerns I have for using this approach to synthesize the real complex programs.	Review	O	0
[line_break_token][line_break_token]1) First of all, the notion of property signatures are easy to understand and is very natural.	Review	O	0
Just like human beings, when we write a program, we first think about the possible attributes of this program may have given a set of input-output pairs for both correctness and completeness.	Review	B-Review	1
However, this is also the hard part of this idea.	Review	I-Review	1
Potentially it could have an exponential number of possible properties as the program goes more complex and complex.	Review	I-Review	1
It will quickly become computationally intractable problem.	Review	I-Review	1
[line_break_token][line_break_token]2) When I read the middle of paper, I would eager to know how authors can effectively find a good set of properties of a target program from a given input-output pairs.	Review	O	0
However, when I eventually reached the Section 4, I was kindly disappointed since I did not see any effective and principle way to get them.	Review	B-Review	2
All I saw are "randomly sample and generate".	Review	I-Review	2
This may be Ok for a very simple program given a set of simple input-output pairs.	Review	I-Review	2
But it is definitely not feasible for any complex function, not to mention project.	Review	I-Review	2
I think this is the key for the proposed idea since how to construct a good set of property signatures is crucial to treat them as the inputs for any program synthesis task later.	Review	I-Review	2
[line_break_token][line_break_token]3) There are very little baselines to compare against even though authors listed "substantial prior work on program synthesis".	Review	O	0
I understand the existing works may have their limitation in both what they can do and how well they can do.	Review	B-Review	3
But it is still important to compare with directly on the same set of benchmarks.	Review	I-Review	3
Otherwise, it is hard to be convincing that this approach is indeed superior compared to existing ones.	Review	I-Review	3
 	Review	I-Review	1
i and thanks again,[line_break_token][line_break_token]We've run a new experiment that we believe largely addresses your 3rd point.	Reply	O	0
[line_break_token]We wonder if, in light of this new experiment and our previous response (which addresses your 1st and 2nd points),[line_break_token]you might consider increasing your score slightly?	Reply	B-Reply	1
[line_break_token]In light of the other two reviews, a score of 1 seems perhaps a bit harsher than is warranted?	Reply	O	0
[line_break_token][line_break_token]Please let us know if there are any other questions we can answer.	Reply	O	0

The paper investigates to what degree Convolutional Neural Networks (CNNs) learn to encode positional information.	Review	O	0
[line_break_token]Rather interesting finding is the not only they do encode this information, but that it is to a large degree function of the padding commonly used in the CNN architectures.	Review	O	0
[line_break_token][line_break_token]The problem the paper is looking at is well motivated, the experiments are nicely designed and it includes comprehensive ablation study.	Review	O	0
[line_break_token]Previous and related work seems to be well referenced.	Review	O	0
[line_break_token]The main idea of introducing the PosENet to predict the gradient map is neat, and allows for interesting experiments (e.g. what layers most strongly encode the positional information).	Review	O	0
[line_break_token][line_break_token]I really enjoyed the paper, the overall quality is high and does not seem to be rushed (no obvious typos or mistakes in the figures/tables).	Review	O	0
[line_break_token]I believe this should be an accept.	Review	O	0
[line_break_token][line_break_token]Q:[line_break_token]I can understand why you removed the pooling layers, but did you try to run some of your experiments with these as well?	Review	O	0
How were the numbers effected?	Review	B-Review	1
e really appreciate your review and  we‚Äôre glad to hear you are pleased with the paper!	Reply	O	0
[line_break_token][line_break_token]Please let us further clarify the implementation details.	Reply	B-Reply	1
We did not remove any pooling layers except the last average pooling layer in the ResNet, which was designed to compress the output in order to feed to a Fully Connected (FC) layer.	Reply	I-Reply	1
The pooling layers within each network (convolutional part, sometimes called backbone) have been retained because the weight was trained based on that structure design.	Reply	I-Reply	1
It is commonplace to replace the FC layers with conv layers as in most dense labeling tasks.	Reply	I-Reply	1

TLDR: split node embeddings into medatadata and graph structure, force them to be orthogonal.	Review	O	0
[line_break_token][line_break_token]The paper proposes to split node embeddings in a graph into two parts:[line_break_token]1.	Review	O	0
graph structure embeddings: Es[line_break_token]2.	Review	O	0
known node metadata embeddings: Em[line_break_token]To prevent Es from containing information about Em, the authors propose a scheme which puts Es into the Nullspace of Em through repeated SVD factorizations.	Review	O	0
This prevents linear classifiers that operate on Es to reliably predict information in Em.	Review	O	0
[line_break_token][line_break_token]The weakness of the paper stems from the proposed definition of debiasing.	Review	B-Review	1
Just like two random variables can be dependent, but have a linear correlation coefficient of 0, in the proposed method the two embeddings may be linearly unrelated, but have a strong non-linear relationship.	Review	I-Review	1
[line_break_token][line_break_token]This is an important caveat that should be highlighted in the papers' abstract, not burried deep on p4, under Theorem 2.	Review	I-Review	1
[line_break_token][line_break_token]In fact, looking at Fig 3c information about party affiliation follows a XOR-like pattern in the PCA space.	Review	I-Review	3
This means that a linear classifier will fail (indeed the linear SVM in Table 1 fails), but a non-linear one should work OK.	Review	I-Review	3
Thus, contrary to the abstract, the proposed method doesn't remove the effect of arbitrary covariates, but removes a LINEAR dependence.	Review	I-Review	3
[line_break_token][line_break_token]Thus the paper proposes to solve an important problem and proposes a partial solution, but overstates the results in the abstract and hides the true efficiency of the method.	Review	I-Review	3
[line_break_token][line_break_token]Action items ot correct the paper:[line_break_token]- be more honest about the true result.	Review	I-Review	4
Decorrelation does not imply independence.	Review	I-Review	4
[line_break_token]- redo Table 1 with strong non-linear classifiers such a Gaussian SVM or Random Forest to show how much is not filtered out by your linear decorrelation method[line_break_token][line_break_token]Finally, contrast with the adversarial information removal [1] and  the information bottleneck [2], both of which also promise to remove non-linear dependencies.	Review	O	0
It may happen that the you method works better, even though it only guarantees no linear dependencies.	Review	B-Review	2
[line_break_token][line_break_token][1] <a href="https://arxiv.org/abs/1505.07818" target="_blank" rel="nofollow">https://arxiv.org/abs/1505.07818</a>[line_break_token][2] D. Moyer, S. Gao, R. Brekelmans, A. Galstyan, and G. Ver Steeg, ‚ÄúInvariant Representations without Adversarial Training,‚Äù in Advances in Neural Information Processing Systems 31, 2018[line_break_token][line_break_token]	Review	O	0
ortunately, we were able to implement an attribute adversary into our GloVe model using the framework in [1]. All references to adversarial learning work you gave (and others mentioned by other reviewers) are extremely relevant, and aim to solve closely related problems.	Reply	B-Reply	2
We discuss them in our related work section.	Reply	I-Reply	2
However, none of the associated models apply directly to our problem, unless one makes significant modifications (verging on novel work).	Reply	I-Reply	2
Therefore we decided to directly adapt a fundamental adversarial learner (from [1]) to our GloVe trainer.	Reply	I-Reply	2
To our knowledge, this is actually a novel (though naive and preliminary) incorporation of adversarial learning in unsupervised GNNs.	Reply	I-Reply	2
While by no means a mature and complete approach to the problem, we believe it helps shed light on how a comparable adversarial approach would work as an alternative to MONET.	Reply	I-Reply	2
The option to use the adversarial loss will be available in the code we are open sourcing as a reference implementation of the ideas discussed in the paper.	Reply	I-Reply	2
[line_break_token][line_break_token]Since our last update we have added a paragraph about the connection to adversarial networks in our Methods section (S 3.4).	Reply	I-Reply	2
We now describe our adversarial baseline in the beginning of the experiments section and more fully in the Appendix.	Reply	I-Reply	2
Note that the shilling experiment involves real-valued attributes, which requires a different type of adversarial network than that needed for the political blogs experiment.	Reply	I-Reply	2
We consider the development of multiple adversaries in our unsupervised setting beyond the scope of this paper, so we use the adversary baseline only for the first experiment.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token][1] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio.	Reply	O	0
Generative adversarial nets.	Reply	O	0
In Advances in neural information processing systems, pages 2672‚Äì2680, 2014	Reply	O	0

In this work, the authors propose to transfer knowledge from a teacher model to a smaller student model with two variations:[line_break_token]1) knowledge is transferred by matching the feature vector before the softmax [line_break_token]2) the teacher is trained with an additional regularization term to make the feature vectors more dense within the same class.	Review	O	0
[line_break_token][line_break_token]This is a solid piece work that should be accepted.	Review	O	0
One question:[line_break_token]- Does the TF-baseline refer to student model trained with traditional cross-entropy knowledge transfer?	Review	O	0
or the feature vector transfer?	Review	B-Review	1
If the latter, can you please have additional baseline numbers for student models trained with (standard) cross-entropy loss transfer?	Review	I-Review	1
[line_break_token][line_break_token]Minor comments:[line_break_token]- Citations: Should really cite Bucila et al.	Review	O	0
2006 for knowledge distillation and LeCun et al.	Review	B-Review	2
1990 (Optimal Brain Damange) for model compression, as these predate some of the more recent work (Hinton 2015, Han 2016, Jaderberg 2014, etc.)	Review	I-Review	2
[line_break_token][line_break_token]- "Mimic learning": probably best just to stick to "knowledge distillation"	Review	O	0
Thank you for your comment.	Reply	O	0
[line_break_token][line_break_token]Regarding your question, TF-baseline refers to student model trained with feature vector transfer.	Reply	B-Reply	1
We couldn't get the error rate go down below 9% by training a student model with traditional cross-entropy transfer (stated in your comment).	Reply	I-Reply	1
This is expected as previous works (Srivastava et al. (	Reply	I-Reply	1
2015) and Chen et al. (	Reply	I-Reply	1
2016)) indicated that the cross-entropy transfer strategy did not outperform baseline networks trained from scratch where baseline networks are sufficiently deep neural networks with strong regularizers such as batch-norm.	Reply	I-Reply	1
[line_break_token][line_break_token]We'll add suggested citations as well	Reply	I-Reply	2

This paper has studied the efficiency and stability of computing the Wasserstein metric through its dual formulation under weight clipping, gradient penalty, c-transform and (c- œµ)-transform.	Review	O	0
The results show that (c- œµ)-transform and c-transform give more estimation of the Wasserstein distances than the gradient penalty and weight clipping methods in the given experiments, but the gradient penalty method produces more compelling samples in the generative setting.	Review	O	0
[line_break_token][line_break_token]The paper is well written and the experiment section is extensive.	Review	O	0
However, it is more like an extended experiment report to me which is very valuable but lacks sufficient technical novelty expected at ICLR.	Review	B-Review	1
[line_break_token][line_break_token]Another comment is that when the authors mentioned "... are compared to ground truth values d_ground computed by POT", there needs more explanations on what that library actually does to compute the Wasserstein distance to make the paper self-contained, e.g. what exact algorithms it uses as there are also dozens of different algorithms implemented in that library.	Review	I-Review	2
[line_break_token][line_break_token]In Section 3.1, the authors state that "it tends to converge within couple of iterations of the symmetric Sinkhorn-Knopp algorithm.	Review	I-Review	3
For efficiency, we approximate these terms with one Sinkhorn-Knopp iteration".	Review	I-Review	3
What is the extent of sacrifice in accuracy due to this approximation?	Review	I-Review	3
The authors should provide more evidences to justify the approximation.	Review	I-Review	3
hank you for pointing out where we could improve.	Reply	O	0
Below, we will address those comments, for which the explanations will also be added to the paper.	Reply	O	0
Furthermore, we give arguments to why we view the contribution as a fit for ICLR.	Reply	O	0
[line_break_token][line_break_token]We utilize POT‚Äôs ot.emd method to compute the ordinary optimal transport quantity, which is implemented using the method in [1]. We apologize for not explaining which method is used in the entropic case, where the ot.sinkhorn method is utilized with the ‚Äòsinkhorn‚Äô option.	Reply	B-Reply	2
[line_break_token][line_break_token]The sacrifice due to only applying one Sinkhorn-Knopp iteration for the unbiasing terms is slight, as can be seen from the resulting errors with respect to the ground truth in the experiments.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]We view the main contributions of this paper to be the study of the approximation and estimation (stability) of the WGAN methods, which unfortunately has not been considered to its rightful extend in the literature yet.	Reply	I-Reply	1
On the technical side, we are the first to consider the smooth c-transform in the WGAN setting, although it relates closely to [2], where the primal formulation of entropic optimal transport is considered.	Reply	I-Reply	1
We are happy to hear that you consider the experimentation extensive.	Reply	I-Reply	1
On top of new methodological contributions, it is important to also consider comparative studies to guide the development of new methodologies.	Reply	I-Reply	1
For example, it is important to consider which functional classes the discriminator should belong to, which reflects on the representation part of ICLR.	Reply	I-Reply	1
From our experiments, it seems that, when evaluating optimal transport quantities in the general setting (independent of generation), the-transform provides a meaningful class.	Reply	I-Reply	1
In the generative setting the task gets more complicated due to the minimax nature of the game.	Reply	I-Reply	1
[line_break_token][line_break_token][1] Bonneel, N., Van De Panne, M., Paris, S., &amp; Heidrich, W. (2011, December).	Reply	O	0
Displacement interpolation using Lagrangian mass transport.	Reply	O	0
In&nbsp;ACM Transactions on Graphics (TOG)&nbsp;(Vol.	Reply	O	0
30, No.	Reply	O	0
6, p. 158).	Reply	O	0
ACM.	Reply	O	0
[line_break_token][line_break_token][2] Genevay, A., Peyre, G. &amp; Cuturi, M.. (2018).	Reply	O	0
Learning Generative Models with Sinkhorn Divergences.	Reply	O	0
Proceedings of the Twenty-F	Reply	O	0

This paper introduced a linear interpolation method that could be applied to the latent space of a generative model.	Review	O	0
 With their method, interpolating instances generated by those generative models all maintain high quality in terms of the realism index they proposed.	Review	O	0
[line_break_token][line_break_token]This paper first introduced the quantity realism index, which is a measure of how well a generated instance in the latent space is fitted to the ground truth manifold of the data space.	Review	O	0
The definition of realism index is the probability measure of the sublevel set of some f (f:latent -&gt; R+) function threshold by the f(z) for some z. f(z) could be the density function of feature in the latent space.	Review	O	0
[line_break_token][line_break_token]There are two types of realism index which has analytic form introduced in this paper.	Review	O	0
The one based on normal density.	Review	O	0
Another is based on Frechet inception distance.	Review	O	0
If the density of latent feature is normal, normal density based index is used and it could be approximated with a analytic form; while if the density is not accessible, then f is the gaussian density of certain transformation of features in the latent space.	Review	O	0
[line_break_token][line_break_token]If an arbitrary f is used, a kernel density estimator is used to estimate the density of log(f).	Review	O	0
After the realism index is introduced, the optimal interpolation  is the one has the highest cumulative realism index along the interpolation curve.	Review	O	0
[line_break_token][line_break_token]To optimize, a linear interpolation is used as initialization.	Review	O	0
All the intermediate results are updated iteratively.	Review	O	0
[line_break_token][line_break_token]Results show better interpolation than linear ones.	Review	B-Review	1
But not many baselines are available.	Review	I-Review	1
[line_break_token][line_break_token]Overall, I think the problem is very interesting and important.	Review	O	0
The results seem reasonable although only beating an obviously flawed baseline.	Review	O	0
[line_break_token][line_break_token]Typo in Equation (3): w-&gt;s?	Review	O	0
[line_break_token][line_break_token]-----------------[line_break_token][line_break_token]After reading rebuttal and other reviews, I agree that quantitative results is crucially missing especially when the proposed method involves proposing an optimization method to find the best geodesic.	Review	O	0
I think the authors should find a reasonable model that can at least show the proposed geodesic is better than a linear interpolation in the accumulated realism score.	Review	B-Review	3
Also some quantitative evaluation of the proposed optimization scheme will be very helpful.	Review	I-Review	3
hank you for reviewing our work!	Reply	O	0
We believe that Equation (3) is correct, although the notation used there was not explained clearly enough.	Reply	B-Reply	2
The letter ‚Äúw‚Äù in this Equation is only used to define the set over which we are integrating.	Reply	I-Reply	2
We are grateful to the reviewer for pointing out this issue, and we will update the paper to address it	Reply	I-Reply	2

This paper proposes applying random convolutions to the observation space to improve the ability of deep RL agents to generalize to unseen environments.	Review	O	0
To encourage the learning of invariant features, the authors further include a loss term to align features of perturbed and unperturbed observations.	Review	O	0
Thorough experiments on multiple generalization benchmarks show that this method outperforms many previously used regularization and data augmentation techniques.	Review	O	0
[line_break_token][line_break_token]Although the proposed method is simple, it represents a useful contribution.	Review	B-Review	5
The need to generalize across low level transformations in the observation space features prominently in several environments, including DeepMind Lab and CoinRun.	Review	O	0
The clear need for agents to be invariant to these low level transformations well motivates the proposed approach, as does the failure of many existing methods to provide this invariance.	Review	O	0
[line_break_token][line_break_token]The authors could more explicitly discuss the main drawbacks of this approach.	Review	B-Review	1
As with any data augmentation, there is an assumption that the applied transformation generally won‚Äôt destroy information pertinent to the task.	Review	I-Review	1
While this is true for the MDPs investigated here, it is easy to imagine slight variants of these MDPs for which this approach would fail.	Review	I-Review	1
If an optimal policy must condition on color or texture information from observations, then using these random convolutions would render training impossible.	Review	I-Review	1
Encountering such MDPs is not farfetched, so this weakness seems worth acknowledging.	Review	I-Review	1
[line_break_token][line_break_token]In Figure 5 it would be useful to visualize performance of an agent trained directly on these unseen environments, as this presumably serves as an upper bound for the zero-shot performance of ‚ÄúPPO + ours‚Äù.	Review	I-Review	2
How close does ‚ÄúPPO + ours‚Äù come to closing this gap?	Review	I-Review	2
Without any context on the reward scale, it‚Äôs hard to infer how well this method is generalizing, beyond seeing that it beats some (possibly weak) baselines.	Review	I-Review	2
Admittedly some closely related curves can be found in Appendix Figures 9 and 14, though they‚Äôre a bit out of the way.	Review	I-Review	2
[line_break_token][line_break_token]Section 3.1 mentions that using alpha = 0 complicates training.	Review	I-Review	3
It is somewhat surprising that using alpha &gt; 0 is necessary or significant and yet the value used (alpha = .1) is relatively small.	Review	O	0
Any further comments on this choice?	Review	B-Review	3
[line_break_token][line_break_token]I appreciate the discussion in Appendix F. It‚Äôs natural to wonder about alternative injection sites for the random network, and it‚Äôs good to see how the proposed method compares to these alternatives.	Review	I-Review	4
[line_break_token]	Review	O	0
e appreciate your valuable comments, efforts and times on our paper.	Reply	O	0
As you and R3 mentioned, we introduce a simple, yet powerful solution for generalization in deep RL, and show that it achieves significant performance gains in comparison to many known regularization and data augmentation techniques in various environments.	Reply	B-Reply	5
Our responses to all your questions are provided below.	Reply	O	0
Revised parts in the new draft are colored by red (in particular, we updated Section 3, 4 and 5, Appendix A, L, M, and N, and Figure 5, 7, 16, and 17).	Reply	O	0
[line_break_token][line_break_token]Q1.	Reply	O	0
Handling potential failure case of our methods[line_break_token][line_break_token]A1.	Reply	O	0
Thank you for the suggestion to acknowledge the failure cases of our method.	Reply	B-Reply	1
As you pointed out, some color (or texture)-conditioned RL tasks can be difficult for our methods to work.	Reply	I-Reply	1
For example, consider an extreme seek-avoid object gathering setup, where the agent must learn to collect good objects and avoid bad objects which have the same shape but different colors.	Reply	I-Reply	1
However, we remark that our method would not always fail for such tasks if other environmental factors (e.g., the shape of objects in Collect Good Objects in DeepMind Lab [1]) are available to distinguish them.	Reply	I-Reply	1
As shown in Appendix M of the revised draft, our method can perform well on the modified CoinRun environment with good and bad coins by capturing the other factors such as the location of coins to perform this task.	Reply	I-Reply	1
As another example, consider color-matching tasks such as the keys doors puzzle in DeepMind Lab [1] where the agent must collect colored keys to open matching doors.	Reply	I-Reply	1
Even though this task is color-conditioned, a policy trained with our method can perform well because the same colored objects will have the same color value even after randomization, i.e., our randomization method still maintains the structure of input observation.	Reply	I-Reply	1
Finally, we remark that our method can handle such corner cases by adjusting the fraction of clean samples during training  on page 4, in the paragraph "Details of the random networks.").	Reply	I-Reply	1
In summary, we believe that the proposed method covers a broad scope of generalization across low-level transformations in the observation space features as you mentioned.	Reply	I-Reply	1
We added related discussions in Section 5 and Appendix M of the revised draft.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2. ‚	Reply	O	0
ÄúOptimal‚Äù performance (i.e. upper bound) [line_break_token][line_break_token]A2.	Reply	O	0
Following your suggestion, we included the performance of an agent trained directly on unseen environments to Figure 5 and 7of the revised draft.	Reply	B-Reply	2
In summary, our method approaches this hypothetical upper bound performance.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3.	Reply	O	0
The choice of[line_break_token][line_break_token]A3.	Reply	O	0
We would like to clarify that the chosen fraction of clean samples is set empirically based on controlled experiments.	Reply	B-Reply	3
To support this, we added controlled experimental results by varying the fraction of clean samples in Figure 17(d) of the revised draft.	Reply	I-Reply	3
[line_break_token][line_break_token][1] Charles Beattie et al.	Reply	O	0
Deepmind lab.	Reply	O	0
arXiv preprint arXiv:1612.03801, 2016.	Reply	O	0

Paper summary: This paper proposes a new normalization technique specially designed for settings with small mini-batch sizes (where previous methods like BatchNorm are known to suffer).	Review	O	0
The approach aggregates mean/variance statistics from previous iterations, weighted based on the Taylor expansion, to get a better estimate of population statistics.	Review	O	0
The authors evaluate their approach on ImageNet classification, and object detection and instance segmentation on the COCO dataset.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]The paper is clearly written and explores an interesting idea---aggregating mini-batch statistics across iterations.	Review	O	0
That being said, I am not convinced by the utility of the proposed approach since it doesn‚Äôt offer over significant benefits over prior approaches designed for the small mini-batch setting (e.g., Group Normalization)---either in terms of empirical performance, implementation complexity, or lower computational/memory requirements.	Review	O	0
[line_break_token][line_break_token]Specific comments/questions:[line_break_token][line_break_token]1.	Review	O	0
Why do the authors not include the Kalman Normalization baseline in the paper?	Review	B-Review	1
Based on my understanding, it is also designed for the low-sample regime (and the original paper also conducts experiments on ImageNet/COCO).	Review	I-Review	1
Also the BRN baseline is included in Table 3 for ImageNet but is missing from the COCO experiments.	Review	I-Review	1
It is important to thoroughly compare to other normalization techniques specifically designed for this regime to clearly highlight relative benefits of the proposed approach.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The authors mention that they average performance across 5 trials but omit confidence intervals in their Figures/Tables.	Review	B-Review	2
Since the difference in performance between the different approaches compared is small, I think confidence intervals should be reported to see whether improvements are within statistical error margins.	Review	I-Review	2
In fact, for CIFAR-10 based on Table 7 in the Appendix, performance of batch renormalization, group normalization and CBN is essentially the same.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
In Table 3, how many iterations was the BRN aggregation performed over?	Review	B-Review	3
Was it also chosen to ensure effective number of samples was not less than 16 (like CBN).	Review	I-Review	3
What do Figures 3 and 4 look like for BRN?	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
One thing I find interesting (the authors do not discuss this specifically) about Figure 5 in the Appendix is that both for CIFAR and COCO (the two datasets for which plots are provided), CBN helps as long as it is used before the final learning rate drop.	Review	B-Review	4
Specifically, choosing a burn-in period as large as 120 for CIFAR and 8 for COCO is fine (in fact, probably the best) as long as you turn on CBN before the final learning rate drop.	Review	I-Review	4
This makes me curious whether BN in the low-sample regime only suffers in terms of generalization performance in the final stages of training (compared to low-sample alternatives like GN/CBN, etc).	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]The authors should include other recent benchmarks (Kalman normalization and BRN in the omitted Tables) and error bars to make the change in performance clearer.	Review	I-Review	5
It would also be interesting to see whether (and probably make the paper stronger if) alternatives like GN/KN benefit from being combined with the proposed scheme to aggregate statistics over time.	Review	I-Review	5
[line_break_token][line_break_token]Overall, while the proposed approach is novel, its performance is comparable to prior approaches, with the disadvantage of an additional computational/memory footprint.	Review	I-Review	6
Thus, I am not yet convinced about how useful/interesting this approach would be to the community.	Review	I-Review	6
[line_break_token]	Review	O	0
e thank the reviewer for the careful reviews and constructive suggestions.	Reply	O	0
We feel we can well address the concerns of R#1, and hope R#1 give a second thought about the paper.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We present our experimental results with BRN as follows:[line_break_token]|         Method         | ImageNet-Top1(%) | COCO-mAP_bbox |[line_break_token]|-------------------------|---------------------------|-------------------------|[line_break_token]| BN-bs16/syncBN |               70.2             |             37.7             |[line_break_token]| BN-bs1                  |               65.1             |             36.3             |[line_break_token]| BRN                       |               67.9             |             37.5             |[line_break_token]| GN                         |               69.0             |             37.8             |[line_break_token]| CBN                       |               69.8             |             37.7             |[line_break_token]For KN, we tried our best to re-implement it and also asked the author for help, but failed to reproduce the result without a response from the author.	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
As mentioned in the paper, the variance between different trials is negligible for both ImageNet and COCO.	Reply	B-Reply	2
For CIFAR-10, we show the error bar in Table 7 of the Appendix.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
For BRN, the statistics are updated in a "moving" policy.	Reply	B-Reply	3
So there is no parameter similar to ‚Äúaggregation iteration‚Äù.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
Many thanks to the reviewer for sharing this interesting perspective.	Reply	B-Reply	4
To perform this further exploration, we design a new ablation experiment to remove other influences: we first train the model on COCO with standard BN and a small batch size, then switch BN to syncBN (the learning rate will be divided by 10 at epoch-9 and epoch-11).	Reply	I-Reply	4
We present the experimental results as follows:[line_break_token]| Resume Epoch | Epoch-8  | Epoch-9  | Epoch-10 | Epoch-11 |[line_break_token]|----------------------|-------------|-------------|---------------|--------------|[line_break_token]| mAP_bbox         |     37.7    |     37.7     |      37.6      |      37.3     |[line_break_token][line_break_token]Interestingly, as mentioned by the reviewer, BN in the low-sample regime only hurts the generalization performance in the final stage after the learning rate drops.	Reply	I-Reply	4
We leave this as a direction for future study.	Reply	I-Reply	4
[line_break_token][line_break_token]The major concern on ‚Äúhow useful/interesting this approach would be to the community‚Äù is addressed in the comment to all reviewers, please check it.	Reply	I-Reply	6
Thanks!	Reply	I-Reply	6
[line_break_token][line_break_token]We hope that your concerns are addressed.	Reply	O	0

Cons[line_break_token][line_break_token]1.	Review	O	0
[tab_token]There is no study of the representations developed by the model, which is unfortunate because this is a conference on learning representations and because there is little light shed on how the network achieves its rather high level of performance.	Review	O	0
[line_break_token]2.	Review	O	0
[tab_token]It seems less generally useful to have such a special-purpose network for computing global properties like tautologicality than to have a network that produces actual vector encodings of propositions, as typical of the bottom-up tree-structured models.	Review	O	0
[line_break_token][line_break_token]Pros[line_break_token][line_break_token]3.	Review	O	0
[tab_token]The paper is quite clear.	Review	O	0
[line_break_token]4.	Review	O	0
[tab_token]The problem is important.	Review	O	0
[line_break_token]5.	Review	O	0
[tab_token]The paper pursues the familiar path of a tree-structured network isomorphic to the parse tree of a propositional-calculus formula, but with the original twist of passing information top-down rather than bottom-up.	Review	O	0
[line_break_token]6.	Review	O	0
[tab_token]The results are impressively strong.	Review	O	0
In particular, it improves by 10% absolute over the special-purpose and highly performant PossibleWorldNet on the most difficult category of problems, the ‚Äòmassive‚Äô category, achieving 83.6% accuracy.	Review	O	0
[line_break_token][line_break_token]Pro/Con mix[line_break_token][line_break_token]7.	Review	O	0
[tab_token]Although the paper did not provide much insight into what was going on in the network to allow it to perform well (point 1 in ‚ÄòCons‚Äô), I was able to convince myself I could understand a way the architecture *could* succeed (whether this possible approach matches the actual processing in the model I have no way of assessing).	Review	O	0
In brief, the vector that is passed down the network can be thought of as a list of truth values across multiple possible worlds of the tree node at which the vector resides.	Review	B-Review	3
To search for a counterexample to tautologicalhood, the original input vector to the root node could be the zero (false) vector.	Review	I-Review	3
If the kth value in the vector at a parent node labeled ‚Äòor‚Äô is 0 (the disjunction is false in world k) then in the two children the kth value must also be 0.	Review	I-Review	3
If the kth value of the vector at an XOR node is 0, the kth value of the two children must both be 0 or both be 1; actually these values need not reside in position k so the children could both have value 0 at some position i and both have value 1 at another position j. Then in the RNN-Var component of the network, which checks for consistency across multiple tokens of the same proposition variable, each position k in all vectors for the same variable can be checked for equality, producing a value 1 in the output vector if all have value 1, producing 0 if all have value 0, and producing value -1 if the values do not all agree.	Review	I-Review	3
Then RNN-All checks across all vectors for proposition variable types to see if there‚Äôs a position k in which no value -1 occurs; if so, the values of the variable vectors at position k give the truth values for all variables such that the overall proposition has the desired value 0: a counterexample exists.	Review	I-Review	3
If no such position k exists, the proposition is a tautology.	Review	I-Review	3
This seems roughly right, at least.	Review	I-Review	3
Thank you for your comments.	Reply	O	0
A new Section 3.1 was added to a revised version of the paper, where the inner working of the model is briefly discussed.	Reply	B-Reply	4
Although it is definitely far from being conclusive, it, hopefully, sheds some light on the model.	Reply	I-Reply	4
[line_break_token][line_break_token]Your description (point 7) of how the model can possible work corresponds to the idea behind the model as described in Section 2 and discussed in new Section 3.1.	Reply	I-Reply	3
An interesting point in your text is that values may change their positions in lists of truth values.	Reply	I-Reply	3
In fact, something like that can actually happen, but so far, it is really unclear how to do this, because such changes have to be (almost) consistent through the whole model.	Reply	I-Reply	3
Moreover, to make things even more complicated, different atoms occur at different levels (their depth) in a formula.	Reply	I-Reply	3
[line_break_token][line_break_token]You are right (point 2) that the model, in its current form, cannot produce suitable vector encodings of propositions.	Reply	I-Reply	2
For example, the model is invariant to the renaming of atoms.	Reply	I-Reply	2
However, for formulae where this is no longer an issue, e.g., sentences in FOL, it is possible to imagine such interpretations even using a top-down approach	Reply	I-Reply	2

Summary:[line_break_token]The paper describes a noisy channel approach for document-level translation, which does not rely on parallel documents to train.	Review	O	0
The approach relies on a sentence-level translation model (from target-to-source languages) and a document level language model (on target language), each is trained separately.	Review	O	0
For decoding, the paper relies on another proposal model (i.e., a sentence level translation model from source to target) and performs beam-search weighted by a linear combination of the scores of all three models.	Review	O	0
Experiments show strong results on two standard translation benchmarks.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token]-  The proposed approach is strongly based on the neural noisy channel model of Yu et al.	Review	O	0
2017 but mainly extends it to context aware translation.	Review	B-Review	1
While the paper is referenced, I believe more emphasis should be put on the differences of the proposed approach[line_break_token]-  It seems that the Document Transformer uses parallel-documents to train, so I am wondering if you can still claim that your approach does not require parallel documents.	Review	O	0
[line_break_token]-  In general, I think the paper is well written and results are compelling.	Review	O	0
[line_break_token]	Review	O	0
hank you for your review.	Reply	O	0
[line_break_token][line_break_token]Regarding the differences to Yu et al.,	Reply	B-Reply	1
2017.	Reply	I-Reply	1
While both papers indeed use a noisy channel decomposition, the novelty in this paper is the theoretical justification for training a model using only parallel sentences and monolingual documents, and then using it to infer document translations (an important task!).	Reply	I-Reply	1
This asymmetry in available data is exactly the situation that exists in the world today, and our model, which addresses it directly and elegantly, will undoubtedly be of general interest.	Reply	I-Reply	1
Moreover, while the Yu et al.,	Reply	I-Reply	1
2017 model could be used on documents by concatenating their sentences to form a single long sequence, this would not let us use the conditional sentence independence assumptions that gives our model the flexibility to use just parallel sentences.	Reply	I-Reply	1
Secondarily, the Yu et al.	Reply	I-Reply	1
inference algorithm is specialized to their channel model, and it has a quadratic (in the length of the sentence) complexity, which would be prohibitive for sequences longer than a single sentence; in practice our inference technique is much faster.	Reply	I-Reply	1
We will clarify these differences in the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding whether our approach really needs parallel documents.	Reply	I-Reply	2
First, there are two models in this paper- the joint translation model and proposal model we use to do inference.	Reply	I-Reply	2
The joint translation model is only ever trained using parallel sentences.	Reply	I-Reply	2
For inference, we use a proposal model that approximates the posterior, and we compare two variants: one that is trained using just parallel sentences (effectively, we assume independence between translations given the source document) and one that is trained with document context (see Table 2).	Reply	I-Reply	2
As predicted, a proposal model that more closely matches the true posterior (i.e., the one with document context) is more effective than one that is less accurate (no document context), but the crucial result is that in both cases, document information has a positive impact on the performance of the system.	Reply	I-Reply	2
The secondary result is that search is a hard problem, and while usable approximations exist, this is an important open question.	Reply	I-Reply	2
We will clarify this	Reply	I-Reply	2

I have read the author response, thank you for responding.	Review	O	0
[line_break_token][line_break_token]Original review:[line_break_token]This paper presents the extraction of a bibliographic database of Chinese technical papers.	Review	O	0
 This database could potentially be a valuable resource for the community.	Review	O	0
 However, the paper is mis-targeted to the ICLR conference, as it does not discuss learning representations or using deep learning (the 36-page appendix does include some material on knowledge graph embedding, but this is not covered in the main body of the paper).	Review	O	0
 Also, for important tasks like name deduplication, the paper does not discuss or compare against techniques from previous work, and instead proposes a small set of heuristics, which is a sensible approach for building a resource but will not be of interest to the ICLR audience.	Review	O	0
[line_break_token][line_break_token]The paper refers to their resource as a knowledge graph, but I would say it is more accurate to call it a bibliographic database (it consists primarily of paper titles, authors, and keywords).	Review	B-Review	3
 This is very different from the broader KBs and KGs discussed in the related work.	Review	I-Review	3
 YAGO, Freebase, Cyc, and so on capture a much wider variety of semantic relationships and entity types.	Review	I-Review	3
 I think re-positioning this submission as being aimed at building a bibliographic database, rather than a Knowledge Graph, would help ensure it reaches the right audience.	Review	I-Review	3
 Also, targeting a different venue like a digital libraries conference and making a strong case that this set of bibliographic data offers advantages in coverage or accuracy over other comparable resources, if any, would help.	Review	I-Review	3
[line_break_token][line_break_token]Finally, one of the most valuable features of a bibliographic database is the citation graph, it would be exciting if TechKG could be extended to include citation information.	Review	I-Review	4
[line_break_token][line_break_token]Minor:[line_break_token]Section 2, most of these citations should not be shortcites but should be regular full cites.	Review	I-Review	5
 For example in the first paragraph, Miller (1995) should be (Miller, 1995).	Review	O	0
[line_break_token]	Review	O	0
e would like to thank the reviewer for the thorough and valuable feedback for the manuscript.	Reply	O	0
But we want to clarify some misunderstandings of our paper.	Reply	O	0
[line_break_token][line_break_token]1.We claim in our paper that TechKG is a new Chinese KG and it can be used as a dataset for many diverse AI-related applications.	Reply	O	0
In our primpary experiments in the appendix part, we use three completely different applications to show  the adaptability of TechKG.	Reply	B-Reply	1
All of these applications are related to deep learning.	Reply	I-Reply	1
Especially, the "knowledge graph embedding" application is directly related to representation learning.	Reply	I-Reply	1
So we think that our paper matches the scope of ICLR well.	Reply	I-Reply	1
[line_break_token][line_break_token]2. "	Reply	O	0
name deduplication" is not an important task in TechKG, instead, it is just one of the important characteristics in TechKG (section 4, page 5).	Reply	B-Reply	2
Totally, there are three important characteristics that make TechKG be a more challenging dataset for many applications.	Reply	I-Reply	2
For example, in the "knowledge graph embedding" application, the ConvE model, one of the state-of-the-art method, achieves very poor results.	Reply	I-Reply	2
We analyzed the reason in page14.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
The comment that "This is very different from the broader KBs and KGs discussed in the related work. "	Reply	B-Reply	3
is right.	Reply	I-Reply	3
In Table 8 (page 8) of our paper, we compare the differences between different KGs.	Reply	I-Reply	3
TechKG is a very different KG compared with current existing KGs mainly due to the following two reason.	Reply	I-Reply	3
First, TechKG is technology-oriented KG, while other KGs are general purpose.	Reply	I-Reply	3
Second, TechKG takes technical papers as data source, while most of other KGs take Wikipedia as datasource.	Reply	I-Reply	3
Because of these two reasons, both the semantic relationships and the entity types are proper in TechKG.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	I-Reply	2
TechKG is a completely different KGs and it provides a new choice for lots of applications: the AI-related applications are diverse, thus there should be diverse datasets.	Reply	I-Reply	4
Besides, a lot of new characteristics hierent in TechKG raise new challenges for many existing methods. (	Reply	I-Reply	4
page 10, "conclusion" section	Reply	I-Reply	4

This paper provides new generalization bounds for deep neural networks using the PAC-Bayesian framework.	Review	O	0
Recent efforts along these lines have proved bounds that [line_break_token]either apply to a classifier drawn from a distribution or to a compressed form of the trained classifier.	Review	O	0
In contrast, the paper uses PAC Bayesian bounds to [line_break_token]provide generalization bounds for the original trained network.	Review	O	0
At this same time, the goal is to provide bounds that do not scale exponentially in the depth of the[line_break_token]network and depend on more nuanced parameters such as the noise-stability of the network.	Review	B-Review	1
In order to do that the paper formalizes properties that a classifier must [line_break_token]satisfy on the training data.	Review	I-Review	1
While these are a little difficult to understand in general, in the context of ReLU networks these boil down to bounding the l2-norms[line_break_token]of the Jacobian and the hidden layer outputs on each data point.	Review	I-Review	1
Additionally, the paper also requires the pre-activations to be sufficiently large, which as the authors [line_break_token]acknowledge, is an unrealistic assumption that is not true in practice.	Review	I-Review	2
Despite that, the paper makes an important contribution towards our current understanding of [line_break_token]generalization of deep nets.	Review	I-Review	2
It would have been helpful if the authors had a more detailed discussion on how their assumptions relate to the specific assumptions in the papers[line_break_token]of Arora et al.	Review	I-Review	3
and Neyshabur et al.	Review	I-Review	3
This would help when comparing the results of the paper with existing ones.	Review	I-Review	3
Dear Reviewer,[line_break_token][line_break_token]Thanks for your positive feedback!	Reply	O	0
[line_break_token][line_break_token]We have uploaded a revised version with Appendix G where we have added a one-page discussion relating our noise-resilience conditions and the conditions in prior work.	Reply	B-Reply	1
We hope this provides you better context to understand our assumptions.	Reply	O	0
Happy to provide more details if needed.	Reply	O	0
[line_break_token]	Reply	O	0

- Does the paper present substantively new ideas or explore an under explored or highly novel[line_break_token]question?	Review	O	0
[line_break_token][line_break_token]Yes, the paper combines two frameworks (Imitation Learning and Model Base[line_break_token]Reinforcement Learning) to incorporate target information while fitting to	Review	O	0
Thank you for your helpful feedback.	Reply	O	0
[line_break_token][line_break_token]Q1: ‚ÄúThe authors do not address the problem of IL when the stochasticity in the environment and/or model results in trajectories outside of expert‚Äôs distribution.	Reply	O	0
‚Äù[line_break_token]A1: In our original submission, we evaluated our model‚Äôs ability to control the agent in a held out test scene (Town02).	Reply	O	0
This demonstrated our model‚Äôs ability to generalize its behavior beyond the behaviors observed in the data.	Reply	O	0
As further evidence of generalization, we performed additional experiments designed to force the model to produce trajectories outside of the distribution of observed trajectories.	Reply	O	0
In one, we added simulated potholes to the scene, which we modelled with a cost map.	Reply	O	0
This forced our planning to produce trajectories that avoid the potholes.	Reply	O	0
We found that the model could still complete most of its episodes, while avoiding most potholes, despite the fact that the agent was forced into situations not seen in the training data.	Reply	O	0
Please see the revised paper for these results.	Reply	O	0
[line_break_token][line_break_token]Q2: ‚Äúthe experiments only compare the proposed algorithm to its components, namely proportional controller, IL only controller and Model Basel RL only controller.	Reply	O	0
‚Äù [line_break_token]A2: We agree that relevant comparison is important.	Reply	O	0
Our current IL comparison is not an ablation of our method, but rather a comparison to prior offline IL work.	Reply	O	0
It most closely resembles the method of Codevilla, et al. "	Reply	O	0
End-to-end driving via conditional imitation learning."	Reply	O	0
ICRA, 2018.	Reply	O	0
However, this prior method uses categorical command prediction, "turn left/turn right/go straight", for a learned lower-level controller, whereas our variant of this method regresses setpoints provided to a PID controller.	Reply	O	0
We did not make the connection clear in the original paper, which we will fix.	Reply	O	0
[line_break_token]We also conducted additional experiments against the state-of-the-art with the ‚Äúbranched‚Äù network of Codevilla, et al.	Reply	O	0
2018, which we include in our revised comparison.	Reply	O	0
We found this approach to slightly outperform the original IL baseline we included in our paper, but still underperform the MBRL method and our proposed method.	Reply	O	0
Please see the updated paper for our quantitative comparison.	Reply	O	0
[line_break_token][line_break_token]Q3: ‚Äúthe paper does not provide any detail on the training procedure (Network architecture, cost function, etc), which makes results hard to reproduce‚Äù[line_break_token]A3: In our updated version, we have simplified our explanation and expanded on additional details, including network architecture, cost function, etc.	Reply	O	0
Please see Section 2.2 in the updated paper	Reply	O	0

The paper proposes to learn a custom translation or rotation invariant kernel in the Fourier representation to maximize the margin of SVM.	Review	O	0
Instead of using Monte Carlo approximation as in the traditional random features literature, the main point of the paper is to learn these Fourier features in a min-max sense.	Review	O	0
This perspective leads to some interesting theoretical results and some new interpretation.	Review	O	0
Synthetic and some simple real-world experiments demonstrate the effectiveness of the algorithm compared to random features given the fix number of bases.	Review	O	0
[line_break_token][line_break_token]I like the idea of trying to formulate the feature learning problem as a two-player min-max game and its connection to boosting.	Review	O	0
As for the related work, it seems the authors have missed some very relevant pieces of work in learning these Fourier features through gradient descent [1, 2]. It would be interesting to compare these algorithms as well.	Review	O	0
[line_break_token][line_break_token][1] Zichao Yang, Marcin Moczulski, Misha Denil, Nando de Freitas, Alex Smola, Le Song, Ziyu Wang.	Review	O	0
Deep Fried Convnets.	Review	O	0
ICCV 2015.	Review	O	0
[line_break_token][2] Zichao Yang, Alexander J. Smola, Le Song, Andrew Gordon Wilson.	Review	O	0
A la Carte ‚Äî Learning Fast Kernels.	Review	O	0
AISTATS 2015.	Review	O	0
Similar to our work, paper [2] also considers learning the Fourier spectrum of a shift-invariant kernel, where the spectrum is parameterized as a mixture of (a fixed number of) Gaussians or a piecewise linear function, which can definitely fit in our min-max formulation.	Reply	B-Reply	2
However, in comparison, our end-to-end method is more general since it doesn‚Äôt rely on any specific parameterization.	Reply	I-Reply	2
Paper [1] is also interesting and relevant since it draws connections between spectrally learned kernel machines and deep neural networks.	Reply	I-Reply	2
As we mention in the conclusion, it is an exciting future direction to build our method into a deep neural network.	Reply	I-Reply	2
We thank the reviewer for pointing out these references, and we‚Äôll add them to the related work section.	Reply	I-Reply	1

This paper presents a novel application of machine learning using Graph NN's on ASTs to identify incorrect variable usage and predict variable names in context.	Review	O	0
It is evaluated on a corpus of 29M SLOC, which is a substantial strength of the paper.	Review	O	0
[line_break_token][line_break_token]The paper is to be commended for the following aspects:[line_break_token]1) Detailed description of GGNNs and their comparison to LSTMs[line_break_token]2) The inclusion of ablation studies to strengthen the analysis of the proposed technique[line_break_token]3) Validation on real-world software data[line_break_token]4) The performance of the technique is reasonable enough to actually be used.	Review	O	0
[line_break_token][line_break_token]In reviewing the paper the following questions come to mind:[line_break_token]1) Is the false positive rate too high to be practical?	Review	O	0
 How should this be tuned so developers would want to use the tool?	Review	B-Review	1
[line_break_token]2) How does the approach generalize to other languages? (	Review	O	0
Presumably well, but something to consider for future work.)	Review	B-Review	2
[line_break_token][line_break_token]Despite these questions, though, this paper is a nice addition to deep learning applications on software data and I believe it should be accepted.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
Thank you for reviewing our work so kindly.	Reply	O	0
Please note that the evaluation in our submission only covers 2.9M SLOC (not 29M), even though we have performed additional experiments with similar results on the Roslyn project (~2M SLOC).	Reply	O	0
[line_break_token][line_break_token]Regarding your first question: We have just updated our submission to also include ROC and PR curves for our main model in the appendix, which show that for a false positive rate of 10%, our model achieves a true positive rate of 73% on the SeenTestProj dataset and 69% on UnseenTestProj.	Reply	B-Reply	1
We expect our system to be most useful in a code review setting, where locations in which the model disagrees with the ground truth are highlighted for a reviewer.	Reply	I-Reply	1
The PR curve indicates that setting a high certainty threshold for such highlighting should yield relatively few false positives.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding your second question: We have not tested our model on other languages so far.	Reply	I-Reply	2
However, we expect similar performance on other strongly typed languages such as Java.	Reply	I-Reply	2
An interesting research question will be to explore how the model could be adapted to gradually typed (e.g. TypeScript) or untyped (e.g. JavaScript or Python) languages.	Reply	I-Reply	2

Summary:[line_break_token]This paper tackles the problem of context modelling within recurrent neural networks (RNNs).	Review	O	0
The authors propose an interdependent gating mechanism that enriches the coupling between inputs and hidden states.	Review	O	0
For an input x_0 and hidden state h_0; h_0 gates x_0 to create x_1; x_1 then gates h_0 to create h_1; this cyclical gating operation is applied for several rounds and it's output is fed into a recurrent neural network.	Review	O	0
For the next time-step, this process is repeated, with h_0 as the final h obtained after the final round of gating in the previous time-step.	Review	O	0
This results in the RNN processing a more contextualized version of the input tokens x.[line_break_token][line_break_token]Main Contributions:[line_break_token]1.	Review	O	0
A simple pre-processing step that contextualizes inputs for recurrent neural networks and significantly improves performance.	Review	O	0
[line_break_token]2.	Review	O	0
An extensive evaluation of the proposed technique against previous works and on all relevant datasets.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]The paper is very well-written and clear.	Review	O	0
It motivates and explores the questions and issues surrounding this topic very well.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]It would be good to see how this performance translates to other RNN architectures such as GRUs.	Review	O	0
[line_break_token][line_break_token][line_break_token]Final notes:[line_break_token]This paper raises many interesting question:[line_break_token]- What is the really going on with the gating mechanism?	Review	O	0
[line_break_token]The authors explore this question but the jury is still out on exactly what is going on here.	Review	B-Review	2
[line_break_token]- "Mogrification" as a general preprocessing step: could it also improve performance for transformer models?	Review	O	0
[line_break_token]- Are there better ways to preprocess and gate the RNN inputs?	Review	O	0
[line_break_token][line_break_token]--------[line_break_token][line_break_token]Review Decision:[line_break_token]It is clear, well motivated, well written and represents a concrete contribution to the language modelling literature.	Review	O	0
Furthermore, most claims made are substantiated via thorough experimentation.	Review	O	0
Lastly, this work demonstrates that rather than relying on data and model scaling to improve performance; there is alot left to be done in tackling language modelling on smaller scale datasets.	Review	O	0
e thank Reviewer #3 for their comments.	Reply	O	0
[line_break_token][line_break_token]- "Mogrification" as a general preprocessing step: could it also[line_break_token]  improve performance for transformer models?	Reply	O	0
[line_break_token][line_break_token]Possibly, but it would be quite surprising, as attention might very[line_break_token]well be able to express similar transformations.	Reply	B-Reply	3
[line_break_token][line_break_token]As to whether there better ways to preprocess and gate the RNN inputs,[line_break_token]we are sure that the answer is yes.	Reply	I-Reply	3
More generally, we believe that[line_break_token]our neural models lack the necessary biases perform well in a[line_break_token]data-efficient manner.	Reply	I-Reply	3
Large datasets can alleviate the problem, but[line_break_token]may not be able to solve it.	Reply	I-Reply	3

Summary:[line_break_token][line_break_token]The authors propose a method to make exploration in really sparse reward tasks more efficient.	Review	O	0
They propose a method called Workflow Guided Exploration (WGE) which is learnt from demonstrations but is environment agnostic.	Review	O	0
Episodes are generated by first turning demonstrations to a workflow lattice.	Review	O	0
This lattice encodes actions which are in some sense similar to those in the demonstration.	Review	O	0
By rolling out episodes which are randomly sampled from this set of similar actions for each encountered state, it is claimed that other methods like Behavor Cloning + RL (BC-then-RL) can be outperformed in terms of number of sample complexity since high reward episodes can be sampled with much higher probability.	Review	O	0
[line_break_token][line_break_token]A novel NN architecture (DOMNet) is also presented which can embed structured documents like HTML webpages.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]- The paper is well-written and relevant literature is cited and discussed.	Review	O	0
[line_break_token]- My main concern is that while imitation learning and inverse reinforcement learning are mentioned and discussed in related work section as classes of algorithms for incorporating prior information there is no baseline experiment using either of these methods.	Review	O	0
Note that the work of Ross and Bagnell, 2010, 2011 (cited in the paper) establish theoretically that Behavior Cloning does not work in such situations due to the non-iid data generation process in such sequential decision-making settings (the mistakes grow quadratically in the length of the horizon).	Review	B-Review	2
Their proposed algorithm DAgger fixes this (the mistakes by the policy are linear in the horizon length) by using an iterative procedure where the learnt policy from the previous iteration is executed and expert demonstrations on the visited states are recorded, the new data thus generated is added to the previous data and a new policy retrained.	Review	I-Review	2
Dagger and related methods like Aggrevate provide sample-efficient ways of exploring the environment near where the initial demonstrations were given.	Review	I-Review	2
WGE is aiming to do the same: explore near demonstration states.	Review	I-Review	2
[line_break_token]- The problem with putting in the replay buffer only episodes which yield high reward is that extrapolation will inevitably lead the learnt policy towards parts of the state space where there is actually low reward but since no support is present the policy makes such mistakes.	Review	O	0
[line_break_token]- Therefore would be good to have Dagger or a similar imitation learning algorithm be used as a baseline in the experiments.	Review	O	0
[line_break_token]- Similar concerns with IRL methods not being used as baselines.	Review	O	0
[line_break_token][line_break_token]Update: Review score updated after discussion with authors below.	Review	O	0
[line_break_token]	Review	O	0
We would like to thank the reviewer for the feedback!	Reply	O	0
[line_break_token][line_break_token]The reviewer suggested further comparisons with inverse reinforcement learning (IRL) and DAgger-based methods (e.g., DAgger, AggreVaTe).	Reply	O	0
In our paper revision, we will address the critical differences between our setting and the settings of these methods, which are summarized below:[line_break_token][line_break_token]- In IRL, the system does not receive rewards from the environment and instead extracts a reward function from demonstrations.	Reply	O	0
In our setting, the system already observes the true reward from the environment, so applying IRL would be redundant.	Reply	B-Reply	1
Furthermore, IRL would struggle to learn a good reward function from such a small number of demonstrations (e.g., 3-10), which we have in our setting.	Reply	I-Reply	1
[line_break_token][line_break_token]- DAgger-based methods require access to an expert policy, which is iteratively queried to augment the training data.	Reply	O	0
In our setting, the system gets a small number of demonstrations and can interact with the environment, but does not have access to an expert policy, so these methods cannot be directly applied.	Reply	B-Reply	2
In addition, while DAgger-based methods do indeed provide an alternative way to explore around a neighborhood of the demonstrations, their goal is different from ours: DAgger addresses compounding errors, while our work addresses finding sparse reward.	Reply	I-Reply	2
[line_break_token][line_break_token]Finally, we want to clarify the concern that only high reward episodes are placed in the buffer.	Reply	I-Reply	3
The neural policy updates both off-policy from the buffer and on-policy during roll-outs.	Reply	I-Reply	3
If the neural policy begins to make mistakes, it will be penalized by receiving low reward during the on-policy rollouts, which will correct these mistakes	Reply	I-Reply	3

This papers show the effects of under-fitting in a neural network as the size of a single neural network layer increases.	Review	O	0
The overall model is composed of SIFT extraction, k-mean, and this single hidden layer neural network.	Review	O	0
The paper suggest that this under-fitting problem is due to optimization problems with stochastic gradient descent.	Review	O	0
[line_break_token][line_break_token]Pros[line_break_token]For a certain configurations of network architecture the paper shows under-fitting remains as the number of hidden units increases.	Review	O	0
[line_break_token][line_break_token]Cons[line_break_token]This paper makes many big assumptions:[line_break_token]1) that the training set of millions of images is labelled correctly.	Review	O	0
[line_break_token]2) training on sift features followed by kmeans retains enough information from the images in the training set to allow for proper learning to proceed.	Review	O	0
[line_break_token]3) a single hidden layer network is capable of completely fitting (or over-fitting) Imagenet.	Review	O	0
[line_break_token][line_break_token]While the idea seems novel, it does appear to be a little rushed.	Review	B-Review	2
Perhaps more experimentation with larger models and directly on the input image would reveal more.	Review	I-Review	2
The 3 assumptions can be thought of has 3 conditions that are necessary for the model to be able to fit ImageNet.	Reply	B-Reply	1
In traditional experiments this would be true, however, in this case we are only monitoring *training* error.	Reply	I-Reply	1
To learn the training set, only one assumption is necessary: no training image has an exact duplicate with a different label.	Reply	I-Reply	1
In this case, the model can at least learn a KNN-like function that gives 0 error.	Reply	I-Reply	1
[line_break_token][line_break_token]As for more experiments, we are planning experiments starting from the raw images	Reply	I-Reply	2

This paper proposes a method, R3L, for exploration in reinforcement learning.	Review	O	0
R3L performs an exploration procedure before policy optimization.	Review	O	0
In R3L exploration, it considers the task as a planning problem, and applies RRT to find feasible solutions (trajectories).	Review	O	0
Then it applies a warm start procedure for policy optimization, where the feasible solutions found by RRT are used to initialize the policy by supervised learning.	Review	O	0
The paper provides theoretical guarantees of R3L exploration finding feasible solutions.	Review	O	0
Empirically, the algorithmic contribution is demonstrated by comparing with information theoretical exploration methods in benchmark control domains.	Review	O	0
[line_break_token][line_break_token]The paper makes two strong assumptions, which are made to guarantee RRT can be successfully applied in the task.	Review	B-Review	1
However, it is unlikely that these two assumptions can hold in RL problems we consider in general, where the learning agent only have access to the transition data gathered by interactions with the environment.	Review	I-Review	1
This makes the proposed R3L algorithm not a general method for exploration in RL.	Review	I-Review	1
Due to this reason I think this paper should be rejected.	Review	I-Review	1
[line_break_token][line_break_token]The first assumption is that random states can be uniformly sampled from the MDP state space.	Review	O	0
The author further argue that sampling a random state is typically equivalent to trivially sampling a hyper-rectangle.	Review	B-Review	2
But isn't this a domain-dependent property?	Review	I-Review	2
For example, how to sample a random state in Atari games and decide if it is valid?	Review	I-Review	2
By the method proposed in the paper, one need to sample a random image, then apply a function to decide if the image is valid in the game.	Review	I-Review	2
How to get such a function?	Review	I-Review	2
The second assumption is that the environment state can be set to an arbitrary state.	Review	I-Review	3
This basically assumes the learning agent is available to the transition function, so that a new state can be added to the current search tree.	Review	I-Review	3
But again, this assumption might not be appropriate in the general RL framework.	Review	I-Review	3
[line_break_token][line_break_token]For the theoretical contribution, the paper shows that RRT is complete with high probability, which is a standard result of RRT.	Review	I-Review	4
In experiments, R3L is compared with VIME.	Review	I-Review	4
But is this a fair comparison since R3L assumes to have a generative model?	Review	I-Review	4
The tested domains are picked such that RRT can be directly applied.	Review	I-Review	4
Can R3L be applied in domains like mujoco or Atari games?	Review	I-Review	4
[line_break_token][line_break_token]The main idea of this paper is to deal with exploration using planning algorithms.	Review	O	0
But once a generative model of the environment is given, the exploration problem will be very different with the exploration considered in RL.	Review	B-Review	5
I would like to improve my score if the author can demonstrate the efficiency of R3L with a learned generative model.	Review	I-Review	5
[line_break_token][line_break_token]Minor issues:[line_break_token][line_break_token]1.	Review	O	0
Can you give more details about how pi_l is learned in Algorithm 1?	Review	B-Review	6
In line 9 an action is generated using pi_l(s_near, s_rand-s_near).	Review	I-Review	6
But in line 11, the action is again updated by ({s_near, s_rand-s_near}, a), which is very confusing.	Review	I-Review	6
[line_break_token][line_break_token]2.	Review	O	0
The notations for state and valid state are very confusing.	Review	B-Review	7
In 3.1, the transition and reward functions are defined on S. But later in the paper, S contains states that are not valid.	Review	I-Review	7
What's the transitions and rewards on invalid states?	Review	I-Review	7
[line_break_token]	Review	O	0
e would like to thank Reviewer 4 for the thorough review and helpful suggestions.	Reply	O	0
[line_break_token][line_break_token]Reviewer 4 has raised some concerns about the assumptions.	Reply	B-Reply	1
First, it is important to note that these assumptions only pertain to the demonstration generation (planning) phase, not the RL phase.	Reply	I-Reply	1
We will clarify this in the text.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding Assumption 1, we stress that the random states sampled from do not need to be valid, as stated in the paper following Assumption 1.	Reply	I-Reply	2
is not added to the tree.	Reply	I-Reply	2
Hence, there is no need for a function that will test states for validity.	Reply	I-Reply	2
Sampling a (not necessarily valid) state from is indeed domain specific, as Reviewer 4 notes.	Reply	I-Reply	2
Nonetheless, it reduces to sampling a hyper-rectangle in all common RL benchmark tasks (OpenAI Gym, MuJoCo, Atari Learning Environment, DMControl), since all of these tasks define the state space as a hyper-rectangle.	Reply	I-Reply	2
[line_break_token][line_break_token]We have changed Assumption 2 to make it milder and more accurate.	Reply	I-Reply	3
It now reads: "The environment state can be set to a previously visited state".	Reply	I-Reply	3
In simulation, setting the environment to a specific state can be implemented as a variable assignment.	Reply	I-Reply	3
As such, this step does not involve a transition from the current state to the target state, and does not require access to the transition dynamics, and does not involve a generative model.	Reply	I-Reply	3
As discussed in Section 6, policies learned in simulated environments can be transferred to real world tasks using sim-to-real techniques, which is left as future work.	Reply	I-Reply	3
We will clarify the connection between simulation and Assumption 2 in the main text.	Reply	I-Reply	3
[line_break_token][line_break_token]As noted above, is not added to the tree. (	Reply	I-Reply	3
almost always different from) is generated by executing action in state.	Reply	I-Reply	3
Assumption 2 is used to set the state to for this purpose.	Reply	I-Reply	3
Action attempts to reach but is not guaranteed to succeed.	Reply	I-Reply	3
This is a classic RL transition, which does not require knowing transition dynamics, and enforces that is a valid state.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding the theoretical contribution, our results extend RRT planning guarantees to the setting of MDPs, where the goal might be specified not as a subset of the state space but in terms of the return (cf.	Reply	I-Reply	4
Theorem 2).	Reply	I-Reply	4
Further, Theorem 3 is not a standard result in RRTs or in RL.	Reply	I-Reply	4
[line_break_token][line_break_token]As to mujoco and Atari environments, we note that three of the domains considered in the paper (Reacher, Fetch Reach and Hand Reach) are mujoco domains.	Reply	I-Reply	4
[line_break_token]R3L is most suitable to fully observable, continuous control, sparse-reward problems.	Reply	I-Reply	5
R3L should be applicable as-is to Atari problems, but will not necessarily be as efficient as methods tailored for discrete state and action spaces, or for image data.	Reply	I-Reply	5
Extending R3L to make it practical on high-dimensional tasks is mentioned as future work in Section 6.	Reply	I-Reply	5
We will clarify that this includes Atari/image data problems.	Reply	I-Reply	5
[line_break_token][line_break_token]Concerning the minor issues:[line_break_token]  * The local policy is defined as, mapping a state and a goal state to an action.	Reply	O	0
line 11 does not update, but rather the policy model.	Reply	B-Reply	6
The action is used as supervision for this update.	Reply	I-Reply	6
[line_break_token]  * An invalid state is e.g. a robotic arm being inside a wall.	Reply	O	0
Such a state is implausible, but in practice most MDPs include it in their definition of the state space.	Reply	B-Reply	7
Since this paper is in the sparse reward setting, the reward for such a state would be should it somehow be encountered.	Reply	I-Reply	7
The transition dynamics in that state would depend on the MDP.	Reply	I-Reply	7
In the example of the robotic arm getting stuck inside a wall, this would be an absorbing state, as no action can change the pose of the arm.	Reply	I-Reply	7

[line_break_token][line_break_token]This paper describes a general purpose differentiable molecular dynamics physics package, JAX MD.	Review	O	0
It shows several instances, where it simplifies the research process and enables new avenues of work.	Review	O	0
[line_break_token][line_break_token]The Github link is provided for reproducible research and future development.	Review	O	0
It should be encouraged.	Review	O	0
[line_break_token][line_break_token]I am sure whether this paper fit the ICLR or not, or how deep learning community can benefit from it.	Review	B-Review	2
[line_break_token][line_break_token]The writing does not feel academic enough sometime.	Review	I-Review	1
For example,  "Please let us know if there are features that you would find interesting.	Review	I-Review	1
We are always seeking contributions!"	Review	I-Review	1
Please consider the rephrase it.	Review	I-Review	1
hank you for taking the time to review our work and we appreciate your advice about the writing.	Reply	B-Reply	1
We will fix the sentence you noted and generally make the writing more formal.	Reply	I-Reply	1
[line_break_token][line_break_token]We would like to discuss the applicability of this work to the ML community.	Reply	I-Reply	2
While it is true that JAX MD will be of use to Physicists, we note that there has been significant research among ML practitioners that would be aided by JAX MD.	Reply	I-Reply	2
In particular, we note the following (non-exhaustive) list of papers [1-7] that were published recently in Machine Learning Conferences.	Reply	I-Reply	2
In each case, these papers leverage physical simulation; however, they were hindred since the simulations used were not integrated with deep learning libraries.	Reply	I-Reply	2
This is precisely the gap that JAX MD hopes to fill.	Reply	I-Reply	2
We would like to draw particular attention to [1], ‚ÄúLearning Protein Structure with a Differentiable Simulator‚Äù that could have been implemented out-of-the-box using JAX MD and received an oral at ICLR last year.	Reply	I-Reply	2
[line_break_token][line_break_token]Apart from this, we believe (though there has been less work in this direction so far) that physical systems are an ideal environment to explore meta-optimization since the inner-loop is much better understood than neural networks in deep learning.	Reply	I-Reply	2
[line_break_token][line_break_token][1] Learning Protein Structure with a Differentiable Simulator[line_break_token]Ingraham et al.;	Reply	O	0
ICLR 2019[line_break_token][line_break_token][2] Interaction Networks for Learning about Objects, Relations and Physics[line_break_token]Battaglia et al.;	Reply	O	0
NeurIPS 2016[line_break_token][line_break_token][3] Visual Interaction Networks: Learning a Physics Simulator from Video[line_break_token]Watters et al.;	Reply	O	0
NeurIPS 2017[line_break_token][line_break_token][4] SchNet: A continuous-filter convolutional neural network for modeling quantum interactions[line_break_token]Sch√ºtt et al.;	Reply	O	0
NeurIPS 2017[line_break_token][line_break_token][5] Learning Invariant Representations of Molecules for Atomization Energy Prediction[line_break_token]Montavon et al.;	Reply	O	0
NeurIPS 2012[line_break_token][line_break_token][6] A Compositional Object-Based Approach to Learning Physical Dynamics[line_break_token]Chang et al.;	Reply	O	0
ICLR 2017[line_break_token][line_break_token][7] End-to-End Differentiable Physics for Learning and Control[line_break_token]Belbute-Peres et al.;	Reply	O	0
NeurIPS 2018	Reply	O	0

This paper introduces the idea of energy based model to the traditional classifier, and proposes a new framework to improve the performances of the model in multiple aspects.	Review	O	0
The idea of reinterpreting the traditional classifier is very interesting, and the experiments show some good results of the proposed method.	Review	O	0
 [line_break_token][line_break_token]Here are my main concerns of the current paper:[line_break_token]1.	Review	O	0
The training procedure seems to be very sensitive, and the SGLD may take a long time at each iteration to converge.	Review	B-Review	1
This may be a big limitation of the proposed method.	Review	I-Review	1
[line_break_token]2.	Review	O	0
According to equation (8), the proposed method is having a trade-off between classification and generation, and this seems to be the key to improve the performance of the model in generation by sacrificing some classification accuracy.	Review	B-Review	2
I think author should emphasize this instead of energy based model.	Review	I-Review	2
[line_break_token]3.	Review	O	0
The presentation is not very clear in section 5.	Review	B-Review	3
What is the task of calibration, and what is the definition of ECE?	Review	I-Review	3
[line_break_token]4.	Review	O	0
The robustness guarantee seems too good to be true.	Review	B-Review	4
Although the authors claim that they allow the attacker to have access to the gradient  of SGLD, the SGLD will add noise during the forward process, this will obfuscate the gradient.	Review	I-Review	4
In this sense, I don‚Äôt think the proposed method will have the strong robustness as they claimed.	Review	I-Review	4
[line_break_token][line_break_token]----------------[line_break_token]Post-Rebuttal Comments:[line_break_token]Thanks for addressing my concerns.	Review	O	0
Although I think the proposed method is not comprehensive to check obfuscated gradients, I do think the current version is a good fit for ICLR, and I decide to increase my score.	Review	O	0
PART 1 OF 2)[line_break_token][line_break_token]We thank you for your time reviewing our work.	Reply	O	0
We will address your concerns in order and we have updated the manuscript accordingly.	Reply	O	0
We hope these changes will encourage you to change your score:[line_break_token][line_break_token]1) Your concerns on the sensitivity and speed of SGLD training of EBMs.	Reply	O	0
[line_break_token][line_break_token]Regarding your concern about sensitivity: [line_break_token][line_break_token]While we agree that SGLD training of EBMs can be sensitive to hyper-parameter settings, we note that throughout our work we used the exact same hyper-parameters for every model and every dataset.	Reply	O	0
We also found these settings transferred well to datasets such as MNIST which we did not present in our paper.	Reply	B-Reply	1
Further, we found these same settings worked well across a variety of model architectures such as MLPs, non-resnet convnets, and resnets.	Reply	I-Reply	1
This was stated in Appendix  G.2 of our paper, but we have added it to the main body of our paper for clarity.	Reply	I-Reply	1
This hyper-parameter transferability behavior has also been reported in prior work on EBM training such as [1, 2].[line_break_token][line_break_token]Regarding your other concern about the convergence time: [line_break_token][line_break_token]In our work we put a great deal of focus into being able to train as quickly as possible with minimal hardware requirements.	Reply	O	0
We have been able to train EBMs with far fewer SGLD steps per training iteration than in previous work and found that at these settings stable training can still take place.	Reply	B-Reply	1
All of our models were trained on a single GPU and each training run took hours.	Reply	I-Reply	1
While this is slower than training a standard classifier on these datasets, our training speed falls comfortably in the range of other popular classes of generative models such as flows [3] and GANs [4].[line_break_token][line_break_token]We admit that we did not put enough emphasis on these two facts in our original draft and we have added this information in section 5.	Reply	I-Reply	1
We hope this clarifies your concerns regarding training sensitivity and run-time.	Reply	I-Reply	1
 [line_break_token][line_break_token]Overall we feel that training and sampling are the biggest challenges when working with EBMs.	Reply	I-Reply	1
Developing improved methods for this is important further work but we also feel it is outside of the scope of our current work.	Reply	I-Reply	1
The main point of our work was to demonstrate that despite the challenges which currently exist in training EBMs, they can be used to achieve a very interesting and diverse set of results on problems which other classes of generative models have not been able to achieve at this scale.	Reply	I-Reply	1
These results provide a strong motivation for more work in the space of EBM training methods.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2) We are slightly unsure of what you mean with this point.	Reply	O	0
We train our model using the factorized likelihood of Equation (8).	Reply	B-Reply	2
As we explain in the following sentence, this was done to reduce bias in our training procedure, not because there is a need to weight these terms differently.	Reply	I-Reply	2
We are aware that this is common practice in other hybrid-models [4, 5], but we do not do this in our model.	Reply	I-Reply	2
Each term in this objective is weighted equally.	Reply	I-Reply	2
While different results could possibly be achieved if we did weight each term in (8) we feel that our model's ability to weight the terms equally and still perform well at both tasks is actually a benefit of our approach over competing methods.	Reply	I-Reply	2
We hope this clarifies your concerns.	Reply	I-Reply	2
[line_break_token][line_break_token](CONTINUED BELOW)[line_break_token][line_break_token][1] "Implicit Generation and Generalization in Energy-Based Models"  Yilun Du, Igor Mordatch.	Reply	O	0
<a href="https://arxiv.org/abs/1903.08689" target="_blank" rel="nofollow">https://arxiv.org/abs/1903.08689</a>[line_break_token][2] "On the Anatomy of MCMC-based Maximum Likelihood Learning of Energy-Based Models"  Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, Ying Nian Wu.	Reply	O	0
<a href="https://arxiv.org/abs/1903.12370" target="_blank" rel="nofollow">https://arxiv.org/abs/1903.12370</a>[line_break_token][3] "Large Scale GAN Training for High Fidelity Natural Image Synthesis"  Andrew Brock, Jess Donahue, Karen Simonyan.	Reply	O	0
<a href="https://arxiv.org/abs/1809.11096" target="_blank" rel="nofollow">https://arxiv.org/abs/1809.11096</a>[line_break_token][4] "Glow: Generative Flow with Invertible 1x1 Convolutions"  Diederik P. Kingma, Prafulla Dhariwal.	Reply	O	0
<a href="https://arxiv.org/abs/1807.03039" target="_blank" rel="nofollow">https://arxiv.org/abs/1807.03039</a>[line_break_token][5] "Residual Flows for Invertible Generative Modeling"  Ricky T. Q. Chen, Jens Behrmann, David Duvenaud, J√∂rn-Henrik Jacobsen.	Reply	O	0
<a href="https://arxiv.org/abs/1906.02735" target="_blank" rel="nofollow">https://arxiv.org/abs/1906.02735</a>[line_break_token][6] "On Calibration of Modern Neural Networks"  Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q. Weinberger.	Reply	O	0
<a href="https://arxiv.org/abs/1706.04599" target="_blank" rel="nofollow">https://arxiv.org/abs/1706.04599</a>[line_break_token]	Reply	O	0

Review: This paper focuses on generating adversarial perturbation in semantic space.	Review	O	0
The main contribution of this paper is to propose a general method to generate semantic adversarial examples by using advances in differential rendering and inverse graphics.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
Generally, the presentation is clear and easy to follow.	Review	O	0
[line_break_token]2.	Review	O	0
A general way to transform any pixel-attack algorithm to its ‚Äúsemantic version‚Äù is novel.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
There are already a lot of ways to make adversarial examples even semantic adversarial examples.	Review	B-Review	1
It‚Äôs not enough to just propose a new way to make adversarial examples.	Review	I-Review	1
I think this paper would be more compelling if proposed SAEs have some special property (e.g, easy to take effect in the real world or stronger robustness against defense strategy).	Review	I-Review	1
[line_break_token]2.	Review	O	0
In section 5.3, the authors show that data augmentation using SAEs increase the robustness to SAEs, but pixel perturbation AEs do not.	Review	B-Review	2
This result is of little value.	Review	I-Review	2
It is obvious that data augmentation using SAEs can increase more robustness to SAEs or pixel-perturbation AEs can increase more robustness to pixel-perturbation AEs.	Review	I-Review	2
The authors are suggested to compare changes in general robustness caused by two types of data augmentations.	Review	I-Review	2
For example, compare minimum adversarial distortion.	Review	I-Review	2
e thank the reviewer for his/her valuable feedback.	Reply	O	0
Below, we respond to some of the questions raised by the reviewer.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Motivation + Novelty: While we believe that pixel perturbations are hard to realize in the physical world, the SAEs we generate are much easier to realize.	Reply	B-Reply	1
Thanks to your feedback, we re-iterate this point several times through the paper to make it clearer to the reader.	Reply	I-Reply	1
We also compare and contrast our approach of generating SAEs with prior works in the space (see the text in blue in the related work section); the generality of our approach coupled with the ability to easily transform existing pixel perturbation attacks to attacks capable of generating SAEs is novel and has not been studied before.	Reply	I-Reply	1
[line_break_token]2.	Reply	O	0
Results: We have moved the results regarding the impact of SA-training on PP and vice-versa to the appendix (now Appendix A1) to make for clearer reading.	Reply	B-Reply	2
[line_break_token]3.	Reply	O	0
Adversarial Distortion: We believe that measuring the distortion caused by the adversary is a challenging proposition in the context of SAEs; in the case of pixel perturbations, adversarial distortion is measured using p-norms, which serve as a proxy for visual perception.	Reply	B-Reply	2
However, there exists no function that accurately captures changes in semantics, and ties it to visual perception.	Reply	I-Reply	2
Should such a function exist, we will be able to easily add it to our optimization framework, and produce SAEs with lesser computational overhead.	Reply	I-Reply	2
We thank the reviewer for pointing this out; we have clarified this in the paper (added as a footnote on page 4), and pose discovering such a function as an open question to researchers in the community.	Reply	I-Reply	2

This paper studied the problem of the encoded position information in convolution neural networks.	Review	O	0
The hypothesis is that CNN can implicitly learn to encode the position information.	Review	O	0
The author tests the hypothesis with lots of experiments to show how and where the position information is encoded.	Review	O	0
[line_break_token][line_break_token]Clarity:[line_break_token]This paper is interesting for me.	Review	O	0
It tries to understand the encoded position information that is easily ignored by researchers.	Review	O	0
I like adequate experiments with learned position information and position illustrations.	Review	O	0
[line_break_token][line_break_token]Experiments:[line_break_token]1.	Review	O	0
The paper mainly discussed the zero-padding and found it is the source of position information.	Review	B-Review	1
How about other padding modes like constant-padding, reflection-padding, and replication-padding?	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The partial convolution-based padding method [1] (padded regions are masked out) shows that its recognition accuracy is higher than the traditional zero-padding approach.	Review	B-Review	2
Can you help investigate where the position information comes from for this case?	Review	I-Review	2
[line_break_token][line_break_token][1] Partial Convolution based Padding, <a href="https://arxiv.org/pdf/1811.11718.pdf."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1811.11718.pdf.</a>[line_break_token][line_break_token][line_break_token]Some of my concerns are well addressed by the author thus I upgrade my score.	Review	O	0
[line_break_token]	Review	O	0
any thanks for your review and we appreciate your insightful feedback.	Reply	O	0
[line_break_token][line_break_token]In our paper we discussed the implicit effect of the widely used zero-padding mechanism in CNNs.	Reply	B-Reply	1
We believe the strong position information is encoded by the value transition near the boundary, zero to non-zero values.	Reply	I-Reply	1
Intuitively, we believe other padding strategies, e.g. reflection or replication padding, are not able to deliver this clear position information.	Reply	I-Reply	1
[line_break_token][line_break_token]We compared the effect of Circular padding implemented in Pytorch with the commonly used zero-padding on the Horizontal (H) setting using VGG16, First row of Table 1 (VGG).	Reply	I-Reply	1
The training loss of zero-padding starts from 0.045 and drops to 0.03 in the end.	Reply	I-Reply	1
While the loss for circular-padding begins at 0.065 and ends at 0.056, much higher than zero-padding.	Reply	I-Reply	1
The results of circular-padding on the PASCAL-S dataset are (SPC 0.381, MAE 0.224).	Reply	I-Reply	1
Note that this result is similar to the setting of VGG w/o padding, Table 4 (VGG w/o padding on H).	Reply	I-Reply	1
This further validates our hypothesis that the position information is delivered by the value transition of zero-padding.	Reply	I-Reply	1
[line_break_token][line_break_token]For the conv-padding paper, according to Equations (4) and (5), their method essentially still applies zero-padding, which means the position information should be encoded.	Reply	I-Reply	2
Their method is actually weighing the output of the convolution based on how many zeros are padded, r(i, j).	Reply	I-Reply	2

The authors propose a way to visualize which areas of an image provide mostly influence a certain DNN response mostly.	Review	O	0
They apply some very elegant and convincing improvements to the basic method by Robnik-Sikonja and Konononko from 2008 to DNNs, thus improving it's analysis and making it usable for images and DNNs.	Review	O	0
[line_break_token][line_break_token]The authors provide a very thorough analysis of their methods and show very convincing examples (which they however handpicked.	Review	O	0
It would be very nice to have maybe at least one figure showing the analysis on e.g. 24 random picks from ImageNet).	Review	O	0
[line_break_token]One thing I would like to see is how their method compares to some other methods they mention in the introduction (like gradient-based ones or deconvolution based ones).	Review	B-Review	1
[line_break_token][line_break_token]They paper is very clearly written, all necessary details are given and the paper is very nice to read.	Review	O	0
[line_break_token][line_break_token]Alltogether: The problem of understanding how DNNs function and how they draw their conclusions is discussed a lot.	Review	O	0
The author's method provides a clear contribution that can lead to further progress in this field (E.g. I like figure 8 showing how AlexNet, GoogLeNet and VGG differ in where they collect evidence from).	Review	O	0
I can think of several potential applications of the method and therefore consider it of high significance.	Review	O	0
[line_break_token][line_break_token]Update: The authors did a great job of adopting all of my suggestions.	Review	O	0
Therefore I improve the rating from 8 to 9.	Review	O	0
Thank you very much for your review.	Reply	O	0
We understand that for the reader it would make a convincing point to see results on random picks, and therefore ran additional experiments on 34 randomly selected ImageNet images.	Reply	B-Reply	1
We also added the results of the method from Simonyan et al. (	Reply	I-Reply	1
2013) for direct comparison.	Reply	I-Reply	1
Please see <a href="https://www.dropbox.com/s/0eoe1krqg4m6gv8/results_random_legend.png" target="_blank" rel="nofollow">https://www.dropbox.com/s/0eoe1krqg4m6gv8/results_random_legend.png</a> for the results (we will add them to the appendix of the paper in a revised version).	Reply	O	0
[line_break_token][line_break_token]Further, we made our code publicly available, see <a href="https://github.com/lmzintgraf/DeepVis-PredDiff" target="_blank" rel="nofollow">https://github.com/lmzintgraf/DeepVis-PredDiff</a>	Reply	O	0

In the paper, the authors propose a novel optimization method for training deep learning models.	Review	O	0
The idea is from the LARS and AdamW. The authors then test the proposed method on multiple experiments, results showing that the proposed method works better than other compared methods.	Review	O	0
 The following are my concerns:[line_break_token][line_break_token]1) No convergence guarantee in the paper.	Review	O	0
There are too many papers claiming faster convergence these days, proof of convergence guarantee is always preferred.	Review	B-Review	1
[line_break_token]2) The proposed method is straightforward and easy to understand.	Review	O	0
It is just a combination of AdamW and LARS.	Review	B-Review	2
I am worried about the novelty of this paper.	Review	I-Review	2
[line_break_token]3) In the experiments, why the compared methods are usually different.	Review	O	0
For example, compared methods are Adam, SGD, and NovoGrad in table 4 and compared methods are Adam, AdamW, and NovoGrad in table 6.	Review	B-Review	3
 Why not compare all these methods?	Review	I-Review	3
[line_break_token]4) When the batch size varies,  is it required to tune beta_2 accordingly?	Review	O	0
I didn't find it clearly mentioned in the paper, could authors explain how to set it?	Review	B-Review	4
[line_break_token]5)  I am confusing that NovoGrad method works much better than Adam or AdamW in Table 6 with no weight decay, more explanations are required.	Review	O	0
[line_break_token]6) It is unclear why NovoGrad is better than LARS.	Review	O	0
LARS normalizes learning rate through |w|_2/|g|_2.	Review	B-Review	6
The authors should explain why normalizes using layerwise |g|_2 is better.	Review	I-Review	6
[line_break_token][line_break_token]Although the idea is straightforward, the proposed method may be helpful for the community.	Review	O	0
  I will consider increasing the score if authors can address my concerns.	Review	O	0
hank you for the review.	Reply	O	0
Clearly we could  do better comparison of NovoGrad with LARS and explain why removed scaling of normalized gradients by.	Reply	B-Reply	1
[line_break_token] [line_break_token]Q1:"There is no convergence guarantee in the paper.	Reply	O	0
There are too many papers claiming faster convergence these days, proof of convergence guarantee is always preferred."	Reply	O	0
[line_break_token]A1: The proofs of convergence for the majority of optimizers (e.g. Adam, AdaFactor, LARS etc) are given for convex / quasi-convex case only, and usually these proofs closely follow the original proof from Adagrad paper [1].  The proof for Stochastic Normalized GD was also given only in  quasi-convex setting (Hazan et al , 2014 [2]).	Reply	O	0
This proof can be extended in straight-forward  way for NovoGrad.	Reply	B-Reply	1
The convexity / quasi-convexity assumptions that don't hold for deep networks.	Reply	I-Reply	1
[line_break_token]The convergence proof for deep networks with more  than 2 layers is open problem.	Reply	I-Reply	1
As far as I know, even for vanilla gradient descent  the convergence proof for deep networks was  proposed only for  deep linear networks in Aurora et al , 2018 [3].  We are working to extend their proof for Normalized Gradients type algorithms.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: "The proposed method is just a combination of AdamW and LARS.	Reply	O	0
I am worried about the novelty of this paper."	Reply	O	0
[line_break_token]A2:   NovoGrad comparison  to  LARS:[line_break_token]1.	Reply	O	0
LARS uses norm of layer gradient for normalization.	Reply	B-Reply	2
NovoGrad uses the norm of  second moments for the layer.	Reply	I-Reply	2
So if we set, the norm of second moment will become just norm of gradient.	Reply	I-Reply	2
So NovoGrad is more general comparing to LARS.	Reply	I-Reply	2
[line_break_token]2.	Reply	O	0
After normalization, LARS rescales the update proportional to the norm of layer weight.	Reply	B-Reply	2
NovoGrad doesn't .	Reply	I-Reply	2
The reasons why we removed this rescaling are explained in the A6 below.	Reply	I-Reply	2
[line_break_token]NovoGrad comparison  to  AdamW:[line_break_token]The main difference between AdamW and NovoGrad is that NovoGrad normalize gradients before it compute first moment, while AdamW first computes the first moment, and then normalize it by second moment.	Reply	I-Reply	2
This change in order makes NovoGrad more robust to the "gradients outlier", while AdamW keeps remembering very high gradient for long period.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: "Why the compared methods are usually different.	Reply	O	0
For example, compared methods are Adam, SGD, and NovoGrad in table 4 and compared methods are Adam, AdamW, and NovoGrad in table 6.	Reply	O	0
 Why not compare all these methods?"	Reply	O	0
[line_break_token]A: The choice of baseline algorithms for each particular problem was based on the best performing optimizers from the literature.	Reply	O	0
We tried to solve several tasks with ‚Äúnon-traditional‚Äù optimizers but did not succeed.	Reply	B-Reply	3
For example, we could not make Adam converge on ResNet-50 to reasonable accuracy and we could not make SGD converge on Transformer NMT.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4: "When the batch size varies,  is it required to tune accordingly?"	Reply	O	0
[line_break_token]A: No.	Reply	O	0
We didn‚Äôt use tuning for different batch sizes.	Reply	B-Reply	4
The default suggested value is which we used in the majority of our experiments (ASR, LM, NMT).	Reply	I-Reply	4
ResNet-50 experiments were conducted with  the earlier version of the code with=0.98[line_break_token][line_break_token]Q5:"Why NovoGrad method works much better than Adam or AdamW in Table 6 with no weight decay?"	Reply	O	0
[line_break_token]A: For language modeling with Transformer-XL, we used only Dropout for regularization, following the original paper [4]. We experimented with weight decay too, but did not manage to get better results for both NovoGrad and Adam (the scores of AdamW are comparable to those of Adam).	Reply	O	0
[line_break_token][line_break_token]Q6: "Why NovoGrad is better than LARS.	Reply	O	0
LARS normalizes learning rate through.	Reply	O	0
The authors should explain why normalizes using layer-wise is better."	Reply	O	0
[line_break_token]A: The main weakness of LARS is its behavior in the regions with either too small or too large weights.	Reply	O	0
If weights are near 0, then scaling by will make update very small, and it will take too long to leave this region.	Reply	B-Reply	6
If weights are large, then the update (which is proportional to the weights norm) can be too large, which might cause instability.	Reply	I-Reply	6
NovoGrad does not have this weakness.	Reply	I-Reply	6
This is major reason why we removed scaling of normalized gradients by in NovoGrad.	Reply	I-Reply	6
[line_break_token][line_break_token]References:[line_break_token][1] J. Duchi, E. Hazan, Y. Signer.	Reply	O	0
Adaptive subgradient methods for online learning and stochastic optimization, 2011.	Reply	O	0
[line_break_token][2] E. Hazan, K. Levy, S. Shalev-Shwartz.	Reply	O	0
Beyond Convexity: Stochastic Quasi-Convex Optimization, 2014[line_break_token][3] S. Arora, N. Cohen, N. Golowich, W.Hu.	Reply	O	0
A Convergence Analysis of Gradient Descent for Deep Linear Neural Networks, 2018.	Reply	O	0
[line_break_token][4] Z. Dai, Z. Yang, Y. Yang, J. Carbonell, Q. Le, R. Salakhutdinov.	Reply	O	0
Transformer-XL: language models beyond a fixed-length context, 2019.	Reply	O	0
[line_break_token]	Reply	O	0

The paper claims that a combination of policy gradients calculate by different RL algorithms would provide better objective values.	Review	O	0
Main focus of the work is to devise and adaptive combination scheme for policy gradient estimators.	Review	O	0
Authors claim that by using the statistical shrinkage estimators combining different gradients that have different bias-variance trade-off would provide better mean-square error than each of those individual gradient estimators.	Review	O	0
The key observations made by the authors are that gradients computed by on-policy methods would provide nearly unbiased estimators with very high variance while the gradients obtained by the off-policy methods in particular model based approaches would provide highly biased estimators with low variance.	Review	O	0
Proposed statistical tool to combine gradients is James-Steim shrinkage estimator.	Review	O	0
JS estimator provides strong theoretical guarantees for Gaussian cases but some practical  heuristics tor more complex non-Gaussian cases.	Review	O	0
Authors do not discuss  whether the JS estimator actually suitable for this task given the fact that strong assumptions of the underlying statistical approach is violated.	Review	B-Review	1
They also do not go into any discussion about theoretical guarantees nor they provide any exposures or intuitions about that.	Review	I-Review	2
The scope of the experiments is very limited.	Review	I-Review	3
Given the fact that there is no theory behind the claims and the lack of strong evidence I believe this paper does not cut the requirements for publication.	Review	I-Review	4
[line_break_token][line_break_token]To improve please add significantly more empirical evidence, provide more discussion about theoretical ground work and discussion about the suitability of the JS estimators when its required assumptions are not satisfied.	Review	I-Review	5
We would like to thank reviewer's valuable comments.	Reply	O	0
As for theoretical gurantees,  JS estimator was originally motivated for normal distributions for which nice inequalities can be established to guarantee the decrease of MSE.	Reply	B-Reply	2
 However, it is easily applicable to more general cases and provides a simple yet powerful strategy for addressing the {very challenge of bias-variance trade-off} that is crucial in many components of RL.	Reply	I-Reply	2
The goal of this work is to fill this gap between RL and JS literature.	Reply	I-Reply	2
Note that the decrease of MSE in our experiments is already a direct evidence of the effectiveness of JS in RL.	Reply	I-Reply	2
 In the future we will try to use recent extended efficient shrinkage estimators in parametric models (hansen, 2016), which relaxes the normal distribution to general asymptotic distributions.	Reply	I-Reply	2
[line_break_token][line_break_token]Hansen, Bruce E. Efficient shrinkage in parametric models.	Reply	O	0
Journal of Econometrics, 190(1):115‚Äì132, 2016.	Reply	O	0

This paper gives theoretical and empirical results for a gradient clipping variant of Adam they call ACClip.	Review	O	0
 While the theoretical analysis is rather  sophisticated and nontrivial, I personally do not believe that analyses of this form are of any value in guiding practice.	Review	O	0
 But that is a long discussion that is not specific to this paper.	Review	B-Review	1
 The bottom line is that for me it is mainly the experimental results that matter.	Review	I-Review	1
[line_break_token][line_break_token]The experimental results are not compelling.	Review	I-Review	2
 It is now clear that careful hyperparameter search is critical to drawing experimental conclusions about optimizers.	Review	I-Review	2
 This paper simply states the hyperparameters used with no discussion of hyperparameter search.	Review	I-Review	2
I strongly believe that any claim about optimizers needs to be backed up by experiments with very careful hyper-parameter optimization.	Review	I-Review	2
[line_break_token][line_break_token]Postscript:  I have modified this review in response to the authors.	Review	O	0
 I remain unconvinced that the theory is providing anything more than an intuitive hypothesis that Adam is importance when the variance is large.	Review	B-Review	1
 Since Adam and RMSprop are explicitly damping variance in the gradients, this intuition is reasonable even before we prove any theorems.	Review	I-Review	1
 I still believe the theorems do not add really add anything to the intuition and it is the experiments that matter.	Review	I-Review	1
e thank the reviewer for the comments and feedback.	Reply	O	0
We address the reviewer‚Äôs questions as follows:[line_break_token][line_break_token]1‚Äúanalyses of this form are of no value in guiding practice;  it is mainly the experimental results that matter‚Äù:[line_break_token][line_break_token]The discrepancy between convergence analysis and empirical result is the main motivation of our work.	Reply	O	0
Particularly, we show that under a more realistic assumption that noise is heavy tailed, theory can guide practice.	Reply	B-Reply	1
[line_break_token][line_break_token]We would like to emphasize that the central goal of the paper is to address the important practical question: Why Adam outperforms SGD in Attention models?	Reply	I-Reply	1
It is indeed puzzling why training these models necessitates the use of adaptive optimization techniques like Adam in comparison to computer vision models like ResNet where SGD + Momentum gives the best performance.	Reply	I-Reply	1
[line_break_token][line_break_token]In this paper, we hypothesize that heavy-tail noise is one root cause of this difference and provide strong theoretical (see Table 1 and corresponding theorems) and empirical evidence for this hypothesis.	Reply	I-Reply	1
These results show that under heavy tail noise of stochastic gradients (or high variance in general) , the performance of SGD deteriorates significantly (see Assumption 1 and Section A of Appendix).	Reply	I-Reply	1
While we believe that the convergence rates are interesting and important, even from a practical standpoint, our theoretical results provide qualitative insights into why SGD fails to perform well in the aforementioned settings.	Reply	I-Reply	1
 Our analysis provides guidelines for the development of optimization techniques for attention models (indeed, ACClip follows as a direct consequence of this analysis).	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token][line_break_token]2. ‚	Reply	O	0
ÄúThere is no mention of RoBERTa and her descendents.	Reply	O	0
‚Äù: [line_break_token][line_break_token]Since RoBERTa is a different training procedure (more data, more iterations, larger batch) of the same BERT model, we believe that ACClip should perform similarly well in these models.	Reply	O	0
We will be happy to run more experiments and include them in the final version if this is the point of concern.	Reply	B-Reply	2
[line_break_token][line_break_token]We indeed extensively tuned the hyperparameters to get the best result for each optimizer and will include the details in the next version.	Reply	I-Reply	2
We thank the reviewer for pointing out our oversight.	Reply	I-Reply	2
In particular, we found that the set of ADAM hyperparameters used in the original BERT [Devlin et al] paper works the best.	Reply	I-Reply	2
Hence we use the same params as in [Devlin et al] and achieved slightly better baseline performance.	Reply	I-Reply	2
[line_break_token][line_break_token]It will indeed be great if GLUE leader board members can examine the paper and try our optimization technique.	Reply	I-Reply	2
We will be happy to help them in this process.	Reply	I-Reply	2
That said, we would like to emphasize that the primary focus of the paper is not to achieve SOTA results for attention models but rather understand the optimization challenges in training attention models and provide guidelines for development of optimization techniques specially catered to these settings.	Reply	I-Reply	2

Pros:[line_break_token]1.	Review	O	0
This work suggests a surprisingly elegant approach to identify data with corrupted labels.	Review	O	0
The proposed AUL (area under the loss curve) makes intuitive sense, and exploiting the fact that noisy examples are hard to learn at the early stage of training, leading to higher AULs than clean examples.	Review	O	0
[line_break_token]2.	Review	O	0
The paper is well-written, with plenty of visualization to aid the understanding.	Review	O	0
[line_break_token]3.	Review	O	0
Experimental results suggest advantage of the proposal.	Review	O	0
Evaluation seem to suggest the using AULs is more robust against large corruptions compared with SOTA.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
The biggest concern is the generalizability of AULs to datasets that are more challenging than CIFAR10 and CIFAR100.	Review	B-Review	1
This has been the concern not only for this work, but also for this general research area.	Review	I-Review	1
For instance, on Tiny-ImageNet dataset (e.g., used in SELFIE: Refurbishing Unclean Samples for Robust Deep Learning (ICML19), which could btw be used in the benchmark), a clean dataset only gives ~55% test error, compared with about ~10% on CIFAR10 and ~30% on CIFAR100.	Review	I-Review	1
The robustness of AULs needs to be tested on those harder problems as well.	Review	I-Review	1
[line_break_token]2.	Review	O	0
AULs are based on the assumption of a clear separation of two types of examples -- clean and noisy.	Review	B-Review	2
It ignores the difficulty of training examples.	Review	I-Review	2
This raises the question of where to place hard-clean examples between those two modes.	Review	I-Review	2
[line_break_token]3.	Review	O	0
It usually helps to include a real-world noisy datasets where its noisy corruption is unknown.	Review	B-Review	3
One would be curious to know the noisy level estimate.	Review	I-Review	3
[line_break_token][line_break_token]Questions:[line_break_token]1.	Review	O	0
It seems from the experiments that MoGs are fit per training example in order to compute weights for the cost?	Review	B-Review	4
[line_break_token]2.	Review	O	0
The computational cost of AUL-based training is not mentioned.	Review	B-Review	5
Is it 2x, 3x, considering there are distinct stages of training before and after AUL estimation?	Review	I-Review	5
.R.T. additional benchmarks and datasets: We have since performed additional experiments on TinyImagenet.	Reply	O	0
A ResNet-32 trained on 95000 training samples (5000 withheld for validation) receives 49.4% test error on the clean dataset.	Reply	B-Reply	1
With 40% label noise this number drops to 65.5%.	Reply	I-Reply	1
AUL reweighting achieves 55.7% error.	Reply	I-Reply	1
We will update the paper with these results.	Reply	I-Reply	1
Additionally, see the response to Reviewer #2 regarding real-world datasets.	Reply	I-Reply	3
[line_break_token][line_break_token]W.R.T. ‚Äúhard‚Äù clean examples: please see response to Reviewer #2.	Reply	O	0
[line_break_token][line_break_token]W.R.T. the MoG: we use the initial network to compute the AUL for all 45,000 training points.	Reply	O	0
Then we fit the MoG to these 45,000 AULs.	Reply	B-Reply	4
[line_break_token][line_break_token]W.R.T the computation cost: thank you for noting this omission.	Reply	O	0
It is roughly 1.5x as much as normal training.	Reply	B-Reply	5
The initial AUL estimate requires training a network for 0.5x the usual training budget (right before the learning rate is dropped for the first time) Fitting the MoG is negligible compared to training the network.	Reply	I-Reply	5

This paper proposes to train a Universal Phonetic Model for building speech recognition for new languages without any training data.	Review	O	0
It suggests to use X-SAMPA to map phones from all the languages into a single phonetic space.	Review	O	0
The prediction models are designed to first predict the phonetic features and then the phones depending on the target language.	Review	O	0
[line_break_token]Overall , the paper is quite clear written.	Review	O	0
[line_break_token]- Strengthens:[line_break_token]+ It observed overall improvements for all the target languages.	Review	O	0
[line_break_token][line_break_token]- Weaknesses:[line_break_token]+ The idea and the proposed model are not novel.	Review	O	0
[line_break_token]+ All the baseline systems have relative high phone error rates.	Review	O	0
[line_break_token]+ The authors claimed to have a universal phonetic model but actually the model was trained only with English data.	Review	O	0
Therefore, experimental setup could be improved.	Review	B-Review	3
In my opinion, it makes more sense to define a bunch of resource-rich languages as source and then train a real universal phonetic model.	Review	I-Review	3
[line_break_token]+ Overall, this paper lacks an analysis what are exactly improved and why the improvements for some target languages are larger than for the others.	Review	O	0
[line_break_token] 	Review	B-Review	1
Thank you for your valuable comments !	Reply	O	0
[line_break_token][line_break_token]We think that the term ‚ÄúUniversal Phonetic Model‚Äù might have confused the reviewer.	Reply	B-Reply	3
We are sorry about that.	Reply	I-Reply	3
The problem that we want to address is the task of zero-shot learning for speech recognition, which consist of learning an acoustic model without any resources for a given target language.	Reply	I-Reply	3
We call our model ‚ÄúUniversal Phonetic Model‚Äù, because it has the ability to predict any phoneme, even the ones that are not present during training (therefore it covers a ‚Äúuniversal‚Äù set).	Reply	I-Reply	3
We achieve this by decomposing the phone label into its phone attributes.	Reply	I-Reply	3
[line_break_token][line_break_token]One of the weakness that has been pointed out is that the idea and model is not novel.	Reply	I-Reply	1
However, we did not find any works that attempt the same problem with a similar model.	Reply	I-Reply	1
It is possible we are unaware of related work, it would be helpful if the reviewer can give some references so that we can investigate further.	Reply	I-Reply	1
Most of the work on zero-shot in speech community that we found only identified ‚Äúsimilar‚Äù speech concepts or sounds, but could not ground them to phone labels making it hard to do speech recognition.	Reply	I-Reply	1
Similarly, the idea of decomposing sounds into articulatory features is old, but our work presents the first approach that actually decomposes sounds into ‚Äúuniversal‚Äù articulatory features and recognizes speech in unseen languages using such representations.	Reply	I-Reply	1
[line_break_token][line_break_token]As we mentioned to AnonReviewer1, we agree that our baseline model has too high a phone error rate to be usable in practice.	Reply	I-Reply	2
Unfortunately this is what the current CTC acoustic models provide for the task of zero-shot speech recognition.	Reply	I-Reply	2
Both the baseline and UPM models had practical and competitive phoneme error rate in the test data of the 3 english datasets that were used during training.	Reply	I-Reply	2
However, we do believe that some of the performance reduction when using this model cross-lingually and cross-domain could because our input features are not robust against acoustic domain mismatch.	Reply	I-Reply	2
We are currently re-running the experiments with a new set of input features proposed in [1], and first results indicate that we can get even better improvements in the same settings, and on top of a much improved baseline.	Reply	I-Reply	2
We believe this is due to the stronger (noise robust and domain invariant) overall baseline allowing for a better sharing of the linguistically informative information across languages, and we are working towards applying this idea to all the experiments including baseline, so that an updated version of the paper will again be consistent.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]We do agree that a better universal phoneme recognizer can be built by training on even more languages.	Reply	I-Reply	4
But we believe that our experiments show that problem we want to address here, specifically the ability to predict unseen phonemes, in a zero-shot speech recognition scenario, can be tackled with the proposed method.	Reply	I-Reply	4
Using more training languages would reduce appearance of unknown phonemes, but there will still almost always be at least a few unseen phones, which we show our model is effective in reducing..[line_break_token][line_break_token][1] S.Dalmia, X. Li, F. Metze and AW Black, ‚ÄúDomain Robust Feature Extraction for Rapid Low Resource ASR Development‚Äù, in Proc SLT 2018, <a href="https://arxiv.org/pdf/1807.10984.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1807.10984.pdf</a>	Reply	O	0

To improve the robustness of neural networks under various conditions, this paper proposes a new regularizer defined on the graph of the training examples, which penalizes the large similarities between representations belonging to different classes, thus increase the stability of the transformations defined by each layer of the network.	Review	O	0
[line_break_token][line_break_token]The paper is overall well written, and the idea involving the Laplacian of the similarity graph is interesting.	Review	O	0
I have reviewed this paper before.	Review	O	0
Compared to the previous version, this paper made a good improvement in its experimental results, by adding two different robustness settings in section 4.1 and section 4.3, and also include DeepFool as a strong attack method for testing adversarial robustness.	Review	O	0
[line_break_token][line_break_token]However, my main concern about the paper is still about its significance.	Review	O	0
[line_break_token]1.	Review	O	0
It is still not clear why would this regularization help robustness especially when considering adversarial examples.	Review	B-Review	1
Example 1 seems not obvious to me why maintaining the boundary margin (rather than expanding or shrinking) is preferred.	Review	I-Review	1
As stated in the second paragraph in section 3.4, ‚Äúlower value of \sigma^\ell(s) are indicative of better separation between classes‚Äù, what is the reason of not directly penalizing this value, rather than requesting a ‚Äústability‚Äù property on this value?	Review	I-Review	1
How is this stability related to the robustness?	Review	I-Review	1
This would request a deeper analysis and more empirical proofs in the paper.	Review	I-Review	1
[line_break_token]2.	Review	O	0
Experimental results still seem not convincing to me.	Review	B-Review	2
On one hand, based on the reported result, I am not very convincing that the proposed method outperforms Parseval, especially when considering the inconsistent behaviour of ‚ÄúProposed + Parseval‚Äù.	Review	I-Review	2
On the other hand, for adversarial robustness, the authors should have compared to the method of adversarial training as well.	Review	I-Review	2
Beyond that, the authors should also be careful of the gradient masking effect of the proposed method.	Review	I-Review	2
I am not sure if there is some other obvious benchmarks should be included for the other two robustness settings.	Review	I-Review	2
[line_break_token][line_break_token]Other comments:[line_break_token]1.	Review	O	0
Descriptions in the last 3 paragraphs in section 3.2 are not very clear.	Review	B-Review	3
It always took me a while to figure it out every time I read the paper.	Review	I-Review	3
It would be very helpful if the computation process and the discussions can be separated here, maybe with a pseudo-code for computing the regularizer.	Review	I-Review	3
[line_break_token]2.	Review	O	0
On the other hand, while the proposed regularizer can be interpreted in a perspective of the Laplacian of the similarity graph, the third part in Equation (4), that expresses the smoothness as the sum of similarities between different classes, seems more intuitive to me.	Review	B-Review	4
Emphasizing in this interpretation may also help convey the message.	Review	I-Review	4
We would like to thank the reviewer for their comments and suggestions.	Reply	O	0
We greatly appreciate that they acknowledged the paper improved since the last submission.	Reply	O	0
[line_break_token][line_break_token]Regularization and robustness:[line_break_token]To answer the first point, we added a discussion in the supplementary material (see also answer to reviewer 1).	Reply	O	0
In particular, a regularizer that aims at minimizing the quantity would result in dilation in space between examples of distinct classes.	Reply	B-Reply	1
The expected consequence of this would be to transform small variations in the input to large variations in the output, which is the opposite of the desired robustness behavior.	Reply	I-Reply	1
Also, the boundary region would likely fall into a ``stretched'' part of the space, resulting in sharp transitions between classes.	Reply	I-Reply	1
As shown in [Zhang et al 2017], this is not a desirable property as far as the generalization is concerned.	Reply	I-Reply	1
We also added experiments to show the connection between the proposed regularizer and the boundary region.	Reply	I-Reply	1
In Figure~11 of the supplementary material, we draw the average network function decision along segments between two input examples in distinct classes.	Reply	I-Reply	1
As is shown in this figure, the proposed regularizer results in a boundary closer to the middle of the segment, thus yielding better robustness along this axis.	Reply	I-Reply	1
[line_break_token][line_break_token]Experimental results: To better address the significance concerns, we have multiple experiments in the supplementary material to stress the abilities of the proposed method.	Reply	O	0
We tested against another dataset (CIFAR-100) and with new architecture/hyperparameters (WideResnet and standard data augmentation), and in those experiments proposed regularizer was always the most robust (sometimes in combination with Parseval).	Reply	B-Reply	2
Concerning adversarial training, we have tested the proposed regularizer in combination with methods from both [Kurakin 2017,Madry 2018], and the results show that the proposed regularizer is able to increase robustness even when used in combination with adversarial training.	Reply	I-Reply	2
[line_break_token][line_break_token]Gradient Masking: Experiments with Gaussian noise can be seen as evidence that the robustness of our proposed method is not due only to gradient masking (since Gaussian noise is added without knowledge of the gradients).	Reply	O	0
We also added black box tests, where the attacks are generated on a network trained using a distinct method from the one it is used upon, to the supplementary material.	Reply	B-Reply	2
We obtained that for all sources, the most robust target network was the one that combined the proposed regularizer with Parseval, proving that the obtained results are not solely due to gradient masking, but to the increased robustness due to the use of the regularizer.	Reply	I-Reply	2
[line_break_token][line_break_token]Pseudo-code: In regards to pseudo-code, we will be adding one to the additional material and we are willing to share the code as soon as the review process is over, as we think that is the easiest way to explain the method and increase reproducibility.	Reply	O	0
About presentation, we added a paragraph after Equation (4) to ease readability: ``In this paper we are particularly interested in smoothness of the label signals.	Reply	B-Reply	3
We call \emph{label signal} associated with class a binary ) vector whose nonzero coordinates are the ones corresponding to input vectors of class.	Reply	I-Reply	3
In other words, is in class.	Reply	I-Reply	3
Using Equation~(4), we obtain that the smoothness of the label signal is the sum of similarities between examples in distinct classes.	Reply	I-Reply	3
Thus a smoothness of 0 means that examples in distinct classes have 0 similarity.''.	Reply	I-Reply	3
[line_break_token][line_break_token]References:[line_break_token][Kurakin 2017] Kurakin, Alexey, Ian Goodfellow, and Samy Bengio. "	Reply	O	0
Adversarial machine learning at scale."	Reply	O	0
ICLR 2017.	Reply	O	0
[line_break_token][Zhang 2018] Zhang, Hongyi, et al. "	Reply	O	0
mixup: Beyond empirical risk minimization."	Reply	O	0
ICLR 2018.	Reply	O	0
[line_break_token][Madry 2018] Madry, Aleksander, et al. "	Reply	O	0
Towards deep learning models resistant to adversarial attacks."	Reply	O	0
ICLR 2018.	Reply	O	0

The authors propose a model for Click-Through Rate Prediction using a model consisting of an embedding layer, a Transformer stack, a Factorization Machine, and a DNN.	Review	O	0
[line_break_token][line_break_token]I have several major concerns about the submission:[line_break_token]2.	Review	O	0
Relevance: This work is extremely application specific, the application is not relevant to this community.	Review	O	0
[line_break_token]1.	Review	O	0
Clarity and writing: The contributions which are relevant to the ICLR community are not explained well and the paper needs copy-editing for English grammar[line_break_token]4.	Review	O	0
Novelty: While seemingly showing good results on some benchmarks, the model is a mix of many components and it's not clear which components actually improve performance and would be worth further study.	Review	O	0
[line_break_token][line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]Applying the DNN directly on top of the embeddings, and having a parallel stack of Encoder-FM, is not well explained.	Review	O	0
What does it mean that "DNN aims at bit-wise level" if the DNN receives the same embedding features as the encoder, which supposedly "learn[s] at vector wise level"?	Review	B-Review	4
[line_break_token][line_break_token]References to datasets are missing[line_break_token][line_break_token]Ablation study is limited, and has surprising results.	Review	O	0
E.g. even completely removing self-attention barely makes a dent in how well the method compares to other published work, moving it from rank 1 to rank 2.	Review	B-Review	6
Otherwise only small tweaks with even more minor effects are made.	Review	I-Review	6
What about removing e.g. the FM, other major components?	Review	I-Review	6
[line_break_token][line_break_token]The biggest architectural innovations here are the bi-linear attention mechanism and max-pooling self attention.	Review	I-Review	7
They are hard to interpret in this context.	Review	I-Review	7
It's not clear how they would perform in a simpler architecture (e.g. vanilla BERT or Transformer) and in the context of a more standard benchmark.	Review	I-Review	7
That study would have a lot more relevance to this community than the present one.	Review	I-Review	7
[line_break_token]	Review	O	0
e thank the reviewer for the feedback and address the concerns in detail below[line_break_token]1.	Reply	O	0
[tab_token]Relevance to ICLR[line_break_token]Thanks, our paper aims to use the encoder to gain better field feature representation for CTR task, which is relevant to learning representations.	Reply	O	0
[line_break_token]2.	Reply	O	0
[tab_token]The meaning of ‚ÄúDNN learns at bit-wise level.	Reply	O	0
‚Äù[line_break_token]The statement ‚ÄúDNN learns at bit-wise level‚Äù means that DNN learns the feature representation by the linear and non-linear transformation of neurons.	Reply	O	0
The FM learns the inner product of two features, which is a vector-wise level.	Reply	B-Reply	4
[line_break_token]3.	Reply	O	0
[tab_token]Major component study.	Reply	O	0
[line_break_token]Thanks, we have added the ablation study for the main component.	Reply	B-Reply	6
We have removed the FM, DNN to analyze the contribution of FM and DNN in our work.	Reply	I-Reply	6
The results show that the AUC of ‚ÄúDeepEnFM w/o DNN‚Äù is 0.8037 on criteo dataset, which is higher than AutoInt, which demonstrates the effectiveness of our encoder with bilinear and max-pooling method.	Reply	I-Reply	6
Surprisingly, the AUC of  ‚ÄúDeepEnFM w/o FM‚Äù is 0.8059 on criteo dataset, which is very close to the full model(0.8077).	Reply	I-Reply	6
The gap to the full model demonstrates the effect of each component	Reply	I-Reply	6

**Summary of the paper: [line_break_token]The paper proposes an IL method named support-guided adversarial IL (SAIL), which is based on generative adversarial IL (GAIL) (Ho and Ermon, 2016) and random expert distillation (RED) (Wang et al.,	Review	O	0
2019).	Review	B-Review	4
The key idea of SAIL is to construct a reward function by multiplying reward functions learned by GAIL and RED.	Review	O	0
This multiplication yields two benefits; 1) it handles the issue of biased reward in GAIL, since state-action pairs outside the expert‚Äôs support are assigned low reward values.	Review	O	0
2) SAIL‚Äôs reward is more reliable than RED‚Äôs reward for state-action pairs inside the expert‚Äôs support.	Review	O	0
The authors show that SAIL is at least as fast as than GAIL in terms of the sample complexity.	Review	O	0
Experiments on continuous control benchmarks show that SAIL is overall more stable than GAIL.	Review	O	0
[line_break_token][line_break_token]**Rating: [line_break_token]The paper proposes a simple but effective combination of existing methods.	Review	O	0
The proposed method is well motivated and performs well on benchmarks.	Review	O	0
Still, the paper has some issues regarding justification, clarity, and evaluation, which should be addressed (see below).	Review	O	0
I vote for weak acceptance.	Review	O	0
[line_break_token][line_break_token]**Major comments/questions: [line_break_token]- No guarantee of the optimality of the learned policy.	Review	O	0
[line_break_token]Can it be guaranteed that SAIL learns the expert policy? (	Review	B-Review	1
assuming the expert policy is realizable).	Review	I-Review	1
Propositions 1 and 2 show the convergence of the support estimation, but these results are not related to the optimality of a policy learned with the reward function.	Review	I-Review	1
This is an important point for justifying SAIL, since SAIL does not perform distribution matching to learn the expert policy, and it also does not perform IRL to learn the reward function.	Review	I-Review	1
Therefore, SAIL lacks the optimality guarantee from both distribution matching and IRL perspectives.	Review	I-Review	1
Please address and clarify this point.	Review	I-Review	1
[line_break_token][line_break_token]- Clarity in the theoretical analysis.	Review	O	0
[line_break_token]In the theoretical analysis, the paper assumes a rate of GAIL for support estimation.	Review	B-Review	1
This is quite confusing, since GAIL performs distribution matching and does not estimate the support.	Review	I-Review	1
Also, given that r_gail = -log D(s,a), the reward‚Äôs upper-bound (R_gail) is infinity and the bound in Eq. (	Review	I-Review	1
9) is not informative.	Review	I-Review	1
[line_break_token][line_break_token]- The reward r_red is constant at the optimal.	Review	O	0
[line_break_token]Eq. (	Review	B-Review	1
2) and Eq. (	Review	I-Review	3
3) imply that, for state-action pairs from the expert‚Äôs state-action distribution, r_red is constant at the optimal.	Review	I-Review	3
Specifically, the optimal solution of Eq. (	Review	I-Review	3
2) is \hat{\theta} = \theta, which yields to a constant value of r_red(s,a) in Eq. (	Review	I-Review	3
3).	Review	I-Review	3
In this scenario, SAIL is equivalent to GAIL for the expert state-action distribution.	Review	I-Review	3
This means that Eq. (	Review	I-Review	3
2) should not be optimized until optimal, and some early stopping criteria are required.	Review	I-Review	3
Does this scenario (constant value of r_red) occur in the experiments?	Review	I-Review	3
[line_break_token][line_break_token]- IRL baseline methods.	Review	O	0
[line_break_token]The paper should compare SAIL to methods which aim to handle the bias in reward function, e.g., DAC (Kostrikov et al.	Review	B-Review	4
2019).	Review	I-Review	4
While DAC requires the time limit, this time limit is known in the benchmark tasks.	Review	I-Review	4
Also, IRL methods such as AIRL (Fu et al.,	Review	I-Review	4
2018) should be compared, since IRL methods are better than GAIL at handling bias in reward function (Kostrikov et al.	Review	I-Review	4
2019).	Review	I-Review	4
[line_break_token][line_break_token]**Minor comments/questions: [line_break_token]- Typos: "offline RL algorithms" should be "off-policy RL algorithms".	Review	O	0
Line 5 of Algorithm 1 should perform gradient ascent instead of gradient descent.	Review	B-Review	5
An expectation over state-action distribution of expert is missing from Eq. (	Review	I-Review	5
2).	Review	I-Review	5
[line_break_token][line_break_token]- What are the bold numbers in table 1 and 2 indicating?	Review	O	0
Why does the Hopper task have two bold numbers, but the other tasks have only one?	Review	B-Review	2
[line_break_token][line_break_token]--After author response--[line_break_token]I have read the author response and other reviews.	Review	O	0
I thank the authors for including additional experiments.	Review	O	0
However, the authors' arguments regarding optimality do not fully address my comments (see below).	Review	O	0
I will keep the vote of weak acceptance.	Review	O	0
 [line_break_token][line_break_token]The authors argue that "In this asymptotic case, SAIL is equivalent to performing distribution matching via GAIL with the additional *constraint* that candidate distributions need to have the same support of the expert distribution".	Review	O	0
However, the support of the expert distribution may coincide with the entire state-action space, which makes the additional constraint uninformative in the asymptotic case.	Review	B-Review	1
Specifically, the expert distribution coincides with the state-action space when the expert policy has an infinite support (e.g., the expert policy is Gaussian).	Review	I-Review	1
Assuming the asymptotic case, the support estimation in RED will give an indicator function over an entire state-action space, and the support constraint in SAIL is always satisfied.	Review	I-Review	1
In other words, SAIL is exactly equivalent to GAIL in this case.	Review	I-Review	1
For these reasons, the authors' arguments regarding optimality do not fully address my comments.	Review	I-Review	1
I think additional assumptions are required, e.g., the expert policy needs to have a finite support or be deterministic.	Review	I-Review	1
 [line_break_token][line_break_token][line_break_token]	Review	I-Review	1
e thank the reviewer for the constructive feedback.	Reply	O	0
[line_break_token][line_break_token]- Clarification on method justification &amp; theoretical analysis[line_break_token]As the reviewer pointed out, distribution matching does not necessarily imply support estimation (it depends on the metric used for the distribution matching).	Reply	O	0
However, following the intuition in motivating this work, restricting the distribution matching problem to the support of the target distribution (the expert) might help the overall learning.	Reply	B-Reply	1
 In this sense, the results in Prop.	Reply	I-Reply	1
1 and 2 show that, even if GAIL were to perform a very slow support estimation (or no support estimation at all), the distribution matching process would be constrained onto the expert‚Äôs support, thanks to RED.	Reply	I-Reply	1
[line_break_token][line_break_token]In the asymptotic setting, RED converges to an indicator function on the support of the expert policy: r_red(s, a) =1 if (s, a) belongs to the support of the expert policy, and 0 otherwise.	Reply	I-Reply	1
[line_break_token][line_break_token]Therefore, In this asymptotic case, SAIL is equivalent to performing distribution matching via GAIL with the additional *constraint* that candidate distributions need to have the same support of the expert distribution.	Reply	I-Reply	1
Since we are restricting candidate estimators to the support of the target distribution, distribution matching methods (e.g. GAIL) can still be adopted.	Reply	I-Reply	1
[line_break_token][line_break_token]- Clarification on why optimizing Eq.	Reply	O	0
2 doesn‚Äôt recover the \theta and thus render the red reward a constant[line_break_token]The technique of random network distillation was first proposed in (Burda et al.	Reply	O	0
2018), which states that empirically, standard training would converge to a local minimum other than the randomly initialized \theta.	Reply	B-Reply	3
We have similar observations in our experiment, and thus no special treatment (e.g. early stopping) is used.	Reply	I-Reply	3
[line_break_token][line_break_token]- Clarification on additional comparison[line_break_token]We have included a comparison with the absorbing state (AS) technique (Kostrikov et al.	Reply	O	0
2019) in Table 5 from Appendix.	Reply	B-Reply	4
We also run SAIL combined with AS, since the two methods are not mutually exclusive.	Reply	I-Reply	4
[line_break_token][line_break_token]The results are:[line_break_token]Default env[line_break_token]GAIL 258.30¬±28.98 | GAIL+AS  271.46¬±11.90 | SAIL 262.97¬±18.11 | SAIL+AS 270.33¬±15.86[line_break_token]Modified env (renamed as ‚ÄúGoal-terminal‚Äù env in the appendix)[line_break_token]GAIL -7.16¬±31.64 | GAIL+AS 110.22¬±119.25 | SAIL 252.07¬±67.22 | SAIL+AS 258.30¬±20.75[line_break_token][line_break_token]AS improves GAIL significantly in both environments.	Reply	I-Reply	4
In particular, in the default environment, GAIL+AS has performance comparable to (or slightly better than) SAIL.	Reply	I-Reply	4
[line_break_token][line_break_token]However, we also observe that: 1) SAIL+AS either outperforms (or is comparable to) GAIL+AS, showing that the proposed approach is generally more favorable than GAIL.	Reply	I-Reply	4
Also, SAIL+AS has much smaller variance than standard SAIL.	Reply	I-Reply	4
2) In the modified environment, GAIL+AS is unable  to reach the expert‚Äôs performance and suffers from a high variance, even when it improves significantly upon GAIL.	Reply	I-Reply	4
On the contrary, SAIL and SAIL+AS are on-par with the expert.	Reply	I-Reply	4
[line_break_token][line_break_token]To better study the effect of SAIL, we further modified LunarLander to contain no terminal states at all.	Reply	I-Reply	4
We refer to this setting as NoTerm.	Reply	I-Reply	4
Here each episode ends only after a fixed time limit (1000 steps).	Reply	I-Reply	4
In this environment, the absorbing state (AS) method is not applicable.	Reply	I-Reply	4
We obtain the following returns (updated Table 1 in the paper): [line_break_token][line_break_token]GAIL 169.73¬±80.84 | SAIL 256.83¬±20.99[line_break_token][line_break_token]showing that SAIL is significantly more robust than GAIL also in this setting.	Reply	I-Reply	4
[line_break_token][line_break_token]In summary, the results on all variants of LunarLander suggests that AS and SAIL both mitigate the implicit reward bias.	Reply	I-Reply	4
[line_break_token][line_break_token]- On minor points[line_break_token]We thank the reviewer for pointing out the typos, they have been fixed.	Reply	O	0
[line_break_token]The bold font highlights the best performance of each row for ease of reading.	Reply	B-Reply	2
Hopper had 2 because we considered them comparable.	Reply	I-Reply	2
We have updated the paper to remove the additional highlighting.	Reply	I-Reply	2
[line_break_token]	Reply	O	0

This paper proposes to replace the traditional KL term of VAE with the KL between two conditional distributions, which is to equip the model with the ability to address multimodal data.	Review	O	0
Moreover, the paper also extend the model to add an additional network to predict the label from the reconstructed image to enhance the decoder with supervised information.	Review	B-Review	2
[line_break_token][line_break_token]In general, the model is contrived and the  novelty of the paper is incremental.	Review	O	0
Is Eq.	Review	O	0
2 the ELBO of the new model?	Review	O	0
If so, the authors should provide the derivation of the ELBO.	Review	O	0
If not, can you prove the objective is the correct one to be optimized?	Review	O	0
[line_break_token]Moreover, the model is just an trivial extension of VAE and all key techniques are borrowed from existing work (Chen et al.	Review	O	0
2016).	Review	O	0
[line_break_token][line_break_token]The experiments are only conducted on MNIST and Fashion-MNIST, which is not sufficient.	Review	B-Review	1
CIFAT10 should be at least added, and other more challenging benchmarks should also be considered to make the model more solid.	Review	I-Review	1
[line_break_token]	Review	O	0
"The experiments are only conducted on MNIST and Fashion-MNIST, which is not sufficient.	Reply	O	0
CIFAT10 should be at least added, and other more challenging benchmarks should also be considered to make the model more solid."	Reply	O	0
[line_break_token][line_break_token]We accept that it is desirable to include additional data sets (something we are currently working on, but that takes time).	Reply	B-Reply	1
 Clearly if we were, for example, proposing a new classifier then results on MNIST would clearly be inadequate.	Reply	I-Reply	1
 However, for exploring the semantics of latent spaces, MNIST and Fashion-MNIST provide an adequate proof of principle in our judgement.	Reply	I-Reply	1
 We cannot see why the latent space embedding would be very different if we used a data set that is visually more complex.	Reply	I-Reply	1
 It is unclear to us that the CIFAR-10 data set is the best next step as many of the classes in CIFAR10 seem unrelated (ship and horse) so the learnt semantic embedding is likely to be uninteresting.	Reply	I-Reply	1
 CIFAR-100 seems more appropriate, but the relative sparseness of the data makes it big step beyond the MNIST data sets we used.	Reply	I-Reply	1
Moving to such a dataset also would require significant changes to the architecture of the encoder and decoder (they would both likely have to be convolutional to achieve good performance), and it is not obvious that this actually adds much to the main point of our paper (which is to demonstrate that our model learns meaningful latent spaces).	Reply	I-Reply	1
[line_break_token][line_break_token]To conclude we would once again like to thank the reviewer for their time.	Reply	I-Reply	1
In the revised version of the paper, we have addressed the points made by the other reviewers, and hopefully the exposition of the novelty should be even more clear in the revision.	Reply	I-Reply	1
We would be happy to respond to any further questions that might arise.	Reply	I-Reply	1

The authors propose a new CNN architecture and show results on object and speech recognition.	Review	O	0
In particular, they propose a multi-scale CNN module that processes feature maps at various scales.	Review	O	0
They show compelling results on IN and a reduction of compute complexity[line_break_token][line_break_token]Pros:[line_break_token](+) The paper is well written[line_break_token](+) The method is elegant and reproducible[line_break_token](+) Results are compelling and experimentation is thorough[line_break_token]Cons:[line_break_token](-) Transfer to other visual tasks, beyond IN, is missing[line_break_token](-) Memory requirements are not mentioned, besides FLOPs, speed and parameters[line_break_token][line_break_token]Overall, the proposed approach is elegant and clear.	Review	O	0
The impact of the multi-scale module is evident, in terms of FLOPs and performance.	Review	O	0
While their approach performs a little worse than NASNet, both in terms of FLOP efficiency and top1-error, it is simpler and easier to train.	Review	O	0
I'd like for the authors to also discuss memory requirements for training and testing the network.	Review	B-Review	2
[line_break_token][line_break_token]Finally, various papers have appeared over the recent years showing improvements over baselines on ImageNet.	Review	I-Review	1
However, most of these papers are not impactful, because they do not show any impact to other visual tasks, such as detection.	Review	I-Review	1
On the contrary, methods that do transfer get adopted very fast.	Review	I-Review	1
I would be much more convinced of this approach, if the authors showed similar performance gains (both in terms of complexity and metrics) for COCO detection.	Review	I-Review	1
[line_break_token]	Review	O	0
We thank the reviewer for the constructive comments.	Reply	O	0
[line_break_token][line_break_token]- Transfer capability of bLNet:[line_break_token]We used bLNet as a backbone network for feature extraction in the Faster RCNN + FPN detector.	Reply	O	0
[line_break_token]The detection results on PASCAL VOC and COCO datasets are included in Table 10 in Appendix A6.	Reply	B-Reply	1
[line_break_token]Our bLNet achieves comparable or better accuracy than the baseline detectors while reducing FLOPs by about 1.5 times.	Reply	I-Reply	1
[line_break_token]Please refer to Table 10 in Appendix A6 for more detail.	Reply	I-Reply	1
[line_break_token][line_break_token]- Memory requirements of bLNet:[line_break_token]We benchmarked the GPU memory consumption in runtime at both the training and test phases for all the models evaluated in Fig.	Reply	O	0
3.	Reply	B-Reply	2
[line_break_token]The results are shown in Fig.	Reply	I-Reply	2
5 in Appendix A7.	Reply	I-Reply	2
The batch size was set to 8, which is the largest number allowed for NASNet on a P100 GPU card (16 GiB memory).	Reply	I-Reply	2
The image size for any model in this benchmark experiment is the same as that used in the experiment reported in Fig.	Reply	I-Reply	2
3.	Reply	I-Reply	2
For bLNet, the input image size is 224x224 in training and 256x256 in test.	Reply	I-Reply	2
[line_break_token][line_break_token]From Fig.	Reply	I-Reply	2
5, we can see that bLNet is the most memory-efficient for training among all the approaches.	Reply	I-Reply	2
[line_break_token]In test, bL-ResNeXt consumes more memory than inception-resnet-v2 and inception-v4 at the same accuracy, [line_break_token]but bL-SEResNeXt outperforms all the approaches.	Reply	I-Reply	2
Note that NASNet and PNASNet are not memory friendly.	Reply	I-Reply	2
[line_break_token]This is largely because they are trained on a larger image size (331x331) and these models are composed of many layers.	Reply	I-Reply	2

This paper first introduces a method for quantifying to what extent a dataset split exhibits compound (or, alternatively, atom) divergence, where in particular atoms refer to basic structures used by examples in the datasets, and compounds result from compositional rule application to these atoms.	Review	O	0
The paper then proposes to evaluate learners on datasets with maximal compound divergence (but minimal atom divergence) between the train and test portions, as a way of testing whether a model exhibits compositional generalization, and suggests a greedy algorithm for forming datasets with this property.	Review	O	0
In particular, the authors introduce a large automatically generated semantic parsing dataset, which allows for the construction of datasets with these train/test split divergence properties.	Review	O	0
Finally, the authors evaluate three sequence-to-sequence style semantic parsers on the constructed datasets, and they find that they all generalize very poorly on datasets with maximal compound divergence, and that furthermore the compound divergence appears to be anticorrelated with accuracy.	Review	O	0
[line_break_token][line_break_token]This is an interesting and ambitious paper tackling an important problem.	Review	O	0
It is worth noting that the claim that it is the compound divergence that controls the difficulty of generalization (rather than something else, like length) is a substantive one, and the authors do provide evidence of this.	Review	O	0
At the same time, I think the authors could possibly do more to show that the trend in the plots in Figure 2 can't be explained by something else: for example, the authors could show that the length ratios remain constant as the compound divergence is varied.	Review	B-Review	2
 I think it is also not necessarily clear how easily the notion of differing compound distributions generalizes to other types of tasks.	Review	I-Review	3
[line_break_token][line_break_token]Presentation-wise, much of the paper is clear and well written, though I think the discussion of weighted frequency distributions of compounds (top of page 3) could be clarified further, and in particular an example subgraph of a rule application DAG should be highlighted here.	Review	O	0
hank you for reading our paper in depth and for the interesting comments and observations.	Reply	O	0
[line_break_token][line_break_token]Addressing the specific comments in order:[line_break_token][line_break_token]On (other) explanations for the trend between compound divergence and accuracy which we observe in Figure 2 ("show that the length ratios remain constant as the compound divergence is varied"): We did some further specific analysis to show that length variation (as measured by the length ratios) is not a better explanation for the drop in accuracy.	Reply	O	0
We added a paragraph discussing this to the paper in Section 5.2 now.	Reply	B-Reply	2
Also, we had already observed in Table 3 and the discussion that we did not expect the lengths to stay perfectly constant between train and test splits.	Reply	I-Reply	2
Note, however, that the splitting algorithm could be extended in a way that would try to achieve maximum compound divergence while keeping both the atom divergence close to zero and the length distribution constant between the splits.	Reply	I-Reply	2
Here, we focus on the compound divergence as a single measure of compositionality challenge. (	Reply	I-Reply	2
Compare also the discussion in Section 4: "Interestingly, the MCD splits still correlate with the aspects of compositional generalization that are targeted by the other experiments in this table.	Reply	I-Reply	2
As shown in the four right columns of Table 3, for each MCD split, the train set V contains on average shorter examples than the test set W (measured by the ratio of average lengths), and [...].	Reply	I-Reply	2
However, these correlations are less pronounced than for the experiments that specifically target these aspects, and they vary significantly across the different MCD splits.")	Reply	I-Reply	2
[line_break_token][line_break_token]On using the idea of varying compound divergence for other tasks ("not necessarily clear how easily the notion of differing compound distributions generalizes to other types of tasks"): We agree that this is an interesting direction for future work.	Reply	I-Reply	3
For example, we believe that a similar approach may be applicable to visual tasks for which the compounds can be programmatically analyzed, e.g. visual question answering tasks like CLEVR.	Reply	I-Reply	3
We mention this now explicitly in Section 7.	Reply	I-Reply	3
The same way that splits based on lengths or patterns have been used for natural language compositionality analysis, vision tasks have used specific splits for analysis of compositionality e.g. based on color or pairs of objects in images. (	Reply	I-Reply	3
We discuss this in Section 6 to some degree.)	Reply	I-Reply	3
Therefore it seems a reasonable expectation to us that the DBCA approach would also transfer to such tasks.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding the "discussion of weighted frequency distributions of compounds": Thank you for your suggestion to clarify this section.	Reply	O	0
[line_break_token][line_break_token]We have reworded the relevant paragraph to make it more precise.	Reply	B-Reply	1
We have also added illustrative examples of subgraphs in Appendix L.4, together with a more detailed explanation of the weight calculation.	Reply	I-Reply	1
We hope that the more precise presentation and the discussion in the appendix help to clarify this point.	Reply	I-Reply	1

To my knowledge, this paper is probably the first one to apply few-shot learning concept into high-level computer vision tasks.	Review	O	0
In this paper's sense, segmentation.	Review	O	0
It proposes a general framework to few from the very few sample, extract a latent representation z, and apply it to do segmentation on a query.	Review	O	0
Cases of semantic, interactive and video segmentation are applied.	Review	O	0
Experiments are very thorough.	Review	O	0
[line_break_token][line_break_token]We see too many variants of few-shot learning papers on mini-imagenet or omniglot.	Review	O	0
For the reason of applying to high-level segmentation, the paper already deserves an acceptance for the first work.	Review	O	0
I believe this work would inspire many follow-ups in related domain (especially for high-level vision tasks)[line_break_token][line_break_token]Comments:[line_break_token][line_break_token]- what is interactive segmentation?	Review	O	0
I looked through the related work, it just mentioned some previous work without defining or describing it.	Review	B-Review	1
[line_break_token][line_break_token]- z is the network output of g?	Review	O	0
is there any constraint on z?	Review	B-Review	2
Like Gaussian distributions like what z is like in VAE models.	Review	I-Review	2
[line_break_token][line_break_token]	Review	O	0
Thank you for the review and your enthusiasm for applying few-shot learning to richer visual tasks like segmentation!	Reply	O	0
We provide a few clarifications and address the questions listed in your review.	Reply	O	0
Given our response here, we would appreciate it if you could comment further regarding[line_break_token][line_break_token]- novelty with respect to the one existing few-shot segmentation method we cite[line_break_token]- clarity of our figure summarizing interactive segmentation and the other segmentation tasks we address (Figure 2)[line_break_token][line_break_token]We agree that few-shot learning need not be limited to image classification and should address higher-level tasks such as different types of segmentation as we show in this work.	Reply	O	0
We hope that our work inspires more progress on few-shot learning for structured output tasks for which labels are even more costly and scarce than image-level supervision.	Reply	B-Reply	3
[line_break_token][line_break_token]Our work is not the first to consider few-shot learning for structured output, but we do significantly generalize the problem scope and extend the approach.	Reply	I-Reply	3
Shaban et al. (	Reply	I-Reply	3
2017) consider one-shot semantic segmentation.	Reply	I-Reply	3
We consider a wider range of tasks (instance, semantic, and video object segmentation), experiment with varying shot and way (from one-shot to 1000+ shot and 2-20 way) beyond the prior 1-5 shot and fixed 2-way of Shaban et al.,	Reply	I-Reply	3
and propose a novel late fusion architecture (that is faster to update during inference).	Reply	I-Reply	3
[line_break_token][line_break_token]> what is interactive segmentation?	Reply	O	0
[line_break_token][line_break_token]Interactive segmentation is the task of inferring dense segmentation masks from sparse pixel-wise labels within the same image (see middle panel of Figure 2 and our references Kass et al.	Reply	B-Reply	1
1998, Boykov and Jolly 2001, and Xu et al.	Reply	I-Reply	1
2016).	Reply	I-Reply	1
Guided segmentation is our extension to interactive segmentation that can propagate pixel labels across images and not just within images.	Reply	I-Reply	1
Guided segmentation is necessary to (1) cumulatively incorporate labels across inputs to keep improving the segmentation and (2) increase data efficiency by not requiring annotations on every input.	Reply	I-Reply	1
[line_break_token][line_break_token]> is there any constraint on z?	Reply	O	0
Like Gaussian distributions like what z is like in VAE models[line_break_token][line_break_token]z is the latent task encoding extracted by the guide branch g (see Figure 1 and Sections 4 & 4.1).	Reply	O	0
We do not enforce a distribution over z, although this is a possible extension of our work for regularization or sampling diverse segmentations.	Reply	B-Reply	2
We are revising the text to make it clear that there is no constraint on the value of z.	Reply	I-Reply	2

A method is proposed, which learns to reason on physical interactions of different objects (solids like cuboids, tetrahedrons etc.).	Review	O	0
Traditionally in related work the goal is to predict/forecast future observations, correctly predicting (and thus learning) physics.	Review	O	0
This is also the case in this paper, but the authors explicitly state that the target is to evaluate the learned model on downstream tasks requiring a physical understanding of the modelled environment.	Review	O	0
[line_break_token][line_break_token]The main contribution here lies in the fact that no supervision is used for object properties.	Review	O	0
Instead, a mask predictor is trained without supervision, directly connected to the rest of the model, ie.	Review	O	0
to the physics predictor and the output renderer.	Review	O	0
The method involves a planning phase, were different objects are dropped on the scene in the right order, targeting bottom objects first and top objects later.	Review	O	0
The premise here is that predicting the right order of the planning actions requires understanding the physics of the underlying scene.	Review	O	0
[line_break_token][line_break_token]I particularly appreciated the fact, that object instance renderers are combined with a global renderer, which puts individual images together using predicted heatmaps for each object.	Review	O	0
With a particular parametrization, these heatmaps could be related to depth maps allowing correct depth ordering, but depth information has not been explicitly provided during training.	Review	O	0
[line_break_token][line_break_token]Important issues:[line_break_token][line_break_token]One of the biggest concerns is the presentation of the planning algorithm, and more importantly, a proper formalization of what is calculated, and thus a proper justification of this part.	Review	O	0
The whole algorithm is very vaguely described in a series of 4 items on page 4.	Review	B-Review	1
It is intuitively almost clear how these steps are performed, but the exact details are vague.	Review	I-Review	1
At several steps, calculated entities are ‚Äúcompared‚Äù to other entities, but it is never said what this comparison really results in.	Review	I-Review	1
The procedure is reminiscent of particle filtering, in that states (here: actions) are sampled from a distribution and then evaluated through a likelihood function, resulting in resampling.	Review	I-Review	1
However, whereas in particle filtering there is clear probabilistic formalization of all key quantities, in this paper we only have a couple of phrases which describe sampling and ‚Äúcomparisons‚Äù in a vague manner.	Review	I-Review	1
[line_break_token][line_break_token]Since the procedure performs planning by predicting a sequence of actions whose output at the end can be evaluated, thus translated into a reward, I would have also liked a discussion (or at least a remark) why reinforcement learning has not been considered here.	Review	I-Review	2
[line_break_token][line_break_token]I am also concerned by an overclaim of the paper.	Review	I-Review	3
As opposed to what the paper states in various places, the authors really only evaluate the model on video prediction and not on other downstream tasks.	Review	I-Review	3
A single downstream task is very briefly mentioned in the experimental section, but it is only very vaguely described, it is unclear what experiments have been performed and there is no evaluation whatsoever.	Review	I-Review	3
[line_break_token][line_break_token]Open questions:[line_break_token][line_break_token]Why is the proposed method better than one of the oracles?	Review	O	0
[line_break_token][line_break_token]Minor remarks:[line_break_token][line_break_token]It is unclear what we see in image 4, as there is only a single image for each case (=row) and method (=column).	Review	O	0
[line_break_token][line_break_token]The paper is not fully self-contained.	Review	B-Review	6
Several important aspects are only referred to by citing work, e.g. CEM sampling and perceptual loss.	Review	I-Review	6
These are concepts which are easy to explain and which do not take much space.	Review	I-Review	6
They should be added to the paper.	Review	I-Review	6
[line_break_token][line_break_token]A threshold is mentioned in the evaluation section.	Review	I-Review	7
A plot should be given showing the criterion as a function of this threshold, as is standard in, for instance, pose estimation literature.	Review	I-Review	7
[line_break_token][line_break_token]I encourage the authors to use the technical terms ‚Äúunary terms‚Äù and ‚Äúbinary terms‚Äù in the equation in section 2.2.	Review	I-Review	8
This is the way how the community referred to interactions in graphical models for relational reasoning long before deep learning showed up on the horizon, let‚Äôs be consistent with the past.	Review	I-Review	8
[line_break_token][line_break_token]I do not think that the physics module can be reasonable be called a ‚Äúphysics simulator‚Äù as has been done throughout the paper.	Review	I-Review	9
It does not simulate physics, it predicts physics after learning, which is not a simulation.	Review	I-Review	9
[line_break_token][line_break_token]A cube has not been confused with a rectangle, as mentioned in the paper, but with a rectangular cuboid.	Review	I-Review	10
A rectangle is a 2D shape, a rectangular cuboid is a 3D polyhedron.	Review	I-Review	10
[line_break_token]	Review	O	0
Thank you for your feedback and suggestions.	Reply	O	0
We have updated the paper to make the planning algorithm clearer, give short descriptions of CEM and perceptual losses, and incorporate your terminology suggestions (‚Äòrectangular cuboid‚Äô, ‚Äòunary‚Äô, ‚Äòbinary‚Äô, etc).	Reply	B-Reply	1
At the request of other reviewers, we have also tested our approach on a physical Sawyer robot.	Reply	I-Reply	1
The following video gives a qualitative result analogous to Figure 4: [line_break_token]goo.gl/151BT1[line_break_token]These results will be included in the paper in a second revision this week.	Reply	I-Reply	1
Below, we give more details about the current changes.	Reply	I-Reply	1
[line_break_token][line_break_token]-- Evaluation on downstream tasks [line_break_token]Downstream task results were in the original submission (all Figures after 3 and Table 1); we have updated the paper to better differentiate between image prediction results in isolation and the use of our model‚Äôs predictions in a planning procedure to build towers.	Reply	O	0
[line_break_token][line_break_token]Figure 4 shows qualitative results on this building task, and Table 1 gives quantitative results.	Reply	B-Reply	3
Figures 5 and 6 give some analysis of the procedure by which our model selects actions.	Reply	I-Reply	3
Figure 7 briefly shows how our model can be adapted to other physics-based tasks: stacking to maximize height, and building a tower to make a particular block stable.	Reply	I-Reply	3
[line_break_token][line_break_token]-- Planning algorithm[line_break_token]We have added a more precise algorithmic description on page 4 to make the tower-building procedure clearer (Algorithm 1: Planning Procedure).	Reply	O	0
[line_break_token][line_break_token]-- Oracle models[line_break_token]We have added a sentence to the Table 1 caption to explain why O2P2 outperforms Oracle (pixels).	Reply	O	0
The Oracle (pixels) model has access to the true physics simulator which generated the data, but not an object-factorized cost function.	Reply	B-Reply	4
Instead, it uses pixel-wise L2 over the entire image (Section 3.2).	Reply	I-Reply	4
The top row of Figure 4 is illustrative here: the first action taken by Oracle (pixels) was to drop the blue rectangular cuboid in the bottom left to account for both of the blue cubes in the target.	Reply	I-Reply	4
Our model, despite having a worse physics predictor, performs better by virtue of its object factorization.	Reply	I-Reply	4
 [line_break_token][line_break_token]-- Figure 4 clarification[line_break_token]We have updated the caption of Figure 4 and changed some text in the graphic.	Reply	O	0
Figure 4 shows qualitative results on the tower building task described above.	Reply	B-Reply	12
We show four goal images (outlined in green), and the towers built by each of five methods.	Reply	I-Reply	12
This figure has a few utilities:[line_break_token]    1.	Reply	I-Reply	12
It illustrates what our model‚Äôs representations capture well for planning and what they do not.	Reply	I-Reply	12
For example, most mistakes made by our model concern object colors.	Reply	I-Reply	12
This suggests that object positions are more prominently represented by our model‚Äôs representations than color.	Reply	I-Reply	12
[line_break_token]    2.	Reply	I-Reply	12
It shows why an object-factorization is still useful even if one has access to the ‚Äútrue‚Äù physics simulator (as discussed in the previous question).	Reply	I-Reply	12
[line_break_token]    3.	Reply	I-Reply	12
It shows that the types of towers being built in the downstream task are not represented in the training set of the perception, graphics, and physics modules (depicted in Figure 3, where we show reconstruction and prediction results).	Reply	I-Reply	12
The object-factorized predictions allow our model to generalize out of distribution more effectively than an object-agnostic video prediction model (Table 1).	Reply	I-Reply	12
[line_break_token][line_break_token]-- Reinforcement learning baseline[line_break_token]We have found that a PPO agent works poorly on this task, possibly due to the high dimensionality of the observation space (raw images).	Reply	O	0
We will continue to try to get this baseline to work for the next revision, and would be happy to try out any other RL algorithms that the reviewer might suggest.	Reply	B-Reply	13

This paper uses reinforcement learning for automated theorem proving.	Review	O	0
The proposed method aims to generalize the short proofs to longer proofs with similar structure.	Review	O	0
Experiments were run to compare the performance of curriculum learning with the ones without curriculum.	Review	O	0
[line_break_token][line_break_token]Overall the paper attempts to explain clearly the original contribution of the proposed approach, which is using curriculum learning in RL based proof guidance.	Review	O	0
However,  I am not convinced about the how compelling the results are in support of the claim.	Review	B-Review	1
The main arguments to bolster my decision are as follows.	Review	O	0
[line_break_token][line_break_token]I am familiar with RL and curriculum learning but not so much with connection tableau calculus.	Review	B-Review	1
The description given in the paper seems to be insufficient and confusing for readers with limited knowledge in this area.	Review	I-Review	1
A step-by-step explanation with a toy example might have done the job nicely.	Review	I-Review	1
Without such a clear understanding of the calculus, it gets hard to appreciate the merits of the results.	Review	I-Review	1
[line_break_token][line_break_token]Some claims of the paper are not clearly validated by the reported experimental results.	Review	I-Review	2
For example:[line_break_token]- in Table 8, curriculum learning is worse in some cases and better in others.	Review	I-Review	2
What to conclude from such a report?	Review	I-Review	2
[line_break_token]- in experiment 3, curriculum learning tends to find shorter proofs.	Review	O	0
Isn't that contrary to the focus of the paper?	Review	B-Review	4
[line_break_token]- in Table 3, curriculum learning performs lot worse than the other method.	Review	O	0
What is to be inferred from such a report?	Review	B-Review	5
[line_break_token][line_break_token]It would be nice if there was a clear explanation of the role of curriculum in the learning algorithm.	Review	I-Review	3
For example, in Algorithm 1, how is Line 8 helping in overall objective of learning longer proofs?	Review	I-Review	3
If one advances curriculum, one takes lesser number of proof steps according to stored proofs.	Review	I-Review	3
How does that help in the learning?	Review	I-Review	3
Does it imply 'less memorizing' with advancement of curriculum?	Review	I-Review	3
ear Reviewer,[line_break_token]Thank you for your comments.	Reply	O	0
[line_break_token][line_break_token]It is a challenging task to provide a proper introduction to the connection calculus in such a short paper.	Reply	B-Reply	1
However, we did our best to provide illustration on the project webpage <a href="http://bit.ly/site_atpcurr" target="_blank" rel="nofollow">http://bit.ly/site_atpcurr</a> .	Reply	O	0
Here you can find some screencasts and logs that cover few selected problems and include all details of the reasoning.	Reply	B-Reply	1
[line_break_token][line_break_token]The primary role of our curriculum is to provide more training signal to the learner, as well as to allow a priori knowledge to the system through proofs (please see the answer given to Rewiever #3).	Reply	I-Reply	2
Figure 5 in Appendix B illustrates that curriculum learning indeed yields more reward during training.	Reply	I-Reply	2
The upside is that this makes training faster and more stable.	Reply	I-Reply	2
However, the downside of better is training is the risk of overfitting.	Reply	I-Reply	2
We can see our curriculum as a tradeoff between faster training and higher chance of overfitting.	Reply	I-Reply	2
As described in Appendix A, Failure Modes, Stage 3 is very sensitive to overfitting as different proofs of the same problem can yield very different generalization, this is why curriculum can be detrimental.	Reply	I-Reply	2
[line_break_token][line_break_token]RL methods are oftenly biased towards shorter solutions: even if no reward discounting is applied, exploration is more likely to find shorter solutions than longer ones.	Reply	I-Reply	4
This is true with and without curriculum.	Reply	I-Reply	4
What curriculum learning does is to speed up learning once a proof was found.	Reply	I-Reply	4
So it is beneficial if used on some "good" proofs and detrimental if used on "bad" proofs.	Reply	I-Reply	4
Table 3 shows an example of each scenario (Stage 2 and 3).	Reply	I-Reply	4
Assessing the quality of proofs (with respect to generalization) is, we believe, an important research question.	Reply	I-Reply	4
[line_break_token][line_break_token]While our project targets to learn to solve hard problems that require long proofs, given a particular problem, we have no incentive to prefer longer proofs of that problem.	Reply	I-Reply	4
Our only concern during training is to learn how to generalize to other problems.	Reply	I-Reply	4
[line_break_token][line_break_token]The advancement of curriculum is meant to ensure that the system is continuously faced with a "reasonably" hard problem.	Reply	I-Reply	5
Once it becomes easy to finish the proof from a particular state, we make things harder by moving the starting state backwards.	Reply	I-Reply	5
It is only after we have gone through the full curriculum that the system has been exposed to all the states of the proof.	Reply	I-Reply	5
[line_break_token][line_break_token]The reason why we believe our setting is useful for learning long proofs is that we are capable of performing very long rollouts during training time, without facing an exponentially diminishing chance of getting some reward.	Reply	I-Reply	3
The system thus trains on long sequences of proof steps	Reply	I-Reply	3

Summary: This paper proposes a policy optimization framework for Bayesian RL (BPO).	Review	O	0
BPO is based on a Bayesian model-based RL formulation.	Review	O	0
Using a Bayesian approach, it is expected to have better trade-off between exploration and exploitation in RL, and be able to deal with model uncertainty as well.	Review	O	0
Experiments are done on multiple domains consisting both POMDP planning tasks and RL.	Review	O	0
[line_break_token][line_break_token]In general, the paper is well written.	Review	O	0
Related work are thoroughly discussed.	Review	O	0
In my opinion, the proposed idea is a solid combination of existing techniques: Monte-Carlo sampling (step 3), Bayes belief update, and policy gradient in POMDP (G(PO)MDP).	Review	O	0
However, this combination is still worth trying and has been shown to scale to larger problems through the use of deep learning.	Review	O	0
[line_break_token][line_break_token]I have some following major concerns about the paper:[line_break_token][line_break_token]- Root sampling (step 3 in Algorithm 1) would result in sampled models that are fixed in every simulation.	Review	O	0
In a pure nature of Bayes RL, after each update at new observation (step 11: belief update), the model distribution already changes.	Review	B-Review	1
Thus how does this Algorithm can guarantee an optimal solution for BAMDP?	Review	I-Review	1
can the authors have more discussions on this point?	Review	I-Review	1
Does this explain why TRPO (using a mean model) can perform comparably to BPO in Ant?	Review	I-Review	1
[line_break_token][line_break_token]- Belief representation is based on a Bayes filter which requires discretization.	Review	O	0
Finely discretized belief would increase the complexity and computation dramatically with the dimension of the latent space.	Review	B-Review	2
This would result in very slow SIMULATE steps, especially for a long-horizon problem, let alone further computation for BatchPolicyOptimization.	Review	I-Review	2
[line_break_token][line_break_token]- I wonder how TRPO using RNN would perform in this case, instead of using a wrong starting model (an average model)?	Review	O	0
Thank you for your feedback.	Reply	O	0
In addition to the clarification on belief representation (Section 4) and the newly added section on Bayes filter (Section 5), we would like to answer some of the concerns you have raised.	Reply	O	0
[line_break_token][line_break_token]Root sampling results in sampled models that are fixed in every simulation: [line_break_token]This is indeed the correct realization of the BAMDP framework, where the underlying model is fixed but unknown.	Reply	O	0
Our algorithm addresses this by fixing the sampled model for the whole episode.	Reply	B-Reply	1
Since the true model is hidden from the agent, it maintains a belief over the possible models.	Reply	I-Reply	1
After each belief update, the agent‚Äôs belief over the model changes, but the actual underlying model remains the same.	Reply	I-Reply	1
A Bayes-optimal agent learns to act such that the uncertainty in the belief distribution reduces to the degree necessary for maximal long-term reward.	Reply	I-Reply	1
[line_break_token][line_break_token]TRPO on Ant performs well on certain cases but poorly on corner cases.	Reply	I-Reply	1
The reason why BPO seems to have only marginal gain in this case is due to the particular four-legged nature of Ant, which allows a mean-model agent to walk reasonably under small geometric variation.	Reply	I-Reply	1
The visualization of a corner case is added in Figure 4.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Computational complexity of discretization: [line_break_token]We agree that increasing the belief discretization level increases the time required to perform posterior updates at each timestep.	Reply	O	0
Ultimately, this is an implementation detail of the black-box Bayes filter.	Reply	B-Reply	2
However, we have empirically found that fine discretization of the continuous latent state space may be unnecessary: BPO produces high-performing agents even with a coarse discretization.	Reply	I-Reply	2
For MuJuCo problems, we outperform the other baselines with only 25 bins to discretize the latent parameter space.	Reply	I-Reply	2
For the Chain problem, the discretization with 10 bins is as good as or slightly better than 1e2 or 1e3 bins.	Reply	I-Reply	2
This implies two things: 1) our algorithm is robust to approximate beliefs, and 2) the agent only needs the belief to be sufficiently accurate to inform its actions.	Reply	I-Reply	2
Due to these properties, we believe that more computationally-efficient approximate Bayes filters can be used without significantly degrading performance.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]RNN: [line_break_token]As you suggest, a recurrent policy could learn to act with respect to a history of observations.	Reply	O	0
In our case, the history of observation is encoded by the belief, so TRPO in the belief space has as much information as an RNN.	Reply	B-Reply	3
The use of RNN for jointly training the Bayes filter and the policy could certainly be effective, as proposed in (Karkus et al.,	Reply	I-Reply	3
2017).	Reply	I-Reply	3

This work presents an extension of Lazaridou et al.,	Review	O	0
2017 (another ICLR submission) to communication between agents with sequence of symbols.	Review	O	0
Due to the complexity of the problem (generating a sequence of symbols rather than a single symbol), the authors switch from using 1-hot symbols (and thus RL) to using Gumbel-softmax distribution, thus allowing for training the agents in an end-to-end fashion by backprop.	Review	B-Review	2
Similar to Lazaridou et al.,	Review	I-Review	3
they attempt grounding the communication protocol to natural language (at this point it's not entirely clear to me whether the authors trained the sender on caption generation or the receiver on caption retrieval).	Review	O	0
Interestingly, when this happens, the induced communication protocol reflects properties of natural language  (as measured by the omission score) while at the same time decreasing the agents' communication performance (from 95% to 52%).	Review	O	0
[line_break_token][line_break_token]The fact that a very similar paper has already been accepted in the same venue takes away some of the novelty points.	Review	B-Review	1
Moreover, the fact that the communicative success with the grounding task decreases so much hints that the proposed way of grounding is not an effective one (also from the text it's not crustal clear how is the grounding achieved as the KL is measured  between the probability of the messages as produced by the sender and some unspecified p_w(m) distribution).	Review	O	0
Perhaps, the authors need to look into the strength of the regularizer as it seems to be taking over.	Review	B-Review	4
 The analysis of the appendix is really interesting, as well as the point about hierarchical coding.	Review	O	0
[line_break_token][line_break_token]Overall, this is a very intriguing line of research and, as the authors point in the conclusions, many open questions remain.	Review	B-Review	6
That being said, the current work does feel a bit rushed; many parts are not clear (specifically details regarding the grounding part) and the proposed grounding approach doesn't seem to be effective in terms of communication.	Review	I-Review	6
[line_break_token][line_break_token]pros:[line_break_token]- extending the rather limited setup of Lazaridou et al.	Review	O	0
to sequences of symbols, resembling more natural language[line_break_token]- to the best of my knowledge, the use of Gumbel-distribution for text generation is novel[line_break_token][line_break_token]cons:[line_break_token]- lack of clarity, especially in the section about grounding[line_break_token]- proposed grounding method is not effective with regards to communicative success[line_break_token]- rather limited novelty (given the emphasis of the ICLR workshop) as work is direct extension of previous work[line_break_token][line_break_token]	Review	O	0
Thank you very much for your review and feedback.	Reply	O	0
 We would like to comment on a couple of your remarks and clarify points which we think were misunderstood.	Reply	O	0
[line_break_token][line_break_token]> The fact that a very similar paper has already been accepted in the same venue takes away some of the novelty points.	Reply	O	0
[line_break_token][line_break_token]Indeed, the setup is inspired by Lazaridou et al.,	Reply	B-Reply	1
2017.	Reply	I-Reply	1
 Though conceptually it seems natural to go from symbols to sequences of symbols, in practice, it is not straightforward to make such an approach scalable and efficient.	Reply	I-Reply	1
 In fact, though several neural network approaches have been proposed for inducing protocols consisting of single symbols (including Lazaridou et al; see the paper for reference), we believe we are the first to generalize the set-up to sequences of symbols and also to show that using sequences results in more efficient communication than using single symbols.	Reply	I-Reply	1
Also, apart from the setting, our method and that of Lazaridou et al.	Reply	I-Reply	1
are very different.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]> the authors switch from using 1-hot symbols (and thus RL) to using Gumbel-softmax distribution[line_break_token][line_break_token]We would like to emphasize that in the proposed method one-hot symbols are still used during training and testing phases.	Reply	O	0
During training and testing, symbols in messages are generated from Categorical distribution (Gumbel-argmax).	Reply	B-Reply	2
The fact that we have used neither continuous messages nor RL is another aspect which differentiates us from previous work on multi-agent protocol induction.	Reply	I-Reply	2
[line_break_token][line_break_token]> (at this point it's not entirely clear to me whether the authors trained the sender on caption generation or the receiver on caption retrieval)[line_break_token][line_break_token]Indeed, this kind of grounding is possible, but, in the proposed approach, we neither trained the Sender for the caption generation task nor trained the Receiver for caption retrieval.	Reply	O	0
Our grounding process consists of imposing a prior on the communication protocol q(m|t).	Reply	B-Reply	3
Minimizing the Kullback-Leibler divergence from the natural language to the learned protocol KL[q(m|t)||p_NL(m)] favors generated messages to have a high probability according to the distribution p_NL(m) (natural language) but at the same time should have high entropy.	Reply	I-Reply	3
[line_break_token][line_break_token]In other words, though the word ‚Äòred‚Äô may not refer to ‚Äòred‚Äô in the protocol, the goal was to ensure that statistical properties of the protocol are similar to these of the natural language, and see what effect it would have on the communicative success.	Reply	I-Reply	3
  In hindsight, maybe we should not have referred to it as ‚Äògrounding‚Äô, as we now realized it is potentially misleading.	Reply	I-Reply	3
[line_break_token][line_break_token]> Moreover, the fact that the communicative success with the grounding task decreases so much hints that the proposed way of grounding is not an effective one ... Perhaps, the authors need to look into the strength of the regularizer as it seems to be taking over.	Reply	O	0
[line_break_token][line_break_token]In our case, we tested a hypothesis whether favoring ‚Äúnaturalness‚Äù of the protocol makes it more efficient.	Reply	B-Reply	4
It turns out the answer is no.	Reply	I-Reply	4
Also, we tested, whether agents would start using, e.g., nouns as nouns, adjectives as adjectives, without us imposing stricter forms of supervision (e.g. training the Sender for caption generation).	Reply	I-Reply	4
[line_break_token][line_break_token]It worth mentioning that Imaginet establishes an upper bound for any communication protocol that looks like a language from the MSCOCO dataset.	Reply	I-Reply	4
Any protocol that will obey the proposed KL constraint (will look like MSCOCO language) will have worse performance than the Imaginet model or equal.	Reply	I-Reply	4
Proposed model has comparable performance to the upper bound (Imaginet).	Reply	I-Reply	4
[line_break_token][line_break_token]By decreasing the impact of the KL regularizer, the communication protocol will less resemble natural language, and that contradicts the goal of the grounding process.	Reply	I-Reply	4
Also, one should bear in mind that MSCOCO descriptions were not generated for the referential game, that is why they can be not very discriminative.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]> ... the KL is measured  between the probability of the messages as produced by the sender and some unspecified p_w(m) distribution)[line_break_token][line_break_token]As we mentioned in the extended abstract,  we used an estimated language model p_œâ(m).	Reply	O	0
We implemented p_œâ(m) as an LSTM language model.	Reply	B-Reply	5
We used image captions of randomly selected (50%) images from the training set to estimate parameters of the language model.	Reply	I-Reply	5
It is worth mentioning that these images were not used for training the Sender and the Receiver.	Reply	I-Reply	5
Unfortunately, given the 3-page constraint on the extended abstract, we could not describe all the details of the set-up.	Reply	I-Reply	5
[line_break_token]	Reply	O	0

This paper presents a method for generating 3D objects.	Review	O	0
They train a VAE to generate voxel occupancy grids.	Review	O	0
Then, they allow a user to generate novel shapes using the learned model by combining latent codes from existing examples.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The idea of linking affordances to 3D object generation is interesting, and relevant to the machine learning and computer vision communities.	Review	O	0
[line_break_token][line_break_token]- They propose to evaluate the quality of the shape based on a physical simulation (Section 4.4.3), which is an interesting idea.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- This paper is not well written.	Review	O	0
The method is described in too much detail, and the extra length (10 pages) is unnecessary.	Review	B-Review	1
Cross entropy, VAEs, and many of the CNN details can usually just be cited, instead of being described to the reader.	Review	I-Review	1
[line_break_token][line_break_token]- The paper uses suggestive terminology, like "functional essence" and "functional arithmetic" for concepts that are fairly mundane (see Lipton and Steinhardt, 2018 for an extended discussion of this issue).	Review	O	0
For example, the "functional essence" of a class is essentially an average of the VAE latent vectors (Section 3.3.1).	Review	B-Review	2
The paper claims, without sufficient explanation, that this is computation is motivated by the idea that "form follows function".	Review	I-Review	3
[line_break_token][line_break_token]- The results are not very impressive.	Review	O	0
There is no rigorous evaluation.	Review	B-Review	4
They propose several nice metrics to use (eg.	Review	I-Review	4
affordance simulation), but the results they present for each metric are quite limited.	Review	I-Review	4
The qualitative results are also not particularly compelling.	Review	I-Review	4
[line_break_token][line_break_token]- The paper should more thoroughly evaluate the importance weighting that is described in Section 3.3.2.	Review	O	0
[line_break_token][line_break_token] - The technical approach (combining VAE vectors to make new shapes) is not particularly novel[[line_break_token][line_break_token]Overall:[line_break_token][line_break_token]The paper should not be accepted in its current form, both due to the confusing writing, and the lack of careful evaluation.	Review	O	0
[line_break_token]	Review	O	0
Thank you for the time you took to review our paper.	Reply	O	0
[line_break_token]We appreciate the reviewer's insight in summarising our paper and addressing the main points.	Reply	O	0
[line_break_token][line_break_token]Following your remarks, we have reorganised the article, extruding and placing the part about the neural network architecture into an appendix.	Reply	B-Reply	1
[line_break_token][line_break_token]Regarding the first concern on the structure of the paper, the initial purpose of describing the details of the architecture was to make the paper self-sufficient.	Reply	I-Reply	1
However, according with the feedback we received from the community, we agree with the reviewer that some details are verbose.	Reply	I-Reply	1
The part on the neural network architecture was removed from the main body of the paper, and left for an optional appendix.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the second concern on the employed terminology, we re-read the paper by Lipton and Steinhardt, and renamed the term "functional essence" into "functional form" of an object.	Reply	I-Reply	2
[line_break_token]We preferred this term, as it denotes the purpose of this operation.	Reply	I-Reply	2
[line_break_token]We also did not name it "averaging of latent vectors" because there  may be multiple methods for extracting this "functional form" (one is presented by us, another one from [2] is cited).	Reply	I-Reply	2
[line_break_token]We thus preferred to use the term "functional form extraction" for a family of algorithms performing this task.	Reply	I-Reply	2
[line_break_token][line_break_token]The term "functional arithmetic" makes use of the analogy with the term "shape arithmetic" [1]. Following this parallel, we manipulate latent vectors corresponding to _functionalities_ (as opposed to _shapes_ in the cited reference).	Reply	I-Reply	2
Thus, we argue to maintain this term.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding the computations being motivated by the idea "form follows function":[line_break_token]We follow the principle form follows function, and assume that the form of an object is correlated to its function.	Reply	I-Reply	3
Moreover, since we extract shape features from a dataset of objects designed by humans for humans, it is reasonable to assume that the employed shapes are close to optimal for performing their intended function.	Reply	I-Reply	3
We included this mention in the paper.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding the third concern on the results:[line_break_token]We would like to point out that (to the best of our knowledge) there are no alternative methods for shape generation conditioned on desired functionalities.	Reply	I-Reply	4
[line_break_token]Hence, it would be misleading to state that they are not at the level of the state-of-the-art.	Reply	I-Reply	4
[line_break_token][line_break_token]As this research is based on exploring new concepts, detailed quality of the reconstructions is not the major contribution of our work.	Reply	I-Reply	4
Rather, we try to formulate a new problem for generating shapes based on functionalities.	Reply	I-Reply	4
For instance, the generated bathtub-workdesk does provide the desired functionalities, but its aesthetics should improve with further research.	Reply	I-Reply	4
[line_break_token][line_break_token]Regarding the evaluation of the importance weighting described in Section 3.3.2, we added images of the combination of toilet and bathtub functional forms, to show the interpolation spectrum (see Fig.	Reply	I-Reply	5
11 in the Appendix).	Reply	I-Reply	5
[line_break_token]We admit that a rigorous evaluation would have required an evaluation of all the shapes generated using different combination parameters, in order to choose the parameters that consistently provide best results.	Reply	I-Reply	5
This will become meaningful once we will have a bigger set of affordance/functionality tests.	Reply	I-Reply	5
[line_break_token]For the moment, we decided to view this multitude of solutions as design proposals, leaving the final choice for the human designer.	Reply	I-Reply	5
[line_break_token]Hopefully, these new additions brought the paper closer to the desired rigour standard.	Reply	I-Reply	5
[line_break_token][line_break_token]Regarding the remaining concerns:[line_break_token]Indeed, the employed architecture is not conceptually novel (it is still a 3D autoencoder).	Reply	I-Reply	6
However, the same paper by Lipton and Steinhardt [3] mentioned above also states that "empirical advances often come about [...] through clever problem formulations [...] or by applying existing methods to interesting new tasks."	Reply	I-Reply	6
We consider the formulation of the problem of shape design conditioned on desired functionalities/affordances valuable in itself.	Reply	I-Reply	6
[line_break_token][line_break_token]To summarise, we used the advice from the reviewers and revised accordingly the paper (changes are highlighted in yellow).	Reply	O	0
We hope that the quality of the writing has improved.	Reply	O	0
[line_break_token][line_break_token]Thank you again for the time invested into this review.	Reply	O	0
[line_break_token][line_break_token]References:[line_break_token][1] Jiajun Wu, Chengkai Zhang, Tianfan Xue, Bill Freeman, and Josh Tenenbaum.	Reply	O	0
Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling.	Reply	O	0
[line_break_token]In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett (eds.),	Reply	O	0
Advances in Neural Information Processing Systems 29, pp.	Reply	O	0
82‚Äì90.	Reply	O	0
Curran Associates, Inc., 2016.	Reply	O	0
[line_break_token][line_break_token][2] Larsen, Anders Boesen Lindbo, et al. "	Reply	O	0
Autoencoding beyond pixels using a learned similarity metric."	Reply	O	0
arXiv preprint arXiv:1512.09300 (2015).	Reply	O	0
[line_break_token][line_break_token][3] Lipton, Zachary C., and Jacob Steinhardt. "	Reply	O	0
Troubling trends in machine learning scholarship."	Reply	O	0
arXiv preprint arXiv:1807.03341 (2018)	Reply	O	0

The authors apply linear time subset scanning to find groups of anomalous inputs and network activations.	Review	O	0
They further use this method to detect effects of the same adversarial perturbation algorithm over a set of images.	Review	O	0
[line_break_token]Major comments:[line_break_token]Overall this is quite interesting work, and seems like a promising method to detect groups of anomalies.	Review	O	0
However, this work is not complete without comparison to existing methods, the lack of which makes it impossible to evaluate its usefulness.	Review	B-Review	1
See [1,2].[line_break_token][line_break_token]Minor questions/comments:[line_break_token]The results seem to be applied to ReLU activation networks and anomalous signals are described as having higher activation that the background or the clean images.	Review	O	0
Could you clear up whether this method works for all activations or just ReLU networks?	Review	B-Review	2
[line_break_token]I‚Äôm envisioning a case where the anomalous images are all anomalous because they are all very similar.	Review	I-Review	3
If I put 100 of the same (or very similar images) would this be something that this method could detect?	Review	I-Review	3
[line_break_token]Your results seem to suggest that adversarial perturbation methods produce adversarial images with activations that are more extreme than natural images.	Review	I-Review	4
This doesn‚Äôt seem immediately obvious to me and I would be interested in further exploration of this direction.	Review	I-Review	4
[line_break_token]A value of \epsilon=0.02 was used in experiments for BIM.	Review	I-Review	5
While I agree that smaller values of \epsilon are harder to detect it would be useful to have an evaluation of performance over smaller values of \epsilon even if these did not perform as well.	Review	I-Review	5
[line_break_token][1] Xiong, L., P ÃÅoczos, B., Schneider, J., Connolly, A., VanderPlas, J.: Hierarchical probabilistic models for group anomaly detection.	Review	O	0
In: AISTATS 2011 (2011)[line_break_token][2] Chalapathy R., Toth E., Chawla S. (2019) Group Anomaly Detection Using Deep Generative Models.	Review	O	0
In: ECML PKDD 2018.	Review	O	0
Lecture Notes in Computer Science, vol 11051.	Review	O	0
Springer, Cham	Review	O	0
hank you for bringing this piece to our attention.	Reply	B-Reply	1
 Chalapathy R., Toth E., Chawla S. (2019) Group Anomaly Detection Using Deep Generative Models.	Reply	I-Reply	1
  A quick review does seem to show a similar philosophy in the goal of detecting patterns that persist across multiple images/inputs.	Reply	I-Reply	1
  Future work will consider this in direct comparisons due to their ability to also scale to groups.	Reply	I-Reply	1
 [line_break_token][line_break_token]ReLu is actually trickier than sigmoid and tanh in this regard and that is because it is difficult for an activation to be anomalously 'low' due to the large prevalence of '0' activations.	Reply	O	0
 Therefore we only considered anomalously 'high' activations.	Reply	B-Reply	2
 (The difference is simply defining a left or right tailed pvalues).	Reply	I-Reply	2
  With sigmoid and tanh it is possible to define anomalous in either direction (i.e. 2 tailed pvalues).	Reply	I-Reply	2
 However, we felt that relu seems to be the most common activation function and did not want give the impression that a user's  model would have to be retrained before being 'scannable'.	Reply	I-Reply	2
 [line_break_token][line_break_token]We briefly considered scanning over 'pre-relu' activations which does have a notion of some activations being more negative than others.	Reply	I-Reply	2
 This did not help detection performance.	Reply	I-Reply	2
 We suspect its because in terms of propagating information through the network, a severely negative activation (pre-relu) is no different than a barely negative one (post-relu).	Reply	I-Reply	2
 In short, scanning for larger than expected values on post-relu activations was the best balance for direct explanations of the overall process.	Reply	I-Reply	2
 [line_break_token][line_break_token]Excellent question on performance whether an anomalous pattern would be detected by a dominant class of the same image type (and all clean examples).	Reply	O	0
 We did not consider that.	Reply	B-Reply	3
 Our clean images in the test sets were always constructed with a uniform sampling from the larger group of images.	Reply	I-Reply	3
 This means that each class would've been equally represented.	Reply	I-Reply	3
 We suspect the correct way to explore this would be through evaluating the role that alpha_max plays.	Reply	I-Reply	3
 We currently have an agnostic role of alpha_max by leaving it at 0.5.	Reply	I-Reply	3
 By decreasing this value we would be giving preference to a smaller number of nodes that produce more extreme (smaller pvalue) activations.	Reply	I-Reply	3
  This parameterization would likely downplay the role of the scenario you described.	Reply	I-Reply	3
 In fact, we currently estimate that an alpha_max value of 0.5 is too high.	Reply	I-Reply	3
 A smaller value may potentially decrease recall, but drastically increase precision.	Reply	I-Reply	3
 This type of question is easily addressed if we wish to go into supervised detection.	Reply	I-Reply	3
 However, at that point the more interesting question is which layers provide the best detection power.	Reply	I-Reply	3
[line_break_token][line_break_token]Re: Noised examples producing more extreme activations than clean ones.	Reply	O	0
 Other work in this space <a href="https://arxiv.org/pdf/1810.08676.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1810.08676.pdf</a> considers detection power over multiple layers of a smaller, simpler network.	Reply	O	0
  Detection power varies across layers and, critically to your point, in some layers the noised examples produced much more 'boring' activations than clean ones.	Reply	B-Reply	4
 This is noted by a AUC value &lt;&lt; 0.5.	Reply	O	0
 The authors of that piece propose that adversarial noise is running 'interference' by removing the signal normally present in clean images.	Reply	B-Reply	4
Once that signal is removed, a new label assignment can be made trivially.	Reply	I-Reply	4
   The current work under review only considers the final convolution layer for scanning.	Reply	I-Reply	4
  It is possible that other layers provide higher detection results, or as shown in the arxiv piece, some layers may appear 'hollow' for noised images.	Reply	I-Reply	4

The paper studies a phenomenon of unusual memorisation in deep overparametrized neural networks.	Review	O	0
[line_break_token]Authors observe that, if an auto-encoder overfits to machine precision on a number of images, they can be reliably decoded from random noise and that it is even possible to memorise this way a sequence of images.	Review	O	0
[line_break_token]Essentially, images from such a training set become attractors for the mapping defined by the auto-encoder.	Review	O	0
[line_break_token]The impact of network size, nonlinearity and initialization is studied and, quite surprisingly, very unusual trigonometric non-linearities performed the best.	Review	O	0
[line_break_token][line_break_token]I find the studied phenomenon rather interesting and the analysis well-performed, but I am not sure how practically important is this work.	Review	B-Review	2
[line_break_token]First, I would argue that to call the overfit auto-encoder a function associative memory, it must be able to retrieve stored images not just from random noise, but from a somehow distorted or partially known version.	Review	I-Review	2
[line_break_token]Otherwise we are just left with a ridiculously large network that can only recall a handful of images we could store in the raw format using much less numbers.	Review	I-Review	2
[line_break_token]Second, training until convergence takes prohibitively long time.	Review	I-Review	3
[line_break_token][line_break_token]I would be also interested to at least an interesting discussion, if not an answer, to the question of why and how exactly trained images become attractors.	Review	I-Review	3
[line_break_token][line_break_token]In terms of novelty, it feels like Zhang et al, 2019 already studied a very similar phenomenon and the submitted paper does not add much to understanding of memorisation in neural networks.	Review	I-Review	1
However, memorization of sequences was indeed a surprise.	Review	I-Review	1
[line_break_token][line_break_token]Overall, I do not have a strong opinion on rejecting the paper, it just feels like more work in this direction will make the paper significantly better.	Review	O	0
e thank the reviewer for the comments and  emphasizing that the phenomenon we identify is interesting and that our analysis is well performed.	Reply	O	0
 [line_break_token][line_break_token]Regarding the comparison to Zhang et al, 2019:  We would like to point out that the first arXiv version of our paper precedes the first version of Zhang, et al.	Reply	O	0
Just like our paper, Zhang, et al has only been presented in a workshop, which does not count as a refereed publication.	Reply	B-Reply	1
 Furthermore, a version of Zhang, et al is concurrently under review in this same venue.	Reply	I-Reply	1
  Therefore, we strongly feel that our paper should be reviewed on its own merits and not compared against Zhang, et al.	Reply	I-Reply	1
[line_break_token][line_break_token]In terms of the importance of this result, our method is the first for training a model to store and recover high dimensional inputs up to numerical precision.	Reply	I-Reply	2
Moreover, there is considerable interest in understanding the similarities and differences in artificial neural networks and biological neural networks.	Reply	I-Reply	2
Our results point to a biologically plausible mechanism for memory retrieval (while the biological plausibility of the training process still remains an open question).	Reply	I-Reply	2
Namely, we show that iterating a trained autoencoder allows retrieving stored images.	Reply	I-Reply	2
 Our results also suggest an interesting hypothesis for biological neural networks, which we are currently following up on with neuroscientists.	Reply	I-Reply	2
We demonstrated that it is ‚Äúeasier‚Äù for an artificial neural network to store sequences of images instead of individual images, or more precisely, smaller networks can be used to store sequences of images as compared to the same number of single images.	Reply	I-Reply	2
Similar phenomena may be observed in biological neural networks.	Reply	I-Reply	2
 [line_break_token][line_break_token]Moreover, a question of considerable interest in machine learning is the identification of the inductive bias of neural networks.	Reply	O	0
In the overparameterized setting, a neural network can achieve zero training error.	Reply	B-Reply	3
There are many different functions that can achieve zero training error.	Reply	I-Reply	3
What are the functions learned by a neural network, i.e. what is its inductive bias?	Reply	I-Reply	3
Our study identifies a novel form of inductive bias of deep networks that persists across different architectures: deeper networks tend to store training examples as attractors.	Reply	I-Reply	3
This means that deep networks learn functions that are contractive at the training examples, a form of self-regularization.	Reply	I-Reply	3
[line_break_token][line_break_token]By the definition of an attractor, iterating the network on points within an open set around an attractor will converge to the attractor.	Reply	I-Reply	3
 Hence, the model does represent associative memory as small perturbations to an attractor (i.e. a point within this open set) will converge to the attractor upon iterating the network.	Reply	I-Reply	3
 Importantly, this condition is a mathematical guarantee for associative memory.	Reply	I-Reply	3
 Hence, the networks learned do implement associative memory mechanisms with mathematically verifiable conditions on which training examples are attractors.	Reply	I-Reply	3
 We will add some experiments to highlight this in the revision.	Reply	I-Reply	3
 	Reply	I-Reply	1

I have read the authors response.	Review	O	0
In the response the authors clarified the contributions of this paper.	Review	O	0
I agree with the authors that the analysis of gradient descent-ascent is a difficult problem, and the optimization results given in this paper is a contribution of importance.	Review	O	0
Because of this I have improved my score.	Review	O	0
[line_break_token][line_break_token]However, I do not agree with the authors that studying quadratic discriminators instead of more complicated ones should be considered as a contribution instead of drawback.	Review	B-Review	1
In my opinion, as long as the focus is on WGAN, results involving standard neural networks are still more desired compared with the results in this submission.	Review	I-Review	1
For example, similar results for a neural network discriminator might be even more impactful, because the optimization problem is even more difficult.	Review	I-Review	1
Therefore I still consider the simple discriminator and generator as a weak point of this paper.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]======================================================================================================[line_break_token][line_break_token]This paper studies the training of WGANs with stochastic gradient descent.	Review	O	0
The authors show that for one-layer generator network and quadratic discriminator, if the target distribution is modeled by a teacher network same as the generator, then stochastic gradient descent-ascent can learn this target distribution in polynomial time.	Review	O	0
The authors also provide sample complexity results.	Review	O	0
[line_break_token][line_break_token]The paper is well-written and the theoretical analysis seems to be valid and complete.	Review	O	0
However, I think the WGANs studied in this paper are simplified too much that the analysis can no longer capture the true nature of WGAN training.	Review	B-Review	2
[line_break_token][line_break_token]First, the paper only studies linear and quadratic discriminators.	Review	I-Review	3
This is not very consistent with the original intuition of WGAN, which is to use the worst Lipschitz continuous neural network to approximate the worst function in the set of all Lipschitz continuous functions in the definition of Wasserstein distance.	Review	I-Review	3
When the discriminator is as simple as linear or quadratic functions, there is pretty much no ‚ÄúWasserstein‚Äù in the optimization problem.	Review	I-Review	3
[line_break_token][line_break_token]Moreover, the claim that SGD learns one-layer networks can be very misleading.	Review	I-Review	4
In fact what is a ‚Äúone-layer‚Äù neural network?	Review	I-Review	4
[line_break_token]- if the authors meant ‚Äútwo-layer network‚Äù or ‚Äúsingle hidden layer network‚Äù, then this is not true.	Review	I-Review	4
Because as far as I can tell, the model is much more difficult than the model.	Review	I-Review	4
The former is a standard single hidden layer network which is non-convex, while the latter is essentially a linear model especially when \phi is known.	Review	I-Review	4
[line_break_token]- if the authors meant ‚Äúa linear model with elementwise monotonic transform‚Äù, then I would like to suggest that a more appropriate name should be used to avoid unnecessary confusion.	Review	I-Review	4
[line_break_token][line_break_token]As previously mentioned, the discriminators are too simple to approximate the Wasserstein distance, and therefore in general it should not be possible to guarantee recovery of the true data distribution.	Review	I-Review	5
However, in this paper it is still shown that certain true distributions can be learned.	Review	I-Review	5
This is due to the extremely simplified true model.	Review	I-Review	5
In fact, even if the activation function is unknown, it seems that one can still learn well (for example, by Kendall‚Äôs tau).	Review	I-Review	5
[line_break_token]	Review	O	0
hank you for your reviews.	Reply	O	0
Unfortunately there is a significant misunderstanding of our contributions.	Reply	O	0
We will try to clarify some concerns here and hope it will justify our contributions more clearly.	Reply	O	0
[line_break_token][line_break_token]We want to emphasize our contributions first.	Reply	O	0
[line_break_token]1.	Reply	O	0
To begin with, the global convergence of gradient descent-ascent in the GAN setting has not been extensively studied.	Reply	B-Reply	1
We provide the to show for.	Reply	I-Reply	1
The difficulty in analyzing gradient descent-ascent is twofold: the generator dynamics and discriminator dynamics.	Reply	I-Reply	1
On the discriminator side, our choice of quadratic discriminator not only simplifies the dynamics but also has sufficient discriminating power (we will justify it  below).	Reply	I-Reply	1
On the generator side, its minimization problem is non-convex, and therefore our convergence result to global equilibria is highly non-trivial.	Reply	I-Reply	1
Our primary contribution in gradient descent-ascent analysis is to choose a proper discriminator set and to understand the generator dynamics.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
For the generator class we are considering, we proved the quadratic discriminator both and (see point 3 below).	Reply	B-Reply	1
Had we chosen to use a more complex discriminator, even if the maximization step were tractable, this would increase the sample complexity, potentially to a non-parametric rate (Feizi et al.,	Reply	I-Reply	1
2017; Bai et al.,	Reply	I-Reply	1
2018).	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
Our sample analysis also matches the upper bound of on dependence of the error provided in (Wu et al.,	Reply	B-Reply	1
2019).	Reply	I-Reply	1
This is also a side proof that with WGAN we could via.	Reply	I-Reply	1
[line_break_token][line_break_token]Next we justify our choice of discriminator class.	Reply	O	0
[line_break_token]We want to emphasize that our goal is to show that SGD learns the ground truth generating distribution, with minimal requirements for the discriminator class.	Reply	B-Reply	3
[line_break_token][line_break_token]Our choice of discriminator class, quadratic discriminators, already to learn the family of distributions parametrized by our generator class.	Reply	I-Reply	3
As shown in Theorem 3, the quadratic discriminator class is sufficient to learn the optimal generator.	Reply	I-Reply	3
In fact using a larger discriminator family will only make the learning harder by increasing the sample complexity; see (Feizi et al.,	Reply	I-Reply	3
2017; Bai et al.,	Reply	I-Reply	1
2018) for a discussion of the importance of appropriately constraining the discriminator class to attain parametric sample complexity.	Reply	I-Reply	3
Our choice of small discriminator class is a strength, not a weakness.	Reply	I-Reply	3
[line_break_token][line_break_token]When more complex discriminators are necessary (on studying more complicated generators for future work), we believe the discriminator dynamics can be analyzed using recent developments in the training of neural networks for classification problems (e.g. NTK results).	Reply	I-Reply	3
However, this is not the focus of our paper since we are learning to recover one-layer generator, which does not need a complex discriminator.	Reply	I-Reply	3
[line_break_token][line_break_token]Finally we clarify some other points you‚Äôve raised.	Reply	O	0
[line_break_token]Q: ‚Äúwhat is one-layer generator‚Äù &amp; ‚Äúit can be learned easily‚Äù[line_break_token]A: By one-layer generator we mean the second case as you have suggested.	Reply	O	0
This terminology is also used in some prior work, for instance in (Wu et al.,	Reply	B-Reply	4
2019).	Reply	I-Reply	1
As we have emphasized, our goal is not just to learn the one-layer generator by any method, but to understand the dynamics of gradient descent-ascent with WGAN on learning the distribution.	Reply	I-Reply	4
We also demonstrate the near optimal sample complexity when learning with WGAN.	Reply	I-Reply	4
Even though the generator is a simple formulation, this work still provides the first result on successful learning a non-linear generator with WGAN setting.	Reply	I-Reply	4
[line_break_token][line_break_token]Reference:[line_break_token](Feizi et al.	Reply	O	0
2017) Feizi, S., Farnia, F., Ginart, T., &amp; Tse, D. (2017).	Reply	O	0
Understanding GANs: the LQG setting.	Reply	O	0
arXiv preprint arXiv:1710.10793.	Reply	O	0
[line_break_token](Bai et al.	Reply	O	0
2018) Bai, Y., Ma, T., &amp; Risteski, A. (2018).	Reply	O	0
Approximability of discriminators implies diversity in GANs.	Reply	O	0
arXiv preprint arXiv:1806.10586.	Reply	O	0
[line_break_token](Wu et al.	Reply	B-Reply	1
2019) Wu, S., Dimakis, A. G., &amp; Sanghavi, S, ‚ÄúLearning Distributions Generated by One-Layer ReLU Networks‚Äù, NeurIPS 2019	Reply	O	0

This paper addresses the issue of interpretability of GAN generation through an alternative approach to the introduction of variability.	Review	O	0
To seed the generation, instead of providing a random input vector (typically sampled from a standard Gaussian distribution), the authors instead modify the generator architecture so as to allow for randomization in the routing: each layer is replaced by a bucket consisting of several blocks, and in forward propagation only through randomly chosen blocks.	Review	O	0
In this case, the input vector is chosen to be a constant - the only source of randomization[line_break_token]provided to the generator is in the choice of blocks through which to propagate.	Review	O	0
The explanability derives from the tendency of blocks to associate with a common interpretation after training.	Review	O	0
Their use of blocks necessitates the introduction of a block diversity loss, to discourage mode collapse.	Review	O	0
The scheme is referred to as RPGAN, for "Random Path GAN".	Review	O	0
[line_break_token][line_break_token]The main strengths of the paper:[line_break_token][line_break_token](1) Their proposed approach is highly flexible.	Review	O	0
In principle, any underlying GAN architecture can be adapted by assigning each layer to a distinct bucket, and then replicating the layer across the blocks.	Review	O	0
[line_break_token][line_break_token](2) Experimental results do show that different block sequences are associated with common image characteristics after training, especially for the initial and final layers.	Review	O	0
[line_break_token][line_break_token](3) The use of non-standard ways of introducing stochasticity to GAN generation is an interesting idea in itself.	Review	O	0
[line_break_token][line_break_token]The main weaknesses:[line_break_token][line_break_token](1) Although the authors provide experimental examples showing images associated with various paths through the architecture, is not clear how interpretations can be associated with these paths.	Review	O	0
In the examples presented, there seems to be a tendency for greater interpretability at the initial and final layers, with the explanation given for the intermediate layers being less convincing.	Review	B-Review	1
[line_break_token][line_break_token](2) The number of experimental examples is low, yet the authors draw rather firm conclusions (end of Section 4.1) regarding interpretability across layers.	Review	O	0
I am not sure that their conclusions adequately capture what is going on here, nor am I convinced that they generalize to other situations.	Review	B-Review	2
[line_break_token][line_break_token](3) The number of buckets limits the numbers of explanations.	Review	O	0
Essentially, the method has the same difficulties as in clustering, where specifying too many or too few groups can profoundly influence the nature and quality of the result.	Review	B-Review	3
Although the authors do discuss an approach by which the number of buckets can be incrementally increased (thereby allowing for variation in the number of explanations generated), the experimental evidence is insufficient.	Review	I-Review	3
[line_break_token][line_break_token](4) Presumably, the replication of a layer across the blocks assigned to its bucket would require more training data and/or greater training times.	Review	O	0
What is the relationship in both time and quality between the original GAN network and its RPGAN versions?	Review	B-Review	4
[line_break_token][line_break_token](5) There are many presentational problems with this paper, in grammar, vocabulary and terminology, sentence structure, etc.	Review	O	0
[line_break_token][line_break_token]Overall, in its current state (not least due to presentational issues) the paper appears to be below the acceptance threshold.	Review	O	0
[line_break_token]	Review	O	0
hank you for your time and comments; we address the items from your weaknesses list below.	Reply	O	0
[line_break_token][line_break_token]1) [is not clear how interpretations can be associated with these paths.]	Reply	O	0
[line_break_token]To avoid possible confusion: the interpretations are associated with buckets, not with paths.	Reply	B-Reply	1
Varying active blocks in each bucket we get an understanding of what factors of variations are captured by this bucket.	Reply	I-Reply	1
For instance, in Figure 3, using different blocks in the fourth bucket results in images with the same content but of different colors, which indicates that the fourth bucket is ‚Äúresponsible for‚Äù coloring.	Reply	I-Reply	1
As another example, varying blocks in the first bucket shows that this bucket mostly determines an object location on the image.	Reply	I-Reply	1
[line_break_token][line_break_token](2) [I am not convinced that the conclusions generalize to other situations.]	Reply	O	0
[line_break_token]We do not claim that the layers‚Äô roles identified in the section 4.1 are the same for all datasets and generator architectures.	Reply	B-Reply	2
Moreover, Figure 6 (left) of the original submission demonstrates that on MNIST, the first bucket is responsible for image semantics, while on CIFAR10 semantics is determined by the intermediate buckets.	Reply	I-Reply	2
[line_break_token]However, we argue that the RPGAN tool is general: it allows to analyze the roles of different generator layers on any datasets.	Reply	I-Reply	2
As an addition, we accomplish the RPGAN results with a number of experiments on other domains, model architectures and learning strategies.	Reply	I-Reply	2
Namely, we show that the concept works for DCGAN-like generators trained as Wasserstein-GP GANs on colored MNIST, CIFAR10 and CelebA datasets (see Figures 8, 19, 21).	Reply	I-Reply	2
[line_break_token][line_break_token](3) [The number of buckets limits the numbers of explanations.]	Reply	O	0
[line_break_token]To avoid confusion between \textit{buckets} and \textit{blocks}: each bucket corresponds to the particular generator layer, while different blocks denote different replications of this layer inside the bucket.	Reply	B-Reply	3
The number of buckets hence equals to the number of layers in the generator.	Reply	I-Reply	3
The number of blocks in all our experiments equals 10-40, e.g., see Figure 7.	Reply	I-Reply	3
In all our experiments, a few dozens of images are enough to understand the factors of variations, corresponding to the particular buckets.	Reply	I-Reply	3
[line_break_token][line_break_token](4)[What is the relationship in both time and quality between the original GAN network and its RPGAN versions?]	Reply	O	0
[line_break_token]In all our experiments, we use completely the same training protocols for both RPGAN and the original GAN.	Reply	B-Reply	4
Both models are always trained on the same data, with the same number of steps for generator/discriminator, etc, see the beginning of Section 4.	Reply	I-Reply	4
In terms of wall-clock time, there were no differences in training time for both models on our hardware and the implementations from the code <a href="https://github.com/rpgan-ICLR2020/RPGAN."	Reply	O	0
target="_blank" rel="nofollow">https://github.com/rpgan-ICLR2020/RPGAN.</a>[line_break_token][line_break_token](5) In a new revision, we have largely rewritten the text and expect it to be easier to follow.	Reply	O	0

This paper shows that we can relate the solution of specific autoencoder to the data generating distribution.	Review	O	0
Specifically solving for general reconstruction function with regularizer that is the L2 penalty of reconstruction contraction relates the reconstruction function derivative of the data probability log likelihood.	Review	O	0
This is in the limit of small regularization.	Review	O	0
The paper also shows that in the limit of small penalty this autoencoder is equivalent to denoising autoencoder with small noise.	Review	O	0
[line_break_token][line_break_token]Section 3.2.3: You get similar attractive behavior using almost any autoencoder with limited capacity.	Review	B-Review	1
The point of your work is that with the specific form of regularization - square norm of contraction of r - the r(x)-x relates to derivative of log probability (proof seem to require it - it would be interesting to know what can be said about other regularizers).	Review	I-Review	1
It would be good to compare these plots with other regularizers and show that getting log(p) for contractive one is somehow advantageous.	Review	I-Review	1
Otherwise this section doesn't support this paper in any way.	Review	I-Review	1
[line_break_token][line_break_token]As authors point out, it would be good to know something not in the limit of penalty going to zero.	Review	I-Review	2
At least have some numerical experiments, for example in 1d or 2d.	Review	I-Review	2
[line_break_token][line_break_token]Figure 4. - '	Review	I-Review	3
Top plots are for one model and bottom plots for another' - what are the two models?	Review	I-Review	3
It would be good to specify this in the figure, e.g. denosing autoencoders with different initial conditions and parameter settings.	Review	I-Review	3
[line_break_token][line_break_token]Section 3.2.5 is important and should be written a little more clearly.	Review	I-Review	4
[line_break_token][line_break_token]I would suggest deriving (13) in the appendix directly from (11) without having the reader recall or read about Euler-Lagrange equations, and it might actually turn out to be simpler.	Review	I-Review	5
Differentiating the first term with r(x) gives r(x)-x.	Review	I-Review	5
For the second term one moves the derivative to the other size using integration by parts (and droping the boundary term) and then just applying it to the product p(x)dr/dx resulting in (13).	Review	I-Review	5
[line_break_token][line_break_token]Minor - twice you say in the appending that the proof is in the appendinx (e.g. after statement of theorem 1)[line_break_token][line_break_token]The second last sentence in the abstract is uncomfortable to read.	Review	O	0
[line_break_token][line_break_token]This is probably not important, but can we assume that r given by (11) actually has a taylor expansion in lambda? (	Review	B-Review	9
probably, but in the spirit of prooving things).	Review	I-Review	9
[line_break_token][line_break_token]You don't actually derive formulas the second moments in the appendix like you do for the first moment, you mean they can similarly be derived?	Review	I-Review	6
> It would be good to compare these plots with other regularizers and show that getting log(p) for contractive one is somehow advantageous.	Reply	O	0
[line_break_token][line_break_token]We have worked on the denoising/contracting auto-encoders with squared error because we were able to prove our results with them, but we believe that other regularized auto-encoders (even those with discrete inputs) also estimate something related to the score, i.e., the direction in input space in which probability increases the most.	Reply	B-Reply	1
The intuition behind that statement can be obtained by studying figure 2: the estimation of this direction arises out of the conflict between reconstructing training examples well and making the auto-encoder as constant (regularized) as possible.	Reply	I-Reply	1
[line_break_token][line_break_token]Other regularizers (e.g. cross-entropy) as well as the challenging case of discrete data are in the back of our minds and we would very much like to extend mathematical results to these settings as well.	Reply	I-Reply	1
[line_break_token]We have added a brief discussion in the conclusion about how we believe these results could be extended to models with discrete inputs, following the tracks of ratio matching (Hyvarinen 2007).	Reply	I-Reply	1
[line_break_token][line_break_token]We have also added (in new sec.	Reply	I-Reply	1
3.2.3) a brief discussion of how these new results (on r(x)-x estimating the score) contradict previous interpretations of the reconstruction error of auto-encoders (Ranzato & Hinton NIPS 2007) as being akin to an energy function.	Reply	O	0
Indeed whereas both interpretations agree on having a low reconstruction error at training examples, the score interpretation suggests (and we see it experimentally) other (median) regions that are local maxima of density, where the reconstruction error is also low.	Reply	B-Reply	1
[line_break_token][line_break_token]> it would be good to know something not in the limit of penalty going to zero[line_break_token][line_break_token]We agree.	Reply	O	0
We did a few artificial data experiments.	Reply	B-Reply	2
In fact, we ran the experiment shown in section 3.2.2 using values of lambda ranging from 10^-6 to 10^2 to observe the behavior of the optimal solutions when the penalty factor varies smoothly.	Reply	I-Reply	2
The optimal solution degrades progressively into something comparable to what is shown in Figure 2.	Reply	I-Reply	2
It becomes a series of increasing plateaus matching the density peaks.	Reply	I-Reply	2
Regions of lesser density are used to 'catch up' with the fact that the reconstruction function r(x) should be relatively close to x.[line_break_token][line_break_token][line_break_token]> Figure 4. - '	Reply	O	0
Top plots are for one model and bottom plots for another' - what are the two models?	Reply	O	0
It would be good to specify this in the figure, e.g. denosing autoencoders with different initial conditions and parameter settings.	Reply	O	0
[line_break_token][line_break_token]We have addressed this concern that many of the reviewers had.	Reply	B-Reply	3
The whole section 3.2.3 has been edited and we decided to remove two of the plots which may have introduced confusion.	Reply	I-Reply	3
Reviewers seem to focus on the difference between the two models and wanted to know why the outcomes were different.	Reply	I-Reply	3
They were only different because of the non-convexity of the problem and the dependance on initial conditions (along with the random noise used for training).	Reply	I-Reply	3
At the end of the day, the point is that the vector field points in the direction of the energy gradient, and that is illustrated nicely by the two plots left (far and close distance).	Reply	I-Reply	3
[line_break_token][line_break_token]> Section 3.2.5 is important and should be written a little more clearly.	Reply	O	0
[line_break_token][line_break_token]We have reworked that section (now identified as 3.2.6), to emphasize the main point: whereas Vincent 2011 showed that denoising auto-encoders with a particular form estimated the score, our results extend this to a very large family of estimators (including the non-parametric case).	Reply	B-Reply	4
The section also shows how to interpret Vincent's results so as to show that any auto-encoder whose reconstruction function is a derivative of an energy function can be shown to estimate a score.	Reply	I-Reply	4
Instead, the rest of our paper shows that we achieve an estimator of the score even without that strong constraint on the form of the auto-encoder.	Reply	I-Reply	4
[line_break_token][line_break_token]> I would suggest deriving (13) in the appendix directly from (11) without having the reader recall or read about Euler-Lagrange equations[line_break_token][line_break_token]We must admit to not having understood the hints that you have given us.	Reply	O	0
If indeed there was such a way to, as you say, spare the reader the headaches of Euler-Lagrange, we agree that it would be an interesting approach.	Reply	B-Reply	5
[line_break_token][line_break_token]> You don't actually derive formulas the second moments in the appendix like you do for the first moment, you mean they can similarly be derived?	Reply	O	0
[line_break_token][line_break_token]Yes, an asymptotic expansion can be derived in a similar way for the second moment.	Reply	B-Reply	6
That derivation is 2 to 3 times longer and is not very useful in the context of this paper.	Reply	I-Reply	6
[line_break_token][line_break_token]Please also have a look at a new short section (now identified as 3.2.5) that we just added in	Reply	I-Reply	6

Brief summary of the paper:[line_break_token]This paper studies data-parallel SGD that K processors work together to minimize an objective function.	Review	O	0
Each processor computes a stochastic gradient and broadcasts to other peers.	Review	O	0
In this distributed system, there is a trade-off between the *communication cost* from sharing the stochastic gradient and the *variance* from gradient quantization.	Review	O	0
This paper is a follow-up of Alistarh et al.&nbsp;(2017).	Review	O	0
It proposes a non-uniform (logarithmic) quantization scheme (NUQSGD).	Review	O	0
This paper provides theoretical analysis of the variance and communication cost of NUQSGD.	Review	O	0
Then the paper analyzes the convergence rate of NUQSGD for convex and smooth objective function.	Review	O	0
At the end, this paper empirically evaluates NUQSGD for image classification problem.	Review	O	0
[line_break_token][line_break_token][line_break_token]Originality and significance:[line_break_token]This paper follows up on the parallel SGD framework proposed by Alistarh et al.&nbsp;(2017), where the authors proposed QSGD using a uniform quantization.	Review	O	0
This paper proposes NUQSGD using a non-uniform quantization method.	Review	O	0
The quantization of the stochastic gradient amplifies the stochastic variance, which influences the rate of convergence of SGD.	Review	O	0
Thus, on one hand, it is important to design a quantization method to improve the variance, for the sake of convergence rate.	Review	O	0
On the other hand, it is also important to decrease the communication cost.	Review	O	0
NUQSGD does not provide significant improvements in terms of the variance and communication cost.	Review	B-Review	1
[line_break_token][line_break_token]Theorem 2 and Theorem 3: QSGD has a variance of min {d/s^2, \sqrt{d}/s} and NUQSGD has a variance of min{O(d/2^{-2s}), O(\sqrt{d/2^{-2s}})}. QSGD has communication cost of \tilde O(s(s+\sqrt{d})) and NUQSGD has communication cost of \tilde O(2^{2s}\sqrt{d} ).	Review	O	0
Compared to QSGD, we can see that NUQSGD improves the dependence on s for the variance term, but it has a worse (exponential) dependence on s for the communication cost.	Review	O	0
Usually s is a small number and it serves as a hyper-parameter to be tuned.	Review	O	0
We would expect NUQSGD to improve the dependence on the dimension d, which is more significant.	Review	B-Review	2
However, NUQSGD has the same dependence on d as QSGD in terms of both variance and communication cost.	Review	I-Review	2
[line_break_token][line_break_token]Experiments: Figure 3 compares NUQSGD with other parallel SGD algorithms and vanilla SGD.	Review	O	0
Figure 3 shows how fast the training loss decreases with respect to iterations.	Review	O	0
It would be great to add learning curves with the ‚Äòtime‚Äô being the x-axis as well.	Review	B-Review	3
Also, I would suggest the authors to record the time needed to proceed one iteration for each parallel algorithm to compare the communication cost.	Review	I-Review	3
[line_break_token][line_break_token]Quality and clarity:[line_break_token]This paper is well-written.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
hanks for your feedback.	Reply	O	0
Below is our specific feedback to your review.	Reply	O	0
We have also posted a general response (see our top-level comment) to all reviewers addressing high level points.	Reply	O	0
[line_break_token][line_break_token]&gt;NUQSGD does not provide significant improvements in terms of the variance and communication cost.	Reply	O	0
[line_break_token][line_break_token]The goal of the paper was to close the gap between QSGD and QSGDinf.	Reply	B-Reply	1
QSGD provides theoretical guarantees but is empirically worse than QSGDinf.	Reply	I-Reply	1
QSGDinf has no theoretical guarantees.	Reply	I-Reply	1
NUQSGD matches the empirical performance of QSGDinf and has slightly stronger asymptotic guarantees than QSGD, and so we don't see the fact that the improvement is "minor" as undermining the significance.	Reply	I-Reply	1
In practice, it's much better than QSGD.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt;We would expect NUQSGD to improve the dependence on the dimension d, which is more significant[line_break_token][line_break_token]We have proven that, for any given set of levels, there exists a distribution of points with dimension d such that the variance is in Omega(sqrt{d}), and so our bound is tight in d. We will include this proof in the updated version (forthcoming).	Reply	O	0
[line_break_token][line_break_token]&gt;It would be great to add learning curves with the ‚Äòtime‚Äô being the x-axis as well.	Reply	O	0
Also, I would suggest the authors to record the time needed to proceed one iteration for each parallel algorithm to compare the communication cost.	Reply	O	0
[line_break_token][line_break_token]Regarding simulation-based learning curves with respect to time, if different compression schemes are run on the same gpu, there will be no difference between any quantization method.	Reply	B-Reply	3
This does not hold for error-corrected methods though, since they require additional storage for the error.	Reply	I-Reply	3
We will add convergence-versus-time bounds to the updated version.	Reply	I-Reply	3
In addition, we will record the time needed to proceed one iteration for each parallel algorithm.	Reply	I-Reply	3

The paper proposes a multi-document extractive machine reading model and algorithm.	Review	O	0
The model is composed of 3 distinct parts.	Review	O	0
First, the document retriever and the document reader that are states of the art modules.	Review	O	0
Then, the paper proposes to use a "multi-step-reasoner" which learns to reformulate the question into its latent space wrt its current value and the "state" of the machine reader.	Review	O	0
[line_break_token][line_break_token]In the general sense, the architecture can be seen as a specific case of a memory network.	Review	B-Review	1
Indeed, the multi-reasoner step can be seen as the controller update step of a memory network type of inference.	Review	I-Review	1
The retriever is the attention module and the reader as the final step between the controller state and the answer prediction.	Review	I-Review	1
[line_break_token][line_break_token]The authors claim the method is generic, however, the footnote in section 2.3 mentioned explicitly that the so-called state of the reader assumes the presence of a multi-rnn passage encoding.	Review	I-Review	2
Furthermore, this section 2.3 gives very little detailed about the "reinforcement learning" algorithms used to train the reasoning module.	Review	I-Review	2
[line_break_token][line_break_token]Finally, the experimental section, while giving encouraging results on several datasets could also have been used on QAngoroo dataset to assess the multi-hop capabilities of the approach.	Review	I-Review	3
Furthermore, very little details are provided regarding the reformulation mechanism and its possible interpretability.	Review	I-Review	4
We thank you for your helpful reviews.	Reply	O	0
We have significantly updated the writing of the paper to hopefully address all confusion and we‚Äôve also updated the results section of the paper for better comparison.	Reply	B-Reply	5
In a nutshell, we have added a section on retriever performance demonstrating the scalability of our approach (sec 4.1).	Reply	I-Reply	5
We have improved results for our experiments with BiDAF reader and we have also added new results on the open-domain version of the SQuAD dataset.	Reply	I-Reply	5
[line_break_token][line_break_token]> In the general sense, the architecture can be seen as a specific case of a memory network.	Reply	O	0
 Indeed, the multi-reasoner step can be seen as the controller update step of a memory network type of inference.	Reply	O	0
The retriever is the attention module and the reader as the final step between the controller state and the answer prediction.	Reply	O	0
[line_break_token][line_break_token]We agree with you and think its a valid way of viewing our framework.	Reply	B-Reply	1
We have updated and cited memory networks in our paper (Sec 4) .	Reply	I-Reply	1
However, we would like to point out that most memory network architectures are based on soft-attention, but in our case the retriever actually makes a ‚Äúhard selection‚Äù of the top-k paragraphs and hence for the same reason, we have to train it via reinforcement learning.	Reply	I-Reply	1
[line_break_token][line_break_token]> The authors claim the method is generic, however, the footnote in section 2.3 mentioned explicitly that the so-called state of the reader assumes the presence of a multi-rnn passage encoding.	Reply	O	0
Furthermore, this section 2.3 gives very little detailed about the "reinforcement learning" algorithms used to train the reasoning module.	Reply	O	0
[line_break_token][line_break_token]We agree with you and based on your comments we have made this absolutely clear in the paper.	Reply	B-Reply	2
Our method needs access to the internal token level representation of the reader model in order to construct the current state.	Reply	I-Reply	2
The current API of machine reading models only return the span boundaries of the answer, but for our method, it needs to return the internal state as well.	Reply	I-Reply	2
What we wanted to convey is, our model does not depend/need any neural architecture re-designing to an existing reader model.	Reply	I-Reply	2
To show the same, we experimented and showed improvements with two popular and widely used reader architectures - DrQA and BiDAF.	Reply	I-Reply	2
[line_break_token]Regarding results of BiDAF -- During submission we ran out of time and hence we could not tune the BiDAF model.	Reply	I-Reply	2
But now the results of BiDAF have improved a lot and as can be seen from (Table 2, row 9), the results of BiDAF are comparable to that of DrQA.	Reply	I-Reply	2
[line_break_token]We have also significantly updated the model section of our paper to include more details about methods and training (Sec 2 & 3) with details about our policy gradient methods and training procedure.	Reply	O	0
[line_break_token][line_break_token]> Finally, the experimental section, while giving encouraging results on several datasets could also have been used on QAngaroo dataset to assess the multi-hop capabilities of the approach.	Reply	O	0
[line_break_token][line_break_token]We did not consider QAngaroo for the following reasons -- (a) The question in QAngaroo are based on knowledge base relations and are not natural language questions.	Reply	B-Reply	3
This makes the dataset a little synthetic in nature and we were unsure if our query reformulation strategy would work in this synthetic setting. (	Reply	I-Reply	3
b) In this paper, we have tried to focus on datasets for open domain settings where the number of paragraphs per query is large (upto millions).	Reply	I-Reply	3
QAngaroo on the other hand is quite small in that respect (avg of 13.7 paragraphs per question).	Reply	I-Reply	3
We were unsure, that in this small setting, if we would see significant gains by doing query reformulation.	Reply	I-Reply	3
[line_break_token][line_break_token]We have shown the effectiveness of our model in 4 large scale datasets including new results on SQuAD-open since submission.	Reply	I-Reply	3
We sincerely hope, we will not be penalized for not showing the effectiveness of our model on enough number of datasets.	Reply	I-Reply	3
[line_break_token][line_break_token]> Furthermore, very little details are provided regarding the reformulation mechanism and its possible interpretability.	Reply	O	0
[line_break_token][line_break_token]We have significantly updated this section of the paper.	Reply	B-Reply	4
We have added a whole new section (Sec 5.3) with detailed analysis of the effect of query reformulation.	Reply	I-Reply	4
In Table 4, we quantitatively measure if the iterative interaction between the retriever and reader is able to retrieve better context for the reader.	Reply	I-Reply	4
[line_break_token]	Reply	O	0

The paper presents a maximally expressive parameter-sharing scheme for hypergraphs, and in general when modeling the high order interactions between elements of a set.	Review	O	0
This setting is further generalized to multiple sets.	Review	O	0
The paper shows that the number of free parameters in invariant and equivariant layers corresponds to the different partitioning of the index-set of input and output tensors.	Review	O	0
Experimental results suggest that the proposed layer can outperform existing methods in supervised learning with graphs.	Review	O	0
[line_break_token][line_break_token]The paper presents a comprehensive generalization of a recently proposed model for interaction across sets, to the setting where some of these sets are identical.	Review	O	0
This is particularly useful and important due to its applications to graphs and hyper-graphs, as demonstrated in experiments.	Review	O	0
[line_break_token][line_break_token]Overall, I enjoyed reading the paper.	Review	O	0
My only concern is the experiments:[line_break_token][line_break_token]1) Some of the benchmark datasets for the proposed task as well as some well-known methods (see Battaglia et al‚Äô18 and references in there) are missing.	Review	O	0
[line_break_token][line_break_token]2) Applying the model of Hartford et al‚Äô18 to problems where interacting sets are identical is similar to applying convolution layer to a feature vector that is not equivariant to translation. (	Review	O	0
In both cases the equivariance group of data is a strict subgroup of the equivariance of the layer.)	Review	B-Review	1
 Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?	Review	I-Review	1
[line_break_token]	Review	O	0
We thank the reviewer for the positive comments.	Reply	O	0
Below we address the main concerns.	Reply	O	0
[line_break_token][line_break_token]Q: ‚ÄùApplying the model of Hartford et al.	Reply	O	0
to problems where interacting sets are identical is similar to applying convolution layer to a feature vector that is not equivariant to translation... Do you agree that for this reason, all the experiments on the synthetic dataset is flawed?‚Äù[line_break_token][line_break_token]A: Our goal in performing the synthetic experiments was to quantify the expressive power that is  gained by adding our basis elements to [Hartford et al.	Reply	O	0
18]. We felt it is an informative experiment since [Hartford et al.	Reply	B-Reply	1
18] also discuss applying their model in the jointly exchangeable setting (page 3, second column, top paragraph).	Reply	I-Reply	1
[line_break_token]Having said that, we agree with the reviewer that [Hartford et al.	Reply	I-Reply	1
18] probably cannot handle such tasks by construction.	Reply	I-Reply	1
As we mentioned in our response to Reviewer1 we will change the wording of this section to better reflect that this is *not* a failure of Hartford et al.	Reply	I-Reply	1
but merely a setting outside their scope due to a different assumption on the symmetry group of the data.	Reply	I-Reply	1
 [line_break_token]If the reviewers feel strongly about this experiment, we are open to replace it with a discussion.	Reply	I-Reply	1
 [line_break_token][line_break_token]--------------------------------------------------------------------------------------------------------------------------------[line_break_token]Q: ‚ÄúSome of the benchmark datasets for the proposed task as well as some well-known methods (see Battaglia et al‚Äô18 and references in there) are missing‚Äù.	Reply	O	0
[line_break_token][line_break_token]A: We did our best to survey and compare to the most related works on the dataset collection introduced in [Yanardag & Vishwanathan 2015]. These datasets contain graphs from multiple origins, where some of them consist of highly varying graph sizes (within the same dataset).	Reply	O	0
In any case we will make the code available as soon as possible.	Reply	B-Reply	2
   [line_break_token]--------------------------------------------------------------------------------------------------------------------------------	Reply	O	0

The main significance of this paper is to propose the task of generating the lead section of Wikipedia articles by viewing it as a multi-document summarization problem.	Review	O	0
Linked articles as well as the results of an external web search query are used as input documents, from which the Wikipedia lead section must be generated.	Review	O	0
Further preprocessing of the input articles is required, using simple heuristics to extract the most relevant sections to feed to a neural abstractive summarizer.	Review	O	0
A number of variants of attention mechanisms are compared, including the transofer-decoder, and a variant with memory-compressed attention in order to handle longer sequences.	Review	O	0
The outputs are evaluated by ROUGE-L and test perplexity.	Review	O	0
There is also a A-B testing setup by human evaluators to show that ROUGE-L rankings correspond to human preferences of systems, at least for large ROUGE differences.	Review	O	0
[line_break_token][line_break_token]This paper is quite original and clearly written.	Review	B-Review	1
The main strength is in the task setup with the dataset and the proposed input sources for generating Wikipedia articles.	Review	I-Review	1
The main weakness is that I would have liked to see more analysis and comparisons in the evaluation.	Review	I-Review	1
[line_break_token][line_break_token]Evaluation:[line_break_token]Currently, only neural abstractive methods are compared.	Review	O	0
I would have liked to see the ROUGE performance of some current unsupervised multi-document extractive summarization methods, as well as some simple multi-document selection algorithms such as SumBasic.	Review	B-Review	2
Do redundancy cues which work for multi-document news summarization still work for this task?	Review	I-Review	2
[line_break_token][line_break_token]Extractiveness analysis:[line_break_token]I would also have liked to see more analysis of how extractive the Wikipedia articles actually are, as well as how extractive the system outputs are.	Review	O	0
Does higher extractiveness correspond to higher or lower system ROUGE scores?	Review	B-Review	3
This would help us understand the difficulty of the problem, and how much abstractive methods could be expected to help.	Review	I-Review	3
[line_break_token][line_break_token]A further analysis which would be nice to do (though I have less clear ideas how to do it), would be to have some way to figure out which article types or which section types are amenable to this setup, and which are not.	Review	I-Review	4
[line_break_token][line_break_token]I have some concern that extraction could do very well if you happen to find a related article in another website which contains encyclopedia-like or definition-like entries (e.g., Baidu, Wiktionary) which is not caught by clone detection.	Review	I-Review	5
In this case, the problem could become less interesting, as no real analysis is required to do well here.	Review	I-Review	5
[line_break_token][line_break_token]Overall, I quite like this line of work, but I think the paper would be a lot stronger and more convincing with some additional work.	Review	O	0
[line_break_token][line_break_token]----[line_break_token]After reading the authors' response and the updated submission, I am satisfied that my concerns above have been adequately addressed in the new version of the paper.	Review	O	0
This is a very nice contribution.	Review	O	0
[line_break_token]	Review	O	0
Thank you for the detailed review with actionable feedback.	Reply	O	0
We found common feedback from the three reviewers to augment the evaluation section of the paper and believe we have significantly improved it.	Reply	O	0
In particular, please see responses below in-line where we address all of your feedback.	Reply	O	0
[line_break_token][line_break_token]‚ÄúThis paper is quite original and clearly written.	Reply	O	0
The main strength is in the task setup with the dataset and the proposed input sources for generating Wikipedia articles. ‚	Reply	O	0
Äú[line_break_token][line_break_token]- In addition to the task setup, we believe we‚Äôve demonstrated how to do very long (much longer than previously attempted) text-to-text sequence transduction and introduced a new model architecture to do it.	Reply	O	0
We believe this is of great interest to the ICLR community.	Reply	B-Reply	1
[line_break_token][line_break_token]‚ÄúCurrently, only neural abstractive methods are compared.	Reply	O	0
I would have liked to see the ROUGE performance of some current unsupervised multi-document extractive summarization methods, as well as some simple multi-document selection algorithms such as SumBasic.	Reply	O	0
Do redundancy cues which work for multi-document news summarization still work for this task?‚Äù[line_break_token][line_break_token]- We implemented SumBasic and TextRank (along with tf-idf) to evaluate extractive methods on their own and evaluated them on this task.	Reply	O	0
I believe we show convincingly in the results (e.g. extractive bar-plot) that the abstractive stage indeed adds a lot to the extractive output in terms of ROUGE and human evaluation of linguistic quality and that redundancy cues are not enough.	Reply	B-Reply	2
[line_break_token][line_break_token]‚ÄúI would also have liked to see more analysis of how extractive the Wikipedia articles actually are, as well as how extractive the system outputs are.	Reply	O	0
Does higher extractiveness correspond to higher or lower system ROUGE scores?	Reply	O	0
This would help us understand the difficulty of the problem, and how much abstractive methods could be expected to help.	Reply	O	0
‚Äù[line_break_token][line_break_token]- In Section 2.1 we computed the proportion of unigrams/words in the output co-occurring in the input for our task and for the Gigaword and CNN/DailyMail datasets and showed that by this measure WikiSum is much less extractive.	Reply	O	0
In particular, the presence of wiki-clones in the input would give a score of 100%, whereas we report 59.2%.	Reply	B-Reply	3
[line_break_token][line_break_token]‚ÄúA further analysis which would be nice to do (though I have less clear ideas how to do it), would be to have some way to figure out which article types or which section types are amenable to this setup, and which are not.	Reply	O	0
‚Äù[line_break_token][line_break_token]- We added a comparison in the paper with Sauper & Barzilay on two Wiki categories.	Reply	O	0
It turns out we do worse on Diseases compared to Actors.	Reply	B-Reply	4
We think this is because we use a single model for all categories and the training data is heavily biased toward people.	Reply	I-Reply	4
[line_break_token][line_break_token]‚ÄúI have some concern that extraction could do very well if you happen to find a related article in another website which contains encyclopedia-like or definition-like entries (e.g., Baidu, Wiktionary) which is not caught by clone detection.	Reply	O	0
In this case, the problem could become less interesting, as no real analysis is required to do well here.	Reply	O	0
‚Äù[line_break_token]- We hope our added analysis in Section 2.1 mentioned above should address this concern.	Reply	O	0

This paper introduces a mutual information term into the training objective of message passing graph neural networks.	Review	O	0
 The additional term favors the preservation on information in a mapping from an input edge feature vector e_{i,j} to a weight matrix f(e_{i,j}) used in computing messages across the edge from node i to node j.  A variational lower bound on the mutual information is used in training.	Review	O	0
 Impressive empirical results are given for chemical property prediction and relation prediction in knowledge graphs.	Review	O	0
 I have no real complaints other than I might recommend citing the original work on infomax:[line_break_token][line_break_token]"Self Organization in a Perceptual Network", Ralph Linsker, 1988.	Review	B-Review	1
[line_break_token][line_break_token]Postscript:  I have been swayed by the complaints of reviewer 1 and reduced my score to weak reject.	Review	O	0
e appreciate your positive feedback and thank you for pointing out the original paper on infomax ([Linsker 1998]) which explains the importance of applying the infomax principle for designing neural networks.	Reply	B-Reply	1
We have cited the paper and discussed it in Section 3.1.	Reply	I-Reply	1
[line_break_token][line_break_token][Linsker 1998] Linsker, Ralph. "	Reply	O	0
Self-organization in a perceptual network."	Reply	O	0
Computer 21.3 (1988): 105-117.	Reply	O	0

The paper provides an unsupervised domain adaptation approach[line_break_token]in the context of deep learning.	Review	O	0
The motivation is clear, related work[line_break_token]sufficient and experimental settings and results convincing.	Review	O	0
[line_break_token]I have only very minor comments:[line_break_token]- I would prefer to get the paper additionally linked to a few more[line_break_token]  transfer learning techniques out of the deep learning domain[line_break_token]  which is important as well[line_break_token]- do you really need to call it (multi) flow network .... - a flow network[line_break_token]  is a well established concept in algorithmics and refers to a graph problem[line_break_token]  ... to avoid name clashes ...[line_break_token]- in the references you have provided back links to the pages where the references[line_break_token]  are used - this is handy but also confusing and a bit unusual - I think it was not part [line_break_token]  of the standard template[line_break_token]- please avoid using arxiv references but replace them by reviewed material.	Review	O	0
In parts[line_break_token]  I am willing to accept such kind of gray literature provided by well known authors but[line_break_token]  this should not become a standard habit[line_break_token]- I am happy to see that the code will be published - I hope this is really done, because[line_break_token]  from the material it maybe hard to reconstruct the method	Review	O	0
hank you for your insights.	Reply	O	0
Here are our responses:[line_break_token][line_break_token]&gt;- I would prefer to get the paper additionally linked to a few more transfer[line_break_token]&gt;learning techniques out of the deep learning domain which is important as well[line_break_token][line_break_token]We focused our literature review on deep learning because our work proposes an[line_break_token]approach for deep architectures.	Reply	O	0
For the sake of completeness, we will[line_break_token]nonetheless include the following papers:[line_break_token][line_break_token]- Boosting for Transfer Learning [Dai07][line_break_token]- Covariate Shift by Kernel Mean Matching [Gretton09][line_break_token]- Domain adaptation via transfer component analysis [Pan10][line_break_token]- Unsupervised Visual Domain Adaptation Using Subspace Alignment [Fernando13][line_break_token]- Deep CORAL: Correlation Alignment for Deep Domain Adaptation [Sun16][line_break_token]- A DIRT-T approach to unsupervised domain adaptation [Shu18][line_break_token][line_break_token]&gt;- do you really need to call it (multi) flow network .... - a flow network is[line_break_token]&gt;a well established concept in algorithmics and refers to a graph problem ...[line_break_token]&gt;to avoid name clashes ...[line_break_token][line_break_token]We propose to rename our approach as Domain-Adaptive Multibranch Networks.	Reply	O	0
[line_break_token][line_break_token]&gt;- in the references you have provided back links to the pages where the[line_break_token]&gt;references are used - this is handy but also confusing and a bit unusual - I[line_break_token]&gt;think it was not part of the standard template[line_break_token][line_break_token]We will abide by the template and remove the back links.	Reply	O	0
[line_break_token][line_break_token]&gt;- please avoid using arxiv references but replace them by reviewed material.	Reply	O	0
[line_break_token]&gt;In parts I am willing to accept such kind of gray literature provided by well[line_break_token]&gt;known authors but this should not become a standard habit[line_break_token][line_break_token]We have replaced the arxiv references with reviewed ones when available.	Reply	O	0
[line_break_token][line_break_token]&gt;- I am happy to see that the code will be published - I hope this is really[line_break_token]&gt;done, because from the material it maybe hard to reconstruct the method[line_break_token][line_break_token]Our code is currently stored in a private github repository, which will be set as public once the blind review period ends.	Reply	O	0
[line_break_token][line_break_token]We have updated the manuscript to reflect the above changes.	Reply	O	0
[line_break_token][line_break_token]Thank you for your input	Reply	O	0

Pros: [line_break_token]- Introduction of a nice filter banks and its implementation[line_break_token]- Good numerical results[line_break_token]- Refinement of the representation via back propagation, and a demonstration that it speeds up learning[line_break_token][line_break_token]Cons:[line_break_token]- The algorithms (section 3.1) are not necessary, and they even affect the presentation of the paper.	Review	O	0
However, a source code would be great!	Review	B-Review	1
[line_break_token]- The link with a scattering transform is not clear[line_break_token]- Sometimes (as mentionned in some of my comments), the writing could be improved.	Review	O	0
[line_break_token][line_break_token]From a personal point of view, I also believe the negative points I mention can be easily removed.	Review	O	0
The current available revised version contains the code and link to GitHub, the writing is improved, and we added SPEECH TIMIT experimentation showing improvement on vowel recognition using proposed FCT	Reply	B-Reply	5

[line_break_token]I have mixed feelings about this paper.	Review	O	0
On one hand, it‚Äôs a thorough and well-written experimental paper, something which is really important but is also clearly underappreciated in the machine learning community.	Review	O	0
On the other, it was not really obvious to me why some of objectives tested here are interesting: LM objectives like ELMo have seen a lot of uptake in the NLP community (and this is definitely an NLP paper), but most of the others‚Äîlike skip-thought, MT, and autoencoders‚Äîhave not.	Review	B-Review	1
So the basic research question doesn‚Äôt seem like an especially burning one.	Review	I-Review	1
The trends in Fig.	Review	O	0
2 show that these alternatives underperform an LM objective, which suggests that the NLP community can keep using that objective without worry‚Äîand everything else in the figure seems as we would expect.	Review	O	0
[line_break_token][line_break_token]In short, I think the paper is a well-done study on a hypothesis of perhaps minor interest.	Review	O	0
The results are sensible but confirm what we already strongly suspected, and they seem unlikely to strongly influence other research, since they confirm that everyone has been the right thing all along.	Review	B-Review	2
I‚Äôm not entirely sure what I learned from this.	Review	I-Review	2
[line_break_token][line_break_token]To me, the most interesting experiment is the final one in Section 6.	Review	O	0
This experiment seems like it could be the germ for a far more interesting paper getting at how these pretraining objectives help with downstream tasks.	Review	O	0
As it stands, it feels like an interesting nugget tacked on to an otherwise complete (and much less interesting) paper.	Review	O	0
[line_break_token][line_break_token]Presentational comments:[line_break_token][line_break_token]Fig.1: really nitpicky, but the typography of the POS tags and CCG categories is all wrong.	Review	O	0
These aren‚Äôt mathematical symbols!	Review	B-Review	3
[line_break_token][line_break_token]Fig 2.	Review	I-Review	4
Slightly confused why these are broken up into two separate plots.	Review	I-Review	4
[line_break_token][line_break_token]Fig 4.	Review	I-Review	5
is hard to read due to the lurid colors and patterns, which require a lot of cross-referencing with the legend.	Review	I-Review	5
I wonder if this would be better as simply a table.	Review	I-Review	5
I also found it very confusing at first since the y-axes are out of sync between the two figures‚Äîinitially it looked as if the legend was overlaid on a set of bars in the left figure that had the same baseline as the right figure.	Review	I-Review	5
[line_break_token]	Review	O	0
Our contribution is a thorough examination of several different pretraining tasks, controlling for the domain, amount of data, and training procedure.	Reply	B-Reply	2
When CoVe was released at NIPS last year, it achieved SoTA numbers on several prominent NLP tasks.	Reply	I-Reply	2
Although ELMo compares to CoVe in their paper and outperforms CoVe, since CoVe was trained on WMT English-German and ELMo was trained on the One Billion Word Benchmark, it was unclear if the performance gain of ELMo was primarily due to the increased amount of training data.	Reply	I-Reply	2
Moreover, without a direct comparison we can‚Äôt even be sure that language modeling is better because ELMo could have just been more carefully tuned.	Reply	I-Reply	2
Our finding that language modeling, an unsupervised task, outperformed translation models trained on the *same* data is still surprising because the translation models are given the source sentence in a different language and thus have strictly more information than language models.	Reply	I-Reply	2
We also agree that the results of our analysis of the randomly-initialized encoder in Section 6 are surprising, and could form the basis for a larger study.	Reply	I-Reply	2
[line_break_token][line_break_token]Fig 1: You are right.	Reply	I-Reply	3
We just fixed the typography in our most recent revision.	Reply	I-Reply	3
[line_break_token][line_break_token]Fig 2: The upper plot is for POS tagging and the bottom for CCG supertagging.	Reply	I-Reply	4
Each of those plots are then split into three columns corresponding to different amounts of classifier training data.	Reply	I-Reply	4
Each column has two plots because when we tried plotting all ten lines into one figure it was difficult to read, so we split up the models into two groups: models with attention (plus BiLMs) and models without attention (plus forward LM).	Reply	I-Reply	4
We welcome further suggestions for improving our presentation.	Reply	I-Reply	4
[line_break_token][line_break_token]Fig 4: We included the patterns and bright colors in order to make it easier for the visually impaired to read	Reply	I-Reply	5

UPDATE:[line_break_token]I looked at the arxiv version of the paper.	Review	O	0
It is much longer and appears more rigorous.	Review	O	0
Fig 3 there is indeed more insightful.	Review	O	0
[line_break_token]However, I am reviewing the submission and my overall assessment does not change.	Review	O	0
This is not a minor incremental contribution, and if you want to compress it into a conference submission of this type, I would recommend choosing message you want to convey, and focus on that.	Review	O	0
As you say, "...ICLR submission focus on the ParMAC algorithm...", I would focus on this properly - and remove or move to appendix all extensions and theoretical remarks, and have an extra page on explaining the algorithm.	Review	O	0
Additionally, make sure to clearly explain the relation of the arxiv paper, in particular that the submission was a compressed version.	Review	O	0
[line_break_token][line_break_token]ORIGINAL REVIEW:[line_break_token]The submission proposes ParMAC, based on MAC (Method of Auxiliary Coordinates), formulating a distributed variant of the idea.	Review	O	0
[line_break_token][line_break_token]Related Work: In the part on convex ERM and methods, I would recommend citing general communication efficient frameworks, COCOA (Ma et al.)	Review	O	0
and AIDE (Reddi et al.).	Review	O	0
I believe these works are most related to the practical objectives authors of this paper set, while number of the papers cited are less relevant.	Review	O	0
[line_break_token][line_break_token]Section 2, explaining MAC, is quite clearly written, but I do not find part on MAC and EM particularly useful.	Review	B-Review	1
[line_break_token][line_break_token]Section 3 is much less clearly written.	Review	I-Review	2
I have trouble following notation, particularly in the speedups part, as different symbols were introduced at different places.	Review	I-Review	2
Perhaps a quick summary or paragraph on notation in the introduction would be helpful.	Review	I-Review	2
In paragraph 2, you write as if reader knew how data/anything is distributed, but this was not mentioned yet; it is specified later.	Review	I-Review	2
It is not clear what is meant by "submodel".	Review	I-Review	2
Perhaps a more precise example pointing back to eqs (1) & (2) would be useful.	Review	O	0
As far as I understand from what is written, there are P independent sets of submodels, that traverse the machines in circular fashion.	Review	B-Review	2
I don't understand how are they initialized (identically?),	Review	I-Review	2
and more importantly I don't understand what would be a single output of the algorithm (averaging?	Review	I-Review	2
does not seem to make sense).	Review	I-Review	2
Since this is not addressed, I suppose I get it wrong, leaving me to guess what was actually meant.	Review	I-Review	2
[line_break_token]The fact that I am not able to understand what is actually happening, I see as major issue.	Review	O	0
[line_break_token][line_break_token]I don't like the later paragraphs on extensions, model for speedup, convergence and topologies.	Review	B-Review	3
I don't understand whether these are novel contributions or not, as the authors refer to other work for details.	Review	I-Review	3
If these are novel, the explanation is not sufficient, particularly speedup part, which contains undefined quantities, e.g. T(P) (or I can't find it).	Review	I-Review	3
If this is not novel, It does not provide enough explanation to understand anything more, compared with a its version compressed to 1/4 of its size and referring to the other work.	Review	I-Review	3
The statement that we can recover the original convergence guarantees seems strong and I don't see why it should be trivial to show (but author point to other work which I did not look at).	Review	I-Review	3
In topologies part, claiming that something does "true SGD", without explaining what is "true SGD" seems very strange.	Review	I-Review	3
Other statements in this section seem also very vague and unjustified/unexplained.	Review	I-Review	3
[line_break_token][line_break_token]Experimental section seems to suggest that the method is interesting for binary autoencoders, but I don't see how would I conclude anything about any other models.	Review	I-Review	4
ParMAC is also not compared to alternative methods, only with itself, focusing on scaling properties.	Review	I-Review	4
[line_break_token][line_break_token]Conclusion contains statements that are too strong or misleading based on what I saw.	Review	I-Review	5
In particular, "we analysed its parallel speedup and convergence" seems ungrounded.	Review	I-Review	5
Further, the claim "The convergence properties of MAC remain essentially unaltered in ParMAC" is unsupported, regardless of the meaning of "essentially unchanged".	Review	I-Review	5
[line_break_token][line_break_token]In summary, the method seems relevant for particular model class, binary autoencoders, but clarity of presentation is insufficient - I wouldn't be able to recreate the algorithm used in experiments - and the paper contains a number of questionable claims.	Review	O	0
Regarding clarity of presentation, we regret you didn't find the paper sufficiently clear and thank you for your suggestions.	Reply	O	0
We tried to make it approachable and point to the longer arXiv version as needed.	Reply	O	0
But, given the MAC and ParMAC frameworks are very different from the standard practice (backpropagation, SGD, GPUs, etc.),	Reply	O	0
this is bound to be a denser than usual paper.	Reply	O	0
We do find the analogy of MAC and EM very helpful in order to explain how ParMAC works based on our experience in describing this work to people who are familiar with EM (this would include most machine learning researchers).	Reply	O	0
In particular, it should help understand the notion of "submodels" and "coordinates" (since what these exactly are depends on the model used).	Reply	O	0
[line_break_token][line_break_token]We try to answer your specific questions, as follows.	Reply	O	0
[line_break_token][line_break_token]- Firstly, the notion of submodels only applies during a W step.	Reply	O	0
In the Z step, we have a single model, the binary autoencoder.	Reply	B-Reply	2
In the W step, this single model splits into submodels because the objective function additively separates given Z.[line_break_token][line_break_token]- There are M (not P) independent submodels and P processors.	Reply	O	0
Each submodel indeed traverses the machines in circular fashion (in the W step).	Reply	B-Reply	2
[line_break_token][line_break_token]- Crucially, each submodel is trained on different data (different input dimensions or different output dimensions), so different submodels will differ at the end of the W step.	Reply	O	0
Specifically, each encoder l has the same input vector x but a different output bit z_l; and each decoder d has the same input vector z but a different output dimension x_d (see pseudocode in fig.	Reply	B-Reply	2
1).	Reply	I-Reply	2
[line_break_token]  In the analogy with EM, each Gaussian (= submodel) trains on different data: the training points, and the posterior probabilities (= auxiliary coordinates), which are different for each Gaussian.	Reply	I-Reply	2
[line_break_token][line_break_token]- Initialisation of each submodel: from PCA.	Reply	O	0
But, since different submodels train on different data, they will differ anyway.	Reply	B-Reply	2
Besides, in the binary autoencoder), each submodel is a convex problem (encoder = a binary SVM, decoder = a linear regressor).	Reply	I-Reply	2
[line_break_token][line_break_token]- "what would be a single output of the algorithm?":	Reply	O	0
we don't understand what you mean, but hopefully the above explanation has cleared this up.	Reply	B-Reply	2
There is one overall model (the binary autoencoder), it's just that during the W step it splits into M independently trained submodels (L encoders, D decoders), given the training data and auxiliary coordinates.	Reply	I-Reply	2
[line_break_token]  Perhaps fig.	Reply	I-Reply	2
3 in the arXiv paper (which works best as an animation) may help you understand better the training of the independent submodels in the W step.	Reply	I-Reply	2
[line_break_token][line_break_token]- "later paragraphs on extensions, model for speedup, >convergence and topologies": all those parts are novel contributions indeed and are more fully explained in the arXiv paper.	Reply	O	0
Unfortunately we can't fit all the details in a conference paper.	Reply	B-Reply	3
We think it is better to have the ICLR submission focus on the ParMAC algorithm, which is the most important part, and point to the longer paper for these other things.	Reply	I-Reply	3
[line_break_token]  We did omit the definition of T(P): T(P) = TW(P) + TZ(P).	Reply	I-Reply	3
[line_break_token]  "True SGD" means SGD as it would run in a single machine.	Reply	I-Reply	3
[line_break_token]  The statement that we can recover the original convergence guarantees follows by realising that the critical condition we need to ensure for MAC to converge is "to reduce the gradient of the penalised function below a tolerance for each value of \mu" (arXiv p. 19).	Reply	I-Reply	3
Proposition 1 in Bertsekas/Tsisiklis00 guarantees this for SGD even for nonconvex functions.	Reply	I-Reply	3
Essentially, if you run the W steps (= SGD on each submodel) for sufficiently many epochs, you follow the path over \mu closely enough, and you converge in the limit.	Reply	I-Reply	3
For full details, see section 6 in the arXiv paper.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding the choice of the binary autoencoder for the experiments, see our "response to reviewers".	Reply	O	0
[line_break_token][line_break_token]The ICLR submission (together with the arXiv paper) does contain a detailed theoretical analysis of the speedup.	Reply	O	0
The arXiv paper does describe the convergence properties.	Reply	O	0
We provide the full C/MPI code in our website to recreate the experiments in either a shared- or a distributed-memory system.	Reply	O	0

This paper proposed a pre-trainable generic representation for visual-linguistic tasks call VL-BERT.	Review	O	0
VL-BERT extend BERT by changing the input from subsequent sentence to image regions and modify the caption words has the additional visual feature embedding.	Review	O	0
The authors pre-train the VL-BERT on the conceptual caption dataset and Wikipedia and book corpus dataset, empirical results show that the VL-BERT achieve the SOTA performance on the VCR, VQA and refer expression tasks.	Review	O	0
[line_break_token][line_break_token]As the authors mentioned in Table 5, pre-training the visolinguistic representation for vision and language tasks is very popular recently, and 5~6 similar works have appeared recently.	Review	O	0
One of the nice features I found on this work is it's joint train with text-only corpus and faster RCNN weight.	Review	O	0
While ViLBERT designs for easier extendable for other modalities, VLBERT is more focus on the representation learning on the vision and language, since the caption input also combines with the visual feature embedding.	Review	O	0
[line_break_token][line_break_token]Overall the paper is well written and performs extensive experiments/ablations.	Review	O	0
There is some specific point that is not clear to me or needs further clarifications from the authors.	Review	O	0
[line_break_token][line_break_token]1: The authors mentioned the improvement over tuning the visual parameters, I wonder what is the details on that?	Review	O	0
is the region proposal network's weight fixed?	Review	B-Review	1
if not, how to avoid the shift on the proposal layer?	Review	I-Review	1
Is the model still has the visual genome target or objective?	Review	I-Review	1
Which layer is fixed/updated?	Review	I-Review	1
and what is the optimizer and learning rate scheduler?	Review	I-Review	1
[line_break_token][line_break_token]2: I notice there is a change in the textual input which take visual feature embeddings.	Review	O	0
I wonder what is the performance without these features?	Review	B-Review	2
What is the visual feature input for textual corpus?	Review	I-Review	2
[line_break_token][line_break_token]3: For the Masked RoI classification with Linguistic Clues, what if there are overlapped regions?	Review	O	0
what if the detection label from faster rcnn is incorrect?	Review	B-Review	3
will this introduce any noise?	Review	I-Review	3
[line_break_token][line_break_token]4: For VCR tasks, it seems the VL-BERT_base w/o pre-training is performed similar compare to the with pre-training (only 0.7% lower on val of Q-&gt;A) I wonder what is the reason of this?	Review	O	0
Is this show the pre-training is not important for the VCR tasks?	Review	B-Review	4
[line_break_token][line_break_token]5: The VCR tasks also have the object bounding box correspondence, is VL-BERT take any of this supervision for input?	Review	O	0
If not, how does the VL-BERT learn the correspondence?	Review	B-Review	5
[line_break_token][line_break_token]6: For refer expression tasks, the VL-BERT_base is actually worse than ViLBERT on the detected regions.	Review	O	0
It's not a fair comparison since other models use bert-base model.	Review	B-Review	6
[line_break_token][line_break_token]Overall, I think this paper is well written and has solid experiment results.	Review	O	0
It will be great if the authors can further clarify the above questions.	Review	O	0
e thank the reviewer for the careful reviews and constructive suggestions.	Reply	O	0
We clarify the questions as follows.	Reply	O	0
[line_break_token][line_break_token]Q#1: Details on tuning the visual parameters.	Reply	O	0
[line_break_token][line_break_token]A#1: As described in Section 3.2 and Fig.	Reply	O	0
1, in VL-BERT, only the object detection branch (i.e., Fast R-CNN) in Faster R-CNN is exploited to extract visual feature embeddings for each RoI. The region proposal network is not involved in training/inference of VL-BERT.	Reply	B-Reply	1
The optimizer and learning rate mentioned in experiments are shared for all the parameters in VL-BERT and Fast R-CNN.	Reply	I-Reply	1
[line_break_token][line_break_token]Indeed, such a training scheme would cause shift on the proposal layer in Faster R-CNN.	Reply	I-Reply	1
Here we extract the RoIs on the training/test samples by a separate pre-trained Faster R-CNN.	Reply	I-Reply	1
The shift may well be alleviated by joint training on object detection tasks.	Reply	I-Reply	1
[line_break_token][line_break_token]Q#2: ``What is the visual feature input for textual corpus?‚Äù ``I wonder what is the performance without these features?‚Äù[line_break_token][line_break_token]A#2: The visual feature input for textual corpus is a learnable embedding shared for all words.	Reply	O	0
We did not try experimenting without such features.	Reply	B-Reply	2
We shall clarify in revision.	Reply	I-Reply	2
[line_break_token][line_break_token]Q#3: What if there are overlapped regions in task Masked RoI classification with Linguistic Clues?	Reply	O	0
What if the detection label from the pre-trained Faster R-CNN is incorrect?	Reply	O	0
[line_break_token][line_break_token]A#3: The pixels laid in the masked RoI are set as zeros, regardless of whether the pixels also belong to other RoIs.	Reply	O	0
Thus, for the pixels covered by overlapping RoIs, they are also simply set as zeros.	Reply	B-Reply	3
The detection labels on Conceptual Captions can be incorrect, since they are just pseudo labels generated by a pre-trained Faster R-CNN.	Reply	I-Reply	3
Because there are no ground-truth detection annotations on Conceptual Captions, we cannot validate the effect for the time being.	Reply	I-Reply	3
[line_break_token][line_break_token]Q#4: Is the pre-training not important for the VCR tasks?	Reply	O	0
[line_break_token][line_break_token]A#4: We believe this is because the pre-training task on Conceptual Captions is for image captioning, where no commonsense reasoning is involved, which is vital for the VCR task.	Reply	O	0
[line_break_token][line_break_token]Q#5: Does VL-BERT use object bounding box correspondence annotations for VCR dataset?	Reply	O	0
[line_break_token][line_break_token]A#5: No, we did not use the bounding box correspondence annotations for VCR dataset, for the coherence in the design of VL-BERT.	Reply	O	0
We also tried exploiting the annotated bounding box correspondence in VCR, but there is little difference in accuracy.	Reply	B-Reply	5
We feel VL-BERT might already learned to encode such correspondence.	Reply	I-Reply	5
[line_break_token][line_break_token]Q#6: VL-BERT is actually worse than ViLBERT on refer expression tasks[line_break_token][line_break_token]A#6: Yes, VL-BERT is slightly shy of ViLBERT on RefCOCO+.	Reply	O	0
Meanwhile, VL-BERT and ViLBERT are concurrent works.	Reply	B-Reply	6
We feel there is no problem that VL-BERT does not surpass ViLBERT on every benchmark.	Reply	I-Reply	6

This paper proposes to learn implicit generative models by a feature matching objective which forces the generator to produce samples that match the means of the data distribution in some fixed feature space, focusing on image generation and feature spaces given by pre-trained image classifiers.	Review	O	0
[line_break_token][line_break_token]On the positive side, the paper is well-written and easy to follow, the experiments are clearly described, and the evaluation shows the method can achieve good results on a few datasets.	Review	O	0
The method is nice in that, unlike GANs and the stability issues that come with them, it minimizes a single loss and requires only a single module, the generator.	Review	O	0
[line_break_token][line_break_token]On the other hand, the general applicability of the method is unclear, the novelty is somewhat limited, and the evaluation is missing a few important baselines.	Review	O	0
In detail:[line_break_token][line_break_token]1) The proposed objective was used as a GAN auxiliary objective in [Salimans et al.,	Review	O	0
2016] and further explored in [Warde-Farley & Bengio, 2017]. The novel bit here is that the proposed objective doesn‚Äôt include the standard GAN term (so no need for an adversarially-optimized discriminator), and the feature extractor is a fixed pre-trained classifier or encoder from an auto-encoder (rather than a discriminator).	Review	O	0
[line_break_token][line_break_token]2) The method only forces the generator‚Äôs sample distribution to match the first moment (the mean) of the data distribution.	Review	O	0
While the paper shows that this can result in a generator that produces reasonably good samples in practice, it seems like this may have happened due to a ‚Äúlucky‚Äù artifact of the chosen pre-trained feature extractors.	Review	B-Review	2
For example, a degenerate generator that produces a single image whose features exactly match the mean would be a global optimum under this objective, equally good as a generator that exactly matches the data distribution.	Review	I-Review	2
Perhaps no such image exists for the chosen pre-trained classifiers, but it‚Äôs nonetheless concerning that the objective does nothing to prevent this type of behavior in the general case. (	Review	I-Review	2
This is similar to the mode collapse problem that often occurs with GAN training in practice, but at least a GAN generator is required to exactly match the full data distribution to achieve the global optimum of that objective.)	Review	I-Review	2
[line_break_token][line_break_token]3) It‚Äôs unclear why the proposed ADAM-based Moving Average (AMA) updates are appropriate for estimate the mean features of the data distribution.	Review	O	0
Namely, unlike EMA updates, it‚Äôs not clear that this is an unbiased estimator (I suspect it‚Äôs not); i.e. that the expectation of the resulting estimates is actually the true mean of the dataset features.	Review	B-Review	3
 It‚Äôs therefore not clear whether the stated objective is actually what‚Äôs being optimized when these AMA updates are used.	Review	I-Review	3
[line_break_token][line_break_token]4) Related to (3), an important baseline which is not discussed is the true fixed mean of the dataset distribution.	Review	O	0
In Sec.	Review	B-Review	4
2.4 (on AMA) it‚Äôs claimed that ‚Äúone would need large mini-batches for generating a good estimate of the mean features...this can easily result in memory issues‚Äù, but this is not true: one could trivially compute the full exact dataset mean of these fixed features by accumulating a sum over the dataset (e.g., one image a time, with minibatch size 1) and then dividing the result by the number of images in the dataset.	Review	I-Review	4
Without this baseline, I can‚Äôt rule out that the method only works due to its reliance on the stochasticity of the dataset mean estimates to avoid the behavior described in (2), or even the fact that the estimates are biased due to the use of ADAM as described in (3).	Review	I-Review	4
[line_break_token][line_break_token]5) The best results in Table 3 rely on initializing G with the weights of a decoder pretrained for autoencoding.	Review	O	0
However, the performance of the decoder itself with no additional training from the GFMN objective is not reported, so it‚Äôs possible that most of the result relies on *autoencoder* training rather than feature matching to get a good generator.	Review	B-Review	5
This explanation seems especially plausible due to the fact that the learning rate is set to a miniscule value (5*10^-6 for ADAM, 1-2 orders of magnitude smaller than typical values).	Review	I-Review	5
Without the generator pretraining, the next best CIFAR result is an Inception Score of 7.67, lower than the unsupervised result from [Warde-Farley & Bengio, 2017] of 7.72.	Review	O	0
[line_break_token][line_break_token]6) It is misleading to call the results based on ImageNet-pretrained models ‚Äúunconditional‚Äù -- there is plenty of overlap in the supervision provided by the labeled images of the much larger ImageNet to CIFAR and other datasets explored here.	Review	O	0
This is especially true given that the reported metrics (Inception Score and FID) are themselves based on ImageNet-pretrained classifiers.	Review	B-Review	6
If the results were instead compared to prior work on conditional generation (e.g. ProGAN (Karras et al.,	Review	I-Review	6
2017), which reports CIFAR IS of 8.56), there would be a clear gap between these results and the state of the art.	Review	I-Review	6
[line_break_token][line_break_token]Overall, the current version of the paper needs additional experiments and clarifying discussion to address these issues.	Review	O	0
[line_break_token][line_break_token]=======================================[line_break_token][line_break_token]REVISION[line_break_token][line_break_token]Based on the authors' responses, I withdraw points 3-5 from my original review.	Review	O	0
Thanks to the authors for the additional experiments.	Review	O	0
On (3), I indeed misunderstood where the moving average was being applied; thanks for the correction.	Review	O	0
On (4), the additional experiment using the global mean features for real data convinces me that the method does not rely on the stochasticity of the estimates. (	Review	O	0
Though, given that the global mean works just as well, it seems like it would be more efficient and arguably cleaner to simply have that be the main method.	Review	O	0
But this isn't a major issue.)	Review	O	0
On (5), I misread the learning rate specified for "using the autoencoder features" as being the learning rate for autoencoder *pretraining*; thanks for the correction.	Review	O	0
The added results in Appendix 11 do show that the pretrained decoder on its own does not produce good samples.	Review	O	0
[line_break_token][line_break_token]My biggest remaining concerns are with points (2) and (6) from my original review.	Review	O	0
[line_break_token][line_break_token]On (2), I did realize that features from multiple layers are used, but this doesn't theoretically prevent the generator from achieving the global minimum of the objective by producing a single image whose features are the mean of the features in the dataset.	Review	B-Review	7
That being said, the paper shows that this doesn't tend to happen in practice with existing classifiers, which is an interesting empirical contribution. (	Review	I-Review	7
It would be nice to also see ablation studies on this point, showing the results of training against features from single layers across the network.)	Review	I-Review	7
[line_break_token][line_break_token]On (6), I'm still unconvinced that making use of ImageNet classifiers isn't providing something like a conditional training signal, and that using such classifiers isn't a bit of an "unfair advantage" vs. other methods when the metrics themselves are based on an ImageNet classifier.	Review	I-Review	8
I realize that ImageNet and CIFAR have different label sets, but most if not all of the CIFAR classes are nonetheless represented -- in a finer-grained way -- in ImageNet.	Review	I-Review	8
If ImageNet and CIFAR were really completely unrelated, an ImageNet classifier could not be used as an evaluation metric for CIFAR generators. (	Review	I-Review	8
And yes, I saw the CelebA results, but for this dataset there's no quantitative comparison with prior work, and qualitatively, if the results are as good as or better than the 3 year old DCGAN results, I can't tell.)	Review	I-Review	8
[line_break_token][line_break_token]On the other hand, given that the approach relies on these classifiers, I don't have a good suggestion for how to control for this and make the comparison with prior work completely fair.	Review	I-Review	9
Still, it would be nice to see acknowledgment and discussion of this caveat in a future revision of the paper.	Review	I-Review	9
[line_break_token][line_break_token]Overall, given that most of my concerns have been addressed with additional experiments and clarification, and that the paper is well-written and has some interesting results from its relatively simple approach, I've raised my rating to above acceptance threshold.	Review	O	0
[line_break_token]We would like to thank the reviewer for the questions and comments.	Reply	O	0
[line_break_token]In order to better address your concerns, we have uploaded a new version of the paper that contains three new appendices: A.11, A.12 and A.13.	Reply	O	0
Please see below our detailed reply for your questions/comments.	Reply	O	0
We believe that the new added appendices and the clarifications given in our reply will address all the concerns and misconceptions of the reviewer.	Reply	O	0
 [line_break_token][line_break_token]1) About the loss function and novelty:[line_break_token][line_break_token]AUTHORS:  Regarding the objective function, please note that, in the paper, we never mentioned that our loss function is novel, nor that we were the first to perform feature matching.	Reply	O	0
As you mentioned, one of the key novelties is on avoiding the min/max game by using a pretrained feature extractor, which sets our work completely apart from [Salimans et al.,	Reply	B-Reply	1
2016] and [Warde-Farley & Bengio, 2017]. In addition, notice that differently from [Salimans et al.,	Reply	O	0
2016] and [Warde-Farley & Bengio, 2017] we perform feature matching using all the layers of the network and this is extremely important for the good performance of the method (as you can see in Table 2).	Reply	O	0
[line_break_token][line_break_token]The research community in generative models has spent the last few years trying to figure out methods to make GANs training more stable.	Reply	B-Reply	1
Here we offer an alternative novel method that is competitive with GANs while moving away completely from the problematic min/max game.	Reply	I-Reply	1
Hence, it is safe to say that the paper presents a relevant novel contribution for the research community in generative models.	Reply	I-Reply	1
[line_break_token][line_break_token]2)  Muli-scale features (on multiple layers of the CNN)  prevent degeneracy of the generator : [line_break_token][line_break_token]AUTHORS:  Please note that our loss does not perform matching using a single feature map, it uses many layers to do feature matching, and this is crucial to prevent such degeneracy.	Reply	O	0
As we are matching effectively on f_1... f_m where m are are features extracted on different layers, we are getting matching on different scales of the generated image.	Reply	B-Reply	2
Hence the claim of the reviewer that nothing prevents degeneracy in the objective is not true, and this is not an artifact of the features, it is due to the multi-scale nature of the features!	Reply	I-Reply	2
 This multi-feature matching on multiple scales regularizes the learning of the generator.	Reply	I-Reply	2
We quote here [1]: " representations obtained across the layers of a CNN increasingly capture the statistical properties of natural images, producing impressive texture synthesis results".	Reply	I-Reply	2
  [line_break_token][line_break_token]Note that this multi-features matching has been exploited also in end to end style transfer, or super-resolution [1], but it is novel in generative modeling context .	Reply	I-Reply	2
In [1] for instance, the authors show that by matching CNN layers of a pretrained network  one can do super-resolution, we push these observation further by showing that those multi scale features are sufficient statistics also for generation.	Reply	I-Reply	2
 Moreover  our empirical results on generation from those deep priors from pretrained features complements theoretical results in [2], that gives theoretical guarantees  for signal recovery from features of deep networks in inverse problems.	Reply	I-Reply	2
[line_break_token][line_break_token][1] Bruna et al.	Reply	O	0
Super-Resolution with Deep Convolutional Sufficient Statistics.	Reply	O	0
ICLR 2016, <a href="https://arxiv.org/pdf/1511.05666.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1511.05666.pdf</a>[line_break_token][2]Global Guarantees for enforcing deep generative priors by empirical risk minimization, Hand et al.	Reply	O	0
[line_break_token]<a href="https://arxiv.org/pdf/1705.07576.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.07576.pdf</a>	Reply	O	0

The paper is an extension of the matching networks by Vinyals et al.	Review	O	0
in NIPS2016.	Review	O	0
Instead of using all the examples in the support set during test, the method represents each class by the mean of its learned embeddings.	Review	O	0
The training procedure and experimental setting are very similar to the original matching networks.	Review	B-Review	1
I am not completely sure about its advantages over the original matching networks.	Review	I-Review	1
It seems to me when dealing with 1-shot case, these two methods are identical since there is only one example seen in this class, so the mean of the embedding is the embedding itself.	Review	I-Review	2
When dealing with 5-shot case, original matching networks compute the weighted average of all examples, but it is at most 5x cost.	Review	I-Review	2
The experimental results reported for prototypical nets are only slightly better than matching networks.	Review	I-Review	3
I  think it is a simple, straightforward,  novel extension, but I am not fully convinced its advantages.	Review	I-Review	3
We thank Reviewer 2 for reviewing our paper.	Reply	O	0
This review‚Äôs main criticism is that our approach is too similar to the matching networks model proposed by Vinyals et al.	Reply	O	0
2016.	Reply	O	0
We will update the related work section of our paper to clarify the relationship between prototypical networks and matching nets.	Reply	O	0
In the meantime, we would like to take this opportunity to elaborate upon some of the benefits of our approach relative to matching networks: better computational efficiency, a simpler form for the classifier, and a straightforward extension to the zero-shot setting.	Reply	O	0
[line_break_token][line_break_token]First and foremost, prototypical networks are computationally more efficient than matching networks.	Reply	B-Reply	1
If there are K classes, each with N support examples, then computing distances for a query point will take O(K) time for prototypical networks vs. O(KN) for matching networks.	Reply	I-Reply	1
This is indeed a 5x speedup for the 5-shot scenario, which though not enormous is also not insignificant.	Reply	I-Reply	1
Even slightly larger scales such as N=10 or N=100 would lead to useful performance gains.	Reply	I-Reply	1
We see favorable applications of our approach to tasks such as document tagging where it is important to quickly label new documents without needing to compute distances to multiple support examples per tag.	Reply	I-Reply	1
[line_break_token][line_break_token]Second is the simpler expression of our classifier (see Section 3.2 of our paper) compared to the non-parametric form of matching networks.	Reply	I-Reply	2
Not only does this require less storage (O(K) vs. O(KN)) but it also sets the stage for future work that explores the prediction of alternate classifiers beyond the linear ones we investigate here.	Reply	I-Reply	2
[line_break_token][line_break_token]Finally, our approach affords a straightforward extension to the zero-shot setting that matching networks do not.	Reply	I-Reply	3
The matching networks approach is fundamentally about embedding support examples whereas prototypical networks focuses on learning an embedded representation for each class.	Reply	I-Reply	3
For the few-shot scenario we chose our representation to be the mean of embedded points, while for the zero-shot scenario we utilized the embedded metadata.	Reply	I-Reply	3
Such a generalization of the matching networks approach to zero-shot classification does not exist	Reply	I-Reply	3

This paper sets to understand whether pretraining word embeddings for[line_break_token]programming language code by using NLP-like language models has an[line_break_token]impact on extreme code summarization task (i.e., generate/predict the[line_break_token]name of a function based on its body).	Review	O	0
[line_break_token][line_break_token]I think the paper asks some important questions, however the execution[line_break_token]of the research and the results presented are not convincing.	Review	O	0
[line_break_token][line_break_token]I think the area is relevant and the research questions are worth[line_break_token]pursuing; however the work as it is presented in the paper needs[line_break_token]improvement to be accepted for publication.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]* The study of language models for programming language code[line_break_token]* Pretraining is performed for 3 different languages (C, Java, Python) - target task is in Python[line_break_token][line_break_token]Cons:[line_break_token]* Strange claims of speedup and performance improvement[line_break_token]* Inconclusive results[line_break_token][line_break_token]Some suggestions for improvement:[line_break_token][line_break_token]* The section on language models pretraining is very sparse, more[line_break_token]  details are needed.	Review	O	0
[line_break_token][line_break_token]* The claims of speedup and improvement are strange.	Review	O	0
Speedup refers to[line_break_token]  the training speed, I suppose.	Review	B-Review	2
The performance of the downstream[line_break_token]  task is never discussed.	Review	I-Review	2
Only the validation loss is shown and all[line_break_token]  the performance "improvement" is discussed on these graphs, which I[line_break_token]  found strange.	Review	I-Review	2
Also, the graphs have their y-axes starting at[line_break_token]  non-zero values.	Review	I-Review	2
I personally prefer graphs that start at zero and[line_break_token]  if there is a need to "zoom-in" find a way to "zoom-in" to the part[line_break_token]  of the graph that is important.	Review	I-Review	2
[line_break_token][line_break_token]* In general the paper writing and reporting on the experiments sounds[line_break_token]  ad-hoc and not well thought-out.	Review	O	0
[line_break_token][line_break_token]* I don't agree with many of the explanations in the paper.	Review	O	0
For[line_break_token]  example (page 6), it's not true that the extreme summarization task[line_break_token]  does not require much of the syntactic information (there are[line_break_token]  submission at the current ICLR'19 that show exactly the opposite,[line_break_token]  encoding based on syntactic information is useful).	Review	B-Review	4
The model[line_break_token]  studied in the paper does NOT use any syntactic information, it[line_break_token]  treats the code like a sequence of tokens.	Review	I-Review	4
[line_break_token][line_break_token]* The last question in Section 6 is not a Yes/No question, the answer[line_break_token]  is phrased as a Yes/No question.	Review	O	0
[line_break_token][line_break_token]I encourage the authors to pursue the research questions, however in a[line_break_token]more systematic and with better methodology.	Review	O	0
Thank you for the comments and feedback.	Reply	O	0
[line_break_token][tab_token][line_break_token]1.	Reply	O	0
We have added details about the size of the datasets for the language modeling.	Reply	B-Reply	1
More details about the model are available in the papers by Merity et al.,	Reply	I-Reply	1
which is referenced in our paper.	Reply	I-Reply	1
[line_break_token][tab_token][line_break_token]2.	Reply	O	0
You are correct in that speedup refers to the increase in training speed.	Reply	B-Reply	2
This is detailed in the results section where we mention how speedup, S, is calculated as the number of epochs taken by the random embeddings to reach its best validation loss, N\_r, divided by the number of epochs taken by a non-random embedding to reach that same validation loss, N\_e.	Reply	I-Reply	2
[line_break_token][tab_token][line_break_token]3.	Reply	O	0
The downstream task in this experiment is the extreme summarization task.	Reply	B-Reply	2
We have clarified this in the abstract \& introduction.	Reply	O	0
[line_break_token][tab_token][line_break_token]4.	Reply	O	0
The performance improvement is for the test loss (using the parameters achieved from the lowest validation loss).	Reply	B-Reply	2
The paper previously incorrectly stated that improvement was calculated via the validation loss and this has now been corrected.	Reply	I-Reply	2
We have also added a table of results for the rank 1 F1 scores and made sure to explicitly mention the performance improvements (both for F1 scores and test loss) in the results section.	Reply	I-Reply	2
[line_break_token][tab_token][line_break_token]5.	Reply	O	0
We agree that syntactic information is useful and you are correct in that the model is not explicitly fed the syntactic information.	Reply	B-Reply	4
However, the model does implicitly use syntactic information as the syntax does exist within the sequence of tokens.	Reply	I-Reply	4
Furthermore, as per AnonReviewer1's comments, we have added results obtained from using embeddings trained on a natural language (English), and have shown they achieve comparable results to each of the programming languages used.	Reply	I-Reply	4
As all 4 of these embeddings achieve similar results - with the main difference between them being the syntax - we would argue that this supports the view that the syntax is less important - although admittedly still useful - than the semantic information provided by sensible variable names for this task.	Reply	I-Reply	4
We do think the usefulness of syntactic information for the extreme summarization task is an interesting area of research and requires further investigation, but we believe it is outside the scope of this work.	Reply	I-Reply	4
[line_break_token][tab_token][line_break_token]6.	Reply	O	0
Thank you for spotting the error with RQ6, this has now been corrected.	Reply	B-Reply	5

[line_break_token]CONTRIBUTIONS:[line_break_token][line_break_token]C1.	Review	O	0
Cross-linguistic token overlap.	Review	O	0
Fake-English: English, but with the Unicode codes of English characters all shifted by a large constant so that there is no overlap between Fake-English characters and those of actual languages, but the language-internal structure remains that of English.	Review	O	0
[line_break_token][line_break_token]C2.	Review	O	0
A bilingually-trained BERT, pretrained on languages L and L‚Äô, is then trained on a downstream task in L then tested on that task in L‚Äô.	Review	O	0
The task is Cross-Lingual NLI (XNLI) or Cross-Lingual NER.	Review	O	0
L‚Äô is Spanish, Hindi, or Russian.	Review	O	0
L is English or Fake-English.	Review	O	0
Comparing the success at test when L = English vs. when L = Fake-English, it is shown that eliminating all token overlap between L and L‚Äô has a small effect (less than 1.5% on XNLI, less than about 3.5% on NER). (	Review	O	0
Table 1)[line_break_token][line_break_token]C3.	Review	O	0
Several architectural parameters of BERT are varied holding the others roughly constant (same tasks as C2, with L = Fake-English).	Review	O	0
This shows that depth (Table 2) and level of tokenization matter (Table 7), while little effect results from varying the number of attention heads (Table 3), number of parameters (Table 4), whether the next sentence prediction task is used for training (Table 5), or whether the language of an input is explicitly given (Table 6).	Review	O	0
[line_break_token][line_break_token]C4.	Review	O	0
Testing cross-language entailment on XNLI by B-BERT shows that there is a large reduction in performance when the hypothesis and premises sentences are from different languages.	Review	O	0
[line_break_token][line_break_token]RATING: Weak reject[line_break_token][line_break_token]REASONS FOR RATING (SUMMARY).	Review	O	0
Aside from the invention of Fake-English, which as far as I know is original and a clever approach to assessing the importance of token overlap in cross-language transfer, the other contributions are reporting results of mechanical changes.	Review	O	0
The paper‚Äôs contributions are useful, but do not reach a level of generality, originality, or depth justifying presentation at ICLR.	Review	B-Review	1
[line_break_token][line_break_token]Although it did not factor into my rating, I would like to point out that saying ‚Äòstructural similarity is important‚Äô and saying ‚Äòword-piece overlap is not important‚Äô is saying exactly the same thing twice, since the gain not attributable to word-piece overlap, by their definition, equals the gain due to ‚Äòstructural similarity‚Äô, which is a concept otherwise undefined and unmeasurable.	Review	I-Review	2
e sincerely thank the reviewer for reviewing our paper.	Reply	O	0
[line_break_token]&gt; **Lack of generality, originality or depth**[line_break_token][line_break_token](1) First, we would like to point out that this paper is the first to propose an experimental design that proves that word-pieces overlap do not contribute to the transferability of M-BERT.	Reply	O	0
This was done by inventing the notion of Fake-English, with a distinct word-piece space.	Reply	B-Reply	2
Moreover, we believe that the methodology we propose in this paper is general enough to support additional insights, and will be followed up by other authors, and therefore this in itself is a significant contribution.	Reply	I-Reply	2
[line_break_token][line_break_token](2) Second, while the design of our architectural experiments may not be sophisticated, we are the first to perform this set of experiments systematically, and identify the aspects of the architecture that are important for transferability, as well as those that are not.	Reply	O	0
We believe that this, too, is an important contribution to understanding M-BERT.	Reply	B-Reply	1
Further, we have added a few more results on the number of parameters to understand the threshold, and also showed that we can get comparable performance with only a small number of parameters and attention heads, even in multilingual case (four language BERT).	Reply	I-Reply	1
Please refer to appendix section ‚ÄúFURTHER DISCUSSIONS ON ARCHITECTURE‚Äù[line_break_token][line_break_token](3) Third, our results are the first to show clearly that the transferability of M-BERT depend on some aspect of structural similarity between the languages, and has nothing to do with lexical similarity.	Reply	O	0
While we have not isolated yet which aspects of structural similarity contribute to transferability, and how much, this is already an important contribution, please refer to the appendix section ‚ÄúFURTHER  DISCUSSIONS ON STRUCTURAL SIMILARITY‚Äù, for some of our initial experiments that break this down a bit more.	Reply	B-Reply	1
[line_break_token][line_break_token](4) Our final observation of the drastic drop in performance when the premise and hypothesis are in different languages (Table 8) might suggest that BERT is simply learning the word matching instead of learning the actual entailment.	Reply	O	0
This observation definitely needs special attention to understand what BERT learns from entailment supervision.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token]General comment:[line_break_token]Also, please take a look at the general comments for more on structural similarity and the number of parameters experiment.	Reply	O	0

The authors propose and evaluate using SPN's to generate embeddings of input and output variables, and using MPN to decode output embeddings to output variables.	Review	O	0
The advantage of predicting label embeddings is to decouple dependencies in the predicted space.	Review	O	0
The authors show experimentally that using SPN based embeddings is better than those produced by RBM's.	Review	O	0
[line_break_token][line_break_token]This paper is fairly dense and a bit hard to read.	Review	O	0
After the discussion, the main contributions of the authors are:[line_break_token][line_break_token]1.	Review	O	0
They propose the scheme of learning SPN's over Y and then using MPN's to decode the output, or just SPNs to embed X.[line_break_token]2.	Review	O	0
They propose how to decode MPN's with partial data.	Review	O	0
[line_break_token]3.	Review	O	0
They perform some analysis of when their scheme will lead to perfect encoding/decodings.	Review	O	0
[line_break_token]4.	Review	O	0
They run many, many experiments comparing various ways of using their proposed method to make predictions on multi-label classification datasets.	Review	O	0
[line_break_token][line_break_token]My main concerns with this paper are as follows:[line_break_token][line_break_token]- The point of this paper is about using generative models for representation learning.	Review	O	0
In their experiments, the main task is discriminative; e.g. predict multiple Y from X. The only discriminative baseline is a L2 regularized logistic regression, which does not have any structure on the output; it'd be nice to see how a discriminative structured prediction method would do, such as CRF or belief propagation.	Review	O	0
[line_break_token][line_break_token]- The many experiments suggest that their encoder/decoder scheme is working better than the alternatives; can you please give more details on the relative computation complexity of each method?	Review	O	0
[line_break_token][line_break_token]- One thing I'm still having trouble understanding is *why* this method works better than MADE and the other alternatives.	Review	O	0
Is it learning a better model of the distribution of Y?	Review	O	0
Is it better at separating out correlations in the output into individual nodes?	Review	O	0
 Does it have larger representations?	Review	O	0
[line_break_token][line_break_token]- I think the experiments are overkill and if anything, they way they are presented detract from the paper.	Review	O	0
There's already far too many numbers and graphs presented to be easy to understand.	Review	O	0
 If I have to dig through hundreds of numbers to figure out if your claim is correct, the paper is not clear enough.	Review	O	0
And, I said this before in my comments, please do not refer to Q1, Q2, etc. --	Review	O	0
these shortcuts let you make the paper more dense with fewer words but at the cost of readability.	Review	O	0
[line_break_token][line_break_token]I *think* I convinced myself that your method works...I would love to see a table that shows, for each condition: (A) a baseline X->Y, (B) one *average* result across datasets for your method, and (C) one *average* result from a reasonable best competitor method.	Review	O	0
Please show for both the exact match and hamming losses, as that will demonstrate the gap between independent linear prediction and structured prediction.	Review	O	0
That would still be plenty of numbers but would make it much easier for the reader to verify your claims and you can put everything else in the Appendix.	Review	O	0
 E.g. something like:[line_break_token][line_break_token]Input | Predicted Output | Decoder | Hamming | Exact Match[line_break_token]----[line_break_token]X | P(Y) | CRF | xx.xx | xx.xx   (this is your baseline)[line_break_token]SPN E_X | P(Y) | n/a | xx.xx | xx.xx [line_break_token]X | SPN E_Y | MPN | xx.xx | xx.xx  (given X, predict E_Y, then decode it with an MPN)[line_break_token][line_break_token]Does a presentation like that make sense?	Review	O	0
It's just really hard and time-consuming for me as a reviewer to verify your results, the way you've laid them out currently.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
--------------------------[line_break_token]Dear reviewer, thanks for your time and suggestions.	Reply	O	0
[line_break_token]We will try to answer your questions more in detail, hoping to improve the paper towards a full acceptance.	Reply	O	0
[line_break_token][line_break_token][line_break_token]> The point of this paper is about using generative models for	Reply	O	0

This paper studies the effects of using function of ngram statistics as feature to generate attention score per word.	Review	O	0
The attention score is then used as weights to aggregate document embedding by doing a weighted average on word embedding.	Review	O	0
The output is finally fed into a ridge regressor to do the final predictions on target labels.	Review	O	0
[line_break_token][line_break_token]Main comments:[line_break_token]This paper has a clear motivation and decent experimental results (though some concern on baseline models, see below).	Review	O	0
The introduction of using distributional signature to derive attention scores seems interesting and a novel contribution.	Review	B-Review	1
However I was not able to fully understand the intuition behind the benefit of doing attention mechanism on top of ngram statistics (see my question below as well).	Review	I-Review	1
[line_break_token]Also the reference/baseline models used in the experiment might not be strong enough.	Review	I-Review	2
If you could compare your model with some latest algorithms proposed in the few-shot-learning communities, that would be more convincing as well.	Review	I-Review	2
[line_break_token]To list a few:[line_break_token]* P-MAML: [Zhang et al.,	Review	I-Review	2
2019][line_break_token]* Induction-Network-Routing: [Geng et al.,	Review	I-Review	2
2019][line_break_token]* ROBUSTTC-FSL [Yu et al.,	Review	I-Review	2
2018][line_break_token][line_break_token]I am leaning to give a "weak reject" based on my current knowledge and understanding of the paper.	Review	O	0
But I will be willing to revisit the decision after we get feedback from the author(s).	Review	O	0
[line_break_token][line_break_token]In particular, I would be glad if the author could clarify the questions below.	Review	O	0
[line_break_token][line_break_token]* From table 1, it seems Method IDF+RR is a competitive model.	Review	O	0
IIUC, the statistics of s(.)	Review	B-Review	3
is highly correlated with IDF which also indicates general word importance in corpus.	Review	I-Review	3
My questions are that, [line_break_token]1) regarding ablation test "OUR w/o biLSTM", how is calculated in this case (without biLSTM)?	Review	I-Review	3
[line_break_token]2) since each word is represented based on two statistical number (map function by t(.)	Review	O	0
and s(.)),	Review	B-Review	4
can you give any intuitive explanation that why getting attention score from that makes sense?	Review	I-Review	4
[line_break_token]3) do you have any experiments using the distributional signature as a common feature in standard text classification problems?	Review	O	0
In other words, is this method only (significantly) beneficial to few-short-learning?	Review	B-Review	5
If it is also useful in general text classification task, it would be a good "plus" here.	Review	I-Review	5
[line_break_token][line_break_token]* From table 2, can you explain why CNN+RR benefits a lot from the BERT embedding?	Review	O	0
Actually it gets more percentage of improvement than the model "OUR".	Review	B-Review	6
[line_break_token][line_break_token]* For all the usages of pre-trained embedding (fasttext or BERT), are you further finetuning the embedding parameters during your training?	Review	O	0
Or you freeze the embedding parameters?	Review	B-Review	7
[line_break_token][line_break_token][Zhang et al.,	Review	I-Review	2
2019] Ningyu Zhang et al.,	Review	O	0
Improving Few-shot Text Classification via Pretrained Language Representations.	Review	O	0
arXiv preprint arXiv: 1908.08788[line_break_token][Geng et al.,	Review	O	0
2019] Ruiying Geng, Binhua Li, Yongbin Li, Yuxiao Ye, Ping Jian, and Jian Sun.	Review	O	0
2019.	Review	O	0
Few-shot text classification with induction network.	Review	O	0
arXiv preprint arXiv:1902.10482.	Review	O	0
[line_break_token] [Yu et al.,	Review	B-Review	2
2018] Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng, Gerald Tesauro, Haoyu Wang,[line_break_token]and Bowen Zhou.	Review	O	0
2018.	Review	O	0
Diverse few-shot text classification with multiple metrics.	Review	O	0
arXiv preprint arXiv:1805.07513	Review	O	0
hank you for the detailed comments and suggestions!	Reply	O	0
[line_break_token][line_break_token]The main idea of the paper is that if we want to learn transferable knowledge, methods that memorize word identities will fail when the word distribution shifts.	Reply	B-Reply	1
By learning meta-knowledge on top of n-gram statistics, class-specific words will still be important (and common stop words unimportant), even if the actual words themselves change. (	Reply	I-Reply	1
More specific example regarding our two statistics below.)	Reply	I-Reply	1
[line_break_token][line_break_token]Additional Experiments: Based on the suggestions, we have compared our work to P-MAML and Induction Network Routing.	Reply	O	0
Detailed results are located in Appendix A.5.	Reply	B-Reply	2
[line_break_token] [line_break_token]On average, our method outperforms P-MAML by 18.5% on 1-shot and 19.3% on 5-shot, and Induction Networks by 21.1% on 1-shot and 32.4% on 5-shot (Table 4).	Reply	I-Reply	2
While both P-MAML and Induction Networks are able to overfit the meta-train data easily, they are unable to generalize when faced with lexical mismatch (Figure 9).	Reply	I-Reply	2
[line_break_token][line_break_token]Furthermore, we show that we can improve Induction Networks by replacing its lexically-aware encoder with our attention-weighted representation learned from distributional signatures  (Appendix A.9).	Reply	I-Reply	2
On average, distributional signatures increase Induction Networks accuracy by 14.3% on 1-shot and 25.1% on 5-shot.	Reply	I-Reply	2
[line_break_token][line_break_token]RobustTC-FSL is not directly applicable to our setting since it considers a fixed set of tasks during meta-training (e.g. binary sentiment classification across 23 Amazon domains) and utilizes their cross-task transferability.	Reply	I-Reply	2
[line_break_token][line_break_token]Questions:[line_break_token]* s(.)	Reply	O	0
and IDF both indicate general word importance.	Reply	B-Reply	3
We experimented with both during our development stage and found that they perform similarly when used in our attention generator (idf 77.8 vs s(.)	Reply	I-Reply	3
78.0 for 5 shot classifications averaged across 6 datasets).	Reply	I-Reply	3
We choose the current formulation as it is more interpretable in context of robustness against word-substitution perturbation.	Reply	I-Reply	3
[line_break_token][line_break_token]1) We apply an MLP on top of the [s(); t()] at each position, where ; denotes concatenation.	Reply	I-Reply	3
After that we applied softmax over the output of the MLP.	Reply	I-Reply	3
This MLP has 2 inputs, 50 hidden units (ReLU activation) and 1 output.	Reply	I-Reply	3
[line_break_token][line_break_token]2) One indicates word importance for general classification (estimated from source pool) and the other indicates how important the feature is for this particular task (a rough estimate).	Reply	O	0
[line_break_token][line_break_token]For example, suppose we have lots of data from political and sports news, and we want to expand into arts news.	Reply	B-Reply	4
General word importance (learned from politics and sports) can tell us that words like ‚Äúthe‚Äù and ‚Äúwe‚Äù are not useful, so we learn to ignore them.	Reply	I-Reply	4
However, politics and sports news also have no use for arts-specific words, like ‚Äúpainting‚Äù or ‚Äúperformance.	Reply	I-Reply	4
‚Äù Thus, we require task-specific word importance (learned from few arts examples) to refine our understanding of useful words.	Reply	I-Reply	4
[line_break_token][line_break_token]3) The general idea of ‚Äúdistributional signatures‚Äù is not new.	Reply	O	0
Prior to the age of deep learning, linear SVM + TF-IDF was considered a strong baseline to beat, and more recently, Arora 2016 showed that SIF-weighted representations (statistics used for s(.)	Reply	B-Reply	5
in our model) do outperform LSTMs/CNNs on some (standard) tasks.	Reply	I-Reply	5
In our setting, we noted that the idea may also be helpful for few-shot classification, as these statistics are more transferable across tasks.	Reply	I-Reply	5
For general classification tasks with lots of annotation, the representation power of distribution signatures may be limited (though this is slightly beyond the scope of our paper).	Reply	I-Reply	5
[line_break_token][line_break_token]* BERT is contextual, so the embedding of one word represents not only itself, but also its surroundings.	Reply	O	0
Correspondingly, if a CNN downweights an important word from an unseen class, its adjacent words still contain information about that word.	Reply	B-Reply	6
This means that it is less ‚Äúcostly‚Äù to ignore important words from unseen classes, as a result of overfitting on seen classes.	Reply	I-Reply	6
For OUR, this means that we don‚Äôt have to be as precise about picking out each important word.	Reply	I-Reply	6
[line_break_token][line_break_token]* Since the vocabulary of meta-train classes and meta-test classes may be very different, we freeze the pre-trained embeddings (Fasttext or BERT) during meta training.	Reply	O	0
This is to avoid disrupting the inherent geometry of word embeddings, as finetuning will cause these embeddings to lose the relationship between meta-train vocabulary (seen during finetuning) and meta-test vocabulary (not seen, and thus not optimized for).	Reply	B-Reply	7
Empirically, we show that freezing word embeddings outperforms finetuning (Table 6).	Reply	I-Reply	7
[line_break_token][line_break_token]We hope we have adequately addressed your concerns.	Reply	O	0
Please let us know if you have any more questions.	Reply	O	0
Thank you!	Reply	O	0

This paper puts forward a new schema for language modeling, especially for relationship between two parts far apart.	Review	O	0
[line_break_token][line_break_token]The experimental results on WikiText-103 are good, improving the STOA PPL by 9.0.	Review	O	0
On the other three datasets, however, there's little or no gain.	Review	O	0
The speed comparison should be carried out over more LM models, as Al-Rfou is not the fastest.	Review	O	0
[line_break_token][line_break_token]The writing is not very clear, especially around equations.	Review	O	0
[line_break_token][line_break_token]Overall the contribution of this paper is marginally incremental:[line_break_token]1.	Review	O	0
The major proposed idea is just to add one no-grad previous segment into the prediction for next segment.	Review	O	0
This is similar to Residual network idea but more simplified.	Review	O	0
[line_break_token]2.	Review	O	0
Using relative positional encoding is not a new idea, e.g. <a href="https://arxiv.org/pdf/1803.02155.pdf."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1803.02155.pdf.</a>[line_break_token]3.	Review	O	0
Reusing previous level/segment computation with gradient fixed is also not a big innovation.	Review	O	0
[line_break_token][line_break_token]typo:[line_break_token]1.	Review	O	0
end of page 3, and "W." denotes".	Review	O	0
[line_break_token]2.	Review	O	0
The speed experiment should be put in the main text.	Review	O	0
Dear reviewer, we believe we have addressed your concerns in the rebuttal (see the General Response above and the comments below).	Reply	O	0
Especially, we have further improved over state-of-the-art results ever since.	Reply	O	0
Do you have an updated assessment or other concerns of our paper?	Reply	O	0
Thank you	Reply	O	0

The paper introduces a new intrinsic reward for MARL, representing the causal influence of an agent‚Äôs action on another agent counterfactually.	Review	O	0
The authors show this causal influence reward is related to maximising the mutual information between the agents‚Äô actions.	Review	O	0
The behaviour of agents using this reward is tested in a set of social dilemmas, where it leads to increased cooperation and communication protocols, especially if given an explicit communication channel.	Review	O	0
As opposed to related work, the authors also equip the agents with an internal Model of Other Agents that predicts the actions of other agents and simulates counterfactuals.	Review	O	0
This allows the method to run in a decentralized fashion and without access to other agents‚Äô reward functions.	Review	O	0
[line_break_token][line_break_token]The paper proposes a very interesting approach.	Review	O	0
I‚Äôm not a MARL expert, so I focused more on the the causal aspects.	Review	O	0
The paper seems generally well-organized and well-written, although I‚Äôm a bit confused about the some of the causal modelling decisions and assumptions.	Review	O	0
This confusion and  some potential errors, which I describe in detail below, are the reason for my borderline decision, despite liking the paper otherwise.	Review	O	0
[line_break_token] [line_break_token]First, I‚Äôm a bit confused about the utility of the Section 2.1 model (Figure 1), mostly because of the temporal and multiple agents aspects that seem to be dealt with (‚Äúmore‚Äù) correctly in the MOA model.	Review	O	0
Specifically in Figure 1, one would need to assume that there is only one agent A influencing agent B at the same time (and agent B does not influence anything else).	Review	B-Review	1
For example, there is no other agent C which actions also influence agent B, and no agent D that is influenced by agent B, otherwise the backdoor-criterion would not work, unless you add also the action of agent C to the conditioning set (or its state).	Review	I-Review	1
Importantly, adding the actions of all agents, also a potential agent D that is downstream of B would be incorrect.	Review	I-Review	1
So in this model there is some kind of same time interaction and there seems to be the need for a causal graph that is known a priori.	Review	I-Review	1
These problems should disappear if one assumes that only the time t-1 actions can influence the time t actions, as in the MOA model.	Review	I-Review	1
I assume the idea of the Figure 1 model was to show a relationship with mutual information, but for me specifically it was quite confusing.	Review	I-Review	1
[line_break_token][line_break_token]I was much less confused by the MOA causal graph represented in Figure 4, although I suspect there are quite some interactions missing (for example s_t^A causes u_t^A similarly to the green background?	Review	I-Review	2
s_t causes s_{t+1} (which btw in this case should probably be split in two nodes, one s_{t+1} and one s_{t+1}^B?).	Review	I-Review	2
Possibly one could also add the previous time step for agent B (with u_{t+1}^B influenced by u_t^B I would assume?).	Review	I-Review	2
As far as I can see there is no need to condition on a_t^B in this case to see the influence of a_t^A on a_{t+1}^B, u_t^A and s_t^A should be enough?	Review	I-Review	2
[line_break_token][line_break_token]Minor details:[line_break_token]Is there possibly a log missing in Eq.	Review	O	0
2?	Review	B-Review	3
[line_break_token]	Review	O	0
Thanks for your feedback - we are glad that you found the paper interesting, and we hope to be able to clear up any confusion surrounding the causal modeling.	Reply	O	0
[line_break_token][line_break_token]You are correct that the first method of implementing the causal influence reward described in section 2.1 has the important limitation that agents cannot mutually influence each other.	Reply	B-Reply	1
However, we believe we have handled the conditioning correctly to satisfy the back door criterion, by imposing a sequential ordering on agents‚Äô actions.	Reply	I-Reply	1
We allow only a fixed number of agents to be influencers, and the rest are influencees.	Reply	I-Reply	1
Only an influencer gets the causal influence reward, and only an influencee can be influenced.	Reply	I-Reply	1
At each timestep, the influencers choose their actions first, and these actions are then given as input to the influencees.	Reply	I-Reply	1
Let‚Äôs say that agent A and B are influencers, and C is an influencee.	Reply	I-Reply	1
Then C receives both a^A_t and a^B_t as input.	Reply	I-Reply	1
When computing the causal influence of A on C, we also add a^B_t to the conditioning set, as you describe.	Reply	I-Reply	1
However, we do not condition on actions downstream of C, as you mention.	Reply	I-Reply	1
You are correct that in this model the causal graph does need to be known a priori, and in that sense it is more limited.	Reply	I-Reply	1
We only introduced this initial model as a proof-of-concept, and retained it in the paper because it is associated with some of the interesting qualitative results we present in Section 4.1.	Reply	I-Reply	1
We will modify the paper to include a more detailed description of the sequential nature of agents‚Äô actions in order to reduce confusion in the future.	Reply	I-Reply	1
However, you are correct that the MOA approach is likely to be more effective in practice, and we would like to emphasize the success of this approach, and the communication results in Section 4.2, as more important contributions.	Reply	I-Reply	1
[line_break_token][line_break_token]You are right that we are missing an arrow from s_t -> s_{t+1}, and the partially observed states s^B_{t+1} in Figure 4; we will add these to the Figure and update it in the next revision.	Reply	O	0
You are also correct that we do not need to condition on a_t^B, but we do allow the model to use a_t^B when making its predictions about a_{t+1}^B, so we have shown this as shaded in the Figure.	Reply	B-Reply	2
 [line_break_token][line_break_token]We don‚Äôt believe there is a missing log in equation 2; the log is absorbed into the KL term.	Reply	O	0

The paper proposes simple modifications to GAN architecture for unsupervised conditional image generation.	Review	O	0
The authors achieve this by making the distribution of noise z dependent on variable y that can depend on the label distribution when available.	Review	O	0
This involves learning to predict the input noise z as well as y from the generated image.	Review	O	0
The qualitative results shown for unsupervised conditional image generations using the approach are convincing.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token][tab_token]- The paper is well written and easy to follow.	Review	O	0
[line_break_token][tab_token]- The simple modification to the noise distribution leads to good results on unsupervised conditional image generation.	Review	O	0
[line_break_token][tab_token]- Minimizes loss terms exactly instead of lower bound as is commonly done in other similar unsupervised approaches.	Review	O	0
[line_break_token][tab_token]- Theoretical justifications for the approach are convincing.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][tab_token]- The paper can be strengthened by including ablation studies on the loss term for the z reconstruction.	Review	O	0
[line_break_token][tab_token]- How will InfoGAN and VEEGAN compare with similar loss terms for the z reconstruction added to their objective?	Review	O	0
[line_break_token][tab_token]- It will be useful to show FID and other similar scores to better evaluate the learned generative model.	Review	O	0
Including mode counting, experiments will strengthen the paper.	Review	B-Review	3
[line_break_token][tab_token]- ACGAN can suffer from the issue of generating images where it is easy to infer y [1]. This leads to mode collapse within each category/class.	Review	O	0
Will the proposed approach suffer from similar issues?	Review	B-Review	4
[line_break_token][line_break_token][1] Shu, Rui, Hung Bui, and Stefano Ermon. "	Review	O	0
AC-GAN Learns a Biased Distribution."	Review	O	0
We thank the reviewer for the constructive feedback and comments.	Reply	O	0
Below are our responses for the concerns raised.	Reply	O	0
We are happy to answer further questions, if any.	Reply	O	0
[line_break_token][line_break_token]Q1.	Reply	O	0
The paper can be strengthened by including ablation studies on the loss term for the z reconstruction.	Reply	O	0
[line_break_token][line_break_token]Ans: Thank you for this suggestion.	Reply	O	0
We have now included the ablation studies in the experimental section.	Reply	B-Reply	1
The following are the observations - [line_break_token][line_break_token]Our model involves two reconstruction stages for the latent space  and).	Reply	I-Reply	1
To study the effect of individual components of the model, we perform the following ablation studies -  (a) training a NEMGAN without the network, (b) training a NEMGAN without the network, (c) training a conventional GAN with noise engineering.	Reply	I-Reply	1
Experiment (a) and (b) are conducted on the MNIST dataset and the output images are shown in Fig 9.	Reply	I-Reply	1
It can be seen that the absence of the KL-loss ) results in the mixing of classes within each mode and the absence of norm-loss ) results in lack of variety within each mode.	Reply	I-Reply	1
For example, 1's with serifs are not generated in absence of.	Reply	I-Reply	1
Results for the experiment (c) is depicted in the Appendix E which suggests that a conventional GAN with latent space engineering cannot separate out the modes.	Reply	I-Reply	1
These experiments suggests that the inclusion of the norm-based reconstruction term encourages the model to avoid the intra-class mode collapse unlike in the case of supervised conditional GANs [1]. [line_break_token][line_break_token]Q2.	Reply	O	0
How will InfoGAN and VEEGAN compare with similar loss terms for the z reconstruction added to their objective?	Reply	O	0
[line_break_token][line_break_token]Ans: The original VEEGAN has a latent space reconstruction term in it by construction.	Reply	O	0
We included the z reconstruction term in the official implementation of the InfoGAN and found that it is unable to produce the MNIST images.	Reply	B-Reply	2
We believe that this might be because of the fact that the Q network, which is used to maximize the mutual information, is made a part of the discriminator.	Reply	I-Reply	2
Thus, performing a joint task of maximizing mutual information between the categorical code and the generated images as well as reconstructing the noise term is not feasible.	Reply	I-Reply	2
That is perhaps the reason authors of InfoGAN terms ‚Äòz‚Äô as the irreducible noise.	Reply	I-Reply	2
On the contrary, our architecture has the discriminator and the latent reconstructor decoupled from each other which is the reason our method performs multiple tasks such as conditional generation, data inference etc.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3.	Reply	O	0
It will be useful to show FID and other similar scores to better evaluate the learned generative model.	Reply	O	0
Including mode counting, experiments will strengthen the paper.	Reply	O	0
[line_break_token][line_break_token]Ans: Thank you again for this suggestion.	Reply	O	0
We have included the FID values in Table 2 and 3 of the current version of the paper and compared with the existing methods.	Reply	B-Reply	3
We have also included the mode counting experiments on standard stacked MNIST data and a toy 8 component GMM data in Appendix D. Mode counting results are summarized in Table 1 of the current version of the paper and it is found that NEMGAN captures the most number of modes.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4.	Reply	O	0
ACGAN can suffer from the issue of generating images where it is easy to infer y [1]. This leads to mode collapse within each category/class.	Reply	O	0
Will the proposed approach suffer from similar issues?	Reply	O	0
[line_break_token][line_break_token]Ans: This is precisely the reason we broke down the z-reconstruction loss into two parts - KL and norm-based.	Reply	O	0
The below paragraph (from Sec.	Reply	B-Reply	4
2 of the paper) summarizes the idea - [line_break_token][line_break_token]Using proposition 1 and 2, one can make the data generating distribution to be bimodal, however, produced modes might be degenerated in a sense that's  reduce to singletons (mode collapse).	Reply	I-Reply	4
 To avoid this degenerative case, we propose to decompose   as a composite of two mappings and.	Reply	I-Reply	4
Minimizing a norm distance between the samples of and prevents degenerative modes in.	Reply	I-Reply	4
This is because enforces a unique reconstruction of every sample of which in turn ensures that a unique sample of is generated by a unique sample of.	Reply	I-Reply	4
The function can be seen as an activity regularizer that would force every unique noise sample within each mode to map to a unique samples in the inversion and the generated spaces.	Reply	I-Reply	4
[line_break_token][line_break_token]These ideas are reconciled with the ablation experiments (Sec.	Reply	I-Reply	4
4.4) where the inclusion of norm-based loss is seen to avoid the intraclass mode collapse.	Reply	I-Reply	4
This point has been brought out in the current version of the paper.	Reply	I-Reply	4
[line_break_token][line_break_token][1] Shu, Rui, Hung Bui, and Stefano Ermon. "	Reply	O	0
AC-GAN Learns a Biased Distribution.	Reply	O	0

Paper's Claims[line_break_token][line_break_token]The paper introduces a new unsupervised abstractive summarization approach called TED, using a Transformer encoder and decoder.	Review	O	0
Their main contributions are as follows:[line_break_token]1) Pretraining the encoder and decoder on news articles using the first beginning as the target summary.	Review	O	0
[line_break_token]2) Fine-tune on other datasets using so-called theme modeling, and separately a denoising loss.	Review	O	0
[line_break_token]3) TED's performance is claimed to significantly improve over GPT-2 while not being too far from the best unsupervised extractive summarization results.	Review	O	0
[line_break_token][line_break_token]Decision[line_break_token][line_break_token]Edit: After revisions and discussions, I recommend we accept this paper.	Review	O	0
[line_break_token][line_break_token]I am leaning towards accepting this paper mostly because of the contribution #1 above.	Review	O	0
Unsupervised learning using large quantities of text that have the property of being typically written in a style that synthesizes information in the first 1-3 sentences is a powerful idea.	Review	O	0
That the performance is improved compared to other unsupervised abstractive summarization confirms the importance of this approach.	Review	O	0
[line_break_token][line_break_token]However the importance of and justification for the fine-tuning steps are comparatively much more limited in my opinion.	Review	O	0
Also, some important details about the preprocessing for pre-training appear to be missing and they could be quite important.	Review	O	0
[line_break_token][line_break_token]Detailed arguments for decision[line_break_token][line_break_token]I view this effort as aiming to reproduce the BERT approach in the context of abstractive summarization, which is a good idea.	Review	O	0
The most clever contribution is in leveraging un-labeled text using the first few sentences as the target summary for pretraining.	Review	O	0
The results of just this part are already beating previous approaches, while not requiring any in-domain data, which is quite powerful.	Review	O	0
[line_break_token][line_break_token]However, some relatively important details regarding the methodology are omitted or only glossed over and it would greatly contribute to making this work more reproducible if the details were included (see my detailed notes below, notably regarding section 2.2).	Review	B-Review	1
[line_break_token][line_break_token]On the fine-tuning steps, I have several worries.	Review	I-Review	2
First, why not fine-tune using supervised learning, as would be the analog to the BERT approach?	Review	I-Review	2
Instead the authors go out of their way to do in-domain unsupervised learning, which provides a boost, yes, but still doesn't compare positively to extractive and/or supervised methods.	Review	I-Review	2
Second, why not perform the theme modeling and denoising also -- or rather only -- on the unlabelled pretraining data?	Review	I-Review	2
Why should it be done on the in-domain fine-tuning data instead (while not using the most valuable piece of in-domain information, namely the example summaries)?	Review	I-Review	2
After all, it's a fully unsupervised approach and it can actually be performed on any text at all, whether a summary for it exists or not.	Review	I-Review	2
[line_break_token][line_break_token]Again regarding the unsupervised approach, and to push the BERT analogy further, I'm wondering why not initialize the pretraining model with a BERT-style trained model?	Review	I-Review	3
After all we could imagine building a system that adds more and more in-domain characteristics sequentially: first pretrain a BERT model, then fine-tune to summarization using what this paper calls pretraining, and then finally fine-tune again to a specific summarization domain.	Review	I-Review	3
[line_break_token][line_break_token]So, to conclude, I find that this paper goes in the right direction and introduces important ideas for pretraining and fine tuning unsupervised abstractive summarization models, but that some decisions about how to use the various ideas (theme and denoising but no supervised learning, in-domain vs during pretraining) have not been explored enough.	Review	O	0
[line_break_token][line_break_token]Extra notes[line_break_token][line_break_token]page 2, second line: pretrainleverages (typo)[line_break_token]section 2.1: fix first sentence to make it an actual sentence.	Review	O	0
[line_break_token]section 2.2: "we obtain three years of online new articles ... via a search engine" please be more specific about your methodology.	Review	B-Review	6
[line_break_token]section 2.2: You should double check more throughly that there is no data leakage in test.	Review	I-Review	7
There could be articles about the same exact events, years apart, for example.	Review	I-Review	7
I doubt that this would be a big effect, but there are easily ways to find highly similar articles between the pretraining data and test data to make sure.	Review	I-Review	7
[line_break_token]section 2.2: "Next we conduct following data cleaning" fix (typo?).	Review	I-Review	8
Also that sentence probably belongs to the next paragraph.	Review	I-Review	8
[line_break_token]section 2.2: Why did you pick the values that you did for the preprocessing heuristics (such as between 10-150 words, 150-1200 words, 3 sentences and not 2 or 1 or 4, the ratio 0.65, etc.)?	Review	I-Review	9
Were other values tried?	Review	I-Review	9
[line_break_token]section 2.2: You mention you end up with 21.4M articles.	Review	I-Review	10
How many were there to start with?	Review	I-Review	10
What's the filtering ratio?	Review	I-Review	10
[line_break_token]section 2.2: You mention that you pick the model with the best ROUGE-L score on the validation set.	Review	I-Review	11
How many models were there?	Review	I-Review	11
What was different between them?	Review	I-Review	11
[line_break_token]section 2.2, OOV Problem: the information in this whole subsection would fit better in 2.1 where 'tokens' are left generic without specifying which type of token you're considering.	Review	I-Review	12
[line_break_token]Figure 1: I find the upper part of this figure very confusing.	Review	I-Review	13
Why are there arrows going from the encoder/decoder to a summary, to theme loss, to article and back to encoder/decoder?	Review	I-Review	13
It's important that the summary is never seen by the theme loss otherwise it's not unsupervised anymore, and I also don't see why the arrow would go through article *after* theme loss.	Review	I-Review	13
I assume there must have been a mistake, please fix.	Review	I-Review	13
[line_break_token]section 2.4: "the sequence is slightly shuffled by applying a permutation /sigma such that ..." The formula given here tells me that all token indices are shuffled with another token within a window k. That seems like a lot of moving around, and also depending on the implementation a token from the beginning could possibly end up at the very tail of the sentence by being picked iteratively again and again, thus falling outside the permutation distance k. Please provide more details on how this is done and a justification for why it was decided to do it this way.	Review	I-Review	14
[line_break_token]Section 3.1: I'd like to know how long (preferably number of words, or at least number of wordpiece tokens) the summaries generated are.	Review	I-Review	15
What determines how long they are, is it a fixed size, or the model decides to stop on his own (or when hitting some limit), or something else?	Review	I-Review	15
[line_break_token]section 4.2: Do you have any idea why your unsupervised approach yields more novel n-grams than a the supervised model you compare against?	Review	I-Review	5
This can be good as much as it can be bad, in that it could be going off-track.	Review	I-Review	5
Yes humans have high novelty, but high novelty in itself isn't necessarily good.	Review	I-Review	5
I don't find the argument that have more novel ngrams is intrinsically, necessarily good, compelling.	Review	I-Review	5
If I'm wrong, then it would be nice to have better explanation in the paper.	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]	Review	O	0
egarding the extra notes (with the same order as in ‚ÄúExtra notes‚Äù):[line_break_token][line_break_token](1) (2) Sorry about the typos.	Reply	O	0
We have fixed them.	Reply	B-Reply	4
[line_break_token](3) The search engine indexes major online news domain, for instance, New York Times and Bloomberg.	Reply	O	0
Then we collect the parsed articles within the 2016-2019 time range as the raw data.	Reply	B-Reply	6
[line_break_token](4)  We understand your concern about data leakage.	Reply	O	0
We went through the three test sets and did not find significantly overlapped articles as in the pretraining.	Reply	B-Reply	7
[line_break_token](5) Thanks for pointing it out.	Reply	O	0
We have revised it.	Reply	B-Reply	8
[line_break_token](6) Some explanations for the heuristic values selections:[line_break_token][line_break_token]150 and 1,200 words: Articles with very long content are filtered them mainly to reduce memory consumption.	Reply	O	0
Short articles are filtered since the information might be too condensed and not suitable for summarization pretraining.	Reply	B-Reply	9
[line_break_token][line_break_token]10 and 150 words: Some leading sentences are extremely short, e.g. one or two words phrases.	Reply	I-Reply	9
Those are filtered since they have too little information to be reasonable summaries.	Reply	I-Reply	9
Longer leading sentences are removed to reduce the pretraining time.	Reply	I-Reply	9
[line_break_token][line_break_token]0.65: The overlap ratio is an indicator of the amount of information that the leading sentences maintain.	Reply	I-Reply	9
For instance,  in CNN/DM dataset, the median of the overlapping ratio of non-stopping words between golden summary and the article is 0.87, and the ratio between the first 3 sentences and the rest of the article is 0.77 (median).	Reply	I-Reply	9
Setting the number at 0.65 makes the final training set size fit with the available computation resources and ensures that the leading sentences contain enough information.	Reply	I-Reply	9
[line_break_token][line_break_token]We mean to have demanding filtering criteria since we want high-quality pretraining data.	Reply	I-Reply	9
We didn‚Äôt try other settings since pretraining is a time-consuming process.	Reply	I-Reply	9
[line_break_token][line_break_token](7) We start with about 407 million articles.	Reply	O	0
The filtering ratio is about 95%.	Reply	B-Reply	10
We‚Äôve also added this information to the paper.	Reply	I-Reply	10
[line_break_token][line_break_token](8) We train one model for 10 epochs.	Reply	O	0
After each epoch, the model is evaluated on validation data.	Reply	B-Reply	11
We pick the check points with the highest ROUGE L.[line_break_token][line_break_token](9) About OOV.	Reply	O	0
It is a good idea.	Reply	B-Reply	12
We have edited and moved the paragraph to section 2.1[line_break_token][line_break_token](10)  About Figure 1.	Reply	O	0
Sorry about the confusion.	Reply	B-Reply	13
The ‚Äúsummary‚Äù refers to the generated summary from the transformer encoders/decoders, not the groundtruths summaries.	Reply	I-Reply	13
The process follows that the article is input to the transformer encoder/decoders and a summary is generated.	Reply	I-Reply	13
Then we compute the theme loss using the generated summary and the article.	Reply	I-Reply	13
We‚Äôve changed the text label ‚Äúsummary‚Äù in figure to ‚Äúgenerated summary‚Äù to avoid the confusion.	Reply	I-Reply	13
[line_break_token][line_break_token](11) About sequence shuffling.	Reply	O	0
Here is how we generate the permutations (the variable perm) of the indices using numpy.	Reply	B-Reply	14
Assume the length of the sequence is L, and the window size is k.[line_break_token]ids = np.arange(L)[line_break_token]noise =  np.random.uniform(0, k, size = L)[line_break_token]tmp = ids + noise[line_break_token]perm = tmp.argsort()[line_break_token]For tokens in the beginning, e.g. the first token, since there are at most k -1 elements smaller than tmp[0] in tmp, so the first token is at most shuffled to the kth position.	Reply	I-Reply	14
[line_break_token][line_break_token]The motivation of shuffling is as follows.	Reply	I-Reply	14
The information is to extract and summarize is scattered across an article.	Reply	I-Reply	14
By applying this shuffling noise, we want our model to learn to recognize and reorganize the information.	Reply	I-Reply	14
[line_break_token][line_break_token](12) The generation has a hard limit, which is decided on the validation dataset.	Reply	O	0
For instance, the maximum generation length for CNN/DM dataset is 175.	Reply	B-Reply	15
Also, in beam search, if the generated token is &lt;EOS&gt;, i.e. the end of sentence, then the generation is terminated immediately for the current sequence.	Reply	O	0
[line_break_token][line_break_token](13) Since TED is an abstractive model, this experiment is to show that TED has the ability to summarize using words/phrases not in the original article, which is typical in human-edited summaries.	Reply	O	0
Explanations why TED has more novel grams could be TED has seen more data during the pretraining phase than PGNet (which is only trained using in-domain data).	Reply	B-Reply	5
Also PGNet uses RNN while TED leverages transformer.	Reply	I-Reply	5
The more powerful modeling ability of transformer can also help.	Reply	I-Reply	5
Also the major evaluation metrics is the ROUGE, on which TED shows competitive performances	Reply	I-Reply	5

-- Paper summary --[line_break_token][line_break_token]The primary goal of this paper is to investigate the suitability of BNNs for carrying out post-calibration on trained deep learning models.	Review	O	0
The results are compared to equivalent models calibrated using temperature scaling, and the pr	Review	O	0
I thank the authors for their detailed response to all reviewer comments and providing additional explanations about their method.	Reply	O	0
Unfortunately, I tend to agree with other reviewers that the contribution isn‚Äôt significant enough in isolation, and requires a broader and more extensive experimental evaluation in order to make up for the lack of theoretical innovation.	Reply	O	0
[line_break_token]Consequently, my score remains unchanged.	Reply	O	0

The paper proposed a RNN with skip-connection (external memory) to past hidden states, this is a slightly different version of the TARDIS network.	Review	O	0
The authors experimented on PTB and a temporal action detection method.	Review	O	0
[line_break_token][line_break_token]Novelty:[line_break_token][line_break_token]I dont see a lot of novelty to the method.	Review	O	0
The authors proposed a method very similar to TARDIS, the difference seems to be that MMARNN does not use extra usage vectors for reading from previous memory, but this is not a fundamental difference between MMARNN and Tardis.	Review	B-Review	1
[line_break_token][line_break_token]Shortcomings of the paper:[line_break_token][line_break_token]1.	Review	O	0
The experiments seem rather weak.	Review	B-Review	2
The authors experimented on PTB and temporal action detection method.	Review	I-Review	2
It is not clear why authors experimented with PTB, this is not a task with long-term dependencies, I do not see how this task (compared to many other tasks) can benefit from using external memory (especially when only 1 past hidden state is used[line_break_token][line_break_token]2.	Review	O	0
The model uses a single past hidden state, it is not clear to me why this is better than using  a weighted sum of a few past hidden states, as many tasks requires long-term dependencies from multiple steps in the past.	Review	B-Review	3
The authors should cite "Sparse attentive backtracking" (<a href="https://arxiv.org/abs/1809.03702)" target="_blank" rel="nofollow">https://arxiv.org/abs/1809.03702)</a> at NIPS 2018.	Review	O	0
SAB is very related in that it also propagate gradients to a few hidden states in the memory.	Review	B-Review	3
The difference is that SAB used a few hidden states from the past/ memory instead of one; another difference is that it propagates gradients locally to the selected hidden states/ memory slots.	Review	I-Review	3
[line_break_token][line_break_token]3.	Review	O	0
The paper only demonstrated experimental results on PTB and temporal action prediction.	Review	B-Review	4
I think it would make the paper a lot stronger if the authors experimented with a variety of  different tasks.	Review	I-Review	4
Tasks that requires long term dependencies can really demonstrate the strength of the model (copy and adding tasks).	Review	I-Review	4
[line_break_token][line_break_token]4.	Review	O	0
If the authors could run the model on copy and adding tasks, I would be curious to see if the model is picking the "correct" timestep in the memory / past.	Review	B-Review	5
[line_break_token][line_break_token]post rebuttal: I feel that the authors have addressed some of my concerns, in particular, in terms of additional experimental results.	Review	O	0
I have raised the score to reflect this changes.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your valuable comment.	Reply	O	0
We apologize for not clearly stating our difference against TARDIS and causing some misunderstanding regarding the novelty.	Reply	O	0
We have accordingly revised our paper and can address your concerns as follows:[line_break_token][line_break_token]Q1:Novelty:I don't see a lot of novelty to the method.	Reply	O	0
The authors proposed a method very similar to TARDIS, the difference seems to be that MMARNN does not use extra usage vectors for reading from previous memory, but this is not a fundamental difference between MARNN and Tardis.	Reply	O	0
[line_break_token][line_break_token]We have discussed 5 important differences regarding the cell computation and addressing mechanism , supported by experimental evidences we added.	Reply	B-Reply	1
Please refer to appendix B for a thorough comparison.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: The experiments seem rather weak.	Reply	O	0
The authors experimented on PTB and temporal action detection method.	Reply	O	0
It is not clear why authors experimented with PTB, this is not a task with long-term dependencies, I do not see how this task (compared to many other tasks) can benefit from using external memory (especially when only 1 past hidden state is used.	Reply	O	0
[line_break_token][line_break_token]We apologize for not clearly stating the motivation of our dataset choice of PTB and THUMOS 14.	Reply	B-Reply	2
As we state in the introduction, we aim at building a bridge between simple RNN and complex memory models.	Reply	I-Reply	2
We primarily intend to focus on augmenting RNN's performance on real-world tasks with a light-weight external memory, but not focus on coming up with more functional and complex memory mechanism.	Reply	I-Reply	2
 We choose PTB and THUMOS 14 tasks  because they are real-world tasks where we can examine if our memory network can be helpful.	Reply	I-Reply	2
 In our network, each r_t , although only 1 past hidden state, is a summary of historical hidden states with skip connection selected by auto-addressing mechanism.	Reply	I-Reply	2
The ARMIN(renamed from MARNN) cell learns to recurrently integrate the summary of historical information from r_t into h_t at every time-step, which favors a paradigm of deep transition, as is shown by the success of  deep-transition RNNs on PTB task.	Reply	I-Reply	2
 We believe this  can explain why we choose PTB and why the ARMIN success on PTB.	Reply	I-Reply	2
[line_break_token] [line_break_token]Q3: The model uses a single past hidden state, it is not clear to me why this is better than using  a weighted sum of a few past hidden states, as many tasks requires long-term dependencies from multiple steps in the past.	Reply	O	0
The authors should cite "Sparse attentive backtracking" (<a href="https://arxiv.org/abs/1809.03702)" target="_blank" rel="nofollow">https://arxiv.org/abs/1809.03702)</a> at NIPS 2018.	Reply	O	0
SAB is very related in that it also propagate gradients to a few hidden states in the memory.	Reply	O	0
The difference is that SAB used a few hidden states from the past/ memory instead of one; another difference is that it propagates gradients locally to the selected hidden states/ memory slots.	Reply	O	0
[line_break_token][line_break_token]Thank you for pointing out this paper, and we have cited and introduced the SAB in our paper.	Reply	B-Reply	3
As we state in Q1, each r_t is a summary of historical hidden states with skip connection selected by auto-addressing mechanism(we train the selecting process by backpropagation), so there is no fundamental difference from using  a weighted sum of a few past hidden states.	Reply	I-Reply	3
 Another reason is that the gumbel-softmax can only sample 1-hot vector, so we think a more fundamental comparison between ARMIN and SAB should be : is the 1-hot sampling of gumbel-softmax better or multiple selecting of ReLU and softmax addressing mechanism in SAB is better?	Reply	I-Reply	3
Due to time constraints, we leave this for future work.	Reply	I-Reply	3
[line_break_token][line_break_token]Q3&4.	Reply	O	0
The paper only demonstrated experimental results on PTB and temporal action prediction.	Reply	O	0
I think it would make the paper a lot stronger if the authors experimented with a variety of  different tasks.	Reply	O	0
Tasks that requires long term dependencies can really demonstrate the strength of the model (copy and adding tasks).	Reply	O	0
If the authors could run the model on copy and adding tasks, I would be curious to see if the model is picking the "correct" timestep in the memory / past.	Reply	O	0
[line_break_token][line_break_token]We have added a set of algorithmic tasks introduced by the NTM paper, including copy, repeat copy, associative recall and priority sort.	Reply	B-Reply	4
We think these tasks do require exact long-term dependency, and we demonstrate the efficiency of our network on these tasks.	Reply	I-Reply	4
Specifically, our network can converge 3~4 time faster in terms wall clock time than NTM on most of the tasks.	Reply	I-Reply	4
We also adds enwik8 char-level lm tasks.	Reply	I-Reply	4
We are currently doing experiment on pMNIST, but can't report in time as the training is very slow.	Reply	I-Reply	4
We will report the results in later revision of our paper.	Reply	I-Reply	4
[line_break_token][line_break_token]We hope these answers can address your concerns, thanks!	Reply	O	0
[line_break_token]	Reply	O	0

The authors propose Graph VRNN.	Review	O	0
The proposed method models the interaction of multiple agents by deploying a VRNN for each agent.	Review	O	0
The interaction among the agents is modeled by the graph interaction update on the hidden states of the VRNNs.	Review	O	0
The model predicts the true state (e.g., location) of the agent via supervised auto-regressive learning.	Review	O	0
The proposed model can improve this estimation from partially-observed visual observations.	Review	O	0
In the experiment, the authors apply the proposed method to Basketball and Soccer data to model the positions of the players.	Review	O	0
[line_break_token][line_break_token]The paper is clearly written.	Review	O	0
However, Section 3.2 needs to be elaborated more because using graph interaction update in VRNN is one of the main contributions.	Review	O	0
[line_break_token][line_break_token]I see two main weaknesses.	Review	O	0
The first is that the states are learned by supervised learning where obtaining the state label (i.e., the agent locations) is very expensive.	Review	B-Review	1
Indeed, the authors had to develop their own soccer game to obtain these labels.	Review	I-Review	1
The second weakness is the weak/inconsistent experiment results.	Review	I-Review	2
It seems not clear whether having the graph structure or stochastic modeling is really helping or not.	Review	I-Review	2
For example, for basketball experiment, Graph-RNN works poorly.	Review	I-Review	2
And, for soccer, Graph-VRNN works just as good as Graph-RNN.	Review	I-Review	2
The authors explained that this is due to the simplicity of the player behavior (not much stochastic), but the result in Table 2 shows good performance for Graph-VRNN for future prediction task.	Review	I-Review	2
All these make it difficult to buy the claimed argument.	Review	I-Review	2
It is also a limitation that the model requires to know and fix the number of agents.	Review	I-Review	2
[line_break_token][line_break_token]As minor comments, [line_break_token][line_break_token]- in Table 1.	Review	O	0
Graph-RNN works better for soccer t=4, but not indicated in bold.	Review	B-Review	3
[line_break_token]- Having a single RNN baseline will be helpful to compare with Graph-RNN.	Review	O	0
[line_break_token]- It is confusing to call s_t a belief state because it is observed not latent.	Review	O	0
[line_break_token]- In the qualitative results, I think it can be compared to the heatmap of true distribution.	Review	O	0
[line_break_token][line_break_token]I think the following papers needs to be discussed as related works.	Review	B-Review	7
[line_break_token]- <a href="https://arxiv.org/pdf/1806.01242.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1806.01242.pdf</a> [line_break_token]- <a href="https://arxiv.org/pdf/1802.03006.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.03006.pdf</a>[line_break_token][line_break_token]	Review	O	0
Thank you for your detailed feedback!	Reply	O	0
We have uploaded a revision to address your concerns:[line_break_token][line_break_token](1) Weak/inconsistent results:[line_break_token]We found that joint training of visual encoder and (V)RNN/Graph-(V)RNN lead to suboptimal performance for all methods, which has been addressed by our modified visual encoder and pre-training mechanism.	Reply	O	0
We can see from Table 1, 2 and 3 that graph structure consistently helps for both datasets and both tasks.	Reply	B-Reply	2
We also observe that stochastic modeling is more useful for Graph-RNN than vanilla RNN.	Reply	I-Reply	2
[line_break_token][line_break_token](2) Missing related work:[line_break_token]We have added the references in the related work section.	Reply	O	0
[line_break_token][line_break_token](3) RNN baseline:[line_break_token]We have added this baseline, we find that Graph-RNN outperforms single RNN in both current state estimation and future state prediction tasks.	Reply	O	0
[line_break_token][line_break_token](4) Comparison with true distribution:[line_break_token]This is a great idea.	Reply	O	0
We are looking into the possibility to conduct such comparison for soccer world.	Reply	B-Reply	6
Unfortunately we cannot do it for basketball since the true distribution is unknown	Reply	I-Reply	6

Apologies for the late review.	Review	O	0
[line_break_token][line_break_token]This submission proposes method for class-conditional generative image modeling using auxiliary classifiers.	Review	O	0
Compared to normal GANs the generator also receives a randomly sampled class label c from the class distribution.	Review	O	0
The discriminator has two outputs and two corresponding objectives: determine whether a sample is real or generated, and independently to predict the (real or sampled) class label corresponding to the sample.	Review	O	0
[line_break_token][line_break_token]Figure 2.	Review	O	0
nicely illustrates related methods - this particular method bears similarities to InfoGANs and Semi-supervised GANs.	Review	O	0
Compared to infogans, this method also encourages correspondence between the latent c and the real class labels for the real examples (whereas infogans are presented as fully unsupervised).	Review	O	0
[line_break_token][line_break_token]The authors attempt at evaluating the method quantitatively by looking at the discriminability and diversity of samples.	Review	O	0
It is found - not surprisingly - that higher resolution improves discriminability (because more information is present).	Review	O	0
[line_break_token][line_break_token]Discriminability: Figure 3 doesn‚Äôt have legends so it is a bit hard to understand what is going on.	Review	O	0
Furthermore, my understanding is that when evaluating discriminability the authors downsample and then bicubically upsample the image, which is much more like a blurring, very different from retraining all the models to work on low resolution in the first place.	Review	O	0
[line_break_token][line_break_token]Diversity: The authors try to quantitatively evaluate diversity of samples by measuring the average MS-SSIM between randomly selected pairs of points within each class.	Review	O	0
I think this method is significantly flawed and limited, for reasons mentioned in (Theis et al, 2015, A note on the evaluation‚Ä¶).	Review	B-Review	1
In its behaviour, MS-SSIM is not that dissimilar from Euclidean distance - although it is nonlinear and is bounded between -1 and 1.	Review	I-Review	1
Evaluating diversity/entropy of samples in high dimensions is very hard, especially if the distributions involved are non-trivial for example concentrated around manifolds.	Review	I-Review	2
Consider for example a generative model which randomly samples just two images.	Review	I-Review	2
Assuming that the MSSSIM between these two images is -1, this generative model can easily achieve an average MSSSIM score of 0, implying a conclusion that this model has more diversity than the training data itself.	Review	I-Review	2
Conversely, SSIM is designed not to be sensitive to contrast and average pixel intensity, so if a model is diverse in this sense, that will be ignored by this measure.	Review	I-Review	3
[line_break_token][line_break_token]Overall, the paper proposes a new way to incorporate class labels into training GAN-type models.	Review	O	0
As far as I know the particular algorithm is novel, but I consider it incremental compared to what has been done before.	Review	O	0
I think the proposed evaluation metrics are flawed, especially when evaluating the diversity of the samples for the aforementioned reasons.	Review	O	0
Thank you for the review.	Reply	O	0
We have used ">" for quotes in the below response.	Reply	O	0
[line_break_token][line_break_token]As mentioned in the global response, we believe that the review misstates several key points in our paper.	Reply	O	0
 We have revised our paper for clarity and we respond to each point in detail below.	Reply	O	0
[line_break_token][line_break_token]======================[line_break_token]VARIABILITY AND MS-SSIM[line_break_token]======================[line_break_token][line_break_token]1. ‚	Reply	O	0
ÄúThe authors try to quantitatively evaluate diversity of samples by measuring the average MS-SSIM between randomly selected pairs of points within each class.	Reply	O	0
I think this method is significantly flawed and limited, for reasons mentioned in (Theis et al, 2015, A note on the evaluation‚Ä¶).	Reply	O	0
In its behaviour, MS-SSIM is not that dissimilar from Euclidean distance - although it is nonlinear and is bounded between -1 and 1.‚Äù[line_break_token][line_break_token]The main claim of Theis et al (2015) is that log-likelihood might not correspond to sample quality in a generative model.	Reply	O	0
Furthermore, training a model based on one objective will not guarantee good performance under another objective.	Reply	B-Reply	1
We view these points as orthogonal to our evaluation framework.	Reply	I-Reply	1
If the reviewer views this differently, we would be interested to hear their perspective.	Reply	I-Reply	1
That said, Theis et al (2015) provide an explicit motivation for us to build an evaluation method that is independent of the training objective.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
In regards to the statement that ‚ÄòMS-SSIM is not that dissimilar from Euclidean distance‚Äô, we strongly disagree.	Reply	O	0
We believe that this statement is not supported by the literature.	Reply	O	0
[line_break_token][line_break_token]To start with, SSIM is a highly nonlinear metric that has been constructed to reflect human perceptual judgements [*].	Reply	O	0
The original SSIM paper as well as follow up works on MS-SSIM have demonstrated that SSIM-based metrics provide substantially improved quantitative estimates of human perceptual judgements compared to simple Euclidean distance measures (and many other quantitative measures of perceptual similarity) [1, 2, 3; and references therein].[line_break_token][line_break_token]A simple intuition for why SSIM is perceptually superior to Euclidean distance can be gained through looking at examples.	Reply	O	0
The SSIM web page (<a href="http://www.cns.nyu.edu/~lcv/ssim/" target="_blank" rel="nofollow">http://www.cns.nyu.edu/~lcv/ssim/</a> ) shows that images which are drastically different perceptually can have the same MSE and quite different SSIM scores.	Reply	O	0
[line_break_token][line_break_token][1] Wang, Zhou, Eero P. Simoncelli, and Alan C. Bovik. "	Reply	O	0
Multiscale structural similarity for image quality assessment."	Reply	O	0
[line_break_token][2] Z. Wang, A. C. Bovik, H. R. Sheikh and E. P. Simoncelli, "Image quality assessment: From error visibility to structural similarity"[line_break_token][3] Kede Ma, Qingbo Wu, Zhou Wang, Zhengfang Duanmu, Hongwei Yong, Hongliang Li, and Lei Zhang.	Reply	O	0
Group mad competition - a new methodology to compare objective image quality models.	Reply	O	0
[line_break_token][*] Note that our MS-SSIM implementation ranges from [0, 1] and not from [-1, 1]. All values on our graphs should be interpreted accordingly.	Reply	O	0
[line_break_token] [line_break_token]3. ‚	Reply	O	0
ÄúEvaluating diversity/entropy of samples in high dimensions is very hard, especially if the distributions involved are non-trivial for example concentrated around manifolds.	Reply	O	0
Consider for example a generative model which randomly samples just two images.	Reply	O	0
Assuming that the MSSSIM between these two images is -1, this generative model can easily achieve an average MSSSIM score of 0, implying a conclusion that this model has more diversity than the training data itself.	Reply	O	0
‚Äù[line_break_token][line_break_token]We claim that this example is seriously flawed, for the following reasons:[line_break_token][line_break_token]a. The range of MS-SSIM is [0, 1] (see above), so the average would be 0.5, which corresponds to half as much diversity as in the least diverse ImageNet class.	Reply	O	0
[line_break_token]b. This type of memorization would manifest as high variance of the mean MS-SSIM, but we report lower variance for samples than for training data (In other words, we explicitly account for this in the metric itself).	Reply	B-Reply	2
One could also compute higher moments or look at a histogram of pairwise MS-SSIM values, etc.	Reply	I-Reply	2
[line_break_token]c. We have also ruled out memorization explicitly by examining both latent space interpolations and nearest neighbors (both by L1 and MS-SSIM).	Reply	I-Reply	2
[line_break_token]d. We have provided 10,000 sample images, which do not show this type of memorization.	Reply	I-Reply	2
[line_break_token]e. It‚Äôs not even clear how well other existing methods of measuring diversity would perform in this case.	Reply	I-Reply	2
[line_break_token][line_break_token]4.	Reply	O	0
The reviewer suggests that in an ideal world we would compute the entropy of the generator distribution.	Reply	O	0
We argue that -- even if this were feasible -- we would still want to use perceptually calibrated metrics such as MS-SSIM.	Reply	O	0
Namely, we might want to ignore variability due to contrast or pixel intensity in favor of diversity of image content.	Reply	O	0
[line_break_token][line_break_token]5. ‚	Reply	O	0
ÄúConversely, SSIM is designed not to be sensitive to contrast and average pixel intensity, so if a model is diverse in this sense, that will be ignored by this measure.	Reply	O	0
‚Äù[line_break_token][line_break_token]We think that this is a good thing (see above).	Reply	O	0
[line_break_token]This is a sense in which Euclidean distance measures are very different than MS-SSIM, which directly contradicts the reviewer‚Äôs earlier point.	Reply	B-Reply	3
[line_break_token][line_break_token]=============[line_break_token]DISCRIMINABILITY[line_break_token]===============[line_break_token][line_break_token]1. ‚	Reply	O	0
ÄúDiscriminability: Figure 3 doesn‚Äôt have legends so it is a bit hard to understand what is going on.	Reply	O	0
Furthermore, my understanding is that when evaluating discriminability the authors downsample and then bicubically upsample the image, which is much more like a blurring, very different from retraining all the models to work on low resolution in the first place.	Reply	O	0
‚Äù[line_break_token][line_break_token]We feel that there was a large misunderstanding about our methods, so we present a quick summary of what was done to measure discriminability:[line_break_token][line_break_token]Our goal in this analysis was to measure how much of the output resolution is actually used by the image synthesis model.	Reply	O	0
In other words, does a 128x128 model just produce 32x32 images that are naively resized to 128x128?	Reply	O	0
This is the goal of the ‚Äòblurring‚Äô analysis and a question that has not been addressed in the literature.	Reply	O	0
If a sample were a naive resizing, a blurring would not reduce its discriminability.	Reply	O	0
[line_break_token][line_break_token]For each image analyzed, and for each resolution in [16, 32, 64, 128, 256], we iteratively resized the sample from its original size (using bilinear interpolation) to the resolution in question.	Reply	O	0
We then passed the image to a pretrained Inception model, which resizes all inputs to 299x299 before processing.	Reply	O	0
We took note of whether Inception correctly classified the input, and then we reported these results in the lower left hand corner of figure 3.	Reply	O	0
We have revised the manuscript to better describe these methods.	Reply	O	0
[line_break_token][line_break_token]2. ‚	Reply	O	0
ÄúIt is found - not surprisingly - that higher resolution improves discriminability (because more information is present).‚Äù[line_break_token][line_break_token]If the reviewer means that simply increasing the resolution should result in higher discriminability: We did explicitly test for this by upsampling images to confirm that simply upsampling would not increase discriminability.	Reply	O	0
See Figure 3 and Section 4.1.	Reply	O	0
[line_break_token][line_break_token]If the reviewer means that it is unsurprising that the model is successfully making use of its available output resolution: Naive resizing is not an idle concern.	Reply	O	0
We tested another model that actually failed to meaningfully increase discriminability score from 64x64 to 128x128.	Reply	O	0
[line_break_token][line_break_token]3."[the authors do not retrain] all the models to work on low resolution in the first place".	Reply	O	0
[line_break_token][line_break_token]We did retrain models at a lower output resolution.	Reply	O	0
We found that samples from these models are about half as discriminable at the 128x128 resolution as samples from the 128x128 model.	Reply	O	0
The results of this experiment correspond to the blue curve in the lower left of Figure 3.	Reply	O	0
This procedure was also described in section 4.1.	Reply	O	0

This paper studies the problem of visual representation learning from 2.5D video streams by exploring the 2D-3D geometry structures in the 3D visual world.	Review	O	0
Building upon the previous work GRNN (Tung et al.	Review	O	0
2019), this paper introduced a novel view-contrast objective applied to its internal 2D and 3D feature space.	Review	O	0
To facilitate the 3D view-contrast learning, this paper proposed a novel 2D-3D inverse graphics networks with a 2D-to-3D un-projection encoder, a 2D encoder, a 3D bottlenecked RNNs, an ego-motion stabilization module, and a 3D-to-2D projection module.	Review	O	0
Compared to previous work (Tung et al.	Review	O	0
2019), view-contrastive inverse graphics networks decode in the feature space rather than RGB space.	Review	O	0
Experimental evaluations are conducted using CARLA simulator (sim) and KITTI dataset (real).	Review	O	0
Results demonstrate the strengths of the proposed view-contrastive framework in feature learning, 3D moving object detection, and 3D motion estimation.	Review	O	0
[line_break_token][line_break_token]Overall, this paper studies an important problem in computer vision with a novel solution using unsupervised feature learning.	Review	O	0
While the technical novelty is clear, reviewer has several questions regarding the implementation and experimental details.	Review	O	0
[line_break_token][line_break_token](1) For 3D box detection on KITTI (see Table 1), the comparisons to state-of-the-art models are currently missing.	Review	O	0
While the benefit of unsupervised feature learning has been demonstrated, it would be more convincing to compare against the following papers (at least with a paragraph of discussion).	Review	B-Review	1
[line_break_token][line_break_token](2) The 3D-to-2D projection module seems very expensive.	Review	O	0
Can you possibly report the training and inference time compared to baselines?	Review	B-Review	2
Also, the design of the projection module is a bit counter-intuitive as it has 8x8 convolutions.	Review	I-Review	2
In principle, such projection should be learning-free or with only 1x1 convolutions (aggregation along depth channel).	Review	I-Review	2
It would be good to consider such ablation studies in the final version.	Review	I-Review	2
[line_break_token][line_break_token]-- Multi-view Supervision for Single-view Reconstruction via Differentiable Ray Consistency.	Review	O	0
Tulsiani et al.	Review	O	0
In CVPR 2017.	Review	O	0
[line_break_token]-- Perspective Transformer Nets: Learning Single-View 3D Object Reconstruction without 3D Supervision.	Review	O	0
Yan et al.	Review	O	0
In NIPS 2016.	Review	O	0
[line_break_token]-- MarrNet: 3D Shape Reconstruction via 2.5D Sketches.	Review	O	0
Wu et al.	Review	O	0
In NIPS 2017.	Review	O	0
[line_break_token][line_break_token](3) It seems that the proposed method assumes slow moving background across consecutive frames.	Review	O	0
In principle, the view-contrastive objective should mask out new pixels in frame T+1.	Review	B-Review	3
Also, because the view-contrastive loss is applied at feature-level, reviewer would like to know performance on detecting small objects.	Review	I-Review	3
[line_break_token][line_break_token](4) As the latent map update module uses an RNN, it would be good to consider consistency beyond 2 frames (given mask is applied to view-contrastive objective).	Review	O	0
Curriculum learning could be helpful for further improvements.	Review	B-Review	4
[line_break_token][line_break_token]-- Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis.	Review	O	0
Yang et al.	Review	O	0
In NIPS 2015.	Review	O	0
[line_break_token][line_break_token](5) How does the proposed method perform when applied to indoor environments?	Review	O	0
[line_break_token][line_break_token](6) Additional ablation study to consider: what if 2D/3D contrastive loss is turned off?	Review	O	0
[line_break_token][line_break_token]	Review	O	0
ear reviewer,[line_break_token][line_break_token]Thank you for your detailed analysis.	Reply	O	0
[line_break_token][line_break_token]-- For 3D box detection on KITTI (see Table 1), the comparisons to state-of-the-art models are currently missing.	Reply	O	0
While the benefit of unsupervised feature learning has been demonstrated, it would be more convincing to compare against the following papers.	Reply	O	0
[line_break_token][line_break_token]The state-of-the-art for KITTI is at approximately 0.8 mAP at the 0.5 IOU threshold, which exceeds our 0.6 mAP score.	Reply	B-Reply	1
The main reason for this is resolution.	Reply	I-Reply	1
The SOTA models in KITTI achieve extremely high resolution outputs, by sacrificing the ‚Äúvertical‚Äù dimension of their latent representation: they build a ‚Äúbird‚Äôs eye view‚Äù of the scene, and do 2D convolutions in that space.	Reply	I-Reply	1
Our approach aims to be more general, and treats all three axes equally; we therefore use 3D convolutions throughout our model.	Reply	I-Reply	1
Nonetheless, we are actively trying to bridge this resolution gap, via efficient implementations of sparse 3D convolutions: by avoiding wasteful computation on the ‚Äúempty air‚Äù part of the scene, we are able to nearly double our resolution.	Reply	I-Reply	1
Competing with SOTA on KITTI also requires careful augmentation of the pointclouds, via object-centric and scene-centric jittering and non-rigid transforms, to expand the training distribution to cover test statistics.	Reply	I-Reply	1
We are doing this also, and hope to have results soon, but please note that higher resolution and augmented data lead to slower training, so it will take several days for each model to train.	Reply	I-Reply	1
With luck, we will add these results into the paper by Friday.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]-- The 3D-to-2D projection module seems very expensive.	Reply	O	0
Can you possibly report the training and inference time compared to baselines?	Reply	O	0
Also, the design of the projection module is a bit counter-intuitive as it has 8x8 convolutions.	Reply	O	0
In principle, such projection should be learning-free or with only 1x1 convolutions (aggregation along depth channel).	Reply	O	0
It would be good to consider such ablation studies in the final version.	Reply	O	0
[line_break_token][line_break_token]Thank you for writing this.	Reply	B-Reply	2
Our description should have been better.	Reply	I-Reply	2
Our 3D-to-2D architecture is actually quite cheap. (	Reply	I-Reply	2
There are no 8x8 convolutions.)	Reply	I-Reply	2
[line_break_token]- The module starts with a perspective transform, which puts viewing rays along the depth axis of a tensor.	Reply	I-Reply	2
[line_break_token]- Then there is a max pooling operation with a 1x8x1 kernel and 1x8x1 stride, where the 8 is along the depth axis; this quickly and coarsely aggregates along the ray axis, as you suggest.	Reply	I-Reply	2
[line_break_token]- Following this aggregation, there is a 3D convolution with kernel size 3x3x3.	Reply	I-Reply	2
[line_break_token]- Then there is a reshape, putting the depth dimension together with channels.	Reply	I-Reply	2
[line_break_token]- Finally there are two 2D convolution layers, with a 3x3 kernel then a 1x1 kernel.	Reply	I-Reply	2
[line_break_token]We have updated the text to clarify this.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding the related works you pointed out: Tulsiani et al.	Reply	I-Reply	2
does not actually have an image renderer: that work only has a 2D-to-3D mapping, and then uses losses to encourage the 3D representation to be consistent with the 2.5D data (RGB-D images).	Reply	I-Reply	2
Wu et al.	Reply	I-Reply	2
is similar to Tulsiani et al.:	Reply	I-Reply	2
they have no renderer and apply losses directly in 3D voxelspace, except they assume an orthographic camera instead of a perspective one.	Reply	I-Reply	2
Our work‚Äôs ‚Äúperspective transform‚Äù step is very similar to the first step in Yan et al.,	Reply	I-Reply	2
except they follow this by a single depthwise maxpool and output the result; this has no capacity for occlusion-reasoning and cannot be effective when the scene includes a background.	Reply	I-Reply	2
The Yang et al.	Reply	I-Reply	2
model uses a 1D (vector) latent space uses fully-connected layers for the transformations; our model‚Äôs 3D latent space allows for explicit geometric transformations.	Reply	I-Reply	2
Another related work is DeepVoxels (Sitzmann et al.),	Reply	I-Reply	2
which has a softmax on the ray axis, followed by a dot product.	Reply	I-Reply	2
We tried this, and found it did not work better than our CNN-based renderer.	Reply	I-Reply	2
We will add this result into the paper, as you suggest.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]-- It seems that the proposed method assumes slow moving background across consecutive frames.	Reply	O	0
[line_break_token][line_break_token]This is a great observation.	Reply	B-Reply	3
We do not explicitly assume a slow-moving background, but the egomotion module (with its coarse-to-fine cross correlations) has a limited effective range.	Reply	I-Reply	3
In particular, we use 3 scales in this module (0.25, 0.5, 1.0), and the correlations have a maximum displacement of 3 voxels; this means a limit of approximately 5 meters displacement between timesteps.	Reply	I-Reply	3
The rotation limit is approximately 8 degrees.	Reply	I-Reply	3
We chose these limits based on the statistics of camera motion in the KITTI dataset.	Reply	I-Reply	3
You are right that if the camera motion becomes unexpectedly extreme at test time, we will not be able to ‚Äúcancel it out‚Äù as desired, since our egomotion estimation will fail.	Reply	I-Reply	3
[line_break_token] [line_break_token][line_break_token](We continue in the next comment, due to the OpenReview character count limit.	Reply	O	0

This paper proposes a method for generalized image recognition based on random forest, that use directly the features extracted by the backbone, that assign pseudo-labels to the data.	Review	O	0
The learning is performed with a triplet loss adapted for better generalization.	Review	O	0
[line_break_token]Decision: weak reject[line_break_token]Motivation: the method is incremental and presented in general in a clear way and easy to follow, the authors present a simple but interesting trick to make the triplet loss more effective on a random forest in the case of generalization to a new unlabeled dataset.	Review	O	0
This method looks incremental to me because it is addressing the problem of pseudo-labelling for learning on a new dataset and instead of using confidence measures uses a random forest to assign labels.	Review	B-Review	8
[line_break_token]The experimental section of the paper is a bit confusing because is not clear if the results presented are with comparable network (e.g. ResNet18) like the cited state-of-the-art papers, from further readings I am confident the autors compared fairly with similar architectures.	Review	I-Review	1
Authors should perhaps stress they compare with state-of-the-art in fair condition to avoid confusion as in my case.	Review	I-Review	1
How much is the overhead of building the random forest for each iteration of the learning (algorithm 1), a more detailed analysis on this is useful for understanding the method.	Review	I-Review	2
Could this method be used to train a network from scratch on an unlabeled data or on data with noisy labels?	Review	I-Review	2
How did the authors choose the T decision trees, is there any ablation study, general practice or euristics behind the choice of 1,10,50?	Review	I-Review	3
The comparison with state-of-the-art Tab 3 and Tab 4 shows that for some datasets other techniques are better, did the authors draw some conclusions from that?	Review	I-Review	7
Comparing Tab 3 and 4 with Tab 5/6/7/8/9 looks like this method can work but only in the case of much bigger network like ResNet50 and DenseNet 161 which can limit its use for high resources (computing power) cases.	Review	I-Review	4
[line_break_token]Replicability: I think with improvements in the experimental section the method results can be replicated.	Review	O	0
At the moment it lack many details like learning rates, epoch of training and other useful information that are useful.	Review	B-Review	6
[line_break_token]Minor: there are two lines out of the 9 page limit	Review	O	0
e thank Reviewer 3 for the helpful comments.	Reply	O	0
We answer to the comments of Reviewer 3.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	3
Backbone networks[line_break_token]We compare the proposed algorithm with the state-of-the-art methods using the same backbone network such as ResNet-18 (Table 3), AlexNet (Table 4), ResNet-50 (Table 5, 6, 8 and 9), ResNet-152 (Table 7) and DenseNet-161 (Table 9).	Reply	I-Reply	1
[line_break_token][line_break_token]In Table 9, we use two backbone networks (ResNet-50 and DenseNet-161) for comparisons.	Reply	I-Reply	1
Since pairwise confusion (PC) [1] report results from both backbone networks, we compare the proposed method with PC on both for fair comparisons.	Reply	I-Reply	1
[line_break_token][line_break_token]We also revised the paper to clarify the backbone networks on page 6 and abstract.	Reply	I-Reply	1
[line_break_token] [line_break_token][1] Abhimanyu Dubey, Otkrist Gupta, Pei Guo, Ramesh Raskar, Ryan Farrell, and Nikhil Naik.	Reply	O	0
Pairwise confusion for fine-grained visual classification.	Reply	O	0
In European Conference on Computer Vision, pp.	Reply	O	0
70‚Äì86, 2018.	Reply	O	0
[line_break_token][line_break_token]2.	Reply	B-Reply	4
Overhead of each iteration[line_break_token]We measured the overhead of training time for random forests.	Reply	I-Reply	2
[line_break_token][line_break_token]As stated in answer 3, we use 300 epochs and random forests are trained at every 3 epochs for reducing the overhead.	Reply	I-Reply	2
[line_break_token][line_break_token]The time for training a random forest is about 15 seconds (MIT Indoor dataset with ResNet-50), which results in only 15sec X 300 epochs / 3 = 25 minute overhead in the whole learning process.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	4
The number of trees[line_break_token]We compare the performance of random forests constructed on canonical, strengthened, and generalized feature space with T=1,10 and 50 in Table 1.	Reply	O	0
As shown in [2] there is little change in performance above 64 trees for a random forest,  we measure the performance change from 1 to 50 in a way similar to [2]. Table 1 shows the ablation study of the performance with regard to the number of trees.	Reply	B-Reply	3
[line_break_token][line_break_token][2] Oshiro Thais Mayumi, Perez Pedro Santoro, Baranauskas Jos¬¥e Augusto, How many trees in a random forest?.	Reply	O	0
In International workshop on machine learning and data mining in pattern recognition, pp.	Reply	O	0
154‚Äì168, 2012[line_break_token][line_break_token]4.	Reply	O	0
Some results in Table 3 and 4[line_break_token]There are some cases that the proposed GCFN does not outperform the state-of-the-art methods.	Reply	O	0
However, the GCFN outperforms them in terms of average accuracy for each dataset, which shows the effectiveness of GCFN.	Reply	B-Reply	7
It is more important to analyze the overall average performance of all cases to validate the generalization ability rather than one or two cases.	Reply	I-Reply	7
[line_break_token][line_break_token]5.	Reply	I-Reply	4
Validation on small networks[line_break_token]We perform some additional experiments on the AlexNet [1] which is relatively small and fast networks compared to ResNet-50 and DenseNet-161.	Reply	I-Reply	4
[line_break_token][line_break_token]We compare the random forests on canonical features as the baseline with the proposed GCFN on the DTD, MIT Indoor and Scene-15 datasets.	Reply	I-Reply	4
[line_break_token][line_break_token]The results also confirm that GCFN also performs well with relatively small networks.	Reply	I-Reply	4
[line_break_token]                            DTD                      MIT Indoor                  Scene-15              [line_break_token]                  T=1   T=10  T= 50    T=1  T=10  T= 50       T=1   T=10  T= 50 [line_break_token]Base          44.9   60.4  62.8       39.9  59.2   62.0         79.9  88.5   88.9   [line_break_token]GCFN        55.0   63.1  64.2       51.6  62.1   63.1         84.7  88.7   89.5  [line_break_token][line_break_token][1] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.	Reply	O	0
Imagenet classification with deep convolutional neural networks.	Reply	O	0
In Neural Information Processing Systems, 2012[line_break_token][line_break_token]6.	Reply	O	0
Implementation details [line_break_token]We add the implementation details about the learning rate, batch size, number of epochs, and training process in Page 12 of the paper as below.	Reply	O	0
[line_break_token][line_break_token]We use 300 epochs with 5*10^(-3) learning rate, weigh decay with 9*10^(-4) for the network training.	Reply	B-Reply	6
Random forests are created at every 3 epochs to reduce the overhead.	Reply	I-Reply	6
Once we build a random forest, the neural networks are updated for 3 epochs based on the split result of the random forest.	Reply	I-Reply	6
The training time overhead due to the random forests is 15 seconds for MIT Indoor dataset with ResNet-50, which results in only 25 minute overhead in the whole learning process.	Reply	I-Reply	6
For the fast training, we use 50 trees with the split function of `F' for the network update.	Reply	I-Reply	6
[line_break_token][line_break_token]7.	Reply	O	0
Page limit  [line_break_token]We fix the page limit issue by moving some parts to the appendix.	Reply	O	0

This paper proposes generating feature representations for set elements using weighted multiset automata.	Review	O	0
Experiments show that this leads to better generalization performance in some tasks.	Review	O	0
[line_break_token][line_break_token]I am leaning to reject this paper.	Review	O	0
The proposed algorithm for generating features seems relevant and correct, but there are shortcomings in the presentation and the experiments are not entirely convincing.	Review	B-Review	4
[line_break_token][line_break_token]In particular, the paper begins by introducing weighted multiset automata quite clearly, but it fails to explain how exactly these automata would be used to generate set representations.	Review	I-Review	1
I assumed that the set would be represented as the state of the automaton after processing a string (where each element of the set is a symbol from the alphabet in the string) but in section 4 the different states of the automaton while processing a string are used instead.	Review	I-Review	1
If this paper proposes a new way of learning representations for sets, I would like to see a general recipe for the application of this idea.	Review	I-Review	1
[line_break_token][line_break_token]Reading the paper it is not entirely clear what theoretical results are novel and which proofs are restatements of existing proofs.	Review	I-Review	2
It would be useful to guide the reader a bit more clearly here.	Review	I-Review	2
[line_break_token][line_break_token]The second statement in section 4.1 is not clear to me: In what sense is the diagonal with alternating complex conjugate entries fully general?	Review	I-Review	3
[line_break_token][line_break_token]The experimental results are difficult to interpret.	Review	I-Review	4
Since there are no confidence intervals it is impossible to draw conclusions from table 1.	Review	I-Review	4
I am also not entirely convinced by figure 2.	Review	I-Review	7
The "unit digit of a sum" task seems slightly artificially constructed to be suitable for a network which uses complex numbers.	Review	I-Review	7
Although this is not a bad thing, it doesn't necessarily validate that complex weighted automata have better representational power.	Review	I-Review	7
If that was the case, wouldn't we expect better results for other tasks that don't explicitly have a cyclic nature?	Review	I-Review	7
[line_break_token][line_break_token]The main questions I would like to see answered (and adjusted in the paper) for me to accept this paper would be:[line_break_token][line_break_token]* What is the general recipe for applying this technique to get representations of a multiset?	Review	O	0
[line_break_token]* How do the experimental results validate the increased representational power of complex-weighted diagonal automata?	Review	O	0
hank you for taking the time to read and review our paper.	Reply	O	0
 We appreciate your feedback and below address questions you expressed.	Reply	O	0
[line_break_token][line_break_token]&gt; What is the general recipe for applying this technique to get representations of a multiset?	Reply	O	0
[line_break_token][line_break_token]Sorry that this wasn't clear.	Reply	B-Reply	5
The automaton is nondeterministic, so at each time step it could be in any state.	Reply	I-Reply	5
The vector fw(w) of forward weights could be thought of as like a distribution over the state that the machine is in after reading w, except that the values don't have to be probabilities.	Reply	I-Reply	5
This vector fw(w) is what we propose as the "general recipe" to represent multiset w.[line_break_token][line_break_token]&gt; It is not entirely clear what theoretical results are novel and which proofs are restatements of existing proofs.	Reply	O	0
[line_break_token][line_break_token]Again, sorry for not making this clear.	Reply	B-Reply	2
Proposition 1 and Lemma 4 are not novel.	Reply	I-Reply	2
To our knowledge, Propositions 2 and 3 are novel, as are the results in the appendices.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; In what sense is the diagonal with alternating complex conjugate entries fully general?	Reply	O	0
[line_break_token][line_break_token]To be fully general, we should have put in front of each and in front of each; apologies for this error.	Reply	B-Reply	3
With that correction in place, the form at the top of page 5 is general in the sense that any real-weighted multiset automaton is close to a complex-weighted diagonal automaton (Prop 3), and because the original automaton had real weights, the diagonal entries that are complex must come in conjugate pairs.	Reply	I-Reply	3
Those that are real can be duplicated to form conjugate pairs.	Reply	I-Reply	3
Thus, any real-weighted multiset automaton is close to one that can be put into the form shown.	Reply	I-Reply	3
We will try to make this clearer in a future version of the paper.	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; Since there are no confidence intervals it is impossible to draw conclusions from table 1.	Reply	O	0
[line_break_token][line_break_token]We've run bootstrap resampling to compare the other lines against the first line (the original position encodings).	Reply	B-Reply	4
Roughly, significance is at about 0.4 BLEU.	Reply	I-Reply	4
In the last line (learned per-position), all differences are significant except for Urdu-English.	Reply	I-Reply	4
This confirms our conclusion that learned per-position encodings are worse, but the rest are all about the same.	Reply	I-Reply	4
[line_break_token][line_break_token]&gt; The "units digit of a sum" task seems slightly artificially constructed to be suitable for a network which uses complex numbers.	Reply	O	0
Although this is not a bad thing, it doesn't necessarily validate that complex weighted automata have better representational power.	Reply	O	0
If that was the case, wouldn't we expect better results for other tasks that don't explicitly have a cyclic nature?	Reply	O	0
[line_break_token][line_break_token]The sum task demonstrates that DeepSets and our method are able to outperform LSTM and GRU models on multiset structured input, specifically being able to generalize results to multisets which are larger than were seen at training time.	Reply	B-Reply	7
 The units-digit-of-sum task is meant to be a simple extension of the sum task to demonstrate that our method can not only represent the same types of data as the DeepSets method, but also represent other behavior such as cycles.	Reply	I-Reply	7
 We have not run other tasks which don't explicitly have a cyclic nature for which DeepSets obtains less than 100% accuracy	Reply	I-Reply	7

This paper presents an approach for skills transfer from one task to another in a control setting (trained by RL) by forcing the embeddings learned on two different tasks to be close (L2 penalty).	Review	O	0
The experiments are conducted in MuJoCo, with a set of experiments being from the state of the joints/links (5.2/5.3) and a set of experiments on the pixels (5.4).	Review	O	0
They exhibit transfer from arms with different number of links, and from a torque-driven arm to a tendon-driven arm.	Review	O	0
[line_break_token][line_break_token]One limitation of the paper is that the authors suppose that time alignment is trivial, because the tasks are all episodic and in the same domain.	Review	B-Review	1
Time alignment is one form of domain adaptation / transfer that is not dealt with in the paper, that could be dealt with through subsampling, dynamic time warping, or learning a matching function (e.g. neural network).	Review	I-Review	1
[line_break_token][line_break_token]General remarks: The approach is compared to CCA, which is a relevant baseline.	Review	O	0
However, as the paper is purely experimental, another baseline (worse than CCA) would be to just have the random projections for "f" and "g" (the embedding functions on the two domains), to check that the bad performance of the "no transfer" version of the model is due to over-specialisation of these embeddings.	Review	B-Review	2
I would also add (for information) that the problem of learning invariant feature spaces is also linked to metric learning (e.g. [Xing et al.	Review	I-Review	2
2002]).	Review	I-Review	2
More generally, no parallel is drawn with multi-task learning in ML.	Review	I-Review	2
In the case of knowledge transfer (4.1.1), it may make sense to anneal \alpha.	Review	I-Review	2
[line_break_token][line_break_token]The experiments feel a bit rushed.	Review	I-Review	3
In particular, the performance of the baseline being always 0 (no transfer at all) is uninformative, at least a much bigger sample budget should be tested.	Review	I-Review	3
Also, why does Figure 7.b contain no "CCA" nor "direct mapping" results?	Review	I-Review	3
Another concern that I have with the experiments: (if/how) did the author control for the fact that the embeddings were trained with more iterations in the case of doing transfer?	Review	I-Review	3
[line_break_token][line_break_token]Overall, the study of transfer is most welcomed in RL.	Review	O	0
The experiments in this paper are interesting enough for publication, but the paper could have been more thorough.	Review	O	0
Thank you for your review.	Reply	O	0
We agree that assuming a trivial time alignment is somewhat unsatisfying, and to address this we have formulated an alternating optimization to learn the alignment jointly with the embeddings, described in Section 3.3.2.	Reply	B-Reply	1
The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space, as described in Section 3.3.2.	Reply	I-Reply	1
Results using this method can be found in Figure 5, Figure 7a.	Reply	I-Reply	1
Using this approach usually works better than just assuming timestep correspondences, or as well in the case of well aligned data.	Reply	I-Reply	1
[line_break_token][line_break_token]As per the suggestion of comparing with random projections, we have added a comparison using random projections as feature embeddings.	Reply	I-Reply	2
As shown in Figures 5 and 7a, this method achieves a low level of performance in between the CCA method and no transfer.	Reply	I-Reply	2
Also, as pointed out in the review we do indeed anneal \alpha over the course of learning in all our experiments.	Reply	I-Reply	2
[line_break_token][line_break_token]As shown in Table 1, we have run the ‚ÄúNo Transfer‚Äù method for 75 iterations (seeing 3 times more samples).	Reply	I-Reply	3
A likely reason the no transfer baseline doesn‚Äôt work even with this greater sample budget is that the exploration is insufficiently coherent for any reward to be obtained at all, leading to the behavior seen.	Reply	I-Reply	3
[line_break_token][line_break_token]Finally, we have added a connection to metric learning in the last paragraph of Section 2, as well as a paragraph on multitask learning (the third paragraph in Section 2).	Reply	I-Reply	3
[line_break_token][line_break_token]Figure 7b does not yet contain the comparisons with CCA and direct mapping because we have been adding these comparisons over the course of the response period.	Reply	I-Reply	3
This figure will contain all comparisons for the final version.	Reply	I-Reply	3
Thanks!	Reply	O	0

This paper proposes a method for link prediction on Knowledge Bases.	Review	O	0
The method contains 2 main innovations: (1) an iterative inference process that allows the model to refine its predictions and (2) a shared memory component.	Review	O	0
Thanks to these 2 elements, the model introduced in the paper achieved remarkable results on two benchmarks.	Review	O	0
[line_break_token][line_break_token][line_break_token]The paper is fairly written.	Review	O	0
The model is interesting and the experimental results are strikingly good.	Review	O	0
Still, I only rate for a weak accept for the following reasons.	Review	O	0
[line_break_token][line_break_token]* The main problem with this paper is that there is little explanation of how and why the two new elements aforementioned are leading to such better results.	Review	O	0
For instance:[line_break_token]  - What are the performance without the shared memory?	Review	B-Review	1
And when its size is grown?	Review	I-Review	1
[line_break_token]  - How does the performance is impacted when one varies Tmax from 1 to 5 (which the chosen value for the experiments I assume)?	Review	O	0
This gives an indications of how often the termination gate works.	Review	B-Review	2
[line_break_token]  - It would also be interesting to give the proportion of examples for which the inference is terminated before hitting Tmax.	Review	O	0
[line_break_token]  - What is the proportion of examples for which the prediction changed along several inference iterations?	Review	O	0
[line_break_token][line_break_token]* A value of \lambda set to 10 (Section 2) seems to indicate a low temperature for the softmax.	Review	O	0
Is the attention finally attending mostly at a single cell?	Review	B-Review	5
How do the softmax activations change with the type of relationships?	Review	I-Review	5
the entity type?	Review	I-Review	5
[line_break_token][line_break_token]* FB15k and WN18 are quite old overused benchmarks now.	Review	O	0
It would be interesting to test on larger conditions.	Review	B-Review	6
Thanks for your insightful review.	Reply	O	0
To address your comments, we added Table 2 and a corresponding paragraph to analyze the performance with different termination steps (T_max = 1, 2, 5, 8) and memory sizes (|M| = 32, 64, 128, 256, 4096).	Reply	B-Reply	2
In the T_max = 1 cases, it is the case where IRNs do not use the shared memory.	Reply	I-Reply	2
We found the number of times IRNs access the shared memory is critical for the performance, so IRNs cannot achieve the same level of performance without using shared memory.	Reply	I-Reply	2
[line_break_token]Regarding the attention over memory cells, we have found some interesting behaviors of the shared memory by counting the most active relations of each memory cell.	Reply	I-Reply	1
For example, in one particular memory cell, we observe its most active relations from a cluster around ‚Äúfamily/spouse based‚Äù relations.	Reply	I-Reply	1
We will update some findings in the discussion and we will test the current model on more challenge tasks, i.e., knowledge base QA, machine reading, and conversation bot in the future.	Reply	I-Reply	1

The paper claims to propose a computationally efficient algorithm for training deep CNNs by making assumptions about the distribution of data.	Review	O	0
The authors argue that (i) they don't make very simplistic assumptions about the data generating distribution as some other papers do, and (ii) their algorithm resembles the actual methods that are used for training deep models and shows some surprising properties of SGD.	Review	O	0
[line_break_token][line_break_token]Throughout the paper, the authors make a number of assumptions which seem arbitrary at times; not much justifications are provided.	Review	B-Review	11
The authors claim that their assumptions are not as simplistic as assuming e.g., the inputs are sampled from Gaussian distribution.	Review	I-Review	11
Unfortunately this is highly unclear: while the "assumptions" themselves are complex, the combination of those assumptions may make the problem solution trivial.	Review	I-Review	11
While proving a lower bound to address this issue may be hard, at least the authors should try to illuminate more why the solution is not trivial (e.g., why a linear classifier doesn't work, etc.)	Review	I-Review	11
[line_break_token][line_break_token]Despite the claims, I find the proposed algorithm very far from the usual SGD-based training methods; this is not a problem per se but I don't think that the result illuminates on the effectiveness of SGD (as the authors suggest).	Review	I-Review	12
The proposed algorithm is a greedy layer-wise method that in each level does a clustering and also trains a "linear" CNN with SGD.	Review	I-Review	12
So the hardness of end-to-end training of a deep network does not show up.	Review	I-Review	12
Furthermore, it is not clear for training a linear CNN the SGD is even needed.	Review	I-Review	12
[line_break_token][line_break_token]I suggest that the authors name each of the assumptions and clearly say which ones are assumed for which result.	Review	O	0
Here are some of the assumptions that the authors talk about.	Review	O	0
[line_break_token][line_break_token]1_ The data is generated by the following recursive procedure: First a small "high-level image" is generated from a distribution, G_0.	Review	O	0
The "pixels" of this high-level image are supposed to encode semantic classes, e.g., sky or ground.	Review	B-Review	1
In the next step, each of these high-level pixels are turned into a small (lower-level) image.	Review	I-Review	1
Therefore, we will have a more refined image after the second step. (	Review	I-Review	1
each semantic class (e.g., sky) has a corresponding distribution that generates the smaller lower-level image (e.g., uniform over 4 possible types of skies)).	Review	I-Review	1
This procedure continues recursively until we have the final image.	Review	I-Review	1
[line_break_token][line_break_token]2_ G_0 is "linearly separable".	Review	O	0
[line_break_token][line_break_token]3_ Semantic classes defined in the model are different enough from each other[line_break_token][line_break_token]4_ {F_c} corresponding to semantic classes are linearly independent [line_break_token][line_break_token]5_ Patch Orthonormality (apparently not assumed everywhere) [line_break_token][line_break_token][line_break_token]it appears that if one assumes all of 1-5, then the problem becomes trivial (linearly separable).	Review	O	0
The authors then say that we don't want to make assumption 5 for this reason; still, the problem solution may be trivial (authors should at least intuitively justify why it isn't )[line_break_token][line_break_token]Here are some more uses of the word "assumption".	Review	O	0
[line_break_token][line_break_token]6_ "For simplicity of analysis, we assume only the first layer of the network is trained".	Review	O	0
[line_break_token][line_break_token]7_ "We assume the algorithm [KMEANS++] returns a mapping [...] such that [...]" [line_break_token][line_break_token]The experiments do not seem conclusive.	Review	O	0
Only a few experiments have been done.	Review	B-Review	8
I think the acquired results for CIFAR-10 are below the usual ones using CNNs, and the effects of various hyper-parameters may have interfered.	Review	I-Review	8
[line_break_token][line_break_token]--[line_break_token]After reading the authors' response, I still think the way that the contributions are depicted (e.g., a justifying the effectiveness of SGD) are inaccurate/unsupported.	Review	O	0
[line_break_token][line_break_token]Furthermore, although the authors' suggest that they have tested a linear classifier and observed that the data is not linearly separable, more explanations/intuitions are needed about the assumptions that are made throughout the paper.	Review	B-Review	10
Thank you for the response.	Reply	O	0
[line_break_token]We will give here a few notes of clarification about the assumptions, and we can add these to the final revision of the paper.	Reply	O	0
We hope that these comments provide the intuitions and explanations that are missing.	Reply	O	0
[line_break_token][line_break_token]Assumption 1: The linear separability of the latent distribution captures the fact that the observed images are generated from a latent distribution that is "simple" to learn.	Reply	O	0
[line_break_token][line_break_token]Assumption 2: We assume that sets of patches that belong to different semantic classes are disjoint - this is just another way of writing that the there exists a partition of the set of patches, where each subset in the partition is identified with a semantic class.	Reply	O	0
The assumption that these subsets have the same size is just for simplification of the notations in the analysis.	Reply	B-Reply	3
[line_break_token][line_break_token]Assumption 3: We require that the frequency matrices of patches from different semantic classes are linearly independent in pairs - i.e, that two frequency matrices of different semantic classes are not linearly dependent (similar up to scaling by a positive scalar).	Reply	O	0
This is a way to make sure that the semantic classes defined in the model are different from each other, as otherwise one could define many different models that generate the same output distribution.	Reply	B-Reply	4
The empirical experiments that were added in Figure 3 show that this requirement holds for a model with random parameters.	Reply	I-Reply	4
[line_break_token][line_break_token]Assumption 4: The assumption about the orthonormality of the patches is given only in section 4, as a technical step that is not needed in the later analysis of the full algorithm	Reply	O	0

In my opinion, the paper contains very interesting novel ideas.	Review	B-Review	1
[line_break_token]However, some parts needs a future clarification and the state-of-the-art must be improved.	Review	I-Review	1
[line_break_token][line_break_token]- First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified.	Review	I-Review	1
For instance, I believe you can create a unique section with title " Choice of Proposal density " and then schematically describe each proposal from the simplest to the more sophisticated one.	Review	I-Review	1
[line_break_token][line_break_token]- At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.	Review	O	0
[line_break_token][line_break_token]- Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates where, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way.	Review	O	0
This is more general that your scheme but very related.	Review	B-Review	3
Please see[line_break_token][line_break_token]Qin, Z.S., Liu, J.S., 2001.	Review	I-Review	3
Multi-point Metropolis method with application to hybrid Monte Carlo.	Review	I-Review	3
Journal of Computational Physics 172, 827‚Äì840.	Review	I-Review	3
[line_break_token][line_break_token]L. Martino, V. P. Del Olmo, J. Read, "A multi-point Metropolis scheme with generic weight functions", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.	Review	I-Review	3
[line_break_token][line_break_token]L. Martino, "A Review of Multiple Try MCMC algorithms for Signal Processing", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.	Review	I-Review	3
[line_break_token][line_break_token]- Related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed.	Review	O	0
If I have properly understood, you also adapt a mixture via variational inference.	Review	B-Review	4
Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,[line_break_token][line_break_token]P. Giordani and R. Kohn, ‚ÄúAdaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,‚Äù Journal of Computational and Graphical Statistics, vol.	Review	O	0
19, no.	Review	O	0
2, pp.	Review	O	0
243‚Äì259, September 2010.	Review	O	0
[line_break_token][line_break_token]Tran, M.-N., M. K. Pitt, and R. Kohn.	Review	O	0
Adaptive Metropolis‚ÄìHastings sampling using reversible dependent mixture proposals.	Review	O	0
Statistics and Computing, 26, 1‚Äì21, 2014.	Review	O	0
[line_break_token][line_break_token]D. Luengo, L. Martino, "Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.	Review	O	0
[line_break_token][line_break_token]Roberts, G. O. and J. S. Rosenthal (2009).	Review	O	0
Examples of adaptive MCMC.	Review	O	0
Journal of Computational and Graphical Statistics 18, 349‚Äì367.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
Thank you for your review and well considered comments.	Reply	O	0
[line_break_token][line_break_token]> Review: In my opinion, the paper contains very interesting novel ideas.	Reply	O	0
[line_break_token]> However, some parts needs a future clarification and the state-of-the-art must be improved.	Reply	O	0
[line_break_token][line_break_token][line_break_token]> First of all,  Sections 2.3.1 or 2.3.2 can be improved and clarified.	Reply	O	0
For instance, I believe you can create a unique section with title " Choice of Proposal density " and then schematically describe each proposal from the simplest to the more sophisticated one.	Reply	O	0
[line_break_token][line_break_token]Thanks for the feedback.	Reply	B-Reply	1
As we edit the paper to include other changes we'll bear this in mind.	Reply	I-Reply	1
We'd hoped this was what we had done already but will try to make it clearer.	Reply	I-Reply	1
[line_break_token][line_break_token]> At the beginning of Section 2, please devote more sentence to explain why extending the space and apply the variational inference is good for finding a suitable good proposal density.	Reply	O	0
[line_break_token][line_break_token]We believe that this was made clear in sections 2.3.1 and 2.3.2.	Reply	B-Reply	2
In particular the discussion immediately following equation (9) tries to make this point.	Reply	I-Reply	2
However, we can add a further sentence emphasising this at the start of section 2 as well.	Reply	I-Reply	2
[line_break_token][line_break_token]> Related  to Section 2 ( theMixture Proposal MCMC contribution), the authors should discuss (in the introduction and also in the related works section) the Multiple Try Metropolis schemes with correlated candidates were, for instance, a path of candidates is generated and one of them is selected and tested with MH-type acceptance probability, in a proper way.	Reply	O	0
This is more general that your scheme but very related.	Reply	O	0
Please see[line_break_token][line_break_token]> Qin, Z.S., Liu, J.S., 2001.	Reply	O	0
Multi-point Metropolis method with application to hybrid Monte Carlo.	Reply	O	0
Journal of Computational Physics 172, 827‚Äì840.	Reply	O	0
[line_break_token][line_break_token]> L. Martino, V. P. Del Olmo, J. Read, "A multi-point Metropolis scheme with generic weight functions", Statistics and Probability Letters, Volume 82, Issue 7, Pages: 1445-1453, 2012.	Reply	O	0
[line_break_token][line_break_token]>L. Martino, "A Review of Multiple Try MCMC algorithms for Signal Processing", Digital Signal Processing, Volume 75, Pages: 134-152, 2018.	Reply	O	0
[line_break_token][line_break_token]Thanks for the pointers to these papers.	Reply	B-Reply	3
We are aware of Multiple Try Metropolis (MTM) but many of the references you provided below were new to us.	Reply	I-Reply	3
Whilst we acknowledge that MTM is a powerful tool in the MCMC arsenal, we felt that it was quite different to our method and really offers an orthogonal direction for improvement.	Reply	I-Reply	3
We don't attempt a thorough review of the state-of-the-art in MCMC, which we feel is beyond the scope here, but instead try to focus our discussion on other neural adaptive samplers such as L2HMC and A-NICE-MCMC.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]> related again with the state-of-the-art description, the references regarding  Adaptive Mixture Metropolis methods are completely missed.	Reply	O	0
If I have properly understood, you also adapt a mixture via variational inference.	Reply	O	0
Please, in Section 4, consider the different works that considers an adapting mixture proposal for a  Metropolis-type algorithm,[line_break_token][line_break_token]Thanks for the pointers to these papers.	Reply	O	0
These were mostly new to us and do seem very related.	Reply	B-Reply	4
After reading the papers more closely we will try to include them in our references.	Reply	I-Reply	4
[line_break_token][line_break_token]>P. Giordani and R. Kohn, ‚ÄúAdaptive independent Metropolis-Hastings by fast estimation of mixtures of normals,‚Äù Journal of Computational and Graphical Statistics, vol.	Reply	O	0
19, no.	Reply	O	0
2, pp.	Reply	O	0
243‚Äì259, September 2010.	Reply	O	0
[line_break_token][line_break_token]>Tran, M.-N., M. K. Pitt, and R. Kohn.	Reply	O	0
Adaptive Metropolis‚ÄìHastings sampling using reversible dependent mixture proposals.	Reply	O	0
Statistics and Computing, 26, 1‚Äì21, 2014.	Reply	O	0
[line_break_token][line_break_token]>D. Luengo, L. Martino, "Fully Adaptive Gaussian Mixture Metropolis-Hastings Algorithm", IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), Vancouver (Canada), 2013.	Reply	O	0
[line_break_token][line_break_token]>Roberts, G. O. and J. S. Rosenthal (2009).	Reply	O	0
Examples of adaptive MCMC.	Reply	O	0
Journal of Computational and Graphical Statistics 18, 349‚Äì36	Reply	O	0

This paper proposes a feature-wise transformation layer to augment the image features, which is a new regularization of neural networks and leads to better generalization ability of the features.	Review	O	0
And the proposed method performs well in the few-shot classification problem.	Review	O	0
Furthermore, the paper develops a learning-to-learn model in the cross-domain setting to choose optimal hyper-parameters of the feature-wise transformation layers.	Review	O	0
Which leads to consistent improvement in the cross-domain leave-one-out setting.	Review	O	0
[line_break_token][line_break_token]Although I vote weak accept for this paper, I still have several concerns:[line_break_token]* In equation, how to calculate the gradient of w.r.t in the condition that the is calculated after removing the feature-wise transformation layers from the model?	Review	O	0
In my understanding, The is not related to after the removal of the feature-wise transformation layers.	Review	B-Review	1
[line_break_token]* In Section 4.2, why not choose the Prototypical networks?	Review	O	0
According to the results in (Chen et al.,	Review	B-Review	2
2019a), it performs much better in the mini-ImageNet to CUB setting.	Review	I-Review	2
[line_break_token]* In Section 4.3, what's the initial value of and?	Review	O	0
Is the initial value sensitive to the performance?	Review	B-Review	3
[line_break_token]* In Section 4.2, actually, you can learn the and automatically even in a single domain.	Review	O	0
For example, use a different batch to update and.	Review	B-Review	4
What's the performance under this setting?	Review	I-Review	4
[line_break_token]* There is no direct comparison to the state-of-the-art methods.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is well written and the figures are well illustrated.	Review	O	0
The experiments show the effectiveness of the proposed feature-wise transformation layers and the learning-to-learning approach.	Review	O	0
But the above concerns should be addressed.	Review	O	0
‚Äî‚Äî---[line_break_token]&gt;&gt;&gt; Comments: There is no direct comparison to the state-of-the-art methods.	Reply	O	0
[line_break_token][line_break_token]&gt; Response: We include the results of several state-of-the-art methods [Qiao et al.,	Reply	O	0
2018; Oreshkin et al.,	Reply	B-Reply	5
2018; Lifchitz et al.,	Reply	I-Reply	5
2019; Lee et al.,	Reply	I-Reply	5
2019; Rusu et al.,	Reply	I-Reply	5
2019] on the mini-ImageNet dataset in Table 7 in the appendix.	Reply	I-Reply	5
Our conclusion is that training the metric-based framework with 1) pre-trained feature encoder, and 2) the proposed feature-wise transformation layers can demonstrate competitive performance.	Reply	I-Reply	5
For instance, the GNN approach trained with our pre-determined feature-wise transformation layers shows 66% 1-shot and 81% 5-shot classification accuracies on the mini-ImageNet dataset, which is comparable to the state-of-the-art MetaOptNet [Lee et al.,	Reply	I-Reply	5
2019] (with the accuracy of 64% 1-shot and 80% 5-shot).	Reply	I-Reply	5
[line_break_token][line_break_token]For the cross-domain setting, we report the performance of MetaOptNet [Lee et al.,	Reply	I-Reply	5
2019]. We use the model trained on the mini-ImageNet dataset provided by the authors (<a href="https://github.com/kjunelee/MetaOptNet)" target="_blank" rel="nofollow">https://github.com/kjunelee/MetaOptNet)</a> for the evaluation on other datasets.	Reply	O	0
As shown in the table below, while MetaOptNet [Lee et al.,	Reply	B-Reply	5
2019]  achieves state-of-the-art performance on the mini-ImageNet dataset, this approach also suffers from the domain shifts in the cross-domain setting.	Reply	I-Reply	5
Training the GNN framework with pre-trained feature encoder and feature-wise transformation layers performs favorably against the MetaOptNet method  [Lee et al.,	Reply	I-Reply	5
2019] under the cross-domain setting.	Reply	I-Reply	5
[line_break_token][line_break_token]5-way 5-shot performance of models trained on the mini-ImageNet dataset:[line_break_token]                                          CUB                       Cars                     Places                  Plantae[line_break_token][Lee et al.,	Reply	I-Reply	5
2019] |  54.67 ¬± 0.56%  |  45.90 ¬± 0.49%  |  65.83 ¬± 0.57%  |  46.48 ¬± 0.52%  |[line_break_token]GNN                      |  62.25 ¬± 0.65%  |  44.28 ¬± 0.63%  |  70.84 ¬± 0.65%  |  52.53 ¬± 0.59%  |[line_break_token]GNN + FT             |  66.98 ¬± 0.68%  |  44.90 ¬± 0.64%  |  73.94 ¬± 0.67%  |  53.85 ¬± 0.62%  |[line_break_token][line_break_token]S. Qiao et al.,	Reply	O	0
Few-Shot Image Recognition by Predicting Parameters From Activations, CVPR 2018.	Reply	O	0
[line_break_token][line_break_token]B. Oreshkin et al.,	Reply	O	0
TADAM: Task Dependent Adaptive Metric for Improved Few-Shot Learning, NeurIPS 2018.	Reply	O	0
[line_break_token][line_break_token]Y. Lifchitz et al.,	Reply	O	0
Dense Classification and Implanting for Few-Shot Learning, CVPR 2019.	Reply	O	0
[line_break_token][line_break_token]K. Lee et al.,	Reply	O	0
Meta-Learning with Differentiable Convex Optimization, CVPR 2019.	Reply	O	0
[line_break_token][line_break_token]A. Rusu et al.,	Reply	O	0
Meta-Learning with Latent Embedding Optimization, ICLR 2019	Reply	O	0

Summary:[line_break_token]The paper presents a novel method for answering ‚ÄúHow many ‚Ä¶?‚Äù questions in the VQA datasets.	Review	O	0
Unlike previously proposed approaches, the proposed method uses an iterative sequential decision process for counting the relevant entity.	Review	O	0
The proposed model makes discrete choices about what to count at each time step.	Review	O	0
Another qualitative difference compared to existing approaches is that the proposed method returns bounding boxes for the counted object.	Review	O	0
The training and evaluation of the proposed model and baselines is done on a subset of the existing VQA dataset that consists of ‚ÄúHow many ‚Ä¶?‚Äù questions.	Review	O	0
The experimental results show that the proposed model outperforms the baselines discussed in the paper.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]1.	Review	O	0
[tab_token]The idea of sequential counting is novel and interesting.	Review	O	0
[line_break_token]2.	Review	O	0
[tab_token]The analysis of model performance by grouping the questions as per frequency with which the counting object appeared in the training data is insightful.	Review	O	0
[line_break_token] [line_break_token]Weaknesses:[line_break_token]1.	Review	O	0
[tab_token]The proposed dataset consists of 17,714 QA pairs in the dev set, whereas only 5,000 QA pairs in the test set.	Review	O	0
Such a 3.5:1 split of dev and test seems unconventional.	Review	B-Review	1
Also, the size of the test set seems pretty small given the diversity of the questions in the VQA dataset.	Review	I-Review	1
[line_break_token]2.	Review	O	0
[tab_token]The paper lacks quantitative comparison with existing models for counting such as with Chattopadhyay et al.	Review	O	0
This would require the authors to report the accuracies of existing models by training and evaluating on the same subset as that used for the proposed model.	Review	B-Review	2
Absence of such a comparison makes it difficult to judge how well the proposed model is performing compared to existing models.	Review	I-Review	2
[line_break_token]3.	Review	I-Review	1
[tab_token]The paper lacks analysis on how much of performance improvement is due to visual genome data augmentation and pre-training?	Review	O	0
When comparing with existing models (as suggested in above), this analysis should be done, so as to identify the improvements coming from the proposed model alone.	Review	B-Review	3
[line_break_token]4.	Review	O	0
[tab_token]The paper does not report the variation in model performance when changing the weights of the various terms involved in the loss function (equations 15 and 16).	Review	B-Review	4
[line_break_token]5.	Review	O	0
[tab_token]Regarding Chattopadhyay et al.	Review	B-Review	2
the paper says that ‚ÄúHowever, their analysis was limited to the specific subset of examples where their approach was applicable.	Review	I-Review	2
‚Äù It would be good it authors could elaborate on this a bit more.	Review	I-Review	2
[line_break_token]6.	Review	O	0
[tab_token]The relation prediction part of the vision module in the proposed model seems quite similar to the Relation Networks, but the paper does not mention Relation Networks.	Review	O	0
It would be good to cite the Relation Networks paper and state clearly if the motivation is drawn from Relation Networks.	Review	B-Review	5
[line_break_token]7.	Review	O	0
[tab_token]It is not clear what are the 6 common relationships that are being considered in equation 1.	Review	O	0
Could authors please specify these?	Review	B-Review	5
[line_break_token]8.	Review	O	0
[tab_token]In equation 1, if only 6 relationships are being considered, then why does f^R map to R^7 instead of R^6?	Review	B-Review	5
[line_break_token]9.	Review	O	0
[tab_token]In equations 4 and 5, it is not clarified what each symbol represents, making it difficult to understand.	Review	B-Review	6
[line_break_token]10.	Review	O	0
[tab_token]What is R in equation 15?	Review	O	0
Is it reward?	Review	B-Review	6
[line_break_token][line_break_token]Overall:[line_break_token]The paper proposes a novel and interesting idea for solving counting questions in the Visual Question Answering tasks.	Review	O	0
However, the writing of the paper needs to be improved to make is easier to follow.	Review	O	0
The experimental set-up ‚Äì the size of the test dataset seems too small.	Review	B-Review	1
And lastly, the paper needs to add comparisons with existing models on the same datasets as used for the proposed model.	Review	I-Review	2
So, the paper seems to be not ready for the publication yet.	Review	O	0
We would like to thank the reviewer for their thoughtful and constructive feedback.	Reply	O	0
Before addressing the reviewer‚Äôs concerns, we should mention that since the original submission, we have observed superior performance (for all the models we consider) when using the visual features released with the original UpDown paper (those used by Anderson et al.).	Reply	B-Reply	7
We believe this choice simplifies our work by focusing our contribution on the counting module and, by using publicly available visual features, facilitates future comparison.	Reply	I-Reply	7
[line_break_token][line_break_token][line_break_token]Regarding comment 1: To examine the robustness of the test metrics, we re-computed the accuracy for the development and test splits after diverting 6500 randomly chosen QA pairs from dev to test (giving the adjusted dev/test splits 11k QA pairs each).	Reply	O	0
We did this for the 8 IRLC models from the hyperparameter sweep whose penalty weights surrounded the optimum.	Reply	B-Reply	1
On the original dev/test splits, those models have average accuracies of 56.21 & 57.06.	Reply	O	0
In the adjusted split, the average accuracies are 56.18 & 56.64.	Reply	O	0
This analysis suggests that the smaller test size does introduce some noise into the accuracy measurement, but the effect of that noise is small compared to the scale of the performance differences between SoftCount, UpDown and IRLC.	Reply	B-Reply	1
[line_break_token][line_break_token]Regarding comments 2, 3 and 5: The reviewer points out that we did not sufficiently place our work in the context of Chattopadhyay et al.	Reply	O	0
We agree and have attempted to correct that mistake in our revised submission (changes appear in Related Works and Models [page 4] sections).	Reply	B-Reply	2
[line_break_token]To further clarify our reasoning here, there are three main reasons we do not compare to their work.	Reply	O	0
[line_break_token]1) Our work and theirs both examine counting, but we use counting as a lens for exploring interpretability in visual question answering.	Reply	O	0
This led to considerably different architectures as considered between our works.	Reply	B-Reply	2
[line_break_token]2) Our work examines generalization for unseen or few-shot classes.	Reply	O	0
Since the question is a sentence, not a single word, there are a number of cases where the effective class is a combination of noun and adjective or position (eg.	Reply	B-Reply	2
black birds, people sitting on the bench).	Reply	I-Reply	2
Chattopadhyay et al.	Reply	I-Reply	2
only handles counting a fixed set of object classes and lacks the flexibility required for question answering.	Reply	I-Reply	2
[line_break_token]3) The reviewer has suggested that we train and evaluate a model based on their proposals (i.e. ‚Äúseq-sub‚Äù); however, to do so would make it very difficult to control for the quality/structure of visual features and the mechanism of visual-linguistic fusion.	Reply	O	0
Additionally, the seq-sub architecture is not amenable to question answering or supervision from VQA data alone.	Reply	B-Reply	2
[line_break_token]All in all, we believe that the issues described above makes quantitatively comparing our work to that of Chattopadhyay et al.	Reply	I-Reply	2
overly complicated and we hope the reviewer will agree with our assessment.	Reply	I-Reply	2
[line_break_token][line_break_token]As part of incorporating the new visual features, we have revised the model section describing the vision module.	Reply	I-Reply	5
This revision has resulted in the removal of the confusing text that the reviewer mentioned in comments 6-8.	Reply	I-Reply	5
[line_break_token][line_break_token]Following this change, we cannot readily assess how details of pre-training affect ultimate performance, as recommended in comment 3.	Reply	I-Reply	3
However, we have included an experiment to demonstrate the effect of data augmentation with Visual Genome (Appendix Section C in revised submission).	Reply	I-Reply	3
We observe that removing the Visual Genome data reduces accuracy by 2.7% on average and increases RMSE by 0.12 on average and that IRLC is most robust to the decrease in training data.	Reply	I-Reply	3
[line_break_token][line_break_token]In addition, we have incorporated the experiment suggested in comment 4 (Appendix Section C in revised submission).	Reply	I-Reply	4
The results demonstrate the range of weight settings in which the penalties improve performance.	Reply	I-Reply	4
[line_break_token][line_break_token]We have also clarified the model descriptions referred to in comments 9 and 10.	Reply	I-Reply	6
[line_break_token][line_break_token][tab_token][tab_token][tab_token][tab_token][tab_token][line_break_token]Anderson et al.	Reply	O	0
Bottom-Up and Top-Down Attention for Image Captioning and VQA.	Reply	O	0
In CVPR, 2017.	Reply	O	0
[line_break_token][line_break_token]Chattopadhyay et al.	Reply	B-Reply	2
Counting Everyday Objects in Everyday Scenes.	Reply	O	0
In CVPR, 2017.	Reply	O	0

This paper proposes to combine the distributed and symbolic execution for natural language queries.	Review	O	0
Based on the finding that the symbolic executor's column selection generally aligns with the field attention of the distributed enquirer, the authors incorporate the symbolic executor to the loss of the distributed enquirer by augmenting a field attention cross entropy loss into the original loss.	Review	O	0
This information is also used in pre-train the policy for the REINFORCE algorithm.	Review	O	0
The experiments show by combining the distributed and symbolic execution this way, the model achieve better performance.	Review	O	0
[line_break_token][line_break_token]I like the idea of incorporating the symbolic executor model into the neural model via attention.	Review	B-Review	1
Similar ideas have been proposed in other papers too (for example <a href="https://arxiv.org/pdf/1511.04586.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1511.04586.pdf</a> -- section 2.6) It would be nice if the authors can refer more to the related works.	Review	O	0
Thank you.	Reply	O	0
[line_break_token][line_break_token]Special thanks to the recommendation of the paper (<a href="https://arxiv.org/pdf/1511.04586.pdf)," target="_blank" rel="nofollow">https://arxiv.org/pdf/1511.04586.pdf),</a> where the authors train neural attention with IBM Model 4.	Reply	O	0
Our main idea works in an opposite way: we first make use of fully differentiable neural networks to learn meaningful (although imperfect) intermediate execution steps, and then guide an external symbolic system, which is more natural in our semantic parsing scenario.	Reply	B-Reply	1
[line_break_token][line_break_token]We revised the paper with discussion at the end of Section 1.	Reply	O	0
Due to page limitation, we had included more discussion in our extended version (Section 4 in <a href="https://arxiv.org/pdf/1612.02741.pdf);" target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.02741.pdf);</a> the suggested paper will also be discussed next time we update the arXiv version (i.e., in mini-batch fashion).	Reply	O	0

Summary:-[line_break_token]The authors investigates downsampling as one method by which autoencoding CNNs may memorize data.	Review	O	0
The theoretical motivation provided concentrates on linear CNNs.	Review	O	0
They show that downsampling linear CNNs tent to learn a point-map of the training data, even though (under certain initializations) they are capable of learning identity maps.	Review	O	0
However, non-downsampling linear CNNs learn identity maps.	Review	O	0
Given enough data however, the authors claim that the downsampling CNN will learn the identity map.	Review	O	0
[line_break_token][line_break_token]Strengths:-[line_break_token]+ Authors present a good exploration of how linear CNNs memorize data when they do downsampling.	Review	O	0
[line_break_token]+ A theoretical prediction of the amount of training data needed to counteract data memorization for downsampling linear CNNs is provided, "Our conjecture also implies that when training a linear downsampling CNN on images of size 3 ¬∑ 224 ¬∑ 224, which corresponds to the input image size for VGG and ResNet (He et al. (	Review	O	0
2016), Simonyan & Zisserman (2015)), the number of linearly independent training examples needs to be at least 3 ¬∑ 224 ¬∑ 224 = 153, 228 before the network can learn the identity function."	Review	O	0
[line_break_token][line_break_token]Weaknesses:-[line_break_token]+ Not enough theoretical proof is provided to support the hypothesis.	Review	O	0
Which would be fine but some key experiments are missing to make the paper empirically rigorous.	Review	B-Review	1
[line_break_token]++ Would be good to see experiments that illustrate the predication that a certain amount of data would allow for learning identity maps, both for linear and non-linear CNNs.	Review	O	0
[line_break_token]++ In the non-linear CNN setting, I'd like to see the same early-stopping experiment done for linear CNNs whose results are in Fig.	Review	O	0
3.	Review	B-Review	3
I don't see any obvious theoretical reason why that result form Fig.	Review	I-Review	3
3 must extend to the non-linear setting.	Review	I-Review	3
[line_break_token]+ Initializations are pointed to as effecting the type of function the network learns.	Review	O	0
The authors give an example of a hand-designed initialization that allows a downsampling linear CNN to learn the identity map but they don't explain how they arrived at this initialization, or its properties that make it a good initialization.	Review	B-Review	4
In general however, I think it's alright to assign exploration of effect of initialization to future work, since it seems like a non-trivial task.	Review	I-Review	4
[line_break_token]+ It is mentioned that "the results are not observed for linear networks when using Kaiming initialization," which I read to mean the downsampling linear CNNs with Kaiming initialization learn the identity map, not point-map.	Review	O	0
If this is true, it seems like a vital point and should be included in discussions of future work.	Review	B-Review	5
[line_break_token][line_break_token]Recommendation:  I think this could be a better short paper.	Review	I-Review	6
There are some interesting contributions, but maybe not enough for a full length paper.	Review	I-Review	6
For a full length paper, some further exploration of _why_ downsampling leads to (if indeed there is a causality) data memorization is needed.	Review	I-Review	6
[line_break_token][line_break_token]Minor stuff:-[line_break_token]Citation "Gunasekar et al."	Review	I-Review	7
is missing year (conclusions section)	Review	I-Review	7
In the following we provide a point-by-point response to the remarks concerning weaknesses :[line_break_token][line_break_token]In response to the first two points:  "+ Not enough theoretical proof is provided to support the hypothesis.	Reply	O	0
Which would be fine but some key experiments are missing to make the paper empirically rigorous. " "	Reply	O	0
++ Would be good to see experiments that illustrate the predication that a certain amount of data would allow for learning identity maps, both for linear and non-linear CNNs. "	Reply	O	0
[line_break_token][line_break_token]For linear downsampling networks, this experiment is shown in the proof of our proposition, namely we see that for 4 linearly independent training examples the network from Figure 4a learns the identity function exactly.	Reply	B-Reply	1
 Depending on the nonlinearity it may be impossible for non-linear CNNs to learn the identity map (for example a single layer with a ReLU activation can never learn the full identity function as it will always zero out the negative values), which is why our conjecture is made only for linear downsampling networks.	Reply	I-Reply	1
  [line_break_token][line_break_token]In response to "++ In the non-linear CNN setting, I'd like to see the same early-stopping experiment done for linear CNNs whose results are in Fig.	Reply	O	0
3.	Reply	B-Reply	3
I don't see any obvious theoretical reason why that result form Fig.	Reply	O	0
3 must extend to the non-linear setting. "	Reply	O	0
[line_break_token][line_break_token]We have run these experiments and they are identical to those for linear networks in Figure 3.	Reply	B-Reply	3
 For example, even after running for 100 iterations, downsampling non-linear networks learn the point map while non-downsampling non-linear networks learn a mapping more similar to the identity function.	Reply	I-Reply	3
 [line_break_token][line_break_token]With regard to  "+ Initializations are pointed to as effecting the type of function the network learns.	Reply	O	0
The authors give an example of a hand-designed initialization that allows a downsampling linear CNN to learn the identity map but they don't explain how they arrived at this initialization, or its properties that make it a good initialization.	Reply	O	0
In general however, I think it's alright to assign exploration of effect of initialization to future work, since it seems like a non-trivial task."	Reply	O	0
[line_break_token][line_break_token]In regard to the initialization of the identity map, we provide a full description of the initialization in Appendix A.  To provide more intuition around how we arrived at this initialization: the manual initialization is meant to preserve all pixels of the input image through the layers so that they can be rearranged by the final layer to get the identity function.	Reply	B-Reply	4
 [line_break_token][line_break_token]Lastly, in response to "+ It is mentioned that "the results are not observed for linear networks when using Kaiming initialization," which I read to mean the downsampling linear CNNs with Kaiming initialization learn the identity map, not point-map.	Reply	O	0
If this is true, it seems like a vital point and should be included in discussions of future work."	Reply	O	0
[line_break_token][line_break_token]We thank the reviewer for pointing out this possible misinterpretation.	Reply	B-Reply	5
When we say that the results are not observed for linear networks when using the Kaiming initialization, we meant to say that under the Kaiming initialization, the downsampling linear CNN learns neither the point map nor the identity map.	Reply	I-Reply	5
 [line_break_token][line_break_token][line_break_token]"Recommendation: I think this could be a better short paper.	Reply	O	0
There are some interesting contributions, but maybe not enough for a full length paper.	Reply	O	0
For a full length paper, some further exploration of _why_ downsampling leads to (if indeed there is a causality) data memorization is needed."	Reply	O	0
[line_break_token][line_break_token]Thanks, we will consider this in our future submission.	Reply	B-Reply	6
[line_break_token][line_break_token]"Minor stuff:- Citation "Gunasekar et al."	Reply	O	0
is missing year (conclusions section)"[line_break_token][line_break_token]Agreed, thanks.	Reply	O	0

Summary: This work proposes a new transformer architecture for tasks that involve a query sequence and multiple candidate sequences.	Review	O	0
The proposed architecture, called poly-encoder, strikes a balance between a dual encoder which independently encodes the query and candidate and combines representations at the top, and a more expressive architecture which does full joint attention over the concatenated query and candidate sequences.	Review	O	0
Experiments on utterance retrieval tasks for dialog and an information retrieval task show that poly-encoders strike a good trade-off between the inference speed of the dual encoder model and the performance of the full attention model.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- Strong results compared to baselines on multiple dialog and retrieval tasks.	Review	O	0
[line_break_token]- Detailed discussion of hyperparameter choices and good ablations.	Review	O	0
[line_break_token]- Paper is well written and easy to follow.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- Limited novelty of methods.	Review	O	0
Ideas similar to the model variants discussed in this work have been considered in other work (Eg: [1]).	Review	B-Review	1
It is also known that in-domain pre-training (i.e, pre-training on data close to the downstream task‚Äôs data distribution) helps (Eg: [2]).	Review	I-Review	6
So this work can be considered as an application of existing ideas to dialog tasks.	Review	I-Review	6
[line_break_token]- In terms of impact, utterance retrieval has fairly limited applicability in dialog.	Review	O	0
The dialog tasks considered in this work have a maximum of 100 candidate utterances, whereas in practice, the space of possible responses is much larger.	Review	B-Review	3
While retrieval models are useful, I am skeptical about the practical value of the improvements shown in the paper (especially the improvements over bi-encoder, which is already a decent model).	Review	I-Review	4
[line_break_token][line_break_token]Suggestions:[line_break_token]One way to get around the inefficiency of the cross-encoder architecture is to first use an inexpensive scoring mechanism such as TFIDF or bi-encoder to identify a small number of promising candidates from all the possible candidates.	Review	O	0
We can then use the cross-encoder to do more precise scoring of only the promising candidates.	Review	B-Review	5
I am curious where a pipelined model such as this compares against the variants discussed in the paper in terms of speed and performance.	Review	I-Review	5
[line_break_token][line_break_token]While the paper presents strong results on several dialog utterance retrieval tasks, the methods presented have limited novelty and impact.	Review	O	0
I am hence leaning towards borderline.	Review	O	0
[line_break_token][line_break_token]References[line_break_token][line_break_token][1] Logeswaran Lajanugen, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob Devlin, and Honglak Lee.	Review	O	0
2019.	Review	O	0
Zero-Shot Entity Linking by Reading Entity Descriptions.	Review	O	0
In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics.	Review	O	0
[line_break_token][2] Jeremy Howard and Sebastian Ruder.	Review	O	0
2018.	Review	O	0
Universal language model fine-tuning for text classification.	Review	O	0
In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics.	Review	O	0
[line_break_token][line_break_token]Edit: I have read the author response.	Review	O	0
Based on the rebuttal, I am more convinced about the practical impact of the approach.	Review	O	0
I am raising my score and recommending accept.	Review	O	0
hank you for your review.	Reply	O	0
[line_break_token][line_break_token]Re: "utterance retrieval has fairly limited applicability in dialog"[line_break_token][line_break_token]Firstly, there are whole competitions run by dialogue researchers evaluating retrieval systems, e.g. DSTC7 Track 1 last year, and again this year in DSTC8, implying researchers in the field feel it is very important.	Reply	O	0
Secondly, on a number of dialogue tasks, direct human evaluation comparing SOTA generative models with SOTA retrieval models ends up with retrieval models winning, see e.g. <a href="https://openreview.net/forum?id=r1l73iRqKm" target="_blank" rel="nofollow">https://openreview.net/forum?id=r1l73iRqKm</a> from last ICLR.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Re: "The dialog tasks considered in this work have a maximum of 100 candidate utterances, whereas in practice, the space of possible responses is much larger."	Reply	O	0
[line_break_token][line_break_token]The tasks do really involve 100,000+ candidates (all utterances from the training set, see Table 1) but the evaluation metrics used in previous work involve using a subset of those per evaluated example, presumably because methods such as cross-encoder are too slow to evaluate otherwise.	Reply	B-Reply	3
Poly-encoder can handle these sizes as evidenced in Table 5, which is of course the actual goal.	Reply	I-Reply	3
Note the IR task evaluation did use 10,000 candidates also (Table 4), where the methods worked very well.	Reply	I-Reply	3
This point seems to be more a criticism of standard evaluation practice, which we follow,  than our method.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Re: "I am skeptical about the practical value of the improvements shown in the paper (especially the improvements over bi-encoder, which is already a decent model)."	Reply	O	0
[line_break_token][line_break_token]The anonymity constraint of ICLR makes this response harder than it should be for us to reply to -- in fact, this approach has become our standard method going forward that we use in real situations, and hence we do emphasize it has strong practical value.	Reply	B-Reply	4
The method is practical because it is elegant &amp; simple, fast and gives great results, as evidenced by the evaluation metrics (Table 4) and inference speed (Table 5).	Reply	O	0
For us, it‚Äôs one of those papers where you do actually end up using the method, which definitely isn‚Äôt every time!	Reply	B-Reply	4
[line_break_token][line_break_token][line_break_token]Re: "One way to get around the inefficiency of the cross-encoder architecture is to first use an inexpensive scoring mechanism such as TFIDF or bi-encoder to identify a small number of promising candidates from all the possible candidates.	Reply	O	0
We can then use the cross-encoder to do more precise scoring of only the promising candidates.	Reply	O	0
I am curious where a pipelined model such as this compares against the variants discussed in the paper in terms of speed and performance."	Reply	O	0
[line_break_token][line_break_token]Building hybrids, pipelines and ensembles is often useful, but in this case looks tricky.	Reply	B-Reply	5
For example, if we cut down the number of candidates from 100k to 1k with a bi-encoder, then switched to a cross-encoder, we would still need 20 seconds (on CPU) to rank with the cross-encoder (see Table 5).	Reply	I-Reply	5
In this paper, we only compare single, related architectures against each other (bi, cross, poly).	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]Re: "Ideas similar to the model variants discussed in this work have been considered in other work (Eg: [1])."	Reply	O	0
[line_break_token][line_break_token]Firstly, our work actually predates that work (an earlier version of this submission was uploaded to a non-archival venue).	Reply	B-Reply	1
In any case, their brief description of architectures is not completely clear to us in terms of overlap, but apparently what they tried did not work as they conclude ‚ÄúThe significant gap between Full-Transformer and the other variants shows the importance of allowing fine-grained comparisons between the two inputs via the cross attention mechanism embedded in the Transformer‚Äù.	Reply	I-Reply	1
This is quite a different conclusion to ours, where we developed Poly-encoders which have almost the same performance as cross-encoders, but with huge speed-ups.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Re: "It is also known that in-domain pre-training (i.e, pre-training on data close to the downstream task‚Äôs data distribution) helps (Eg: [2]).	Reply	O	0
So this work can be considered as an application of existing ideas to dialog tasks."	Reply	O	0
[line_break_token][line_break_token]We agree that it is long-known that multi-tasking similar tasks is more useful than dissimilar tasks, as cited in our paper, and indeed our work is another example of this.	Reply	B-Reply	6
As we understand [2], which is also on a different topic as you say, doesn‚Äôt actually compare two types of pre-training to show this helps though, it only compares ‚Äúusing no pre-training with pre-training on WikiText-103‚Äù (and then fine-tunes on the data of interest).	Reply	I-Reply	6
 We also note that WikiText 103 experiments are not on the same scale as ours -- our pre-training on Reddit is more than 100x larger and compares to modern BERT pre-training.	Reply	I-Reply	6
 We believe our result is important because much recent work is ignoring related-domain pre-training and using BERT-based (and variant) models etc.	Reply	I-Reply	6
and scaling to larger &amp; larger data without considering this crucial point of related-domain pre-training.	Reply	O	0
 Our work provides clear empirical results that this is important even at massive scale.	Reply	B-Reply	6
 (We will however add this cite, thanks.	Reply	I-Reply	6

This paper introduces Distribution Matching Prototypical Network (DMPN) for Unsupervised Domain Adaptation (UDA).	Review	O	0
The proposed method explicitly models the feature distribution as a Gaussian mixture model in both source and target domains.	Review	O	0
Then the method aligns the target distribution with the source distribution by minimizing losses, which are called Gaussian Component Mean Matching (GCMM) and Pseudo Distribution Matching (PDM).	Review	O	0
[line_break_token][line_break_token]This paper should be rejected because (1) the novelty of the main idea is marginal, and (2) the performance gain over the baseline methods is also marginal.	Review	O	0
[line_break_token][line_break_token]Pan et al.	Review	B-Review	3
already proposed the idea of transferring the knowledge from the source to the target using the prototype of each class.	Review	I-Review	3
It is required to explain why explicit modeling performs better than implicit modeling of prototypes by theory or practice.	Review	I-Review	4
[line_break_token][line_break_token]In table 2, the proposed method seems better than TPN, but in the appendix, by comparing then in each category, the proposed method wins six categories, whereas TPN also wins six categories.	Review	I-Review	5
Therefore, it is hard to say the proposed DMPN is more effective than another method.	Review	I-Review	5
[line_break_token][line_break_token]Each prototype is modeled using a mean and a covariance matrix.	Review	I-Review	6
Why the authors don't use the estimated covariance matrix to measure the distance in eq.5?	Review	I-Review	6
[line_break_token][line_break_token]Because the proposed method uses pseudo-labeling for the target domain, it seems that the weights to determine unreliable examples are crucial.	Review	I-Review	7
The paper should show the sensitivity of ways to determine the weights.	Review	I-Review	7
What happens if values of 0.1 and 0.9 are changed in (pi-0.1)/0.9 on page 6?	Review	I-Review	7
hanks for reviewing our paper.	Reply	O	0
You rejected our paper based on two reasons: "This paper should be rejected because (1) the novelty of the main idea is marginal, and (2) the performance gain over the baseline methods is also marginal.".	Reply	O	0
We know it is difficult to argue about the novelty part, as different people have different tastes, however we want to have a try.	Reply	O	0
[line_break_token][line_break_token]As a researcher in the area of domain adaptation, you and us all agree on the importance of this area and have read a lot of great works and come across tons of ideas in this area.	Reply	B-Reply	1
But in all of these works and ideas, as far as we are concerned, none of them thought about modeling the feature distribution for domain adaptation though it facilitates us to better measure the distribution discrepancy across domains.	Reply	I-Reply	1
This is the gap in the area of domain adaptation we are trying to fill with this work.	Reply	I-Reply	1
You mentioned "the novelty of the main idea is marginal", so we want to ask which work do you have in mind that generates our idea as a marginal when you claim that?	Reply	I-Reply	1
If you have, please provide us the example.	Reply	I-Reply	1
Thanks very much.	Reply	I-Reply	1
[line_break_token][line_break_token]You mentioned "Pan et al.[1] already proposed the idea of transferring the knowledge from the source to the target using the prototype of each class.",	Reply	I-Reply	3
however, we want to clarify again that our work is not about applying prototypical network for domain adaptation, the main idea in our work is to model the feature distribution for domain adaptation, which is a new methodology for domain adaptation.	Reply	I-Reply	3
Thus, inspired from Wan et al.	Reply	I-Reply	3
's [2] work, we model the feature distribution as Gaussian Mixture.	Reply	I-Reply	3
In the Related Works section, we cite Snell et al.	Reply	I-Reply	3
's [3] paper, showing that learning prototypical network is equivalent to modeling feature distribution as exponential density.	Reply	I-Reply	3
This statement shows the only connection between our work and Pan et al.	Reply	I-Reply	3
's.	Reply	I-Reply	3
However, the equivalence expressed in the statement is only true for training a model in a single domain.	Reply	I-Reply	3
Our work is way different from Pan et al.	Reply	I-Reply	3
's work in the setting of domain adaptation.	Reply	I-Reply	3
[line_break_token]First, we base on different ideas.	Reply	I-Reply	3
While Pan et al.	Reply	I-Reply	3
propose a novel idea to remold Prototypical Network (PN) for domain adaptation, as stated in their paper, our work is based on the idea that almost all existing domain adaptation methods are minimizing the feature distribution discrepancy for effective knowledge transfer from source domain to target domain, however none of them explicitly models the feature distribution though intuitively it facilitates the measuring of distribution discrepancy, thus minimizing the measurement reduces the discrepancy.	Reply	I-Reply	3
[line_break_token]Second, the two works propose different distribution discrepancy loss functions.	Reply	I-Reply	3
While Pan et al.	Reply	I-Reply	3
proposes multi-granular distribution discrepancy loss functions at both class-level and sample-level.	Reply	I-Reply	3
Our work proposes two novel distribution discrepancy loss function based on probability, one is Gaussian Component Mean Matching and one is Pseudo Distribution Matching.	Reply	I-Reply	3
The two distribution discrepancy loss functions work at different aspects and complement each other, where GCMM brings the two distribution closer, PDM shapes the two distribution alike.	Reply	I-Reply	3
The two distribution discrepancy loss functions also work at different levels.	Reply	I-Reply	3
GCMM reduces domain discrepancy at class level, while PDM reduces domain discrepancy at sample level.	Reply	I-Reply	3
We all know that discrepancy loss functions play the central role in a domain adaptation method and devising new domain discrepancy loss functions for domain adaptation is an active research area [4,5,6]. Thus, researchers in the area of domain adaptation would not ignore the two novel discrepancy loss functions we put forward.	Reply	I-Reply	3
Furthermore, the idea that modeling the feature distribution enables us to propose new distribution discrepancy loss functions inspires further exploration in this direction to device more novel distribution discrepancy measures.	Reply	I-Reply	3
[line_break_token][line_break_token]You further mentioned "It is required to explain why explicit modeling performs better than implicit modeling of prototypes by theory or practice.".	Reply	I-Reply	4
As we are exploring the direction of modeling feature distribution for domain adaptation, we do not have much theory to back it up currently.	Reply	I-Reply	4
Indeed, modeling the feature distribution as Gaussian Mixture enables us to propose two novel domain discrepancy loss functions.	Reply	I-Reply	4
One is Gaussian Component Mean Matching (GCMM) and one is Pseudo Distribution Matching (PDM).	Reply	I-Reply	4
For GCMM, Pan et.	Reply	I-Reply	4
al.	Reply	I-Reply	3
have proposed a similar one, which they called general purpose domain adaptation, but theirs is more complicated and does not inherit a probability interpretation.	Reply	I-Reply	4

This paper proposes an RL training procedure that maintains an ensemble of k policies and periodically pushes all the policies to be closer to the best performing one.	Review	O	0
The formulation, experiments and analysis are very clear and show a mild improvement over using the same underlying RL algorithm without the imitation part.	Review	O	0
The idea is close to many other proposed in the literature, but to my knowledge it is the first time this exact procedure is studied in detail.	Review	O	0
[line_break_token][line_break_token]The first piece of their approach is an off-policy RL algorithm.	Review	O	0
In their case, they use SAC.	Review	O	0
The second piece is adding an ensemble of policies (3 in their case), and randomly selecting one of them every time a rollout is collected, and using the collected rollout to update all the policies.	Review	O	0
This effectively implies 3 times more overall gradient updates compared to SAC.	Review	O	0
They call this ablation SAC-ensemble.	Review	O	0
Interestingly they only use the most recently collected trajectories to update all policies, and despite storing the rollouts in a replay buffer, they seem to only use the stored transitions for the imitation part described below.	Review	B-Review	1
Some of their experimental results uses extra gradient steps, although it‚Äôs not clear if those gradient steps are also only on the last rollout collected, or on transitions sampled from the replay buffer as it is typical in off-policy RL methods.	Review	I-Review	2
In general, I think the work could improve with more details about how much the policy training could improve by increasing the number of gradient steps on the full replay buffer.	Review	I-Review	2
[line_break_token][line_break_token]The final piece of their method is selecting the best performing policy (or ‚Äúteacher‚Äù) of the ensemble based on the recent experience, and update all other policies by executing some gradient steps on the KL divergence between them and the current ‚Äúteacher‚Äù.	Review	O	0
They also try an experiment where the ‚Äúteacher‚Äù is selected randomly, and it does surprisingly well in my opinion (specially realizing that the ‚ÄúHalfCheetah‚Äù experiments seem to not have all seeds run to convergence, please report the full results).	Review	O	0
I suspect that most of the benefit of their method comes from randomly perturbing the parameters of the policies in the ensemble.	Review	B-Review	3
More thorough and careful experimentation needs to be carried out to investigate this direction.	Review	I-Review	3
This is in fact not very surprising given the results of Evolutionary Strategy methods, or Population-based training (even if usually used for hyper-parameters adaptation).	Review	I-Review	3
[line_break_token][line_break_token]Furthermore, the authors only run the environments for 1M steps, whereas in previous works some environments are shown to get higher return after more training steps.	Review	I-Review	5
I would also encourage the authors to report the results in all the standard MuJoCo benchmarks for the ablations (even if it‚Äôs in the appendix) to better asses their claims.	Review	I-Review	5
[line_break_token][line_break_token]Overall, this is a very well presented work, although it lacks some novelty and a few more thorough experiments to fully understand the improvements they show.	Review	O	0
I think this idea is worth sharing with the community, and I recommend a weak accept.	Review	O	0
irst, we would like to thank the reviewer for the time and effort given to the review, and for his/her valuable comments.	Reply	O	0
We will address various points that the reviewer mentioned here.	Reply	O	0
[line_break_token][line_break_token]-‚ÄúInterestingly they only use the most recently collected trajectories to update all policies, and despite storing the rollouts in a replay buffer, they seem to only use the stored transitions for the imitation part described below.	Reply	O	0
‚Äù[line_break_token]-‚ÄúSome of their experimental results uses extra gradient steps, although it‚Äôs not clear if those gradient steps are also only on the last rollout collected, or on transitions sampled from the replay buffer as it is typical in off-policy RL methods‚Äù.	Reply	O	0
[line_break_token][line_break_token]In fact, we indeed do what the reviewer notes that we should do, i.e., we use ‚Äútransitions sampled from the replay buffer as it is typical in off-policy RL methods‚Äù, for all of our experiments, as the original SAC algorithm does.	Reply	B-Reply	1
Perhaps this misunderstanding stems from our pseudocode (Algorithm 1), which was written to be general.	Reply	I-Reply	1
Though we allude to the use of experience replay for policy training in Section 4.2, we realize that the pseudocode is misleading to make one think that our policy is only trained by the most recent rollouts.	Reply	I-Reply	1
We have rewritten our pseudocode to accurately reflect our experiments and the SAC algorithm.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]-‚ÄúI suspect that most of the benefit of their method comes from randomly perturbing the parameters of the policies in the ensemble.	Reply	O	0
More thorough and careful experimentation needs to be carried out to investigate this direction.	Reply	O	0
‚Äù[line_break_token][line_break_token]First, we would like to clarify that our results demonstrate that selecting the best agent to be the teacher has some benefit over choosing a random teacher.	Reply	O	0
Perhaps we misunderstood, but we interpreted the reviewer‚Äôs mention of the ‚Äúrandom perturbation‚Äù to mean the change in parameters after performing distillation with a random teacher.	Reply	B-Reply	3
 We agree that this question is worth investigating, and we will address these in subsequent experiments in the future.	Reply	I-Reply	3
[line_break_token][line_break_token]Our hypothesis (which we have updated in the draft), outlined in Section 5.4, is that the reason that distillation from a random teacher performs quite well is because reducing the KL divergence between policies in the ensemble makes each policy better at learning from off-policy data generated from other members of the ensemble, by reducing the extrapolation error that comes from off-policy data distributions [11]. Thus, the distillation improves the quality of the off-policy RL updates, leading to better-than-expected performance for the agents.	Reply	I-Reply	3
[line_break_token][line_break_token]We intend to investigate this improvement by measuring the extrapolation error [11] (stemming from learning from off-policy data) before and after distillation to measure this effect.	Reply	I-Reply	3
We can do so with the method used by Fujimoto et al. [	Reply	I-Reply	3
11], where they measured the extrapolation error for DDPG, an off-policy actor-critic method applied to Mujoco tasks.	Reply	I-Reply	3
We will also run additional ablations where we withhold some agents in the ensemble from distillation or distill from all members of the ensemble to a single agent.	Reply	I-Reply	3
[line_break_token][line_break_token]We would like to re-emphasize that these additional investigations are not fundamental to our core claims and results in the paper.	Reply	I-Reply	3
These experiments are interesting supplementary experiments that better explain the reasons behind our performance improvements upon Ensemble-SAC.	Reply	I-Reply	3
However, they will not change our core result which is that Ensemble-SAC augmented with CIKD gives improves performance across several Mujoco tasks.	Reply	I-Reply	3
[line_break_token][line_break_token]-‚Äúspecially realizing that the ‚ÄúHalfCheetah‚Äù experiments seem to not have all seeds run to convergence, please report the full results‚Äù[line_break_token]-‚ÄúFurthermore, the authors only run the environments for 1M steps, whereas in previous works some environments are shown to get higher return after more training steps.	Reply	O	0
‚Äù [line_break_token][line_break_token]We intend to run experiments for longer training times and on all standard Mujoco tasks.	Reply	O	0
Due to limited resources, we have prioritized (for the rebuttal) running experiments for longer training times.	Reply	B-Reply	4
These experiments for longer training times are currently underway and we will post them to the rebuttal as soon as possible.	Reply	I-Reply	4
We will also run experiments on more Mujoco tasks, though it is not likely that we will be able to complete them within the rebuttal period.	Reply	I-Reply	4

The paper describes a "layer" that aims at producing embeddings for discrete objects by using fewer parameters than classical embeddings layers.	Review	O	0
Indeed, the model proposes, instead of learning an embedding matrix of size VxN, to learn a matrix of embeddings of anchors (AxN) and a transformation matrix (VxA) such that the embedding of any object can be found by multiplying A with T. On top of that, they propose different regularization techniques to improve the quality of the learned embeddings, and particularly a proximal gradient method over a L1 normalization on T to reduce the number of parameters.	Review	O	0
They propose also different ways to initialize A and also a method for incorporating a priori information (e.g knowledge) into the model.	Review	O	0
 They evaluate this model on different tasks: text classification and language modeling and show that they can achieve good performance while using fewer parameters than Sota methods.	Review	O	0
[line_break_token][line_break_token]First of all, the paper is well written, and the description is very detailed and understandable.	Review	O	0
It was a pleasure to read such a paper!	Review	O	0
 [line_break_token][line_break_token]One point which is unclear is the interest of using such a method, and more precisely in which cases, this method can be useful.	Review	O	0
Indeed, the overall number of parameters of ANT is AxN + VxA (N being the size of the embeddings, A the number of anchors and V the size of the vocabulary) while classical methods are VxN parameters.	Review	B-Review	1
Said otherwise, we need to have V&lt;N to really have less parameters to train in the model -- knowing that classical embeddings spaces size is usually between 256 and 1024, it means that we have to target a task where the number of anchors is quite low.	Review	O	0
I agree that the sparsity term on T is here to encourage to decrease the number of parameters but first, the same sparsity could be applied on the original VxN embedding matrix, and also, even if, at the end, the T matrix is sparse, during learning one has to maintain a large matrix in memory.	Review	B-Review	1
 I would like the authors to discuss more on this point which is crucial?	Review	I-Review	1
Particularly, I am not sure to understand what the #Emb value is in the table (AxN + AxV or just AxN), and how to compare the models. (	Review	I-Review	1
There is a discussion in Section 3, but the argumentation does not explain why having so many parameters at train time is not a problem).	Review	O	0
 Also, since this is the crucial point in the paper, I would be interested in having a discussion about the use of neural models compression techniques after learning that could also "do the job" (even if they are not trained end-to-end).	Review	O	0
[line_break_token][line_break_token]One other remark concerns the different "components" added into the model (e.g sparsity, orthogonality, Relu...).	Review	B-Review	3
It is difficult to measure the interest of each of them, and I would recommend the authors to provide an ablation study to make the effect of the different choices more understandable by the reader.	Review	I-Review	3
[line_break_token][line_break_token]The notion of anchors also is misleading since it gives the impression that the A matrix will store embeddings for particular objects, while there is no constraint of that type.	Review	I-Review	4
Each line of the A matrix is an embedding, but this embedding is not associated with one of the objects seen at train time (no direct mapping from anchors to words in the vocabulary).	Review	I-Review	4
This has to be made more clear at the beginning of the paper.	Review	I-Review	4
[line_break_token][line_break_token]Concerning the initialization of A by K-means, it assumes that the space of objects has a particular metric.	Review	I-Review	5
The authors say that this metric can come from a pretrained embedding space, but in that case, the problem in the number of parameters (which is the main justification of this work) is invalid (i.e if you already have an embedding matrix, then just let us fine-tune it).	Review	I-Review	5
Could you clarify ?	Review	I-Review	5
[line_break_token][line_break_token]The fact that the method would allow incorporating knowledge is certainly the most interesting point.	Review	O	0
The way it is done has to be better explained (I do not understand why positive pairs are taken into account by not enforcing sparsity on T at this particular point, the way negative pairs are handled seem more natural)[line_break_token][line_break_token]The paper is interesting and proposes a new simple model that could be used to keep good performance while reducing the number of parameters of the final model.	Review	O	0
Discussions have to be added to discuss the relevance of the approach since it still needs a large number of parameters at train time, and the role of each component could be studied more in depth.	Review	B-Review	3
hank you for your detailed comments and suggestions for improvements.	Reply	O	0
We answer your questions and provide more experimental comparisons with baselines below.	Reply	O	0
[line_break_token][line_break_token][R3 usefulness] Our methods are implemented using a dense matrix for the anchor embeddings A and a **sparse matrix** for the transformations T. Although, naively deep learning frameworks do not fully support backprop on such sparse matrix (basically change of non-zero locations in the sparse matrix is not supported) and we had do some engineering around it.	Reply	O	0
In particular, for T we store only the non-zero positions and their values in a sparse format that allow efficient row slicing (adjacency list or CSOO format).	Reply	B-Reply	1
The memory usage during training, storage, and evaluation are proportional to the size of A and the number of non-zero entries in T: size(A) + nnz(T).	Reply	I-Reply	1
Time complexity is hard to analyse, but empirically the runtime for training does increase by 1.6 times on WikiText-103 language modeling task, but its mostly due to our unoptimized engineering.	Reply	I-Reply	1
However, during inference time we see negligible difference because now native sparse ops for the T matrix can be utilized.	Reply	I-Reply	1
 We do not require that V &lt; N for our method to work, au contraire typically V &gt;&gt; N. In our experiments, we find that T is indeed very sparse, allowing us to obtain 10-100x compression of the embedding matrix, which in our opinion is a good trade-off.	Reply	O	0
We have added these details to subsection 3.4 in the paper.	Reply	B-Reply	1
We also outlined several tips to further speedup training in Appendix C and ways to incorporate our method with existing speedup techniques like softmax sampling or noise-contrastive estimation.	Reply	I-Reply	1
[line_break_token][line_break_token]Simply applying l1 sparsity to the entire V x N embedding matrix can be seen as a special case of our method where we use **no** anchors.	Reply	I-Reply	1
This is undesirable since 1) each object is also modeled independently without information sharing between objects (from a statistical perspective, no strength in parameter sharing), and 2) there are no underlying anchors to induce the remaining representations.	Reply	I-Reply	1
[line_break_token][line_break_token][R3 compression techniques] For the purposes of comparison, we selected a method based on hashing [3] as a post-processing step after training the embedding matrix.	Reply	O	0
Specifically, we call Post-SH baseline where we take the trained embedding matrix from a language model trained on PTB or WikiText-103, compress the matrix using the method from [3] (k-means to obtain the anchors + sparse representation the remaining points as in Alg 1 of [3]), and use the reconstructed matrix for evaluation.	Reply	B-Reply	2
As performance was not good, we tried to improve the method.	Reply	I-Reply	2
In particular, we use k-SVD [4] to solve for a sparse representation instead of using ad-hoc projection methods (eq 8-9) from [3] and report it as an additional baseline which we call Post-SH+k-SVD.	Reply	I-Reply	2
Comparing to these post-processing methods we demonstrate that end-to-end joint training of sparse embedding matrices is beneficial over post-processing compression.	Reply	I-Reply	2
[line_break_token][line_break_token]We present these results as follows:[line_break_token]Using AWD-LSTM on PTB language modeling:[line_break_token][line_break_token][tab_token][tab_token][tab_token]        #anchors[tab_token]perplexity[tab_token]#params (M)[line_break_token]Post-SH [tab_token][tab_token]        1,000[tab_token][tab_token]118.8[tab_token][tab_token]0.60[line_break_token]Post-SH[tab_token][tab_token]        500 [tab_token][tab_token]        166.8[tab_token][tab_token]0.30[line_break_token]Post-SH+k-SVD[tab_token]1,000 [tab_token][tab_token]78.0 [tab_token][tab_token]0.60[line_break_token]Post-SH+k-SVD[tab_token]500 [tab_token][tab_token]        103.5 [tab_token][tab_token]0.30[line_break_token]ANT (ours)[tab_token][tab_token]1000[tab_token][tab_token]72.0[tab_token][tab_token]        0.44[line_break_token]ANT (ours)[tab_token][tab_token]500[tab_token][tab_token]        74.0[tab_token][tab_token]        0.26[line_break_token][line_break_token]Using AWD-LSTM on WikiText-103 language modeling:[line_break_token][line_break_token][tab_token][tab_token][tab_token]        #anchors[tab_token]perplexity[tab_token]#params (M)[line_break_token]Post-SH [tab_token][tab_token]        1,000[tab_token][tab_token]764.7[tab_token][tab_token]5.7[line_break_token]Post-SH[tab_token][tab_token]        500 [tab_token][tab_token]        926.8[tab_token][tab_token]2.9[line_break_token]Post-SH+k-SVD[tab_token]1,000 [tab_token][tab_token]73.7 [tab_token][tab_token]5.7[line_break_token]Post-SH+k-SVD[tab_token]500 [tab_token][tab_token]        148.3 [tab_token][tab_token]2.9[line_break_token]ANT (ours)[tab_token][tab_token]1000 [tab_token][tab_token]39.7 [tab_token][tab_token]3.1[line_break_token]ANT (ours) [tab_token][tab_token]500 [tab_token][tab_token]        54.2 [tab_token][tab_token]0.4[line_break_token][line_break_token]We have also updated Tables 2 and 3 in the paper accordingly with these new baselines.	Reply	I-Reply	2
[line_break_token][line_break_token]These empirical results show that joint end-to-end training of the sparse embedding matrices is beneficial over post-processing compression, where errors may accumulate in both downstream tasks as well as embedding reconstruction.	Reply	I-Reply	2
We observe that the performance improvement of ANT over post-processing compression methods is larger on WikiText-103 as compared to PTB, demonstrating that our end-to-end sparse embedding method is particularly suitable for tasks with large vocabularies.	Reply	I-Reply	2
We emphasize that we are the first to incorporate these ideas of anchor points and sparse transformations into modern neural models for discrete objects	Reply	I-Reply	2

What is the task?	Review	O	0
[line_break_token]Multilingual natural language inference (NLI)[line_break_token][line_break_token]What has been done before?	Review	O	0
[line_break_token]Current state-of-the-art results in multilingual natural language inference (NLI) are based on tuning XLM (a pre-trained polyglot language model) separately for each language involved, resulting in multiple models.	Review	O	0
[line_break_token][line_break_token]What are the main contributions of the paper?	Review	O	0
[line_break_token][Not novel] Significantly higher average XNLI accuracy with a single model for all 15 languages.	Review	O	0
[line_break_token][Moderately novel] Cross-lingual knowledge distillation approach that uses one and the same XLM model to serve both as teacher (for English sentences) and student (for their translations into other languages).	Review	O	0
The approach does not require end-task labels and can be applied in an unsupervised setting[line_break_token][line_break_token]What are the main results?	Review	O	0
[line_break_token] A single model trained for all 15 languages in the XNLI dataset can achieve better results than 15 individually trained models, and get even better when unrelated poorly-translated languages are removed from the multilingual tuning scheme.	Review	O	0
[line_break_token] Using XD they outperformed the previous methods that also do not use target languages labels.	Review	O	0
[line_break_token][line_break_token]Weaknesses :[line_break_token]1.	Review	O	0
Combining XD with multilingual tuning is not effective in improving average results or even in case of target languages[line_break_token]2.	Review	O	0
Final system is adhoc as experiments on a particular set of languages have been used to support claims.	Review	B-Review	2
For example, Urdu was excluded to get the best MLT model.	Review	I-Review	2
Only 4 languages were used while combining XD and MLT[line_break_token]3.	Review	O	0
Findings, methods and experiments are not strongly novel.	Review	B-Review	3
[line_break_token]4.	Review	O	0
Paper was not an easy read.	Review	B-Review	4
[line_break_token][line_break_token]Strengths:[line_break_token] Using XD they outperformed the previous methods that also do not use target languages labels.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
hank you for your review and sorry for making you read a rushed submission -- we will definitely improve the writing and clarity of the paper.	Reply	O	0
[line_break_token][line_break_token]In our view the novelty here is that we present 2 approaches that achieve state-of-the-art results on XNLI (at the moment of the ICRL submission deadline): one using labels for all the languages, another one using only English labels.	Reply	B-Reply	3
The combination between the multilingual approach and XD gives a further small improvement, probably because they are based on the same XNLI inputs, but we still added this as an additional experiment.	Reply	I-Reply	3
[line_break_token][line_break_token]Concerning the choice of languages, it was mostly guided, not ad-hoc: for example, the removal of Urdu was driven by its lowest BLEU score of the MT system used to create the XNLI dataset; the 4 languages of the combination were indeed chosen without a thorough comparison (why not 3?	Reply	I-Reply	2
5?),	Reply	I-Reply	2
but again based on their BLEU score and NLI performance of the baseline model.	Reply	I-Reply	2
The idea was just to illustrate the sensitivity of XD to the quality of multilingual ‚Äúalignment‚Äù data	Reply	I-Reply	2

Although this paper seems to only combine existing techniques in community detection and node embedding into a co-train process.	Review	O	0
The idea is simple and easy understood and the paper is well-written.	Review	O	0
Theoretical analysis is provided for the approximation error for the sampling strategy.	Review	O	0
However, major concerns are:[line_break_token][line_break_token]1.	Review	O	0
Experimental results show that co-training node embedding and community detection can improve the performance for node classification.	Review	B-Review	1
The improvements may result from the assumption that papers with the same class label are associated with the same community in the citation graph.	Review	I-Review	1
However, in the dataset, there are many cases that there are not dense connections among the same labeled papers.	Review	I-Review	1
The authors should check the correlation between the detected communities and the original paper labels.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
No comparison with other community-preserving node embedding methods, such as "Community Preserving Network Embedding" in AAAI17[line_break_token][line_break_token]3.	Review	O	0
Since this paper aims to combine community detection and node embedding process, a set of baseline should be considered.	Review	B-Review	3
For example, if considering the downstream node classification of node embedding as an evaluation task, then how about the performance of the following two-step method.	Review	I-Review	3
We can first detect communities based on the node features then do graph node embedding by considering the communities' membership and node features together (e.g. simply concatenating both community membership features and node features).	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
Efficiency and scalability evaluations are needed.	Review	B-Review	4
Spectral clustering has a scalability issue when meeting big graphs.	Review	I-Review	4
Since the spectral process is also applied in the proposed method, efficiency and scalability evaluations are encouraged to provide, especially for big graphs which are not covered in the selected datasets in this paper.	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	I-Review	5
In Sec 5.3 and Fig 2, it's mentioned that trends of the three datasets are different.	Review	I-Review	5
For the increasing trend, how about the performance for an extreme case where all nodes are considered in one batch.	Review	I-Review	5
On the other hand, adding more nodes in one minibatch could provide more information, but why there exists a decreasing trend?	Review	I-Review	5
Though the authors provide a reason in Sec 5.3, it's better to analyze the reason directly from the datasets.	Review	I-Review	5
e would like to thank the reviewer for these constructive comments.	Reply	O	0
[line_break_token]1.	Reply	O	0
The assumption that each class label is associated with a community is not entirely correct.	Reply	B-Reply	1
First, there is no 1-to-1 mapping between a class label and a community.	Reply	I-Reply	1
The 1-to-1 mapping relies on an assumption that the number of communities and the number of classes should be the same.	Reply	I-Reply	1
There are cases that there are more communities than classes which makes n-to-1 mapping between communities and class labels.	Reply	I-Reply	1
For instance, several small unconnected communities form a class label.	Reply	I-Reply	1
[line_break_token]Second, the node embeddings can be considered as unnormalized probabilities of assigning nodes to communities.	Reply	I-Reply	1
Since the classifier is built on the node embeddings, there could be cases that all the nodes that have 60% chance to be in community C1 and 40% chance to be in community C2 to be classified to label L1 while another node with different probability assignments is assigned to another label.	Reply	I-Reply	1
[line_break_token]The assumption only makes sense when there are clear separation between communities in the graph and each community is associated with a label.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
It is worth noting that the technique in [1] (which is called M-NMF) is an extended version of one baseline (NMF) that we have compared in the paper.	Reply	B-Reply	2
However, we have added a comparison with the mentioned paper for completeness.	Reply	I-Reply	2
Please see Table 2 in the updated paper.	Reply	I-Reply	2
Still, our proposed method is able to outperform M-NMF significantly on all datasets.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
In this paper, we do not aim to combine community detection and node embedding process.	Reply	B-Reply	3
We aim to learn node embeddings by detecting community.	Reply	I-Reply	3
In the baseline proposed by the reviewer, it requires concatenation between community membership and node features, which requires knowing the community structure before learning the node embeddings.	Reply	I-Reply	3
Our experiment confirms that our approach outperforms the baseline.	Reply	I-Reply	3
For instance, in the Cora dataset, DMC achieves 0.839 while this baseline's accuracy is 0.749.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
It is worth noting that our proposed method (DMC) does not use spectral process.	Reply	B-Reply	4
In our paper, we discuss spectral method as it provides an analytical solution to minimize the mincut loss.	Reply	I-Reply	4
This means spectral method can serve as a baseline to compare our results obtained using neural networks with DMC.	Reply	I-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
It is expected that adding more nodes in a minibatch provide more information, which provides better performance.	Reply	B-Reply	5
After analysing the dataset, we found out another reason for the decreasing trend for the Pubmed dataset that the node features are extremely useful for node classification.	Reply	I-Reply	5
Adding more structure information (by adding nodes to the minibatch) would add noise, which decreases the classification accuracy.	Reply	I-Reply	5
On the other hand, for other datasets, we obtain an increasing trend as expected.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token][1] Wang, Xiao, et al. "	Reply	O	0
Community preserving network embedding."	Reply	O	0
Thirty-First AAAI Conference on Artificial Intelligence.	Reply	O	0
2017	Reply	O	0

This paper proposes a neural architecture for segmental language modeling[line_break_token]that enables unsupervised word discoveries.	Review	O	0
The architecture employes a [line_break_token]two-stage architecture that a word might be a type, or a sequence of characters[line_break_token]of its spellings.	Review	O	0
[line_break_token]This idea is basically similar to Nested Pitman-Yor language models [line_break_token](Mochihashi et al.	Review	B-Review	1
2009) and two-stage language models (Goldwater et al.	Review	I-Review	1
2011),[line_break_token]but the authors seem not to notice these previous work.	Review	I-Review	1
[line_break_token]Experimental results show some improvements on naive baselines, but clearly [line_break_token]below the state-of-the-art in unsupervised word segmentation.	Review	I-Review	2
[line_break_token][line_break_token]As noted above, the crucial drawback of this paper is that the authors are[line_break_token]completely unaware of latest achievements on unsupervised word segmentation[line_break_token]and discovery, rather than old, simplistic baselines such as Goldwater+ (2009,[line_break_token]idea is based on Goldwater+ ACL 2006) or Berg-Kirkpatrick (2010).	Review	I-Review	3
[line_break_token]The idea of using characters and words is already exploited in Mochihashi+[line_break_token](ACL 2009) in a nonparametric Bayesian framework; it has a better F1 than this[line_break_token]work by a large margin.	Review	I-Review	4
Moreover, it is recently extended (Uchiumi+ TACL [line_break_token]2015) to also include latent word categories as well as segmentations to yield [line_break_token]the state-of-the-art accuracies on F1=81.6 on PKU corpus, as compared to 73.1 [line_break_token]in this paper.	Review	I-Review	4
[line_break_token]Note that they employ a prior distribution on segment lengths as a (mixture of) [line_break_token]Poisson distributions or negative binomials whose parameters are [line_break_token]automatically learned during inference, as compared to a post-hoc regularization[line_break_token]used in this paper.	Review	I-Review	5
[line_break_token][line_break_token]In a Bayesian framework, interpolations between words and characters are[line_break_token]theoretically derived and quite carefully learned, and regularizations are[line_break_token]automatically adjusted.	Review	I-Review	6
While neural architectures have some potentials [line_break_token]to improve over them, current heuristic architectures that have lower [line_break_token]performance does not have any advantage over these methods, [line_break_token]both theoretically and empicially.	Review	I-Review	6
[line_break_token]	Review	O	0
This work presents a recurrent neural network language model that obtains better predictive distributions (perplexity) than an LSTM while also discovering the words that exist in language.	Reply	B-Reply	3
The review above misconstrues the aim of this paper as simply producing the best segmentation accuracy, which the papers cited achieve by tuning for segmentation performance on held out data and sacrificing predictive accuracy.	Reply	I-Reply	3
While we agree with the reviewer that there has been much excellent work done on nonparametric Bayesian segmentation (and two key ideas from that modeling tradition directly inspired this work!),	Reply	I-Reply	3
no such model has been shown to achieve perplexities close to those of an RNN.	Reply	I-Reply	3
However no previous RNN has been shown to discover plausible word segmentations.	Reply	I-Reply	3
Our model achieves both.	Reply	I-Reply	3
In doing so we argue that word segmentation is not a task that should be studied in isolation from the rest of the language learning but that the flexibility of neural models means they can approach other aspects (e.g., grounding in different modalities or tasks, learning large scale syntactic regularities) more naturally than would be practical with current Bayesian techniques.	Reply	I-Reply	3
[line_break_token][line_break_token]Below we elaborate on several more technical objections to this review:[line_break_token][line_break_token]First, our decision to focus on DP/HDP models rather than the extensions referred to in the review (specifically PYP/HPYPs, nested PYPs, integrating out hyperparameters, etc.)	Reply	I-Reply	3
was not due to ignorance, but rather that we were incorporating a two core ideas from Bayesian nonparametric word segmentation/language modeling into neural networks and we chose the simplest possible Bayesian model that made our points.	Reply	I-Reply	3
These are: (1) that a lexicon that memorizes word chunks is useful for inducing good segmentations; (2) that capacity control is important when you have a lexicon like this.	Reply	I-Reply	3
We do agree that nested PYPs, which learn to model character sequences (although not across word boundaries), deserve discussion and we will update the paper accordingly (again we emphasize that this is an oversight, not something that changes the meaningfulness of our results).	Reply	I-Reply	3
Thus, the DP/HDP models otherwise perfectly illustrates the points they needed to illustrate, and the newer variations do not offer any additional insight into how to fix the problems that RNNs have with discovering words.	Reply	I-Reply	3
[line_break_token][line_break_token]Second, our results are not precisely comparable since Bayesian unsupervised learning has traditionally been evaluated in a setup which does not distinguish between a train and test set, or which uses observations from both when performing posterior inference.	Reply	I-Reply	3
As we demonstrated, in Bayesian models, selecting hyperparameters empirically (ie, based on held-out likelihood) results in less effective structure discovery than setting the hyperparameters subjectively (however, since some standard datasets did not have a train/test split until this paper, we expect that in many cases, these models were chosen based on reported segmentation accuracies!).	Reply	I-Reply	3
We certainly appreciate the insights that have been enabled by using both methodologies, but our perspective is that relying on held-out likelihood for model selection is eminently defensible methodology.	Reply	I-Reply	3
However, held-out likelihood is indeed a radically different development/training/evaluation methodology for working on segmentation that is a better fit for neural models (and, we think, Bayesian models as well) than what came before, and it does make the results incomparable.	Reply	I-Reply	3
Finally, another source of incompatibility is that the Uchiumi et al (2015) length distribution correction relies on hand-engineered features.	Reply	I-Reply	3
We expected these were selected to improve reported segmentation accuracy (rather than validation likelihood), and as an ICLR paper, we are exploring how well we can do with learning representations, rather than engineering them.	Reply	I-Reply	3
[line_break_token][line_break_token]Third, the goal of this paper was to show that it is possible to align the goals of good segment discovery with good held-out models of language (after all, humans are good at both!).	Reply	I-Reply	3
In their zeal to argue that our segmentation accuracy lags behind that of the best Bayesian models (which we questioned in the previous paragraph), the reviewers ignore the crucial fact that the most basic RNNs outperform the best hierarchical Bayesian language models by far in terms of predicting held-out data.	Reply	I-Reply	3
Surprisingly, although posterior predictive checking is a standard tool for assessing Bayesian models, none of the existing Bayesian segmentation papers seem to have used this methodology, and so we had to include our own likelihood experiments (Table 4) to demonstrate this disparity.	Reply	I-Reply	3
These results show clearly that while Bayesian models are perhaps slightly better than our models in terms of segmentation accuracy, they are far less good than RNNs in terms of predictive accuracy.	Reply	I-Reply	3
On the other hand, our RNNs are good at both	Reply	I-Reply	3

The paper introduces a neural translation model that automatically discovers phrases.	Review	O	0
 This idea is very interesting and tries to marry phrase-based statistical machine translation with neural methods in a principled way.	Review	O	0
However, the clarity of the paper could be improved.	Review	O	0
[line_break_token][line_break_token]The local reordering layer has the ability to swap inputs, however, how do you ensure that it actually does swap inputs rather than ignoring some inputs and duplicating others?	Review	B-Review	1
[line_break_token][line_break_token]Are all segments translated independently, or do you carry over the hidden state of the decoder RNN between segments?	Review	I-Review	2
In Figure 1 both a BRNN and SWAN layer are shown, is there another RNN in the SWAN layer, or does the BRNN emit the final outputs after the segments have been determined?	Review	I-Review	3
Thank you for your valuable comments.	Reply	O	0
 We address the comments and questions below:[line_break_token]1.	Reply	O	0
The local reordering layer has the ability to swap inputs, however, how do you ensure that it actually does swap inputs rather than ignoring some inputs and duplicating others?	Reply	O	0
[line_break_token]<Response>: We do not have a guarantee that the layer forces to swap inputs as it is data driven.	Reply	O	0
In Appendix A, we show an example translating from "can you translate it ?"	Reply	B-Reply	1
to  "k√∂nnen es √ºbersetzen?"	Reply	I-Reply	1
to show that some input information is swapped.	Reply	I-Reply	1
 Note that the example needs to be reordered from "translate it" to "es √ºbersetzen".	Reply	I-Reply	1
 Each row of Figure 3 represents a window of size 7 that is centered at a source sentence word.	Reply	I-Reply	1
We can observe that the gates mostly focus on the central word since the first part of the sentence only requires monotonic alignment.	Reply	I-Reply	1
Interestingly, the model outputs "$" (empty) when the model has the word "translate" in the center of the window.	Reply	I-Reply	1
 Then, the model outputs "es" when the model encounters "it".	Reply	I-Reply	1
 Finally, in the last window (top row), the model not only has a large gate value to the center input "?",	Reply	I-Reply	1
but the model also has a relatively large gate value to the word "translate" in order to output the translation "√ºbersetzen ?".	Reply	I-Reply	1
 This shows an example of the reordering effect achieved by using the gating mechanism of the reordering layer.	Reply	I-Reply	1
[line_break_token] [line_break_token]2.	Reply	I-Reply	2
Are all segments translated independently, or do you carry over the hidden state of the decoder RNN between segments?	Reply	O	0
[line_break_token]<Response>: Yes, all the segments are translated independently.	Reply	O	0
We do not carry over the hidden states between segments.	Reply	B-Reply	2
Hence, the decoding can be parallelized.	Reply	I-Reply	2
We are highlighting this part in the second to last paragraph of Section 2.2.	Reply	I-Reply	2
[line_break_token] [line_break_token]3.	Reply	O	0
In Figure 1 both a BRNN and a SWAN layer are shown, is there another RNN in the SWAN layer, or does the BRNN emit the final outputs after the segments have been determined?	Reply	O	0
[line_break_token]<Response>: In Figure 1, the reordering layer and BRNN can be considered as the encoder of an input sequence.	Reply	O	0
The SWAN is the decoder, which contains another unidirectional RNN for p(a_t|x_t) in Eq. (	Reply	B-Reply	3
1).	Reply	I-Reply	3
The BRNN emits x_t to SWAN.	Reply	I-Reply	3
We added some clarification in defining x_t to address it	Reply	I-Reply	3

This paper presents a method for blind source separation relying on randomly initialized networks to decompose an input audio spectrogram into two components.	Review	O	0
[line_break_token]The networks are designed to promote temporal contiguity of spectral energy in the estimated signals, which are modulated (in time) by estimated masks.	Review	O	0
[line_break_token]The proposed method is evaluated on a collection of 150 random mixes of sounds, and performs favorably relative to some standard baseline methods (RPCA, NMF, KAM).	Review	O	0
[line_break_token][line_break_token]This seems like a promising line of work, but at this point I think the weaknesses of the paper outweigh its strengths (as detailed below).	Review	O	0
 Some of these points may be addressed during discussion, but I currently lean toward reject.	Review	O	0
[line_break_token][line_break_token][line_break_token]Strengths of the paper:[line_break_token][line_break_token]- The ideas are interesting, and appear to perform well on a simulated and real(ish) data.	Review	O	0
[line_break_token][line_break_token]- The authors investigate several variations and applications of source separation, including interactive editing, co-separation, and texture synthesis.	Review	O	0
[line_break_token][line_break_token]- A small (qualitative) ablation study is included to clarify the importance of different components of the loss function.	Review	O	0
[line_break_token][line_break_token][line_break_token]Weaknesses of the paper:[line_break_token][line_break_token]- Much of the presentation is vague or opaque.	Review	O	0
 There is little detail provided about the specific architectural parameters of the model, and the diagram (figure 1) does not appear to match the equations.	Review	B-Review	1
 Specifically, it's unclear whether S_1^* is a function of S_mixture or not.	Review	I-Review	1
[line_break_token][line_break_token]- The quantitative evaluation focuses entirely on one (new) dataset with unclear characteristics.	Review	O	0
 No details are provided about the evaluation protocol, and in particular, the tuning of hyperparameters for the various methods under comparison.	Review	B-Review	2
 Aggregate statistics are included (mean?	Review	I-Review	2
SDR, etc), but no notion of variance or error bars are included.	Review	I-Review	2
 It's not ultimately clear how fair this evaluation is.	Review	I-Review	2
 There should at minimum be a comparison on a standard source separation or speech enhancement dataset, in addition to the new set presented here.	Review	I-Review	2
[line_break_token][line_break_token]- Most of the spectrogram figures appear to be upside-down, which is confusing.	Review	O	0
 The details of the audio processing are omitted: STFT parameters are stated, but not the sampling rate.	Review	B-Review	3
[line_break_token][line_break_token]- There are numerous typos ("grounth", "spectrogram stokes", etc), indicative of the authors not running a spell-checker on their submission.	Review	O	0
[line_break_token][line_break_token][line_break_token]Questions for the authors:[line_break_token][line_break_token]- The model itself consists of several competing loss functions, but it seems like they may have a trivial, optimal solution at S1 = S_mix (M_1 = 1) and S_2 = 0 (M_2 = 0 or 1).	Review	O	0
 As far as I can tell, this solution would trivially minimize each term of equation 9.	Review	B-Review	5
 (If S_1* does not depend on S_mixture, this may be less of an issue, but the trivial solution may still exist when the driving noise is of sufficiently high dimension and the optimization is run long enough.)	Review	I-Review	5
 Am I misunderstanding the algorithm, or is there some deeper reason why this solution would not be preferred?	Review	I-Review	5
[line_break_token]	Review	O	0
hank the reviewer for recognizing our work and providing constructive comments.	Reply	O	0
We try to address the concerns brought up below.	Reply	O	0
[line_break_token][line_break_token]A1: Since U-net is commonly used in previous works (Ulyanov et al.,	Reply	O	0
2018; Gandelsman et al.,	Reply	B-Reply	1
2019), we only give the reference in the paper for making the paper be concise and leaving pages for delivering methods and several exciting applications.	Reply	I-Reply	1
But now, to make it more clear to readers, we have illustrated the network in the updated appendix (please see Section A.1 and Figure 10).	Reply	I-Reply	1
[line_break_token][line_break_token]Figure 1 is consistent with Equation 1 in the paper.	Reply	I-Reply	1
As shown in the Figure and formulated in the Equation, we decompose a sound mixture to individual sounds with corresponding mask modulations.	Reply	I-Reply	1
To achieve the decomposition, unlike all existing sound separation networks that use sound mixtures as separation network inputs, our DAP model learn individual audio source generator network and mask generator network for each audio source with randomly sampled noise as inputs.	Reply	I-Reply	1
Therefore, S_{mixture} is not a function input and it will serve as the groundtruth signal for learning as in Equation 2.	Reply	I-Reply	1
[line_break_token][line_break_token]A2: We have indeed faced the problem in our evaluation to find an existing dataset for validating our method whether can learn to handle various audio sources.	Reply	O	0
However, we learn that most existing datasets only contain either music or speech sounds.	Reply	B-Reply	2
To evaluate the generalizability of our deep audio prior network, we build a dataset containing 150 sound mixtures covering a large range of sound categories appeared in our daily life.	Reply	I-Reply	2
[line_break_token][line_break_token]For evaluation, we adopt the commonly used mir_eval library <a href="https://github.com/craffel/mir_eval" target="_blank" rel="nofollow">https://github.com/craffel/mir_eval</a> to compute SDR and SIR scores and LSD is implemented by us.	Reply	O	0
For the compared methods, we carefully tuned their parameters for fair comparisons.	Reply	B-Reply	2
However, the conventional matrix decomposition and kernel regression-based blind separation methods have limited capacity to well model rich and diverse audio patterns as shown in Figure 3 and also results in our anonymous Github repository.	Reply	I-Reply	2
[line_break_token][line_break_token]Since averaged scores of SDR, SIR, and LSD are commonly used metrics in previous literature, we also adopt the practice in our paper.	Reply	I-Reply	2
For additional comparison, we have compared our method with recent speech enhancement methods: DNP and SEGAN on a noisy speech, where the clean speech is from the used dataset in the SEGAN paper.	Reply	I-Reply	2
[line_break_token][line_break_token]To further address the concerns, we would like to show additional results on our dataset using a new metric and test our method on an existing standard sound separation dataset containing music and speech sounds.	Reply	I-Reply	2
We have included the additional experimental results in the Appendix of the paper (please see Section A.2.)	Reply	I-Reply	2
[line_break_token][line_break_token]To further clarify the numerical results, except from the mean SDR, mean SIR, and mean LSD, which are sensitive to over large or over small values (variance also has the same issue), we count the better result ratio based on the three metrics.	Reply	I-Reply	2
The ratio will count our DAP is better than the compared the method on how many testing samples.	Reply	I-Reply	2
For example, compared to the NMF in terms of SDR, the ratio is 0.753, which shows that our method is better than the NMF on 75.3% testing samples.	Reply	I-Reply	2
In terms of SDR, SIR and LSD, compared to NMF, RPCA, and KAM, the ratio results are (0.753, 0.66, 0.56)@SDR, (0.767, 0.627, 0.667)@SIR, and (0.714, 0.58, 0.714)@LSD, respectively.	Reply	I-Reply	2
The results further show the superiority and robustness of our method.	Reply	I-Reply	2
[line_break_token][line_break_token]To further validate our method, we compare with other methods on a sound separation benchmark (Vincent et al, 2007), which has 20 testing samples and each sample has 3 clean sounds.	Reply	I-Reply	2
In our testing, we take the first two sounds from each sample to compose sound mixtures.	Reply	I-Reply	2
The (SDR, SIR, LSD) results for NMF, RPCA, KAM, and DAP are (-3.36, -0.93, 0.56), (-4.49, -1.00, 0.57), (-2.16, -0.32, 2.19), and (-1.37, 0.82, 0.48).	Reply	I-Reply	2
We can see that our method outperforms the three compared methods in terms of SDR, SIR, and LSD.	Reply	I-Reply	2
Note that it is smaller and better for LSD.	Reply	I-Reply	2
[line_break_token][line_break_token]E. Vincent, R. Gribonval and M.D. Plumbley, Oracle estimators for the benchmarking of source separation algorithms, Signal Processing 87(8), p. 1933-1950, 2007.	Reply	O	0
[line_break_token][line_break_token]	Reply	O	0

The authors introduce MelNet, an autoregressive model of Mel-frequency scaled spectrograms.	Review	O	0
They convert audio into high resolution spectrograms to reduce the audio artifacts introduced by inverting spectrograms (here they use gradient-based inversion over Griffin-Lim).	Review	O	0
To improve modeling of long term dependencies, they perform multi-scale splitting of the spectrograms and maximize the likelihood at each scale (avoiding dominance of noise at higher resolutions).	Review	O	0
They condition generation at finer scales from coarser scales, enabling sampling through an ancestral process.	Review	O	0
The authors also highlight the difference between temporal and frequency dimensions, creating different conditioning stacks for the past in time vs. the "past" in frequency (lower frequencies), and mixing conditioning between the two stacks through layers of the network.	Review	O	0
Multilayer RNNs are used throughout the network and external conditioning is incorporated at the input.	Review	O	0
[line_break_token][line_break_token]The challenge the authors are attempting to address is modeling of audio structure on both long and short timescales.	Review	O	0
As the authors demonstrate with strong baselines, WaveNet models, while superior on fine-scale fidelity, fail to capture dynamics more than a couple hundred milliseconds.	Review	O	0
The experiments demonstrate improvements on state-of-the-art for unconditional generation on text-to-speech datasets (generating coherent words and phrases) and the MAESTRO piano dataset (generating sections with consistent dynamics/timing/motifs).	Review	O	0
The continuations of primed examples in both domains are particularly impressive qualitatively, as they maintain much of the character of the priming sample.	Review	O	0
Ablation experiments qualitatively demonstrate the importance of multi-scale modeling for unconditional generation.	Review	O	0
Human listener studies support the claims made from qualitative evaluation of long term structure.	Review	O	0
[line_break_token][line_break_token]This paper should be accepted because it represents a non-trivial adaptation of autoregressive modeling to handle multi-scale structure in audio.	Review	O	0
The baselines comparisons and strong, and experiments validate the claims of the paper.	Review	O	0
[line_break_token][line_break_token]That said, several things could be done to improve the clarity and significance of the paper.	Review	O	0
[line_break_token][line_break_token]* While the network architecture is described in detail and some figures, the full network structure itself is non-trivial and still somewhat opaque from the plain text description.	Review	O	0
A schematic diagram of the full network architecture, even in the appendix, could help clarify how many layers are present connecting each component of the model, which would improve reproducibility.	Review	B-Review	1
[line_break_token][line_break_token]* The paper is a bit thin on metrics.	Review	O	0
Human listening studies compare long-term structure, but not short-scale fidelity.	Review	B-Review	2
For TTS, there are clear artifacts from the spectrogram inversion process.	Review	I-Review	2
Mean opinion scores on conditional samples could help to quantify the importance of each element of the network for audio quality.	Review	I-Review	2
For instance, how does MOS compare between Griffin-Lim MelNet, Gradient Inversion MelNet, and WaveNet?	Review	I-Review	2
How does MelNet compare to Linear scaled spectrograms?	Review	I-Review	2
[line_break_token][line_break_token]* Generating MelSpectrograms to model long-term structure is a fairly established technique, most notably employed by all of the Tacotron variants (<a href="https://google.github.io/tacotron/)."	Review	O	0
target="_blank" rel="nofollow">https://google.github.io/tacotron/).</a> These models are perhaps a more appropriate comparison for MelNet in many ways, and opt for spectrogram inversion by smaller WaveRNN models.	Review	O	0
One of the claims of the paper is that it is important to model the fine-scale structure of spectrograms, but it is not clear if that really is the case.	Review	B-Review	3
A proper comparison to Tacotron models (where spectrograms are generated at the same resolution / the same inversion methods are used) would help clarify the importance of end-2-end training, vs. the learned inversion approach.	Review	I-Review	3
[line_break_token][line_break_token]	Review	O	0
hank you for the comments and suggestions.	Reply	O	0
[line_break_token][line_break_token]&gt; While the network architecture is described in detail and some figures, the full network structure itself is non-trivial and still somewhat opaque from the plain text description.	Reply	O	0
A schematic diagram of the full network architecture, even in the appendix, could help clarify how many layers are present connecting each component of the model, which would improve reproducibility.	Reply	O	0
[line_break_token][line_break_token]We spent a fair amount of time discussing how to show the architecture schematically, but ultimately did not come up with anything particularly satisfying.	Reply	B-Reply	1
 Most of the intricacy lies in the implementation of the multi-dimensional recurrence and the connectivity between the time and frequency stacks, so we focused on including equations and figures which provide clarity in these areas.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]&gt; The paper is a bit thin on metrics.	Reply	O	0
Human listening studies compare long-term structure, but not short-scale fidelity.	Reply	O	0
For TTS, there are clear artifacts from the spectrogram inversion process.	Reply	O	0
Mean opinion scores on conditional samples could help to quantify the importance of each element of the network for audio quality.	Reply	O	0
For instance, how does MOS compare between Griffin-Lim MelNet, Gradient Inversion MelNet, and WaveNet?	Reply	O	0
How does MelNet compare to Linear scaled spectrograms?	Reply	O	0
[line_break_token][line_break_token]We generally agree with your comments here.	Reply	B-Reply	2
 As we don‚Äôt provide any experiments regarding short-term fidelity, we made sure to restrict our claims to state that the benefit of MelNet relates to its ability to capture long-range structure.	Reply	I-Reply	2
 In cases where audio fidelity is paramount, time-domain models could be used to invert spectrograms generated by MelNet.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]&gt;  Generating MelSpectrograms to model long-term structure is a fairly established technique, most notably employed by all of the Tacotron variants (<a href="https://google.github.io/tacotron/)."	Reply	O	0
target="_blank" rel="nofollow">https://google.github.io/tacotron/).</a> These models are perhaps a more appropriate comparison for MelNet in many ways, and opt for spectrogram inversion by smaller WaveRNN models.	Reply	O	0
One of the claims of the paper is that it is important to model the fine-scale structure of spectrograms, but it is not clear if that really is the case.	Reply	O	0
A proper comparison to Tacotron models (where spectrograms are generated at the same resolution / the same inversion methods are used) would help clarify the importance of end-2-end training, vs. the learned inversion approach.	Reply	O	0
[line_break_token][line_break_token]The main distinction between MelNet and models such as Tacotron is that MelNet utilizes a much more flexible probabilistic model that allows it to be applied to unconditional generation tasks such as music generation.	Reply	B-Reply	3
 The experiments in this paper are restricted to unconditional audio generation, so direct comparison with models such as Tacotron would not be possible.	Reply	I-Reply	3
 We‚Äôve revised the paper to include a discussion of existing TTS models.	Reply	I-Reply	3

This paper propose a new approach to dialogue modeling by introducing two[line_break_token]innovations over an established dialogue model: the HRED (Hierarchical[line_break_token]Recurrent Encoder-Decoder) network.	Review	O	0
The innovations are: (1) adding a GAN[line_break_token]objective to the standard MLE objective of the HRED model; and (2)[line_break_token]modifying the HRED model to include an attention mechanism over the local[line_break_token]conditioning information (i.e. the "call" before the present "response").	Review	O	0
 [line_break_token][line_break_token]Writing: The writing was mostly ok, though there were some issues early in[line_break_token]Section 2.	Review	O	0
The authors rather awkwardly transition from a mathematical[line_break_token]formalism that included the two halves of the dialogue as X (call) and Y[line_break_token](response), to a formalism that only considers a single sequence X. [line_break_token][line_break_token]Novelty and Impact:  The proposed approach explicitly combines an established[line_break_token]model with two components that are themselves well-established.	Review	O	0
[line_break_token]It's fair to say that the novelty is relatively weak.	Review	B-Review	2
The model development[line_break_token]is sensible, but reasonably straightforward.	Review	I-Review	2
It isn't clear to me that a[line_break_token]careful reader of the literature in this area (particularly the GAN for[line_break_token]text literature) will learn that much from this paper.	Review	I-Review	2
[line_break_token][line_break_token]Experiments: Overall the empirical evaluation shows fairly convincingly[line_break_token]that the proposed model is effective.	Review	I-Review	3
I do wonder why would the hredGAN[line_break_token]model outperform the hred model on perplexity.	Review	I-Review	3
The hred model is[line_break_token]directly optimizing MLE which is directly related to the perplexity[line_break_token]measure, while the hredGAN include an additional objective that should[line_break_token](perhaps) sacrifice likelihood.	Review	I-Review	3
This puzzling result was not discussed and[line_break_token]really should be.	Review	I-Review	3
[line_break_token][line_break_token]The generated responses, given in table 3 -- while showing some improvement[line_break_token]over hred and Vhred (esp.	Review	I-Review	4
in terms of response length and specificity) --[line_break_token]do not fit the context particularly well.	Review	I-Review	4
This really just shows we still[line_break_token]have some way to go before this challenging task is solved.	Review	I-Review	4
[line_break_token][line_break_token]It would be useful if the authors could run an ablation study to help[line_break_token]resolve the relative contributions of the two innovations (GAN and[line_break_token]attention) to the improvements in results.	Review	I-Review	5
Perhaps the improvement in[line_break_token]perplexity (discussed above) is do to the use of attention.	Review	I-Review	5
[line_break_token][line_break_token]Detailed comments / questions[line_break_token][line_break_token]- In the paragraph between Eqns 2 and 3, the authors seem to suggest that[line_break_token]  teacher forcing is an added heuristic -- however this is just the[line_break_token]  correct evaluation of the MLE objective.	Review	O	0
[line_break_token][line_break_token]- In discussing the combined MLE-GAN objective in Eqn.	Review	O	0
8 Does the MLE[line_break_token]  objective use teacher forcing?	Review	B-Review	7
Some earlier text (discussed above) leads[line_break_token]  me to suspect that it does not.	Review	I-Review	7
[line_break_token]	Review	O	0
Thank you for your review.	Reply	O	0
[line_break_token][line_break_token]-- The authors rather awkwardly transition from a mathematical formalism that included the two halves of the dialogue as X (call) and Y (response), to a formalism that only considers a single sequence X.[line_break_token]We try to depict the original problem by Eq.(2) which is difficult to learn or train and substitute with a well known approximation (teacher forcing) in Eq.(3).	Reply	O	0
This a well established trick for training machine translation and dialogue response generation.	Reply	B-Reply	1
[line_break_token][line_break_token]--The model development is sensible, but reasonably straightforward.	Reply	O	0
[line_break_token]While HRED and GAN are will established concept, it is not trivial to combine due to the lack of end-to-end differentiability between the HRED generator and the GAN discriminator.	Reply	B-Reply	2
Also, the questions of where to inject noise and how to apply discrimination also arise.	Reply	I-Reply	2
Our paper addresses these problems by [line_break_token](i) proposing shared encoder and word embedding between the generator and the discriminator.	Reply	I-Reply	2
Existing works with seq2seq generator either use policy gradient (Li at.	Reply	I-Reply	2
Al, 2016) with no end-to-end differentiability or approximate embedding layer (Xu et al.	Reply	I-Reply	2
2017, Zhang et al.	Reply	I-Reply	2
2018) which is memory and computationally intensive with large vocabulary size.	Reply	I-Reply	2
 [line_break_token](ii) exploring noise injection at the word and utterance levels and discrimination at word level with RNN and at the utterance with CNN         [line_break_token][line_break_token]-- I do wonder why would the hredGAN model outperform the hred model on perplexity.	Reply	O	0
Perhaps the improvement in perplexity (discussed above) is do to the use of attention.	Reply	O	0
[line_break_token]We agree with your observation but due to space limitations, we only discussed this in the Ablation experiments in the Appendix.	Reply	B-Reply	3
Indeed, the presence of attention in the model is responsible for the low perplexity but it didn‚Äôt address the lack of diversity until we introduced GAN.	Reply	I-Reply	3
We will include the complete results for HRED+Attention in the ablation section for comparison in the final version.	Reply	I-Reply	3
[line_break_token][line_break_token]-- In the paragraph between Eqns 2 and 3, the authors seem to suggest that teacher forcing is an added heuristic [line_break_token]We agree with the reviewer that teacher forcing is the actual evaluation of MLE objective.	Reply	O	0
However, the problem of dialogue response generation is indeed autoregressive and not teacher forcing  (Please see Lamb et.	Reply	B-Reply	6
al 2016 for details).	Reply	I-Reply	6
During inference, Eq. (	Reply	I-Reply	6
2) is used while Eq.(3) is used as a tractable and accurate approximation during training.	Reply	I-Reply	6
This discrepancy, known as exposure bias has been the subject of several dialogue modeling papers (including Lamb et.	Reply	I-Reply	6
al 2016 and references there in).	Reply	I-Reply	6
[line_break_token]-- In discussing the combined MLE-GAN objective in Eqn.	Reply	O	0
8 Does the MLE objective use teacher forcing?	Reply	O	0
[line_break_token]Yes, the MLE objective uses teacher forcing as can be seen in Eq.(7).	Reply	B-Reply	7
  [line_break_token][line_break_token]Let us know if you have additional questions while we collate and analyze the human evaluation as well as the HRED+Attention results.	Reply	O	0

In many ways this work is well presented.	Review	B-Review	1
However, I have major concerns regarding the novelty of the proposed method and the theoretical rationale for the key design choices.	Review	I-Review	1
Although the authors do cite and discuss (Rosenbaum et al.,	Review	I-Review	1
2019), what is very much not clear to me is how the Gumbel-Matrix Routing proposed in this work differs from past work using the Gumbel Softmax within routing networks.	Review	I-Review	1
It seems like past work even focused on using only the task for routing, so it is not clear to me how the approach here is really novel in comparison.	Review	I-Review	1
Even if there is some distinction I am missing, the high level idea is clearly not that new.	Review	I-Review	1
Additionally, there is not much theoretical discussion about what the Gumbel Softmax adds to routing networks.	Review	I-Review	1
[line_break_token][line_break_token]The bias/variance tradeoff of Gumbel Softmax / RELAX / REINFORCE was already highlighted in (Rosenbaum et al.,	Review	I-Review	2
2019).	Review	I-Review	2
Can the performance of the model on the settings tested be attributed to this tradeoff?	Review	I-Review	2
If so, would a RELAX model perform even better?	Review	I-Review	2
Moreover, there is not much discussion of important implications of using the Gumbel Softmax trick in the context of routing.	Review	I-Review	2
First, as the authors acknowledge, but don't really elaborate on, using the Gumbel Softmax means we must backprop through every possible routing choice in each layer.	Review	I-Review	2
As a result, the Gumbel approach results in a large scaling of computation with the number of modules, limiting the applicability to more ambitious settings.	Review	I-Review	2
Moreover, while a clear motivation of this work is eliminating interference between tasks, it is not really explained how Gumbel Softmax does this and how it compares to hard routing decisions in this respect.	Review	I-Review	2
During backprop, the computation it very similar to mixtures of experts models, and should contain more interference than hard routing.	Review	I-Review	2
Can you explicitly show that the shape of the Gumbel distribution results in less interference between modules during learning than the standard mixtures of experts softmax approach?	Review	I-Review	2
[line_break_token][line_break_token]Furthermore, (Rosenbaum et al.,	Review	I-Review	3
2019) found that a number of RL based models outperform Gumbel Softmax when routing on multi-task settings of CIFAR-100 and the Stanford Corpus of Implicatives.	Review	I-Review	3
The authors do not provide any explanation for why this approach did not succeed in their settings.	Review	I-Review	3
This also leads me to doubt how impressive the results presented here are as there is really not any apples to apples comparison with the same architecture and different routing decisions.	Review	I-Review	3
In Tables 1 and 2 the best baseline is full sharing.	Review	I-Review	3
This indicates to me that the performance difference with other cited baselines has to do with different architecture choices and not changes in the routing policy itself.	Review	I-Review	3
The experiments can be much improved by discussing why past approaches to Gumbel based routing have failed and by thoroughly comparing to other methods for just the routing decisions with the same base architecture as done in prior work.	Review	I-Review	3
 Unfortunately, in its current form, there is not enough context provided for the community to understand the implications of the proposed approach in the submitted draft even though it achieves good performance.	Review	I-Review	3
e thank the reviewer for the valuable comments.	Reply	O	0
Our responses to specific comments are provided below.	Reply	O	0
[line_break_token][line_break_token]1) Novelty of our method[line_break_token][line_break_token]We agree that the Gumbel trick and the Gumbel-Softmax routing method is not new.	Reply	O	0
In this work, we propose a new method for multi-task learning and not a new routing method.	Reply	B-Reply	1
[line_break_token][line_break_token]While Gumbel-based routing has been already applied to multi-task learning, we claim that our formulation (in its full form) is novel for the following reasons:[line_break_token]- We learn flexible parameter sharing among tasks by learning binary allocation matrices indicating how each component is allocated to each task.	Reply	I-Reply	1
This is in contrast to previous works, which typically consider routing with a sequence of decisions ‚Äúwhere to route‚Äù.	Reply	I-Reply	1
We argue that our formulation is more natural for multi-task learning, as it provides an explicit way to control parameter sharing between tasks (depending on their relatedness).	Reply	I-Reply	1
Right now we condition on the task id, but in the future we envision conditioning on task embeddings, which can better capture the relatedness of the tasks.	Reply	I-Reply	1
[line_break_token]- Moreover, we also introduced ways to regularize our method such as the budget penalty (see Section 4.4) that promotes sparsity of the allocation solution.	Reply	I-Reply	1
[line_break_token][line_break_token]Since the proposed method is a new method for multi-task learning (and not a new routing method), we argue that evaluating different routing solvers (such as REINFORCE or RELAX) goes beyond the scope of this work.	Reply	I-Reply	1
However, it is a very interesting direction and it will definitely be the focus of our future work.	Reply	I-Reply	1
As per reviewer‚Äôs suggestion, this may further improve the results.	Reply	I-Reply	1
[line_break_token][line_break_token]2) Hard vs soft routing decisions[line_break_token][line_break_token]Please note that our method does use hard decisions, since we use the Straight-Through variant of the Gumbel-Softmax trick (the original Gumbel-Softmax paper introduces both the soft variant, and the Straight-Through variant).	Reply	O	0
If a connection is sampled to be inactive, the corresponding component will not contribute to the output and therefore will not get gradients.	Reply	B-Reply	2
It will only be used to compute the gradient for the per-connection routing probability.	Reply	I-Reply	2
[line_break_token][line_break_token]3) Comparing apples to apples[line_break_token][line_break_token]We believe that the Omniglot experiment is an apples-to-apples comparison, since we re-used the same architecture that achieved the previous SotA (‚ÄúDiversity and Depth in Per-Example Routing Models‚Äù, ICLR 2019).	Reply	O	0
We made sure that we reproduced all the details by contacting the authors of that prior work; we also used the same regularization strategies and the same optimizer.	Reply	B-Reply	3
The only difference is the routing method.	Reply	I-Reply	3
[line_break_token][line_break_token]4) Scalability[line_break_token][line_break_token]It is indeed the case that due to the use of Gumbel-Softmax, the backward pass needs to activate all of the components of the model.	Reply	O	0
Hence, the training phase of our method is more expensive than for other sparse baselines (such as the sparsely-gated mixture-of-experts).	Reply	B-Reply	3
[line_break_token]However, it is important to note that inference phase of our method is pretty scalable, since it uses hard decisions (and the budget penalty promotes even sparser solutions).	Reply	I-Reply	3
Therefore, we argue that our method is practical for many multi-task learning applications	Reply	I-Reply	3

[line_break_token]This paper trains low-precision network with quantized weights and quantized activation.	Review	O	0
The main idea is to split the scale and quantized values.	Review	O	0
Both scales and weights are updated with backprop and SGD.	Review	O	0
The paper presents excellent experimental results on ImageNet.	Review	O	0
[line_break_token][line_break_token]The paper is generally well written and easy to follow.	Review	O	0
However, there does exist quite some grammar errors, especially in abstract, which could be improved.	Review	B-Review	1
[line_break_token][line_break_token]Moreover, I would like the authors to clarify some technical details.	Review	I-Review	2
Are the scales s, so called step size in the paper, for every weight, every convolutional kernel, or very layer?	Review	I-Review	2
How do you deal with BatchNorm?	Review	I-Review	2
[line_break_token][line_break_token]What is the main benefits of the proposed quantization method in general?	Review	I-Review	3
Is it for fast inference, fast training, or just memory compression?	Review	I-Review	3
Do the authors see the real benefits in practice besides claiming the accuracy does not drop?	Review	I-Review	3
[line_break_token][line_break_token]I would suggest the authors discuss and compare with XNOR network in detail.	Review	I-Review	4
The proposed method looks similar.	Review	I-Review	4
[line_break_token][line_break_token]I am wondering how the baseline methods are tuned.	Review	I-Review	5
There are quite a few ‚Äútricks‚Äù like learning rate scheduler and weight decay, which I do consider them as contributions of the paper.	Review	I-Review	5
But would baseline methods also benefit from more hyper-parameter tuning?	Review	I-Review	5
[line_break_token][line_break_token]Minor issue, I donot get the explanation of eq (4), and it looks rather unnecessary.	Review	I-Review	6
It sounds to me starting from a trained network and then train 90 epochs is a rather long time.	Review	I-Review	6
Could the authors convince me this is a standard setting by providing some reference?	Review	I-Review	6
[line_break_token][line_break_token][line_break_token]================ after rebuttal=========================[line_break_token]Thank the authors for reply.	Review	O	0
My rating does not change.	Review	O	0
The proposed does look similar to XNOR, and the only difference seems to be how the scales are updated.	Review	B-Review	4
Since there is only one scale per layer, I will be quite surprised if the proposed method can be much better than XNOR.	Review	I-Review	4
Moreover, since BatchNorm is not quantized and it is everywhere in a ResNet-like architecture, it surprises me how much the scale helps.	Review	I-Review	4
Finally, I am worried about practical benefits towards the authors' claim because the networks are not fully quantized.	Review	I-Review	4
[line_break_token]	Review	O	0
We have carefully read through the manuscript to look for and fix grammatical issues.	Reply	B-Reply	1
 If the reviewer points out any specific issues that remain, we will be happy to fix them to improve the manuscript.	Reply	I-Reply	1
[line_break_token][line_break_token]There is one step size for each layer of weights (that is, for each weight tensor) and one step size for each layer of activations.	Reply	I-Reply	2
 This is noted in section 2.1 with the line "each layer of weights and each layer of activations has a distinct step size".	Reply	I-Reply	2
 BatchNorm is handled using full precision operations.	Reply	I-Reply	2
 We have updated the text in section 2.3 to clarify this point.	Reply	I-Reply	2
[line_break_token][line_break_token]The proposed method offers 2 main benefits.	Reply	I-Reply	3
 First, it allows for a reduction in model size, facilitating the deployment deep networks operating on the edge (for example, in mobile phones).	Reply	I-Reply	3
 Second, it points to the value of developing next generation inference hardware optimized for low precision operations to improve throughput and energy efficiency, while reducing latency.	Reply	I-Reply	3
 As we also note in our response to Review #2, we believe it is the correct first step to demonstrate the ability of deep networks to achieve high accuracy at these extremely low precisions before inference chips optimized for these precisions is commercially available.	Reply	I-Reply	3
 As such hardware becomes available, we look forward to benchmarking these low precision networks against full precision alternatives.	Reply	I-Reply	3
 [line_break_token][line_break_token]We now highlight the importance of XNOR in the introduction by noting it provided the first demonstration of tuned quantization.	Reply	O	0
 XNOR differs from our approach in that the former employs a quantizer tuned based on data statistics, in approach later taken by techniques such as TWN, Dorefa, FAQ, and Half-wave gaussian quantization, while the latter learns the quantization through backpropagation, which is noted in the introduction.	Reply	B-Reply	4
[line_break_token][line_break_token]Providing a comparison between various quantization methods using exactly the same weight decay or learning rate schedule is difficult, as there is no standardization across prior papers on settings.	Reply	I-Reply	5
 Properly re-implementing and re-running methods from prior papers can be challenging if even trivial details (for example, initial values) are missing from the original publications, and even if done properly, it is possible that different weight decay values or schedulers are optimal for different methods.	Reply	I-Reply	5
 However, we have sought to address this as best we can by showing our results at different weight decay values and showing the simple power of 2 search that was employed to find the weight decays chosen (Table 2).	Reply	I-Reply	5
 Notably, our approach still out performs the next best method even when using a weight decay of 10^-4, which is fairly standard for a full precision ResNet-18.	Reply	I-Reply	5
 We also ran an experiment using a more traditional step-based weight decay (Section 3.5), and found that again our approach still out performs that next best method (with only 90 epochs of fine-tuning, compared to a total of 360 epochs of fine-tuning for the next best method).	Reply	I-Reply	5
[line_break_token][line_break_token]If of interest, Table 3 explores the value of the gradient adjustment derived from Equation 4, and shows that it is important for achieving high accuracy.	Reply	I-Reply	6
[line_break_token][line_break_token]Relatively long fine-tuning in the quantized space after initializing from a full precision trained network is fairly common when targeting networks with less than 8-bits of precision, and in fact the 90 epochs we employ is on the short side.	Reply	I-Reply	6
 For example  Choi et al. ("	Reply	I-Reply	6
Learning low precision deep neural networks through regularization") fine-tuned for 100 epochs, McKinstry et al. ("	Reply	I-Reply	6
Discovering low-precision networks close to full- precision networks for efficient embedded inference") fine-tuned for 110 epochs, Baskin et al. ("	Reply	I-Reply	6
Nice: Noise injection and clamping estimation for neural network quantization") fine-tuned for 120 epochs, and Jung et al., ("	Reply	I-Reply	6
Joint training of low-precision neural network with quantization interval parameters") used a progressive quantization approach that amounted to a total of 360 additional epochs of fine-tuning for 2-bit models	Reply	I-Reply	6

The paper proposes to make a clear connection between the InfoNCE learning objective (which is a lower bound of the mutual information) and multiple language models like BERT and XLN.	Review	O	0
Then based on the observation that classical LM can be seen as instances of InfoNCE, they propose a new (InfoWord) model relying on the same principles, but taking inspiration from other models also based on InfoNCE.	Review	O	0
Mainly, the proposed model  differs both in the nature of the a and b variables used in InfoNCE, and also on the fact that it uses negative sampling instead of softmax.	Review	O	0
Experiments are made on two tasks and compared to a classical BERT model, and on the BERT-NCE model that is a BERT variant proposed by the authors which is somehow in-between BERT and InfoWord.	Review	O	0
They show that their approach works quite well.	Review	O	0
[line_break_token][line_break_token]I have a very mitigated opinion on the paper.	Review	B-Review	1
I) First, I really like the idea of trying to unify different models under the same learning principles, and then show that these models can be seen as specific instances of generic principles.	Review	I-Review	1
But the way it is presented and explained lacks of clarity: for instance in Section 2, some notations are not well defined (e.g what is f?) .	Review	I-Review	1
Moreover, the way classical models are casted under the InfoNCE principle is badly written: it assumes that readers have a very good knowledge of the models, and the paper does not show well the mapping between the loss function of each model and the InfoNCE criterion.	Review	I-Review	1
It gives technical details that could (in my opinion) get ignored, and I would clearly prefer to catch the main differences between the different models that being flooded by technical details.	Review	I-Review	1
So, my suggestion would be to improve the writing of this section to make the message stronger and relevant for a larger audience.	Review	I-Review	1
II) The Infoword model can be seen as a simple instance of word masking based models, and as an extension of deep infomax for sequences (it would be certainly nice to describe a little bit what Deep InfoMax is to facilitate the reading).	Review	I-Review	1
 Here again, the article moves from technical details (e.g "hidden state of the first token (assumed to be a special start of sentence symbol ") without providing formal definitions.	Review	I-Review	1
Having a first loss function after paragraph 4 could help to understand the principle of this model (before restricting the model to n-grams).	Review	I-Review	1
 Moreover, the equation J_DIM seems to be wrong since it contains g_\omega twice while I think (but maybe I am wrong) that it has also to be defined by g_\psi.	Review	I-Review	1
J_MLM is also not clear since x_i is never defined (I assume it is x_{i:i}).	Review	I-Review	1
At last,  after unifying multiple models under one common learning objective, the authors propose to mix two different losses which is strange (the effect of the second term is slightly studied in the experimental section) without allowing us to understand why it is important to have this second loss function and why the first one is not sufficient enough.	Review	I-Review	1
At last, I am pretty sure to not be able to reproduce the model described in the paper (adding a section on that in the supplementary material would help), and many concrete aspects are described too fast (like the way to sample negative pairs).	Review	I-Review	1
[line_break_token][line_break_token]Concerning the experimental section, experiments are convincing and show that the model is able to achieve a performance which is close to classical models.	Review	O	0
In my opinion, tis section has to be interpreted as  a proof that the proposed unified vision is a good way to easily define new and efficient models.	Review	O	0
[line_break_token][line_break_token]To summarize, the unification under the InfoNCE principle is interesting,  but the way the paper is written makes it very difficult to follow, and the description of the proposed model is unclear (making the experiments difficult to reproduce) and lacks of a better discussion about the interest of mixing multiple loss.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
hank you for your thoughtful review.	Reply	O	0
[line_break_token][line_break_token]We have updated the paper based on your comments to improve clarity and reproducibility.	Reply	B-Reply	1
We list a summary of our main changes below:[line_break_token]- In order to make it easier for readers to understand the differences between different models and how they are related to InfoNCE, we have added a summary in Table 1.	Reply	I-Reply	1
[line_break_token]- We have improved notations by adding explicit definitions before they are used in Section 2 and Section 4, and added a short description of Deep InfoMax in Section 4.	Reply	O	0
[line_break_token]- We have included model and training hyperparameter details in Section 5.1 and Appendix B.[line_break_token]- We added a motivation for mixing two different terms in the objective function.	Reply	O	0
Our DIM is primarily designed to improve sentence and span representations.	Reply	B-Reply	1
We combine it with MLM which is designed for learning (contextual) word representations, since our overall goal is to create better representations for both the sentence and each word in the sentence.	Reply	I-Reply	1
We also note that Deep InfoMax for learning image representations mixes multiple terms in their objective function.	Reply	I-Reply	1
We only take one of the terms from the full objective function and mix it with MLM.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding equation I_{DIM}, it is supposed to contain two g_{\omega} and no g_{\psi} as we use one network for encoding both the sentence and n-grams.	Reply	I-Reply	1
This is not a typo.	Reply	I-Reply	1

This paper is well written, and the quality of the figures is good.	Review	O	0
In this paper, the authors propose an invariant-covariant idea, which should be dated back at least to the bilinear models.	Review	O	0
The general direction is important and should be pursued further.	Review	O	0
[line_break_token][line_break_token]However, the literature is not well addressed.	Review	B-Review	1
Eslami et al.	Review	I-Review	1
2018 have been cited, but some very important and related earlier works like: [line_break_token][1] Kulkarni et al.	Review	I-Review	1
2015, Deep Convolutional Inverse Graphics Network[line_break_token][2] Cheung et al.	Review	I-Review	1
2015, Discovering Hidden Factors of Variation in Deep Networks[line_break_token]were not discussed at all.	Review	I-Review	1
The authors should certainly make an effort to discuss the connections and new developments beyond these works.	Review	I-Review	1
At the end of section 1, the authors argue that the covariant vector could be more general, but in fact, these earlier works can achieve further equivalence, which is much stronger than the proposed covariance.	Review	I-Review	1
[line_break_token][line_break_token]There is also an effort to compare this work to Sabour et al.	Review	I-Review	2
2017 and the general capsule idea.	Review	I-Review	2
I would like to point out, the capsule concept is a much more fine-grained what & where separation rather than a coarse-grained class & pose separation in one shot.	Review	O	0
In a hierarchical representation, what & where can appear at any level as one class can consist of several parts each with a geometrical configuration space.	Review	O	0
So the comparison of this work to the generic capsule network is only superficial if the authors can not make the proposed architecture into a hierarchical separation.	Review	B-Review	2
Besides different capsule network papers, I found another potentially useful reference on a fine-grained separation:[line_break_token][3]Goroshin et al.,	Review	I-Review	2
Learning to Linearize Under Uncertainty[line_break_token][line_break_token]In the paper, it is argued several times that the latent vector r_y contains a rich set of global properties of class y, rather than just its label and the aim is that it can learn what the elements of the class manifold have in common.	Review	O	0
But this point is not supported well since we can always make a label and this latent vector r_y equivalent by a template.	Review	B-Review	3
I think this point could be meaningful if we look at r_y's for different y, where each of the dimension may have some semantic meaning.	Review	I-Review	3
Additional interpretation is certainly needed.	Review	I-Review	3
[line_break_token][line_break_token]Under equation (3), "Note that v is inferred from r_y" should be "inferred from both r_y and x", which is pretty clear from the fig 5.	Review	I-Review	4
Related to this, I could imagine some encoder can extract the 'style' directly from x, but here both r_y and x are used.	Review	I-Review	4
I couldn't find any guarantee that v only contains the 'style' information based on the architecture with even this additional complication, could the authors comment on this?	Review	I-Review	4
[line_break_token][line_break_token]Equation (5) is not really a marginalization and further equation (6) may not be a lower bound anymore.	Review	I-Review	5
This is probably a relatively minor thing and a little extra care is probably enough.	Review	I-Review	5
[line_break_token][line_break_token]The numbers in table 2 seems a little outdated.	Review	I-Review	6
[line_break_token][line_break_token]To conclude, I like the general direction of separating the identity and configurations.	Review	O	0
The natural signals have hierarchical structures and the class manifold concept is not general enough to describe the regularities and provide a transparent representation.	Review	B-Review	2
Rather, it's a good starting point.	Review	I-Review	1
If the authors could carefully address the related prior works and help us understand the unique and original contributions of this work, this paper could be considered for publication.	Review	I-Review	1
We appreciate deeply the reviewer's detailed feedback.	Reply	O	0
The reviewer made a number of useful suggestions to improve this submission, of which we felt that the most prominent theme was improving our discussion and comparison to the literature.	Reply	O	0
We discuss this first.	Reply	O	0
[line_break_token][line_break_token]Overall, we have included 9 new references to the literature along with discussion in Section 1, which has been significantly modified.	Reply	B-Reply	1
In particular, we discuss the two important references [1] and [2] provided by the reviewer.	Reply	I-Reply	1
Indeed these two references are able to separate more structure into their latent variables (for data sets that contain structured labels for different variations of the data) using a 'clamping' technique during training to force particular latent components to be disentangled (as in [1]), or by predicting the labels and using a cross-covariance term in the objective function of their deterministic autoencoder (as in [2]).	Reply	I-Reply	1
Similarly, we discuss InfoGAN (Chen et al, 2016), which achieves disentanglement by adding a mutual-information maximisation term between the meaningful latent and the model generations.	Reply	I-Reply	1
We consider the simplicity of our probabilistic model, trained with log-likelihood maximisation (no additional objective function hyperparameters), augmented only with a complementary batch of same-class data for each training data point, to be attractive in comparison to these other approaches.	Reply	I-Reply	1
[line_break_token][line_break_token]However, there are other significant differences.	Reply	I-Reply	1
One major difference is that our invariant representation takes as input multiple data points that come from the same class, but are different from the reconstructed data point.	Reply	I-Reply	1
Thus, our invariant representation directly learns to encode the information common to the overall class, but not the individual data point.	Reply	I-Reply	1
This is why there is no need for clamping or cross-covariance / mutual information penalty terms in our objective function: there is no way for the invariant representation to store data-point specific information due to the information flow through it.	Reply	I-Reply	1
In further contrast to some of the other approaches in the literature, we deliberately use a deterministic latent for the class-invariant information, and a stochastic latent for the smooth 'style' information (an idea employed by Zhu et al. (	Reply	I-Reply	1
2014), for their binary neurons).	Reply	I-Reply	1
This modelling choice is why we do not need to force the equivariant latent to not contain any class-level information (which is clear from our results) because it is available and easier to access from the deterministic latent.	Reply	I-Reply	1
This last point was a question raised by the reviewer which we have addressed with an added discussion after Equation 3 in Section 2.	Reply	I-Reply	1
[line_break_token][line_break_token]..	Reply	O	0

#Summary[line_break_token][line_break_token]This paper proposes a generalised self-training framework to build a Graph Neural Network to label graphs.	Review	O	0
 Of importance is the dynamic nature of the self-training.	Review	O	0
The authors do not change the GCN but extend the self-training portion as per the prior GCN paper by introducing Dynamic Self-Training that keeps a confidence score of labels predicted for unlabelled nodes.	Review	O	0
[line_break_token][line_break_token]# Comments[line_break_token][line_break_token]This is a very interesting paper in terms of looking at the effects of changing the self-training framework to better utilise the underlying structure.	Review	O	0
As such we can exploit information from other nodes that are yet to be labelled.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
As the self-training is going on, are there different computational costs or are they about the same?	Review	B-Review	1
[line_break_token]2.	Review	O	0
For CiteSeer 20 and 50, why does \beta = 0.45 switch from the other experiments?	Review	B-Review	2
[line_break_token]3.	Review	O	0
Will such self-training be useful for general NN self-training procedures[line_break_token]4.	Review	O	0
If we had soft-labelling or uncertainty on which label each node has, how would the dynamic self-training be changed?	Review	B-Review	4
[line_break_token][line_break_token]#Other notes[line_break_token]Please remove the [line_break_token][line_break_token]An appendix[line_break_token]You may include other additional sections here	Review	O	0
e thank the reviewer for the constructive comments.	Reply	O	0
[line_break_token][line_break_token]1. "	Reply	O	0
As the self-training is going on, are there different computational costs or are they about the same?"	Reply	O	0
[line_break_token]The computational costs is only slightly increased.	Reply	B-Reply	1
The reason is that the computational cost of the original GCN model is dominated by previous layers, where the entire graph is included.	Reply	I-Reply	1
So even if all nodes become pseudo labels, the size of the entire network is increased by at most a factor of 2, and the number of parameters remains the same.	Reply	I-Reply	1
Therefore, the computational costs will increase by at most a small constant in theory.	Reply	I-Reply	1
We have also verified this empirically.	Reply	I-Reply	1
We record the training time of GCN and GAT before and after applying our framework.	Reply	I-Reply	1
In the experiments, the training size is 20 per class, the number of epochs is 200, and the time is the average time (in seconds) of 25 runs.	Reply	I-Reply	1
[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]Cora       [line_break_token]           GCN        2.6[line_break_token]         DSGCN     6.3[line_break_token]           [line_break_token]           GAT        4.7[line_break_token]         DSGAT     8.7[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]    Citeseer[line_break_token]          GCN         3.0[line_break_token]         DSGCN     9.7[line_break_token][line_break_token]         GAT           5.2[line_break_token]        DSGAT      11.9[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token]2. "	Reply	O	0
For CiteSeer 20 and 50, why does \beta = 0.45 switch from the other experiments?"	Reply	O	0
[line_break_token]We didn‚Äôt use \beta = 0.45 for CiteSeer 20 and 50.	Reply	B-Reply	2
As explicitly explained in the paper, we use a threshold of 0.6 when the number of labels per class is below 3 and set the threshold to 0.75 for label rate above 3 but below 10.	Reply	I-Reply	2
Otherwise, the threshold is 0.9 by default.	Reply	I-Reply	2
In Figure 1, \beta=0.45 here is used for comparison with other thresholds on various label rate.	Reply	I-Reply	2
We are sorry for any ambiguity in the paper.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]3. "	Reply	O	0
Will such self-training be useful for general NN self-training procedures"[line_break_token]We believe our self-training method will be useful for general NN training, although we think it is most effective for GNN models.	Reply	O	0
We have tested our self-training methods on other GNNs, e.g., GraphSage, GAT, SGC, and some preliminary results are as follows.	Reply	B-Reply	3
[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                                                  Cora[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                              5            10              20             50         [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]GraphSage       69.3         75.3          79.2          82.5[line_break_token]DSGraphSage  72.5         78.4          81.0          84.0[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]GAT                    71.1         76.0          79.6          83.4[line_break_token]DSGAT               71.9         77.1          81.0          83.6[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]SGC                    63.5         72.5         75.9          78.9[line_break_token]DSSGC               65.0         73.4         76.2          78.9    [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                                             Citeseer[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]                               5             10           20             50         [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]GraphSage        59.7        65.4         68.8          72.1[line_break_token]DSGraphSage   60.6        66.3         69.5          72.6[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]GAT                     54.9        60.8         68.2          71.5[line_break_token]DSGAT                58.3        67.0         70.8          73.5[line_break_token]---------------------------------------------------------------------------------------------------[line_break_token]SGC                     55.5        63.7         69.0           72.6[line_break_token]DSSGC                59.6        65.0         69.7           73.4        [line_break_token]---------------------------------------------------------------------------------------------------[line_break_token][line_break_token][line_break_token]4. "	Reply	O	0
If we had soft-labelling or uncertainty on which label each node has, how would the dynamic self-training be changed?"	Reply	O	0
[line_break_token]In general, we can treat all original labels as ‚Äúpseudo labels‚Äù as well.	Reply	B-Reply	4
We just need a mechanism to determine the initial confidence of these labels and then all labels in the training set can be treated equally.	Reply	I-Reply	4

In this paper, the authors proposed methodologies to identify mislabeled training examples.	Review	O	0
Specifically, the authors proposed to examine the training loss of each example to identify examples with high training losses.	Review	O	0
To mitigate the randomness in the training loss, the authors proposed an AUL (area under the loss) metric, which is less noisy that directly examining the loss.	Review	O	0
The authors proposed to use Gaussian mixture to approximate the AUL distribution, and then estimate the probability of mislabeling.	Review	O	0
The authors proposed to downweight training examples with high likelihood of being mislabeled.	Review	O	0
The proposal is examined in numerical studies.	Review	O	0
[line_break_token][line_break_token]While I agree the method has a good potential to be significant, in its current form, I have several concerns that prevent me from recommending acceptance.	Review	O	0
[line_break_token]1.	Review	O	0
How can we be sure that examples with large training loss are mislabeled examples, rather than examples that are inherently difficult to classify?	Review	B-Review	1
For example, if the dataset consists of 99% bright images and 1% dark images, then it could be possible that dark image training examples have a higher loss.	Review	I-Review	1
This question becomes more relevant when the model does not have sufficient complexity, or does not have the correct form of complexity.	Review	I-Review	1
[line_break_token]2.	Review	O	0
If we cannot distinguish mislabeled examples with examples that are hard to classify, then it seems to me that a simple downweighting based on AUL could potential lead to the opposite outcome.	Review	B-Review	2
Intuitively, we should upweight those difficult to classify examples to improve generalizability.	Review	I-Review	2
[line_break_token]3.	Review	O	0
It is somewhat surprising to me that the AUL distribution is a nicely looking bimodal shape.	Review	B-Review	3
Could it be due to the fact that the wrong labels are randomly generated with equal probabilities from other classes?	Review	I-Review	3
What it we have a different error distribution, e.g., the label has p probability of being correct, and (1-p) probability of being k, where k is a constant?	Review	I-Review	3
[line_break_token]4.	Review	O	0
Given the above concerns, I feel the numerical studies are insufficient.	Review	B-Review	4
The authors may consider 1) including more noise distributions, 2) presenting the AUL distributions to check whether they are truly bimodal, and 3) trying more datasets and more model architectures.	Review	I-Review	4
hank you for your review.	Reply	O	0
We hope that we are able to clarify some misunderstanding and address your comments.	Reply	O	0
[line_break_token][line_break_token]W.R.T. ‚Äúhard‚Äù clean examples: From our observations, it appears that ‚Äúhard‚Äù examples have higher AUL than most clean examples, but lower AUL than mislabeled examples. (	Reply	O	0
Intuitively, this makes sense, because truly mislabeled examples will be the hardest for the network to generalize to.)	Reply	B-Reply	1
Therefore, hard samples will be downweighted some, but not as much as noisy examples.	Reply	I-Reply	1
We would note that curriculum learning (e.g. Bengio et al, ICML 2019; Hacohen and Weinshall, ICML 2019) similarly down-weights (rather than up-weights) difficult examples until the end of training.	Reply	I-Reply	1
To some extent AUL-based downweighting will have a similar effect: the network will not reduce the loss of difficult examples until the high-weight easy examples have sufficiently low loss.	Reply	I-Reply	1
[line_break_token][line_break_token]W.R.T. other noise models: Please refer to our ‚Äúpair flip‚Äù experiments in Figure 7 and Table 1.	Reply	O	0
These experiments are exactly the noise model you propose (p probability of being correct, and (1-p) probability of being k).	Reply	B-Reply	2
We note that our proposed method is adept at estimating and correcting for label error in this setting as well.	Reply	I-Reply	2
[line_break_token][line_break_token]W.R.T. presenting AUL distributions: we observed the bimodal behavior for both CIFAR10 and CIFAR100 on all experiments that we performed - regardless of noise model, noise percentage, or network architecture.	Reply	O	0
We will update the paper with additional plots that demonstrate this bimodality.	Reply	B-Reply	3
[line_break_token][line_break_token]W.R.T. real-world datasets: To demonstrate our method‚Äôs applicability on real-world (non-image) datasets, we trained a model on a Machine Translation dataset (IWSLT14 German-to-English dataset).	Reply	O	0
AUL determines that roughly 25 training samples have an incorrect target (the English sentence in the translation pair).	Reply	B-Reply	4
Typically, these targets are not English and therefore are mislabeled.	Reply	I-Reply	4
For example:[line_break_token][line_break_token]SOURCE: vielen dank .	Reply	I-Reply	4
[line_break_token]TARGET: merci beaucoup .	Reply	I-Reply	4
[line_break_token][line_break_token]SOURCE: google glass : aroi mann 9 : mmm , aroi .	Reply	I-Reply	4
[line_break_token]TARGET: google glass : ‡∏≠‡∏£ ‡πà ‡∏≠‡∏¢man 9 : mmm , ‡∏≠‡∏£ ‡πà ‡∏≠‡∏¢	Reply	I-Reply	4

&lt;Paper summary&gt;[line_break_token]The authors proposed Distribution Matching Prototypical Network (DMPN) for unsupervised domain adaptation.	Review	O	0
DMPN extracts features from the input data and models them as Gaussian mixture distributions.	Review	O	0
By explicitly modeling the distributions that the features follow, the discrepancy between the distribution of source data and that of target data can be easily evaluated.	Review	O	0
DMPN is trained by jointly minimizing two kinds of loss, which are classification loss on the source data and domain discrepancy loss that is calculated via the explicit models.	Review	O	0
Experimental results on two popular benchmark datasets validate the advantage of DMPN over other state-of-the-art methods.	Review	O	0
[line_break_token][line_break_token]&lt;Review summary&gt;[line_break_token]The proposed method seems simple but empirically performs well.	Review	O	0
The paper is well written and easy to follow, so we can maybe easily implement it.	Review	O	0
However, I have several concerns mainly about the details and theories of the proposed method, which makes my score a bit lower than the border line.	Review	O	0
Given clarifications in an author response, I would be willing to increase the score.	Review	O	0
[line_break_token][line_break_token]&lt;Details&gt;[line_break_token]* Strength[line_break_token] + The motivation of using ProtoNet for domain adaptation seems reasonable.	Review	O	0
[line_break_token] + The proposed method performs well in the experiments.	Review	O	0
[line_break_token] + The paper, especially the experiment section, is well written and easy to follow.	Review	O	0
[line_break_token][line_break_token][line_break_token]* Weakness and concerns[line_break_token] - Several points on the proposed loss (GCMM and PDM) are not sufficiently discussed.	Review	O	0
[line_break_token]  -- Why do we need two kinds of loss?	Review	O	0
These losses seem to play almost same role.	Review	B-Review	2
Since PDM loss corresponds to target-side log likelihood regularization term (Eq. (	Review	I-Review	2
3)), I wonder if we really need GCMM loss.	Review	I-Review	2
[line_break_token]  -- Since the authors explicitly model the feature distributions by Gaussian mixtures (GMs), it might be possible to calculate a standard divergence between source and target data distributions by using the parameters of GMs.	Review	O	0
Compared with such a straightforward approach, the proposed method seems to be ad-hoc and is not theoretically validated.	Review	B-Review	3
What term of divergence (or distance) does it minimize?	Review	I-Review	3
[line_break_token]  -- When a certain class does not appear in pseudo-labeled target data, how can we calculate GCMM loss? (	Review	O	0
specifically, \mu^{et}_c)[line_break_token]  -- Are Eq. (	Review	O	0
3) and Eq. (	Review	B-Review	5
6) correct?	Review	I-Review	5
These are defined as total loss, not average, over each domain.	Review	I-Review	5
It means that the scale of the coefficients for these terms changes according to the number of training data, but the sensitivity analysis in Fig.	Review	I-Review	5
2 does not show such effect.	Review	I-Review	5
[line_break_token]  -- Since the proposed losses heavily depend on the pseudo labels on the target data, it should be important to carefully set a proper threshold for the confidence.	Review	O	0
Is the proposed method sensitive against the change of this threshold?	Review	B-Review	6
If so, how can we tune it?	Review	I-Review	6
[line_break_token]  -- How can we know p(c) in advance?	Review	O	0
[line_break_token][line_break_token] - The theory shown in 3.5 is not sufficiently validated.	Review	O	0
[line_break_token]  -- The authors state ````we minimize the first term through minimizing the domain discrepancy losses," but it is not sufficiently supported, because the relationship between the proposed losses and H-delta-H divergence is not clear.	Review	O	0
[line_break_token][line_break_token] - I am concerned about whether the proposed method works well with harder datasets such as Office-Home dataset, because each class data are modeled by a simple Gaussian distribution in the proposed method.	Review	O	0
[line_break_token][line_break_token][line_break_token]* Minor concerns that do not have an impact on the score[line_break_token] - Using both f^s_i and F(x^s_i; \theta) is confusing.	Review	O	0
[line_break_token] - Typo in Eq. (	Review	B-Review	11
7): PMD -&gt; PDM[line_break_token]	Review	O	0
hanks for reviewing our paper and your appreciation of our idea.	Reply	O	0
Here we answer your concerns and clarify some of the weak points you mentioned:[line_break_token][line_break_token]1).	Reply	O	0
These two losses actually serve with different purposes when we design them.	Reply	B-Reply	2
The GCMM loss brings the two distribution closer via minimizing the corresponding Gaussian Component means of the source and target data.	Reply	I-Reply	2
And the PDM loss shapes the target feature distribution similar as the source feature distribution via minimizing the likelihood of generating the target feature from the source feature distribution.	Reply	I-Reply	2
In this sense, they complement each other, to match the target feature distribution to be exactly like the source feature distribution.	Reply	I-Reply	2
Furthermore, these two losses also reduce distribution discrepancy at different levels, GCMM reduces distribution discrepancy at the class-level and PDM reduces distribution discrepancy at the sample-level, thus in this sense, they also complete each other for domain adaptation.	Reply	I-Reply	2
[line_break_token][line_break_token]2).	Reply	O	0
We want to clarify here.	Reply	B-Reply	3
Our method does not learn the distribution parameters for the target data.	Reply	I-Reply	3
We learn the distribution parameters of the source data.	Reply	I-Reply	3
We use the empirically calculated distribution parameter estimator of the source and target data to minimize the distribution discrepancy loss function.	Reply	I-Reply	3
Thus, we cannot "calculate a standard divergence between source and target data distributions by using the parameters of GMs."	Reply	I-Reply	3
For the GCMM loss, our method minimizes the euclidean distance between the corresponding Gaussian Component means of the source and target data for each class.	Reply	I-Reply	3
PDM loss minimizes the likelihood of generating the target feature with the source feature distribution.	Reply	I-Reply	3
[line_break_token][line_break_token]3).	Reply	O	0
We will ignore data from that class in the batch in that training iteration.	Reply	B-Reply	4
As training data are sampled randomly in each iteration, and in the end, all data updates the model.	Reply	I-Reply	4
[line_break_token][line_break_token]4).	Reply	O	0
Yes, you are correct.	Reply	B-Reply	5
We forgot to average the term when writing the paper.	Reply	I-Reply	5
We have corrected it in the revised paper.	Reply	I-Reply	5
Thanks for pointing this out.	Reply	I-Reply	5
[line_break_token][line_break_token]5).	Reply	O	0
We have added a sensitivity experiment on the confidence threshold.	Reply	B-Reply	6
The results are in the appendix of the revised paper.	Reply	I-Reply	6
Here is the summary:[line_break_token][line_break_token]confidence-threshold: 0.6, 0.7, 0.8, 0.9[line_break_token]Mean-accuracy: 81.3, 81.4, 81.4, 81.5[line_break_token][line_break_token]The results show that our method is also robust against confidence threshold.	Reply	I-Reply	6
[line_break_token]For our proposed probability based weighting mechanism, as there is no hyper-parameter in there, so there is no need to provide sensitivity analysis on it.	Reply	I-Reply	6
[line_break_token][line_break_token]6).	Reply	O	0
We know p(c) in the source domain, as it has labels.	Reply	B-Reply	7
We do not know p(c) in the target domain, but we can estimate it.	Reply	I-Reply	7
In this paper, we assume p(c) is uniform, as we focus on co-variate shift in this paper.	Reply	I-Reply	7
Our work can be easily augmented to work for label shift too, once we estimate the target label distribution.	Reply	I-Reply	7
However, we leave this as future work.	Reply	I-Reply	7
[line_break_token][line_break_token]7).	Reply	O	0
The H-delta-H divergence is small when the two distribution discrepancy is small.	Reply	B-Reply	9
As GCMM loss brings the two distribution closer, and PDM loss shapes the two distribution to be alike, the source and target feature distribution discrepancy will be smaller.	Reply	I-Reply	9
Thus H-delta-H becomes smaller as we minimize GCMM loss and PDM loss.	Reply	I-Reply	9
We have updated the paper on this part to make it clearer.	Reply	I-Reply	9
Thanks for indicating this.	Reply	I-Reply	9
[line_break_token][line_break_token]8).	Reply	O	0
We have added an experiment on the Office-Home dataset in the appendix of our paper.	Reply	B-Reply	10
Our paper performs the best in all the transfer tasks in Office-Home compared to state-of-the-art UDA methods, showing that it also works for this more challenging dataset.	Reply	I-Reply	10
[line_break_token][line_break_token]9).	Reply	O	0
Thanks for pointing out some of our typos, we have made the changes in our revised paper	Reply	B-Reply	11

This paper proposes an algorithm for supervising networks for image classification and reconstruction with the object's hierarchical categories in mind.	Review	O	0
The claimed benefits are the improved generalizability and interpretability.	Review	O	0
The paper reports per-category-level analysis on the semantic image reconstruction task and retrieval on seen and unseen object categories.	Review	O	0
[line_break_token][line_break_token]I am currently leaning towards weak accept because I find the paper's claim and technical details generally convincing and simultaneously extracting low-level and high-level features trained using the hierarchical levels of categories is novel.	Review	O	0
Generalization to unseen categories tends to be a good proxy for real world performance and directly learning the high level categories is a useful idea for doing so.	Review	O	0
[line_break_token][line_break_token]Although I am leaning towards weak accept, I think this paper is close to borderline because the findings do not seem experimentally well validated.	Review	B-Review	1
It would be more interesting to see Table 3 on multiple unseen categories instead of one special case per dataset.	Review	I-Review	1
Another idea for experiments is doing cross-dataset evaluations where different datasets may have different leaf categories but shared high level ones.	Review	I-Review	2
I think it may also be interesting to compare with a non-hierarchical retrieval model and then obtain their high-level prediction accuracy using the corresponding parent level categories.	Review	I-Review	3
[line_break_token][line_break_token]The paper generally needs polishing.	Review	I-Review	4
Minor typos I found:[line_break_token][line_break_token]Page 5: classificaiton, classifers[line_break_token]Page 6: intuitional-&gt;intuitive[line_break_token]Page 7: an significant[line_break_token]Page 8: leraning[line_break_token]Page 1: human[line_break_token]Figure 3: arbitary	Review	O	0
e thank you for your valuable comments and suggestions.	Reply	O	0
We have followed your suggestions and conducted experiments which would make our work more interesting.	Reply	O	0
[line_break_token]1).	Reply	O	0
Table.3 evaluated on multiple unseen categories.	Reply	B-Reply	1
[line_break_token]During rebuttal, we tried our best to collect and preprocess more unseen categories in each dataset.	Reply	I-Reply	1
Specifically, we observed all 40 attributes on CelebA and finally used the bald and gray hair which are unseen leaf-level hair colors.	Reply	I-Reply	1
We further investigated the 205 categories of ShapeNet and preprocessed 3D models for kinds of new tables and sofas which are regarded as the unseen leaf-level categories for ShapeNet-C. Finally, objects with other poses for ShapeNet-P are also considered in this experiment.	Reply	I-Reply	1
Typical examples of these unseen categories are shown in Fig.11 in the Appendix.	Reply	I-Reply	1
[line_break_token]The new test results are updated in Tab.3 in the revision.	Reply	I-Reply	1
We find that the performance of super-categories decreased to some extent due to more categories added.	Reply	I-Reply	1
Overall, our method still has considerable generalization ability for unseen but similar objects.	Reply	I-Reply	1
[line_break_token][line_break_token]2).	Reply	O	0
Cross dataset evaluations.	Reply	B-Reply	2
[line_break_token]Thanks for this interesting and valuable comments.	Reply	I-Reply	2
We preprocessed a facial expressions dataset called RAF (Li et al.,	Reply	I-Reply	2
CVPR 2017) and a fine-grained cars dataset called CompCars (Yang et al.,	Reply	I-Reply	2
CVPR2015).	Reply	I-Reply	2
These two datasets are quite challenging compared we have used for training our model and have different leaf-level annotations.	Reply	I-Reply	2
Similar to the evaluation of our method for unseen categories but within the same dataset, we also test the performance of hierarchical prediction and semantic translation.	Reply	I-Reply	2
Detailed results can be found in Sec.	Reply	I-Reply	2
A.4.	Reply	I-Reply	2
[line_break_token]It is found that the performance would become relatively poor due to the large domain shift.	Reply	I-Reply	2
Even so, we can still extract and transfer some meaningful information in high-level, e.g. the gender, smiling on Faces, the poses on Cars, which demonstrates the robustness and advantages of hierarchical feature learning compared to the flat ways.	Reply	I-Reply	2
[line_break_token][line_break_token]3).	Reply	O	0
Compare with non-hierarchical retrieval models and obtain their high-level performance using the corresponding parent level categories.	Reply	B-Reply	3
[line_break_token]In fact, the compared hashing methods in Tab.2 are all non-hierarchical retrieval models and we trained them in each level.	Reply	I-Reply	3
Training them using the annotations in each level can make them perform best in that level, but a little inefficient.	Reply	I-Reply	3
Following your advice, we only trained them in the leaf-level and used the learned features to test on high-level using corresponding parent level categories.	Reply	I-Reply	3
Results are added to Tab.2 (methods with ‚Äú-S‚Äù postfix).	Reply	I-Reply	3
Besides, we also added pre-trained GANs as baselines for comparison in this experiment.	Reply	I-Reply	3
We find that using only one model trained in leaf-level is efficient but the mAP drops.	Reply	I-Reply	3
This also proves both efficient and effective of our HDN for disentangled features.	Reply	I-Reply	3
[line_break_token][line_break_token]4).	Reply	O	0
Typos.	Reply	B-Reply	4
[line_break_token]We are sorry for these inaccurate expressions which have influenced your reading experience and thank you for your careful reading and good suggestions.	Reply	I-Reply	4
We have carefully modified corresponding writings one by one in our revision.	Reply	I-Reply	4
[line_break_token][line_break_token]Ref.	Reply	O	0
[line_break_token]Shan Li, Weihong Deng, and JunPing Du.	Reply	O	0
Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild.	Reply	O	0
In CVPR 2017[line_break_token]Linjie Yang, Ping Luo, Chen Change Loy, and Xiaoou Tang.	Reply	O	0
A large-scale car dataset for fine-grained categorization and verification.	Reply	O	0
In CVPR 2015	Reply	O	0

This paper notes that ensemble distillation (EnD) loses the distributional information from the original ensemble, which prevents users of the distilled model from being able to obtain estimates of its knowledge uncertainty.	Review	O	0
It proposes the challenge of distilling the ensemble in a way that preserves information about the ensemble distribution, so that knowledge uncertainty can still be extracted from the distilled model.	Review	O	0
It names this task "Ensemble Distribution Distillation (EnD^2)".	Review	O	0
It then proposes using Prior Networks (introduced in Malinin &amp; Gales 2018) as a solution, and proceeds to evaluate it with a series of experiments -- first obtaining some intuition from spiral dataset, then more rigorously on benchmark image datasets (CIFAR10/100/TinyImageNet).	Review	O	0
[line_break_token][line_break_token]First, it trains ensembles of 10 and 100 NNs on a spiral dataset, distills them using the regular approach (EnD) and Prior Networks (EnD^2), compares their performance, and notes that the Prior Networks approach has comparable performance.	Review	O	0
Next, it visualizes over the input space of the spiral dataset the total uncertainty, data uncertainty, and knowledge uncertainty estimates, which are extracted directly from the original ensemble and from the EnD^2 distilled model (Figure 3).	Review	O	0
It notes that while the original ensemble is able to correctly estimate the knowledge uncertainty in regions that are far away from the training distribution, the EnD^2 model fails at this task (Figure 3f).	Review	O	0
It then proposes to augment the training set with out-of-distribution data, and demonstrates that this improves the estimation of knowledge uncertainty (Figure 3i).	Review	O	0
It also proposes a new metric for evaluating the Prediction Rejection Ratio (PRR), uses it to compare how the EnD^2 model compares to the original ensemble and the EnD model.	Review	O	0
Finally, it demonstrates using a series of benchmark image classification tasks that the EnD^2 model is able to identify out-of-distribution samples with comparable performance to the original ensemble.	Review	O	0
[line_break_token][line_break_token]Decision: Leaning-to-Accept.	Review	O	0
Distillation is a well-established technique, and adapting it so that the same NN can perform both predictions and knowledge uncertainty estimates is impactful.	Review	O	0
This work proposes using Prior Networks as a way to distill ensembles of NNs in a way that preserves the knowledge uncertainty estimates, and evaluated this claim with a sequence of experiments.	Review	O	0
This work also proposes a new evaluation metric (Prediction Rejection Ratio), and can be used to evaluate future models that are able to simultaneously perform prediction and knowledge uncertainty estimation.	Review	O	0
However, the way that the paper is organized around the proposal of "Ensemble Distribution Distillation" as a novel machine learning task does not seem very well motivated, as the distribution was solely used to provide uncertainty estimates.	Review	B-Review	1
[line_break_token][line_break_token]Strengths:[line_break_token]- The visualizations in Figure 3 helped to provide intuition to the reader.	Review	O	0
[line_break_token]- Experiments have a clear logical flow.	Review	O	0
Spiral experiments provide intuition, motivate out-of-distribution data augmentation, then image data experiments provide evidence for the applicability of the method.	Review	O	0
[line_break_token]- Motivates and explains the newly proposed evaluation metric (prediction rejection ratio) in the appendix.	Review	O	0
[line_break_token]- The out-of-distribution detection experiments are quite comprehensive.	Review	O	0
[line_break_token]- The training procedures are clearly detailed in the appendix.	Review	O	0
[line_break_token]- Investigates the appropriateness of the Dirichlet distribution in the appendix.	Review	O	0
[line_break_token][line_break_token]Weaknesses:[line_break_token]- The proposal of the novel machine learning task of "Ensemble Distribution Distillation" does not seem very well motivated.	Review	O	0
In this paper, the distribution distillation was solely used to obtain a knowledge uncertainty estimation.	Review	B-Review	1
Besides that, what else would the distribution be used for?	Review	I-Review	1
It was also initially unclear to me what this paper contributes on top of "Predictive Uncertainty Estimation via Prior Networks (Malinin &amp; Gales, 2018)".	Review	O	0
A suggestion is to rewrite the summary of contributions to emphasize that the use of Prior Networks to produce a single model that can both perform predictions and provide uncertainty estimates as an extension of ensemble distillation is novel, and that a more comprehensive set of experiments on more difficult image datasets were done in this paper.	Review	B-Review	1
[line_break_token][line_break_token]Minor comments:[line_break_token]- page 2, expression right before equation 2, and in the first sentence on page 3 is missing closing parentheses.	Review	I-Review	2
[line_break_token]- page 3, figure 1.	Review	I-Review	2
It wasn't initially obvious to me that the triangle represents the simplex of the softmax output, and each black dot represents the output of one model of the ensemble.	Review	I-Review	2
[line_break_token]- page 4, equation 9.	Review	I-Review	2
Add some space to the right of the equality sign.	Review	I-Review	2
[line_break_token]- Use backticks`   instead of single quotation mark ' to open quotation marks in LaTeX.[line_break_token][line_break_token][line_break_token]Rebuttal response:[line_break_token]I acknowledge the authors' point about the importance of EnDD in addition to knowledge uncertainty estimation, and maintain my rating.	Review	O	0
ear Reviewer III,[line_break_token][line_break_token]The benefit of Ensemble Distribution Distillation is the ability to explicitly emulate a source ensemble and decompose measures of uncertainty.	Reply	O	0
This is common practice for tasks such as Bayesian Active Learning (Kirsch 2019), where knowledge uncertainty is commonly used.	Reply	B-Reply	1
Thus, we believe that the ability to model an ensemble and decompose uncertainties via EnDD is by itself significant.	Reply	I-Reply	1
However, we speculate that Ensemble Distribution Distillation may have additional benefits by consuming extra degrees of freedom from the model and adding a regularizing effect.	Reply	I-Reply	1
This may make the model more robust to, for example, adversarial attacks.	Reply	I-Reply	1
This is supported by the findings in (Malinin &amp; Gales, 2019), where it is shown that it is more difficult to construct adversarial attacks against Prior Network models due to their rich measures of uncertainty.	Reply	O	0
However, investigating this is left to future work.	Reply	B-Reply	1
[line_break_token][line_break_token](Kirsch, 2019) "BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning" (NeurIPS 2019)[line_break_token](Malinin and Gales, 2019) "Reverse KL-divergence training of Prior Networks: Improved Uncertainty and Adversarial Robustness" (NeurIPS 2019)	Reply	O	0

The method works by substituting a hidden layer with a denoised version.	Review	B-Review	1
[line_break_token]Not only it enable to provide more robust classification results, but also to sense and suggest to the analyst or system when the original example is either adversarial or from a significantly different distribution.	Review	I-Review	1
[line_break_token]Improvements in adversarial robustness on three datasets are significant.	Review	I-Review	1
[line_break_token][line_break_token]Bibliography is good, the text is clear, with interesting and complete experimentations.	Review	I-Review	1
‚ÄúThe method works by substituting a hidden layer with a denoised version.	Reply	O	0
[line_break_token]Not only it enable to provide more robust classification results, but also to sense and suggest to the analyst or system when the original example is either adversarial or from a significantly different distribution.	Reply	O	0
[line_break_token]Improvements in adversarial robustness on three datasets are significant.	Reply	O	0
[line_break_token]Bibliography is good, the text is clear, with interesting and complete experimentations.	Reply	O	0
‚Äù[line_break_token][line_break_token]Thank you for your feedback.	Reply	O	0
We have obtained several new results to address concerns related to gradient obfuscation raised by other reviewers and the public comment.	Reply	B-Reply	1

This paper proposes two techniques for fast linear interpolation on CPUs.	Review	O	0
They achieved speedups by reducing 1) fixed overhead cost and 2) per example computation (linear interpolation operation level optimization).	Review	O	0
[line_break_token]Authors consider this problem for small operation models like linear interpolation rather than the models requiring large operations such as ResNet.	Review	O	0
In this case, dispatch overhead cannot be ignored and so they use the MLIR frameworks to optimize trained model into the C++ code (reducing fixed overhead cost).	Review	O	0
This results in 2-3x speed up.	Review	O	0
Secondly, they propose the way to construct auxiliary index-mapping function by considering spacing of the key points rather just using for example evenly spaced index-mapping.	Review	O	0
[line_break_token]They compare proposed method to C++ interpreter implementation on two-layer and deep lattice networks and achieve 5-10x speed improvements.	Review	O	0
[line_break_token][line_break_token]It seems the topic of this paper does not fit ICLR and most machine learning researchers are unlikely to be interested in and even understand this paper.	Review	O	0
This reviewer also does not have enough knowledge and background to judge this paper.	Review	O	0
But my impression is that achieving&nbsp;speed up using existing MLIR framework has no surprising novelty.&nbsp;[line_break_token]Moreover, the experimental results seems quite limited in the sense that they only experiment with trained 2 and 4-layer calibrated lattice models which are kind of small.&nbsp;&nbsp;[line_break_token][line_break_token]It would be better to highlight why the proposed method is meaningful and provide more background knowledge to understand this paper.&nbsp;[line_break_token][line_break_token]This is only consider optimization on CPUs.	Review	O	0
What about the case of using GPUs?	Review	B-Review	4
[line_break_token][line_break_token]Is branch free assumption for functions ‚ÄòAdjust‚Äô &amp; ‚ÄòT‚Äô is valid? (	Review	O	0
I don‚Äôt have much knowledge on compiler..)	Review	B-Review	5
e hope these responses give you more perspective on the novelty and significance.	Reply	O	0
[line_break_token][line_break_token]Re: ‚ÄúBut my impression is that achieving speed up using existing MLIR framework has no surprising novelty. ‚	Reply	O	0
Äú[line_break_token]The key novelty here is that we show that ML models with many small ops (here, linear interpolation ops) are not bottlenecked by their computation, but by the interpreter itself, and we additionally present low-level optimizations and data-handling that enable incredibly fast runtimes on widely available CPUs.	Reply	O	0
 This is in contrast to ML models with large matrix operations (like ResNet or DNN‚Äôs) where the interpreter is a small fraction of total runtime, and have well-studied primitives.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token]Re: ‚ÄúThis is only consider optimization on CPUs.	Reply	O	0
What about the case of using GPUs?‚Äù[line_break_token]Evaluation runtimes in our experiments are at or below the typical GPU latency of around 10 microseconds, so our CPU implementation would already have finished by the time you moved the data to a GPU.	Reply	O	0
 [line_break_token][line_break_token]Re: ‚ÄúIs branch free assumption for functions ‚ÄòAdjust‚Äô &amp; ‚ÄòT‚Äô is valid? (	Reply	O	0
I don‚Äôt have much knowledge on compiler..)‚Äù[line_break_token]Yes, please see Section 2.1 for details.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Re: ‚Äútrained 2 and 4-layer calibrated lattice models which are kind of small.	Reply	O	0
‚Äù [line_break_token]Yes, the models in the experiments ranged from very small to medium-sized, the largest was the selector model that had 75,000 parameters.	Reply	O	0
 This paper is focused on models with runtimes in the microseconds or nanoseconds.	Reply	B-Reply	2
 In production systems such models can run early in a latency-critical pipeline, or many such models may need to be run serially, making speed-ups important.	Reply	I-Reply	2
 	Reply	I-Reply	1

- Are there some labels more important than others, or shouldn‚Äôt we employ taxonomic distances ?	Review	O	0
[line_break_token]- How make model to decide on number of output labels ?	Review	O	0
[line_break_token]- It would be nice to have experiments comparing it to the network pretrained on imagenet.	Review	O	0
'Are there some labels more important than others, or shouldn‚Äôt we employ taxonomic distances' [line_break_token][line_break_token]The standard evaluation protocol described in [25] is used in our work, and we have evaluated different methods by 5 different protocols (which is more comprehensive than [25]).	Reply	O	0
The overall precision and overall recall emphasis on frequent tags, and per-class recall and per-class precision emphasis on infrequent tags.	Reply	B-Reply	1
So we believe the evaluation is thorough.	Reply	I-Reply	1
The point raised by the reviewer is definitely interesting, however we believe it is orthogonal to this paper.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]'How make model to decide on number of output labels ?'	Reply	O	0
[line_break_token][line_break_token]We follow the standard practice in most previous works [25,14,26] to fix the number of output labels for each image to 3 or 5.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token] 'It would be nice to have experiments comparing it to the network pretrained on imagenet.'	Reply	O	0
[line_break_token][line_break_token]We have tested it before and found using pretrained weights can further improve the performance for around 2% for all methods.	Reply	B-Reply	3
However, our goal is to perform a clear comparison between different loss functions for multilabel annotation, and want to use the simplest experimental setting, so we did not includ the pretrained results	Reply	I-Reply	3

This paper proposes a method for unsupervised clustering.	Review	O	0
Similarly to others unsupervised learning (UL) papers like "Deep Clustering for Unsupervised Learning of Visual Features" by Caron et al.,	Review	O	0
they propose an algorithm alternating between a labelling phase and a training phase.	Review	O	0
Though, it has interesting differences.	Review	O	0
For example, unlike the Caron et al.	Review	O	0
paper, not all the samples get assigned a labels but only the most confident ones.	Review	O	0
These samples are determined by the pruning of a graph whose edges are determined by the votes of an ensemble of clustering models.	Review	O	0
Then, these pseudo labels are used within a supervised loss which act as a regularizer for the retraining of the clustering models.	Review	O	0
[line_break_token][line_break_token]Novelties /contributions/good points:[line_break_token]* Votes from the clustering models to create a graph[line_break_token]* Using a graph to identify the most important samples for pseudo labelling[line_break_token]* Modification of the ladder network to be used as clustering algorithm[line_break_token]* Good amount of experiments and good results[line_break_token][line_break_token]Weaknesses:[line_break_token]* The whole experiment leading to Table 1 in page 2 is unclear for me.	Review	O	0
I have trouble understanding the experiment settings.	Review	B-Review	1
Could you please rephrase it.	Review	I-Review	1
About initial/ final clustering for example and the rest as well.	Review	I-Review	1
The whole thing puzzles me whereas the experiments section at the end is much more clear.	Review	I-Review	1
[line_break_token]* Lack of motivation about why using the Ladder method rather than another one.	Review	O	0
Other recent methods have better results in semi-supervised learning.	Review	B-Review	2
[line_break_token]* Algorithm 1 seems quite ad-hoc.	Review	O	0
Do more principled algos exist to solve this problem ?	Review	B-Review	3
You could write about it and at least explain why it would not be feasible here.	Review	I-Review	3
The sentence "The intuition is that most of the neighbours of that node will also be connected with each other" is unmotivated: no empirical proof for this ?	Review	I-Review	3
[line_break_token]* Related work section is too light.	Review	O	0
It is an important section and should really not be hidden or neglected.	Review	B-Review	4
[line_break_token]* In the experiments, you could add the "Deep Clustering for Unsupervised Learning of Visual Features"  as baseline as well even if they use it for unsupervised learning as they do clustering as well.	Review	O	0
[line_break_token]* In the experiments, you use the features extracted from ResNet-50 but what about finetuning this network rather than adding something on top or even better starting from scratch.	Review	O	0
Because here CIFAR-10 benefits greatly from the ImageNet features.	Review	B-Review	6
I know that you should reproduce the settings from other papers but it might be good to go a bit beyond.	Review	I-Review	6
Especially, if the settings of previous papers are a bit faulty.	Review	I-Review	6
[line_break_token]* Regarding, the impact of number of models in section D of the appendix, there is no saturation at 10 models.	Review	O	0
So how many models are necessary for saturation of the performance ?	Review	B-Review	7
[line_break_token]* Minor point: several times, you write "psuedo".	Review	O	0
[line_break_token][line_break_token]Conclusion: the algorithm is novel and represents a nice contribution.	Review	O	0
Though, there are a lot of weaknesses that could be solved.	Review	O	0
So, I am putting "Weak accept" for the moment but it could change towards a negative rating depending on the rebuttal.	Review	O	0
[line_break_token]	Review	O	0
hank you for your comments and the positive review of the paper.	Reply	O	0
[line_break_token][line_break_token]* We have updated the paper to clarify these experiments better.	Reply	O	0
At a high level, the goal of the experiments in page 2 is to see the effect of generating pseudo labels using existing approaches on the final clustering accuracy using our iteration-based approach.	Reply	B-Reply	1
These experiments establish two things: 1) We need good quality of initial pseudo labels to get good final clustering accuracy.	Reply	I-Reply	1
2) None of the existing methods provide high accuracy pseudo labels.	Reply	I-Reply	1
[line_break_token][line_break_token]* Yes, there are several recent methods for semi-supervised learning that have higher accuracy than ladder networks.	Reply	O	0
 For some of these approaches [1,2],  data-augmentation is a core component which assumes some domain knowledge of the dataset.	Reply	B-Reply	2
Further, many of the data-augmentation techniques are specific to image datasets.	Reply	I-Reply	2
There are other  methods [3,4] which uses adversarial training to learn latent features.	Reply	I-Reply	2
However, we found that these methods do not work well if we jointly train them with unsupervised losses.	Reply	I-Reply	2
Ladder networks does not require any domain-dependent augmentation, works for both image and text datasets, and can be easily jointly trained with supervised and unsupervised losses.	Reply	I-Reply	2
Thus, we chose to work with Ladder networks though our approach is general enough to work with any semi-supervised method that accommodates training with unsupervised loss terms.	Reply	I-Reply	2
[line_break_token][line_break_token]* Traditional clustering algorithms focus mainly on clustering the entire data set, not on finding high accuracy clusters of subsets of the data, and thus do not achieve high enough accuracy required for improving final clustering accuracy.	Reply	O	0
One principled algorithm is Girvan‚ÄìNewman algorithm [5]  that was proposed for community detection but we found that it was computationally impractical given the size of our datasets.	Reply	B-Reply	3
[line_break_token]Regarding the intuition that most of the neighbours of that node will be connected with each other, we found this to be empirically true in our experiments.	Reply	I-Reply	3
For example, on Cifar10, for the threshold of 90% models agreeing on the label, about 81% of the nodes in a cluster were connected to each other.	Reply	I-Reply	3
If the threshold is at 100%, all nodes in a cluster are connected with each other due to transitivity.	Reply	I-Reply	3
We have updated the paper with these numbers.	Reply	I-Reply	3
[line_break_token][line_break_token]*  We have updated the related work section with discussion of several other related papers.	Reply	O	0
[line_break_token][line_break_token]* We found that running K means starting with a random initialization to assign pseudo-labels as described in the paper resulted in poor pseudo-label accuracy.	Reply	O	0
Further, if we iterate based on these low accuracy pseudo-labels, the model degenerates to assigning most of the samples to the same cluster.	Reply	B-Reply	5
Thus, we felt that it was unfair to the authors to add these results as a baseline, especially since the authors themselves did not report clustering performance.	Reply	I-Reply	5
Note that, for the results in section 2, we did not start with a random initialization (we used a ladder network trained with an unsupervised loss to generate the initial pseudo-labels).	Reply	I-Reply	5
[line_break_token][line_break_token]* We did try some experiments on not using any pre-trained models for features and training convnets from scratch.	Reply	O	0
On the cifar10 dataset, using Resnet34 as CNN initialized randomly, our method was able to achieve clustering accuracy of 35.17 ( achieving about 2% improvement over the same model without our framework) .	Reply	B-Reply	6
In the literature, there are a couple of papers [6 , 7 ] that performs clustering on cifar-10 datasets from scratch, but they use a variety of domain-based data augmentation-based techniques to improve performance and we were not able to reproduce their results.	Reply	I-Reply	6
Furthermore, they are applicable to only image datasets and do not help with text-based datasets that we also evaluate on.	Reply	I-Reply	6
[line_break_token][line_break_token]* We ran additional experiments with 15 models in the ensemble and the accuracy remained at 98.5% accuracy on the MNIST dataset.	Reply	O	0
This suggests that accuracy saturates after 10 models.	Reply	B-Reply	7
We have updated the paper with this result.	Reply	I-Reply	7
[line_break_token][line_break_token]* Thanks for pointing it out, we have fixed it in the revised version of the paper.	Reply	O	0
[line_break_token][line_break_token][1] David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin Raffel.	Reply	O	0
 Mixmatch: A holistic approach to semi-supervised learning[line_break_token][line_break_token][2]  Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V Le.	Reply	O	0
 Unsupervised data augmentation[line_break_token][line_break_token][3] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii.	Reply	O	0
Virtual adversarial training: a regularization method for supervised and semi-supervised learning[line_break_token][line_break_token][4] Saki Shinoda, Daniel E Worrall, and Gabriel J Brostow.	Reply	O	0
 Virtual adversarial ladder networks for semi-supervised learning[line_break_token][line_break_token][5] Girvan M. and Newman M. E. J., Community structure in social and biological networks[line_break_token][line_break_token][6] Jianlong Chang, Lingfeng Wang, Gaofeng Meng, Shiming Xiang, and Chunhong Pan.	Reply	O	0
Deep adaptive image clustering[line_break_token][line_break_token][7] Xu Ji, Jo√£o F Henriques, and Andrea Vedaldi.	Reply	O	0
Invariant information clustering for unsupervised image classification and segmentation	Reply	O	0

The paper proposed a weakly-supervised wMAN model for moment localization in untrimmed videos.	Review	O	0
Only the video-level annotation is available for training, and the goal is retrieving the video segment described by the sentence.	Review	O	0
The proposed model explored to utilize better context information and captured the relation between video and sentence/word via graph neural networks.	Review	O	0
In particular, instead of modeling the context information between the sentence and each video frame, wMAN tried to learn the representation with multi-level and co-attention, which considers all possible pairs between the word and the frame.	Review	O	0
The proposed model was evaluated on two publicly-available dataset and achieved reasonable results.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- Weakly-supervised method for video moment localization is a reasonable and important direction.	Review	O	0
[line_break_token]- wMAN explicitly utilized multi-level context information between the sentence and the video frame, and used the graph neural network and the message passing to model the representation.	Review	O	0
I think this is a reasonable direction.	Review	O	0
[line_break_token]- wMAN is evaluated with two publicly available datasets, and is compared with state-of-the-art methods and other "oracle" baselines.	Review	O	0
The performance is impressive and could be a better baseline for the future work.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- wMAN model the relation for all possible pairs of the word and the video frame.	Review	O	0
However, if the video is quite long, say 10 minutes, 30 minutes, or even few hours, will the method still be efficient and effective?	Review	B-Review	1
[line_break_token]- When building the relation between the word and the frame, is there any emphasis on verb, some particular word, or self-learned attention?	Review	O	0
For some particular word, say "people" and "cup", won't it have strong connection with many frames?	Review	B-Review	2
But for some of the words, say "hold" and "sits", could it play a more important role?	Review	I-Review	2
[line_break_token]- Followed by previous question, in the qualitative results, it seems the boundary parts of the predicted video segments are less accurate.	Review	O	0
Is it because some of the words case these false positive results?	Review	B-Review	3
What do you think the reason is?	Review	I-Review	3
[line_break_token]- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.	Review	O	0
For example, the full model of wMAN works better than FBW on R@1, but worse on R@5 and R@10.	Review	B-Review	4
Is there a particular reason about this?	Review	I-Review	4
PE seems to be important for wMAN, and the authors provides few sentences analysis about this, but I don't think I fully understand this part.	Review	I-Review	4
Another problem is that there is only few qualitative results, and in both these two examples, predicted results cover the GT segments.	Review	I-Review	4
Is this always the case for wMAN?	Review	I-Review	4
Why?	Review	I-Review	4
Some failure cases could also be very helpful.	Review	I-Review	4
[line_break_token]- Less technical comments: The paper writing is fine to me, but I don't like the typesetting.	Review	O	0
I suggest to put the model figure more close to the methodology section and the qualitative results on page 8.	Review	B-Review	5
[line_break_token][line_break_token]Overall, I think the paper is marginal above the accept line.	Review	O	0
hank you for your review.	Reply	O	0
We address your concerns below.	Reply	O	0
[line_break_token][line_break_token]- wMAN model the relation for all possible pairs of the word and the video frame.	Reply	O	0
However, if the video is quite long, say 10 minutes, 30 minutes, or even few hours, will the method still be efficient and effective?	Reply	O	0
[line_break_token][line_break_token]Computing effective video representations for long videos efficiently is still an unsolved problem in computer vision.	Reply	B-Reply	1
There is a lot of ongoing work in this area.	Reply	I-Reply	1
With this said, based on the observed memory requirements of our proposed approach during inference, the efficiency and effectiveness of our method should be scalable to videos lasting a few minutes.	Reply	I-Reply	1
As mentioned before, reasoning about videos lasting a few hours efficiently and effectively is still an unsolved research topic.	Reply	I-Reply	1
However, with increased computational resources, there is no reason to believe that our method is not scalable to such videos.	Reply	I-Reply	1
One possible solution is to reduce the sampling rate of video frame.	Reply	I-Reply	1
Another option is to break the video into smaller parts and localize within each part individually.	Reply	I-Reply	1
Finding a way to reason about long videos and natural language effectively from a low frame sampling rate in this task provides an interesting avenue for future work.	Reply	I-Reply	1
[line_break_token][line_break_token]- When building the relation between the word and the frame, is there any emphasis on verb, some particular word, or self-learned attention?	Reply	O	0
[line_break_token][line_break_token]The motivation behind the frame-by-word interaction mechanism in our approach is that it encourages the model to learn the association between words and action sequences in videos.	Reply	B-Reply	2
Words such as ‚Äòhold‚Äô and ‚Äòsits‚Äô definitely play a much more important role in localizing the relevant temporal segment in videos.	Reply	I-Reply	2
For example, in Figure 3b, we observe that the top 3 weights assigned to each frame for ‚Äòperson‚Äô and ‚Äòchair‚Äô generally occur in tandem with ‚Äòsits‚Äô and ‚Äòdown‚Äô.	Reply	I-Reply	2
This demonstrates that our model learns the association between verbs and entities via self-learned attention.	Reply	I-Reply	2
This is consistent with our observations in Figure 3a as well.	Reply	I-Reply	2
[line_break_token][line_break_token]- Followed by previous question, in the qualitative results, it seems the boundary parts of the predicted video segments are less accurate.	Reply	O	0
[line_break_token][line_break_token]One possible reason is that we are using non-overlapping segments as proposals on Charades-Sta to facilitate fair comparison with prior work.	Reply	B-Reply	3
Given that these proposals have static boundaries, it will cause the boundary parts of the candidate proposals to be less accurate.	Reply	I-Reply	3
[line_break_token][line_break_token]- Experimental results: I suggest the author to provide more ablation analysis to the experiment section.	Reply	O	0
[line_break_token][line_break_token]It appears that contextual cues generally help to improve retrieval accuracy on harder settings such as higher IOU thresholds and Recall@1 accuracy.	Reply	B-Reply	4
Using just the FBW module leads to better performance only on the lowest IOU threshold and Recall@5 and Recall@10 accuracies.	Reply	I-Reply	4
We observe the same consistency in our ablation experiments on DiDeMo as well.	Reply	I-Reply	4
We hypothesize that these cues help to make our model more discriminative in harder settings which is arguably more practical for real-world applications such as in video search engines.	Reply	I-Reply	4
Finally, the overall performance of wMAN is better than that of the FBW module.	Reply	I-Reply	4
If we average the scores, we obtain 57.0% and 58.2% for the FBW module and wMAN respectively.	Reply	I-Reply	4
[line_break_token][line_break_token]- Less technical comments [line_break_token][line_break_token]We will update the next version of the paper with the necessary clarifications and modifications.	Reply	O	0
[line_break_token][line_break_token]We hope that we have addressed your concerns satisfactorily.	Reply	O	0
Please let us know if you have any further concerns or questions	Reply	O	0

This paper propose local prior matching to leverage a language model to use unlabeled speech data to improve an ASR system.	Review	O	0
This is a worthy goal.	Review	O	0
The details of the proposal were a bit hard for me to understand.	Review	B-Review	1
The proposed method reminded me of "posterior regularization" (K. Ganchev et al.	Review	I-Review	1
2010), but I could not understand Section 2.2 well enough to draw a direct link.	Review	I-Review	1
I encourage the authors to condense 2.2 and make it clearer what, exactly, Local Prior Matching is.	Review	I-Review	1
[line_break_token][line_break_token]The paper presents extensive, interesting results.	Review	I-Review	2
I do want to point that they seem to be considerably off of the LibriSpeech state of the art, e.g. see K. Irie et al.	Review	I-Review	2
Interspeech 2019.	Review	I-Review	2
e thank the reviewer for the thoughtful comments.	Reply	O	0
Below are our itemized responses to address the concerns.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q1: The details of the proposal were a bit hard for me to understand.	Reply	O	0
The proposed method reminded me of "posterior regularization" (K. Ganchev et al.	Reply	O	0
2010), but I could not understand Section 2.2 well enough to draw a direct link.	Reply	O	0
I encourage the authors to condense 2.2 and make it clearer what, exactly, Local Prior Matching is.	Reply	O	0
[line_break_token][line_break_token]A1: We thank the reviewer for the suggestion on writing.	Reply	O	0
We will clarify Section 2 of the paper.	Reply	B-Reply	1
If the reviewer has specific parts in mind that are not clear, we will gladly address them.	Reply	I-Reply	1
[line_break_token][line_break_token]In a nutshell, we propose a training objective for unlabeled speech.	Reply	I-Reply	1
Our approach is like pseudo-labeling, but instead of using the top-1, we use top-k with beam search, and re-weight this top-k by the LM score.	Reply	I-Reply	1
We call it the ‚Äúlocal prior‚Äù because it gives a distribution proportional to the prior (LM), but only in a region close to the ground truth, where p(speech | text) is high.	Reply	I-Reply	1
We then train an ASR system using unlabeled speech by matching the ASR model distribution with this target distribution, and hence the proposed training objective is termed ‚Äúlocal prior matching.	Reply	I-Reply	1
‚Äù[line_break_token][line_break_token]Both posterior regularization (PR) [1] and our work aim to incorporate implicit supervision, but the methods differ significantly.	Reply	I-Reply	1
PR focuses on incorporating domain knowledge (e.g., in POS tagging there must be at least one noun and one verb in the output) through adding *handcrafted* and *linear* constraints to the posterior distribution family.	Reply	I-Reply	1
Optimization of PR is done with an EM algorithm.	Reply	I-Reply	1
[line_break_token][line_break_token]On the other hand, we propose a Bayesian-based method, where the implicit supervision from the language model corresponds to the prior in the Bayesian framework.	Reply	I-Reply	1
Unlike PR, there is no limitation on what models can be used for parameterizing the prior distribution.	Reply	I-Reply	1
Hence, we can use a very strong prior model that incorporates all the prior knowledge (e.g., in the POS tagging example, any sequence with no verb and no noun should have extremely low prior probability).	Reply	I-Reply	1
One of our main contributions is proposing a tractable and theoretically justified posterior estimator utilizing a strong prior distribution model for sequence transduction tasks.	Reply	I-Reply	1
[line_break_token][line_break_token][1] Ganchev, Kuzman, Jennifer Gillenwater, and Ben Taskar. "	Reply	O	0
Posterior regularization for structured latent variable models."	Reply	O	0
Journal of Machine Learning Research 11.Jul (2010): 2001-2049.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q2: The paper presents extensive, interesting results.	Reply	O	0
I do want to point that they seem to be considerably off of the LibriSpeech state of the art, e.g. see K. Irie et al.	Reply	O	0
Interspeech 2019.	Reply	O	0
[line_break_token][line_break_token]A2: We thank the reviewer for pointing out the reference and we are also aware of those work.	Reply	O	0
As described in our paper, we base our model on [2] because it is light-weight and efficient compared to the RNN-based encoders used in [3; 4], while achieving comparable performances.	Reply	B-Reply	2
Below we list our baseline model results and those from some very recent literature using seq2seq+attention ASR models trained on LibriSpeech train-clean-100.	Reply	I-Reply	2
Our baseline model is on-par with the second place and not far from the best results.	Reply	I-Reply	2
[line_break_token][line_break_token]*Baseline Performances (WER)*[line_break_token]Paper  |  test-clean |  test-other  [line_break_token]Ours   |  14.85%     |  39.95%[line_break_token][5]       |  25.2%       |  (not reported)[line_break_token][6]       |  21.0%       |  (not reported)[line_break_token][3]       |  14.7%       |  40.8%[line_break_token][4]       |  12.9%       |  35.5%[line_break_token][line_break_token]We also point out that the reference the reviewer mentioned [4] was concurrent work published just one week before the ICLR submission deadline.	Reply	I-Reply	2
Since the focus of our paper is semi-supervised learning and not on achieving the best possible baseline, we feel that the important results are the amount of improvement from the baseline and the gap reduced from using a larger labeled dataset (WER recovery rate, WRR).	Reply	I-Reply	2
In that respect, our proposed method demonstrates superior performance compared to the literature as shown below (complete results are in Table 11), while being extremely simple to implement and theoretically well-justified.	Reply	I-Reply	2
[line_break_token][line_break_token]*Proposed Method Performances with 360hr of unlabeled speech*[line_break_token]WRR = (WER(sup.	Reply	I-Reply	2
100) - WER(proposed)) / (WER(sup.	Reply	I-Reply	2
100) - WER(sup.	Reply	I-Reply	2
460))[line_break_token]Paper |  test-clean WER  |  test-clean WRR[line_break_token]Ours  |  9.21%           |  82.22%[line_break_token][5]      |  21.5%           |  27.6%[line_break_token][6]      |  17.5%           |  38.0%[line_break_token][line_break_token][line_break_token][2] Hannun, Awni, et al. "	Reply	O	0
Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions."	Reply	O	0
Interspeech (2019).	Reply	O	0
[line_break_token][3] L√ºscher, Christoph, et al. "	Reply	O	0
RWTH ASR systems for LibriSpeech: Hybrid vs Attention."	Reply	O	0
Interspeech (2019).	Reply	O	0
[line_break_token][4] Irie, Kazuki, et al. "	Reply	O	0
On the Choice of Modeling Unit for Sequence-to-Sequence Speech Recognition."	Reply	O	0
Interspeech (2019).	Reply	O	0
[line_break_token][5] Hori, Takaaki, et al. "	Reply	O	0
Cycle-consistency training for end-to-end speech recognition."	Reply	O	0
ICASSP (2019).	Reply	O	0
[line_break_token][6] Baskar, Murali Karthick, et al. "	Reply	O	0
Self-supervised Sequence-to-sequence ASR using Unpaired Speech and Text."	Reply	O	0
Interspeech (2019)	Reply	O	0

Results on the VQA task are good for this simple model, the ablation study of table 1 gives some insights as to what is important.	Review	O	0
[line_break_token][line_break_token]Missing are some explanations about the language embedding and the importance in deciding embedding dimension and final output dimension, equivalent to deciding the projected dimension in[tab_token]the compact bilinear model.	Review	B-Review	1
Since the main contribution of the[line_break_token]paper seems to be slightly better performance with fairly large reduction in parameters vs. compact bilinear something should be said about choice of those hyper parameters.	Review	I-Review	1
If you increase embedded and output dimensions to equalize parameters to the compact bilinear model are further gains possible?	Review	I-Review	1
 How is the question encoded?	Review	I-Review	1
Is word order preserved in this encoding, the compact bilinear model compared to in table 1 mentions glove, the proposed model is using this as well?	Review	I-Review	1
The meaning of visual attention in this model along with the number of glimpses should be tied to the sentence embedding, so now we are looking at particular spatial components when that part of the sentence is encoded, then we stack according to your equation 9?	Review	I-Review	2
[line_break_token]	Review	O	0
Explanation about the question embedding can be found in Appendix A.1.1, and please refer to our recent comment on that.	Reply	B-Reply	1
The output dimension (the number of candidate answers) and joint embedding size is fixed according to Kim et al., (	Reply	I-Reply	1
2016b).	Reply	I-Reply	1
Our preliminary study shows that the choice of the number of joint embedding size is difficult, since the variance of performance is relatively high, but around 1,000 is fairly good.	Reply	I-Reply	1
[line_break_token][line_break_token]For the multiple-glimpse attention mechanism, we get two different attention probability distributions over 14x14 grids using attention mechanism, and concatenating the two different weighted-sum visual features for each distribution, respectively	Reply	I-Reply	2

1.	Review	B-Review	2
This papers leverages the concept of wavelet transform within a deep architecture to solve the classic problem (especially for wavelet analysis) of change point detection.	Review	I-Review	1
The authors do a reasonably comprehensive job of demonstrating the efficacy of the proposed framework using various synthetic and real data sets with both gradual and abrupt changes[line_break_token][line_break_token]2.	Review	O	0
The concept of pyramid network idea is not really new, in the context of CNN it has been established quite well.	Review	B-Review	2
The paper should highlight this fact by citing papers such as "Lin, Tsung-Yi, et al. "	Review	I-Review	2
Feature Pyramid Networks for Object Detection."	Review	I-Review	2
CVPR.	Review	I-Review	2
Vol.	Review	I-Review	2
1.	Review	I-Review	2
No.	Review	I-Review	2
2.	Review	I-Review	2
2017."	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Involving wavelet transforms in deep nets have been done before.	Review	B-Review	3
This paper attempts to learn wavelet transform parameters by involving them as trainable layers.	Review	I-Review	3
But even this kind of idea is also emerging in the community.	Review	I-Review	3
Papers such as "Fujieda, Shin, Kohei Takayama, and Toshiya Hachisuka. "	Review	I-Review	3
Wavelet Convolutional Neural Networks."	Review	I-Review	3
arXiv preprint arXiv:1805.08620 (2018)" need to be discussed in this context.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
The biggest issue in my mind is that I feel "Chung et al 2016" is still a very similar framework as the proposed one.	Review	B-Review	4
While authors argue that it uses more like CNN architecture and the proposed method may pick up the multi-scale features better, comparison with this seems to be most appropriate.	Review	I-Review	4
This will also clearly identify the benefits of the wavelet structure to the filters and multi-resolution analysis approaches.	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	I-Review	3
RCNN term has been used for CNN+RNN architecture.	Review	I-Review	5
This may not be a good terminology to use since RCNN is a very popular term referring to Region based CNN for detection and localization purposes.	Review	I-Review	5
[line_break_token][line_break_token]6.	Review	O	0
AUC metric, I believe is the - area under ROC curve, this needs to be spelled out, how it is computed?	Review	B-Review	6
at least in the Appendix[line_break_token][line_break_token]xxxxxxxxxxxxxxxxxxx[line_break_token][line_break_token]Appreciate the authors' rebuttal, updated my score.	Review	O	0
We thank the reviewer for their helpful comments and have both updated the paper and planned experiments to further improve it.	Reply	O	0
Specific replies are below.	Reply	O	0
[line_break_token][line_break_token]2-3) The reviewer states that ‚Äúthe concept of pyramid network is not really new‚Äù and that ‚Äúinvolving wavelet transforms in deep nets have been done before‚Äù.	Reply	O	0
We have added both papers to the related work, however there are crucial differences between our approach and the cited works.	Reply	B-Reply	2
Both Lin et al and Fujieda et al address multiscale data, though this is in the context of image data with varying scale/resolution.	Reply	I-Reply	2
However, these works focus on images, each of which has data at multiple scales.	Reply	I-Reply	2
In contrast, we focus on temporal dependencies among multivariate time series, which are not captured by these approaches.	Reply	I-Reply	2
For example, Lin et al.	Reply	I-Reply	2
built feature pyramids for each input image to model different scales, but in our data the change points relate to earlier signals rather than the same moment captured at a different resolution.	Reply	I-Reply	2
For example, blood glucose changes in response to factors like exercise or food intake that happened earlier.	Reply	I-Reply	2
The wavelet method proposed by Fujieda et al has the same limitations, since that method is designed specifically for capturing spatial dependencies for different scales.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]4) The reviewer had some questions about how the paper advances the state of the art over the work of Chung et al (2016).	Reply	O	0
While that work also examines temporal dependencies at different scales, the approach is not designed specifically for CPD.	Reply	B-Reply	4
However, this approach is not scale invariant, relies on the hierarchical boundary structure, and has stronger connections between layers in the hierarchy.	Reply	I-Reply	4
The available code was used for prediction, but we are now attempting to apply the approach to the datasets in our paper by replacing the RNN framework in our proposed PRNN with the Hierarchical Multiscale Recurrent Neural Network (HMRNN) proposed by Chung et al.	Reply	I-Reply	4
The comparison results will be added to our paper once the experiments are completed.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]5) We have updated the terminology used.	Reply	O	0
[line_break_token]6)AUC: We included detail on the calculation under the implementation details (sec.	Reply	B-Reply	5
4.3) of our original submission, but have revised to make this clearer and have expanded the appendix to discuss how AUC is computed for each tolerance level.	Reply	I-Reply	5
[line_break_token][line_break_token]To detect changepoints, we apply non-maximum suppression with a sliding window of length and filter the maximum values with a threshold.	Reply	I-Reply	5
We evaluate AUC by iterating over this threshold.	Reply	I-Reply	5
Since changepoints may not exactly match the true changepoints, we use a tolerance parameter that sets how close a detected change must be to a true change to be considered a correct detection.	Reply	I-Reply	5
We match detected changepoints to the closest true changepoint within time ste	Reply	I-Reply	5

Generating high-quality sentences/paragraphs is an open research problem that is receiving a lot of attention.	Review	O	0
This text generation task is traditionally done using recurrent neural networks.	Review	O	0
This paper proposes to generate text using GANs.	Review	O	0
GANs are notorious for drawing images of high quality but they have a hard time dealing with text due to its discrete nature.	Review	O	0
This paper's approach is to use an actor-critic to train the generator of the GAN and use the usual maximum likelihood with SGD to train the discriminator.	Review	O	0
The whole network is trained on the "fill-in-the-blank" task using the sequence-to-sequence architecture for both the generator and the discriminator.	Review	O	0
At training time, the generator's encoder computes a context representation using the masked sequence.	Review	O	0
This context is conditioned upon to generate missing words.	Review	O	0
The discriminator is similar and conditions on the generator's output and the masked sequence to output the probability of a word in the generator's output being fake or real.	Review	O	0
With this approach, one can generate text at test time by setting all inputs to blanks.	Review	O	0
[line_break_token][line_break_token]Pros and positive remarks: [line_break_token]--I liked the idea behind this paper.	Review	O	0
I find it nice how they benefited from context (left context and right context) by solving a "fill-in-the-blank" task at training time and translating this into text generation at test time.	Review	O	0
[line_break_token]--The experiments were well carried through and very thorough.	Review	O	0
[line_break_token]--I second the decision of passing the masked sequence to the generator's encoder instead of the unmasked sequence.	Review	O	0
I first thought that performance would be better when the generator's encoder uses the unmasked sequence.	Review	O	0
Passing the masked sequence is the right thing to do to avoid the mismatch between training time and test time.	Review	O	0
[line_break_token][line_break_token]Cons and negative remarks:[line_break_token]--There is a lot of pre-training required for the proposed architecture.	Review	O	0
There is too much pre-training.	Review	B-Review	1
I find this less elegant.	Review	I-Review	1
[line_break_token]--There were some unanswered questions:[line_break_token]            (1) was pre-training done for the baseline as well?	Review	O	0
[line_break_token]            (2) how was the masking done?	Review	O	0
how did you decide on the words to mask?	Review	B-Review	3
was this at random?	Review	I-Review	3
[line_break_token]            (3) it was not made very clear whether the discriminator also conditions on the unmasked sequence.	Review	O	0
It needs to but [line_break_token]                  that was not explicit in the paper.	Review	B-Review	4
[line_break_token]--Very minor: although it is similar to the generator, it would have been nice to see the architecture of the discriminator with example input and output as well.	Review	O	0
[line_break_token][line_break_token][line_break_token]Suggestion: for the IMDB dataset, it would be interesting to see if you generate better sentences by conditioning on the sentiment as well.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your review!	Reply	O	0
[line_break_token][line_break_token]*Pretraining*[line_break_token]We found evidence that this architecture could replicate simple data distributions without pretraining and found it could perform reasonably on larger data sets, however, in the interest of computational efficiency, we relied on pretraining procedures, similar to other work in this field.	Reply	O	0
All our baselines also included pre-training.	Reply	B-Reply	2
[line_break_token][line_break_token]To test whether all the pretraining steps were necessary, we experimented with training MaskMLE and MaskGAN on PTB without initializing from a pretrained language model.	Reply	I-Reply	2
The perplexity of the generated samples were 117 without pretraining and 126 with pretraining, showing that at least for PTB language model pretraining does not appear to be necessary.	Reply	I-Reply	2
[line_break_token][line_break_token]Models trained from scratch were found to more computationally intense.	Reply	I-Reply	2
 By building off near state-of-the-art language models, we were able to rapidly iterate over architectures thanks to faster convergence.	Reply	I-Reply	2
 Additionally, we were working at a word-level representation where our softmax is producing a distribution over O(10K)-tokens.	Reply	I-Reply	2
 Attempting reinforcement learning methods from scratch on an ‚Äòaction space‚Äô of this magnitude is prone to extreme variance.	Reply	I-Reply	2
 The likelihood of producing a correct token and receiving a positive reward is exceedingly rare; therefore, the model spends a long time exploring the space with almost always negative rewards.	Reply	I-Reply	2
 As a related and budding research avenue, one could consider the properties and characteristics of exclusively GAN-trained language models.	Reply	I-Reply	2
 [line_break_token][line_break_token]*Masking Strategy*[line_break_token]We predominantly evaluated two masking strategies at training time.	Reply	O	0
 One was a completely random mask and the other was a contiguous mask, where blocks of adjacent words are masked.	Reply	B-Reply	3
 Though we were able to train with both strategies, we found that the random mask was more difficult to train.	Reply	I-Reply	3
 However, and more significantly, the random mask doesn‚Äôt share the primary benefit of GAN autoregressive text generation (termed free-running mode in the literature).	Reply	I-Reply	3
 One can see this because for a given percentage of words to omit, a Generator given the random mask will fill-in shorter sequences autoregressively than the contiguous mask will.	Reply	I-Reply	3
 GAN-training allows our training and inference procedure to be the same, in contrast to teacher-forcing in maximum likelihood training.	Reply	I-Reply	3
 Therefore, we generally found it beneficial to allow the model to produce long sequences, conditioned on what it had produced before, rather than filling in short disjoint sequences or or even single tokens.	Reply	I-Reply	3

Summary:[line_break_token][line_break_token]The paper provides a description of a new framework for reproducible and efficient RL experiments, as well as benchmarks of many algorithms on popular environments, such as `Atari and Roboschool.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- I agree that reproducibility is an extremely important question for the RL research, and thus such a code library is very beneficial for the community.	Review	O	0
[line_break_token]- The library is well designed, and allows for creating extensions rather easily in the future.	Review	O	0
[line_break_token]- Benchmarks are quite extensive and instructive.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]-  Comparison with the library [1] is missing (see also [2] for description and benchmarks).	Review	O	0
As both libraries are focused on reproducibility and flexible implementations of algorithms, such a comparison would support authors claims.	Review	B-Review	1
[line_break_token]- I am not sure that ICLR is the right venue for such paper.	Review	O	0
Perhaps a more specialized conference of a workshop would be better.	Review	B-Review	2
[line_break_token]- Anonymity violation[line_break_token][line_break_token]Questions:[line_break_token]- How difficult it is to implement distributional algorithms in your framework?	Review	O	0
[line_break_token]- What about different exploration strategies? (	Review	O	0
Boltzmann, epsilon-greedy, parameter noise etc.).	Review	B-Review	5
I guess it should be quite easy to make it configurable as well[line_break_token][line_break_token][line_break_token][1] <a href="https://github.com/catalyst-team/catalyst" target="_blank" rel="nofollow">https://github.com/catalyst-team/catalyst</a>[line_break_token][2] <a href="https://arxiv.org/pdf/1903.00027.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1903.00027.pdf</a>[line_break_token]	Review	O	0
[line_break_token]Thank you for taking the time to review this paper and for your thoughtful comments.	Reply	O	0
Please see our responses below.	Reply	O	0
[line_break_token][line_break_token]---[line_break_token]‚ÄúComparison with the library [1] is missing‚Ä¶‚Äù[line_break_token]Thanks for bringing this library to our attention.	Reply	O	0
We added a comparison in Table 3, and the similarities and differences are summarized below:[line_break_token][line_break_token]Both libraries addresses reproducibility using config/spec files, although SLM Lab uses the git SHA to reference code as opposed to saving source as Catalyst does.	Reply	B-Reply	1
They both report benchmark results, however SLM Lab is more comprehensive.	Reply	I-Reply	1
Parallelization in Catalyst can scale to multiple machines, where as parallelization in SLM Lab is focused on the single machine use case.	Reply	I-Reply	1
SLM Lab also logs to Tensorboard, and provides a more extensive automatic experiment analysis.	Reply	I-Reply	1
Finally, Catalyst does not appear to provide hyper-parameter search.	Reply	I-Reply	1
This is a key feature of SLM Lab and is configured in the spec file.	Reply	I-Reply	1
[line_break_token][line_break_token]---[line_break_token]‚ÄúI am not sure that ICLR is the right venue for such paper...‚Äù[line_break_token]Our paper is as much an empirical contribution as a software contribution.	Reply	O	0
It provides what is, to the best of our knowledge, the most comprehensive set of benchmark RL results published to date (including entirely new results for the SAC algorithm), and moreover one which is a fairer comparison between RL algorithms than previous benchmarks due to the SLM Lab design that minimizes implementation differences.	Reply	B-Reply	2
It also includes a new hybrid parallelization capability applicable to all RL algorithms.	Reply	I-Reply	2
[line_break_token][line_break_token]Even considering just the software contribution of the SLM Lab library, however, we feel that ICLR is an appropriate venue for this paper.	Reply	I-Reply	2
 We note that the call for papers specifically lists ‚Äúimplementation issues, parallelization, software platforms, hardware‚Äù as a relevant topic.	Reply	I-Reply	2
We also note that some of the libraries cited in Table 3 have been published at similar venues, such as ELF at NeurIPS 2017, and RLLib at ICML 2018.	Reply	I-Reply	2
[line_break_token][line_break_token]---[line_break_token]‚ÄúHow difficult it is to implement distributional algorithms in your framework?‚Äù[line_break_token]This is on the SLM Lab roadmap.	Reply	O	0
 It is not difficult, and can be implemented as an extension of the DQN class with a custom network output sampling mechanism and loss computation.	Reply	B-Reply	4
[line_break_token][line_break_token]---[line_break_token]‚ÄúWhat about different exploration strategies?...‚Äù[line_break_token]Boltzmann and epsilon-greedy exploration strategies are implemented and can be specified in the spec file.	Reply	O	0
We have updated the paper to make it clear that this is available.	Reply	B-Reply	5
[line_break_token][line_break_token]Parameter noise is not currently implemented, but adding it is relatively straightforward, and it is on our future roadmap	Reply	I-Reply	5

This paper focuses on decoding/generation in neural sequence models (specifically machine translation) in a non-autoregressive manner that instead of generating in a left-to-right manner, focuses on generating sequences by picking a length first ,and then indices to replace in a deterministic or random scheme and, finally using a context sensitive distribution over vocabulary (using BERT-like masked LM scheme)  to pick the word to replace.	Review	O	0
In practice, this procedure of picking indices and words to replace is repeated T number of times and hence the final sequence is obtained by this iterative refinement procedure.	Review	O	0
This is an interesting and important research direction because not only would it result in better and context sensitive greedy/approximate-MAP decoded outputs, but also opens up opportunities for parallelization of the decoding procedure which is difficult to achieve with left-to-right decoders.	Review	O	0
[line_break_token]That said, the results are fairly inconclusive and the practical implementation does leave things desired for a practical decoder.	Review	O	0
As observed by the authors, different deterministic strategies for choosing T results in very different performances among the variants of the proposed approach.	Review	O	0
Besides among the variants, one clear pattern is that uniformly random picking of indices is worse than other schemes (left-to-right, least-to-most, easy-first) which is not unexpected but no conclusive empirical evidence can be found for relative differences between the performances of other 3 schemes.	Review	B-Review	3
Moreover, the proposed decoding variants generally perform worse than or at best similarly to standard autoregressive baselines.	Review	I-Review	3
As authors note, this is due to the mismatch between the method in which the model was trained and the decoding procedure which is not surprising, but at the same time this does not give insight into the effectiveness of the proposed decoding objective.	Review	I-Review	3
The central question is: if the training prefers left-to-right generation then how valuable is it to device  more reasonable but incompatible decoding procedures?	Review	I-Review	1
[line_break_token][line_break_token]Also, authors also note that index picking schemes investigated in the paper are heuristic based and a more interesting decoder could be learned if index selection procedure itself was learned with features depending on the previous index selection states, decoded states Y, and other relevant quantities.	Review	I-Review	2
They attribute poor performance of the proposed decoder to the nature of index selection approaches investigated in the paper.	Review	I-Review	2
I think the paper would be strengthened with results with a more sophisticated learned index selection procedure in addition to the heuristics investigated in this paper.	Review	I-Review	2
[line_break_token][line_break_token]Overall, while the idea and motivation behind this work is exciting, the inconclusive results and the approaches for practical implementation leave open significant room for improvement.	Review	O	0
e appreciate that you found our work exciting!	Reply	B-Reply	3
We disagree that there is no clear pattern on which decoding strategy to use for linear/constant time decoding scenarios.	Reply	I-Reply	3
For linear time case (Table 1), left2right and easy-first decoding strategies outperform both least2most and uniform decodings while left2right having slight performance improvement over easy-first decoding strategy.	Reply	I-Reply	3
These results hold across various linear-time decoding hyperparameter settings (beam size, decoding budget (T) and whether using reranking with an autoregressive model).	Reply	I-Reply	3
For constant-time decoding results (Table 3) least2most decoding strategy works best when annealing number of generated symbols at each step (L -&gt; 1) while easy-first strategy works best when generating constant L/T number of tokens.	Reply	O	0
In practice if one would to use our method, left2right is recommended for linear-time translation and least2most is recommended for constant-time translation with annealing number of tokens L-&gt;1.	Reply	O	0
[line_break_token][line_break_token]&gt; ‚ÄúThe central question is: if the training prefers left-to-right generation then how valuable is it to device more reasonable but incompatible decoding procedures?‚Äù[line_break_token][line_break_token]We don‚Äôt think it‚Äôs obvious that left2right decoding is the best decoding strategy for all possible decoding settings.	Reply	O	0
For example, from our experiments in the constant time decoding, left2right decoding performs considerably worse than least2most decoding.	Reply	B-Reply	1
Furthermore, given the proliferation of and advantages of non-left-to-right pretraining objectives, we argue that it is worthwhile to investigate non-left-to-right decoding strategies.	Reply	I-Reply	1
Such strategies have additional potential benefits, such as being easier to parallelize.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; ‚ÄúI think the paper would be strengthened with results with a more sophisticated learned index selection procedure in addition to the heuristics investigated in this paper.	Reply	O	0
‚Äù[line_break_token][line_break_token]We would agree that learning position selecting mechanism would be interesting to investigate, but we think this would be a significant undertaking on its own, as we would need to develop and test ways of providing generation order error signal and methods to learn against that signal	Reply	O	0

This paper proposed a study on audio adversarial examples and conclude the input transformation-based defenses do not work very well on the audio domain, especially for adaptive attacks.	Review	O	0
They also point out the importance of temporal dependency in designing defenses which is specific for the audio domain.	Review	O	0
This observation is very interesting and inspiring as temporal dependency is an important character that should be paid attention to in the field of audio adversarial examples.	Review	O	0
They also design some adaptive attacks to the defense based on temporal dependency but either fail to attack the system or can be detected by the defense.	Review	O	0
[line_break_token][line_break_token]Based on the results in Table S7, it seems like being aware of the parameter k when designing attacks are very helpful for reducing the AUC score.	Review	O	0
My question is if the attacker uses the random sample K_A to generate the adversarial examples, then how the performance would be.	Review	B-Review	1
Another limitation of this work is that the proposed defense can differentiate the adversarial examples to some extent, but the ASR is not able to make a right prediction for adversarial examples.	Review	I-Review	2
In addition, the writing of Section 4 is not very clear and easy to follow.	Review	I-Review	3
[line_break_token][line_break_token]In all, this paper proposed some interesting findings and point out a very important direction for audio adversarial examples.	Review	O	0
If the author can improve the writing in experiments and answer the above questions, I would support for the acceptance.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
We appreciate your insightful comments and feel sorry about hard following in Section 4.	Reply	O	0
Here are some response to questions you concerned and we‚Äôve uploaded new version of our paper with clearer structure.	Reply	O	0
[line_break_token][line_break_token]Q: My question is if the attacker uses the random sample K_A to generate the adversarial examples, then how the performance would be.	Reply	O	0
[line_break_token]A: Following your comment, we added the corresponding experiments in TableA7 in Appendix when k_A = rand(0.2, 0.8).	Reply	O	0
We observe that even k_A is chosen randomly, the results are similar to k_A equals to a fixed number when k_D is also a random number.	Reply	B-Reply	1
And when k_D is a fixed number, the attack detection results are also good because if k_A is not close to defender‚Äôs k_D, the attack effectiveness will be limited.	Reply	I-Reply	1
[line_break_token][line_break_token]Q: Another limitation of this work is that the proposed defense can differentiate the adversarial examples to some extent, but the ASR is not able to make a right prediction for adversarial examples[line_break_token]A: Yes, the proposed TD method is a detection instead of defense method, and our goal is to tell the adversarial instances apart from benign.	Reply	O	0
In many scenarios, detection is very important.	Reply	B-Reply	2
For instance, in malware or adversarial audio based attacks, if users can detect adversarial instances and remove or ignore them, it indeed helps to ensure system security.	Reply	I-Reply	2
[line_break_token][line_break_token]Q: writing in Section 4[line_break_token]A: We apologize that we did not put enough efforts in presenting the experimental results in Section 4.	Reply	O	0
Based on the review comments, we have reorganized and revised Section 4 to make the presentation clearer, including adding new tables (Tables 1 & 4) that highlight the overall structure of our attack & defense / detection	Reply	O	0

Summary:[line_break_token][line_break_token]The paper focuses on designing a generative framework for 3-D point data clouds.	Review	O	0
These point clouds correspond to objects shapes in 3-dimensions.	Review	O	0
According to the paper, previous approaches for generating such 3-D point clouds involved autoencoder and GANs used separately.	Review	O	0
The authors propose a framework combining both autoencoder and GAN in a single network.	Review	O	0
The authors claim that part of the network learns effective latent space embedding for 3-d point clouds corresponding to different objects and thus the entire network is more effective in generating 3-d point cloud.	Review	O	0
Experimental results are presented to support the claims for efficient embeddings, and better generation of 3-d point clouds.	Review	O	0
[line_break_token][line_break_token]Decision[line_break_token][line_break_token]The paper has some lacking in explanation.	Review	O	0
I am particularly interested in the answers to the following questions:[line_break_token]1.	Review	O	0
[tab_token]The encoder module (denoted as E in the paper) uses a loss function that apparently does not involve the encoder output (z in the paper).	Review	B-Review	1
How the module weights can be updated this way is unclear.	Review	I-Review	1
[line_break_token]2.	Review	O	0
[tab_token]G1 is updated twice in each iteration, according to algorithm 1 in paper (once during update of ùúΩG1 and ùúΩG).	Review	B-Review	2
How the generator G1‚Äôs output manages to converge to output z from encoder E is unclear.	Review	I-Review	2
[line_break_token]3.	Review	O	0
[tab_token]The authors claim that the proposed model has both better performance and efficiency.	Review	O	0
Although experimental results are provided to support claim for better performance, none have been offered for efficiency claim. (	Review	B-Review	3
calculation of EMD distance seems to be very expensive computationally)[line_break_token][line_break_token]Feedback[line_break_token][line_break_token]For section 5.5, a quantitative analysis might make the claim for portability of the framework stronger.	Review	O	0
In paragraph 1 of introduction, disadvantage of 3d point cloud data can be better explained.	Review	B-Review	4
[line_break_token]	Review	O	0
hank you for your review, and we hope that our revisions address your concerns.	Reply	O	0
[line_break_token]Q1:[line_break_token]The encoder module (denoted as E in the paper) uses a loss function that apparently does not involve the encoder output (z in the paper).	Reply	O	0
How the module weights can be updated this way is unclear[line_break_token][line_break_token]A:[line_break_token]Thanks for reading our paper carefully, and it id indeed a good question.	Reply	O	0
We use the loss between and to update the parameter E. Although z did not pass g2, we can still do this through some tricks in the code.	Reply	B-Reply	1
The purpose of this design is to not only help encoder generate latent code, but also help minimize the distance between representation z and \bar{z} from encoder.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: G1 is updated twice in each iteration, according to algorithm 1 in paper (once during update of G1 and G).	Reply	O	0
How the generator G1‚Äôs output manages to converge to output z from encoder E is unclear.	Reply	O	0
[line_break_token][line_break_token]AÔºö[line_break_token]Thanks.	Reply	O	0
The reason why we let G1 be updated twice in one iteration is as follow: the first time we use Lgan(noise \rightarrow z) to only update the G1 parameter, and the purpose of this step is to make the distribution of close to that of z; and then we use loss LG to update total model G including G1, in order to let G1 learn global information and increase the diversity of generator.	Reply	B-Reply	2
[line_break_token][line_break_token]Q3:[line_break_token]The authors claim that the proposed model has both better performance and efficiency.	Reply	O	0
Although experimental results are provided to support claim for better performance, none have been offered for efficiency claim. (	Reply	O	0
calculation of EMD distance seems to be very expensive computationally)[line_break_token][line_break_token]A:[line_break_token]Thanks.	Reply	O	0
The reason why we claim that our model has better efficiency is that our approach is one-stage, and the previous methods with similar ideas are two-stage.	Reply	B-Reply	3
The previous approach need to train a model first and then use pre-trained model‚Äôs result to train generator, while our model can be trained end-to-end, which will greatly shorten the training time.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4:[line_break_token]For section 5.5, a quantitative analysis might make the claim for portability of the framework stronger.	Reply	O	0
In paragraph 1 of introduction, disadvantage of 3d point cloud data can be better explained.	Reply	O	0
[line_break_token][line_break_token]A:[line_break_token]Thanks for you suggestion.	Reply	O	0
We have added the quantitative analysis of the 2D results in section 5.5 and modified the paragraph 1	Reply	B-Reply	4

This paper proposes active learning with partial feedback, which means at each step, the learner actively chooses both which example to label and which binary question to ask, then learn the multi-class classifier with these partial labels.	Review	O	0
Three different sampling strategies are used during active learning.	Review	O	0
Experimental results demonstrate that the proposed ALPF strategy outperforms existing baselines on the predicting accuracy under a limited budget.	Review	O	0
[line_break_token][line_break_token]This paper is well-written.	Review	O	0
The main ideas and claims are clearly expressed.	Review	O	0
ALPF combines active learning with learning from partial labels.	Review	O	0
This setting is interesting and important, especially when the number of categories is large and share some hierarchical structure.	Review	O	0
The experimental results are promising.	Review	O	0
My main concern about this work is the lack of theoretical guarantees, which is usually important for active learning paper.	Review	B-Review	1
it‚Äôs better to provide some analysis on the efficiency of ALPF to further improve the quality of the paper.	Review	I-Review	1
[line_break_token]I have the following questions for the authors:[line_break_token]+Why vanilla active learning strategy does not work well?	Review	O	0
Which uncertainty measurement do you use here?	Review	B-Review	2
[line_break_token]+The performances of this work heavily rely on the taxonomy of labels, while in some cases the taxonomy of labels is not tree structure but a graph, i.e. a label may belong to multiple hyper-labels.	Review	O	0
Can ALPF still work on these cases?	Review	B-Review	3
[line_break_token]	Review	O	0
We thank the reviewer for their thoughtful feedback and were glad to see that you found our proposed setting to be both interesting and important.	Reply	O	0
We would like to respond to your concerns briefly:[line_break_token][line_break_token]First, concerning your questions:[line_break_token]***Re the failure of vanilla active learning***[line_break_token]Since theoretical analysis guaranteeing the performance of active + deep learning has yet to be established, it‚Äôs hard to say *why* vanilla uncertainty-sampling-based active learning doesn‚Äôt work so well when applied on image classification datasets with convolutional neural networks.	Reply	O	0
However, we are not the first to find this.	Reply	B-Reply	2
Take for example the results Active Learning for Convolutional Neural Networks: A Core Set Approach (<a href="https://arxiv.org/pdf/1708.00489.pdf)," target="_blank" rel="nofollow">https://arxiv.org/pdf/1708.00489.pdf),</a> which was published at ICLR 2018, where uncertainty sampling and even the more recent deep Bayesian active learning by disagreement perform no better than random on CIFAR 10 and only marginally better for CIFAR 100.	Reply	O	0
In contrast, vanilla AL strategies have demonstrated promise on a number of NLP tasks (e.g. <a href="https://arxiv.org/pdf/1808.05697.pdf)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1808.05697.pdf).</a>[line_break_token][line_break_token]***Re the taxonomy of labels***[line_break_token]While tree-structured taxonomies are especially convenient, our methods do not in principle depend specifically on tree structure, requiring only a list of composite labels.	Reply	O	0
One can draw a parallel to general formulations of the game twenty questions where the available set of questions needn‚Äôt form tree.	Reply	B-Reply	3
We thank the reviewer for the suggestion for future work and plan to evaluate our methods on with label ontologies like the MeSH labels (medical subject headings) used to annotate biomedical articles that do not form a strict tree hierarchy (some nodes have multiple parents).	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding theoretical guarantees, we agree with the reviewer that establishing theoretical guarantees for active learning with partial labels is an especially exciting direction and plan to pursue future work in this direction.	Reply	I-Reply	1
We note that generally there is a considerable gap between the theory of active learning and the practical methods established to cope with high dimensional data and modern classifiers and hope to close this gap in the future with rigorous analysis.	Reply	I-Reply	1

This paper compares the use of hand-designed and learned features for the analysis of 3d objects.	Review	O	0
The authors use an extensive set of 25 hand-designed features to obtain 92.33% accuracy for the task of agglomerating neuron fragments.	Review	O	0
They then explored fully supervised end to end learning of features from raw inputs, but only obtain 85.54% accuracy.	Review	O	0
However, because the data is small compared to its dimensionality, unsupervised learning provides some improvement.	Review	O	0
Finally, a dynamic pooling method allows them to match the hand-designed features score.	Review	O	0
Data augmentation however brings fully supervised and unsupervised approaches on par.	Review	O	0
[line_break_token][line_break_token]Novelty and quality: I am not very familiar with the literature in 3d analysis but the introduction suggests that feature learning (fully supervised and unsupervised) has not been used before or is not common.	Review	O	0
If so, the methods themselves are not novel but their application to this particular field is.	Review	B-Review	1
It would be good if the authors could state clearly if this has ever been tried before or not.	Review	I-Review	1
The quality of the work is good and thorough.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- directly comparing hand-designed and learned features is good.	Review	O	0
[line_break_token]- learned features are shown to be slightly superior in accuracy.	Review	O	0
Thank you for your comments.	Reply	O	0
[line_break_token][line_break_token]To our knowledge, this work is indeed the first to use representation learning in the context of 3d shape analysis, and we state this at the end of the introduction	Reply	B-Reply	1

This paper explores maximally expressive linear layers for jointly exchangeable data and in doing so presents a surprisingly expressive model.	Review	O	0
I have given it a strong accept because the paper takes a very well-studied area (convolutions on graphs) and manages to find a far more expressive model (in terms of numbers of parameters) than what was previously known by carefully exploring the implications of the equivariance assumptions implied by graph data.	Review	O	0
The result is particularly interesting because the same question was asked about exchangeable matrices (instead of *jointly* exchangeable matrices) by Hartford et al. [	Review	O	0
2018] which lead to a model with 4 bases instead of the 15 bases in this model, so the additional assumption of joint exchangeability (i.e. that any permutations applied to rows of a matrix must also be applied to columns - or equivalently, the indices of the rows and columns of a matrix refer to the same items / nodes) gives far more flexibility but without losing anything with respect to the Hartford et al result (because it can be recovered using a bipartite graph construction - described below).	Review	O	0
So we have a case where an additional assumption is both useful (in that it allows for the definition of a more flexible model) and benign (because it doesn't prevent the layer from being used on the data explored in Hartford et al.).	Review	O	0
[line_break_token][line_break_token]I only have a couple of concerns: [line_break_token]1 - I would have liked to see more discussion about why the two results differ to give readers intuition about where the extra flexibility comes from.	Review	O	0
The additional parameters of this paper come from having parameters associated with the diagonal (intuitively: self edges get treated differently to other edges) and having parameters for the transpose of the matrix (intuitively: incoming edges are different to outgoing edges).	Review	B-Review	1
Neither of these assumptions apply in the exchangeable setting (where the matrix may not be square so the diagonal and transpose can't be used).	Review	I-Review	1
Because these differences aren't explained, the synthetic tasks in the experimental section make this approach look artificially good in comparison to Hartford et al.	Review	I-Review	1
 The tasks are explicitly designed to exploit these additional parameters - so framing the synthetic experiments as, "here are some simple functions for which we would need the additional parameters that we define" makes sense; but arguing that Hartford et al. "	Review	I-Review	1
fail approximating rather simple functions" (page 7) is misleading because the functions are precisely the functions on which you would expect Hartford et al.	Review	I-Review	1
to fail (because it's designed for a different setting).	Review	I-Review	1
[line_break_token]2 - Those more familiar of the graph convolution literature will be more familiar with GCN [kipf et al.	Review	O	0
2016] / GraphSAGE [Hamilton et al.	Review	B-Review	3
2017] / Monti et al [2017] / etc.. Most of these approaches are more restricted version of this work / Hartford et al.	Review	I-Review	3
so we wouldn't expect them to perform any differently from the Hartford et al.	Review	I-Review	3
 baseline on the synthetic dataset, but including them will strengthen the author's argument in favour of the work.	Review	I-Review	3
I would have also liked to see a comparison to these methods in the the classification results.	Review	I-Review	2
[line_break_token]3 - Appendix A - the 6 parameters for the symmetric case with zero diagonal reduces to the same 4 parameters from Hartford et al.	Review	O	0
if we constrained the diagonal to be zero in the output as well as the input.	Review	B-Review	4
This is the case when you map an exchangeable matrix into a jointly exchangeable matrix by representing it as a bipartite graph [0, X; X^T, 0]. So the two results coincide for the exchangeable case.	Review	I-Review	4
Might be worth pointing this out.	Review	I-Review	4
[line_break_token]	Review	O	0
We thank the reviewer for the detailed review.	Reply	O	0
Below we address the main concerns.	Reply	O	0
[line_break_token][line_break_token]--------------------------------------------------------------------------------------------------------------------------------[line_break_token]Q:‚Äùso framing the synthetic experiments as, "here are some simple functions for which we would need the additional parameters that we define" makes sense; but arguing that Hartford et al. "	Reply	O	0
fail approximating rather simple functions" (page 7) is misleading because the functions are precisely the functions on which you would expect Hartford et al.	Reply	O	0
to fail‚Äù[line_break_token][line_break_token]A: We agree with the reviewer and will change our wording accordingly.	Reply	O	0
[line_break_token]--------------------------------------------------------------------------------------------------------------------------------[line_break_token]Q:‚ÄùI would have liked to see more discussion about why the two results differ to give readers intuition about where the extra flexibility comes from‚Äù.	Reply	O	0
 ‚Äúthe two results coincide for the exchangeable case‚Äù[line_break_token][line_break_token]A: We agree with the reviewer that such a discussion will be helpful to the reader.	Reply	O	0
We will add such a discussion (in addition to the short discussion at the end of Appendix 1).	Reply	B-Reply	2
[line_break_token]--------------------------------------------------------------------------------------------------------------------------------[line_break_token]Q: Comparison to popular graph convolution methods (GCN [kipf et al.	Reply	O	0
2016] / GraphSAGE [Hamilton et al.	Reply	O	0
2017] / Monti et al [2017] / etc.).	Reply	O	0
[line_break_token][line_break_token]A: As discussed in our response to Reviewer 2, We will add a theoretical result that shows that our model is at least as powerful in terms of universality as [Kipf & Welling ICLR 2017].	Reply	O	0

Background disclaimer: I work in RL research for quite an amount of time, but I do not know much about the domain of distributed systems.	Review	O	0
For this reason, I may not know the details of technical terms, and I might not be the best person to review this work (when compared with the literature in this field).	Review	O	0
Nevertheless, below I try to give my evaluation based on reading the paper.	Review	O	0
[line_break_token][line_break_token]====================[line_break_token]In this work, the authors applied value-based reinforcement learning to learn an optimal policy for global parameter tuning in the parameter server (PS) that trains machine learning models in a distributed way using  stochastic gradient descent.	Review	O	0
Example parameters include SGD hyper-parameters (such as learning rate) and system-level parameters.	Review	B-Review	1
Immediate cost is to minimize the training time of the SGD algorithm, and i believe the states are the server/worker parameters.	Review	I-Review	1
From the RL perspective, the algorithm used here is a standard DQN with discrete actions (choices of parameters).	Review	I-Review	1
But in general I am puzzled why the action space is discrete instead of continuous, if the actions are the hyper-parameters.	Review	I-Review	1
State transition wise, I am not sure if the states follow an action-dependent MDP transition, and therefore at this point I am not sure if DQN is the best algorithm for this applications (versus bandits/combinatorial bandits).	Review	I-Review	1
 While it is impressive to see that RL beats many of the SOTA baselines for parameter tuning, I also find that instead of using data in the real system to do RL training, the paper proposes generating "simulation" data by training a separate DNN.	Review	I-Review	1
I wonder how the performance would differ if the RL policy is trained on the batch real data.	Review	I-Review	1
[line_break_token][line_break_token]	Review	O	0
n the following, we list your concerns on the Problem I and our detailed responses.	Reply	O	0
[line_break_token][line_break_token]Problem I:[line_break_token]In this work, the authors applied value-based reinforcement learning to learn an optimal policy for global parameter tuning in the parameter server (PS) that trains machine learning models in a distributed way using  stochastic gradient descent.	Reply	O	0
Example parameters include SGD hyper-parameters (such as learning rate) and system-level parameters.	Reply	O	0
Immediate cost is to minimize the training time of the SGD algorithm, and i believe the states are the server/worker parameters.	Reply	O	0
From the RL perspective, the algorithm used here is a standard DQN with discrete actions (choices of parameters).	Reply	O	0
In general I am puzzled why the action space is discrete instead of continuous, if the actions are the hyper-parameters.	Reply	O	0
State transition wise, I am not sure if the states follow an action-dependent MDP transition, and therefore at this point I am not sure if DQN is the best algorithm for this applications (versus bandits/combinatorial bandits).	Reply	O	0
[line_break_token][line_break_token]Response to Problem I:[line_break_token]Thank you for your kind review.	Reply	O	0
First let us clarify the difference of our work with learning hyperparameters, then answer the question on actions and states.	Reply	B-Reply	1
[line_break_token][line_break_token]In this paper, we learn an optimal ''synchronization policy'' used for the distributed training of machine learning models with Stochastic Gradient Descent (SGD) in Parameter-Server (PS)-based environment.	Reply	I-Reply	1
This setting consists of one (or several) PS maintaining model parameters and receiving updated gradients from workers, and multiple workers pulling model parameters from PS, computing gradients and pushing them back to PS.	Reply	I-Reply	1
[line_break_token][line_break_token]The synchronization policy is a mechanism to coordinate the execution progress of all workers in the PS setting.	Reply	I-Reply	1
It determines in each step, i.e., whenever a worker pushes its gradient to the PS, whether this worker should continue to run for the next step or wait for sometime for the completion of some other workers.	Reply	I-Reply	1
Thus, it is independent of the hyper-parameters of SGD and system parameters.	Reply	I-Reply	1
Hence, we are trying to optimize the mechanism of the synchronization policy to save training time but not tuning the global hyperparameters of SGD.	Reply	I-Reply	1
 In short, our work falls in the category of "learning how to learn" to train the underlying ML models while hyperparameter tuning falls in the category of "learning which model to learn" to optimize the hyperparameters of the underlying ML models.	Reply	I-Reply	1
[line_break_token][line_break_token]To  this end, we formalize the design of a synchronization policy as a reinforcement learning problem (see Figure 1 in Page 5 for an illustration).	Reply	I-Reply	1
In this RL problem, for the state we choose  features which characterize the execution progress of SGD training in each step.	Reply	I-Reply	1
To ensure the expression power of the state, the state space in our problem is large when compared to more standard RL problem instances.	Reply	I-Reply	1
Each state vector may contain dozens to hundreds of features (See the paragraphs in Page 4 entitled with "State" for more details).	Reply	I-Reply	1
Therefore, we choose a deep neural network to represent the transition function \pi(S, a) and apply DQN to train the RL policy.	Reply	I-Reply	1
The tabular and bandits algorithms are unable to represent the large and complex transition function in this application.	Reply	I-Reply	1
[line_break_token][line_break_token]In our RL problem, each action represents a decision for each worker to run or wait at each step.	Reply	I-Reply	1
Therefore, the action space is discrete.	Reply	I-Reply	1
It contains at most 2^n actions for n workers since for each worker it need to be decided whether to run or wait, respectively.	Reply	I-Reply	1
We choose a small but powerful action space containing three valid actions to enable fast training of the RL policy (See the paragraphs in Page 5 entitled with "Action" for more details).	Reply	I-Reply	1
We design the state and action in this manner in our RL setting to ensure its generality while keeping training and inference efficiency.	Reply	I-Reply	1
[line_break_token][line_break_token]The state clearly follows an action-dependent MDP transition since the next position of execution process is purely determined by the current state (where we are) and the next action (where we go)	Reply	I-Reply	1

In this paper, the authors study an interesting problem called open-ended content style recombination, i.e., recombining the style of one image with the content of another image.	Review	O	0
In particular, the authors propose a VAE (variational autoencoder) based method (i.e., Style Transfer onto Open-Ended Content, STOC), which is optimized over a VAE reconstruction loss and/or a leakage filtering (LF) loss.	Review	O	0
More specifically, there are four variants of STOC, including CC (content classifier), CE (content encoding), PM (predictability minimization, Section 2.1) and LF (leakage filtering, Section 2.2).	Review	O	0
The main advantage of STOC is its ability to handle novel content from open domains.	Review	O	0
Experimental results on image synthesis and data set augmentation show the effectiveness of the proposed method in comparison with the state-of-the-art methods.	Review	O	0
The authors also study the comparative performance of four variants, i.e., CCF, CE, PM and LF.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is well presented.	Review	O	0
[line_break_token][line_break_token]Some comments/suggestions:[line_break_token][line_break_token](i) The authors are suggested to include an analysis of the time complexity of the proposed method (including the four variants).	Review	O	0
[line_break_token][line_break_token](ii) The authors are suggested to include more results with different configurations such as that in Table 1 in order to make the results more convincing.	Review	O	0
[line_break_token]	Review	O	0
We thank the reviewer for the thoughtful evaluation and feedback.	Reply	O	0
Regarding the investigation of different model configurations, in the Appendix (Figure 8) we vary the coefficients of the various costs in the training objective function on the naturally-evaluated, synthetically-trained (NEST) task.	Reply	B-Reply	2
We show that each component cost contributes to the model‚Äôs overall performance.	Reply	I-Reply	2
Regarding time complexity, predictability minimization incorporates a GAN-like adversarial objective, which makes it strictly inferior to STOC in time complexity and--as we show in the paper--in the quality of synthesized images.	Reply	I-Reply	1
The penalty in the STOC leakage filtering loss is proportional to the number of within- and between-class pairs that are drawn from P^+ and P^- in a minibatch	Reply	I-Reply	1

This paper introduces a new way of interpreting the VQ-VAE, [line_break_token]and proposes a new training algorithm based on the soft EM clustering.	Review	O	0
[line_break_token][line_break_token]I think the technical aspect of this paper is written concisely.	Review	O	0
[line_break_token]Introducing the interpretation as hard EM seems natural for me, and the extension[line_break_token]to the soft EM training is sound reasonable.	Review	O	0
[line_break_token]Mathematical complication is limited, this is also a plus for many non-expert readers.	Review	O	0
[line_break_token][line_break_token]I'm feeling difficulties in understanding the experimental part.	Review	B-Review	1
[line_break_token]To be honest, I think the experimental section is highly unorganized, not a quality for ICLR submission.	Review	I-Review	1
[line_break_token]I'm just wondering why this happens, given clean and organized technical sections...[line_break_token][line_break_token]First, I'm confusing what is the main competent in the Table 1.	Review	O	0
[line_break_token]In the last paragraph of the page 6, it reads; [line_break_token]"Our implementation of VQ-VAE achieves a significantly better BLEU score and faster decoding speed compared to (10)."	Review	B-Review	2
[line_break_token]However, Ref. (	Review	I-Review	2
10) is not mentioned in the Table 1.	Review	I-Review	2
Which BLEU is the score of Ref. (	Review	I-Review	2
10)?	Review	I-Review	2
[line_break_token][line_break_token]Second, terms "VQ-VAE", (soft?)"EM" and "our {model, approach}" are used in a confusing manner.	Review	I-Review	3
[line_break_token]For example, in Table 1, below the row "Our Results", there are:[line_break_token]- VQ-VAE[line_break_token]- VQ-VAE with EM[line_break_token]- VQ-VAE + distillation[line_break_token]- VQ-VAE with EM + distillation[line_break_token][line_break_token]The "VQ-VAE" is not the proposed model, correct?	Review	I-Review	3
[line_break_token]My understanding is that the proposal is a VQ-VAE solved via soft EM, which corresponds to "VQ-VAE with EM".	Review	I-Review	3
[line_break_token][line_break_token]Third, a paragraph "Robustness of EM to Hyperparameters" is mis-leading.	Review	I-Review	4
[line_break_token]The figure 3 does not show the robustness against a hyperparameter.	Review	I-Review	4
[line_break_token]It shows the BLEU against the number of "samples" (in fact, there is no explanation about what the "samples" means).	Review	I-Review	4
[line_break_token]I think hyperparameters are model constants such as the learning rate of the SGD, alpha-beta params for Adam, dimension of hidden units, number of layers, etc.	Review	I-Review	4
The number of samples are not considered as a model hyperparameter; it's a dataset property.	Review	I-Review	4
[line_break_token]The figure 5 shows the reconstructed images of the original VQ-VAE and the proposed VQ-VAE with EM.	Review	I-Review	5
[line_break_token]However, there is no explanation which hyperparameter is tested to assess "the robustness to hyperparameters".	Review	I-Review	5
[line_break_token][line_break_token]Fourth, there is no experimental report on the image reconstructions (with CIFAR and SVHN) in the main manuscript.	Review	I-Review	6
[line_break_token]In fact, there is a short paragraph that mentions about the SVHN results, [line_break_token]but it only refers to the appendix.	Review	I-Review	6
[line_break_token]I think appendix is basically used for additional results or proofs, that are not essential for the main message of the paper.	Review	I-Review	6
[line_break_token]However, performance in the image reconstruction is one of the main claims written in the abstract, the intro, etc.	Review	I-Review	6
[line_break_token]So, the authors should include the image reconstruction results in the main body of the paper.	Review	I-Review	6
[line_break_token]Otherwise, claims about the image reconstructions should be removed from the abstract, etc.	Review	I-Review	6
[line_break_token][line_break_token][line_break_token]+ Insightful understanding of the VQ-VAE as hard EM clustering[line_break_token]+ Natural and reasonable extension to soft-EM based training of the VQ-VAE[line_break_token]-- Unorganized experiment section.	Review	O	0
This simply ruins the quality of the technical part.	Review	B-Review	1
[line_break_token][line_break_token][line_break_token]## after feedback[line_break_token][line_break_token]Some of my concerns are addressed the feedback.	Review	O	0
[line_break_token]Considering the interesting technical parts, I raise the score upward, to the positive side.	Review	O	0
We thank the reviewer for reading our paper.	Reply	O	0
Below we address specific points raised by the reviewer:[line_break_token][line_break_token]>[line_break_token]I'm feeling difficulties in understanding the experimental part.	Reply	O	0
[line_break_token]To be honest, I think the experimental section is highly unorganized, not a quality for ICLR submission.	Reply	O	0
[line_break_token]I'm just wondering why this happens, given clean and organized technical sections...[line_break_token]>[line_break_token][line_break_token]We have made an effort to clean up the experimental section part in the updated draft.	Reply	O	0
We would appreciate specific comments to help us make the experimental section more readable and organized.	Reply	B-Reply	1
[line_break_token][line_break_token]>[line_break_token]First, I'm confusing what is the main competent in the Table 1.	Reply	O	0
[line_break_token]In the last paragraph of the page 6, it reads; [line_break_token]"Our implementation of VQ-VAE achieves a significantly better BLEU score and faster decoding speed compared to (10)."	Reply	O	0
[line_break_token]However, Ref. (	Reply	O	0
10) is not mentioned in the Table 1.	Reply	O	0
Which BLEU is the score of Ref. (	Reply	O	0
10)?	Reply	O	0
[line_break_token]>[line_break_token][line_break_token]This should be fixed in the updated version.	Reply	O	0
[line_break_token][line_break_token]>[line_break_token]Second, terms "VQ-VAE", (soft?)"EM" and "our {model, approach}" are used in a confusing manner.	Reply	O	0
[line_break_token]For example, in Table 1, below the row "Our Results", there are:[line_break_token]- VQ-VAE[line_break_token]- VQ-VAE with EM[line_break_token]- VQ-VAE + distillation[line_break_token]- VQ-VAE with EM + distillation[line_break_token][line_break_token]The "VQ-VAE" is not the proposed model, correct?	Reply	O	0
[line_break_token]My understanding is that the proposal is a VQ-VAE solved via soft EM, which corresponds to "VQ-VAE with EM".	Reply	O	0
[line_break_token]<[line_break_token][line_break_token]Yes VQ-VAE is not the proposed model, although we report it in "Our Results" because the implementation is different from Kaiser et al in two crucial aspects 1) No attention to source sequences for the discrete latents 2) Product Quantization (PQ) which the authors of Kaiser et al call DVQ is not being used.	Reply	O	0
Hence we also report it in "Our Results".	Reply	B-Reply	3
[line_break_token][line_break_token]>[line_break_token]Third, a paragraph "Robustness of EM to Hyperparameters" is mis-leading.	Reply	O	0
[line_break_token]The figure 3 does not show the robustness against a hyperparameter.	Reply	O	0
[line_break_token]It shows the BLEU against the number of "samples" (in fact, there is no explanation about what the "samples" means).	Reply	O	0
[line_break_token]I think hyperparameters are model constants such as the learning rate of the SGD, alpha-beta params for Adam, dimension of hidden units, number of layers, etc.	Reply	O	0
The number of samples are not considered as a model hyperparameter; it's a dataset property.	Reply	O	0
[line_break_token]>[line_break_token][line_break_token]The number of samples used for EM training of VQ-VAE is a hyperparameter, how is it a property of the dataset?	Reply	O	0
You are free to choose any number of samples regardless of the dataset.	Reply	B-Reply	4
[line_break_token][line_break_token]>[line_break_token]The figure 5 shows the reconstructed images of the original VQ-VAE and the proposed VQ-VAE with EM.	Reply	O	0
[line_break_token]However, there is no explanation which hyperparameter is tested to assess "the robustness to hyperparameters".	Reply	O	0
[line_break_token]<[line_break_token][line_break_token]Our apologies, this should be robustness to initialization of the codebook.	Reply	O	0
VQ-VAE/K-means is much more sensitive to a good initialization as compared to EM.	Reply	B-Reply	5
[line_break_token][line_break_token]>[line_break_token]Fourth, there is no experimental report on the image reconstructions (with CIFAR and SVHN) in the main manuscript.	Reply	O	0
[line_break_token]In fact, there is a short paragraph that mentions about the SVHN results, [line_break_token]but it only refers to the appendix.	Reply	O	0
[line_break_token]I think appendix is basically used for additional results or proofs, that are not essential for the main message of the paper.	Reply	O	0
[line_break_token][line_break_token]However, performance in the image reconstruction is one of the main claims written in the abstract, the intro, etc.	Reply	O	0
[line_break_token]So, the authors should include the image reconstruction results in the main body of the paper.	Reply	O	0
[line_break_token]Otherwise, claims about the image reconstructions should be removed from the abstract, etc.	Reply	O	0
[line_break_token]>[line_break_token][line_break_token]We have removed all image references from the main section and now only report it in the Appendix.	Reply	O	0
We hope this helps improving the quality and clarity of the main paper	Reply	B-Reply	6

This paper proposes a new set of heuristics for learning a NN for generalising a set of NNs trained for more specific tasks.	Review	O	0
This particular recipe might be reasonable, but the semi-formal flavour is distracting.	Review	B-Review	1
The issue of model selection (clearly the main issue here) is not addressed.	Review	I-Review	2
A quite severe issue with this report is that the authors don't report relevant learning results from before (+-) 2009, and empirical comparisons are only given w.r.t.	Review	I-Review	3
other recent heuristics.	Review	I-Review	3
This makes it for me not possible to advice publication as is.	Review	O	0
We thank the reviewer for time and feedback.	Reply	O	0
We think the questions aren‚Äôt precise enough for us to act upon:[line_break_token]1.	Reply	O	0
We‚Äôd appreciate if the reviewer can point out the parts that are according to the reviewer‚Äôs opinion `semi-formal‚Äô?	Reply	B-Reply	1
We are more than happy to revise the text but are currently left guessing, particularly since another reviewer points out that the paper is `well written.	Reply	I-Reply	1
‚Äô [line_break_token]2.	Reply	O	0
We compare to recent baselines, in particular state-of-the-art methods like PNN and PathNet.	Reply	B-Reply	3
If the reviewer would specify which papers from before 2009 we should compare to, we are very happy to include a statement, assuming that PNN and/or PathNet or their predecessors haven‚Äôt compared to those already.	Reply	I-Reply	3
[line_break_token]3.	Reply	O	0
To the best of our knowledge, the two baselines (PNN and PathNet) we compare with are the state-of-the-art RL transfer frameworks.	Reply	B-Reply	3

########## UPDATED AFTER AUTHOR RESPONSE ##########[line_break_token][line_break_token]Thanks for the good revision and response that addressed most of my concerns.	Review	O	0
I am bumping up my score.	Review	O	0
[line_break_token][line_break_token]###############################################[line_break_token][line_break_token][line_break_token]This paper presents a Disentangled Inferred Prior (DIP-VAE) method for learning disentangled features from unlabeled observations following the VAE framework.	Review	O	0
The basic idea of DIP-VAE is to enforce the aggregated posterior q(z) = E_x [q(z | x)] to be close to an identity matrix as implied by the commonly chosen standard normal prior p(z).	Review	O	0
The authors propose to moment-match q(z) given it is hard to minimize the KL-divergence between q(z) and p(z).	Review	O	0
This leads to one additional term to the regular VAE objective (in two parts, on- and off-diagonal).	Review	O	0
It has the similar property as beta-VAE (Higgins et al.	Review	O	0
2017) but without sacrificing the reconstruction quality.	Review	O	0
Empirically the authors demonstrate that DIP-VAE can effectively learn disentangled features, perform comparably better than beta-VAE and at the same time retain the reconstruction quality close to regular VAE (beta-VAE with beta = 1).	Review	O	0
[line_break_token][line_break_token]The paper is overall well-written with minor issues (listed below).	Review	B-Review	9
I think the idea of enforcing an aggregated (marginalized) posterior q(z) to be close to the standard normal prior p(z) makes sense, as opposed to enforcing each individual posterior q(z|x) to be close to p(z) as (beta-)VAE objective suggests.	Review	I-Review	9
I would like to make some connection to some work on understanding VAE objective (Hoffman & Johnson 2016, ELBO surgery: yet another way to carve up the variational evidence lower bound) where they derived something along the same line of an aggregated posterior q(z).	Review	O	0
In Hoffman & Johnson, it is shown that KL(q(z) | p(z)) is in fact buried in ELBO, and the inequality gap in Eq (3) is basically a mutual information term between z and n (the index of the data point).	Review	O	0
Similar observations have led to the development of VAMP-prior (Tomczak & Welling 2017, VAE with a VampPrior).	Review	O	0
Following the derivation in Hoffman & Johnson, DIP-VAE is basically adding a regularization parameter to the KL(q(z) | p(z)) term in standard ELBO.	Review	O	0
I think this interpretation is complementary to (and in my opinion, more clear than) the one that‚Äôs described in the paper.	Review	B-Review	9
[line_break_token][line_break_token]My concerns are mostly regarding the empirical studies: [line_break_token][line_break_token]1.	Review	O	0
One of my main concern is on the empirical results in Table 1.	Review	B-Review	1
The disentanglement metric score for beta-VAE is suspiciously lower than what‚Äôs reported in Higgins et al.,	Review	I-Review	1
where they reported a 99.23% disentanglement metric score on 2D shape dataset.	Review	I-Review	1
I understand the linear classier is different, but still the difference is too large to ignore.	Review	I-Review	1
Hence my current more neutral review rating.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Regarding the correlational plots (the bottom row of Table 3 and 4), I don‚Äôt think I can see any clear patterns (especially on CelebA).	Review	B-Review	2
I wonder what‚Äôs the point of including them here and if there is a point, please explain them clearly in the paper.	Review	O	0
[line_break_token][line_break_token]3.	Review	B-Review	3
Figure 2 is also a little confusing to me.	Review	I-Review	3
If I understand the procedure correctly, a good disentangled feature would imply smaller correlations to other features (i.e., the numbers in Figure 2 should be smaller for better disentangled features).	Review	I-Review	3
However, looking at Figure 2 and many other plots in the appendix, I don‚Äôt think DIP-VAE has a clear win here.	Review	I-Review	3
Is my understanding correct?	Review	I-Review	3
If so, what exactly are you trying to convey in Figure 2?	Review	I-Review	3
[line_break_token][line_break_token]Minor comments: [line_break_token][line_break_token]1.	Review	O	0
In Eq (6) I think there are typos in terms of the definition of Cov_q(z)(z)?	Review	B-Review	4
It appears as only the second term in Eq (5).	Review	I-Review	4
[line_break_token][line_break_token]2.	Review	O	0
Hyperparameter subsection in section 3: Shouldn‚Äôt \lambda_od be larger if the entanglement is mainly reflected in the off-diagonal entries?	Review	B-Review	5
Why the opposite?	Review	I-Review	5
[line_break_token][line_break_token]3.	Review	I-Review	3
Can you elaborate on how a running estimate of Cov_p(x)(\mu(x)) is maintained (following Eq (6)).	Review	I-Review	6
It‚Äôs not very clear at the current state of the paper.	Review	I-Review	6
[line_break_token][line_break_token]4.	Review	O	0
Can we have error bars in Table 2?	Review	B-Review	7
Some of the numbers are possibly hitting the error floor.	Review	I-Review	7
[line_break_token][line_break_token]5.	Review	O	0
Table 5 and 6 are not very necessary, unless there is a clear point.	Review	B-Review	8
Thank you for the careful reading of the paper and thoughtful comments!	Reply	O	0
We were not aware of the work [Hoffman & Johnson 2016, ELBO Surgery] and it looks like the method can also be motivated from that perspective.	Reply	O	0
However we are not sure about your note ‚Äúthe inequality gap in Eq (3) is basically a mutual information term between z and n (the index of the data point)‚Äù -- it looks like the gap between KL(q(z|x)||p(z)) and KL(q(z)||p(z)) is the mutual information term between z and n, whereas the Inequality (3) compares KL(q(z|x)||p(z|x)) and KL(q(z)||p(z)).	Reply	B-Reply	9
[line_break_token][line_break_token][[Disentanglement metric score on \beta-VAE:]][line_break_token]We found out that \beta-VAE for \beta=60 was not trained to convergence which now gives the best metric score for \beta-VAE on 2DShapes data (95.7%).	Reply	O	0
We have updated the Table 1 and Figure 1 with new results. [	Reply	B-Reply	1
Higgins et al, 2017] report 99.23% score on 2D shape which is close to what we get.	Reply	I-Reply	1
Apart from the linear classifier, the difference could also be due to the evaluation protocol where in [Higgins et al, 2017]  that trained 30 \beta-VAE models with different random seeds and ‚Äúdiscarded the bottom 50% of the thirty resulting scores and reported the remaining results‚Äù (quoting verbatim from [Higgins et al, 2017]).	Reply	I-Reply	1
We also discovered in this duration that the metric proposed in [Higgins et al, 2017] is not a good indicator of disentanglement seen in the latent traversal plots (ie, decoder‚Äôs output by varying one latent while fixing others).	Reply	I-Reply	1
We added a short section (Sec 3) on the new metric we propose (referred as Separated Attribute Predictability or SAP score) which is much better aligned with the subjective disentanglement we see in the latent traversals.	Reply	I-Reply	1
We have also added plots for SAP score vs reconstruction error (Fig 1 and 2).	Reply	I-Reply	1
[line_break_token][line_break_token][[Correlation plots:]][line_break_token]We agree that these plots were not conveying any insights or quantitative measure for disentanglement.	Reply	O	0
We have omitted them in the revised version.	Reply	B-Reply	2
[line_break_token][line_break_token][[Fig 2 in the submitted version:]][line_break_token]As CelebA dataset has many ground truth attributes which are correlated with each other, it is not possible to infer different dimensions of latents capturing these (at least with the current approaches).	Reply	O	0
Through this plot we were trying to show that the top attributes corresponding to a given dimension are semantically more similar for our method compared to the baselines.	Reply	B-Reply	3
As you rightly noticed this is a subjective question so we have omitted these plots in the revised version.	Reply	I-Reply	3
[line_break_token][line_break_token][[Cov_{q(z)}[z] in Eq 6:]][line_break_token]The first term in Cov_{q(z)}[z] in Eq 5 is a diagonal matrix (expectation of variance of variational posterior, which is a Gaussian with diagonal covariance) and contributes only to the variances of z~q(z), so in the regularizer we had considered only the second term Cov_{p(x)} [\mu(x)] which is a dense square matrix.	Reply	O	0
However we have now included another variant (DIP-VAE-II) where the regularizer uses complete Cov_{q(z)}[z]. This actually provides better results on 2D Shapes data.	Reply	B-Reply	4
[line_break_token][line_break_token][[Hyperparameters \lambda_od and \lambda_d:]][line_break_token]We have included a discussion on this in the paragraph after Eq 5.	Reply	O	0
Essentially, penalizing the off-diagonal entries of Cov_{p(x)} [\mu(x)] also ends up reducing the diagonals of this matrix as off-diagonal are really derived from the diagonals (product of square root of diagonals for each example followed by averaging over examples).	Reply	B-Reply	5
Hence holding the diagonals to a fixed value was important.	Reply	I-Reply	5
We found that \lambda_d > \lamda_od was better for decreasing the covariance without impacting the variance.	Reply	O	0
[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token][[Running estimate of Cov_p(x)(\mu(x)):]][line_break_token]If the estimate using the current minibatch is B and the previous cumulative estimate is C, we take a combination B + a*C with ‚Äòa‚Äô being the inertia parameter (0.95 or so) and then normalize by (1/1-a).	Reply	O	0
C is treated as constant while backpropagating the gradients.	Reply	B-Reply	6

The authors of this paper analyse feed-forward networks of linear rectifier units (RELUs) in terms of the number of regions in which they act linearly.	Review	O	0
 They give an upper bound on the number of regions for networks with a single hidden layer based on known results in geometry, and then show how deeper networks can have a much larger number of regions by constructing examples.	Review	O	0
  The constructions form the main novel technical contribution, and they seem non-trivial and interesting.	Review	O	0
[line_break_token][line_break_token]Overall I think this is a good and interesting paper.	Review	O	0
 It is well written with the notable exception of the proof of theorem 8 and the latter half of the introduction.	Review	O	0
 In most spots, the math is precise and accessible (to me anyway), the results nicely broken into lemmas, and the diagrams are very useful for providing intuition.	Review	O	0
[line_break_token][line_break_token]These results can be interpreted as separating networks with a single hidden layer from deep networks in terms of the types of functions they can efficiently compute.	Review	O	0
 However, number of linear regions is a pretty abstract notion, and it isn't obvious what these results can say about the expressibility by neural nets of functions that we can actually write down.	Review	O	0
 Do you know of any natural examples of functions that require a finite but super-exponential number of regions?	Review	O	0
 [line_break_token][line_break_token]Unfortunately, region counting can't say anything about the representability of functions defined on such input spaces of the form S^n0 where S is a finite set, since there are only |S|^n0 input values, and |S|^n0 < n^n0 = region upper bound.	Review	O	0
[line_break_token][line_break_token][line_break_token]About Theorem 8: [line_break_token][line_break_token]After hours trying to understand the proof of Theorem 8 I gave up.	Review	O	0
 However, I was able to use Prop 7, and intuition provided from the diagrams, to prove a slightly different version of Thm 8 myself, and so I think the result is correct, and the proof is probably trying to describe basically the same thing I came up with (except my proof went from the top layer down, instead of the bottom layer up).	Review	O	0
 So while I don't doubt the correctness of the statement of Thm 8, but the write-up of the proof of Thm 8 needs to be completely redone to be understandable and intuitive.	Review	O	0
 I don't think you need to make it 100% formal (Prop 7 isn't completely formal either, but it's fine as is), but you need to make it possible to understand with a reasonable amount of effort.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]Detailed comments:[line_break_token]---[line_break_token][line_break_token]Title: Please pick a different title.	Review	O	0
 These are feed-forward networks so calling the regions 'inference regions' doesn't make sense.	Review	B-Review	1
[line_break_token][line_break_token]Abs: Why is it 'computational geometry' and not just 'geometry'?	Review	O	0
 What is specifically computational about arrangements of hyperplanes?	Review	O	0
[line_break_token][line_break_token]Page 2: Missing from the review of previous results about the power networks is all of the work done on threshold units (see the papers of Wolfgang Maass for example, or the seminal of Hajnal et al.	Review	B-Review	2
proving lower bounds for shallow threshold networks).	Review	I-Review	2
 Unlike the single paper by Hastad et al.	Review	I-Review	2
cited, none of these require the weights to be non-negative.	Review	I-Review	2
 Moreover, these results are hardly non-realistic, as neural networks with sigmoids can easily simulate thresholds, and under certain assumptions the reverse simulation can be done approximately and reasonably efficiently too.	Review	O	0
[line_break_token][line_break_token]Also missing from this review is recent work of Montufar et al.	Review	B-Review	2
and Martens et al.	Review	I-Review	2
analysing the expressive power of generative models (RBMs).	Review	I-Review	2
[line_break_token][line_break_token]Beginning of page 3: I have a hard time following this high-level discussion.	Review	I-Review	3
 I think this doesn't belong in the introduction, as it is too long and convoluted.	Review	I-Review	3
 Instead, I think you should include such discussion as intuition about your formal constructions *as you give them*.  The way it is written right now, the discussion tries to be intuitive, precise, and comprehensive, and it doesn't really succeed at being any of these.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]Page 3: You should formally define what you mean by 'hyperplane' and 'arrangement'.	Review	I-Review	3
  In particular, a hyperplane is the set of points defined by the equation, not the equation itself.	Review	I-Review	3
 And if an arrangement is taken to be a set of hyperplanes (as per the usual definition), then the statement in Prop 6 isn't formal (although its meaning is still obvious).	Review	I-Review	3
 In particular, how does a ball S 'intersect' with a set of hyperplanes?	Review	I-Review	3
 Do you mean that it intersects with the union of the hyperplanes in the arrangement?	Review	I-Review	3
 I know these are nit-picky points, but if you should try to be technically precise.	Review	I-Review	3
[line_break_token][line_break_token]Page 5: There is a missing reference here: 'Zaslavsky's theorem (?,	Review	I-Review	4
Theorem A)'[line_break_token][line_break_token]Page 5: You should explain the concept of general position precisely.	Review	O	0
 I don't know what 'generic weights' is supposed to mean, the actual definition has to do with lack of colinearity.	Review	B-Review	4
 You might want to point out that any choice of hyperplanes can be infinitesimally perturbed so that they end up in general position.	Review	I-Review	4
[line_break_token][line_break_token]Page 6: 'Relative position' is never formally defined, and it's not immediately obvious what it means.	Review	O	0
[line_break_token][line_break_token]Page 6: The explanation after the statement of Prop 6 is much clearer.	Review	B-Review	5
 Perhaps you should just prove this (stronger) statement directly, and not the fairly opaque and abstract statement made in Prop 6.	Review	I-Review	5
[line_break_token][line_break_token]Figure 3: Why are there 2 dotted circles instead of just 1?	Review	I-Review	6
[line_break_token][line_break_token]Page 7: 'arrangements 2-dimensional essentialization'?	Review	I-Review	7
[line_break_token][line_break_token]Page 7: '{0,...,n}, a < b'  ->  '{0,...,n} s.t.	Review	O	0
a < b'[line_break_token][line_break_token]Page 7: What do you mean by 'independent groups of n0 units within the n units of a layer'?	Review	O	0
 How can a unit be 'within' a unit?	Review	B-Review	7
[line_break_token][line_break_token]Page 7: What do you mean by an 'enumeration' of a 2-dimensional arrangement?	Review	I-Review	7
 [line_break_token][line_break_token][line_break_token]Page 9:  Below the statement of prop 7, it was suggested that the construction would be top down, where each group in a lower layer 'duplicates' the number of regions constructed by the layer above.	Review	O	0
 But the construction given here seems to proceed bottom up... at least in the structure of the proof.	Review	B-Review	8
 This makes it less intuitive.	Review	I-Review	8
[line_break_token][line_break_token]Page 9:  The proof starts out very confusingly.	Review	I-Review	8
 I wasn't able to follow the sentence 'Then we find...'.	Review	I-Review	8
 These 'groups' haven't been formally defined at this stage, only informally alluded to.	Review	I-Review	8
 [line_break_token][line_break_token]And I have another question:  how is Prop 7 actually used here?	Review	O	0
 Merely to establish the existence of network where there is n/n0 regions that each only turn on for different groups Ii?	Review	B-Review	9
 Isn't it trivial to construct such a thing?	Review	I-Review	9
 i.e. take the input weights to the units in a given group to be all the same, and make sure the square n0xn0 matrix formed by taking the weight vector for each group is full-rank (e.g. the identity matrix)?	Review	I-Review	9
[line_break_token][line_break_token]I suspect the reason this doesn't work is that the dimensions would collapse to 1 since each unit in a group would behave identically.	Review	I-Review	10
 However, one could then perturb the final expanded weight matrix to get a general position matrix, so that the subspace associated with each group wouldn't collapse to dimension 1.	Review	I-Review	10
 Is there anything wrong with this?	Review	I-Review	10
 [line_break_token][line_break_token][line_break_token]Page 9: Don't say 'decompose' here.	Review	O	0
 'Decompose' implies you already have weights and are decomposing them into factors.	Review	B-Review	11
 Instead, what you are doing is defining some weights to be a product of particular matrices.	Review	I-Review	11
[line_break_token][line_break_token]You should emphasize that it is a common V shared by all the i.  This is easy to miss.	Review	I-Review	12
[line_break_token][line_break_token][line_break_token]Page 9: What does it mean for a linear map to be 'with Ii-coordinates equal to...'?	Review	I-Review	13
 The 'Ii-coordinates' are the inputs to this map?	Review	I-Review	13
 The outputs?	Review	I-Review	13
[line_break_token][line_break_token]Page 9: What is R_i^(1)?	Review	I-Review	14
 It is never defined.	Review	I-Review	14
 Is it different from the version without the superscript?	Review	I-Review	14
 Is it defined implicitly the first time it is used?	Review	I-Review	14
 If so, what is a 'region of activation values'?	Review	I-Review	14
[line_break_token][line_break_token]What is very confusing is that you use x to define this function, when I had the impression that x was for the original inputs only.	Review	I-Review	15
 This isn't consistent with the h notation you use in figure 1 for example.	Review	I-Review	15
[line_break_token][line_break_token][line_break_token]Page 9: You say that something 'passed through' rho^2 is the 'input' to the second layer.	Review	I-Review	16
 This is the input to the rectifier units without their weights (which I'm guessing are contained in rho^2)?	Review	I-Review	16
 Or is it these units with the 'V' factor part of their weights only, but not the 'U' part?	Review	I-Review	16
 This is all extremely confusing.	Review	I-Review	16
 Without careful definitions of your notation it requires a lot more work on the part of the reader to understand what is going on.	Review	I-Review	16
[line_break_token][line_break_token]Page 9: How can rho_i^(2)(R_i^(1)) be a 'subset' of an subspace that lives in R^(n1)?	Review	I-Review	17
 rho_i^(2)(R_i^(1)) is going to be a set of vectors living in R^(n0)!	Review	O	0
[line_break_token][line_break_token][line_break_token]Page 10:  What do you mean when you say that 'this arrangement is repeated once in each region'?	Review	B-Review	18
 What does it mean for an arrangement to be 'repeated in a region'?	Review	I-Review	18
[line_break_token][line_break_token]I feel like the proof becomes mostly a proof-by-diagram as this point.	Review	I-Review	18
 Maybe you should have started off with this kind of diagram and the intuition of 'duplicating regions', explaining how composing piece-wise linear functions can achieve this kind of thing (which is really the critical point that gets glossed over), and then proceeding to show that you could formally construct each 'piece' required to do this.	Review	I-Review	18
  And you should have done the construction starting at the top layer going down.	Review	I-Review	18
[line_break_token][line_break_token]Having reconstructed the proof in a way that I actually understood it, it seemed that one could also proof that one can (prod_{i=1}^{k-1} n_i)/2^{k-1} * sum_i=0^2 (n_k choose i) regions, which in some cases might be a lot larger than the expression you arrived at.	Review	I-Review	19
  Unlike your Thm 8 does, this version would actually need to use the fact the constructions are 2-dimensional in Prop 7.	Review	I-Review	19
[line_break_token][line_break_token]Page 11:  The asymptotic analysis is just very routine and uninteresting computations and should be in the appendix.	Review	I-Review	20
 It breaks the flow of your paper.	Review	I-Review	20
 I would much prefer to see more detailed commentary about the implications of Thm 8.	Review	I-Review	20
We appreciate the detailed comments of Reviewer 2699.	Reply	O	0
They were very helpful for preparing the present revision of the manuscript.	Reply	O	0
In the following we address all comments of the reviewer and give description of the changes made to the manuscript.	Reply	O	0
[line_break_token][line_break_token]In response to the general comments we [line_break_token][line_break_token]* Changed the title of the manuscript to ``On the number of response regions of deep feedforward networks with piecewise linear activations''[line_break_token][line_break_token]* Shortened the Introduction (and removed an erroneous example that was given there)[line_break_token][line_break_token]* Completely overworked the proof of the former Theorem 8 (now Theorem 1).	Reply	O	0
[line_break_token][line_break_token]* Moved the asymptotic analysis to the appendix[line_break_token][line_break_token]* Included a new section (Section 5) discussing tighter bounds for deep models.	Reply	O	0
[line_break_token][line_break_token]In the following we address the detailed comments.	Reply	O	0
[line_break_token][line_break_token]* ``Computational geometry'' refers to the study of algorithms using geometry.	Reply	O	0
Here, using the word ``computational'' is just a matter of taste.	Reply	B-Reply	2
Our motivation is that a neural network is a computational system and an algorithm (compute output of unit for, sum the outputs of units, etc.).	Reply	I-Reply	2
 [line_break_token][line_break_token]* We included a reference to Hajnal's work in the Introduction.	Reply	O	0
[line_break_token][line_break_token]* We included pointers to the work of Montufar et al.	Reply	O	0
and Martens et al.	Reply	B-Reply	2
in the Introduction.	Reply	I-Reply	2
[line_break_token][line_break_token]* We removed the long discussion from the Introduction and decided, instead, to include an example (Example 1) in the vicinity of the main theorem (Theorem 1).	Reply	O	0
[line_break_token][line_break_token]* We included several definitions and worked on making our formulations more precise.	Reply	O	0
[line_break_token][line_break_token]* We corrected a missing reference to Zaslavsky's work.	Reply	O	0
[line_break_token][line_break_token]* We included the formal definition of ``general position'' and comments on infinitesimal perturbations.	Reply	O	0
[line_break_token][line_break_token]* We no longer use the expression ``relative position'' For clarity, in the previous manuscript, the definition was as follows: Two arrangements have the same relative position if they are combinatorially equivalent, or more formally, if there is a bijection of their intersection posets, where the intersection poset of an arrangement is the set of all nonempty intersection of its hyperplanes partially ordered by reverse inclusion.	Reply	O	0
[line_break_token][line_break_token]* We reformulated the former Proposition 6 in terms of scaling and shifting, moving technical details to the proof, and avoiding the use of the expression ``relative position''.	Reply	O	0
[line_break_token][line_break_token]* We corrected the former Figure 3, which now shows just 1 dotted circle instead of 2.	Reply	O	0
[line_break_token][line_break_token]* We explained the notion of ``essentialization'' in more detail.	Reply	O	0
Proposition 4 describes the combinatorics of-dimensional arrangements with-dimensional essentialization; that is, arrangements of hyperplanes whose intersections with the span of their normal vectors build a-dimensional arrangement (on the span of the normal vectors).	Reply	B-Reply	7
[line_break_token][line_break_token]* We corrected '.	Reply	O	0
[line_break_token][line_break_token]* We improved our formulations, especially about ``independent groups of units'' and ``enumeration'' of the hyperplanes in an arrangement.	Reply	O	0
[line_break_token][line_break_token]* We made significant efforts in clarifying how the construction works, bottom to top.	Reply	O	0
[line_break_token][line_break_token]* We improved the formulations ``we find'', ``groups'', trying to make the arguments more formal and clearer.	Reply	O	0
[line_break_token][line_break_token]* The reviewer asked how Proposition 7 was used in the proof of the theorem.	Reply	O	0
Using the same activation weights for a collection of units would cause them to behave identically.	Reply	B-Reply	9
The entire collection of units would have an output of dimension at most one, which would not be useful for our proof.	Reply	I-Reply	9
Perturbing the weights to produce a full dimensional matrix would work.	Reply	I-Reply	9
A high level proof could be formulated in this way.	Reply	I-Reply	9
We found it important to give an explicit choice of weights for which certain well defined properties hold, instead of relying only on high level arguments, in particular, because this allows us to verify the accuracy of our intuitions.	Reply	I-Reply	9
[line_break_token][line_break_token]In fact, our construction is stable, in the sense that small perturbations of the specified weights cause only small perturbations of the computed function.	Reply	I-Reply	9
The resulting perturbed function has at least as many linear regions as the original one.	Reply	I-Reply	9
[line_break_token] [line_break_token]* The word `decompose' was meant in the opposite way that `compose' is used for compositions of functions,.	Reply	O	0
Thanks for the comment, we tried to use more precise expressions.	Reply	B-Reply	11
[line_break_token][line_break_token]* The reviewer asked [line_break_token]``Page 9: What does it mean for a linear map to be 'with Ii-coordinates equal[line_break_token]to...'?	Reply	O	0
 The 'Ii-coordinates' are the inputs to this map?	Reply	O	0
The outputs? ''	Reply	O	0
[line_break_token][line_break_token]We tried to make this more precise in the revision.	Reply	B-Reply	13
For clarity, the terminology is the standard one: [line_break_token]A ``coordinate'' of a map is any of the functions for.	Reply	I-Reply	13
 Given a subset of, the-coordinates of the map are the functions with.	Reply	I-Reply	13
[line_break_token]For example, if, we can consider the map defined by the-coordinates of, which is the map.	Reply	I-Reply	13
[line_break_token][line_break_token]* The reviewer asked ``What is?	Reply	O	0
It is never defined...''.	Reply	O	0
[line_break_token][line_break_token]We worked on better explaining the notation and using it uniformly.	Reply	B-Reply	14
[line_break_token][line_break_token]* The reviewer wrote ``Page 9: You say that something 'passed through' is the 'input' to the''... [line_break_token][line_break_token]We improved the terminology.	Reply	O	0
[line_break_token][line_break_token]* Also ``Page 9: How can be a 'subset' of an subspace that lives...''[line_break_token][line_break_token]We overworked these parts as well.	Reply	O	0
[line_break_token][line_break_token]* The reviewer suggested a new construction for proving statements about deep models.	Reply	O	0
We do not argue that our construction or our analysis yields the maximal number of regions of linearity.	Reply	B-Reply	18
It merely demonstrates that deep models are exponentially more efficient than shallow models.	Reply	I-Reply	18
In the revision we included a new construction of weights of deep rectifier networks (in Section 5), which shows tighter bounds for certain choices of layer widths.	Reply	I-Reply	18
Other constructions exploiting higher dimensional versions of the former Proposition 7 are worth studying in the future, in order to arrive at yet tighter bounds.	Reply	I-Reply	18
[line_break_token][line_break_token]* We moved the asymptotic analysis to the appendix.	Reply	O	0
In the Discussion we included comments about the number of linear regions computable per parameter	Reply	B-Reply	20

This paper introduces new benchmarks for measuring the robustness of computer vision models to various image corruptions.	Review	O	0
In contrast with the popular notion of ‚Äúadversarial robustness‚Äù, instead of measuring robustness to small, worst-case perturbations this benchmark measures robustness in the average case, where the corruptions are larger and more likely to be encountered at deployment time.	Review	O	0
The first benchmark ‚ÄúImagenet-C‚Äù consists of 15 commonly occurring image corruptions, ranging from additive noise, simulated weather corruptions, to digital corruptions arising from compression artifacts.	Review	O	0
Each corruption type has several levels of severity and overall corruption score is measured by improved robustness over a baseline model (in this case AlexNet).	Review	O	0
The second benchmark ‚ÄúImagenet-P‚Äù measures the consistency of model predictions in a sequence of slightly perturbed image frames.	Review	O	0
These image sequences are produced by gradually varying an image corruption (e.g. gradually blurring an image).	Review	O	0
The stability of model predictions is measured by changes in the order of the top-5 predictions of the model.	Review	O	0
More stable models should not change their prediction to minute distortions in the image.	Review	O	0
Extensive experiments are run to benchmark recent architecture developments on this new benchmark.	Review	O	0
It‚Äôs found that more recent architectures are more robust on this benchmark, although this gained robustness is largely due to the architectures being more accurate overall.	Review	O	0
Some techniques for increasing model robustness are explored, including a recent adversarial defense ‚ÄúAdversarial Logit Pairing‚Äù, this method was shown to greatly increase robustness on the proposed benchmark.	Review	O	0
The authors recommend future work benchmark performance on this suite of common corruptions without training on this corruptions directly, and cite prior work which has found that training on one corruption type typically does not generalize to other corruption types.	Review	O	0
Thus the benchmark is a method for measuring model performance to ‚Äúunknown‚Äù corruptions which should be expected during test time.	Review	O	0
[line_break_token][line_break_token]In my opinion this is an important contribution which could change how we measure the robustness of our models.	Review	O	0
Adversarial robustness is a closely related and popular metric but it is extremely difficult to measure and reported values of adversarial robustness are continuously being falsified [1,2,3]. In contrast, this benchmark provides a standardized and computationally tractable benchmark for measuring the robustness of neural networks to image corruptions.	Review	O	0
The proposed image corruptions are also more realistic, and better model the types of corruptions computer vision models are likely to encounter during deployment.	Review	O	0
I hope that future papers will consider this benchmark when measuring and improving neural network robustness.	Review	B-Review	3
It remains to be seen how difficult the proposed benchmark will be, but the authors perform experiments on a number of baselines and show that it is non-trivial and interesting.	Review	I-Review	3
At a minimum, solving this benchmark is a necessary step towards robust vision classifiers.	Review	I-Review	3
[line_break_token][line_break_token]Although I agree with the author‚Äôs recommendation that future works not train on all of the Imagenet-C corruptions, I think it might be more realistic to allow training on a subset of the corruptions.	Review	I-Review	1
The reason why I mention this is it‚Äôs unclear whether or not adversarial training should be considered as performing data augmentation on some of these corruptions, it certainly is doing some form of data augmentation.	Review	I-Review	1
Concurrent work [4] has run experiments on a resnet-50 for Imagenet and found that Gaussian data augmentation with large enough sigma (e.g. sigma = .4 when image pixels are on a [0,1] scale) does improve robustness to pepper noise and Gaussian blurring, with improvements comparable to that of adversarial training.	Review	I-Review	1
Have the authors tried Gaussian data augmentation to see if it improves robustness to the other corruptions?	Review	I-Review	1
I think this is an important baseline to compare with adversarial training or ALP.	Review	I-Review	1
[line_break_token][line_break_token]Few specific comments/typos:[line_break_token][line_break_token]Page 2 ‚Äúl infinity perturbations on small images‚Äù[line_break_token][line_break_token]The (Stone, 1982) reference is interesting, but it‚Äôs not clear to me that their main result has implications for adversarial robustness.	Review	I-Review	2
Can the authors clarify how to map the L_p norm in function space of ||T_n - T(theta) || to the traditional notion of adversarial robustness?	Review	I-Review	2
[line_break_token][line_break_token]1.	Review	O	0
<a href="https://arxiv.org/pdf/1705.07263.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1705.07263.pdf</a>[line_break_token]2.	Review	O	0
<a href="https://arxiv.org/pdf/1802.00420.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.00420.pdf</a>[line_break_token]3.	Review	O	0
<a href="https://arxiv.org/pdf/1607.04311.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1607.04311.pdf</a>[line_break_token]4.	Review	O	0
<a href="https://openreview.net/forum?id=S1xoy3CcYX&noteId=BklKxJBF57" target="_blank" rel="nofollow">https://openreview.net/forum?id=S1xoy3CcYX&noteId=BklKxJBF57</a>	Review	O	0
Thank you for your interest in this topic and your analysis of our paper.	Reply	O	0
[line_break_token][line_break_token]‚ÄúI think it might be more realistic to allow training on a subset of the corruptions.	Reply	O	0
‚Äù[line_break_token]Researchers could train on various other corruptions, such as film grain, adversarial noise, HSV noise, uniform noise,[line_break_token]high-pass filtering, median blur, spherical camera distortions, pincushion distortions, out-of-distribution object occlusions, stylized images ( <a href="https://openreview.net/forum?id=Bygh9j09KX" target="_blank" rel="nofollow">https://openreview.net/forum?id=Bygh9j09KX</a> ), lens scratches, image quilting, color quantization, etc.	Reply	O	0
We have updated the text to make it clearer that researchers can train on more than just cropped and flipped images, but we still do not want researchers training on the test corruptions.	Reply	B-Reply	1
In the paper we experimented with uniform noise data augmentation in the stability training experiment and found minor perturbation robustness gains, but not with Gaussian noise with a large standard deviation.	Reply	I-Reply	1
[line_break_token][line_break_token]Thank you for pointing out that the brief Stone comment requires much more context.	Reply	I-Reply	1
For that reason we have removed the citation.	Reply	I-Reply	1
Essentially, if f is a model and f^\hat is an approximation, and if input x is d-dimensional, then if we want | f(x) - f^\hat (x) | < epsilon, then in some scenarios the number of samples necessary is ~ epsilon^{-d}. Other context is on slide 10 of <a href="https://github.com/joanbruna/MathsDL-spring18/blob/master/lectures/lecture1.pdf" target="_blank" rel="nofollow">https://github.com/joanbruna/MathsDL-spring18/blob/master/lectures/lecture1.pdf</a>[line_break_token][line_break_token]‚Äúl infinity perturbations on small images‚Äù[line_break_token]Thanks to your suggestion, we have changed this to ‚Äúperturbations on small images.	Reply	O	0
‚Äù We kept the word ‚Äúsmall‚Äù as the images often have side length 32 pixels.	Reply	B-Reply	2
We removed ‚Äúl_infinity‚Äù since that method has had some success for perturbations which are small in an l_2 sense	Reply	I-Reply	2

This paper introduces a new method for training a classifier that simultaneously optimizes for a fairness criterion and robustness to data poisoning.	Review	O	0
The method is shown to increase measures of fairness and reduce inaccuracy on poisoned data relative to classifiers that only consider accuracy or fairness.	Review	O	0
Extensive results are shown for both synthetic and real benchmark data sets.	Review	O	0
[line_break_token][line_break_token]I would lean to reject for the following reasons: 1) the problem is not well-motivated.	Review	O	0
I would like a more clear example of some problem with sensitive attributes in which the data is publicly available and the providers of the data are motivated to falsify it.	Review	B-Review	1
2) the contribution is very simple and the individual pieces do not seem to be significant contributions.	Review	O	0
In particular, the use of GANs for fairness is previously done, and the use of the GAN for robustness here seems too simple to be broadly useful 3) the results are less convincing than they might otherwise be because none of the competing methods tested make use of a clean validation set 4) the paper is somewhat unpolished.	Review	O	0
I find the results difficult to read, although the arrows are helpful, and it is not clear to me whether these results are on a test set or the training set.	Review	B-Review	4
[line_break_token][line_break_token]Lack of convincing tests for robustness: It is disappointing that FR-GAN does not offer any promises to be robust in general.	Review	I-Review	5
Despite access to a clean validation set, the classifier is trained only to ignore the type of data poisoning that exists in the training set.	Review	I-Review	5
If the test set were out of distribution in a different way relative to the training set, I see no reason to believe FR-GAN would protect against this.	Review	I-Review	5
Furthermore, because it is not stated that these are test set results, I am not certain that they are not training set results, in which case some performance may be due to overfitting.	Review	I-Review	5
[line_break_token][line_break_token]Minor notes:[line_break_token][line_break_token]It would be nice for comparison if the charts had the same axes throughout.	Review	O	0
[line_break_token][line_break_token]What are the numbers of nodes used in the hidden layers?	Review	B-Review	6
hanks for the insightful comments.	Reply	O	0
[line_break_token][line_break_token]Q3-1. (	Reply	O	0
1) motivation[line_break_token][line_break_token]A3-1.	Reply	O	0
[line_break_token]We believe that given that real data would increasingly become both biased and poisoned (this is what we expect in the big data era - see the next paragraph for details), our main contribution of providing an integrated solution for fair and robust training is likely to become important in the near future.	Reply	B-Reply	1
[line_break_token][line_break_token]We contend that supporting robust training is just as critical as fair training.	Reply	I-Reply	1
Dataset searching is becoming mainstream as demonstrated by Google Dataset Search (Goods) [1] and its public version for searching scientific datasets [2]. While data lakes within companies may consist of refined datasets, datasets in the public are easy to poison.	Reply	I-Reply	1
In our experiments, we could easily poison the Adult and COMPAS datasets using simple label flipping techniques.	Reply	I-Reply	1
And anyone can poison public datasets using attacks in the literature and share them.	Reply	I-Reply	1
We thus believe that it is essential to address both bias and poisoning as a preventive measure.	Reply	I-Reply	1
We reflected these points in our revision (Section 1, highlighted in blue).	Reply	I-Reply	1
[line_break_token][line_break_token][1] Goods: Organizing Google's Datasets, ACM SIGMOD 2017.	Reply	O	0
[line_break_token][2] Google Dataset Search: Building a search engine for datasets in an open Web ecosystem, WWW 2019.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q3-2. (	Reply	O	0
2) contributions[line_break_token][line_break_token]A3-2.	Reply	O	0
[line_break_token]We agree that the fairness part of FR-GAN is similar to Adversarial Debiasing (AD) [3]. However, we strengthen the theoretical results of AD using information theory, and this motivates us to propose a novel robust training discriminator.	Reply	B-Reply	2
We agree that the key insight of using adversarial training to minimize mutual information between the prediction and sensitive attribute is the same for FR-GAN and AD.	Reply	I-Reply	2
Although, the end algorithms of FR-GAN and AD are also similar, our paper plays a role in providing systematic methodology not only for various fairness metrics, but also for the design of robust training.	Reply	I-Reply	2
As far as we know, no other validation-set-based approach (including Ren et.	Reply	I-Reply	2
al.	Reply	I-Reply	2
2018) leverages the idea of adversarial training.	Reply	I-Reply	2
We reflected these points in our revision (Section 2, highlighted in blue).	Reply	I-Reply	2
[line_break_token][line_break_token][3] Mitigating Unwanted Biases with Adversarial Learning, AAAI 2018.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Q3-3. (	Reply	O	0
3) competing methods[line_break_token][line_break_token]A3-3.	Reply	O	0
[line_break_token]As Reviewer 2 mentioned, FR-GAN is one of the first works to address both fairness and robustness and that there are few baselines to compare with.	Reply	B-Reply	3
Hence, we employed one reasonable baseline, which first sanitizes the poisoned data using a well-known sanitization technique and then performs a fair training (see Tables 1 and 2, rows with +LD).	Reply	I-Reply	3
We clarified these points in our revision (Section 5.1, highlighted in blue).	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Q3-4. (	Reply	O	0
4) writeup[line_break_token][line_break_token]A3-4.	Reply	O	0
[line_break_token]All of our results are on a separate test set.	Reply	B-Reply	4
We clarified this in our revision (Section 5, highlighted in blue) to avoid any confusion.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]Q3-5.	Reply	O	0
Lack of convincing tests for robustness[line_break_token][line_break_token]A3-5.	Reply	O	0
[line_break_token]We agree that generalizing to all poisoning attacks is important.	Reply	B-Reply	5
If we know all possible attacks, we can construct a training set containing these attacks.	Reply	I-Reply	5
In the more challenging case where we do not know which attacks even exist, there seems to be a fundamental limitation in protecting against the attacks.	Reply	I-Reply	5
Generalization is a universal problem in machine learning where a model trained on one dataset is not guaranteed to perform well in another dataset with a different distribution.	Reply	I-Reply	5
Although the generalization is a critical issue to address, we think it is beyond the scope of the current work.	Reply	I-Reply	5
We reflected these points in our revision (Section 6, highlighted in blue).	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]Q3-6.	Reply	O	0
Minor notes[line_break_token][line_break_token]A3-6.	Reply	O	0
[line_break_token]We will display the figures with the same axes throughout in our revision.	Reply	B-Reply	6
We added the information about the number of nodes in the hidden layers in our revision (Appendix A.4, highlighted in blue).	Reply	I-Reply	6

[line_break_token]Pros:[line_break_token]The paper shows that we could have a better document/sentence embedding by partitioning the word embedding space based on a topic model and summing the embedding within each partition.	Review	O	0
The writing and presentation of the paper are clear.	Review	O	0
The method is simple, intuitive, and the experiments show that this type of method seems to achieve state-of-the-art results on predicting semantic similarity between sentences, especially for longer sentences.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]The main concern is the novelty of this work.	Review	O	0
The method is very similar to SCDV (Mekala et al.,	Review	B-Review	1
2017).	Review	I-Review	1
The high-level flow figure in appendix H is nearly identical as the Figure 1 and 2 in Mekala et al.,	Review	I-Review	1
2017.	Review	I-Review	1
The main difference seems to be that this paper advocates K-SVD (extensively studies in Arora et al.	Review	I-Review	1
2016) as their topic model and SCDV (Mekala et al.,	Review	I-Review	1
2017) uses GMM.	Review	I-Review	1
[line_break_token]However, in the semantic similarity experiments (STS12-16 and Twitter15), the results actually use GMM.	Review	I-Review	1
So I suppose the results tell us that we can achieve state-of-the-art performances if you directly combine tricks in SIF (Arora et al.,	Review	I-Review	1
2017) and tricks in SCDV (Mekala et al.,	Review	I-Review	1
2017).	Review	I-Review	1
[line_break_token]In the document classification experiment, the improvement looks small and the baselines are not strong enough.	Review	I-Review	2
The proposed method should be compared with other strong unsupervised baselines such as ELMo [1] and p-mean [2].[line_break_token][line_break_token]Overall:[line_break_token]The direction this paper explores is promising but the contributions in this paper seem to be incremental.	Review	O	0
I suggest the authors to try either of the following extensions to strengthen the future version of this work.	Review	B-Review	3
[line_break_token]1.	Review	I-Review	3
In addition to documentation classification, show that the embedding is better than the more recent proposed strong baselines like ELMo in various downstream tasks.	Review	I-Review	3
[line_break_token]2.	Review	I-Review	9
Derive some theories.	Review	I-Review	3
One possible direction is that I guess the measuring the document similarity based on proposed embedding could be viewed as an approximation of Wasserstein similarity between the all the words in both documents.	Review	I-Review	3
The matching step in Wasserstein is similar to the pooling step in your topic model.	Review	I-Review	3
You might be able to say something about how good this approximation is.	Review	I-Review	3
Some theoretical work about doing the nearest neighbor search based on vector quantization might be helpful in this direction.	Review	I-Review	3
[line_break_token][line_break_token]Minor questions:[line_break_token]1.	Review	O	0
I think another common approach in sparse coding is just to apply L1 penalty to encourage sparsity.	Review	B-Review	4
Does this K-SVD optimization better than this L1 penalty approach?	Review	I-Review	4
[line_break_token]2.	Review	I-Review	9
How does the value k in K-SVD affect the performances?	Review	I-Review	5
[line_break_token]3.	Review	I-Review	9
In Aorora et al.	Review	I-Review	6
2016b, they constrain alpha to be non-negative.	Review	I-Review	6
Did you do the same thing here?	Review	I-Review	6
[line_break_token]4.	Review	I-Review	9
How important this topic modeling is?	Review	I-Review	7
If you just randomly group words and sum the embedding in the group, is that helpful?	Review	I-Review	7
[line_break_token]5.	Review	I-Review	9
In Figure 2, I would also like to see another curve of performance gain on the sentences with different lengths using K-SVD rather than GMM.	Review	I-Review	8
[line_break_token] [line_break_token]Minor writing suggestions:[line_break_token]1.	Review	O	0
In the 4th paragraph of section 3, "shown in equation equation 2", and bit-wise should be element-wise[line_break_token]2.	Review	B-Review	9
In the 4th paragraph of section 4, I think the citation after alternating minimization should be Arora et al.	Review	I-Review	9
2016b and Aharon et al.	Review	I-Review	9
2006 rather than Arora et al.,	Review	I-Review	9
2016a[line_break_token]3.	Review	I-Review	9
In the 2nd paragraph of section 6.1, (Jeffrey Pennington, 2014) should be (Pennington et al.,	Review	I-Review	9
2014).	Review	I-Review	9
In addition, the author order in the corresponding Glove citation in the reference section is incorrect.	Review	I-Review	9
The correct order should be Jeffrey Pennington, Richard Socher, Christopher D. Manning.	Review	I-Review	9
[line_break_token]4.	Review	I-Review	9
In the 3rd paragraph of section 6.1, "Furthermore, Sentence"[line_break_token]5.	Review	I-Review	9
In the 6th paragraph of section 6.1, I thought skip-thoughts and Sent2Vec are unsupervised methods.	Review	I-Review	9
[line_break_token]6.	Review	I-Review	9
In Table 2 and 3, it would be easier to read if the table is transposed and use the longer name for each method (e.g., use skip-thought rather than ST)[line_break_token]7.	Review	I-Review	9
In Table 2,3,4,5, it would be better to show the dimensions of embedding for each method[line_break_token]8.	Review	I-Review	9
Table 10 should also provide F1[line_break_token]9.	Review	I-Review	9
Which version of GMM is used in STS experiment?	Review	I-Review	9
The one using full or diagonal covariance matrix?	Review	I-Review	9
[line_break_token][line_break_token][line_break_token][1] Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018).	Review	O	0
Deep contextualized word representations.	Review	O	0
NAACL[line_break_token][2] R√ºckl√©, A., Eger, S., Peyrard, M., & Gurevych, I. (2018).	Review	O	0
Concatenated p-mean Word Embeddings as Universal Cross-Lingual Sentence Representations.	Review	O	0
arXiv preprint arXiv:1803.01400.	Review	O	0
Apologies for the delay in response.	Reply	O	0
We would like to thank the reviewer for evaluating our manuscript.	Reply	O	0
We have tried to address the reviewer concerns in a proper way and believe that our paper has improved.	Reply	O	0
We would be happy to make further corrections and look forward to hearing from you soon.	Reply	O	0
We respond to the questions and concerns in the following points:[line_break_token][line_break_token]1.	Reply	O	0
We agree that the methods draw inspiration from the SCDV (Mekala et al.,	Reply	B-Reply	1
2017).	Reply	I-Reply	1
However, there are major differences between SCDV (Mekala et al.,	Reply	I-Reply	1
2017) and this work:[line_break_token][line_break_token]a) SCDV (Mekala et al.,	Reply	I-Reply	1
2017) uses GMM whereas P-SIF uses k-svd (Arora et al.	Reply	I-Reply	1
2016) for topic modelling.	Reply	I-Reply	1
It should be noted that we did not apply manual hard thresholding over final documents representation as the method in SCDV did.	Reply	I-Reply	1
Because of k-svd we implicitly put the sparsity constraint during clustering.	Reply	I-Reply	1
This yields several other benefits such as sparser documents thus reducing space and time complexity.	Reply	I-Reply	1
For single sentence datasets (STS 12-16 and Twitter15), we found out that both GMM and k-svd work really well.	Reply	I-Reply	1
GMM works slightly better as it is much easier to optimize compared to k-svd.	Reply	I-Reply	1
We also noted for these datasets the total number of clusters is small.	Reply	I-Reply	1
However, for datasets containing multiple sentences such as 20NewsGroup and Reuters (200-500-word documents), k-svd outperforms GMM a.k.a P-SIF outperforms SCDV.	Reply	I-Reply	1
Additionally, using k-svd leads to a fewer number of total clusters and hence fewer dimensions of document vectors for better representations.	Reply	I-Reply	1
As a result, the feature formation, training and prediction time are faster.	Reply	I-Reply	1
We will add time and space complexity results in the paper as well.	Reply	I-Reply	1
[line_break_token][line_break_token]b) We used the SIF weighting and common component removal in P-SIF, whereas SCDV used tf-idf.	Reply	O	0
SIF (Arora et.	Reply	B-Reply	1
al.	Reply	I-Reply	1
2017) has shown the benefit of using such weighting and common component removal.	Reply	I-Reply	1
We have successfully generalized SIF (Arora et.	Reply	I-Reply	1
al.	Reply	I-Reply	1
2017) using the ideas from the SCDV paper.	Reply	I-Reply	1
Additionally, SCDV used SGNS-initialised word vectors, whereas P-SIF used Doc2VecC-initialised word vectors.	Reply	I-Reply	1
Also, in Doc2VecC the averaging is based on sentence representation and training of word vectors is done jointly with corruptions.	Reply	I-Reply	1
This kind of training with corruption results in zeroing of common words' word vectors.	Reply	I-Reply	1
However, since our approach is about partition based averaging such as zeroing, we can yield more robust document representation.	Reply	I-Reply	1
We will add more downstream tasks which were requested by the reviewer as well.	Reply	I-Reply	1
It should be noted that we have more thorough experiments on 26 STS similarity and 2 text classification datasets of the SCDV paper (28 in total).	Reply	I-Reply	1
[line_break_token][line_break_token]The proposed baselines in document classification are taken from a very recently published paper (2017-2018).	Reply	I-Reply	2
As suggested by reviewer we will add more baselines such as the Elmo [1] and p-mean [2] for text classification.	Reply	I-Reply	2
We didn't find the baselines for our reported datasets, but we have found the code to run on our datasets.	Reply	I-Reply	2
[line_break_token][line_break_token]Minor Questions:[line_break_token]1.	Reply	O	0
Yes, but directly optimising the L1 is an NP-hard objective.	Reply	B-Reply	4
So k-svd does an alt-min (Arora et al.	Reply	I-Reply	4
2016b and Aharon et al.	Reply	I-Reply	4
2006) between clustering and thresholding to achieve the require sparsity.	Reply	I-Reply	4
[line_break_token]2.	Reply	O	0
We keep the k small, unlike other normal k-svd applications as we know that in text each word has a very limited number (< 5) of total senses.	Reply	O	0
We use the procedure similar to (Arora et al.	Reply	B-Reply	5
2016b) to choose the optimal k. For our experiments, we take k equal to the total_clusters of clusters (K) divided by 10, which is a good approximation.	Reply	I-Reply	5
[line_break_token]3.	Reply	O	0
Yes, if we randomly average words in same clusters and analyze the top dominant words in the clusters, we observe words with similar meanings are close to each other.	Reply	B-Reply	7
A similar observation was reported by (Mekala et al.,	Reply	I-Reply	7
2017) and (Arora et al.	Reply	I-Reply	7
2016b).	Reply	I-Reply	7
[line_break_token]4.	Reply	O	0
We will plot the point.	Reply	B-Reply	8
Our institution is that initially for small length documents GMM and K-svd perform equally well (GMM may be slightly better due to easier optimization) but later for long length documents k-svd will easily outperform GMM with a fewer lesser number of clusters as reported in the text classification.	Reply	I-Reply	8
[line_break_token]5.	Reply	I-Reply	3
We used the full covariance matrix of the GMM in our paper.	Reply	I-Reply	6
[line_break_token][line_break_token]We thank the reviewer for providing helpful directions for theoretical derivations [line_break_token]We were having doubts about how to proceed with the theoretical analyzes.	Reply	I-Reply	3
The idea of measuring the document similarity based on P-SIF embedding and viewing it as an approximation of Wasserstein similarity between all the words in both documents seem interesting.	Reply	I-Reply	3
As stated, the matching step in Wasserstein is indeed similar to the pooling step in our topic model.	Reply	I-Reply	3
We will also delve into the theoretical work on doing the nearest neighbour search on vector quantizations.	Reply	I-Reply	3
Thanks for your suggestion.	Reply	I-Reply	3
We pinned down atleast one relevant paper: <a href="http://proceedings.mlr.press/v37/kusnerb15.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v37/kusnerb15.pdf</a> .	Reply	O	0
[line_break_token][line_break_token]Minor writing corrections[line_break_token]We made the correction suggested in the revised version.	Reply	O	0
We didn't transpose the table due to page limitation	Reply	B-Reply	9

This paper proposes two sparsifying methods of computing attention weights, dubbed sparsemax and TVmax, which appear to slightly improve objective and subjective image captioning scores.	Review	O	0
   The sparsifying projections are posed as optimization problems, and algorithms for their computation, along with formula for their gradients are given.	Review	O	0
 Proof of the optimality of these algorithms relies significantly on prior work, so could not be checked deeply without bringing in additional sources.	Review	O	0
 [line_break_token][line_break_token]It is not clear that the motivation for these sparsifying objectives is sound.	Review	O	0
  The conventional softmax approach to attention weights should be capable of producing attention weights near zero, which would be effectively sparse, especially if the pre-activations, z_i, in equation (1), are allowed to have a large enough range.	Review	B-Review	1
  It's not clear why weights should need to be zero exactly in the ignored regions, since being near zero should be sufficient to contribute almost nothing to the subsequent weighted sum.	Review	I-Review	1
   So it is also not clear why the strict sparsity itself, as opposed to the effective sparsity of the softmax, should explain the differences in Figure 1, and in the results.	Review	I-Review	1
 In particular it is unclear why the strict sparsity should prevent repetition; when looking at the weight distributions in the two cases, a more likely story seems to be that the weight distributions don't repeat as much from one word to the next in the second case, but there is no clear reason to attribute this to sparsity.	Review	I-Review	1
  The pictures of the attention weights are lacking a color scale, so it is impossible to see how close to zero it comes in the unattended regions, although the gray color values chosen for these regions might be misleading.	Review	I-Review	1
[line_break_token]The TVmax approach, in addition to sparsity, also constrains the non-zero region to be contiguous.	Review	O	0
  To the extent that this improves performance, this presumably introduces an inductive bias that matches the data.	Review	O	0
  It is unclear why this fails to produce better objective scores than sparsemax, while producing better human ratings.	Review	B-Review	3
  In any case it is not clear why this should necessarily be a good inductive bias for all images, although it is plausible that it helps in some cases.	Review	I-Review	3
 [line_break_token]In many neural network problems, what makes a difference has more to do with the optimizability of the gradients, than the specific activations per se, and that might be the case here too, although the paper does not analyze this aspect of the proposed models.	Review	I-Review	3
  [line_break_token][line_break_token]Overall the paper is flawed by the lack of clarity in the motivation for the proposed methods, and the lack of retrospective analysis and understanding of why the proposed methods should improve results.	Review	O	0
[line_break_token]	Review	O	0
hank you for your detailed comments.	Reply	O	0
The main points you raised are related to 1) the motivation for our proposed method and 2) the analysis and understanding of why it improves results.	Reply	O	0
We clarify these two points below and we added new analyses to the revised version of the paper to help understanding where the improvements come from.	Reply	O	0
[line_break_token][line_break_token]1) Motivation for our proposed method.	Reply	O	0
[line_break_token]While softmax may lead to attention weights near zero, prior work [1,2,3,4] shows that it has the tendency of accumulating too much probability mass on a long tail of irrelevant features, which may harm model performance.	Reply	B-Reply	1
In contrast, sparse attention mechanisms are able to select only a small set of features, with improved attention focus.	Reply	I-Reply	1
In the refs above, the success of sparse attention has been shown for NLP tasks such as machine translation, textual entailment, summarization, and morphological inflection.	Reply	I-Reply	1
The main motivation for this work is to test if this hypothesis also holds for a significantly different task, image captioning, where attention is visual.	Reply	I-Reply	1
Our findings confirm those of Xu et al. [	Reply	I-Reply	1
5], who obtained better results and improved interpretability with hard attention over softmax.	Reply	I-Reply	1
However, their approach is not end-to-end differentiable, requiring imitation learning or Monte Carlo policy gradient approximations, while ours is differentiable and can be used as a drop-in replacement for softmax.	Reply	I-Reply	1
To further induce structural bias on top of sparsity (important when we want to exploit spatial correlations in visual tasks), we proposed TVmax, that promotes selection of contiguous regions.	Reply	I-Reply	1
We will make these motivations clearer in the final version of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]2) Analysis and understanding of why it improves results.	Reply	O	0
[line_break_token]Thank you for suggesting a color scale to facilitate the visualization of the attention plots -- we included it in the new version of the paper.	Reply	B-Reply	2
The sparsity benefits are qualitatively illustrated in Figure 1 and 3: we can observe that when using sparsemax and TVmax the weights given to the relevant regions are much higher than the ones given when using softmax, while the non relevant regions receive zero attention.	Reply	I-Reply	2
This is corroborated by the human attention evaluation.	Reply	I-Reply	2
It also confirms our motivation for TVmax that by focusing in contiguous regions, high attention weights can be attributed to compact objects, improving their detection.	Reply	I-Reply	2
[line_break_token]Moreover, human evaluation scores and automatic REP scores are considerably higher when using TVmax.	Reply	I-Reply	2
This happens even though TVmax generates longer sentences.	Reply	I-Reply	2
[line_break_token][line_break_token]We posit that the reasons behind the decrease in the number of repetitions are two-fold:[line_break_token]- By using softmax, some attention (even if small) is given to all regions of the image in every time step, even those that are not relevant for the word being generated (see point 1 above).	Reply	I-Reply	2
Consequently, the feature vector obtained is more similar between time steps than with sparsemax or TVmax, possibly leading to the generation of the same word repeatedly.	Reply	I-Reply	2
This is in agreement with your intuition that the smaller number of repetitions is caused by the weight distributions not repeating as much.	Reply	I-Reply	2
[line_break_token]- Focusing on compact regions of the image leads to the detection of more objects, which can lead to less repetitions.	Reply	I-Reply	2
[line_break_token][line_break_token]To corroborate the first point, we measured the Jensen-Shannon divergence (JS) between the attention probabilities for each time step of the captions correspondent to the MSCOCO test set images.	Reply	I-Reply	2
The mean JS values are 0.12, 0.29, and 0.34 for softmax, sparsemax, and TVmax, respectively.	Reply	I-Reply	2
This confirms our intuition that sparsemax and TVmax lead to less similar attention distributions across time steps and, consequently, to less repetitions.	Reply	I-Reply	2
We report this statistic in the new version of the paper.	Reply	I-Reply	2
[line_break_token][line_break_token]Note that this decrease of repetitions is consistent with previous findings in sequence-to-sequence models (machine translation) which has shown that sparsemax has much lower propensity for repetitions than softmax (see ref [1] below, Table 1, which reports consistently better REP scores for several language pairs).	Reply	I-Reply	2
[line_break_token][line_break_token][1] C. Malaviya, P. Ferreira, and A. Martins.	Reply	O	0
Sparse and constrained attention for neural machine translation.	Reply	O	0
ACL 2018.	Reply	O	0
<a href="https://www.aclweb.org/anthology/P18-2059.pdf" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/P18-2059.pdf</a>[line_break_token][line_break_token][2] A. Martins and R. Astudillo.	Reply	O	0
From softmax to sparsemax: A sparse model of attention and multi-label classification.	Reply	O	0
ICML 2016.	Reply	O	0
<a href="http://proceedings.mlr.press/v48/martins16.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v48/martins16.pdf</a>[line_break_token][line_break_token][3] V. Niculae and M. Blondel.	Reply	O	0
A regularized framework for sparse and structured neural attention.	Reply	O	0
NeurIPS 2017.	Reply	O	0
[line_break_token]<a href="https://papers.nips.cc/paper/6926-a-regularized-framework-for-sparse-and-structured-neural-attention.pdf" target="_blank" rel="nofollow">https://papers.nips.cc/paper/6926-a-regularized-framework-for-sparse-and-structured-neural-attention.pdf</a>[line_break_token][line_break_token][4] B. Peters, V. Niculae, and A. Martins.	Reply	O	0
Sparse sequence-to-sequence models.	Reply	O	0
ACL 2019.	Reply	O	0
[line_break_token]<a href="https://www.aclweb.org/anthology/P19-1146.pdf" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/P19-1146.pdf</a>[line_break_token][line_break_token][5] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, and Y. Bengio.	Reply	O	0
Show, attend and tell: Neural image caption generation with visual attention.	Reply	O	0
ICML 2015.	Reply	O	0
<a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v37/xuc15.pdf</a	Reply	O	0

Summary: The paper considers a variational inference strategy for learning neural networks with binary weights.	Review	O	0
In particular, the paper proposes using a structured recognition model to parameterise the variational distribution, which couples the weights in different layers/filters in a non-trivial way.	Review	O	0
The gradient of the expected likelihood term in the variational lower bound is estimated using the REINFORCE estimator.	Review	O	0
This paper adjusts this estimator to use the gradient of the log-likelihood wrt the samples.	Review	O	0
Experiments on several image classification tasks are provided.	Review	O	0
[line_break_token][line_break_token]evaluation:[line_break_token][line_break_token]pros:[line_break_token]- the idea of the proposed approach is interesting: using variational inference for binary weight neural networks.	Review	O	0
While recent work on VI for discrete variables only focused on discrete latent variable models, this work shows how VI can be used for binary neural networks.	Review	O	0
[line_break_token] [line_break_token]cons:[line_break_token]- the writing, in my opinion, needs to be improved [see my comments below]. The VI presentation is cluttered and the justification of using the pseudo-reward for reinforce is not clear.	Review	O	0
[line_break_token]- the experimental results are mixed and it's not clear to me how to interpret them/compare to the baselines -- what is the goal here: computational efficiency, compression or accuracy?	Review	O	0
[line_break_token][line_break_token]Some specific questions/comments:[line_break_token][line_break_token]+ What is the input of the policy/recognition network?	Review	O	0
It's not clear from the paper whether this includes the inputs of the current batch or outputs or both?	Review	B-Review	3
If so, how are variable batch sizes handled?	Review	I-Review	3
What is the input to this network at test time?	Review	I-Review	3
In contrast to generative models/VAEs, the weights here are global parameters and it's not clear to me these should be varied for different data batches.	Review	I-Review	3
[line_break_token][line_break_token]+ related to the question above: how is prediction handled at test time?	Review	O	0
Say the parameters of the variational distribution over weights are generated using the recognition network, then 100 weights are sampled given these parameters which then give 100 predictions -- should these be then averaged out to get the final prediction?	Review	B-Review	4
I'm not quite sure I understand why the paper chose to *pick the best one* out of 100 predictions and the justification/criterion for this procedure.	Review	I-Review	4
 [line_break_token][line_break_token]+ The writing is not very clear at places, and it does not help that the references being merged with the text.	Review	O	0
I'm also not sure about some of the technical jargons/terms used in the papers:[line_break_token]- reinforcement learning: is this really a reinforcement learning problem?	Review	B-Review	5
If you tackle this problem from a pure variational perspective, reinforce is used to obtain the gradient of the expected log-likelihood wrt the variational parameters.	Review	I-Review	5
But instead of using the log likelihood, a learning signal that depends on the gradient of the log-likelihood is used.	Review	I-Review	5
[line_break_token]- concrete weights -- what are these?	Review	I-Review	5
I assume they are just binary weights sampled from the variational approximation.	Review	I-Review	5
[line_break_token]- middle of page 3: p(w|X, Y) = p_\theta(w): this is not precise as p_\theta(w) is only an approximation to the exact posterior, which then allows us to lower bound the log marginal likelihood. "	Review	I-Review	5
common practice in modern variational approximation": This is the standard way of deriving the lower bound and has been used for many years.	Review	I-Review	5
[line_break_token][line_break_token]+ the reinforce estimator tends to have high variances since it does not make use of the gradient of the function in the expectation.	Review	O	0
This paper adjusts the vanilla estimator with a learning signal that involves the gradient.	Review	B-Review	6
Could you comment on the bias/variance trade-off of the resulting estimator?	Review	I-Review	6
Much of recent literature on learning discrete variables, as far as I understand, propose ways to not to have to use the vanilla reinforce, for example Concrete, Relax or rebar, albeit the focus on latent variable models.	Review	I-Review	6
[line_break_token][line_break_token]+ model selection and uncertainty measure: the paper mentions these potential advantages of the proposed approach over deterministic binarisation schemes, but does not fully explore and test these.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
- We thank R2 for pointing out the issue w.r.t.	Reply	O	0
the pseudo-reward for reinforce.	Reply	B-Reply	1
For now, we admit it is ad-hoc.	Reply	I-Reply	1
We will try to formulate it in a more elegant manner in a future version.	Reply	I-Reply	1
[line_break_token]- We admit that the proposed method is not better than baselines.	Reply	O	0
A	Reply	B-Reply	2

This paper considers from a high level the problem of learning a latent representation of high dimensional observations with underlying dynamics for control.	Review	O	0
 The authors specifically describe some desiredata for latent representations for LLC algorithms.	Review	O	0
The authors rigorously construct a learning framework that can satisfy the desiredata and then show how this can be tractably instantiated.	Review	O	0
[line_break_token][line_break_token]The paper overall is clear, however there is many equations in 4.2  with heavy subscritping making it sometimes difficult to read.	Review	O	0
The authours could attempt to better highlight the more critical parts of their propositins (e.g. eq.	Review	B-Review	1
8/9).	Review	I-Review	1
[line_break_token][line_break_token]The methodology and insights appear novel and well motivated, however I am not familiar with many of the prior work.	Review	O	0
 The experiments compared to competing methods  show substantial improvement.	Review	O	0
The authors also motivate well why these improvements over the existing methods should occur and provide ablations to validate all the components of the final loss.	Review	O	0
Overall the paper appears very solid and may motivate insights and research  in more complex model based control and planning [line_break_token]	Review	O	0
e thank the reviewer for appreciating our work in terms of novelty, theory, and experiments.	Reply	O	0
[line_break_token][line_break_token]We will improve the notations and presentation of the mathematical results, especially in Section 4.2, in the final version of the paper.	Reply	B-Reply	1

In this article, the authors propose a generative adversarial network named UWGAN to generate realistic underwater images from the pairs of in-air images and depth images.	Review	O	0
Then, a U-Net was leveraged to enhance the results.	Review	O	0
[line_break_token]However, the text suffers from too many language problems.	Review	O	0
The authors should consult professional proofreading services.	Review	O	0
As a courtesy towards referees, the quality of writing needs meticulous attention before a scientific paper should be submitted.	Review	O	0
[line_break_token][tab_token]Other comments:[line_break_token]1.	Review	O	0
[tab_token]The literature is limited.	Review	B-Review	1
I found some novel works being done in the field that must be addressed and listed in the background and experiments.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	2
[tab_token]The underwater imaging model presented in this paper derives from the Jaffe-McGlamery model, which is a common sense in this field.	Review	O	0
The authors use a generator to produce underwater images that only implements the common model by a neural network.	Review	B-Review	2
Moreover, the statement of section 2.2 is not clear.	Review	I-Review	2
Please rewrite this section.	Review	I-Review	2
[line_break_token]3.	Review	O	0
[tab_token]The authors used U-Net without any improvement to enhance the results generated from UWGAN, which is the integration of existing models.	Review	O	0
[line_break_token]4.	Review	O	0
[tab_token]The authors claimed that their model is better than others, while there is no evidence to indicates that.	Review	B-Review	4
For example, 1) in (page 5, line 4 from bottom), ‚ÄúIt can be seen that our proposed method has achieved a higher score.	Review	I-Review	4
‚Äù, can we observe this from the Table 1 and 2?	Review	I-Review	4
2) ‚ÄúThe method we proposed has the fastest processing speed compared to other methods.	Review	I-Review	4
Moreover, the method proposed in this paper has the fewest parameters compared to other deep-learning-based methods.	Review	I-Review	4
‚Äù, it is suggested that a study about the parameters and FLOPs of the involved methods should be given.	Review	I-Review	4
[line_break_token]5.	Review	I-Review	5
[tab_token]Please carefully check the references.	Review	O	0
For example, ‚ÄúHummel R. Image enhancement by histogram transformation[J]. Unknown, 1975.‚Äù lacks the journal name.	Review	B-Review	5
[line_break_token]6.	Review	O	0
[tab_token]High-resolution figures should be given in the manuscript.	Review	O	0
[line_break_token]	Review	O	0
e would like to thank the reviewer for pointing out some problems in our work.	Reply	O	0
Please find our response to your questions below.	Reply	O	0
We have updated the paper and uploaded a revision on Nov 13.	Reply	O	0
[line_break_token][line_break_token]**1) The literature is limited.**	Reply	O	0
[line_break_token][line_break_token]**Response:** We have cited and listed some new references in the background.	Reply	O	0
In section 4, the method we chose to compare with ours can be roughly divided into three types: model-free algorithms, model-based algorithms, and deep-learning-based algorithms.	Reply	B-Reply	1
These methods are classical and representative, we can't list too much due to paper length limit.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; Anwar S, Li C, Porikli F. Deep underwater image enhancement[J]. arXiv preprint arXiv:1807.03528, 2018.	Reply	O	0
[line_break_token]&gt;[line_break_token]&gt; Ancuti C, Ancuti C O, De Vleeschouwer C. D-hazy: A dataset to evaluate quantitatively dehazing algorithms[C]//2016 IEEE International Conference on Image Processing (ICIP).	Reply	O	0
IEEE, 2016: 2226-2230.	Reply	B-Reply	1
[line_break_token]&gt;[line_break_token]&gt; Uplavikar P, Wu Z, Wang Z. All-In-One Underwater Image Enhancement using Domain-Adversarial Learning[J]. arXiv preprint arXiv:1905.13342, 2019.	Reply	O	0
[line_break_token]&gt;[line_break_token]&gt; Anwar S, Li C. Diving Deeper into Underwater Image Enhancement: A Survey[J]. arXiv preprint arXiv:1907.07863, 2019.	Reply	O	0
[line_break_token]&gt;[line_break_token]&gt; Ding X, Wang Y, Yan Y, et al.	Reply	O	0
Jointly Adversarial Network to Wavelength Compensation and Dehazing of Underwater Images[J]. arXiv preprint arXiv:1907.05595, 2019.	Reply	B-Reply	1
[line_break_token]&gt;[line_break_token]&gt; Redmon J, Farhadi A. Yolov3: An incremental improvement[J]. arXiv preprint arXiv:1804.02767, 2018.	Reply	O	0
[line_break_token][line_break_token]**2) The underwater imaging model presented in this paper derives from the Jaffe-McGlamery model, which is a common sense in this field.	Reply	O	0
The authors use a generator to produce underwater images that only implements the common model by a neural network.	Reply	O	0
Moreover, the statement of section 2.2 is not clear.	Reply	O	0
Please rewrite this section.**	Reply	O	0
[line_break_token][line_break_token]**Response:** We have rewritten section 2.1 and 2.2.	Reply	O	0
Inspired by in-air images dehazing algorithms, we improved the underwater imaging model in this paper.	Reply	B-Reply	2
Then, we employed GAN for generating more realistic underwater-style images based on the improved model (taken both light attenuation and haze effect in real-world underwater images into consideration), which can be found in Sections 2.1 and 2.2 in this paper.	Reply	I-Reply	2
[line_break_token][line_break_token]**3) The authors used U-Net without any improvement to enhance the results generated from UWGAN, which is the integration of existing models.**	Reply	O	0
[line_break_token][line_break_token]**Response:** U-Net is an efficient tool for the proposed pipeline.	Reply	O	0
We employed U-Net as an enhancement network structure, but not only that, we studied the effect of different loss functions in U-Net (The detailed content can be found in Page 11, section APPENDIX), which could provide a new idea for further research about loss functions on underwater image enhancement.	Reply	B-Reply	3
Considering the inference speed and Flops, U-Net is better than other networks and could run on real-time compared to other deep-learning-based methods mentioned in this paper.	Reply	I-Reply	3
[line_break_token][line_break_token]**4) The authors claimed that their model is better than others, while there is no evidence to indicates that.**	Reply	O	0
[line_break_token][line_break_token]**Response:** We have revised some imprecise sentences of the result analysis part in section 4, ‚ÄúTable 1 and Table 2 quantitatively show the scores of sample images in Figure 5 and Figure 6 respectively.	Reply	O	0
It can be seen that our proposed method has achieved the highest scores in (a), (c) and (f).	Reply	B-Reply	4
In addition, the average quantized scores evaluated on RealA, RealB, and RealC datasets are shown in Table 3.	Reply	I-Reply	4
Our model achieves the best score in terms of color restoration.	Reply	I-Reply	4
‚Äù Besides, we add FLOPs of deep-learning-based methods in Table 5.	Reply	I-Reply	4
[line_break_token][line_break_token]**5) Please carefully check the references.**	Reply	O	0
[line_break_token][line_break_token]**Response:** We have revised small errors in references.	Reply	O	0
[line_break_token][line_break_token]&gt; ‚ÄúHummel R. Image enhancement by histogram transformation[J]. Computer Graphics and Image Processing, 1977, 6(2):184-195.‚Äù[line_break_token][line_break_token]**6) High-resolution figures should be given in the manuscript.**	Reply	O	0
[line_break_token][line_break_token]**Response:**  We have improved the resolution of images in this paper.	Reply	O	0
It should support higher magnifications	Reply	B-Reply	6

[line_break_token]I'd like to thank the authors for their detailed response to my questions.	Review	O	0
[line_break_token][line_break_token]The paper proposes a support regularized version of sparse coding that takes into account the underlying manifold structure of the data.	Review	O	0
For this purpose, the authors augment the classic sparse coding loss with a term that encourages near by points to have similar active set.	Review	O	0
Convergence guarantees for the optimization procedure are presented.	Review	O	0
Experimental evaluation on clustering and semi-supervised learning shows the benefits of the proposed approach.	Review	O	0
[line_break_token][line_break_token]The paper is well written and a nice read.	Review	O	0
The most relevant contribution of this work is to including (and optimizing) the regularization function, and not an approximation or surrogate.	Review	O	0
The authors derive a a PGD-styple iterative method and present convergence analysis for it.	Review	O	0
[line_break_token][line_break_token]Thanks for the clarifications regarding the assumptions used in Section 3.	Review	B-Review	1
It would be nice to include some of that in the manuscript.	Review	I-Review	1
[line_break_token][line_break_token]The authors also propose a fast encoding scheme for their proposed method.	Review	O	0
[line_break_token]The authors included a new experiment in semi-supervised consists of a very interesting use (of the method and the fast approximation).	Review	B-Review	2
While this is an interesting addition, I think that using fast encoders is not particularly novel or the main part of the work. "	Review	I-Review	2
Converting" iterative optimization algorithms into feed-forward nets for accelerating the inference process has been done in the past (several times with quite similar problems).	Review	I-Review	2
Is natural that this can be done, and not very surprising.	Review	I-Review	2
Maybe would be interesting to evaluate how important is to have an architecture matching the optimization algorithm, compared to a generic network (though some of this analysis has also been performed in the past).	Review	I-Review	2
[line_break_token][line_break_token][line_break_token]	Review	O	0
Thank you for your comment!	Reply	O	0
[line_break_token][line_break_token]We have included the intuition of what implies the condition G_ki >=0  in Section 3.	Reply	O	0
Moreover, we have presented the additional experiments in the revised paper on the MNIST and CIFAR-10 data for the clustering and semi-supervised learning tasks, which further demonstrate the effectiveness of SRSC and Deep-SRSC.	Reply	B-Reply	2

This paper is a survey of unsupervised learning techniques applied to the unsupervised task of descriptor matching.	Review	O	0
Various methods such as Gaussian RBMs, sparse RBMs, and mcRBMs were applied to image patches and the resulting feature vectors were used in a matching task.	Review	O	0
These methods were compared to standard hand-crafted descriptors such as SIFT, SURF, etc.	Review	O	0
[line_break_token][line_break_token]Pros[line_break_token]Provides a survey of descriptors for matching pairs of image patches.	Review	O	0
[line_break_token][line_break_token]Cons[line_break_token]It is not clear what the purpose of the paper is.	Review	O	0
The paper compares several learning algorithms on the task of what essentially seems like clustering image patches to find their correspondences.	Review	B-Review	2
The ground truth correspondences of the dataset were found by clustering the image patches to find correspondences... In this paper, simple clustering methods were not compared to such as kmeans or sparse coding which are less complicated models than RBMs and are meant for finding correspondences.	Review	O	0
Additionally, training in a supervised way makes much more sense for finding correspondences.	Review	B-Review	5
[line_break_token][line_break_token]It is not clear from the paper alone what is considered at match between descriptors?	Review	I-Review	6
Is it the distance being below a threshold, the pair of descriptors being closer than any other pair of descriptors, etc.?	Review	I-Review	6
[line_break_token][line_break_token]The preprocessing of the image patches seems different for each method.	Review	I-Review	7
This could lead to wildly different scales of the input pixels and thus the corresponding representations of the various methods.	Review	I-Review	7
[line_break_token][line_break_token]In section 3.3 it is mentioned that it is surprising that L1 normalization works better because sparsity hurts classification typically.	Review	I-Review	8
However, the sparsity in the paper is directly before the distance calculation, and not before being fed as input to a classifier which is a different setup and would thus be expected to behave differently with sparsity.	Review	I-Review	9
This is the typical setup in which sparsity is found to hurt classification performance because information is being thrown away before the classifier is used.	Review	I-Review	9
[line_break_token][line_break_token]Novelty and Quality:[line_break_token]This paper is not novel in that it is survey of prior work applied to matching descriptors.	Review	O	0
It is well written but does not appear to apply to a wide audience as other papers have done a comparison of unsupervised methods in the past, for example:[line_break_token]- A. Coates, H. Lee, and A. Ng.	Review	B-Review	10
An analysis of single-layer networks in unsupervised feature learning.	Review	I-Review	10
In Proc.	Review	I-Review	10
AISTATS, 2011.	Review	I-Review	10
[line_break_token]- A. Coates and A. Ng.	Review	I-Review	10
The importance of encoding versus training with sparse coding and vector quanti- zation.	Review	I-Review	10
In Proc.	Review	I-Review	10
ICML, 2011.	Review	I-Review	10
Dear 3338,[line_break_token]Thank you for your feedback.	Reply	O	0
In order to give a comprehensive[line_break_token]answer, we quote sentences from your feedback and try to respond[line_break_token]appropriately.	Reply	O	0
[line_break_token][line_break_token]> It is not clear what the purpose of the paper is.	Reply	O	0
[line_break_token]We suggest that the way unsupervised feature learning[line_break_token]methods are evaluated should be extended: A more direct evalution[line_break_token]of the learnt representations without subsequent supervised algorithms,[line_break_token]and not tied to the task of high-level object classification.	Reply	B-Reply	2
[line_break_token][line_break_token]> The ground truth correspondences of the dataset were found by [line_break_token]> clustering the image patches to find correspondences.	Reply	O	0
[line_break_token]This is not how the description of [R1] with respect to the[line_break_token]Ground Truth Data (section II in [R1]) reads.	Reply	B-Reply	3
[line_break_token][line_break_token]> In this paper, simple clustering methods were not [line_break_token]> compared to such as kmeans ...[line_break_token]We added a K-Means experiment to the new version of the paper.	Reply	O	0
[line_break_token]We run K-Means (with a soft threshold function) [R2] on the dataset,[line_break_token]it performs worse than spGRBM. (	Reply	B-Reply	4
This is mentioned in the new version[line_break_token]3 of the paper).	Reply	I-Reply	4
[line_break_token][line_break_token]> Additionally, training in a supervised way makes much more sense[line_break_token]> for finding correspondences.	Reply	O	0
[line_break_token]This is not the question that we are asking.	Reply	B-Reply	5
We deliberately [line_break_token]avoid any supervised training because we want to investigate[line_break_token]purely unsupervised methods.	Reply	I-Reply	5
We are not trying to achieve any [line_break_token]state-of-the-art results.	Reply	I-Reply	5
[line_break_token][line_break_token]> It is not clear from the paper alone what is considered at match [line_break_token]> between descriptors[line_break_token]We have added some text that describes how a false positive[line_break_token]rate for a fixed true positive rate is computed.	Reply	O	0
[line_break_token][line_break_token]> The preprocessing of the image patches seems different for each [line_break_token]> method.	Reply	O	0
This could lead to wildly different scales of the input [line_break_token]> pixels and thus the corresponding representations of the various [line_break_token]> methods.	Reply	O	0
[line_break_token]Could you elaborate why this is something to consider [line_break_token]in our setting?	Reply	B-Reply	7
[line_break_token][line_break_token]> In section 3.3 it is mentioned that it is surprising that L1 [line_break_token]> normalization works better because sparsity hurts classification [line_break_token]> typically.	Reply	O	0
[line_break_token]We don't say that 'sparsity hurts classification typically'.	Reply	B-Reply	8
We say[line_break_token]the exact opposite (that sparse representations are beneficial[line_break_token]for classification) and give a reference to [R3], a paper that you[line_break_token]also reference.	Reply	I-Reply	8
We say that it is surprising that a sparse representation[line_break_token]('sparse' as produced by spGRBM, not by a normalization scheme) [line_break_token]performs better in a  distance calculation, because the general [line_break_token]understanding is (to our  knowledge) that sparse representations [line_break_token]suffer  more from the curse of dimensionality when considering [line_break_token]distances.	Reply	I-Reply	8
[line_break_token][line_break_token]> However, the sparsity in the paper is directly before the distance [line_break_token]> calculation, and not before being fed as input to a classifier which [line_break_token]> is a different setup and would thus be expected to behave differently [line_break_token]> with sparsity.	Reply	O	0
This is the typical setup in which sparsity is found to [line_break_token]> hurt classification performance because information is being thrown [line_break_token]> away before the classifier is used.	Reply	O	0
[line_break_token]We don't understand what is meant here.	Reply	B-Reply	9
Wasn't the gist of [R3] that[line_break_token]a sparse encoding is key for good classification results?	Reply	I-Reply	9
However, we[line_break_token]think that the main point that we wanted to convey in the referred part[line_break_token]of the paper was poorly presented.	Reply	I-Reply	9
We tried[line_break_token]to make the presentation of the analysis part better in the new version[line_break_token](arxiv version 3) of the paper.	Reply	I-Reply	9
[line_break_token][line_break_token]> ...does not appear to apply to a wide audience as other papers have [line_break_token]> done a comparison of unsupervised methods in the past'[line_break_token]Those comparisions are, as explained in the paper, done always in combination[line_break_token]with a subsequent supervised classification algorithm on a high-level[line_break_token]object classification task.	Reply	O	0
We want to avoid exactly this setting.	Reply	B-Reply	10
We think[line_break_token]that the paper is relevant for researchers working on[line_break_token]unsupervised (feature) learning methods and for researchers working in [line_break_token]Computer Vision.	Reply	I-Reply	10
[line_break_token][line_break_token]A new version (arxiv version 3) of the paper is uploaded on March 11.	Reply	O	0
[line_break_token][line_break_token][R1] M. Brown, G. Hua, and S. Winder.	Reply	O	0
Discriminative learning of local image descriptors.	Reply	O	0
[line_break_token][R2] A. Coates, H. Lee, and A. Ng.	Reply	O	0
An analysis of single-layer networks in unsupervised feature learning.	Reply	O	0
[line_break_token][R3] A. Coates and A. Ng.	Reply	O	0
The importance of encoding versus training with sparse coding and vector quantization	Reply	O	0

[line_break_token]The authors propose CMOW, an extension of the CBOW model that allows the model to capture word order.	Review	O	0
Instead of each word being represented as a vector, words are represented by matrices.	Review	O	0
They extend the CBOW objective to take into account word order by replacing the averaging of vectors to create the context with matrix multiplication (a non-commutative operation).	Review	O	0
This is the first time this model has been applied in a large scale unsupervised setting.	Review	O	0
They are able to do this using their objective and an initialization strategy where the matrix embeddings are set to the identity matrix with some Gaussian noise added.	Review	O	0
[line_break_token][line_break_token]The results of this paper are its main weakness.	Review	B-Review	1
I did enjoy reading the paper, and it is nice to see some results using matrices as embeddings and matrix multiplication as a compositional function.	Review	I-Review	1
They include a nice analysis of how word order is captured by these CMOW embeddings while CBOW embeddings capture the word content, but it doesn't seem to make much of a difference on the downstream tasks where CBOW is better than CMOW and close to the performance of the hybrid combination of CBOW and CMOW.	Review	I-Review	1
[line_break_token][line_break_token]I think it's clear that their model is able to capture word information to some extent, but other models  (RNNs etc.)	Review	I-Review	2
can do this as well, that admittedly are more expensive, but also have better performance on downstream tasks.	Review	I-Review	2
I think a stronger motivation for their method besides an analysis of some phenomena it captures and a slight improvement on some downstream tasks when combined with CBOW is needed though for acceptance.	Review	I-Review	2
Could it be used in other settings besides these downstream transfer tasks?	Review	I-Review	2
[line_break_token][line_break_token]PROS:[line_break_token]- introduced an efficient and stable approach for training CMSM models[line_break_token]- Show that their model CMOW is able to capture word order information[line_break_token]- Show that CMOW compliments CBOW and a hybrid model leads to improved results on downstream tasks.	Review	O	0
[line_break_token][line_break_token]CONS[line_break_token]- The results on the hybrid model are only slightly better than CBOW.	Review	O	0
CMOW alone is mostly worse than CBOW.	Review	B-Review	1
Dear reviewer,[line_break_token][line_break_token]Thanks for your review!	Reply	O	0
To my understanding, your main concerns with our paper are:[line_break_token][line_break_token]1. ‚	Reply	O	0
ÄúThe improvements of the Hybrid model over CBOW are not large enough‚Äù[line_break_token]2. ‚	Reply	O	0
ÄúThere are other, more powerful models (RNNs) that achieve much better results, so there is not enough justification.	Reply	O	0
‚Äù[line_break_token][line_break_token]Let me address these issues one at a time:[line_break_token][line_break_token]1.	Reply	O	0
[line_break_token]We conducted a study in the field of learning universal sentence embeddings.	Reply	B-Reply	1
Obviously, an embedding that doesn‚Äôt have a notion of word order should not be considered "universal".	Reply	I-Reply	1
The goal of our research is thus to push the limits of what simple word aggregation methods are capable of encoding.	Reply	I-Reply	1
Finding some empirical evidence, Henao et al. (	Reply	I-Reply	1
2018) hypothesize that the main difference of simple word embedding methods to RNNs may be their inability to capture word order.	Reply	I-Reply	1
[line_break_token][line_break_token]We successfully propose a way to diminish that difference.	Reply	I-Reply	1
Our hybrid CBOW-CMOW model is not only able to capture word order information, it scores 8% better on average on the linguistic probing tasks than CBOW.	Reply	I-Reply	1
Even if we disregard the benefit from BShift, the improvement is still large (~4%).	Reply	I-Reply	1
From the perspective of learning linguistically informed universal sentence embeddings, this is an important result, especially at a conference that is all about learning representations.	Reply	I-Reply	1
[line_break_token][line_break_token]It is true that the results on linguistic probing tasks do not transfer to the same extent to the downstream tasks, achieving an average improvement of "only" 1.2%.	Reply	I-Reply	1
We have added this in the revised version of the paper.	Reply	I-Reply	1
[line_break_token]We evaluate our models on the SentEval benchmark.	Reply	I-Reply	1
This framework is the de facto standard for evaluating sentence embeddings, and thus we should evaluate our models this way as well.	Reply	I-Reply	1
Most tasks in SentEval depend heavily on word content memorization (Conneau et al.,	Reply	I-Reply	1
2018).	Reply	I-Reply	1
Thus, the selection of downstream tasks rather disfavors our model, since it improves in every aspect but Word Content memorization.	Reply	I-Reply	1
[line_break_token]Recently, more doubt has been cast repeatedly whether the selection of tasks in SentEval is sufficient to test the generality of sentence embeddings (‚ÄúAnonymous ICRL Submission‚Äù, 2018), especially their compositionality (Dasgupta et al.,	Reply	I-Reply	1
2018).	Reply	I-Reply	1
[line_break_token][line_break_token]In summary, considering the strong results on linguistic probing tasks, and the nature of the SentEval framework, we believe that the results obtained by our hybrid CBOW-CMOW model are already strong evidence that our method produces more general, robust sentence embeddings.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
[line_break_token][line_break_token]The research community in sentence embedding learning has paid a lot of attention to baselines based on word embedding aggregation methods (such as the one presented in this paper) that are conceptually simple, e.g., Henao et al. (	Reply	B-Reply	2
2018), Pagliardini et al. (	Reply	I-Reply	2
2018), Rueckle et al. (	Reply	I-Reply	2
2018), including important work presented at ICLR (Wieting et al (2016), Arora et al. (	Reply	I-Reply	2
2017).	Reply	I-Reply	2
[line_break_token]The reasoning is two-fold: i) Aggregated word embeddings are computationally inexpensive compared to RNNs (see Hill et al. (	Reply	I-Reply	2
2016), and the measurements in our work).	Reply	I-Reply	2
ii) Pushing the limits of conceptually simple encoders helps to identify the benefit introduced by more sophisticated encoders, which has also been a recurring topic of interest ( Adi et al. (	Reply	I-Reply	2
2016), Conneau et al. (	Reply	I-Reply	2
2018), Zhu et al. (	Reply	I-Reply	2
2018), Anonymous (2018) ).	Reply	I-Reply	2
[line_break_token]Our paper is clearly motivated by reason i), since our method is computationally as inexpensive as CBOW.	Reply	I-Reply	2
It is also motivated by reason ii): The conceptual difference between CBOW and CMOW boils down to using matrix multiplication instead of addition, followed by simple adaptations to the training procedure.	Reply	I-Reply	2
Yet, these changes substantially improve the model's ability to learn linguistic properties such as word order, which were formerly left up to more sophisticated RNNs.	Reply	I-Reply	2
[line_break_token][line_break_token]Adi et al. (	Reply	I-Reply	2
2016) : Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction Tasks, ICLR 2017[line_break_token]Anonymous (2018) : No Training Required: Exploring Random Encoders for Sentence Classification.	Reply	O	0
URL: <a href="https://openreview.net/forum?id=BkgPajAcY7" target="_blank" rel="nofollow">https://openreview.net/forum?id=BkgPajAcY7</a> , ICLR 2019 Submission[line_break_token]Arora et al. (	Reply	O	0
2017) : A Simple But Tough-to-Beat Baseline for Sentence Embeddings, ICLR 2017[line_break_token]Conneau et al. (	Reply	O	0
2018): What you can cram into a single vector, ACL 2018[line_break_token]Henao et al. (	Reply	O	0
2018) : Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms, ACL 2018[line_break_token]Hill et al. (	Reply	O	0
2016) : Learning Distributed Representations of Sentences from Unlabelled Data, NAACL 2016[line_break_token]Pagliardini et al. (	Reply	O	0
2018) : Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features, NAACL 2018[line_break_token]Rueckle et al. (	Reply	O	0
2018) : Concatenated Power Mean Word Embeddings as Universal Cross-Lingual Sentence Representations, arXiv:1803.01400[line_break_token]Wieting et al. (	Reply	O	0
2016) : Towards Universal Paraphrastic Sentence Embeddings, ICLR 2016[line_break_token]Zhu et al. (	Reply	O	0
2018) : Exploring Semantic Properties of Sentence Embedding	Reply	O	0

This paper performs a very important service: exploring in a clear and systematic way the performance and trainability characteristics of a set of neural network architectures -- in particular, the basic RNN motifs that have recently been popular.	Review	O	0
  [line_break_token][line_break_token]Pros:[line_break_token][line_break_token]* This paper addresses an important question I and many others would have liked to know the answer to but didn't have the computational resources to thoroughly attack it.	Review	O	0
  This is a nice use of Google's resources to help the community.	Review	O	0
[line_break_token][line_break_token]* The work appears to have been done carefully so that the results can be believed.	Review	O	0
[line_break_token][line_break_token]* The basic answer arrived at (that, in the "typical training environment" LSTMs are reliable but basically GRUs are the answer) seems fairly decisive and practically useful.	Review	O	0
  Of course the real answer is more complicated than my little summary here, but the subtleties are discussed nicely in the paper.	Review	O	0
[line_break_token][line_break_token]* The insistence on a strong distinction between capacity and trainability helps nicely clear up a misconception about the reasons why gated architectures work.	Review	O	0
 In sum, they're much more easily trainable but somewhat lower capacity than vanilla RNNs, and in hard tasks, the benefits of better trainability far outweigh the costs of mildly lower capacity.	Review	O	0
[line_break_token][line_break_token]* The point about the near-equivalence of capacity at equal numbers of parameters is very useful.	Review	O	0
  [line_break_token][line_break_token]* The paper makes it clear the importance of HP tuning, something that has sometimes gotten lost in the vast flow of papers about new architectures.	Review	O	0
[line_break_token][line_break_token]* The idea of quantifying the fraction of infeasible parameters (e.g. those that diverge) is nice, because it's a practical problem that everyone working with these networks has but often isn't addressed.	Review	O	0
[line_break_token][line_break_token]* The paper text is very clearly written.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]* The work on the UGRNNs and the +RNNs seems a bit preliminary.	Review	O	0
 I don't think that the authors have clearly shown that the +RNN should be "recommended" with the same generality as the GRU.	Review	B-Review	1
  I'd at the least want some better statistics on the significance of differences between +RNN and GRU performances quantifying the results in Figure 4 (8-layer panel).	Review	I-Review	1
  In a way the high standards for declaring an architecture useful that are set in the paper make the UGRNNs and +RNN contributions seem less important.	Review	I-Review	1
  I don't really mind having them in the paper though.	Review	I-Review	1
  I guess the point of this paper is not really to be novel in the first place -- which is totally fine with me, though I don't know what the ICLR area chairs will think.	Review	O	0
[line_break_token][line_break_token]* The paper gives short shrift to the details of the HP algorithm itself.	Review	O	0
 They do say: [line_break_token][line_break_token]     "Our setting of the tuner‚Äôs internal parameters was such that it uses Batched GP Bandits with an expected improvement acquisition function and a   [line_break_token]     Matern 5/2 Kernel with feature scaling and automatic relevance determination performed by optimizing over kernel HPs"  [line_break_token][line_break_token]and give some good references, but I expect that actually trying to replicate this involves a lot of missing details.	Review	O	0
  [line_break_token][line_break_token]* I found some of the figures a bit hard to read at first, esp.	Review	O	0
Fig 4, mostly due to the panels being small, having a lot of details, and bad choices for visual cleanliness.	Review	B-Review	4
  [line_break_token][line_break_token]* The neuroscience reference ("4.7 bits per synapse") seems a little bit of a throw-away to me, because the connection between these results and the experimental neuroscience is very tenuous, or at any rate, not well explained.	Review	O	0
 I guess it's just in the discussion, but it seems gratuitous.	Review	B-Review	5
  Maybe it should couched in slightly less strong terms (nothing is really strongly shown to be "in agreement" here between computational architectures and neuroscience, but perhaps they could say something like -- "We wonder if it is anything other than coincidence that our 5 bits result is numerically similar to the 4.7 bits measurement from neuroscience.")	Review	I-Review	5
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
Thank you for your review!	Reply	O	0
[line_break_token][line_break_token]Our experiments have demonstrated that the UGRNN performs competitively with gated architectures in terms of trainability (Fig 4) while maintaining capacity comparable to the vanilla RNN.	Reply	B-Reply	1
In the deepest trainability scenario we tested (8 layer architectures), we show that the +RNN outperforms all other architectures in both tasks, on both of our metrics.	Reply	O	0
While we do not report additional statistics on the significance of the differences between architectures on these trainability tasks (this is difficult as we believe that the use of an HP tuner leads to samples that are not i.i.d.),	Reply	B-Reply	2
we measured how robust our experiments are against random batching and weight initializations by running the same HP sets multiple times and looking at the final losses (Table 1 of appendix).	Reply	I-Reply	2
We found that the losses don‚Äôt deviate very much across runs, leading us to believe our results generally, and our findings regarding the UGRNN and +RNN.	Reply	I-Reply	3
 Obviously, the GRU and LSTM are better vetted through extensive study by the entire deep learning community.	Reply	O	0
 We have softened our language in the discussion regarding our recommendation of the +RNN, to ‚ÄúOf course further experiments will be required to fully vet the UGRNN and +RNN.	Reply	O	0
All things considered, in an uncertain training environment, we would recommend using the GRU or +RNN‚Äù.	Reply	B-Reply	4
[line_break_token][line_break_token]As you suggested, we have also now done statistical tests on the experiment described in Fig.	Reply	I-Reply	5
5, which shows evaluation losses for randomly selected HPs for different architectures trained on the parentheses task.	Reply	I-Reply	5
We ran a Welch‚Äôs t-test and found that for the 1 layer case, the differences between all loss distributions are statistically significant.	Reply	I-Reply	5
In the 8 layer case, we found that the differences were statistically significant for most architecture pairs, except for the differences between the GRU and UGRNN, LSTM and RNN, and IRNN and RNN.	Reply	I-Reply	5
 These findings have been summarized in the caption for Fig.	Reply	I-Reply	5
5.,	Reply	I-Reply	5
and exact values are reported in the Appendix	Reply	I-Reply	5

This paper proposes a new adversarial attack method by combining spatial transformations with perturbation-based noises.	Review	O	0
The proposed method uses two networks to generate the parameters of spatial transformation and the perturbation noise.	Review	O	0
The whole architecture is trained by a variant of GAN-loss to make the adversarial examples realistic to humans.	Review	O	0
Experiments on MNIST prove that the proposed attack method can improve the success rate of white-box attacks against several models.	Review	O	0
[line_break_token][line_break_token]Overall, this paper considers an important problem of adversarial robustness of classifiers, and present a new approach to craft adversarial examples.	Review	O	0
The writing is clear.	Review	O	0
However, I have some concerns about this paper.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
This paper seems to integrate multiple ideas studied before into a single attack method.	Review	B-Review	1
Perturbation-based adversarial examples, spatial transformation-based adversarial examples, generating adversarial examples based on the GAN loss are all studied before.	Review	I-Review	1
And the proposed method integrates them together to form a new attack.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The experiments are only conducted on MNIST and Fashion MNIST.	Review	B-Review	2
More experiments on CIFAR-10 and ImageNet can further prove the effectiveness of the proposed method.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
More robust defense models should be incorporated in experiments, at least the PGD-based adversarial training model (Madry et al.,	Review	B-Review	3
2018).	Review	I-Review	3
ur response is as follows:[line_break_token][line_break_token]1.	Reply	O	0
Please allow us to re-emphasize the main novelty of our method: We focus on generating adversarial examples that look realistic to humans but also attack the classifier well; We achieve this goal by proposing a generator that conducts both spatial distortions and perturbations.	Reply	B-Reply	1
Importantly, the proposed generator is fully differentiable so that we can train it to generate spatial distortions and perturbations jointly.	Reply	I-Reply	1
In the joint process, spatial distortions and perturbations are ‚Äúaware of‚Äù each other and ‚Äúwork collaboratively‚Äù, so that we are able to use small spatial distortions plus small perturbations to achieve better attack performance.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
We are conducting experiments on CIFAR and CelebA. We will try our best to report the results in the rebuttal.	Reply	B-Reply	2
If the experiments cannot be concluded by the rebuttal deadline, we will report them in the revised paper.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
We have conducted the experiments of adversarial training + PGD, i.e.,  Adv-Train-PGD.	Reply	B-Reply	3
The performance results are shown in the following table.	Reply	I-Reply	3
It can be observed that Adv-Train-PGD defends well against perturbation-based methods but is less effective than our proposed approaches.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]+---------------+--------------------------------+--------------------------------+--------------------------------+--------------------------------+[line_break_token]|               |         MNIST, Model A         |         MNIST, Model B         |     Fashion MNIST, Model A     |     Fashion MNIST, Model B     |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|               | Adv-Train-FGSM | Adv-Train-PGD | Adv-Train-FGSM | Adv-Train-PGD | Adv-Train-FGSM | Adv-Train-PGD | Adv-Train-FGSM | Adv-Train-PGD |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|   No attack   |     0.9916     |     0.9915    |     0.9757     |     0.9830    |     0.9057     |     0.9060    |     0.8869     |     0.8854    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|      STM      |     0.9481     |     0.4241    |     0.1200     |     0.0413    |     0.1296     |     0.1323    |     0.1112     |     0.1132    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|  SdAdv (ours) |      0.074     |     0.0631    |     0.0744     |      0.08     |     0.1502     |     0.1049    |     0.1420     |     0.1850    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|      FGSM     |     0.9481     |     0.9710    |     0.8753     |     0.8189    |     0.8838     |     0.7499    |     0.8558     |     0.6076    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|      PGD      |     0.0926     |     0.9427    |     0.0147     |     0.7419    |     0.0764     |     0.6619    |     0.0431     |     0.5140    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|      MIM      |     0.1584     |     0.9358    |     0.0373     |     0.7201    |     0.1054     |     0.5987    |     0.0515     |     0.4401    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]|     AdvGAN    |     0.9278     |     0.9906    |     0.2868     |     0.8680    |     0.1854     |     0.3762    |     0.1015     |     0.1387    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+[line_break_token]| SdpAdv (ours) |      0.033     |     0.0752    |     0.0741     |     0.092     |     0.0444     |     0.1113    |     0.0392     |     0.1081    |[line_break_token]+---------------+----------------+---------------+----------------+---------------+----------------+---------------+----------------+---------------+	Reply	I-Reply	3

The paper presents a model that learns an embedding/representation for spatial points (POI's).	Review	O	0
There are two specific things the representations are trying to encode - location modeling and spatial context modeling and the model tries to do it in multi-scale manner to increase the information/granularity of the learnt representations.	Review	O	0
[line_break_token][line_break_token]The experiments are performed on Yelp Data challenge which has 21,830 POI's with 1191 POI types.	Review	O	0
In the location context experiments authors show that by going after a smaller grid size we can get much better results compared to other methods while other methods like tile, wrap and rbf have more parameters causing overfitting.	Review	O	0
Similarly, on spatial context modeling we see better results.	Review	O	0
[line_break_token][line_break_token]Overall, the problem of learning vector representations for spatial points is interesting and useful and this paper has valuable contributions on how to do it.	Review	O	0
[line_break_token][line_break_token]One thing I would like to have seen to strengthen the paper further is the application of these representations in other tasks like image classification or recommendation systems or retrieval.	Review	B-Review	1
The paper currently misses that.	Review	I-Review	1
[line_break_token][line_break_token]For ex - <a href="https://arxiv.org/abs/1505.03873" target="_blank" rel="nofollow">https://arxiv.org/abs/1505.03873</a> uses location information to improve image classification, similarly can we use the representation learned through this method instead of positional coordinates and show that it helps the final task.	Review	O	0
hank you for your valuable suggestion about adding another application of the proposed space representation model.	Reply	B-Reply	1
We followed your suggestion and applied our Space2Vec to the task of  fine-grained image classification.	Reply	I-Reply	1
[line_break_token] [line_break_token]The core idea is to use our Space2Vec to capture the spatial prior information of species distribution.	Reply	I-Reply	1
We follow the exact experiment setup as Mac Aodha et al. [	Reply	I-Reply	1
1], which had a similar inductive learning set up as our main result: using a location encoder to encode geographic coordinates into location embeddings.	Reply	I-Reply	1
Mac Aodha et al.	Reply	I-Reply	1
combined the location encoder with a pretrained InceptionV3 network to do image classification.	Reply	I-Reply	1
Tang et al. [	Reply	I-Reply	1
2] leveraged a diverse set of metadata (e.g. hashtags, ACS data), but they discretized latitude and longitude to train embedding for each space block, which is comparable to our tile-based baselines in Table 1 and 2.	Reply	I-Reply	1
In fact, Mac Aodha et al. [	Reply	I-Reply	1
1] already included Tang et al. [	Reply	I-Reply	1
2] as a baseline for fine-grained image classification task.	Reply	I-Reply	1
We also included Tang et al. [	Reply	I-Reply	1
2] in Table 3.	Reply	I-Reply	1
[line_break_token] [line_break_token]We utilized the original code of Mac Aodha et al. [	Reply	I-Reply	1
1] and replaced their location encoder with our Space2Vec model.	Reply	I-Reply	1
We picked two fine-grained image classification datasets of significant sizes, BirdSnap‚Ä† (49,829 images spanning 500 species of North American birds) and NABirds‚Ä† (555 categories with a total of 48,562 images) as example datasets which have been used in Mac Aodha et al. [	Reply	I-Reply	1
1]. Experiment results showed that our grid and theory model can outperform previous models as well as the model of Mac Aodha et al. [	Reply	I-Reply	1
1] on both datasets.	Reply	I-Reply	1
For experiment results and details, please refer to Appendix A.6 in our updated paper on openreview.	Reply	I-Reply	1
[line_break_token] [line_break_token]We believe that this additional task demonstrates the generalizability of our space representation model.	Reply	I-Reply	1
[line_break_token] [line_break_token]References:[line_break_token]1.	Reply	O	0
Mac Aodha, O., Cole, E. and Perona, P., 2019.	Reply	O	0
Presence-Only Geographical Priors for Fine-Grained Image Classification.	Reply	O	0
arXiv preprint arXiv:1906.05272.	Reply	O	0
[line_break_token]2.	Reply	B-Reply	1
Tang, K., Paluri, M., Fei-Fei, L., Fergus, R. and Bourdev, L., 2015.	Reply	O	0
Improving image classification with location context.	Reply	O	0
In Proceedings of the IEEE international conference on computer vision (pp.	Reply	O	0
1008-1016).	Reply	O	0
<a href="https://arxiv.org/abs/1505.03873" target="_blank" rel="nofollow">https://arxiv.org/abs/1505.03873</a>	Reply	O	0

[line_break_token]##### Rebuttal Response:[line_break_token]The other reviewers seem to have understood more than me.	Review	O	0
Their opinion and the rebuttal did not convince me to update my score.	Review	O	0
In my opinion the writing must be adapted to be interesting to the ICLR community and the bigger picture should be highlighted more, as the bigger picture is remains quite unclear at the current state.	Review	B-Review	3
[line_break_token][line_break_token][line_break_token]##### Review:[line_break_token]Summary: [line_break_token][...][line_break_token][line_break_token][line_break_token]Conclusion:[line_break_token]I have read the paper multiple times and I still have a problem summarizing the paper with my own words.	Review	O	0
The contributions summarize the most fundamental works of RL but do not really relate these methods to the proposed approach.	Review	B-Review	1
Therefore, I am still uncertain about the general motivation and intention of the work as well as the evaluation.	Review	I-Review	1
Currently I vote for borderline reject as I am familiar with RL &amp; PDE'S but do not understand the motivation and intention.	Review	O	0
I am leaning towards rejection as the paper is a resubmission from Neurips and has not been substantially improved.	Review	B-Review	1
However, I am not certain about my evaluation.	Review	I-Review	1
I am happy to adapt my vote based on the other reviewers and a clarified and better structured paper, which can be submitted during the rebuttal.	Review	O	0
hanks the reviewer for your feedbacks.	Reply	O	0
[line_break_token][line_break_token]We have updated the manuscript for the following 3 parts, where all the updates are in the "Complementary Experiments" section (section A) in the Appendix.	Reply	B-Reply	2
1) We added experiments on comparing our RL-based method and a SL-based method, in appendix A.1.	Reply	I-Reply	2
2) We add more figures analyzing the performance of our RL policy on smooth regions and near singularities of the PDE solutions in appendix A.2.	Reply	I-Reply	2
3) We report and compare the inference time of our RL policy and WENO in appendix A.3.	Reply	I-Reply	2
Currently we put these contents in appendix, but if the paper gets accepted, we would then incorporate them into the main body in the final version.	Reply	I-Reply	2

This paper uses a collection of methods (with minor improvements) to obtain good prediction performance on ImageNet-subset data.	Review	O	0
I sincerely recommend authors improving the paper's quality by offering more analysis and insights of their method.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
Could authors add more experiments on explaining their motivations?	Review	B-Review	1
[line_break_token]- The big motivation to their work is "feature representations will become more similar as depth increases leading to easier classification" (in the introduction).	Review	I-Review	1
However, this is only supported with results in a small table in Appendix.	Review	I-Review	1
C.[line_break_token]- It is better to show results directly based on GCNZ, and then results on SGCN.	Review	O	0
[line_break_token]- It seems that the performance in Table 6 and 1 (hop 2) are not consistent.	Review	O	0
Are there any reasons for this?	Review	B-Review	3
[line_break_token]- Except for accuracy, could author design some other measurement to evaluate the smoothness of the embedding in deeper layers? (	Review	O	0
perhaps t-SNE as Wang etal 2018).	Review	B-Review	4
[line_break_token]- All the above will make the paper sound more principle and better motivated.	Review	O	0
Currently, the motivation is not well justified.	Review	B-Review	1
[line_break_token][line_break_token]2. "	Review	O	0
Rethinking" indicates in-depth analysis of existing works, based on Q1, I suggest the author changes their title as well.	Review	B-Review	5
[line_break_token][line_break_token]3.	Review	O	0
The connections to ancestors and descendants look tricky.	Review	B-Review	6
Are there any insight reasons for connecting and training in this way?	Review	I-Review	6
[line_break_token]- Specifically, the connectivity patterns in the graph is very complex.	Review	I-Review	6
The authors have also said there can be DAG in the graph, so, why should we connect in this way?	Review	I-Review	6
[line_break_token][line_break_token]4.	Review	O	0
Can the proposed method be used on other kinds of data sets except those from the image domain?	Review	B-Review	7
[line_break_token][line_break_token]5.	Review	O	0
The motivation in this paper is inconsistent with experiments in Wang et al 2018.	Review	B-Review	8
Wang has shown in Section:"how important is the depth of GCN" & Table 4 that the model performance increasing with the depth of layers.	Review	O	0
So, could the authors repeat the same experiments on NELL & NEIL?	Review	O	0
This will make the motivation more convincing.	Review	B-Review	8
Dear Reviewer 3.	Reply	O	0
Thank you for your constructive comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
[line_break_token]- Thank you for pointing out that the motivation might not have been clear enough in the original submission.	Reply	O	0
In Appendix C we only include a small study because our conclusion is derived from theoretical analysis.	Reply	B-Reply	1
We will update Section 3.2 to include:[line_break_token]The Laplacian smoothing operation in matrix form can be written as, as also noted in Li et al. (	Reply	I-Reply	1
2018).	Reply	I-Reply	1
Substituting the graph Laplacian with its definition the operation simplifies for (looking only at the immediate neighbors) to.	Reply	I-Reply	1
This corresponds to the first part of the update rule in Equation~(1) meaning that the complete update rule is thus a smoothing operating followed by a matrix multiplication with the weights, which can be interpreted as a fully connected layer.	Reply	I-Reply	1
Thus, repeatedly applying the update rule in Equation~(1) will lead to repeatedly applying Laplacian smoothing, thus diluting the information.	Reply	I-Reply	1
[line_break_token][line_break_token]- It is better to show results directly based on GCNZ, and then results on SGCN.	Reply	O	0
[line_break_token]Appendix D shows the transition from GCNZ to SGCN illustrating all the modifications that have been made.	Reply	B-Reply	2
[line_break_token][line_break_token]- It seems that the performance in Table 6 and 1 (hop 2) are not consistent.	Reply	O	0
Are there any reasons for this?	Reply	O	0
[line_break_token]Thank you for indicating that this can cause confusion.	Reply	B-Reply	3
The results in Table 6 are for the non-finetuned version of SGCN while the results in Table 1 are for the finetuned version of SGCN.	Reply	I-Reply	3
We will state this explicitly in the updated version.	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	I-Reply	1
We designed it so that that it allows all nodes to communicate with each other within two propagation steps.	Reply	I-Reply	6
Another advantage of this connection scheme is that it is not very complex as ancestors and descendants are well defined in a DAG due to the direction of the edges.	Reply	I-Reply	6
[line_break_token][line_break_token]4.	Reply	O	0
Indeed, the proposed method can be used for other kinds of data sets.	Reply	B-Reply	7
The only requirement is that we have a DAG that describes meaningful relations between classes and some form of semantic representation of each class (for example the word embedding).	Reply	I-Reply	7
Non-image data could be considered by replacing the pre-trained CNN with a pre-trained fully connected network.	Reply	I-Reply	7
[line_break_token][line_break_token]5.	Reply	O	0
Our motivation of focusing on the ImageNet dataset is that it is a commonly used large-scale benchmark dataset for zero-shot learning that, most importantly, is openly available to allow reproducibility.	Reply	B-Reply	8
We want to stress that there is a fundamental difference in our experimental setting and the study in Wang et al 2018 as their ablation study does not only modify the number of layers in the network but at the same time the number of neurons per layer.	Reply	I-Reply	8
Their 2-layer (one hidden layer) model has 512 neurons, the 4-layer (three hidden layer) one uses a 2048-1024-512 setup and the 6-layer (five hidden layer) setup is 2048-2048-1024-1024-512.	Reply	I-Reply	8
In our study in Appendix C we instead keep the number of neurons in the hidden layer constant to avoid the effects that varying the number of nodes introduces	Reply	I-Reply	8

This paper is the first (I believe) to establish a simple yet important result that Convnets for NMT encoders can be competitive to RNNs.	Review	O	0
The authors present a convincing set of results over many translation tasks and compare with very competitive baselines.	Review	O	0
I also appreciate the detailed report on training and generation speed.	Review	O	0
I find it's very interesting when position embeddings turn out to be hugely important (beside residual connections); unfortunately, there is little analysis to shed more lights on this aspect and perhaps compare other ways of capturing positions (a wild guess might be to use embeddings that represent some form of relative positions).	Review	O	0
The only concern I have (similar to the other reviewer) is that this paper perhaps fits better in an NLP conference.	Review	B-Review	2
[line_break_token][line_break_token]One minor comment: it's slight strange that this well-executed paper doesn't have a single figure on the proposed architecture :) It will also be even better to draw a figure for the biLSTM architecture as well (it does take some effort to understand the last paragraph in Section 2, especially the part on having a linear layer to compute z).	Review	O	0
We will add figures illustrating our model architecture better; our baseline biLSTM architecture closely follows [Zhou et al, TACL 2016] <a href="https://arxiv.org/pdf/1606.04199v3.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1606.04199v3.pdf</a> who have detailed figures illustrating the model.	Reply	O	0
[line_break_token]Position embeddings are important.	Reply	B-Reply	1
Without them our encoder has no notion of position.	Reply	I-Reply	1
We investigated position embeddings numbered from the left to right and right to left but found that one direction was enough.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding conference fit: we show that RNNs are not necessary to perform encoding in a complex sequence to sequence task and that CNNs are comparable or better.	Reply	I-Reply	2
Of course, this is of interest to the NLP community but also to the ML community.	Reply	I-Reply	2
In term of representation learning, the two stack CNN highlight that attention weights and the input representation might benefit from different depth, which can impact other tasks, and other models.	Reply	I-Reply	2
Our work also highlights  that the success of RNNs in MT cannot be attributed to their unique ability to model long term dependencies.	Reply	I-Reply	2
We believe that those findings are of great interest to the ML community	Reply	I-Reply	2

This is an interesting paper that studies the latent variable modeling from an information theoretic perspective.	Review	O	0
Specifically, the authors argue that the rate-distortion theory for lossy compression provides a natural toolkit for studying latent variable models, and they propose a lower bound (also a gap function) that could be used to assess the goodness of data fitting given a pair of prior distribution over latent factor and a likelihood function.	Review	O	0
Overall the paper is very well-written, clear to follow, and the authors did a great job in not overclaiming their results.	Review	O	0
[line_break_token][line_break_token]Several questions follow: [line_break_token]1.	Review	O	0
 In Eq. (	Review	B-Review	1
3), why the R.H.S. is an upper bound of the L.H.S.?	Review	I-Review	1
Under the assumption of (1) should this be equal?	Review	I-Review	1
[line_break_token]2.	Review	O	0
 In section 2, "must use at use" -> "must use at least".	Review	O	0
[line_break_token]3.	Review	B-Review	4
 Since the mutual information is convex in the conditional distribution Q(Z|X), when considering the Lagrangian, since \alpha is constrained to be positive, should the sign before \alpha be positive instead of negative?	Review	O	0
[line_break_token]4.	Review	O	0
 In section 3.3, "An very common" -> "A very common".	Review	O	0
[line_break_token][line_break_token]To me the most interesting result in this paper is in Thm.	Review	O	0
1, Eq. (	Review	O	0
9), where the authors show that the optimization over the prior in latent variable modeling is exactly equivalent to the optimization of the channel in rate-distortion theory.	Review	O	0
Following this line the authors propose a gap function that could be used to assess the goodness of a model.	Review	O	0
One drawback of the current framework is that it only links the optimization of the prior, rather than the likelihood function, to rate-distortion theory, while in practice it is usually the other way around.	Review	B-Review	5
Although the authors argue in section 3.3 that similar conclusion could be achieved for a family of likelihood functions, the analysis is only possible under the very restrictive (in my personal view) assumption that relies on the existence of a smooth and invertible mapping.	Review	I-Review	5
This assumption usually does not hold in practice, e.g., the ReLU network, and as a result the analysis here is only of theoretical interest.	Review	I-Review	5
[line_break_token][line_break_token]The experimental validation basically shows the usefulness of the proposed gap function in assessing the goodness of model fitting in latent variable models.	Review	O	0
It would be great if there are more direct use of the proposed lower bound, but I appreciate the novelty in this paper on bridging the two subfields.	Review	B-Review	6
[line_break_token]	Review	O	0
[line_break_token]In the paper, we argued that results pertaining to the problem of prior optimization were relevant also to the problem of likelihood function optimization (although for the latter problem only weaker statements are possible).	Reply	B-Reply	5
In the paper we made an assumption that there existed an invertible mapping that transformed a random variable distributed according to (the "current" prior) to a random variable with distribution (the "better" prior).	Reply	I-Reply	5
Both reviewers 1 and 3 pointed out this as a limitation in the usefulness of the result.	Reply	I-Reply	5
[line_break_token][line_break_token]It turns out that the conditions imposed in the original submission were unnecessarily restrictive.	Reply	I-Reply	5
The result holds under a very general condition - we only need to assume that is a measurable function.	Reply	I-Reply	5
The claims in the paper have been restated and the proof of this is now included in the Appendix; the proof is a fairly straightforward application of basic concepts in Lebesgue integration.	Reply	I-Reply	5
However, we point out if the starting distribution is discrete, or has some discrete portions (as it is obviously the case when the alphabet \mathcal{Z} is finite), it isn't clear that such a mapping can be found.	Reply	I-Reply	5
In the paper, we do give examples of common continuous distributions where such a mapping is guaranteed to exist (multivariate gaussians and product of continuous distributions).	Reply	I-Reply	5
[line_break_token][line_break_token]We now address the individual comments:[line_break_token][line_break_token]1.	Reply	O	0
 In Eq. (	Reply	O	0
3), why the R.H.S. is an upper bound of the L.H.S.?	Reply	O	0
Under the assumption of (1) should this be equal?	Reply	O	0
[line_break_token][line_break_token]We have overloaded the meaning of - whenever it is outside of an optimization expression we imply it to be the "current" model that the statistician is trying to improve, and when inside of an optimization expression we think of as a "free" quantity that one can optimize over.	Reply	B-Reply	1
We have clarified in the paper the notation overload.	Reply	I-Reply	1
if the reviewer thinks this is still not clear, then we can consider revising the notation in the entire paper.	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	I-Reply	4
 Since the mutual information is convex in the conditional distribution Q(Z|X), when considering the Lagrangian, since \alpha is constrained to be positive, should the sign before \alpha be positive instead of negative?	Reply	O	0
[line_break_token][line_break_token]In rate-distortion theory, we want "low rate" (which implies "low" mutual information, which denotes the number of bits used to describe a source sample) and "low distortion".	Reply	B-Reply	3
The Lagrangian in rate-distortion thus needs to be setup so that minimizing it promotes reducing mutual information and reducing distortion.	Reply	I-Reply	3
In the case of a generative model, whenever is high, the meaning is that the data is well explained by the latent variable and therefore it corresponds to the notion of "low distortion".	Reply	I-Reply	3
Conversely, if is very low, then then it means that and are mismatched and thus the distortion is high.	Reply	I-Reply	3
In the Lagrangian, the logarithm of is what appears, but the logarithm is a strictly increasing function.	Reply	I-Reply	3
Since, then the correct sign is as written, i.e. I(X;Z) - \alpha \log \ell(x|z).	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]2. &	Reply	O	0
4. -	Reply	B-Reply	4
suggestions taken.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token][line_break_token]	Reply	O	0

[Contribution summary][line_break_token]Authors propose a new model for the DST task that (1) reduces the inference time complexity with an non-autoregressive decoder, and (2) obtains the competitive DST accuracy (49.04% joint accuracy on MultiWoZ 2.1).	Review	O	0
[line_break_token][line_break_token][Comments][line_break_token]- The proposed model is well motivated and well structured.	Review	O	0
Empirical results show improvement over other baselines, with the main gain coming from delexicalization, slot gating, fertility output, etc.	Review	O	0
[line_break_token][line_break_token]- Some of the details are not entirely provided - e.g. please provide the loss hyper-parameter values (e.g. Eq.23) and optimizer parameters for the training.	Review	O	0
[line_break_token][line_break_token]- Overall presentation, notations, figures, etc.	Review	O	0
could improve.	Review	B-Review	2
[line_break_token][line_break_token]- There have been recent work on DST with new SOTA results (e.g. ‚ÄúTowards Scalable Multi-domain Conversational Agents: The Schema-Guided Dialogue Dataset‚Äù by Rastogi et al.) --	Review	O	0
please consider comparing the approaches.	Review	B-Review	3
[line_break_token]	Review	O	0
hank you very much for your review.	Reply	O	0
Below are our responses:[line_break_token][line_break_token]1.	Reply	O	0
About the details of parameter settings, we simply set the loss hyper-parameters and to 1.	Reply	B-Reply	1
 We set the optimizer parameters for training to,, and.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Thanks for pointing out the presentation issue.	Reply	B-Reply	2
We made some improvement including standardizing the notations.	Reply	I-Reply	2
We will further improve the paper presentation in the final version.	Reply	I-Reply	2
 [line_break_token][line_break_token]3.	Reply	O	0
Thanks for pointing out the new paper.	Reply	B-Reply	3
We note that the paper addresses a different setting and the authors employed a different evaluation metric instead of traditional joint goal accuracy.	Reply	I-Reply	3
This metric is based on a Fuzzy Matching score on non-categorical slots but traditional metric uses exact word matching instead.	Reply	I-Reply	3
 We are not sure if this metric is the one reported in the paper.	Reply	I-Reply	3
We also do not know how the authors decide which slot is categorical or non-categorical in the MultiWOZ benchmark.	Reply	I-Reply	3
Therefore, it is difficult for us to make a direct comparison of our model performance to this work.	Reply	I-Reply	3

This paper studies the importance of a neural networks weights and to which extend do they need to be updated.	Review	O	0
Particularly, the authors show that freezing weights which have small gradient in the very beginning of the training only results in a very slight drop in the final accuracy.	Review	O	0
[line_break_token][line_break_token]This paper should be rejected because (1) the paper only provides some empirical results on freezing network network weights, I don't think there are much insights and useful information; (2) To my knowledge, the phenomenon that only a few parameters are important has been observed before by many papers.	Review	O	0
[line_break_token][line_break_token]Given that, I vote for a rejection.	Review	O	0
hank you for your feedback.	Reply	O	0
To best of our knowledge, the previous studies have observed the process of freezing complete layers in a neural network unlike our studies that investigates the importance of the individual gradient parameters even in different layers without the need to freeze the complete layer and here lies the uniqueness of our study.	Reply	B-Reply	1

*Summary*[line_break_token]The authors perform RNA secondary prediction using deep learning.	Review	O	0
The outputs are subject to hard constraints on which nucleotides can be in contact with others.	Review	O	0
They unroll a sophisticated optimization algorithm for a relaxation of the task of finding the optimal contact map subject to these constraints.	Review	O	0
This work is in a long line of work demonstrating that end-to-end training of models that incorporate application-specific optimization routines as sub-modules is very useful.	Review	O	0
In particular, it outperforms an approach where the inputs to this optimization problem come from a network that was trained using a simple loss that ignores the fact that it will feed into this structured optimizer.	Review	O	0
The paper also considers an application domain that will be unfamiliar to many ICLR readers interested in deep structured prediction, and may serve as a call to arms for the community engaging with additional problems in this field.	Review	O	0
  [line_break_token][line_break_token]*Overall Assessment*[line_break_token]The paper is well written, well executed, and part of a general research thread that ICLR readers care about.	Review	O	0
There are a number of technical details, such as the loss function in (8) that will be of general interest.	Review	O	0
I advocate for acceptance.	Review	O	0
[line_break_token][line_break_token]*Comments*[line_break_token]The actual specification of the output constraints doesn't occur until late in the paper.	Review	O	0
Before then, the discussion of them is very abstract.	Review	B-Review	1
Given that the constraints are easy to describe, the exposition would be improved notably if you described the specific constraints earlier on.	Review	I-Review	1
This would help me understand the problem domain better.	Review	I-Review	1
[line_break_token][line_break_token]Fyi, the idea of nested structures vs. non-nested structures appears in NLP in terms of projective parsing vs. non-projective parsing.	Review	I-Review	2
There may be some relevant reading for you to do there.	Review	I-Review	2
Your specific work (minus the unrolled constraint enforcement) is similar to "Dozat et al.	Review	I-Review	2
2017.	Review	I-Review	2
Deep biaffine attention for neural dependency parsing."	Review	I-Review	2
[line_break_token][line_break_token]The idea of backpropping through some constraint-enforcing process is reminiscent of backpropping through belief propagation.	Review	I-Review	3
See, for example, Domke's "Learning Graphical Model Parameters with Approximate Marginals Inference."	Review	I-Review	3
Or Hershey et al. "	Review	I-Review	3
Deep Unfolding: Model-Based Inspiration of Novel Deep Architectures."	Review	I-Review	3
You should also cite work using unrolled ISTA to learn sparse coding dictionaries.	Review	I-Review	3
They have terms similar to (5).	Review	I-Review	3
[line_break_token][line_break_token]What exactly was your motivation for the setup in "Test On ArchiveII Without Re-training?"	Review	I-Review	4
[line_break_token][line_break_token]How sensitive is performance to the number of optimizer iterations?	Review	I-Review	5
Does it work to train with a fixed number of unrolled iters, but at test time run the optimizer until convergence?	Review	I-Review	6
[line_break_token][line_break_token](8) is cool!	Review	O	0
[line_break_token]	Review	O	0
e would like to thank the reviewer for the overall positive comments, constructive suggestions on paper refinement and references to interesting related works!	Reply	O	0
[line_break_token][line_break_token][line_break_token]***Q1.	Reply	O	0
 ‚Äú...output constraints doesn't occur until late...‚Äù[line_break_token][line_break_token]Thank you for your suggestion on the flow of our paper!	Reply	O	0
In the revised version, we state the RNA secondary structure prediction problem, including the concrete constraints, in a newly added section ‚Äú3 RNA Secondary Structure Prediction Problem‚Äù, which follows the Related Work section.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token]***Q2.	Reply	O	0
Related work in NLP[line_break_token][line_break_token]Thank you for referring us to these related works in NLP!	Reply	O	0
We also noticed the relation to NLP as we mentioned at the end of the introduction section.	Reply	B-Reply	2
This indeed motivates us to use transformers and also the trick mentioned in BERT to compute position information by a series of base functions.	Reply	I-Reply	2
However, it is interesting to know about projective parsing vs. non-projective parsing which we didn‚Äôt notice before!	Reply	I-Reply	2
We‚Äôve added a paragraph in the related work section to discuss this aspect.	Reply	I-Reply	2
Thank you for pointing it out, which can help us relate our work to a larger range of problems in ML.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]***Q3.	Reply	O	0
Related work on Graphical Models and ISTA[line_break_token][line_break_token]Thanks!	Reply	O	0
We found the ‚Äúdeep unfolding‚Äù work very related and cited it in the revised paper.	Reply	B-Reply	3
[line_break_token]In our first submission, we‚Äôve cited the unrolled ISTA paper ‚ÄúTheoretical linear convergence of unfolded ISTA and its practical weights and thresholds.	Reply	I-Reply	3
‚Äù[line_break_token][line_break_token][line_break_token]***Q4.	Reply	O	0
Motivation for the setup in "Test On ArchiveII Without Re-training"[line_break_token][line_break_token]One can think of ArchiveII as a separate held-out test dataset.	Reply	O	0
E2Efold is only learned from RNAStralign training set, but can directly generalize to ArchiveII, and obtain the best test results.	Reply	B-Reply	4
[line_break_token][line_break_token]In fact, testing on the ArchiveII dataset is a more challenging test for generalization, because the data distribution in ArchiveII can have a larger difference with the RNAStralign training set.	Reply	I-Reply	4
To see this, we performed additional statistical hypothesis tests using Maximum Mean Discrepancy (MMD)  [1] and attached the results in Appendix D.2.	Reply	I-Reply	4
[line_break_token][line_break_token]More specifically, we computed the empirical MMD to evaluate the differences between[line_break_token](a) RNAStralign_train and RNAStralign_test, where the MMD is 0.0025 (*can not reject* null hypothesis of no difference with p-value 0.1)[line_break_token](b) RNAStralign_train and ArchiveII, where the MMD is 0.0296 (*reject* null hypothesis of no difference with p-value &lt; 0.001)[line_break_token]These tests suggest that the difference between RNAStralign training set and ArchiveII is much larger.	Reply	O	0
[line_break_token][line_break_token]Therefore, the data distribution in ArchiveII is very different from the RNAStralign training set.	Reply	B-Reply	4
A good performance on ArchiveII shows a significant generalization power of our model.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]***Q5.	Reply	O	0
the number of optimizer iterations [line_break_token][line_break_token]For the explanation on the choice/effect of the number of optimizer iterations, please kindly refer to our response to this common question posted above.	Reply	O	0
[line_break_token][line_break_token][line_break_token]***Q6.	Reply	O	0
Does it work to train with a fixed number of unrolled iters, but at test time run the optimizer until convergence?‚Äù[line_break_token][line_break_token]It‚Äôs very interesting that the reviewer asked this question!	Reply	O	0
We were also curious about this before and tried it empirically.	Reply	B-Reply	6
We trained the model on T=20 and used it for T=50 iterations during the test phase.	Reply	I-Reply	6
However, the performance is not as good as keeping T=20 for the test.	Reply	I-Reply	6
[line_break_token][line_break_token]We think the reason could be: we choose the discounting factor in equation 9, which is also a default choice in some related works.	Reply	I-Reply	6
It gives the output at each time step T=t an equal weight.	Reply	I-Reply	6
With a smaller, the outputs at later steps can gain more weights.	Reply	I-Reply	6
In this case, it is possible that the trained network will output a progressively closer approximation of the ground truth and further generalize to a larger number of iterations.	Reply	I-Reply	6
We would investigate this option in the future.	Reply	I-Reply	6
[line_break_token][line_break_token][line_break_token]***Finally[line_break_token][line_break_token]Yes, we also like the differentiable F1 score!	Reply	O	0
Imbalanced data (more negative samples than positive samples) is a common issue in many computational biology problems (e.g. [4,5]) and our proposed method is very simple and effective in this case.	Reply	B-Reply	7
[line_break_token][line_break_token][line_break_token][1] Gretton, Arthur, et al. "	Reply	O	0
A kernel two-sample test."	Reply	O	0
JMLR (2012)[line_break_token][4] Zhou, Jian, and Olga G. Troyanskaya. "	Reply	O	0
Predicting effects of noncoding variants with deep learning‚Äìbased sequence model."	Reply	O	0
Nature methods 12.10 (2015): 931.	Reply	O	0
[line_break_token][5] Armenteros, Jos√© Juan Almagro, et al. "	Reply	O	0
SignalP 5.0 improves signal peptide predictions using deep neural networks."	Reply	O	0
Nature biotechnology 37.4 (2019): 420.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Please expect the revised paper posted soon	Reply	O	0

Authors provide a novel approach for outlier detection of SIFT feature matchings.	Review	O	0
They construct a graph by connecting each SIFT feature to its 5 nearest neighbors initially.	Review	O	0
Then optimize a regression loss to find the matching between the 2d keypoints and 3d universal points.	Review	O	0
Hence applying cycle-consistency to figure out image matchings.	Review	O	0
[line_break_token][line_break_token]Their formulation of the problem as a GNN pruning is brilliant and widens the path for future research in the feature matching field.	Review	O	0
They also incorporate epipolar line constraints as a regularizer for their training.	Review	O	0
Experiments show effectiveness of adding the epipolar constraints.	Review	O	0
[line_break_token][line_break_token]Their experiments show that this is a promising approach, but probably requires further research to achieve state of the art results.	Review	O	0
 [line_break_token][line_break_token]I believe this work is a valuable and novel method for pruning the sift feature matches.	Review	O	0
It is in an early but acceptable stage.	Review	O	0
Adding extra regularizers on F_v (to make it one-hot?)	Review	B-Review	1
would be a promising first step.	Review	I-Review	1
Also it has been shown that GNNs performance deteriorates with increased depth.	Review	I-Review	2
There are recent developments in GNNs that alleviate the oversmoothing problem.	Review	I-Review	2
Maybe switching to these architectures would enable this work to try 15 pass GNNs.	Review	I-Review	2
[line_break_token][line_break_token]Question: How do you tune the hyper-parameters? (	Review	O	0
learning rate, number of layers, etc)[line_break_token][line_break_token]Improvement: In the experiment section explain the specifics of the geometric loss, how camera calibration, etc is calculated.	Review	O	0
 ‚ÄúAdding extra regularizers on F_v (to make it one-hot?)	Reply	O	0
would be a promising first step.	Reply	O	0
‚Äù[line_break_token][line_break_token]Indeed this would mean to enforce the image to universe mapping to be a partial permutation.	Reply	O	0
We could even add a differential step that rotates the ‚Äúsoft‚Äù image to universe mapping to a partial permutation.	Reply	B-Reply	1
We preferred to avoid any of those steps in order to keep the soft mapping as a feature representation which we can prune in order to compute hard matches.	Reply	I-Reply	1
But we agree that we have to investigate how such a loss term (or the rotation step) would affect the final matching outcome and we will definitely add it to our experiments.	Reply	I-Reply	1
[line_break_token][line_break_token]- ‚ÄúAlso it has been shown that GNNs performance deteriorates with increased depth.	Reply	O	0
There are recent developments in GNNs that alleviate the oversmoothing problem.	Reply	O	0
Maybe switching to these architectures would enable this work to try 15 pass GNNs.	Reply	O	0
‚Äù[line_break_token][line_break_token]This is a good observation, as we indeed noticed that after 12 passes of the GNN their were diminishing returns even with skip connections.	Reply	O	0
Looking over such architectures will be important for future work.	Reply	B-Reply	2
[line_break_token][line_break_token]- ‚ÄúQuestion: How do you tune the hyper-parameters? (	Reply	O	0
learning rate, number of layers, etc)‚Äù[line_break_token][line_break_token]For the architecture, we searched over increasing sized networks, starting with 4 layers and going up to 15, searching various numbers of hidden nodes.	Reply	O	0
We also explored various extensions such as Graph Convolutional Networks, Graph Attention Networks, and (what we finally decided on) Graph Networks from Deepmind‚Äôs graph network library.	Reply	B-Reply	3
For other hyperparameters, we searched in log-linear space.	Reply	I-Reply	3
[line_break_token][line_break_token]- ‚ÄúImprovement: In the experiment section explain the specifics of the geometric loss, how camera calibration, etc is calculated.	Reply	O	0
‚Äù[line_break_token][line_break_token]We will add details on the calibration in the paper, and how the geometric loss is computed into the appendix.	Reply	O	0

This paper investigates the issue of whether and how to use syntactic dependencies in unsupervised word representation learning models like CBOW or Skip-Gram, with a focus one the issue of bound (word+dependency type, 'She-nsubj') vs. unbound (word alone, 'She') representations for context at training time.	Review	O	0
The empirical results are extremely mixed, and no specific novel method consistently outperforms existing methods.	Review	O	0
[line_break_token][line_break_token]The paper is systematic and I have no major concerns about its soundness.	Review	O	0
However, I don't think that this paper is of broad interest to the ICLR community.	Review	O	0
The paper is focused on a fairly narrow detail of representation learning that is entirely specific to NLP, and its results are primarily negative.	Review	O	0
A short paper at an ACL conference would be a more reasonable target.	Review	O	0
Dear reviewer,[line_break_token]A new version of this paper is uploaded and we are exited to share the results with you.	Reply	O	0
[line_break_token]Please see our recent comment for more information.	Reply	O	0
Thanks	Reply	O	0

This paper proposes a neural architecture search (NAS) algorithm which automatically finds a efficient network architecture, FasterSeg, for real time semantic segmentation.	Review	O	0
In designing a NAS algorithm the author takes cue from recent architectural advances introduced for faster segmentation as well as improved accuracy.	Review	O	0
For instances a) it explores and integrates multi-resolution branches from BiSeNet during NAS b) simultaneously optimizes the loss for accuracy and latency (as done in CAS algorithm) and c) knowledge distillation for semantic segmentation.	Review	O	0
However, the usage of these blocks in FasterSeg has been well refined to integrate with NAS search.	Review	O	0
To be precise, their improved version of latency loss avoids architectural collapse during latency-constrained search and it claims to be the first work to co-search for teacher and student network using NAS.	Review	O	0
Empirical experiments on benchmark dataset suggests that FasterSeg  is more than 30 percent faster with similar accuracy as state-of-the-art real-time segmentation algorithms.	Review	O	0
[line_break_token][line_break_token]This paper weakly leans towards rejection.	Review	O	0
Some of the contributing factors [line_break_token]1) Overall presentation of algorithm leaves one more confused.	Review	O	0
Perhaps, the paper is targeted at small set of audience who primarily works on NAS.	Review	B-Review	1
More about specific comment in 'Clarification'.	Review	I-Review	1
[line_break_token]2) There is not a single concrete contribution.	Review	O	0
For example, NAS search in semantic segmentation using cells and downsampling rates was done in Auto-Deeplab.	Review	B-Review	2
Further, resource-constrained search for segmentation was introduced in Zhang et al while distillation for segmentation task was proposed by Liu et al.	Review	I-Review	2
[line_break_token]3) No doubt that it achieves improved efficiency.	Review	O	0
But at the cost of accuracy.	Review	B-Review	3
On Camvid and BDD, the competitive algorithm is 1.7 % better in absolute terms.	Review	I-Review	3
On cityscapes it performs on par.	Review	I-Review	3
However, the large improvement in accuracy can be attributed to distillation process (Table 3: absolute 2%), without which the overall performance of NAS is suboptimal.	Review	I-Review	3
[line_break_token][line_break_token]Clarification:[line_break_token]1.	Review	O	0
It is not clear what is the form of initial network which is pre-trained for 20 epochs ?	Review	B-Review	4
My guess is, initial network consists of b=3 branches with L=16 sequential layers and for each cell in a layer, the network pre-trains 5 operators as well as for different expansion ratios.	Review	I-Review	4
Is it correct ?	Review	I-Review	4
[line_break_token]2.	Review	I-Review	14
Can you explain 697 unique paths as well as 10^55 unique combinations ?	Review	I-Review	5
[line_break_token]3.	Review	I-Review	7
It is noted that by default b=2 is used.	Review	I-Review	6
However, in FasterSeg network shown in figure 6, I note three branches s={8,16,32}. Am I missing something ?	Review	I-Review	6
Also, how more branches will introduce more latency ?	Review	I-Review	6
Branches operate in parallel with max sensitivity s=0.01 and max L=16.	Review	I-Review	6
[line_break_token]4.	Review	O	0
Next, as pointed in 3.4 the discrete architecture is obtained by computing \argmax_l over \beta.	Review	B-Review	7
In that case, there should only be single connection which branches out from s-&gt;2s.	Review	O	0
In figure 6, I note two branches from 8-&gt;16 (4th and 6th cell).	Review	O	0
[line_break_token]5.	Review	O	0
If the teacher and student network shares the same weight, then what is the need for distillation ?	Review	B-Review	8
Only difference I currently note is in the expansion ratio.	Review	I-Review	8
May be you want to say same pretrained network ?	Review	I-Review	8
[line_break_token]6.	Review	I-Review	6
Can you explain with example how \gamma's are updated using backpropagation and lookup-table ?	Review	I-Review	9
[line_break_token]7.	Review	O	0
Are you employing STE for Gumbel-Max trick ?	Review	B-Review	10
[line_break_token]8.	Review	O	0
The individual terms in eq (3) optimizes for \alpha, \beta and \gamma respectively ?	Review	B-Review	11
[line_break_token]9.	Review	O	0
In eq (2), each cell output O is linear combination of different operator ?	Review	B-Review	12
[line_break_token]10.	Review	O	0
Once the discrete architecture is obtained, is it retrained on cityscapes from scratch or fine-tuned ?	Review	B-Review	13
[line_break_token][line_break_token]Request for ablation:[line_break_token]1.	Review	I-Review	14
What is the variation in NAS output with changes in \lambda ?	Review	I-Review	14
Precisely, can one tradeoff accuracy for improved latency just by tuning \lambda ?	Review	I-Review	14
[line_break_token]2.	Review	I-Review	14
What happens if teacher network is also optimised over \gamma ?	Review	I-Review	14
The difference between teacher and student will then only be in loss function.	Review	I-Review	14
[line_break_token]3.	Review	I-Review	7
Currently, discrete architecture is greedily extracted.	Review	I-Review	14
This need not be the best.	Review	I-Review	14
Instead one can utilize sequential beam search (vitterbi algorithm).	Review	I-Review	14
With this it is possible to visualise the accuracy and latency distribution of, say top 100 architecture obtained by NAS.	Review	I-Review	14
[line_break_token][line_break_token]Minor comments:[line_break_token]1.	Review	I-Review	15
Seachable -&gt; Searchable[line_break_token][line_break_token]Updates:[line_break_token]I read through the reviews of other reviewers as well as the rebuttal posted by authors.	Review	O	0
Overall, I am satisfied with the authors response and hence Improving my scores to Weak Accept.	Review	O	0
hank you for your time and comments.	Reply	O	0
We have revised our paper and we believe our responses and revisions address all your concerns.	Reply	O	0
We would be very grateful if you would please look over our paper again, and consider changing your scores.	Reply	O	0
[line_break_token][line_break_token]Indeed, our paper primarily targets at contributions to the NAS fields.	Reply	B-Reply	1
 However, we also expect the work to provide broad reference values to the general audience working on related computer vision problems.	Reply	I-Reply	1
We apologize if our paper didn‚Äôt read smoothly to you at the first glance: we have addressed all your specified ‚Äúclarification‚Äù comments and hope our work‚Äôs merit now becomes more clear to you.	Reply	I-Reply	1
[line_break_token][line_break_token]We respectfully cannot agree on your comment ‚Äúthere is not a single concrete contribution‚Äù.	Reply	I-Reply	2
We apologize if your misunderstanding arose from our lack of writeup clarity or else.	Reply	I-Reply	2
Please see our detailed explanations below.	Reply	I-Reply	2
[line_break_token][line_break_token]First of all, we are well aware of NAS search works done in semantic segmentation.	Reply	I-Reply	2
Meanwhile, in most NAS papers published, designing novel search spaces and improving the search algorithms are considered as the two core contributions to claim: see [1,2,3] for example.	Reply	I-Reply	2
They are also what makes FasterSeg substantially different and novel from Auto-DeepLab.	Reply	I-Reply	2
 As confirmed by other reviewers, both our multiscale search space, the regularized latency optimization, and the co-searching algorithm are significant contributions.	Reply	I-Reply	2
They are for the first time proposed, well-motivated, and supported by our solid ablation studies.	Reply	I-Reply	2
Furthermore, we push the performance of real-time segmentation to a new state of the art.	Reply	I-Reply	2
[line_break_token][line_break_token]Second, our distillation is not appended as a post-processing to the searched/designed models as done in the mentioned literature.	Reply	I-Reply	2
Instead, integrating distillation into the NAS framework (and therefore enabling jointly search multiple networks) is the KEY.	Reply	I-Reply	2
This is confirmed by the last two rows in Table 3, where we distill to the pruned teacher net and to our search student net respectively, from the same teacher network.	Reply	I-Reply	2
With the same distillation training setting, the pruned teacher is 6% worse than our searched student, indicating that the important reason for our FasterSeg‚Äôs superior performance is in the optimized architecture.	Reply	I-Reply	2
[line_break_token][line_break_token]In sum, while we all agree that neither ‚Äú(efficient) NAS for segmentation‚Äù nor ‚Äúdistillation‚Äù is novel now, our methods‚Äô contributions are concretely established, well beyond those.	Reply	I-Reply	2
Hopefully, the above answers have resolved your confusion on our novelty.	Reply	I-Reply	2
[line_break_token][line_break_token]In the experiments, by further fine-tuning our FasterSeg, we are now able to achieve 71.5% on Cityscapes test set, bypassing all previous works on both mIoU and FPS in Table 4, making CityScape our clear all-win case.	Reply	I-Reply	3
In Table 5 and 6, our FasterSeg now achieves 71.1% and 54.9% respectively, reaching the same bar on mIoU as CAS and DRN, while surpassing their latency by over-doubling the FPS.	Reply	I-Reply	3
[line_break_token][line_break_token]Notice that, we target at extremely efficient segmentation, for our own specific application needs at very high FPSs (~150 - ~400).	Reply	I-Reply	3
Such is considered as "well-motivated" by the other two reviewers.	Reply	I-Reply	3
To meet that demanding requirement, our model is clearly the best option available that can still maintain state-of-the-art mIOUs in addition to its unparalleled efficiency.	Reply	I-Reply	3
[line_break_token][line_break_token]We note that the other two reviewers concur and appreciate our paper‚Äôs novelty points well.	Reply	O	0
We are more than happy to provide extra clarification and justifications if needed.	Reply	O	0
[line_break_token][line_break_token][1] Bender, Gabriel, Pieter-Jan Kindermans, Barret Zoph, Vijay Vasudevan, and Quoc Le. "	Reply	O	0
Understanding and simplifying one-shot architecture search."	Reply	O	0
ICML 2018.	Reply	O	0
[line_break_token][2] Liu, Chenxi, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li, Li Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy. "	Reply	O	0
Progressive neural architecture search."	Reply	O	0
ECCV 2018.	Reply	O	0
[line_break_token][3] Cai Han, Ligeng Zhu, and Song Han. "	Reply	O	0
Proxylessnas: Direct neural architecture search on target task and hardware."	Reply	O	0
ICLR 2019	Reply	O	0

The contribution of the paper is the following two findings: 1.	Review	B-Review	1
Despite the fact that local minima are connected in the loss landscape the functions corresponding to the points on the curve are significantly distinct.	Review	I-Review	1
2.	Review	I-Review	1
The points along the training trajectory correspond to similar functions.	Review	I-Review	1
[line_break_token][line_break_token]Originality and novelty.	Review	I-Review	2
Both findings do not seem quite new.	Review	I-Review	2
The first conclusion can be mostly derived from Figure 2 right [1]. Moreover, the difference between functions on the curve in terms of predictions is the main motivation of Fast Geometric Ensembling.	Review	I-Review	2
The second conclusion is also not quite new and there were several approaches to overcome it e.g. SWA [2]. I appreciate that the authors did a much broader investigation of this phenomena than it was done in previous works.	Review	I-Review	3
Another drawback is lack of practical implications.	Review	I-Review	4
It is known that ensembling based on dropout is worse than independent networks, but the main advantage of this and similar approaches is memory efficiency.	Review	I-Review	4
[line_break_token][line_break_token]The clarity.	Review	O	0
The paper is well written, contains all necessary references and is easy to follow.	Review	O	0
The provided experimental results and supporting plots are also clear and contain the necessary description.	Review	O	0
The only part that I found a bit confusing is radial plots.	Review	O	0
I would recommend the authors to add more rigorous description of how they constructed these plots to increase clarity of the paper.	Review	B-Review	5
Can the authors please also clarify how they derived formulas for the expected fractional difference for f^* and f functions in the section 3.2?	Review	I-Review	5
[line_break_token][line_break_token]Overall, it is an interesting paper, but the findings are not quite new.	Review	O	0
[line_break_token][1]  Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry P Vetrov, and Andrew G Wilson.	Review	O	0
Loss surfaces, mode connectivity, and fast ensembling of DNNs.	Review	O	0
InNeurIPS, 2018[line_break_token][2] Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson.	Review	O	0
Av-eraging weights leads to wider optima and better generalization.arXiv preprint arXiv:1803.05407,2018[line_break_token]	Review	O	0
hank you for your review.	Reply	O	0
[line_break_token][line_break_token]‚ÄúThe contribution of the paper is the following two findings: 1.	Reply	O	0
Despite the fact that local minima are connected in the loss landscape the functions corresponding to the points on the curve are significantly distinct.	Reply	O	0
2.	Reply	O	0
The points along the training trajectory correspond to similar functions. ‚	Reply	O	0
Äú [line_break_token][line_break_token]These comments seem focused on particular subsections (Section 3.3 and Section 3.1) and significantly under-estimates the total contributions of our paper.	Reply	O	0
[line_break_token][line_break_token]To the best of our knowledge, we are the first to comprehensively investigate deep ensembles vs Bayesian neural nets from loss landscape perspective.	Reply	B-Reply	1
We carefully investigated the role of random initialization in deep ensembles, tested the complementary effects of ensembling and subspace methods, and measured diversity of functions.	Reply	I-Reply	1
Aside from earlier results on CIFAR-10 and ImageNet, we have also added new experiments on CIFAR-100 (see Figure S3 in Appendix C) which are consistent with our earlier results.	Reply	I-Reply	1
[line_break_token][line_break_token]Please see also the summary of contributions from other reviewers.	Reply	I-Reply	1
[line_break_token][line_break_token]R1 said ‚ÄúThis paper analyzes ensembling methods in deep learning from the perspective of the loss landscapes.	Reply	I-Reply	1
The authors empirically show that popular methods for learning Bayesian neural networks produce samples with limited diversity in the function space compared to modes of the loss found using different random initializations ... The paper also demonstrates the complementary benefits of using subspace sampling/weight averaging in combination with deep ensembles and shows that relative benefits of deep ensembles are higher. ‚	Reply	I-Reply	1
Äú[line_break_token][line_break_token]R2 said ‚ÄúThis paper is trying to answer the question why ensembles of deep neural networks trained with random initialization work so well in practice in improving accuracy ... Overall, the paper is very well written and provides interesting insights into the multi-modal structure of deep neural network loss landscapes.	Reply	I-Reply	1
‚Äù[line_break_token][line_break_token]--------------[line_break_token][line_break_token]‚ÄúI would recommend the authors to add more rigorous description of how they constructed these plots to increase clarity of the paper.	Reply	O	0
Can the authors please also clarify how they derived formulas for the expected fractional difference for f^* and f functions in the section 3.2? ‚	Reply	O	0
Äú[line_break_token][line_break_token]We have added the derivation of the two limiting functions in the appendix.	Reply	O	0
The upper limit corresponds to the best case for ensembling, where the two functions are uncorrelated.	Reply	B-Reply	5
The lower limit corresponds to the worst case, where the predictions are obtained by perturbing the outputs of the reference function by different amounts of noise, therefore retaining a large amount of correlation between their predictions.	Reply	I-Reply	5
We provide the detailed derivation in the appendix our updated version.	Reply	I-Reply	5
[line_break_token][line_break_token]--------------[line_break_token][line_break_token]‚ÄúThe first conclusion can be mostly derived from Figure 2 right of Garipov et al.	Reply	O	0
‚Äù [line_break_token][line_break_token]We do not agree that this conclusion can be reached from that figure as you are suggesting.	Reply	O	0
Figure 2 in Garipov et al.	Reply	B-Reply	2
only plots loss and accuracy, and does not measure function space similarity, between different initializations, or along the tunnel at all.	Reply	I-Reply	2
Just by looking at accuracy and loss values, there is no way to infer how similar the predictions of the two functions are.	Reply	I-Reply	2
[line_break_token][line_break_token]--------------[line_break_token][line_break_token]‚ÄúThe second conclusion is also not quite new and there were several approaches to overcome it e.g. SWA [2].‚Äù[line_break_token][line_break_token]We are not sure what exactly you mean.	Reply	O	0
Could you clarify your claim?	Reply	B-Reply	3
[line_break_token]We showed that functions along a trajectory (or subspace thereof) are similar whereas ensembling over random initializations leads to much more diversity; see sections 3.2 for diversity vs accuracy plots and Section 4 where we measure the relative effects of ensembles and subspace sampling methods.	Reply	I-Reply	3
These results indicate that random initialization provides more diversity than subspace sampling methods.	Reply	I-Reply	3
[line_break_token][line_break_token]--------------[line_break_token][line_break_token]‚ÄúAnother drawback is lack of practical implications.	Reply	O	0
It is known that ensembling based on dropout is worse than independent networks, but the main advantage of this and similar approaches is memory efficiency.	Reply	O	0
‚Äù[line_break_token][line_break_token]We‚Äôre happy to add a discussion about different regimes (training time constraints, serving time constraints, memory constraints, etc), but it is beyond the scope of this paper to discuss every possible setting in detail.	Reply	O	0
Some of these solutions are well-known in the literature, cf.	Reply	B-Reply	4
the discussion in (Lakshminarayanan et al.	Reply	I-Reply	4
2017) or the take-home messages in (Ovadia et al.	Reply	I-Reply	4
2019): for instance, distillation is a popular solution when serving time is the primary constraint.	Reply	I-Reply	4
Implicit ensembles (e.g. Monte-Carlo dropout) are popular when memory is the main constraint.	Reply	I-Reply	4
The best method would obviously depend on the specific constraints (as you also point out).	Reply	I-Reply	4
[line_break_token][line_break_token]The goal of this work is to understand the general question of why ensembles work well and we provide an explanation from the perspective of loss landscapes.	Reply	I-Reply	4
In future work, we plan to take these insights to develop better algorithms for specific settings	Reply	I-Reply	4

[line_break_token]This paper studies the accuracy vs model-size trade-off of quantized CNNs under different channel width multipliers.	Review	O	0
The authors demonstrated that while all-to-all convolution works well under low bit settings, depthwise conv needs a different sweet spot.	Review	O	0
The authors then proceed to use the insight to design quantized cnns that have two different schemes for depthwise and normal conv.	Review	O	0
[line_break_token][line_break_token][line_break_token]Strength[line_break_token][line_break_token]The paper is well written and motivated.	Review	O	0
By adding network width to the search space,  using the simple heuristics, the authors provide a better results than previously DRL based search method.	Review	O	0
[line_break_token][line_break_token]Weakness[line_break_token][line_break_token]One of my main concerns is the direct usage of total number of bits as an equivalent measurement between models.	Review	O	0
While it is useful to measure the storage cost for weights.	Review	B-Review	1
The choices of bit width will likely affect the computing cost in a non-trivial way, depending on the target hardware platform.	Review	I-Review	1
It is unclear whether equal model size would mean equal inference latency in practice (most likely they would not be).	Review	I-Review	1
Providing empirical implementations of these models will shed light into this question.	Review	I-Review	1
[line_break_token][line_break_token]These weakness makes it a borderline paper.	Review	O	0
[line_break_token][line_break_token]Question:[line_break_token][line_break_token]How do you handle batchnorm layer, do you use floating points?	Review	O	0
[line_break_token][line_break_token]How many bits did you use for accumulating the results?	Review	B-Review	3
[line_break_token][line_break_token]Update after rebuttal:[line_break_token][line_break_token]I have read the authors' response.	Review	O	0
I would like to keep my current review as it is.	Review	O	0
Also note that the authors uses floating pt for batchnorm and 32 bit for accumulation, such additional cost might out-weights the benefit of choosing ultra low bits in the low bits regime, making the study less relevant for practice reasons[line_break_token][line_break_token][line_break_token]	Review	B-Review	2
e thank the reviewer for their feedback and for finding our paper well-written and motivated.	Reply	O	0
[line_break_token][line_break_token]Regarding your main concern, we agree that it is non-trivial to see if equal model size reflects compute (in terms of latency and/or energy) since it depends on the application scenario and software/hardware implementation.	Reply	B-Reply	1
However, our insights and good results from the model size standpoint set a strong motivation for future study to target a specific application scenario and research on hardware acceleration.	Reply	I-Reply	1
We argue that this does not constitute a weakness for our paper since there are scenarios where model sizes is important.	Reply	I-Reply	1
From the perspective of information theory and Minimum Description Length (MDL) principle [1,2], our results show that by trading weight precision values with the number of channels, one can achieve a smaller description length for the model with equal accuracy, which is more preferable based on the MDL principle.	Reply	I-Reply	1
Moreover, considering edge devices that are deployed for streaming inference scenarios (single image per batch), our analyses in the updated manuscript (Appendix F and Figure 6) show lower memory footprint is needed for the proposed model to achieve equally accurate results compared to the baseline.	Reply	I-Reply	1
We argue that for streaming inference applications that run on IoT devices, model size is an important factor due to their limited RAM.	Reply	I-Reply	1
[line_break_token][line_break_token]Beyond the above argument for the efficacy of DualPrecision, we would like to re-iterate that our contributions are more than the proposed DualPrecision method.	Reply	I-Reply	1
Specifically, the following three contributions are non-trivial, novel, and can be built upon for future study:[line_break_token]-[tab_token]We are the first to show that lower precision weight values outperform higher precision weight values in a Pareto sense (accuracy vs. model size) for networks with standard convolutions.	Reply	I-Reply	1
This is intriguing since it implies that scaling up (in terms of model size) along the channel count dimension is more effective for accuracy than the precision value dimension.	Reply	I-Reply	1
This finding can lead to follow-up works trying to understand or exploit this phenomenon.	Reply	I-Reply	1
[line_break_token][line_break_token]-[tab_token]We are the first to show that the fan-in channel counts per output filter for a convolution layer determine the effectiveness of accuracy improvement along the weight precision dimension and provide both theoretical and empirical reasoning for this.	Reply	I-Reply	1
This finding is useful for future works that are interested in optimizing the neural architecture regarding both channel counts and weight precision as we show what might affect the effectiveness of weight precision scaling.	Reply	I-Reply	1
[line_break_token][line_break_token]-[tab_token]We are the first to show that with a simple scaling rule, one can achieve a more accurate model (given the same model size) even compared to mixed-precision prior art that uses DRL to search for layer-wise weight precision values.	Reply	I-Reply	1
Moreover, the results are validated on the large-scale dataset, i.e., ImageNet.	Reply	I-Reply	1
This is a manifestation of our two previous findings.	Reply	I-Reply	1
[line_break_token][line_break_token]We hope the reviewer can take into account the above-listed contributions and their potential impacts when making the final recommendation.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the questions, we use floating-point for batch norm.	Reply	I-Reply	2
The accumulation of results is done in 32 bits (We simulate the quantization process in PyTorch according to Figure C.4 in [3]).	Reply	I-Reply	2
[line_break_token][line_break_token][1] Blier, L√©onard, and Yann Ollivier. "	Reply	O	0
The description length of deep learning models."	Reply	O	0
NeurIPS 2018.	Reply	O	0
[line_break_token][2] Havasi, Marton, Robert Peharz, and Jos√© Miguel Hern√°ndez-Lobato. "	Reply	O	0
Minimal Random Code Learning: Getting Bits Back from Compressed Model Parameters."	Reply	O	0
ICLR 2019.	Reply	O	0
[line_break_token][3] Benoit Jacob, Skirmantas  Kligys,  Bo  Chen,  Menglong  Zhu,  Matthew  Tang,  Andrew  Howard,Hartwig Adam, and Dmitry Kalenichenko.	Reply	O	0
Quantization and training of neural networks for effi-cient integer-arithmetic-only inference.	Reply	O	0
InThe IEEE Conference on Computer Vision and PatternRecognition (CVPR), June 2018	Reply	O	0

The paper studies learning in deep neural networks with hard activation functions, e.g. step functions like sign(x).	Review	O	0
Of course, backpropagation is difficult to adapt to such networks, so prior work has considered different approaches.	Review	O	0
Arguably the most popular is straight-through estimation (Hinton 2012, Bengio et al.	Review	O	0
2013), in which the activation functions are simply treated as identity functions during backpropagation.	Review	O	0
More recently, a new type of straight-through estimation, saturated STE (Hubara et al.,	Review	O	0
2016) uses 1[|z|<1] as the derivative of sign(z).	Review	O	0
[line_break_token][line_break_token]The paper generalizes saturated STE by recognizing that other discrete targets of each activation layer can be chosen.	Review	O	0
Deciding on these targets is formulated as a combinatorial optimization problem.	Review	O	0
Once the targets are chosen, updating the weights of each layer to minimize the loss on those targets is a convex optimization.	Review	O	0
The targets are heuristically updated through the layers, starting out the output using the proposed feasibility target propagation.	Review	O	0
At each layer, the targets can be chosen using a variety of search algorithms such as beam search.	Review	O	0
[line_break_token][line_break_token]Experiments show that FTP often outperforms saturated STE on CIFAR and ImageNet with sign and quantized activation functions, reaching levels of performance closer to the full-precision activation networks.	Review	O	0
[line_break_token][line_break_token]This paper's ideas are very interesting, exploring an alternative training method to backpropagation that supports hard-threshold activation functions.	Review	O	0
The experimental results are encouraging, though I have a few questions below that prevent me for now from rating the paper higher.	Review	O	0
[line_break_token][line_break_token]Comments and questions:[line_break_token][line_break_token]1) How computationally expensive is FTP?	Review	O	0
The experiments using ResNet indicate it is not prohibitively expensive, but I am eager for more details.	Review	B-Review	1
[line_break_token][line_break_token]2) Does (Hubara et al.,	Review	O	0
2016) actually compare their proposed saturated STE with the orignal STE on any tasks?	Review	B-Review	2
I do not see a comparison.	Review	I-Review	2
If that is so, should this paper also compare with STE?	Review	I-Review	2
How do we know if generalizing saturated STE is more worthwhile than generalizing STE?	Review	I-Review	2
[line_break_token][line_break_token]3) It took me a while to understand the authors' subtle comparison with target propagation, where they say "Our framework can be viewed as an instance of target propagation that uses combinatorial optimization to set discrete targets, whereas previous approaches employed continuous optimization."	Review	O	0
It seems that the difference is greater than explicitly stated, that prior target propagation used continuous optimization to set *continuous targets*. (One could imagine using continuous optimization to set discrete targets such as a convex relaxation of a constraint satisfaction problem.)	Review	B-Review	3
Focusing on discrete targets gains the benefits of quantized networks.	Review	I-Review	3
If I am understanding the novelty correctly, it would strengthen the paper to make this difference clear.	Review	I-Review	3
[line_break_token][line_break_token]4) On a related note, if feasible target propagation generalizes saturated straight through estimation, is there a connection between (continuous) target propagation and the original type of straight through estimation?	Review	O	0
[line_break_token][line_break_token]5) In Table 1, the significance of the last two columns is unclear.	Review	O	0
It seems that ReLU and Saturated ReLU are included to show the performance of networks with full-precision activation functions (which is good).	Review	B-Review	5
I am unclear though on why they are compared against each other (bolding one or the other) and if there is some correspondence between those two columns and the other pairs, i.e., is ReLU some kind of analog of SSTE and Saturated ReLU corresponds to FTP-SH somehow?	Review	I-Review	5
Thank you for your review.	Reply	O	0
We respond to each of your questions below.	Reply	O	0
[line_break_token][line_break_token]1) FTP-SH is no more expensive than backprop (in the same way that SSTE isn‚Äôt either, and SSTE is a special case of FTPROP-MB).	Reply	O	0
The only added cost is that the soft hinge loss requires computing an exponential, which is slower than a max (i.e., the cost of computing a sigmoid vs. a ReLU), but this is a minor difference in compute time.	Reply	B-Reply	1
[line_break_token][line_break_token]2) In the experiments, Hubara et al. (	Reply	O	0
2016) does not compare SSTE and STE directly, but in the text of the paper they report that ‚ÄúNot [saturating] the gradient when [the input] is too large significantly worsens performance.	Reply	B-Reply	2
‚Äù This is also what we found in preliminary experiments, where the unsaturated STE is significantly worse than STE.	Reply	I-Reply	2
Note, however, that STE is also a special case of our framework where the loss function is just loss(z, t) = -zt, so we generalize that as well (and pretty much any type of STE can be obtained by choosing different losses in our framework).	Reply	I-Reply	2
[line_break_token][line_break_token]3) Yes, this is a good point and correct.	Reply	O	0
We will update the paper to make this fact more clear.	Reply	B-Reply	3
Thank you.	Reply	O	0
[line_break_token][line_break_token]4) It‚Äôs possible, although if so it‚Äôs not an obvious connection, and we haven‚Äôt studied this issue in detail yet.	Reply	O	0
[line_break_token][line_break_token]5) Yes, good point.	Reply	O	0
This is somewhat confusing, and we will clarify it in the paper and remove the bolding, since the goal isn‚Äôt really to compare them against each other (although it is mildly interesting that saturating the ReLU improves performance in some cases).	Reply	B-Reply	5
There is no correspondence between those two columns and the other pairs; the formatting of the table is just unclear	Reply	I-Reply	5

The paper proposes a means of improving the predictions of a "simple" (low-capacity) model.	Review	O	0
The idea is to take the predictions of a "complex" (high-capacity) model, and weight the loss in the simple model based on the ratio of complex to simple models' predictions.	Review	O	0
Intuitively, this seeks to focus on instances which the complex model can fit, but the unweighted simple model cannot.	Review	O	0
Experiments show the proposed method to have some benefits over existing approaches.	Review	O	0
[line_break_token][line_break_token]The application of importance-weighting to the "model distillation" problem is interesting, and the paper gives a reasonable intuition for why this approach might work.	Review	B-Review	5
One general comment is that in contrasting their approach to a number of existing approaches, they note that several of them are typically employed with fairly complex simple models (e.g., neural networks).	Review	I-Review	5
This may be true, but it was not clear that any of them require this to be the case.	Review	I-Review	5
Surely they can also be used with simple models as ones you consider in the paper?	Review	I-Review	5
In this case, I would've liked more elucidation as to why the proposed method can be expected to offer superior performance.	Review	I-Review	5
[line_break_token][line_break_token]The theoretical justification of the approach is provided by means of Lemmas 3.1 and 3.2, for which I have some comments:[line_break_token]- Lemma 3.1: the notation here is a bit imprecise.	Review	I-Review	6
In general, a loss for example (x, y) takes in a true label y and predicted score z(x).	Review	I-Review	6
You refer to the loss of a probabilistic prediction p(y | x), but do not refer to the actual label y itself.	Review	I-Review	6
From the proof, it is implicit that you are considering y to be binary, and the use of a margin loss.	Review	I-Review	6
This is ok, but for the hinge loss one doesn't use a probability estimate p(y | x) as input to the loss, but rather, a real-valued score.	Review	I-Review	6
[line_break_token][line_break_token]I think the result itself could be proven by noting that if œÜ is non-increasing and q &lt; p, then œÜ(p)/œÜ(q) &lt;= 1 &lt; p/q.	Review	O	0
[line_break_token][line_break_token]- Lemma 3.2: the result is interesting, but it seems that for practical purposes you are only using the first term, since it is the only quantity that depends on Œ∏. Since max(1, .) &	Review	O	0
gt;= 1 and -log pŒ∏(y | x) &gt;= 0, it seems one could trivially bound the LHS by the first term since -log pŒ∏(y | x) &lt;= max(1, .) *	Review	O	0
-log pŒ∏(y | x)?	Review	B-Review	7
Would this not suffice for the purposes of justifying your method?	Review	I-Review	7
It should also be noted here how the subsequent requirement that the weights be capped (so as to prevent outliers) fits into the analysis.	Review	I-Review	7
[line_break_token][line_break_token]In describing the method itself, the authors introduce a notion of Œ¥-graded subsets.	Review	I-Review	4
I found this to be a bit difficult to parse, and it was not clear why this notion was needed.	Review	I-Review	4
It does not seem to feature in the description of Algorithm 1, nor the subsequent discussion.	Review	I-Review	4
On the other hand, I felt that the meaning and need for parameters Œ≤ and Œ≥ ought to have been discussed more prominently upfront.	Review	I-Review	4
[line_break_token][line_break_token]The experiments show favourable performance of the proposed method over baselines, including the distillation approach of Hinton.	Review	I-Review	1
The datasets are mostly small-scale, but this is in keeping with the goal of the paper, viz.	Review	I-Review	1
addressing scenarios where simple models may be desired.	Review	I-Review	1
Per earlier comments, I did not have a deep sense of what additional information the proposed method exploits so as to improve performance.	Review	I-Review	1
I gather that the weighting including the predictions of the simple model is one difference; it might have been nice to give a sense of what fraction of points this amplifies or suppresses, compared to just using the predictions of the complex model.	Review	I-Review	2
[line_break_token][line_break_token]There is a nice illustration in Fig 1 (right) as to the class-labels of the training samples assigned various weights.	Review	I-Review	2
This shows that points with low weight tend to have low agreement with their neighbours' labels.	Review	I-Review	2
One question is how using a nearest neighbour probability estimate itself (i.e., using this as the "complex" model) would fare.	Review	I-Review	2
[line_break_token][line_break_token]Minor comments:[line_break_token]- the title is a bit confusing.	Review	I-Review	3
It is not clear what "its" refers to.	Review	I-Review	3
You are leveraging the predictions of a complex model to enhance those of a simple model?	Review	I-Review	3
[line_break_token]- the text has a number of long sentences that could benefit from rewriting or splitting.	Review	I-Review	3
[line_break_token]- proof of Lemma 3.2, use \cdot not *.	Review	I-Review	3
[line_break_token]- proof of Lemma 3.2, Œ∏* should use superscript.	Review	I-Review	3
[line_break_token]- Fig 1, the caption is overlong.	Review	I-Review	3
Most of this should be in the text.	Review	I-Review	3
[line_break_token]- Fig 1, use crisper fonts for the text.	Review	I-Review	3
hank you very much for the comments.	Reply	O	0
 We below address them and have posted a new version of the paper.	Reply	O	0
[line_break_token][line_break_token]Regarding Lemma 3.2: You are correct about the trivial bound, but the bound would not be as tight without the other term.	Reply	O	0
In any case, please refer to our response about Lemma 3.2 to Reviewer 4.	Reply	B-Reply	7
We have modified the result to include the requirement that weights be capped, which also provides further intuition into the algorithm and how to select the cap.	Reply	I-Reply	7
[line_break_token][line_break_token]Regarding comparison with existing methods: We added a paragraph discussing relationships between our work and the existing ones that Reviewer 4 pointed out in the related work.	Reply	O	0
[line_break_token][line_break_token]Regarding delta-graded classifiers: Again, please refer to our response to Reviewer 4.	Reply	O	0
The notion of delta-graded classifiers is necessary in order to extract information from a a large class of models and generalizes how Dhurandhar et al (2018) attach probes to different layers of a neural network to generate predictions from various layers of a neural network.	Reply	B-Reply	4
As in Dhurandhar et al (2018), using such information proved to be useful here, in comparison to simply using the final prediction of a model (which is labelled ConfWeight in our experiments).	Reply	I-Reply	4
We further clarify this in the beginning of Section 3 (Methodology).	Reply	I-Reply	4
[line_break_token][line_break_token]Regarding what additional information the proposed method exploits: Indeed, using a weighting that includes the predictions of the simple model is the key difference from all other works, and judging from our experiments, is a significant differentiator from other weighting schemes.	Reply	O	0
[line_break_token][line_break_token]Regarding what fractions of points were suppressed: Figure 1 (left) demonstrates that less than 1% of points were suppressed as being too difficult for the simple model (no points are suppressed by only using the complex model predictions).	Reply	O	0
[line_break_token][line_break_token]Regarding Minor Comments: Please note that, regarding the title, we are leveraging the simple model predictions (along with the complex model predictions) to enhance those of a simple model, so "its" refers to the Simple model.	Reply	O	0
We can remove "its" if it is still not clear.	Reply	B-Reply	3
We have made a thorough pass and did some rewriting, fixing long sentences, and improving the overall flow.	Reply	I-Reply	3
Most of the caption to Figure 1 has been moved to the text	Reply	I-Reply	3

This paper presents AutoGen, which combines a generative variational autoencoder (VAE) with a high-fidelity reconstruction model based on autoencoder.	Review	O	0
The motivation behind AutoGen is to address a common problem when training VAEs with powerful encoders (e.g., autoregressive models) that the model simply ignores the latent representation and does not associate latent representation with the generated data in a meaningful way.	Review	O	0
A common strategy to (partially) solve this problem is by introducing KL annealing, gradually turning up the KL term in the standard ELBO, which unfortunately means the model is no longer optimizing a valid lower bound on the log-likelihood of the data.	Review	O	0
AutoGen provides an alternative solution by adding a reconstructing term to the standard ELBO for VAE to enforce the latent representation striking a balance between generation and reconstruction -- the objective still remains a valid lower bound (albeit not on the data log-likelihood) and has close connection to the standard ELBO.	Review	O	0
It also provides alternative interpretations for some other similar techniques, e.g., beta-VAE and KL-annealing.	Review	O	0
Experimental results and survey studies demonstrate that AutoGen is able to leverage latent representation more effectively when comparing with VAE without annealing, has better reconstruction overall, but at the same time lose some ability to generate good samples from prior -- this is not too surprising considering the model objective balances between generation and reconstruction.	Review	O	0
  [line_break_token][line_break_token]Overall the paper is clearly written with some minor issues listed below.	Review	O	0
The paper presents a simple but reasonable adjustment to the standard VAE training and yields an objective that is intuitive and connects nicely to some other similar techniques that scale the KL term.	Review	O	0
I have a few concerns about the paper, however, that I hope the authors could better address:[line_break_token][line_break_token]1.	Review	O	0
My major concern is that VAE after all is a generative model and its ability to sample from prior is an important property.	Review	B-Review	1
VAE with annealing, admittedly unprincipled, addresses this issue better than AutoGen, especially on shorter generated sentences.	Review	I-Review	1
There might be cases where reconstruction is important, but the paper did not demonstrate that (this relates to the point 3 below).	Review	I-Review	1
In the current state, even though the paper presents a simple and intuitive adjustment to the VAE training objective, it hasn't convinced me that if I want a generative model of language I would try to use AutoGen rather than VAE with annealing.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
As mentioned in the paper, VAE with annealing is an unprincipled approach.	Review	B-Review	2
It would be interesting to see if AutoGen compares favorably over some other principled approaches along the line of better utilizing the latent representation, e.g., Krishnan et al.	Review	I-Review	2
On the challenges of learning with inference networks on sparse, high-dimensional data, 2018.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	I-Review	7
I can understand that because of the objective of AutoGen, it does not make much sense comparing held-out likelihood or ELBO between VAE and AutoGen.	Review	I-Review	3
However, currently the paper is lacking in terms of quantitative evaluation.	Review	I-Review	3
An interesting experiment would be to use the latent representation z from both AutoGen and VAE (with/without annealing) for some downstream tasks and see if better reconstruction in this case helps.	Review	I-Review	3
This would also demonstrate the importance of incorporating a reconstruction term in the objective.	Review	I-Review	3
[line_break_token][line_break_token]Minor: [line_break_token][line_break_token]1.	Review	O	0
Above equation (5): What exactly do you mean by ‚Äúsymmetric‚Äù?	Review	B-Review	4
[line_break_token][line_break_token]2.	Review	O	0
Above equation (9): instead of just 2 -> instead of just 1?	Review	O	0
since m represents the number of reconstructions[line_break_token][line_break_token]3.	Review	O	0
Also above equation (9): it is worth more elaboration on how to generalize to m reconstructions: it is not L_AutoGen = L_VAE + m * L_SAE (which is what the text seems to suggest), rather it's L_SAE = \int_z p(x|z)^m p(z|x) dz.	Review	B-Review	6
[line_break_token][line_break_token]4.	Review	O	0
Section 3.2, since the model "finds different reconstructions every time from the same input sentence", how robust is the reconstruction to the sampling variations?	Review	B-Review	7
We appreciate the reviewers detailed comments.	Reply	O	0
[line_break_token][line_break_token]Major:[line_break_token][line_break_token]1.	Reply	O	0
We agree that there are certainly use cases where generation from the prior is more important than reconstruction.	Reply	B-Reply	1
In these cases we would recommend using a VAE.	Reply	I-Reply	1
However there are many use cases where the latent variable is of critical importance (see for example citations in our response to Reviewer 3 above).	Reply	I-Reply	1
In fact, we would argue that there are relatively few downstream tasks in which you would only want to generate say, text or images from Gaussian noise, with no regard for the latent variable.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	6
The paper by Krishnan et al.	Reply	I-Reply	2
is certainly interesting, and quite a different approach to the AutoGen model.	Reply	I-Reply	2
However, they are not using their model to generate sentences, and are taking a bag-of-words approach.	Reply	I-Reply	2
For this reason, we felt it made more sense to compare our experimental results to that of Bowman et al.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
We agree that it would certainly be interesting to see the performance of AutoGen on downstream tasks.	Reply	B-Reply	3
[line_break_token][line_break_token]Minor:[line_break_token][line_break_token]1.	Reply	O	0
We assume that in a stochastic autoencoder, the encoding distribution and decoding distribution should be closely related.	Reply	B-Reply	4
In fact we assume that this relationship can be captured via Bayes‚Äô Rule, as shown in Equation (5).	Reply	I-Reply	4
[line_break_token][line_break_token]2.	Reply	I-Reply	6
Yes, you are correct, this is an error and has been amended in the revised submission.	Reply	I-Reply	5
There is only 1 reconstruction.	Reply	I-Reply	5
[line_break_token][line_break_token]3.	Reply	O	0
In the case of multiple reconstructions, we agree with your statement that there would be a term of the form  \int_z p(x|z)^m p(z|x) dz.	Reply	B-Reply	6
However, after applying the assumptions in Equation (5) as before, we get \int_z p(x|z)^(m+1) p(z)/p(x) dz.	Reply	I-Reply	6
The result then follows as in Section 2.	Reply	I-Reply	6
I cannot see where we suggest that L_AutoGen = L_VAE + m * L_SAE, however if you can indicate where this is, we will gladly amend it.	Reply	I-Reply	6
[line_break_token][line_break_token]4.	Reply	O	0
We have not done this experiment directly, but agree that this would be interesting to see.	Reply	B-Reply	7
Note that in Table 5, we demonstrate how interpolating across the latent space can affect the output sentences, and found the interpolations to be smoother.	Reply	I-Reply	7
From this, we would assume that the Autogen model is more robust to sampling variations than the VAE.	Reply	I-Reply	7

This is a strong deep learning theory paper, and I recommend to accept.	Review	O	0
[line_break_token][line_break_token]This paper studies the trajectory induced by applying gradient descent/gradient flow for optimizing a homogeneous model with exponential tail loss functions, including logistic and cross-entropy loss in particular.	Review	O	0
This is an important direction in recent theoretical studies on deep learning as we need to understand which global minimizer the training algorithm picks to analyze the generalization behavior.	Review	O	0
[line_break_token][line_break_token]This paper makes a significant contribution to this direction.	Review	O	0
This paper rigorously proves gradient descent / gradient flow can maximize the L2 margin of homogeneous models.	Review	O	0
Existing works mostly focus on linear models or deep linear networks, and comparing with Nascon et al.,	Review	O	0
2019a, the assumptions in this paper are significantly weaker.	Review	O	0
Furthermore, this paper provides convergence rates, which seem to be the first work of this kind for non-linear models.	Review	O	0
[line_break_token][line_break_token]I really like Lemma 5.1.	Review	O	0
This is not only a technical lemma for proving the main theorem.	Review	O	0
Lemma 5.1 itself has a nice geometric interpretation.	Review	O	0
It naturally decomposes the dynamics of the smoothed version into a radial component and a tangential velocity component.	Review	O	0
I believe this lemma can be useful in other settings as well.	Review	O	0
[line_break_token][line_break_token][line_break_token]Comments:[line_break_token]The bibliography should be fixed.	Review	O	0
Some papers are already published, so they should not be cited as the arXiv version, and author lists in some papers have "et al."	Review	B-Review	1
[line_break_token][line_break_token]-----------------------------------------------------[line_break_token]I have read the rebuttal and I maintain my score.	Review	O	0
hanks for your appreciation!	Reply	O	0
We will fix the errors in the bibliography	Reply	B-Reply	1

This paper proposes a framework for semantic parsing, which includes a neural generator that synthesizes the logical forms from natural language utterances, and a neural reranker that re-ranks the top predictions generated by beam search decoding using the neural generator.	Review	O	0
While the neural generator is the same as prior work, the main novelty is the reranker design, which is a binary classifier that takes a pair of natural language utterance/logical form, and predicts the similarity between them.	Review	O	0
This reranker could also be pre-trained using auxiliary data sources, e.g., Quora question pairs benchmark for paraphrasing.	Review	O	0
They evaluate their approach on 3 semantic parsing datasets (GEO, ATIS, and OVERNIGHT), and show that their reranker can further improve the performance of the base generator.	Review	O	0
[line_break_token][line_break_token]I think the general motivation of the framework is sound.	Review	O	0
Although the idea of reranking is not new in the semantic parsing community, with the most recent work [1] already shows the promise of this direction, the concrete approach described in this paper is different, seems simple yet effective.	Review	O	0
The most interesting part is to transform the generated logical form into a pseudo-natural language text, so that it becomes a paraphrase of the input natural language utterance in some sense, which enables the re-ranker to be pre-trained with auxiliary data sources, and to use the wordpiece tokenizer that is effective in understanding natural language.	Review	O	0
In their evaluation, they indeed show that this transformation helps improve the performance of the reranker.	Review	O	0
[line_break_token][line_break_token]My main concern of  this paper is about evaluation.	Review	B-Review	1
First, although they already evaluate on 3 datasets, all of them are not among the most challenging benchmarks in semantic parsing.	Review	I-Review	1
In [1], they also evaluate on Django and Conala, which are 2 benchmarks to translate natural language to Python, and also are more complicated than the benchmarks in this paper.	Review	I-Review	1
It would be helpful for the authors to show results on such datasets that the results of baseline neural generators are less satisfactory, which may also make more room for the possible improvement using a re-ranker.	Review	I-Review	1
[line_break_token][line_break_token]On the other hand, they also lack a comparison with existing re-ranking approaches.	Review	I-Review	2
For example, it will be helpful to compare with [1], given that they also evaluate on GEO and ATIS.	Review	I-Review	2
Right now the results are not directly comparable because: (1) the base generators are different; and (2) the beam size used in this paper (10) is larger than the beam size (5) in [1]. It will be helpful if the authors can at least provide results with a smaller beam size, and would be better if they can provide results that are directly comparable to [1].[line_break_token][line_break_token][1] Yin and Neubig, Reranking for Neural Semantic Parsing, ACL 2019.	Review	O	0
[line_break_token][line_break_token]------------[line_break_token]Post-rebuttal comments[line_break_token][line_break_token]I thank the authors for the response.	Review	O	0
However, I don't think my concerns are addressed; e.g., without a comparison with previous re-ranking methods, it is hard to justify their proposed approach, given that other re-ranking methods are also able to improve over an existing well-performed generator.	Review	B-Review	2
Therefore, I keep my original assessment.	Review	O	0
[line_break_token]------------	Review	O	0
omment: My main concern of this paper is about evaluation.	Reply	O	0
First, although they already evaluate on 3 datasets, all of them are not among the most challenging benchmarks in semantic parsing.	Reply	O	0
In [1], they also evaluate on Django and Conala, which are 2 benchmarks to translate natural language to Python, and also are more complicated than the benchmarks in this paper.	Reply	O	0
It would be helpful for the authors to show results on such datasets that the results of baseline neural generators are less satisfactory, which may also make more room for the possible improvement using a re-ranker.	Reply	O	0
[line_break_token][line_break_token]Response: We agree with the reviewer that applying our architecture on more benchmark datasets would make this work stronger and we also stated this as a future work.	Reply	O	0
However, we believe that significantly improving the best performing model over three widely used semantic parsing datasets and achieving the state-of-the-art results, along with showing through error analysis how our architecture is systematically helpful is already a very strong and convincing argument of the fact that the introduced reranker model is very effective.	Reply	B-Reply	1
[line_break_token][line_break_token]We note that the choice for the datasets we used were not arbitrary.	Reply	I-Reply	1
We wanted to test with the best performing generator model because if we were to use a weaker model, then the improvement would be questionable and one could easily argue whether the introduced approach can improve the best model in the literature.	Reply	I-Reply	1
Therefore, it was important for us to show that our approach can improve upon already the best performing model in the literature.	Reply	I-Reply	1
We chose the overnight dataset because this is a dataset that has 8 various domains with large number of examples and allows for all the three processing methods we proposed to be experimented.	Reply	I-Reply	1
We chose the GEO and ATIS datasets because the generator we use was not applied to the overnight dataset, but it was applied to these two datasets.	Reply	I-Reply	1
So we wanted to show that we can also improve the performance on these datasets as well.	Reply	I-Reply	1
Of course, evaluating on more benchmark datasets (like challenging ones such as Django and Conala) would make our results stronger, however, we believe our set of results are already significant and can show the effectiveness of the reranker model we introduced.	Reply	I-Reply	1
[line_break_token][line_break_token]Comment: On the other hand, they also lack a comparison with existing re-ranking approaches.	Reply	O	0
For example, it will be helpful to compare with [1], given that they also evaluate on GEO and ATIS.	Reply	O	0
Right now the results are not directly comparable because: (1) the base generators are different; and (2) the beam size used in this paper (10) is larger than the beam size (5) in [1]. It will be helpful if the authors can at least provide results with a smaller beam size, and would be better if they can provide results that are directly comparable to [1].[line_break_token][line_break_token]Response: We agree with the reviewer that the results are not directly comparable and we would like to emphasize that our approach improves upon the best performing model in the literature, which is a more challenging improvement.	Reply	O	0
We agree with the reviewer that a direct comparison would be better and we will do this comparison in future work	Reply	B-Reply	2

The paper describes a mid-level representation for videos that can be faster than existing representations and yields similar performance.	Review	O	0
The idea is to train many SVMs to detect predefined action instances on sub-blocks from the video, and then to aggregate the SVM responses into a representation for the whole video.	Review	O	0
[line_break_token][line_break_token]This work seems like a fairly straightforward extension of previous similar work that was done on images (Malisiewicz et al.),	Review	B-Review	5
but there are some technical differences like the use of an integral video trick to compute SVM responses fast, which seems nice.	Review	I-Review	5
[line_break_token][line_break_token]I don't really understand the mining of negative examples for training the exemplar SVMs.	Review	I-Review	1
Why is it not possible to train the SVM, say with stochastic gradient descent, on all or many negative examples?	Review	I-Review	1
[line_break_token][line_break_token]The method relies on extra, intermediate labels for training which are not used by bag-of-words.	Review	O	0
This makes it hard to judge the performance differences between the two and seems to be unfair towards bag-of-words.	Review	O	0
[line_break_token][line_break_token]3.3: Rather than learning to scale svm confidences within a sigmoid, why not train a regularized logistic regression classifier in the first place, instead of the svm?	Review	O	0
[line_break_token][line_break_token]The feature extraction time is reported as the total on the whole UT-I dataset.	Review	B-Review	3
It would be much better to report it in frames per second to make it comparable with other datasets without having to dig up the description of this dataset.	Review	I-Review	3
If I am not mistaken it amounts to approximately 5 frames (with more or less standard resolution) per second?	Review	I-Review	3
If correct, this means that despite the improvement over action bank, the bottleneck is really feature exctraction not classification.	Review	I-Review	3
So the speed up due to the linear classifier will be swamped by the feature extraction and is not really that relevant, unless I'm missing something.	Review	O	0
[line_break_token][line_break_token]pro:[line_break_token]- Well-written, uses some nice engineering tricks like the integral video for computing SVM responses.	Review	O	0
[line_break_token][line_break_token][line_break_token]neg:[line_break_token]- The paper seems like a slightly strange fit for this conference as it describes a vision system rather than investigating the learning of representations.	Review	O	0
That intermediate labels are useful on this data is well-known (and unsurprising).	Review	B-Review	4
The paper does propose a faster way to use them, which is probably worthwhile.	Review	I-Review	4
We thank the reviewer for the thoughtful suggestions.	Reply	O	0
We would like to comments on a few points of the review.	Reply	O	0
[line_break_token][line_break_token]- We believe that it is quite apparent that our approach is not a straightforward extension of [Malisiewicz et al.	Reply	O	0
,2011]. This prior work has not been applied to videos, just to object detection in still images.	Reply	B-Reply	5
A naive application of [Malisiewicz et al.	Reply	I-Reply	5
,2011] to videos is simply not feasible because of the prohibitive cost.	Reply	I-Reply	5
In our paper we describe how to adapt it to work efficiently on videos so that it can scale to large datasets.	Reply	I-Reply	5
This is not a trivial contribution, as partly acknowledged by the reviewer.	Reply	I-Reply	5
[line_break_token][line_break_token]- The mining of hard negatives is a standard strategy in the learning of exemplar SVMs.	Reply	O	0
Having said this, the reviewer makes an excellent suggestion in proposing the use of stochastic gradient descent on the entire negative set.	Reply	B-Reply	1
This is definitely an interesting experiment for future work.	Reply	I-Reply	1
However, our expectation is that results would be quite similar as those obtained with iterative hard negative mining since only examples violating the margin (i.e., the hard negatives) would contribute to refining the parameters in stochastic gradient descent.	Reply	O	0
[line_break_token][line_break_token]- We agree with the reviewer that regularized logistic regression may be a sensible alternative to the two-step learning of the SVMs and the sigmoids.	Reply	O	0
Again, we opted for the simple two-step solution as it has been proven to work effectively in several prior systems (e.g., [Malisiewicz et al.,	Reply	B-Reply	2
2011; Deng et al.,	Reply	I-Reply	2
CVPR 2011, Bergamo and Torresani, CVPR 2012]).	Reply	I-Reply	2
[line_break_token][line_break_token]- As suggested by the reviewer, we will make sure to report the feature extraction time also in frames per second in order to make this number more easily interpretable.	Reply	O	0
We recognize that, despite the significant speedup enabled by our approach, feature extraction remains more costly than recognition.	Reply	B-Reply	3
However, we note that there are many practical scenarios where a feature extraction time of 5 frames per second (as opposed to the 4 frames per *minute* of Action Bank) would enable application of action recognition in large-scale datasets.	Reply	I-Reply	3
For example, consider the motivating application of interactive content-based video search where the user may query a system by providing an example sequence in order to find videos containing the same action in the database.	Reply	I-Reply	3
In such scenario the search index (containing the features) can be built offline while the training of the action classifier and the recognition itself must be done at query time.	Reply	I-Reply	3
Our system can be directly used in such scenarios, in principle even for YouTube-size datasets, while prior mid-level descriptors are simply too costly to be computed for large databases.	Reply	I-Reply	3
[line_break_token][line_break_token]- We disagree with the final conclusion of the reviewer that this paper 'describes a vision system rather than investigating the learning of representations.'	Reply	O	0
Our entire work centers around the learning of a novel intermediate representation for action recognition.	Reply	B-Reply	4
While it is true that it shares similarities with prior high-level descriptors (which we discuss in the paper), it should also be acknowledged that our new representation model introduces significant advantages in terms of computational cost and recognition accuracy over the most closely related prior system	Reply	I-Reply	4

This work builds on a sum(top k) identity to derive a pathwise differentiable sampler of 'unimodal row stochastic' matrices.	Review	O	0
The Plackett-Luce family has a tractable density (an improvement over previous works) and is (as developed here) efficient to sample.	Review	O	0
[line_break_token][line_break_token][OpenReview did not save my draft, so I now attempt to recover it from memory.]	Review	O	0
[line_break_token][line_break_token]Questions:[line_break_token]- How much of the improvement is attributable to the lower dimension of the parameterization? (	Review	O	0
e.g. all Sinkhorn varients have N^2 params; this has N params) Is there any reduction in gradient variance due to using fewer gumbel samples?	Review	B-Review	1
[line_break_token]- More details needed on the kNN loss (uniform vs inv distance wt?	Review	O	0
which one?);	Review	B-Review	2
and the experiment overall: what k got used in the end?	Review	I-Review	2
[line_break_token]- The temperature setting is basically a bias-variance tradeoff (see Fig 5).	Review	O	0
How non-discrete are the permutation-like matrices ultimately used in the experiments?	Review	B-Review	3
While the gradients are unbiased for the relaxed sort operator, they are still biased if our final model is a true sort.	Review	I-Review	3
Would be nice to quantify this difference, or at least mention it.	Review	I-Review	3
[line_break_token][line_break_token]Quality:[line_break_token]Good quality; approach is well-founded and more efficient than extant solutions.	Review	O	0
Fairly detailed summaries of experiments in appendices (except kNN).	Review	O	0
Neat way to reduce the parameter count from N^2 to N.[line_break_token][line_break_token]I have not thoroughly evaluated the proofs in appendix.	Review	O	0
[line_break_token][line_break_token]Clarity:[line_break_token]The approach is presented well, existing techniques are compared in both prose and as baselines.	Review	O	0
Appendix provides code for maximal clarity.	Review	O	0
[line_break_token][line_break_token]Originality:[line_break_token]First approach I've seen that reduces parameter count for permutation matrices like this.	Review	O	0
And with tractable density.	Review	O	0
Very neat and original approach.	Review	O	0
[line_break_token][line_break_token]Significance:[line_break_token]More scalable than existing approaches (e.g: only need N gumbel samples instead of N^2), yields better results.	Review	O	0
[line_break_token][line_break_token]I look forward to seeing this integrated into future work, as envisioned (e.g. beam search)	Review	O	0
Thanks for reviewing our paper and the helpful feedback!	Reply	O	0
We have addressed your questions below.	Reply	O	0
[line_break_token] [line_break_token]Q1.	Reply	O	0
How much of the improvement is attributable to the lower dimension of the parameterization? (	Reply	O	0
e.g. all Sinkhorn varients have N^2 params; this has N params) Is there any reduction in gradient variance due to using fewer gumbel samples?	Reply	O	0
[line_break_token]A1.	Reply	O	0
Precise quantification of the gains due to lower dimension of the parameterization alone is hard since the relaxation itself is fundamentally different from the Sinkhorn variants.	Reply	B-Reply	1
In an attempt to get a handle on these aspects (n^2 vs. n parameters and doubly stochastic vs. unimodal matrices), we analyzed the signal-to-noise (SNR) ratio for the Stochastic Sortnet and Gumbel-Sinkhorn approaches with the same number of Gumbel samples (=5).	Reply	I-Reply	1
Here, we define SNR as the ratio of the absolute value of the expected gradient estimates and the standard deviation.	Reply	I-Reply	1
For the experiments in Section 6.1, the SNR ratio averaged across all the parameters is shown in Figure 8.	Reply	I-Reply	1
We observe a much higher SNR for the proposed approach, in line with the overall gains we see on the underlying task.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2.	Reply	O	0
More details needed on the kNN loss (uniform vs inv distance wt?	Reply	O	0
which one?);	Reply	O	0
and the experiment overall: what k got used in the end?	Reply	O	0
[line_break_token]A2.	Reply	O	0
We used a uniformly weighted kNN loss for both the Sortnet approaches, while noting that it is straightforward to extend our framework to use an inverse distance weighting.	Reply	B-Reply	2
Appendix E.3 includes the formal expressions for the loss functions optimized in our framework.	Reply	I-Reply	2
Furthermore, we have included new results in Table 5 which show the raw performance of Deterministic and Stochastic Sortnet for all values of k considered.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3.	Reply	O	0
The temperature setting is basically a bias-variance tradeoff (see Fig 5).	Reply	O	0
How non-discrete are the permutation-like matrices ultimately used in the experiments?	Reply	O	0
[line_break_token]A3.	Reply	O	0
That‚Äôs a great suggestion!	Reply	B-Reply	3
One way to quantify the non-discreteness could be based on the element-wise mean squared difference between the inferred unimodal row stochastic matrix and its projection to a permutation matrix, for  the test set of instances.	Reply	I-Reply	3
We have included these results for the sorting experiment in Table 4.	Reply	I-Reply	3
[line_break_token][line_break_token]Please let us know if there are any further questions	Reply	O	0

The paper proposes to use low-rank matrix decomposition for embedding compression, with relu in the reconstruction layer to gain non-linearity.	Review	O	0
Experiments on machine translation task shows improvement compared with state-of-the-art methods with different compression rates.	Review	O	0
[line_break_token][line_break_token]Detailed comments:[line_break_token]1)[tab_token]The technical contribution seems to be a bit limited.	Review	O	0
Using relu in the reconstruction function looks straightforward and adding reconstruction loss in objective function is also common practice.	Review	B-Review	1
Also, not much insight is provided on why such approach works better than other baselines.	Review	I-Review	1
[line_break_token][line_break_token]2)[tab_token]Experiments:[line_break_token]a.[tab_token]It is good to see such simple approach outperforms several more sophisticated baseline methods.	Review	O	0
Also, ablation study is also performed to show the effect of different components.	Review	B-Review	2
[line_break_token][line_break_token]b.[tab_token]How does the time complexity and running time of the proposed method compared to the baselines?	Review	O	0
[line_break_token][line_break_token]c.[tab_token]The paper only evaluates distilled embedding on one task (i.e., machine translation).	Review	O	0
The experiments would be more convincing if evaluated on more tasks as well.	Review	B-Review	2
[line_break_token][line_break_token]d.[tab_token]It could be helpful to include some sensitivity analysis on the hyperparameters such as \alpha which controls the weight of reconstruction loss.	Review	O	0
[line_break_token][line_break_token]In conclusion, this paper seems to be below the bar and I would recommend a ‚Äòweak reject‚Äô for the paper.	Review	O	0
[line_break_token]	Review	O	0
) We specifically chose RELU so that the model can learn to regularize certain embedding dimensions, which is useful when dealing with a high dimensional embedding space, further, since this will lead to a reduction in reconstruction performance, we introduce the reconstruction loss and hyper-parameter ‚Äòalpha‚Äô, to balance out regularization and reconstruction.	Reply	O	0
These were mentioned in the paper but you are right that they were not highlighted well.	Reply	B-Reply	1
[line_break_token]2) The reason we did not run experimental results for measuring the inference time is that the only accurate method to do it is either on edge device or in a simulated environment.	Reply	O	0
Secondly, more than inference speed, running memory reduction is also important that is where the SVD based techniques (including ours) are superior, as there is no need to reconstruct the entire embedding matrix.	Reply	B-Reply	2
We ran the experiment on inference speed and the results are shown below,[line_break_token]Experimental Setup: We used 1 P100 GPU (12GB), and measured the time for the forward graph on the validation dataset (size 7590), with a batch size of 1024.	Reply	I-Reply	2
We averaged this time for 30 runs and summarize are results below.	Reply	I-Reply	2
[line_break_token][line_break_token]|              Model                        | Inference Time (Sec) |[line_break_token]| Distilled Embedding (ours) |           29.23                  |[line_break_token]| SVD                                         |           29.63                   |[line_break_token]| Structured Embedding        |           31.18                  |[line_break_token]| Base Model                           |           27.92                   |[line_break_token]We did not perform experiments on Group Reduce and Tensor Train, but they are likely to perform comparably to SVD and Our Method, or even slower.	Reply	I-Reply	2

In the paper, the authors proposed to solve the learning problem of adversarial examples from Riemannian geometry viewpoint.	Review	O	0
More specifically, the Euclidean metric in Eq.(7) is generated to the Riemannian metric (Eq.(8)).	Review	O	0
Later, the authors built the correspondence between the metric tensor and the higher order of Taylor expansions.	Review	O	0
 Experiments show the improvement over the state-of-the art methods.	Review	O	0
[line_break_token][line_break_token]Some questions:[line_break_token]First of all, the idea of introducing Riemannian geometry is appealing.	Review	O	0
[line_break_token]In the end, a neural network can be roughly viewed as a chart of certain Riemannian manifold.	Review	B-Review	1
[line_break_token]The challenging part is how can you say something about the properties of the high dimensional manifold, such as curvature, genus, completeness etc.	Review	I-Review	1
[line_break_token]Unfortunately, I didn't find very insightful analysis about the underlying structure.	Review	I-Review	1
[line_break_token]Which means, hypothetically, without introducing Riemannian geometry we can still derive Eq.(14) from Eq.(12), Taylor expansion will do the work.	Review	I-Review	1
[line_break_token]So more insights about metric tensor G determined manifold structure can be very helpful.	Review	I-Review	1
[line_break_token] [line_break_token]Second, Lagrange multipliers method is a necessary condition, which means the search directions guided by the constraint may not lead to the optimal solutions.	Review	O	0
[line_break_token]It would be better if the authors can provide either theoretical or experimental study showing certain level of direction search guarantee.	Review	B-Review	2
[line_break_token] [line_break_token]Last, the experiment results are good, though it lacks of detailed discussion, for example could you decompose the effect achieved by proposed new Riemannian constraint and neural network architecture?	Review	O	0
Merely demonstrating the performances does not tell the readers too much.	Review	B-Review	3
[line_break_token]	Review	O	0
To Q1: [line_break_token][line_break_token]Thanks for your comments.	Reply	O	0
Our paper offers a new insight to study adversarial examples (from the perspective of Riemannian geometry).	Reply	B-Reply	1
Our work is the first one that investigates the effect of the norm on adversarial examples.	Reply	I-Reply	1
We also construct an intrinsic Riemannian space based on the loss function, with a property that the descent direction can be maintained at each training step.	Reply	I-Reply	1
Our paper offers a new starting point which can inspire new insight to study adversarial examples.	Reply	I-Reply	1
On the other hand, we agree that it is better to define the physical meaning of manifold properties like the curvature, which could be one of our future work.	Reply	I-Reply	1
In the future, it is also meaningful to study how to define other metric tensors (like fisher information matrix).	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]To Q2: [line_break_token]We agree that the Lagrange multiplier is just the necessary condition.	Reply	O	0
Similar to almost all the optimization associated with neural networks, the global optimum of the loss function could not be guaranteed with the proposed algorithm in the paper.	Reply	B-Reply	2
 Nonetheless, we manage to find the steepest direction on the defined manifold.	Reply	I-Reply	2
We prove that each training step would point to the descent direction, which could guarantee a local optimum.	Reply	I-Reply	2
This proposed algorithm was verified to be effective with very promising empirical results.	Reply	I-Reply	2
To better visualize the convergence property, we also added the plots of convergence curves in the revision.	Reply	I-Reply	2
[line_break_token][line_break_token]To Q3: [line_break_token]We actually have already provided the performance of baseline model (CNN model), baseline + l_2 adversarial training, and our proposed method (i.e., baseline + l_2 Riemannian constraint adversarial training).	Reply	O	0
Compare with these three methods, we can conclude that our proposed Riemannian constraint can improve the performance of CNN model and appears more appropriate than the adversarial constraint defined in the Euclidean space.	Reply	B-Reply	3

This paper provides a theoretical justification for the benefit of multi-task deep RL (MTRL) with shared representations.	Review	O	0
By extending prior work (Farahmand (2011) and Maurer et al. (	Review	O	0
2016)), the authors demonstrate that the bound of MTRL can be improved if the cost of learning the shared representation at each AVI iteration can be reduced, which is mitigated as we increase the number of tasks.	Review	O	0
The author also empirically verify their theoretical results in a tabular Q-Fitted Iteration domain and also in challenging RL domains such as Mujoco.	Review	O	0
The results show that MTRL with shared representation can outperform their single task counterparts to some degree.	Review	O	0
[line_break_token][line_break_token]Overall this paper adapts the theory shown in Farahmand (2011) and Maurer et al. (	Review	B-Review	1
2016) to the setting of MTRL and demonstrates the effectiveness of using shared layers, which seems intuitive.	Review	I-Review	1
While the theory seems a bit incremental, it‚Äôs the first paper that theoretically validates the benefits of sharing knowledge, which is a contribution to the MTRL field.	Review	I-Review	1
I would recommend a weak accept, though I have a few concerns on experimental results, and hope that the authors can clarify them during rebuttal.	Review	O	0
[line_break_token][line_break_token]Specifically, as the authors have noted, there is a wide range of prior works [1,2,3] that have empirically demonstrated the effectiveness of utilizing shared representations in MTRL.	Review	B-Review	2
While the authors claim that the goal of the experiments is to show that MTRL with shared layers can outperform its sing task counterparts and thus they ignore other MTRL approaches.	Review	I-Review	2
I believe that is not the main argument of the paper.	Review	I-Review	2
The authors should provide empirical evidence on the claim that with an increasing number of tasks in MTRL, the error bound should improve and the performance of MTRL should also boost.	Review	I-Review	2
Besides, I find the comparison where single-task training is initialized with shared representation a bit confusing.	Review	I-Review	2
Training would definitely be improved when it‚Äôs initialized with some related pretrained features.	Review	I-Review	2
Maybe the authors should compare this to some other methods such as initializing with single-task representation or even representation learned from training different tasks.	Review	I-Review	2
[line_break_token][line_break_token][1] M. Hessel, H. Soyer, L. Espeholt, W. Czarnecki,S. Schmitt, and H. van Hasselt.	Review	O	0
Multi-task deep reinforcement learning with popart.arXiv preprintarXiv:1809.04474, 2018.	Review	O	0
[line_break_token][2] Teh, Y.W., Bapst, V., Czarnecki, W.M., Quan, J., Kirkpatrick, J., Hadsell, R.,Heess, N., Pascanu, R.: Distral: Robust multitask reinforcement learning.	Review	O	0
In: Ad-vances in Neural Information Processing Systems 30: Annual Conference on Neu-ral Information Processing Systems 2017 (2017)[line_break_token][3] Wulfmeier, M., Abdolmaleki, A., Hafner, R., Springenberg, J. T., Neunert, M., Hertweck, T., ... &amp; Riedmiller, M. (2019).	Review	O	0
Regularized Hierarchical Policies for Compositional Transfer in Robotics.	Review	O	0
arXiv preprint arXiv:1906.11228.	Review	O	0
e thank the reviewer for reading the paper and the positive comments about it.	Reply	O	0
In the following, we aim to clarify the reported doubts.	Reply	O	0
[line_break_token][line_break_token]We confirm the opinion of the reviewer that this paper aims at providing theoretical guarantees on the intuitive benefit of sharing representation of multiple tasks in Deep RL.	Reply	B-Reply	1
Theorem 3 derives the upper bound of the approximation error averaged over multiple tasks, and Theorem 2 derives the first multi-task AVI bound in literature.	Reply	I-Reply	1
Since the bound in Theorem 2 contains the task-averaged approximation error, which is bounded by the upper bound in Theorem 3 that decreases for an increasing number of tasks, the bound in Theorem 2 shows the benefit of multi-task RL w.r.t.	Reply	I-Reply	1
learning a single task.	Reply	I-Reply	1
More in detail, Theorem 2 proves that learning multiple tasks together helps to converge to the optimal-function faster than the single-task scenario.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the experiments, we firstly address this doubt of the reviewer: ‚ÄúI believe that is not the main argument of the paper.	Reply	I-Reply	2
The authors should provide empirical evidence on the claim that with an increasing number of tasks in MTRL, the error bound should improve and the performance of MTRL should also boost.	Reply	I-Reply	2
‚Äù Since this is definitely something useful, we provide this analysis in Figure 1(b) and Figure 1(c).	Reply	I-Reply	2
Theorem 2 bounds the norm-1 of the difference between the optimal-function and the-function at each update of the policy; thus, we want to measure the progress of this measure during learning in single-task and multi-task scenarios.	Reply	I-Reply	2
Note that, except for very easy tabular problems, it is not easy to compute the optimal-function in RL.	Reply	I-Reply	2
Nevertheless, we choose the car-on-hill MDP which is a not trivial problem that still allows us to compute the optimal-function.	Reply	I-Reply	2
We solve it using Neural Fitted-Iteration, based on a neural network built accordingly to our proposed architecture.	Reply	I-Reply	2
Since a neural network is a parametric regressor, we are not sure about what the reviewer means when it refers to ‚Äútabular‚Äù Fitted-Iteration.	Reply	I-Reply	2
In the left plot in Figure 1(b), we consider four different tasks in the car-on-hill MDP.	Reply	I-Reply	2
We solve each of these tasks with a single-task network, and all of them together in our multi-task network.	Reply	I-Reply	2
Then, we show the progress of the averaged norm-1s of each single task network, and the norm-1 of the multi-task network.	Reply	I-Reply	2
The plot shows how the multi-task network is able to get closer to the optimal-function w.r.t.	Reply	I-Reply	2
the single task network.	Reply	I-Reply	2
Then, Figure 1(c) provides evidence of the benefit of increasing the number of tasks.	Reply	I-Reply	2
Note how the approximation of the optimal-function gets progressively better and more stable for an increasing number of tasks.	Reply	I-Reply	2
Moreover, the right plot in Figure 1(b) also shows the benefit of multi-task in terms of performance.	Reply	I-Reply	2
We think this experiment shows what the reviewer is asking, and we wonder if this is not clear in the paper.	Reply	I-Reply	2
Regarding the initialization of the single-task network, we emphasize that the shared representation is learned on all the other tasks, excluding the one used for training the single-task network.	Reply	I-Reply	2
This experiment has the purpose of providing another empirical evidence of the meaningfulness of the extracted shared features.	Reply	I-Reply	2
We hope to have clarified the reviewer‚Äôs doubts; otherwise, we will be glad to resolve further concerns.	Reply	I-Reply	2
[line_break_token][line_break_token]We noted that the last reference provided by the reviewer is not included in our paper; we thank the reviewer for the additional reference and we have added it in the revised version of the paper.	Reply	I-Reply	2

This paper carries out several kinds of analysis on the GAT networks of Velickovic (2018), which augment GNN updates with multihead self attention.	Review	O	0
Three standard attention types are compared, on several different datasets, and differences between uniform attention and learned attention are reported.	Review	O	0
An experiment is carried out where low-attention edges are pruned.	Review	O	0
[line_break_token][line_break_token]While understanding the value of attention is important, this paper leaves many questions open.	Review	B-Review	1
First, since the graphs studied in this paper are, if not generally sparse to begin with at least they only include connections that are meaningful, the sparsification experiment is a bit hard to understand.	Review	I-Review	1
One particular extension would improve things: adding random edges (can the model learn to prune them out?),	Review	I-Review	1
but learning sparse attention (see e.g., Maruf et al.,	Review	I-Review	1
2019) rather than thresholding seems to be a reasonable point of comparison.	Review	I-Review	1
[line_break_token][line_break_token]Overall this paper would be more valuable if a clear and concise recommendation could be given regarding how to use or understand attention; but the lack of a consistent pattern of results makes any obvious narrative hard to support.	Review	I-Review	2
I would encourage the authors to continue this line of work so that it can be used to provided guidance to those who would like to make more effective use of GNNs.	Review	I-Review	2
e thank the reviewer for his encouragement and suggestions on future work	Reply	O	0

This paper demonstrates some limitations of censoring for privacy with respect to sensitive attributes.	Review	O	0
In particular, the authors show that censoring reduces, but does not eliminate, the ability of a neural network to infer private/sensitive attributes, e.g. to infer race from a model aiming to predict gender.	Review	O	0
Part of the proposed method is a component that performs de-censoring using an auxiliary dataset.	Review	O	0
The authors show that censoring strength often does reduce the ability to infer sensitive attributes, but also affects the ability to perform the main (non-sensitive) task; and in some cases, may actually increase ability to infer sensitive attributes.	Review	O	0
This type of work is important in that privacy is of growing importance, and so is the risk to privacy; this particular work is well carried out.	Review	O	0
[line_break_token][line_break_token]One concern: In Sec.	Review	O	0
3.1, there is an assumption of the availability of D_{aux}. How realistic is this assumption?	Review	B-Review	1
hanks for the review!	Reply	O	0
[line_break_token]With the growing availability of public datasets, if the adversary knows only the input domain (e.g., face images), today it is relatively easy to find public data with the desired target attribute (e.g., race)	Reply	B-Reply	1

The paper is well written and flows very well.	Review	O	0
The idea is straightforward and easy to understand.	Review	O	0
Here are my feedbacks:[line_break_token][line_break_token]--Method--[line_break_token][line_break_token]Methodology-wise, the novelty is somewhat limited.	Review	O	0
The main technical contributions are: 1) formulate linear programming to reduce energy costs, and the formulation of linear programming is straightforward.	Review	O	0
2) the claimed main contribution is an application of Rayleigh-Quotient gradient descent to approximate the eigenvalue calculations in the model proposed by Wu et al (2019).	Review	O	0
[line_break_token][line_break_token]I believe computing the eigenvalue shall not be the only way to solve Eq.(3), e.g. using gradient-based method or Lagrange.	Review	B-Review	1
My main question is whether computing the global optimum really matters?	Review	I-Review	1
Since your method is still essentially an approximation algorithm, which may break the optimality condition here.	Review	I-Review	1
From the experimental results, it seems that your approximation is quite close to the analytical solution.	Review	I-Review	1
Therefore, it is unclear computing a global optimum really matters here.	Review	I-Review	1
[line_break_token][line_break_token]I tried to buy the idea of escaping the saddle point with splitting (it indeed sounds straightforward and reasonable).	Review	I-Review	2
It will be great if the author can add some empirical experiments to verify it.	Review	I-Review	2
[line_break_token][line_break_token]--Content--[line_break_token]The entire section2 is at reviewing prior works, and I believe you should cut down the content here.	Review	O	0
[line_break_token][line_break_token]--Experiments--[line_break_token]1.	Review	O	0
Diversity of your tests: the author main uses MobileNet in testing their ideas.	Review	B-Review	3
It seems that their method starts at MobileNet, then tries to improve it.	Review	I-Review	3
I suggest authors adding other recent works, e.g. FBNet, MobileNetV3, into their tests to diversify the types of networks.	Review	I-Review	3
[line_break_token][line_break_token]2.	Review	O	0
Results variations: all figures, e.g. fig.3, fig.4, in the paper lack plotting their results variations.	Review	B-Review	4
Since the optimization may converge to different local optimum, it is more persuasive to show their performance variations.	Review	I-Review	4
[line_break_token][line_break_token]3.	Review	O	0
The final results are not surprising: in table.1 and table.2, as far as I'm aware, the mainstream accuracy for ImageNet under the mobile setting should be 75% top-1.	Review	B-Review	5
And the SOTA top-1 accuracy on ImageNet is around 85.5%.	Review	I-Review	5
Table.1 and table.2 do somewhat show the effectiveness of your method, but its significance is limited especially considering the limited novelty of methodology.	Review	I-Review	5
[line_break_token][line_break_token]Minors:[line_break_token]In Fig.3 k = 6, it seems vanilla splitting is better than accuracy and parameters, except for 0.2 log higher flops.	Review	O	0
I don't think this makes a compelling case here.	Review	B-Review	6
[line_break_token][line_break_token]In Fig.4, from flops 7 ~ 9, your results are similar to Bn especially accuracy &gt; 0.6.	Review	O	0
When accuracy &lt; 0.6, it is less interesting, and I believe the improvement should be huge.	Review	O	0
[line_break_token][line_break_token]Fig.5, could you please compare the time using MAGMA from NVIDIA?	Review	B-Review	8
I had some experiences in implementing the LAPACK and BLAS on GPUs, and it should not be that slow.	Review	I-Review	8
[line_break_token][line_break_token]Overall, this paper has some interesting results, which shows the eigenvalue can be approximated by Rayleigh-Quotient gradient descent, and show positive improvement.	Review	O	0
However, the methodological and experimental results can definitely be strengthened.	Review	B-Review	9
The author may consider proving that achieving the global optimum on Eq.(3) really matters, then motivate the methodology.	Review	I-Review	9
Thank you.	Review	O	0
[line_break_token]	Review	O	0
**I believe computing the eigenvalue shall not be the only way to solve Eq.(3), e.g. using gradient-based method or Lagrange;**  [line_break_token]  [line_break_token]Since Eigen-problem is equivalent to Eq (3) in the zero-step size limit, our algorithm is already in some sense doing gradient descent for Eq (3).	Reply	O	0
Brute-forcefully applying gradient descent can be problematic because the gradient of the two off-springs would cancel with each other and yield zero gradients (because they move along opposite directions).	Reply	B-Reply	1
As shown in the theory of the original splitting descent paper, the structural descent is a second-order update.	Reply	I-Reply	1
Eigen-formulation avoids this problem because it allows us to analytically derive the gradient, which requires to look at some (partial) second-order terms of the objective function in Eq(3).	Reply	I-Reply	1
 [line_break_token][line_break_token]To put it in another way,  if someone tries to derive a gradient descent algorithm for Eq (3), they will end up with something similar or equivalent to our method, after careful mathematical derivation.	Reply	I-Reply	1
  [line_break_token][line_break_token]We hope this makes it clear that Eq (3) is not trivial mathematically and theoretical thinking is needed.	Reply	I-Reply	1
For example, without deriving the eigen-formulation, we would need to optimize the weights w and size m, which makes the problem complicated.	Reply	I-Reply	1
   [line_break_token][line_break_token]Issue of "global vs. local optimality"[line_break_token][line_break_token]Following our comments above, we do not think there is an issue of global vs. local optimality here.	Reply	O	0
We are already doing a type of gradient descent on Eq (3), for which the global optimum happens to be the only stable local optimum thanks to its equivalent to Eigen-problem.	Reply	B-Reply	1
[line_break_token][line_break_token]Question: "I tried to buy the idea of escaping the saddle point with splitting (it indeed sounds straightforward and reasonable).	Reply	O	0
It will be great if the author can add some empirical experiments to verify it."	Reply	O	0
[line_break_token][line_break_token]Reply: We believe this question has already been fully answered in the original splitting descent paper.	Reply	O	0
For example, Figure 1 in that paper offers very intuitively and convincing illustrations that might alleviate R#3?s concerns.	Reply	B-Reply	2
[line_break_token]Our main focus is on scaling the algorithm to large-scale settings.	Reply	I-Reply	2
We only cite and explain their point on this aspect.	Reply	I-Reply	2
[line_break_token][line_break_token] [line_break_token]Question: "adding other recent works, e.g. FBNet, MobileNetV3, into their tests to diversify the types of networks."	Reply	O	0
[line_break_token][line_break_token]Reply:  We choose MobileNetV1 and MobileNetV2 as our testbed mainly due to their popularity and nice accuracy-flops tradeoff.	Reply	O	0
And MobileNetV1 and MobileNetV2 together define all basic blocks/layers of many recent works such as FBNet and MobileNetV3.	Reply	B-Reply	3
We expect that the results will be similar on FBNet and MobileNetV3.	Reply	I-Reply	3
[line_break_token][line_break_token]Question:  "it is more persuasive to show their performance variations."	Reply	O	0
[line_break_token][line_break_token]Reply:  We provide ablation studies in section 5.4 (see Figure 6).	Reply	O	0
[line_break_token][line_break_token]Question:  "The final results are not surprising: in table.1 and table.2, as far as I'm aware, the mainstream accuracy for ImageNet under the mobile setting should be 75% top-1.	Reply	O	0
And the SOTA top-1 accuracy on ImageNet is around 85.5%."	Reply	O	0
[line_break_token][line_break_token]Reply: The main goal of this paper is to provide a way to grow networks that work in practice.	Reply	O	0
Therefore, our method should be compared with existing methods using the same meta-architectures (e.g. same depth, kernel size, resolutions).	Reply	B-Reply	5
 To the best of our knowledge, our results are the current SOTA top-1 accuracy on ImageNet using *MobileNetV1* and *MobileNetV2* with similar Flops compared to expert-designed MobileNets and pruning methods.	Reply	I-Reply	5
[line_break_token][line_break_token]Question:  "In Fig.3 k = 6, it seems vanilla splitting is better than accuracy and parameters, except for 0.2 log higher flops.	Reply	O	0
I don't think this makes a compelling case here."	Reply	O	0
[line_break_token][line_break_token]In this case, all networks are 1) not very deep; 2) trained on a small CIFAR10 dataset.	Reply	B-Reply	6
That said, the differences shouldn't be super significant.	Reply	I-Reply	6
However, the results are shown in Figure 3 clearly demonstrate that our method achieves better accuracy-flops trade-off than the vanilla splitting approach.	Reply	I-Reply	6
[line_break_token][line_break_token]Question: "In Fig.4, from flops 7 ~ 9, your results are similar to Bn especially accuracy &gt; 0.6.	Reply	O	0
When accuracy &lt; 0.6, it is less interesting, and I believe the improvement should be huge."	Reply	O	0
[line_break_token][line_break_token]Reply: We believe it?s already significant enough to show that our method outperforms pruning methods.	Reply	O	0
Pruning methods have already taken advantage of using knowledge from a pre-trained over-parameterized model, while our method training small models from scratch.	Reply	B-Reply	7
[line_break_token][line_break_token]Question: "Fig.5, could you please compare the time using MAGMA from NVIDIA?	Reply	O	0
I had some experiences in implementing the LAPACK and BLAS on GPUs, and it should not be that slow."	Reply	O	0
[line_break_token][line_break_token]Reply:  Thanks for your suggestions.	Reply	O	0
We note that the key bottleneck of the vanilla splitting approach is the requirement of calculating all splitting matrices, which causes a space complexity O(nd^2) (n: number of neurons, d: dimension of each neuron).	Reply	B-Reply	8
 This makes it *impossible* to implement the algorithm on GPUs for modern neural networks with thousands of neurons, mainly due to the explosion of GPU memory	Reply	I-Reply	8

Overview/Contribution:[line_break_token]====================[line_break_token]The authors present a explanation generation framework that help validate post-hoc explanations when the explanations are generated based on feature selection.	Review	O	0
They claim to demonstrate their method by showing failure modes of exiting explanation generation methods.	Review	O	0
[line_break_token][line_break_token]Overall, the paper is not ready to be accepted to the conference and I describe my rational with the following strengths and weaknesses.	Review	O	0
[line_break_token][line_break_token]Strength:[line_break_token]========[line_break_token]+ Explanations make models more transparent and easy to understand for end users of the decision made by complex models such as deep neural networks [1]. In that respect, having a verification mechanism for post-hoc explanations is interesting and useful.	Review	O	0
[line_break_token]+ The paper is easy to read and follow.	Review	O	0
[line_break_token]Weakness:[line_break_token]===========[line_break_token]- evaluating explanations generated for an opaque model with another opaque model (RCNN) is cyclical.	Review	O	0
[line_break_token]- Just like many literature in this nascent space, interpretation (which is measuring the contribution of features or subsets of features towards predicted output) is confused as explanation.	Review	O	0
Human level explanations don‚Äôt necessarily depend on the direct interaction or contribution of model derived features.	Review	B-Review	2
Rather they describe ‚Äòwhy‚Äô the model come up with the decision produced.	Review	I-Review	2
[line_break_token]- Explanation generation is gaining traction in the deep learning community especially for critical applications such as healthcare and security.	Review	O	0
However, the authors claim that post-hoc explanations currently are only evaluated for only simple non-neural model.	Review	B-Review	3
That is misleading given the recent attention toward generating explanations for various deep learning models.	Review	I-Review	3
[line_break_token]- As a generalized pos-hoc explanation generators verification framework, the experiments are seriously lacking and are not well designed to illicit broad applicability.	Review	O	0
[line_break_token][line_break_token]1) Bekele, E., Lawson, W. E., Horne, Z., &amp; Khemlani, S. (2018).	Review	O	0
Implementing a Robust Explanatory Bias in a Person Re-identification Network.	Review	O	0
In&nbsp;Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops&nbsp;(pp.	Review	O	0
2165-2172).	Review	O	0
REVIEWER: Evaluating explanations generated for an opaque model with another opaque model (RCNN) is cyclical.	Reply	O	0
[line_break_token]ANSWER: Our general answer should help clarify this.	Reply	O	0
The RCNN is not meant to explain other opaque models, it only explains itself, hence there is no cycle.	Reply	B-Reply	1
We only evaluate explainers on the trained RCNNs with their associated pruned datasets for which we provided the guarantees mentioned in the general answer.	Reply	I-Reply	1
The RCNN has a degree of transparency that we exploit: it itself, selects the features that it will further exclusively use in the final prediction.	Reply	I-Reply	1
Our 2 pruning procedures ensure that, on the instances of the pruned datasets, the RCNN‚Äôs selection faithfully represents the model‚Äôs inner-working: the non-selected tokens are indeed irrelevant and some of the selected tokens are clearly relevant.	Reply	I-Reply	1
[line_break_token][line_break_token]R: Authors claim that post-hoc explanations currently are only evaluated for simple non-neural model.	Reply	O	0
[line_break_token]A: We do not claim that explainers are only evaluated on non-neural models.	Reply	O	0
In the related work, we had listed the 4 types of evaluations we identified in the literature, the last 3 of which are based on complex neural models, but they have other downsides.	Reply	B-Reply	3
We have updated the paper to ensure that we mention all 4 types of evaluations together in all parts of the paper.	Reply	I-Reply	3
[line_break_token][line_break_token]R: More experiments[line_break_token]A: Please see general answer.	Reply	O	0
[line_break_token][line_break_token]R: Referenced human-level explanation paper[line_break_token]A: Thank you for mentioning it, we added it accordingly in the related work.	Reply	O	0

This paper proposes a strategy to generate audio samples from noise with GANs.	Review	O	0
The treatment is analogous to image generation with GANs, with the emphasis being the changes to the architecture and representation necessary to make it possible to generate convincing audio that contains an interpretable latent code and is much faster than an autoregressive Wavenet based model ("Neural Audio Synthesis of Musical Notes with WaveNet AutoEncoders" - Engel et al (2017)).	Review	O	0
Like the other two related works (WaveGAN - "Adversarial Audio Synthesis" - Donahue et al 2018) and the Wavenet model above, it uses the NSynth dataset for its experiments.	Review	O	0
[line_break_token][line_break_token]Much of the discussion is on the representation itself - in that, it is argued that using audio (WaveGAN) and log magnitude/phase spectrograms  (PhaseGAN) produce poorer results as compared with the version with the unrolled phase that they call 'IF' GANs, with high frequency resolution and log scaling to separate scales.	Review	O	0
 [line_break_token][line_break_token]The architecture of the network is similar to the recently published paper  (Donahue et al 2018), with convolutions and transpose convolutions adapted for audio.	Review	O	0
However, there seem to be two important developments.	Review	O	0
The current paper uses progressive growing of GANs (the current state of the art for producing high resolution images), and pitch conditioning (Odena et al, where labels are used to help training dynamics).	Review	O	0
[line_break_token][line_break_token]For validation, the paper presents several metrics, with the recently proposed "NDB" metric figuring in the evaluations, which I think is interesting.	Review	O	0
The IF-Mel + high frequency resolution model seems to outperform the others in most of the evaluations, with good phase coherence and interpolation between latent codes.	Review	O	0
[line_break_token][line_break_token]My thoughts: [line_break_token]Overall, it seems that the paper's contributions are centered around the representation (with "IF-Mel" being the best).	Review	O	0
The architecture itself is not very different from commonly used DCGAN variants - the authors say that using PGGAN is desirable, but not critical, and the use of labels from Odena et al.	Review	O	0
[line_break_token][line_break_token]Many of my own experiments with GANs were plagued by instability (especially at higher resolution) and mode collapse problems without special treatment (largely documented, such as adding noise, adjusting learning rates and so forth).	Review	B-Review	1
To this end, what do the authors see as 'high' resolution vis a vis audio signals?	Review	I-Review	1
[line_break_token][line_break_token]I am curious if we can adapt these ideas for recurrent generators as might appear in TTS problems.	Review	I-Review	2
[line_break_token][line_break_token]I rate this paper as an accept since this is one of the few existing works that demonstrate successful audio generation from noise using GANs, and  owing to its novelty in exploring representation for audio.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your time and expertise in your review, we've addressed the key points below:[line_break_token][line_break_token]> ‚Äú...what do the authors see as 'high' resolution vis a vis audio signals?‚Äù[line_break_token][line_break_token]In the context of these audio datasets, we use ‚Äúhigh‚Äù resolution to refer more to the dimensionality of the signal to model with a single latent vector, rather than the temporal resolution of the audio.	Reply	O	0
The spectral ‚Äúimages‚Äù that GANSynth models, have 1024 frequencies, 128 timesteps, and 2 channels, [1024, 128, 2], which is roughly equivalent to a [295, 295, 3] RGB image.	Reply	B-Reply	1
This puts the task comparable to some of the higher-resolution GANs for images.	Reply	I-Reply	1
[line_break_token][line_break_token]> ‚ÄúI am curious if we can adapt these ideas for recurrent generators as might appear in TTS problems.	Reply	O	0
‚Äú[line_break_token][line_break_token]We agree that would be an interesting development.	Reply	O	0
Recurrent generators, and even discriminators, would allow for variable-length sequences and variable-length conditioning as is common in speech synthesis or music generation beyond single notes.	Reply	B-Reply	2
Our initial experiments at using recurring generators were not very successful, so we opted to adopt a better tested architecture for this study, but this is definitely still an area ripe for exploration.	Reply	I-Reply	2

Observing shortcomings of BLEU and ROUGE, the paper proposes, JAUNE, a set of criteria for a good evaluation metric.	Review	O	0
These criteria include: high correlation with human judgement; being able to distinguish similar but contradicting statements; penalizing grammatical errors, and hard to game.	Review	O	0
[line_break_token][line_break_token]The paper, as its current form, is not ready for publishing.	Review	O	0
Some suggestions and comments:[line_break_token][line_break_token]- Please carefully check the paper and fix typos and confusing sentences.	Review	O	0
I was collecting these errors but eventually stopped.	Review	B-Review	1
Some examples.	Review	I-Review	1
Sec.	Review	I-Review	1
2.3: punctuation missing between "RUSE" and "this method", comma missing after "a discrete space"; Sec.	Review	I-Review	1
4.1.1: "made to ,for example"....[line_break_token][line_break_token]- The motivation of the paper is unclear.	Review	O	0
Is your criticism only about BLEU and ROUGE, or the state of the arts in NLP evaluation in general?	Review	B-Review	3
To make JAUNE appealing, one has to argue that the state of the arts in NLP evaluation is ineffective.	Review	I-Review	3
For this, the paper needs to review a boarder range of metrics beyond just BLUE and ROUGE.	Review	I-Review	3
[line_break_token][line_break_token]- While the authors suggest a data-driven metric, it reads to me like a model-driven metric (RoBERTAa specifically).	Review	O	0
Doesn't it systematically bias towards a certain family of metrics?	Review	B-Review	4
[line_break_token][line_break_token]- Better and more comprehensive experimental results are highly desired.	Review	O	0
ear Reviewer #1,[line_break_token][line_break_token]1) Thank you for your comments.	Reply	O	0
We have checked the paper for typos, confusing sentences and made it easier to read.	Reply	B-Reply	1
[line_break_token][line_break_token]2) Overall the goals of the paper are to present clear criteria to assess evaluation metrics and show how transformers can be used to assess the quality of candidate translations and summaries.	Reply	O	0
[line_break_token][line_break_token]3) Currently, all summaries/translation results use BLEU/ROUGE, hence the focus on these 2 metrics.	Reply	O	0
The core idea in the experimental section is that in all dimensions capturing the properties of a "good evaluator", BLEU/ROUGE are outperformed by a Transformer trained to predict semantic similarity between candidate and reference sentences.	Reply	B-Reply	3
The earlier version of the paper hinted at a more general framework in which Transformers themselves are used as feature extractors for various sentence pairs but we removed this part to reduce confusion.	Reply	I-Reply	3
[line_break_token][line_break_token]4) We use the term data-driven because the evaluators are general purpose language models fine-tuned on semantic similarity.	Reply	O	0
We took RoBERTa-STS as an example but recent, high-performing models such as ALBERT or ALICe are also applicable.	Reply	B-Reply	4
The constant among those is the training procedure relying on the same data.	Reply	I-Reply	4
The models are anticipated to evolve which is why we did not want to be specifying just a model.	Reply	I-Reply	4
[line_break_token][line_break_token]5) We have added 3 more experiments.	Reply	O	0
The first 2 complete the evaluation of RoBERTa-STS for the 2 dimensions of the scorecard.	Reply	B-Reply	5
The last experiments use RoBERTa-STS on 5300+ WMT sentence pairs and show that this model transfers well.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]	Reply	O	0

This paper performs cache side-channel attacks to extract attributes of a victim model, and infer its architecture accordingly.	Review	O	0
In their threat model, the attacker could launch a co-located process on the same host machine, and use the same DL framework as the victim model.	Review	O	0
Their evaluation shows that: (1) their attacks can extract the model attributes pretty well, including the number of different types of layers; (2) using these attributes, they train a decision tree classifier among 13 CNN architectures, and show that they can achieve a nearly perfect classification accuracy.	Review	O	0
They also evaluate some defense strategies against their attacks.	Review	O	0
[line_break_token][line_break_token]Model extraction attack under a black-box setting is an important topic, and I am convinced that their threat model is a good step towards real-world attacks.	Review	O	0
As for the novelty, although Yan et al.	Review	O	0
also evaluate cache side-channel attacks, that paper was released pretty shortly before ICLR deadline, thus I would consider this work as an independent contribution at its submission.	Review	O	0
[line_break_token][line_break_token]I have several questions and comments about this paper:[line_break_token][line_break_token]- One difference of the evaluation setup between this paper and Yan et al.	Review	O	0
is that in Yan et al.,	Review	B-Review	1
they are trying to infer more detailed hyper-parameters of the architecture (e.g., the number of neurons, the dimensions of each layer, the connections), but within a family of architectures (i.e., VGG or ResNet).	Review	I-Review	1
On the other hand, in this paper, the authors extract higher-level attributes such as the number of different layers and activation functions, and predict the model family (from 5 options) or the concrete model architecture (from 13 options).	Review	I-Review	1
While I think inferring the model family type is also an interesting problem, this setup is still a little contrived.	Review	I-Review	1
Would the classifier predict the family of a model correctly if it is not included in the training set, say, could it predict ResNet32 as R (ResNet)?	Review	I-Review	1
[line_break_token][line_break_token]- In Table 3, it looks like the errors in the captured computation sequences show some patterns.	Review	O	0
Are these error types consistent across different runs?	Review	B-Review	2
Could you provide some explanation of these errors?	Review	I-Review	2
[line_break_token][line_break_token]- In Table 5, my understanding is that we need to compare the avg errors to the numbers in Table 2.	Review	O	0
In this case, the errors seem to be even larger than the sum of the attribute values.	Review	B-Review	3
Is this observation correct?	Review	I-Review	3
If so, could you discuss what attributes are most wrongly captured, and show some examples?	Review	I-Review	3
[line_break_token][line_break_token]- It would be beneficial to provide a more detailed comparison between this work and Yan et al.,	Review	O	0
e.g., whether the technique proposed in this work could be also extended to infer more fine-grained attributes of a model, and go beyond a classification among a pre-defined set of architectures.	Review	B-Review	4
[line_break_token][line_break_token]- The paper needs some editing to fix some typos.	Review	O	0
For example, in Table 5, the captions of Time (Baseline) and Time (+TinyNet) should be changed, and it looks confusing at the first glance.	Review	B-Review	5
[line_break_token]	Review	O	0
We thank the reviewer for the constructive feedback: the questions and comments can improve and make our contributions more concrete.	Reply	O	0
We will update our paper accordingly to include their points.	Reply	O	0
In the meantime, we would like to provide initial answers to the reviewer‚Äôs questions:[line_break_token][line_break_token](1) Could our classifier predict the family of a model correctly (ex.	Reply	O	0
ResNet32) not in the training data?	Reply	O	0
[line_break_token][line_break_token]No, our classifier could not predict this because it cannot learn how to classify unobserved samples into the families that have similar features (or attributes).	Reply	B-Reply	1
Suppose that the samples from ResNet18 or 34 are not in our training set.	Reply	I-Reply	1
Since the architecture attributes of ResNet18 or 34 are similar to those of VGG16/19 or MobileNetV1/2, our classifier may predict the unseen samples as some other close family (VGGs or MobileNets).	Reply	I-Reply	1
However, we are sure that if we include the ResNet18 or 34 to our training set, our classifier will learn to specify them as ResNets.	Reply	I-Reply	1
[line_break_token][line_break_token]The key contribution of our (fingerprinting) experiment is to examine which of the architecture attributes that our attacker can extract are essential to specify network families.	Reply	I-Reply	1
We identified that four common attributes (#relus, #merges, #convs, and #poolings) are important to know the family of a victim‚Äôs network.	Reply	I-Reply	1
This information can help our attacker to launch large-scale attacks in the transfer learning scenario because our attacker already knows multiple commonly used pre-trained models + architectures that she can train her classifier on.	Reply	I-Reply	1
Then, by passively observing the information leakage from cache side-channels, the attacker can specify which actual pre-trained model that the victim uses and synthesize adversarial samples with the pre-trained model that also works for the victim model (as prior work [1] warned).	Reply	I-Reply	1
[line_break_token][line_break_token](2) Reconstruction errors observable in Table 3.	Reply	O	0
[line_break_token][line_break_token]In our experiments, we could not find specific error patterns in the extracted attribute sequences.	Reply	B-Reply	2
As we can see in Table 3, there are the cases where convolutional layers are missing and/or added and activations are missing and/or added.	Reply	I-Reply	2
Also, the locations of missing attributes are different in each run.	Reply	I-Reply	2
We attribute these errors to a few primary causes: there is background noise of other processes that our flush+reload cache-based side channel attack may pick up (e.g. other background processes pull something into the cache and evict our target functions between when the victim calls the function and we reload it), or we may experience common errors associated with flush+reload (e.g. a victim may call the function during the time when we reload, causing us to see a cache miss instead of correctly observing a cache hit) [2].[line_break_token][line_break_token](3) Comparison of avg.	Reply	O	0
errors in Table 5 (running decoy process as a defense).	Reply	O	0
[line_break_token][line_break_token]Yes, in Table 5, our experiments indicate that the errors are larger than the sum of the original attribute values (that we can expect from ResNet50).	Reply	B-Reply	3
In our experiments in Table 5, we increase the errors associated with the attributes that we aim to obfuscate.	Reply	I-Reply	3
For instance, when we run the TinyNet with only one convolutional layer, we observe the #conv attribute is significantly increased.	Reply	I-Reply	3
This result is important because, with our defenses, a defender can choose the attributes to obfuscate.	Reply	I-Reply	3
By introducing noise into the cache side channel by means of another process, we can make differentiating between functions that are called by our victim and our decoy incredibly difficult and therefore mitigate, and possibly eliminate, any useful information that an attacker can gain by these side channels.	Reply	I-Reply	3
Since the defender has control over what noise gets introduced, they can also dynamically and adaptively change what noise is added into the attacker‚Äôs observations, thereby increasing our defenses‚Äô effectiveness and generalizability.	Reply	I-Reply	3
[line_break_token][line_break_token](4) Emphasizing our contributions over the concurrent work (Yan et al.,	Reply	O	0
2018).	Reply	O	0
[line_break_token][line_break_token]Our key contributions over the concurrent work (Yan et al.,	Reply	B-Reply	4
2018) are highlighted in the initial response to the reviewer‚Äôs comments below [comment 1]: <a href="https://openreview.net/forum?id=rk4Wf30qKQ&noteId=B1l2z9wgTm" target="_blank" rel="nofollow">https://openreview.net/forum?id=rk4Wf30qKQ&noteId=B1l2z9wgTm</a> / comment 2: <a href="https://openreview.net/forum?id=rk4Wf30qKQ&noteId=Sye8V5wx67]." target="_blank" rel="nofollow">https://openreview.net/forum?id=rk4Wf30qKQ&noteId=Sye8V5wx67].</a> We plan to include the comparison in our related work section.	Reply	O	0
[line_break_token][line_break_token](5) Fixing typos in our paper.	Reply	O	0
[line_break_token][line_break_token]We are working on revising our paper based on the reviewers‚Äô feedback.	Reply	B-Reply	5
We will include those fixes in the revised version.	Reply	I-Reply	5
[line_break_token][line_break_token][1] Bolun Wang, Yuanshun Yao, Bimal Viswanath, Haitao Zheng, and Ben Y Zhao.	Reply	O	0
With great training comes great vulnerability: Practical attacks against transfer learning.	Reply	O	0
USENIX Security, 2018[line_break_token][2] Yarom, Yuval, and Katrina Falkner. "	Reply	O	0
FLUSH+ RELOAD: A High Resolution, Low Noise, L3 Cache Side-Channel Attack."	Reply	O	0
USENIX Security Symposium.	Reply	O	0
Vol.	Reply	O	0
1.	Reply	O	0
2014	Reply	O	0

This paper performs a general analysis of sign-based methods for non-convex optimization.	Review	O	0
They define a new norm-like function depending on the success probabilities.	Review	O	0
Using this new norm-like function and under an assumption, they prove exponentially variance reduction properties in both directions and small mini-batch sizes.	Review	O	0
[line_break_token][line_break_token]I am not convinced about assumption 1, which plays the key role of the proof.	Review	B-Review	1
It assumes that success probabilities are always large or equal to 1/2.	Review	I-Review	1
[line_break_token][line_break_token]How can we guarantee this property hold for an algorithm?	Review	I-Review	2
I suggest the authors provide some real learning examples, under which it will satisfy the condition.	Review	I-Review	2
 I may revise my rating according to this.	Review	O	0
[line_break_token]	Review	O	0
e provided 3 different setups, where assumption 1 is satisfied:[line_break_token]1) Unimodal and symmetric noise setup (Lemma 1).	Reply	B-Reply	1
As noted in (Bernstein et al.,	Reply	I-Reply	1
2018), it is backed up by central limit theorem when training neural networks.	Reply	I-Reply	1
[line_break_token]2) Strong growth condition with fixed mini-batch size (updated Lemma 2).	Reply	I-Reply	1
This setup corresponds to over-parameterized deep network learning, where the model can fit the training data completely.	Reply	I-Reply	1
[line_break_token]3) Adaptive mini-batch size setup (Lemma 3), which guarantees converge merely by choosing appropriate mini-batch size.	Reply	I-Reply	1
[line_break_token][line_break_token]Note that, while sign matching SPB assumption is quite intuitive in sign based methods, it is not assumed or somehow claimed that it holds automatically for simple problems.	Reply	I-Reply	1
Even in one dimensional regression problem SPB assumption might fail, as much as signSGD might fail to converge.	Reply	I-Reply	1
Furthermore, the SPB assumption describes the convergence of sign descent methods, which is known to be problematic (see e.g. (Balles &amp; Hennig, 2018), section 6.2 Results)	Reply	O	0

This paper proposes a drop-in module of disentangled patch representation learning for adversarial learning-based domain adaptation.	Review	O	0
The main idea is to encourage the source patch level representation to be disentangled, by creating certain intermediate pseudo-ground truths via clustering the label patch histograms using k-means.	Review	O	0
This basically creates an alternative, additional view of prediction target of the network outputs.	Review	O	0
And similar to global network output alignment by Tsai et al.,	Review	O	0
the authors impose an adversarial loss on the additionally introduced view.	Review	O	0
[line_break_token][line_break_token]Clarity: The paper is well-written with good clarity.	Review	O	0
[line_break_token][line_break_token]Results: This paper has a good experimental validation of proposed module.	Review	O	0
[line_break_token][line_break_token]Concerns: [line_break_token]- The idea of using patches in domain adaptation is not completely new.	Review	O	0
ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes, CVPR 2018 also uses the patch level information to help domain adaptation.	Review	B-Review	1
Although the ideas are not entirely identical, this paper should at least cite and compare this work.	Review	I-Review	1
[line_break_token][line_break_token]- The disentangled patch feature learning introduces two additional loss, L_d and L_adv^l, which require three extra parameters, including K in K-means, lambda_d and lambda_adv^l.	Review	O	0
It will be great if a formal sensitivity analysis on the parameters can be conducted.	Review	B-Review	2
There are some details missing in the paper too.	Review	I-Review	2
For example, what is the performance of the VGG source model without adaptation?	Review	I-Review	2
I am also curious about the learning behavior of the proposed method.	Review	I-Review	2
Could you show the mIoU v.s.	Review	I-Review	2
epoch curve for GTA2Cityscapes, or any other benchmarks?	Review	I-Review	2
[line_break_token][line_break_token]- Although consistently improving over Tsai et al.,	Review	O	0
CVPR18, the introduced methods does not show very significant gain in multiple experiments.	Review	B-Review	3
On SYNTHIA-to-City, only 0.4 mIoU gain is obtained.	Review	I-Review	3
In addition, while the proposed method is empirically effective, it is largely task-specific and restricted to domain adaptation for scene parsing only.	Review	I-Review	3
It seems difficult to generalize the same method to other domain adaptation tasks.	Review	I-Review	3
The limitation on the performance gain and generalizability somehow reduced the contribution from this work to the community.	Review	I-Review	3
[line_break_token][line_break_token]- A major concern of this work is the lack of citation and direct comparison to multiple previous SOTAs.	Review	O	0
For example, the paper should compare the end-system performance with several published works such as:[line_break_token]1.	Review	B-Review	4
Zhang et al.,	Review	I-Review	4
Fully convolutional adaptation networks for semantic segmentation, CVPR2018[line_break_token]2.	Review	I-Review	4
Zhu et al.,	Review	I-Review	4
Penalizing top performers: conservative loss for semantic segmentation adaptation, ECCV2018[line_break_token]3.	Review	I-Review	4
Zou et al.,	Review	I-Review	4
Domain adaptation for semantic segmentation via class-balanced self-training, ECCV2018[line_break_token]And according to the results reported by these works, the proposed joint framework in this paper does not seem very competitive in terms of the UDA performance in multiple settings	Review	I-Review	4
Thanks for the valuable comments.	Reply	O	0
For the CVPR‚Äô18 work (ROAD: Reality Oriented Adaptation for Semantic Segmentation of Urban Scenes), we acknowledge their idea of using spatial-aware adaptation on spatial regions in the image (will cite it in the revised paper).	Reply	B-Reply	1
However, their idea is more similar to the PatchGan discriminator used in Tsai, et al.,	Reply	I-Reply	1
CVPR‚Äô18 (i.e., spatially global alignment), and is different from the proposed patch-level alignment.	Reply	I-Reply	1
Our patch alignment focuses on refining small patches (e.g., 32x64) and is location-independent (as described in Figure 1, introduction, and Section 3.3), while the CVPR‚Äô18 works assume fixed local regions with larger patches (e.g., 171x342) that account for the context information.	Reply	I-Reply	1
In addition, as shown in the ablation study (without reshaped \hat{F} in Table 1), it shows that the proposed location-independent operation helps patch-level alignment.	Reply	I-Reply	1
[line_break_token][line_break_token]For the number of clusters K, we find that the result varies on the GTA5-to-Cityscapes dataset.	Reply	I-Reply	2
For example, when K is small (e.g., 20), there would be ambiguities for the patch-level alignment process and the performance drops to 41.6, while it is also more difficult to match patches across domains when K is too large (e.g., 200).	Reply	I-Reply	2
In practice, we find that within a reasonable range, e.g., K = [30, 80], the IoU is in a range of [42.6%, 43.2%]. For \lambda_d, the goal is to simply perform classification based on clustering, and we find that the results do not differ a lot when choosing \lambda_d from a range of [0.005, 0.02]. For \lambda_adv^l in a range of [0.00005, 0.001], the results are in a range of [42.7%, 43.2%]. We will provide a complete analysis in the revised paper.	Reply	I-Reply	2
Note that, choosing such hyper-parameters is an open question for domain adaptation tasks.	Reply	I-Reply	2
We will put this as a future work and we hope that by providing such analysis, it would help the audience better understand the effect of hyper-parameters.	Reply	I-Reply	2
[line_break_token][line_break_token]Following Tsai, et al.,	Reply	I-Reply	3
CVPR‚Äô18, the source-only performance using VGG is 26.4% and 30.7% on GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes, respectively.	Reply	I-Reply	3
For the mIoU v.s.	Reply	I-Reply	3
epoch curve on GTA5-to-Cityscapes, since there is no supervision on the target domain, the performance usually fluctuates as most domain adaptation methods do via adversarial learning.	Reply	I-Reply	3
In our experiments, the IoUs are [42.6, 42.0, 42.1, 43.2, 42.1] when training for [50, 55, 60, 65, 70] K iterations using a batch size of 1.	Reply	I-Reply	3
[line_break_token][line_break_token]Although the improvement on SYNTHIA-to-Cityscapes is smaller, we find larger gains on certain categories against Tsai, et al.,	Reply	I-Reply	3
CVPR‚Äô18, such as road (3%), sidewalk (2.2%), and sky (1.5%).	Reply	I-Reply	3
This is because that the proposed method is designed to overcome domain gaps such as camera pose or field of view via location-independent patch-level alignment.	Reply	I-Reply	3
Due to this merit of our approach and the ease of integrating our module into any architectures, we believe that it could be beneficial for other tasks (e.g., depth estimation) that also suffer from the similar issues to semantic segmentation.	Reply	I-Reply	3
[line_break_token][line_break_token]We thank for pointing out related works.	Reply	I-Reply	4
Different from these methods that mostly focus on the usage of pixel-level domain adaptation (synthesized target images), loss function design, and pseudo label re-training, our work explores a new perspective via patch-level adversarial alignment and the proposed module is general for different architectures or design choices.	Reply	I-Reply	4
While the performance is competitive compared to these methods, we believe that our contribution is orthogonal to theirs.	Reply	I-Reply	4
We will add and discuss these papers in the revised paper	Reply	I-Reply	4

In this paper,  the authors pay attention on the bottleneck in the NAS of its large architecture space which cause low efficiency.	Review	O	0
They introduce the multi agent reinforcement learning method to take the neural architecture search as a multi agent reinforcement learning problem.	Review	O	0
[line_break_token][line_break_token]Main contribution is :(1) Framing the MAS as a multi agent problem. (	Review	O	0
2)Purpose two lightweight implementation. (	Review	O	0
3) Presenting 3 new datasets for NAS evaluation to minimize algorithmic over-fitting.	Review	O	0
[line_break_token][line_break_token]It seems like that it is the first work to combine multi agent reinforcement learning with NAS, and you have make complete proof about the algorithm's efficiency both mathematically and empirically.	Review	O	0
But from the view of multi agent reinforcement learning, there are also some points which make me confused.	Review	B-Review	1
[line_break_token][line_break_token]The main problem is coordination, and I understand it as the agents in your work aim to get a joint action and the training process of them are independent, but we all know that in multi agent problems, the changing of agent's policy will cause change of the environment, so it will bring the instability, so I want to know that how you deal with the instability or whether the instability influence a lot in your work?	Review	I-Review	1
Another problem may be not a theoretically problem that I want to know that have you made the guarantee of the consistency of agents' policies when using parallel training (May be the framework in coding process guarantee it ?)	Review	I-Review	1
or the consistency is unnecessary to talk because it doesn't influence the result?	Review	I-Review	1
e thank the reviewer for the encouraging and insightful comments.	Reply	O	0
We hope the following will address the issues raised.	Reply	O	0
[line_break_token][line_break_token]Regarding instability:[line_break_token]Our theoretical guarantees are based on the worst-case scenarios of adversarial losses, which includes potential instabilities in the joint behavior of the agents.	Reply	O	0
Indeed, this can be seen as a special form of reward stochasticity, which our algorithm is robust to.	Reply	B-Reply	1
In practice, we never encounter instabilities during training nor failure in convergence.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding, consistency of agents' policies:[line_break_token]If by parallel training the reviewer means training on multiple GPUs, then this is not an issue, as we wait for the full batch step to complete on all GPU cards before computing the reward, i.e. the coordination is synchronized and therefore the agents' policies are consistent.	Reply	O	0
Please let us know if we misunderstood the question	Reply	B-Reply	1

This paper proposes a novel advantage estimate for reinforcement learning based on estimating the extent to which past actions impact the current state.	Review	O	0
More precisely, the authors train a classifier to predict the action taken k-steps ago from the state at time t, the state at t-k and the time gap k. The idea is that when it is not possible to accurately predict the action, the action choice had no impact on the current state, and thus should not be assigned credit for the current reward, they refer to this as the "independence property" between current action and future states.	Review	O	0
Based on this idea, the authors introduce a "dependency factor", using the ratio P(s_{t+k},a_{t+k}|s_t,a_t)/P(s_{t+k},a_{t+k}|s_t).	Review	O	0
They later show that this can be reworked using Bayes theorem into a ratio of the form P(a_t|s_t,s_{t+k})/\pi(a_t|s_t) which is more convenient to estimate.	Review	O	0
The authors show mathematically that, when the dependency factor is computed with the true probabilities and use to weight each reward in a trajectory, the result is an unbiased advantage estimator.	Review	O	0
Importantly the expectation, in this case, is taken over trajectories sampled according to the policy pi conditioned only on S_t.	Review	O	0
This is distinct from the Monte-Carlo estimator which is based only on samples in which A_t, the action whose advantage is being estimated, was selected.	Review	O	0
[line_break_token][line_break_token]They go on to say that this estimator will tend to have lower variance than the conventional Monte-Carlo estimator when future rewards are independent of current actions.	Review	O	0
However, the variance can actually be higher, due to the importance sampling ratio used, when future rewards are highly dependent on the current action.	Review	O	0
They propose a method to combine the two estimators on a per reward while maintaining unbiasedness using a control variate style decomposition.	Review	O	0
This introduces a tunable reward decomposition parameter which determines how to allocate each reward between the two estimators.	Review	O	0
The authors propose a method to tune this parameter by approximately optimizing an upper bound on the variance of the combined estimator.	Review	O	0
[line_break_token][line_break_token]As a final contribution, the authors introduce a temporal-difference method of estimating the action probability P(a_t|s_t,s_{t+k}) required by their method.	Review	O	0
[line_break_token][line_break_token]In the experiments, the authors provide empirical evidence that various aspects of their proposed method can work as suggested on simple problems.	Review	O	0
They also provide a simple demonstration where their advantage estimator is shown to improve sample efficiency in a control problem.	Review	O	0
[line_break_token][line_break_token]This paper suffers from moderate clarity issues, but I lean toward acceptance primarily because I feel that the central idea is a solid contribution.	Review	O	0
The idea of improving credit assignment by explicitly estimating how much actions impact future states seems reasonable and interesting.	Review	O	0
The temporal difference method introduced for estimating P(a_t|s_t,s_{t+k}) is also interesting and clever.	Review	O	0
I'm less confident in the introduced method for trading off between the Monte Carlo and importance sampling estimators.	Review	O	0
The experiments seem reasonably well executed and do a fair job of highlighting different aspects of the proposed method.	Review	O	0
[line_break_token][line_break_token]The derivation of the combined estimator was very confusing to me.	Review	B-Review	1
It's strange that the derivation of the variance lower bound includes terms which are drawn from both a state conditional and state-action conditional trajectory.	Review	I-Review	1
You're effectively summing variances computed with respect to two different measures, but the quantity being bounded is referred to as just the "variance of the advantage estimator".	Review	I-Review	1
What measure is this variance supposed to be computed with respect to?	Review	I-Review	1
Especially given that as written the two estimators rely on samples drawn from two different measures.	Review	I-Review	1
It doesn't help that the advantage estimator whose variance is being constructed is never explicitly defined but just referred to as "advantage estimator derived from equation 3".	Review	I-Review	1
Nevertheless, if we ignore the details of what exactly it is a lower bound of, the sum of the three variances in equation 5 seems a reasonable surrogate to minimize.	Review	I-Review	1
[line_break_token][line_break_token]Related to the above point I don't fully understand what the variances shown in table 1 mean in the experiments section.	Review	I-Review	2
For the IAE estimator for example, is the variance computed based on each sample using three independent trajectories (one for each term) or is it computed from single trajectories?	Review	I-Review	2
If it's from single trajectories I can't understand how the expression would be computed.	Review	I-Review	2
[line_break_token][line_break_token]Questions for the authors:[line_break_token]-Could you please explicitly define the "advantage estimator derived from equation 3"?	Review	O	0
[line_break_token]-Could you please explain precisely how the variance is computed in table 1?	Review	O	0
[line_break_token][line_break_token]Update:[line_break_token][line_break_token]Having read the other reviews and authors response I will maintain my score of a weak accept, though given more granularity I would raise my score to a 7 after the clarifications.	Review	O	0
I appreciate the authors' clarification of the advantage estimator and feel the related changes to the paper are very helpful.	Review	O	0
I still feel the central idea of the work is quite strong.	Review	O	0
[line_break_token][line_break_token]However, I also feel the control variate part of the work is very loosely specified.	Review	B-Review	3
In particular, given the use of function approximation in practice instead of actually sampling 3 trajectories the validity of the control variate method applied is questionable.	Review	I-Review	3
As the authors say "if the random variable in either term has high variance, function approximators will tend to have large error", This may be true initially but the function approximator can already reduce variance over time by learning, so it's not clear how the function approximators and control variate complement each other.	Review	I-Review	3
This is something I feel would be worthwhile to explore more in future work.	Review	I-Review	3
[line_break_token][line_break_token]Also, I feel it's worth pointing out that a concurrent paper presenting a very similar idea is scheduled to be presented at NeurIPS 2020, which can be found here: <a href="https://papers.nips.cc/paper/9413-hindsight-credit-assignment."	Review	O	0
target="_blank" rel="nofollow">https://papers.nips.cc/paper/9413-hindsight-credit-assignment.</a> I don't feel this in any way undermines the contribution of the work presented here, but merely wanted to make the meta reviewer aware in case it was relevant to their decision.	Review	O	0
In fact, I feel this work complements that one in a number of ways, including the presentation of the temporal difference method for learning the action probabilities.	Review	B-Review	4
hank you so much for your supportive comments.	Reply	O	0
In the following sections, we will give response to two questions you have.	Reply	O	0
Please let us know if you have any questions in the response.	Reply	O	0
[line_break_token] [line_break_token][Define the "advantage estimator derived from equation 3‚Äù][line_break_token] [line_break_token]We are sorry that we didn't clearly define the advantage estimator without function approximations.	Reply	O	0
In our updated version of paper, the advantage estimator is defined formally, based on one assumption that we can sample multiple trajectories on the same state.	Reply	B-Reply	1
If three samples are individually sampled in every expectation term in equation (3), we are able to define an advantage estimator with the variance in the same form as equation (5) in the old version of paper, except that the factor is 1.	Reply	I-Reply	1
The rest of discussions, which focuses on how to minimize the variance, will not be affected by this change.	Reply	I-Reply	1
[line_break_token] [line_break_token]If we consider the problem practically, since we cannot sample multiple trajectories from the same state, we must use function approximators to represent some of values in equation (3).	Reply	I-Reply	1
That doesn't mean it is unnecessary to consider the variance in either of three terms: if the random variable in either term has high variance, function approximators will tend to have large error.	Reply	I-Reply	1
Thus practically, we think that using the sum of three variances as a surrogate objective will be a reasonable choice.	Reply	I-Reply	1
[line_break_token] [line_break_token][How variance is computed in table 1][line_break_token] [line_break_token]We are sorry that we didn‚Äôt clearly mention this.	Reply	O	0
For all three methods, we estimate the advantage function of the same state-action pair.	Reply	B-Reply	2
For IAE, we individually sample three trajectories for each estimation of, one starting from and two starting from s, and use these three trajectories to compute the three terms in equation (3).	Reply	I-Reply	2
We have added these details to the experiment section in the updated version of our paper	Reply	I-Reply	2

The authors propose a new neural network model, called as Dissimilarity Network, to improve the few-shot learning accuracy.	Review	O	0
[line_break_token]Overall the idea is well motivated that by emphasizing the difference among classes, the model can achieve more accurate predictions for classes where only limited data points are available for training.	Review	O	0
[line_break_token]However, the paper is not quite well written.	Review	O	0
[line_break_token]Firstly, much of the work is built upon previous work including attention mechanisms, episodic training for few-shot learning.	Review	B-Review	1
Such components are the core of this work because the attention mechanisms implement the class-awareness, and the episodic training facilitates the LSTM structure.	Review	I-Review	1
Yet these are not well explained and not much context is provided, thus making the paper hard to follow.	Review	I-Review	1
[line_break_token]Secondly, some terms are fairly overloaded, or not clearly defined.	Review	I-Review	2
For example, the ‚Äúprior‚Äù as mentioned in both the abstract and the introduction doesn‚Äôt refer to the commonly interpreted term as in the Bayesian settings, but rather as a hand-waiving term to indicate the model design.	Review	I-Review	2
Also, the terms, ‚Äúscore‚Äù, ‚Äúmetric‚Äù, ‚Äúdissimilarity‚Äù are mentioned in the paper but the paper is not really learning the metric, to my understanding.	Review	I-Review	2
Thus the details of the paper is quite hard to grasp.	Review	I-Review	2
[line_break_token]Lastly, the idea of designing the global embedding and the task aware embedding is interesting but shouldn‚Äôt really be restricted to few-shot learning.	Review	I-Review	3
It would be interesting to test the idea on general classification tasks, for example in a simple cross validation settings.	Review	I-Review	3
[line_break_token]Thus I think the paper would be stronger if the above are addressed and it‚Äôs not ready for publishing yet in its current form.	Review	O	0
[line_break_token][line_break_token]Below are some more detailed comments:[line_break_token]1)[tab_token]In the abstract, the ‚Äúnewly introduced dataset H-CIFAR‚Äù is not precise to me; my understanding is that the paper proposes such an experiment design for testing how well a classifier can predict the labels with hierarchy.	Review	O	0
The current writing refers to that the authors comprises a completely new dataset with new labels.	Review	B-Review	4
[line_break_token]2)[tab_token]In the last sentence of the second paragraph in Introduction, the question is asked ‚Äúwhat prior‚Äù should be reasonable.	Review	O	0
Since the authors didn‚Äôt really add any priors in a Bayesian settings but rather designed an architecture, I suggest to reword something like ‚Äúhow to explicitly encode hierarchies into the model structure‚Äù.	Review	B-Review	6
[line_break_token]3)[tab_token]In Section 2.1, some more description for ‚Äúepisodic training‚Äù would be nice: why should it be used?	Review	O	0
How is it used and why it makes sense in the few-shot learning context?	Review	B-Review	7
[line_break_token]4)[tab_token]In Section 2.2, it would be nice to add the mathematical definition of ‚Äúprototype‚Äù.	Review	O	0
[line_break_token]5)[tab_token]In Section 2.2.1, it would be nice to define ‚ÄúH‚Äù.	Review	O	0
[line_break_token]6)[tab_token]In Section 2.2.2, is M required to be fixed given it‚Äôs episodic training?	Review	O	0
Also it would be nice to add more details about the attention mechanism.	Review	B-Review	10
[line_break_token]7)[tab_token]In the result section, it would be nice to discuss when the proposed method is doing better than other methods, for example RelationNet, as well as when it‚Äôs worse since different datasets show different results.	Review	O	0
[line_break_token]	Review	O	0
hanks for taking the time to review our paper.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Explanation about Components[line_break_token]---[line_break_token]We have updated the manuscript to include more explanation about the methods that we rely upon.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Terms &amp; Similarity Learning[line_break_token]---[line_break_token]We have updated the manuscript to use more appropriate terms: inductive bias and similarity learning.	Reply	O	0
[line_break_token][line_break_token]Our method adopts the approach of similarity learning.	Reply	B-Reply	2
Instead of learning a distance or similarity function, we learn a space (embedding) that works well with a fixed similarity-based classifier in that space.	Reply	I-Reply	2
Specifically, our model learns to construct a space that is optimized to separate data that belong to different classes for a classifier that uses dot-product as its similarity function.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Application on General Classification Tasks[line_break_token]---[line_break_token]In the usual classification tasks, the labels are fixed during the training and testing.	Reply	O	0
Our approach is advantageous if the labels are changing between task -- as in few-shot classification.	Reply	B-Reply	3
[line_break_token][line_break_token][line_break_token]Detailed Comments[line_break_token]---[line_break_token]We have updated our manuscript based on the above comments.	Reply	O	0
We also updated the name of our harder variant of CIFAR dataset to CIFAR-Hard to avoid confusion -- as CIFAR is already hierarchically labeled.	Reply	B-Reply	4
For point (1), it‚Äôs true that our new dataset can be seen through the lens of experiment design.	Reply	I-Reply	4
However, it‚Äôs also true that the dataset is new, in a sense that the dataset comprises of a new set of image label pairs, with the label derived from the original CIFAR.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]Results &amp; Discussions[line_break_token]---[line_break_token]We have added more discussion about the results in the manuscript.	Reply	O	0
Please have a look at the updated manuscript.	Reply	B-Reply	5

The paper discusses connections between the properties of DNN loss surfaces and the step length SGD algorithms take, a timely topic.	Review	O	0
 On the whole, reasonably well done, with some interesting observations.	Review	O	0
[line_break_token][line_break_token]It makes several claims, most notably that there is an initial regime where SGD visits increasingly sharp regions of the loss surface, followed by a regime where the loss surface gets smoother.	Review	O	0
 Useful to know, and characterized moderately well.	Review	O	0
[line_break_token][line_break_token]A weakness is that the generality of that claim is not made clear.	Review	B-Review	1
 Like many papers in the area, it is an observation, the realm of which is not clarified.	Review	I-Review	1
 E.g., what properties of the neural network or data does it depend on.	Review	I-Review	1
 Also not clarified is how this depends on initialization, etc.	Review	I-Review	1
[line_break_token][line_break_token]The evaluation should be more systematic, as it is hard to tell how general is the claims of the paper as well as how they depend on implementation details.	Review	I-Review	2
[line_break_token] [line_break_token]The discussion of Hessian directions ignores very relevant work by Yao et al (<a href="https://arxiv.org/abs/1802.08241" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.08241</a> and follow up).	Review	O	0
[line_break_token][line_break_token]The first figure in Fig 1 is probably misleading, and probably not worth having, the latter two are what is measured and thus more interesting.	Review	B-Review	4
[line_break_token][line_break_token]The obvious conclusion from the poor conditioning is that methods designed to addressed poor conditioning, i.e., second order methods, should be considered.	Review	I-Review	5
 Those should have a complementary dynamics to what is discussed.	Review	I-Review	5
 This is what is the elephant in the room when you talk about steering towards or away from regions whose curvature matches the SGD step.	Review	I-Review	5
[line_break_token][line_break_token]I don't know what it means to say "Where applicable, the Hessian is estimated with regularization applied"  Is this to speed up computation, why doesn't this change the loss surface, etc.	Review	I-Review	6
 If you are not measuring Hessian information precisely, then all the claims of the paper fall apart.	Review	I-Review	6
[line_break_token][line_break_token]Several times claims like "SGD reaches a region in which the SGD step matches ..."  Of course, the energy surface changes with training time, so it is a little unclear what is being said.	Review	I-Review	7
[line_break_token][line_break_token]The main method Nudged-SGD sounds like a poor-mans second order method.	Review	I-Review	8
 Why not describe it as such (in more than a footnote and appendix), rather than introducing a new acronym.	Review	I-Review	8
 I don't know that I believe the "key design principle" in the appendix for second order methods.	Review	I-Review	8
 Second order methods rotate and stretch to take a locally-correct step length, and this method sounds like it is doing a poor mans version of that.	Review	I-Review	8
 There is a good question as to whether the "thresholding" into large and small that NSGD is doing causes it to do something very different, but that isn't really evaluated.	Review	I-Review	8
[line_break_token][line_break_token]Averaging over two random seeds is not a lot.	Review	I-Review	9
[line_break_token]	Review	O	0
We thank the reviewer for his valuable comments.	Reply	O	0
Based on yours and other reviewers‚Äô remarks we run additional experiments using Adam, different initialization schemes  and on data from a sentence classification task.	Reply	O	0
We summarized them in <a href="https://goo.gl/yYM1DG," target="_blank" rel="nofollow">https://goo.gl/yYM1DG,</a> and would be happy to add them to the paper.	Reply	O	0
We will address now each point in order.	Reply	O	0
[line_break_token][line_break_token]* On generality *[line_break_token]On the whole, our experiments were run on CIFAR-10 and PTB as described  in the main text, and CIFAR-100 and Fashion-MNIST as descibed in the Appendix.	Reply	O	0
We also experimented with 4 models (Resnet-32, SimpleCNN, VGG, and LSTM).	Reply	B-Reply	1
We therefore believe that our main results describing how the Hessian behaves along the optimization trajectory were  supported by a reasonable (compared to similar papers in the domain) set of settings.	Reply	I-Reply	1
Please also note that related results were observed in concurrent ICLR submissions [1], [2] and [3]. In particular [2] shows that indeed a measure of curvature (Fisher Information) closely related to the Hessian grows initially very quickly - which confirms some of our observations in 3.1.	Reply	I-Reply	1
[line_break_token][line_break_token]Having said that we fully agree that extending the analysis to different initialization and dataset dependence would be desirable.	Reply	I-Reply	1
We rerun similar analysis to 3.1 using Adam, different initialization (we compared uniform to normal, with different scaling) and on IMDB (a sentence classification task).	Reply	I-Reply	1
These experiment corroborate our main finings.	Reply	I-Reply	1
[line_break_token][line_break_token]* Extending results to second order methods *[line_break_token]We fully agree that investigating second order methods would be very interesting.	Reply	O	0
Based on your remark as the first step towards this direction we rerun some of the experiments using Adam, see <a href="https://goo.gl/yYM1DG."	Reply	O	0
target="_blank" rel="nofollow">https://goo.gl/yYM1DG.</a> On the whole the main focus of the paper is on SGD, and thus a more extensive study perhaps should left for future work.	Reply	O	0
[line_break_token][line_break_token]Hessian and regularization.	Reply	B-Reply	5
We apologize for the unclear formulation.	Reply	I-Reply	5
We wanted to say, that we used regularization when computing the Hessian (e.g. including L2 terms, or sampling dropout mask) if this was also done for computing the loss  uring optimization.	Reply	I-Reply	5
In this sense we get a  more *realistic* estimate and this choice has *no bearing on the computation speed*. We will make this more clear in the revised version of the manuscript.	Reply	I-Reply	5
[line_break_token][line_break_token]What does ‚ÄúSGD matches curvature‚Äù mean.	Reply	I-Reply	5
Let us clarify what we mean by the phrase that SGD finds a region where its steps matches the curvature.	Reply	I-Reply	5
Consider projecting SGD step onto the directions corresponding to the largest eigenvalues of the Hessian.	Reply	I-Reply	5
Our claim is that along these directions the projection is too large to reduce the loss.	Reply	I-Reply	5
Visually, SGD step crosses the minima in the subspace spanned by the sharpest directions.	Reply	I-Reply	5
Please also see Fig.1 for an illustration.	Reply	I-Reply	5
We agree that wording is confusing, and we will formulate this in the revised version.	Reply	I-Reply	5
[line_break_token][line_break_token]*NSGD as a poor-mans second order *[line_break_token]We agree that NSGD is a second order method in the sense that it uses second order information to adapt the step-size.	Reply	O	0
It is different from typical second order methods in that it does not seek to minimize loss along the sharpest directions.	Reply	B-Reply	8
Instead, NSGD step typically crosses over the minima along the sharpest direction, just like in the case of SGD (in the sense as depicted in Fig.	Reply	I-Reply	8
1, and as discussed in the last Appendix).	Reply	I-Reply	8
To further clarify - the goal of this section was to investigate importance of SGD dynamics along the sharpest directions.	Reply	I-Reply	8
We did not seek to prove NSGD is a better optimizer than other second order methods, which is why we were inadvertently brief in the discussion about how it differs from other second order methods.	Reply	I-Reply	8
 We will clarify all of this and in particular note that NSGD is a specific form of a second order method.	Reply	I-Reply	8
[line_break_token][line_break_token]* Other points *[line_break_token]Thank you for pointing us to Yao et al.	Reply	O	0
We will add a discussion of Yao et al.	Reply	B-Reply	3
to ‚ÄòRelated work‚Äô.	Reply	I-Reply	3
[line_break_token][line_break_token]You mentioned that Fig.	Reply	I-Reply	4
1 is not useful.	Reply	I-Reply	4
In general, we would like to keep an intuitive depiction of the main findings.	Reply	I-Reply	4
Please let us know if you have any suggestions how to improve Fig.	Reply	I-Reply	4
1.	Reply	I-Reply	1
[line_break_token]---[line_break_token][line_break_token]Thank you again for your valuable comments, and we will update the manuscript shortly.	Reply	O	0
[line_break_token][line_break_token][1] Gradient Descent Happens in a Tiny Subspace, <a href="https://openreview.net/forum?id=ByeTHsAqtX" target="_blank" rel="nofollow">https://openreview.net/forum?id=ByeTHsAqtX</a>[line_break_token][2] Critical Learning Periods, <a href="https://openreview.net/forum?id=BkeStsCcKQ&noteId=BkeStsCcKQ" target="_blank" rel="nofollow">https://openreview.net/forum?id=BkeStsCcKQ&noteId=BkeStsCcKQ</a>[line_break_token][3] A Walk with SGD: How SGD Explores Regions of Deep Network Loss?,	Reply	O	0
<a href="https://openreview.net/forum?id=B1l6e3RcF7&noteId=BylzRFgP2Q" target="_blank" rel="nofollow">https://openreview.net/forum?id=B1l6e3RcF7&noteId=BylzRFgP2Q</a>[line_break_token][line_break_token]EDIT: We updated now the manuscript and added a summary of the experiments with a more careful analysis of NSGD results on IMDB.	Reply	O	0

The paper is easy to read and the presentation is clear, and I really appreciate this.	Review	O	0
[line_break_token][line_break_token]The authors address the very important topic of feature extraction and state representation learning.	Review	O	0
New results in this area are always valuable and welcome.	Review	O	0
However, my feeling is that the paper falls short in terms of making sufficient new contributions for an ICLR paper.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
The authors propose to learn a state representation by either training using a combined loss function, or training several representations using multiple loss functions followed by stacking.	Review	B-Review	1
These are standard and well-known techniques in machine learning.	Review	I-Review	1
The key contribution one looks for is in terms of new insights on why and when each approach works.	Review	I-Review	1
The paper fails to provide much insight in this regard.	Review	I-Review	1
Take this simple scenario: Suppose my input image is actually generated by a linear map plus gaussian noise on the true states.	Review	I-Review	1
Then I can simply use a PCA as my "auto encoder" and happily learn a high quality state representation close to the ground truth.	Review	I-Review	1
We know why this works.	Review	I-Review	1
In the real task, the image is a complex non-linear transformation of the true states.	Review	I-Review	1
What insights do I gain from this work in terms of how I should tackle this?	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Section 3 states some desirable characteristics in constructing a state representation.	Review	B-Review	2
These are well-known and fundamental aspects of machine learning -- applicable to almost all models that we want to learn.	Review	I-Review	2
In this sense, I do not find the section very informative.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
The empirical results (say, Table 1) seem too noisy to interpret (other than that using the ground truth provides the best performance).	Review	B-Review	3
It almost seems to suggest that one should simply use random features (as done in the "extreme learning machine" approach).	Review	I-Review	3
Again, not much insight to draw from this.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
Last comment.	Review	B-Review	4
Suppose I have a new robotic goal-directed task and my inputs are camera images.	Review	I-Review	4
Does this work tell me something that I don't already know in terms of learning new feature representation that is highly suitable for my task?	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
[line_break_token]Dear reviewer,[line_break_token]Thank you for your remarks!	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We indeed do not have strong theoretical result on the applicability of our approach, however, we provide some insight about the way of performing efficient state representation learning in the case of goal based tasks.	Reply	B-Reply	1
 In particular, we highlight the fact that auto-encoder based approaches and approaches based on action or next state prediction have complementary strengths that need to be combined to achieve good performances.	Reply	I-Reply	1
The use of GTC metrics also provides better understanding of what was learned by the SRL methods and we show that this is a good proxy for the final RL performance.	Reply	I-Reply	1
[line_break_token][line_break_token]Although the idea of "stacking" models is not new, this is, to the best of our knowledge, the first work proposing stacking for learning a disentangled state representation.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
We agree the desirable aspects are common sense.	Reply	B-Reply	2
We wanted to give more context, as it is still important for us to clarify what we are looking for before proposing any solution.	Reply	I-Reply	2
Following your remark, we reduced this section size to give more space for the technical description of our approach.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]3.	Reply	O	0
Table 1 should not be used alone.	Reply	B-Reply	3
It only gives insights about the "sufficiency" of each method using a large budget (5 Millions steps).	Reply	I-Reply	3
One should look at additional tables (with different time-steps budgets) along with the ground truth correlation (GTC, i.e., what was learned, is the representation interpretable?).	Reply	I-Reply	3
[line_break_token]Indeed, the evaluation of random features in comparison with other SRL approaches is one of our interesting results and we consider it as a good baseline versus end-to-end learning.	Reply	I-Reply	3
Nevertheless, the first contribution of the paper is to advocate for the decoupling of policy learning from feature extraction.	Reply	I-Reply	3
We hypothesize that random features should work in environments where visual observations are simple enough, and random features can preserve enough information (cf GTC tables).	Reply	I-Reply	3
[line_break_token]Following your remark, we updated the experiment and intro sections to clarify our results.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
Good question.	Reply	B-Reply	4
First, if you adopt reinforcement learning, this work should incite you to use a SRL model instead of learning the policy end to end.	Reply	I-Reply	4
Our study will also help you choose the objective function: it is important to combine several objectives; using an inverse model or an auto-encoder alone is usually not sufficient.	Reply	I-Reply	4
Finally, it gives you hints on the choice and effects of the different hyper-parameters: what state dimension is required, how many samples are needed, how to evaluate the learned states (using GTC as a proxy for RL performance) or how to choose the weights when combining objectives (and insights on the influence of changing the weights)	Reply	I-Reply	4

Summary[line_break_token]The paper describes using the technique of modifying the weights for the outer layers, used in teacher-student network for same task, to transfer learning for different tasks by modifying the loss function and pre-training using target network labels to emphasize the neurons that are considered important for prediction.	Review	O	0
The technique seems to be no more/slightly better than the Lsquare SP, but exceeds when used with attention.	Review	O	0
[line_break_token][line_break_token]Improvements[line_break_token]- the amount of training time needed to pre-train using the L-square FE and target labels should be mentioned as it seems that for large network, and large data, this can be a factor[line_break_token]- The choice of Resnet, at least one of the more recent networks for object detection (Inception, YOLO etc.)	Review	O	0
 would be a good add	Review	B-Review	2
Thank you for your review and encouraging comments.	Reply	O	0
We summarize Reviewer 1‚Äôs major concerns as following two questions and we try to respond these two answers accordingly.	Reply	O	0
[line_break_token][line_break_token]Q1. ‚	Reply	O	0
Äúthe amount of training time needed to pre-train using the L-2 FE and target labels should be mentioned as it seems that for large network, and large data, this can be a factor‚Äù[line_break_token][line_break_token]Response: Thanks for the comment.	Reply	O	0
We totally agree that the time-consumption of L2-FE adaption and attention learning should be considered as the overhead of our method.	Reply	B-Reply	1
Indeed, the time spent by L2-FE adaption and attention learning is no more than 50% of overall training time.	Reply	I-Reply	1
 For example, DELTA (w/o Attention) requires 139 minutes on Caltech30 task transferring from Resnet-101 pre-trained model, while DELTA (with Attention) consumes 197 minutes (42% more than DELTA w/o Attention which doesn‚Äôt need L2-FE adaption and attention learning).	Reply	I-Reply	1
Furthermore, L2-SP takes124 minutes and L2 spends 115 minutes on the same task in the same settings.	Reply	I-Reply	1
It is thus reasonable to conclude the extra time consumption on L2-FE adaption and attention learning does not add a significant overhead to common deep transfer learning practices.	Reply	I-Reply	1
[line_break_token][line_break_token]When we further breakdown such time overhead, we found that the major overhead is due to the attention learning, where for each filter forward inference is needed to estimate the contribution of such filter to the overall accuracy.	Reply	I-Reply	1
It should not be a significant performance bottleneck even for a large dataset, as the number of filters needed to evaluate might be fixed with given scratch for transfer learning.	Reply	I-Reply	1
 Note that one key contribution made in this manuscript is to improve the deep transfer learning via feature-map based regularization through introducing attention mechanism.	Reply	I-Reply	1
All in all, many thanks for your comments.	Reply	I-Reply	1
We are revising the manuscript, including the discussion on time consumption, accordingly.	Reply	I-Reply	1
[line_break_token][line_break_token]Q.2 The choice of Resnet, at least one of the more recent networks for object detection (Inception, YOLO etc.)	Reply	O	0
 would be a good add[line_break_token][line_break_token]Response: Thanks for comments.	Reply	O	0
We agree to incorporate more results and neural network architectures.	Reply	B-Reply	2
We are revising the manuscript with supplementary experiments on both new architecture (inception v3) and datasets(CUB-200-2011[1], Food-101[2]).	Reply	I-Reply	2
The results of above experiments will be reported in our new version.	Reply	I-Reply	2
[line_break_token][line_break_token][1] C.Wah,S.Branson,P.Welinder,P.Perona,andS.Belongie.	Reply	O	0
The caltech-ucsd birds-200-2011 dataset.	Reply	O	0
California Institute of Technology, 2011.	Reply	O	0
6, 7, 8[line_break_token][2] L. Bossard, M. Guillaumin, and L. Van Gool.	Reply	O	0
Food-101‚Äìmining discriminative components with random forests.	Reply	O	0
In ECCV, 2014.	Reply	O	0
6, 8	Reply	O	0

The authors apply neural architecture search techniques to the problem of physics based learning.	Review	O	0
It is interesting because it cleverly tackles the challenge of manually designing priors and network architectures.	Review	O	0
The results are also impressive as the proposed method surpasses all the considered baselines.	Review	O	0
Despite of the above upsides, I have the following questions/concerns.	Review	O	0
[line_break_token]1.	Review	B-Review	1
There is limited technical novelty as the entire method is mainly based on previous work on neural architecture search.	Review	I-Review	1
Nevertheless, it might be helpful to have some ablation study to show the improvement of the task-specific adaptations presented in the paper, with which I believe this could be a good paper on the application side.	Review	I-Review	1
[line_break_token]2.	Review	O	0
I'm curious about the performance of the baseline methods given the same amount of computation.	Review	B-Review	2
For example, is it possible to perform intensive hyperparameter tuning for the baselines to also obtain improvement.	Review	I-Review	2
It seems that the authors did not discuss the computational costs and whether different methods are compared given the same cost.	Review	I-Review	2
hank you for your detailed review.	Reply	O	0
[line_break_token][line_break_token]Q1: Ablation Study (Comparison with NAS without Task-specific Adaptations)[line_break_token]A1: We have added such a comparison.	Reply	O	0
The added experiment results in Appendix Section D and Fig.13  justify that our task-specific adaptations significantly boost the performance.	Reply	B-Reply	1
The details about task-specific adaptations and our novelty in merging NAS with PBL are in reply ‚ÄòGeneral reply about Novelty in merging NAS with PBL‚Äô.	Reply	O	0
[line_break_token][line_break_token]Q2: Intensive hyperparameter tuning for the baselines.	Reply	O	0
[line_break_token]A1: In our previous submission, we have tuned the hyperparameters for perfecting the baseline performance.	Reply	O	0
We now make it clearer by adding illustrations in ‚ÄòTraining details‚Äô, Section 4.3.	Reply	B-Reply	2
The illustrations are ‚ÄòMoreover, for all baseline approaches we compare in this paper, we fine-tune their hyperparameters in order to make fair comparisons.	Reply	I-Reply	2
We choose three hyperparameter sets for each scenario and run five times for each method.	Reply	I-Reply	2
We finally pick out the best result for each method.	Reply	I-Reply	2
‚Äô   [line_break_token]	Reply	O	0

This paper proposes an autoencoder architecture and training procedure for producing high-quality reconstructions and realistic interpolations.	Review	O	0
A "generator" autoencoder is trained to fool a "discriminator" autoencoder.	Review	O	0
The generator tries to minimize its own reconstruction error and minimize the reconstruction error of the discriminator when fed with interpolated latent vectors of real datapoints.	Review	O	0
The discriminator autoencoder has three losses, corresponding to minimizing reconstruction error on real datapoints and maximizing reconstruction error on the generator's output on both real datapoints and interpolated outputs.	Review	O	0
The authors also propose a loss which encourages the distances between real datapoints and their corresponding latent vectors to be similar, as well as a heuristic procedure for stabilizing GAN training.	Review	O	0
Qualitative results are shown on CelebA.[line_break_token][line_break_token]While the results look nice, the paper is not fit for publication in its current form.	Review	O	0
At a high level, the issues include a lack of convincing experimental verification of the method, a generally contradictory and confusing description of the methods, and frequent factual errors or mischaracterizations.	Review	O	0
Here I will try to describe many of the issues I found while reading the paper:[line_break_token]- Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure.	Review	O	0
The experimental results are completely qualitative.	Review	B-Review	1
No effort is made to provide a quantitative proof of claims such as "the reconstructions are less blurry" or "the interpolations are higher quality"; only a few examples are shown.	Review	I-Review	1
The experiments are not even described in the text, and many of the figures are unreferenced.	Review	I-Review	1
No ablation studies are done to determine the importance of different loss terms, such as L_dist.	Review	I-Review	1
No mention is given to how hyperparameters like alpha should be chosen (and in fact, the value given for it "1^{-4}/2" is nonsense; 1^{-4} is just 1).	Review	I-Review	1
No results for a baseline autoencoder (i.e., just optimizing reconstruction loss) are given.	Review	I-Review	1
[line_break_token]- At a higher level, no effort is given to argue why interpolation is a useful characteristic to try to encourage.	Review	O	0
There are no downstream applications proposed or tested.	Review	B-Review	2
Earlier models, such as VAEGAN, also give reasonable reconstructions and good interpolations.	Review	I-Review	2
Why is GAIA better?	Review	I-Review	2
On what problem would I use GAIA and achieve better results apart from making nice-looking interpolations of people's faces?	Review	I-Review	2
[line_break_token]- Definitions are often unclear or contradictory.	Review	I-Review	2
For example, the generator autoencoder is alternatingly treating as taking input X and taking input Z. I believe what is meant is that the generator consists of two networks which compute Z = encoder(X) and X = decoder(Z).	Review	I-Review	2
Instead, the paper just switches between G(Z) and G(X) wherever convenient.	Review	I-Review	2
Similarly, the equation for \delta_Disc is different in Algorithm 1 and in the equation in 2.2.	Review	I-Review	2
Interpolation, arguably one of the core parts of the model, is described as "interpolations are Euclidean interpolations between pairs of points in Z, sampled from a Gaussian distribution around the midpoint between Zg1en and Zg2en."	Review	I-Review	2
I assume the mean of this Gaussian is the midpoint; what is its covariance?	Review	I-Review	2
Etc.	Review	I-Review	2
[line_break_token]- All autoencoders are not generative models, and in particular GAIA is not a generative model.	Review	O	0
There is no generative process.	Review	B-Review	3
It does not estimate a data distribution.	Review	I-Review	3
A VAE is a generative model which an autoencoder-like structure, but this does not make all autoencoders generative models.	Review	I-Review	3
[line_break_token]- GAIA is described as encouraging "convex latent distributions" and a convex set is defined in the text as "A convex set of points is defined as a set in which the line connecting any pair of points will fall within the rest of the set."	Review	O	0
A convex set is not defined in terms of lines; it's defined in terms of convex combinations of points within the set.	Review	B-Review	4
In the paper, only lines between points are considered.	Review	I-Review	4
Claiming that the latent space is "convex" in the sense of purple blobs in B is not done - you would need to take a convex combination of multiple latent vectors and decode the results.	Review	I-Review	4
[line_break_token][line_break_token]This is an incomplete list of the issues with this paper.	Review	O	0
The paper would need significant changes before publication.	Review	O	0
Dear reviewer,[line_break_token][line_break_token]We thank you for your comprehensive list of issues raised with the initial submission of our article.	Reply	O	0
We believe we have exhaustively addressed each issue raised by each reviewer in our revised submission.	Reply	O	0
In response to each reviewer, we have divided each review into a point-by-point list of each issue raised followed by our response, pointing to where that issue was addressed in the text.	Reply	O	0
[line_break_token][line_break_token]We have made several major revisions, listed below, as well as a number of other revisions which are addressed point-by-point in response to reviewers.	Reply	O	0
[line_break_token][line_break_token]Major revisions:[line_break_token]As requested by all three reviewers, we added a set of quantitative and ablation experiments on a low dimensional dataset.	Reply	O	0
These experiments can be seen in Figures 2 and 6, as well as Table 1.	Reply	O	0
[line_break_token]We added an experiments section to the text and rearranged the text for structure.	Reply	O	0
[line_break_token]We rewrote sections of the introduction to better motivate our research.	Reply	O	0
[line_break_token]We added a number of relevant references and extended our discussion of related works.	Reply	O	0
[line_break_token]We edited the entire document for consistent notation both internally and to other related papers.	Reply	O	0
[line_break_token][line_break_token]We thank you for the time and energy put into your excellent reviews of our article and believe that our submission has greatly increased in quality because of your input.	Reply	O	0
[line_break_token][line_break_token]________________________________________[line_break_token]"- Experimental results are only given on CelebA which is a dataset with a very strong and easy-to-model structure.	Reply	O	0
The experimental results are completely qualitative.	Reply	O	0
[line_break_token]-------------------------------------------------------[line_break_token]We added a low dimensional dataset example (Figure 2, Table 1, Figure 6), and a quantitative assessment of the likelihood of interpolations and reconstructions, the correlation between latent structure and structure in high dimensional space, and the KL divergence between data and interpolations, as well as data and reconstructions.	Reply	O	0
We compared a VAE, and AE, and GAIA (both with and without the pairwise-distance loss term).	Reply	B-Reply	1
[line_break_token][line_break_token]________________________________________[line_break_token]"No effort is made to provide a quantitative proof of claims such as "the reconstructions are less blurry" or "the interpolations are higher quality"; only a few examples are shown.	Reply	O	0
[line_break_token]-------------------------------------------------------[line_break_token]We edited these section and sentences to not make comparative claims.	Reply	O	0
We now show examples in the appendix of reconstructions on several low dimensional datasets.	Reply	B-Reply	1
We can add additional interpolation and attribute vector figures in the appendix as well if the reviewer finds it important.	Reply	I-Reply	1
[line_break_token][line_break_token]________________________________________[line_break_token]"The experiments are not even described in the text, and many of the figures are unreferenced.	Reply	O	0
[line_break_token]-------------------------------------------------------[line_break_token]We added an experiments section to the text which now includes subsections for both datasets, describing each measure.	Reply	O	0
[line_break_token][line_break_token]________________________________________[line_break_token]"No ablation studies are done to determine the importance of different loss terms, such as L_dist.	Reply	O	0
No mention is given to how hyperparameters like alpha should be chosen[line_break_token]-------------------------------------------------------[line_break_token]We now perform an ablation study by comparing our autoencoder with adversarial regularization, to an autoencoder of the same architecture without regularization.	Reply	O	0
We also ablate L_dist.	Reply	B-Reply	1
[line_break_token]	Reply	O	0

This work proposed a new goodness of fit measure for generative network evaluations, which is based on how well the network can generate the training data.	Review	O	0
The measure is zero if the network could perfectly recover the training data, and would represent how far it is from generating the training set in the average manner of the total least square sense, where the one-to-one mapping between the generated data and the training sample is constructed through latent space optimization.	Review	O	0
Using the proposed measure, the authors showed an interesting trend present in the DCGAN training and the impact of the residual connection.	Review	O	0
The authors might want to add some discussion in Section 4.2 regarding why the residual connection is detrimental for covering the support.	Review	O	0
 Increasing the model complexity through larger latent space dimension and learning mixtures is proposed as solutions to improve the measure as well.	Review	O	0
[line_break_token][line_break_token]With all the interesting results presented, I still have the concerns about the sensitivity of the proposed measure:[line_break_token]- It is an average over the training data or the selected sample.	Review	O	0
Above Section 4, the authors argued that "\hat{F}(G) &gt; 0 meaning that we do not observe any memorization".	Review	O	0
This seems overly assertive.	Review	B-Review	1
Since the measure is an average over the training data, it has difficulty to differentiate between one network which has almost zero value for part of the training data but large values for the rest, and another network with roughly the same \hat{F}(G) value but small values for all training data.	Review	I-Review	1
The variance could help, but can not resolve this issue.	Review	I-Review	1
This would be more important when the training data contains noise or outliers.	Review	I-Review	1
[line_break_token]- It only concerns the generation of the training data, but not the sampled data from the network (at least not directly).	Review	O	0
Therefore it has no direct control of the fidelity of the generated samples.	Review	B-Review	2
[line_break_token]- As shown by the authors, the proposed measure can be considered as the approximation of the true probability support not covered by the generative models, which also defines a necessary condition to avoid mode collapse.	Review	O	0
But what about the other part?	Review	B-Review	3
It would have difficulty comparing two models with the same support but different high-density areas.	Review	I-Review	3
Indeed, there are existing works which consider both the precision and recall of the generative models [1, 2, 3], and directly work with the generated samples instead of the training data.	Review	I-Review	3
These should be discussed and compared with, not just the FID scores which have already been shown to have issues [3]. [line_break_token][line_break_token]Some notations:[line_break_token]- In the last equation on Page 2,  should it be L_{G} instead of L_{D}?	Review	O	0
[line_break_token]- In the first equation on Page 3, should the denominator be N_{B} instead of N_{N}?	Review	O	0
[line_break_token]- "Optimality" in terms of generative models may depend on the downstream tasks.	Review	O	0
I do not think there exists a universal definition of "optimality" for generative models.	Review	B-Review	6
[line_break_token][line_break_token][1] M.S.M. Sajjadi, O. Bachem, M. Lucic, O. Bousquet, and S. Gelly.	Review	O	0
Assessing generative models via precision and recall.	Review	O	0
NeurIPS 2018.	Review	O	0
[line_break_token][2] L. Simon, R. Webster, and J. Rabin.	Review	O	0
Revisiting precision and recall definition for generative model evaluation.	Review	O	0
ICML 2019.	Review	O	0
[line_break_token][3] T. Kynkaanniemi, T. Karras, S. Laine, J. Lehtinen, and T. Aila.	Review	O	0
Improved precision and recall metric for assessing generative models.	Review	O	0
Arxiv:1904.06991.	Review	O	0
hank you for the feedback on our paper.	Reply	O	0
We address your concerns as follows:[line_break_token][line_break_token]- It is true that if F&gt;0 then we can still have memorization, because we are taking an average.	Reply	O	0
In practice, this does not happen, as we captured in the histograms of Figure 4 and Figure 8 in the paper.	Reply	B-Reply	1
We observe that the distribution of distance is relatively symmetric and unimodal, making the average a very informative measure of memorization.	Reply	I-Reply	1
In addition, we are mostly concerned with having complete memorization of the data instead of just partial memorization.	Reply	I-Reply	1
For partial memorization scenarios, we agree that variations on our metric (such as minimum distance) could be very useful as well.	Reply	I-Reply	1
[line_break_token][line_break_token]- We consider generating the training set as a first step toward understanding important issues like mode collapse.	Reply	O	0
Of course, our measure alone will not be used to directly evaluate the fidelity of generated samples.	Reply	B-Reply	2
High fidelity samples are desirable, but if F &gt; 0 for these models, then that means that they are not learning the simplest distribution of all: the empirical distribution.	Reply	O	0
Hence, generative models should have F = 0, which implies that there is no mode collapse with the empirical distribution.	Reply	B-Reply	2
[line_break_token][line_break_token]- We are comparing the support of G to the training set only (and not the probability densities), because we are focusing on the simpler, yet necessary, topic of memorization in generative networks.	Reply	O	0
If a generative network cannot learn the training set, then there exists an image x such that the probability of generating x is equal to 0.	Reply	B-Reply	3
Thus, a probabilistic distance of x from the distribution of Imag(G) is related to the distance between the image of G and x, which is our approach.	Reply	I-Reply	3
[line_break_token][line_break_token]Let us know if you have any further concerns about our paper, and thank you for the helpful feedback	Reply	O	0

This paper tackles the problem of compressing trained convnets with the goal of reducing memory overhead and speeding up the forward pass.	Review	O	0
As I understand it, the main contribution of this work is to develop fast convolution routines for sparse conv weights int he case of general sparsity (as compared with structured sparsity).	Review	B-Review	1
They evaluate their method on both AlexNet and GoogLeNet as well as on various platforms.	Review	O	0
The authors make code available online.	Review	O	0
The paper is well written and does a good job of putting this work in the context of past model reduction techniques.	Review	O	0
[line_break_token][line_break_token]My main request of the authors would be to provide a concise summary of the speedup/memory gains achievable with this new work compared with previously published work.	Review	B-Review	2
The authors do show the various sparsity level obtained with various methods of pruning but it is unclear to me how to translate the information given in the paper into an understanding of gains relative to other methods.	Review	I-Review	2
Please note that, in addition to our fast convolution algorithms, another important contribution is the performance model guiding the pruning process that allows pursuing desired speedup and model size reduction without falling into combinatorial number of choices offered by multiple layers.	Reply	B-Reply	1
Our performance model can also guide other methods discussed in related work as shown by our application to dynamic network surgery (GDNS in Figure 4(a)).	Reply	I-Reply	1
[line_break_token][line_break_token]Thanks for the suggestion on summarizing inference speedups and model size reductions of related work.	Reply	O	0
A quick summary is shown below, which we will also consider including in our paper.	Reply	O	0
It is important to note that our work achieves highest speedup without accuracy loss among all the techniques below.	Reply	B-Reply	2
The speedups shown that are not our own measurements should be taken with a grain of salt because 1) many papers only provide relative speedups to a baseline whose efficiency is suboptimal (e.g. in some cases, the baseline is Caffe running on CPU, which is known to be suboptimal as it is tuned for GPU), and 2) what some papers report as "speedup" is actually FLOP reduction, not actual timing measurements.	Reply	I-Reply	2
As we did in our paper, for more scientific comparison among different CNN speedup techniques, we recommend using dense matrix multiplication (GEMM) FLOP/s of the evaluated platform as the baseline, because many platforms readily have vendor-provided extensively-optimized GEMM implementations which can be a proxy of highly-optimized dense CNN implementation.	Reply	I-Reply	2
This also aligns with a long-accepted common practice in the high-performance computing (HPC) community.	Reply	I-Reply	2
We omit Denton et al.	Reply	I-Reply	2
2014, Jaderberg et al.	Reply	I-Reply	2
2014, and Lebedev et al.	Reply	I-Reply	2
2015 in the summary because they report improvements in a subset of conv and fc layers.	Reply	I-Reply	2
[line_break_token] [line_break_token]AlexNet[line_break_token]GESL (ours, 0% top-1 accuracy drop):                8.5x smaller model,                      2.5x speedup,                                      4.2x FLOP reduction[line_break_token]DNS (0.5% top-1 accuracy drop):                    17.7x smaller model,                      1.0x speedup (not enough sparsity in conv layers), 2.8x FLOP reduction[line_break_token]SSL (0% top-1 accuracy drop):                       1.01x smaller model (no sparsity in fc), 1.5x speedup,                                      1.3x FLOP reduction[line_break_token]Lebedev and Lempitsky (1.3% top-1 accuracy drop):   2.9x smaller model,                      3.0x speedup? (	Reply	I-Reply	2
not sure if this is a real speedup or FLOP reduction)[line_break_token]Liu et al. (	Reply	I-Reply	2
1% top-1 accuracy drop):                1.04x smaller model (no sparsity in fc), 4.4x speedup (not sure if lowering overhead included)[line_break_token]Kim et al. (	Reply	I-Reply	2
1.7% top-5 accuracy drop):              5.5x smaller model,                      1.8x speedup,                                      2.7x FLOP reduction[line_break_token]Tai et al. (	Reply	I-Reply	2
0.4% top-5 accuracy drop):              5.0x smaller model,                      1.8x speedup,                                      5.3x FLOP reduction[line_break_token][line_break_token]GoogLeNet[line_break_token]GESL (0.2% top-1 accuracy drop):                    3.3x smaller model,                      2.0x speedups in conv and fc layers,               3.0x FLOP reduction[line_break_token]DNS (our own evaluation, 2.5% top-1 accuracy drop): 1.5x smaller model,                      2.0x speedups in conv and fc layers,               2.6x FLOP reduction[line_break_token]SSL (our own evaluation, 2% top-1 accuracy drop):   2.1x smaller model,                      speedup N/A yet,                                   2.3x FLOP reduction[line_break_token]Kim et al. (	Reply	I-Reply	2
0.2% top-5 accuracy drop):              1.3x smaller model,                      1.2x speedup,                                      1.3x FLOP reduction[line_break_token]Ioannou et al. (	Reply	I-Reply	2
0.4% top-1 accuracy drop):          1.7x smaller model,                      speedup N/A,                                       1.4x FLOP reduction[line_break_token]Tai et al. (	Reply	I-Reply	2
0.4% top-5 accuracy drop):              2.8x smaller model,                      1.2x speedup,                                      2.9x FLOP reductio	Reply	I-Reply	2

This paper describes a method of training neural networks to be robust to a worse case mixture of a set of predefined example attributes.	Review	O	0
This is done with a loss in accuracy in the average case but improvements in the worse case.	Review	O	0
The proposed algorithm is relatively simple and convergence rates are also given for this new algorithm.	Review	O	0
[line_break_token][line_break_token]Building neural networks that perform well in the face of group-level worse case test-set distributions is a very important problem particularly in areas such as health and safety-critical applications as past work points out.	Review	O	0
This paper shows good results in the worse case and additionally shows that the common technique of importance reweighting cannot arrive at the same solution.	Review	O	0
The convergence analyses also yield additional insight into this new algorithm.	Review	O	0
The paper is well written and relatively easy to understand with good details on the experimental setup.	Review	O	0
The algorithm has a downside in that the groups must be known a priori, is it possible for these groups to be learnt?	Review	B-Review	1
Also, can using a hinge loss also improve robustness to the worse case examples?	Review	O	0
[line_break_token][line_break_token]However, there are some unanswered questions in the paper.	Review	O	0
What is the effect on the training time of this algorithm?	Review	B-Review	3
Is it just the time for an additional forward prop?	Review	I-Review	3
What is the effect on the worse-case examples of weight decay on the Bert model?	Review	I-Review	4
Even though it hurts the average performance does it improve the worse case at all?	Review	I-Review	4
In the last line of algorithm 1 why is q_G used instead of q_g?	Review	I-Review	5
[line_break_token][line_break_token]Other comments:[line_break_token]At the bottom of P5: The ordering of 93.4% and 97.1% seem to be reversed.	Review	O	0
[line_break_token]Above eq.	Review	B-Review	7
5 , \delta_g seems to be overloaded.	Review	I-Review	7
In the paragraph, it first refers to the generalization gap and then later to a heuristic.	Review	I-Review	7
[line_break_token]Table 2: The drop in average accuracy for waterbirds does not seem 'small'.	Review	I-Review	8
[line_break_token]Bottom of P8: 'background is more unique', it seems this is supposed to mean the background appears less often?	Review	I-Review	9
[line_break_token][line_break_token]======================================================================================================[line_break_token]Update after rebuttal:[line_break_token][line_break_token]Thanks for the detailed answers to my comments and the additional experiments done with a hinge loss.	Review	O	0
I will keep my rating.	Review	O	0
hank you very much for your detailed comments and for going through our paper so carefully.	Reply	O	0
[line_break_token][line_break_token][line_break_token]1. ‚	Reply	O	0
ÄúThe algorithm has a downside in that the groups must be known a priori, is it possible for these groups to be learnt?‚Äù[line_break_token][line_break_token]Thanks for raising this point; please refer to our response to all reviewers.	Reply	O	0
[line_break_token][line_break_token][line_break_token]2. ‚	Reply	O	0
ÄúCan using a hinge loss also improve robustness to the worse case examples?‚Äù[line_break_token][line_break_token]We ran new experiments using the hinge loss in the CelebA and Waterbirds datasets (since these are binary classification tasks), but performance on the worst-case group did not improve.	Reply	O	0
Compared to the logistic loss, performance with the hinge loss was similar or slightly worse across each group.	Reply	B-Reply	2
For CelebA (on the test set and with early stopping), robust accuracy was 84.4% with the hinge loss and 88.3% with the logistic loss; and similarly for Waterbirds, robust accuracy was 84.7% with the hinge loss and 84.9% with the logistic loss.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]3. ‚	Reply	O	0
ÄúWhat is the effect on the training time of this algorithm?	Reply	O	0
Is it just the time for an additional forward prop?‚Äù[line_break_token][line_break_token]Optimizing for the worst-case group loss instead of the average loss has little effect on the run time of the algorithm.	Reply	O	0
In practice, optimizing for the worst-case group loss vs. average loss takes a similar amount of time (&lt;5% difference) for a given number of epochs.	Reply	O	0
For example, it took 12h 50min to train the CelebA ERM model for 50 epochs on an NVIDIA TITAN Xp, and 13h 20 min to train the corresponding DRO model.	Reply	B-Reply	3
[line_break_token][line_break_token]The small difference above is expected because the computation of the loss and its gradient dominates the run time of each iteration in both optimization algorithms.	Reply	I-Reply	3
The robust optimizer in Algorithm 1 requires only a few additional computations over the standard optimizer: a. Multiplying the weights by exponentiated losses and normalizing (second-to-last line in Algorithm 1), and b. Multiplying the loss gradient by (last line in Algorithm 1).	Reply	I-Reply	3
These are relatively cheap operations.	Reply	I-Reply	3
[line_break_token][line_break_token]This comparison of training times is an important point to clarify in the paper, and we will make it explicit in our revision.	Reply	I-Reply	3
Thanks for highlighting it.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]4. ‚	Reply	O	0
ÄúWhat is the effect on the worse-case examples of weight decay on the BERT model?	Reply	O	0
Even though it hurts the average performance does it improve the worse case at all?	Reply	O	0
[line_break_token][line_break_token]On the BERT model, we found that weight decay (specifically,) did not seem to affect the model‚Äôs accuracy on the worst-case group in comparison to the model without weight decay; training the above models to convergence resulted in similar (bad) performance on the worst-case group.	Reply	B-Reply	4
[line_break_token][line_break_token]Much larger values of weight decay ) were too conservative and significantly lowered model performance across all groups.	Reply	I-Reply	4
In CelebA and Waterbirds datasets, we similarly observed that weight decays that are too high result in poor overall performance.	Reply	I-Reply	4
[line_break_token][line_break_token]While it is possible that we have not found the appropriate value of weight decay for the BERT/MultiNLI model, these results may suggest that weight decay is not an effective form of regularization (compared to early stopping) for this particular model.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]5. ‚	Reply	O	0
ÄúIn the last line of algorithm 1 why is used instead of?‚Äù[line_break_token][line_break_token]That is a typo, and it should indeed be.	Reply	O	0
We will fix it.	Reply	B-Reply	5
Thank you.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]6. ‚	Reply	O	0
ÄúAt the bottom of P5: The ordering of 93.4% and 97.1% seem to be reversed.	Reply	O	0
‚Äù[line_break_token][line_break_token]That is also a typo, and we will fix it.	Reply	O	0
Thank you.	Reply	B-Reply	5
[line_break_token][line_break_token][line_break_token]7. ‚	Reply	O	0
ÄúAbove eq.	Reply	O	0
5 , seems to be overloaded.	Reply	O	0
In the paragraph, it first refers to the generalization gap and then later to a heuristic.	Reply	O	0
‚Äù[line_break_token][line_break_token]Thanks for catching the overloading.	Reply	O	0
We will refer to the heuristic as instead.	Reply	B-Reply	7
[line_break_token][line_break_token][line_break_token]8. ‚	Reply	O	0
ÄúTable 2: The drop in average accuracy for waterbirds does not seem 'small'.	Reply	O	0
‚Äù[line_break_token][line_break_token]You‚Äôre right that it is not a small change in relative error.	Reply	O	0
Thanks for the catch; we will clarify the text.	Reply	B-Reply	8
[line_break_token][line_break_token][line_break_token]9.	Reply	O	0
Bottom of P8: 'background is more unique', it seems this is supposed to mean the background appears less often?	Reply	O	0
[line_break_token][line_break_token]We will explain the example more clearly in the updated version.	Reply	B-Reply	9
The idea is the following: Assume that the actual spurious association is the same as in the original Waterbirds dataset (whether the background is water or land).	Reply	I-Reply	9
However, instead of a single water background and single land background, we now have fine-grained labelings of water and land backgrounds, such that waterbirds appear in 9 different water backgrounds (e.g., ‚Äúlake‚Äù, ‚Äúpond‚Äù, ‚Äúsea‚Äù, etc.)	Reply	I-Reply	9
and 1 land background, while landbirds appear in 9 different land backgrounds and 1 water background.	Reply	I-Reply	9
In this setting, each group of (waterbird/landbird, background) is the same size, so resampling yields the same model as ERM.	Reply	I-Reply	9
However, the DRO model would correctly upweight the waterbirds on a land background (and vice versa)	Reply	I-Reply	9

In this paper, the authors present two contributions:[line_break_token]1)[tab_token]The primary contribution is to show that CycleGAN can be formulated as a probabilistic version of a particular penalized-least squares problem (theory)[line_break_token]2)[tab_token]As proof of concept, they apply their version of CycleGAN to accelerated MRI and deconvolution microscopy (application)[line_break_token][line_break_token]While I find the idea to be potentially interesting, the presentation of the theory is unclear and not well-motivated; after reading, I‚Äôm not convinced that the connection to CycleGAN is as significant as the authors claim.	Review	O	0
The experimental results are preliminary.	Review	B-Review	10
My decision is to reject.	Review	O	0
Below are separate critiques on the sections.	Review	O	0
[line_break_token][line_break_token]Section 2-3: Hope the authors could clarify / strengthen these points in revision:[line_break_token]-[tab_token]Since the discussion in Section 3 is based on the optimization problem in Equation (7), this problem should be well-motivated.	Review	O	0
Currently it is presented as a problem that has been explored previously by Zhang et al and Aggarwal et al.	Review	B-Review	1
However, after taking a look at those papers, I don‚Äôt understand where this regularization term comes from.	Review	I-Review	1
In these papers, the regularization term (i.e. equation 2 or 3 of Zhang et al) appears independent of y. Since this term is key to the paper, it should be well explained here.	Review	I-Review	1
E.g. at the end of section 2.2: G_\theta(y) is a CNN pretrained on what task?	Review	I-Review	1
[line_break_token][line_break_token]-[tab_token]In the inverse problem, the objective is to estimate x from y. Therefore we care about \argmin x in Equation (7).	Review	O	0
In the probabilistic setting presented in Equation (8), analogously the objective is to estimate \pi^*, which is the solution to the primal problem.	Review	B-Review	2
The theory shows that the primal formulation in Equation (8) is equivalent to the dual formulation in Equation (16), but does not show how the dual solution yields the primal solution, which is lacking as obtaining the primal solution seems to be the point of solving the PLS problem. (	Review	I-Review	2
Interestingly, in Section 4, the authors are using the dual solution x = G_\theta(y) as if it is the mapping given by pi(x|y)‚Ä¶ this needs to be explained.)	Review	I-Review	2
[line_break_token][line_break_token]-[tab_token]The authors claim that Proposition 1 shows that the cyclic loss term in their dual formulation is a more general version of the cycle-consistency loss in CycleGAN.	Review	O	0
But looking closely at Proposition 1 and its proof, it seems that the equivalence holds only for specific weights, not for arbitrary weights.	Review	B-Review	3
Additionally, the specific weights are unknown (they depend on the solution \pi^* to the primal problem‚Ä¶).	Review	I-Review	3
I do not understand the claim that this is a generalization of cycle-consistency loss, nor do I see how the authors implement their version of the cyclic loss as it depends on unknown weights.	Review	I-Review	3
[line_break_token][line_break_token]-[tab_token]The connection to CycleGAN seems to hold only when p=q=1?	Review	O	0
[line_break_token][line_break_token]-[tab_token]End of section 3: The authors conclude ‚Äúour cost formulation using (17) with (18) and (19) is more general compared to the standard CycleGAN, since a general form of measurement data generator Hx can be used‚Äù.	Review	O	0
I don‚Äôt see the connection between the theory and this claim.	Review	B-Review	5
Even with CycleGAN, both generators can be arbitrary or fixed if one of them is known.	Review	I-Review	5
[line_break_token][line_break_token]-[tab_token]The proofs are easy to follow, though perhaps they could be moved to the Appendix in favor of providing more motivation and explanation in the main text.	Review	O	0
[line_break_token][line_break_token]Section 4:[line_break_token]-[tab_token]The authors motivate the problem with the PLS setup but then they use the learned regularization term x = G_\theta(y) as if it is the mapping given by pi(x|y).	Review	O	0
 I am confused by this.	Review	B-Review	7
[line_break_token]-[tab_token]Putting aside the connection to the PLS problem, my interpretation of the experimental setup is that the authors use CycleGAN with Wasserstein GAN loss instead of the classic discriminator loss, where one of the generators is known (and hence only one generator/discriminator pair is needed).	Review	O	0
I might be missing something, but I‚Äôm not sure that this approach is different enough from CycleGAN.	Review	B-Review	8
[line_break_token]-[tab_token]Considering that the authors have the ground truth, they could provide quantitative evaluation of their method against other methods, rather than showing a few qualitative results where it is working.	Review	O	0
[line_break_token]	Review	O	0
Q] .. I‚Äôm not convinced that the connection to CycleGAN is as significant as the authors claim... [line_break_token][line_break_token]==&gt;  We would like to assure the reviewer that the primary motivation of this work is to provide a principled method for designing cycleGAN for various inverse problems by using the original physics as regularization for OT.	Reply	O	0
This is an important advance over the existing CycleGAN, which is mainly derived from trial and error.	Reply	B-Reply	10
In particular,  the reason we enforce the proposed PLS cost for the OT problem is to lead the primal solution to become a true inverse of the forward operator at the global minimum.	Reply	I-Reply	10
As the other reviewers pointed out, our formulation is more generic than the classical cycleGAN formulation, and demonstrating their deep relationships, followed by two clear and concise derivations and their practical application,  is compelling.	Reply	I-Reply	10
 See General Comments.	Reply	I-Reply	10
[line_break_token][line_break_token][Q]  ...  Currently it is presented as a problem that has been explored previously by Zhang et al and Aggarwal et al.	Reply	O	0
H.. Since this term is key to the paper, . ..	Reply	O	0
[line_break_token][line_break_token]==&gt; We found that the latex bib file incorrectly referred to different Zhang's paper.	Reply	O	0
We are quoting a correct one now.	Reply	B-Reply	1
However, we understand the reviewers' concern that the existing deep learning prior approaches are indirectly related to y.  In this revision, rather than emphasizing our method as an extension of the existing PLS with deep learning prior, we have highlighted the difference in our formulation.	Reply	I-Reply	1
We emphasize that the reason for using (9) is to lead the primal solution to become a true inverse of the forward operator.	Reply	I-Reply	1
[line_break_token][line_break_token][Q]...   but does not show how the dual solution yields the primal solution....[line_break_token][line_break_token]==&gt; Thanks to our PLS formulation (9),  we confirmed that the dual solution and the primal solution are equivalent when the global optimum is achieved with.	Reply	O	0
[line_break_token][line_break_token][Q] The authors claim ... the cyclic loss term in their dual formulation is a more general version of the cycle-consistency loss in CycleGAN. ...	Reply	O	0
[line_break_token][line_break_token]==&gt; Kindly note that the term "general version" is used when, under certain conditions, the new formulation can be reduced to the standard one.	Reply	O	0
Similar to the standard cycleGAN, the hyperparameters should be selected by trial and error.	Reply	B-Reply	3
We agree that this is the limitation for both the standard and the proposed cycleGAN.	Reply	I-Reply	3
However, our "generalized" formulation gives better insight into the selection of hyperparameters.	Reply	I-Reply	3
In fact, the parameter is the relative match between two data distributions.	Reply	I-Reply	3
If it turns out that both pairs are perfect, the parameter should be 1.	Reply	I-Reply	3
In a real training scenario, the perfect match can not be found so that the hyperparamereter should be between 0 and 1.	Reply	I-Reply	3
[line_break_token][line_break_token][Q] The connection to CycleGAN seems to hold only when p=q=1?	Reply	O	0
[line_break_token][line_break_token]==&gt; We only considered  due to the simple c-transformation.	Reply	O	0
The widely used W-GAN is derived similarly by assuming p = 1.	Reply	B-Reply	4
The use of general PLS costs is of course possible and could lead to an interesting variation of the cycleGAN architecture.	Reply	I-Reply	4
[line_break_token][line_break_token][Q] ... Even with CycleGAN, both generators can be arbitrary or fixed if one of them is known.	Reply	O	0
[line_break_token][line_break_token]==&gt; The standard CycleGAN could use a fixed generator, but there is no optimal design criterion to show why this is better.	Reply	O	0
On the other hand, our formulation requires only a single deep generator if the measurement physics is given by the forward model Hx.	Reply	B-Reply	5
In fact, as one of the other reviewers noted,  this can be seen as a consistency term from the forward model to acts as a regularization term for OT.	Reply	I-Reply	5
[line_break_token][line_break_token][Q]The proofs ... could be moved to the Appendix..[line_break_token][line_break_token]==&gt; Done.	Reply	O	0
 [line_break_token][line_break_token][Q] ... but then they use the learned regularization term x = G_\theta(y) as if it is the mapping given by pi(x|y).	Reply	O	0
 [line_break_token][line_break_token]==&gt; Our novel PLS cost (9) enforces the dual solution to be the primal solution of the PLS when the global minimum is reached.	Reply	O	0
Therefore, in this case, is actually the map given by.	Reply	B-Reply	7
[line_break_token][line_break_token][Q] ...my interpretation of the experimental setup is that the authors use CycleGAN with Wasserstein GAN loss instead of the classic discriminator loss, where one of the generators is known ...  but I‚Äôm not sure that this approach is different enough from CycleGAN.	Reply	O	0
[line_break_token][line_break_token]==&gt; Our main contribution is the principal derivation of the cycleGAN architecture for various inverse problems.	Reply	O	0
If we use p = q = 1, the resulting discriminator loss becomes Wasserstein GAN.	Reply	B-Reply	8
However, with different p, q values and the regularized version of optimal transport, our formulation offers a new class of discriminator architecture.	Reply	I-Reply	8
In addition, if the forward mapping is unknown, the framework is reduced to the standard cycleGAN with two deep generators.	Reply	I-Reply	8
 Therefore, our framework is much more flexible.	Reply	I-Reply	8
[line_break_token][line_break_token][Q] ..they could provide quantitative evaluation of their method against other methods...[line_break_token][line_break_token]==&gt; Done.	Reply	O	0
In the revised paper, we have provided the quantitative results for both accelerated MRI and deconvolution microscopy.	Reply	B-Reply	9
The results clearly showed the advantages of the proposed method.	Reply	I-Reply	9

This paper combines a contrastive objective measuring the mutual information between the representations learned by a teacher and a student networks for model distillation.	Review	O	0
The objective enforces correlations between the learned representations.	Review	O	0
When combined with the popular KL divergence between the predictions of the two networks, the proposed model shows consistently improvement over existing alternatives on three distillation tasks.	Review	O	0
[line_break_token][line_break_token]This is a solid work ‚Äì it is based on sound principles and provides both rigorous theoretical analysis and extensive empirical evidence.	Review	O	0
I only have two minor suggestions.	Review	O	0
[line_break_token][line_break_token]1, From Section 3.2 to Section 3.4, it is not clear to me that on the model compression task, are both the proposed contrastive loss and the loss in Eq. (	Review	O	0
10) used?	Review	B-Review	1
[line_break_token][line_break_token]2, The ‚ÄúDeep mutual learning‚Äù, Zhang et al, CVPR‚Äô18 paper needs to be discussed.	Review	O	0
I‚Äôd also like to see some experiments on the effects of training the teacher and student networks jointly from scratch using the proposed loss.	Review	B-Review	2
[line_break_token]	Review	O	0
Dear Reviewer 1,[line_break_token][line_break_token]Thank you very much for the constructive comments.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
For our CRD results in Table 1&amp;2, we only use CRD loss.	Reply	O	0
We have added CRD+KD results in the revised version to avoid such confusion, and CRD+KD shows further small improvement.	Reply	B-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
We have added a discussion of the ‚ÄúDeep Mutual Learning‚Äù paper in Sec 6.8.	Reply	B-Reply	2
We have evaluated several different distillation methods under the mutual learning setting, see Table 8.	Reply	I-Reply	2
[line_break_token][line_break_token]Please don‚Äôt hesitate to let us know for any further feedback.	Reply	O	0
Thanks!	Reply	O	0

This paper discusses the application of word prediction for software keyboards.	Review	O	0
The goal is to customize the predictions for each user to account for member specific information while adhering to the strict compute constraints and privacy requirements.	Review	O	0
[line_break_token][line_break_token]The authors propose a simple method of mixing the global model with user specific data.	Review	O	0
Collecting the user specific models and averaging them to form the next global model.	Review	O	0
[line_break_token][line_break_token]The proposal is practical.	Review	B-Review	1
However, I am not convinced that this is novel enough for publication at ICLR.	Review	I-Review	1
[line_break_token][line_break_token]One major question.	Review	O	0
The authors assume that the global model will depict general english.	Review	B-Review	2
However, it is not necessary that the population of users will adhere to general English and hence the averaged model at the next time step t+1 might be significantly different from general English.	Review	I-Review	2
It is not clear to me as how this mechanism guarantees that it will not over-fit or that there will be no catastrophic forgetting.	Review	I-Review	2
Thank you for your review!	Reply	O	0
[line_break_token]I would like to make some clarifications and remarks.	Reply	O	0
[line_break_token][line_break_token]1) In the review you write [line_break_token]"One major question.	Reply	O	0
The authors assume that the global model will depict general english.	Reply	O	0
However, it is not necessary that the population of users will adhere to general English and hence the averaged model at the next time step t+1 might be significantly different from general English.	Reply	O	0
It is not clear to me as how this mechanism guarantees that it will not over-fit or that there will be no catastrophic forgetting."	Reply	O	0
[line_break_token][line_break_token]In our problem statement we consider general English to be the common language i.e. the commonly used language with statistically insignificant portion of user-specific expressions.	Reply	B-Reply	2
It is NOT necessarily the language induced by our in-house corpus.	Reply	I-Reply	2
As far as we have a model averaged on many users on the server we can treat this model as general language model.	Reply	I-Reply	2
So at each stage T the server-side model represents general language.	Reply	I-Reply	2
When the model is sent to the device it is updated according to the user data so there is a risk of catastrophic forgetting.	Reply	I-Reply	2
We prevent it by using (eventually) random rehearsal on device (only!).	Reply	I-Reply	2
[line_break_token][line_break_token]2) I also would like to draw your attention to the original and practically relevant problem statement.	Reply	O	0
In the works on Federated Learning issued so far each node is considered only as a client in distributed learning system for gradient calculation.	Reply	B-Reply	1
In our approach we guarantee that the model sent to the aggregation server is at the same time the actual model used for typing and gives the best performance for the end user.	Reply	I-Reply	1
It is guaranteed by the forgetting prevention mechanism.	Reply	I-Reply	1
It has at least following advantages: 1) No need  for synchronization after every iteration as in standard Federated learning scheme.	Reply	I-Reply	1
Standard Federated learning uses no more than 20 iterations on each device for reduction of the communication cost (McMahan et al.	Reply	I-Reply	1
2016, <a href="https://arxiv.org/abs/1602.05629)" target="_blank" rel="nofollow">https://arxiv.org/abs/1602.05629)</a> while we send our models only once in an epoch thus significantly reducing the communication cost. ;	Reply	O	0
2) Simpler synchronization scheme on the server; 3) Faster convergence; 4) Only 1 model is stored on the disk.	Reply	B-Reply	1
We think that these results may be interesting to many ML practitioners.	Reply	I-Reply	1
[line_break_token][line_break_token]3) You didn't discuss the privacy analysis part of the paper which we included in the list of our contributions.	Reply	O	0
We consider our contribution significant at least for the following reason.	Reply	B-Reply	1
To our knowledge deep neural networks have never been checked for differential privacy coming from the randomness of the training algorithm (combination of SGD, dropout regularization and model averaging in our case).	Reply	I-Reply	1
Existing approaches (e.g. Papernot et al.	Reply	I-Reply	1
2017, <a href="https://arxiv.org/pdf/1610.05755.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1610.05755.pdf)</a> suggest adding random noise at different stages of training leading to the tradeoff between accuracy and privacy.	Reply	O	0
At the same time our experiments show that the differential privacy can be guaranteed even without special treatment of the neural networks at least in some situations	Reply	B-Reply	1

summary:[line_break_token]The paper proposes a method to efficiently verify that generative models are consistent with respect to some known (latent) attribute.	Review	O	0
The authors defines attribute consistency by 1) mapping pairs of input (x1, x2) with matching attribute to a latent space using an encoder n_E(x) and 2) measuring how correctly an auxiliary classifier will classify the known attribute using (decoded) linear interpolations between the two latent encodings.	Review	O	0
Importantly, the proposed method gives guaranteed bounds on this consistency score, as opposed to simply evaluating the classifier on a fixed set uniformly sampled points between x1 and x2.	Review	O	0
In experiments the authors use their method to test for attribute independence as well as consistency under left-right flipping of an image using two different autoencoder models (VAE and CycleAE) obtaining tighter bounds on the ‚Äòattribute consistency‚Äô score than competing methods.	Review	O	0
 [line_break_token][line_break_token]Decision &amp; supporting arguments:[line_break_token]Conceptually I found the paper very appealing, and it tackles an important problem in generative modelling.	Review	O	0
However I have some concerns with respect to the paper in its current state:[line_break_token]1) It is not clear to me why the attribute consistency score, a key component in the paper, is a good measure of consistency in generative models.	Review	O	0
Notably, I miss motivation for why linear interpolations between encoded inputs should necessarily keep the attribute stable.	Review	B-Review	1
[line_break_token]2) Although I found the experiments interesting, I did not find the experimental section completely comprehensive.	Review	O	0
There is no discussion or experiments probing the dependency on the quality of the auxiliary classifier or the encoder/decoder model used.	Review	B-Review	2
[line_break_token]3) I did not find the description of the proposed method to be reasonably self-contained.	Review	O	0
Especially section 3 which describes the proposed method is challenging to follow.	Review	B-Review	3
The background material in section 2 reads very much like a set of definitions.	Review	I-Review	3
Since ICLR has a quite broad audience, I think the paper should be written in a more pedagogical way, with for instance clarifying examples.	Review	I-Review	3
An example of a sentence that is incredibly hard to parse is on page 4, describing domain lifting: ‚ÄúAny deterministic abstract domain can be directly interpreted as a probabilistic abstract domain, where the concretization of an element is given as the set of probability measures whose support is a subset of the set produced by the deterministic concretization.	Review	I-Review	3
‚Äù I think making this paper more pedagogical requires major rewriting.	Review	I-Review	3
[line_break_token][line_break_token]Due to the above reasons I currently score the paper as a ‚Äòweak reject‚Äô.	Review	O	0
[line_break_token][line_break_token]Further detailed questions/comments:[line_break_token]Consistency Score[line_break_token]Q1: What is the motivation behind the definition of the consistency attribute score.	Review	O	0
Especially, why is an attribute considered consistent if it is stable to linear interpolations in the latent space?	Review	B-Review	4
[line_break_token][line_break_token]Experiment Results:[line_break_token]Q2.1: Did you perform any experiments on how the L1 score of the auxiliary classifier affects the consistency score?	Review	O	0
I would also like to see some quantitative numbers on the auxiliary classifier.	Review	B-Review	5
[line_break_token]Q2.2: Why is the L1 score used for training the classifier instead of bernoulli which seems more natural for binary attributes?	Review	O	0
[line_break_token]Q2.3: Similarly, I would like to see some numbers on the quality of the encoder/decodes.	Review	O	0
Simply inspecting the interpolations in figure 3) the reconstructions seem quite blurry, likely due to the relatively small models used.	Review	B-Review	7
Is it prohibitively expensive to run the proposed method on bigger models (e.g. ResNet based encoder/decoders or Unet-style models)?	Review	I-Review	7
[line_break_token]Q2.4: I believe it would be more informative to show the actual confidence intervals in figure 2b) instead of only the width of the confidence intervals?	Review	O	0
[line_break_token][line_break_token]Readability:[line_break_token]Q3: I found it quite challenging to understand how the proposed is implemented in practice - My suggestion is that the authors add a pseudo-code / algorithm to section 3 clarifying exactly how the bounds reported in the experimental section are calculated.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
hank you for the thorough and clear review.	Reply	O	0
 We will answer in two parts.	Reply	O	0
[line_break_token][line_break_token]Q1.1: It is not clear to me why the attribute consistency score, a key component in the paper, is a good measure of consistency in generative models.	Reply	O	0
Notably, I miss motivation for why linear interpolations between encoded inputs should necessarily keep the attribute stable.	Reply	O	0
[line_break_token][line_break_token]There have been a wealth of papers that propose autoencoder/generative model systems that claim that linear interpolations produce "interpretable" results [1-11]. It is in fact possible that not all defined attributes for a dataset should be preserved under "interpretable" interpolations.	Reply	B-Reply	1
For example, interpolating between a person with only a beard and the same person with only a mustache would likely fail to satisfy the disjunctive attribute "no beard or no mustache."	Reply	I-Reply	1
However, for many attributes we do expect intuitively consistency along interpolations between examples with those attributes, such as "has blond hair."	Reply	I-Reply	1
One can examine the named attributes provided with CelebA to decide whether they should remain consistent among interpolations (we believe they should).	Reply	I-Reply	1
[line_break_token][line_break_token]Interestingly, this brings up the important point that deciding whether an attribute should correspond to a direction in the encoded representation for a dataset is likely a subjective question.	Reply	I-Reply	1
We do not claim to answer this.	Reply	I-Reply	1
Rather, our system attempts to verify this for a given dataset and given property.	Reply	I-Reply	1
[line_break_token][line_break_token]Q1.2: Especially, why is an attribute considered consistent if it is stable to linear interpolations in the latent space?	Reply	O	0
[line_break_token][line_break_token]We clarify that we do not measure the consistency of an attribute in vacuum, but with respect to a particular autoencoder.	Reply	B-Reply	4
An attribute which is consistent for one autoencoder might very well be inconsistent for another autoencoder, and this is not a judgement on the consistency of the attribute as much as it is a judgement on the consistency of the autoencoder.	Reply	I-Reply	4
[line_break_token][line_break_token][1] Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb, Martin Arjovsky, and Aaron Courville.	Reply	O	0
Adversarially learned inference.	Reply	O	0
arXiv preprint arXiv:1606.00704, 2016.	Reply	O	0
[line_break_token][2] Michael F Mathieu, Junbo Jake Zhao, Junbo Zhao, Aditya Ramesh, Pablo Sprechmann, and Yann LeCun.	Reply	O	0
Disentangling factors of variation in deep representation using adversarial training.	Reply	O	0
In Advances in Neural Information Processing Systems, pp.	Reply	O	0
5040‚Äì5048, 2016.	Reply	O	0
[line_break_token][3] Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio.	Reply	O	0
[line_break_token]Generating sentences from a continuous space.	Reply	O	0
arXiv preprint arXiv:1511.06349, 2015.	Reply	O	0
[line_break_token][4] Alec Radford, Luke Metz, and Soumith Chintala.	Reply	O	0
Unsupervised representation learning with deep convolutional generative adversarial networks.	Reply	O	0
arXiv preprint arXiv:1511.06434, 2015.	Reply	O	0
[line_break_token][5] Lars Mescheder, Sebastian Nowozin, and Andreas Geiger.	Reply	O	0
Adversarial variational bayes: Unifying variational autoencoders and generative adversarial networks.	Reply	O	0
In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp.	Reply	O	0
2391‚Äì2400.	Reply	O	0
JMLR.	Reply	O	0
org, 2017.	Reply	O	0
[line_break_token][6] David Ha and Douglas Eck.	Reply	O	0
A neural representation of sketch drawings.	Reply	O	0
arXiv preprint arXiv:1704.03477, 2017.	Reply	O	0
[line_break_token][7] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.	Reply	O	0
Density estimation using real nvp.	Reply	O	0
arXiv preprint arXiv:1605.08803, 2016.	Reply	O	0
[line_break_token][8] Anders Boesen Lindbo Larsen, S√∏ren Kaae S√∏nderby, Hugo Larochelle, and Ole Winther.	Reply	O	0
Autoencoding beyond pixels using a learned similarity metric.	Reply	O	0
arXiv preprint arXiv:1512.09300, 2015.	Reply	O	0
[line_break_token][9] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al.	Reply	O	0
Conditional image generation with pixelcnn decoders.	Reply	O	0
In Advances in neural information processing systems, pp.	Reply	O	0
4790‚Äì4798, 2016.	Reply	O	0
[line_break_token][10] Yongyi Lu, Yu-Wing Tai, and Chi-Keung Tang.	Reply	O	0
Attribute-guided face generation using conditional cyclegan.	Reply	O	0
In Proceedings of the European Conference on Computer Vision (ECCV), pp.	Reply	O	0
282‚Äì297, 2018.	Reply	O	0
[line_break_token][11] Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, and Xilin Chen.	Reply	O	0
Attgan: Facial attribute editing by only changing what you want.	Reply	O	0
IEEE Transactions on Image Processing, 2019.	Reply	O	0

The authors propose the use of statistics of softmax outputs to estimate the probability of error and probability of a test sample being out-of-domain.	Review	O	0
They contrast the performance of the proposed method with directly using the softmax output probabilities, and not their statistics, as a measure of confidence.	Review	O	0
[line_break_token][line_break_token]It would be great if the authors elaborate on the idea of ignoring the logit of the blank symbol.	Review	O	0
[line_break_token][line_break_token]It would be interesting to see the performance of the proposed methods in more confusable settings, ie.,	Review	B-Review	1
in cases where the out-of-domain examples are more similar to the in-domain examples.	Review	I-Review	1
e.g., in the case of speech recognition this might correspond to using a different language's speech with an ASR system trained in a particular language.	Review	I-Review	1
Here the acoustic characteristics of the speech signals from two different languages might be more similar as compared to the noisy and clean speech signals from the same language.	Review	I-Review	1
[line_break_token][line_break_token]In section 4, the description of the auxiliary decoder setup might benefit from more detail.	Review	I-Review	2
[line_break_token][line_break_token]There has been recent work on performance monitoring and accuracy prediction in the area of speech recognition, some of this work is listed below.	Review	I-Review	3
[line_break_token]1.	Review	O	0
Ogawa, Tetsuji, et al. "	Review	O	0
Delta-M measure for accuracy prediction and its application to multi-stream based unsupervised adaptation."	Review	O	0
Proceedings of ICASSP.	Review	O	0
2015.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
Hermansky, Hynek, et al. "	Review	O	0
Towards machines that know when they do not know."	Review	O	0
Proceedings of ICASSP, 2015.	Review	O	0
[line_break_token][line_break_token]3.	Review	O	0
Variani, Ehsan et al. "	Review	O	0
Multi-stream recognition of noisy speech with performance monitoring."	Review	O	0
INTERSPEECH.	Review	O	0
2013.	Review	O	0
Thank you for your analysis of our paper.	Reply	O	0
[line_break_token][line_break_token]When performing detection, we compute the softmax probabilities while ignoring the blank symbol's logit.	Reply	B-Reply	1
However, in training we leave the blank symbol alone.	Reply	I-Reply	1
With the blank symbol's presence, the softmax distributions at most time steps predict a blank symbol with high confidence, but without the blank symbol we can better differentiate between normal and abnormal distributions.	Reply	I-Reply	1
We now added this elaboration to the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]We tested the model in confusable settings for vision and NLP (CIFAR-10 and SUN, MNIST and Omniglot, IMDB and Movie Reviews, WSJ and Webblog).	Reply	I-Reply	3
Your comment made us realize we should add a test for speech.	Reply	I-Reply	3
We used Chinese speech and found that we could still detect the speech reliably (but not as easily), and the abnormality module still generalized to detecting this speech better than softmax probabilities alone.	Reply	I-Reply	3
These results are in the updated paper.	Reply	I-Reply	3
[line_break_token][line_break_token]We updated the paper to provide more detail of the abnormality module per your suggestion.	Reply	I-Reply	2
[line_break_token][line_break_token]Finally, thank you for the links.	Reply	O	0
We can differentiate between our work and their work if you want	Reply	O	0

This paper evaluates the empirical power of neural tangent kernel (NTK) on small-data tasks.	Review	O	0
The authors demonstrate the superior performance of NTK for classification/regression tasks on UCI database, small CIFAR-10 dataset and VOC07 testbed.	Review	O	0
[line_break_token][line_break_token]Overall, this paper is well written and organized.	Review	O	0
The experimental results are also quite interesting.	Review	O	0
Besides, some questions and comments are as follows:[line_break_token][line_break_token]One of the baseline algorithms in Table 1 is NN with NTK initialization.	Review	O	0
However, this paper does not give the formal definition of NTK initialization.	Review	B-Review	1
[line_break_token][line_break_token]In Figures 1-2, it can be observed that NTK cannot universally outperform baselines on all dataset.	Review	I-Review	2
For some dataset, NTK can be worse than baselines but for some other dataset, NTK can be significantly better than baselines.	Review	I-Review	2
Therefore, I would like the authors to briefly discuss which kind of data can be more efficiently learned through NTK or other training algorithms.	Review	I-Review	2
[line_break_token][line_break_token]In Tables 2-5, it can be observed that for CIFAR10 dataset, increasing the number of layers leads to higher test accuracy.	Review	I-Review	3
But for VOC07, one can observe the opposite thing.	Review	I-Review	3
Is there any explanation for this phenomenon?	Review	I-Review	3
[line_break_token][line_break_token]The authors should provide a clear description of the experimental setting.	Review	I-Review	4
For example, do you use batch normalization/weight decay in ResNets?	Review	I-Review	4
For training NN, which optimization algorithms do you use?	Review	I-Review	4
Do you use learning rate decay?	Review	I-Review	4
[line_break_token][line_break_token]======================[line_break_token]After reading authors' response:[line_break_token][line_break_token]Thanks for your response, I would like to keep my score.	Review	O	0
[line_break_token]	Review	O	0
hank you for your positive review.	Reply	O	0
Please find our response to your comments.	Reply	O	0
[line_break_token]1.	Reply	O	0
[tab_token]NTK initialization means a neural network with parameterization defined in Equation 2 with all weighted being initialized to be i.i.d.. We have added a sentence after Equation 2 to clarify this.	Reply	O	0
[line_break_token]2.	Reply	B-Reply	2
[tab_token]‚ÄúIn Figures 1-2, it can be observed ‚Ä¶..‚Äù There is no clear trend on which dataset NTK can be better than other classifiers.	Reply	O	0
We believe that investigating on which dataset NTK gives better performance requires more domain knowledge.	Reply	B-Reply	2
Some analyses on pairwise comparisons: NTK vs. RF and NTK vs. Gaussian kernel, are provided in Section 4.2.	Reply	I-Reply	2
[line_break_token]3.	Reply	O	0
[tab_token]‚ÄúIn Tables 2-5, it can be observed that ‚Ä¶‚Ä¶‚Äù Note for Tables 2-5, CNTKs are used on top of raw images, so to achieve better performance, one needs to use multi-layer CNTKs to extract higher-level features.	Reply	O	0
On the other hand, CNTKs on VOC07 are used on top of extracted features from ResNet-50, which are already high-level features.	Reply	B-Reply	3
Therefore, shallow CNTKs suffice for this case.	Reply	I-Reply	3
[line_break_token]4.	Reply	I-Reply	2
[tab_token]We have stated the experiment details in the third paragraph in Section B.	Reply	O	0

Summary:[line_break_token]       The authors take two tasks,sentiment analysis and natural language inference, and identify datasets for them which they counterfactually augment it by asking people over the Amazon Mechanical Turk Platform to change either the sentiment (in the case of sentiment analysis) or the nature of relationship in the NLI task by making minimal changes to the text that produce the targeted changes.	Review	O	0
[line_break_token][line_break_token]Authors find that popular models trained on either fail on the other dataset while the models trained on both actually generalize much better.	Review	O	0
This is because the original sample and its counterfactual pair the label changed , has the difference in the text that matters to the change and this pair could reduce spurious correlations that models might find in the data distribution.	Review	O	0
[line_break_token][line_break_token]Pros: [line_break_token] This is a very interesting experiment and certainly the dataset that will be released would be extremely valuable to the community.	Review	O	0
The one part (I dont have much NLP background but I do have a causality background) that I like most is that the new text generated are counterfactual in some real sense with respect to a real world generating process - that is people modifying text with changed targets.	Review	O	0
[line_break_token][line_break_token] A lot of existing work that claim to do counterfactual changes do not specify assumptions about the generating mechanism.	Review	O	0
For counterfactuals to be valid they have to be intervention on the actual generating mechanism (or an assumed one) acting on a given unit (latent) that produced the current sample.	Review	O	0
The paper in that respect (even if it does not explicitly specify relationship between counterfactuals and generating mechanisms) tries to be faithful to a "strict causal notion" by actually asking people to modify the text.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]    - I think the authors want to make an explicit connection to counterfactuals as understood in the causality community.	Review	O	0
Then they shy away from it saying they are inspired by it.	Review	B-Review	1
May be a formal exposition in the supplement about counterfactuals and generating mechanisms could help readers from other communities (NLP) even it means repeating standard/synthetic examples.	Review	I-Review	1
Its good to say what exactly in a counterfactual generation process, the "people" in amazon turk were substituting.	Review	I-Review	1
[line_break_token][line_break_token]   -  Is the romantic/ horror flips and their absence the only spurious thing in Figure 4 ?	Review	O	0
[line_break_token]  -  In figure 6, it appears that BERT is sensitive to the domain - does it mean that it is bad ? -	Review	O	0
Authors indicate that ideally it must not be so.	Review	B-Review	3
Because Table 3 results seem to indicate that BERT performs the best in almost all the cases .	Review	I-Review	3
[line_break_token] -  Can the authors highlight the best performances in each case in the Tables by a bold face.	Review	O	0
 It helps easily eye ball the best performing model.	Review	B-Review	4
[line_break_token] 	Review	I-Review	1
hank you for the thoughtful review and positive assessment.	Reply	O	0
We are glad to see that you appreciate the genuine flavor of causality in our paper and support our paper‚Äôs acceptance.	Reply	O	0
[line_break_token][line_break_token]We agree that a formal exposition introducing an NLP/deep learning audience to the basics of interventions and counterfactuals and expressing a toy DAG to explain the spurious associations between the review sentiment and the manifestation in text of other attributes of the review, including but not limited to the genre, actors, budget, etc.	Reply	B-Reply	1
We are actively working on preparing this exposition and while it is not yet in the draft we plan to have it prepared in advance of the camera-ready version.	Reply	I-Reply	1
[line_break_token][line_break_token]We thank the reviewer for pointing out that we should have been more thorough in explaining that while genre is a clear example of such a spurious association, it is far from the only one captured in Figure 4.	Reply	I-Reply	2
Indeed, many other words, including ‚Äúwill‚Äù, ‚Äúmy‚Äù, ‚Äúhas‚Äù, ‚Äúespecially‚Äù, ‚Äúlife‚Äù, ‚Äúworks‚Äù, ‚Äúboth‚Äù, ‚Äúit‚Äù, ‚Äúits‚Äù, ‚Äúlives‚Äù, ‚Äúgives‚Äù, ‚Äúown‚Äù, ‚Äújesus‚Äù, ‚Äúcannot‚Äù, ‚Äúeven‚Äù, ‚Äúinstead‚Äù, ‚Äúminutes‚Äù, ‚Äúyour‚Äù, ‚Äúeffort‚Äù, ‚Äúscript‚Äù, ‚Äúseems‚Äù, and ‚Äúsomething‚Äù, appear to be spuriously associated with sentiment and are captured by the original-only and revised-only classifiers as highly-weighted features.,	Reply	I-Reply	2
Notably all of these features fall out from the highly-weighted features when our classifier is trained on counterfactually-augmented data.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding the sensitivity of BERT models, Table 9 shows the ability of a model explicitly trained to differentiate between the original and the revised data.	Reply	I-Reply	3
This is to shed some insight on how much the two differ (on account of our intervention).	Reply	I-Reply	3
Because the two indeed are different, we expect that a model should be able to differentiate them to some degree.	Reply	I-Reply	3
We note that a model class‚Äôs ability to differentiate between the original and revised data when explicitly trained to do so may not necessarily be correlated with how susceptible that model is to breaking when evaluated out of sample.	Reply	I-Reply	3
[line_break_token][line_break_token]We‚Äôre grateful for your comments on exposition and will continue to address these points as we improve the draft.	Reply	O	0

The aim of this paper is to learn a heuristic for a backtracking search algorithm utilizing Reinforcement learning.	Review	O	0
The proposed model makes use of Graphical Neural Networks to produce literal and clauses embeddings, and use them to predict the quality of each literal, through a NN, which in turn decides the probability of each action.	Review	O	0
[line_break_token][line_break_token]Positives[line_break_token]A new approach on how to employ Machine learning techniques to Automated reasoning problems.	Review	O	0
Works with any 2QBF solver.	Review	O	0
[line_break_token]The learned heuristic seems to perform better than the state of the art in the presented experiments.	Review	O	0
[line_break_token][line_break_token]Negatives[line_break_token]No theoretical justification about why this heuristic should work better than the existing ones.	Review	O	0
[line_break_token]Doesn't solve QBF formulas in general, but only 2QBF.	Review	B-Review	2
[line_break_token]It is not clear whether the range of formulas that can be solved using this approach is greater than that of existing solvers.	Review	I-Review	3
[line_break_token]Having a substantial amount of formulas that produce incomplete episodes, as it might be the case in real world scenarios, hinders learning, so the dataset has to be manually adjusted.	Review	I-Review	4
[line_break_token][line_break_token]Conclusion[line_break_token]The proposed framework is an interesting addition to existing techniques in the field and the idea is suitable for further exploration and refinement.	Review	O	0
The experimental results are promising, so the direction of the work is worth pursuing.	Review	O	0
However, some of the foundations and overall nature of the work needs some improvement and maturity.	Review	O	0
We thank the reviewer for the detailed feedback.	Reply	O	0
[line_break_token][line_break_token]> No theoretical justification about why this heuristic should work better than the existing ones.	Reply	O	0
[line_break_token][line_break_token]This is a very interesting question, but surprisingly hard to answer.	Reply	B-Reply	1
Even for the simpler question of why CDCL for SAT solvers is so unreasonably effective for a wide range of applications, there is no concrete theoretical explanation - despite two decades of research!	Reply	I-Reply	1
When there is no satisfactory theoretical explanation, we suggest that it is better to learn the heuristics based on the data itself.	Reply	I-Reply	1
[line_break_token][line_break_token]> Doesn't solve QBF formulas in general, but only 2QBF.	Reply	O	0
[line_break_token][line_break_token]Our approach could be easily applied to general QBF as well.	Reply	B-Reply	2
The limitation to 2QBF is also due to the underlying tool.	Reply	I-Reply	2
But keep in mind that most applications of QBF, e.g. in verification and program synthesis, can be encoded with just one quantifier alternation, so we believe that we captured the most interesting cases of QBF.	Reply	I-Reply	2
[line_break_token][line_break_token]> It is not clear whether the range of formulas that can be solved using this approach is [line_break_token]> greater than that of existing solvers.	Reply	O	0
[line_break_token][line_break_token]Our experiments demonstrate that we can solve significantly more formulas when given enough formulas from a single source (=distribution).	Reply	B-Reply	3
We do not claim that the learned models generalize to formulas far away from that distribution.	Reply	I-Reply	3
The question whether it is possible to learn models that apply to a wide ‚Äúrange of formulas‚Äù is indeed an open one.	Reply	I-Reply	3
[line_break_token][line_break_token]> Having a substantial amount of formulas that produce incomplete episodes, as it might be[line_break_token]> the case in real world scenarios, hinders learning, so the dataset has to be manually[line_break_token]> adjusted.	Reply	O	0
[line_break_token][line_break_token]We believe that this the inherent challenge of problem solving: how can we learn to solve problems that we have never solved?	Reply	B-Reply	4
The assumption underlying this paper is that learning how to solve simpler problems faster, helps us to solve harder problems, too.	Reply	I-Reply	4
Our experiments demonstrate that this is indeed possible for problems sets containing many related formulas of different hardness levels.	Reply	I-Reply	4

# 1.	Review	O	0
Summary[line_break_token]The paper deals with the problem of learning grounded captions from images without joint text-location information, but instead texts (words in captions) and locations are provided independently and the model needs to figure out their link.	Review	O	0
The model is built upon GVD (Zhou et al.,	Review	O	0
2019): each word generated by the encoder is grounded to the locations provided by the region proposal module (Up-Down model (Anderson et al.,	Review	O	0
2018)), used to reconstruct the ground-truth caption.	Review	O	0
    [line_break_token][line_break_token]My weak reject decision was guided by the following strengths and weaknesses of the paper.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]* The reconstruction formulation of the problem is interesting and relevant for the task[line_break_token]* Proposed new metric to measure grounding performance[line_break_token]      [line_break_token]Weaknesses:[line_break_token]* Questionable motivations: it is not clear what application is grounding text to the image useful for?	Review	O	0
[line_break_token]* Marginal (not statistically significant?)	Review	O	0
improvement on image captioning metrics by using grounded text (proposed method) compared to not grounding (GVD)[line_break_token]* Limited novelty: extension of GVD, where attention is removed and object locations are used instead[line_break_token]     [line_break_token]      [line_break_token]# 2.	Review	O	0
Clarity and Motivation[line_break_token]The paper is generally well written, however there are some concerns on motivations.	Review	O	0
[line_break_token][line_break_token]One concern is related to the motivations of the paper.	Review	B-Review	1
The authors use grounding as a proxy to improve image captioning results, which improvement is marginal wrt GVD (see Table 1).	Review	I-Review	1
Why do we need to localize text if this has very marginal impact on the captioning metrics?	Review	I-Review	1
It is missing the link between the potential applications where the localization of words is relevant.	Review	I-Review	1
[line_break_token][line_break_token]The authors claim that they do not uses any grounding annotation, however the pre-trained Faster-RCNN has been trained using annotations which consist of bounding boxes + categories.	Review	I-Review	2
Therefore, the model do (in an implicit way) rely on grounding annotations, especially because there might be an overlap between the words (classes) used to pretrain the detector and the words in the captions.	Review	I-Review	2
The authors should assess if this ovelap/bias in the pre-trained Faster-RCNN exists or not.	Review	I-Review	2
[line_break_token][line_break_token]Some other questions are still to be answered:[line_break_token]* How are the regions R parametrized?	Review	O	0
Is it the visual representation or bounding box locations?	Review	B-Review	4
[line_break_token]* What happens to words that are not grounded to the image (e.g., verbs or articles)?	Review	O	0
Do you have a special way to deal with those?	Review	B-Review	5
[line_break_token]* What is the intuition of multiplying word embedding and region embeddings to generate z in Eq.	Review	O	0
6?	Review	B-Review	6
[line_break_token][line_break_token][line_break_token]# 3.	Review	O	0
Novelty[line_break_token]The proposed method is an extension of the existing model GVD, where the attentional module is removed and its functionality is replaced by the cyclical training mode with reconstruction of the object locations.	Review	O	0
From the technical point of view this is limited novelty, but still an interesting improvement of the model; however the experiments and results do not support the claim that using such model improves image captioning result in a significant way.	Review	B-Review	3
One way to answer to this question would have been by showing an application where the outputted locations are used for downstream tasks.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]# 4.	Review	O	0
Experimentation[line_break_token]The experiments are carried out in a scrupulous way, by showing the comparing with GVD (with and without attention; with and without grounding supervision).	Review	O	0
The non-convincing part of them (as mentioned above already) is the fact that the improvements on these datasets might be non significant for image captioning.	Review	B-Review	7
For example, let's consider the image captioning results in Table 1 (Flickr30k Entities): cyclical have a max improvement of 0.7 (CIDER) and min of 0 (B@4) when compared with GVD without grounding supervision.	Review	I-Review	7
There is an obvious huge improvement on the grounding evaluation, which is obvious since GVD does not do it explicitly.	Review	I-Review	7
The same trend is in Table 2.	Review	I-Review	7
[line_break_token]These results are not convincing, combined by the fact that it is not clear in which applications one would want a very accurate grounded text.	Review	I-Review	8
[line_break_token][line_break_token][line_break_token]# Minor Points[line_break_token]* Sec.	Review	O	0
3.1: it is not clear that the Language LSTM is the decoder.	Review	B-Review	9
Please explicitly say it before Eq.	Review	I-Review	9
1[line_break_token]* Caption of Table 3: which dataset is this?	Review	I-Review	9
[line_break_token]	Review	O	0
We would like to thank the reviewer for the thoughtful and detailed feedback.	Reply	O	0
We address the reviewer‚Äôs questions as below.	Reply	O	0
[line_break_token][line_break_token]--------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token]1.	Reply	O	0
We focus on making captioning model more visually-grounded, not improving its captioning performance[line_break_token]--------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token]As mentioned in the ‚Äúcontributions summary‚Äù in the introduction section, we focus on improving the grounding accuracy and retaining high captioning quality.	Reply	O	0
We did not claim that the proposed method would significantly improve captioning scores.	Reply	B-Reply	1
[line_break_token][line_break_token]Recently, visual grounding has received a great deal of attention [2] - [11]. The primary reason for this is that in many vision-and-language downstream tasks researchers have discovered that the model can learn to heavily exploit and rely on linguistic priors or dataset priors.	Reply	I-Reply	1
These vision and language models suffer from poor visual grounding.	Reply	I-Reply	1
They often fall back on easy-to-learn priors rather than basing model predictions on visual concepts.	Reply	I-Reply	1
They do this to (seemingly) achieve good performance according to the evaluation metrics.	Reply	I-Reply	1
For example, in the visual captioning task, the SoTA models can achieve CIDEr score &gt; 1.0 on MS-COCO which is higher than the human‚Äôs 0.85 [1]. However, the quality of the generated caption is still far from the quality of those generated by humans.	Reply	O	0
[line_break_token][line_break_token]For this reason, we believe that there are other important aspects besides improving captioning metrics that the research community should focus on, and much existing work has been actively discussing why visual grounding is an important topic and potentially mitigate other issues in visual question answering (VQA), embedding question answering (EQA), vision-and-language navigation (VLN), visual captioning, etc [2] - [11]. Toward this direction, to the best of our knowledge, we are the first ones proposing to significantly improve grounding accuracy for captioning model without relying on the ground-truth grounding annotation and without introducing extra computation at test time.	Reply	B-Reply	1
We showed that the improvements are consistent across image and video datasets.	Reply	I-Reply	1
Our results in Figure 4 also indicates that our performance on rare words (which is better than the supervised method) shows that improving grounding in an unsupervised way can lead to less bias due to long-tail distribution of the grounding annotation.	Reply	I-Reply	1
Finally, enforcing the model to be more visually-grounded makes the model more trustworthy and interpretable.	Reply	I-Reply	1
[line_break_token][line_break_token]--------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token]2.	Reply	O	0
Grounding annotation and its relation to pre-trained object detector[line_break_token]--------------------------------------------------------------------------------------------------------------------------------------------------------[line_break_token]Grounding annotation is typically referred to as the direct links/correspondences between the words in the sentence and regions in the image/video [9][10]. [line_break_token][line_break_token]We argue that while the faster-RCNN is pre-trained from the object detection dataset, the pre-trained object classes do not directly translate to the words in the captions.	Reply	O	0
Besides, the same image region could have different words describing it depending on the sentence context.	Reply	B-Reply	2
For example, image regions on a tree could correspond to: ‚Äútree‚Äù, ‚Äúforest‚Äù, ‚Äúmountain‚Äù, ‚Äúshrubs‚Äù, and ‚Äúbushes‚Äù in sentences like: ‚ÄúA man is cutting a tree‚Äù, ‚ÄúA woman is entering a forest‚Äù, ‚ÄúA man is hiking in the mountain‚Äú, ‚ÄúA woman is trimming shrubs‚Äù, etc.	Reply	I-Reply	2
[line_break_token][line_break_token]If the model is biased towards the visually-groundable words (object words) in the dataset, it will, however, have poor captioning performance as we discussed in Sec 4.3, Table 3, and Table 4.	Reply	I-Reply	2
Note that in all three different cases (original object detector, grounding-biased object detector, and unrealistically perfect object detector), we showed that grounding is still an important issue and our proposed method can successfully improve grounding accuracy regardless of whether the object detector is biased.	Reply	I-Reply	2

The authors propose a method that incorporates two types of graphs into a graph convolutional networks:[line_break_token][line_break_token](1) the given graph, which the authors refer to as node affinity graph, and [line_break_token](2) the graph that models an affinity between node attribute values.	Review	O	0
[line_break_token][line_break_token]The main contribution of their work is a type of graph convolution that combines convolutions operating on these two graphs.	Review	O	0
[line_break_token][line_break_token]The paper is densely written and provides several mathematical derivations that are unnecessary to convey the proposed method.	Review	B-Review	1
Personally, I don't see any benefits in having sections 3.1-3.4 in the main paper.	Review	I-Review	1
The method actually proposed and evaluated in the paper is described in section 3.5.	Review	I-Review	1
Sections 3.1-3.4 could be moved to an appendix.	Review	I-Review	1
They confuse the reader more than they help. (	Review	I-Review	1
They demonstrate knowledge of graph signal processing on the parts of the authors but little more.)	Review	I-Review	1
[line_break_token][line_break_token]Trying to provide some theoretical analysis of the proposed method (and standard graph convolutions) by showing that the intra-class variance is reduced is laudable.	Review	I-Review	2
The theorems, however, only hold under strong assumptions and could, in my opinion, also be moved to an appendix.	Review	I-Review	2
In the end, they don't have any bearing on the performance of the methods using real-world datasets.	Review	I-Review	2
Adding some experiments to analyse to what extent the assumptions made by the theorems are met in the given datasets would be an interesting addition to the paper.	Review	I-Review	2
[line_break_token][line_break_token]The authors discuss related work sufficiently with one exception: there has been recent work on learning the structure of graph neural networks.	Review	I-Review	3
See for example [1]. The structure is derived/bootstrapped using node attribute similarities and it is shown that augmenting the graph with these new edges improves accuracy significantly.	Review	I-Review	3
I would like to point the authors specifically to Figure 2 and Table 1 in said paper, where the authors show that adding edges (e.g., based on some node attribute affinity before or during training) is beneficial and improves accuracy.	Review	I-Review	3
It would therefore be interesting to see how the authors proposed 2-D convolution would compare to a baseline where the edges based on attribute affinity are added to the original (node affinity) graph.	Review	I-Review	3
It is a (somewhat simpler) alternative way to combine node affinity and node attribute graphs.	Review	I-Review	3
[line_break_token][line_break_token][1] <a href="https://arxiv.org/pdf/1903.11960.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1903.11960.pdf</a>[line_break_token][line_break_token]The empirical results are mixed.	Review	O	0
Due to the numerous different variations of DSGC for which experiments were conducted, the difference between DSGC and existing methods is probably not statistically significant (a bonferroni correction was not performed to counteract the multiple comparisons).	Review	B-Review	4
[line_break_token][line_break_token]Overall this an interesting paper that introduces a way to incorporate node attribute affinity graphs.	Review	O	0
It is too densely written and could benefit from moving the theoretical parts to an appendix.	Review	B-Review	5
They don't really add much to the core of the paper.	Review	I-Review	5
Moreover, the authors do not consider approaches that also add edges to the graph (based, e.g., on attribute value similarity or during learning, see e.g. [1]) showing that that improves performance even when using a vanilla GCN.	Review	I-Review	5
A comparison to a baseline that simply adds edges based on attribute affinity to the graph and applied a vanilla GCN should be part of the evaluation.	Review	I-Review	5
The empirical results are mixed and don't show a clear advantage of the proposed method.	Review	I-Review	5
[line_break_token]	Review	O	0
hank you for your positive and constructive feedback.	Reply	O	0
[line_break_token][line_break_token]Q1.	Reply	O	0
Comparison with works on learning graph structures such as LDS (<a href="https://arxiv.org/pdf/1903.11960.pdf)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1903.11960.pdf).</a>[line_break_token][line_break_token]&gt;&gt; First of all, we would like to thank the reviewer for pointing out this interesting work.	Reply	O	0
In the revised manuscript, we have included some discussion on this line of research in the 3rd paragraph of section 2.	Reply	B-Reply	5
[line_break_token][line_break_token]We have also conducted experiments on LDS.	Reply	I-Reply	5
Since LDS cannot scale to the size of the 20 Newsgroup dataset (out of GPU Memory) used in our experiments, we follow the authors to test on a 10-category subset of the 20 NG.	Reply	I-Reply	5
We then test LDS on this subset of 20 NG, L-Cora, and Wiki.	Reply	I-Reply	5
For classification on each dataset, LDS uses 20 labels per class for training and extra 20 labels per class for validation (the algorithm requires validation).	Reply	I-Reply	5
Note that we do not use any validation data for the proposed DSGC method for classification.	Reply	I-Reply	5
Due to the differences in datasets and experimental setup, we do not include the results of LDS in Table 1.	Reply	I-Reply	5
[line_break_token][line_break_token]Instead, we report the results of LDS in Table 2 to see whether the proposed DSGC can be used to improve LDS.	Reply	I-Reply	5
We incorporate DSGC into LDS as described in section 5.2 by applying attribute graph convolution on the node features before training.	Reply	I-Reply	5
The results in Table 2 show that DSGC significantly improves LDS on Newsgroup and Wiki and slightly improves LDS on L-Cora.	Reply	I-Reply	5
We have also tested another case of LDS without using the given node affinity graphs of the three datasets and observed similar results.	Reply	I-Reply	5
[line_break_token][line_break_token]The experiments show that DSGC can complement and improve LDS, just as it can complement and improve other SOTA methods based on the regular 1-D graph convolution such as GCN/GAT/GraphSAGE as shown in Table 2.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]Q2.	Reply	O	0
The paper is densely written.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt; As the reviewer suggested, we have reorganized sections 3 and 4 to make them more compact in the revised manuscript.	Reply	O	0
In section 3, we intend to show how the proposed 2-D graph convolution DSGC is derived, which follows a similar path of the development of 1-D GCN (from ‚Äúspectral networks‚Äù to ‚ÄúChebyNet‚Äù to ‚ÄúGCN‚Äù).	Reply	B-Reply	1
In section 4, we want to provide some insights into why DSGC works by analyzing the variance reduction effect of node graph convolution and attribute graph convolution respectively.	Reply	I-Reply	1
[line_break_token][line_break_token]Q3.	Reply	O	0
The empirical results are mixed.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt; We have improved the presentation of the experiments in the revised manuscript.	Reply	O	0
We kindly ask the reviewer to read section 7 about the experiments again.	Reply	B-Reply	4
Our results are statistically significant.	Reply	I-Reply	4
For datasets with good node affinity graphs such as 20 Newsgroup and L-Cora, the proposed 2-D graph convolution DSGC (GXF) significantly outperforms most SOTA methods.	Reply	I-Reply	4
For datasets with bad node affinity graphs such as Wiki, the proposed 2-D graph convolution DSGC (GXF) still outperforms most SOTA methods by a large margin but is less effective than DSGC (XF) (since the node affinity graph G is bad).	Reply	I-Reply	4
DSGC can also be used to significantly improve SOTA methods including GCN, GAT, LDS and GraphSAGE.	Reply	I-Reply	4
Please refer to section 7 in the manuscript for more detailed explanation.	Reply	I-Reply	4
[line_break_token]	Reply	O	0

In this paper, the authors proposed a novel scheme to interpret deep neural networks‚Äô prediction by identifying the most important neurons/activations for each category using a Lasso algorithm.	Review	O	0
[line_break_token][line_break_token]Firstly, the authors produce a 1-dimensional descriptor for each filter in each convolutional layer for each image.	Review	O	0
Then these descriptors are concatenated as a new feature vector for this image.	Review	O	0
A feature selection algorithm (u-Lasso) is then trained to minimize the classification loss between the prediction from the new feature vector and the original prediction from DNN (formula (1)).	Review	O	0
Finally, the importance of each filter is identified by the weights of the lasso for each category.	Review	O	0
[line_break_token][line_break_token]The authors also improved the visual feedback quality over the deconvolution+guided back-propagation methods, and release a new synthetic dataset for benchmarking model explanation.	Review	O	0
[line_break_token][line_break_token]The paper is well-written, however, I have several concerns about this paper:[line_break_token][line_break_token]1.	Review	O	0
     How to verify the importance of the identified relevant features is a problem.	Review	B-Review	1
In the experiments, the authors removed features in the network by setting their corresponding layer/filter to zero.	Review	I-Review	1
The authors only compared their method with randomly removing features.	Review	I-Review	1
And in Fig 4, the differences seem small for ImageNet.	Review	I-Review	1
The results are not convincing enough to me.	Review	I-Review	1
It is a bit baffling randomly removing features did almost as well as the proposed approach.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
     I don't think one should get away with only showing some results from the synthetic dataset without showing any quantitative results on any real datasets.	Review	O	0
I like the idea of having a synthetic dataset where all the parameters are controllable.	Review	B-Review	2
However in this case it is very simple and maybe lacking enough distracting features that can really test the capability of the algorithm.	Review	I-Review	3
I would believe quantitative results on a realistic dataset are still necessary for the pubilcation of this paper.	Review	I-Review	3
[line_break_token][line_break_token]3.	Review	O	0
     Recently several papers pointed out some significant issues in Guided BP, [line_break_token][line_break_token]Xie et al.	Review	O	0
A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations.	Review	B-Review	4
ICML 2018[line_break_token]Adebayo et al.	Review	I-Review	4
Sanity Checks for Saliency Maps.	Review	I-Review	4
NIPS 2018[line_break_token]Kindermans et al.	Review	I-Review	4
The (Un)reliability of saliency methods.	Review	I-Review	4
NIPS workshop 2017[line_break_token][line_break_token]can the authors comment on that?	Review	I-Review	4
Based on those papers I don't seem to think Guided BP is actually doing anything that is relevant to the classification, but is just finding prominent gradients.	Review	I-Review	4
This, unfortunately would lead to reasonably good behavior on the synthetic dataset created by the authors.	Review	I-Review	4
Thanks for the feedback.	Reply	O	0
[line_break_token][line_break_token]Regarding (1), the ablation of features labeled as "random" refers to settings where features were removed by setting to zero the response of randomly selected filters from layers that were indicated to host important features by the u-lasso optimization.	Reply	B-Reply	1
[line_break_token]As such, these features (filter responses) are not 100% random per se.	Reply	I-Reply	1
To verify this aspect, we have conducted an experiment on the full imageNet dataset where we ablated completely randomly selected features  (i.e  both layers and filter locations).	Reply	I-Reply	1
We computed the mean performance after 5 runs and obtained a classification accuracy of 0.33, which is  10% higher than that when the selected relevant features are ablated (0.23).	Reply	I-Reply	1
[line_break_token]In addition, different from the other datasets tested with a VGG-based method, the setting of the full imageNet dataset has the highest ratio between classes of interest and features.	Reply	I-Reply	1
At this higher ratio, features internally modeled by the network are more likely to be shared between the classes.	Reply	I-Reply	1
As such, ablating one feature may have a side effect on another class as well.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Regarding (2), we respectfully disagree.	Reply	I-Reply	2
Our synthetic dataset may look simple and artificial, but that's on purpose to make it clear beyond discussion what elements are crucial to explain a decision.	Reply	I-Reply	2
To the best of our knowledge there isn't any realistic dataset with such annotation and in fact, we have no idea how one would go about to create one.	Reply	I-Reply	2
Nor is there any other unbiased quantitative evaluation setup using realistic data, as far as we know.	Reply	I-Reply	2
For instance, using semantic labels as done in (Zhang et al, CVPR'18 / arXiv:1710.00935¬Ö ignores the validity of any context cues that fall outside of the object boundaries.	Reply	I-Reply	2
In our synthetic dataset, the regions to be highlighted are controlled by design, therefore providing an objective means of evaluation.	Reply	I-Reply	2
If however the reviewer can point us towards a realistic dataset which such level of annotation, we would be happy to try it out, to further strengthen our manuscript.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding the presence of distracting features mentioned in (2), we are conducting experiments on the classification task of Pascal VOC'07.	Reply	I-Reply	3
In this dataset there are several distracting instances/objects per image.	Reply	I-Reply	3
Initial results show that despite the presence of these distracting objects/elements, our method is able to highlight image regions related to the prediction made by the model.	Reply	I-Reply	3
If requested by the reviewers, we will revise the manuscript in order to include some of these new results.	Reply	I-Reply	3
[line_break_token]In addition, adding distracting objects/features could be an interesting way to extend our current synthetic dataset.	Reply	I-Reply	3
We will work towards having an additional variant of our dataset that includes distracting elements for the moment of its official release	Reply	I-Reply	3

[Paper Summary][line_break_token]This paper tackles the problem of learning dynamics of non-rigid objects in a physics simulator.	Review	O	0
This learned dynamics can then be used for planning later.	Review	O	0
The non-rigid objects are represented via a particle-based system.	Review	O	0
The dynamics model is learned using NVIDIA's particle-based simulator "Flex".	Review	O	0
The main idea is to adapt Interaction Networks [Battaglia, 2016] which was earlier proposed for rigid-body simulators to particle-based simulators.	Review	O	0
Instead of maintaining interactions at the level of objects as in [Battaglia, 2016], the proposed approach models interaction at the level of particles.	Review	O	0
[line_break_token][line_break_token][Paper Strengths][line_break_token]The paper is clearly written and tackles an important research problem.	Review	O	0
The existing literature is presented well.	Review	O	0
[line_break_token][line_break_token][Paper Weaknesses][line_break_token]=> The introduction and the text in the first two pages seem to be introducing a new way to model "dynamic" interactions between particles for handling non-rigid transformations.	Review	O	0
However, upon reading the method section, the approach seems to be a direct application of the Interaction Graph Networks (originally applied to the rigid-body simulator) to the particle-based simulator.	Review	B-Review	1
The only difference is that instead of maintaining a fully-connected graph (memory and computational bottleneck), each particle is only connected to the near-by particles within distance d.[line_break_token][line_break_token]=> One of the major issue with the paper is the experimental section of the paper.	Review	O	0
Since the proposed method is quite incremental over the prior work, a strong empirical section is must to justify the approach.	Review	B-Review	2
Here are the comments:[line_break_token]   - Since the proposed approach is an adaptation of [Battaglia, 2016], it should be compared to other existing methods.	Review	I-Review	2
The experiment section in its current state does not compare to any baseline.	Review	I-Review	2
The well-written related work (section-2) talks about (Mrowca et.al.	Review	I-Review	2
2018) and (Schenck and Fox, 2018) as the works which investigate learning dynamics of deformable objects using a particle-based simulator.	Review	I-Review	2
However, no comparison is provided to either of the methods.	Review	I-Review	2
Hence, it is not possible to judge the quality of the presented results.	Review	I-Review	2
[line_break_token][line_break_token]   - All results in Figure-5 or Figure-3 are quite close to each other.	Review	I-Review	2
It is not clear whether the improvement is significant or not since the error bars are not provided at all.	Review	I-Review	2
[line_break_token][line_break_token]   - No ablation is performed to test the sensitivity of the proposed method with respect to the hyper-parameters introduced; for instance, the distance 'd'.	Review	I-Review	2
[line_break_token][line_break_token]=> The name "Dynamic Particle Interaction" is overloaded with terms, especially, the use of word 'dynamic' here just refers to the interaction of particles to model deformable objects.	Review	O	0
This "dynamic" interaction is not "learned" but simply hard-coded by deleting the edges which are farther than d distance apart and adding near ones.	Review	B-Review	3
Something like "Particle-level Interaction Networks" would be a more honest description of the approach.	Review	I-Review	3
[line_break_token][line_break_token][Final Recommendation][line_break_token]I request the authors to address the comments raised above and will decide my final rating based on that.	Review	O	0
With the current set of experiments, the paper doesn't seem to be ready yet.	Review	O	0
Dear Reviewer 1,[line_break_token][line_break_token]Thanks again for your constructive comments.	Reply	O	0
We have made substantial changes in the revision according to your review.	Reply	O	0
In particular, we‚Äôve included detailed comparisons with (Mrowca et al, 2018), ablation studies, and errors bars.	Reply	B-Reply	2
As the discussion period is about to end, please don‚Äôt hesitate to let us know if there are any additional clarifications that we can offer, as we would love to convince you of the merits of the paper.	Reply	O	0
Thanks!	Reply	O	0

The paper is on an improvement of multi-task learning by considering the input tasks at two levels: (1) at task level, i.e. the relationship between the tasks and (2) by the data associated with each task.	Review	O	0
Their major argument is that most current methods hold the assumption that the tasks are correlated with each other but they conjecture that in the real-world this is not necessarily true and try to model the relationship between the input tasks at these two levels and incorporate that in the learning framework.	Review	O	0
To show effectiveness of their approach they test their method on differently oriented public datasets representing graphs, nodes and text and compare performance with some of the recent approaches to multi-task learning.	Review	O	0
[line_break_token][line_break_token]Comments to authors[line_break_token]1.	Review	O	0
Overall while one could get the gist of the arguments in the paper, it was not thoroughly reviewed by the authors for grammar, so it was hard to follow the finer points of the arguments.	Review	B-Review	1
There are several grammatical mistakes and errors, on every page, it'd be too cumbersome to point them all out.	Review	I-Review	1
[line_break_token]2.	Review	O	0
The distinction between the "general task dependency" and the "data dependency" does not seem significant enough.	Review	B-Review	2
The data-dependent task dependency actually depends on the "general task dependency" as stated in the paper.	Review	I-Review	2
This is probably manifested in the relatively slight improvement of the method compared with the SOTA.	Review	I-Review	2
Perhaps more clarity on the difference and contribution of each "level" would make the significance stand out  clearer.	Review	I-Review	2
hank you for your constructive comments.	Reply	O	0
We address your questions as follows.	Reply	O	0
[line_break_token][line_break_token]Q1: ‚ÄúIt was not thoroughly reviewed by the authors for grammar.	Reply	O	0
‚Äù[line_break_token][line_break_token]R1: We apologize for the grammar mistakes.	Reply	O	0
We have carefully revised the paper and also re-scrutinized to improve the language.	Reply	B-Reply	1
[line_break_token][line_break_token]Q2: ‚ÄúPerhaps more clarity on the difference and contribution of each "level" would make the significance stand out clearer.	Reply	O	0
‚Äù[line_break_token][line_break_token]R2: The motivation for the multi-level task dependency is the hierarchical structure in text and graph data (i.e. word -&gt; sentence and node -&gt; graph).	Reply	O	0
The task dependency at word/node level may be different from the general task dependency.	Reply	B-Reply	2
[line_break_token][line_break_token]Take sentence classification as an example, besides the general relationship between sentiment analysis tasks and discourse relation identification tasks, words like ‚Äúgood‚Äù or ‚Äúbad‚Äù may transfer more knowledge from sentiment analysis tasks, while words like ‚Äúbecause‚Äù and ‚Äúso‚Äù may transfer more from discourse relation identification tasks.	Reply	I-Reply	2
[line_break_token][line_break_token]Previous work [1] can only capture the general task dependency but does not utilize the inner hierarchical structure of ‚Äúdiscrete‚Äù data (text and graph).	Reply	I-Reply	2
An extreme case would be each word/node has the same task dependency, in which our model will perform as well as [1].[line_break_token][line_break_token][line_break_token][1] Taskonomy: Disentangling Task Transfer Learning, 201	Reply	O	0

*Summary.*	Review	O	0
The paper presents and addresses the problem of performing domain adaptation when the target domain is systematically (i.e., not the result of a stochastic process) missing subsets of the data.	Review	O	0
The issue is motivated by applications where one modality of data becomes unavailable in the target domain (e.g., when deciding which ads to serve to new users, the predictor may have access to behavior across other websites but not on a specific merchant's website).	Review	O	0
The proposed method learns to map source and target data to a latent space where the representations for the source and target are aligned, the missing components of the target can be inferred, and classification can be performed successfully.	Review	O	0
These are achieved by adversarial/optimal transport loss on source and target features, a mean-squared error and adversarial loss on latent generation/imputation, and a cross entropy loss on source label prediction, respectively.	Review	O	0
Experiments are performed on digits and click-through rate (CTR) prediction and include a thorough set of baselines/oracles for comparison.	Review	O	0
[line_break_token][line_break_token]*Review.*	Review	O	0
While the problem statement is novel, I am unconvinced that the advertising experiment includes both a domain adaptation and imputation problem.	Review	O	0
I describe this in detail below.	Review	B-Review	1
For this reason, I am giving the paper a weak reject.	Review	I-Review	1
[line_break_token][line_break_token]*Questions that impacted rating.*	Review	I-Review	1
[line_break_token]1.	Review	I-Review	1
Ads experiment: From my understanding, the source domain is the traffic of users who have interacted with (clicked through to?)	Review	I-Review	1
a specific partner and the target domain is the traffic of the users who have not interacted with that specific partner.	Review	I-Review	1
The data that needs to be imputed is the click through rate for target users with that specific partner.	Review	I-Review	1
In this case, it is not obvious to me why there is a domain shift between these two groups of users.	Review	I-Review	1
This would imply that the traffic of source users and target users is different for other partners.	Review	I-Review	1
I don't see why this would need to be true.	Review	I-Review	1
Could the authors provide an explanation as to why this is the case (e.g., by showing that CTRs differ with other (partner, publisher) pairs between source and target).	Review	I-Review	1
From my understanding, Table 5 only shows CTR averaged across all users in each domain, but does not show that the CTRs differ between source and target users for contexts/(partner, publisher) pairs (i.e., the results in table 5 could be due to the fact that the prior distribution over context is different for source and target users).	Review	I-Review	1
[line_break_token][line_break_token]*Additional notes.	Review	O	0
Immaterial to rating.*	Review	O	0
[line_break_token]1.	Review	B-Review	1
I personally felt that the motivation for UDA vs imputation in the first paragraph was a bit muddled.	Review	I-Review	2
I think sticking to one example would make the motivation more clear to the reader.	Review	I-Review	2
E.g., explain the prediction problem for medical imaging (which I assume is disease diagnosis, but it is not stated explicitly), describe how some medical imaging may be missing for certain patients (imputation), then explain that there may be noise across different medical imaging systems (UDA), then list the other applications where this arises with citations (e.g., These phenomena have also been documented in advertising applications [1], ...).	Review	I-Review	2
[line_break_token]2.	Review	O	0
I was surprised by the difference between Adaptation-Partial and the other two train/test conditions in Figure 2 when p=30%.	Review	B-Review	3
Out of curiosity, do the authors have an explanation for this discrepancy?	Review	I-Review	3
I would have predicted that, if most of the information necessary for prediction was available in the remaining 70% of the image that the performance of these cases would be very similar.	Review	I-Review	3
 I think it would be helpful to see the accuracy on the source domain and the labeled target domain to better understand that result.	Review	I-Review	3
hanks a lot for your feedback and your recommendations.	Reply	O	0
We provide below a detailed response.	Reply	O	0
[line_break_token][line_break_token]A) Joint domain shift and missing data hypothesis for the ads experiments: [line_break_token]    [line_break_token]We do agree that this is not obvious.	Reply	O	0
As mentioned in the paper, the ads problem was our initial motivation for this work and our formulation of the problem comes from preliminary exploratory data analyses performed on ads datasets.	Reply	B-Reply	1
We have added in Appendix E in the new paper version, distribution plots (Figure 6) and mean values (Table 6) for the different observed features used in the ads-kaggle dataset for the source and target domains.	Reply	I-Reply	1
This shows that there is indeed a domain shift between the two domains.	Reply	I-Reply	1
The same conclusion holds for the ads-real dataset.	Reply	I-Reply	1
More details are provided below.	Reply	I-Reply	1
[line_break_token]    [line_break_token]Your description of the problem in the detailed comments (*Questions that impacted rating.*)	Reply	I-Reply	1
is basically right.	Reply	I-Reply	1
We figured out however that we might not have been precise enough in the text and we provide below more details clarifying the experimental setting.	Reply	I-Reply	1
[line_break_token][line_break_token]The source dataset is composed of all user-partner pairs for which the user visited the partner and the target dataset is composed of all the user-partner pairs for which the user never visited this partner.	Reply	I-Reply	1
A key point here is that there are several partners (and of course users) per domain, and this was probably not clear enough from the text.	Reply	I-Reply	1
Typically we could expect thousands of partners depending on the size of an ads company's partner portfolio.	Reply	I-Reply	1
For the source domain, we have available complete data (mean statistics on all visited partners + traces on a specific ad partner for a user-partner pair) and for the target domain only partial data (mean statistics but no partner specific traces for a user-partner pair).	Reply	I-Reply	1
[line_break_token]Regarding domain shift, in Figure 6 Appendix E, we plot the normalized feature distributions for the source (blue plots) and target (red plots) domains.	Reply	I-Reply	1
While some features have a similar distribution for the source and target domains, many have completely different distributions indicating a clear domain shift.	Reply	I-Reply	1
This is synthesized in Table 6 Appendix E, giving the mean values for all the features for the two domains.	Reply	I-Reply	1
We notice that feature 5 is missing on the target.	Reply	I-Reply	1
[line_break_token][line_break_token]This shift was initially a surprising finding for us too.	Reply	I-Reply	1
Our hypothesis is that the source domain includes users with a higher overall activity both for visiting partner websites and for interacting with the websites.	Reply	I-Reply	1
Target domain includes users that are probably less active.	Reply	I-Reply	1
This is confirmed by the mean value of the features in the two domains in Table 6 Appendix E: feature distributions from users in the source domain tend to have higher mean values than features in the target domain.	Reply	I-Reply	1
These features typically measure click, visit and sale activities which is consistent with the above hypothesis	Reply	I-Reply	1

Summary:[line_break_token][line_break_token]This paper introduces the use of asymptotic constraints to find[line_break_token]prune the search space of mathematical expressions for symbolic[line_break_token]regression.	Review	O	0
 This is done by training a neural network to[line_break_token]generate production rules conditioned on being given the[line_break_token]asymptotic constraints and previously generated production[line_break_token]rules.	Review	O	0
This neural network is then itself also used to guide a[line_break_token]MCTS to generate mathematical expressions.	Review	O	0
[line_break_token][line_break_token]The algorithms is compared against a reasonable set of baselines[line_break_token]and related algorithms.	Review	O	0
[line_break_token][line_break_token]Feedback:[line_break_token][line_break_token]This is a very clear and well-written paper.	Review	O	0
It was[line_break_token]straightforward to understand and very easy to see how it fits in[line_break_token]with the broader literature.	Review	O	0
The insight about using asymptotic[line_break_token]constraints makes the result a bit limited to only generating[line_break_token]mathematical expressions, and it would have been a bit nicer if[line_break_token]there was something more generically applicable to program[line_break_token]synthesis in general.	Review	B-Review	1
It's not really clear to me how the[line_break_token]existing work extends to programs.	Review	I-Review	1
[line_break_token][line_break_token]The evaluation was very thorough and the appropriate algorithms[line_break_token]were compared against the work.	Review	O	0
I came away with a good[line_break_token]understanding of how well the model generalizes to larger[line_break_token]expressions compared to existing work.	Review	O	0
[line_break_token][line_break_token]Minor notes:[line_break_token][line_break_token]The abstract is a bit inaccurate as the NN generates production rules[line_break_token]and not expressions.	Review	O	0
hank you for your encouraging comments and constructive feedback.	Reply	O	0
[line_break_token][line_break_token]We presented a general two-step framework of first learning a generative model of production rules in a grammar and then using that model to guide MCTS for efficient search.	Reply	B-Reply	1
We acknowledge that we evaluated this framework in the context of symbolic regression and focused on the leading power properties.	Reply	I-Reply	1
However, we believe our framework and similar modeling ideas could be equally useful in general program synthesis settings, where other properties such as program‚Äôs desired time complexity or maximum control flow nesting could be used to condition the generative model.	Reply	I-Reply	1
We hope to explore such directions in future, but we will add more discussion about the generality of our approach.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that the naming of the neural network component is confusing.	Reply	I-Reply	2
We have changed the name to "conditional production rule generating neural network" everywhere and clarified it in the paper, including in the abstract	Reply	I-Reply	2

Strengths[line_break_token]ÔÅÆ-- An interesting proposal for a smaller CNN architecture designed for embedded CNN applications.	Review	O	0
[line_break_token]ÔÅÆ-- Balanced exploration of CNN macroarchitecture and microarchitecture with fire modules.	Review	O	0
[line_break_token]ÔÅÆ-- x50 less memory usage than AlexNet, keeping similar accuracy [line_break_token]ÔÅÆ-- strong experimental results[line_break_token][line_break_token]Weaknesses[line_break_token]ÔÅÆ--Would be nice to test Sqeezenet on multiple tasks[line_break_token][line_break_token]ÔÅÆ--lack of insights and rigorous analysis into what factors are responsible for the success of SqueezeNet.	Review	O	0
For example, how are ResNet and GoogleNet connected to the current architecture?	Review	B-Review	2
Another old paper (Analysis of correlation structure for a neural predictive model with application to speech recognition, Neural Networks, 1994) also showed that the ‚Äúby-pass‚Äù architecture by mixing linear and nonlinear prediction terms improves long term dependency in NN based on rigorous perturbation analysis.	Review	I-Review	2
Can the current work be placed more rigorously on theoretical analysis?	Review	I-Review	2
[line_break_token]	Review	O	0
Thank you for your feedback and encouragement.	Reply	O	0
Let me take a moment to discuss the weaknesses/questions that you mentioned.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
SqueezeNet on other tasks.	Reply	O	0
[line_break_token]We recently added a detection layer at the end of SqueezeNet and fine-tuned it on KITTI object detection.	Reply	B-Reply	1
We identified a variant of SqueezeNet that is simultaneously the fastest, smallest, and most accurate (in terms of mean-average precision) model on the KITTI detection task, compared to previous reported results.	Reply	I-Reply	1
We will be posting this to the KITTI leaderboard soon, but meanwhile we have released some details in this paper:[line_break_token]<a href="https://arxiv.org/abs/1612.01051" target="_blank" rel="nofollow">https://arxiv.org/abs/1612.01051</a>[line_break_token][line_break_token]2.	Reply	O	0
Theoretical analysis.	Reply	O	0
[line_break_token]We certainly appreciate the theoretical aspects of deep neural network research.	Reply	B-Reply	2
If you ask a more specific question, we will do our best to answer it.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Placing SqueezeNet in the context of GoogLeNet and ResNet.	Reply	O	0
[line_break_token]Take a look at our response to the earlier comment thread, "SqueezeNet versus other models than AlexNet."	Reply	B-Reply	2
[line_break_token][line_break_token]	Reply	O	0

  *Synopsis*:[line_break_token]  This paper focuses on current limitations of deploying RL approaches onto real world robotic systems.	Review	O	0
They focus on three main points: the need to use raw sensory data collected by the robot, the difficulty of handcrafted reward functions without external feedback, the lack of algorithms which are robust outside of episodic learning.	Review	O	0
They propose a complete system which addresses these concerns, combining approaches from the literature and novel improvements.	Review	O	0
They then provide an empirical evaluation and ablation testing of their approach and other popular systems, and show a demonstration on a real robotic system.	Review	O	0
[line_break_token] [line_break_token]  Main Contributions:[line_break_token]  - A discussion of the current limitations of RL on real robotic systems[line_break_token]  - A framework for doing real world robotic RL without extra instrumentation (outside of the robot).	Review	O	0
[line_break_token][line_break_token]  *Review*: [line_break_token]  Overall, I think the paper is well written and provides some nice analysis of the current state of RL and robotics.	Review	O	0
I am not as familiar with the RL for robotics literature, but from some minor snooping around I believe these ideas to be novel and useful for the community.	Review	O	0
I have a few suggestions for the authors, and a few critical pieces I would like added to the main text.	Review	O	0
[line_break_token][line_break_token]  Critical additions:[line_break_token]  1.	Review	O	0
I would like some more details on your simulation experiments.	Review	B-Review	3
Specifically:[line_break_token]    - How many runs were your experiments?	Review	I-Review	3
[line_break_token]    - What are the error bars on your plots?	Review	O	0
[line_break_token]    - What ranges of hyper-parameters did you test for tuning?	Review	O	0
[line_break_token][line_break_token]  2.	Review	O	0
I would quite like the discussion of the real world tasks from the appendix to appear in the main text.	Review	B-Review	1
Specifically, giving the evaluation metrics you mentioned in the appendix.	Review	I-Review	1
[line_break_token][line_break_token]  Suggestions/Questions:[line_break_token][line_break_token]  S1: It is not clear if a VAE is the best choice for unsupervised representation learning for RL agents.	Review	O	0
Although a reasonable choice, Yashua Bengio recently released a look at several unsupervised techniques for representation learning in Atari which you may want to look at: <a href="https://arxiv.org/pdf/1906.08226.pdf."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/pdf/1906.08226.pdf.</a> [line_break_token][line_break_token]  Q1: Did you try any of the other approaches on the real robotics system?	Review	O	0
Or was there no way to deploy these algorithms to your specific setup without instrumentation?	Review	B-Review	4
e thank the reviewer for their insightful and constructive feedback!	Reply	O	0
We have run additional hardware comparisons and quantitative evaluations as requested (Section 6.3) and have updated the paper according to your suggestions and comments to better discuss related work.	Reply	B-Reply	1
We respond to individual concerns in detail below:[line_break_token][line_break_token]‚Äúdiscussion of the real world tasks from the appendix to appear in the main text.	Reply	O	0
‚Äù[line_break_token]-&gt; We have moved this discussion from the Appendix to Section 6.3.	Reply	O	0
Additional comparisons to a VICE (Fu et al) baseline have been added for real world experiments in Section 6.3, Fig 8.	Reply	B-Reply	1
We see that our algorithm is able to outperform this baseline on the real world tasks.	Reply	I-Reply	1
[line_break_token][line_break_token]‚ÄúIt is not clear if a VAE is the best choice for unsupervised representation learning for RL agents.	Reply	O	0
‚Äú[line_break_token]-&gt; While a VAE works well in the domains we considered in this paper, we certainly agree that a VAE is not necessarily the optimal choice for all RL domains.	Reply	O	0
We have updated Section 4.2 to reflect this explicitly, and have included references to Anand et al, Hjelm et al.	Reply	B-Reply	2
and Lee et al as you pointed out as alternative methods for representation learning.	Reply	I-Reply	2
We did not mean to claim that VAE‚Äôs were the only representation learning scheme that might suffice in this scenario, and many of the schemes suggested might also be effective.	Reply	I-Reply	2
[line_break_token][line_break_token]‚ÄúI would like some more details on your simulation experiments‚Ä¶‚Äù[line_break_token]-&gt; We have updated Section 6 and Appendix C to include details about the experimental setup, both in simulation and in the real world.	Reply	O	0
We have updated Fig 7 after removing a small visual artifact in the environment, which allows the baselines to perform a bit better, but still maintains the same trends.	Reply	B-Reply	3
[line_break_token]-- The plots are averaged over 5 random seeds for each method and task [line_break_token]-- The (shaded) error regions correspond to the variance of the seeds for each curve[line_break_token]-- Appendix B has been updated to include information on ranges of hyperparameters tuned, in addition to the optimal values used to generate the plots in figures 7 &amp; 8[line_break_token][line_break_token]‚ÄúQ1: Did you try any of the other approaches on the real robotics system?	Reply	O	0
Or was there no way to deploy these algorithms to your specific setup without instrumentation?‚Äù[line_break_token]-&gt; Yes we did add a new real-world comparison to the VICE baseline, as requested, in Fig 8.	Reply	O	0
We have updated Section 6.3 with a comparison in the real world on the valve rotation and bead manipulation tasks.	Reply	B-Reply	4
A quantitative evaluation corroborates findings from the simulated environments and shows that our method outperforms these methods in terms of sample efficiency and robustness.	Reply	I-Reply	4

This paper focuses on transmitting messages reliably by learning joint coding with the bandwidth-limited channel.	Review	O	0
The authors justify joint systems outperform their separate counterparts when coding is performed by flexible learnable function approximators.	Review	O	0
Their experiments show the advantage of their design decisions via improved distoration and FID scores.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]1.	Review	O	0
This paper is clearly written and well-structured in logic.	Review	O	0
For example, the authors use Figures 1 and 2 assist readers to catch the difference between joint communication system and separate communication system.	Review	O	0
[line_break_token][line_break_token]2.	Review	B-Review	1
This paper gives a reliazation of joint source-channel coding, especially to give auxilary latent variable decoders.	Review	O	0
[line_break_token][line_break_token]3.	Review	O	0
This paper has been verified in both Gaussian channel and bandwidth-limited channel.	Review	O	0
The empirical results show the advantage of joint coding.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]1.	Review	O	0
Intuitively, you Section 4.3 should be better than Section 4.2.	Review	B-Review	1
However, I don't see any difference or major items to justify this kind of benefits.	Review	I-Review	1
Could you please explain why techniques in Section 4.3 can outperform these in Section 4.2.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	1
Although the authors verified their work on CelebA, it seems that the proposed method has very limited applications.	Review	I-Review	2
If possible, the authors should do more datasets to verify their proposed method, which will be more useful to boarder readers.	Review	I-Review	2
hank you for your review.	Reply	O	0
In the following, we would like to address both of your questions.	Reply	O	0
[line_break_token][line_break_token]Question 1: Why does joint coding outperform separate coding specifically in the ML setting?	Reply	O	0
[line_break_token][line_break_token]This is indeed very interesting and has sparked various discussions among ourselves as well.	Reply	B-Reply	1
[line_break_token]There is of course classical research that illuminates why solving the joint problem may be possible in some scenarios where solving the communication problem separately is not possible (under more realistic assumptions).	Reply	I-Reply	1
[line_break_token][line_break_token]More specifically, in the ML context when separate coding is performed, it is understood that the channel coder receives the distribution of source embeddings.	Reply	I-Reply	1
However, to be source agnostic, this distribution needs to be a generic (i.e. source data independent) distribution.	Reply	I-Reply	1
For example, this could be a standard Gaussian as is used in a basic VAE.	Reply	I-Reply	1
This, however, induces a bottleneck: The source coder needs to match the aforementioned generic prior distribution such that the channel coder receives the correct input.	Reply	I-Reply	1
At the same time, if the source coder was to perfectly match this prior, there would be no mutual information I(source data; source embedding), and thus nothing would be learned.	Reply	I-Reply	1
Joint coding does not suffer from this trade-off problem.	Reply	I-Reply	1
We believe this is why it outperforms separate coding in our experiments.	Reply	I-Reply	1
[line_break_token][line_break_token]Questions 2a:  Relevance of the bandwidth-limited channel.	Reply	O	0
[line_break_token][line_break_token]We hope in our main rebuttal we could point out why modelling with the bandwidth limited channel has such a central role in modelling communication, and why introducing learning to coding is a relevant contribution.	Reply	B-Reply	2
[line_break_token][line_break_token]Question 2b: How does our approach extend to other domains (non-vision)?	Reply	O	0
[line_break_token][line_break_token]Concerning the dataset we used, we are currently running an experiment on imagenet to diversify our claim.	Reply	B-Reply	2
[line_break_token]We do believe, however, that our findings extend far beyond image datasets to video, language, audio and even beyond perceptual tasks.	Reply	I-Reply	2
We believe that there is evidence that the architecture of the neural encoders and decoders that are employed will determine the success in these domain.	Reply	I-Reply	2
Domain specific architectures are, however, not the focus of this work.	Reply	I-Reply	2
Farsad et al. (	Reply	I-Reply	2
2018) for example considers a language application.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]We thank the reviewer for any further feedback and are happy to discuss more if desired.	Reply	O	0

The paper proposes a technique to perform reasoning on mathematical formulas in a latent space.	Review	O	0
The model is trained to predict whether a rewrite rule can be applied to a formula given its latent representation.	Review	O	0
When the rewrite is possible, the model also predicts the embedding of the resulting formula.	Review	O	0
Experiments show that the network can be applied multiple steps in a row, while operating only in the embedding space.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
As mentioned in the paragraph before Section 4.1, it would be much simpler to consider a single latent embedding space L. In that case, \sigma and \alpha become unnecessary and we only need to train \omega.	Review	B-Review	1
Did you try to have a single network?	Review	I-Review	1
This seems a much more natural approach to me, and I'm surprised that you did not start with that.	Review	I-Review	1
From my experience, aligning embedding spaces is something that usually does not work very well, especially in high dimension.	Review	I-Review	1
The role of \sigma seems very redundant given \omega.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
If you consider \sigma, why do you also predict the rewrite success with \omega?	Review	B-Review	2
Couldn't it be simply a function from S x S -&gt; L ?	Review	O	0
[line_break_token][line_break_token]3.	Review	O	0
The graph neural networks used in the model are not described in the paper, only a reference to Paliwal et al (2019) is given.	Review	B-Review	3
It would be helpful to have a brief paragraph describing this architecture, for readers not familiar with the referenced paper.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	I-Review	1
How large is the training set of (T, P) pairs?	Review	I-Review	4
I don't think this is mentioned in the paper.	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	O	0
To train \sigma and \omega, the negative instances are selected randomly.	Review	B-Review	5
You mention that negative mining should improve over this strategy.	Review	I-Review	5
What does negative mining correspond to in this context?	Review	I-Review	5
Are there bad rewrites better than others?	Review	I-Review	5
[line_break_token][line_break_token]6.	Review	O	0
Did you consider using an inverse function (say G), that maps an embedding in L / L' back to S (i.e. the inverse function of gamma / gamma').	Review	B-Review	6
I would imagine that even if an embedding X is a bit noisy, because not exactly equal to gamma(P) where P is the expression it represents, you could consider doing the propagation with gamma(G(X)).	Review	I-Review	6
This could be a possibility to remove the noise you have when doing multi-step operations (and potentially go way beyond 4 steps).	Review	I-Review	6
Also, G could be used to check whether you obtain the expected formula after 4 steps, which would be a more informative information than the L2 distance between the resulting embedding and the embedding of the final formula.	Review	I-Review	6
[line_break_token][line_break_token]Overall, the model is a bit complicated (e.g. question 1.),	Review	O	0
but the results are promising, the paper is well written, and the ability to manipulate formula embeddings is probably going to be useful in the context of theorem proving.	Review	O	0
e thank the reviewer for the constructive feedback.	Reply	O	0
The use of a fixed embedding space and a separate space was useful as it naturally prevents the collapse of embeddings.	Reply	B-Reply	1
However this could be counteracted by stopping the gradient at the right place in the simplified architecture  which was suggested in the original paper and is now described in the updated paper.	Reply	I-Reply	1
[line_break_token][line_break_token]As suggested, we have added further analysis of failure cases, and describe strategies for negative mining from these examples.	Reply	I-Reply	3
In addition, we have included a brief description of the graph neural network architecture used in Paliwal et al (2019).	Reply	I-Reply	3
We also include further details on the construction of training set.	Reply	I-Reply	3
 [line_break_token][line_break_token]Training a decoder to predict the results of rewrites from the latent space is an interesting idea, but is technically challenging and we felt it was out of scope for this paper.	Reply	O	0
We managed to counteract the noisiness of predicted embedding by training on noisy embeddings which trains the network to be robust to random changes and improves the prediction of multi-step rewrites significantly.	Reply	B-Reply	5
[line_break_token][line_break_token]We are grateful for the suggestions that contributed significantly to improving the quality of the paper	Reply	O	0

Summary:[line_break_token]The paper proposes a method for coordinating the exploration efforts of agents in a multi-agent reinforcement learning setting.	Review	O	0
The approach has two main components: (i) learning different exploration policies using different "joint" intrinsic rewards; and (ii) learning a higher-level policy that selects one of the exploration policies to be executed at the beginning of each episode.	Review	O	0
[line_break_token][line_break_token]Each agent has its own novelty function which quantifies the novelty of observation seen by that agent.	Review	O	0
To coordinate exploration, these novelty functions are combined using aggregation functions to produce intrinsic reward for the agent.	Review	O	0
Each such aggregating function yields a different intrinsic reward.	Review	O	0
The authors propose several such aggregating functions as examples, however the method is applicable to other aggregating functions as well, as long as they can be computed off-policy.	Review	O	0
[line_break_token][line_break_token]During training, the higher level policy selects one of the exploration policies which is then executed for the entire episode.	Review	O	0
The episode data is used in two ways: (i) to train the higher-level policy using policy gradients for maximizing extrinsic rewards along with an entropy term; and (ii) to train each exploration policy using soft actor-critic on its own intrinsic reward function (and extrinsic reward) in an off-policy manner.	Review	O	0
[line_break_token][line_break_token]Experiments done on grid-world and VizDoom environment for three different tasks demonstrate that, on most tasks, the proposed approach performs at least as well as separately trained individual intrinsic rewards.	Review	O	0
Further ablation studies confirm that both the hierarchical setup and the "joint" intrinsic rewards are useful.	Review	O	0
[line_break_token][line_break_token][line_break_token]Questions to the Authors:[line_break_token][line_break_token]1.	Review	O	0
The second sentence in section 5 is not clear - "Furthermore, the type of reward ... sufficiently complex".	Review	B-Review	1
The high-level policy selects an exploration strategy at the beginning of each episode and then sticks to it for the entire duration of the episode.	Review	I-Review	1
Changing the exploration strategy over the course of training might be useful in cases when agent needs to switch to a different exploration strategy after reaching a particular bottleneck state.	Review	I-Review	1
However, this would require the exploration strategy to be changed in the middle of an episode which is not supported.	Review	I-Review	1
Could you give an example where the exploration strategy must be changed over time even if one only selects the strategy at the beginning of each episode?	Review	I-Review	1
Also, why not select the exploration strategy after every fixed number of time steps within each episode (by making high-level policy a function of the current state)?	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Analyzing the role of high-level policy and its evolution over time on different tasks would be a very nice addition to the paper.	Review	B-Review	2
Qualitative experiments demonstrating that it provides a curriculum which helps the agents in surpassing the performance of individual intrinsic rewards would be helpful.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Should \Pi in (10) also depend on i?	Review	B-Review	3
[line_break_token][line_break_token]Though paper is reasonably well written I find the contributions are very marginal.	Review	I-Review	4
If authors can position the paper well with the existing literature and bring out the impact of the contributions it will be helpful.	Review	I-Review	4
[line_break_token]	Review	O	0
hank you for the detailed and insightful comments.	Reply	O	0
To address your first point, we can provide an illustrative example.	Reply	B-Reply	1
Let us say that we are attempting to solve task 1, where agents must spread out and collect all rewards on the map.	Reply	I-Reply	1
In this case it is possible that Leader-Follower rewards may be most successful at first since they all explore similar areas simultaneously, so if they happen to reach a region where a reward is located, there will be multiple agents there to have a chance at collecting it; however, this behavior is not optimal, as there are other rewards to collect around the map.	Reply	I-Reply	1
At this point in training, burrowing rewards may become more optimal since at least one of the agents will continue exploring the same region to collect the reward, but the other agents will explore other regions, potentially collecting more rewards.	Reply	I-Reply	1
We find that this type of situation occurs with reasonable frequency during training.	Reply	I-Reply	1
Re-selecting the exploration strategy within each episode may be useful for tasks with multi-stage goals, though we don‚Äôt consider these types of tasks in this work.	Reply	I-Reply	1
[line_break_token][line_break_token][tab_token]We have analyzed the role of the policy selector and have found some interesting behaviors.	Reply	O	0
We refer the reviewer to the revised Appendix (section A.6) for a discussion on this analysis.	Reply	B-Reply	2
Finally, the \Pi in equation 10 (i.e. the policy selector) does not depend on i, as all agents roll out their policies trained on the same intrinsic reward simultaneously.	Reply	I-Reply	2
In other words, there is no mixing of different policy types.	Reply	I-Reply	2
[line_break_token][line_break_token][tab_token]With respect to the position of our work within the literature, we believe we are the first work to address the problem of spatially coordinated exploration in deep multi-agent reinforcement learning.	Reply	O	0
Many multi-agent tasks require some notion of spatial coordination for optimal performance (e.g. search-and-rescue), and our method induces such coordination in exploration with decentralized agents, enabling success in these types of tasks with sparse rewards.	Reply	B-Reply	4
We show that naive applications of single-agent methods (Figure 3b independent and centralized intrinsic rewards) to multi-agent systems are relatively ineffective when compared to our approach.	Reply	I-Reply	4

The paper tackles the task of music generation.	Review	O	0
They use an orderless NADE model for the task of "fill in the notes".	Review	O	0
Given a roll of T timesteps of pitches, they randomly mask out some pitches, and the model is trained to predict the missing notes.	Review	O	0
This follows how the orderless NADE model can be trained.	Review	O	0
During sampling, one normally follows an ancestral sampling procedure.	Review	O	0
For this, an ordering is defined over outputs, and one runs the model on the current input, samples one of the outputs according to the order, adds this output to the next input, and continues this procedure until all outputs have been sampled.	Review	O	0
The key point of the paper is that this is a bad sampling strategy.	Review	O	0
Instead, they suggest the strategy of Yao et al.	Review	O	0
2014, which uses a blocked Gibbs sampling approach.	Review	O	0
The blocked Gibbs strategy instead masks N inputs randomly and independently, samples them, and repeats this procedure.	Review	O	0
The point of this strategy is the make sure the sampling chain mixes well, which will happen for large N. However, since the samples are independent, having a large N gives incoherent samples.	Review	O	0
Thus, the authors follow an annealed schedule for N, making it smaller over time, which will eventually reduce to ancestral sampling (giving global structure to the sample).	Review	O	0
They conduct a variety of experiments involving both normal metrics and human evaluations, and find that this blocked Gibbs sampling outperforms other sampling procedures.	Review	O	0
[line_break_token][line_break_token]This is a well written paper - great job.	Review	O	0
[line_break_token][line_break_token]My main problem with the paper is that having read Uria and Yao, I don't know how much I have learned from this work in the context of this being an ICLR submission.	Review	O	0
If this was submitted to some computational music / art conference, this paper would be a clear accept.	Review	O	0
However, for ICLR, I don't see enough novelty compared with previous works this builds upon.	Review	O	0
Orderless NADE is an established model.	Review	O	0
The blocked Gibbs sampling and annealing scheme are basically the exact same one used in Yao.	Review	O	0
Thus, the main novelty of this paper is its application to the music domain, and finding that Yao's method works better for sampling music.	Review	O	0
This is a good contribution, but more tailored to those working in the music domain.	Review	O	0
If the authors found that these results also hold for other domains like images (e.g. on CIFAR / tiny Imagenet) and text (e.g. document generation), then I would change my mind and accept this paper for ICLR.	Review	O	0
Even just trying musical domains other than Bach chorales would be useful.	Review	O	0
However, as it stands, the experiments are not convincing enough.	Review	O	0
Thank you for your review.	Reply	O	0
 We respond to your question above.	Reply	O	0

This paper proposes a Frank-Wolfe based method, called DFW, for training Deep Network.	Review	O	0
The DFW method linearizes the loss function into a smooth one, and also adopts Nesterov Momentum to accelerate the training.	Review	B-Review	1
Both techniques have been widely used in the literature for similar settings.	Review	I-Review	2
This paper mainly focuses on the algorithm part, but only empirically demonstrate the convergence results.	Review	I-Review	3
[line_break_token][line_break_token]After reading the authors‚Äô feedback and the paper again, I think overall this is a good paper and should be of broader interest to the broader audience in machine learning community.	Review	O	0
[line_break_token][line_break_token]In Section 6.1, the authors mention the good generalization is due to large number of steps at a high learning rate.	Review	B-Review	4
Can we possibly get any theoretical justification on this?	Review	I-Review	4
[line_break_token][line_break_token]This paper uses multi class hinge loss as an example for illustration.	Review	I-Review	5
Can this approach be applied for structure prediction, for example, various ranking loss?	Review	I-Review	5
We thank the reviewer for their comments.	Reply	O	0
We provide answers below:[line_break_token][line_break_token]* ‚ÄúThe DFW linearizes the loss function into a smooth one, and also adopts Nesterov momentum to accelerate the training.	Reply	O	0
‚Äù [line_break_token]We would like to clarify this statement: one of the key ideas of the DFW algorithm is not to linearize the loss function, but only the model.	Reply	O	0
[line_break_token][line_break_token]* ‚ÄúBoth techniques have been widely used in the literature for similar settings‚Äù.	Reply	O	0
[line_break_token]We wish to clarify the main technical contributions of this paper, since the SVM smoothing and the application of Nesterov acceleration are not the main novelty of this work.	Reply	B-Reply	2
We discuss the summary of contributions (available at the end of section 1 of the paper) in the context of technical novelty.	Reply	I-Reply	2
[line_break_token]- Employing a composite framework allows us to use an efficient primal-dual algorithm.	Reply	O	0
As stated by Reviewer 1, this is novel in the context of deep neural networks: ‚ÄúTo my knowledge, the submission is the first sound attempt to adapt this type of Dual-based algorithm for optimization of Deep Neural Network [..]‚Äù.	Reply	B-Reply	2
[line_break_token]- Crucially, our approach yields an update at the same computational cost per iteration as SGD and with the same level of parallelization.	Reply	O	0
In contrast, in the closest approach to ours, the algorithm of Singh & Shawe-Taylor (2018) can only process a single sample at a time.	Reply	O	0
This results in an approach whose runtime is virtually multiplied by the batch-size (it would be slower by two orders of magnitude in typical classification settings, including for the experiments of this paper).	Reply	B-Reply	2
[line_break_token]- We do not mean to claim that the application of Nesterov acceleration is a technical novelty in itself.	Reply	O	0
However, its use is subtle in our case (see appendix A.7) and it is empirically crucial for good performance, hence its mention in the paper.	Reply	B-Reply	2
[line_break_token]- To the best of our knowledge, the hyper-parameter free smoothing approach that we propose in this work is novel (but is not the main contribution).	Reply	O	0
[line_break_token][line_break_token]We have adapted the abstract and summary of contributions to focus on the main novelty, which is an optimization algorithm for deep neural networks with an optimal step-size at the same computational cost per iteration as SGD.	Reply	B-Reply	2
[line_break_token][line_break_token]If the reviewer remains concerned by a lack of novelty, we would be grateful if he/she could provide specific references so that we can compare them in detail with the DFW algorithm.	Reply	O	0

The paper states that basic transformation (translation and rotation) can easily fool a neural network in image classification tasks.	Review	O	0
Thus, image classification models are actually more vulnerable than people thought.	Review	O	0
The message conveyed by the paper is clear and easy to get.	Review	O	0
The experiments are natural and interesting.	Review	O	0
Some interesting points:[line_break_token]  --The model trained with data augmentation that covers the attack space does not alleviate the problem sufficiently.	Review	O	0
[line_break_token]  --Gradient descent does not provide strong attack, but grid search does.	Review	O	0
This may be due to the high non-concavity, compared to the small perturbation case.	Review	O	0
[line_break_token][line_break_token]One possible question is the novelty, as this idea is so simple that probably many people have observed similar phenomenon--but have not experimented that extensively.	Review	B-Review	1
[line_break_token]Also, there are some related works that also show the vulnerability under spatial transformations.	Review	I-Review	1
But some are concurrent works to 1st version of the paper (though published), so I tend to not to judge it by those works.	Review	I-Review	1
 [line_break_token][line_break_token]Other comments: [line_break_token]1.	Review	O	0
page 3 in the paragraph starting with ‚ÄòWe implement ‚Ä¶‚Äô, the author chooses a differentiable bilinear interpolation routine.	Review	B-Review	3
However, the interpolation method is not shown or explained.	Review	I-Review	3
[line_break_token]2.	Review	O	0
In term of transformation, scaling and reflecting are also transformations.	Review	B-Review	4
It should be straightforward to check the robustness with respect to them.	Review	I-Review	4
Comments?	Review	I-Review	4
[line_break_token]3.	Review	O	0
Header in tables is vague.	Review	B-Review	5
Like ‚ÄòNatural‚Äô or ‚ÄòOriginal‚Äô, etc.	Review	I-Review	5
More description of the Header under tables is helpful.	Review	I-Review	5
[line_break_token]4.	Review	O	0
For CIFAR10 and especially for ImageNet dataset, Aug30 and Aug40 models showed lower accuracy&nbsp;than No Crop model&nbsp;on Nat test set.	Review	O	0
This is little strange because data augmentation (such as random rotation) is commonly used strategy to improve test accuracy.	Review	B-Review	6
I think this might mean that the model is not trained enough and underfitted, maybe because excessive data augmentation lowered the training speed.	Review	I-Review	6
[line_break_token]	Review	O	0
We thank the reviewer for their kind words.	Reply	O	0
[line_break_token][line_break_token]Regarding the novelty of our paper: We agree that we are not the first to experimentally study the robustness of classifiers to rotations and translation (as we mention in our paper including relevant citations).	Reply	B-Reply	1
We would like to emphasize however that simply pointing out this flaw is not enough to establish it as a relevant problem with current classifiers.	Reply	I-Reply	1
After all, we also need to understand if this issue is only a small glitch that we can fix with a few simple modifications, or if it requires more thought and further research.	Reply	I-Reply	1
This is why we go into significantly more depth than prior work with respect to possible fixes and show that standard approaches (data augmentation, robust optimization, ensembles / majority voting) do help to some extent, but are still far from fully solving the problem. (	Reply	I-Reply	1
Please also refer to our response to Reviewer 3 on the same topic.)	Reply	I-Reply	1
[line_break_token][line_break_token]We will address the other points raised below.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We used the approach from "Spatial Transformer Networks" (Jaderberg et al.,	Reply	B-Reply	3
2015) and their open source implementation.	Reply	I-Reply	3
We will clarify this point in our updated manuscript and add a link to the implementation.	Reply	I-Reply	3
[line_break_token][line_break_token]2.	Reply	O	0
We agree that scaling and reflecting are natural transformations to consider.	Reply	B-Reply	4
We decided to restrict ourselves to two transformations and perform a comprehensive study in this case, rather than perform fewer experiments with more transformations.	Reply	I-Reply	4
We chose translations since ConvNets are often claimed to be inherently robust to these transformations, and rotations since we believe they are the simplest to describe.	Reply	I-Reply	4
Moreover, rotations don't discard any image information (other than edge effects) while (say) downscaling does.	Reply	I-Reply	4
[line_break_token][line_break_token]3.	Reply	O	0
 We will update the manuscript to clarify the table headers.	Reply	O	0
[line_break_token][line_break_token]4.	Reply	O	0
To the best of our knowledge, none of the publicly available implementations for training state-of-the-art ImageNet or CIFAR10 models use random rotations as data augmentation.	Reply	B-Reply	6
This is likely due to the fact that random rotations typically do not yield  any benefits in (non-robust) test error (as our experimental results show).	Reply	I-Reply	6
[line_break_token][line_break_token]We would also like to emphasize that all of our models were trained until convergence (the loss plateaued) and hence the reduced test performance is not an artifact of training for insufficient steps (we will add a note about this to our manuscript).	Reply	I-Reply	6
At a high level, a decrease in test performance due to data augmentation is not surprising.	Reply	I-Reply	6
If the transformations used are not present in the test set, then a model that has learned to be invariant to these transformations will typically perform worse on the test set. (	Reply	I-Reply	6
This is also the case when learning models that are adversarially robust to L_p perturbations; there is a decrease in test accuracy.)	Reply	I-Reply	6
As an extreme, consider an MNIST model that learns to be invariant to rotations up to 180 degrees.	Reply	I-Reply	6
Clearly, this invariance is only hurting the model's performance since it cannot easily distinguish '6' from '9'.	Reply	I-Reply	6

Summary: [line_break_token][line_break_token]This paper presents a new training algorithm for vector-quantized autoencoders (VQVAE), a discrete latent variable model akin to continuous variational autoencoders.	Review	O	0
[line_break_token]The authors propose a soft-EM training algorithm for this model, that replaces hard assignment of latent codes to datapoints with a weighted soft-assignment.	Review	O	0
[line_break_token][line_break_token]Overall the technical writing in the paper is sloppy, and the presentation of the generative model takes the form of an algorithmic description of the training algorithm, rather than being a clear definition of the generative model itself.	Review	B-Review	1
[line_break_token][line_break_token]The technical presentation of the work by the authors starts only at page 5 (taking less than a full page), after several pages of imprecise presentation of previous and related work.	Review	I-Review	2
The paper could be significantly improved by making this preceding material more concise and rigorous.	Review	I-Review	2
[line_break_token][line_break_token]Quantitative experimental evaluation is limited to a machine translation task, which is rather uncommon in the literature on generative latent variable models.	Review	I-Review	3
I would expect evaluation in terms of held-out data log-likelihood (ie bits-per-dimension) used in probabilistic generative models, and possibly also using measures from the GAN literature such as inception scores.	Review	I-Review	3
Datasets that are common include CIFAR-10 and resized variants of the imagenet dataset.	Review	I-Review	3
[tab_token] [line_break_token][line_break_token][line_break_token]Specific comments:[line_break_token][line_break_token]- Please adhere to the ICLR template bibliography style, which is far more readable than the style that you used.	Review	O	0
[line_break_token][line_break_token]- Figure 1 does not seem to be referenced in the text.	Review	O	0
[line_break_token][line_break_token]- The last paragraph of section 2.1 is unclear.	Review	O	0
It mentions a sampling a sequence of latent codes.	Review	B-Review	6
The notion of sequentiality has not been mentioned before, and it is not clear what it refers to in the context of the model defined so far up to that point.	Review	I-Review	6
[line_break_token][line_break_token]- The technical notation is very sloppy.	Review	O	0
[line_break_token]* In numerous places the paper refers to the joint distribution P(x1,‚Ä¶,x_n, z1, ‚Ä¶, zn) without defining that the distribution factorizes across the samples (xi,zi), and without specifying the forms of p(zi) and p(xi|zi).	Review	B-Review	7
[line_break_token]* This makes that claims such as ‚Äúcomputing the expectation in the M step (Equation 11) is computationally infeasible‚Äù are not verifiable.	Review	I-Review	7
[line_break_token][line_break_token]- Please be clear about how much is gained by replacing the exact M-step with a the one based on the samples from the posterior computed in the E-step.	Review	O	0
[line_break_token][line_break_token]- What is the reason to decode the weighted average of the embedding vectors, rather than decoding all of them, and updating the decoder in a weighted manner?	Review	O	0
[line_break_token][line_break_token]- reference 14 for Variational autoencoders is incorrect, please use the following citation instead: [line_break_token]@InProceedings{kingma14iclr,[line_break_token]  Title                    = {Auto-Encoding Variational {B}ayes},[line_break_token]  Author                   = {D. Kingma and M. Welling},[line_break_token]  Booktitle                = {{ICLR}},[line_break_token]  Year                     = {2014}[line_break_token]}[line_break_token][line_break_token]- The related work section (4) provides a rather limited overview of relevant related work.	Review	O	0
[line_break_token]Half of it is dedicated to recent advances in machine translation, which does not bear a direct connection to the technical material presented in section 3.	Review	B-Review	11
[line_break_token][line_break_token]- There is no justification of using *causal* self-attention on the source embedding, is this a typo?	Review	O	0
[line_break_token][line_break_token]- As for the experimental evaluation results: it seems that distillation is a much more critical factor to achieve good performance than the proposed EM training of the VQ-VAE model.	Review	O	0
Unfortunately, this fact goes unmentioned when discussing the experimental results.	Review	B-Review	13
[line_break_token][line_break_token]- What is the significance of the observed differences in BLEU scores?	Review	O	0
Please report average performance and standard deviations over several runs with randomized parameter initialization and batch scheduling.	Review	B-Review	14
[line_break_token][line_break_token]- It seems that the tuning of the number of discrete latent codes (table 2 in appendix) and other hyper-parameters (table 3 in appendix) was done on the test set, which is also used to compare to related work.	Review	O	0
A separate validation set should be used for hyper parameter tuning in machine learning experiments.	Review	B-Review	15
[line_break_token][line_break_token]- It seems that all curves in figure 3 collapse from about 45 BLEU to values around 17 BLEU, why is this?	Review	O	0
The figure is hard to read since poor quality, and curves that are superposed.	Review	B-Review	16
[line_break_token]	Review	O	0
We thank the reviewer for taking the time to read our paper.	Reply	O	0
Below we address the specific points raised by the reviewer:[line_break_token][line_break_token]>[line_break_token]Overall the technical writing in the paper is sloppy....[line_break_token]<[line_break_token][line_break_token]In this work, we improve upon VQ-VAE to learn shorter latent representations of a target sentence in order to speed up MT, rather than to train a generative model.	Reply	O	0
We achieve considerable speedup in decoding state of the art NMT models without much loss in BLEU (a universally accepted metric for translation quality), which has powerful implications for real world, production level MT systems.	Reply	B-Reply	1
While evaluating the improvements of our training for generative modeling is interesting, our focus is on using VQ-VAE for a practical task.	Reply	I-Reply	1
[line_break_token][line_break_token]Moreover, we have now added a paragraph on the generative process (Page 3).	Reply	I-Reply	1
We hope that this will clarify some of the content.	Reply	I-Reply	1
We welcome the reviewer to share what they think is "sloppy" and "imprecise", and what would help us further improve the content of the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]>[line_break_token]The technical presentation of the work by the authors starts only at page 5...[line_break_token]<[line_break_token][line_break_token]Our goal is to use the autoencoder from VQ-VAE as a tool to compress the target sentence for fast decoding.	Reply	O	0
We therefore chose to focus on the part of the algorithm, describing it's connection to hard-EM and our improvements on it using EM.	Reply	B-Reply	2
We would appreciate concrete suggestions to improve the content.	Reply	I-Reply	2
[line_break_token][line_break_token]>[line_break_token]Quantitative experimental evaluation is limited to a machine translation task...[line_break_token]<[line_break_token][line_break_token]The main focus of our work is to design a better non-autoregressive machine translation model and which is an area of active research (see for e.g., [1, 2, 3, 4]).	Reply	O	0
None of those works evaluate their proposed method on datasets other than machine translation because the goal of their work is non-autoregressive MT.	Reply	B-Reply	3
We do not care about generative modeling of images with VQ-VAE because plenty of other models do it much better (for e.g., a GAN/VAE/PixelCNN++).	Reply	I-Reply	3
[line_break_token][line_break_token]The keywords of our paper states: "machine translation, vector quantized autoencoders, non-autoregressive, NMT", while the TL;DR of our submission is "Understand the VQ-VAE discrete autoencoder systematically using EM and use it to design non-autogressive translation model matching a strong autoregressive baseline."	Reply	I-Reply	3
[line_break_token][line_break_token]>[line_break_token]- The related work section (4) provides a rather limited overview of relevant related work...[line_break_token]<[line_break_token][line_break_token]Again, the main aim of our work is to speed up the decoding for real world Neural Machine Translation (NMT) systems, which is an active area of research (see e.g., [1, 2, 3, 4]).	Reply	O	0
We have focussed on generative models that are practically relevant to non-autoregressive NMT and because of page limitations we have not been able to include every paper on generative modeling.	Reply	B-Reply	11
If we have missed relevant references we would appreciate if the reviewer would let us know what they are.	Reply	I-Reply	11
[line_break_token] [line_break_token][1] <a href="https://openreview.net/forum?id=B1l8BtlCb" target="_blank" rel="nofollow">https://openreview.net/forum?id=B1l8BtlCb</a>[line_break_token][2] <a href="http://proceedings.mlr.press/v80/kaiser18a/kaiser18a.pdf" target="_blank" rel="nofollow">http://proceedings.mlr.press/v80/kaiser18a/kaiser18a.pdf</a>[line_break_token][3] <a href="https://openreview.net/forum?id=r1gGpjActQ" target="_blank" rel="nofollow">https://openreview.net/forum?id=r1gGpjActQ</a>[line_break_token][4] <a href="https://arxiv.org/abs/1802.06901" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.06901</a	Reply	O	0

This paper provides a depth learning architecture (global-local structure) from two images.	Review	O	0
It claims that SoTA depth can be estimated from the supervision of a very sparse ground truth by leveraging the optical flow information between two images.	Review	O	0
In the experiments, it shows superior performance than other baseline methods such as Eigen's network and DispNet.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1: The paper is well written and motivations are clearly explained.	Review	O	0
[line_break_token]2: The architecture proposed is reasonable and generate good results, since it accept the ground truth scale from sparse map and relative dense matching cues from optical flow, where implicitly relative camera pose is from global module.	Review	O	0
[line_break_token][line_break_token][line_break_token]Cons:[line_break_token]1`: It is a fairly standard network design similar to DeMoN[25], where motion network for global pose and local dense network for local matching.	Review	O	0
[line_break_token][line_break_token]1: The claim of  robustness to camera intrinsics is not solved in principle but due to training using ground truth from multiple dataset .	Review	O	0
It still suffer from depth motion confusion if there is no ground truth depth guidance when testing.	Review	B-Review	2
 It is also unfair for comparison of this metric with unsupervised approach where a universal intrinsic is assumed.	Review	I-Review	2
[line_break_token][line_break_token]2: I think the comparison might not be fair since the baselines are all single image estimation networks, while the approach has two images, where disparities are serving as a strong cue for depth.	Review	O	0
Other possible  architectures such as flow net, pwc net,  DeMoN[25] and stereo networks such as (gc-net or psm-net) should be considered since these networks are more focus on feature matching.	Review	B-Review	3
 [line_break_token][line_break_token]3:  Even for single image network, eigen's method is not SoTA, the author may consider (1)  as one of the baseline, etc.	Review	O	0
[line_break_token][line_break_token](1) "Deeper Depth Prediction with Fully Convolutional Residual Networks"[line_break_token][line_break_token]	Review	B-Review	4
e thank the reviewer for the detailed comments.	Reply	O	0
 We address the raised concerns below.	Reply	O	0
We hope these clarifications help better understanding our contribution and experiment design and we are looking forward to hearing back from the reviewer.	Reply	O	0
[line_break_token][line_break_token]We respectfully disagree that our architecture is very similar to the one proposed in DeMoN [25]. Here are the main differences:[line_break_token]We predict the convolutional filters in an input dependent way to transform local matches in depth.	Reply	B-Reply	1
There is no similar network in the literature to the best of our knowledge.	Reply	I-Reply	1
[line_break_token]We do not explicitly predict camera pose, but a hidden representation of it.	Reply	I-Reply	1
[line_break_token]We do not iteratively transform flow to depth using geometry equations.	Reply	I-Reply	1
[line_break_token][line_break_token]Since the reviewer might have slightly misunderstood our problem setup, we briefly summarize it here.	Reply	I-Reply	2
We are interested in the problem of learning depth from very sparse supervision signal (available only at training time!),	Reply	I-Reply	2
similar to‚Äúhaptic feedback‚Äù, without explicitly using geometry.	Reply	I-Reply	2
 Our evaluation was not designed to thoroughly show the advantage over state-of-the-art methods, but to fairly study the new problem setting.	Reply	I-Reply	2
In order to do so, we compared to a set of well known architectures for depth estimation, which we tuned to reach the best performance on our task (see Section 6.2.1  in the Appendix).	Reply	I-Reply	2
Since our method and the baselines are tuned for the task and trained on exactly the same data, we believe that our evaluation is fair: any advantage our method has is due to the architecture, not the training regime.	Reply	I-Reply	2
We have modified section 4.2 to clarify this point.	Reply	I-Reply	2
[line_break_token][line_break_token]The experiment with varying intrinsics was designed with the explicit goal of showing that state-of-the art unsupervised depth estimation approaches strongly depend on the camera calibration parameters: when intrinsics are precisely know they can be very good, but are brittle otherwise.	Reply	I-Reply	3
Even though concurrent unsupervised approaches can learn intrinsics together with depth [2], they still require intrinsics to be constant over time.	Reply	I-Reply	3
 Our method, in contrast, can adapt to instantaneous  changes in camera parameters.	Reply	I-Reply	3
Why is this evaluation not fair?	Reply	I-Reply	3
[line_break_token][line_break_token]As requested by the reviewer, we added two additional baselines:[line_break_token]PWC-Net (Table 8, Appendix): We added a convolutional head on top of the off-the-shelf PWC-Net architecture and finetuned the entire system with only the very sparse depth loss.	Reply	I-Reply	4
We found its performance to be generally poor, mainly due to overfitting.	Reply	I-Reply	4
Details could be found in the Appendix in Table 8.	Reply	I-Reply	4
[line_break_token]The FCRN architecture from [1] (Table 2, main manuscript):  In order to make a fair comparison, we tuned this architecture for our task of learning from sparse supervision.	Reply	I-Reply	4
Specifically, we changed its input layer to provide it with the same input as ours:  a pair of frames and the optical flow.	Reply	I-Reply	4
We also had to change the activation function of the network from Relu to Leaky Relu to have better performance (details in the appendix in section 6.2.1).	Reply	I-Reply	4
We then trained this baseline with exactly the same input as ours, and we found its performance to be lower than our method, but similar to our DispNet baseline [48, manuscript].[line_break_token][line_break_token][1] Laina, Iro, et al. "	Reply	O	0
Deeper depth prediction with fully convolutional residual networks."	Reply	O	0
2016 Fourth international conference on 3D vision (3DV).	Reply	O	0
IEEE, 2016.	Reply	O	0
[line_break_token][2] Gordon, Ariel, et al. "	Reply	O	0
Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras."	Reply	O	0
arXiv preprint arXiv:1904.04998 (2019)	Reply	O	0

This paper tackles the task of rotation estimation in a setting where both labelled and unlabelled examples are available for training.	Review	O	0
It proposes to learn a generative model of images (a VAE), where the ‚Äòcode‚Äô is factored into a latent vector z and the object rotation r.  As in training a VAE, an image encoder that predicts the distribution over (z, r) and the generator are jointly trained, but with additional supervision on the distribution over r for the labelled examples.	Review	O	0
[line_break_token][line_break_token]I think the overall idea of learning a disentangled generative model in a semi-supervised setting is simple and elegant, and could in principle help leverage unlabelled data.	Review	O	0
However,  I do have some concerns regarding the specific contributions of this work, and several reservations about the experiments reported, and would overall argue for rejection.	Review	O	0
[line_break_token][line_break_token]Concerns:[line_break_token]1) The central empirical result stated is that using this approach allows one to reduce amount of labelled data by 10-20 %.	Review	O	0
First, even if valid, this is not a very convincing reduction in the amount of supervision.	Review	B-Review	1
However, I feel this claim is not well-established by the experiments:[line_break_token][line_break_token]1a)  The paper should report a baseline with only using the loss in eqn 3 and only training the encoder (using various fractions of training data) to predict the rotation i.e. purely discriminative training without training a generative model.	Review	I-Review	1
The current plots of performance vs fraction of labelled data don't mean much until compared to a similar plot for this baseline.	Review	I-Review	1
The current results don't really highlight the importance of training the generative model or using the unlabelled data.	Review	I-Review	1
[line_break_token][line_break_token]1b) I think there are some inconsistencies in performances reported in Fig 2.	Review	O	0
I assume the test set is same despite different training data, because the paper states "All of the trained models are evaluated with respect to the complete test set".	Review	B-Review	2
In this regard, I am puzzled why using 100% labelled data with 16 renders is significantly better than using 50% labelled data with 32 renders -- these should imply similar number of labelled examples, and more unlabelled ones in the former.	Review	I-Review	2
[line_break_token][line_break_token]2) While the discussion points to this, the paper would really benefit from having results in a real setting, in particular as pose estimation is a field with a lot of prior methods that have been shown to work in these settings.	Review	O	0
The current results are all in a setup with synthetic, unoccluded data, without background variation, equidistant camera uniformly sampled along a circle.	Review	B-Review	3
The central idea of using a generative model would be much more difficult to operationalize in a realistic setting where these simplifying assumptions are not made, and I'd only be convinced about the applicability of the approach by results in that setting.	Review	I-Review	3
As a possible setup, one case use many imagenet images in conjunction with labelled examples in PASCAL3D+ to try this approach.	Review	I-Review	3
[line_break_token][line_break_token]3) The overall approach maybe novel in context of pose estimation, but this idea of learning a disentangled generative model is not, and there are several papers which do so with varying amount of supervision e.g. see [1] below for similar ideas, and pointers.	Review	O	0
While some details here may vary, in context of these prior works, I'd view this paper as mostly applying well-established ideas to a new task.	Review	B-Review	4
[line_break_token][line_break_token]--[line_break_token]In addition to the above, I have a question regarding the training/testing data:[line_break_token]Q: The dataset description only states data was randomly divided - was this random division at an image level, or model level i.e. could different renderings of the same model be in train and test set?	Review	O	0
[line_break_token]--[line_break_token][line_break_token][1] Learning Disentangled Representations with Semi-Supervised Deep Generative Models, NIPS 2017.	Review	O	0
Siddharth et.	Review	O	0
al.	Review	O	0
ear reviewer, I would like to thank you for the time and effort spent in analyzing this paper and for the specific suggestions made to improve this work.	Reply	O	0
We will answer the concerns presented in the review and indicate the future actions to improve the paper.	Reply	O	0
[line_break_token]1) The central empirical result stated is that using this approach allows one to reduce amount of labelled data by 10-20 %.	Reply	O	0
First, even if valid, this is not a very convincing reduction in the amount of supervision.	Reply	O	0
However, I feel this claim is not well-established by the experiments:[line_break_token]1a) The paper should report a baseline with only using the loss in eqn 3 and only training the encoder (using various fractions of training data) to predict the rotation i.e. purely discriminative training without training a generative model.	Reply	O	0
The current plots of performance vs fraction of labelled data don't mean much until compared to a similar plot for this baseline.	Reply	O	0
The current results don't really highlight the importance of training the generative model or using the unlabeled data.	Reply	O	0
[line_break_token]A: Thank you very much for your suggestion.	Reply	O	0
We will include these experiments in a future version of the paper.	Reply	B-Reply	1
[line_break_token][line_break_token]1b) I think there are some inconsistencies in performances reported in Fig 2.	Reply	O	0
I assume the test set is same despite different training data, because the paper states "All of the trained models are evaluated with respect to the complete test set".	Reply	O	0
In this regard, I am puzzled why using 100% labelled data with 16 renders is significantly better than using 50% labelled data with 32 renders -- these should imply similar number of labelled examples, and more unlabeled ones in the former.	Reply	O	0
[line_break_token]A: To answer this question, it is important to clarify that the split between labeled and unlabeled data is done at 3D model level.	Reply	O	0
This means that for 100% labeled and 16 renders the CVAE sees all the available 3D models in the training dataset but only from 16 different angles whereas for the 50% labeled and 32 renders, the model just sees half of the 3D models but with renders that have more angle coverage.	Reply	B-Reply	2
Therefore, even though the amount of data is similar in both cases, one case has less examples at model level (which would mean that it has seen less variability in).	Reply	I-Reply	2
[line_break_token][line_break_token]2) While the discussion points to this, the paper would really benefit from having results in a real setting, in particular as pose estimation is a field with a lot of prior methods that have been shown to work in these settings.	Reply	O	0
The current results are all in a setup with synthetic, unoccluded data, without background variation, equidistant camera uniformly sampled along a circle.	Reply	O	0
The central idea of using a generative model would be much more difficult to operationalize in a realistic setting where these simplifying assumptions are not made, and I'd only be convinced about the applicability of the approach by results in that setting.	Reply	O	0
As a possible setup, one case use many imagenet images in conjunction with labelled examples in PASCAL3D+ to try this approach.	Reply	O	0
[line_break_token]A: Thank you very much for your suggestion, this can further strengthen our claims.	Reply	O	0
We will include these experiments in a future version of the paper.	Reply	B-Reply	1
[line_break_token][line_break_token]3) The overall approach maybe novel in context of pose estimation, but this idea of learning a disentangled generative model is not, and there are several papers which do so with varying amount of supervision e.g. see [1] below for similar ideas, and pointers.	Reply	O	0
While some details here may vary, in context of these prior works, I'd view this paper as mostly applying well-established ideas to a new task.	Reply	O	0
[line_break_token]A: We agree with the fact that we are using the established framework from [1] in a new setting.	Reply	O	0
One important detail to be taken into account is that we are incorporating prior geometrical knowledge specific to our task in the method.	Reply	B-Reply	4
Since rotations have specific topological properties, we have chosen a suitable latent space for the predictions of the network (in this case choosing a circle S^1 as latent space).	Reply	I-Reply	4
In a future version of the paper we will try to emphasize this perspective from our work and search for new ways to include more topological properties into our predictions and latent representations.	Reply	I-Reply	4
[line_break_token]4) In addition to the above, I have a question regarding the training/testing data: Q: The dataset description only states data was randomly divided - was this random division at an image level, or model level i.e. could different renderings of the same model be in train and test set?	Reply	O	0
[line_break_token]A: The training/testing dataset were divided at model level i.e. during training the CVAE has received no renders from the testing 3D models.	Reply	O	0
This way we ensure there has been no information leakage about certain models from the training dataset into the testing phase.	Reply	B-Reply	5
[line_break_token]Once again, we would like to thank the reviewer for taking the time to analyze the work and provide useful suggestions to improve our work.	Reply	O	0
[line_break_token]-- [1] Learning Disentangled Representations with Semi-Supervised Deep Generative Models, NIPS 2017.	Reply	O	0
Siddharth et.	Reply	O	0
al.	Reply	O	0

The paper describes a cache side-channel attack on a deep learning model.	Review	O	0
In a cache side-channel attack, the attacker sets up a process on the same machine where the victim process (that is running the training or evaluation job for the DNN model) is running.	Review	O	0
It is assumed that the victim process uses a common shared library for DNN computations as the attacking process.	Review	O	0
The attacking process flushes the cache, then observes access times for key functions.	Review	O	0
The paper shows that, based on the speed of accessing previously flushed functions, the attacker can discover the high-level network architecture, namely the types of layers and their sequence.	Review	O	0
The paper shows that, by spying on such cache access patterns in the Tensorflow library, this method can reliably extract the above high-level information for 11 different network architectures.	Review	O	0
It also describes a few counterattack alternatives whereby the victim can obfuscate its cache access patterns for self-protection.	Review	O	0
[line_break_token][line_break_token]The significance of the results is not clear to me.	Review	B-Review	1
The extracted information is very high level.	Review	I-Review	1
What realistic attacks can be constructed from such a coarse-grained fingerprinting?	Review	I-Review	1
The experimental results show that the fingerprint can be used to map the architecture to one of the 13 well-known architectures (VCC16, ResNet, DenseNet, Inception, etc.).	Review	I-Review	1
But so what?	Review	I-Review	1
What does the victim lose by revealing that it's using one of a few very well known types of DNNs (the ones tested in this paper).	Review	I-Review	1
There may very well be a good reason why this is very dangerous, but that is not explained in the paper.	Review	I-Review	1
Not being familiar with this line of research and its significance, I looked up several of the related papers (Suciu et al.,	Review	I-Review	1
2018, Tramer et al.,	Review	I-Review	1
2017, Papernot et al.,	Review	I-Review	1
2017, Yan et al.,	Review	I-Review	1
2018).	Review	I-Review	1
None of them could explain why this particular type of fingerprinting is dangerous.	Review	I-Review	1
[line_break_token][line_break_token]Of the cited previous work, Yan et al.,	Review	I-Review	2
2018 seems to present the most closely related approach.	Review	I-Review	2
The method described in that paper is very similar: cache side attack on a shared library through a co-located attacker process.	Review	I-Review	2
They monitor at a finer grain -- Generalized Matrix Multiplications -- and are thus able to infer more details such as the size of the layers.	Review	I-Review	2
This also makes the inference problem harder -- they were able to narrow down the search space of networks from >4x10^35 to 16 (on VGG16).	Review	O	0
On the surface, the results presented in this paper seem stronger.	Review	B-Review	2
But they are actually solving a much easier problem -- their search space is one of 13 well-known networks.	Review	I-Review	2
To me, Yan et al.	Review	I-Review	2
's approach is a much more powerful and promising setup.	Review	I-Review	2
[line_break_token][line_break_token]Overall, while the paper is clearly written and presents the idea succinctly, it is derivative of previous research, and the results are not stronger.	Review	O	0
I'm not an expert in this area, so it's possible that I missed something.	Review	O	0
Based on my current understanding, however, I recommend reject.	Review	O	0
We thank the reviewer for the constructive feedback.	Reply	O	0
We will update the paper accordingly.	Reply	O	0
Additionally, we clarify here the significance of DNN fingerprinting attacks and the relation to the concurrent work of (Yan et al.,	Reply	O	0
2018).	Reply	O	0
[line_break_token][line_break_token](1) The threat of DNN fingerprinting attacks and the significance of our results.	Reply	O	0
[line_break_token][line_break_token]Prior work on black-box attacks [1, 2, 3] against neural networks assumes an adversary who has knowledge of the victim's network architecture.	Reply	B-Reply	1
This is an impractical assumption, and thus, releasing this assumption is the last-mile problem: if an attacker can easily know the architecture of a victim network, this will enable most black-box attacks on DNNs.	Reply	I-Reply	1
For instance, without this knowledge, the success of black-box adversarial sample crafting can decrease dramatically, as illustrated in [7]: in attacks against transfer learning services, where the attacker has partial knowledge about the victim network's architecture, having lesser knowledge can decrease the attack's success rate from 88.4% (only the last 3-4/16 layers are unknown) to 1.2% (the last 6/16 layers are unknown).	Reply	I-Reply	1
Additionally, DNNs are often proprietary and represent the key intellectual property, and thus their architectures are hidden from attackers.	Reply	I-Reply	1
The reconstruction of DNN attributes is also the topic of [4], published at ICLR'18, where the open reviews deemed the problem setting novel and interesting.	Reply	I-Reply	1
[line_break_token][line_break_token]What is more, this simple cache side-channel attack is more effective than other network reconstruction attacks proposed in prior work [4, 5]. These approaches are either time intensive (i.e., 40 GPU days for the technique proposed in [4]) or monitor computations while an attacker actively queries a victim model.	Reply	I-Reply	1
With our DeepRecon attack, we demonstrate that high-level architectural information --- that prior work aims to extract --- can be easily leaked through our side-channel attacks with little computation and passive monitoring (Sec.	Reply	I-Reply	1
3.2-3.4).	Reply	I-Reply	1
This allows an attacker to reconstruct the full network architecture of an arbitrary network (Sec.	Reply	I-Reply	1
3.5) without specifying or assuming knowledge of a network family.	Reply	I-Reply	1
[line_break_token][line_break_token]Moreover, our results go beyond proposing and analyzing a fingerprinting attack.	Reply	I-Reply	1
We propose a statistical model for fingerprinting to quantify the importance of each piece of leaked information to the attacker's success (Sec.	Reply	I-Reply	1
4).	Reply	I-Reply	1
We also propose simple and effective defenses that obfuscate the observations made through cache side-channels, which can be implemented without specific hardware or operating system support (Sec 5).	Reply	I-Reply	1
[line_break_token][line_break_token]To the best of our knowledge, this represents the first comprehensive assessment of the vulnerability of DNNs to cache side-channel attacks.	Reply	I-Reply	1
We hope that our results will stimulate follow-on work on defending ML systems against such attacks	Reply	I-Reply	1

Value-Driven Hindsight Modelling proposes a method to improve value function learning.	Review	O	0
The paper introduces the hindsight value function which estimates the expected return at a state conditioned on the future trajectory of the agent.	Review	O	0
How use this hindsight value function is not obvious, since an agent does not have access to the future states needed in order to take actions (for Q-Learning) and the hindsight value function is a biased gradient estimator for training policy gradient methods.	Review	O	0
[line_break_token][line_break_token]The authors train the standard value function (which does not have access to future information) to predict the features which the highsight value function learns to summarize the value relevant parts of the future trajectory.	Review	O	0
These predicted features can then be used in place of the actual hindsight value function, circumventing the issues discussed above.	Review	O	0
The authors argue that this auxiliary objective provides a richer training signal to the normal value function, helping it to better learn what information in a given state is relevant to predicting future rewards.	Review	O	0
[line_break_token][line_break_token]The paper is well structured and written, flowing from high level motivation and review into the core of the method, followed by analysis of the approach, and then proceeds through three experiments.	Review	O	0
The first two are toy / crafted experiments which build intuition and probe the behavior of the method and finally a large scale test on the Atari 57 benchmark demonstrating improvements when augmenting a state-of-the-art method with HiMo.	Review	O	0
[line_break_token][line_break_token]This reviewer recommends acceptance (I would give a 7 given more granularity) based on the contribution of a new auxiliary objective for value functions and the strength of the experimental suite.	Review	O	0
The Portal Choice environment is well crafted and instrumented with the graphs of figure 5b and 5c to show the behavior of the approach and the clean demonstration of an improvement over a previously SOTA method for Atari 57 is encouraging (the same architecture and the ablation simply sets the auxiliary objective‚Äôs weight to 0).	Review	O	0
However, the reviewer has some caution and concerns as follows:[line_break_token][line_break_token]1) The lack of a large scale experiment demonstrating improvement with an actor-critic method.	Review	O	0
While the Portal Choice experiments are informative and use Impala, it is a bit toy, and it would increase the reviewer‚Äôs confidence in the generality and robustness of the approach if improvements were also demonstrated for an actor-critic method on a large environment suite.	Review	B-Review	1
Atair 57 could work but ideally a different setting such as DMLab 30 or continuous control from pixels.	Review	I-Review	1
Demonstrating improvements in one of these additional settings would raise the reviewer to a strong acceptance.	Review	I-Review	1
[line_break_token][line_break_token]2) The potential sensitivity of the approach to the two important hyperparameters that the authors mention, the dimensionality of the hindsight feature space (to reduce approximation error) and the # of future states it conditions on (to avoid just observing the full return directly).	Review	O	0
The very low dimensionality of the hindsight feature space (d=3 for Atari) seems a bit at odds with the explanation that the hindsight features provide a strong training signal for learning to better extract value relevant information from the state.	Review	B-Review	2
Experiments that studied sensitivity to these would provide better perspective on the robustness of HiMo.	Review	I-Review	2
[line_break_token][line_break_token]Questions and suggestions for improving the paper:[line_break_token][line_break_token]For Figure 6 the dynamic range gets squashed by a few games with relatively large performance improvements or regressions.	Review	O	0
Changing to a log-scale on the y-axis could be more informative?	Review	B-Review	3
For instance, I find it pretty difficult to eyeball the ~1 human normalized score median improvement according to Table 1 from the chart.	Review	I-Review	3
[line_break_token][line_break_token]Figure 3 could also be improved.	Review	I-Review	4
It requires significant context from definitions in the paper in order to understand.	Review	I-Review	4
It could be reworked into a stand alone expository overview of HiMo that helps readers quickly grok the idea of the paper such that abstract + figure is enough.	Review	I-Review	4
[line_break_token][line_break_token]Could the authors consider showing / adding full learning curves (median human normalized score?)	Review	I-Review	5
for HiMO vs the baseline on Atari 57?	Review	I-Review	5
This would help readers get a qualitative feel for the learning dynamics of the algorithm instead of only having a final scalar measure at the end of training.	Review	I-Review	5
hank you for taking the time to review our paper.	Reply	O	0
[line_break_token][line_break_token]1- Re: large-scale experiment[line_break_token]We ran a control experiment on the bowling Atari game using Impala (see Figure 7-c)  that tested whether the gains using R2D2 were not specific to Q-value based methods.	Reply	O	0
These results suggest the benefits at scale are not limited to the value-based R2D2 setting.	Reply	B-Reply	1
Testing the approach more broadly (on dmlab or challenging continuous control tasks as you suggested) is certainly something we want to look at in the future.	Reply	I-Reply	1
[line_break_token][line_break_token]2- RE:sensitivity:[line_break_token]Yes this is a good point.	Reply	O	0
It is not overly sensitive to these exact values (a dimension of 16 for \phi does fine for example) but much larger values did tend to perform worse when we were tuning the architecture.	Reply	B-Reply	2
One hypothesis is that a \phi with small dimensionality regularize the representation to only include relevant features, while larger dimensional \phi may contain less relevant information that will distract the modeling effort on phi.	Reply	I-Reply	2
We plan to investigate that aspect more in future work.	Reply	I-Reply	2
[line_break_token][line_break_token]Thank you for the suggestions regarding the figures.	Reply	I-Reply	5
We‚Äôll include the learning curves for all the games in the appendix.	Reply	I-Reply	5
[line_break_token][line_break_token]We take your point about Figure 3, we‚Äôll think about a way to make it more useful without relying too much on the text	Reply	I-Reply	4

Summary: This paper adapts the UCB Q-learning method to the inifinite-horizon discounted MDP setting.	Review	O	0
With an analysis similar to that of Jin et al (2018), it shows that this algorithm achieves a PAC bound of (1-gamma)^-7 |S||A|/eps^2, improving previous best-known bound (Delayed Q-learning, Strehlet et al, 2006, (1-gamma)^-8 |S||A|/eps^4) for this case.	Review	O	0
[line_break_token][line_break_token]Evaluation: As I see this paper a direct extension of that of Jin et al (2018), I am afraid I have to recommend a rejection.	Review	O	0
[line_break_token][line_break_token]Here are some more detailed comments:[line_break_token][line_break_token]Significance: [line_break_token]This paper studies the RL problem for the infinite-horizon discounted MDP setting.	Review	O	0
This is an important setting in reinforcement learning.	Review	O	0
However, the bound is not optimal as the dependence of (1-gamma) is significantly larger than the lower bound.	Review	B-Review	2
Moreover, both the algorithm and analysis are direct extensions of that of Jin et al, I do not see a huge technique improvement.	Review	I-Review	1
[line_break_token][line_break_token]Technique Novelty:[line_break_token]As stated in the paper, the major difficulty is that the inf-horizon case does not have a set of "consecutive episodes".	Review	O	0
Therefore the "learning error at time t cannot be decomposed as errors from a set of consecutive time[line_break_token]steps before t, but errors from a set of non-consecutive time steps without any structure."	Review	O	0
However, I do not see a major technological innovation is needed to get around this issue.	Review	B-Review	1
As a result, the analysis and algorithm in this paper are very similar to that of Jin et al 2018, who nearly implicitly contain the results in this paper.	Review	I-Review	1
[line_break_token][line_break_token]Furthermore, I would think there is a (likely) very simple reduction from the inf-horizon to finite-horizon: break the inifinite horizon into episodes of length R = O((1-\gamma)^-1 log(eps^-1)).	Review	I-Review	3
Now, although the MDP does not restart, but it can be treated as restarting at a history-dependent initial state distribution at the beginning of every episode.	Review	I-Review	3
So, an optimal finit-horizon algorithm in this setting is at most epsilon worse than the optimal inf-horizon algorithm, no matter where/when you start.	Review	I-Review	3
With little to no modification, we can see that Jin et al work in this setting.	Review	I-Review	3
Thus, we obtain an algorithm for the inf-horizon as well.	Review	I-Review	3
[line_break_token][line_break_token]A good match for this conference?	Review	O	0
[line_break_token]As this paper is an adaptation of a previously known Q-learning algorithm to a slightly different setting in RL, I do not see how it fits the "learning representation" paradigm.	Review	B-Review	4
Of course, Q-function can be argued as a representation of the MDP model, but this Q-function itself is not a new concept in this paper.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
irst of all, we thank the reviewer for giving detailed technical comments.	Reply	O	0
The major concern of the reviewer is that there exists simple reduction from infinite-horizon setting to the episodic setting; and it is straightforward to generalize Jin et al (2018) to obtain our results.	Reply	B-Reply	3
[line_break_token] [line_break_token]However, the reduction given by the reviewer is incorrect.	Reply	I-Reply	3
Below we explain why the reduction doesn‚Äôt hold, and this clearly illustrates the subtle differences between the infinite-horizon setting and the episodic case.	Reply	I-Reply	3
In fact, as we already emphasized in the paper (Section 3.2), infinite-horizon setting cannot be solved by reducing to finite-horizon setting as long as we consider sample complexity instead of regret.	Reply	I-Reply	3
[line_break_token][line_break_token]We focus on sample complexity of exploration in infinite horizon setting, which is a standard measure widely used in previous results in this setting, while Jin et al proved a regret bound.	Reply	I-Reply	3
Please note that sublinear regret does NOT imply finite sample complexity of exploration.	Reply	I-Reply	3
[line_break_token][line_break_token]The reduction giving by the reviewer does NOT work for infinite horizon setting.	Reply	I-Reply	3
[line_break_token]1.	Reply	I-Reply	3
[tab_token]The algorithm in Jin et.	Reply	I-Reply	3
al finds a time-dependent policy.	Reply	I-Reply	3
Running finite-horizon algorithm can only guarantee near-optimal behavior at step 1, 1+R, 1+2R, etc.	Reply	I-Reply	3
For other steps, the policy given by Jin et.	Reply	I-Reply	3
al can be suboptimal.	Reply	I-Reply	3
For example, at step 1+R/2, the policy given by finite horizon algorithm only maximizes over the reward of remaining R/2 steps, which cannot guarantee optimal bound in the infinite horizon setting.	Reply	I-Reply	3
[line_break_token]2.	Reply	I-Reply	3
[tab_token]Sublinear regret does NOT imply finite sample complexity of exploration.	Reply	I-Reply	3
For example, if an algorithm takes sub-optimal moves at step 1, 4, 9, ‚Ä¶, t^2, ‚Ä¶, the regret is bounded by.	Reply	I-Reply	3
However, the sample complexity of exploration of this algorithm is unbounded.	Reply	I-Reply	3
Therefore, no direct reduction can be made from sample complexity of exploration to regret.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Response to other comments:[line_break_token][line_break_token]Regarding the dependence of  1-gamma: [line_break_token]Previously best-known model-free algorithm for infinite horizon setting is Delayed Q-learning, which achieves a bound of.	Reply	O	0
We also show that Delayed Q-learning cannot achieve near-optimal bound due to the inefficient usage of samples in Appendix D. Compared to this bound, our result is a significant improvement since we match the lower bound in terms of epsilon as well as S and A up to logarithmic factors.	Reply	B-Reply	2
Besides, The previously best claimed result of model-based algorithms is 1/(1-gamma)^6, which is close to our result (1/(1-gamma)^7) and also significantly above the lower bound.	Reply	I-Reply	2
Further improving the dependence on 1-gamma is a future direction.	Reply	I-Reply	2
[line_break_token][line_break_token]Regarding the technical novelty: [line_break_token]As stated in section 3.2, there are two major difficulties.	Reply	O	0
Firstly, since we need to bound sample complexity of exploration, we need to establish convenient sufficient condition for being epsilon-optimal.	Reply	B-Reply	1
We carefully design Condition 1 and Condition 2 to solve this problem.	Reply	I-Reply	1
Secondly, we need to decompose errors to that of non-consecutive steps without any structure.	Reply	I-Reply	1
See section 3.2 for detailed discussion.	Reply	I-Reply	1

The paper proposes a novel trial to alleviate the catastrophic forgetting for continual learning which is kind a mixture model of on and off-policy.	Review	O	0
The core concept of the method is utilizing experience replay buffer for all past events with new experience.	Review	O	0
They mainly worked on their method in the setting of reinforcement learning.	Review	O	0
In the experiments, they show that the model successfully mitigate the catastrophic forgetting with this behavioral cloning, and has the performance comparable to recent continual learning approaches.	Review	O	0
[line_break_token][line_break_token]The paper is easy to follow, and the methodology is quite intuitive and straight forward.	Review	O	0
In this paper, I have several questions.	Review	O	0
[line_break_token][line_break_token]Q1.	Review	O	0
I wonder the reason that every tasks are trained cyclically in sequence.	Review	B-Review	1
And is there any trial to learn each task just once and observe the catastrophic forgetting of them when they have to detain the learned knowledge in a long time without training them again, as does most of visual domain experiments of the other continual learning research.	Review	I-Review	1
[line_break_token][line_break_token]Q2.	Review	O	0
In figure 5, I wonder why the natlab_varying_map_ramdomize(probe task) can perform well even they didn‚Äôt learn yet.	Review	B-Review	2
The score of brown line increases nearly 60~70% of final score(after trained) during training the first task.	Review	I-Review	2
Because the tasks are deeply correlated?	Review	I-Review	2
or it is just common property of probe task?	Review	I-Review	2
[line_break_token][line_break_token]Q3.	Review	O	0
Using reservoir(buffer) to prevent catastrophic forgetting is natural and reasonable.	Review	B-Review	3
Is there some of quantitative comparison in the sense of memory requirement and runtime?	Review	I-Review	3
I feel that 5 or 50 million experiences at each task are huge enough to memorize and manage.	Review	I-Review	3
[line_break_token][line_break_token]Additionally, in the experiment of figure 5, I think it could be much clear with a verification that the probe task  is semantically independent (no interference) over all the other tasks.	Review	I-Review	4
[line_break_token][line_break_token]Also, it is quite hard to compare the performance of the models just with plots.	Review	I-Review	5
I expect that it could be much better to show some of quantitative  results(as number).	Review	I-Review	5
We thank the reviewer for these comments and have made additional changes to the paper to address them, as we describe below.	Reply	O	0
[line_break_token][line_break_token]Q1: We presented tasks cyclically in sequence for several reasons.	Reply	O	0
Presenting all tasks before returning to any one of them to represents a ‚Äúworst-case‚Äù scenario for catastrophic forgetting and tests our method in the hardest situation.	Reply	B-Reply	1
 Our experiment is designed to address exactly the scenario the reviewer describes -- spending a lot of time on the other tasks before returning to a specific one.	Reply	I-Reply	1
The time spent on each task in the cycle is actually quite long, and if one imagines cutting off each figure after the first iteration of the cycle, one would end up with the figures the reviewer suggests.	Reply	I-Reply	1
These figures would already provide ample support for all of our conclusions regarding CLEAR.	Reply	I-Reply	1
[line_break_token][line_break_token]Further, presenting tasks cyclically is a natural model of learning in which similar experiences are revisited over and over.	Reply	I-Reply	1
Early researchers of human memory, e.g. Ebbinghaus, considered memorization tasks in which memorized items were recurrent and revisited several days in a row or over longer inter-experiment intervals.	Reply	I-Reply	1
Recurrent study experiments permit the evaluation of several effects, including the phenomenon of savings, in which forgotten memories are rapidly re-acquired with marginal subsequent study.	Reply	I-Reply	1
Here, we are also interested in demonstrating that repeated exposure to a task can be used to train the behavior of an agent.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: This is an interesting phenomenon!	Reply	O	0
It is a demonstration of genuine constructive interference or positive transfer in which learning other tasks promotes coherent exploratory behavior in natlab_varying_map_randomize.	Reply	B-Reply	2
This interference does not detract from the conclusions of the figure that catastrophic interference is present in this as in other tasks, that CLEAR fixes the problem, and that the ability of CLEAR to learn from new experience is unaffected by the amount of information already in the replay buffer.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: We understand the motivation behind this question, but the specific memory requirements depend on implementation, including the use of compression and caching techniques, which are engineering-level questions, and beyond the scope of what we can present in the paper, which is focused on the benefits that a mixture of on- and off-policy learning with behavioral cloning provides with respect to learning and forgetting.	Reply	O	0
Notably, the buffer can almost certainly be compressed considerably given the commonalities between experiences.	Reply	B-Reply	3
What memory requirements are unavoidable can leverage hard drive storage, with minimal RAM needed.	Reply	I-Reply	3
[line_break_token][line_break_token]Re Figure 5: The collection of results in the other figures are designed to show how a newly introduced task affects learning on other tasks.	Reply	O	0
In this experiment, we were specifically interested in one question: Does having a full replay buffer from past experiences on other tasks slow learning on a new task?	Reply	B-Reply	4
In Figure 5, note that the final performance obtained on the probe task doesn‚Äôt depend on whether it comes after another task, implying that learning the task is largely independent of the other tasks, except for the initial positive transfer.	Reply	I-Reply	4
[line_break_token][line_break_token]In the revision, we include a variation of the probe task experiment in Appendix B, in which we show that when using pure off-policy learning (instead of a mixture of on- and off-policy learning, as in CLEAR), the probe task does indeed decrease in performance when other tasks are learned before it.	Reply	I-Reply	4
CLEAR avoids this failure mode by blending new experience with replay.	Reply	I-Reply	4
[line_break_token][line_break_token]Re numerical comparison: Absolutely, and we are very grateful for the suggestion.	Reply	I-Reply	5
We have added tabulations of the cumulative sum of performance at the end of training for most experiments in Appendix C. We feel this measure captures both how quickly learning occurs and how much performance is maintained over the course of training on multiple tasks	Reply	I-Reply	5

This paper presents a method for conditional text generation that has higher factual precision, minimizing hallucination of facts.	Review	O	0
The method involves predicting confidence of generation at each time step and using this confidence measure to skip tokens during generation and calibrate output probabilities in test time.	Review	O	0
Their method achieves SoTA performance on automatically measured precision and human evaluated "faithfulness."	Review	O	0
However their method does see a drop in recall (automatic metric and human evaluation).	Review	O	0
[line_break_token][line_break_token]Comments and issues,[line_break_token]- The intuitive explanation for the confidence score is a little confusing.	Review	O	0
In Section 4, page 3, you say that "If a token is likely a content word (i.e. when its generation probability by the encoder-decoder is much higher than the unconditioned language model), but the attention score is low, then the token might not be predicted based on the source, and could be hallucination."	Review	B-Review	1
However, this doesn't seem like an airtight conclusion.	Review	I-Review	1
Isn't it possible that the base-LM and enc-dec model have similar probabilities for a content word with the enc-dec attention being low?	Review	I-Review	1
This seems possible given your observation that low attention to the source is what may be causing content hallucination.	Review	I-Review	1
This same thing is essentially restated in section 4.1 "we expect P(y_t |y_&lt;t, x) to be higher than P(y_t | y_&lt;t) for content words so the confidence score will largely depend on the attention score", which seems more tangled up since P(y_t |y_&lt;t, x) inherently depends on the attention score.	Review	O	0
This is all clarified when you explain the alteration made to the base-LM.	Review	B-Review	1
I would recommend rewording/rearranging some of the earlier explanation for the efficacy of the confidence score since it seems that the alteration to the base-LM is an essential part of the explanation.	Review	I-Review	1
[line_break_token]- Need some explanation for Equation 6.	Review	O	0
I don't really get the intuition behind it.	Review	B-Review	2
[line_break_token]- The presented results are pretty good!	Review	O	0
However, I would like to see some numbers on average score across a few runs.	Review	B-Review	3
[line_break_token]- It would also be good to see results on one more dataset like E2E.[line_break_token]- Provide a little more detail on human evaluation, you don't even mention if the evaluation was done with crowd-workers or another pool of people like grad students.	Review	O	0
How many annotators?	Review	B-Review	5
What is the inter-annotator agreement?	Review	I-Review	5
What was the prompt/structure?	Review	I-Review	5
Human evaluation of models is notoriously difficult, more details would give some more weight to the results.	Review	I-Review	5
[line_break_token][line_break_token]I think this is a well written paper with thought out experiments.	Review	O	0
I recommend it be accepted to ICLR.	Review	O	0
I'd also be curious to see some future work that improves, or at least maintains recall, while keeping the higher precision.	Review	B-Review	7
[line_break_token][line_break_token]Minor requests/recommendations: [line_break_token]- Include more examples of generations.	Review	O	0
Could be an appendix.	Review	B-Review	6
[line_break_token]	Review	O	0
hanks for the detailed review.	Reply	O	0
Reviewer #3 has suggested motivating our model designs better, describing more details about our human evaluation, and adding more generation examples.	Reply	B-Reply	5
We have added these in our revised paper.	Reply	I-Reply	5
[line_break_token][line_break_token]We have also done some extra work on additional runs and more datasets, as discussed below:[line_break_token][line_break_token]&gt; I would like to see some numbers on average score across a few runs[line_break_token][line_break_token]We do not have an average across multiple runs, but a second run of our model suggests that: similar BLEU and PARENT scores can be achieved by different runs, but the best performing hyper-parameters vary -- the chosen \rho, \gamma and \lambda reported in our paper do not always give the best results; it is better to sweep on these hyper-parameters.	Reply	O	0
[line_break_token][line_break_token]&gt; It would also be good to see results on one more dataset like E2E.[line_break_token][line_break_token]Actually, we had results on a second dataset: the RotoWire (Wiseman et al.	Reply	O	0
2017).	Reply	B-Reply	4
We did not use E2E because E2E seems simpler and has less source-reference divergence; we wanted to test on a more complicated and hallucination-prone dataset.	Reply	I-Reply	4
Our results on RotoWire are as follows:[line_break_token][line_break_token]Entity Modelling (Puduppully et al.	Reply	I-Reply	4
2019): BLEU 16.37  PARENT Prec.	Reply	I-Reply	4
34.68 Rec.	Reply	I-Reply	4
36.79 F1 34.47 Avg.	Reply	I-Reply	4
Len.	Reply	I-Reply	4
295[line_break_token]Content Planning (Puduppully et al.	Reply	I-Reply	4
2018): BLEU 16.85 PARENT Prec.	Reply	I-Reply	4
35.40 Rec.	Reply	I-Reply	4
40.41 F1 36.59 Avg.	Reply	I-Reply	4
Len.	Reply	I-Reply	4
332[line_break_token]Pointer-Generator: BLEU 9.15 PARENT Prec.	Reply	I-Reply	4
37.68 Rec.	Reply	I-Reply	4
36.48 F1 35.94 Avg.	Reply	I-Reply	4
Len.	Reply	I-Reply	4
251[line_break_token]Confident Pointer-Generator: BLEU 8.40 PARENT Prec.	Reply	I-Reply	4
42.64 Rec.	Reply	I-Reply	4
35.23 F1 37.69 Avg.	Reply	I-Reply	4
Len.	Reply	I-Reply	4
233[line_break_token][line_break_token]It seems that our Confident Pointer-Generator achieves SoTA PARENT Precision on RotoWire as well.	Reply	I-Reply	4
However, we did not report these results in our paper because we did not conduct human evaluation.	Reply	I-Reply	4
[line_break_token][line_break_token]&gt; I'd also be curious to see some future work that improves, or at least maintains recall, while keeping the higher precision.	Reply	O	0
[line_break_token][line_break_token]Absolutely.	Reply	B-Reply	7
To extend this approach and achieve high precision text generation on more complicated datasets is one of the major topics we are working on.	Reply	I-Reply	7

Summary[line_break_token]This paper tackles the problem of transferring a policy from source to target MDP, which differ in the state transition function.	Review	O	0
The idea is to add an additional cost that is the KL divergence between the trajectory likelihood under target policy (being learned) and target dynamics and the trajectory likelihood under the source policy (assumed optimal and deterministic) and source dynamics.	Review	O	0
The intuition is that the target policy will learn to match the state distribution of the optimal source policy.	Review	O	0
Results on MuJoCo locomotion robots with varying physics show that the proposed method performs better on target than warm-started RL or learning from scratch.	Review	O	0
[line_break_token][line_break_token]I think the problem of transferring knowledge from one task to another in RL is very important for RL to be applicable to more real-world scenarios.	Review	O	0
[line_break_token][line_break_token]Concerns / Questions[line_break_token]Line 7 of Alg1 is confusing because it refers to a ‚Äútarget task model‚Äù, but in Assumption 2, it says only a model of the source transition function is needed.	Review	O	0
I think it makes sense that only the source transition model is needed because the target next state is given by experience.	Review	B-Review	1
[line_break_token]I think the combined assumptions of a) access to expert behavior (same as DAGGER) and b) that the MDPs differ only in dynamics functions and c) access to the source transition model are rather strong.	Review	O	0
I think (b) is a special case of transfer learning - a lot of transfer learning is concerned with changing reward functions as well, which this method wouldn‚Äôt apply to.	Review	B-Review	5
I think this could be made more clear in the paper.	Review	I-Review	5
It would be good if all these assumptions were made clear and discussed.	Review	I-Review	5
[line_break_token]I think the related work section is missing important areas of research in imitation learning and meta-reinforcement learning.	Review	I-Review	6
For imitation learning, the approach strikes me as bearing similarity to PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings (Rhinehart et al.),	Review	I-Review	6
and the topic of imitation learning should be discussed in general.	Review	I-Review	6
For meta-RL, mentioning that it shares the same goal of transfer and citing a few main works (e.g. Duan et al.	Review	I-Review	6
2016, Wang et al.	Review	I-Review	6
2016, Finn et al.	Review	I-Review	6
2017 etc) would be good.	Review	I-Review	6
[line_break_token][line_break_token]Writing Suggestions[line_break_token]Some terms used throughout the paper are quite unclear (e.g., ‚Äúunsupervised RL‚Äù, ‚Äúintrinsic adaptation reward‚Äù, ‚Äúsupervised reference trajectory tracking‚Äù).	Review	O	0
I suggest standardizing and defining terms early to avoid unnecessary confusion.	Review	B-Review	7
[line_break_token]Writing the Bellman operator and the value function equations in Section 2 don‚Äôt seem very relevant as they are I think never used again?	Review	I-Review	8
[line_break_token]Sections 3.1 and 3.2 are quite difficult to understand on first read (e.g., what does ‚Äúpoint-wise local trajectories‚Äù mean?).	Review	I-Review	9
[line_break_token]I find Section 3.2.1 a bit misleading, ‚ÄúThe optimization is more akin to supervised learning‚Äù - I agree the KL minimization is essentially imitation learning, but you are still doing policy search in addition to it?	Review	I-Review	9
[line_break_token]	Review	O	0
e thank reviewer #2 for a detailed review of our work.	Reply	O	0
Following are our response to the reviews[line_break_token][line_break_token]1) In line 7, of Algorithm-1, "Propagate the target task model at state s_i and action a_i,": we meant Apply the action a_i at state s_i in the target task.	Reply	O	0
We do not need the target transition model; the target task could be a real agent or a simulation environment.	Reply	B-Reply	1
[line_break_token][line_break_token]2) The assumptions, as highlighted by the reviewer.	Reply	O	0
[line_break_token]    a) access to expert behavior (same as DAGGER):  [line_break_token]        We need a source policy.	Reply	O	0
[line_break_token][line_break_token]    b) MDPs differ only in dynamics function:  [line_break_token]       We can also handle cross-domain transfer where the target and source differ in the state and action space dimension and representation, apart from the model transition differences (please refer our cross-domain  domain transfer results in Appendix, Mountain-car to Inverted pendulum and Cart-pole to Bicycle transfer experiments)[line_break_token][line_break_token]    c) access to the source transition model[line_break_token]We do not need the true transition model for source and the target, but only assume to have access to a black box simulator model of the source (Assumption-2)[line_break_token][line_break_token]Given these corrections, we feel the assumptions are not very strong.	Reply	O	0
[line_break_token][line_break_token]Reviewer #2: I think (b) is a special case of transfer learning - a lot of transfer learning is concerned with changing reward functions as well, which this method wouldn't apply to.	Reply	O	0
[line_break_token][line_break_token]The existing Transfer learning architectures which aim at learning task by reward shaping [1-3] or learning an expert reward model and carrying out an Inverse-RL[4-5], do not enjoy similar reduced sample complexity as our method.	Reply	B-Reply	6
Methods like Inverse RL, Reward shaping, or Representation transfer are eventually an RL task and suffer the same curse of dimensionality as the RL problem.	Reply	I-Reply	6
[line_break_token][line_break_token]Hence we have demonstrated in this paper that adaptation of the learned policy is a more efficient way of transferring skills between tasks.	Reply	I-Reply	6
We will try to bring out these discussions more clearly in the paper.	Reply	I-Reply	6
[line_break_token][line_break_token]3) Thank you for pointing us to the additional references.	Reply	O	0
We will study and appropriately cite them in the future draft.	Reply	B-Reply	6
[line_break_token][line_break_token]4)We will incorporate the changes to define the terms more explicitly and early in the text for better clarity in the future draft.	Reply	O	0
[line_break_token][line_break_token]5) The definition of Bellman operator is provided for the sake of completeness and \epsilon-optimality proof (lemma-4.3) in the Appendix which uses the notion of the \gamma-contraction principle of the operator.	Reply	O	0
[line_break_token][line_break_token]6) Reviewer #2: "The optimization is more akin to supervised learning - I agree the KL minimization is essentially imitation learning, but you are still doing policy search in addition to it?"	Reply	O	0
[line_break_token][line_break_token]Agreed!	Reply	B-Reply	9
Environmental rewards are added to intrinsic adaptation rewards through reward mixing, which leads to policy search like architecture.	Reply	I-Reply	9
The reward mixing is done for two reasons[line_break_token]a)It aids sufficient exploration, thereby we need not only look into the direction of source behavior mapped onto the target task.	Reply	I-Reply	9
[line_break_token]b) Env reward also helps target agent to learn skills beyond what a source policy can teach.	Reply	I-Reply	9
[line_break_token][line_break_token]However, we do not need the reward mixing for every experiment.	Reply	I-Reply	9
For example, the Hopper env can be learned purely by adapting the source policy to the target agent.	Reply	I-Reply	9
 [line_break_token][line_break_token][line_break_token][1] Marco Colombetti and Marco Dorigo.	Reply	O	0
Robot shaping: developing situated agents through learning[line_break_token][2] Tom Erez and William D. Smart.	Reply	O	0
 What does shaping mean for computational reinforcement learn-ing?	Reply	O	0
[line_break_token][3] Maja J. Mataric.	Reply	O	0
Reward functions for accelerated learning.	Reply	O	0
International Conference on MachineLearning[line_break_token][4] Ramachandran, Deepak, and Eyal Amir. "	Reply	O	0
Bayesian Inverse Reinforcement Learning.	Reply	O	0
[line_break_token][5] Andrew Ng and S. Russell.	Reply	O	0
Algorithms for inverse reinforcement learning	Reply	O	0

The paper proposes to stack NMF models on top of each other.	Review	O	0
At each level, a non-linear function of normalized decomposition coefficients is used and decomposed using another NMF.	Review	O	0
[line_break_token][line_break_token]This is essentially an instance of a deep belief network, where the unsupervised learning part is done using NMF, which, to the best of my knowledge had not been done before.	Review	O	0
[line_break_token][line_break_token]The new method is then applied to document data where a hierarchy of topics seems to be discovered.	Review	O	0
Applications are also shown on reconstructing digits.	Review	O	0
[line_break_token][line_break_token]The extended abstract however does not give many details on all the specifics of the method.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token]-It would have been nice (a) to relate the hierachy to existing topic models [A,B], and (b) to see more topics.	Review	O	0
[line_break_token]-On Figure 2, why are reconstruction errors decreasing with the number of features?	Review	B-Review	2
[line_break_token]-On the digits, the differences between shallow and deep networks are not clear.	Review	I-Review	3
[line_break_token][line_break_token][A] D. Blei, T. Griffiths, and M. Jordan.	Review	O	0
  The nested Chinese restaurant process and Bayesian nonparametric inference of topic hierarchies.	Review	O	0
  Journal of the ACM, 57:2 1‚Äì30, 2010.	Review	O	0
 [line_break_token][line_break_token][B] R. Jenatton, J. Mairal, G. Obozinski, F. Bach.	Review	O	0
Proximal Methods for Hierarchical Sparse Coding.	Review	O	0
Journal of Machine Learning Research, 12, 2297-2334, 2011.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]-Interesting idea of stacking NMFs.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]-Experimental results are interesting but not great.	Review	O	0
What is exactly achieved is not clear.	Review	B-Review	4
- Points on the con that experimental results are not great:[line_break_token]When we refer to Figure 2 in the paper, the proposed hierarchical feature extraction method results in much better classification and reconstruction performance, especially for small number of	Reply	O	0

Summary:[line_break_token]This paper proposed an ensemble method (CIKD) that train multiple agents and[line_break_token]use knowledge distillation to transfer knowledge from the current best agent to[line_break_token]sub-optimal agents periodically.	Review	O	0
 According to the reported results, CIKD is a[line_break_token]simple yet effective approach to improve sample-efficiency and final performance.	Review	O	0
 [line_break_token]The experimental results are sufficient, and the ablation studies are conducted thoroughly.	Review	O	0
It is shown that both selecting the best agent and using KD to[line_break_token]transfer knowledge are effective comparing to other naive alternatives.	Review	O	0
[line_break_token][line_break_token][line_break_token]I recommend the acceptance of this paper.	Review	O	0
[line_break_token][line_break_token]The paper proposed a novel approach (CIKD) to improve the sample-efficiency of the state-of-the-art.	Review	O	0
The proposed ensemble approach is aligned with our intuition, and it is effective.	Review	O	0
The authors proposed to train several agents at the same time and randomly select one of[line_break_token]the agents as a behavior policy during each rollout.	Review	O	0
Then the collected trajectory is used to update the policy of all agents.	Review	O	0
Meanwhile,[line_break_token]they keep tracking the performance of each agent and use the current best agent to conduct knowledge distillation to other agents periodically.	Review	O	0
[line_break_token][line_break_token]This paper first conducts experiments to show when consolidating[line_break_token]the SAC with CIKD, both of the final performance and sample-efficiency can be improved.	Review	O	0
Then a set of ablation studies verified the best agent selection strategy, and the knowledge distillation[line_break_token]strategy is necessary for the ensemble method.	Review	O	0
[line_break_token][line_break_token][line_break_token]Investigation on the reasons for improvement:[line_break_token]Though extensive ablation studies have shown the effectiveness[line_break_token]of each component of CIKD.	Review	O	0
It is still not clear why this approach[line_break_token]can be effective.	Review	B-Review	1
[line_break_token]Intuitively, it is possible that the exploration from a set of agents would outperform[line_break_token]a single agent.	Review	I-Review	1
The measure of exploration efficiency could help in explaining the results.	Review	I-Review	1
Furthermore, better exploration not necessarily[line_break_token]leads to better performance and sample-efficiency.	Review	I-Review	2
Does knowledge distillation serve as a better alternative to exploit existing data?	Review	I-Review	2
[line_break_token][line_break_token]Model/algorithm agnostic[line_break_token]The proposed method is more convenient to be applied with off-policy approach when the policy is in the form of softmax.	Review	I-Review	3
Is it also applicable[line_break_token]to other approaches?	Review	I-Review	3
[line_break_token][line_break_token]Experiments:[line_break_token]How do you determine when to stop the KD process?	Review	O	0
As mentioned in section 5.5, if we conduce KD fully, all students would be just imitating[line_break_token]the teacher's behavior.	Review	B-Review	4
It seems the key is to tune a good termination[line_break_token]threshold for each task?	Review	I-Review	4
Are there any guidelines to set up this threshold?	Review	I-Review	4
[line_break_token]Do you have some automatic way to terminate the KD procedure?	Review	I-Review	4
[line_break_token][line_break_token][line_break_token]Minor:[line_break_token]L1, P5, "how to CIKD improves the sample efficiency" [line_break_token][line_break_token]	Review	O	0
e would like to thank the reviewer for reading our paper and providing feedback on our work.	Reply	O	0
We will address the reviewer‚Äôs various points here.	Reply	O	0
[line_break_token][line_break_token]- ‚ÄúThough extensive ablation studies have shown the effectiveness of each component of CIKD.	Reply	O	0
It is still not clear why this approach can be effective.	Reply	O	0
Intuitively, it is possible that the exploration from a set of agents would outperform a single agent.	Reply	O	0
The measure of exploration efficiency could help in explaining the results.	Reply	O	0
‚Äù[line_break_token][tab_token][line_break_token]The purpose of the Ensemble-SAC baseline was to investigate how CIKD itself improves upon Ensemble-SAC, since Ensemble-SAC may naturally benefit from improved exploration upon a single SAC agent.	Reply	O	0
In this way, we can decouple (to a certain degree), the benefits of an ensemble vs. the benefits of applying CIKD to an ensemble.	Reply	B-Reply	1
In future work, it would be interesting to perform more experiments and analyses on the effect of improved exploration and the benefit of distillation (e.g., through plotting the state-visitation frequencies or distilling the knowledge from a separate hand-crafted dataset as opposed to agent data).	Reply	I-Reply	1
[line_break_token][line_break_token]- ‚ÄúFurthermore, better exploration not necessarily leads to better performance and sample-efficiency.	Reply	O	0
Does knowledge distillation serve as a better alternative to exploit existing data?‚Äù[line_break_token][line_break_token]It is unclear how to compare various approaches to exploiting existing data, since there is no general framework for data exploitation.	Reply	O	0
However, we would like to highlight two of our experiments that investigated this question.	Reply	B-Reply	2
Off-policy RL offers an obvious way to exploit experiences.	Reply	I-Reply	2
In Section 5.3 (Fig.	Reply	I-Reply	2
3a), we performed an experiment where we tuned an Ensemble-SAC agent to perform additional off-policy RL updates.	Reply	I-Reply	2
We found that using CIKD with Ensemble-SAC outperforms Ensemble-SAC with additional RL updates.	Reply	I-Reply	2
Our second experiment, the ‚Äúhard-copy‚Äù experiment (Fig.	Reply	I-Reply	2
3b, Section 5.3), copies the best teacher into the students rather than performing distillation.	Reply	I-Reply	2
We found that distillation performs better than strictly hard-copying the best agent.	Reply	I-Reply	2
Interesting directions for future work include performing additional analyses on various data exploitation methods.	Reply	I-Reply	2
[line_break_token][line_break_token]- ‚ÄúModel/algorithm agnostic: The proposed method is more convenient to be applied with off-policy approach when the policy is in the form of softmax.	Reply	O	0
Is it also applicable to other approaches? ‚	Reply	O	0
Äú[line_break_token][line_break_token]Our method is certainly applicable to other approaches.	Reply	O	0
In particular, our KL Loss can be applied to other policy gradient approaches as long as the policy outputs a distribution and is differentiable, as is the case with most modern policy representations.	Reply	B-Reply	3
In principle, CIKD can be applied to value-based approaches as well by changing the distillation loss from a KL-Loss to another loss, such as mean-squared-error (MSE).	Reply	I-Reply	3
In fact, in our paper, we distill our critics using an MSE loss.	Reply	I-Reply	3
[line_break_token][line_break_token]- ‚ÄúHow do you determine when to stop the KD process?	Reply	O	0
As mentioned in section 5.5, if we conduce KD fully, all students would be just imitating the teacher's behavior.	Reply	O	0
It seems the key is to tune a good termination threshold for each task?	Reply	O	0
Are there any guidelines to set up this threshold?	Reply	O	0
Do you have some automatic way to terminate the KD procedure?‚Äù[line_break_token][line_break_token]We didn‚Äôt focus on optimizing the terminating threshold for distillation and found that CIKD worked quite well by randomly dividing the entire (bounded) replay buffer into several minibatches and performing distillation on all of these minibatches.	Reply	O	0
If this process were to be repeated infinitely, this would amount to imitation learning.	Reply	B-Reply	4
To verify that CIKD is not tantamount to pure imitation learning, we ran two key experiments.	Reply	I-Reply	4
In one experiment (Section 5.5, Figure 5d), we tested an alteration of CIKD where we re-initialized the student networks prior to distillation.	Reply	I-Reply	4
This amounts to pure imitation learning in that we have a randomly initialized student learning to directly imitate the teacher.	Reply	I-Reply	4
We found that pure imitation learning fails to perform as well as CIKD.	Reply	I-Reply	4
In Section 5.5 (Fig.	Reply	I-Reply	4
5c), we show that the student often outperforms the teacher after distillation.	Reply	I-Reply	4
Note that outperforming the teacher is atypical in imitation learning, which further supports that CIKD does not reduce to imitation learning.	Reply	I-Reply	4
Returning to the reviewer‚Äôs question, an interesting direction for future work is to investigate the tradeoff between pure imitation learning and a moderate amount of distillation.	Reply	I-Reply	4
But in this work, we found that CIKD achieved good performance with straightforward distillation termination conditions and is in fact superior to distilling via pure imitation learning.	Reply	I-Reply	4
[line_break_token][line_break_token]- ‚ÄúMinor: L1, P5, ‚Äòhow to CIKD improves the sample efficiency‚Äô‚Äù [line_break_token][line_break_token]We have corrected this mistake in the paper.	Reply	O	0

Summary:[line_break_token][line_break_token]Gradient clipping has been studied as an optimization technique and also as a tool for privacy preserving, but in this paper, it studies the robustness properties of gradient clipping.	Review	O	0
 More specifically, the main question of the paper is: Can gradient clipping mitigate label noise?	Review	O	0
 The paper reveals that the answer is no, but further proposes a simple variant of gradient clipping is robust and has nice property of classification calibration.	Review	O	0
 Experiments show that the proposed variant works under label noise.	Review	O	0
[line_break_token][line_break_token][line_break_token]Strength of the paper:[line_break_token][line_break_token]The motivation and goal of the paper is stated in the title and is very clear, making it easier to follow the story of the paper.	Review	O	0
 There are sufficient background on the loss functions and gradient clipping in the beginning that helps guide the reader.	Review	O	0
 The proposed method is robust to label noise and has theoretical guarantees.	Review	O	0
 The relationship between similar work is summarized.	Review	O	0
 Experiments have both synthetic and benchmark datasets to demonstrate the behavior of the proposed method.	Review	O	0
[line_break_token][line_break_token][line_break_token]Weakness of the paper:[line_break_token][line_break_token]Currently, the experiments only include methods studied in the paper.	Review	O	0
 It would be better to include baseline methods stated in the end of Section 5 or in Section 4.3.	Review	B-Review	1
[line_break_token][line_break_token]After response:[line_break_token]Thank you for the clarification!	Review	O	0
 I have read the other reviews and author comments.	Review	O	0
hanks for the feedback!	Reply	O	0
[line_break_token][line_break_token]We compare against the generalised cross-entropy (GCE) as this is (to our knowledge) a state-of-the-art loss-based technique for coping with label noise.	Reply	B-Reply	1
Note that the methods discussed in Sec 4.3 employ the same base loss as GCE.	Reply	I-Reply	1
[line_break_token][line_break_token]The methods listed at the end of Sec 5 are based on distinct, complementary ideas.	Reply	I-Reply	1
While certainly combining these with our clipped loss would be of interest, we wished to focus on our main message in the experiments (namely, the study of the viability of clipping to mitigate label noise)	Reply	I-Reply	1

The paper presents an approach to learning shared neural representations of temporal abstractions in hierarchical RL, based on actor-critic methods.	Review	O	0
The approach is illustrated in two tasks: gridworld with objects and a simplified Minecraft problem).	Review	O	0
 The idea of providing symbolic descriptions of tasks and learning corresponding "implementations" is potentially interesting and the empirical results are promising.	Review	O	0
 However, there are two main drawbacks of the current incarnation of this work.	Review	B-Review	1
 First, the ideas presented in the paper have all been explored in other work (symbolic specifications, actor-critic, shared representations).	Review	I-Review	1
 While related work is discussed, it is not really clear what is new here, and what is the main contribution of this work besides providing a new implementation of existing ideas in the context of deep learning.	Review	I-Review	1
The main contribution if the work needs to be clearly spelled out.	Review	O	0
 Secondly, the approach presented relies crucially on curriculum learning (this is quite clear from the experiments).	Review	B-Review	2
 While the authors argue that specifying tasks in simplified language is easy, designing a curriculum may in fact be pretty complicated, depending on the task at hand.	Review	I-Review	2
 The examples provided are fairly small, and there is no hint of how curriculum can be designed for larger problems.	Review	I-Review	2
Because the approach is sensitive to the curriculum, this limits the potential utility of the work.	Review	I-Review	2
It is also unclear if there is a way to provide supervision automatically, instead of doing it based on prior domain knowledge.	Review	I-Review	2
[line_break_token]More minor comments:[line_break_token]- The experiments are not described in enough detail in the paper.	Review	O	0
It's great to provide github code, but one needs to explain in the paper why certain choices were made in the task setup (were these optimized?	Review	B-Review	3
What's this the first thing that worked?)	Review	I-Review	3
Even with the code, the experiments as described are not reproducible[line_break_token]- The description of the approach is pretty tangled with the specific algorithmic choices.	Review	O	0
Can the authors step back and think more generally of how this approach can be formalized?	Review	B-Review	4
 I think this would help relate it to the prior work more clearly as well.	Review	I-Review	4
NOVELTY[line_break_token][line_break_token]As described in the related work section, our approach indeed shares a number of similarities in existing work on learning hierarchical policy representations.	Reply	O	0
Structurally the model is quite similar to the Option--Critic approach of Bacon & Precup; this is not intended to be a contribution of the paper.	Reply	O	0
What we claim to be novel are (1) the training condition (using discrete high-level policy representations without an explicit grounding or feature abstraction hierarchy) and (2) the objective (using the small amount of extra structure in the training data to decouple actors from critics across multiple tasks).	Reply	B-Reply	1
You mention that symbolic specifications have been explored in other work---as discussed in our earlier comment, we've done our best to describe the differences with nearest neighbors, but are not aware of any previous approaches that learn with as little high-level supervision as we use here.	Reply	I-Reply	1
Again, if you can let us know exactly what you have in mind we would greatly appreciate it!	Reply	O	0
[line_break_token][line_break_token]CURRICULA[line_break_token][line_break_token]The general curriculum learning approach (Algorithm 2) can construct a sampling distribution for any collection of tasks: it relies only on the sketch length and the current empirical performance of the model, both of which can be computed without any task-specific engineering.	Reply	O	0
The collections of tasks in this paper were in fact designed to give rise to particularly challenging curricula (no length-1 tasks, various subpolicies that appear only as constituents of very long tasks, etc.)	Reply	B-Reply	2
and demonstrate robustness to decisions about task selection and curriculum design.	Reply	I-Reply	2
[line_break_token][line_break_token]TASKS[line_break_token][line_break_token]We did most of our development on a restricted subset (only length-2 and length-3 sketches) of crafting domain tasks.	Reply	O	0
Generalization to longer crafting tasks, as well as generalization to the maze domain, worked out of the box without any modifications to the initial task design or tuning of hyperparameters.	Reply	B-Reply	2
As some evidence that the task design process is indeed reproducible, we are happy to point to follow-up work by Rob Fergus's group, who have already succeeded in reimplementing our tasks and evaluation for a different model architecture (<a href="https://uclmr.github.io/nampi/talk_slides/rob-nampi.pdf)."	Reply	O	0
target="_blank" rel="nofollow">https://uclmr.github.io/nampi/talk_slides/rob-nampi.pdf).</a	Reply	O	0

The authors design a program synthesizer that tries to satisfy per-instance specific syntactic and functional constraints,[line_break_token]based on sampling trajectories from an RL agent that at each time-step expands a partial-program.	Review	O	0
[line_break_token][line_break_token]The agent is trained with policy gradients with a reward shaped as the ratio of input/output examples that the synthesized program satisfies.	Review	O	0
[line_break_token][line_break_token]With the 'out-of-box' evaluation, the authors show that their agent can explore more efficiently the harder problems than their non-learning alternatives even from scratch.	Review	O	0
[line_break_token](My intuition is that the agent learns to generate the most promising programs)[line_break_token]It would be good to have a Monte Carlo Tree Search baseline on the'out-of-box' evaluation, to detect exploration exploitation trade-offs.	Review	O	0
[line_break_token][line_break_token]The authors show with the 'meta-solver' approach that the agent can generalize to and also speed up unseen (albeit easy-ish in the authors words) instances.	Review	B-Review	2
[line_break_token][line_break_token]Clarity: Paper is clear and nicely written.	Review	O	0
[line_break_token][line_break_token]Significance: Imagine a single program synthesizer that could generate C++/Java/Python/DSLs  programs and learn from all its successes and failures!	Review	O	0
This is a step towards that.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]+ Generating spec-following programs for different grammars.	Review	O	0
[line_break_token]+ partial tree expansion takes care of syntactic constraints.	Review	O	0
[line_break_token]Neutral[line_break_token]¬∑ The grammar and specification diversity may be too low to feel impressive.	Review	O	0
[line_break_token]¬∑ It would have been nicer by computing likelihood for unseen instances with unique and known solutions (that is, without finetuning).	Review	O	0
[line_break_token]Cons:[line_break_token]- No Tree Search baseline.	Review	O	0
[line_break_token]- No results on programs with control flow/internal state.	Review	O	0
We appreciate your insightful review comments.	Reply	O	0
We address the concerns and questions as follows:[line_break_token][line_break_token]> Have you considered any tree search baseline, for example, Monte-Carlo Tree Search?	Reply	O	0
[line_break_token][line_break_token]In our evaluation, the ESymbolic baseline is a tree search method, except that it expands the nonterminals in a deterministic depth-first fashion and does pruning using constraint solving (e.g. 2QBF) along the way.	Reply	B-Reply	1
For the proposed method, however, while the generated program that our model operates on indeed can be represented by a tree, the RL algorithm we use is essentially model-free, i.e. it is agnostic to the transition dynamics.	Reply	I-Reply	1
We agree with the reviewer that this approach can be further improved with a model-based approach such as MCTS, since we can track the dynamics easily, and presumably yields better performance than the current purely model-free approach.	Reply	I-Reply	1
On the other hand, as one of the main motivations of our work is to study how to cast the classical problem into a learning task, we have been focused on the comparison between learning and non-learning methods, instead of model-free and model-based methods.	Reply	I-Reply	1
However, it would be definitely interesting to explore more on the model-based methods for program synthesis, and we leave this to our future work.	Reply	O	0
[line_break_token][line_break_token]>  How about generalization without fine-tuning?	Reply	O	0
[line_break_token][line_break_token]Indeed, it would be great to generalize to unseen programs even without fine-tuning, but in the meta-learning setting, it is typically very hard as it requires a lot of samples not only in the data space but also in the task space, for which we only have around 200 tasks.	Reply	B-Reply	2
We did test the performance of the learner without fine-tuning, and, with no surprise, it turns out to perform worse than the out-of-the-box version.	Reply	I-Reply	2
 [line_break_token][line_break_token]On the other hand, this train-and-finetune fashion is becoming widely accepted by a number of recent works on meta-reinforcement-learning, for instance, ‚ÄúRecasting Gradient-Based Meta-Learning as Hierarchical Bayes‚Äù.	Reply	I-Reply	2
[line_break_token][line_break_token]> Programs seems too low level and lacks of control flow/internal state, which are common features in general programming language like C, Java, Python, etc.	Reply	O	0
[line_break_token][line_break_token]This is a great suggestion for our future work.	Reply	B-Reply	3
We believe learning programs from logical specifications in a general programming language is an important direction in artificial intelligence, and our work is a step towards this direction	Reply	I-Reply	3

The paper describes a new study about how to make dialogs more empathetic.	Review	O	0
[line_break_token]The work introduced a new dataset of 25k dialogs designed to evaluate the[line_break_token]role that empathy recognition may play in generating better responses [line_break_token]tuned to the feeling of the conversation partner.	Review	O	0
 Several model[line_break_token]set-ups, and many secondary options of the set-ups are evaluated.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]A lot of good thoughts were put into the work, and even though the techniques[line_break_token]tried are relatively unsophisticated, the work represents a serious attempt[line_break_token]on the subject and is of good reference value.	Review	O	0
[line_break_token][line_break_token]The linkage between the use of emotion supervision and better relevancy is interesting.	Review	O	0
[line_break_token][line_break_token]The dataset by itself is a good contribution to the community conducting studies in this area.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]The conclusions are somewhat fuzzy as there are too many effects[line_break_token]interacting, and as a result no clear cut recommendations can be made[line_break_token](perhaps with the exception that ensembling a classifier model trained[line_break_token]for emotion recognition together with the response selector is seen[line_break_token]as having advantages).	Review	O	0
[line_break_token][line_break_token]There are some detailed questions that are unaddressed or unclear from[line_break_token]the writing.	Review	B-Review	2
 See the Misc.	Review	I-Review	2
items below.	Review	I-Review	2
[line_break_token][line_break_token]Misc.	Review	I-Review	2
[line_break_token][line_break_token]P.1, 6th line from bottom: "fro" -> "from"[line_break_token][line_break_token]Table 1:  How is the "situation description" supposed to be related to the[line_break_token]opening sentence of the speaker?	Review	O	0
 In the examples there seems to be substantial[line_break_token]overlap.	Review	B-Review	4
[line_break_token][line_break_token]Figure 2, distribution of the 32 emotion labels used:[line_break_token]this is a very refined set that could get blurred at the boundaries between similar emotions.	Review	I-Review	5
[line_break_token]As for the creators of those dialogs,  does everyone interpret the same emotion label the same way?	Review	I-Review	5
[line_break_token]e.g. angry, furious; confident, prepared; ...; will such potential ambiguities impact the work?	Review	I-Review	5
[line_break_token]One way to learn more about this is to aggregate related emotions to make a coarser set,[line_break_token]and compare the results.	Review	I-Review	5
[line_break_token][line_break_token]Also, often an event may trigger multiple emotions, which one the speaker chooses to focus on[line_break_token]may vary from person to person.	Review	I-Review	6
 How may ignoring the secondary emotions impact the results?	Review	I-Review	6
[line_break_token]To some extent this is leveraged by the prepending method (with top-K emotion predictions).	Review	I-Review	6
[line_break_token]What about the other two methods?	Review	I-Review	6
[line_break_token][line_break_token]P. 6, on using an existing emotion predictor:  does it predict the same set of emotions[line_break_token]that you are using in this work?	Review	I-Review	7
[line_break_token][line_break_token]	Review	O	0
‚Äúthis is a very refined set that could get blurred at the boundaries between similar emotions.	Reply	O	0
‚Äù:[line_break_token] as mentioned in the paper, we consulted existing works on emotion classification, especially works that had provided previous datasets of similar nature (e.g., Skerry and Saxe 2015).	Reply	O	0
We decided to include all the emotion labels used in those previous works so that people who had used those datasets before could more easily transition to ours, possibly by using only the subset that had those emotion labels.	Reply	B-Reply	5
Distinction between similar emotions was not as important to us, since our main focus was generating situations to which Listeners could react with empathy, rather than distinguishing between them.	Reply	I-Reply	5
We selected a very fine-grained set of emotion labels so that researchers could group together similar emotions, as needed depending on the application they are interested in (and indeed there is a lot of work on how to cluster labels in a data-driven way, e.g. , Bengio et al 2010 [1]), though we do not try that here.	Reply	I-Reply	5
We reasoned that it is easier to group together after the fact than to separate and the focus of this work is not emotion classification.	Reply	I-Reply	5
 We also thought that keeping emotions that are similar but suggest some intensity gradation (e.g., angry vs. furious) could even be useful down the line for tasks such as grading emotion intensity, like the task 1 of SemEval 2018.	Reply	I-Reply	5
[line_break_token][line_break_token]‚Äúdoes everyone interpret the same emotion label the same way‚Äù: no, indeed, but the agreement between humans is high enough to get good signal, and this has been quantified -- for example, see Fig 1C in Skerry and Saxe 2015  (reference in the paper) that finds an accuracy of 65% for 20 labels (all part of our set of 32), where chance would be 5%.	Reply	O	0
[line_break_token]For an explicit feature-based analysis of similarity, relevant analyses of overlap of features and similarities can also be found in Skerry and Saxe 2015 -- in particular Figure 2 shows how labels (20 labels, that are included in our list of 32) relate to appraisal features (e.g., expectedness, future, familiarity, suddenness, etc), basic emotions, and the affective circumplex.	Reply	B-Reply	5
[line_break_token][line_break_token]‚Äú will such potential ambiguities impact the work?	Reply	O	0
[line_break_token]One way to learn more about this is to aggregate related emotions to make a coarser set,[line_break_token]and compare the results.	Reply	O	0
‚Äù ‚ÄúWhat about [multitask and ensemble]?‚Äù:  With supervised fine-tuning or concatenating representations (the multitask and ensemble settings), the representation used in the model is taken before a single winner is outputted, so there isn‚Äôt an information loss caused by the winner-take-all process of outputting a single label  -- however, it is definitely possible that having better clustering of emotions could focus learning on more crucial information than distinguishing whether someone is ‚Äúangry‚Äù or ‚Äúfurious‚Äù while they‚Äôre actually somewhere in between, and this could be tested in future work, for example in conjunction with existing methods to combine labels.	Reply	O	0
Thanks for the suggestion.	Reply	B-Reply	5
[line_break_token]As you also mention, ‚ÄúTo some extent this is leveraged by the prepending method (with top-K emotion predictions).‚Äù -- and indeed that was our reason for experimenting with K > 1.	Reply	O	0
[line_break_token][line_break_token]‚Äúon using an existing emotion predictor:  does it predict the same set of emotions[line_break_token]that you are using in this work?‚Äù  all of the emotion predictors that we use from other works were trained with different sets of labels than what we use, and not directly emotions (e.g., emojis), however we fine-tune the deepmoji+ model on our set of labels.	Reply	O	0
The deepmoji paper presents many experiments on transferring their emoji classification learning to multiple loosely emotion-related tasks, like sentiment classification (Table 9 in the appendix lists many of those datasets.)	Reply	B-Reply	7
One of those datasets is the ISEAR set, which uses labels that we did include in our list and which also starts from short situation descriptions, so we had reason to believe that deepmoji could transfer well to our task.	Reply	I-Reply	7
[line_break_token][line_break_token][1] Bengio, S., Weston, J. and Grangier, D., 2010.	Reply	O	0
Label embedding trees for large multi-class tasks.	Reply	O	0
In Advances in Neural Information Processing Systems (pp.	Reply	O	0
163-171).	Reply	O	0

# Review ICLR20, RGBD-GAN[line_break_token][line_break_token]This review is for the originally uploaded version of this article.	Review	O	0
Comments from other reviewers and revisions have deliberately not been taken into account.	Review	O	0
After publishing this review, this reviewer will participate in the forum discussion and help the authors improve the paper.	Review	O	0
[line_break_token][line_break_token]## Overall[line_break_token][line_break_token]The article proposes a method of modifying image-generating networks to also produce depth maps in an unsupervised way by enforcing rotational consistency.	Review	O	0
[line_break_token][line_break_token]I enjoyed reading this work and I'm recommending it to be accepted.	Review	O	0
However, first there are some (in my opinion straight-forward) changes that need to be made to this work before I can recommend its publication: [line_break_token][line_break_token]- The common "Related Works" section is missing and some of the literature is taking place in the introduction.	Review	O	0
I find this unorganized and I'd recommend keeping the intro shorter and just moving the literature either behind the intro or to the end of the paper.	Review	B-Review	1
[line_break_token]- Most figures and especially your headline figure (1) suffer from not having the depth normalized and not having a scale to it.	Review	O	0
The fix for this is simple and two-fold: for each depth image, subtract the minimum value and divide by the range (to normalize it and increase contrast), then write in the caption or as a legend that white is closer to the camera and black is further back.	Review	B-Review	2
[line_break_token]- 3D vs. 2.5D - If the common geometric definition of "3D" was applied here, the article's title was correct.	Review	O	0
However, in computer vision and especially 3D vision, the term is commonly used to refer only to models that include full scene geometry, including the occluded backs of objects and the term 2.5D is used to describe assigning depth values to pixels in an RGB image (and therefore only covering the view-dependent front of the object), which I think is the case here.	Review	B-Review	3
However, this is not a hill that I'll die on so if you insist on that terminology, I won't block acceptance.	Review	I-Review	3
[line_break_token]- When you first discuss HoloGAN, you mention one of its main downsides being scalability and then proceed to not only explain that but also use a HoloGAN-like architecture in one of your experiments.	Review	O	0
I'd either remove the scalability argument or justify not just that but also how that's not relevant to your experiments.	Review	B-Review	4
[line_break_token]- The following phrase occurs multiple times throughout: "camera parameter conditional image generation".	Review	O	0
I _think_ you're missing a dash between "parameter" and "conditional".	Review	B-Review	5
[line_break_token][line_break_token][line_break_token]## Specific comments and questions[line_break_token][line_break_token]### Abstract[line_break_token][line_break_token]All good.	Review	O	0
[line_break_token][line_break_token]### Intro[line_break_token][line_break_token]- Fig.1 normalize image [line_break_token]- The literature section in intro mentions "For all methods, 3D annotations must be used..." - that's not true.	Review	O	0
See [Rezende, 2016][1] and [Rajeswar, 2018][2][line_break_token]- I understand how some literature is required to position your method, but I think it's better to not have the entire literature section in the center of the introduction[line_break_token][line_break_token][1]: <a href="https://arxiv.org/abs/1607.00662" target="_blank" rel="nofollow">https://arxiv.org/abs/1607.00662</a>[line_break_token][2]: <a href="https://openreview.net/forum?id=BJeem3C9F7" target="_blank" rel="nofollow">https://openreview.net/forum?id=BJeem3C9F7</a>[line_break_token][line_break_token]### Method[line_break_token][line_break_token]- 2.1 clear + nicely written[line_break_token]- Figure 2 good, caption a bit too short - figure+caption should be able to stand on their own[line_break_token]- Illustration of Figure 3 nice, except for unclear DeepVoxel part: what's the wavy orange flag stand for?	Review	O	0
[line_break_token][line_break_token]### Experiments[line_break_token][line_break_token]- You mention K is fixed, but where does the initial K come from?	Review	O	0
I assume it's just neglected (since it's not important for StyleGAN/PGGAN), but then this needs to be mentioned in the methods sections closer to the formulas dealing with K.[line_break_token]- Figure 4 - the depth maps need to be normalized.	Review	O	0
All we see here is a grey mush, even worse in Fig.	Review	B-Review	13
7[line_break_token]- For ShapeNet cars, the model seems to suffer from not having a reference for the top and bottom of the image - have you tried adding floor/sky?	Review	O	0
[line_break_token]- Figure 6, the tire marker is a good idea but image still unclear - I recommend slightly less rotation or an intermediate step between generated image and e.g. front view[line_break_token]- For quantitative results/FID: try using Hausdorff or Chamfer distance on the rendered scenes' pixels.	Review	O	0
We don't care about the goodness of the RGB generation but the depth.	Review	B-Review	16
[line_break_token][line_break_token]### Conclusion[line_break_token][line_break_token]All good, albeit a bit short.	Review	O	0
[line_break_token][line_break_token]### Appendix[line_break_token][line_break_token]I don't think I saw any references to the appendix in the main paper.	Review	O	0
e would like to thank the reviewer for valuable comments.	Reply	O	0
[line_break_token][line_break_token]Related works[line_break_token]- We will separate the related work section from the introduction section.	Reply	O	0
[line_break_token][line_break_token]Depth visualization[line_break_token]- We will normalize the depth maps and visualize it in colormap (as reviewer2 says) for better visualization.	Reply	O	0
[line_break_token][line_break_token]3D vs. 2.5D[line_break_token]- Our model can not only generate RGBD images, which is commonly considered 2.5D, but also explicitly control camera poses while preserving the image content.	Reply	O	0
Therefore, it can be regarded that the model can learn full 3D geometry implicitly, though the output is not fully 3D. This is the intuition to use the word "3D".	Reply	B-Reply	3
[line_break_token][line_break_token]Scalability of HoloGAN[line_break_token]- We agree that the badness of the scalability of HoloGAN is not supported by our experimental results.	Reply	O	0
Therefore, we will delete the scalability part from the introduction.	Reply	B-Reply	4
[line_break_token][line_break_token]Necessity for 3D annotations[line_break_token]- Thank you for introducing related papers.	Reply	O	0
Though they do not need annotations, both methods can only deal with synthetic primitive datasets.	Reply	B-Reply	7
Our method, however, can work on natural images.	Reply	I-Reply	7
We will add the discussion to the related works section.	Reply	I-Reply	7
[line_break_token][line_break_token]wavy flag[line_break_token]- This is a conceptual figure of learned DeepVoxels.	Reply	O	0
DeepVoxels are implicit representations, and we cannot visualize what is acquired.	Reply	B-Reply	11
We agree that the figure is ambiguous, we will replace the figure.	Reply	I-Reply	11
[line_break_token][line_break_token]About K[line_break_token]- Because learning K from single images is difficult, we initialize K with [[2s, 0, s/2], [0, 2s, s/2], [0, 0, 1]] (numpy-style order), where is image size.	Reply	O	0
We will add the explanation in the paper.	Reply	B-Reply	12
[line_break_token][line_break_token]floor/sky[line_break_token]- We did not try adding floor or sky to render the ShapeNet car dataset.	Reply	O	0
We think adding simple sky or floor will help learning depth information to some extent, but it is difficult to learn consistent depth.	Reply	B-Reply	14
This is because foreground regions have common salient concepts across views (eg.	Reply	I-Reply	14
tire, headlight, window, ...) but the background does not.	Reply	I-Reply	14
This is also problematic when we train the model on a car image dataset, which has floor and sky, as shown in Figure 7.	Reply	I-Reply	14
[line_break_token][line_break_token]Evaluation for depth[line_break_token]- Evaluating the generated depth is difficult because we cannot obtain ground truth depth for the generated images.	Reply	O	0
A possible approach to evaluate depth images without ground truth images is calculating the inception score (IS) [5] or FID on the generated depth images, but we do not think it is appropriate.	Reply	B-Reply	16
This is because IS and FID are estimated in the feature space of a pre-trained CNN, and they cannot consider the geometry in the 3D world.	Reply	I-Reply	16
Therefore it is almost impossible to evaluate how the generated depth is plausible in 3D space.	Reply	I-Reply	16
Instead, we will evaluate the depth consistency across views to quantitatively compare the generated depth among different methods.	Reply	I-Reply	16
When we plot point clouds generated from the same but different, all points should be on a single surface.	Reply	I-Reply	16
Therefore, by calculating the variation of the generated depth, we can quantitatively evaluate the 3D consistency across views.	Reply	I-Reply	16
It is expected that 3D-latent-feature-based models have better performance than other models.	Reply	I-Reply	16
We will add the results in the paper.	Reply	I-Reply	16
[line_break_token][line_break_token][5] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.	Reply	O	0
Improved techniques for training gans.	Reply	O	0
In NIPS, 2016	Reply	O	0

The authors present a method for training probabilistic models by maximizing a stochastic variational-lower-bound-type objective.	Review	O	0
Training involves sampling and then learning a transition-based inference to "walk back" samples to the data.	Review	O	0
Because of its focus on transitions, it can be used to learn a raw transition operator rather than purely learning an energy-based model.	Review	O	0
The objective is intuitively appealing because of its similarity to previous successful but less principled training methods for MRFs like Contrastive Divergence.	Review	O	0
[line_break_token][line_break_token]The idea for the algorithm is appealing, and it looks like it could find a nice place in the literature.	Review	O	0
However, the submission in its current form is not yet ready for publication.	Review	O	0
Experiments are qualitative and the generated samples are not obviously indicative of a high model quality.	Review	O	0
As pointed out elsewhere, the mathematical analysis does not currently demonstrate tightness of the variational bound in the case of a learned transition operator.	Review	O	0
More evaluation using e.g. annealed importance sampling to estimate held-out likelihoods is necessary.	Review	B-Review	1
Assuming that the analysis can be repaired, the ability to directly parametrize a transition operator, an interesting strength of this method, should be explored in further experiments and contrasted with the more standard energy-based modeling.	Review	I-Review	1
[line_break_token][line_break_token]This looks like a promising idea, and other reviews and questions have already raised some important technical points which should help strengthen this paper for future submission.	Review	O	0
An appendix was added which clarifies the conditions under which the approximation of the true posterior by the variational estimator Q becomes tight (basically hinging on a slow annealing).	Reply	B-Reply	1
However, keep in mind that even though Q does not match the true posterior, like for any other variational method, we are optimizing a valid bound on the log-likelihood	Reply	I-Reply	1

This paper tries to propose a new method to stabilize the training procedure of GAN.	Review	O	0
To this end, they use adversarial samples of real data to train the discriminator, and claim that it is helpful to reduce the adversarial noise contained in the gradient.	Review	O	0
Although training GAN with adversarial samples of discriminator is somewhat novel, the method and experiments are not convincing.	Review	O	0
[line_break_token]I do not recommend the acceptance based on the limited contribution of this paper.	Review	O	0
The following is a detailed evaluation.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
The paper uses vague description such as ‚ÄúThis approach can improve the robustness of discriminator and reduce adversarial noise contained in gradient‚Äù without convincing justification.	Review	B-Review	1
Please give a formal description or notation of ‚Äúadversarial noise contained in gradient‚Äù, and discuss how to remove the effect of ‚Äúadversarial noise‚Äù in principle instead of extensively testing adversarial training of discriminator.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The experiment is not convincing and the improvement is not significant.	Review	B-Review	2
The author running adversarial training on CIFAR10 dataset with FGSM and the perturbation is tested from 0.2/255 ~ 4/255.	Review	I-Review	2
The performance (FID score) is a bit sensitive to the amount of perturbation level.	Review	I-Review	2
Moreover, this The improvement over DCGAN is quite limited given previous works such as WGAN-GP.	Review	I-Review	2
Combined together, the result is not convincing (it seems to be a heavy tuning result rather than a principled solution).	Review	I-Review	2
hank you for your thoughtful and detailed review.	Reply	O	0
We will address your concerns one by one below.	Reply	O	0
[line_break_token][line_break_token]1 . ‚	Reply	O	0
ÄùThe paper uses vague description such as ‚ÄúThis approach can improve the robustness of discriminator and reduce adversarial noise contained in gradient‚Äù without convincing justification.	Reply	O	0
Please give a formal description or notation of ‚Äúadversarial noise contained in gradient‚Äù, and discuss how to remove the effect of ‚Äúadversarial noise‚Äù in principle instead of extensively testing adversarial training of discriminator.	Reply	O	0
‚Äù[line_break_token][line_break_token]Response: [line_break_token]We will make description of main claim more clear in the revised version.	Reply	O	0
Adversarial noise means the component in gradient of discriminator used to update generated images, which can not improve the fidelity of generated images but can drastically change the prediction of the discriminator.	Reply	B-Reply	1
Existence of adversarial noise is because the decision boundary of discriminator is not ideal ,ie, discriminator as a classifier realized by a neural network is vulnerable to small well-crafted perturbation, eg, perturbation in gradient direction, which is an universal property of neural networks [1]. Intuitively, adversarial noise as guide signal can mislead generator so as to make training unstable.	Reply	I-Reply	1
To this end, we introduce adversarial training on real samples that does not exist in GAN training framework, which can make discriminator more robust and smooth the decision boundary so as to reduce adversarial noise.	Reply	I-Reply	1
This can be validated by the gradient visualization shown as Fig 1.	Reply	I-Reply	1
Gradient given by standard discriminator seems like noise but gradient given by adversarially trained discriminator contains less noise and more semantic information, eg, profile of face.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
The experiment is not convincing and the improvement is not significant.	Reply	O	0
The author running adversarial training on CIFAR10 dataset with FGSM and the perturbation is tested from 0.2/255 ~ 4/255.	Reply	O	0
The performance (FID score) is a bit sensitive to the amount of perturbation level.	Reply	O	0
Moreover, this The improvement over DCGAN is quite limited given previous works such as WGAN-GP.	Reply	O	0
Combined together, the result is not convincing (it seems to be a heavy tuning result rather than a principled solution).	Reply	O	0
[line_break_token][line_break_token]Response:[line_break_token]It is reasonable that FID score is sensitive to perturbation level because too small perturbation (0~0.1/255 ) can not improve the robustness of discriminator and too large perturbation (&gt;5/255) can drastically degrade real samples so as to mislead discriminator, which is clarified in Sec 3.4 and 4.1 .	Reply	O	0
We validated that best performance improvement can be achieved with default setting of perturbation level (1/255 on image generation tasks) on CIFAR10, CelebA, LSUN with DCGAN and ResNet architecture.	Reply	B-Reply	2
FID score is improved about 50% on CelebA, and 35% on LSUN.	Reply	I-Reply	2
This is a significant improvement, which can not be realized by parameter tuning.	Reply	I-Reply	2
We do not use other tricks to improve FID score.	Reply	I-Reply	2
Suitability of default perturbation level is quite well and it is not required for heavy searching of perturbation level when applying the proposed method on other datasets with different network architectures.	Reply	I-Reply	2
Extensive experiments validated that improvement is general and of principle but does not depend on heavy hyper-parameter tuning.	Reply	I-Reply	2
Moreover, the proposed method is much efficient than gradient penalty.	Reply	I-Reply	2
[line_break_token]Here is comparison of average training time of one epoch measured on single RTX 2080ti.	Reply	I-Reply	2
[line_break_token]----------------------------------------------------------------------------------------[line_break_token]Setting              DCGAN   AS-DCGAN(ours)   SN-DCGAN  DCGAN-GP[line_break_token]Training time   19.83s     26.40s                      24.50s          31.57s[line_break_token]----------------------------------------------------------------------------------------[line_break_token][line_break_token]Thank you for your review!	Reply	O	0
[line_break_token][line_break_token][1] Szegedy C, Zaremba W, Sutskever I, et al.	Reply	O	0
Intriguing properties of neural networks[J]. arXiv preprint arXiv:1312.6199, 2013.	Reply	O	0
[line_break_token]	Reply	O	0

The authors present an algorithm for actively learning the nodes in a graph that should be sampled/labeled in order to improve classifier performance the most.	Review	O	0
The proposed techniques use both the graph structure, and the current classifier performance/accuracy into account while (actively) selecting the next node to be labeled.	Review	O	0
[line_break_token][line_break_token]There seem to be two main contributions in the paper.	Review	O	0
1) The propose to sample nodes nodes based on "regional" uncertainty rather than node uncertainty 2) They use an variant of pagerank to determine nodes that are central, and hence most likely to affect subsequent classification in graph convolution classifiers.	Review	O	0
Both approaches seem to be interesting.	Review	O	0
There are experiments to show effectiveness of these techniques, and there are some interesting observations (for example, that the APR technique works better for smaller sample sizes, while the regional uncertainty methods do better for larger sampling fractions.).	Review	O	0
[line_break_token][line_break_token]While both techniques seem straightforward extensions of previous approaches (and are well explained in the paper),  the experiments indicate that they work better than prior approaches.	Review	O	0
It would have been nice if the authors had also discussed ways in which one or more of these techniques could be combined though, or discussed how we could pick the right approach (in a more empirical way, since it is not clear what the threshold for high sampling rate/low sampling rate distinction is, or if it varies from problem to problem)	Review	B-Review	1
eviewer 1 has one main critique, which is that there is no clear explanation of how to choose in advance a method.	Reply	O	0
This critique is also shared by the second reviewer.	Reply	O	0
Following both comments reviews, we now add a clear section on how to choose among the different algorithms that we propose.	Reply	O	0

The paper presents an improved analysis of the signSGD gradient estimator.	Review	O	0
The authors propose to relax the requirements on the gradient estimator in Bernstein (2019).	Review	O	0
The only requirement imposed on the gradient is that it should have the correct sign with probability greater than 1/2.	Review	O	0
In particular this approach allows the gradient estimate to be biased as opposed to Bernstein (2019) which requires unbiased gradients.	Review	O	0
The authors also show this condition to be necessary by a small counterexample.	Review	O	0
[line_break_token][line_break_token]In my view the paper presents a relatively minor but still interesting extension of the work in Bernstein (2019).	Review	O	0
The main problem is that the relaxation is not well motivated in terms of scenarios where this might be applicable.	Review	B-Review	1
Experimental validation is also very weak.	Review	I-Review	3
[line_break_token][line_break_token]It is claimed in the experiment section that the stochastic gradient of the Rosenbrock function g(x) = \del f_i(x) + eps, where eps is a 0-mean Gaussian and i is uniform random is biased.	Review	I-Review	2
This seems incorrect to me and the gradient estimate should be unbiased when the expectation is taken over the randomness in i and eps.	Review	I-Review	2
[line_break_token][line_break_token]A key claim of the paper is the ability to use biased gradient estimates.	Review	I-Review	3
Experimental validation of this (in light of the above) is completely missing.	Review	I-Review	3
[line_break_token][line_break_token]The experiments that are presented on MNIST are very general and not very closely connected to the specific claims of the paper.	Review	I-Review	3
The only real conclusion drawn is that larger batch sizes improve convergence.	Review	I-Review	3
[line_break_token][line_break_token]I think the paper needs better targeted experiments.	Review	I-Review	4
They need to show covergence in a case where the conditions in Berstein (2019) do not hold.	Review	I-Review	4
[line_break_token][line_break_token]How are the properties of the \rho norm related to the observations on l_1 norm for high and l_2 norm for low SNR components in Bernstein (2019)?	Review	I-Review	5
If they are related this should be referenced.	Review	I-Review	5
[line_break_token]	Review	O	0
e motivated the relaxation by comparing it with 4 different conditions used in the literature: 1) unimodal symmetric noise assumption.	Reply	B-Reply	1
2) Strong growth condition with fixed mini-batch size.	Reply	I-Reply	1
3) Adaptive mini-batch size.	Reply	I-Reply	1
4) Bounded variance assumption in the sense of uncertainty.	Reply	I-Reply	1
[line_break_token][line_break_token]In fact the stochastic gradient of the Rosenbrock function considered in the paper is biased as expectation gives 1/(d-1) times the function itself.	Reply	I-Reply	2
[line_break_token]*We will add better targeted experiments.*	Reply	I-Reply	4
[line_break_token][line_break_token]The observation on low/high SNR components in (Bernstein et al.,	Reply	I-Reply	5
2019) were done under the unimodal symmetric noise assumption.	Reply	I-Reply	5
Similar observation is done in our paper for rho_norm and the second half of section 3 (including figure 1) is devoted just to that.	Reply	I-Reply	5
[line_break_token]*We added an explicit reference to (Bernstein et al.,	Reply	I-Reply	5
2019) at the end of section 3.	Reply	I-Reply	5

POST-REBUTTAL FEEDBACK[line_break_token][line_break_token]Thanks for your response.	Review	O	0
[line_break_token][line_break_token]The justifications provided in the response have not convinced me to improve my score.	Review	B-Review	10
They are at times hard to understand: For example, the authors have claimed that while their design choice is not reasonable, it is less unreasonable than the other.	Review	I-Review	10
[line_break_token][line_break_token]SUMMARY OF REVIEW[line_break_token][line_break_token]The authors have proposed the use of a neural surrogate model in place of the GP posterior mean and a weighted Reptile algorithm to meta-learn the initial weights of the neural surrogate model.	Review	O	0
This approach appears interesting.	Review	O	0
However, there seems to be multiple highly restrictive (at times impractical) assumptions in this work that are atypical of the BO setting adopted by other meta BO algorithms and not discussed, as detailed below.	Review	O	0
Justifications are required.	Review	O	0
[line_break_token][line_break_token]Clarifications are also needed with regards to how they exactly run their algorithm in the experiments and whether the prior/initial information from related problems/meta tasks provided to the tested algorithms is fair.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]DETAILED COMMENTS[line_break_token][line_break_token]The authors say that "We still use the variance in Eq. (	Review	O	0
4) to measure uncertainty, because the estimation uncertainty should be independent in individual problems."	Review	B-Review	1
This does not seem to hold true.	Review	I-Review	1
If a meta task or train set is indeed correlated (or provides information) to the new problem, the posterior variance/uncertainty at a point depends on the observations in the meta task or train set near to this point (see, for example, [line_break_token]Feurer et al. (	Review	I-Review	1
2018)).	Review	I-Review	1
Can the authors discuss the implications of such an assumption in their work?	Review	I-Review	1
[line_break_token][line_break_token]Q and Q_i have always been referred to as problems.	Review	I-Review	2
In Algorithm 3, Q is suddenly referred to as meta train set.	Review	I-Review	2
On page 4, you have said that x^*_i is the minimizer of i-th problem Q_i(x) in meta train set.	Review	I-Review	2
Based on these information, I assume that the authors consider x^*_i as the global minimizer and that x^*_i is known in order to compute the rewards.	Review	I-Review	2
Can the authors discuss why is this a reasonable assumption?	Review	I-Review	2
[line_break_token][line_break_token]In their proposed weight Reptile algorithm (Algorithm 3), the authors have also assumed access to the black-box functions of the related problems or meta tasks, which is not typical of other meta BO works that only require the existing observations or datasets of the related problems/meta tasks.	Review	I-Review	9
As a result, compared with the existing meta BO algorithms, their proposed weighted Reptile is considerably more expensive due to the need to additionally evaluate the black-box functions of the related problems or meta tasks many times during execution.	Review	I-Review	9
Can the authors discuss the practical implications of such an assumption and how it affects the types of problems/applications that can be considered by this work?	Review	I-Review	9
[line_break_token][line_break_token]The authors have not provided any justification for their choice of reward on page 4.	Review	I-Review	10
If the black-box function is indeed complex and highly varying, the distance between points may not work well at all.	Review	I-Review	10
Can the authors provide a justification and discuss the practical implications and limitations with such a choice?	Review	I-Review	10
[line_break_token][line_break_token]Isn't it more natural to consider a single Bayesian neural network instead of using a neural network for the mean and a GP for the variance?	Review	I-Review	11
[line_break_token][line_break_token]For the experiments, it would be good to see two other variants of the proposed algorithm to understand the individual contributions of the neural surrogate model and weighted Reptile algorithm: one without neural surrogate model and the other with simply the use of neural surrogate model.	Review	I-Review	3
[line_break_token][line_break_token]Can the authors explain in greater detail how they run their algorithms (Algorithms 2 and 3) in the experiments?	Review	I-Review	12
For example, the authors say that "WRA-N starts with learned initial surrogate model".	Review	I-Review	12
I assume that WRA-N refers to Algorithm 3 based on its acronym.	Review	I-Review	12
Isn't the learned initial surrogate model the output of WRA-N in the first place?	Review	I-Review	12
Also, the graphs in Fig.	Review	I-Review	12
2 seem to show iteration 1 to 13 in NOE (Algorithm 2).	Review	I-Review	12
However, Algorithm 3 accepts N_T = 13 and executes NOE for N_T = 13 (and not 1, 2, or 3, ...) for each problem in each epoch.	Review	I-Review	12
How do the authors generate the plot of WRA-N for iterations 1 to 12?	Review	I-Review	12
[line_break_token]What seems to make more sense to me is that the authors in fact run Algorithm 2 instead of Algorithm 3 for each experiment and they initialize w in Algorithm 2 to the output of Algorithm 3.	Review	I-Review	4
In any case, a clarification is needed here.	Review	I-Review	4
[line_break_token][line_break_token]It is not clear to me whether the initial/prior information from related problems/meta tasks provided to WRA-N, TST-R, AND TSR-M is fair.	Review	I-Review	13
Can the authors provide a justification?	Review	I-Review	13
[line_break_token][line_break_token]To clarify, for each related problem/function, only N_T number of datapoints are used to train a corresponding neural network with 1 hidden layer of 15 hidden units?	Review	I-Review	5
[line_break_token][line_break_token]The authors say that "Since TST-R needs base models for combination, we sample 20 points from uniform distribution in (‚àí10, 10) to construct base models."	Review	I-Review	6
Is this sampling procedure the same as that in (Wistuba et al.,	Review	I-Review	6
2016)?	Review	I-Review	6
[line_break_token][line_break_token]Can the authors explain the comparable performance of WRA-N and TST-R in Fig.	Review	I-Review	7
5?	Review	I-Review	7
Why are the error bars missing?	Review	I-Review	7
[line_break_token][line_break_token]How does the proposed approach compare with that of Feurer et al. (	Review	I-Review	8
2018)?	Review	I-Review	8
[line_break_token][line_break_token][line_break_token][line_break_token]Minor issues[line_break_token][line_break_token]Page 1, 3: adapt well to new tasks.	Review	I-Review	14
[line_break_token]Page 2: The author says "depends on a GP-based surrogate model fitting function values without learnable parameters".	Review	I-Review	14
This is not true: The GP hyperparameters need to be learned and they adapt to new problems.	Review	I-Review	14
[line_break_token]Page 4: descent order?	Review	I-Review	14
[line_break_token]Pages 4, 5: Why is there an input x to Q_i?	Review	I-Review	14
[line_break_token]Algorithm 2: t^* should be at the superscript of x.[line_break_token]Equation 7: What is N?	Review	I-Review	14
[line_break_token]Page 5: Does it make a difference in the performance when delta is set to 0?	Review	I-Review	14
[line_break_token]Page 5: well define meta-features?	Review	I-Review	14
hanks for your review,[line_break_token]1 Feurer et al. (	Reply	O	0
2018) used linear combination of variance of related problems.	Reply	B-Reply	1
It is not reasonable,  first as the variance of  related problems is not determinate as it depends on sampling points.	Reply	I-Reply	1
Thus different sampling points can cause different variance, then cause different surface in new problem.	Reply	I-Reply	1
Second, in related problems, lower variance means lower uncertainty, then should this lower uncertainty bring to new problem?	Reply	I-Reply	1
 If so, then in new problems, the variance of points sampled in related problems are low and the variance of points not sampled in related problems are high.	Reply	I-Reply	1
It is absurd.	Reply	I-Reply	1
[line_break_token]2 Knowing accurate global minimizer is acctually hard, however, we can use global minimizer of surrogate model.	Reply	O	0
In other words, when meeting a problem, we sampled some points on it and construct a surrrogate model, then using this global minimizer to substitute.	Reply	B-Reply	2
[line_break_token]3 Actually, when tuning hyper-parameters for neural networks, we may have tuned several similar (in structure )networks.	Reply	O	0
Then these knowledge can be used to new tuning process.	Reply	B-Reply	2
[line_break_token]4 May be global minimizer is not a reasonable setting.	Reply	O	0
However, using function value is more unreasonable.	Reply	B-Reply	2
Our aim is to finding global minimizer of objective function, thus using distance of global minimizer seems no problem.	Reply	I-Reply	2
[line_break_token]5  'For the experiments, it would be good to see two other variants of the proposed algorithm to understand the individual contributions of the neural surrogate model and weighted Reptile algorithm: one without neural surrogate model and the other with simply the use of neural surrogate model.'	Reply	O	0
[line_break_token]I can give you the comparation about initialization on ablation study (on problem of synthetic function): [line_break_token]initialization    |2.1|1.2|  0  |-0.8|-1.1|-1.2|-1.3|-1.4|-1.4|-1.4[line_break_token]after training  |0.1|  0 |-0.7|-1.2|-2.4|-3.5|-4.1|-4.8|-5.0|-5.9[line_break_token]But how to use WRA without neural surrogate model?	Reply	B-Reply	3
WRA is a training method to train neural surroagte models.	Reply	I-Reply	3
Without  neural surrogate model, what should WRA learn?	Reply	I-Reply	3
[line_break_token]6 'What seems to make more sense to me is that the authors in fact run Algorithm 2 instead of Algorithm 3 for each experiment and they initialize w in Algorithm 2 to the output of Algorithm 3.'	Reply	O	0
You are right, we do not write clearly.	Reply	B-Reply	4
We actually use Alg 2 to get  iterations 1 to 12 and its initialization is got by Alg 3.	Reply	I-Reply	4
[line_break_token]7 'To clarify, for each related problem/function, only N_T number of datapoints are used to train a corresponding neural network with 1 hidden layer of 15 hidden units?'	Reply	O	0
We actually use neural network with 1 hidden layer of 15 hidden units.	Reply	B-Reply	5
[line_break_token]8   'sample 20 points from uniform distribution in (‚àí10, 10)' is the same as Feurer et al. (	Reply	O	0
2018) who has compared TST-R.[line_break_token]9 TST-R based on linear combination of related problems, thus related problems determine the performance of TST-R. The comparable performance in SVM problem may beacuse this data set is suitable to TST-R. However, other datasets are not so suitable.	Reply	O	0
[line_break_token]10  I can give you the comparation about Feurer et al. (	Reply	O	0
2018) on ablation study (on problem of synthetic function): [line_break_token]Feurer et al. (	Reply	B-Reply	8
2018)   |0.1|  0 |-1.7|-1.7|-1.7|-1.7|-1.7|-2.0|-2.0|-2.1[line_break_token]WRA-N                        |0.1|  0 |-1.9|-2.7|-2.8|-2.8|-3.5|-4.1|-4.4|-5.	Reply	I-Reply	8

This paper proposed an aggregated momentum methods for gradient based optimization.	Review	O	0
The basic idea is instead of using a single velocity vector, multiple velocity vectors with different damping factors are used in order to improve the stability.	Review	O	0
[line_break_token][line_break_token]In term of novelty, the proposed method seems quite incremental.	Review	O	0
Using multiple velocity vectors seems interesting but not surprising, There is no theoretical guideline how to determine the number of velocity vectors and how to choose the damping factors.	Review	B-Review	1
[line_break_token][line_break_token]I would also suggest that authors should put some main theoretical results like the convergence analysis to the main paper instead of the appendix.	Review	I-Review	2
[line_break_token][line_break_token]In terms of the clarity, I think the paper is well written and the experiments are sufficient and convincing.	Review	O	0
[line_break_token][line_break_token]One minor question is: what is \lambda in Fig.	Review	B-Review	3
1?	Review	I-Review	3
[line_break_token][line_break_token] 	Review	I-Review	1
"Using multiple velocity vectors seems interesting but not surprising": I am not aware of works using a similar technique, despite momentum dating back to 1964.	Reply	O	0
As a result, I am not sure I understand your comment.	Reply	B-Reply	1
Could you please explain	Reply	I-Reply	1

This paper presents a system that infers programs describing 3D scenes composed of simple primitives.	Review	O	0
The system consists of three stages each of which is trained separately.	Review	O	0
First, the perceptual module extracts object masks and their attributes.	Review	O	0
The objects are then are split into several groups.	Review	O	0
Finally, each group is mapped to a corresponding DSL program using a sequence-to-sequence network similar to the ones typically employed in neural machine translation.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]+ The paper is written clearly and easy to read.	Review	O	0
[line_break_token]+ Visual program synthesis is very exciting and important direction both for image understanding and generation.	Review	O	0
[line_break_token]+ The results on synthetic datasets are good.	Review	O	0
The authors also demonstrate the applicability of the approach to real-world data (albeit significantly constrained).	Review	O	0
[line_break_token]+ I find it surprising that a seq2seq is good at producing an accurate program for a group of objects.	Review	O	0
[line_break_token]+ Visual analogy making experiments are impressive.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- The proposed model requires rich annotation of training data since all the components of the systems are trained in a supervised fashion.	Review	O	0
It‚Äôs not clear how to use the method on the in-the-wild data without such annotation.	Review	B-Review	1
[line_break_token]- Related to the previous point, even when it‚Äôs possible to synthesize data, it is non-trivial to obtain the ground-truth grouping of objects.	Review	O	0
Judging by Table 2, it seems that the system breaks in absence of the grouping information.	Review	B-Review	2
[line_break_token]- The data used in the paper is quite simplistic (limited number of primitives located in a regular grid).	Review	O	0
I‚Äôm wondering if there is a natural way to extend the approach to more complex settings.	Review	B-Review	3
My guess is that the performance will drop significantly.	Review	I-Review	3
[line_break_token][line_break_token]Notes/questions:[line_break_token]* Section 2, paragraph 1: The paper by [Ganin et al.,	Review	O	0
2018] presents both a system for reproducing an image as well as for sampling from a distribution; moreover, it presents experiments on 3D data (i.e., not limited to drawing).	Review	B-Review	4
[line_break_token]* Section 3.4, paragraph 2: I‚Äôm not sure I understand the last sentence.	Review	O	0
How can we know that we successfully recovered the scene at test time?	Review	B-Review	5
Could the authors elaborate on the stopping criterion for sampling?	Review	I-Review	5
[line_break_token]* Section 4.2, paragraph 2: Do I understand correctly that the main difference between the test set and the generalization set is the number of groups? (	Review	O	0
i.e., 2 vs 3).	Review	B-Review	6
If so, it‚Äôs a fairly limited demonstration of generalization capabilities of the system.	Review	I-Review	6
[line_break_token]* Section 4.2, paragraph 4: ‚Äúwe search top 3 proposals ...‚Äù ‚Äì How do we decide which one is better?	Review	O	0
Do we somehow have an access to the ground truth program at test time?	Review	B-Review	7
[line_break_token]* Could the authors explain the representation of a program more clearly?	Review	O	0
How are loops handled?	Review	B-Review	8
How can one subtract/add programs in the analogy making experiment?	Review	I-Review	8
[line_break_token][line_break_token]Overall, I think it is a interesting paper and can be potentially accepted on the condition that the authors address my questions and concerns.	Review	O	0
Thank you for your thoughtful review.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Data annotations [line_break_token][line_break_token]Our model requires supervised training data in the pre-training stage for each of its components, but the program synthesizer needs no further training when generalizing to other data distributions since it works on object attribute space.	Reply	O	0
We consider this as an advantage of our model, as it is easy to get synthetic data, but much harder to obtain annotations (in particular program annotations) on in-the-wild images.	Reply	B-Reply	1
Disentangling vision recognition and program synthesis is a key to our model‚Äôs success on real images (Fig.	Reply	I-Reply	1
7): our model accurately predicts programs for the test set with only 90 labeled real images for fine-tuning.	Reply	I-Reply	1
[line_break_token][line_break_token]The group information is inherently included in the program and easy to obtain: when synthesizing data, we first sample several program blocks from our DSL, where each block corresponds to a set of objects that form a group.	Reply	I-Reply	1
These program blocks are then combined into the overall program description of the scene.	Reply	I-Reply	1
Our model explicitly learns the group information and shows advantages over baseline methods which learn directly from the overall program.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Scene complexity [line_break_token][line_break_token]In our main experiment, we place objects on a grid and then jitter their positions and orientations.	Reply	O	0
Results on these data suggest that scene programs describe these structured images well.	Reply	B-Reply	3
We agree with reviewers on the importance of handling more complex data.	Reply	I-Reply	3
In the revision by Nov. 26, we will add results on scenes where objects are placed at random.	Reply	I-Reply	3
[line_break_token][line_break_token]3.	Reply	O	0
Specific questions[line_break_token][line_break_token]1) Ganin et al: We will revise the description of this work in the updated draft.	Reply	O	0
[line_break_token][line_break_token]2) The stopping criterion is whether the scene has been successfully reconstructed, i.e., when the execution results of the program are the same as the object parsing results obtained from the vision module.	Reply	O	0
[line_break_token][line_break_token]3) Generalization: Yes, the main difference is the number of groups.	Reply	O	0
This is only one of our experiments on generalization.	Reply	B-Reply	6
The experiments on real image show our model‚Äôs ability to generalize to new data distributions.	Reply	I-Reply	6
[line_break_token][line_break_token]4) Top proposals: Note that the group detector also outputs the classification result of the group category.	Reply	O	0
Here ‚Äútop‚Äù refers to the softmax score.	Reply	B-Reply	7
We don‚Äôt have any information of the ground truth program at test time.	Reply	I-Reply	7
[line_break_token][line_break_token]5) Program representations: We will give detailed definitions in the Appendix.	Reply	O	0
In short, a program is represented as a matrix, where each row contains a program command, which is a program token followed by its parameters.	Reply	B-Reply	8
[line_break_token][line_break_token]Thanks!	Reply	O	0
Please don‚Äôt hesitate to let us know for any additional comments on the paper or on the planned changes.	Reply	O	0

If I understood correctly, in experimental part pre-trained embeddings, taken from word2vec, is a ground truth.	Review	O	0
Given those embeddings, a system of hyperplanes are trained (every hyperplane refers to a certain word attribute and a region in space, centered around a word, to which reflection is applied).	Review	O	0
[line_break_token][line_break_token]In my opinion, the most natural way to check "the reflection hypothesis" is to train new embeddings where to word2vec objective the loss function (16) is added and to look how perplexity will behave with that additional cost and to look how your accuracy and stability will behave on the test set.	Review	B-Review	1
[line_break_token][line_break_token]It is also interesting to learn how this reflection based attribute transfer can be applied to the same word, but with embeddings that play different role in a model: e.g. input and output embeddings.	Review	O	0
[line_break_token]In fact, input and output embeddings are located in the same space, they can be considered as pairs of words with 1 attribute flipped (i.e. role in a model, input-&gt;output).	Review	O	0
Can an output embedding be obtained from an input embedding via reflections that you describe.	Review	B-Review	2
How many hyperplanes we need in that case?	Review	I-Review	2
This is an interesting edge of the problem.	Review	I-Review	2
In simplest models, there is some evidence, that output embeddings are result of reflections of input embeddings in half the dimensions.	Review	I-Review	2
It would be interesting to learn your comment on that.	Review	I-Review	2
[line_break_token]	Review	O	0
hank you for the encouraging feedback.	Reply	O	0
We address your comments and questions below.	Reply	O	0
[line_break_token][line_break_token]1. "	Reply	O	0
In my opinion, the most natural way to check ‚Äúthe reflection hypothesis‚Äù is to train new embeddings where to word2vec objective the loss function (16) is added and to look how perplexity will behave with that additional cost and to look how your accuracy and stability will behave on the test set."	Reply	O	0
[line_break_token]In this study, we tried to incorporate reflection into a given word embeddings space as our first step.	Reply	B-Reply	1
Training word embeddings from scratch with reflection constraints would be promising future work.	Reply	I-Reply	1
[line_break_token][line_break_token]2. "	Reply	O	0
Can an output embedding be obtained from an input embedding via reflections that you describe.	Reply	O	0
How many hyperplanes we need in that case?"	Reply	O	0
[line_break_token]Yes, that‚Äôs right.	Reply	B-Reply	2
In this work, we parameterize mirror hyperplanes instead of a single mirror, and the mirror parameters are determined according to an input word embedding.	Reply	I-Reply	2
In other words, we can use different mirror hyperplanes for different input words	Reply	I-Reply	2

[Overview][line_break_token][line_break_token]In this paper, the authors proposed a simple but effective way to augmentation the language model through memorization.	Review	O	0
Specifically, after obtaining a language model on a dataset, the model further uses the dataset to build a lookup table and then a k-nearest neighbor is used to searching the closest tokens for a token during inference.	Review	O	0
Based on this, the output distribution of a target token during the inference time would be modified accordingly.	Review	O	0
Through a comprehensive experiments and ablation studies, the authors showed that the proposed strategy can improve the performance of language models significantly for both the in-domain and out-domain testing scenarios.	Review	O	0
This is very insightful considering recently a lot of language models are focusing on increasing the size of model and training data.	Review	O	0
[line_break_token][line_break_token][Pros]:[line_break_token][line_break_token]Overall I think the paper is well-written and presents clearly.	Review	O	0
Detailed points below:[line_break_token][line_break_token]1.	Review	O	0
the authors proposed a simple but effective method for increasing the generalization ability of language model through a memorization strategy.	Review	O	0
Specifically, the authors proposed to build a lookup table which memorizes the representation and output token pairs which are then used for the inference of language model.	Review	O	0
Different from conventional way, the proposed strategy does not introduce any more parameters in the model and also does not need any more training or fine-tuning on the target dataset.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
The authors showed that the proposed strategy can improve the performance of language generation model (i.e., transformer) without any extra training or data, as shown in Table 1.	Review	O	0
Also, using the continuous caches  with KNN-LM further improve the performance.	Review	O	0
[line_break_token][line_break_token]3.	Review	O	0
Besides the main results shown in Table 1 and Table 2, the authors also showed using kNN-LM can probably outperforms the model which is directly trained on it.	Review	O	0
Also, it also supports domain adaptation from one language domain to another domain.	Review	O	0
[line_break_token][line_break_token]4.	Review	O	0
Finally, the authors presented a number of ablation studies to investigate how the performance is affected by the method of building datastore, including the size of nearest neighbor, the interpolation parameter, etc.	Review	O	0
These results are also insightful and meaningful for the readers to understand the method.	Review	O	0
[line_break_token][line_break_token][Cons]:[line_break_token][line_break_token]I think this paper is a solid paper.	Review	O	0
So I would have some suggestions below:[line_break_token][line_break_token]1.	Review	O	0
The first concern about the method is the efficiency.	Review	B-Review	1
At page 3, the authors mentioned that the proposed strategy will bring more time cost.	Review	I-Review	1
It would be good if the authors can perform more systematical analysis on the time cost of building the datastore and inference for the proposed model.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Second, the authors should not only evaluate the proposed method based on transformers.	Review	B-Review	2
It would be good to test on various language models to verify the generalization ability across different models, including the old-fashioned one like RNN and CNN.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Also, the authors should try to extend the proposed model to other language tasks, such as translation.	Review	B-Review	3
[line_break_token][line_break_token][Summary][line_break_token][line_break_token]In this paper, the authors introduced a simple but effective method to augment the pertained language model through memorizations.	Review	O	0
Though this is not absolutely new and relatively simple , the authors successfully demonstrate that it can be applied to improve the generation of language model much.	Review	O	0
The.	Review	O	0
thorough ablation studies help to understand the property of the proposed strategy.	Review	O	0
I think this paper overall is insightful and thoughtful.	Review	O	0
It would be good to see the authors add more analysis on the computational complexity and also evaluate on more type of language models.	Review	B-Review	3
[line_break_token]	Review	O	0
ello Reviewer1,[line_break_token][line_break_token]Thanks for your comments.	Reply	O	0
We‚Äôre glad you enjoyed the paper!	Reply	O	0
[line_break_token][line_break_token]Efficiency:[line_break_token]Building the datastore: A single epoch of training over the Wikitext-103 data takes ~5 hours on a single GPU.	Reply	O	0
In comparison, a single forward pass over the same dataset to save keys/values took ~4 hours.	Reply	B-Reply	1
Then, creating the datastore using FAISS took two hours on a single CPU.	Reply	I-Reply	1
Hence, building the datastore is is comparable to a single epoch of training.	Reply	I-Reply	1
In addition, the saving of keys/values as well as creating the datastore are trivial to parallelize.	Reply	I-Reply	1
[line_break_token][line_break_token]Inference: We measured the decoding speed of kNN-LM and found that it can sample roughly 60 tokens per second on one GPU, which is easily fast enough for most applications (albeit slower than the vanilla LM, which can sample roughly 500 tokens per second).	Reply	O	0
Improving the efficiency is not a focus of this work, but it is likely that it could be significantly improved - for example, by downsampling frequent words from the datastore.	Reply	B-Reply	1
[line_break_token][line_break_token]Other architectures:[line_break_token]We are in the process of evaluating the model on a CNN-based LM as well!	Reply	O	0
Thanks for the suggestion!	Reply	O	0
[line_break_token][line_break_token]Future work:[line_break_token]We also agree that applying kNN-LM to translation would be an exciting next step which we hope to pursue in followup work!	Reply	O	0
[line_break_token][line_break_token]Thanks!	Reply	O	0

This paper proposes a new and simple framework for learning cross-lingual embeddings that, based on well-supported insights, unifies two standard frameworks: joint learning and alignment-based approaches.	Review	O	0
While I like and acknowledge the fact that the paper examines these frameworks critically and has also some didactic value, I still have some concerns regarding the current experiments, and would like to see some additional analyses in the paper.	Review	O	0
Honestly, this type of work would work better as a short ACL/EMNLP paper, as the core methodological contribution is a very simple combination of the existing techniques.	Review	O	0
[line_break_token][line_break_token]With joint methods, it is true that shared words can be used as implicit bilingual learning signal which gets propagated further in the model.	Review	B-Review	1
Even in the case of alignment-based methods, it was shown that this signal can assist in learning shared cross-lingual spaces, but: 1) such spaces are of lower-quality than the spaces learned by relying on seed dictionaries (see e.g., the work of Vulic and Korhonen (ACL 2016)), 2) this is useful only for similar language pairs which use the same script.	Review	I-Review	1
The paper fails to provide an insightful discussion on how the scores differ when we move towards more distant languages.	Review	I-Review	1
For instance, English-Chinese is included as a more distant language pair, and the combined method seems to work fine, but the reader is left wondering why that happens.	Review	I-Review	1
The same is true for English-Russian.	Review	I-Review	1
The paper should definitely provide more information and insights here.	Review	I-Review	1
[line_break_token][line_break_token]One experiment that would be quite interesting imho is to take seed dictionaries to initialise the joint training method.	Review	I-Review	2
It will not be unsupervised any more, but it would be very useful to report the differences in results between fully unsupervised joint initialisation (which, as mentioned should work only with more similar languages) and such weakly supervised init: e.g., the method could take all one-to-one translation pairs from the seed dictionary as 'shared words'.	Review	I-Review	2
It would also be interesting to combine such 'shared words' and words that are really shared (identically spelled words) as initialisation and measure how it affects the results, also in light of differences in language distance.	Review	I-Review	2
Adding one such experiment would make the paper more interesting.	Review	I-Review	2
[line_break_token][line_break_token]Some recent strong baselines are missing: e.g., I wonder how the model that does self-learning on top of seed dictionaries (similar to the work of Vulic et al.,	Review	I-Review	3
EMNLP 2019) compares to the proposed method.	Review	I-Review	3
Also, can we use the same self-learning technique with the combined method here?	Review	I-Review	3
Would that lead to improved results?	Review	I-Review	3
Another work I would like to see comparisons to is the work of Zhang et al. (	Review	I-Review	3
ACL 2019) and despite the fact that the authors explicitly stated that they decided not to compare to the work of Artetxe et al. (	Review	I-Review	3
ACL 2019) as they see it as concurrent work, I would still like to see that comparison as the model of Artetxe et al.	Review	I-Review	3
seems very relevant to the presented work.	Review	I-Review	3
[line_break_token][line_break_token]I do not see the extension to contextualized representations (described in Section 3.2) as a real contribution: this is a very straightforward method to apply an alignment-based method on multilingual BERT representations, and very similar techniques have been probed in previous work (e.g., by Aldarmaki &amp; Diab), only the bilingual signal/dictionary came from parallel data instead.	Review	O	0
[line_break_token][line_break_token]Finally, as mentioned before, one of the must-have experiments is including more (distant and diverse) language pairs and analysing the results across such language pairs, with an aim to further understand how the levels of sharing, over-sharing, and non-isomorphism affect performance.	Review	O	0
Also, while the authors state that reduced isomorphism is the key problem of alignment-based methods, I still fail to see how exactly the alignment refinement step does not suffer from that problem?	Review	B-Review	5
More discussion is needed here.	Review	I-Review	5
[line_break_token][line_break_token]Other comments:[line_break_token]- It would be useful to also point to the survey paper of Ruder et al. (	Review	I-Review	6
JAIR 2019) where the difference between alignment-based and joint models is described in more detail and could inform an interested reader beyond the confines of the related work section in this paper.	Review	I-Review	6
Similarly, differences between joint models and alignment-based models have also been analysed by Upadhyay et al. (	Review	I-Review	6
ACL 2016); Vulic and Korhonen (ACL 2016).	Review	I-Review	6
[line_break_token][line_break_token]- I like how Figure 1 clearly visualizes the main intuitions behind the proposed framework, and how mitigating the oversharing problem leads to better alignments.	Review	O	0
This was very nice.	Review	B-Review	7
[line_break_token][line_break_token]- In light of the problems with silver standard MUSE datasets (see also the recent work of Kementchedjhieva, EMNLP 2019), I would suggest to run BLI experiments on more language pairs: e.g., there are BLI datasets of Glavas et al available for 28 language pairs.	Review	O	0
hank you for your comprehensive review and valuable feedback.	Reply	O	0
We address your comments one by one as following:[line_break_token][line_break_token][Improvements of distant language pairs/Reduced isomorphism][line_break_token][line_break_token]The source of improvement for jointly training two distant languages is still an open question.	Reply	O	0
As recently shown in [1], joint training is still beneficial even for languages using disjoint vocabulary sets.	Reply	B-Reply	1
Although their findings are based on contextualized representations, we observe similar improvements for non-contextualized representations in our experiments and we hypothesize that the improvement is due to the overlap in training corpus resulting in more similar graph structures of embeddings (i.e. suffer less from the reduced isomorphism issue).	Reply	I-Reply	1
[line_break_token][line_break_token]To analyze the effect of reduced isomorphism, we compute the eigenvector similarity proposed in [2]. This metric measures the degree of similarity between two embedding graphs and therefore can be used to estimate the degree of isomorphism.	Reply	I-Reply	1
In particular, we compute this metric using four embeddings: monolingual fasttext, fasttext aligned with RCSLS, joint training (unsupervised), and joint_align with RCSLS.	Reply	I-Reply	1
The results are shown below (smaller values indicates graphs are more similar).	Reply	I-Reply	1
In particular, we observe that jointly trained embeddings share more similar graph structures than independently trained counterparts and thus they suffer less from the reduced isomorphism problem.	Reply	I-Reply	1
These results also suggest that the alignment refinement step suffers less from this problem due to a better initialization from joint training.	Reply	I-Reply	1
[line_break_token][line_break_token]                                  en-es |en-fr|en-de|en-it|en-ru|en-zh| avg[line_break_token]fasttext                       3.25 | 3.73 | 4.48 | 4.15 | 4.92 | 5.02 | 4.26[line_break_token]fasttext_RCSLS          2.56 | 2.59 | 2.02 | 2.72 | 3.60 | 2.82 | 2.72[line_break_token]Unsupervised Joint   2.59 | 1.98 | 2.38 | 2.59 | 2.94 | 2.79 | 2.55[line_break_token]Joint_Align                  1.48 | 2.00 | 1.75 | 2.45 | 3.07 | 2.68 | 2.24[line_break_token][line_break_token][Joint training with seed dictionary][line_break_token][line_break_token]We agree that adding a joint training baseline using seed dictionaries is didactic.	Reply	O	0
However, this is a non-trivial task since joint training works best with fasttext in order to utilize subword information, which does not take an explicit form of seed dictionary nor allow tokens with different surface forms to share same embeddings.	Reply	B-Reply	2
Therefore, instead of fundamentally modifying fasttext, we use a simple approach: (1) for each word in the dictionary, we randomly replace its occurrences in the concatenated corpus with its translation 50% of the time and keep it unchanged for the rest, (2) we then train the joint training embeddings as in the paper, (3) for words in the seed dictionary, we take the average of their embeddings and treat them as one single word shared between the two languages.	Reply	I-Reply	2
We use the same seed dictionary from MUSE as in other experiments.	Reply	I-Reply	2
As pointed out by reviewer 3, manipulating the degree of sharing is an ambitious goal that we plan to study in the future and may include in a later version.	Reply	I-Reply	2
[line_break_token][line_break_token]As shown in the table below, we observe that using the seed dictionary as ‚Äúshared words‚Äù improves the performance of unsupervised joint training.	Reply	I-Reply	2
However, since this method still treats identically spelled words as shared words (which is implicitly forced by the nature of fasttext), it still suffer from the oversharing problem as we observe further improvements by applying an extra vocabulary reallocation step.	Reply	I-Reply	2
[line_break_token][line_break_token]BLI:[line_break_token]                                 en-es|es-en|en-fr|fr-en |en-de|de-en|en-it|it-en|en-ru|ru-en|en-zh|zh-en|avg[line_break_token]Unsupervised Joint  33.4| 36.6 | 42.2 | 47.4 | 39.5 | 41.4  | 36.8 | 38.8| 4.00 | 3.50 | 17.9  | 10.2  |29.3 [line_break_token]Replace                      48.2| 47.7 | 49.4 | 52.1 | 46.5 | 46.9  | 43.8 | 45.8| 20.3 | 36.6 | 32.7  | 34.1  |42.0 [line_break_token]Replace+VR               67.1| 68.7 | 66.4 | 68.4 | 62.3 | 64.2  | 57.3 | 60.6| 42.6 | 50.1 | 46.5  | 43.6  |58.2 [line_break_token]Joint_Align                 86.0| 88.5 | 83.9 | 85.8 | 79.3 | 78.7  | 79.9 | 83.1| 60.4 | 69.2 | 57.2  | 50.4  |75.2 [line_break_token][line_break_token]NER:[line_break_token]                                       es     |      nl     |     de     |    avg[line_break_token]Unsupervised Joint  50.28   |   42.77  |  21.49  |   38.18[line_break_token]Replace                      65.28   |   68.44  |  51.59  |   61.77 [line_break_token]Joint_Align                 70.46   |   72.10  |  56.47  |   66.34 [line_break_token][line_break_token](The method described above is denoted as ‚ÄúReplace‚Äù and we also include baselines from the paper for your convenience. ‚	Reply	I-Reply	2
ÄúVR‚Äù denotes vocabulary reallocation.)	Reply	I-Reply	2
[line_break_token][line_break_token][Extension to contextualized representations][line_break_token][line_break_token]We agree that applying alignment methods to contextualized representations is straightforward.	Reply	O	0
The point is to show that further alignment on an already well-trained multilingual model can still improve performance, which has also been shown by [3] and is consistent with findings reported in [1]	Reply	B-Reply	4

This paper introduces MusicNet, a new dataset.	Review	O	0
Application of ML techniques to music have been limited due to scarcity of exactly the kind of data that is provided here: meticulously annotated, carefully verified and organized, containing enough "hours" of music, and where genre has been well constrained in order to allow for sufficient homogeneity in the data to help ensure usefulness.	Review	O	0
This is great for the community.	Review	O	0
[line_break_token][line_break_token]The description of the validation of the dataset is interesting, and indicates a careful process was followed.	Review	O	0
[line_break_token][line_break_token]The authors provide just enough basic experiments to show that this dataset is big enough that good low-level features (i.e. expected sinusoidal variations) can indeed be learned in an end-to-end context.	Review	O	0
[line_break_token][line_break_token]One might argue that in terms of learning representations, the work presented here contributes more in the dataset than in the experiments or techniques used.	Review	O	0
However, given the challenges of acquiring good datasets, and given the essential role such datasets play for the community in moving research forward and providing baseline reference points, I feel that this contribution carries substantial weight in terms of expected future rewards. (	Review	O	0
If research groups were making great new datasets available on a regular basis, that would place this in a different context.	Review	O	0
But so far, that is not the case.)	Review	O	0
In otherwords, while the experiments/techniques are not necessarily in the top 50% of accepted papers (per the review criteria), I am guessing that the dataset is in the top 15% or better.	Review	O	0
Thank you for your positive comments	Reply	O	0

Summary.	Review	O	0
[line_break_token]The paper improves the existing feature attribution method by adding regularizers to enforce (human) expectations about a model‚Äôs behavior.	Review	O	0
Three different datasets (i.e. image, gene expression, health-care) are chosen to evaluate the proposed model‚Äôs effectiveness, while different regularizers (i.e. image prior, graph prior, and sparsity prior) are explored for the respective task.	Review	O	0
[line_break_token][line_break_token]Strengths.	Review	O	0
[line_break_token]1.	Review	B-Review	3
Incorporating human knowledge into the model has a growing interest in ML / CV communities.	Review	O	0
[line_break_token]2.	Review	B-Review	3
Three datasets from different domains (i.e. image classification data, gene expression data, and health care data) are used to evaluate the effectiveness of the proposed approach.	Review	O	0
Data shows that the proposed approach shows better generalization performance (i.e. better performance in test dataset) than baselines.	Review	O	0
[line_break_token]3.	Review	B-Review	3
The paper provides well-documented supplemental materials that contain details of the experimental setting and additional supporting figures.	Review	O	0
[line_break_token][line_break_token]Weaknesses.	Review	O	0
[line_break_token]1.	Review	B-Review	3
Task-specific heuristic human prior[line_break_token]I agree (and personally like) the motivation that a method is needed to align a model‚Äôs behavior with human knowledge or intuition -- model‚Äôs behavior may be explained by feature attribution methods while making models accept human knowledge is challenging.	Review	O	0
However, such an ability is achieved by simply adding task-specific heuristic functions as a penalty or a regularizer.	Review	B-Review	1
Also, the introduced human priors are similar to general regularization conventions, i.e. a penalty of smoothness over adjacent pixels is commonly used in the CV community.	Review	I-Review	1
I am concerned that only a limited set of expert-invented human priors can be used in this approach.	Review	I-Review	1
[line_break_token][line_break_token]Further, feature attribution methods aim to develop a richer notion of the contribution of a pixel to the output.	Review	I-Review	1
However, the difficulty would be the lack of formal measures of how the network output is affected by spatially-extended features (rather than pixels).	Review	I-Review	1
The explored priors (e.g. a total variation loss to make neighboring pixels have a similar impact on the final verdict) actually relieve this issue.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	I-Review	3
Incorporating humans into the modeling process?	Review	O	0
[line_break_token]A key motivation behind this work is ‚Äúincorporating humans into the modeling process‚Äù.	Review	O	0
This would imply that (human-understandable) information needs first to be transferred from a model to humans.	Review	O	0
However, I am concerned about what information end-users are expected to obtain from the model.	Review	B-Review	2
For example, Figure 1 (left) shows an attribution map that highlights multiple intermittent regions from which I cannot understand its behavior.	Review	I-Review	2
Unless end-users cannot understand the model‚Äôs behavior, how can we expect humans can provide knowledge to model?	Review	I-Review	2
A user study would be needed to support that the proposed method can really provide a way to incorporate humans into the modeling process.	Review	I-Review	2
[line_break_token][line_break_token]Minor comments.	Review	I-Review	3
[line_break_token]1.	Review	I-Review	3
Plots in Figure 3 are not intuitively understandable.	Review	I-Review	3
[line_break_token]2.	Review	I-Review	3
There is no section Conclusion.	Review	I-Review	3
[line_break_token]3.	Review	I-Review	3
A template for the reference section looks different from other ICLR papers.	Review	I-Review	3
hank you for discussing several strengths of our paper.	Reply	O	0
We believe these strengths represent a significant contribution toward addressing the issue of incorporating human knowledge into neural network models.	Reply	O	0
Below, we discuss the weaknesses described in the review: [line_break_token][line_break_token]1) We first want to respond to the point that only a limited set of expert-invented human priors can be used in our approach.	Reply	O	0
There are also only a limited number of expert-invented ways to regularize model parameters, yet parameter regularization (from parameter priors) is very important and widely studied in machine learning and statistics.	Reply	B-Reply	1
In the same way we believe that regularizing feature attributions using expert-invented attribution priors promises to be a fundamentally new alternative to parameter regularization.	Reply	I-Reply	1
Our paper significantly extends the pioneering work in this area by Ross et al (2017), and in doing so greatly expands the applicability of attribution priors.	Reply	I-Reply	1
[line_break_token][line_break_token]2) In the context of incorporating human knowledge into machine learning models, we believe that one critical evaluation metric is how well our models do on prediction tasks.	Reply	O	0
Our experiments show that our method is successful: it leads to improved performance in all three domains by using penalties derived from human intuition about the data.	Reply	B-Reply	2
In terms of learning more intuitive models, we chose three task-specific metrics to optimize: smoothness in images, capturing related genes in gene expression data, and sparsity on clinical data.	Reply	I-Reply	2
In all cases, we achieve our stated goal as evidenced by Figures 1-3.	Reply	I-Reply	2
Whether or not these goals represent the most human-intuitive goals to optimize for in their respective domain would be valuable future work.	Reply	I-Reply	2
In general, what constitutes an ‚Äúinterpretable‚Äù model is a challenging and open question.	Reply	I-Reply	2
However, given the flexibility of our framework, we anticipate that it can be adapted to changing definitions of interpretability	Reply	I-Reply	2

- Summary[line_break_token][line_break_token]This paper studies the sample elicitation problem where agents are asked to report samples.	Review	O	0
The goal is then to evaluate the quality of these reported samples by means of a scoring function S. Following previous related works, the authors use the equivalence between maximizing the expected proper score and minimizing some f-divergence.	Review	O	0
Their approach relies on the dual expression of the f-divergence which writes as a maximum over a set of functions t. Theoretical guarantees are given for f-scorings obtained (with or without ground truth samples) by first computing the empirical optimal function t, then plugged to estimate the f-divergence.	Review	O	0
Finally, a deep learning approach is proposed by considering functions f parameterized as sparse deep neural networks.	Review	O	0
[line_break_token][line_break_token]- Critics[line_break_token][line_break_token]The paper is globally well written but not well motivated and sometimes difficult to understand.	Review	O	0
[line_break_token]In particular, the notions of "elicitation", "reports" and "score function" should be defined mathematically more clearly.	Review	B-Review	1
[line_break_token]Moreover, the deep learning aspect of the paper is not well motivated and is introduced in a very arbitrary way.	Review	I-Review	1
Why not choosing another parametric family of functions?	Review	I-Review	1
Is there another (broad) family of functions for which the computation of the argmin in Equation (4.3) is more tractable in practice?	Review	I-Review	1
[line_break_token]A convincing way to motivate this deep learning approach would be to include numerical experiments and to compare to other parametric families.	Review	I-Review	1
[line_break_token]	Review	O	0
ince ICLR is the premier deep learning conference, we are motivated to collect credible and quality samples from strategic agents (e.g., ordinary people) for deep learning.	Reply	B-Reply	1
Naturally, we think it is of interest to try using deep learning techniques to solve the score function design problem via a data-driven approach.	Reply	I-Reply	1
Along the way of developing our results, we realized the connection between our elicitation problem and GAN, which we detail in Section 5.	Reply	I-Reply	1
[line_break_token][line_break_token]Beyond above, the deep learning based estimators are able to handle complex data.	Reply	I-Reply	1
And with our deep learning solution, we are further able to provide estimates for the divergence functions used for our scoring mechanisms, with provable finite sample complexity.	Reply	I-Reply	1
In our opinion, these are highly non-trivial contributions.	Reply	I-Reply	1
In this paper, we focus on developing theoretical guarantees- other parametric families either can not handle complex data, e.g., it is hard to handle images using kernel methods, or do not have provable guarantees on the sample complexity.	Reply	I-Reply	1
[line_break_token][line_break_token]We wonder whether there is another reason that leads to the reviewer‚Äôs recommendation of rejection.	Reply	O	0
We are happy to further clarify.	Reply	O	0

This paper proposes GRAM-nets using MMD as the critic to train GANs.	Review	O	0
Similar to MMD-GAN, the MMD is computed on a projected lower dimensional space to prevent the kernel struggle in the high dimensional observed space.	Review	O	0
On the other hand, contrary to MMD-GAN, GRAM-nets trains the projection f_{\theta} trying to matching the density ratio of p/q between the observed and the latent space.	Review	O	0
The proposed density ratio matching criterion avoids the adversarial training in MMD-GAN, thus can potentially fix the two-player optimization problem.	Review	O	0
The paper shows improved FID scores and nice-looking CIFAR10 generations.	Review	O	0
[line_break_token][line_break_token]Strengths, [line_break_token]1, Matching density ratios is a novel and interesting idea.	Review	O	0
If the data lives in a lower dimensional subspace, matching density ratio could probably reveal the subspace.	Review	O	0
Compared to adversarially training f_theta, the proposed approach could lead to more stable training potentially.	Review	O	0
[line_break_token]2, By manipulating E (px/qx - pz/qz)^2, they avoid estimating the high-dimensional px/qx and only estimate pz/qz.	Review	O	0
[line_break_token][line_break_token][line_break_token]Weakness,[line_break_token]1, The paper needs to be more careful with mathematical expressions.	Review	O	0
1) Eq(2) should be MMD^2, instead of MMD.	Review	B-Review	1
2) Eq(5) and Eq(6) are wrong, although the used Eq(7) becomes true again.	Review	I-Review	1
In Eq(5), Eq(6), the integration should be over f(x) instead of x, that is to say.	Review	I-Review	1
[line_break_token]2, It is unclear why one needs the regularization in Eq(9).	Review	O	0
In fact, the major problem of the density ratio estimator lies in that r(x) might be negative, so a clipping might be useful.	Review	B-Review	2
[line_break_token]3, The major contribution of GRAM-nets lies in removing the adversarial training in MMD-GAN.	Review	O	0
Therefore, more empirical comparisons should be made with MMD-GAN.	Review	B-Review	3
For example, how MMD-GAN evolves in Figure 2 is necessary.	Review	I-Review	3
[line_break_token]4, In real image generation tasks, it is beneficial to show the stability of training GRAM-nets, compared with GAN, MMD-GAN as well as WGAN-GP; And Inception scores should also be reported for better validating the effectiveness of the proposed method.	Review	O	0
.	Reply	B-Reply	1
On integration measure: Thanks for correctly pointing out, indeed, the integrals are defined with respect to the measure. (	Reply	O	0
7) becomes correct again after invoking LOTUS (law of unconscious statistician).	Reply	B-Reply	1
We will fix these typos.	Reply	I-Reply	1
We would also like to clarify if this is what you referred to as the 'fundamental error'?	Reply	I-Reply	1
If not, could you please point it out.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
Clipping DRE: Our motivation to add the non-negativity regularization term is to encourage f_theta to produce a reduced space on which the density ratio estimator tends to produce positive values, which is trying to alleviate the problem that you pointed out.	Reply	O	0
In fact, we tried your suggestion on the synthetic datasets and MNIST and found that clipping the estimator works very robustly.	Reply	B-Reply	2
Thanks for this great suggestion!	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Synthetic data experiment for MMD-GAN: We ran the experiments from Figure 2 for MMD-GANs, which are provided in Figure 10 (Appendix F).	Reply	O	0
Note that these plots take 4,000 epochs, each with 5 steps for the critic network and 1 step for the generative network, while Figure 2b for GRAM-nets only takes 2,000 epochs with a single joint step for both the networks.	Reply	B-Reply	3
Even with longer training, the quality of MMD-GAN is visually worse than GRAM-nets in this synthetic example.	Reply	I-Reply	3
Notice, how the generated samples of MMD-GAN are similar to the successful runs for GAN in Figure 2a: generated samples tend to be too concentrated around the mode of the individual clusters.	Reply	I-Reply	3
Our method on the other hand, with shorter training time, is clearly able to recover all the 8 clusters along with their spread[line_break_token][line_break_token]4.	Reply	O	0
On comparison with WGAN-GP: Wasserstein distance and MMD are both instances of integral probability metrics and have been compared to each other before in great details by Binkowski et al, (2018).	Reply	B-Reply	4
They were able to show that MMD-GAN is better (stable, efficient with higher IS) than WGAN-GP, therefore we chose to compare to MMD-GAN in this work given its direct relevance.	Reply	I-Reply	4
Figure 5 shows the stability of GRAM-nets v.s.	Reply	I-Reply	4
MMD-GANs.	Reply	I-Reply	4
We have added inception scores for MMD-GANs, GANs and GRAM-nets on CIFAR10 in Appendix E, as per your suggestion.	Reply	I-Reply	4

This paper attempts to establish a notion of thermodynamics for machine learning.	Review	O	0
Let me give an attempt at summary.	Review	O	0
First, an objective function is established based on demanding that the multi-information of two graphical models be small.	Review	O	0
The first graphical model is supposed to represent the actual dependence of variables and parameters used to learn a latent description of the training data, and the model demands that the latents entirely explain the correlation of the data, with the parameters marginalized out.	Review	O	0
Then, a variational approximation is made to four subsets of terms in this objective function, defining four "thermodynamic"  functionals.	Review	O	0
Minimizing the sum of these functionals puts a variational upper bound on the objective.	Review	O	0
Next, the sum is related to an unconstrained Lagrange multiplier problem making use of the facts (1) that such an objective will likely have many different realizations of the thermodynamic functionals for specific value of the bound and (2) that on the optimal surface the value of one of the functional can be parametrized in terms of the three others.	Review	O	0
If we pick the entropy functional to be parameterized in terms of the others, we find ourself precisely in the where the solution to the optimization is a Boltzmann distribution; the coefficients of the Lagrange multipliers will then take on thermodynamic interpretations in of temperature, generalized chemical potentials, etc.	Review	O	0
At this point, the machinery of thermodynamics can be brought to bear, including a first law, Maxwell relations (equality of mixed partial derivatives), etc.	Review	O	0
[line_break_token][line_break_token]I think the line of thinking in this paper is very much worth pursuing, but I think this paper requires significant improvement and modifications before it can be published.	Review	B-Review	1
Part of the problem is that the paper is both very formal and not very clear.	Review	I-Review	1
It's hard to understand why the authors are establishing this analogy, where they are going with it, what's its use will be, etc.	Review	I-Review	1
Thermodynamics was developed to explain the results of experiments and is often explained by working out examples analytically on model systems.	Review	I-Review	1
This paper doesn't really have either such a motivation or such examples, and I think as a result I think it suffers.	Review	I-Review	1
[line_break_token][line_break_token]I also think the "Tale of Two Worlds" laid out in Section 2 requires more explanation.	Review	I-Review	2
In particular, I think more can be said about why Q is the the "world we want" and why minimizing the difference between these worlds is the right way to create an objective. (	Review	I-Review	2
I have no real problem with the objective once it is derived.)	Review	I-Review	2
Since this paper is really about establishing this formal relationship, and the starting point is supposed to be the motivating factor, I think this needs to be made much clearer.	Review	I-Review	2
[line_break_token][line_break_token]The I(Z_i, X_i, Theta) - I(X_i, Z_i) terms could have been combined into a conditional mutual information. (	Review	I-Review	3
I see this is discussed in Appendix A.) This leads to a different set of variational bounds and a different thermodynamics.	Review	I-Review	3
Why do we prefer one way over the other?	Review	I-Review	3
At the level of the thermodynamics, what would be the relationship between these different ways of thinking?	Review	I-Review	3
Since it's hard to see why I want to bother with doing this thermodynamics (a problem which could be assuaged with worked examples or more direct and clear experiments), it's hard to know how to think about this sort of freedom in the analogy. (	Review	I-Review	3
I also don't understand why the world Q graphical model is different in Appendix A when we combined terms this way, since the world Q lead to the objective, which is independent of how we variationally bound it.)	Review	I-Review	3
I think ultimately the problem can be traced to the individual terms in the objective (7) not being positive definitive, giving us the freedom to make different bounds by arranging the pieces to get different combinations of positive definite terms.	Review	I-Review	3
How am I supposed to think about this freedom?	Review	I-Review	3
[line_break_token][line_break_token]In conclusion, I would really like to see analogies like this worked out and be used to better understand machine learning methods.	Review	O	0
But for this program to be successful, I think a very compelling case needs to be made for it.	Review	O	0
Therefore, I think that this paper needs to be significantly rewritten before it can be published.	Review	O	0
Thank you for the review and careful read of the paper, and constructive criticism.	Reply	O	0
[line_break_token][line_break_token]We agree that there is more work to be done in further exploring the analogy to thermodynamics, but at least at present thought the existence of the analogy was interesting enough to warrant the current draft.	Reply	B-Reply	1
 We hope to develop tighter analogies and analytical examples for simple systems, but realistically we are already very pressed for space.	Reply	I-Reply	1
[line_break_token][line_break_token]We agree that more should be said about the choice of world Q and its implications.	Reply	I-Reply	3
 Part of the difficulty is the world Q shown in the body of the main work isn't necessarily the best, but it is the one that most directly connects with a wide range of existing objectives in the literature.	Reply	I-Reply	3
 We thought it is interesting to note that existing objectives can be motivated as minimizing an information projection to the world Q shown.	Reply	I-Reply	3
 We should better emphasize that if the reader finds world Q suspect, but trusts our general program, this could reasonably fuel a suspicion of the utility of the existing objectives.	Reply	I-Reply	3
[line_break_token][line_break_token]We are still investigating the utility of the modified objective in Appendix A.  (We note that world Q in Appendix A is Markov equivalent to the one in the main body, the Z<-X arrow simply changed direction.)	Reply	O	0
We suspect it might actually prove a more useful objective in practice than the existing formulation.	Reply	B-Reply	3
 We suspect the existing objective has the form it does not for any deep reason but because people naturally think in terms of decoders as a natural element of learning a useful representation.	Reply	I-Reply	3
 That in the infinite family limit there is an equivalence in the two forms of objective for a parametric representation with and without a decoder we find interesting.	Reply	I-Reply	3
 But at present we can only point out this equivalence as we haven't finished the experimental investigation yet	Reply	I-Reply	3

Deep Randomized Least Squares Value Iteration[line_break_token]=========================================================[line_break_token][line_break_token]This paper proposes a method for exploration via randomized value functions in Deep RL.	Review	O	0
[line_break_token]The algorithm performs a standard DQN update, but then acts according to an exploration policy sampled from a posterior approximation based on a last layer linear rule.	Review	O	0
[line_break_token]The authors show that this algorithm can perform well on a toy domain designed to require efficient exploration, together with some results on Atari games.	Review	O	0
[line_break_token][line_break_token][line_break_token]There are several things to like about this paper:[line_break_token]- The problem of efficient exploration in Deep RL is a pressing one, and there is no clearly effective method out there widely used.	Review	O	0
[line_break_token]- The proposed algorithm is interesting, and appears to have some reasonable properties.	Review	O	0
One nice thing is that it requires only relatively minor changes to the DQN algorithm.	Review	O	0
[line_break_token]- The general flow of the paper and structured progression is nice.	Review	O	0
[line_break_token]- The algorithm generally appears to bring superior exploration and outperform epsilon-greedy baseline.	Review	O	0
[line_break_token][line_break_token][line_break_token]However, there are some other places the work could be improved:[line_break_token]- I think that the name "Deep RLSVI" is a little imprecise... actually RLSVI could already be a "deep" algorithm as defined by the JMLR paper: <a href="http://jmlr.org/papers/volume20/18-339/18-339.pdf" target="_blank" rel="nofollow">http://jmlr.org/papers/volume20/18-339/18-339.pdf</a> (Algorithm 4).	Review	O	0
I see that you mean this as an extension to the linear case for RLSVI... but I do think it would be better to call it something more explicit like "Last-layer RLSVI for DQN".	Review	B-Review	1
[line_break_token]- Related to the above, the comparison to other similar methods for exploration via "randomized value functions" is not very comprehensive.	Review	O	0
I'm not sure what the pros/cons are of this method versus BootDQN or the very similar work from Azizzadenesheli?	Review	B-Review	2
[line_break_token]- It would be good to compare these methods more explicitly, particularly on the domains designed specifically for testing exploration.	Review	O	0
To this end, I might suggest bsuite <a href="https://github.com/deepmind/bsuite" target="_blank" rel="nofollow">https://github.com/deepmind/bsuite</a> and particularly the "deep sea" domains?	Review	O	0
[line_break_token]- Something feels a little off about the Atari results, particularly the curves for "rainbow"... these appear to be inconsistent with published results (look at Breakout).	Review	O	0
[line_break_token][line_break_token]Overall I think there is interesting material here, and I'd like to see more.	Review	O	0
[line_break_token]However, I do have some concerns about the treatment/comparison to related work and I think without this it's not ready for publication.	Review	B-Review	3
 We will consider changing the algorithm‚Äôs name, thank you.	Reply	B-Reply	1
[line_break_token]- As you mentioned above, the goal of this paper is to demonstrate the benefit of replacing vanilla DQN‚Äôs exploration strategy to RLSVI.	Reply	O	0
While other methods use an ensemble of networks (BootDQN) or change the network structure and loss (BDQN), we simply change the exploration strategy.	Reply	B-Reply	2
[line_break_token]- Thank you, we will consider it.	Reply	O	0
[line_break_token]- For the results of the baselines in the Atari section, we used the publicly available results in <a href="https://github.com/google/dopamine" target="_blank" rel="nofollow">https://github.com/google/dopamine</a> as supplied by DeepMind.	Reply	O	0

This paper presents an approach to modeling videos based on a decomposition into a background + 2d sprites with a latent hidden state.	Review	O	0
The exposition is OK, and I think the approach is sensible, but the main issue with this paper is that it is lacking experiments on non-synthetic datasets.	Review	O	0
As such, while I find the graphics inspired questions the paper is investigating interesting, I don't think it is clear that this work introduces useful machinery for modeling more general videos.	Review	O	0
[line_break_token][line_break_token]I think this paper is more appropriate as a workshop contribution in its current form.	Review	O	0
Thanks for your review.	Reply	O	0
We will use your suggestions to improve our work	Reply	O	0

The authors introduce a class of quasi-hyperbolic algorithms that mix SGD with SGDM (or similar with Adam) and show improved empirical results.	Review	O	0
They also prove theoretical convergence of the methods and motivate the design well.	Review	O	0
The paper is well-written and contained the necessary references.	Review	O	0
Although I did feel that the authors could have better compared their method against the recent AggMom (Aggregated Momentum: Stability Through Passive Damping by Lucas et al.).	Review	B-Review	1
Seems like there are a few similarities there.	Review	I-Review	1
[line_break_token][line_break_token]I enjoyed reading this paper and endorse it for acceptance.	Review	O	0
The theoretical results presented and easy to follow and state the assumptions clearly.	Review	O	0
I appreciated the fact that the authors aimed to keep the paper self-contained in its theory.	Review	O	0
The numerical experiments are thorough and fair.	Review	O	0
The authors test  the algorithms on an extremely wide set of problems ranging from image recognition (including CIFAR and ImageNet), natural language processing (including the state-of-the-art machine translation model), and reinforcement learning (including MuJoCo).	Review	O	0
I have not seen such a wide comparison in any paper proposing training algorithms before.	Review	O	0
Further, the numerical experiments are well-designed and also fair.	Review	O	0
The hyperparameters are chosen carefully, and both training and validation errors are presented.	Review	O	0
I also appreciate that the authors made the code available during the reviewing phase.	Review	O	0
Out of curiosity, I ran the code on some of my workflows and found that there was some improvement in performance as well.	Review	O	0
[line_break_token][line_break_token][line_break_token]	Review	O	0
We thank the reviewer for their encouraging and constructive feedback.	Reply	O	0
We are heartened that the reviewer has found the algorithms useful for their own applications!	Reply	O	0
[line_break_token][line_break_token]# Using multiple momentum buffers[line_break_token][line_break_token]We appreciate the pointer to the AggMo algorithm (Lucas et al.,	Reply	O	0
2018), which proposes the additive use of many momentum buffers with different values of beta (the momentum constant).	Reply	B-Reply	1
We had tried this in independent preliminary experimentation (toward analyzing many-state optimization), and we found that using multiple momentum buffers yields negligible value over using a single slow-decaying momentum buffer and setting an appropriate immediate discount (i.e. QHM with high beta and appropriate nu).	Reply	I-Reply	1
Given the added costs and complexity of using multiple momentum buffers, we decided against discussing many-state optimization.	Reply	I-Reply	1
[line_break_token][line_break_token]We believe that the two papers are largely orthogonal, as one paper focuses in depth on two-state optimization, while the other more broadly explores many-state optimization.	Reply	I-Reply	1
However, in light of AggMo's existence, we believe it is valuable to comment on the relationship between QHM and AggMo.	Reply	I-Reply	1
Specifically, we have updated the manuscript as follows:[line_break_token]- In section 4.5, we briefly connect QHM to AggMo.	Reply	I-Reply	1
[line_break_token]- In Appendix H, we provide a supplemental discussion and comparison with AggMo.	Reply	I-Reply	1
Specifically, we perform the autoencoder study from Appendix D.1 of Lucas et al. (	Reply	I-Reply	1
2018) with both algorithms, using the EMNIST dataset.	Reply	I-Reply	1
In short, we believe that the results of this comparison support the above notion from our preliminary experimentation.	Reply	I-Reply	1

### Summary of contributions[line_break_token][line_break_token]This paper aims to accelerate the training of deep networks using a selective sampling.	Review	O	0
[line_break_token]They adapt ideas from active learning (which use some form of uncertainty estimation about the class of the label) to selectively choose samples on which to perform the backward pass.	Review	O	0
Specifically, they use the minimal margin score (MMS).	Review	O	0
[line_break_token]Their algorithm works by computing the forward pass over a batch of size B (which is much larger than the regular batch of size b), compute the uncertainty measure for each sample, and only perform the backward pass over the b samples with the highest uncertainty.	Review	O	0
The motivation is that the backward pass is more expensive than the forward pass, and that by only performing this pass on a subset of samples, computations are saved.	Review	O	0
[line_break_token][line_break_token][line_break_token]### Recommendation[line_break_token][line_break_token]Reject.	Review	O	0
The central premise of the paper is unclear, the writing/presentation needs improvement, and the experiments are not convincing.	Review	O	0
[line_break_token][line_break_token][line_break_token]### Detailed comments/improvements: [line_break_token][line_break_token][line_break_token]There is a central premise of the paper that I don't understand: that the forward pass is much cheaper than the backward pass.	Review	O	0
[line_break_token]This is claimed in the intro by referring to charts that hardware manufacturers publish (but there are no references included), but I don't see why this should be the case.	Review	B-Review	1
[line_break_token]For a linear network with weights W, the forward pass is given by the matrix-matrix product (rows of X are minibatch samples):[line_break_token]Y = XW^T[line_break_token][line_break_token]and the backward pass is given by the two matrix-matrix products:[line_break_token]dL/dX = dL/dY*dY/dX = dL/dY*W[line_break_token]dL/dW = dL/dY*dY/dW = dL/dY*X^T[line_break_token][line_break_token]Similarly the two operations in the backward pass for convolutional layers are given by a convolution of the output gradients with the transposed weigtht kernels and the input image respectively.	Review	I-Review	1
[line_break_token][line_break_token]Point being, I don't see why the backward pass should be more than 3x more expensive than the forward pass.	Review	I-Review	1
A simple experiment in PyTorch confirms this: the code snippet pasted at the bottom shows that the backward pass takes only around 2.6x longer than the forward pass.	Review	I-Review	1
 [line_break_token][line_break_token]fprop: 0.009286s[line_break_token]bprop: 0.0240s[line_break_token]bprop/fprop: 2.5893x[line_break_token][line_break_token]In algorithm 1, it is assumed that b &lt;&lt; B. For this to be effective the forward pass would have to be *much* faster than the backward pass for this method to yield an improvement in computation.	Review	O	0
Can the authors comment on where this justification comes from?	Review	B-Review	1
[line_break_token][line_break_token]I am unclear on what the purpose of Section 4.1 is.	Review	I-Review	1
This shows that the MMS of the proposed method is lower than the other two, but this should be completely expected since that is exactly the quantity being minimized.	Review	I-Review	1
[line_break_token]There are also several unsubstantiated claims: "Lower MMS scores resemble a better...batch of samples", "the batches selected by our method provide a higher value for the training procedure vs. the HNM samples.", "	Review	I-Review	1
Evidently, the mean MMS provides a clearer perspective...and usefulness of the selected samples".	Review	I-Review	1
What does higher value, usefulness, clearer perspective mean?	Review	I-Review	1
[line_break_token][line_break_token]More generally, it is unclear if there is really any improvement in the final performance from using the proposed method.	Review	O	0
[line_break_token]In Figure 2, all methods seem to have similar final performance.	Review	B-Review	2
[line_break_token]In Figure 5, is there a reason why the curve for MMS is cut off?	Review	I-Review	3
How does its final performance compare to that of the baseline method in red?	Review	I-Review	3
It looks like the baseline might be better, but it's hard to tell from the figure.	Review	I-Review	3
[line_break_token][line_break_token]Why are the experiments with the entropy measure in a seperate section?	Review	I-Review	4
Please include them along with the other methods in the same plot, i.e merge Figure 2 and Figure 4.	Review	I-Review	4
[line_break_token][line_break_token]My suggestions for improving the experimental section are as follows:[line_break_token]- include all methods together in all the plots/tables[line_break_token]- repeat experiments multiple times with different seeds to get error bars.	Review	O	0
Include these both in the learning curves and in the tables.	Review	B-Review	6
[line_break_token]- It's hard to see small differences in the learning curves, so including tables as well is important.	Review	O	0
Include best performance for all the methods in the tables.	Review	B-Review	7
[line_break_token][line_break_token]Finally, in 2019 CIFAR alone is not longer a sufficient dataset to report experiments on.	Review	I-Review	8
Please report results on ImageNet as well.	Review	I-Review	8
[line_break_token][line_break_token]One of the central premises of the paper is acceleration in terms of compute/time.	Review	I-Review	9
To make this point, there should also be results in terms of walltime and floating-point operations.	Review	I-Review	9
Please include these results in the paper.	Review	I-Review	9
 [line_break_token]    [line_break_token][line_break_token][line_break_token][line_break_token]### Code snippet timing forward/backward passes[line_break_token][line_break_token][line_break_token]import torch, torch.nn as nn, time[line_break_token][line_break_token]model =[tab_token]nn.	Review	I-Review	9
Sequential(nn.	Review	I-Review	9
Linear(784, 1000),[line_break_token]                      nn.	Review	I-Review	9
ReLU(),[line_break_token]                      nn.	Review	I-Review	9
Linear(1000, 1000),[line_break_token]                      nn.	Review	I-Review	9
ReLU(),[line_break_token]                      nn.	Review	I-Review	9
Linear(1000, 10),[line_break_token]                      nn.	Review	I-Review	9
LogSoftmax())[line_break_token][line_break_token]data = torch.randn(128, 784)[line_break_token]labels = torch.ones(128).long()[line_break_token]t = time.time()[line_break_token]pred = model.forward(data)[line_break_token]loss = nn.functional.nll_loss(pred, labels)[line_break_token]fprop_time = time.time() - t[line_break_token]t = time.time()[line_break_token]loss.backward()[line_break_token]bprop_time = time.time() - t[line_break_token]print('fprop: {:.4}s'.format(fprop_time))[line_break_token]print('bprop: {:.4f}s'.format(bprop_time))[line_break_token]print('bprop/fprop: {:.4f}x'.format(bprop_time / fprop_time))[line_break_token]	Review	I-Review	9
ear reviewer #2:[line_break_token][line_break_token]We would like to thank you for the feedback and the effort involved in running the performance example you presented.	Reply	O	0
We will answer the questions and reply to the comments raised:[line_break_token][line_break_token]1) As for the answer regarding our central premise.	Reply	O	0
In order to select the samples using our MMS scheme, we leverage inference concepts that are entirely different from training.	Reply	B-Reply	1
Some of the prominent ideas are low precision arithmetic operations when applying quantization, layers fusion like Convolution-BatchNorm (applying the BN running statistics into the convolutions and eliminating the need of performing BN) and weight compression.	Reply	I-Reply	1
These concepts are not theoretical as they are being used when building specialized hardware accelerators as T4 (by Nvidia), Goya (by Habana) and TPU (by Google), allowing these devices to be ~10X faster at inference than running training step on a modern GPU.	Reply	I-Reply	1
A detailed explanation and performance charts can be seen in Google‚Äôs TPU paper ‚ÄúIn-Datacenter Performance Analysis of a Tensor Processing Unit‚Äù.	Reply	I-Reply	1
[line_break_token][line_break_token]Additionally, for distributed training on large-scale hardware, the advantage of the inference devices is even greater.	Reply	I-Reply	1
As the training instances must wait to a gradient reduction across all instances, the inference devices can perform forward passes on multiple instances in full parallelism (i.e. inference is embarrassingly parallel), without the need to wait to any other instance in the system.	Reply	I-Reply	1
 Thus, it can potentially select more offline examples for our MMS scheme.	Reply	I-Reply	1
[line_break_token][line_break_token]Finally, more performance benchmarks can be found when referring to Habana‚Äôs site (<a href="https://habana.ai/inference/" target="_blank" rel="nofollow">https://habana.ai/inference/</a> and <a href="https://habana.ai/training/)" target="_blank" rel="nofollow">https://habana.ai/training/)</a> as the training vs. inference throughput on their hardware is 1650 vs. 15453 images/sec.	Reply	O	0
[line_break_token][line_break_token]2) As for "In Figure 2 all methods seem to have similar final performance.".	Reply	O	0
Our main goal is not to improve final accuracy but rather to train less steps than the vanilla training regime.	Reply	B-Reply	2
For that purpose, we introduced the early LR drop regime (as seen in Figure 5).	Reply	I-Reply	2
We presented the plots in Figure 2 in order to show the relatively large deviation in the validation error as well as the training error.	Reply	I-Reply	2
The validation error decrease using our MMS method implies a faster convergence and that a faster regime can be used.	Reply	I-Reply	2
We further accept the comment and will move these plots to the appendix as well as mention their purpose in the paper.	Reply	I-Reply	2
[line_break_token][line_break_token]3) As for cutting CIFAR100 validation error for the early LR drop regime.	Reply	O	0
We decided to end this experiment when the error reaches a sufficient performance w.r.t the baseline training (red).	Reply	B-Reply	3
Moreover, we explicitly stated the final accuracy of the baseline and our MMS method in Table 1, showing a drop of 0.07% with almost halving the baseline required steps (from 156K to 80K steps).	Reply	I-Reply	3
[line_break_token][line_break_token]4) We kindly accept your comment regarding the entropy experiment and will include it with the other methods plot.	Reply	O	0
[line_break_token][line_break_token]5) We couldn't run many experiments due to time limitations, but we will make the effort to add STD bars.	Reply	O	0
[line_break_token]6) We will expand Table 1 as suggested with the entropy experiment and will add more relevant step information for clarity.	Reply	O	0
[line_break_token]7) We will add the ImageNet experiment.	Reply	O	0

The authors extend recent work in equivariant set encoding to the setting of entity-relation data.	Review	O	0
 Similar to the cited previous work, they encode sets of objects (in this case the tuples of a relational database) with a permutation invariant function.	Review	O	0
They use a parameter tieing scheme to enforce this invariance.	Review	O	0
[line_break_token][line_break_token]I don‚Äôt find the paper to be particularly well motivated.	Review	B-Review	1
Relational DBs are not necessarily a setting where you would always want equivariance.	Review	I-Review	1
While the ordering of tuples do not matter, relations are often asymmetrical.	Review	I-Review	1
Further, the idea of concatenating all tuples of a relational DB to be passed through a particular feed forward layer is infeasible for all but the smallest datasets.	Review	I-Review	2
Real world databases such as knowledge bases contains millions to billions of entries.	Review	I-Review	2
Scaling issues aside, the experiments do not actually show that this method outperforms any reasonable baselines such as a simple tensor factorization.	Review	I-Review	3
[line_break_token][line_break_token]I also found it particularly hard to follow the descriptions of the methods.	Review	I-Review	4
A few specific points:[line_break_token]- The text and notation in the beginning of section 2 could be a lot clearer.	Review	I-Review	4
I had to read these paragraphs multiple times to pick out precisely what you were trying to say.	Review	I-Review	4
Maybe have the set of relations be [R] like your other sets rather than a different script R. [line_break_token]- In the next paragraph you say ‚ÄúA particular relation R is a multiset if it contains multiple copies of the same entity‚Äù but you previously defined R to be a set of instances and not entities.	Review	O	0
I think you need to be more consistent with your terminology since the differences between type level entities and instances is important for your definitions and as you noted in your first footnote, these terms are often used very differently.	Review	B-Review	5
[line_break_token]- This explanation could be helped a lot by improving the figure.	Review	O	0
The caption and images are both very dense but still requires a lot of coreference.	Review	B-Review	6
For example, labeling the entities and relations with their ids in figure 1a directly would make it much easier to mentally map to what you are explaining in the caption.	Review	I-Review	6
Also figure 1c is not at all clear.	Review	I-Review	6
[line_break_token][line_break_token]Lastly, the methodology seems quite incremental over the previous work.	Review	O	0
A lot of the context and background that was sent to the appendix should be included in the main paper, particularly the relation to related work[line_break_token][line_break_token][line_break_token]edits:[line_break_token]double ‚Äòthe‚Äô in abstract ‚Äúlinear complexity in the the data ‚Äú	Review	O	0
hank you for your review.	Reply	O	0
[line_break_token][line_break_token]REVIEW: "I don‚Äôt find the paper to be particularly well motivated.	Reply	O	0
Relational DBs are not necessarily a setting where you would always want equivariance.	Reply	O	0
While the ordering of tuples do not matter, relations are often asymmetrical."	Reply	O	0
[line_break_token][line_break_token]RESPONSE: The notion of ‚Äúasymmetry‚Äù of relations raised in the review is unclear to us.	Reply	O	0
If for example, you mean ‚Äústudent-course‚Äù relation is different from ‚Äúcourse-student‚Äù relation, then we agree.	Reply	B-Reply	1
However, we do not understand your concern.	Reply	I-Reply	1
Could you please elaborate?	Reply	I-Reply	1
[line_break_token][line_break_token]REVIEW: "Further, the idea of concatenating all tuples of a relational DB to be passed through a particular feed forward layer is infeasible for all but the smallest datasets.	Reply	O	0
Real world databases such as knowledge bases contains millions to billions of entries.	Reply	O	0
 "[line_break_token][line_break_token]RESPONSE: Practicality is an important point that we also address in the paper.	Reply	O	0
The model produced here does not perform any subsampling of the database, which is essential for its application to large datasets.	Reply	B-Reply	2
We have seen successful examples of subsampling for graphs, and matrices recently.	Reply	I-Reply	2
In the case of a relational database, subsampling is more involved, as one has to deal with variable amounts of sparsity across different relations (tables).	Reply	I-Reply	2
This is left for future work.	Reply	I-Reply	2
[line_break_token][line_break_token]REVIEW: "Scaling issues aside, the experiments do not actually show that this method outperforms any reasonable baselines such as a simple tensor factorization."	Reply	O	0
[line_break_token][line_break_token]RESPONSE: We could not use tensor-factorization as a baseline in our experiments.	Reply	O	0
Tensor factorization applies to settings where we have a single relation ‚Äî for example, a user-move relation, or user-item-tag relation.	Reply	B-Reply	3
This is the setting studied by Hartford et al‚Äô18.	Reply	I-Reply	3
Since we show that our model reduces to their model in this setting, comparison to tensor factorization would amount to reproducing their results.	Reply	I-Reply	3
To use the language of tensor factorization in our setup: we have multiple tensors that share some dimensions and need to be jointly factorized.	Reply	I-Reply	3
We do not know of any factorization method for this task.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]REVIEW: "- The text and notation in the beginning of section 2..."[line_break_token][line_break_token]RESPONSE: Based on your feedback we will try to make this part more clear (note that Using [R] for the set of relations would be misleading as the notation [X] is often used when X is ordinal or has an ordinal index, while in our paper, R is defined to be a set.)	Reply	O	0
[line_break_token][line_break_token]REVIEW: "In the next paragraph you say ‚ÄúA particular relation R is a multiset if it contains multiple copies of the same entity‚Äù but you previously defined R to be a set of instances and not entities.	Reply	O	0
I think you need to be more consistent with your terminology..."[line_break_token][line_break_token]RESPONSE: We never defined R as a set of instances (could you please identify lines that misled you?	Reply	O	0
Since this is basic notation used throughout the paper, it is important we fix any ambiguity.)	Reply	B-Reply	5

In this paper the authors solve for the task of Raven Progressive Matrices (RPM) reasoning.	Review	O	0
They do so by considering multiplexed graph networks.	Review	O	0
They present an architecture for the same.	Review	O	0
The basic premise is a combination of object level representation that is obtained by a method similar to region proposal and combining them with graph network.	Review	O	0
The approach uses gated graph networks that also uses an aggregation function.	Review	O	0
These are combined and result in node embeddings.	Review	O	0
Detailed analysis of the network is provided.	Review	O	0
This provides improved results over earlier WREN method.	Review	O	0
However, the performance is slightly lesser than another paper simultaneously submitted that achieves similar results.	Review	B-Review	3
That approach uses transformer network for spatial attention while here the spatial attention is just based on object level representation.	Review	I-Review	3
[line_break_token][line_break_token]Over all while the contribution is useful, not much analysis is provided on the interpretability of the results.	Review	I-Review	1
For instance, the statistics in terms of the search space reduction as to how many subsets get pruned.	Review	I-Review	1
Further, there may be subsets of graphs that could span across rows and columns.	Review	I-Review	2
The decision in terms of restricting the reduction to span specific rows or columns may result in pertinent nodes also being pruned.	Review	I-Review	2
Certain aspects that relate to object level representation are not very clear.	Review	I-Review	2
I am not fully aware about results in this specific area and that may also be a reason for the same.	Review	I-Review	2
[line_break_token][line_break_token]To conclude, I believe this paper provides a useful contribution by modeling the diagrammatic abstract reasoning as a graph based reasoning approach.	Review	O	0
The multiplex graph network could be a useful component that is also relevant for other problems.	Review	O	0
The paper provides sufficient analysis to convince us regarding the claims.	Review	O	0
hank you for your valuable comments.	Reply	O	0
In our revised version, we improved explanations of our models with more details.	Reply	O	0
Here we address some of your concerns:[line_break_token][line_break_token]1. "	Reply	O	0
the statistics in terms of the search space reduction as to how many subsets get pruned":[line_break_token]We have added more statistics of the search space reduction experiments in Appendix D, such as the top-16 subsets with the highest gating values.	Reply	O	0
[line_break_token][line_break_token]2.	Reply	O	0
Further, there may be subsets of graphs that could span across rows and columns.	Reply	O	0
The decision in terms of restricting the reduction to span specific rows or columns may result in pertinent nodes also being pruned:[line_break_token][line_break_token]The subsets are not constrained to rows and columns.	Reply	O	0
During search space reduction we only make the weak assumption that edges in the same subset must be adjacent (defined as two edges linking the same node).	Reply	B-Reply	2
This allows for subsets other than rows and columns, such as diagonal of the matrix.	Reply	I-Reply	2
The search space reduction experiments however give lower scores for subsets other than rows and columns.	Reply	I-Reply	2
This is why we hard-gate only row and columns subsets in the final architecture.	Reply	I-Reply	2
We explained this more clearly in the revised version.	Reply	I-Reply	2
[line_break_token][line_break_token]3. "	Reply	O	0
However, the performance is slightly lesser than another paper simultaneously submitted that achieves similar results.	Reply	O	0
That approach uses transformer network for spatial attention while here the spatial attention is just based on object level representation":[line_break_token][line_break_token]We have just noted this parallel submission and compared it with our results.	Reply	O	0
We found that our model performs better for PGM dataset(89.6% against 88.2% in neutral split with beta=10).	Reply	B-Reply	3
In their response to comments, they stated that their model achieved performance of 19.67% for RAVEN-10000, which is the public dataset we used in the experiments.	Reply	I-Reply	3
We achieved 83.91% accuracy.	Reply	I-Reply	3
They did not make it clear how did they obtain 50k samples for each figure configuration, but our guess is that they used the open-source code to generate more data than available in RAVEN-10000	Reply	I-Reply	3

This paper proposed to use the duality gap sup_f V(f, g*) ‚Äì inf_g V(f*, g) as a metric for GAN training.	Review	O	0
It proves that this metric is an upper bound of F-distance.	Review	O	0
It also proves a generalization bound for this metric.	Review	O	0
Simulation resultson MNIST, CIFAR10, etc.	Review	O	0
are reported.	Review	O	0
[line_break_token][line_break_token]  The contribution of this paper is incremental due to the following reasons.	Review	O	0
[line_break_token][line_break_token] 1) The duality gap is only an upper bound of the F-distance.	Review	O	0
This means that if the duality gap is zero then the learned distribution is the true distribution.	Review	B-Review	1
However, the converse is not necessarily true: even if the algorithm starts with the true distribution, the duality gap may not be zero.	Review	I-Review	1
Thus the metric is not a proper metric.	Review	I-Review	1
[line_break_token]  The proof of the upper bound is straightforward.	Review	I-Review	1
[line_break_token][line_break_token]  2) Another issue is the gap between the min-max formulation and the real training algorithm.	Review	O	0
As for GAN, due to the inexact update, it is not really solving the min-max problem.	Review	B-Review	2
For the proposed metric, it is also impossible to solve sup_f V(f, g*) and inf_g V(f*, g) to reasonable accuracy.	Review	I-Review	2
Thus what the algorithm is really doing, perhaps, is to optimizing a new loss which is the sum of the original loss and and an extra term.	Review	I-Review	2
Viewing it as a ‚Äúduality gap‚Äù seems to be far from the practical training.	Review	I-Review	2
This discrepancy exists for GANs, but it is a bigger issue for the duality gap interpretation.	Review	I-Review	2
[line_break_token][line_break_token]  3) The simulation is not convincing.	Review	O	0
The reported FID for CIFAR10 using WGAN-GP is 54.4, which seems to be a bit high.	Review	B-Review	3
I‚Äôm not sure whether it is due to parameter choice or due to weak D/G networks used in the simulation.	Review	I-Review	3
If the paper cannot compare various architecture, it is more convincing to at least use some standard architecture, like DCGAN.	Review	I-Review	3
Or at least report the parameter tuning effort made for getting the results.	Review	I-Review	3
hanks for your attention to our work.	Reply	O	0
[line_break_token]1) For the first problem that the duality gap is only an upper bound of F-distance.	Reply	O	0
Our logic is that: a) There exists a condition s.t.	Reply	B-Reply	1
duality gap = 0.	Reply	I-Reply	1
b) If duality gap = 0, then the generator is the best one that can generate the true distribution.	Reply	I-Reply	1
May be in the algorithm, we will miss the best generator because we do not get the equilibrium.	Reply	I-Reply	1
[line_break_token][line_break_token]2) Our method may encounter the same problem as the traditional algorithm.	Reply	O	0
It is a kind of Markov chain to train the Loss.	Reply	B-Reply	2
And the essence of the algorithm is in fact to solve and.	Reply	I-Reply	2
We should consider some better algorithm to solve it.	Reply	I-Reply	2
[line_break_token][line_break_token]3) For the experiments, we will do some modification and improve our network.	Reply	O	0

1) Summary[line_break_token]This paper presents a graph neural network based architecture that is trained to locate and model the interactions of agents in an environment directly from pixels.	Review	O	0
They propose an architecture that is a composition of recurrent neural networks where each models a single object independently and communicate with other for the overall environment modeling.	Review	O	0
The model is trained with a variational recurrent neural network objective that allows for stochasticity in the predictions while at the same time allows to model the current and future steps simultaneously.	Review	O	0
In experiments, they show the advantage of using the proposed model for tasks of tracking as well as forecasting of agents locations.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]2) Pros:[line_break_token]+ Novel recurrent neural network architecture to model structured dynamics of agents in an environment.	Review	O	0
[line_break_token]+ Outperforms baseline methods.	Review	O	0
[line_break_token]+ New dataset for partially observable prediction research.	Review	O	0
[line_break_token][line_break_token]3) Cons:[line_break_token][line_break_token]Forecasting task:[line_break_token]- The authors argue that a discretization needs to be performed because of the many possible futures given the past, and also provide an error measure based on likelihood.	Review	O	0
However, if trajectories are actually generated from these distributions, I suspect the many possible futures generated will be very shaky.	Review	B-Review	1
Can the authors provide trajectories sampled from this?	Review	I-Review	1
If sampling trajectories does not make sense somehow, can the authors comment on how we can sample multiple trajectories?	Review	I-Review	1
[line_break_token][line_break_token]Lack of baselines:[line_break_token]- The authors mention social LSTM and social GAN in the related work, however, no comparison is provided.	Review	O	0
From a quick glance, the authors of these papers work on trajectories.	Review	B-Review	2
However, the ‚Äúsocial‚Äù principle in those papers is general since it‚Äôs done from the computed feature vector.	Review	I-Review	2
Could it have not been used on top of one of the baselines?	Review	I-Review	2
If not, could the authors provide a reason why this is not the case?	Review	I-Review	2
[line_break_token][line_break_token][line_break_token]Additional comments:[line_break_token]As the authors mention, it would be nice to extend this paper to an unsupervised or semi-supervised task.	Review	O	0
Here are a couple of papers that may interest you:[line_break_token]<a href="https://arxiv.org/abs/1804.04412" target="_blank" rel="nofollow">https://arxiv.org/abs/1804.04412</a>[line_break_token]<a href="https://arxiv.org/abs/1705.02193" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.02193</a>[line_break_token]<a href="https://arxiv.org/abs/1806.07823" target="_blank" rel="nofollow">https://arxiv.org/abs/1806.07823</a>[line_break_token][line_break_token]4) Conclusion[line_break_token]Overall, the paper is well written, easy to understand, and seems to be simple enough to quickly reproduce.	Review	O	0
Additionally, the proposed dataset may be of use for the community.	Review	B-Review	4
If the authors are able to successfully address the issues mentioned, I am willing to improve my score.	Review	I-Review	4
We appreciate your constructive feedback, and very useful references!	Reply	O	0
[line_break_token][line_break_token](1) Forecasting task:[line_break_token]We provide the sampled trajectories in Figure 5 and Appendix.	Reply	O	0
In particular, Figure 5(a) and Figure A2 show the multiple samples generated by Graph-VRNN.	Reply	B-Reply	1
We observe the trajectories are relatively stable.	Reply	I-Reply	1
For soccer data, since the perception task is more challenging and many players are not observed, we find the belief states to be uncertain for the first several steps (having more observed steps would help in this case).	Reply	I-Reply	1
For basketball data, we find that the belief states for players are usually stable, but the ball is more uncertain (bottom right row of Figure 4).	Reply	I-Reply	1
We suspect that it‚Äôs due to the movement of ball is much faster (which may be addressed by using a higher FPS).	Reply	I-Reply	1
[line_break_token][line_break_token](2) Lack of baselines:[line_break_token]As pointed out by the reviewer, Social-LSTM and Social-GAN work with trajectory data by default.	Reply	O	0
However, their social-pooling mechanism can be used as an alternative to the relation network used in Graph-RNN.	Reply	B-Reply	2
We use the pooling mechanism from Social-GAN, which is more recent and has no additional hyper parameters.	Reply	I-Reply	2
We find it to perform slightly worse than Graph-RNN (which uses Relation Networks), but better than Indep-RNN.	Reply	I-Reply	2
Note that the graph network module is a building block in our model, and RN can be replaced by other graph network architectures	Reply	I-Reply	2

The authors use a Gaussian-binary deep Boltzmann machine (GDBM) to model aspects of visual cortex.	Review	O	0
Training of the GDBM involves the centering trick of [8]. The comparison to visual cortex is in terms of learned receptive field properties, and by reproducing experimentally observed properties of activity in V1 as reported by [1]. In particular, these findings relate spontaneous activity in the absence of external stimulation to evoked activity.	Review	O	0
[line_break_token][line_break_token]On the positive side, I think the issue of the nature of spontaneous activity is interesting, and the authors put effort into reproducing the experimental findings of [1]. On the negative side, the significance of the main contributions seems lacking to me, and the authors need to motivate better why their work is important or relevant.	Review	O	0
Quality and clarity need to be improved in several points as well.	Review	O	0
[line_break_token][line_break_token][line_break_token]Details:[line_break_token][line_break_token]To expand on the above, I'll discuss three main points: 1) The centered GDBM.	Review	O	0
2) Reproducing aspects of visual cortex.	Review	O	0
3) The connection to homeostasis.	Review	O	0
[line_break_token][line_break_token]1) I wouldn't see this part as a major contribution of the paper.	Review	B-Review	1
The centering trick was originally applied to a fully binary DBM.	Review	I-Review	1
Applying the same trick to the GDBM (which only differs in having a Gaussian visible layer) seems a very natural thing to do.	Review	I-Review	1
Moreover, there is no further analysis on the efficacy of the centering trick.	Review	I-Review	1
The authors say that centering makes the GDBM easy to train compared to [15], but they don't actually evaluate the performance of the GDBM (other than comparing it to biological phenomenology), and only apply it to image patches.	Review	I-Review	1
In [15], the GDBM was trained on images of faces and evaluated in terms of filling in missing parts of the image.	Review	I-Review	1
Hence, it is not clear whether centering makes the more complicated training of [15] obsolete, as suggested by the authors.	Review	I-Review	1
[line_break_token][line_break_token]Also, when it comes to clarity: given that the authors emphasize the importance of centering, they need to better explain what it is, why it works, and how the centering parameters are computed (the latter is only described in the algorithm float).	Review	I-Review	1
These things are unclear to the reader unless they look at the reference.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]2) Reproducing aspects of visual cortex is the main contribution of the paper.	Review	O	0
First, the learned receptive fields are suggested to qualitatively resemble those in V1 and V2.	Review	B-Review	2
Learning V1-like Gabor filters is of course a quite common result nowadays.	Review	I-Review	2
I don't think it's possible to conclude that the model captures receptive field properties V2 well, just from looking at Figure 1b.	Review	I-Review	2
[line_break_token][line_break_token]Hence, the main contribution here is the analysis of activity.	Review	O	0
I think the results are fine and somewhat interesting, though not surprising.	Review	O	0
What is missing is better motivating/explaining why these results are interesting/relevant.	Review	B-Review	3
Sure, the GDBM reproduces certain experimental findings.	Review	I-Review	3
But have we learned something new about the brain?	Review	I-Review	3
Is the GDBM particularly well suited as a general model of visual cortex?	Review	I-Review	3
Does the model make predictions?	Review	I-Review	3
What about alternative, perhaps simpler models that could have been used instead?	Review	I-Review	3
Etc.	Review	I-Review	3
[line_break_token][line_break_token]Also, are there related models or theoretical approaches to spontaneous activity?	Review	I-Review	3
For example, this comes to mind:[line_break_token][line_break_token]Berkes, P., Orb√°n, G., Lengyel, M., & Fiser, J. (2011).	Review	O	0
Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment.	Review	O	0
Science (New York, N.Y.), 331(6013), 83‚Äì7.	Review	O	0
doi:10.1126/science.1195870[line_break_token][line_break_token]As for clarity: when collecting the spontaneous frames, presumably you are sampling from the full model distribution P(x,y,z) via Gibbs-sampling, with all layers unclamped, correct?	Review	O	0
Because writing that samples were collected from P(y|x,z) seems to suggest that you clamp to a specific x and z and collect multiple samples from the same conditional (not just as a step during Gibbs sampling).	Review	O	0
[line_break_token][line_break_token][line_break_token]3) Lastly, the connection between homeostasis and the author's model is unclear.	Review	B-Review	5
The authors mention homeostasis in the abstract, introduction and discussion, but do not explain homeostasis or how their results relate to it specifically.	Review	O	0
This needs to be explained better, especially to this audience.	Review	O	0
Personally, I know the literature somewhat (e.g. [4]), but am nevertheless unclear about what exactly the authors intend to say.	Review	O	0
[line_break_token]Sentences such as 'we are able to make the model learn the homeostasis from natural image patches' are unclear.	Review	O	0
[line_break_token][line_break_token]When I first read the paper, I thought the authors were referring to the centering trick as something that can be understood as a homeostatic mechanism (i.e., a neuronal mechanism that maintains a certain average firing rate, see [4], [6,7]), which would make sense to me.	Review	B-Review	5
However, on further reading it seems to me that the authors refer to the fact that spontaneous activity resembles evoked activity as an aspect of homeostasis?	Review	I-Review	5
Why?	Review	I-Review	5
For comparison, [6,7] clamped the input to empty images (to simulate blindness), and had an active homeostatic mechanism at play that led to spontaneous activity resembling evoked activity.	Review	I-Review	5
In the authors' paper, spontaneous activity resembles evoked activity simply because the former is taken to be sampled from the unconditioned model distribution..?	Review	I-Review	5
I'm not sure where homeostasis, i.e. being subject to an active self-regularity mechanism, comes into play at this point.	Review	I-Review	5
[line_break_token][line_break_token](As an aside, I don't think the Friston reference [3] clears up what the authors' notion of homeostasis is, in particular as Friston talks about states of agents in their environments.	Review	I-Review	5
Frankly, Friston's theoretical claims are often unclear to me, to say the least, in particular when it comes to mixing together internal models in the brain, and methods that should apply to the latter such as variational inference, and external probabilistic descriptions of agents and environments.	Review	I-Review	5
Either way, if the authors would like to make a connection to Friston's theories in particular, then that connection should be explained better.	Review	I-Review	5
Generative/predictive brain models and homeostatic mechanisms per se are not exclusive to Friston's theory.)	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]Further comments:[line_break_token][line_break_token]* Abstract, 'Spontaneous cortical activity [...] are' -> is[line_break_token][line_break_token]* 2.1 first para, 'consisted' -> consisting[line_break_token][line_break_token]* Not sure why x,y,z are sometimes capitalized, sometimes not.	Review	O	0
[line_break_token][line_break_token]* 3.1 'sparse DBNs show worse match to the biological findings as reported in [1]. A quantitative comparison between centered GDBMs and sparse DBNs is still open for future studies.'	Review	O	0
Where was it shown to be a worse match then?	Review	B-Review	6
[line_break_token][line_break_token]* Figure 2: shouldn't the angles (figure titles) go from 0 to 180?	Review	O	0
[line_break_token][line_break_token][line_break_token]In conclusion, I think this work could potentially be interesting, but in its current form quality and clarity are somewhat lacking and significance is not quite clear.	Review	O	0
Thanks for your helpful comments.	Reply	O	0
[line_break_token]1) ‚ÄúThe centered GDBM.‚Äù[line_break_token][line_break_token]Clarified applying centering to Gaussian DBM is an extension of the previous work in [8]. The point we want to make here is that GDBM with centering can be trained without the pre-training procedure as described in [3]. In comparison, we followed the same setting in [3] with centered GDBM.	Reply	O	0
The reconstruction error here is 41.6 +/- 0.40 compared to the results of about 40 in [3]. We agree that the minor differences are not sufficient to claim the advantages of centered GDBMs over the non-centered version. (	Reply	B-Reply	1
This is also why we did not include this result in the previous version.)	Reply	I-Reply	1
Importantly however, as shown in [8], centering leads to improved conditions.	Reply	I-Reply	1
In our paper, we show that hidden units in both layers of the centered GDBM can learn meaningful features.	Reply	I-Reply	1
Thus, our present results also show empirically that the centering helps to overcome the commonly observed difficulties during training of GDBMs.	Reply	I-Reply	1
[line_break_token] [line_break_token]We have added more details about the centering in the revised version.	Reply	I-Reply	1
Because the main focus of this paper is to illustrate the capacity of GDBM in modeling spontaneous cortical activity, we did not include further analyses of the centering specifically for GDBMs.	Reply	I-Reply	1
[line_break_token][line_break_token]2) ‚ÄúReproducing aspects of visual cortex‚Äù[line_break_token]2.1) ‚ÄúI don't think it's possible to conclude that the model captures receptive field properties V2 well, just from looking at Figure 1b.	Reply	O	0
‚Äù[line_break_token][line_break_token]Done - We removed the statement suggesting that the model captures receptive field properties in V2.	Reply	O	0
See more details in the responses to the common comments B).	Reply	B-Reply	2
[line_break_token][line_break_token]2.2) ‚ÄúWhat is missing is better motivating/explaining why these results are interesting/relevant. ‚	Reply	O	0
Ä¶. have we learned something new about the brain?	Reply	O	0
Is the GDBM particularly well suited as a general model of visual cortex?	Reply	O	0
Does the model make predictions?	Reply	O	0
What about alternative, perhaps simpler models that could have been used instead?	Reply	O	0
Etc.	Reply	O	0
Also, are there related models or theoretical approaches to spontaneous activity?‚Äù[line_break_token][line_break_token]We mainly demonstrate that the GDBM is a meaningful model approach for basic receptive field properties and the emergence of spontaneous activity patterns in early cortical visual areas.	Reply	O	0
Compared to other models for modeling spontaneous cortical activity, GDBMs (or DBMs in general) are not limited to simple, low-dimensional, non-hierarchical variables [7], but extend to generative, hierarchical-structured models with an unsupervised learning fashion.	Reply	B-Reply	3
[line_break_token][line_break_token]Moreover, by reproducing the findings in [1] with centered GDBMs, we suggest that i) the spontaneous activity in early visual cortex are the result of interactions between sensory inputs and feedbacks from higher areas, ii) thus, early visual areas are sufficient to generate the observed spontaneous activity patterns.	Reply	I-Reply	3
[line_break_token][line_break_token]Together with the discussion of the failures to model the cortical activity with GRBMs and DBN (see details in the responses to the common comments E)), we have a new paragraph in the discussion to describe the interpretations of our results.	Reply	O	0
[line_break_token][line_break_token]2.3) ‚Äúwhen collecting the spontaneous frames, presumably you are sampling from the full model distribution P(x,y,z) via Gibbs-sampling, with all layers unclamped, correct?‚Äù[line_break_token][line_break_token]Clarified - During collecting the spontaneous frames, we indeed ran sampling from the full model distribution P(X, Y, Z) via Gibbs-sampling with all layers unclamped.	Reply	O	0
This sampling procedure is supposed to approximate the samples from the model‚Äôs prior distribution P(Y), which are the expected states of the Y without any knowledge of X and Z. And we use P(Y|x, z) from a single step during Gibbs sampling as an approximation of Y, which is referred as to a spontaneous frame.	Reply	B-Reply	4
 We added more details of the samplings procedure in section 3.2.1 and 3.2.2.	Reply	I-Reply	4
See more details in the responses to common comments C).	Reply	I-Reply	4
[line_break_token][line_break_token]3) ‚Äúthe connection between homeostasis and the author's model is unclear.	Reply	O	0
‚Äù[line_break_token][line_break_token]Removed the term ‚Äúhomeostasis‚Äù to avoid misunderstanding.	Reply	O	0
See more details in the responses to common comments D).	Reply	B-Reply	5
[line_break_token][line_break_token]4) ‚Äú3.1 'sparse DBNs show worse match to the biological findings as reported in [1]. A quantitative comparison between centered GDBMs and sparse DBNs is still open for future studies.'	Reply	O	0
Where was it shown to be a worse match then?‚Äù[line_break_token][line_break_token]We have attempted to use the (sparse) DBN to model the cortical activity.	Reply	O	0
But the results show worse match to the biological results in [1] as the spontaneous frames show less correlation to the orientation maps.	Reply	B-Reply	6
Both the comparison of results and the interpretation have been included in the revised discussion part.	Reply	I-Reply	6
See more details in the responses to common comments E).	Reply	I-Reply	6
[line_break_token][line_break_token]5)[line_break_token]* ‚ÄúNot sure why x,y,z are sometimes capitalized, sometimes not.	Reply	O	0
‚Äù[line_break_token][line_break_token]We use the upper case letters to denote the un-instantiated variables, i.e. the values of variables are not given.	Reply	O	0
In contrast, the lower case letters represent the instantiated variables.	Reply	O	0
[line_break_token][line_break_token]* ‚ÄúFigure 2: shouldn't the angles (figure titles) go from 0 to 180?‚Äù[line_break_token][line_break_token]Figure 2: Done ‚Äì Thanks for the hint, typo corrected.	Reply	O	0
The angles should go from 0 to 180	Reply	B-Reply	8

This paper studies the problem of identifying (discovering) synonymous entities.	Review	O	0
The paper proposes using the "contexts" of the entities as they occur in associated text corpora (e.g. Wiki) in the proposed neural-network based embedding approach for this task.	Review	O	0
The key novelties of the approach lie in the "matching" system used, where contexts of one entity are matched with that for the other entity to see how well they align with each other (which effectively determines the similarity of the two entities).	Review	O	0
Experiments are conducted on three different datasets to show the efficacy of the proposed approach.	Review	O	0
[line_break_token][line_break_token]Overall I found the paper to be an interesting read with some nice ideas mixed in.	Review	O	0
However I also had some concerns which are highlighted later down below, which I believe if addressed would lead to a very strong work.	Review	O	0
[line_break_token][line_break_token]Quality: Above average[line_break_token][line_break_token]In general the method seems to work somewhat better than the baselines and the method does have a couple of interesting ideas.	Review	O	0
[line_break_token][line_break_token]Clarity: Average[line_break_token][line_break_token]I found a few key details to be missing and also felt the paper could have been better written.	Review	O	0
[line_break_token][line_break_token]Originality: Average[line_break_token][line_break_token]The matching approach and use of the leaky units was interesting tidbits.	Review	O	0
Outside of that the work is largely about the application of such Siamese RNNs based networks to this specific problem. (	Review	O	0
The use of context of entities has already been looked at in previous works albeit in a slightly more limited manner)[line_break_token][line_break_token]Significance: Slightly below average[line_break_token][line_break_token]I am not entirely sold on the use of this approach for this problem given its complexity and unclear empirical gains vs more sophisticated baselines.	Review	O	0
The matching aspect may have some use in other problems but nothing immediately jumps out as an obvious application.	Review	B-Review	7
[line_break_token][line_break_token]----[line_break_token][line_break_token]Strengths / Things I liked about the paper:[line_break_token][line_break_token]- In general the method is fairly intuitive and simple to follow which I liked.	Review	O	0
[line_break_token]- The matching approach was an interesting touch.	Review	O	0
[line_break_token]- Similarly for the "leaky" unit.	Review	O	0
[line_break_token]- Experiments conducted on multiple datasets.	Review	O	0
[line_break_token]- The results indicate improvements over the baselines considered on all the three datasets.	Review	O	0
[line_break_token][line_break_token]Weaknesses / Things that concerned me:[line_break_token][line_break_token]-  (W1) Slightly unfair baselines?	Review	O	0
One of the first things that struck me in the experimental results was how competitive word2vec by itself was across all three datasets.	Review	B-Review	1
This made me wonder what would happen if we were to use a more powerful embedding approach say FastText, Elmo, Cove or the recently proposed BERT? (	Review	I-Review	1
The proposed method itself uses bidirectional LSTMs)[line_break_token][line_break_token]Furthermore all of them are equally capable of capturing the contexts as well.	Review	I-Review	1
An even more competitive (and fair) set of baselines could have taken the contexts as well and use their embeddings as well.	Review	I-Review	1
Currently the word2vec baseline is only using the embedding of the entity (text), whereas the proposed approach is also provided the different contexts at inference time.	Review	I-Review	1
The paper says using the semantic structure and the diverse contexts are weaknesses of approaches using the contexts, but I don't see any method that uses the context in an embedding manner -- say the Cove context vectors.	Review	I-Review	1
If the claim is that they won't add any additional value above what is already captured by the entity it would be good to empirically demonstrate this.	Review	I-Review	1
[line_break_token][line_break_token]- (W2) Significance testing: On the topic of experimentation, I was concerned that significance testing / error estimates weren't provided for the main emprical results.	Review	O	0
The performance gaps seem to be quite small and to me it is unclear how significant these gaps are.	Review	B-Review	2
Given how important significance testing is as an empirical practice this seems like a notable oversight which I would urge the authors to address.	Review	I-Review	2
[line_break_token][line_break_token]- (W3) Missing key details: There were some key aspects of the work that I thought were not detailed.	Review	O	0
Chief among these was the selection of the contexts for the entities.	Review	B-Review	3
How was this?	Review	I-Review	3
How were the 20 contexts identified?	Review	I-Review	3
Some of these entities are likely far more common than just 20 sentences and hence I wonder how these were selected?	Review	I-Review	3
[line_break_token][line_break_token]Another key aspect I did not see addressed: How were the entities identified in the text (to be able to find the contexts for them)?	Review	I-Review	3
The paper claims that they would like to learn from minimal human annotations but I don't understand how these entity annotations in the text were obtained.	Review	I-Review	3
This again seems like a notable oversight.	Review	I-Review	3
[line_break_token][line_break_token]- (W4) Concerns about the method: I had two major concerns about the method: [line_break_token][line_break_token](a) Complexity of method :  I don't see an analysis of the computational cost of the proposed method (which scales quadratically with P the number of contexts); [line_break_token][line_break_token](b) Effect of redundant "informative" contexts: Imagine you have a number of highly informative contexts for an entity but they are all very similar to each other.	Review	O	0
Due to the way the matching scores are aggregated, these scores are made to sum to 1 and hence no individual score would be very high.	Review	B-Review	4
Given that this is the final coefficient for the associated context, this seems like a significant issue right?	Review	I-Review	4
[line_break_token][line_break_token]Unless the contexts are selected to be maximally diverse, it seems like this can essentially end up hurting an entity which occurs in similar contexts repeatedly.	Review	I-Review	4
I would like to see have seen the rationale for this better explained.	Review	I-Review	4
[line_break_token][line_break_token](c) A smaller concern was understanding the reasoning behind the different loss functions in the siamese loss function with a different loss for the positive and the negative, one using a margin and one which doesn't.	Review	O	0
One which scales to 1/4, the other scaling to (1-m)^2.	Review	B-Review	4
This seems pretty arbitrary and I'd like to understand this.	Review	I-Review	4
[line_break_token][line_break_token]-(W5) Eval setting : My last concern was with the overall evaluation setup.	Review	O	0
Knowledge bases like Freebase are optimized for precision rather than recall, which is why "discovery" of new relations is important.	Review	B-Review	5
However if you treat all missing relationships as negative examples then how exactly are you measuring the true ability of a method?	Review	I-Review	5
Thus overall I'm pretty skeptical about all the given numbers simply because we know the KBs are incomplete, but are penalizing methods that may potentially discover relations not in the KB.	Review	I-Review	5
We thank the reviewer for the thorough review and constructive feedback.	Reply	O	0
[line_break_token][line_break_token]We first would like to thank the reviewer for the positive feedback on our work.	Reply	O	0
[line_break_token][line_break_token]For the part that concerned the reviewer, we elaborate point by point as shown below:[line_break_token][line_break_token](W1) For the experiment setting, the proposed model can work with various word embeddings.	Reply	O	0
The contribution of our work does not lie in the choice of word embeddings, but the proposed architecture that utilizes entity representations for bilateral matching among multiple pieces of contexts.	Reply	B-Reply	1
Our model is independent of the choice of word embeddings, and we adopt Word2vec as a base case.	Reply	I-Reply	1
We aim to experiment the modeling ability of different model architectures given the same word representation information for synonym discovery.	Reply	I-Reply	1
With sophisticated word embedding methods such as Elmo or BERT, which achieve decent performances on various NLP tasks, we do expect that both baselines and our model will get better performance.	Reply	I-Reply	1
[line_break_token][line_break_token](W2) We‚Äôve added the significance testing in the experiment and update Table 2 with discussions.	Reply	O	0
A single-tailed t-test is performed to see whether or not the proposed model can outperform other baselines with significant improvements.	Reply	B-Reply	2
[line_break_token][line_break_token](W3) For the missing key details, the contexts are randomly selected from all contexts in which each entity is mentioned.	Reply	O	0
Due to limitations on computing resources, we are only able to verify the performance of up to 20 pieces of randomly chosen contexts in which each entity is mentioned.	Reply	B-Reply	3
For Wiki+Freebase and PubMed+UMLS, the datasets come with entity mentions annotated.	Reply	I-Reply	3
While in MedBook+MKG, we apply existing NER model [1] with contextualized embeddings [2] to obtain the annotated entities from the text.	Reply	I-Reply	3
We clarified the claim about the annotation: the proposed model does not require additional structured annotations on the free-text corpus, such as entity ontologies, dependency parsing results during training and inference.	Reply	I-Reply	3
The inference stage for synonym discovery is also designed to be data-driven so that we do not need pre-specified candidate entity pairs prepared by domain experts to be verified by the model, which further alleviates annotation efforts.	Reply	I-Reply	3
We added these details in the revised version	Reply	I-Reply	3

Summary of contributions: Studies the effect of # of parameters, # of layers, and # of units on convolutional net performance.	Review	O	0
Uses recurrence to run nets that have e.g. more layers but not more parameters in order to distinguish the effects of these three properties.	Review	O	0
[line_break_token][line_break_token]Novelty: moderate[line_break_token]Quality: low[line_break_token][line_break_token]Pros:[line_break_token][tab_token]-Nice empirical demonstration that more parameters helps.	Review	O	0
[line_break_token]Cons:[line_break_token][tab_token]-Does not study dropout.	Review	O	0
I think dropout is really important for this kind of paper, because dropout has a strong effect on the optimal model size.	Review	B-Review	3
Also, dropout is crucial part of the state of the art system on both CIFAR-10 and SVHN, so it seems out of place for a paper on how to set hyperparameters to good performance out of a neural net to disregard one of the most important techniques for getting good performance.	Review	I-Review	3
[line_break_token][tab_token]-Insufficient tuning of hyperparameters.	Review	O	0
[line_break_token][tab_token]-Support for the claims in the abstract seems weak, with many experiments going against the claims[line_break_token][tab_token]-The stated goal is to provide guidance for how to set hyperparameters so that practitioners don‚Äôt have to resort to trial and error.	Review	O	0
But I don‚Äôt really see anything here that prevents that.	Review	B-Review	6
For example, Fig 4a shows standard U-shaped curves for the # of layers hyperparameter.	Review	I-Review	6
The paper says ‚Äúadding more layers tends to increase performance‚Äù but this is only true on the left side of the U!	Review	I-Review	6
The whole point of trial and error is to figure out where the bottom of the U is, and this paper completely ignores that.	Review	I-Review	6
[line_break_token][tab_token]-The kind of parameter tying considered in this paper is not one that is typically used in practice, at least not for this kind of problem.	Review	O	0
The conclusions are therefore not all that helpful.	Review	B-Review	7
i.e., the authors introduce a new form of parameter tying, and then show it isn‚Äôt useful.	Review	I-Review	7
We don‚Äôt need to publish that conclusion, because no one is using this useless form of parameter tying anyway.	Review	I-Review	7
[line_break_token][tab_token]-The authors don‚Äôt investigate the effect of the tiling range of tiled convolution, which is a form of control on the degree of parameter sharing that people actually use.	Review	O	0
It‚Äôd be much more interesting to study this form of parameter sharing. (	Review	B-Review	8
This paper feels a bit like it started off as a ‚Äúnew methods‚Äù paper advocating convolutional recurrence, and then when the new method didn‚Äôt perform well, the authors tried to salvage it as an ‚Äúempirical investigation‚Äù paper, but the empirical investigation part isn‚Äôt really targeted at the methods that would be most useful to study)[line_break_token][line_break_token]Detailed comments:[line_break_token][line_break_token]1.1 Related work:[line_break_token][line_break_token][tab_token]You should also mention ‚ÄúMulti-Prediction Deep Boltzmann Machines‚Äù, Goodfellow et al 2013.	Review	O	0
This paper uses recurrent networks on the image datasets MNIST and NORB.	Review	B-Review	9
Like DrSAE, it is discriminative.	Review	I-Review	9
It may be interpreted as a form of autoencoder, like the methods you mention in the second paragraph.	Review	I-Review	9
[line_break_token][line_break_token][tab_token][line_break_token]2 Approach:[line_break_token][tab_token]Your approach is definitely not the first to use recurrence and convolution in the same model.	Review	O	0
It‚Äôs probably worth discussing similarities and differences to Honglak Lee‚Äôs convolutional DBN.	Review	B-Review	10
He describes performing mean field inference in this model.	Review	I-Review	10
The mean field computations are essentially forward prop in a convolutional recurrent architecture, but the connectivity is different than in yours, since each update reads from two layers, and some of the weight matrices are constrained to be the transpose of each other rather than being constrained to be equal to each other.	Review	I-Review	10
[line_break_token][line_break_token][tab_token]It‚Äôs also probably worth discussing how you handle the boundaries of the image, since this has a strong effect on the performance of a convolutional net.	Review	I-Review	10
Since you say all the layers have the same size, I‚Äôm assuming you implicitly pad the hidden layer with zeros when running convolution so that the output of the discrete convolution operation has the same size as the input.	Review	I-Review	10
[line_break_token][line_break_token][tab_token][line_break_token]2.1 Instantiation on CIFAR-10 and SVHN[line_break_token][line_break_token][tab_token]I don‚Äôt know what it means to put the word ‚Äúsame‚Äù in quotes.	Review	O	0
I‚Äôm assuming this refers to the zero padding that I described above, but it‚Äôs worth clarifying.	Review	B-Review	11
[line_break_token][line_break_token]2.2[line_break_token][tab_token]I think it‚Äôs fairly disappointing that you don‚Äôt train with dropout.	Review	I-Review	12
[line_break_token][tab_token]How did you choose this one fixed learning rate and momentum value?	Review	I-Review	12
How do you know it doesn‚Äôt bias the results?	Review	I-Review	12
For example, if you find that deeper models are better, are you really finding that deeper models are better in general, or are you just finding that deeper models are more compatible with this specific learning rate and momentum setting?	Review	I-Review	12
[line_break_token][tab_token]It seems especially important to tune the learning rate in this work because varying the amount of parameter sharing implies varying the number of gradient terms that affect each parameter.	Review	I-Review	12
The speed at which the parameters move is probably much higher for the nets with many recurrent steps than it is for the nets with no recurrence.	Review	I-Review	12
[line_break_token][line_break_token]3.1[line_break_token][tab_token]‚ÄúThat we were able to train networks at these large depths is due to the fact that we initialize all W to the identity‚Äù -> it‚Äôs not obvious to me that it should be hard to train convolutional rectifier networks at most of these depths.	Review	O	0
For example, Google‚Äôs house number transcription paper submitted to this conference at the same time trains a 12 layer mostly convolutional network with no mention of network depth posing a challenge or requiring special initialization.	Review	B-Review	13
The maxout paper reports difficulty training a 7 layer rectifier net on MNIST, but that was densely connected, not convolutional.	Review	I-Review	13
Was it only difficult to train the recurrent nets, or also the untied ones?	Review	I-Review	13
This is important to explain, since if the recurrent nets are significantly harder to optimize, that affects the interpretation of your results.	Review	I-Review	13
[line_break_token][tab_token]Are the higher layer weights for all of the networks initialized to the identity, or only the ones with tied parameters?	Review	I-Review	13
Is it literally identity or identity times some scalar?	Review	I-Review	13
If it‚Äôs literally identity rather than identity times some scalar, it might be too hard for SGD to shrink the initial weights and learn a different more interesting function.	Review	I-Review	13
Have you tried other initializations that don‚Äôt impose such a strong hand-designed constraint, such as James Martens‚Äô sparse initialization, where each hidden units gets exactly k randomly chosen non-zero incoming weights?	Review	I-Review	13
This initialization scheme is also described as making it easier to train deep or recurrent nets, and it seems to me like it doesn‚Äôt trap the recurrent layer as being a fairly useless memory layer that mostly functions to echo its input.	Review	I-Review	13
[line_break_token][line_break_token][tab_token]‚ÄúLikewise, for any given combination of feature maps and layers, the untied model outperforms the tied one, since it has more parameters.	Review	I-Review	13
‚Äù I don‚Äôt agree with the claim that the untied model performs better because it has more parameters.	Review	I-Review	13
This would make sense if the tied model was in the underfitting regime.	Review	I-Review	13
But you have already said in the same paragraph that many of the tied models are in the overfitting regime.	Review	I-Review	13
If you look at fig 2.	Review	I-Review	13
there are several points where both the tied and untied model have 0 training error and the tied model has higher validation set error.	Review	I-Review	13
If the correct story here is overfitting due to too many parameters, then the untied model should do worse.	Review	I-Review	13
I suspect what‚Äôs going on here is something like the identity initialization being a bad prior, so that you fit the training set in a way that doesn‚Äôt generalize well, or maybe just your choice of a single momentum and learning rate setting for all experiments ended up benefiting the untied model somehow.	Review	I-Review	13
For example, as I said above, the recurrent nets will generally have larger gradients on each parameter, so maybe the high learning rate makes the recurrent net adapt too much to the first few minibatches it sees.	Review	I-Review	13
[line_break_token][line_break_token][tab_token]Fig 2[line_break_token][tab_token][tab_token]In the abstract you say ‚Äúfor a given parameter budget, deeper models are preferred over shallow ones.	Review	O	0
‚Äù It would be nice if on the plot on the left you evaluted points along the parameter budget contour lines instead of points on a grid, since the grid points don‚Äôt always hit the contour lines.	Review	B-Review	14
As is, it‚Äôs hard to evaluate the claim from the abstract.	Review	I-Review	14
However, I don‚Äôt see a lot of support for it.	Review	I-Review	14
The best test error you get is toward the bottom right: 0.160 at the rightmost point in the second row from the bottom.	Review	I-Review	14
Of course, this is the only point on that parameter budget contour, so it may just be winning because of its cost.	Review	I-Review	14
However, if I look for the point with the most depth, I see one with 0.240 near the 2^18 contour line.	Review	I-Review	14
At the bottom right of this contour line, the shallow but wide model gets 0.205.	Review	I-Review	14
[line_break_token][tab_token][tab_token]Overall, here is my summary of all your contour lines:[line_break_token][tab_token][tab_token][tab_token]2^16: only one point on it[line_break_token][tab_token][tab_token][tab_token]2^17: Contradicts claim[line_break_token][tab_token][tab_token][tab_token]2^18: Contradicts claim[line_break_token][tab_token][tab_token][tab_token]2^19: Contradicts claim[line_break_token][tab_token][tab_token][tab_token]2^20: Supports claim (sort of, points aren‚Äôt that close to contour line)[line_break_token][tab_token][tab_token][tab_token]2^21: Supports claim (sort of, points aren‚Äôt that close to contour line)[line_break_token][tab_token][tab_token][tab_token]2^22: Supports claim (sort of, points aren‚Äôt that close to contour line)[line_break_token][tab_token][tab_token]So it seems to me that this plot contradicts the claim from the abstract at least as much as it supports it.	Review	I-Review	14
[line_break_token][line_break_token][tab_token]Right figure:[line_break_token][tab_token][tab_token]This supports the claim in your abstract.	Review	O	0
[line_break_token][line_break_token][tab_token]Table 1: While it does make sense to compare *these* experiments against methods that don‚Äôt use dropout or data augmentation, I don‚Äôt think it makes sense for these to be your only experiments.	Review	O	0
I think the case for excluding data augmentation from consideration is getting very weak.	Review	B-Review	15
There is now a lot of commercial interest in using neural nets on very large datasets.	Review	I-Review	15
Augmentation of small datasets provides a nice low-cost proxy for exploring this regime.	Review	I-Review	15
[line_break_token]As far as I know, the main reasons for not considering data augmentation are 1) data augmentation requires knowledge of the data domain, in this case that the input is an image and the output is invariant to shifts in the input.	Review	I-Review	15
But you are already exploiting exactly that same knowledge by using a convolutional net and spatial pooling.	Review	I-Review	15
2) gaining improvements in performance by improving data augmentation techniques distracts attention from improving machine learning methods and focuses it on these more basic engineering tricks.	Review	I-Review	15
But I‚Äôm not asking you to engineer new data augmentation methods here; you can just use exactly the same augmentation as many previous authors have already used on CIFAR-10 and SVHN.	Review	I-Review	15
[line_break_token]I don‚Äôt think there is any valid case at all for excluding stochastic regularization from consideration.	Review	I-Review	15
It doesn‚Äôt require any knowledge of the data domain and it is absolutely a machine learning technique rather than just an engineering trick.	Review	I-Review	15
Moreover, it is computationally very cheap, and state of the art across the board.	Review	I-Review	15
By refusing to study stochastic regularization you are essentially insisting on studying obsolete methods.	Review	I-Review	15
The only regime in which stochastic regularization is not universally superior to deterministic backprop is in the extremely large data domain, which as academics you probably don‚Äôt have access to and you are also actively avoiding by not using data augmentation.	Review	I-Review	15
[line_break_token][line_break_token][tab_token]Fig 2 and 3 in general: I understand it‚Äôs too expensive to extensively cross-validate every point on these plots, but I think it‚Äôd be good to pick maybe 4 points for each plot (maybe the upper-left and lower-right of two different contour lines) and run around 10 experiments each for those 4 points.	Review	O	0
Overall that is 80 training runs, which I think is totally reasonable.	Review	B-Review	16
The current plots are somewhat interesting but it‚Äôs hard to have much confidence that the trends they indicate are real.	Review	I-Review	16
Obtaining higher confidence estimates of the real value of a small number of points would help a lot to confirm that the trends are actually caused by the # of feature maps and depth rather than compatibility with a fixed optimization scheme.	Review	I-Review	16
[line_break_token][line_break_token]Section 4:[line_break_token][tab_token]I don‚Äôt think the ‚Äúreceived wisdom‚Äù is that more depth is always better, just that the optimal depth is usually greater than 1.	Review	I-Review	17
[line_break_token][tab_token]You say your experiments show that more depth is better for a fixed parameter budget, but doesn‚Äôt Fig 2. (	Review	I-Review	17
right) contradict this?	Review	I-Review	17
Thank you for your comments.	Reply	B-Reply	18
 We have updated the paper with some major revisions, and it is now online.	Reply	I-Reply	18
 Responses to your comments are below	Reply	I-Reply	18

[line_break_token]The paper essentially addresses the difficult problem of visual representation evaluation.	Review	O	0
It attempts to find a universal way of assessing the quality of a model's representation.	Review	O	0
The authors define a good representation as one that can adapt to unseen tasks with few examples.	Review	O	0
With this in mind, they propose Visual Task Adaptation Benchmark (VTAB), a benchmark that is focused on sample complexity and task diversity.	Review	O	0
[line_break_token][line_break_token]- Very clear, well written and well structured. (	Review	O	0
Although not fully self contained in the main body of the paper - 20 pages of supplementary material!)	Review	O	0
[line_break_token]- The benchmark tasks are constrained to unseen tasks, which seems obvious but is often violated when evaluating representations[line_break_token]- It does a good attempt at covering a large spectrum of realistic domains (19 tasks!)	Review	O	0
to assess generality.	Review	O	0
[line_break_token]- Extensive study is conducted, covering the published state of the art methods in each domain.	Review	O	0
[line_break_token]- The study leads to interesting finding, such as promising results on self-supervision and negative results on generation.	Review	O	0
[line_break_token][line_break_token]Overall, I believe the paper is an important contribution as it provides some interesting analysis of the current state of the art for visual representation learning.	Review	O	0
hank you for your very positive comments.	Reply	O	0
Do you have feedback on any aspects that could improve this work?	Reply	O	0
[line_break_token][line_break_token]We recognise that we defer many details and analyses to the Appendix.	Reply	O	0
It was challenging with both a new benchmark and an extensive study, to distill the most important points into 10 pages.	Reply	O	0
If you think that there are aspects that we should re-prioritize, we would be happy to try to refactor	Reply	O	0

This paper study the lottery ticket hypothesis by observing the properties of lottery tickets.	Review	O	0
In particular, the authors tested several different pruning techniques by varying evaluation criteria (L_1, L_2, L_-\infty and random) and pruning structures (structured, unstructured and hybrid).	Review	O	0
The authors perform experiments mainly on LeNet with the MNIST dataset and analyze the observations.	Review	O	0
[line_break_token][line_break_token]Overall, I think that the observations presented in the paper are not significant due to the following reasons.	Review	O	0
[line_break_token][line_break_token]First, the paper consists of the list of observations but how the observations extend to is not clearly described.	Review	B-Review	2
There are no guidelines how to utilize the observations in future research (e.g., how they can be used for verifying the lottery ticket hypothesis or how they affect to existing pruning techniques) while some observations might be trivial or not very interesting (e.g., contribution 1 and contribution 2) for me.	Review	I-Review	2
[line_break_token][line_break_token]Second, the observations are only presented for LeNet and MNIST and it is non-trivial whether they extend to large scale models.	Review	I-Review	3
The authors present VGG11 and AlexNet results in Appendix but they are not large enough to verify their hypothesis for practice.	Review	I-Review	3
The authors mentioned that larger models are not their subject, but this significantly reduces the confidence of the observations.	Review	I-Review	3
[line_break_token][line_break_token]Other comments:[line_break_token]I think that Figure 5 is not well described.	Review	O	0
Explicitly noting the meaning of color in the figure would be better.	Review	B-Review	1
[line_break_token][line_break_token]Texts in Figure 7 are too small to read.	Review	I-Review	1
[line_break_token]	Review	O	0
irst of all, thank you for your comments.	Reply	O	0
[line_break_token][line_break_token]We would like to offer our point of view for why we disagree with the notion that the contributions and observations presented here are not interesting to the field.	Reply	B-Reply	2
We agree that perhaps these approaches cannot directly be utilized at the moment to help reach SoTA on a given task.	Reply	I-Reply	2
This utilitarian way of evaluating the contribution is at odds with the stated goal of the paper, which is to simply advance fundamental knowledge in the subdomain of science of deep learning.	Reply	I-Reply	2
Many of the findings in this paper directly go to address major open questions around the nature and emergence of lottery tickets, including observations #1 and #2, which we therefore deem to be interesting and relevant to the field (or at least to those doing research in this sub-field).	Reply	I-Reply	2
Objections to the absence of these studies have been raised in the community in the past to challenge the lottery ticket hypothesis itself.	Reply	I-Reply	2
To the best of the authors knowledge, a thorough study of structure characterization of lottery tickets emerging from a multitude of pruning methods is itself of interest to better begin to understand more about this emergent behavior and move towards principled approaches to lottery ticket discovery.	Reply	I-Reply	2
[line_break_token][line_break_token]In addition, we disagree that observations on small models are not significant.	Reply	I-Reply	3
If we are to understand the dynamics of what is happening in pruned models, under the lottery ticket hypothesis or any other hypothesis, we need to remove factors of variation introduced by SoTA seeking architectures.	Reply	I-Reply	3
Even in the case where dynamics discovered in small networks do not apply to a large, say, ResNeXt or NasNet, that alone is interesting future work and important to understand and document.	Reply	I-Reply	3
We do agree that confirmatory experiments in larger more complex domains would be a useful extension of this work, but not a necessary one to make these empirical discoveries worthwhile.	Reply	I-Reply	3
[line_break_token]While we agree that it is non-trivial to extend lottery tickets to larger models (as is well documented in the literature) we believe that understanding why and when lottery tickets emerge in smaller models will help us better apply them to larger models in the future.	Reply	I-Reply	3
[line_break_token][line_break_token]As per your direct comments, we have improved the description of Fig.	Reply	I-Reply	1
5. ‚	Reply	I-Reply	1
Ä®The caption on Figure 7 already contains all the necessary information to decipher what the axes in the subplots represent (the numerical values are not important and the axes could be entirely removed in favor of simply showing the qualitative trend)	Reply	I-Reply	1

Summary: They tackle the problem of out-of-data distribution by leveraging RND applied to data augmentations.	Review	O	0
They train a model f(x) to match the outputs of g_i(aug_i(x)), where g_i is a random network and aug_i is a particular type of augmentation.	Review	O	0
An example with high error in this task is treated as an out-of-distribution example.	Review	O	0
This work focuses on exploring blurring through SVD, where the smallest K singular values are set to 0, and K varies between different aug_i calls.	Review	O	0
They find that their method of consistently can achieve strong detection rates across multiple target-dataset pairs.	Review	O	0
[line_break_token][line_break_token]Comments:[line_break_token]* The experimental results in this work are impressive, which introduces many more questions.	Review	O	0
[line_break_token]* The model used for f and g is not mentioned in the text.	Review	O	0
[line_break_token]* Figure 4 (left) suggests that the SVD-RND performs about the same between 10K and 50K examples.	Review	O	0
The level of robustness is surprising, but doesn‚Äôt seem to square with intuition that more data ought to help.	Review	B-Review	2
How little data can be used?	Review	I-Review	2
In other words, extend the graph to the left.	Review	I-Review	2
[line_break_token]* The geometric transforms baseline is not fair, since SVD-RND uses multiple SVD transforms (b_train &gt; 1) whereas the geometric transforms only have one.	Review	O	0
Please run a model with all the geometric transforms.	Review	B-Review	3
This result is important for understanding whether the gains come from the particular transform (SVD) or the number of transforms used.	Review	I-Review	3
[line_break_token]* Following the spirit of the previous comment, what other data augmentations can be used in place of SVD?	Review	O	0
Typical image classification pipelines use a large variety of augmentations.	Review	B-Review	4
I would suggest taking some augmentations from AutoAugment [1] and running RND on top of them.	Review	I-Review	4
[line_break_token]* An experiment that is missing is RND trained on blurred images.	Review	O	0
Is the blurring itself the important component, or is having multiple different heads important?	Review	B-Review	5
[line_break_token]* In general, I am confused about how a single head RND does not converge to 0 loss by learning the weights of g. This seems to be a simple optimization problem.	Review	O	0
The original RND paper avoided this problem by also using the network to learn a policy, but this does not exist in this approach.	Review	B-Review	6
[line_break_token]* Furthermore, a comparison with Ren et al. [	Review	O	0
2] and Nalisnick et al. [	Review	B-Review	7
3] would be useful. [	Review	I-Review	7
2] also uses data augmentation to create a background model that is compared against the real model.	Review	I-Review	7
One can probably simulate this approach by comparing the error rates of each head of RND.	Review	I-Review	7
[line_break_token][line_break_token]In general, this work seems promising, but lacks proper ablations that elucidate what components of the method are important.	Review	O	0
I am happy to increase my score if the experiments suggests are added to the work.	Review	O	0
[line_break_token][line_break_token][1] AutoAugment: Learning Augmentation Policies from Data.	Review	O	0
Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, Quoc V. Le[line_break_token][2] Likelihood Ratios for Out-of-Distribution Detection.	Review	O	0
Jie Ren, Peter J. Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark A. DePristo, Joshua V. Dillon, Balaji Lakshminarayanan[line_break_token][3] Detecting Out-of-Distribution Inputs to Deep Generative Models Using Typicality.	Review	O	0
Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Balaji Lakshminarayanan	Review	O	0
e first thank the reviewer for the feedback that helped to improve the paper.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
The model used for f and g is not mentioned in the text.	Reply	O	0
[line_break_token][line_break_token]-&gt; We modified the style of the paper and referenced the structure in Appendix B.[line_break_token][line_break_token]2.	Reply	O	0
Figure 4 (left) suggests that the SVD-RND performs about the same between 10K and 50K examples.	Reply	O	0
The level of robustness is surprising, but doesn‚Äôt seem to square with intuition that more data ought to help.	Reply	O	0
How little data can be used?	Reply	O	0
In other words, extend the graph to the left.	Reply	O	0
[line_break_token][line_break_token]-&gt; We extended the graph where 2000,4000,6000,8000 training data are available.	Reply	O	0
When 8000 training data is available, the performance of SVD-RND drops but still outperforms the performance of RND with 50000 training data.	Reply	B-Reply	2
When the data size is smaller than 8000, the performance drop is huge.	Reply	I-Reply	2
We modified Figure 4 to present the phenomenon mentioned above.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	3
 The geometric transforms baseline is not fair, since SVD-RND uses multiple SVD transforms  &gt; 1) whereas the geometric transforms only have one.	Reply	O	0
Please run a model with all the geometric transforms.	Reply	O	0
This result is important for understanding whether the gains come from the particular transform (SVD) or the number of transforms used.	Reply	O	0
[line_break_token][line_break_token]-&gt; First, we have combined the model with geometric transformations in the RND framework.	Reply	O	0
We experimented by merging rotation, flip, and translation, and this results in b_train=4*3*2-1=23.	Reply	B-Reply	3
Such a combination showed TNR(at 95% TPR) of 0.181/0.182/0.199 in CIFAR-10 : (SVHN, LSUN, TinyImageNet) domain.	Reply	I-Reply	3
This shows that combining different transforms to one does not always improve OOD detection performance.	Reply	I-Reply	3
[line_break_token][line_break_token]Also, we want to clarify that rotation or translation employs multiple transforms for training.	Reply	I-Reply	3
For example, in rotation, we assign different target network to each data rotated by 90, 180, and 270 degrees.	Reply	I-Reply	3
Therefore, rotation already has.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
 Following the spirit of the previous comment, what other data augmentations can be used in place of SVD?	Reply	O	0
Typical image classification pipelines use a large variety of augmentations.	Reply	O	0
I would suggest taking some augmentations from AutoAugment and running RND on top of them.	Reply	O	0
 [line_break_token][line_break_token]-&gt; We further experimented with the contrast, shear, and invert introduced in [1], and appended the results on the revised version.	Reply	O	0
[line_break_token][line_break_token]5.	Reply	O	0
 An experiment that is missing is RND trained on blurred images.	Reply	O	0
Is the blurring itself the important component, or is having multiple different heads important?	Reply	O	0
[line_break_token][line_break_token]-&gt; We also experimented RND trained on blurred images in the CIFAR-10 : (SVHN, LSUN, TinyImageNet) domain with varying K. This strategy showed the TNR(at 95% TPR) of 0.021/0.809/0.767, which showed slightly improved result compared to RND but still underperforms over SVD-RND.	Reply	O	0
Therefore, we hypothesize that "teaching the network to discriminate between blurred images and original images helped OOD detection".	Reply	B-Reply	5
[line_break_token][line_break_token]6.	Reply	O	0
In general, I am confused about how a single head RND does not converge to 0 loss by learning the weights of g. This seems to be a simple optimization problem.	Reply	O	0
The original RND paper avoided this problem by also using the network to learn a policy, but this does not exist in this approach.	Reply	O	0
[line_break_token][line_break_token]-&gt; First, we set that each target network in the experiment also corresponds to the complex function.	Reply	O	0
Therefore, we expect that much strict learning rate scheduling and more training epoch will be required to better convergence.	Reply	B-Reply	6
[line_break_token][line_break_token]Also, we reviewed the original RND paper and found that they do not update the predictor network via the policy loss.	Reply	I-Reply	7
The paper updates the predictor network only on the loss, which is the same as us.	Reply	I-Reply	7
We refer to the 14th page of  <a href="https://openreview.net/pdf?id=H1lJJnR5Ym" target="_blank" rel="nofollow">https://openreview.net/pdf?id=H1lJJnR5Ym</a> for the reference.	Reply	O	0
[line_break_token][line_break_token]	Reply	O	0

This paper introduces a new framework to interactively interact document retriever and reader for open-domain question answering.	Review	O	0
While retriever-reader framework was often used for open-domain QA, this bi-directional interaction between the retriever and the reader is novel and effective because[line_break_token]1) If the retriever fails to retrieve the right document at the first step, the reader can give a signal to the retriever so that the retriever can recover its mistake at the next step[line_break_token]2) The idea of `reader state` from the reader to the retriever is new[line_break_token]3) The retriever use question-independent representation of paragraphs, which does not require different representation depending on the question and makes the framework easily scalable.	Review	O	0
[line_break_token][line_break_token]Strengths[line_break_token]1) The idea of multi-step & bi-directional interaction between the retriever and the reader is novel enough (as mentioned above).	Review	O	0
The paper contains enough literature studies on existing retriever-reader framework in open-domain setting, and clearly demonstrates how their framework is different from them.	Review	O	0
[line_break_token]2) The authors run the experiments on 4 different dataset, which supports the argument about the framework‚Äôs effectiveness.	Review	O	0
[line_break_token][line_break_token]Weakness[line_break_token]1) The authors seem to highlight multi-step `reasoning`, while it is not `reasoning` in my opinion.	Review	O	0
Multi-step reasoning refers to the task which you need evidence from different documents, and/or you need to find first evident to find the second evidence from a different document.	Review	B-Review	1
I don‚Äôt think the dataset here are not multi-step reasoning dataset, and the authors seem not to claim it either.	Review	I-Review	1
Therefore, I recommend using another term (maybe `multi-step interaction`?)	Review	I-Review	1
instead of `multi-step reasoning`.	Review	I-Review	1
[line_break_token]2) While the idea of multi-step interaction and how it benefits the overall performance is interesting, the analysis is not enough.	Review	O	0
Figure 3 in the paper does not have enough description ‚Äî for example, I got the left example means step 2 recovers the mistake from step 1, but what does the right example mean?	Review	B-Review	2
[line_break_token][line_break_token]Questions on result comparison[line_break_token]1) On TriviaQA (both open and full), the authors mentioned the result is on hidden test set ‚Äî did you submit it to the leaderboard?	Review	O	0
I don‚Äôt see the same numbers on the TriviaQA leaderboard.	Review	B-Review	3
Also, the authors claim they are SOTA on TriviaQA, but there are higher numbers on the leaderboard (which are submitted prior to the ICLR deadline).	Review	I-Review	3
[line_break_token]2) There are other published papers with higher result on Quasar-T, SearchQA and TriviaQA (such as <a href="https://aclanthology.info/papers/P18-1161/p18-1161" target="_blank" rel="nofollow">https://aclanthology.info/papers/P18-1161/p18-1161</a> and <a href="https://arxiv.org/abs/1805.08092)" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.08092)</a> which the authors did not compare with.	Review	O	0
[line_break_token]3) In Section 4.2, is there a reason for the specific comparison to AQA (5th line), though AQA is not SOTA on SearchQA?	Review	O	0
I don‚Äôt think it means latent space is better than natural language space.	Review	B-Review	5
They are totally different model and the only intersection is they contains interaction between two submodules.	Review	I-Review	5
[line_break_token]4) In Section 5, the authors mentioned their framework outperforms previous SOTA by 15% margin on TriviaQA, but what is that?	Review	O	0
I don‚Äôt see 15% margin in Table 2.	Review	B-Review	6
[line_break_token][line_break_token]Marginal comments:[line_break_token]1) If I understood correctly, `TriviaQA-open` and `TriviaQA-full` in the paper are officially called `TriviaQA-full` and `open-domain TriviaQA`.	Review	O	0
How about changing the term for readers to better understand the task?	Review	B-Review	7
Also, in Section 4, the authors said TriviaQA-open is larger than web/wiki setting, but to my knowledge, this setting is part of the wiki setting.	Review	I-Review	7
[line_break_token]2) It would be great if the authors make the capitalization consistent.	Review	O	0
e.g. EM, Quasar-T, BiDAF.	Review	B-Review	8
Also, the authors can use EM instead of `exact match` after they mentioned EM refers to exact match in Section 4.2.	Review	I-Review	8
[line_break_token][line_break_token]Overall comment[line_break_token]The idea in the paper is interesting, and their model and experiments are concrete.	Review	O	0
My only worries is that the terms in the paper are confusing and performance comparison are weak.	Review	B-Review	9
I would like to update the score when the authors update the paper.	Review	I-Review	9
[line_break_token][line_break_token][line_break_token]Update 11/27/2018[line_break_token]Thanks for the authors for updating the paper.	Review	O	0
The updated paper have more clear comparisons with other models, with more & stronger experiments with the additional dataset.	Review	O	0
Also, the model is claimed to perform multi-step interaction rather than multi-step reasoning, which clearly resolves my initial concern.	Review	O	0
The analysis, especially ablations in varying number of iterations, was helpful to understand how their framework benefits.	Review	O	0
I believe these make the paper stronger along with its initial novelty in the framework.	Review	O	0
In this regard, I vote for acceptance.	Review	O	0
We thank you for your very useful and detailed review.	Reply	O	0
We have significantly updated the writing of the paper to hopefully address all confusion and we‚Äôve also updated the results section of the paper for better comparison.	Reply	B-Reply	9
In a nutshell, we have added a section on retriever performance demonstrating the scalability of our approach (sec 5.1).	Reply	I-Reply	9
We have improved results for our experiments with BiDAF reader and we have also added new results on the open-domain version of the SQuAD dataset.	Reply	I-Reply	9
Below we address your concerns point-by-point.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	3
The authors seem to highlight multi-step `reasoning`, while it is not `reasoning` in my opinion.	Reply	O	0
Multi-step reasoning refers to the task which you need evidence from different documents, and/or you need to find first evident to find the second evidence from a different document.	Reply	O	0
I don‚Äôt think the dataset here are not multi-step reasoning dataset, and the authors seem not to claim it either.	Reply	O	0
Therefore, I recommend using another term (maybe `multi-step interaction`?)	Reply	O	0
instead of `multi-step reasoning`.	Reply	O	0
[line_break_token][line_break_token]After much discussion among us, we have arrived to an agreement with your comment.	Reply	B-Reply	1
We have renamed the title of the paper to ‚ÄúMulti-step Retriever-Reader Interaction for Scalable Open-domain Question Answering‚Äù.	Reply	I-Reply	1
[line_break_token]We believe that our framework that supports retriever-reader interaction would be a starting point to build models for multi-hop reasoning but the current datasets do not explicitly need models with such inductive bias.	Reply	I-Reply	1
There has been some very recent efforts in this direction such as HotpotQA -- but this dataset was very recently released (after the ICLR submission deadline).	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
While the idea of multi-step interaction and how it benefits the overall performance is interesting, the analysis is not enough.	Reply	O	0
Figure 3 in the paper does not have enough description ‚Äî for example, I got the left example means step 2 recovers the mistake from step 1, but what does the right example mean?	Reply	O	0
[line_break_token][line_break_token]We have significantly updated this section of the paper with much more analysis.	Reply	B-Reply	2
We have included a new section on analysis of results (Sec 4.3) in which we quantitatively measure if the iterative interaction between the retriever and the reader is able to retrieve better context for the reader.	Reply	I-Reply	2
We have also updated Figure 2 to report the results of our model for steps = {1, 3, 5, 7} for SearchQA, Qusar-T and TriviaQA-unfiltered.	Reply	I-Reply	2
[line_break_token]To answer your specific question about the second example from figure 3, after the query reformulation the new paragraph that was added also has the right answer string, i.e. the total occurrence of the correct answer span increased after the reformulation step.	Reply	I-Reply	2
Since we sum up the scores of spans, this led to the overall increase in the score of the right answer span (Demeter, in Figure 3)  to be the maximum.	Reply	I-Reply	2
We have explained this in the text of the paper.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
On TriviaQA (both open and full), the authors mentioned the result is on hidden test set ‚Äî did you submit it to the leaderboard?	Reply	O	0
I don‚Äôt see the same numbers on the TriviaQA leaderboard.	Reply	O	0
Also, the authors claim they are SOTA on TriviaQA, but there are higher numbers on the leaderboard (which are submitted prior to the ICLR deadline).	Reply	O	0
[line_break_token][line_break_token]We apologize for the confusion about this experiment.	Reply	B-Reply	3
Ours and the reported baseline results are on the ‚ÄúTriviaQA-unfiltered‚Äù dataset (unfiltered version in <a href="http://nlp.cs.washington.edu/triviaqa/)," target="_blank" rel="nofollow">http://nlp.cs.washington.edu/triviaqa/),</a> for which there is no official leaderboard.	Reply	O	0
The unfiltered version is built for open-domain QA.	Reply	B-Reply	3
The evidence for each question in this setting are top 10 documents returned by Bing search results along with the Wikipedia pages of entities in the question.	Reply	I-Reply	3
In the web setting, each question is associated with only one web document and in the Wikipedia setting, each question is associated with the wiki pages of entities in the question (1.78 wiki pages per query on avg.)	Reply	I-Reply	3
Thus, the unfiltered setting has much more number of paragraphs than the individual web/wiki setting.	Reply	I-Reply	3
 Moreover, there is no guarantee that every document in the evidence will contain the answer making this setting even more challenging.	Reply	I-Reply	3
However we did submit our model predictions to the TriviaQA admin who emailed us back the result on the hidden test set and to the best of our knowledge, we achieve the highest result on this setting of TriviaQA.	Reply	I-Reply	3
We have updated the paper by naming this experiment TriviaQA-unfiltered and have clarified other details.	Reply	I-Reply	3

The paper proposed a novel SampleRNN to directly model waveform signals and achieved better performance both in terms of objective test NLL and subjective A/B tests.	Review	O	0
[line_break_token][line_break_token]As mentioned in the discussions, the current status of the paper lack plenty of details in describing their model.	Review	O	0
Hopefully, this will be addressed in the final version.	Review	O	0
[line_break_token][line_break_token]The authors attempted to compare with wavenet model, but they didn't manage to get a model better than the baseline LSTM-RNN, which makes all the comparisons to wavenets less convincing.	Review	O	0
Hence, instead of wasting time and space comparing to wavenet, detailing the proposed model would be better.	Review	O	0
Thanks for reviewing our paper.	Reply	O	0
It is much appreciated.	Reply	O	0
[line_break_token][line_break_token]Please find the top latest comment for the changelog of the recent revision	Reply	O	0

This paper conducts extensive experiments to study batch normalization, a very popular technique for training a deep convolutional network and its relationship with learning rate and batch size.	Review	O	0
In addition, the authors also propose a new initialization scheme, ‚ÄúZeroInit‚Äù, to train a deep ResNet for better test accuracy.	Review	O	0
This is a very empirical study and the authors also show extensive experimental results.	Review	O	0
However, I do not see any novel findings in this study.	Review	B-Review	1
Mostly this paper confirms the results of previous studies.	Review	I-Review	1
The experimental results do not show much advantage of ZeroInit either.	Review	I-Review	1
Overall, it is unclear what is the major novel contribution in this paper.	Review	I-Review	1
e thank the reviewer for their assessment of our work.	Reply	O	0
The reviewer agrees that our results are extensive but is unclear what the major contributions of this paper are.	Reply	O	0
To clarify:[line_break_token][line_break_token]1.	Reply	O	0
The two most influential recent works studying the benefits of batch normalization are Bjorck et al.	Reply	B-Reply	1
and Santurkar et al. (	Reply	I-Reply	1
both NeurIPS 2018).	Reply	I-Reply	1
Both papers argue that the key benefit of batch normalization is to improve the loss conditioning, which enables stable training with larger learning rates.	Reply	I-Reply	1
Our experiments prove that this statement is false.	Reply	I-Reply	1
When the batch size is small, the optimal learning rate with and without batch normalization is also small, yet batch normalized networks still achieve significantly higher test accuracies and lower training losses.	Reply	I-Reply	1
Large learning rates cannot be the key benefit of batch normalization in residual networks.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
There is great interest in finding alternatives to batch normalization.	Reply	B-Reply	1
We propose an extremely simple initialization scheme, ZeroInit, which is competitive with batch normalization and can be trained without any normalization.	Reply	I-Reply	1
The key component of ZeroInit is to add a scalar multiplier at the end of each residual branch initialized to zero.	Reply	I-Reply	1
Note that this can be implemented in a single line of code.	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
ZeroInit is similar to the recently proposed Fixup initialization (Zhang et al.,	Reply	B-Reply	1
ICLR 2019).	Reply	I-Reply	1
However, Zhang et al.	Reply	I-Reply	1
argued that the key component of Fixup is to rescale the conv layers inside residual branches at initialization.	Reply	I-Reply	1
We show empirically that this component is completely unnecessary, even if L2 regularization is also removed.	Reply	I-Reply	1
[line_break_token][line_break_token]4.	Reply	O	0
Zhang et al.	Reply	B-Reply	1
also argued that Fixup is stable at the same large learning rates as batch normalization.	Reply	I-Reply	1
Again, we show this claim is false.	Reply	I-Reply	1
Both ZeroInit and Fixup are only stable at smaller learning rates and consequently they are both only competitive with batch normalization for small/moderate batch sizes (eg &lt; 1000 on ImageNet)[line_break_token][line_break_token]5.	Reply	O	0
Entire papers have been written whose sole purpose is to provide an alternative to batch normalization when the batch size is too small to estimate batch statistics.	Reply	B-Reply	1
Examples include GroupNorm (over 250 citations) and batch renormalization (over 100 citations).	Reply	I-Reply	1
ZeroInit can be trained at batch size 1 without any drop in final performance.	Reply	I-Reply	1
[line_break_token][line_break_token]In summary, we believe our work contains a number of valuable novel contributions.	Reply	I-Reply	1
Crucially, our paper does not confirm the results of previous studies.	Reply	I-Reply	1
Instead, it shows that the core claims in a number of highly influential papers are false empirically, while also proposing an alternative to batch normalization in residual networks which is significantly simpler to implement than existing methods.	Reply	I-Reply	1

The paper proposes "wavelet pooling" as an alternative for traditional subsampling methods, e.g. max/average/global pooling, etc.,	Review	O	0
within convolutional neural networks.	Review	O	0
[line_break_token]Experiments on the MNIST, CIFAR-10, SHVN and KDEF datasets, shows the proposed wavelet-based method has[line_break_token]competitive performance with existing methods while still being able to address the overfitting behavior of max pooling.	Review	O	0
[line_break_token][line_break_token]Strong points[line_break_token]- The method is sound and well motivated.	Review	O	0
[line_break_token]- The proposes method achieves competitive performance.	Review	O	0
[line_break_token][line_break_token]Weak points[line_break_token]- No information about added computational costs is given.	Review	O	0
[line_break_token]- Experiments are conducted in relatively low-scale datasets.	Review	O	0
[line_break_token][line_break_token][line_break_token]Overall the method is well presented and properly motivated.	Review	O	0
The paper as a good flow and is easy to follow.	Review	O	0
The authors effectively demonstrate with few toy examples the weaknesses of traditional methods, i.e max pooling and average pooling.	Review	O	0
Moreover, their extended evaluation on several datasets show the performance of the proposed method in different scenarios.	Review	O	0
[line_break_token][line_break_token]My main concerns with the manuscript are the following.	Review	O	0
[line_break_token][line_break_token]Compared to traditional methods, the proposed methods seems to require higher computation costs.	Review	B-Review	1
In a deep neural network setting where operations are conducted a large number of times, this is a of importance.	Review	I-Review	1
However, no indication is given on what are the added computation costs of the proposed method and how that compares to existing methods.	Review	I-Review	1
A comparison on that regard would strengthen the paper.	Review	I-Review	1
[line_break_token][line_break_token]In many of the experiments, the manuscript stresses the overfitting behavior of max pooling.	Review	I-Review	2
This makes me wonder whether this is caused by the fact that experiments are conducted or relatively smaller datasets.	Review	I-Review	2
While the currently tested datasets are a good indication of the performance of the proposed method, an evaluation on a large scale scenario, e.g. ILSVRC'12, could solidify the message sent by this manuscript.	Review	I-Review	2
Moreover, it would increase the relevance of this work in the computer vision community.	Review	I-Review	2
[line_break_token][line_break_token]Finally, related to the presentation, I would recommend presenting the plots, i.e. Fig.	Review	I-Review	3
8,10,12,14, for the training and validation image subsets in two separate plots.	Review	I-Review	3
Currently, results for training and validation sets are mixed in the same plot, and due to the clutter it is not possible to see the trends clearly.	Review	I-Review	3
[line_break_token]Similarly, I would recommend referring to the Tables added in the paper when discussing the performance of the proposed method w.r.t.	Review	I-Review	3
traditional alternatives.	Review	I-Review	3
[line_break_token][line_break_token]I encourage the authors to address my concerns in their rebuttal	Review	O	0
We were actually able to add the computational complexity component as a subsection within the results and discussion.	Reply	B-Reply	1
We also modified the graphs and referenced the tables as you requested	Reply	I-Reply	3

The submission proposes to modify the typical GAN architecture slightly to include "encrypt" (Alice) and "decrypt" (Bob) modules as well as a module trying to decrypt the signal without a key (Eve).	Review	O	0
 Through repeated transmission of signals, the adversarial game is intended to converge to a system in which Alice and Bob can communicate securely (or at least a designated part of the signal should be secure), while a sophisticated Eve cannot break their code.	Review	O	0
 Examples are given on toy data:[line_break_token]"As a proof-of-concept, we implemented Alice, Bob, and Eve networks that take N-bit random plain-text and key values, and produce N-entry floating-point ciphertexts, for N = 16, 32, and 64.	Review	O	0
 Both plaintext and key values are uniformly distributed."	Review	O	0
[line_break_token][line_break_token]The idea considered here is cute.	Review	O	0
 If some, but not necessarily all of the signal is meant to be secure, the modules can learn to encrypt and decrypt a signal, while an adversary is simultaneously learned that tries to break the encryption.	Review	O	0
 In this way, some of the data can remain unencrypted, while the portion that is e.g. correlated with the encrypted signal will have to be encrypted in order for Eve to not be able to predict the encrypted part.	Review	O	0
[line_break_token][line_break_token]While this is a nice thought experiment, there are significant barriers to this submission having a practical impact:[line_break_token]1) GANs, and from the convergence figures also the objective considered here, are quite unstable to optimize.	Review	O	0
 The only guarantees of privacy are for an Eve that is converged to a very strong adversary (stronger than a dedicated attack over time).	Review	B-Review	1
 I do not see how one can have any sort of reliable guarantee of the safety of the data transmission from the proposed approach, at least the paper does not outline such a guarantee.	Review	I-Review	1
[line_break_token]2) Public key encryption systems are readily available, computationally feasible, and successfully applied almost anywhere.	Review	O	0
 The toy examples given in the paper do not at all convince me that this is solving a real-world problem at this point.	Review	B-Review	2
 Perhaps a good example will come up in the near future, and this work will be shown to be justified, but until such an example is shown, the approach is more of an interesting thought experiment.	Review	I-Review	2
We are glad about your comment that this paper presents ‚Äúan interesting thought experiment‚Äù, as it is in line with how we regard this work.	Reply	O	0
As for your points on the possible impact of this work:[line_break_token]1) We also agree that the techniques that we present are not likely to yield high-assurance security.	Reply	O	0
They may however yield suitable protection against low-grade attackers (much like spam filters) or against our own actions.	Reply	B-Reply	1
In particular, as suggested in the submission (page 2), they may be adequate in order to prevent one of our own neural-network components from using information that we want to keep from it because of concerns about privacy or discrimination.	Reply	I-Reply	1
[line_break_token]2) An important contrast with readily available encryption systems is that, with our approach, one learns what needs to be ‚Äúscrambled‚Äù for a given a protection goal (as indicated in our reply of December 8).	Reply	O	0

This paper proposes the use of holographic reduced representations in language modeling, which allows for a cleaner decomposition of various linguistic traits in the representation.	Review	O	0
Results show improvements over baseline language models, and analysis shows that the representations are indeed decomposing as expected.	Review	O	0
[line_break_token][line_break_token]The main reviewer concern was the lack of strength of the baseline, although the authors stress that they were using the default baseline from TensorFlow, which seems like it will be reasonable to me.	Review	B-Review	1
Another concern is that there is other work on using HRR to disentangle syntax and semantics in representations for language (e.g. "Distributed Tree Kernels" ICML 2012, but also others), that has not been considered.	Review	I-Review	2
[line_break_token][line_break_token]Based on this, this seems like a very borderline case.	Review	O	0
Given that no reviewer is pushing strongly for the paper I'm leaning towards not recommending acceptance, but I could very easily see the paper being accepted as well.	Review	O	0
We thank all reviewers and chair for your comments.	Reply	O	0
While we fully understand your concerns regarding the baseline results and related work, we hope to make it clear (once more) that:[line_break_token]1) Our intention was to make the results easily reproducible based on the widely available Tensorflow open-source implementation of LM on public datasets, with no sophisticated tricks or model modifications involved.	Reply	O	0
At the same time, we strongly believe that the main contribution of our submission - decomposition of representation - does not have to be correlated with perplexity results.	Reply	B-Reply	1
Better perplexity results do not guarantee decomposed representation, nor is a good decomposed representation hinged on good perplexity results.	Reply	I-Reply	1
[line_break_token]2) We acknowledge Reviewer 1 for pointing out related works, however the existing approaches, although using HRR as a component, are very different from the ones we proposed in our paper.	Reply	O	0
They would not naturally apply to learning disentangled linguistic features, the problem we aim to tackle and major contribution we make in our paper.	Reply	B-Reply	2
Our understanding is that Reviewer 1 raised this point in debating with our claim that a naively implemented chunk-level model is intractable, and it was not his intention to directly apply the work on tree kernel HRR to the decomposition task at hand.	Reply	I-Reply	2
[line_break_token][line_break_token]We believe that our proposed model, formulated specifically for addressing the topic of disentangled linguistic representation, is novel and effective, and provides a viable approach for future research.	Reply	I-Reply	3
We would greatly appreciate it if our comments and previous responses are taken into more serious consideration, and decisions properly revised	Reply	I-Reply	3

This paper presents TopicRNN, a combination of LDA and RNN that augments traditional RNN with latent topics by having a switching variable that includes/excludes additive effects from latent topics when generating a word.	Review	O	0
[line_break_token]Experiments on two tasks are performed: language modeling on PTB, and sentiment analysis on IMBD.	Review	O	0
[line_break_token]The authors show that TopicRNN outperforms vanilla RNN on PTB and achieves SOTA result on IMDB.	Review	O	0
[line_break_token][line_break_token]Some questions and comments:[line_break_token]- In Table 2, how do you use LDA features for RNN (RNN LDA features)?	Review	O	0
[line_break_token]- I would like to see results from LSTM included here, even though it is lower perplexity than TopicRNN.	Review	O	0
I think it's still useful to see how much adding latent topics close the gap between RNN and LSTM.	Review	B-Review	2
[line_break_token]- The generated text in Table 3 are not meaningful to me.	Review	O	0
What is this supposed to highlight?	Review	B-Review	3
Is this generated text for topic "trading"?	Review	I-Review	3
What about the IMDB one?	Review	I-Review	3
[line_break_token]- How scalable is the proposed method for large vocabulary size (>10K)?	Review	O	0
[line_break_token]- What is the accuracy on IMDB if the extracted features is used directly to perform classification? (	Review	O	0
instead of being passed to a neural network with one hidden state).	Review	B-Review	5
I think this is a fairer comparison to BoW, LDA, and SVM methods presented as baselines.	Review	I-Review	5
Thanks for your questions and for suggesting we add results for TopicLSTM!	Reply	O	0
[line_break_token][line_break_token]- In Table 2, the first two lines were results reported in Mikolov et al 2012.	Reply	O	0
They run LDA separately and extract features for words using the topic matrix.	Reply	B-Reply	1
[line_break_token][line_break_token]- We included results from TopicRNN, TopicLSTM, and TopicGRU.	Reply	O	0
Contrary to what we mentioned earlier, TopicLSTM and TopicGRU actually perform very well.	Reply	B-Reply	2
We corrected a bug on the computation of the ELBO.	Reply	I-Reply	2
The new results are consistent with the story and are reported in table 2. (	Reply	I-Reply	2
We are also running experiments with TopicGRU/TopicLSTM on IMDB data.	Reply	I-Reply	2
However, it takes some time to finish.	Reply	I-Reply	2
We will add them when they are available.)	Reply	I-Reply	2
[line_break_token][line_break_token]- Each text is generated using one example input document.	Reply	O	0
The input for IMDB was a negative review.	Reply	B-Reply	3
That sentiment is reflected in the generated text.	Reply	I-Reply	3
Note one can sample from the prior for the topic vector \theta and use that as bias on the trained model.	Reply	I-Reply	3
[line_break_token][line_break_token]-TopicRNN is a language model.	Reply	O	0
As reported at the bottom of page 5, the complexity is dominated by the computation of the softmax output layer as is the case for language models.	Reply	B-Reply	4
As such, all methods for dealing with the softmax layer are also applicable to TopicRNN.	Reply	I-Reply	4
We reported the computation time in the experiments section to give an idea.	Reply	I-Reply	4
[line_break_token][line_break_token]- We followed the procedure in Paragraph&nbsp;Vector.	Reply	O	0
The main comparison here is against other unsupervised neural network based approaches (ex: Le and Mikolov 2014).	Reply	B-Reply	5
Note it is also possible to train the classifier directly with TopicRNN.	Reply	I-Reply	5
However, we wanted to highlight TopicRNN as unsupervised feature extractor.	Reply	I-Reply	5

The paper presents a method to analyse how and what the auto-encoder models that use reconstruction error together with a regularisation cost, are learning with respect to the underlying data distribution.	Review	O	0
The paper focuses on contractive auto-encoder models and also reformulates denoising auto-encoder as a form of contractive auto-encoder where the contraction is achieved through regularisation of the derivative of reconstruction error wrt to the input data.	Review	O	0
The rest of the paper presents a theoretical analysis of this form of auto-encoders and also provides couple of toy examples showing empirical support.	Review	O	0
[line_break_token][line_break_token]The paper is easy to read and the theoretical analysis is nicely split between the main paper and appendices.	Review	O	0
The details in the main paper are sufficient for the reader to understand the concept that is presented in the paper.	Review	O	0
[line_break_token][line_break_token]The theory and empirical data show that one can recover the true data distribution if using contractive auto-encoders of the given type.	Review	O	0
I think this is quite an important result.	Review	B-Review	1
even though limited to this specific type of model, quantitative analysis of generative capabilities of auto-encoders have been limited.	Review	I-Review	1
[line_break_token][line_break_token]I find the experiment shown in Figure 4 somewhat confusing.	Review	I-Review	2
The text suggests that the only difference between the two models is their initial conditions and optimisation hyper parameters.	Review	I-Review	2
Is the main reason due to initial conditions or hyper parameters?	Review	I-Review	2
Which hyper parameters?	Review	I-Review	2
Is the difference in initial condition just a different random seed or different type of initialisation of the network?	Review	I-Review	2
I think this requires more in depth explanation.	Review	I-Review	2
Is it normal to expect such different solutions depending on initial conditions?	Review	I-Review	2
[line_break_token][line_break_token]Section 3.2.4.	Review	I-Review	3
I am not clear what is the importance of this section.	Review	I-Review	3
It seems to state the relationship between the score and reconstruction derivative.	Review	I-Review	3
[line_break_token][line_break_token]Is it possible to link these results and theory to other forms of auto-encoders, such as sparse auto-encoders or with different type of non-linear activation functions?	Review	I-Review	4
It would be very useful to have similar analysis for more general types of auto-encoders too.	Review	I-Review	4
> I think this is quite an important result.	Reply	O	0
even though limited to this specific type of model[line_break_token][line_break_token]As argued in a previous response (to reviewer 4222), we believe that at least at a qualitative level the same is true in general of regularized auto-encoders.	Reply	O	0
We copy here the response: [line_break_token]'We have worked on the denoising/contracting auto-encoders with squared error because we were able to prove our results with them, but we believe that other regularized auto-encoders (even those with discrete inputs) also estimate something related to the score, i.e., the direction in input space in which probability increases the most.	Reply	B-Reply	1
The intuition behind that statement can be obtained by studying figure 2: the estimation of this direction arises out of the conflict between reconstructing training examples well and making the auto-encoder as constant (regularized) as possible.'	Reply	I-Reply	1
[line_break_token]We have added a brief discussion in the conclusion about how we believe these results could be extended to models with discrete inputs, following the tracks of ratio matching (Hyvarinen 2007).	Reply	I-Reply	1
[line_break_token][line_break_token]We have also added (in new sec.	Reply	I-Reply	1
3.2.3) a brief discussion of how these new results (on r(x)-x estimating the score) contradict previous interpretations of the reconstruction error of auto-encoders (Ranzato & Hinton NIPS 2007) as being akin to an energy function.	Reply	O	0
Indeed whereas both interpretations agree on having a low reconstruction error at training examples, the score interpretation suggests (and we see it experimentally) other (median) regions that are local maxima of density, where the reconstruction error is also low.	Reply	B-Reply	1
[line_break_token][line_break_token]> I find the experiment shown in Figure 4 somewhat confusing.	Reply	O	0
[line_break_token][line_break_token]We have addressed this concern that many of the reviewers had.	Reply	B-Reply	2
The whole section 3.2.3 has been edited and we decided to remove two of the plots which may have introduced confusion.	Reply	I-Reply	2
Reviewers seem to focus on the difference between the two models and wanted to know why the outcomes were different.	Reply	I-Reply	2
They were only different because of the non-convexity of the problem and the dependance on initial conditions (along with the random noise used for training).	Reply	I-Reply	2
At the end of the day, the point is that the vector field points in the direction of the energy gradient, and that is illustrated nicely by the two plots left (far and close distance).	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]> Section 3.2.4.	Reply	O	0
I am not clear what is the importance of this section.	Reply	O	0
It seems to state the relationship between the score and reconstruction derivative.	Reply	O	0
[line_break_token][line_break_token]Are you referring to section 3.3 ?	Reply	B-Reply	3
If you are indeed referring to section 3.2.4, the idea there is that it is possible to start the investigation from a trained DAE where the noise level for the training is unknown to us (but it is known by the person who trained the DAE).	Reply	I-Reply	3
In that case, we would be in a situation where we the best that could be done was to recover the energy function gradient up to a scaling constant.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]> Is it possible to link these results and theory to other forms of auto-encoders, such as sparse auto-encoders or with different type of non-linear activation functions?	Reply	O	0
It would be very useful to have similar analysis for more general types of auto-encoders too.	Reply	O	0
[line_break_token][line_break_token]See our first response above.	Reply	O	0
[line_break_token][line_break_token]Please also have a look at a new short section (now identified as 3.2.5) that we just added in	Reply	O	0

This paper aims to synthesize programs in a Java-like language from a task description (X) that includes some names and types of the components that should be used in the program.	Review	O	0
The paper argues that it is too difficult to map directly from the description to a full program, so it instead formulates the synthesis in two parts.	Review	O	0
First, the description is mapped to a "sketch" (Y) containing high level program structure but no concrete details about, e.g., variable names.	Review	O	0
Afterwards, the sketch is converted into a full program (Prog) by stochastically filling in the abstract parts of the sketch with concrete instantiations.	Review	O	0
[line_break_token][line_break_token]The paper presents an abstraction method for converting a program into a sketch, a stochastic encoder-decoder model for converting descriptions to trees, and rejection sampling-like approach for converting sketches to programs.	Review	O	0
Experimentally, it is shown that using sketches as an intermediate abstraction outperforms directly mapping to the program AST.	Review	O	0
The data is derived from an online repository of ~1500 Android apps, and from that were extracted ~150k methods, which makes the data very respectable in terms of realisticness and scale.	Review	O	0
This is one of the strongest points of the paper.	Review	O	0
[line_break_token][line_break_token]One point I found confusing is how exactly the Combinatorial Concretization step works.	Review	O	0
Am I correct in understanding that this step depends only on Y, and that given Y, Prog is conditionally independent of X?	Review	B-Review	1
If this is correct, how many Progs are consistent with a typical Y?	Review	I-Review	1
Some additional discussion of why no learning is required for the P(Prog | Y) step would be appreciated.	Review	I-Review	2
[line_break_token][line_break_token]I'm also curious whether using a stochastic latent variable (Z) is necessary.	Review	I-Review	3
Would the approach work as well using a more standard encoder-decoder model with determinstic Z?	Review	I-Review	3
[line_break_token][line_break_token]Some discussion of Grammar Variational Autoencoder (Kusner et al) would probably be appropriate.	Review	I-Review	4
[line_break_token][line_break_token]Overall, I really like the fact that this paper is aiming to do program synthesis on programs that are more like those found "in the wild".	Review	O	0
While the general pattern of mapping a specification to abstraction with a neural net and then mapping the abstraction to a full program with a combinatorial technique is not necessarily novel, I think this paper adds an interesting new take on the pattern (it has a very different abstraction than say, DeepCoder), and this paper is one of the more interesting recent papers on program synthesis using machine learning techniques, in my opinion.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your feedback about the paper.	Reply	O	0
We answer your specific questions below.	Reply	O	0
[line_break_token][line_break_token]Question: Am I correct in understanding that [Combinatorial Concretization] step depends only on Y, and that given Y, Prog is conditionally independent of X?	Reply	O	0
If this is correct, how many Progs are consistent with a typical Y?	Reply	O	0
[line_break_token][line_break_token]Answer: Yes, Prog is conditionally independent of X given a sketch Y. In theory, there may be an infinite number of Progs for every Y. A simple example is two Progs that differ only in variable names, thereby corresponding to the same Y; for another example, there can be very many expressions that match the type of an API method argument.	Reply	O	0
However, in practice, we use certain heuristics to limit the space of Progs from a given Y (these heuristics are abstractly captured by the distribution P(Prog | Y).	Reply	B-Reply	1
In particular, these heuristics prioritize smaller, simpler programs over complex ones, and name local variables in a canonical way.	Reply	I-Reply	1
[line_break_token][line_break_token]While we didn't collect this data systematically, our experience with the system suggests that under the heuristics actually implemented in it, a typical Y leads to only ~5-10 distinct Progs in our experiments.	Reply	I-Reply	1
We will collect this data more thoroughly and add it to the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]Question: Some additional discussion of why no learning is required for the P(Prog | Y) step would be appreciated.	Reply	O	0
[line_break_token][line_break_token]Answer: In principle, this step could be made data-driven; however, the resulting learning problem would be very difficult.	Reply	O	0
This is because a single sketch used for training can correspond to many training programs that only differ in superficial details (for example local variable names).	Reply	B-Reply	2
Learning to decide which differences between programs are superficial and which are not, solely by looking at the syntax of programs, is hard.	Reply	I-Reply	2
In contrast, our approach of heuristically choosing P(Prog | Y) utilizes our domain knowledge of language semantics (for example, that local variable names do not matter, and that some algebraic expressions are semantically equivalent).	Reply	I-Reply	2
This knowledge allows us to limit the set of programs that we end up generating.	Reply	I-Reply	2
We will clarify this in more detail in the paper.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Question: I'm also curious whether using a stochastic latent variable (Z) is necessary.	Reply	O	0
Would the approach work as well using a more standard encoder-decoder model with deterministic Z?	Reply	O	0
[line_break_token][line_break_token]Answer: The randomness associated with the latent variable Z serves as a way to regularize the learning process (a similar argument is made in the context of VAEs for the stochastic latent variable used during VAE learning).	Reply	O	0
We were concerned that without the stochasticity (i.e., with a deterministic Z), training the model would be more likely to be affected by overfitting.	Reply	B-Reply	3
Practically speaking, the stochasticity also serves as a way to ensure that we can generate a wide variety of possible programs from a given X. If Z was not random, a particular set of labels X will always result in exactly the same value of Z.[line_break_token][line_break_token]Comment: Some discussion of Grammar Variational Autoencoder (Kusner et al) would probably be appropriate.	Reply	O	0
[line_break_token][line_break_token]Answer: Kusner et al‚Äôs work proposes a VAE for context-free grammars.	Reply	O	0
Being an auto-encoder it is a generative model, but it is not a conditional model such as ours.	Reply	B-Reply	4
In their application towards synthesizing molecular structures, given a particular molecular structure, their model can be used to search the latent space for similar valid structures.	Reply	I-Reply	4
In our setting, however, we are not given a sketch but only labels about the sketch, and our task is learn a conditional model that can predict a whole sketch given labels.	Reply	O	0
[line_break_token][line_break_token]We will add the discussion about this work in the final version of the paper.	Reply	O	0

This work makes use of uncertainty estimation methods from active learning to select a subset of training data that produces models with similar (or better) performance compared to models trained on the full training set.	Review	O	0
It proposes a way to improve the Monte Carlo estimation of model uncertainty by including multiple checkpoints that are generated "for free" during a training run, thereby increasing the number of samples from 5-10 in previous work to 100 in this work.	Review	O	0
It compares several initialization schemes for the subset model using mutual information as the acquisition function, finds that a "build-up" approach (based on Chitta et.	Review	O	0
al 2018a) works best, and uses that for the rest of the studies.	Review	O	0
It then compares several acquisition functions, using the build-up approach, finds that variation ratio performs best, and uses that for the rest of the studies.	Review	O	0
Next, it compares the Top-1 accuracy on ImageNet obtained by evaluating the ensemble models produced by different ensembling schemes, and finds that ensembling 20 checkpoints from 5 training runs with different random seeds work best.	Review	O	0
Then, it uses acquisition models that use ensembles from each ensembling scheme to select subsets of the ImageNet data to be used for training the subset model, and then compares the performance of the subset models.	Review	O	0
Finally, it demonstrates this method of selecting a subset of the training data works even if the subset is used to train a model with a different architecture from the acquisition model.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]- Algorithm is likely to be useful in practice.	Review	O	0
Training dataset can be "compressed" using a smaller architecture like ResNet-18, then used to train larger architectures like DenseNet-121, thus saving the amount of compute per training epoch.	Review	O	0
Using training checkpoints in the ensemble is very practical but not obvious (to me), since my first intuition would be that checkpoints from the same training run would not provide enough diversity to improve the acquisition function.	Review	O	0
I am glad that there were thorough experiments to address this concern and demonstrate that it works.	Review	O	0
[line_break_token]- Experiments answer key questions about the method proposed, and the sequence of experiments have a clear logical flow.	Review	O	0
Good baselines.	Review	O	0
Clear notation and problem set-up.	Review	O	0
[line_break_token][line_break_token]Weakness that affected the score:[line_break_token]- Missing detail on the build-up initialization scheme.	Review	O	0
The work referred to Chitta et al.,	Review	B-Review	1
2018a, but that algorithm requires selecting a growth parameter.	Review	I-Review	1
This growth parameter determines the number of times the subset model needs to be retrained, which can affect the viability of this method in practice.	Review	I-Review	1
I would like to see the build-up initialization scheme described in greater detail.	Review	I-Review	1
[line_break_token][line_break_token]Clarifications:[line_break_token]- In Table 2 and Table 3, are the results in the "Single (1)",  "Checkpoints (5)", and "Checkpoints (20)" columns obtained by averaging over the 5 random seeds?	Review	O	0
[line_break_token]- In the last column of Table 2, Top-1 accuracy of ~84% from an ensemble of 100 ResNet-18s (Table 2) seem very high.	Review	O	0
In comparison, ResNet-50 and AmoebaNet-A (2019) obtained a Top-1 accuracy of 77.2% and 83.9% respectively.	Review	B-Review	3
What do the authors think about this?	Review	I-Review	3
[line_break_token]- Why would one expect high accuracy of the ensemble of NNs in the acquisition model to indicate good sampling quality of the acquisition model? (	Review	O	0
caption for table 2)[line_break_token][line_break_token]Minor issues:[line_break_token]- Algorithm 1: first two steps should be kept un-italicized, like the rest of the steps.	Review	O	0
[line_break_token]- Page 7, first paragraph: "This shows that the checkpoints are obtained with no additional computational cost at train time can be used to generate diverse ensembles."	Review	O	0
The first "are" in this sentence is unnecessary.	Review	B-Review	6
[line_break_token]- Build-up was chosen as the initialization scheme for the rest of the studies, as it performed best when the acquisition function was fixed at *mutual information*. However, the acquisition function that was finally chosen for the rest of the studies is *variation ratio*, since it performed best when the initialization scheme was fixed at build-up.	Review	O	0
It would be more convincing if figure 1 also includes variation ratio.	Review	B-Review	7
e appreciate the thoughtful and helpful feedback provided by the reviewer.	Reply	O	0
We address the clarifications requested in the review as follows:[line_break_token][line_break_token]1.	Reply	O	0
Missing detail on the build-up initialization scheme.	Reply	O	0
[line_break_token][line_break_token]Please refer to Section 2.1 on Page 3 of the revised draft, where we have included additional details regarding our use of the build up initialization scheme as follows:[line_break_token][line_break_token]‚ÄúFinally, in the build up scheme, we follow an iterative AL loop.	Reply	B-Reply	1
Specifically, we start by initializing with a randomly selected subset of the data to train an acquisition model.	Reply	I-Reply	1
After performing acquisition, instead of training a single subset model, we optimize an ensemble of networks.	Reply	I-Reply	1
This ensemble is used as an acquisition model for a subsequent iteration.	Reply	I-Reply	1
Our goal is to finally reach a subset of samples.	Reply	I-Reply	1
As observed by [1], exponentially growing the dataset size offers practical benefits in an AL loop setting.	Reply	I-Reply	1
We therefore follow this approach, by initializing with random samples, and iterating two further times at and samples before obtaining a final subset of size.	Reply	I-Reply	1
‚Äù[line_break_token][line_break_token]2.	Reply	O	0
Number of seeds in Tables 2 and 3.	Reply	O	0
[line_break_token][line_break_token]We would like to clarify that the rows ‚ÄòSingle (1)‚Äô, ‚ÄòCheckpoints (5)‚Äô and ‚ÄòCheckpoints (20)‚Äô use the best seed of the 5 runs.	Reply	B-Reply	2
We have now clarified this in the text after referencing Table 2, on Page 7.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
High accuracy of the ResNet-18 100-model ensemble compared to state-of-the-art.	Reply	O	0
[line_break_token][line_break_token]We would like to highlight that the results in Table 2 are not on the official 50,000 image validation set for ImageNet, but on the 40% seen and 60% unseen data out of the 1.28M samples in the ImageNet training partition.	Reply	B-Reply	3
Since the algorithm selects the harder samples to its training data, these numbers are not indicative of performance on an i.i.d validation dataset and cannot be compared directly to state-of-the-art results.	Reply	I-Reply	3
Evaluating accuracy gains due to the proposed implicit ensembling technique is an interesting direction which we will look into for future research.	Reply	I-Reply	3
[line_break_token] [line_break_token]4.	Reply	O	0
Why would one expect high accuracy of the ensemble of NNs to indicate good sampling quality?	Reply	O	0
[line_break_token][line_break_token]The increase in accuracy in Table 2 shows that there is a significant shift in the final prediction of the ensemble with more checkpoints, indicating diversity.	Reply	B-Reply	4
Since the stored checkpoints are large in number and diverse enough to cause an improvement in accuracy, we believe they could also lead to better sampling by Monte Carlo estimation.	Reply	I-Reply	4
We have rephrased the caption of Table 2 to better convey our intended point.	Reply	I-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
Minor typos in Algorithm 1 and Page 7.	Reply	O	0
[line_break_token][line_break_token]Thank you, we have made the recommended changes.	Reply	B-Reply	5
[line_break_token][line_break_token]6.	Reply	O	0
Comparing initialization schemes for variation ratios.	Reply	O	0
[line_break_token][line_break_token]Please refer to Fig.	Reply	B-Reply	7
2 on Page 13 of the revised draft.	Reply	I-Reply	7
Unfortunately, we could not run the complete set of experiments from Fig.	Reply	I-Reply	7
1 using variation ratios, but we plot the validation curve for pretrain, compress and build up on 80% of ImageNet using variation ratios.	Reply	I-Reply	7
We observe that the performance of all three initialization schemes is similar at 80%.	Reply	I-Reply	7
The build up scheme which is used in most of our experiments in the main paper does slightly better than the compress scheme in terms of final validation accuracy.	Reply	I-Reply	7
[line_break_token][line_break_token][1] Kashyap Chitta, Jose M. Alvarez, Adam Lesnikowski.	Reply	O	0
Large-Scale Visual Active Learning with Deep Probabilistic Ensembles.	Reply	O	0
arXiv:1811.03575, 2018	Reply	O	0

SLM Lab is a software framework for reinforcement learning, which includes many different algorithms, networks, and memory types.	Review	O	0
The framework is well structured and modular.	Review	O	0
Thus, it is easily extendable for anyone and can be a pinnacle for future RL research.	Review	O	0
[line_break_token][line_break_token]The really like the paper.	Review	O	0
It is well written, easy to read, and provide a valuable platform / framework to the community, both the scientific community as well as practitioners.	Review	O	0
Although the scientific contribution may be low in the paper, I think the significance and potential impact of the paper outweigh that.	Review	O	0
[line_break_token][line_break_token]The paper also include many results from running the framework in various configurations, showing the flexibility and usefulness of it.	Review	O	0
[line_break_token][line_break_token]The code for SLM Lab is released open source, which is very valuable and enables future research in RL.	Review	O	0
[line_break_token]	Review	O	0
hank you for taking the time to read the paper and for your comments	Reply	O	0

This paper proposes a recurrent neural network for visual question answering.	Review	O	0
The recurrent neural network is equipped with a carefully designed recurrent unit called MAC (Memory, Attention and Control) cell, which encourages sequential reasoning by restraining interaction between inputs and its hidden states.	Review	O	0
The proposed model shows the state-of-the-art performance on CLEVR and CLEVR-Humans dataset, which are standard benchmarks for visual reasoning problem.	Review	O	0
Additional experiments with limited training data shows the data efficiency of the model, which supports its strong generalization ability.	Review	O	0
[line_break_token][line_break_token]The proposed model in this paper is designed with reasonable motivations and shows strong experimental results in terms of overall accuracy and the data efficiency.	Review	O	0
However, an issue in the writing, usage of external component and lack of experimental justification of the design choices hinder the clear understanding of the proposed model.	Review	O	0
[line_break_token][line_break_token]An issue in the writing[line_break_token]Overall, the paper is well written and easy to understand, but Section 3.2.3 (The Write Unit) has contradictory statements about their implementation.	Review	O	0
Specifically, they proposed three different ways to update the memory (simple update, self attention and memory gate), but it is not clear which method is used in the end.	Review	B-Review	1
[line_break_token][line_break_token]Usage of external component[line_break_token]The proposed model uses pretrained word vectors called GloVE, which has boosted the performance on visual question answering.	Review	O	0
This experimental setting makes fair comparison with the previous works difficult as the pre-trained word vectors are not used for the previous works.	Review	B-Review	2
To isolate the strength of the proposed reasoning module, I ask to provide experiments without pretrained word vectors.	Review	I-Review	2
[line_break_token][line_break_token]Lack of experimental justification of the design choices[line_break_token]The proposed recurrent unit contains various design choices such as separation of three different units (control unit, read unit and memory unit), attention based input processing and different memory updates stem from different motivations.	Review	O	0
However, these design choices are not justified well because there is neither ablation study nor visualization of internal states.	Review	B-Review	3
Any analysis or empirical study on these design choices is necessary to understand the characteristics of the model.	Review	I-Review	3
Here, I suggest to provide few visualizations of attention weights and ablation study that could support indispensability of the design choices.	Review	I-Review	3
[line_break_token]	Review	O	0
[line_break_token]Thank you very much for your review - we truly appreciate it!	Reply	O	0
[line_break_token]We have uploaded a revision (by the rebuttal deadline, jan 5) that addresses all your comments:[line_break_token][line_break_token]1.	Reply	O	0
We have revised the description of the writing unit to make it more clear - we have experimented with several variants for this unit - the "standard" one (for which all the results are about), and 3 variants: a. with self-attention, b. with gating, and c. with both self-attention and gating.	Reply	B-Reply	1
In the ablations study section we have included results for each of these for the whole dataset, 10% of the dataset and also showed training curves for each variant.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
We have trained the models without GloVE and added these results along with clarification to the experiments section.	Reply	B-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	3
We have included ablation studies in order to justify the architecture design choices and elucidate their impact.	Reply	I-Reply	3
We have also added visualizations of attention weights for several examples and discussed them.	Reply	I-Reply	3
[line_break_token][line_break_token]Thanks a lot again for your review!	Reply	O	0
[line_break_token]- Paper858 Author	Reply	O	0

The paper is well-written with a few figures to illustrate the ideas and components of the proposed method.	Review	O	0
However, one of the main components in the proposed method is based on Tulsiani et al.	Review	B-Review	1
CVPR'18.	Review	I-Review	1
The remaining components of the proposed method are not very new.	Review	I-Review	1
Hence, I am not very sure whether the novelty of the paper is significant.	Review	I-Review	1
Nevertheless, the performance of the proposed method is fairly good outperforming all baseline methods.	Review	O	0
[line_break_token]I also have a few questions:[line_break_token]1.	Review	O	0
How did you get the instance boxes, union boxes, and binary masks in testing?	Review	B-Review	2
[line_break_token]2.	Review	O	0
What are the training and inference time?	Review	B-Review	3
We are grateful for your feedback.	Reply	O	0
We hope that the above discussion assuaged the reviewer‚Äôs concerns regarding novelty and some unclear details.	Reply	O	0
We briefly address the two questions regarding the setup:[line_break_token][line_break_token]During testing, in the setting with known GT boxes (Sec 4.2), we assume that the 2D instance boxes are given.	Reply	O	0
In the detection setting, the 2D instance boxes are the result of the learned detector.	Reply	B-Reply	2
Given the (detected or known) instance boxes, the union boxes and binary masks can be easily computed - the union box is just the larger box containing both instance boxes, and the mask highlights these instance boxes in the union box.	Reply	I-Reply	2
[line_break_token]Training and Testing  Inference Time on a single GPU (Maxwell Titan X)[line_break_token]1.	Reply	I-Reply	3
Train time: 65 hrs[line_break_token]2.	Reply	I-Reply	3
Test time: 0.55s per image	Reply	I-Reply	3

--------------[line_break_token]Summary:[line_break_token]--------------[line_break_token]This paper presents a series of experiments on language emergence through referential games between two agents.	Review	O	0
They ground these experiments in both fully-specified symbolic worlds and through raw, entangled, visual	Review	O	0
[line_break_token]<review>[line_break_token]random chance of probe classifiers.	Reply	O	0
[line_break_token]</review>[line_break_token]When generating the dataset, we sample locations and floor colors from a continuous scale.	Reply	O	0
For the probe classifiers, we quantize location by clustering each coordinate in 5 clusters (and thus accuracy is reported by averaging the performance of the x and y probe classifiers with chance being at 20% for each co-ordinate) and floor colors in 3 clusters (with chance being at 33%).	Reply	B-Reply	1
We will include the chance levels in Table 4.	Reply	I-Reply	1
[line_break_token][line_break_token]<review>[line_break_token]Why not use cross-entropy loss for listener?	Reply	O	0
[line_break_token]</review>[line_break_token]We decided to train both agents via REINFORCE for symmetry.	Reply	O	0
Given the nature of the listener‚Äôs choice, we don‚Äôt anticipate full supervision to have an effect other than speeding up learning.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token]<review>[line_break_token]What about message length?	Reply	O	0
[line_break_token]</review>[line_break_token]Without any explicit penalty on the length of the messages (Section 2), agents are not motivated to produce shorter messages (despite the fact that as the reviewer points, agents can decide to do so) since this constrains the space of messages (and thus the possibility of the speaker and listener agreeing on a successful naming convention).	Reply	O	0
When we introduced a penalty on the length of the message (Section 3), agents produced shorter messages for the ambiguous messages (since this strategy maximizes the total expected reward).	Reply	B-Reply	3
[line_break_token][line_break_token]<review>[line_break_token]Why use reinforcement learning over some sort of differentiable sampler?	Reply	O	0
[line_break_token]</review>[line_break_token]While a differentiable communication channel would make learning faster, it goes against the basic and fundamental principles of human communication (and also against how this phenomenon is studied in language evolution).	Reply	O	0
 Simply put, having a differentiable channel would mean in practice that speakers can back-propagate through listeners‚Äô brains (which unfortunately is not the case in real life :)) We wanted to stay as close as possible to this communication paradigm, thus using a discrete communication channel	Reply	B-Reply	4

The authors propose a model that learns to play the China Competitive Poker game.	Review	O	0
The model uses CNN to predict the actions, and is trained from actual human game records.	Review	O	0
The model is shown to beat the current best AI and human amateur players.	Review	O	0
[line_break_token][line_break_token]The performance is certainly strong (if it were true).	Review	O	0
But given the double-blinded policy, there is literally no way to verify the correctness of the performance---in other words, the paper is currently not reproducible at all.	Review	B-Review	1
So the following comments are based on the trust-worthiness of the paper.	Review	O	0
[line_break_token][line_break_token](1) immature writing: The writing lacks formality and looks like a final project report.	Review	O	0
For instance, the super-short Section 2 is rather unprofessional---it is hard to believe that the related works can be described within two paragraphs anyway.	Review	B-Review	2
Even as someone who understands the game of China Competitive Poker, I find it very hard to follow Section 3.	Review	I-Review	2
There is a big room for improving the English writing.	Review	I-Review	2
[line_break_token][line_break_token](2) ill-illustrated specialty of the model: In particular, it is not clear why the model should be superior than other modeling choices.	Review	O	0
For instance, what role does the neighboring connections of CNNs play?	Review	B-Review	3
What are the cons and pros of choosing CNNs?	Review	I-Review	3
Are there strong motivations to design the model this way?	Review	I-Review	3
[line_break_token][line_break_token](3) many unanswered mysteries: why does the model trained with human records readily super-human?	Review	O	0
Note that this is controversial to common imitation learning where the typical performance is bound by the human-level performance.	Review	B-Review	4
Even though authors claimed in the response that there are "many professional records"---but how many is many?	Review	I-Review	4
Did the authors analyze the records and separate the professional versus amateur ones?	Review	I-Review	4
Thanks for your review.	Reply	O	0
[line_break_token][line_break_token](1)in other words, the paper is currently not reproducible at all.	Reply	O	0
So the following comments are based on the trust-worthiness of the paper.	Reply	O	0
[line_break_token][line_break_token]We will offer a online interface to public, it will return a action when you sent cards and game process.	Reply	B-Reply	1
You can test the model as you wish.	Reply	I-Reply	1
It will take a few days to prepare I think.	Reply	I-Reply	1
And, I can offer the video of test match (all 10 games) and public email addresses of four top amateur players, you can check with them.	Reply	I-Reply	1
[line_break_token][line_break_token](2)immature writing: The writing lacks formality and looks like a final project report.	Reply	O	0
For instance, the super-short Section 2 is rather unprofessional---it is hard to believe that the related works can be described within two paragraphs anyway.	Reply	O	0
Even as someone who understands the game of China Competitive Poker, I find it very hard to follow Section 3.	Reply	O	0
There is a big room for improving the English writing.	Reply	O	0
[line_break_token][line_break_token]I am really sorry about it.	Reply	B-Reply	2
I will continue to optimize the paper and improve English.	Reply	I-Reply	2
[line_break_token][line_break_token](3)ill-illustrated specialty of the model: In particular, it is not clear why the model should be superior than other modeling choices.	Reply	O	0
For instance, what role does the neighboring connections of CNNs play?	Reply	O	0
What are the cons and pros of choosing CNNs?	Reply	O	0
Are there strong motivations to design the model this way?	Reply	O	0
[line_break_token][line_break_token]The following is the reason written in the paper:[line_break_token][line_break_token]We choose CNN to solve the problem in CCP due to the following reasons: First, CNN has achieved superhuman performance in perfect information games.	Reply	B-Reply	3
Second, there is semi-translational invariance in CCP, e.g. there are two sets of cards in the same category but with different ranks (like ‚Äú34567‚Äù and ‚Äú45678‚Äù, see more information in section 3), if we add each card‚Äôs rank, ‚Äú34567‚Äù become ‚Äú45678‚Äù, this is translational invariance.	Reply	I-Reply	3
The player can play out ‚Äú45678‚Äù after another one played out ‚Äú34567‚Äù, but it is illegal if we swap the order, this is the reason for ‚Äúsemi‚Äù.	Reply	I-Reply	3
[line_break_token][line_break_token]Besides X-axis, I think there is translation invariance in Z-axis also.	Reply	I-Reply	3
CNN can get good performance dealing with translation invariance.	Reply	I-Reply	3
[line_break_token][line_break_token](4)many unanswered mysteries: why does the model trained with human records readily super-human?	Reply	O	0
Note that this is controversial to common imitation learning where the typical performance is bound by the human-level performance.	Reply	O	0
Even though authors claimed in the response that there are "many professional records"---but how many is many?	Reply	O	0
Did the authors analyze the records and separate the professional versus amateur ones?	Reply	O	0
[line_break_token][line_break_token]First, many authors proved that the neural network can get the top amateur level in games just by supervised learning, like Chris J. Maddison‚Äôs paper ‚ÄúMOVE EVALUATION IN GO USING DEEP CONVOLUTIONAL NEURAL NETWORKS‚Äù showed: ‚ÄúWe train a large 12-layer convolutional neural network by supervised learning from a database of human professional games.	Reply	B-Reply	4
The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player.	Reply	I-Reply	4
‚Äù 6 dan is top level in amateur players.	Reply	I-Reply	4
Deepmind got similar conclusion in their paper.	Reply	I-Reply	4
[line_break_token][line_break_token]Second, compared to Go, there are seldom professional players in the strict sense in CCP.	Reply	I-Reply	4
It is not a full time job for "CCP professional players", because players can not get enough money in CCP match.	Reply	I-Reply	4
Maybe "semi-professional player" is more suitable, but they are really top players than others.	Reply	I-Reply	4
As I said in previous reply, game records came from online platform.	Reply	I-Reply	4
Players only need to offer a cellphone number or a tencent account to online platform.	Reply	I-Reply	4
I think it is really very hard to distinguish just by them.	Reply	I-Reply	4
many online platforms support for visitors to log in	Reply	I-Reply	4

The paper is interesting and I like it.	Review	O	0
I draws parallels from biological learning and the well known critical learning phases in biological systems to artificial neural network learning.	Review	O	0
[line_break_token]A series of empirical simulation experiments that all aim to disturb the learning process of the DNN and to artificially create criticality are presented.	Review	O	0
They are providing food for thought, in order to introduce some quantitative results, the authors use well known Fisher Information to measure the changes.	Review	O	0
So far so good and interesting.	Review	O	0
[line_break_token]I was disappointed to see Tishby's result (2017) only remotely discussed, an earlier work than the one by Tishby is by Montavon et al 2011 in JMLR.	Review	B-Review	1
Also in this work properties of successive compression and dimensionality reduction are discussed, perhaps the starting point of quantitative analysis of various DNNs.	Review	I-Review	1
[line_break_token][line_break_token]To this point the paper presents no theoretical contribution, rather empirical findings only, that may or may not be ubiquitous in DNN learning systems.	Review	I-Review	2
The latter point may be worthwhile to discuss and analyse.	Review	I-Review	2
[line_break_token]Overall, the paper is interesting with its nice empirical studies but stays somewhat superficial.	Review	I-Review	2
To learn more a simpler toy model may be worthwhile to study.	Review	I-Review	3
[line_break_token][line_break_token]	Review	O	0
We thank the reviewer for their feedback and suggestions.	Reply	O	0
We have updated the paper accordingly, and address some of the points more in detail below:[line_break_token][line_break_token]> I was disappointed to see Tishby's result (2017) only remotely discussed, an earlier work than the one by Tishby is by Montavon et al 2011 in JMLR.	Reply	O	0
Also in this work properties of successive compression and dimensionality reduction are discussed, perhaps the starting point of quantitative analysis of various DNNs.	Reply	O	0
[line_break_token][line_break_token]We preferred not to elaborate at length on the connections with Schwartz and Tishby's results, since the relationship between the FIM of the weights (which we use in our paper) and the Shannon information of the activations, used by Tishby, is non-trivial and has already been discussed in more detail by other authors.	Reply	B-Reply	1
However, given how important this aspect is and since it has also been discussed by the other reviewers, we have included in the revised version an extended discussion on it, which hopefully will also make the manuscript more self-contained.	Reply	I-Reply	1
[line_break_token][line_break_token]Concerning Montavon's paper, that is indeed our miss; we have added the paper to the revised discussion, and thank the reviewer for pointing it out.	Reply	I-Reply	1
[line_break_token][line_break_token]> To this point the paper presents no theoretical contribution, rather empirical findings only, that may or may not be ubiquitous in DNN learning systems.	Reply	O	0
The latter point may be worthwhile to discuss and analyse.	Reply	O	0
[line_break_token]Overall, the paper is interesting with its nice empirical studies but stays somewhat superficial.	Reply	O	0
[line_break_token][line_break_token]The empirical findings are observed across the most commonly used architectures and optimization algorithms, as we also confirm with the new experiments in Fig.	Reply	B-Reply	2
3.	Reply	I-Reply	2
But it is true that it will take much more experimentation to assess whether they are truly ubiquitous and how they may affect different kinds of data.	Reply	I-Reply	2
On the theoretical side, the analysis of the transient, irreversible, properties of the learning process using the Fisher information in the weights is not only novel, but also different from other theoretical analyses, such as the study of flat minima, which focuses on the asymptotic behavior of the optimization (see the last paragraph of the Discussion).	Reply	I-Reply	2
In particular, our analysis suggests that crossing bottlenecks in the loss landscape, as opposed to convergence to critical points, may play a fundamental role in characterizing the final behavior of the network.	Reply	I-Reply	2
This aspect has, until now, been largely ignored and we are hopeful it may be fruitfully integrated in the current understanding of deep networks using, for example, tools from non-equilibrium dynamics, where such studies are common.	Reply	I-Reply	2
[line_break_token][line_break_token]Although we agree on the need for an analytical model, we tried to avoid the pitfalls of prematurely settling on a particular abstraction of the problem in order to paint a clearer picture, both through empirical experiments and by establishing connections with the most recent theories in deep learning, and yet providing a novel approach where the Fisher Information becomes one of the central quantities to consider.	Reply	I-Reply	2
[line_break_token][line_break_token]> To learn more a simpler toy model may be worthwhile to study.	Reply	O	0
[line_break_token][line_break_token]We fully agree.	Reply	B-Reply	3
In this paper, we focused on testing our hypotheses on current state-of-the-art models and relatively complex datasets, in order to understand what are the key aspects that need to be captured by any simplified model.	Reply	I-Reply	3
Now that this is established, and shown to be of practical relevance, given the widespread practice of fine-tuning, we can and will focus on simpler models that perhaps are also tractable analytically	Reply	I-Reply	3

This paper describes how to use Sum- and Maximum product networks for unsupervised feature learning and decoding and evaluate it within three different learning scenarios by either directly classifying a binary label set based on the original feature space, or by classifying the labels from generated feature encodings or decoding labels from their embedding.	Review	O	0
The authors further propose a full pipeline that produces feature embeddings and decodes them into the label space.	Review	O	0
[line_break_token][line_break_token]The paper alone is quite hard to comprehend and as a reader without prior knowledge in SPN/MPNs I had to consult a lot of literature, which however was provided sufficiently in the paper.	Review	B-Review	1
 The authors compare their method to state of the art approaches like RBMs and auto-encoders and show promising results in their framework.	Review	I-Review	1
Unfortunately the tasks were not described properly and again required to consult further literature.	Review	I-Review	1
I would recommend putting the evaluations partly into the appendix and to elaborate a little bit on that.	Review	I-Review	1
[line_break_token][line_break_token]Minor remarks:[line_break_token][line_break_token]- Typo in first sentence of section 3: usupervisedly[line_break_token]- The change in font size and face on emphasized words makes the general look of the text inconsistent and is quite uncommon	Review	I-Review	2
Dear reviewer,[line_break_token][line_break_token]thanks for your time reviewing our work and "imputing" the missing parts, we really appreciate it.	Reply	O	0
[line_break_token][line_break_token]We acknowledge that the current presentation omits several details about the experimental setting.	Reply	B-Reply	1
Therefore, we updated the paper by including an appendix comprising the full decoding procedure, some paragraphs about[line_break_token]training the models employed and finally more experimental results.	Reply	I-Reply	1
We also refactored the notation following your suggestions.	Reply	I-Reply	1
[line_break_token][line_break_token]Even if the time is running out, let us know if other modifications are required	Reply	O	0

Paper summary: [line_break_token]In this paper, the authors propose a general framework for multi-task learning (MTL) in neural models.	Review	O	0
The framework is general for including some of the current neural models for MTL.	Review	O	0
Under the framework, the author propose a new method that could allow tasks to communicate each other with explicit gradients.	Review	O	0
Based on the gradients being communicated, the system could adjust the updates of one task based on the gradient information of the other task.	Review	O	0
Also, prior task relatedness information could be incorporated to the system.	Review	O	0
[line_break_token][line_break_token]The idea of incorporating passing gradients among tasks seems very interesting, which is new as far as I am aware of.	Review	O	0
Although the idea is simple, but it seems intuitive since purely aggregating gradient updates might have undesired cancelling effects on each other.	Review	O	0
 [line_break_token][line_break_token]There are some questions I have about this method.	Review	O	0
[line_break_token]1.	Review	O	0
[tab_token]I‚Äôm curious about how the sequential update in pairwise task communication affects the performance.	Review	O	0
[line_break_token]2.	Review	O	0
[tab_token]Also, how does sequential update nature of the method affect the training speed, as for now, the parameter update consists of two sequential steps which also involve changes to the traditional update rule.	Review	O	0
[line_break_token]3.	Review	O	0
[tab_token]What is fast weight for and how it is used in (9)?	Review	O	0
It would be better if there are more details on how the update is carried out during the gradient communication.	Review	B-Review	3
[line_break_token]4.	Review	O	0
[tab_token]Regarding the relatedness for List-wise communication, is it possible to update the relatedness dynamically?	Review	O	0
Since the pre-computed relatedness might not always make sense.	Review	B-Review	4
During the learning of the representations, the task relatedness could change in the process.	Review	I-Review	4
[line_break_token]The system framework for MTL introduced by the authors seem to be kind of isolated to the method proposed.	Review	I-Review	5
I feel that the framework is not quite easy to understand from the way it is presented.	Review	I-Review	5
 From my perspective, the effectiveness of analyzing MTL methods using the framework seems a bit limited to me, as it serves more like a way of abstracting MTL models instead of analyzing it.	Review	I-Review	5
Therefore, I feel the content devoted to that part might be too much.	Review	I-Review	5
[line_break_token][line_break_token]Overall, I think the paper is interesting although the method itself is relatively simple.	Review	O	0
And the direction of utilizing gradient communication among tasks seem interesting and could be further explored.	Review	O	0
But I do feel the organization of the paper is a bit too heavy on the framework instead of the methodology proposed.	Review	B-Review	6
And more details of the algorithm proposed could be provided.	Review	I-Review	6
[line_break_token][line_break_token]On a side note, I think the paper exceeds the required length limit of 10 pages if appendices are counted towards it.	Review	O	0
[line_break_token]	Review	O	0
Thanks for your comments and the response of each point is listed below.	Reply	O	0
[line_break_token]      1.	Reply	O	0
 Both pairwise and listwise communication mechanisms are designed for addressing the inconsistent updating problem of shared parameters between different tasks.	Reply	B-Reply	1
The difference is that pairwise communication considers the updating consistency of parameter between two tasks, which is a relatively relaxed constraint. (	Reply	I-Reply	1
In the real scenario, there are features which can be shared partially).	Reply	I-Reply	1
[line_break_token]      2.	Reply	O	0
 Yes, explicitly passing gradients to different tasks will take additional time while the overall training processing is still very efficient.	Reply	B-Reply	2
 [line_break_token]      3.	Reply	O	0
 Here we choose a function without learnable parameters to compute the fast weight.	Reply	O	0
We have give more detailed formulation in our revised version.	Reply	B-Reply	3
[line_break_token]      4.	Reply	O	0
Yes, as we have also claimed in the paper, the relatedness can be computed in a static or dynamic way.	Reply	B-Reply	4
The question ‚Äúhow to choose weights for different tasks ?‚	Reply	I-Reply	4
Äù is a classic problem and pre-compute the task relatedness has been widely used in existing work.	Reply	I-Reply	4
Here, we don‚Äôt explore more about this to make our paper more focused.	Reply	I-Reply	4

The paper presents a Neural Network based method for learning ordinal embeddings only from triplet comparisons.	Review	O	0
[line_break_token]A nice, easy to read paper, with an original idea.	Review	O	0
[line_break_token][line_break_token]Still, there are some issues the authors should address:[line_break_token][line_break_token]- for the experiment with Imagenet images, it is not very clear how many pictures are used.	Review	O	0
Is this number 2500?	Review	B-Review	1
[line_break_token]- the authors state that they use "the power of DNNs" while they are experimenting with a neural network with only 4 layers.	Review	O	0
While there is no clear line between shallow and deep neural networks, I would argue that a 4 layer NN is rather shallow.	Review	B-Review	2
[line_break_token]- the authors fix the number of layers of the used network based on "our experience".	Review	O	0
For the sake of completeness, more experiments in this area would be nice.	Review	B-Review	3
[line_break_token]- for Figure 6, there is not a clear conclusion.	Review	O	0
While, it supports that " that logarithmic growth of the layer width respect to n is enough to obtain desirable performance."	Review	B-Review	4
 I don't see a clear conclusion of how to pick the width of hidden layers, maybe a better representation could be used.	Review	I-Review	4
[line_break_token]- I don't see a discussion about the downsides of the method (for example, the large number of triplet comparison examples needed for training; and possible methods to overcome this problem).	Review	O	0
[line_break_token]- in section 4.4 when comparing the proposed approach with another methods why not use more complex datasets (like those used in section 4.3)[line_break_token]- in section 4.3, there is no guarantee that the intersection between the training set and test set is empty.	Review	O	0
[line_break_token]- in section 4.3 how is the reconstruction built (Figure 3b)?	Review	O	0
[line_break_token][line_break_token]A few typos found:[line_break_token]- In figure 3 (c) "number |T of input" should be  "number |T| of input"[line_break_token]- In figure 5 (a) "cencept" should be "concept"[line_break_token]- In figure 8 "Each column corresponds to ..." should be "Each row corresponds to ...".	Review	B-Review	9
[line_break_token]- In the last paragraph of A1 "growth of the layer width respect" should be "growth of the layer width with respect"[line_break_token]- In the second paragraph of A2 "hypothesize the that relation" should be "hypothesize that the relation".	Review	I-Review	9
[line_break_token]- In section 4.3 last paragraph, first sentence: "with the maximunm number" should be "with the maximum number"[line_break_token]	Review	I-Review	9
e thank the reviewer for the insightful comments.	Reply	O	0
We address the questions in the following:[line_break_token][line_break_token]- How many images did you have in the experiment?	Reply	O	0
[line_break_token][line_break_token]We had 7500 images in total.	Reply	B-Reply	1
We had 3 concept classes, and 2500 images for each concept.	Reply	I-Reply	1
We will mention the total number in the main text.	Reply	I-Reply	1
[line_break_token][line_break_token]- The proposed network is not deep, but shallow[line_break_token][line_break_token]We agree that a clear distinction line between shallow and deep networks does not exist.	Reply	O	0
So we will make a note on that issue.	Reply	B-Reply	2
[line_break_token][line_break_token]- More experiments on the number of layers [line_break_token][line_break_token]We had experimented with fewer layers.	Reply	O	0
We realized that in this case the width of the network should be increased to compensate for the representation power of the network.	Reply	B-Reply	3
As we already had an extensive set of experiments, we decided not to report that.	Reply	I-Reply	3
As the proposed architecture already performs well to solve the ordinal embedding problem, we found it unnecessary to try deeper networks.	Reply	I-Reply	3
[line_break_token][line_break_token]- "I don't see a clear conclusion of how to pick the width of hidden layers, maybe a better representation could be used."	Reply	O	0
[line_break_token][line_break_token]There exist three parameters in this experiment, which makes it hard to come up with the most conclusive representation.	Reply	B-Reply	4
We also generated line plots (multiple curves in one plot) and 3D mesh plots to show the dependency.	Reply	I-Reply	4
In the end, we found the heat-map more informative.	Reply	I-Reply	4
In the revision, we will add the other plots to support the claim.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]- "I don't see a discussion about the downsides of the method"[line_break_token][line_break_token]One of the drawbacks is that our method needs GPUs, while the more traditional algorithms run on CPUs.	Reply	O	0
This can be of disadvantage if non-machine learning experts want to use our method.	Reply	B-Reply	5
However, this is the case for most recent ML methods based on neural nets.	Reply	I-Reply	5
[line_break_token][line_break_token]The number of required triplets is theoretically lower bounded by nd log n, and this is also being confirmed by our experiments (our algorithm, as well as our competitors, break down when they get fewer triplets).	Reply	I-Reply	5
Therefore, in a setting with passive triplet answers, and without extra information, it is impossible to overcome this problem.	Reply	I-Reply	5
[line_break_token][line_break_token]- "in section 4.4 when comparing the proposed approach with another method why not use more complex datasets (like those used in section 4.3)"[line_break_token][line_break_token]Independent of the dataset complexity, provided with enough triplet answers, all methods can yield less than 5% triplet error.	Reply	O	0
However, the computation time is significantly lower for our proposed method.	Reply	B-Reply	6
Due to the iterative nature of all algorithms, the computation time does not depend on the data distribution, but on the number of input points.	Reply	I-Reply	6
Thus, a simple uniform dataset could serve to show our intention in this section.	Reply	I-Reply	6
[line_break_token][line_break_token]- "in section 4.3, there is no guarantee that the intersection between the training set and the test set is empty."	Reply	O	0
[line_break_token][line_break_token]Yes, in theory that is true, but in practice this is negligible: the total number of possible triplets is about 10^9.	Reply	B-Reply	7
So the likelihood that two sets of size 1000 intersect is close to 0.	Reply	I-Reply	7
[line_break_token][line_break_token]- "in section 4.3 how is the reconstruction built (Figure 3b)?"	Reply	O	0
[line_break_token][line_break_token]Figure 3b is the exact output of the ordinal embedding in two dimensions.	Reply	B-Reply	8
The colors are the initial labels of the input items.	Reply	I-Reply	8
There are two or three labels assigned to demonstrate the quality of reconstruction.	Reply	I-Reply	8
Note that the ordinal embedding output is unique only up to isometric transforms.	Reply	I-Reply	8
In other words, every valid output is still valid with rotation, scaling and translation.	Reply	I-Reply	8
[line_break_token]	Reply	O	0

Overall the method proposed in this paper is simple but effective, and adequate experimental results are given to show its performance improvements.	Review	O	0
 However, the literature survey of this paper is not satisfactory.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
To reduce model size, there are several different ways including efficient architecture design, parameter pruning, quantization, tensor decomposition and knowledge distillation.	Review	B-Review	1
The authors forgot to mention tensor decomposition and mixed it with efficient architecture design.	Review	I-Review	1
As for parameter pruning and quantization,  many important papers are missing.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Utilizing the "soft targets" to transfer knowledge from teacher to student model is not first proposed by Hinton et al. (	Review	B-Review	2
2015).	Review	I-Review	2
To the best of my knowledge, it is first proposed in  [line_break_token]J. Li, R. Zhao, J.-T. Huang, Y. Gong, ‚ÄúLearning small-size DNN with output-distribution-based criteria,‚Äù Proc.	Review	I-Review	2
Interspeech-2014, pp.1910-1914.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Leveraging back part of teacher model's guidance to improve student performance has been investigated by other researchers on OCR tasks in [line_break_token]Ding H, Chen K, Huo Q. Compressing CNN-DBLSTM models for OCR with teacher-student learning and Tucker decomposition[J]. Pattern Recognition, 2019, 96: 106957.	Review	B-Review	3
[line_break_token]They combine student's CNN with teacher's DBLSTM to learn better representations.	Review	I-Review	3
[line_break_token][line_break_token]In conclusion, I will give a weak reject currently, unless the authors improve their literature survey and modify their claims.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
ear reviewer #2,[line_break_token][line_break_token]We would like to extend our sincere thanks to you for your constructive feedback.	Reply	O	0
We have modified our claims and improved our literature survey based on your comments.	Reply	O	0
Here are our responses to your major concerns.	Reply	O	0
[line_break_token][line_break_token]Q: To reduce model size, there are several different ways including efficient architecture design, parameter pruning, quantization, tensor decomposition and knowledge distillation.	Reply	O	0
The authors forgot to mention tensor decomposition and mixed it with efficient architecture design.	Reply	O	0
As for parameter pruning and quantization, many important papers are missing.	Reply	O	0
[line_break_token][line_break_token]A: We apologize for the unclear description in our ‚ÄúRelated Work‚Äù section and have improved the literature survey based on your suggestions in the updated version of our paper.	Reply	O	0
Due to the page limitation mentioned in ICLR submission instructions, some of the related works can only be described briefly in our article.	Reply	B-Reply	1
We hope to get your understanding.	Reply	I-Reply	1
[line_break_token][line_break_token]Q: Utilizing the "soft targets" to transfer knowledge from teacher to student model is not first proposed by Hinton et al. (	Reply	O	0
2015).	Reply	O	0
To the best of my knowledge, it is first proposed in J. Li, R. Zhao, J.-T. Huang, Y. Gong, ‚ÄúLearning small-size DNN with output-distribution-based criteria,‚Äù Proc.	Reply	O	0
Interspeech-2014, pp.1910-1914.	Reply	O	0
[line_break_token][line_break_token]A: In paper ‚ÄúLearning small-size DNN with output-distribution-based criteria‚Äù, authors took the KL divergence between the posterior probabilities produced by the softmax operation from student and teacher model as loss function for knowledge transfer.	Reply	O	0
Hinton et al. (	Reply	B-Reply	2
2015) improved the posterior probability from teacher network by employing the softmax function on the teacher logits with temperature T and called it as ‚Äúsoft target‚Äù.	Reply	I-Reply	2
The definition of ‚Äúsoft target‚Äù in our paper is the same as in Hinton‚Äôs.	Reply	I-Reply	2
In other knowledge transfer methods, such as FitNet, AT and FT, the definition of ‚Äúsoft target‚Äù is the same as ours.	Reply	I-Reply	2
We have cited the prior paper in the updated version.	Reply	I-Reply	2
[line_break_token][line_break_token]Q: Leveraging back part of teacher model's guidance to improve student performance has been investigated by other researchers on OCR tasks in Ding H, Chen K, Huo Q. Compressing CNN-DBLSTM models for OCR with teacher-student learning and Tucker decomposition[J]. Pattern Recognition, 2019, 96: 106957.	Reply	O	0
They combine student's CNN with teacher's DBLSTM to learn better representations.	Reply	O	0
[line_break_token][line_break_token]A: We are sorry for missing this paper in our literature survey.	Reply	O	0
However, our work started half a year ago, while this paper is published on July 7, 2019.	Reply	B-Reply	3
We have cited this paper in the updated version of our paper.	Reply	I-Reply	3
[line_break_token]In paper ‚ÄúCompressing CNN-DBLSTM models for OCR with teacher-student learning and Tucker decomposition‚Äù, authors employed a knowledge distillation method with DarkNet-DBLSTM as student network and VGG-DBLSTM as teacher network.	Reply	I-Reply	3
The DBLSTM modules of the student and teacher networks in this paper have same topology, so the student‚Äôs BLSTM and inner product layers can borrow parameters from the teacher‚Äôs counterparts during training and inference.	Reply	I-Reply	3
In contrast, the student networks in our proposed method do not take any part of teacher network for inference and the back part of the teacher network is only employed during the training process.	Reply	I-Reply	3
Therefore, our method can be generalized to situations where the student network and the teacher network have different structure.	Reply	I-Reply	3
Besides, our method can also be applied to different tasks, which has been confirmed through our experiments.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Best regards,	Reply	O	0

Summary:  This paper analyzes and extends a recently proposed goodness-of-fit test based on typicality [Nalisnick et al.,	Review	O	0
ArXiv 2019].  Firstly, the authors give bounds on the type-II error of this test, showing it can be characterized as a function of KLD[q || p_true] where p is the true data generating process and q is an alternative generative process.	Review	O	0
 The paper then shifts to the main contribution: an in-depth study of a Gaussian mixture simulation along with accompanying theoretical results.	Review	O	0
 The simulation shows that maximum likelihood estimation (MLE)---due to it optimizing KLD[p_true || p_model]---does not penalize the model for placing probability in places not occupied by p_true.	Review	O	0
 This means that while samples from p_true should fall within the model‚Äôs typical set, the model typical set may be broader than p_true‚Äôs.	Review	O	0
 Table 1 makes this clear by showing that only 30-40% of samples from the model fall within the typical set of p_true.	Review	O	0
 Yet &gt;93% of samples from p_true fall within the models‚Äô typical sets.	Review	O	0
 The paper then makes the observation that the models do not have high overlap in their typical sets, and thus p_true‚Äôs typical set could be well approximated by the intersection of the various models‚Äô typical sets.	Review	O	0
 Applying this procedure to the Gaussian mixture simulation, the authors observe that ~95% of samples drawn from the intersection of the ensemble fall within p_true‚Äôs typical set.	Review	O	0
 Moreover, ~97% of samples from p_true are in the ensemble (intersection) typical set.	Review	O	0
 The paper closes by proving that the diversity of the ensemble controls the overlap in their typical sets, and hence increasing diversity should only improve the approximation of p_true‚Äôs typical set.	Review	O	0
            [line_break_token][line_break_token]____[line_break_token][line_break_token]Pros:  This paper contributes some interesting ideas to a recent topic of interest in the community---namely, that deep generative models assign high likelihood to out-of-distribution (OOD) data [Nalisnick et al.,	Review	O	0
ICLR 2019] and how should we address this problem if we are to use them for anomaly detection, model validation [Bishop, 1994], etc.	Review	O	0
 This paper makes some careful distinctions between the true data process, the model, and the alternative distribution, which I have not seen done often in this literature.	Review	O	0
 And while the mass-covering effect of MLE on the resulting model fit is well known, this paper is the first with which I am aware that translates that fact into a practical recommendation (i.e. their intersection method).	Review	O	0
 Furthermore, this connection to ensembling may provide important theoretical grounding to other ensemble-based methods for OOD detection [Choi et al.,	Review	O	0
ArXiv 2019].   [line_break_token][line_break_token]____[line_break_token][line_break_token]Cons:  The primary deficiency in the paper is experimental.	Review	O	0
 While the text does make some compelling arguments in the Gaussian mixture simulations, some validation on real data must be provided.	Review	B-Review	1
 Ideally experiments on CIFAR-10 vs SVHN (OOD) and FashionMNIST vs MNIST (OOD) should be reported as these data set pairings have become the benchmark cases in this line of literature.	Review	I-Review	1
 [line_break_token][line_break_token]Besides the lack of experiments on real data, I find the paper‚Äôs material to be a bit disjointed and ununified.	Review	O	0
 For instance, Theorem 1 is never discussed again after it is presented in Section 2.1.	Review	B-Review	2
 I thought for sure the presence of the KLD-term would be referenced again to relate the ensembling methodology back to the bound on the type-II error.	Review	I-Review	2
 For another example, normalizing flows are discussed in Section 2.3 and the change-of-variables formula given in Equation 5.	Review	I-Review	2
 However, normalizing flows are never mentioned again except in passing in the Related Work section.	Review	I-Review	2
     [line_break_token][line_break_token]____[line_break_token][line_break_token]Final Evaluation:  While I find the paper to contain interesting ideas, it is too unfinished for me to recommend acceptance at this time.	Review	O	0
 Experiments on real data must be included and the overall coherence of the draft improved.	Review	O	0
[line_break_token]	Review	O	0
fter reading the two other reviews, it seems that all reviewers agree that the lack of non-toy experiments is a major deficiency in the paper.	Reply	B-Reply	3
 I find R3 to be too harsh in claiming Eqs 3 and 4 are "wrong": the authors clearly show is approximated with samples in Eq 4.	Reply	I-Reply	3
 I also disagree with R3 that the included experiment is "unclear".	Reply	I-Reply	3
 Rather, I find its motivation and results easy to interpret (see my summary).	Reply	I-Reply	3
 I mostly concur with R2's review except for its final conclusion.	Reply	I-Reply	3
 The questions that R2 lists under 'cons' could indeed be answered with a more comprehensive and realistic set of experiments.	Reply	I-Reply	3
 And until high-dimensional experiments are included, I leave my recommendation at "reject".	Reply	I-Reply	3
        	Reply	O	0

[line_break_token]I am putting "weak accept" because I think the paper addresses an important problem (domain adaptation) and has an interesting approach.	Review	O	0
 As the other reviewers pointed out, it's maybe not *super* novel.	Review	O	0
 But it's still interesting, and pretty readable for the most part.	Review	O	0
 [line_break_token][line_break_token]I do question the statistical significance of the TIMIT experiments: TIMIT has a very tiny test set to start with, and by focusing on the female portion only you are further reducing the amount.	Review	O	0
[line_break_token][line_break_token]Small point: I don't think GANs are technically nonparametric, as the neural nets do have parameters.	Review	B-Review	2
[line_break_token][line_break_token]I am a little skeptical that this method would have as general applicability or usefulness as the authors seem to think.	Review	I-Review	3
 The reason is that, since the cycle constraint no longer exists, there is nothing to stop the network from just figuring out the class label of the input (say) image, and treating all the rest of the  information in that image as noise the same way a regular non-cyclic GAN would treat it.	Review	I-Review	3
 Of course, one wouldn't expect a convolutional network to behave like this, but in theory it could happen in general cases.	Review	I-Review	3
 This is just speculation though.	Review	I-Review	3
 Personally I would have tended to accept the paper, but I'm not going to argue with the other reviewers, who are probably more familiar with GAN literature than me.	Review	I-Review	3
[line_break_token][line_break_token]--[line_break_token]I am changing from "marginally above acceptance threshold" to "clear accept" after reading the response and thinking about the paper a bit more.	Review	O	0
 I acknowledge that the difference from previously published methods is not that large, but I still think it has value as it's getting quite close to being a practical method for generating fake training data for speech recognition.	Review	B-Review	4
[line_break_token]	Review	O	0
- Comment on ‚Äústatistical significance on TIMIT experiments‚Äù:[line_break_token]We have chosen TIMIT dataset because of its inherent low-resource domain for different genders.	Reply	O	0
As shown in Table 3, when using only Male speech for training the network, testing on female	Reply	B-Reply	1

Authors have introduced a new type of adversarial attacks that perturb abstract features of the image.	Review	O	0
They have shown that pixel space adversarial attack detection and defense techniques are ineffective in guarding against feature space attacks.	Review	O	0
[line_break_token][line_break_token]I have some concerns about the novelty of the attack and the appropriateness of defenses that have been tested.	Review	B-Review	1
[line_break_token][line_break_token]- Since the attack is done in the feature space, the defense should also be done in the feature space.	Review	O	0
For example, adversarial training or smoothing can be done in the feature space.	Review	B-Review	2
See: <a href="https://arxiv.org/abs/1802.03471" target="_blank" rel="nofollow">https://arxiv.org/abs/1802.03471</a>[line_break_token][line_break_token]- There are attacks that perturb colors or other interpretable features of the image that have not been mentioned in the paper.	Review	O	0
For example, see <a href="https://arxiv.org/abs/1804.00499" target="_blank" rel="nofollow">https://arxiv.org/abs/1804.00499</a> and <a href="https://arxiv.org/pdf/1906.00001" target="_blank" rel="nofollow">https://arxiv.org/pdf/1906.00001</a>[line_break_token][line_break_token]- If the decoder has a high Lipschitz constant, a small perturbation in the feature scape 'can' lead to a large and visible perturbation in the pixel space.	Review	O	0
It was not clear to me how this is being controlled in the current method.	Review	B-Review	4
[line_break_token] 	Review	I-Review	1
e thank for your constructive comments.	Reply	O	0
Here we list your concerns and answer them one by one.	Reply	O	0
[line_break_token][line_break_token]R2Q1: novelty[line_break_token]It is a novel way to conduct feature space attack with the combination of style transfer and manipulation of model internal embedding, as pointed out by Review #1.	Reply	O	0
Common style transfer task requires additional information such as painting styles.	Reply	B-Reply	1
In this paper, we instead use samples from the same class that share rich style features, which is not explored by existing work.	Reply	I-Reply	1
We leverage these implicitly learned features to launch our feature-space attack, which distinguishes ours among various existing attack methods.	Reply	I-Reply	1
[line_break_token]Unlike in [3], where a vanilla GAN-based attack method generates over a distribution of limited support, and has no control of the generated samples, our encoder-decoder based structure enables attacking each individual sample with controlled content and there is no limit on the number of samples, which is also mentioned in Review #3.	Reply	I-Reply	1
[line_break_token]We also conducted an experiment that explores the defensive methods in different spaces.	Reply	I-Reply	1
We observed that pixel-level defense is not effective against feature-space attack, and as we will show in the R2Q2 and R1Q3, existing defense that can be used in the feature space cannot defend our attack.	Reply	I-Reply	1
[line_break_token][line_break_token]R2Q2: add Pixel-DP as possible feature space defense [line_break_token]We use the code provided by authors and the same setting to conduct experiments on Pixel-DP defense.	Reply	O	0
When using l2 norm bound of 0.1, the model accuracy (with Pixel-DP defense) is 80% under PGD l2 attack and 0% under our feature space attacks.	Reply	B-Reply	2
When using l2 norm bound of 1, the model accuracy (with Pixel-DP defense) is 31% under PGD l2 attack and 0% under ours.	Reply	I-Reply	2
When further increasing l2 norm bound to 10, we found the accuracy on normal images degrades to below 15%.	Reply	I-Reply	2
Pixel-DP is hence ineffective against our feature space attack.	Reply	I-Reply	2
The results are reasonable as Pixel-DP can only certify the l_2 norm bound up to 1, whereas our feature space attack generates adversarial samples with l_2 norm usually larger than 10.	Reply	I-Reply	2
[line_break_token]We have also conducted adversarial training experiments over pixel/feature spaces, which is shown in Table 4 in appendix.	Reply	I-Reply	2
When the model is trained with one type of adversarial attacks, it can only achieve non-trivial accuracy on the same attack but is ineffective to other types of attacks.	Reply	I-Reply	2
It is non-trivial to design an effective adversarial training that is robust to all types of adversarial attacks, and it is out of scope of this paper.	Reply	I-Reply	2
[line_break_token][line_break_token]R2Q3: color space attacks[line_break_token]The paper [1] proposed to modify the HSV color space to generate adversarial samples, which transforms all pixels by a non-parametric function uniformly.	Reply	O	0
 The experiments were only conducted on CIFAR-10 dataset and Madry model.	Reply	B-Reply	3
Differently, feature space attack changes colors of specific objects or background alone and the transformation is learned from similar images, which is more imperceptible.	Reply	I-Reply	3
 The paper [2] proposed to change the lighting condition and color similarly in [1] to generate adversarial samples.	Reply	I-Reply	3
We observe in experiments that feature space attack also learns to modify lightning condition, color and texture as well, please refer to Fig.	Reply	I-Reply	3
3.	Reply	I-Reply	1
Compared to these, our attack is more general, and the features attacked are more subtle.	Reply	I-Reply	3
We will include the discussion in the paper.	Reply	I-Reply	3
[line_break_token][line_break_token]R2Q4: large and visible perturbation[line_break_token]Our Decoder is trained to minimize difference between the reconstructed image and the original image.	Reply	O	0
We only modify the mean and variance of activations that are considered style of features [5], where the content of images is preserved.	Reply	B-Reply	4
When launching attack, we bound the perturbation of mean and variance, which controls the perturbation introduced in the pixel space.	Reply	I-Reply	4
Fig.	Reply	I-Reply	3
3, Fig.	Reply	I-Reply	4
5 and Fig.	Reply	I-Reply	4
6 show the pixel/feature space distance of all the generated adversarial samples.	Reply	I-Reply	4
It can be observed that our feature space attack has small feature space distance and even smaller than (pixel-space l_inf bounded) PGD attack in most cases.	Reply	I-Reply	4
And we conducted an additional user study, suggesting feature space attack has comparable perceptual quality as PGD, please refer to R1Q1.	Reply	I-Reply	4
[line_break_token][line_break_token][1] H. Hosseini, R. Poovendran.	Reply	O	0
Semantic Adversarial Examples.	Reply	O	0
<a href="https://arxiv.org/abs/1804.00499" target="_blank" rel="nofollow">https://arxiv.org/abs/1804.00499</a>[line_break_token][2] C. Laidlaw, S. Feizi.	Reply	O	0
Functional Adversarial Attacks.	Reply	O	0
<a href="https://arxiv.org/pdf/1906.00001" target="_blank" rel="nofollow">https://arxiv.org/pdf/1906.00001</a>[line_break_token][3] Y. Song, R. Shu, N. Kushman, S. Ermon.	Reply	O	0
Constructing unrestricted adversarial examples with generative models.	Reply	O	0
<a href="https://arxiv.org/abs/1805.07894" target="_blank" rel="nofollow">https://arxiv.org/abs/1805.07894</a>[line_break_token][4] H. Hosseini, S. Kannan, R. Poovendran, Are Odds Really Odd?	Reply	O	0
Bypassing Statistical Detection of Adversarial Examples.	Reply	O	0
<a href="https://arxiv.org/pdf/1907.12138.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1907.12138.pdf</a>[line_break_token][5] L. A. Gatys, A. S. Ecker, and M. Bethge.	Reply	O	0
Image style transfer using convolutional neural networks.	Reply	O	0
In CVPR, 2016.	Reply	O	0
[line_break_token][6] D. Ulyanov, A. Vedaldi, V. Lempitsky.	Reply	O	0
Instance Normalization: The Missing Ingredient for Fast Stylization.	Reply	O	0
<a href="https://arxiv.org/abs/1607.08022" target="_blank" rel="nofollow">https://arxiv.org/abs/1607.08022</a>[line_break_token][7] X. Huang and S. Belongie.	Reply	O	0
Arbitrary style transfer in real-time with adaptive instance normalization.	Reply	O	0

UPDATE: I think the authors' rebuttal and updated draft address my points sufficiently well for me to update my score and align myself with the other reviewers.	Review	O	0
[line_break_token][line_break_token]-----[line_break_token][line_break_token]ORIGINAL REVIEW: The paper proposes a method for learning post-hoc to condition a decoder-based generative model which was trained unconditionally.	Review	O	0
Starting from a VAE trained with an emphasis on good reconstructions (and at the expense of sample quality, via a small hard-coded standard deviation on the conditional p(x | z)), the authors propose to train two "critic" networks on the latent representation:[line_break_token][line_break_token]1.	Review	O	0
The "realism" critic receives either a sample z ~ q(z) (which is implicitly defined as the marginal of q(z | x) over all empirical samples) or a sample z ~ p(z) and must tell them apart.	Review	O	0
[line_break_token]2.	Review	B-Review	2
The "attribute" critic receives either a (latent code, attribute) pair from the dataset or a synthetic (latent code, attribute) pair (obtained by passing both the attribute and a prior sample z ~ p(z) through a generator) and must tell them apart.	Review	O	0
[line_break_token][line_break_token]The goal is to find a latent code which satisfies both the realism and the attribute-exhibiting criteria, subject to a regularization penalty that encourages it to stay close to its starting point.	Review	O	0
[line_break_token][line_break_token]It seems to me that the proposed realism constraint hinges exclusively on the ability to implictly capture the marginal distribution q(z) via a trained discriminator.	Review	B-Review	1
Because of that, any autoencoder could be used in conjunction with the realism constraint to obtain good-looking samples, including the identity encoder-decoder pair (in which case the problem reduces to generative adversarial training).	Review	O	0
I fail to see why this observation is VAE-specific.	Review	B-Review	3
The authors do mention that the VAE semantics allow to provide some weak form of regularization on q(z) during training, but the way in which the choice of decoder standard deviation alters the shape of q(z) is not explained, and there is no justification for choosing one standard deviation value in particular.	Review	O	0
[line_break_token][line_break_token]With that in mind, the fact that the generator mapping prior samples to "realistic" latent codes works is expected: if the VAE is trained in a way that encourages it to focus almost exclusively on reconstruction, then its prior p(z) and its marginal q(z) have almost nothing to do with each other, and it is more convenient to view the proposed method as a two-step procedure in which an autoencoder is first trained, and an appropriate prior on latent codes is then learned.	Review	O	0
In other words, the generator represents the true prior by definition.	Review	O	0
[line_break_token][line_break_token]The paper is also rather sparse in terms of comparison with existing work.	Review	B-Review	5
Table 1 does compare with Perarnau et al.,	Review	I-Review	5
but as the caption mentions, the two methods are not directly comparable due to differences in attribute labels.	Review	I-Review	5
[line_break_token][line_break_token]Some additional comments:[line_break_token][line_break_token]- BiGAN [1] should be cited as concurrent work when citing (Dumoulin et al.,	Review	I-Review	6
2016).	Review	I-Review	6
[line_break_token]- [2] and [3] should be cited as concurrent work when citing (Ulyanov et al.,	Review	I-Review	6
2016).	Review	I-Review	6
[line_break_token][line_break_token]Overall, the relative lack of novelty and comparison with previous work make me hesitant to recommend the acceptance of this paper.	Review	O	0
[line_break_token][line_break_token]References:[line_break_token][line_break_token][1] Donahue, J., Kr√§henb√ºhl, P., and Darrell, T. (2017).	Review	O	0
Adversarial feature learning.	Review	O	0
In Proceedings of the International Conference on Learning Representations.	Review	O	0
[line_break_token][2] Li, C., and Wand, M. (2016).	Review	O	0
Precomputed real-time texture synthesis with markovian generative adversarial networks.	Review	O	0
In European Conference on Computer Vision.	Review	O	0
[line_break_token][3] Johnson, J., Alahi, A., and Fei-Fei, L. (2016).	Review	O	0
Perceptual losses for real-time style transfer and super-resolution.	Review	O	0
In European Conference on Computer Vision.	Review	O	0
Thank you for your time and insight in your review.	Reply	O	0
We've done our best to address your concerns with paper revisions and in the comments below:[line_break_token][line_break_token][line_break_token]> ‚Äùthe way in which the choice of decoder standard deviation alters the shape of q(z) is not explained, and there is no justification for choosing one standard deviation value in particular.	Reply	O	0
‚Äù[line_break_token][line_break_token]This was not made sufficiently clear in the original version.	Reply	O	0
We chose a standard deviation parameter of 0.1 because it maximizes the ELBO.	Reply	B-Reply	3
Using ELBO maximization as a hyperparameter selection scheme is a very natural and well-established practice (cf.	Reply	I-Reply	3
Bishop's 2006 Pattern Recognition and Machine Learning textbook, for example).	Reply	I-Reply	3
We have updated the text to highlight this and added Table 4 to the appendix, which shows the very significant improvement in ELBO from sigma=1.0 to sigma=0.1.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]> ‚Äúany autoencoder could be used in conjunction with the realism constraint to obtain good-looking samples‚Ä¶‚Äù[line_break_token][line_break_token]This is true enough, and worth emphasizing‚Äîour contributions are not specific to VAEs, but can be used to generate good-looking conditional samples from pretrained classical autoencoders.	Reply	O	0
We have added Figure 15 to the supplement, which explores what happens when the VAE‚Äôs sigma parameter goes to 0 (equivalent to a classical autoencoder).	Reply	B-Reply	1
We obtain reasonably good conditional samples with high-frequency spatial artifacts.	Reply	I-Reply	1
[line_break_token][line_break_token]We focused on VAEs rather than classical AEs both because they have natural sampling semantics and because they produced slightly better results.	Reply	I-Reply	1
We believe this is because the KL divergence term encourages q(z) to fill up as much of the latent space as possible (without sacrificing reconstruction quality).	Reply	I-Reply	1
This penalty encourages more of the latent space to map to reasonable-looking images.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]> ‚Äú...including the identity encoder-decoder pair (in which case the problem reduces to generative adversarial training).‚Äù[line_break_token][line_break_token]This is an interesting observation, and may be true for the simplest version of our approach (although the identity mapping would stretch the definition of ‚Äúlatent‚Äù space).	Reply	O	0
But it breaks down when we regularize the GAN to not move too far from the input z vector, which we found was essential to combat mode collapse and find identity-preserving transformations.	Reply	B-Reply	2
In that case, it is essential that Euclidean distance in latent space be more meaningful than distance in pixel space, making the identity ‚Äúautoencoder‚Äù a poor choice.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]> ‚Äúthe way in which the choice of decoder standard deviation alters the shape of q(z) is not explained‚Äù[line_break_token][line_break_token]Smaller standard deviations will lead to lower-variance posteriors, and therefore a more concentrated q(z).	Reply	O	0
This may not be obvious to all readers, so we updated the text to emphasize it, and added Supplemental Figure 16, which demonstrates the effect experimentally.	Reply	B-Reply	4
[line_break_token][line_break_token][line_break_token]> ‚ÄúThe paper is also rather sparse in terms of comparison with existing work.	Reply	O	0
Table 1 does compare with Perarnau et al.,	Reply	O	0
but as the caption mentions, the two methods are not directly comparable due to differences in attribute labels.	Reply	O	0
‚Äù[line_break_token][line_break_token]We do our best to find work with which to compare, and match experimental conditions, however, there are not well established benchmarks for this type of task.	Reply	O	0
Unfortunately, Perarnau et al.	Reply	B-Reply	5
do not list the specific attributes that they selected as most salient, so an exact comparison is not possible.	Reply	I-Reply	5
We do our best to match conditions, and provide a list our 10 salient features in supplemental Table 3 for future comparison.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]> ‚Äú- BiGAN [1] should be cited as concurrent work when citing (Dumoulin et al.,	Reply	O	0
2016).	Reply	O	0
 [2] and [3] should be cited as concurrent work when citing (Ulyanov et al.,	Reply	O	0
2016).‚Äù[line_break_token][line_break_token]Thank you for bringing these citations to our attention.	Reply	O	0
They are indeed concurrent work with Dumoulin et al.	Reply	B-Reply	6
‚Äôs and Ulyanov et al.	Reply	I-Reply	6
‚Äôs work, and we have cited them as such.	Reply	I-Reply	6
[line_break_token]	Reply	O	0

This paper proposes fully unsupervised learning algorithm for speech recognition.	Review	O	0
It involves two alternating trained component, a phoneme classifier, and a boundary refining model.	Review	O	0
The experiment results demonstrate that it achieves first success on speech recognition that approaches the supervised learning performance.	Review	O	0
 [line_break_token][line_break_token]Pros:[line_break_token]+ The paper propose to use a frame-wise smoothing term J_FS added on J_ODM cost.	Review	O	0
In the new cost function, J_ODM controls the coarse-grained inter-segment distribution using a prepared language model P_LM, while J_FS controls the fine-grained intra-segment distribution.	Review	O	0
It is actually benefit to take use of this hierarchical 2-level scopes than only 1-level scope on evaluate the distribution mismatch in the cost function.	Review	O	0
Because otherwise, if only focus on fine-grained frame level,  much larger number of frame labels and longer N-gram have to be considered to evaluate the distribution of phoneme.	Review	O	0
Consequently, the computation can be exploding.	Review	O	0
[line_break_token]+ The proposed unsupervised phoneme classification method is superior to the baseline (Liu et al.,	Review	O	0
2018) because the baseline relies on a clustering which is upper-bounded by cluster purity.	Review	O	0
Directly optimize on \theta using an end-to-end scheme is preferred.	Review	O	0
[line_break_token]+ I like the idea to use an iterative training algorithm to jointly improve classifier parameter \theta and segment boundaries b. [line_break_token]+ It is quite impressive that unsupervised learning system get close to performance of supervised system on speech recognition.	Review	O	0
The proposed system also outperforms state-of-the-art baseline with large margin.	Review	O	0
[line_break_token]+ The settings of experiments are rather comprehensive.	Review	O	0
Especially the ‚Äúnon-matching language model‚Äù, tests the case where language model cannot directly estimated from training set.	Review	O	0
 [line_break_token][line_break_token]Questions:[line_break_token]1.	Review	O	0
[tab_token]In Appendix B you mentioned that for the N-gram you choose N=5.	Review	B-Review	1
So the original language model P_LM can be a high-dim matrix with exactly 39^5 elements.	Review	I-Review	1
How sparse is the original P_LM?	Review	I-Review	1
It describes that 10000 elements are chosen, which are only 0.001%(=10000/39^5) of elements in the original one.	Review	I-Review	1
How representative are they?	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
[tab_token]I notice for the balance weight of J_FS in (3), you empirically take the best \lambda=1e-5 during experiment.	Review	B-Review	2
To me, the scale of optimal \lambda is such small value maybe because the order of J_FS is improperly determined.	Review	I-Review	2
My suggestion is, could you try using square root on the current J_FS, or using standard deviation of intra-segment outputs.	Review	I-Review	2
The reasons are, first, minimizing std is a more interpretable penalty on diversion in a same segment; second, since you have used mean of outputs in J_ODM, then it is better to use a same dimension statistics, such as std of outputs in J_FS rather than sum of squared differences, when you combine J_ODM and J_FS in a uniform cost.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
[tab_token]What is the time complexity of running a comparable supervised speech recognition task with unsupervised learning method?	Review	B-Review	3
[line_break_token][line_break_token]Minor issues:[line_break_token]Maybe it is a typo that the second term of Eqn (2) should be ‚Äú-p_\theta(y_(t+1)=y|x_(t+1))‚Äù instead?	Review	O	0
Since the p_\theta is defined as posterior probability of the frame label given the corresponding input.	Review	B-Review	4
[line_break_token]	Review	O	0
We thank the reviewer for the constructive feedback!	Reply	O	0
[line_break_token][line_break_token][Top-10000 of P_LM] We found that among the 48^5 elements in the P_LM only 69553 of them are non-zero.	Reply	O	0
We also found that the top 10000 elements of P_LM account for about 48.7% of the total probability in P_LM.	Reply	B-Reply	1
That is, this extremely small portion of the elements in P_LM occupy almost half of the total probability.	Reply	I-Reply	1
[line_break_token][line_break_token][Balance weight of J_FS] As suggested by the reviewer, we conducted experiments by taking the square root of J_FS and obtain results for different values of \lambda.	Reply	O	0
We found that the best value of \lambda becomes 1e-6, which is even smaller than the original value of 1e-5.	Reply	B-Reply	2
The possible reasons are explained below.	Reply	I-Reply	2
First, we observe that the value of J_FS is in fact much smaller than J_ODM  (e.g., 0.15 vs 6.21).	Reply	I-Reply	2
When taking the square root of J_FS, it becomes larger and we will need a smaller lambda to balance it.	Reply	I-Reply	2
Second, the reason that we do not need a large lambda for J_FS is that it mainly plays the role of regularization.	Reply	I-Reply	2
Ideally, if we sample all possible trajectories of \tau in (1) and match their predicted output distribution to P_LM, then the prediction within each segment would also be close to each other.	Reply	I-Reply	2
However, the number of all the possible trajectories \tau in S_1 x S_2 x ‚Ä¶ S_K is exponentially large, and we cannot sample all of them in our training.	Reply	I-Reply	2
Therefore, J_FS would play the role of a regularization that helps promote the consistency in the intro-segment predictions.	Reply	I-Reply	2
For this reason, the regularization term J_FS does not need to be too large in practice.	Reply	I-Reply	2
[line_break_token][line_break_token][Training time of unsupervised learning] In Figure 2(a), we show a learning curve of the validation error over training time when the segmentation is given by a supervised oracle.	Reply	O	0
We can see that the total training could be completed in about an hour, which is similar to supervised learning.	Reply	B-Reply	3
With unsupervised segmentation boundaries, it takes a longer time to converge, which is usually 4-5 hours.	Reply	I-Reply	3
[line_break_token][line_break_token][Typos and minor issues] We have fixed the typos in Eq (2).	Reply	O	0

The paper proposes a novel model that reads in information, decide whether this information is surprising and hence whether or not to keep it in memory and also utilizing information in the memory to quickly adapt or reason.	Review	O	0
The authors experimented with few-shot Omniglot classification and meta learning reasoning tasks.	Review	O	0
[line_break_token][line_break_token]Novelty:[line_break_token][line_break_token]The authors introduced a novel self-contained model that decides what to write to the external memory and making use of the external memory for different tasks.	Review	O	0
[line_break_token][line_break_token]My comments are mostly as follows: [line_break_token][line_break_token]1.	Review	O	0
The paper is well written, the problems are clearly stated, the solution is presented in a clear way, overall very easy to follow.	Review	B-Review	1
[line_break_token][line_break_token]2.	Review	O	0
This is an interesting paper that combines a novel technique for writing to external memory based on surprisal and using it for more difficult tasks such as deductive reasoning.	Review	B-Review	2
 I really like the surprisal mechanism, there are cognitive/ neuroscience materials that supports this approach (that the brain tends to write to memory things that are surprising).	Review	I-Review	2
This also makes total sense from a machine learning perspective.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Could another objective  be used for surprisal?	Review	B-Review	3
Also, instead of a determinstic encoder, decoder, is it possible to use a variational objective?	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	O	0
The experiments look convincing.	Review	B-Review	4
[line_break_token][line_break_token]Overall a very nice paper, nice idea, could show more resul	Review	O	0
Thanks a lot for your comments and suggestions.	Reply	O	0
In the following we address three of the points you raised:[line_break_token][line_break_token]1.	Reply	O	0
Alternative measure of surprise: We have added a discussion on this point as a general comment above.	Reply	B-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
Variational objective.	Reply	B-Reply	3
In this paper the main idea was to test the effectiveness of the memory controller mechanism coupled with a relational decoder.	Reply	I-Reply	3
It is definitely possible to adapt a variational objective in the architecture and it would be a very interesting avenue for future work.	Reply	I-Reply	3
Thank you for the suggestion.	Reply	I-Reply	3
[line_break_token][line_break_token]Additional experiments: as you suggested we have carried out more experiments to further consolidate our presentation of the model.	Reply	I-Reply	3
We have applied APL to a set of continual learning experiments suggested by reviewer 3 and show that APL performs en par with progressive networks.	Reply	I-Reply	3
These results are included the final version of the paper along with some pointers to the relevant literature.	Reply	I-Reply	3
[line_break_token][line_break_token]In light of the positive nature of your reviews we hope that these comments and the additional experiments can sway you to increase your rating of the paper.	Reply	I-Reply	3
[line_break_token]Thanks again for the useful comments	Reply	O	0

* Summary:[line_break_token]The paper introduces a novel tensor decomposition that is reminiscent of canonical decomposition (CP) with low-rank factors, based on the observation that the core tensor in Tucker decomposition can be decomposed, resulting in a model interpolating between CP and Tucker.	Review	O	0
The authors argue that a straight application of AdaGrad on this decomposition is inadequate, and propose Ada^{imp} algorithm that enforces rotation invariance of the gradient update.	Review	O	0
The new decomposition is applied to ComplEx model (called PComplEx) that demonstrates better performance than the baseline.	Review	O	0
[line_break_token][line_break_token]* Comments:[line_break_token]Although the approach is well motivated, the paper has many ambiguities that need to better clarification.	Review	O	0
[line_break_token]1.	Review	O	0
Tucker decomposition results in lower dimension factors, "d" in the paper.	Review	B-Review	1
So the resulting core tensor is of size (d \times d \times d).	Review	I-Review	1
However, this core tensor is further decomposed with a rank-D CP as shown in Section 3, where D &gt;= d. Basically, first the original tensor is factored into lower rank d, and the core tensor is then expanded into rank D &gt;= d. The reader did not understand what is the justification for this approach?	Review	O	0
Please provide further explanation on this part.	Review	B-Review	1
[line_break_token]2.	Review	O	0
The confusion of P_2 and P_3 terms in the paper.	Review	B-Review	2
At the beginning of Section 3, P_2 is assumed to be identity through out the paper.	Review	I-Review	2
But P_2 is mentioned to have specific attributes in other parts of the paper, such as in the second paragraph from the bottom of page 4, the first paragraph and first equation on page 5.	Review	I-Review	2
And P_2 does not appear in AdaGrad algorithm.	Review	I-Review	2
[line_break_token]3.	Review	O	0
The experiment is lacking.	Review	B-Review	3
First, the paper does not explain the meaning of evaluation metrics.	Review	I-Review	3
Second, the authors do not provide an insight, why PComplEx is better than the ComplEx baseline on SVO dataset, but performs similarly on other datasets.	Review	I-Review	3
Which factors lead to such improvement?	Review	I-Review	3
[line_break_token]4.	Review	O	0
The comparison to other state-of-the-arts is inadequate, each compared method only has one or few configurations in terms of number of parameters.	Review	B-Review	4
[line_break_token][line_break_token]Overall the proposed decomposition method might have significant contribution to research progress in this field, but the paper fails to convince the reader of its significance.	Review	O	0
I feel the paper should be overhauled.	Review	O	0
.	Reply	B-Reply	1
Tucker decomposition results in lower dimension factors, "d" in the paper.	Reply	O	0
So the resulting core tensor is of size (d \times d \times d).	Reply	O	0
However, this core tensor is further decomposed with a rank-D CP as shown in Section 3, where D &gt;= d. Basically, first the original tensor is factored into lower rank d, and the core tensor is then expanded into rank D &gt;= d. The reader did not understand what is the justification for this approach?	Reply	O	0
Please provide further explanation on this part.	Reply	O	0
[line_break_token][line_break_token]‚Üí We start from a tensor of size n x n x p. A Tucker decomposition of rank d leads to :[line_break_token]d x (n +n + p) parameters for the factors and d x d x d parameters for the core tensor.	Reply	B-Reply	1
[line_break_token]In order to link this decomposition with the CP decomposition which is easier to optimize, we further decompose this core tensor with a CP decomposition of rank D. Thus, d x d x d parameters become d x (D + D + D) (which is smaller than d x d x d as long as D &lt; d^2/3).	Reply	O	0
[line_break_token]We allow D &gt; d because a tensor of shape d x d x d can have a CP rank as high as d^2.	Reply	O	0
[line_break_token][line_break_token][line_break_token]2.	Reply	B-Reply	1
The confusion of P_2 and P_3 terms in the paper.	Reply	O	0
At the beginning of Section 3, P_2 is assumed to be identity through out the paper.	Reply	O	0
But P_2 is mentioned to have specific attributes in other parts of the paper, such as in the second paragraph from the bottom of page 4, the first paragraph and first equation on page 5.	Reply	O	0
And P_2 does not appear in AdaGrad algorithm.	Reply	O	0
[line_break_token]‚Üí There is indeed a confusion between P_2 and P_3 in the paper,  we thank the reviewer for pointing this out.	Reply	B-Reply	2
Since P_2 is assumed to be the identity, it should not appear in the paper outside of the definition of CPT (beginning of Section 3).	Reply	I-Reply	2
All further occurrences of P_2 are typos and have been fixed in the revision.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
The experiment is lacking.	Reply	O	0
First, the paper does not explain the meaning of evaluation metrics.	Reply	O	0
Second, the authors do not provide an insight, why PComplEx is better than the ComplEx baseline on SVO dataset, but performs similarly on other datasets.	Reply	O	0
Which factors lead to such improvement?	Reply	O	0
[line_break_token]‚Üí Regarding evaluation metrics, we have added the definition of the mean reciprocal rank and hits@5% in Appendix 9.11.	Reply	B-Reply	3
We attribute the difference in performance on SVO to a difference in the underlying structure of the data that makes Tucker decomposition particularly suited.	Reply	I-Reply	3
Similarly to MurP being better on WN18RR than on FB237, it is possible that SVO is a dataset that is more amenable to a Tucker decomposition.	Reply	I-Reply	3
[line_break_token][line_break_token]4.The comparison to other state-of-the-arts is inadequate, each compared method only has one or few configurations in terms of number of parameters.	Reply	O	0
[line_break_token]‚Üí We performed new experiments.	Reply	B-Reply	4
Please, see the general comments.	Reply	I-Reply	4

This paper presents a generative sequence model based on the dilated CNN[line_break_token]popularized in models such as WaveNet.	Review	O	0
Inference is done via a hierarchical[line_break_token]variational approach based on the Variational Autoencoder (VAE).	Review	O	0
While VAE[line_break_token]approach has previously been applied to sequence modeling (I believe the[line_break_token]earliest being the VRNN of Chung et al (2015)), the innovation where is the[line_break_token]integration of a causal, dilated CNN in place of the more typical recurrent[line_break_token]neural network.	Review	O	0
[line_break_token][line_break_token]The potential advantages of the use of the CNN in place of[line_break_token]RNN is (1) faster training (through exploitation of parallel computing across[line_break_token]time-steps), and (2) potentially (arguably) better model performance.	Review	O	0
This[line_break_token]second point is argued from the empirical results shown in the[line_break_token]literature.	Review	O	0
The disadvantage of the CNN approach presented here is that[line_break_token]these models still need to generate one sample at a time and since they are[line_break_token]typically much deeper than the RNNs, sample generation can be quite a bit[line_break_token]slower.	Review	B-Review	1
[line_break_token][line_break_token]Novelty / Impact: This paper takes an existing model architecture (the[line_break_token]causal, dilated CNN) and applies it in the context of a variational[line_break_token]approach to sequence modeling.	Review	O	0
It's not clear to me that there are any[line_break_token]significant challenges that the authors overcame in reaching the proposed[line_break_token]method.	Review	B-Review	2
That said, it certainly useful for the community to know how the[line_break_token]model performs.	Review	I-Review	2
[line_break_token][line_break_token]Writing: Overall the writing is fairly good though I felt that the model[line_break_token]description could be made more clear by some streamlining -- with a single[line_break_token]pass through the generative model, inference model and learning.	Review	O	0
[line_break_token][line_break_token]Experiments: The experiments demonstrate some evidence of the superiority[line_break_token]of this model structure over existing causal, RNN-based models.	Review	O	0
One point[line_break_token]that can be drawn from the results is that a dense architecture that uses multiple levels of the[line_break_token]latent variable hierarchy directly to compute the data likelihood is[line_break_token]quite effective.	Review	O	0
This observation doesn't really bear on the central message[line_break_token]of the paper regarding the use of causal, dilated CNNs.	Review	B-Review	4
[line_break_token][line_break_token]The evidence lower-bound of the STCN-dense model on MNIST is so good (low)[line_break_token]that it is rather suspicious.	Review	O	0
There are many ways to get a deceptively good[line_break_token]result in this task, and I wonder if all due care what taken.	Review	B-Review	5
In[line_break_token]particular, was the binarization of the MNIST training samples fixed in[line_break_token]advance (as is standard) or were they re-binarized throughout training?	Review	I-Review	5
[line_break_token][line_break_token]Detailed comments:[line_break_token]- The authors state "In contrast to related architectures (e.g. (Gulrajani et[line_break_token]al, 2016; Sonderby et al.	Review	O	0
2016)), the latent variables at the upper layers[line_break_token]capture information at long-range time scales" I believe that this is[line_break_token]incorrect in that the model proposed in at least Gulrajani et al also [line_break_token][line_break_token]- It also seems that there is an error in Figure 1 (left).	Review	O	0
I don't think[line_break_token]there should be an arrow between z^{2}_{t,q} and z^{1}_{t,p}. The presence[line_break_token]of this link implies that the prior at time t would depend -- through[line_break_token]higher layers -- on the observation at t. This would no longer be a prior[line_break_token]at that point.	Review	B-Review	7
By extension you would also have a chain of dependencies[line_break_token]from future observations to past observations.	Review	I-Review	7
It seems like this issue is[line_break_token]isolated to this figure as the equations and the model descriptions are[line_break_token]consistent with an interpretation of the model without this arrow (and[line_break_token]including an arrow between z^{2}_{t,p} and z^{1}_{t,p}.[line_break_token][line_break_token]- The term "kla" appears in table 1, but it seems that it is otherwise not[line_break_token]defined.	Review	O	0
I think this is the same term and meaning that appears in Goyal et[line_break_token]al. (	Review	B-Review	8
2017), but it should obviously be defined here.	Review	I-Review	8
[line_break_token]	Review	O	0
To better understand if the experimental improvements shown in our paper only stem from the hierarchical latent space or whether the synergy between the dilated CNNs and latent variable hierarchy is important, we ran additional experiments (as suggested by R1).	Reply	B-Reply	1
We replaced the deterministic TCN blocks with LSTM cells and kept the latent structure intact, dubbed RNNLadder.	Reply	I-Reply	1
We used TIMIT and IAM-OnDB for speech and handwriting datasets.	Reply	I-Reply	1
The log-likelihood performance measured by ELBO is provided below:[line_break_token][line_break_token]=======================================================[line_break_token]                                                                             TIMIT          IAM-OnDB  [line_break_token]=======================================================[line_break_token]  25x256-LadderRNN (Normal)                         28207             1305    [line_break_token]  25x256-LadderRNN-dense (Normal)             27413             1278    [line_break_token]=======================================================[line_break_token]  25x256-LadderRNN (GMM)                             24839             1381    [line_break_token]  25x256-LadderRNN-dense (GMM)                 26240             1377    [line_break_token]=======================================================[line_break_token]  5x512-LadderRNN (Normal)                           49770             1299    [line_break_token]  5x512-LadderRNN-dense (Normal)               48612             1374    [line_break_token]=======================================================[line_break_token]  5x512-LadderRNN (GMM)                               47179             1359    [line_break_token]  5x512-LadderRNN-dense (GMM)                   50113             1581    [line_break_token]=======================================================[line_break_token]  25x256-STCN (Normal)                                    64913             1327    [line_break_token]  25x256-STCN-dense (Normal)                        70294             1729    [line_break_token]=======================================================[line_break_token]  25x256-STCN (GMM)                                        69195             1339    [line_break_token]  25x256-STCN-dense (GMM)                            71386             1796    [line_break_token]=======================================================[line_break_token][line_break_token]Models in the table have similar number of trainable parameters.	Reply	O	0
The most direct translation of the the STCN architecture into an RNN counterpart has 25 stacked LSTM cells with 256 units each.	Reply	B-Reply	5
Similar to STCN, we use 5 stochastic layers.	Reply	I-Reply	5
Please note that stacking this many LSTM cells is unusual and resulted in instabilities during training.	Reply	I-Reply	5
The performance is similar to vanilla RNNs.	Reply	I-Reply	5
Hence, we didn‚Äôt observe a pattern of improvement with densely connected latent variables.	Reply	I-Reply	5
The second RNNLadder configuration uses 5 stacked LSTM cells with 512 units and a one-to-one mapping with the stochastic layers.	Reply	I-Reply	5
[line_break_token][line_break_token]This experiments show that the modular structure of our latent variable design does allow for the usage of different building blocks.	Reply	I-Reply	5
Even when attached to LSTM cells, it boosts the log-likelihood performance (see 5x512-LadderRNN), in particular when used with dense connections.	Reply	I-Reply	5
However, the empirical results suggest that the densely connected latent hierarchy interacts particularly well with dilated CNNs.	Reply	I-Reply	5
We believe this is due to the hierarchical nature in both sides of the architecture.	Reply	I-Reply	5
On both datasets STCN models achieved the best performance and presented significant improvements with the dense connections.	Reply	I-Reply	5
This supports our contribution of a latent variable hierarchy, which models different aspects of information from the input time-series.	Reply	I-Reply	5

This paper proposes an new 8-bit quantization strategy for rapid deployment.	Review	O	0
[line_break_token][line_break_token]8-bit quantization has attracted many attentions recently.	Review	O	0
And it is already well used in GPU servers (cudnn), phones, ARM chips and various ASIC neural network chips.	Review	O	0
In these situations, almost no performance drop is observed for classification and detection tasks.	Review	O	0
[line_break_token][line_break_token]So, the novelty of this paper is limited.	Review	O	0
Thank you very much for your comments.	Reply	O	0
Competing methods in other papers require retraining or needs to cope with high accuracy loss when quantized in a layer-wise fashion.	Reply	O	0
The proposed method is the first of its kind to resolve these issues by incorporating channel-wise quantization and moment-analysis method which DOES NOT require retraining or the training dataset.	Reply	O	0
Na√Øve channel-wise quantization requires adding huge number of HW shifters and providing values for them which make it unrealistic for implementation (please see Figure 1 (b) in the revised manuscript).	Reply	O	0
The biggest contribution of our paper is the HW-friendly channel-wise quantization by manipulating the kernels prior to inference.	Reply	O	0
For your reference, Figure 1 has been modified to make the distinction clearer	Reply	O	0

The main contributions of the work are the new datasets and the overall integration of previous modeling tools in such a way that the final architecture is able to encode semantic spatial relations from textual descriptions.	Review	O	0
This is demonstrated by an implementation that, given textual descriptions, is able to render images from novel viewpoints.	Review	O	0
In terms of these two contributions, as I explain below, I believe there is space to improve the datasets and the paper needs further analysis/comments about the merits of the proposed approach.	Review	O	0
So my current overall rating is below acceptance level.	Review	O	0
[line_break_token][line_break_token]In terms of data, authors provide 2 new datasets: i) a large datasets (10M) with synthetic examples (images and descriptions) and ii) a small dataset (6k) with human textual descriptions corresponding to synthetic images.	Review	O	0
As the main evaluation method of the paper, the author include direct human evaluation of the resulting renderings (3 level qualitative evaluation: perfect-match/partial-match/no-match).	Review	O	0
I agree that, for this application, human evaluation is more adequate than comparing a pixel-level output with respect to a gold image.	Review	B-Review	1
In this sense, it is surprising that for the synthetic dataset the perfect match score of human evaluation for ground truth data is only 66%.	Review	I-Review	1
It will be good to increase this number providing a cleaning dataset.	Review	I-Review	1
[line_break_token][line_break_token]Related to the previous comment, it will be good to provide a deeper analysis about the loss function used to train the model.	Review	I-Review	2
  [line_break_token][line_break_token]In terms of the input data, it is not clear how the authors decide about the 10 views for each scene.	Review	O	0
[line_break_token][line_break_token]In terms of the final model, if I understood correctly, the paper does not claim any contribution, they use a model presented in a previous work (actually information about the model is mostly included as a supplemental material).	Review	B-Review	4
If there are relevant contributions in terms of model integration and/or training scheme, it will be good to stress this in the text.	Review	I-Review	4
[line_break_token][line_break_token]Writing is correct, however, authors incorporate important details about the dataset generation process as well as the underlying model in the supplemental material.	Review	I-Review	5
Given that there is a page limit, I believe the relevant parts of the paper should be self-contain.	Review	I-Review	5
Thank you for the thorough review and insightful comments.	Reply	O	0
[line_break_token][line_break_token]> ‚ÄòIn this sense, it is surprising that for the synthetic dataset the perfect match score of human evaluation for ground truth data is only 66%.	Reply	O	0
It will be good to increase this number providing a cleaning dataset.	Reply	O	0
‚Äô For the synthetic dataset, the noise added by certain objects missing from the captions does not degrade the performance of the model - the model is *only* fed captions as input which means it can integrate the information of multiple captions to create a reconstruction of the scene, and it only reconstructs image pixels, which means it never sees that picture‚Äôs caption.	Reply	O	0
Therefore the imperfect match between pixels and text is an issue that only arises at [human] evaluation time.	Reply	B-Reply	1
Given the cost of cleaning up these captions, we believe the most practical course of action was to collect human evaluations with this mapping and keeping in mind that the gold truth sets an upper bound.	Reply	I-Reply	1
[line_break_token][line_break_token]> ‚Äòdeeper analysis about the loss function used to train the model.	Reply	O	0
‚Äô We use the loss function from previous work by Eslami et al. (	Reply	O	0
2018)--.	Reply	B-Reply	2
We have added more details to the model section in the main text and also provide a detailed description in Appendix section A.2.	Reply	I-Reply	2
[line_break_token][line_break_token]> ‚ÄòIn terms of the input data, it is not clear how the authors decide about the 10 views for each scene.	Reply	O	0
‚Äô For non-language related hyperparameters, we followed the choices in Eslami et.	Reply	O	0
al 2018.	Reply	B-Reply	3
Optimizing this hyperparameter choice is an interesting avenue to explore however we felt it was outside of the scope of this work.	Reply	I-Reply	3
[line_break_token][line_break_token]> ‚ÄòIf there are relevant contributions in terms of model integration and/or training scheme, it will be good to stress this in the text.	Reply	O	0
‚Äô  We have updated the text to explain the novel aspects of the model, which is the integration of language inputs, as well as dataset generation as much as possible.	Reply	O	0
In the appendix you can also find a detailed description of the model setup, hyperparameters, and dataset generation which did not fit into the main text.	Reply	B-Reply	4

The authors present a framework for symbolic superoptimization using methods from deep learning.	Review	O	0
A deep learning approach operating on the expression tree structures is proposed based on a combination of subtree embeddings, LSTM RNN structures, and an attention mechanism.	Review	O	0
[line_break_token][line_break_token]The approach avoids the exploitation of human-generated equivalence pairs thus avoiding human interaction and corresponding bias.	Review	O	0
Instead, the approach is trained using random generated data.	Review	B-Review	1
It remains somewhat unclear how the corresponding random data generation influences general applicability w.r.t.	Review	I-Review	1
other tasks, as the authors apply constraints on the generation process for complexity reasons.	Review	I-Review	1
A corresponding discussion would be valuable here.	Review	I-Review	1
[line_break_token][line_break_token]In Secs.	Review	O	0
3 &amp; 4, the authors present their specific modeling and learning approach.	Review	O	0
However, they do not report on modeling or learning alternatives.	Review	B-Review	2
It would be interesting for the audience to understand, how the authors reached these specific choices, and how (some of) these choice influence performance and learning stability.	Review	I-Review	2
For example, in Sec.	Review	I-Review	2
4.1, an additional loss term is introduced to further support the learning of embeddings.	Review	I-Review	2
However, it might interesting to see comparative results quantitatively investigating the effect of this additional loss term.	Review	I-Review	2
Also, as far as I can see, no information on the choice of hyperparameters (e.g. LSTM dimensions) are provided or analyzed w.r.t.	Review	I-Review	2
their effect on the performance of the proposed approach.	Review	I-Review	2
e have updated our paper.	Reply	O	0
Please refer to the thread ‚ÄúRevised Paper Uploaded‚Äù for a summary of major updates in our revision.	Reply	O	0
Following is a detailed response to Review #2 comments.	Reply	O	0
[line_break_token][line_break_token]1) Ablation studies.	Reply	O	0
[line_break_token]Our revised Appendix C introduces a set of ablation studies.	Reply	B-Reply	3
Specifically, figure 5 shows that the performance drops significantly if the subtree embedding similarity loss is removed.	Reply	I-Reply	3
In addition, appendix C.1 explores why the embedding similarity loss is important.	Reply	I-Reply	3
In short, this loss will provide a more concrete training signal to assist convergence, which is otherwise difficult due to REINFORCE.	Reply	I-Reply	3
In addition to the embedding similarity loss, the ablation studies also investigate the significance of the subtree selector and the tree-LSTM architecture.	Reply	I-Reply	3
For more details, please kindly refer to appendix C.[line_break_token][line_break_token]2) Hyperparameter settings.	Reply	O	0
[line_break_token]Our hyperparameters, including the LSTM dimensions, follow the common setting in previous works, without any explicit tuning.	Reply	B-Reply	2
Our revised Appendix A.3 describes our hyperparameter setting and our decision making in detail.	Reply	I-Reply	2
[line_break_token][line_break_token]3) How data generation affects performance.	Reply	O	0
[line_break_token]Our revised Section 5.1 and Appendix A.1 &amp; A.2 provide a detailed description of datasets preparation and use.	Reply	O	0
We use two datasets: (a) the ‚Äútraverse equivalence dataset‚Äù (mentioned by Review#3) is only used for stage-I training; (b) the benchmark dataset ‚ÄúHalide dataset‚Äù is used by the stage-II training.	Reply	B-Reply	1
The former dataset mainly contains short expressions under a depth of four; the goal is to assist the stage-II training to be performed on the latter dataset.	Reply	I-Reply	1
Therefore, It does not affect the performance that the traverse space is reduced when generating the dataset for complexity reasons.	Reply	I-Reply	1
Section 5.1 and Appendix A.1 &amp; A.2 describes more details about the datasets.	Reply	O	0

The paper presents video generation method with spacio-temporally consistent features.	Review	O	0
This is done through: a) temporal adversarial learning, b) Ping Pong loss, and c) metrics that quantify the quality.	Review	O	0
The methods are evaluated on two datasets and user studies.	Review	O	0
[line_break_token][line_break_token]The idea is interesting and the paper is well written.	Review	O	0
The results are convincing.	Review	O	0
[line_break_token][line_break_token]The originality of the concatenation of several frames is somewhat limited, since it is a standard procedure in other domains such as robotics.	Review	B-Review	1
Nevertheless the results are positive.	Review	I-Review	1
[line_break_token][line_break_token]Seems like the metrics definitions were not included in the main body of the paper - the authors should either include them to remove from the contributions.	Review	I-Review	2
ear reviewer, thank you very much for the review and suggestions.	Reply	O	0
[line_break_token][line_break_token]Q1: ‚Äúoriginality of the concatenation of several frames is somewhat limited‚Äù[line_break_token]A1: It is correct that such a concatenation is used in a variety of other settings.	Reply	O	0
The core aim of our work is to highlight its importance in a very challenging setting, i.e., for training spatio-temporal GANs for natural image sequences.	Reply	B-Reply	1
In this field, L2-based losses dominate, and with our work, we demonstrate how much additional detail can be generated with the right approach for adversarial training.	Reply	I-Reply	1
We will clarify this in the text of our submission.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: ‚Äúthe metrics definitions were not included in the main body of the paper‚Äù[line_break_token]A2: We will move the metrics definitions into the main part in a future version of the paper.	Reply	O	0

The paper proposes an algorithm for training memory networks which have very large memories.	Review	O	0
Training such models in traditional ways, by using soft-attention mechanism over all the memory slots is not only slow, it is also harder to train due to dispersion of gradients.	Review	O	0
The paper proposes to use the k-mips algorithm over the memories to choose a subset of the memory slots over which the attention is applied.	Review	O	0
Since the cost of exact k-mips is the same as doing full attention, the authors propose to use approximate k-mips, which while faster to compute, results in inferior performance.	Review	O	0
An artifact of using k-mips is that one cannot learn the memory slots.	Review	O	0
Hence they are pre-trained and kept fixed during entire training.	Review	O	0
The experimental section shows the efficacy of using k-mips using the SimpleQuestions dataset.	Review	O	0
The exact k-mips results in the same performance as the full attention.	Review	O	0
The approximate k-mips results in deterioration in performance.	Review	O	0
The paper is quite clearly written and easy to understand.	Review	O	0
[line_break_token][line_break_token]I think the ideas proposed in the paper are not super convincing.	Review	O	0
I have a number of issues with this paper.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
The k-mips algorithm forces the memories to be fixed.	Review	B-Review	1
This to me is a rather limiting constraint, especially on problems/dataset which will require multiple hops of training to do compounded reasoning.	Review	I-Review	1
As a results I'm not entirely sure about the usefulness of this technique.	Review	I-Review	1
[line_break_token]2.	Review	O	0
Furthermore, the exact k-mips is the sample complexity as the full attention.	Review	B-Review	2
The only way to achieve speedup is to use approx k-mips.	Review	I-Review	2
That, as expected, results in a significant drop in performance.	Review	I-Review	2
[line_break_token]3.	Review	I-Review	3
The paper motivates the ideas by proposing solutions to eliminate heuristics used to prune the memories.	Review	I-Review	3
However in Section 3.1 the authors themselves end up using multiple heuristics to make the training work.	Review	I-Review	3
Agreed, that the used heuristics are not data dependent, but still, it feels like they are kicking the can down the road as far as heuristics are concerned.	Review	I-Review	3
[line_break_token]4.	Review	O	0
The experimental results are not very convincing.	Review	B-Review	4
First there is no speed comparison.	Review	I-Review	4
Second, the authors do not compare with methods other than k-mips which do fast nearest neighbor search, such as, FLANN.	Review	I-Review	4
Thanks for your valuable feedback.	Reply	O	0
[line_break_token][line_break_token]> The k-mips algorithm forces the memories to be fixed.	Reply	O	0
This to me is a rather limiting constraint, especially on problems/dataset which will require multiple hops of training to do compounded reasoning.	Reply	O	0
As a results I'm not entirely sure about the usefulness of this technique.	Reply	O	0
[line_break_token][line_break_token]It is true that the k-mips algorithm forces the memories to be fixed.	Reply	B-Reply	1
However, it is not the issue with k-mips algorithm only.	Reply	I-Reply	1
We have this issue with nearest neighbor search algorithms and maximum cosine similarity search algorithms as well.	Reply	I-Reply	1
When we need to update the memory, then one can do periodic memory reorganization after every few epochs as done by Vijayanarasimhan et al.,	Reply	I-Reply	1
2014 or Rae et al.,	Reply	I-Reply	1
2016.	Reply	I-Reply	1
[line_break_token][line_break_token]However, this is not a limiting constraint on problems which will require multiple hops.	Reply	I-Reply	1
One can design a separate inference module (like the episodic memory in end-to-end memory nets) that will take care of multiple hops and the main memory can still be fixed.	Reply	I-Reply	1
So we believe that this technique is still useful in the setting mentioned by the reviewer.	Reply	I-Reply	1
[line_break_token][line_break_token]> Furthermore, the exact k-mips is the sample complexity as the full attention.	Reply	O	0
The only way to achieve speedup is to use approx k-mips.	Reply	O	0
That, as expected, results in a significant drop in performance.	Reply	O	0
[line_break_token][line_break_token]Yes true.	Reply	B-Reply	2
Exact k-mips has the sample complexity of full attention.	Reply	I-Reply	2
Our k-mips experiments serve two purposes: 1.	Reply	I-Reply	2
It is a proof of concept that approximate k-mips if done correctly would help us achieve scalability as well as performance.	Reply	I-Reply	2
2.	Reply	I-Reply	2
It is suggestive to use k-mips instead of full attention even in situations where full attention is cheap.	Reply	I-Reply	2
We think that both are important messages.	Reply	I-Reply	2
Our approximate k-mips experiments benchmark the existing state-of-the-art methods for approximate k-mips and show that they are not good enough for this task.	Reply	I-Reply	2
This demands more research on better approximate k-mips methods.	Reply	I-Reply	2
[line_break_token][line_break_token]> The paper motivates the ideas by proposing solutions to eliminate heuristics used to prune the memories.	Reply	O	0
However in Section 3.1 the authors themselves end up using multiple heuristics to make the training work.	Reply	O	0
Agreed, that the used heuristics are not data dependent, but still, it feels like they are kicking the can down the road as far as heuristics are concerned.	Reply	O	0
[line_break_token][line_break_token]We agree with the reviewer.	Reply	B-Reply	3
As the reviewer rightly pointed out, we replaced the dataset-specific heuristics with dataset-independent heuristics which is a research direction worth exploring since it will be applicable to any kind of datasets.	Reply	I-Reply	3
[line_break_token][line_break_token] > The experimental results are not very convincing.	Reply	O	0
First there is no speed comparison.	Reply	O	0
Second, the authors do not compare with methods other than k-mips which do fast nearest neighbor search, such as, FLANN.	Reply	O	0
[line_break_token][line_break_token]FLANN is a standard library that people use for nearest neighbor search.	Reply	B-Reply	4
However, please note that PCA-tree is a better method than FLANN and is a state-of-the-art in tree based methods.	Reply	I-Reply	4
We benchmark three search algorithms each state-of-the-art in clustering-based, tree-based, and hashing-based approaches respectively.	Reply	I-Reply	4
[line_break_token]Speed comparison of different approximate k-mips algorithms used in this paper has already been done in an extensive setup in Auvolat et al.,	Reply	I-Reply	4
2015	Reply	I-Reply	4

The paper deals with an interesting application of adversarial training to encryption.	Review	O	0
It considers the standard scenario of Alice, Eve and Bob, where A and B aim to exchange messages conditioned on a shared key, while Eve should be unable to encrypt the message.	Review	O	0
Experiments are performed in a simple symmetric 16 bit encryption task, and an application on privacy.	Review	O	0
The concepts, ideas and previous literature are quite nicely and carefully presented.	Review	O	0
[line_break_token][line_break_token]The only major concern I have - and I apologize to the authors for not raising this earlier - are the experiments in section 3.	Review	O	0
In particular, I don't quite get the scenario.	Review	O	0
The reasoning here seems to be as follows: given information < A, B, C, D >, I want to give the public the value of D (e.g. movies watched) without releasing information about C (e.g. gender).	Review	O	0
In this scenario, Eve would need to be able to reconstruct D as good as possible without gaining information about C. What is described in section 3, however, is that D and D-public are both reconstructed by Bob, but why would Bob reconstruct the latter (he is not public, in particular because he is allowed to reconstruct C, which is not tested here)?	Review	O	0
Also, Eve only tries to estimate C, thus rendering the scenario not different in any way to the scenario considered in section 2.	Review	O	0
[line_break_token][line_break_token]I have two more minor concerns:[line_break_token][line_break_token]1) As raised in the pre-review, Eve should actually be stronger then Alice and Bob in order to be able to compensate for the missing key.	Review	O	0
The authors noted they have been doing these experiments and are going to add the results.	Review	B-Review	1
[line_break_token][line_break_token]2) In any natural encryption case I would expect the length of the key to be much shorter then the length of the message.	Review	O	0
This, however, could potentially make the scenario much easier for Eve (although I doubt any of the results will change if the key is long enough).	Review	B-Review	2
[line_break_token][line_break_token]I like the creative application of adversarial training to a completely different domain, and I believe it could be the starting point of a very interesting direction in cryptographic systems or in privacy applications (although it is unclear whether the weak guarantees of neural network based approaches can ever be overcome).	Review	O	0
At the same time the application in the privacy setting leaves me quite confused, and the symmetric encryption example is not particularly strong either.	Review	O	0
I'd appreciate if the authors could address the major concern I raised above, and I will be quite happy to raise the score in case this confusion can be resolved.	Review	O	0
Thank you for your encouraging comments.	Reply	O	0
[line_break_token][line_break_token]Regarding the experiments of section 3, the scenario is that Alice provides information so that anyone can observe an estimate of D without gaining information about C. The fact that C is hidden is formulated by introducing Eve, which attempts to reconstruct C. Alice also provides additional information so that Bob, with whom Alice shares a key, can do an even better job at estimating D, but may learn something about C. In sum, the main difference with section 2 is that here the ‚Äúcommunication goal‚Äù and the ‚Äúhiding goal‚Äù concern two different parts of the plaintext (D and C respectively).	Reply	O	0
We hope that this clarifies the matter; we would certainly be happy to expand the discussion in section 3 (perhaps adding diagrams which we have used in talks, but which seemed too long for the submission).	Reply	O	0
[line_break_token][line_break_token]Regarding minor concern (1), we will indeed be glad to include the results indicated in our response and some updated ones in the event that the paper is accepted.	Reply	B-Reply	1
We agree that it is interesting to think about stronger Eve networks, as suggested by the reviewer.	Reply	I-Reply	1
On the other hand, we believe that the appropriate strength of Eve may sometimes be dictated by intended applications; for example, if we are trying to hide information from one of our own neural-network components (as suggested in page 2), it makes sense that Eve be of a similar size and architecture as that component.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding minor concern (2), we have two thoughts.	Reply	I-Reply	2
 First, it may often be appropriate to generate arbitrary-length key material using standard cryptographic key-generation techniques.	Reply	I-Reply	2
 (These techniques generate an arbitrary-length stream of bits given a short initial seed, and parts of that stream of bits could be used as the keys passed into the neural cryptography).	Reply	I-Reply	2
 Second, as a generalization of our work, we agree that the treatment of larger messages could be interesting.	Reply	I-Reply	2
It is natural to evaluate neural cryptography with messages larger than keys;  this should be a straightforward extension of our current work.	Reply	I-Reply	2
 As a more futuristic step, one could explore so-called ‚Äúmodes of operation‚Äù using RNNs or similar architectures	Reply	I-Reply	2

The proposed method is suitable for many NLP tasks, since it can handle the sequence data.	Review	O	0
[line_break_token][line_break_token]I find it difficult to follow through the model descriptions.	Review	B-Review	1
 Perhaps a more descriptive figures would make this easier to follow, I feel that the ART model is a very strait forward and it can be easily described in much simpler and less exhausting (sorry for the strong word) way, while there is nothing wrong with being as elaborating as you are, I feel that all those details belong in an appendix.	Review	I-Review	1
[line_break_token]Can you please explain the exact learning process?	Review	I-Review	2
[line_break_token]I didn‚Äôt fully understand the exact way of collocations, you first train on the source domain and then use the trained source network when training in the target domain with all the collocated words for each training example?	Review	I-Review	7
I deeply encourage you to improve the model section for future readers.	Review	I-Review	7
[line_break_token]In contrast to the model section, the related work and the experimental settings sections are very thin.	Review	I-Review	3
[line_break_token]The experimental setup for the sentiment analysis experiments is quite rare in the transfer learning/domain adaptation landscape, having equal amount of labeled data from both source and target domains is not very realistic in my humble opinion.	Review	I-Review	6
[line_break_token]More realistic setup is unsupervised domain adaptation (like in DANN and MSDA-DAN papers) or minimally supervised domain adaptation (like you did in your POS and NER experiments).	Review	I-Review	6
[line_break_token][line_break_token]In addition to the LSTM baseline (which is trained with target data only), I think that LSTM which is trained on both source and target domains data is required for truly understand ART gains ‚Äì this goes for the POS and NER tasks as well.	Review	I-Review	5
[line_break_token]The POS and NER experiments can use some additional baselines for further comparison, for example:[line_break_token]<a href="http://www.aclweb.org/anthology/Q14-1002" target="_blank" rel="nofollow">http://www.aclweb.org/anthology/Q14-1002</a>[line_break_token]<a href="https://hornhehhf.github.io/hangfenghe/papers/14484-66685-1-PB.pdf" target="_blank" rel="nofollow">https://hornhehhf.github.io/hangfenghe/papers/14484-66685-1-PB.pdf</a>[line_break_token][line_break_token]I am not sure I understand the ‚Äúcell level transfer‚Äù claim, did you mean that you are the first to apply inner LSTM/RNN cell transfer or that you are the first ones to apply word-level fine grained transfer, the latter has already been done:[line_break_token]<a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1802.05365.pdf</a>[line_break_token]<a href="https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=4531&context=sis_research" target="_blank" rel="nofollow">https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=4531&context=sis_research</a>[line_break_token]<a href="http://www.aclweb.org/anthology/N18-1112" target="_blank" rel="nofollow">http://www.aclweb.org/anthology/N18-1112</a>[line_break_token]<a href="https://openreview.net/pdf?id=rk9eAFcxg" target="_blank" rel="nofollow">https://openreview.net/pdf?id=rk9eAFcxg</a>[line_break_token]	Review	O	0
Thank you for your insightful and supportive comments.	Reply	O	0
We have made the following revisions: (1) We added two baselines according to your comments.	Reply	O	0
The results further justify the effectiveness of ART. (	Reply	O	0
2) We added a new experiment for minimally supervised domain adaptation in Table 3.	Reply	O	0
ART still outperforms all the competitors by a large margin. (	Reply	O	0
3) We clarified the ART model and model training process in the revised paper.	Reply	O	0
We will give more details below:[line_break_token][line_break_token]== Writing ==[line_break_token]1.	Reply	O	0
High level description of the ART model.	Reply	O	0
[line_break_token]We have added the following description of ART model in section 2.	Reply	B-Reply	1
[line_break_token]‚ÄúThe source domain and the target domain share an RNN layer, from which the common information is transferred.	Reply	I-Reply	1
We pre-train the neural network of the source domain.	Reply	I-Reply	1
Therefore the shared RNN layer represents the semantics of the source domain.	Reply	I-Reply	1
The target domain has an additional RNN layer.	Reply	I-Reply	1
Each cell in it accepts transferred information through the shared RNN layer.	Reply	I-Reply	1
Such information consists of (1) the information of the same word in the source domain (the red edge in figure 2); and (2) the information of all its collocated words (the blue edges in figure 2).	Reply	I-Reply	1
ART uses attention to decide the weights of all candidate collocations.	Reply	I-Reply	1
The RNN cell controls the weights between (1) and (2) by an update gate.	Reply	I-Reply	1
‚Äù[line_break_token][line_break_token]2.	Reply	O	0
Model training.	Reply	B-Reply	2
We add more details of the model training part in section 2.	Reply	I-Reply	2
[line_break_token]We first pre-train the parameters of the source domain by its training samples.	Reply	I-Reply	2
Then we fine-tune the pre-trained model with additional layers of the target domain.	Reply	I-Reply	2
The fine-tuning uses the training samples of the target domain.	Reply	I-Reply	2
All parameters are jointly fine-tuned.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	I-Reply	6
Related work.	Reply	O	0
[line_break_token]We have rewritten the related work section.	Reply	B-Reply	3
We compare with other cell-level transfer learning approaches and pre-trained models.	Reply	I-Reply	3
[line_break_token][line_break_token]== Innovation of cell-level transfer ==[line_break_token]We agree that some previous transfer learning approaches also consider cell-level transfer.	Reply	O	0
But none of them considers the word collocations.	Reply	B-Reply	4
As a pre-trained model, ELMo uses bidirectional LSTMs to generate contextual features.	Reply	I-Reply	4
Instead, ART uses attention mechanism in RNN that each cell in the target domain directly access information of all cells in the source domain.	Reply	I-Reply	4
We added more details in the related work section.	Reply	I-Reply	4
[line_break_token][line_break_token]== Baselines ==[line_break_token]We added two baselines, LSTM-u and FLORS, according to your comments.	Reply	O	0
LSTM-u uses a standard LSTM and is trained by the union data of the source and the target domain.	Reply	B-Reply	5
FLORS is a domain adaptation model for POS tagging (<a href="http://www.aclweb.org/anthology/Q14-1002)."	Reply	O	0
target="_blank" rel="nofollow">http://www.aclweb.org/anthology/Q14-1002).</a> Their results are shown in Table 2 and Table 5.	Reply	O	0
ART outperforms LSTM-u in almost all settings by a large margin.	Reply	B-Reply	5
Note that FLORS is independent of the target domain.	Reply	I-Reply	5
If the training corpus of the target domain is quite rare (Twitter/0.01), FLORS performs better.	Reply	I-Reply	5
But with richer training data of the target domain (Twitter/0.1), ART outperforms FLORS by a large margin.	Reply	I-Reply	5
[line_break_token][line_break_token]Table 2: ClassiÔ¨Åcation accuracy on the Amazon review dataset.	Reply	I-Reply	5
[line_break_token]Source[tab_token][tab_token]Target[tab_token][tab_token]LSTM-u[tab_token]ART[line_break_token]Books[tab_token][tab_token]DVD[tab_token][tab_token]0.770 [tab_token]0.870 [line_break_token]Books[tab_token][tab_token]Electronics[tab_token]0.805 [tab_token]0.848 [line_break_token]Books[tab_token][tab_token]Kitchen[tab_token][tab_token]0.845 [tab_token]0.863 [line_break_token]DVD[tab_token][tab_token]Books[tab_token][tab_token]0.788 [tab_token]0.855 [line_break_token]DVD[tab_token][tab_token]Electronics[tab_token]0.788 [tab_token]0.845 [line_break_token]DVD[tab_token][tab_token]Kitchen[tab_token][tab_token]0.823 [tab_token]0.853 [line_break_token]Electronics[tab_token]Books[tab_token][tab_token]0.740 [tab_token]0.868 [line_break_token]Electronics[tab_token]DVD[tab_token][tab_token]0.753 [tab_token]0.855 [line_break_token]Electronics[tab_token]Kitchen[tab_token][tab_token]0.863 [tab_token]0.890 [line_break_token]Kitchen[tab_token][tab_token]Books[tab_token][tab_token]0.760 [tab_token]0.845 [line_break_token]Kitchen[tab_token][tab_token]DVD[tab_token][tab_token]0.758 [tab_token]0.858 [line_break_token]Kitchen[tab_token][tab_token]Electronics[tab_token]0.815 [tab_token]0.853 [line_break_token]        Average[tab_token][tab_token][tab_token][tab_token]0.792 [tab_token]0.858[line_break_token][line_break_token]Table 5: Performance over POS tagging.	Reply	I-Reply	5
[line_break_token]Task[tab_token][tab_token][tab_token]Source[tab_token]Target[tab_token][tab_token]FLORS[tab_token]ART[line_break_token]POS Tagging[tab_token]        PTB[tab_token][tab_token]Twitter/0.1[tab_token]0.763[tab_token]0.859[line_break_token]POS Tagging[tab_token]        PTB[tab_token][tab_token]Twitter/0.01[tab_token]0.763[tab_token]0.658[line_break_token][line_break_token]== Experimental settings ==[line_break_token]Based on your comment, we added a new experiment for minimally supervised domain adaptation in sentence classification.	Reply	O	0
For each target domain in the Amazon review dataset, we combined the training/development data of rest three domains as the source domain.	Reply	B-Reply	6
We show the results in Table 3.	Reply	I-Reply	6
ART outperforms the competitors by a large margin.	Reply	I-Reply	6
This verifies its effectiveness in the setting of minimally supervised domain adaptation.	Reply	I-Reply	6
[line_break_token][line_break_token]Table 3: Classification accuracy with scarce training samples of the target domain.	Reply	I-Reply	6
[line_break_token]Target[tab_token][tab_token]LSTM[tab_token]LSTM-u[tab_token]CCT[tab_token][tab_token]LWT[tab_token]HATN[tab_token]ART[line_break_token]Books[tab_token][tab_token]0.745 [tab_token]0.813 [tab_token]0.848 [tab_token]0.808 [tab_token]0.820 [tab_token]0.895 [line_break_token]DVD[tab_token][tab_token]0.695 [tab_token]0.748 [tab_token]0.870 [tab_token]0.770 [tab_token]0.828 [tab_token]0.875 [line_break_token]Electronics[tab_token]0.733 [tab_token]0.823 [tab_token]0.848 [tab_token]0.818 [tab_token]0.863 [tab_token]0.865 [line_break_token]Kitchen[tab_token][tab_token]0.798 [tab_token]0.840 [tab_token]0.860 [tab_token]0.840 [tab_token]0.833 [tab_token]0.870 [line_break_token]Average[tab_token][tab_token]0.743 [tab_token]0.806 [tab_token]0.856 [tab_token]0.809 [tab_token]0.836 [tab_token]0.87	Reply	I-Reply	6

Overview: [line_break_token]The authors proposed a weakly-supervised method to localize video moments given text queries.	Review	O	0
 The model builds multi-level relational graphs among pairs of word and video frame, and the graph is used to aggregate visual-semantic feature for each word and each frame.	Review	O	0
Then the attentive features are used to localize the sentence query in videos by calculating the similarity of words and frames.	Review	O	0
In summary, the proposed weakly-supervised Moment Alignment Network (wMAN) utilizes a multi-level co-attention mechanism to learn richer multimodal representations for language based video retrieval..[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
Significant performance improvement on Didemo and Charades-STA datasets.	Review	O	0
The authors achieved very good performance on both dataset, even higher than some of the full-supervision methods, such as CTRL and MLVI.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
The overall novelty of the proposed methods is limited.	Review	B-Review	1
Essentially, the key points of the model is hierarchical visual semantic co-attention.	Review	I-Review	1
,which is proposed originally in [Hierarchical Question-Image Co-Attention[line_break_token]for Visual Question Answering], although the original application is VQA in image domain.	Review	I-Review	1
So in this way, the novelty is only marginal.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	4
Paper writing can be improved.	Review	I-Review	2
Figure 2 shows the overall structure of the model, however, the caption doesn't explain all the notations in the figure, such as WCVG, and the equations.	Review	I-Review	2
Additionally, the reference is very far away from Figure 2, which makes the whole paper hard to read.	Review	I-Review	2
[line_break_token]3.	Review	O	0
For evaluation part, one important ablation study is missing: the number of steps T for message passing.	Review	B-Review	3
This eval is important, as it shows the necessity of using "multi-level" attention.	Review	I-Review	3
[line_break_token][line_break_token]Minor comments:[line_break_token]1.	Review	O	0
Make the caption of Figure 2 self-explainable, e.g. the meaning of LSE.	Review	B-Review	4
[line_break_token]2.	Review	I-Review	4
There is a "word-conditioned" visual graph network, why not the other way, "frame-conditioned" semantic graph net and iterate over it?	Review	I-Review	4
[line_break_token]	Review	O	0
hank you for your review.	Reply	O	0
We address your concerns below.	Reply	O	0
[line_break_token][line_break_token]1) This is addressed in the general response.	Reply	O	0
[line_break_token][line_break_token]2) We will update the next version of the paper with the necessary clarifications to the caption and modifications.	Reply	O	0
[line_break_token][line_break_token]3) We have updated the submission with an ablation study of how the number of message-passing steps affects the performance of our proposed approach.	Reply	O	0
They are included in Section B of the appendix.	Reply	B-Reply	3
In our experiments across both Charades-Sta and DiDeMo, we have observed that 3 steps work the best.	Reply	I-Reply	3
[line_break_token][line_break_token]We hope that we have addressed your concerns satisfactorily.	Reply	O	0
Please let us know if you have any further concerns or questions	Reply	O	0

The paper proposes to use a multi-step prediction model in model-based RL.	Review	O	0
The proposed model maps from current state and a sequence of actions to the state after taking those actions.	Review	O	0
The paper demonstrates on 2 tasks that in a model-predictive control loop combined with planning by cross-entropy method, this can yield better asymptotic performance than using single-step models.	Review	O	0
[line_break_token][line_break_token]The insight of using multi-step prediction models is certainly appealing and makes a lot of sense in deterministic tasks.	Review	O	0
A systematic empirical comparison of multi-step deep models in RL is of interest, which this paper does provide to some extent.	Review	O	0
[line_break_token][line_break_token]An obvious limitation of the proposed deterministic multi-step forward model is the restriction to deterministic systems.	Review	B-Review	1
One would expect that the performance deteriorates quickly as the system becomes more stochastic.	Review	I-Review	1
An extension to the stochastic case along the lines of Chua et al, 2018 is non-trivial as capturing the stochasticity is typically more challenging in long-term predictions.	Review	I-Review	1
Yet, the paper makes an additional assumption that is less clearly communicated: To be able to plan with a R-step model, one needs to be able to evaluate or approximate the sum of R rewards just from the first and last state in that R-long sequence.	Review	I-Review	2
This work uses simply the reward at the end r(s_{t+R}) as a proxy which works well in these MuJoCo tasks but can fail horribly in others.	Review	I-Review	2
One can imagine that a model not only outputs s_{t+R} but also the sum of R rewards given s_t and a_{t:t+R} which could work in more general settings but this is not explored in this paper.	Review	I-Review	2
The contribution in this paper limited as the proposed approach as well as the experimental comparison is restricted to a relatively specific class of problems and no attempts to generalize are made.	Review	I-Review	3
[line_break_token][line_break_token]The experiments nicely compare against using single-step dynamics models and the results show that using the multi-step models for MPC performs better in the two considered tasks.	Review	O	0
However, as fas as I understand both the ACP and Chua et al baseline using the single-step prediction accuracy to train their models.	Review	B-Review	4
The paper is missing a comparison to single-step models that are trained using multi-step prediction losses ("backprop through time" as in Learning Nonlinear Dynamic Models by Langford et al 2009).	Review	I-Review	4
These models should be much more robust to error blow-up for multi-step prediction and do not require the specific reward structure assumed in this paper.	Review	I-Review	4
[line_break_token][line_break_token]The proposed R-step model-based RL approach could be connected to the use of options (the planner and model operate on R-step options, but the MPC does update the policy after every time step).	Review	O	0
It would be interesting to discuss this potential connection in the paper.	Review	O	0
The paper does a good job of discussing existing recent work in the deep RL literature but it would also be good to also discuss earlier work on multi-step prediction (e.g. in time-series modeling).	Review	O	0
[line_break_token][line_break_token]All in all, I think the paper makes a small contribution demonstrating that multi-step models are useful for model-based RL in specific domains -- which is interesting but certainly not surprising.	Review	O	0
Unfortunately the paper stops somewhat early by not comparing to relevant baselines (single-step models trained with multi-step losses) and by not considering tasks where the benefit of multi-step planning would be less clear.	Review	O	0
We thank the reviewer for a very detailed review.	Reply	O	0
[line_break_token][line_break_token]"capturing the stochasticity is typically more challenging in long-term predictions": Yes, this is an interesting direction.	Reply	O	0
Such a model would need the ability to produce complex multimodal distributions of outcomes.	Reply	B-Reply	1
As our goal in this work was to understand why existing methods failed even on deterministic tasks, we leave it to future work to propose classes of multi-step models appropriate for stochastic environments.	Reply	I-Reply	1
[line_break_token][line_break_token]"This work uses simply the reward at the end": In fact, our model is able to use reward at intermediate time steps.	Reply	O	0
To do this, we can use the variable-action-length version of our model, as used for visualization (mentioned in Section 2.2 paragraph 2 of the original version).	Reply	B-Reply	2
We also use this version in Fig 5.	Reply	I-Reply	2
to evaluate prediction error as a function of timesteps in the future.	Reply	I-Reply	2
We have added Section 2.2.1 to clarify this.	Reply	I-Reply	2
[line_break_token][line_break_token]In our main experiments we use a transformed version of the reward function to select trajectories which have an outcome with the greatest x-axis position.	Reply	I-Reply	2
This is approximately equal to the sum of the rewards obtained along the trajectory under the original reward function, which provides a reward at each timestep proportional to the forward progress at that timestep.	Reply	I-Reply	2
We have updated Section 2.3.1 to better reflect this.	Reply	I-Reply	2
[line_break_token][line_break_token]We apologize for not making these points more clear in the paper.	Reply	I-Reply	2
[line_break_token][line_break_token]"single-step models that are trained using multi-step prediction losses": Yes, we agree that other models which directly minimize long-term prediction error will also produce better predictions that single-step models.	Reply	O	0
However, the main goal of this work is to point out the deficiencies of the single-step class of models typically used in the field.	Reply	B-Reply	4
As such, we simply chose one simple member of the class of multistep models to illustrate our point.	Reply	I-Reply	4
[line_break_token][line_break_token]We have since run experiments to evaluate the potential of recurrent training of single-step models with multi-step loss functions.	Reply	I-Reply	4
While using a multi-step loss provides significant improvement over a single-step loss, the PCP remains somewhat more accurate.	Reply	I-Reply	4
We have updated Figure 5 and the related text with this result.	Reply	I-Reply	4
[line_break_token][line_break_token]We furthermore have run these RNN models on the full bootstrapped planning task.	Reply	I-Reply	4
Planning with these models is hugely slower than with the PCP, as for each prediction of length H the RNN must be run forward H times, whereas the PCP need only be run H/R times; that is, the RNNs take 50 times as long on Swimmer.	Reply	I-Reply	4
We have included preliminary results with RNNs in Figure 7 and will update the paper with the completed experiments before camera ready.	Reply	I-Reply	4
We do not believe these results alter the message of the paper.	Reply	I-Reply	4
[line_break_token][line_break_token]The Langford et al reference is very helpful and we will add a discussion of this paper to our related work.	Reply	I-Reply	4

This paper proposes a framework for deep metric learning.	Review	O	0
Using ideas from distributionally robust optimization, the loss (in each batch) is the worst case weighted average of all pairwise classification losses, taken over an uncertainty set of possible weights.	Review	O	0
The framework is shown to be general and encompass various previous approaches.	Review	O	0
Based on it, the authors propose several new algorithms, which are shown to outperform the SOTA on image retrieval data sets in terms of recall.	Review	O	0
[line_break_token][line_break_token]The main contribution of the paper is a unification of previous deep metric learning algorithms, which would be helpful to the community and could inspire new approaches.	Review	O	0
I found the empirical observation that the proposed algorithms are able to reduce the computation time by nearly half to be compelling.	Review	O	0
However, apart from DRO-TopK-PN, the proposed algorithms appear to be minor modifications of existing algorithms.	Review	B-Review	1
[line_break_token][line_break_token]Questions about the experimental protocol:[line_break_token]1.	Review	O	0
Are the results from one run, or averaged over several?	Review	B-Review	2
Standard errors of the evaluation metrics would be very helpful to judge the improvements made by the algorithms, especially as the algorithms are stochastic due to batching.	Review	I-Review	2
[line_break_token]2.	Review	O	0
The proposed algorithms seem to be similar to those of Fan et al. (	Review	B-Review	3
2017) and Namkoong and Duchi (2017).	Review	I-Review	3
Is there a particular reason why they weren‚Äôt included in the experiments?	Review	I-Review	3
hanks for your comments!	Reply	O	0
For differences between our framework and traditional DRO method, please also check response to Reviewer 3.	Reply	B-Reply	3
We want to emphasize that the modifications (i.e., defining over a mini-bath for the robust loss, and more general and flexible regularization of the dual variables) are subtle but very important for achieving better empirical results than complicated losses and bringing more theoretical insights for complicated losses.	Reply	I-Reply	3

Privacy concerns arise when data is shared with third parties, a common occurrence.	Review	O	0
This paper proposes a privacy-preserving classification framework that consists of an encoder that extracts features from data, a classifier that performs the actual classification, and a decoder that tries to reconstruct the original data.	Review	O	0
In a mobile computing setting, the encoder is deployed at the client side and the classification is performed on the server side which accesses only the output features of the encoder.	Review	O	0
The adversarial training process guarantees good accuracy of the classifier while there is no decoder being able to reconstruct the original input sample accurately.	Review	O	0
Experimental results are provided to confirm the usefulness of the algorithm.	Review	O	0
[line_break_token][line_break_token]The problem of privacy-preserving learning is an important topic and the paper proposes an interesting framework for that.	Review	O	0
However, I think it needs to provide more solid evaluations of the proposed algorithm, and presentation also need to be improved a bit.	Review	O	0
[line_break_token][line_break_token]Detailed comments:[line_break_token]I don‚Äôt see a significant difference between RAN and DNN in Figure 5.	Review	O	0
Maybe more explanation or better visualization would help.	Review	B-Review	1
[line_break_token]The decoder used to measure privacy is very important.	Review	I-Review	2
Can you provide more detail about the decoders used in all the four cases?	Review	I-Review	2
If possible, evaluating the privacy with different decoders may provide a stronger evidence for the proposed method.	Review	I-Review	3
[line_break_token]It seems that DNN(resized) is a generalization of DNN.	Review	I-Review	4
If so, by changing the magnitude of noise and projection dimensions for PCA should give a DNN(resized) result (in Figure 3) that is close to DNN.	Review	I-Review	4
If the two NNs used in DNN and DNN(resized) are different, I believe it‚Äôs still possible to apply the algorithm in DNN(resized) to the NN used in DNN, and get a full trace in the figure as noise and projection changes, which would lead to more fair comparison.	Review	I-Review	4
[line_break_token]The abstract mentioned that the proposed algorithm works as an ‚Äúimplicit regularization leading to better classification accuracy than the original model which completely ignores privacy‚Äù.	Review	I-Review	5
But I don‚Äôt see clearly from the experimental results how the accuracy compares to a non-private classifier.	Review	I-Review	5
[line_break_token]Section 2.2 mentioned how different kind of layers would help with the encoder‚Äôs utility and privacy.	Review	I-Review	6
It would be better to back up the argument with some experiments.	Review	I-Review	6
[line_break_token]I think it needs to be made clearer how reconstruction error works as a measure of privacy.	Review	I-Review	7
For example, an image which is totally unreadable for human eye might still leak sensitive information when fed into a machine learning model.	Review	I-Review	7
[line_break_token]In term of reference, it‚Äôs better to cite more articles with different kind of privacy attacks for how raw data can cause privacy risks.	Review	I-Review	8
For the ‚ÄúNoisy Data‚Äù method, it‚Äôs better to cite more articles on differential privacy and local differential privacy.	Review	I-Review	9
[line_break_token]Some figures, like Figure 3 and 4, are hard to read.	Review	I-Review	10
The author may consider making the figures larger (maybe with a 2 by 2 layout), adjusting the position of the legend & scale of x-axis for Figure 3, and using markers with different colors for Figure 4.	Review	O	0
[line_break_token]	Review	O	0
We thank the comments with cares and insights, which are helpful for improving the quality and readability of our paper.	Reply	O	0
We are glad that you support our paper.	Reply	O	0
We have addressed all the comments as follows:[line_break_token][line_break_token]Response #1: In the revision, we had added a new experiment to zoom in on two categories for clearer utility visualization.	Reply	O	0
In particular, we show the DNN‚Äôs deep features and RAN‚Äôs Encoder output to illustrate how they push the features to cluster with the ‚Äúcar with/without road‚Äù & ‚Äúsailboat with/without water‚Äù images in the feature space.	Reply	O	0
[line_break_token] [line_break_token]Response #2: We agree that we should provide more details about the decoders.	Reply	O	0
Generally, we set the Decoder to mirror the Encoder's architecture.	Reply	B-Reply	2
That is, we assume a powerful adversary that knows the Encoder in training.	Reply	I-Reply	2
Because the Encoders are different for different tasks, the Encoders are different too.	Reply	I-Reply	2
In particular, we select the architecture of Encoder plus Classifier to be LeNet for MNIST, Ubisound and Har, to be AlexNet for CIFAR-10, and to be VGG-16 for ImageNet.	Reply	I-Reply	2
The architectures of Encoder in four cases are different, so the Decoder is varied as well.	Reply	I-Reply	2
In the revision, we have added above explanations about Decoder in Section 2.3 and in experiment settings of Section 3.	Reply	I-Reply	2
[line_break_token][line_break_token]Response #3: We agree that the description of three baselines should be more precise, especially the DNN and DNN(resized) baseline.	Reply	O	0
In the revision, we have added explanations on the difference/similarity between DNN (resized) and DNN baselines.	Reply	B-Reply	4
And explain why we include them as baselines to compare RAN against in Section 3.1.	Reply	I-Reply	4
[line_break_token] [line_break_token]Response #4: We have added more explanations in Section 3.1 about how ‚Äúthe proposed algorithm works as an implicit regularization leading to better classification accuracy than the original model which completely ignores privacy‚Äù.	Reply	O	0
As shown in Figure 3, the utility of RAN‚Äôs Encoder output is higher than that of DNN.	Reply	B-Reply	5
Here the DNN model stands for the non-private feature extractor followed by a non-private classifier.	Reply	I-Reply	5
[line_break_token] [line_break_token]Response #5: We agree that it is necessary to conduct experiments to compare RAN‚Äôs performance concerning privacy and accuracy with/without a different kind of layers so that we can back up the argument mentioned in Section 2.2.	Reply	O	0
On the one hand, we have already conducted exhaustive micro-benchmark experiments to determine the current design of RAN.	Reply	B-Reply	6
For example, we select different model architectures (layers and building blocks), weight updating schemes of different parts (when and how to update Encoder, Decoder and Classifier) and settings of some important hyper-parameters (the setup of ‚Äún‚Äù epochs and ‚Äúk‚Äù steps, learning rate) to select the empirically optimized one.	Reply	I-Reply	6
However, we only present the most important results in this paper due to the space limit.	Reply	I-Reply	6
On the other hand, for all the arguments in Section 2.2, we have added the citation to support them.	Reply	I-Reply	6
[line_break_token] [line_break_token]Response #6: We agree that it is important to justify how the reconstruction error works as a measure of privacy in this paper.	Reply	O	0
 In the revision, we have added the following explanation and justification on privacy quantification in Section 1, Section 2, Section 4 and Section 5.	Reply	B-Reply	7
[line_break_token][line_break_token]First, there is no single standard definition of data privacy-preserving and corresponding adversary attacks.	Reply	I-Reply	7
And a fundamental problem is the natural privacy-utility tradeoff which is affected by different data privacy-preserving methods.	Reply	I-Reply	7
We note that our principal contribution in this paper is the RAN framework and the training algorithm, which can accommodate different choices of privacy attacker and privacy quantification.	Reply	I-Reply	7
[line_break_token][line_break_token]Second, finding the right measurement for privacy is an open problem in itself.	Reply	I-Reply	7
To evaluate RAN, one has to pick some quantifications.	Reply	I-Reply	7
In the present paper, we chose the ‚Äúreconstructive error‚Äù because it is the most intuitive one to measure the risk of original data disclosure given perturbed data (Encoder output).	Reply	I-Reply	7
[line_break_token][line_break_token]Third, in the future, we will evaluate RAN using other quantifications of privacy as well in a defined application.	Reply	I-Reply	7
For example, we could measure the privacy by the hidden failure, i.e., the ratio between the background patterns that were discovered based on RAN‚Äôs Encoder output, and the sensitive patterns founded from the raw data, in an object recognition task.	Reply	I-Reply	7
[line_break_token] [line_break_token]Response #7: Thanks for pointing out the citation problem in Section 3.1.	Reply	O	0
In the revision, we have added explanation and cited more articles about several attacks for how the raw data can cause privacy risks in Section 1.	Reply	B-Reply	9
For example, underlying correlation detection, re-identification and other malicious mining.	Reply	I-Reply	9
As for the ‚ÄúNoisy Data‚Äù method, we have added the citation on differential privacy in Section 3.1.	Reply	I-Reply	9
[line_break_token] [line_break_token]Response #8: We have re-plotted Figure 3 and Figure 4 to improve the readability.	Reply	O	0

[line_break_token][line_break_token][ Summary ][line_break_token][line_break_token]This paper presents a new modified beam search algorithm that promotes diverse beam candidates.	Review	O	0
It is a well known problem ‚Äîwith both RNNs and also non-neural language models‚Äî that beam search tends to generate beam candidates that are very similar with each other, which can cause two separate but related problems: (1) search error: beam search may not be able to discover a globally optimal solution as they can easily fall out of the beam early on, (2) simple, common, non-diverse output: the resulting output text tends to be generic and common.	Review	O	0
[line_break_token][line_break_token]This paper aims to address the second problem (2) by modifying the search objective function itself so that there is a distinct term that scores diversity among the beam candidates.	Review	O	0
In other words, the goal of the presented algorithm is not to reduce the search error of the original objective function.	Review	O	0
In contrast, stack decoding and future cost estimation, common practices in phrase-based SMT, aim to address the search error problem.	Review	O	0
[line_break_token][line_break_token][ Merits ][line_break_token][line_break_token]I think the Diverse Beam Search (DBS) algorithm proposed by the authors has some merits.	Review	O	0
It may be useful when we cannot rely on traditional beam search on the original objective function either because the trained model is not strong enough, or because of the search error, or because the objective itself does not align with the goal of the application.	Review	O	0
[line_break_token][line_break_token][ Weaknesses ][line_break_token][line_break_token]It is however not entirely clear how the proposed method compares against more traditional approaches like stack decoding and future cost estimation, on tasks like machine translation, as the authors compare their algorithm mainly against L&J‚Äôs diverse LM models and simple beam search.	Review	O	0
[line_break_token][line_break_token]In fact, modification to the objective function has been applied even in the neural MT context.	Review	B-Review	2
For example, see equation (14) in page 12 of the following paper:[line_break_token][line_break_token]"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation" (<a href="https://arxiv.org/pdf/1609.08144v2.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1609.08144v2.pdf)</a>[line_break_token][line_break_token]where the attention coverage term serves a role similar to stack decoding (though unlike stack decoding, the objective term is entirely re-defined, more similarly to DBS proposed in this work), and the length penalty may have an effect that indirectly promotes more informative (thus more likely diverse) responses.	Review	O	0
[line_break_token][line_break_token]Comparison against these existing algorithms would make the proposed work more complete.	Review	B-Review	2
[line_break_token][line_break_token]Also, I have a mixed feeling about computing and reporting only *oracle* BLUE, CIDEr, METEOR, etc.	Review	I-Review	3
Especially given how these oracle scores are very close to each other, and that developing a high performing ranking has not been addressed in this work (and that doing so must be not all that trivial), I‚Äôm somewhat skeptical how much of DBS results make a practical difference.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token][line_break_token][line_break_token]**** [Update after the author responses] ****[line_break_token][line_break_token]The authors addressed some of my concerns by adding a new baseline comparison against Wu et al.	Review	O	0
2016.	Review	O	0
Thus I will raise my score to 6.	Review	O	0
[line_break_token][line_break_token][line_break_token][line_break_token]	Review	O	0
Thank you for the feedback.	Reply	O	0
[line_break_token][line_break_token]Comparison to Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation: As noted by the reviewer, this paper uses two methods for diverse decodings ‚Äî (1) modified objective that includes a coverage penalty and (2) length normalization. (	Reply	B-Reply	2
eq.	Reply	I-Reply	2
14)‚Ä®[line_break_token][line_break_token]The coverage penalty term as proposed in that paper (using attention over the inputs to define ‚Äòcoverage‚Äô) is intricately tied to the task of NMT and unlike DBS does not generalize to other sequence decoding tasks (e.g. image captioning, visual question generation, dialog, etc).	Reply	I-Reply	2
Unlike NMT, some input information can be ignored in other tasks.	Reply	I-Reply	2
In contrast, the length-normalization term to select the top-B completed beams can be easily implemented for any decoding scenario.	Reply	I-Reply	2
[line_break_token][line_break_token]Thus, following your request, we have updated the paper to include comparison to this for both captioning and machine translation.	Reply	I-Reply	2
Following the experimental setup in the paper, for fairness to all techniques, we tune the strength \alpha through a grid search for the oracle accuracy on a held-out validation set (0.8 and 0.6 for captioning on PASCAL-50S and 0.6 for MT).	Reply	I-Reply	2
Table 1 and 2 in the updated pdf show results on captioning and MT respectively.	Reply	I-Reply	2
We find that DBS length normalization helps over BS in the order of 0.4 BLEU points, but performs 0.2 BLEU points worse than DBS on MT.	Reply	I-Reply	2
Thank you for this suggestion.&nbsp;‚Ä®[line_break_token][line_break_token]We also investigate the importance of the length term (in the Discussion section of the Appendix) by computing the correlation between the length and the accuracy obtained for each generated hypothesis.	Reply	O	0
On the PASCAL-50S dataset, we observe that the correlation with length and SPICE is insignificant for all decoding methods - BS, DBS and L&J16.	Reply	O	0
[line_break_token]Ôøº[line_break_token]Significance of DBS results:&nbsp;The oracle accuracy is a measure of the maximum accuracy that can be achieved by a list of M decoded solutions (assuming access to a perfect re-ranker).	Reply	O	0
As the goal of our paper is to develop an efficient diverse decoding technique, coming up with better re-ranking methods is an entirely different problem that is beyond the scope of this work.&nbsp;‚Ä®[line_break_token][line_break_token]We perform additional analysis between the beam budget and corresponding oracle accuracy of the generated lists (presented in the Discussion section in the supplementary).	Reply	O	0
We notice that DBS generates high-scoring sequences at smaller beam sizes as compared to the baselines -- meaning that it utilizes the beam budget better to explore the search space.	Reply	B-Reply	1
In this context, we believe that efficient diverse decoding techniques can help us use simpler re-rankers that need to perform fewer comparisons to select the top-1 solution.&nbsp;‚Ä®[line_break_token][line_break_token]Also, we would like to point out that the gains obtained from diverse decoding on NMT are consistent with L&J16 -- oracle@20 increases by a score of 0.6 due to DBS, compared to using BS. (	Reply	O	0
L&J16 obtain a score increase of 0.3 due to diverse decoding at B=200).	Reply	O	0
While it is possible that machine translation as a task does not require significant diversity in its outputs, DBS shows the potential of obtaining competitive gains provided access to a good re-ranker.&nbsp;‚Ä®[line_break_token][line_break_token]Finally, we note that oracle accuracies are a well-established performance metric, used by a line of previous work -- Batra et al.,	Reply	O	0
2012, Prasad et al.,	Reply	B-Reply	3
2014, Kirillov et al.,	Reply	I-Reply	3
2015 and Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles (Lee et al.,	Reply	I-Reply	3
2016).&nbsp	Reply	O	0

The authors present a heirarchical graph-to-graph translation method for generating novel organic molecules.	Review	O	0
[line_break_token]Working from the model of Jin et al. (	Review	O	0
2019), the authors introduce a three step heirarchy - the model first determines where a substructure should be generated, what is the substructure, then the attachments to the existing molecule.	Review	O	0
[line_break_token]All steps of this uses embeddings generated from a message passing network - these embeddings are input into a few bilinear attention layers to obtain the heirarchical generation scheme.	Review	O	0
[line_break_token]The model is trained with molecular pairs (X, Y), and a VAE loss - a hidden z vector controls the way to modify X to improve its properties.	Review	O	0
[line_break_token]The encoder is just a MLP over the difference between sum of embeddings at a atom level and at the substructure level.	Review	O	0
[line_break_token]The model is evaluated on accuracy and diversity, in both conditional and unconditional settings.	Review	O	0
[line_break_token]The experiments show a small improvement over previous SOTA algorithms.	Review	O	0
[line_break_token][line_break_token]This is a borderline paper, and I'm leaning towards a weak reject, because I don't believe the model is well motivated enough:[line_break_token]- Sec 3.1 it's unclear how the substructures are generated - they provide a lot of inductive bias for the algorithm.	Review	O	0
[line_break_token]  Are they automatically generated or built from a database of substructures?	Review	B-Review	1
[line_break_token]- Variational decoding does not seem well motivated enough - would a stochastic decoding procedure not work as well as having a latent vector that essentially adds noise to the training?	Review	O	0
[line_break_token]- The experiments seem interesting and comprehensive - it seems that the model learns to exploit the biases and increase logP, as well as showing the ability to conditionally turn off DRD2-active properties of the molecules.	Review	O	0
[line_break_token][line_break_token]Some questions:[line_break_token]- Why not use a Transformer instead of an LSTM or GRU?	Review	O	0
The cell naturally acts over sets of neighbors and transformers are a natural model to tackle this problem.	Review	B-Review	3
[line_break_token]- Sec 3.1 Topological Prediction, the attention is over c_{X}^{S} but the text claims it should be over c_{X}^{G}?	Review	O	0
Is ^G the attention substructure?	Review	B-Review	4
[line_break_token]- Sec 3.1 Attachment Layer MPN: the A_i seem to be a tuple (S_i, {v_j}).	Review	O	0
The set of attaching atoms is limited to 2 right?	Review	B-Review	5
It might be more clear to simply enumerate them here if so.	Review	I-Review	5
[line_break_token]- Sec 3.1 Substructure Tree: Since tree decompositions are not unique, does this work use the different tree decompositions and DFS traversals as data augmentations?	Review	O	0
[line_break_token]- Table 2b: What is a "two-layer" and "one layer" encoder?	Review	O	0
Is it the size of the MLP or the removal of the attachment MPNs?	Review	B-Review	7
[line_break_token]- Ablation study: Since the Attachment Layer has all the substructure information, this ablation should ideally make sure the models all have a similar number of parameters, and the decrease in performance isn't due to the decrease in parameters.	Review	O	0
[line_break_token][line_break_token]Nits:[line_break_token]- Sec 3.1 "bi-linear" should not have a dash, bilinear is one word.	Review	B-Review	9
[line_break_token]	Review	O	0
hank you for your insightful comments.	Reply	O	0
We want to first explain the motivation of our approach.	Reply	B-Reply	10
The proposed hierarchical architecture seeks to address two key limitations of the junction tree method [Jin et al.	Reply	I-Reply	10
2019], which is illustrated in Figure 1 in the paper (page 2):[line_break_token] - Their decoding is a strictly two-stage process (latent vectors -&gt; junction tree -&gt; graph).	Reply	O	0
In the first stage, substructures are chosen without regard to how they can be attached to each other in the second stage.	Reply	B-Reply	10
Therefore, it can result in invalid junction trees that cannot be realized into any molecule (see Figure 1a).	Reply	I-Reply	10
[line_break_token] - Their local graph decoder can lead to inconsistent substructure attachments (see Figure 1b).	Reply	O	0
[line_break_token][line_break_token]The first problem is addressed by our hierarchical decoding process, where the predicted attachments are fed into decoder message passing network to guide substructure prediction.	Reply	B-Reply	10
We solve the second problem by using an autoregressive decoder where previous attachment choices directly impact later substructure and attachment predictions.	Reply	I-Reply	10
[line_break_token][line_break_token]Some clarifications:[line_break_token] - The encoder is the hierarchical message passing network that outputs substructure and atom vectors (not MLP).	Reply	I-Reply	11
MLP is the variational inference module that learns the latent vector z, which is in addition to the message passing network.	Reply	I-Reply	11
[line_break_token] - The model achieves pretty large improvements on some tasks.	Reply	I-Reply	11
For example, on the DRD2 task our model shows large improvement over previous SOTA (77.8% -&gt; 85.9%).	Reply	O	0
[line_break_token][line_break_token]Q1: How are the substructures generated?	Reply	O	0
[line_break_token]Substructures are automatically extracted from the molecules in the training set, in order to ensure structural coverage.	Reply	B-Reply	1
For a given molecule, we extract its (smallest) rings and bonds as substructures and add them to the vocabulary.	Reply	I-Reply	1
This procedure is purely data-driven.	Reply	I-Reply	1
[line_break_token]Indeed, the substructure vocabulary provides a lot of inductive bias for the algorithm and optimizing the vocabulary for downstream task is an interesting future work.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: Variational decoding is not well motivated.	Reply	O	0
Why not using a stochastic decoding procedure?	Reply	O	0
[line_break_token]We used variational decoding for two reasons:[line_break_token] - All the prior work (Seq2Seq and JTNN) used variational decoding.	Reply	B-Reply	2
Therefore we adopted the same strategy to establish a direct comparison.	Reply	I-Reply	2
[line_break_token] - Recent work has shown that variational decoding can generate more diverse outputs than stochastic decoding (e.g., in image translation [Zhu et al.,	Reply	O	0
2017] and machine translation [Shen et al.,	Reply	B-Reply	2
2019]).	Reply	I-Reply	2
The reason is that stochastic decoding tends to learn small, local variations (e.g., replacing single atoms), while variational decoding captures diversity beyond local variations.	Reply	I-Reply	2
To show this, we trained our model without variational inference and used stochastic decoding at test time.	Reply	I-Reply	2
On the logP (sim 0.6) dataset, the performance drops from 2.49 to 2.06 and diversity drops from 0.381 to 0.342.	Reply	I-Reply	2
On the logP (sim 0.4) dataset, the performance drops from 3.98 to 3.72 and diversity drops from 0.564 to 0.502.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: Why not use a Transformer instead of an LSTM or GRU?	Reply	O	0
[line_break_token]We used LSTM / GRU because message passing networks (MPN) are standard choices for molecules and many previous works build upon MPNs (with various parameterizations).	Reply	B-Reply	3
We agree that transformer is a promising architecture for graphs (especially if further tailored to graphs) but the gains are unclear at this point.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4: Topological Prediction: the attention is over but the text claims it should be over?	Reply	O	0
[line_break_token]We apologize for the confusion.	Reply	B-Reply	4
This is a typo and it should be.	Reply	I-Reply	4
The typo is now fixed.	Reply	I-Reply	4
[line_break_token][line_break_token]Q5: Attachment Layer MPN: the A_i seem to be a tuple.	Reply	O	0
The set of attaching atoms is limited to 2 right?	Reply	O	0
[line_break_token]The set of attaching atoms can be more than 2 because two rings can have three or more overlapping atoms.	Reply	B-Reply	5
[line_break_token][line_break_token]Q6: Since tree decompositions are not unique, does this work use different tree decompositions and DFS traversals as data augmentations?	Reply	O	0
[line_break_token]We didn‚Äôt use different tree decompositions / DFS traversals for data augmentation because none of the baselines used any data augmentation strategies.	Reply	B-Reply	6
[line_break_token][line_break_token]Q7: Table 2b: What is a "two-layer" and "one-layer" encoder?	Reply	O	0
[line_break_token]Two-layer encoder means the top substructure layer MPN is removed.	Reply	B-Reply	7
One-layer encoder means the attachment layer MPN is also removed.	Reply	I-Reply	7
[line_break_token][line_break_token]Q8: Ablation studies, number of parameters.	Reply	O	0
[line_break_token]For ablation studies, all models have a similar number of parameters.	Reply	B-Reply	8
For both datasets, all the model parameters are between 6M to 6.2M. [line_break_token][line_break_token]References[line_break_token]Zhu et al. "	Reply	O	0
Toward multimodal image-to-image translation."	Reply	O	0
Advances in Neural Information Processing Systems.	Reply	O	0
2017.	Reply	O	0
[line_break_token]Shen et al. "	Reply	O	0
Mixture Models for Diverse Machine Translation: Tricks of the Trade."	Reply	O	0
International Conference on Machine Learning.	Reply	O	0
2019	Reply	B-Reply	2

[line_break_token]After the rebuttal:[line_break_token][line_break_token]The paper contains an interesting set of results (mainly produced after the initial submission), but novelty is limited, and presentation is suboptimal.	Review	O	0
[line_break_token][line_break_token]For me now the biggest problem now is that the title and the content do not correspond.	Review	B-Review	8
The authors clearly attack deterministic encoder-decoder models (as described in 3.2), which are not at all the same as generative models, even though many generative models make use of this architecture.	Review	I-Review	8
A small experiment with sampling is interesting, but does not change the overall focus of the paper.	Review	I-Review	8
This inconsistency in not acceptable.	Review	I-Review	8
The whole issue could be resolved for example by simply replacing "generative models" by "encoder-decoder networks" in the title.	Review	I-Review	8
Then I would tend towards recommending acceptance.	Review	I-Review	8
[line_break_token][line_break_token]------[line_break_token]Initial review:[line_break_token][line_break_token]The paper describes three approaches to generating adversarial examples for deep encoder-decoder generative networks (trained as VAE or VAE-GAN), and shows a comparative analysis of these.	Review	O	0
While the phenomenon of adversarial examples in discriminative models is widely known and relatively well studied, I am not aware of previous work on adversarial examples for generative networks, so this work is novel (there is a concurrent work by Tabacof et al.	Review	O	0
which should be cited, though).	Review	O	0
 The paper has significantly improved since the initial submission; still, I have a number of remarks on presentation and experimental evaluation.	Review	O	0
I am in the borderline mode, and may change my rating during the discussion phase.	Review	O	0
[line_break_token][line_break_token]Detailed comments:[line_break_token][line_break_token]1) The paper is 13 pages long - significantly over the recommended page limit of 8 pages.	Review	O	0
Reviewers have to read multiple papers, multiple versions of each, it is a lot of work.	Review	B-Review	1
Large portions of the paper should be shortened and/or moved to the appendix.	Review	I-Review	1
It is job of the authors to make the paper concise and readable. "	Review	I-Review	1
in our attempts to be thorough, we have had a hard time keeping the length down" is a bad excuse - it may be hard, but has to be done.	Review	I-Review	1
[line_break_token][line_break_token]2) I intentionally avoided term "generative model" above because it is not obvious to me if the attacks described by the authors indeed attack generative models.	Review	O	0
To clarify, the authors train encoder-decoders as generative models (VAE or VAE-GAN), but then remove all stochasticity (sampling) and prior on the latent variables: that is, they treat the models as deterministic encoders-decoders.	Review	B-Review	2
It is not a big surprise that a deterministic deep network can be easily tricked; it would be much more interesting to see if the probabilistic aspect of generative models makes them more robust to such attacks.	Review	I-Review	2
Am I missing something?	Review	I-Review	2
I would like the authors to clarify their view on this and adjust the claims in the paper if necessary.	Review	I-Review	2
[line_break_token][line_break_token]3) The paper is motivated by possible attacks on a data channel which uses a generative network for compressing information.	Review	O	0
Description of the attack scenario in 3.1 does not look convincing to me.	Review	B-Review	3
It takes a huge amount of space and I do not think it adds much to the paper.	Review	I-Review	3
First, experiments on natural images are necessary to judge if the proposed attack could succeed in a realistic scenario and second, I am not aware of any existing practical applications of VAEs to image compression: attacking JPEG would be much more practical.	Review	I-Review	3
[line_break_token][line_break_token]4) Experiments are limited to MNIST and, in the latest version, SVHN (which is very nice).	Review	O	0
While no good generative models of general natural images exist, it is common to evaluate generative models on datasets of faces, so this would be another very natural domain for testing the proposed approach.	Review	B-Review	4
[line_break_token][line_break_token]Smaller remarks:[line_break_token]1) Usage of "Oracle" in 3.2 does not look appropriate - oracle typically has access to (part of) ground truth, which is not the case here as far as I understand.	Review	O	0
[line_break_token]2) Beginning of section 4: "All three methods work for any generative architecture that relies on a learned latent representation z" - "are technically applicable to" would be more correct than "work for".	Review	O	0
[line_break_token]3) 4.1: "confidentally"[line_break_token]	Review	O	0
Thanks for the review!	Reply	O	0
 The new draft is shorter, reducing it to 11 pages while also adding some new results.	Reply	O	0
[line_break_token][line_break_token]In this draft we have added experimental results using stochastic sampling.	Reply	B-Reply	2
They are referenced in the second paragraph of Section 5 with a figure in the appendix.	Reply	I-Reply	2
The results show that for most examples, sampling doesn‚Äôt meaningfully change the reconstructed adversarial examples, and the attack is similarly successful even when sampling is being used.	Reply	I-Reply	2
[line_break_token][line_break_token]We have also added some citations to clarify where the attack scenario sits in the current literature.	Reply	I-Reply	3
 There are a few recent publications exploring using deep networks as compression models, similar to what we describe in Section 3.1, for example: <a href="https://arxiv.org/abs/1511.06085," target="_blank" rel="nofollow">https://arxiv.org/abs/1511.06085,</a> and <a href="https://arxiv.org/abs/1608.05148."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1608.05148.</a>  We are not attempting to directly attack these networks in this work, however -- we are instead motivating why this type of attack is relevant to current work.	Reply	O	0
[line_break_token][line_break_token]Thanks for the suggestion to use faces!	Reply	B-Reply	4
 We have added experiments on CelebA in the latest draft.	Reply	I-Reply	4
 The results in Section 5.3 show that the attacks are equally effective even in the more complex domain.	Reply	I-Reply	4
 We have also addressed your other comments in this draft.	Reply	I-Reply	4
[line_break_token]	Reply	O	0

UPDATE: [line_break_token]I acknowledge that I‚Äòve read the author responses as well as the other reviews.	Review	O	0
[line_break_token]I appreciate the clarifications and improvements made to the paper.	Review	O	0
I‚Äòve updated my score to 6 Weak Accept.	Review	O	0
[line_break_token][line_break_token]####################[line_break_token][line_break_token]This paper presents the idea to use blurred images as regularizing examples to improve out-of-distribution (OOD) detection performance based on Random Network Distillation (RND).	Review	O	0
The paper proposes to generate sets of such blurred images via Singular Value Decomposition (SVD) on the training images by pruning the lowest K non-zero singular values.	Review	O	0
The proposed method, SVD-RND, then extends the standard RND objective, which is to train a predictor network f to minimize the L2 loss to the output of some randomly initialized network over the (original) training data, with an additional regularization term that minimizes the L2 loss to the outputs of further multiple randomly initialized networks over the sets of blurred images.	Review	O	0
In OOD experiments on CIFAR-10, SVHN, TinyImageNet, LSUN, and CelebA, the proposed SVD-RND consistently outperforms baselines and recent competitors which are demonstrated to be vulnerable to blurred images.	Review	O	0
[line_break_token][line_break_token]I find it hard to make a definitive evaluation for this work at this point and would like to take the authors' responses into account for my final recommendation.	Review	O	0
The main idea of the paper to generate adversarial examples for training via blurring is rather simple and thus the novelty of this work is somewhat minor.	Review	O	0
I think the quality of the paper also suffers from many statements in the text that draw too general and too bold conclusions at this point in my mind.	Review	B-Review	8
The presentation overall is rather unpolished (see comments below).	Review	I-Review	8
However, I find the empirical results itself quite strong and convincing and think they would make a relevant and significant contribution to the community.	Review	O	0
I do have questions left open though that need clarification:[line_break_token][line_break_token](i) I don‚Äôt see why different techniques for blurring (SVD, DCT, GB) should lead to such different results as the approach remains conceptually similar.	Review	O	0
Do you have a reason/intuition why SVD gives the best results?	Review	B-Review	1
Might SVD just be the easiest to tune method?	Review	I-Review	1
[line_break_token][line_break_token](ii) What do you think is the key reason that SVD-RND also appears to generalize too non-blurry OOD samples?	Review	O	0
Could you elaborate more on the two reasons you give in the paper? (	Review	B-Review	2
1.	Review	I-Review	2
RND performance on samples orthogonal to the data; 2.	Review	I-Review	2
Discrimination between data and its low-rank projection)[line_break_token][line_break_token](iii) The generation and tuning of multiple sets of blurred images (how many samples per set?)	Review	O	0
may get quite extensive for large datasets.	Review	B-Review	3
Could you be specific on the computational cost?	Review	I-Review	3
[line_break_token][line_break_token](iv) Might the deep generative models (e.g. GPND) fail to detect blurred images due to insufficient model capacity of the decoder which results in blurry reconstructions?	Review	O	0
Have you varied the network capacity or latent space dimensionality of such models?	Review	B-Review	4
[line_break_token][line_break_token](v) What is the idea behind choosing the log effective rank in such an equidistant manner as proposed?	Review	O	0
[line_break_token][line_break_token][line_break_token]####################[line_break_token]*Additional Feedback*[line_break_token][line_break_token]*Positive Highlights*[line_break_token]1.	Review	O	0
SVD-RND shows strong OOD detection performance in OOD experiments on a variety of image dataset combinations (CIFAR-10, SVHN, TinyImageNet, LSUN, and CelebA).	Review	O	0
[line_break_token]2.	Review	B-Review	2
The related work includes major works from all the related lines of research (Deep anomaly detection; OOD detection using side information; Adversarial examples/training)[line_break_token]3.	Review	O	0
Useful hyperparameter selection criterion based on effective rank if no OOD validation data is available.	Review	O	0
[line_break_token][line_break_token]*Ideas for Improvement* [line_break_token]4.	Review	O	0
I think the tone of the paper would greatly benefit from not drawing too general conclusions and too bold implications.	Review	B-Review	6
Keep statements precise and evidence-based.	Review	I-Review	6
Declare hypotheses as such.	Review	I-Review	6
[line_break_token]5.	Review	I-Review	15
I would appreciate a plot showing samples before and after blurring in the appendix to see the most effective degree of blurring.	Review	I-Review	7
Maybe also compare the different blurring baselines here to see differences.	Review	I-Review	7
[line_break_token]6.	Review	I-Review	15
Report std.	Review	I-Review	9
devs.	Review	I-Review	9
with your performance results to infer statistical significance.	Review	I-Review	9
[line_break_token]7.	Review	I-Review	15
Compare to the specific geometric transforms method as proposed in the paper [3] and not only using those transformations within your RND approach.	Review	I-Review	10
[line_break_token]8.	Review	I-Review	15
Add missing deep anomaly detection related work [6, 2, 5, 1].[line_break_token]9.	Review	O	0
Expand the sensitivity analysis in Figure 3 (left) over a greater range of K. Especially, I would like to also see K = 0 (unblurred, original images) as a sanity check which may only improve over RND due to ensembling over multiple randomly initialized networks.	Review	B-Review	12
[line_break_token]10.	Review	I-Review	15
Consider the one-vs-rest anomaly detection evaluation benchmarks from Ruff et al. [	Review	I-Review	13
4] or Golan and El-Yaniv [3] to further infer the generalization performance of the proposed method.	Review	I-Review	13
[line_break_token]11.	Review	O	0
I think the paper spends too much time on introducing previous work.	Review	B-Review	14
Section 2 Related Work and Section 3 Background might be combined into one section.	Review	I-Review	14
[line_break_token][line_break_token]*Minor comments*[line_break_token]12.	Review	O	0
In the abstract: ‚Äú... VAE or RND are known to assign lower uncertainty to the OOD data than the target distribution.	Review	B-Review	15
‚Äù is a bit strong.	Review	I-Review	15
Rather ‚Äúhave been observed‚Äù etc.	Review	I-Review	15
This is a working hypothesis in the community, but there is recent work (<a href="https://openreview.net/forum?id=Skg7VAEKDS)" target="_blank" rel="nofollow">https://openreview.net/forum?id=Skg7VAEKDS)</a> indicating (at least for VAEs) those are effects of poor model design.	Review	O	0
[line_break_token]13.	Review	B-Review	15
In the abstract: ‚Äú... efficient in test time ...‚Äù ¬ª ‚Äú... efficient at test time ...‚Äù[line_break_token]14.	Review	I-Review	15
In the abstract: ‚Äú... in CelebA domain.	Review	I-Review	15
‚Äù ¬ª ‚Äú... on the CelebA dataset.	Review	I-Review	15
‚Äù or just ‚Äú... on CelebA.‚Äù[line_break_token]15.	Review	I-Review	15
Section 1: ‚ÄúHowever, such models show underwhelming performance on detecting OOD, such as detecting SVHN from CIFAR-10.	Review	I-Review	15
Specifically, generative models assign a higher likelihood to the OOD data than the training data.	Review	I-Review	15
‚Äù.	Review	I-Review	15
I think those are way too general conclusions at the moment.	Review	I-Review	15
Rather something like ‚ÄúOOD detection performance of deep generative models has been called into question‚Äù and ‚Äúhave been observed to assign ...‚Äù.	Review	I-Review	15
[line_break_token]16.	Review	I-Review	15
Section 1: ‚ÄúSuch results clearly support the degeneracy of deep OOD detection schemes‚Äù.	Review	I-Review	15
Again, I find this way too bold of a statement at this point in time.	Review	I-Review	15
[line_break_token]17.	Review	I-Review	15
Section 2: ‚Äú... a recently proposed paper ...‚Äù ¬ª ‚Äú... a recent paper ...‚Äù[line_break_token]18.	Review	I-Review	15
Section 2: ‚Äú... outlier data independent of OOD data.	Review	I-Review	15
‚Äù.	Review	I-Review	15
What would outlier data not being out-of- distribution be?	Review	I-Review	15
[line_break_token]19.	Review	I-Review	15
Section 2: ‚ÄúGolan et al. (	Review	I-Review	15
2018) design geometrically transformed data and regularized the classifier ...‚Äù.	Review	I-Review	15
Not regularized.	Review	I-Review	15
They trained a classifier on labels identified with these transformations.	Review	I-Review	15
[line_break_token]20.	Review	I-Review	15
Section 2: ‚Äú..., resulting in OOD detection in each labeled data‚Äù ¬ª ‚Äú..., resulting in OOD detection on labeled data‚Äù[line_break_token]21.	Review	I-Review	15
A subsection title directly following a section title is bad style.	Review	I-Review	15
A major section should be introduced with a few sentences on what this section is about.	Review	I-Review	15
[line_break_token]22.	Review	I-Review	15
Figure 2, right plot: These loss curves are rather strange... Increasing, then sharply decreasing again.	Review	I-Review	15
Is there a drop in learning rate at epoch 80?	Review	I-Review	15
[line_break_token]23.	Review	I-Review	15
Many axis labels are too small and hard to read.	Review	I-Review	15
[line_break_token]24.	Review	I-Review	15
In Section 3.3.: ‚	Review	I-Review	15
Äú.. in Section 7.2.‚Äù ¬ª ‚Äú.. in Section 4.2.‚Äù?	Review	I-Review	15
[line_break_token]25.	Review	I-Review	15
The definition of the log effective rank in Eq.~2 is weird.	Review	I-Review	15
It's the entropy over the singular value distribution, i.e.. Also, the parameters/notation involved are not introduced.	Review	I-Review	15
[line_break_token]26.	Review	I-Review	15
Make clear you apply SVD on single images.	Review	I-Review	15
The paper alters formulations between data matrix and images...[line_break_token]27.	Review	I-Review	15
Several instances where citet is used instead of citep.	Review	I-Review	15
[line_break_token]28.	Review	I-Review	15
In Table 1: Separate the target column from the three OOD columns more clearly. (	Review	I-Review	15
e.g. vertical separator, center OOD, target in bold, etc.)	Review	I-Review	15
[line_break_token]29.	Review	I-Review	15
In Section 5.1: ‚Äúarea of the region under the ... curve‚Äù ¬ª ‚Äúarea under the ... curve‚Äù.	Review	I-Review	15
[line_break_token]30.	Review	I-Review	15
Figure 3: Better explain the plots.	Review	I-Review	15
Are the three curves the respective target classes?	Review	I-Review	15
What is the OOD set?	Review	I-Review	15
[line_break_token]31.	Review	I-Review	15
Figure 4: Maybe use subfigures with individual titles/captions.	Review	I-Review	15
[line_break_token]32.	Review	I-Review	15
Section 6: ‚ÄúFor evidence, we fine-tune the classifier ...‚Äù ¬ª ‚ÄúFor evidence, we fine-tune a classifier ...‚Äù[line_break_token]33.	Review	I-Review	15
Plots and Figures are somewhat scattered and not referenced chronologically.	Review	I-Review	15
[line_break_token]34.	Review	I-Review	15
Introduce the effective rank at the point where it is used (Section 6.2).	Review	I-Review	15
Somewhat unclear why to introduce this in Section 3 already.	Review	I-Review	15
[line_break_token]35.	Review	I-Review	15
Visually speaking, I find the RND examples in Figure 4 actually more anomalous than the top-anomalous SVD-RND samples (flashy colors, weird angles, borders, high contrast, ...)[line_break_token][line_break_token][line_break_token]####################[line_break_token]*References*[line_break_token][1] R. Chalapathy and S. Chawla.	Review	O	0
Deep learning for anomaly detection: A survey.	Review	O	0
arXiv preprint arXiv:1901.03407, 2019.	Review	O	0
[line_break_token][2] H. Choi, E. Jang, and A. A. Alemi.	Review	O	0
Waic, but why?	Review	O	0
generative ensembles for robust anomaly detection.	Review	O	0
arXiv preprint arXiv:1810.01392, 2018.	Review	O	0
[line_break_token][3] I. Golan and R. El-Yaniv.	Review	O	0
Deep anomaly detection using geometric transformations.	Review	O	0
In NIPS, 2018.	Review	O	0
[line_break_token][4] L. Ruff, R. A. Vandermeulen, N. G√∂rnitz, L. Deecke, S. A. Siddiqui, A. Binder, E. M√ºller, and M. Kloft.	Review	O	0
Deep one-class classification.	Review	O	0
In International Conference on Machine Learning, pages 4393‚Äì4402, 2018.	Review	O	0
[line_break_token][5] L. Ruff, R. A. Vandermeulen, N. G√∂rnitz, A. Binder, E. M√ºller, K.-R. M√ºller, and M. Kloft.	Review	O	0
Deep semi-supervised anomaly detection.	Review	O	0
arXiv preprint arXiv:1906.02694, 2019.	Review	O	0
[line_break_token][6] T. Schlegl, P. Seeb√∂ck, S. M. Waldstein, U. Schmidt-Erfurth, and G. Langs.	Review	O	0
Unsupervised anomaly detection with generative adversarial networks to guide marker discovery.	Review	O	0
In Proceedings International Conference on Information Processing in Medical Imaging, pages 146‚Äì157.	Review	O	0
Springer, 2017.	Review	O	0
[line_break_token]	Review	O	0
e thank the reviewer for extensive and worthy feedback.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	B-Reply	3
I don‚Äôt see why different techniques for blurring (SVD, DCT, GB) should lead to such different results as the approach remains conceptually similar.	Reply	O	0
Do you have a reason/intuition why SVD gives the best results?	Reply	O	0
Might SVD just be the easiest to tune method?	Reply	O	0
[line_break_token][line_break_token]-&gt; We first note that the performance of Table 2.	Reply	O	0
was conducted on the small size of the hyperparameter search, which cannot cover the whole parameter space of DCT-RND and GB-RND.	Reply	B-Reply	1
Potentially, when we increase b_train or hyperparameter search space, GB-RND or DCT-RND can outperform SVD-RND.	Reply	I-Reply	1
For example, GB-RND shows similar results to SVD-RND on LSUN : SVHN, or TinyImageNet : SVHN domain.	Reply	I-Reply	1
 Therefore, although the result in Table 2 favors SVD-RND, we hesitate to assert that there is something special about SVD-RND.	Reply	I-Reply	1
[line_break_token]Rather, we just think SVD-RND is much easier to optimize than DCT-RND or GB-RND, and this contributed to the success of SVD-RND in Table 2.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	1
What do you think is the key reason that SVD-RND also appears to generalize too non-blurry OOD samples?	Reply	O	0
Could you elaborate more on the two reasons you give in the paper? (	Reply	O	0
1.	Reply	B-Reply	3
RND performance on samples orthogonal to the data; 2.	Reply	O	0
Discrimination between data and its low-rank projection)[line_break_token][line_break_token]-&gt; Reviewer 1 also mentioned this aspect and we conducted an ablation study on reasoning #2.	Reply	O	0
We conducted the ablation by setting two cases: adversarial images that have the same rank to the blurred images, and adversarial images that have the same effective rank to the blurred images.	Reply	B-Reply	2
The result of those ablations was much worse than SVD-RND.	Reply	I-Reply	2
Therefore, we hypothesize that blurred images function as "projection" helps SVD-RND to achieve better OOD detection.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
The generation and tuning of multiple sets of blurred images (how many samples per set?)	Reply	O	0
may get quite extensive for large datasets.	Reply	O	0
Could you be specific on the computational cost?	Reply	O	0
[line_break_token][line_break_token]-&gt; We generate each blurred image as equal to the size of the training data, which is 50000 on the experiment.	Reply	O	0
To be fair, we scaled the training epochs proportional to.	Reply	B-Reply	3
[line_break_token][line_break_token]In the training phase, we observed that generating blurred images compared to geometric transforms does not contribute much to the computation cost.	Reply	I-Reply	3
Rather, based on our setting, we employ an additional target network per blurred image and found that evaluation of the target network is the major factor in the computation cost when increases.	Reply	I-Reply	3
[line_break_token][line_break_token]Specifically, when, 0.255 seconds are taken per batch.	Reply	I-Reply	3
When, 0.294 seconds are taken per batch.	Reply	I-Reply	3
When, 0.333 seconds are taken per batch on average.	Reply	I-Reply	3
Therefore, we can extrapolate that the load of 0.039 seconds is appended for computation cost when b_train increases by 1.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
Might the deep generative models (e.g. GPND) fail to detect blurred images due to insufficient model capacity of the decoder which results in blurry reconstructions?	Reply	O	0
Have you varied the network capacity or latent space dimensionality of such models?	Reply	O	0
[line_break_token][line_break_token]-&gt; We have tried some ablation studies on GPND in CIFAR-10 : (SVHN, LSUN, TinyImageNet ) domain.	Reply	O	0
[line_break_token][line_break_token]1) First, we doubled the size of the latent dimension, and this gave worse results.	Reply	B-Reply	4
[line_break_token]2) We changed the structure of encoder to ResNet34 and this gave TNR(at 95% TPR) of 0.052/0.807/0.692.	Reply	I-Reply	4
[line_break_token]3) We changed the capacity of the network by doubling the output size of each layer of the encoder, decoder, and discriminator.	Reply	I-Reply	4
This gave TNR of 0.053/0.820/0.725.	Reply	I-Reply	4
[line_break_token][line_break_token]In conclusion, through our ablation analysis, performance on SVHN : (LSUN, TinyImageNet) improved by varying the network capacity of GPND.	Reply	I-Reply	4
However, we failed to improve OOD detection performance in CIFAR-10 : SVHN domain.	Reply	I-Reply	4
[line_break_token][line_break_token]5.	Reply	I-Reply	4
What is the idea behind choosing the log effective rank in such an equidistant manner as proposed?	Reply	O	0
[line_break_token][line_break_token]-&gt; By setting target log effective rank equidistantly, we wanted to minimize the worst-case log effective rank difference between the potential OOD and the blurred data chosen by our heuristic.	Reply	O	0
 [line_break_token][line_break_token]6.	Reply	O	0
I think the tone of the paper would greatly benefit from not drawing too general conclusions and too bold implications.	Reply	O	0
Keep statements precise and evidence-based.	Reply	O	0
Declare hypotheses as such.	Reply	O	0
[line_break_token][line_break_token]-&gt; Thanks for the feedback.	Reply	O	0
We have modified strong assertions in the revised version.	Reply	B-Reply	6
[line_break_token][line_break_token]7.	Reply	O	0
I would appreciate a plot showing samples before and after blurring in the appendix to see the most effective degree of blurring.	Reply	O	0
Maybe also compare the different blurring baselines here to see differences.	Reply	O	0
[line_break_token][line_break_token]-&gt; We also appended the CIFAR-10 sample before and after blurring in Appendix E. We plotted with the best performing parameters of SVD-RND, DCT-RND, and GB-RND.	Reply	O	0

Summary:[line_break_token]This paper proposed an extension of the dynamic coattention network (DCN) with deeper residual layers and self-attention.	Review	O	0
It also introduced a mixed objective with self-critical policy learning to encourage predictions with high word overlap with the gold answer span.	Review	O	0
The resulting DCN+ model achieved significant improvement over DCN.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]The model and the mixed objective is well-motivated and clearly explained.	Review	O	0
[line_break_token]Near state-of-the-art performance on SQuAD dataset (according to the SQuAD leaderboard).	Review	O	0
[line_break_token][line_break_token]Other questions and comments:[line_break_token]The ablation shows 0.7 improvement on EM with mixed objective.	Review	O	0
It is interesting that the mixed objective (which targets F1) also brings improvement on EM.	Review	B-Review	1
[line_break_token]	Review	O	0
Thanks for your comments.	Reply	O	0
In practice the F1 and EM metrics are closely correlated.	Reply	B-Reply	1
We chose to use the F1 score as a metric because it offers fine grain signals as to how well the span predicted matches the ground truth span, whereas the EM score only rewards exact gloss matches	Reply	I-Reply	1

* Summarize what the paper claims to do/contribute.	Review	O	0
[line_break_token]This paper claims to extend existing image translation works, like CycleGAN, to domain pairs that are not similar in shape.	Review	O	0
It is proposed to do so by using a VGG network trained on classification (I assume on Imagenet), extracting features from the two domains and learn 5 CycleGANs to translate for each level of the feature hierarchy.	Review	O	0
At each level of the hierarchy the translation from the previous level is used to condition the translation for the current level.	Review	O	0
During inference, the final image translation is done by "feature inversion" (a technique proposed in Dosovitsikiy and Brox, 2016) from the final feature layer.	Review	O	0
The technique is show on example from a number of pairs of domains like Zebra-to-Elephant (and back), Giraffe-to-Zebra (and back), Dog-to-Cat (and back) and is compared with a number of baselines qualitatively and quantitatively with the FID score.	Review	O	0
 [line_break_token][line_break_token]* Clearly state your decision (accept or reject) with one or two key reasons for this choice.	Review	O	0
[line_break_token]Weak Reject.	Review	O	0
[line_break_token][line_break_token]Major reasons:[line_break_token]- The problem itself, as stated in the introduction, seems ill-posed to me.	Review	O	0
One of the struggles I had while looking through the results was to understand what the images should be looking like.	Review	B-Review	1
ie What should a zebra translated to a giraffe look like?	Review	I-Review	1
The motivation for such a problem is also not immediately clear either.	Review	I-Review	1
[line_break_token]- Most of the resulting images do not seem "translated" to me.	Review	O	0
As stated in the paper (end of p.2) "one aims to transform a specific type of object without changing the background."	Review	B-Review	2
As one can see in eg Fig.	Review	I-Review	2
1 the resulting translations are completely different images with the foreground object of the new domain in roughly similar poses.	Review	I-Review	2
The background in most cases does not persist.	Review	I-Review	2
What I suspect is actually happening here is that the high-level semantics from the first image are used as some sort of noise to generate new images from the new domain.	Review	I-Review	2
One question I had, for example: could we be getting similar results if we used the VGG bottleneck as the noise vector in an InfoGAN?	Review	I-Review	2
Since the VGG network is pretrained and used in the same way in both domains, I imagine we would be seeing something very similar. (	Review	I-Review	2
and it would be def.	Review	I-Review	2
preferrable to tuning 10 GANs!)	Review	I-Review	2
[line_break_token][line_break_token]* Provide supporting arguments for the reasons for the decision.	Review	O	0
[line_break_token]Some of the decisions made in the paper were unclear and not supported adequately.	Review	B-Review	3
The questions (in rough order of importance) that made some of the contributions unclear to me:[line_break_token]- Why wasn't a final translator used for the final image, conditioned on the final \tilde{b}_1?	Review	I-Review	3
[line_break_token]- Is the VGG network pretrained on ImageNet?	Review	O	0
Why wasn't another task used that could be retaining more of the relevant features?	Review	B-Review	4
eg on semantic segmentation[line_break_token]- Could this be used for networks pretrained on other datasets?	Review	O	0
Presumably ImageNet has information about the animals translated in this paper.	Review	B-Review	5
Even better, could we somehow learn these features for the domain pairs automatically somehow?	Review	I-Review	5
[line_break_token]- How meaningful is the FID score really in this case?	Review	O	0
[line_break_token]- How were the 10 GANs tuned?	Review	O	0
[line_break_token][line_break_token]* Provide additional feedback with the aim to improve the paper.	Review	O	0
Make it clear that these points are here to help, and not necessarily part of your decision assessment.	Review	O	0
[line_break_token]- It is mentioned on p.4 that "clamping is potentially a harmful irreversible operation" but that harmful results were not observed.	Review	O	0
As I was reading that I was wondering how these results would actually look like.	Review	B-Review	8
[line_break_token]- On p. 6 it is mentioned that the number of images for 2 categories are reported in another paper.	Review	O	0
I think it'd take less space to actually report the number of images here.	Review	B-Review	9
[line_break_token]- On p.7 it is mentioned that the number of instances is preserved, however it should be made clear that it's is perserved in some (or most if that is what was observed) of the examples.	Review	O	0
[line_break_token]	Review	O	0
hank you for taking the time to review our paper and for your thoughtful suggestions and questions.	Reply	O	0
[line_break_token][line_break_token]--- The problem itself is ill-posed.	Reply	O	0
 [line_break_token]Generally UNIT (unpaired image translation) is an ill-posed task: what should a real image look like when translated to a Monet painting?	Reply	O	0
One can imagine the outcome, yet there‚Äôs no precise definition.	Reply	B-Reply	1
We would argue that the degree of ill-posedness depends on the domain.	Reply	I-Reply	1
In the case of animal to animal translation, you would expect the result to contain a realistic looking animal with the same:[line_break_token]    1.	Reply	I-Reply	1
Semantic parts of an animal (i.e. head of a zebra to head of a giraffe).	Reply	I-Reply	1
That also includes translating the correct amount of instances (i.e. 2 zebras to 2 giraffes).	Reply	I-Reply	1
[line_break_token]    2.	Reply	I-Reply	1
 Location and scale of the objects (i.e. a small zebra at the left corner of the image should translate to small giraffe at the same location).	Reply	I-Reply	1
[line_break_token]    3.	Reply	I-Reply	1
Pose [line_break_token]    4.	Reply	I-Reply	1
Background[line_break_token]While we mostly succeed at 1-3, preserving the background is indeed problematic when translating deep features.	Reply	I-Reply	1
However, this is common in UNIT.	Reply	I-Reply	1
While shape non-deforming methods, such as cycleGAN, might not change the structures in the background, the color/style is typically changed.	Reply	I-Reply	1
Shape deforming methods exhibit changes in both style and geometry of the background, see for example the recently proposed TransGaGa.	Reply	I-Reply	1
[line_break_token]While we made some preliminary attempts to incorporate an attention mechanism, the results were unsatisfactory, and we therefore stopped pursuing this direction, as we felt it to be outside the main focus of this work.	Reply	I-Reply	1
[line_break_token][line_break_token]--- One question I had, for example: could we be getting similar results if we used the VGG bottleneck as the noise vector in an InfoGAN?	Reply	O	0
[line_break_token]Using a different architecture instead of cycleGAN for unpaired deep feature translation is indeed interesting.	Reply	B-Reply	2
Could the reviewer please elaborate exactly how did he envision here the use of infoGAN?	Reply	I-Reply	2
Is the noise composed of a domain-part (i.e., zero or one with p=0.5 for each) and the VGG bottleneck features instead of the "traditional" noise?	Reply	I-Reply	2
[line_break_token]Regardless, directly inverting the bottleneck is difficult.	Reply	I-Reply	2
We refer the reviewer to the results of the inversion network proposed by Dosovitskiy and Brox on AlexNet for different layers ("Generating Images with Perceptual Similarity Metrics based on Deep Networks").	Reply	I-Reply	2
In addition, as we show in our ablation study, the cascaded manner of our translation further improves the result achieved by the deepest layer translation only.	Reply	I-Reply	2
[line_break_token][line_break_token]---Why wasn't a final translator used for the final image, conditioned on the final \tilde{b}_1?	Reply	O	0
[line_break_token]We noticed that shallow layers contribution was negligible.	Reply	B-Reply	3
Thus, we omitted the use of \tilde{b}_1.	Reply	I-Reply	3
[line_break_token][line_break_token]--- Is the VGG network pretrained on ImageNet?	Reply	O	0
Why wasn't another task used that could be retaining more of the relevant features?	Reply	O	0
eg on semantic segmentation[line_break_token]Yes, the VGG was pre-trained on ImageNet, we will clarify it in our revision.	Reply	O	0
[line_break_token]VGG pretrained on ImageNet is widely used for feature extraction, from perceptual similarity to cross domain correspondence.	Reply	B-Reply	4
It is remarkable that a network pretrained only with image-level annotations can assist in the translation process.	Reply	I-Reply	4
[line_break_token]Semantic segmentation networks require more elaborate supervision (pixel-level annotation) and allow a different kind of translation approaches, which can directly use the segmentation maps.	Reply	I-Reply	4
[line_break_token][line_break_token] --- Could this be used for networks pretrained on other datasets?	Reply	O	0
Presumably ImageNet has information about the animals translated in this paper.	Reply	O	0
Even better, could we somehow learn these features for the domain pairs automatically somehow?	Reply	O	0
[line_break_token][line_break_token]Yes, different networks can be used, as the approach is generic, although, a good feature extraction network, such as VGG pretrained on ImageNet, is required for a meaningful translation.	Reply	B-Reply	5
Please note that while ImageNet does contain several of the animals translated in this paper, it does *not* contain giraffe and the different types of dogs and cats presented.	Reply	I-Reply	5
We believe that learning the features in a self-supervised manner, will not yield the same quality as VGG features and fine-tuning VGG on the specific domains did not yield better results.	Reply	I-Reply	5
[line_break_token][line_break_token]--- How meaningful is the FID score really in this case?	Reply	O	0
[line_break_token]FID metric is still commonly used to assess how close fake and real samples are.	Reply	B-Reply	6
[line_break_token]FID uses layer of inception trained on ImageNet, thus, it is closely related to our deep features translation.	Reply	I-Reply	6
In a sense, we minimize it directly.	Reply	I-Reply	6
 [line_break_token][line_break_token] --- How were the 10 GANs tuned[line_break_token]The GANs were tuned manually, experimenting with several architecture (similar to all layers), and losses.	Reply	O	0
Same parameters where used for all translation tasks.	Reply	B-Reply	7
We found this process to be relatively simple.	Reply	I-Reply	7
[line_break_token][line_break_token]--- On p.7 it is mentioned that the number of instances is preserved, however, it should be made clear that it's preserved in some (or most if that is what was observed) of the examples.	Reply	O	0
[line_break_token]In most cases the number of instances was preserved, we will clarify it in our revision, thanks	Reply	B-Reply	10

**Summary**[line_break_token][line_break_token]In this paper, the authors extend an existing feature interpretation method for LSTMs to more generic DNNs.	Review	O	0
They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction.	Review	O	0
[line_break_token][line_break_token]**Strength**[line_break_token][line_break_token]1.	Review	O	0
Splitting information into binary groups at each layer is a neat approach to segregate interpretations.	Review	O	0
[line_break_token]2.	Review	O	0
Experiments are elaborate and cover the breadth of the proposed method well.	Review	O	0
[line_break_token]3.	Review	O	0
The paper is well presented and fairly easy to follow.	Review	O	0
[line_break_token][line_break_token][line_break_token]**Weakness**[line_break_token][line_break_token]1.	Review	O	0
Limited contributions in terms of novelty.	Review	B-Review	1
This approach for RNNs is presented fairly well in the previous paper [Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs](<a href="https://arxiv.org/abs/1801.05453)."	Review	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1801.05453).</a>[line_break_token]2.	Review	O	0
It seems that there is not enough justification for the modifications in beta and gamma made for convolution and pooling layers.	Review	B-Review	2
[line_break_token]	Review	O	0
Thanks for your response.	Reply	O	0
We see that you have responded to our comments by adding the sentence "They introduce a hierarchical clustering of the input features and the contributions of each cluster to the final prediction."	Reply	O	0
onto the summary of our paper, and leaving the strengths, weaknesses and rating unchanged.	Reply	O	0
[line_break_token][line_break_token]In light of your updated summary, we feel your main concern should also be revisited.	Reply	B-Reply	1
Your stated concern is that "This approach for RNNs is presented fairly well in the previous [CD] paper".	Reply	I-Reply	1
Our main contribution, hierarchical interpretations, was not presented in the CD paper, or in any other paper, and is independent of CD (it can be applied to any phrase/patch importance score).	Reply	I-Reply	1
The bulk of recent work in this area has focused on (non-hierarchical) heat maps (we cite 13 recent papers in our related work that do this).	Reply	I-Reply	1
Our experiments show that applying our hierarchical interpretation algorithm to CD, yields higher user trust, and more insight into a model's predictive accuracy, than CD alone, or any of our other baselines.	Reply	I-Reply	1
[line_break_token][line_break_token]To be clear, our point is that moving from heat-maps, such as Table 1 in [1] (the CD paper),  Figure 5 in [2], or Figure 4 in [3] (our three baselines), to hierarchies, such as Figure 2 in our paper, is not incremental.	Reply	I-Reply	1
[line_break_token][line_break_token]We responded to concern #2 above, and also modified paragraph 5 of section 3.1 and added a figure on page 27 of the supplement (Fig S5).	Reply	I-Reply	2
Did this address your concern?	Reply	I-Reply	2
[line_break_token][line_break_token][1] <a href="https://arxiv.org/pdf/1801.05453.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1801.05453.pdf</a>[line_break_token][2] <a href="https://arxiv.org/pdf/1612.08220.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1612.08220.pdf</a>[line_break_token][3] <a href="https://arxiv.org/pdf/1703.01365.pdf" target="_blank" rel="nofollow">https://arxiv.org/pdf/1703.01365.pdf</a	Reply	O	0

Summary[line_break_token][line_break_token]This paper showed that out-of-distribution and adversarial samples can be detected effectively if we utilize logits (without softmax activations).	Review	O	0
Based on this observation, the authors proposed 2-logit based detectors and showed that they outperform the detectors utilizing softmax activations using MNIST and CIFAR-10 datasets.	Review	O	0
[line_break_token][line_break_token]I‚Äôd like to recommend "reject" due to the following[line_break_token][line_break_token]The main observation (removing softmax activation can be useful for detecting abnormal samples) is a bit interesting (but not surprising) but there is no theoretical analysis for this.	Review	O	0
It would be better if the authors can provide the reason why softmax activation hinders the novelty detection.	Review	B-Review	1
[line_break_token][line_break_token]The logit-based detectors proposed in the paper are simple variants of existing methods.	Review	I-Review	2
Because of that, it is hard to say that technical contributions are very significant.	Review	I-Review	2
[line_break_token][line_break_token]Questions[line_break_token][line_break_token]For evaluation, could the authors compare the performance with feature-based methods like Mahalanobis [1] and LID [2]?	Review	O	0
[line_break_token][line_break_token]I would be appreciated if the author can evaluate their hypothesis using various datasets like CIFAR-100, SVHN, and ImageNet.	Review	B-Review	4
[line_break_token][line_break_token][1] Lee, K., Lee, K., Lee, H. and Shin, J., 2018.	Review	O	0
A simple unified framework for detecting out-of-distribution samples and adversarial attacks.	Review	O	0
In Advances in Neural Information Processing Systems (pp.	Review	O	0
7167-7177).	Review	O	0
[line_break_token][line_break_token][2] Ma, X., Li, B., Wang, Y., Erfani, S.M., Wijewickrema, S., Schoenebeck, G., Song, D., Houle, M.E. and Bailey, J., 2018.	Review	O	0
Characterizing adversarial subspaces using local intrinsic dimensionality.	Review	O	0
arXiv preprint arXiv:1801.02613.	Review	O	0
hank you for you comments and feedback.	Reply	O	0
We agree that our work would benefit from using more datasets for evaluation and comparing with more methods.	Reply	O	0
We will include these improvements in the next version of the paper	Reply	O	0

This paper proposed a model that is capable of tracking dialogue states in a non-recursive fashion.	Review	O	0
The main techniques behind the non-recursive model is similar to that of the ICLR 2018 paper "NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION".	Review	O	0
Unfortunately, as state tacking can be formulated as one special case of sequence decoding, there is not much of innovation that can be claimed in this paper considering the "fertility" idea was already been proposed.	Review	B-Review	1
The paper did illustrate a strong experimental results on a recent dataset comparing with many state-of-the-art models.	Review	I-Review	1
However, it is not clear how much innovation this work generates and how the ICLR community would benefit from the problem that the paper is addressing.	Review	I-Review	1
 [line_break_token][line_break_token] 	Review	O	0
hanks for reviewing our work.	Reply	O	0
Below are our responses to clarify a few misunderstanding points by the reviewer.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We note that NMT and DST are very different research tasks, and DST has different settings, unique characteristics and challenges.	Reply	B-Reply	2
NMT aims to generate an output sequence that has the same meaning as input sequence and the two sequences are of different languages/domains.	Reply	I-Reply	2
By contract, DST aims to make accurate dialogue state prediction, instead of matching the semantic meanings between input and output.	Reply	I-Reply	2
Our DST approach treats input as a prior for each (domain, slot) pair, and the prior is used as a channel vector to obtain high-level and low-level (token-level) dependencies to achieve better dialogue state prediction.	Reply	I-Reply	2
Hence, the proposed technical approach and contributions in our work are actually quite different from the previous NMT work, although the idea of non-autoregressive was partly inspired by ICLR‚Äô18 NMT paper.	Reply	I-Reply	2
[line_break_token][line_break_token]2.	Reply	O	0
About the novelty and innovation, we highlight that one of our key contributions is to overcome a critical limitation of many existing DST methods.	Reply	B-Reply	1
These methods do not detect dependencies among (domain, slot) pairs because they do not allow the model to explicitly learn signals across domains and slots.	Reply	I-Reply	1
This is a very important contribution that is unique to DST tasks, and is very different from the previous non-autoregressive NMT work.	Reply	I-Reply	1
We also noted that technically it is non-trivial and not straightforward at all to apply the non-autoregressive idea to develop a new state-of-the-art DST technique, which involves several other techniques (such as delexicalization, designs of slot gating, fertility, etc as presented in our paper).	Reply	I-Reply	1
[line_break_token][line_break_token]3.	Reply	O	0
About the significance of this work, our new approach not only achieves the new state-of-the-art results for DST tasks on the MultiWOZ dataset, but the decoding speed is also an order of magnitude faster than the existing DST methods, making it a practically very useful technique to many real-world dialog systems applications.	Reply	B-Reply	3
From a scientific aspect, our technique is also not restricted to DST tasks.	Reply	I-Reply	3
It potentially could be applied to tackle many other similar NLP or machine learning problems that involve structured or compositional prediction such as outline-based or template-based generation.	Reply	I-Reply	3

The paper proposes a neural architecture for summarizing trees inspired by capsule networks from computer vision.	Review	O	0
The authors re-use a tree convolution from previous work for the bottommost layer, and then propose adaptations to the dynamic routing from capsule networks so that it can be applied to variable-sized trees.	Review	O	0
The paper applies the proposed architecture to three different program classification datasets, which are in three different languages.	Review	O	0
The paper reports empirical gains compared to two architectures proposed by previous work.	Review	O	0
[line_break_token][line_break_token]I think that it's interesting to apply the capsule network architecture to tree classification, but unfortunately it doesn't appear that some of the motivation for capsule networks on images didn't seem to transfer neatly to this setting; for example, there is no equivalent of inverse graphics as there is no reconstruction loss (as pointed out by the authors in Section 6.4).	Review	O	0
[line_break_token][line_break_token]Also, the variable-to-static capsule routing indeed appears novel, but I was a bit confused by its internal details.	Review	O	0
It appears that the outputs of the previous layer which occur most often will get routed (considering lines 6-8 of Algorithm 1 which up-weights each of the based on its similarity to; the are initially a re-numbered subset of), without any prior transformation of the previous layer first.	Review	B-Review	2
It seems to me that this doesn't allow for the prior layer to predict more complex features about the input that the subsequent layer is expected to capture.	Review	I-Review	2
In fact, for certain code classification tasks, it may be that rare capsule outputs from the initial layer are the most important to preserve.	Review	I-Review	2
[line_break_token][line_break_token]My biggest concern has to do with the empirical results.	Review	I-Review	3
The source of Dataset C (Mou et al 2016, <a href="https://arxiv.org/pdf/1409.5718.pdf)" target="_blank" rel="nofollow">https://arxiv.org/pdf/1409.5718.pdf)</a> reports 94.0% accuracy in Table 3 on their TBCNN method on the same dataset, whereas this paper reports 79.40% accuracy for TBCNN.	Review	O	0
I understand that the later result comes from a reimplementation, but it seems fairer to compare against (or additionally report) the results from the original authors of the method.	Review	B-Review	3
[line_break_token][line_break_token]Also, the paper cites ASTNN (Zhang et al 2019, <a href="https://dl.acm.org/citation.cfm?id=3339604)" target="_blank" rel="nofollow">https://dl.acm.org/citation.cfm?id=3339604)</a> in the introduction, and even though that paper reports (in table 2) 98.2% accuracy on Dataset C, the results table of the paper under review does not mention this in the evaluation section.	Review	O	0
I don't think that a paper necessarily has to achieve empirical results beating all previous ones in order to merit acceptance, but the way that the comparison is currently set up doesn't seem to facilitate a clear comparison of the pros and cons of this method versus other ones in the literature.	Review	B-Review	4
[line_break_token][line_break_token]For the above reasons, I vote to reject the paper.	Review	O	0
For future submissions, it would be good to see a more comprehensive empirical comparison of the proposed method compared to others, and also to have more explanations about the design of the network.	Review	O	0
e would like to thank the reviewer for his valuable time, helpful feedback and insightful suggestions to further improve our study.	Reply	O	0
[line_break_token][line_break_token]Q2-1: It doesn‚Äôt appear that some of the motivation for capsule networks on images didn‚Äôt seem to transfer neatly to this setting;  for example, there is no equivalent of inverse graphics as there is no reconstruction loss.	Reply	O	0
[line_break_token][line_break_token]Response:[line_break_token][line_break_token]We thank the reviewer for this very important comment.	Reply	O	0
 We kindly invite the reviewer to refer to the common response above. (	Reply	B-Reply	1
<a href="https://openreview.net/forum?id=SJgXs1HtwH&amp;noteId=r1eiYk0oiH)" target="_blank" rel="nofollow">https://openreview.net/forum?id=SJgXs1HtwH&amp;noteId=r1eiYk0oiH)</a>[line_break_token][line_break_token]Q2-2: Variable to Static Routing Algorithm[line_break_token][line_break_token]Response:[line_break_token][line_break_token]We acknowledge the reviewer‚Äôs concern with respect to the preservation of rare capsules.	Reply	O	0
The initialization of is based on the length of the capsule output vector (L2 norm), which represents the probability of existence of the entity learnt by the capsule.	Reply	B-Reply	2
For a given training/testing sample, not all the capsules are activated in a given layer, and source code often consists of non-essential entities, where only a portion of all entities determine the code class.	Reply	I-Reply	2
Hence, we initialize the next layer with the capsules which represent entities with highest probability of existence (in other words, highest activation), and dynamically route the rest of the capsules based on the similarity between the respective vector outputs.	Reply	I-Reply	2
Therefore, it is not necessarily the capsules that occur most often that get routed to the next layer, instead it is the capsules with the most prominent outputs along with the capsules with the highest vector similarities to them.	Reply	I-Reply	2
In this way, rare capsules are still preserved and routed to the next layer.	Reply	I-Reply	2
[line_break_token][line_break_token]Further, we acknowledge that we do not use prior transformations between the primary dynamic layer and the primary static layer.	Reply	I-Reply	2
However, in the layers subsequent to the primary static layer, we use prior transformations aiding them to predict more complex features.	Reply	I-Reply	2
We can use multiple layers similar to the code capsule layer to predict further complex features, depending on the complexity of the classification task.	Reply	I-Reply	2
According to Section 6.3.3, empirical evidence suggests that using more such layers is not very effective for the three particular datasets that we have used.	Reply	I-Reply	2
However, more complex datasets may benefit from stacking multiple code capsule layers.	Reply	I-Reply	2
[line_break_token][line_break_token]Q2-3: Empirical Results[line_break_token][line_break_token]Response:[line_break_token][line_break_token]We acknowledge the reviewer‚Äôs concern with respect to the empirical results.	Reply	O	0
The primary reason for the ambiguity between TBCNN [Mou et al. (	Reply	B-Reply	3
2016)] and our re-implementation is the initial embeddings, as explained in Section 6.2.	Reply	I-Reply	3
Mou et al. (	Reply	I-Reply	3
2016) have used custom-trained initial embeddings for a small set of about 50 AST node types defined specifically for C language only, while our approach generates the initial embeddings for a much larger vocabulary of more than three hundred unified AST node types for both C and Java.	Reply	I-Reply	3
We decided to follow a more generalized approach across programming languages, at the expense of performance gain resulting from small, specific vocabularies.	Reply	I-Reply	3
[line_break_token]We believed that it would be more general and fairer to compare across datasets in more than one programming language by using the same (and larger) set of AST node vocabulary used in our approach.	Reply	I-Reply	3
[line_break_token][line_break_token]We acknowledge the reviewer's perspective on the fairness of the results and potential errors or discrepancies in our re-implementation of TBCNN [Mou et al. (	Reply	I-Reply	4
2016)]. Retrospectively, in addition to using the larger set of AST node vocabulary, we should have also applied our approach directly to the initial embeddings with the same smaller set of AST node vocabulary used in TBCNN [Mou et al. (	Reply	I-Reply	4
2016)] and ASTNN [Zhang et al. (	Reply	I-Reply	4
2019)] etc.	Reply	I-Reply	4
for the dataset in C language so that we may have a clearer comparison.	Reply	I-Reply	4

Quick summary:[line_break_token][line_break_token]The author investigate if we can learn a linearized state space model using deep generative models to guide and transform non-linear dynamic observations into linear state space processes.	Review	O	0
A quick analysis of the feasibilty of the model and its relation to existing models is provided.	Review	O	0
Experimental results include a GAN and a VAE as the generative model on a few datasets.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]  - The model is interesting and the motivation is quite clear[line_break_token]  - analysis is quite nice[line_break_token]  - writing is quite clear and decent[line_break_token][line_break_token]Cons:[line_break_token][line_break_token] - Extremely lacking experimental validation - there are literally no baseline models, no numbers or any kind of quantitative analysis.	Review	O	0
The figures show samples from the model with very little explanation or discussion and it's entirely unclear what we learn from this model.	Review	B-Review	1
Scientifically speaking, this is not up to par.	Review	I-Review	1
[line_break_token][line_break_token]Bottom line - I think this is a good start for a paper about an interesting model, but I don't feel that this teaches us anything about what the model learns and how it relates in practice to other models.	Review	I-Review	2
We thank the reviewer for the constructive feedback.	Reply	O	0
Please find our replies below.	Reply	O	0
Like the other two reviewers, AnonReviewer1 pointed out several shortcomings of the paper that could not be corrected within the revision period.	Reply	O	0
We have therefore decided to withdraw the paper in order to improve it by taking into account the reviewers' comments.	Reply	O	0
[line_break_token][line_break_token]The main concern raised by the AnonReviewer1 is the lack of experimental baselines.	Reply	B-Reply	1
[line_break_token][line_break_token]We understand the importance of experimental comparison with state-of-the-art methods and will do our best to provide a comprehensive evaluation in future versions of our work.	Reply	I-Reply	1
We acknowledge that the experimental section was neglected with respect to this, but we would like to provide some insight into the reasons for this.	Reply	I-Reply	1
[line_break_token][line_break_token]The aim of the work is to learn a generative model of a stochastic process.	Reply	I-Reply	1
Comparative experimental evaluation of such a model is particularly challenging, since a ground truth, by definition, does not exist.	Reply	I-Reply	1
The authors of [1], a seminal work in the field of generative models for video point this difficulty out on the respective project page [2]:[line_break_token][line_break_token]"Evaluation of generative models is hard.	Reply	I-Reply	1
We used a psychophysical 2AFC test on Mechanical Turk asking workers 'Which video is more realistic?'	Reply	I-Reply	1
We think this evaluation is okay, but it is important for the community to settle on robust automatic evaluation metrics."	Reply	I-Reply	1
[line_break_token][line_break_token]Unfortunately, we did not have the means to perform a psychophysical evaluation, so we chose the option that we have seen in some of the papers that have inspired our work, e.g. [3] and [4], namely presenting example sequences of synthesized video and let the reader judge the performance.	Reply	I-Reply	1
We understand that we might have overlooked further possibilities and will do our best to come up with better measures in the future.	Reply	I-Reply	1
[line_break_token][line_break_token][1] Vondrick et al., "	Reply	O	0
Generating Videos with Scene Dynamics"[line_break_token][2] <a href="http://www.cs.columbia.edu/~vondrick/tinyvideo/" target="_blank" rel="nofollow">http://www.cs.columbia.edu/~vondrick/tinyvideo/</a>[line_break_token][3] Johnson et al. "	Reply	O	0
Composing graphical models with neural networks for structured representations and fast inference"[line_break_token][4] Goroshin et al. "	Reply	O	0
Learning to Linearize Under Uncertainty"	Reply	O	0

This paper proposes to compare different methods to build BERT/GPT  representations of long documents, to bypass the limitation of the input size of these models.	Review	O	0
One of the proposed method uses attention mechanism to discover the most significant portion of the text which are use to backpropagate the error on the language model.	Review	O	0
Three combination methods (concatenation, RNN and attention)  are tested on 2 databases plus one modified version of one of the databases to show the impact of the presentation bias in the texts (most important part are at the beginning).	Review	O	0
[line_break_token]Results show that the largest improvement is the base BERT model over the previously proposed model : this aspect should be comment : what is the reason of the improvement ?	Review	B-Review	1
[line_break_token]Combination of textual part also yields improvement, but to a smaller extend.	Review	I-Review	2
Hyper-parameter and Training/Testing time are reported, which is useful from a practical point of view if one should decide to implement the proposed method or not, considering the extra computational load and the relatively small improvement.	Review	I-Review	2
The Shuffling experiment demonstrate an interesting behaviour of the models, that should be confirmed on a real dataset.	Review	I-Review	2
[line_break_token][line_break_token] 	Review	I-Review	1
hank you for taking the time to review our paper.	Reply	O	0
We clarify some points below, and we have added further discussion to the paper.	Reply	O	0
[line_break_token][line_break_token]Q: Why does the BERT-base model show the most improvement over the previously proposed models?	Reply	O	0
[line_break_token][line_break_token]Our BERT-base improves over the PatentBert implementation because PatentBert does not combine the title, abstract, and claim-- but only the title+abstract or just the first claim.	Reply	B-Reply	1
This was done to prevent truncation, but these combinations don't always reach the max input size.	Reply	I-Reply	1
Additionally, our BERT-base improves over the Deep Patent methods and Local Word Glimpses as they use word level embeddings instead of language model based embeddings.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Comment: Shuffling should be confirmed on a real dataset[line_break_token][line_break_token]While we would like to confirm the results of our shuffling experiment on other datasets, we were unable to find any sufficiently long document classification task that would be illuminative.	Reply	O	0
For future work, we would like to find more datasets for this task.	Reply	B-Reply	2

This paper presents an interesting quantization technique that is, unusually, end-to-end trainable and not just an inference technique.	Review	O	0
According to the experiments, the method achieves better performance and computational savings as compared to other quantization method baselines.	Review	O	0
The results are admirably demonstrated on a variety of models, including CNN and RNN-based neural nets, as well as on several datasets in different domains, including ImageNet, CIFAR10, and PTB.	Review	O	0
We see the method seems to generalize across all of these.	Review	O	0
[line_break_token][line_break_token]Nevertheless, while I found this is very interesting work, I have a number of issues with the experiments, which I'll go into below.	Review	O	0
I feel this work is being released prematurely and could use some more polish to help sell the method better.	Review	O	0
Below are a few remarks and questions for the authors that would be helpful to be answered.	Review	O	0
[line_break_token][line_break_token]* Why only report on ResNet-18?	Review	O	0
It would be far more useful to show numbers against ResNet-50.	Review	B-Review	1
It would also be useful to show the non-quantized best results on these models and datasets.	Review	I-Review	1
[line_break_token]* I wish more effort had been spent to analyze the experiments.	Review	O	0
For example, I am not sure I understand the effects of the threshold on this method.	Review	B-Review	2
What happens when it's set manually?	Review	I-Review	2
[line_break_token]* How exactly is computation cost savings calculated so crudely?	Review	O	0
If it uses B_avg, why not calculate the bitwidth per layer and sum things up?	Review	B-Review	3
Using B_avg strikes me as being quite crude.	Review	I-Review	3
[line_break_token]* When the authors address runtime changes except in table 6, they changed their baseline to a vanilla ResNet-18 with dense weights.	Review	O	0
What are the runtime effects relative to ShuffleNet and ShiftNet?	Review	B-Review	4
hank you for the insightful comments that have led to improvements in our paper.	Reply	O	0
Below are our answers to your questions.	Reply	O	0
[line_break_token][line_break_token]Q1: "Why only report on ResNet-18?	Reply	O	0
It would be far more useful to show numbers against ResNet-50.	Reply	O	0
It would also be useful to show the non-quantized best results on these models and datasets."	Reply	O	0
[line_break_token][line_break_token]Reply: In Table 1, we report the results of the floating point baseline for the three models in the first column as ‚Äúfp‚Äù.	Reply	O	0
For example, the floating-point ShiftNet-20 CIFAR-10 model has an accuracy of 89.4%.	Reply	B-Reply	1
In Table 4, we report the floating-point PPW of the LSTM PTB model in the caption.	Reply	I-Reply	1
[line_break_token][line_break_token]To empirically show PG works on more models, we apply PG to ResNet-56 and ResNet-32, then train it on the CIFAR-10 dataset.	Reply	I-Reply	1
The training settings are the same as described in Section 4.	Reply	I-Reply	1
In the latest revision, the additional results are shown in Table 7 in Section A.2.	Reply	I-Reply	1
[line_break_token][line_break_token]Compared to the 8-bit PACT baseline, PG achieves 4x computational cost reduction on both models at the same level of prediction accuracy.	Reply	I-Reply	1
The sparsity in ResNet-56 (98.2%) and ResNet-32 (96.3%) are higher than that (90.1%) in ResNet-18 for CIFAR-10 dataset.	Reply	I-Reply	1
Compared to the fix-threshold baseline, the accuracy of PG increases by 42.5% for ResNet-56 and 46.4% for ResNet-32 with the same computational cost.	Reply	I-Reply	1
This increasing accuracy gap empirically shows that PG also works well on larger DNN models.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: " I am not sure I understand the effects of the threshold on this method.	Reply	O	0
What happens when it's set manually?"	Reply	O	0
[line_break_token][line_break_token]Reply: We can consider the threshold in PG as a measurement of the importance of an output feature.	Reply	O	0
If the MSB result exceeds the threshold, it means that the corresponding output feature is important.	Reply	B-Reply	2
We will then compute this important feature in high precision.	Reply	I-Reply	2
In the bell shaped activation distribution, the larger a threshold is, the less likely an output feature will exceed the threshold, and thus the more output features will be computed using reduced precision.	Reply	I-Reply	2
Hence a large threshold is desired to reduce the computational cost.	Reply	I-Reply	2
We introduce a threshold loss to make the threshold approach a large value.	Reply	I-Reply	2
Moreover, the threshold is also optimized by minimizing the accuracy loss.	Reply	I-Reply	2
As a result, the trainable thresholds are learned to jointly minimize the threshold loss and the accuracy loss.	Reply	I-Reply	2
[line_break_token][line_break_token]We‚Äôve already compared PG to manually set thresholds.	Reply	I-Reply	2
The results of which are shown  in Table 1 under columns of ‚ÄúFix-Threshold‚Äù.	Reply	I-Reply	2
We notice that manually set thresholds yield a much lower model accuracy compared to PG at a similar computational cost.	Reply	I-Reply	2
[line_break_token][line_break_token]In the latest revision, we also show the results of sweeping a series of manually set thresholds on the ResNet-18 for CIFAR-10 with=3/2 in Table 8 in Section A.2.	Reply	I-Reply	2
As the threshold decreases from 3 to -4, the average bitwidth in the update phase consistently increases.	Reply	I-Reply	2
This is expected because we compute more output features in high precision.	Reply	I-Reply	2
The model prediction accuracy therefore increases.	Reply	I-Reply	2
However, compared to the manually set threshold, PG achieves a much better model accuracy (91.2%) with a larger sparsity (90.1%).	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: "How exactly is computation cost savings calculated so crudely?	Reply	O	0
If it uses B_avg, why not calculate the bitwidth per layer and sum things up?"	Reply	O	0
[line_break_token][line_break_token]Reply: The average bitwidth is a good indicator for the compute efficiency when we run PG on customized hardware as it reflects the energy consumption per arithmetic operation.	Reply	O	0
Prior art proposed by Song et al. (	Reply	B-Reply	3
ISCA‚Äô2018) cited in the paper also adopts the same metric of compute efficiency.	Reply	I-Reply	3
[line_break_token][line_break_token]We agree that calculating the bitwidth per layer and summing them up is another good metric.	Reply	I-Reply	3
However, it is essentially equivalent to the average bitwidth reported in the paper.	Reply	I-Reply	3
The average bitwidth is obtained by normalizing the sum of the bitwidth per layer using the total number of features in the network.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4: "When the authors address runtime changes except in table 6, they changed their baseline to a vanilla ResNet-18 with dense weights.	Reply	O	0
What are the runtime effects relative to ShuffleNet and ShiftNet?"	Reply	O	0
[line_break_token][line_break_token]Reply: In Section 4.3, we show the kernel speedup of applying PG to the ResNet-18 model on CIFAR-10 dataset.	Reply	O	0
Since PG works by modifying linear layers (i.e., convolutional layers or fully connected layers) instead of the model architectures, it generalizes to other models containing linear layers	Reply	B-Reply	4

This paper proposes to modify how noise factors are treated when developing VAE models.	Review	O	0
 For example, the original VAE work from (Kingma and Welling, 2013) applies a deep network to learn a diagonal approximation to the covariance on the decoder side.	Review	O	0
 Subsequent follow-up papers have often simplified this covariance to sigma^2*I, where sigma^2 is assumed to be known or manually tuned.	Review	O	0
 In contrast, this submission suggests either treating sigma^2 as a trainable parameter, or else introducing a more flexible zero-mean mixture-of-Gaussians (MoG) model for the decoder noise.	Review	O	0
 These modeling adaptations are then analyzed using various performance indicators and empirical studies.	Review	O	0
[line_break_token][line_break_token]The primary issues I have with this work are threefold:  (i) The paper is not suitably organized/condensed for an ICLR submission, (ii) the presentation quality is quite low, to the extent that clarity and proper understanding are jeopardized, and (iii) the novelty is limited.	Review	O	0
 Consequently my overall impression is that this work is not yet ready for acceptance to ICLR.	Review	B-Review	3
[line_break_token][line_break_token]First, regarding the organization, this submission is 19 pages long (*excluding* references and appendices), despite the clear suggestion in the call for papers to limit the length to 8 pages: "There is no strict limit on paper length.	Review	I-Review	1
However, we strongly recommend keeping the paper at 8 pages, plus 1 page for the references and as many pages as needed in an appendix section (all in a single pdf).	Review	I-Review	1
The appropriateness of using additional pages over the recommended length will be judged by reviewers."	Review	I-Review	1
 In the present submission, the first 8+ pages contain minimal new material, just various background topics and modified VAE update rules to account for learning noise parameters via basic EM algorithm techniques.	Review	I-Review	1
 There is almost no novelty here.	Review	I-Review	1
 In my mind, this type of well-known content is in no way appropriate justification for such a long paper submission, and it is unreasonable to expect reviewers to wade through it all during a short review cycle.	Review	I-Review	1
[line_break_token][line_break_token]Secondly, the presentation quality is simply too low for acceptance at a top-tier international conference (e.g., it is full of strange sentences like "Such amelioration facilitates the VAE capable of always reducing the artificial intervention due to more proper guiding of noise learning."	Review	I-Review	2
 While I am sympathetic to the difficulties of technical writing, and realize that at times sufficiently good ideas can transcend local grammatical hiccups, my feeling is that, at least for now, another serious pass of editing is seriously needed.	Review	I-Review	2
 This is especially true given that it can be challenging to digest so many pages of text if the presentation is not relatively smooth.	Review	I-Review	2
[line_break_token][line_break_token]Third and finally, I do not feel that there is sufficient novelty to overcome the issues already raised above.	Review	I-Review	3
 Simply adapting the VAE decoder noise factors via either a trainable noise parameter or an MoG model represents an incremental contribution as similar techniques are exceedingly common.	Review	I-Review	3
 Of course, the paper also invents some new evaluation metrics and then applies them on benchmark datasets, but this content only appears much later in the paper (well after the soft 8 page limit) and I admittedly did not read it all carefully.	Review	I-Review	3
 But on a superficial level, I do not believe these contributions are sufficient to salvage the paper (although I remain open to hearing arguments to the contrary).	Review	I-Review	3
We‚Äôd like to thank the reviewer for their making effort to reviewing and providing helpful suggestions although they didn't provide fair assessments of our contribution, especially the important content which appears later that used to reveal some basic facts and behaviors of idealistic VAE as well as our indicators.	Reply	O	0
 We have made a number of changes to address them.	Reply	O	0
[line_break_token][line_break_token]A.[tab_token]We condense the original paper into 10 pages.	Reply	O	0
We also try to reduce the number of strange sentences.	Reply	B-Reply	1
[line_break_token][line_break_token]B.[tab_token]We weaken our discussion on noise modeling due to the limitation of the paper length and strengthen the theoretical troubleshooting  of   VAE's properties  and they are listed below[line_break_token][line_break_token]    1.	Reply	O	0
[tab_token]Intrinsic dimension Issue:  "Could the VAE learn the intrinsic number of factors underlying the data?	Reply	B-Reply	2
[line_break_token]Our paper: Yes, idealistic VAE learns and only learns the intrinsic factor dimension and the VAE objective induced by the Gaussian prior also encourages the information sparsity in dimension which is contributing to the learn the intrinsic dimension.	Reply	I-Reply	2
[line_break_token]Besides, in real implementations, the conclusion is also instructive if the noise is proper modeling and the disentanglement(clarified in our paper) is achieved to some extent.	Reply	I-Reply	2
[line_break_token][line_break_token]    2.	Reply	O	0
[tab_token]Disentanglement Issue:  "What are need and range induced by word disentanglement?"	Reply	O	0
[line_break_token]We provide the clarification according to information conservation theorem:[line_break_token]the learned the factors are close to being independent.	Reply	B-Reply	2
[line_break_token]the factors incline to generate the oracle signal and to be inferred perfectly from the oracle signal through a continuous procedure/mapping.	Reply	I-Reply	2
[line_break_token][line_break_token]   3.	Reply	O	0
[tab_token]Real Factor Issue:  "Could the VAE learn the real generating factor underlying the data or just some fantasies?"	Reply	O	0
[line_break_token]We show that idealistic VAE possibly learn any factors set in the equivalence class.	Reply	B-Reply	2
Besides, the experiment results also suggest that the VAE's factor equivalence generally exist.	Reply	I-Reply	2
[line_break_token][line_break_token]   4.	Reply	O	0
[tab_token]Indicator Issue: "Could the effectiveness of current disentanglement metric be guaranteed?"	Reply	O	0
[line_break_token]We show that the current disentanglement introduced by (beta-VAE) is based on "simulated factors" while idealistic VAE possibly learns any factor set in equivalence class induced by the "simulated factors".	Reply	B-Reply	2
Hence, that metric may work sometimes and suffer instability among different trials.	Reply	I-Reply	2
[line_break_token]We further introduce some indicator regarding the mutual information I(x;z) and Dkl(q(z)||p(z)) which provide the assessment to the determination of ``used factors" and to the disentanglement.	Reply	I-Reply	2
[line_break_token][line_break_token]   5.	Reply	O	0
[tab_token]Implementation Issue: "Could the aforementioned analysis be instructive in real implementation?'	Reply	O	0
[line_break_token]We introduce noise modeling to relax the consideration of the real situation.	Reply	B-Reply	2
The experiment results empirically testify the knowledge derived from the idealistic case could be instructive in the real situation.	Reply	I-Reply	2
 They also demonstrate own characteristic of noise modeling in pursuing the disentanglement.	Reply	I-Reply	2
[line_break_token][line_break_token]C.[tab_token]Despite the theoretical discussion on the intrinsic properties of VAE, if we just discuss the novelty of noise modeling of VAE alone, we don't think it is limited.	Reply	O	0
 If you find different noise assumptions/specifications just significantly influence the disentanglement you will believe it	Reply	B-Reply	3

The authors propose an approach for calibrated predictions under domain shift scenarios.	Review	O	0
The approach, that leverages (unlabeled) test samples allows for unsupervised post-processing calibration, even for off-the-shelf models for which the training data is not available.	Review	O	0
Experiments compare the proposed approach with existing calibration methods in shifted domains.	Review	O	0
[line_break_token][line_break_token]Equation (5) is confusing.	Review	B-Review	1
If I understand correctly, the authors are simply making the point that q(x,y=k) can be written in terms of q(x,y\neq k) by weighting by the ratio of conditionals, which are available.	Review	I-Review	1
[line_break_token][line_break_token]Sensitivity to noisy labels.	Review	I-Review	2
The experiment is reasonable and the results are convincing, however, the authors do not justify why accurate (manual) labels on the target set are not feasible in many applications.	Review	I-Review	2
The authors could point to a few examples for context.	Review	I-Review	2
[line_break_token][line_break_token]The authors assume that q_s(y) = q_t(y), which seems restrictive in practice.	Review	I-Review	3
Though it does not impact my opinion of the proposed approach, it seems narrow to think of a practical situation where the space of covariates is changing but the class composition remains unchanged.	Review	I-Review	3
This is vaguely addressed in Section 6.	Review	I-Review	3
Perhaps it can be elaborated further.	Review	I-Review	3
[line_break_token][line_break_token]I enjoyed reading the paper, the proposed reinterpretation of NLL in terms of a weighted average and its approximation based on weights that do not depend on the labels but the (assumed known) labels marginal is interesting and seems to yield good results.	Review	O	0
hank you for your insightful comments, and we are happy that you find the paper interesting.	Reply	O	0
We address your concerns and add some parts to the paper accordingly:[line_break_token][line_break_token]Concerns:[line_break_token]1- Equation (5) is confusing.	Reply	O	0
[line_break_token][line_break_token] We mean exactly the point that the reviewer mentioned.	Reply	O	0
As it was not clear in the text, we rewrite Eq.(5) explanation to make it more clear and precise.	Reply	B-Reply	1
[line_break_token][line_break_token]2- the authors do not justify why accurate (manual) labels on the target set are not feasible in many applications.	Reply	O	0
The authors could point to a few examples for context.	Reply	O	0
[line_break_token][line_break_token]We add three examples of applications (Neuron cells classification taken by electron microscope, pathology images and skin disease classification) that have expensive labeling procedure with high risk of labeling noise to the introduction of the paper (Section 1) to make it clear why labeling even for few number of samples is not possible sometimes.	Reply	B-Reply	2
[line_break_token][line_break_token]3- The authors assume that, which seems restrictive in practice.	Reply	O	0
[line_break_token][line_break_token]In domain shift, UTS is valid under Covariate Shift assumption for classification problem which means the test and training datasets are different in representation but keeps the same proportions of each class occurrence.	Reply	B-Reply	3
Covariate shift assumption is a common domain adaptation assumption that is valid for many classification problems.	Reply	I-Reply	3
For instance in medical image classification, it is very probable that the illumination, capturing noise, resolution, image size or viewpoint of the test images to be different from the training dataset.	Reply	I-Reply	3
In this case,  the representation of two domains is changed  that means but the probability of happening a class of object is staying the same which means.	Reply	I-Reply	3
[line_break_token]In classification problems as the domain is discrete, UTS only needs to calculate empirically the number of occurrence of each class to the total number of samples in the training set which is equal to and use it as to calibrate the model.	Reply	I-Reply	3
[line_break_token][line_break_token]Update to the paper:[line_break_token]We add one extra paragraph to Section 4.1 with the title of  "Validity of UTS in Practice" focusing on Covariate shift assumption in practice and how to calculate  to address this important concern.	Reply	O	0

After  rebuttal period: I recommend accepting  this  paper.	Review	O	0
[line_break_token]======================================[line_break_token]Summary:[line_break_token][line_break_token]This paper attempts to understand if the success of MAML is due to rapid learning or feature reuse.	Review	O	0
The analysis shows that MAML is performing better mainly due to feature reuse.	Review	O	0
Authors use this result to derive a simpler version of MAML called ANIL.	Review	O	0
ANIL does not update the non-final layers of the network during inner loop training and still has similar performance to MAML.	Review	O	0
[line_break_token][line_break_token]My comments:[line_break_token][line_break_token]Overall I think this is an interesting analysis paper which sheds some light on how MAML works, However, I see these analysis not just as a criticism towards MAML.	Review	O	0
I also see these analysis as a criticism against the meta-learning datasets that we use.	Review	O	0
All these datasets are artifically created from the same dataset and hence it might be very easy to reuse features to get good performance.	Review	O	0
I am not sure if the same analysis will hold if we consider a dataset where tasks are not this similar (like Meta-dataset, Triantafillou et al 2019).	Review	B-Review	1
I encourage the authors to have this disclaimer in the end of the paper so that the community does not falsely conclude that MAML cannot do rapid learning.	Review	I-Review	1
hank you very much for your review and comments on our paper.	Reply	O	0
We will update the latest version of our paper with the disclaimer you have mentioned.	Reply	B-Reply	1
We think that exploring how our analysis applies to other datasets from Meta-dataset (Triantafillou et al 2019), or across more diverse tasks, will be interesting future work.	Reply	I-Reply	1

[line_break_token]This paper proposed to improve pre-training of language models (e.g. BERT) by incorporating information around entities based on English Wikipedia.	Review	O	0
The idea is very simple and straightforward: it takes all the anchor links from Wikipedia and replaces some entities by randomly sampling negative ones of the same entity type (according to Wikidata) and adds an extra binary prediction task which predicts if the entity has been replaced or not.	Review	O	0
[line_break_token][line_break_token]The model was initialized by BERT (or the authors‚Äô BERT reimplementation) and trained for another 1M steps with the new training objective and reduced % of masking tokens.	Review	O	0
[line_break_token][line_break_token]The model was evaluated on a fact completion task (created by the authors on the 10 sampled Wikidata relations) and several open-domain QA datasets and an entity typing dataset FIGER, and achieved significant improvements on the BERT baselines.	Review	O	0
[line_break_token][line_break_token]Overall, I think this is a strong paper.	Review	O	0
The idea is simple but effective, the experiments are thorough and improvements over the BERT baselines are significant.	Review	O	0
[line_break_token][line_break_token]Below are some concerns I had when I read the paper and also some suggestions on how to improve this paper: [line_break_token][line_break_token]1) I am slightly concerned about the evaluation of the fact completion task and its baselines.	Review	O	0
[line_break_token][line_break_token]- Why are there only 190-906 candidates for these relations?	Review	B-Review	1
How were the candidates chosen?	Review	I-Review	1
Why not use the full set of possible candidates of that entity type?	Review	I-Review	1
[line_break_token][line_break_token]- I am not sure why you picked the most common entities for predictions.	Review	I-Review	1
Fact completion for rare entities would be more challenging and practical.	Review	I-Review	1
Also, the models might favor choosing more common entities as well.	Review	I-Review	1
[line_break_token][line_break_token]- I am also not sure if the BERT baseline (by using k [MASK] tokens when the candidate answer has k tokens and taking the average of the k probabilities) is a strong one or not in this setting, as BERT was not trained in this way and it is unclear if this would make BERT favor shorter entities or not.	Review	I-Review	1
[line_break_token][line_break_token]2) OpenQA results (Table 4): there is a very strong baseline coming out recently (an EMNLP‚Äô19 paper): [line_break_token][line_break_token]Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering.	Review	O	0
[line_break_token][line_break_token]Even for their BERT-base model, TriviaQA F1 was 67.5, SearchQA F1 was 70.6 and Quasar-T F1 was 59.0.	Review	B-Review	2
It is okay to not directly compare to their results (the focus is different), but the authors should be aware of their results and perhaps remove the state-of-the-art claim.	Review	I-Review	2
[line_break_token][line_break_token]3) I‚Äôd be interested in seeing more ablation studies on the importance of masking/replacement choices.	Review	O	0
What is the percentage of entities that have been replaced?	Review	B-Review	3
50%?	Review	I-Review	3
The only thing I can find is that no adjacent entities have been replaced at the same time.	Review	I-Review	3
How important is that?	Review	I-Review	3
 I imagine that the percentage of entities that have been replaced should also matter the performance significantly.	Review	I-Review	3
[line_break_token][line_break_token]4) If I understand correctly, the model was first trained (as BERT) on English Wikipedia + BooksCorpus and then later trained only on English Wikipedia.	Review	O	0
I wonder how important the first stage would still be.	Review	B-Review	4
Could add an experiment that trains on Wikipedia only?	Review	I-Review	4
[line_break_token][line_break_token]Minor suggestions:[line_break_token]1) Please use ‚ÄúEnglish Wikipedia‚Äù instead of ‚ÄúWikipedia‚Äù (#BenderRule)[line_break_token]2) Table 1: don‚Äôt put ‚Äú572‚Äù next to ‚ÄúAverage Hits @10‚Äù.	Review	O	0
It is confusing.	Review	B-Review	5
[line_break_token]	Review	O	0
hank you for the detailed comments, we have updated the paper accordingly.	Reply	O	0
Please see our reply below:[line_break_token][line_break_token]On Fact Completion Evaluation:[line_break_token][line_break_token]Candidate selection: For each relation, we use the groundtruth answer entities from all queries as the candidate set.	Reply	O	0
Using the full set of entities of the same type could result in much larger candidate sets (there are more than 5 million person entities), which makes it computational expensive to evaluate each query.	Reply	B-Reply	1
Note that we view the fact completion task as a probing task instead of a real-world application.	Reply	I-Reply	1
Thus, we choose to use the compact candidate sets for fast evaluation.	Reply	I-Reply	1
[line_break_token][line_break_token]Why selecting common entities for evaluation: We focus on common entities since common world knowledge is likely to be more useful to NLP applications.	Reply	I-Reply	1
Automatically completing knowledge bases with rare long-tail entities is an important problem, but that‚Äôs not the primary focus of this work.	Reply	I-Reply	1
[line_break_token][line_break_token]BERT baselines: BERT is not trained to handle multi-token entities, so using the average token probability is the best BERT baseline we could think of for the fact completion task.	Reply	I-Reply	1
Our further inspection shows that the BERT baseline does not favor single-token entities: the average ratio of single-token candidates is 24.5% while the ratio of single-token entities among the BERT‚Äôs top10 predictions is 20.0%.	Reply	I-Reply	1
[line_break_token][line_break_token]On OpenQA results:[line_break_token]Thank you for pointing us to the new model (Wang et al.	Reply	O	0
EMNLP‚Äô19, which is presented after the submission deadline).	Reply	B-Reply	2
Wang et al.	Reply	I-Reply	2
show the benefits of normalizing the prediction probabilities across multiple passages during training.	Reply	I-Reply	2
As stated by the reviewer, our focus is different: instead of investigating more effective ways to use pretrained models for QA, we focus on improving the pretrained model itself and our model can easily stack with the new method.	Reply	I-Reply	2
Thus, we use a quite straightforward method for the QA experiments.	Reply	I-Reply	2
We have included a discussion in the revision.	Reply	I-Reply	2
[line_break_token] [line_break_token]On entity replacement strategy:[line_break_token]With the current replacement strategy, the replacement ratio is approximately 50%.	Reply	O	0
With limited resources, we have tried replacing all entities and also increasing the margin to 2 between replaced entities.	Reply	B-Reply	3
These two model variants are able to match vanilla BERT‚Äôs performance on SQuAD (~89.0F1 and ~90.0F1 compared to 90.5F1 with BERT) but fail to produce as much improvement as our final model.	Reply	I-Reply	3
These numbers suggest that the new training objective will be less effective if the replacements are too sparse or too dense.	Reply	I-Reply	3
Also, as we are doing joint training (with MLM), the performance of the two variants is still able to match the vanilla BERT.	Reply	I-Reply	3
[line_break_token][line_break_token]On two-stage training:[line_break_token]We designed our two-stage method in view of the practices of several existing work (<a href="https://arxiv.org/abs/1905.07129," target="_blank" rel="nofollow">https://arxiv.org/abs/1905.07129,</a> <a href="https://arxiv.org/abs/1909.04164,https://arxiv.org/abs/1905.03197)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1909.04164,https://arxiv.org/abs/1905.03197).</a> The BERT initialization allows us to start with a strong baseline and the second stage training is also very stable after the initialization.	Reply	O	0
As the pretraining + end tasks takes a long time to finish, we are unable to add the ablation during the discussion period due to resource constraints.	Reply	B-Reply	4
We are happy to add those experiments in the next revision.	Reply	I-Reply	4

Thank the authors for the response.	Review	O	0
The update looks good to me.	Review	O	0
The discussion section looks much better now.	Review	O	0
[line_break_token]----------------------------------------[line_break_token]Summary[line_break_token]This paper conducts research on adversarial policy against a fixed and black-box policy (victim).	Review	O	0
In this setting, the victim has a fixed policy but the adversary has no access to its white-box information.	Review	O	0
Instead, the adversary can freely access the black-box policy of the victim.	Review	O	0
The experiments show that the trained adversary outperforms the baseline in some scenarios, with three interesting findings: 1) the adversary successfully found the weakness of the victim.	Review	O	0
In some scenarios, the adversary wins by doing some weird actions which make no sense, but those weird actions somehow make the victim fail; 2) the victim fails due to the weird (or I should say adversarial) observation from the adversary but not the physical inference.	Review	O	0
The authors demonstrate this by showing that the victim has a much higher success rate when the observation is replaced with a ‚Äònormal‚Äô opponent.	Review	O	0
I am kind of on the borderline, but still lean to accept paper.	Review	O	0
[line_break_token]Strengths[line_break_token]- This paper presents some experiments on adversarial learning when the policy of the victim is fixed and black-box with interesting findings, demonstrates that the adversary can successfully figure out the weakness of the victim.	Review	O	0
[line_break_token]- The paper formalizes the problem into an MDP whose dynamics is unknown, which is clear.	Review	O	0
[line_break_token]- This paper comes with many experiments supported by great demos, which clearly support the authors‚Äô arguments.	Review	O	0
[line_break_token]Weaknesses[line_break_token]- The paper becomes messy in the end and does not come with a good conclusion.	Review	O	0
With a lot of experiments conducted, the author fails to summarize them into an (or a few) interesting conclusion(s), but end up with a page-long conclusion paragraph, which makes the paper less focused but like listing miscellaneous experiments.	Review	B-Review	1
From the reader‚Äôs perspective, a (or a few) clear conclusion would be very helpful.	Review	I-Review	1
[line_break_token]Possible Improvements[line_break_token]My suggestion is to reorganize the second half of the paper, to make a few clear arguments.	Review	O	0
Currently, the paper looks pretty narrative, and the author might easily get lost while reading the paper.	Review	B-Review	1
e‚Äôre glad that you found the experimental results interesting and that you agree they clearly support our argument.	Reply	O	0
Your concerns center around the clarity of the second-half of the paper, and especially the Discussion section on the final page.	Reply	B-Reply	1
[line_break_token][line_break_token]Thank you for your feedback.	Reply	I-Reply	1
In retrospect, the Discussion section was too crowded, trying to present a conclusion, discussion of consequences and future work.	Reply	I-Reply	1
We have revised this section to be more tightly focused, and have introduced sub-headings to signpost different material.	Reply	I-Reply	1
Two paragraphs justifying our threat model have been removed, with an abbreviated version included in the Framework section.	Reply	I-Reply	1
The Contributions sub-section has been rewritten to be itemized and less narrative.	Reply	I-Reply	1
[line_break_token][line_break_token]Clarity is important to us, and so we would appreciate your thoughts on the revised paper.	Reply	I-Reply	1
We are happy to continue the editing process to improve comprehensibility.	Reply	I-Reply	1
It would be particularly helpful to know if there are any specific sections of the paper you find confusing, or if there are any overarching questions about the work you feel the paper did not address.	Reply	I-Reply	1

This paper introduces ‚Äústiffness‚Äù, a new metric to characterize generalization in neural networks.	Review	O	0
Stiffness is a pretty simple concept and is relatively straightforward to compute.	Review	O	0
The authors evaluate this metric on standard datasets using two relatively small neural networks.	Review	O	0
On the whole, the paper is written clearly and explains its methodology in simple language.	Review	O	0
[line_break_token][line_break_token]I have a few observations:[line_break_token]1.	Review	O	0
The equivalence between equation 2 and equation 3 is mentioned in passing but no explanation is provided.	Review	B-Review	2
Th equivalence is not clear so I would encourage the authors to provide a short proof.	Review	I-Review	2
[line_break_token]2.	Review	I-Review	6
 Since stiffness depends on the gradients obtained on points in the input space, which in turn depends on the loss, why would a practitioner training a neural network turn to stiffness to diagnose overfitting instead of just looking at the values of the training and validation losses?	Review	I-Review	3
Indeed, the authors themselves say that a network has overfitted when training and validation losses diverge.	Review	I-Review	3
The paper fails to motivate why stiffness is better than just looking at losses during training.	Review	I-Review	3
[line_break_token]3.	Review	I-Review	6
The authors mention ‚ÄúThe train-val stiffness is directly related to generalization, as it corresponds to the amount of improvement on the training set transferring to the improvement of the validation set. ‚	Review	I-Review	4
Äù.	Review	I-Review	4
Typically, generalization is evaluated on a held out test set so I fail to understand what the authors mean by this statement.	Review	I-Review	4
We would expect validation error to underestimate test error  so while they are related, train-val stiffness would not necessarily characterize generalization.	Review	I-Review	4
It would be interesting to see a train-test stiffness graph to test the authors claim.	Review	I-Review	4
[line_break_token]4.	Review	I-Review	6
The paper fails to motivate the the utility of the concept of ‚ÄúDynamical Critical distance‚Äù.	Review	I-Review	5
Since the primary goal of  paper is to understand generalization, I would like the authors to clarify the motivation to study this quantity.	Review	I-Review	5
What additional insight does this provide with respect to generalization?	Review	I-Review	5
[line_break_token]5.	Review	O	0
The term ‚Äúdynamical critical distance‚Äù is not used uniformly.	Review	B-Review	6
For example, it is mentioned as ‚Äúdynamical critical scale‚Äù in section 3.3 and ‚Äúdynamical critical length‚Äù in section 4.2.	Review	I-Review	6
[line_break_token]6.	Review	O	0
While the paper on the whole is written in a clear fashion, I found section 4.4 to be particularly confusing.	Review	B-Review	7
The authors should consider rewriting that section to make it clearer.	Review	I-Review	7
[line_break_token][line_break_token]In summary, the concept of stiffness seems to closely follow training and validation losses and any problem diagnosed using stiffness would therefore be also diagnosed via examining the loss values.	Review	I-Review	1
This along with other concerns mentioned above mean that I cannot recommend this paper for publication.	Review	I-Review	1
-----------------------[line_break_token]‚ÄúIn summary, the concept of stiffness seems to closely follow training and validation losses and any problem diagnosed using stiffness would therefore be also diagnosed via examining the loss values.	Reply	O	0
This along with other concerns mentioned above mean that I cannot recommend this paper for publication.	Reply	O	0
‚Äù[line_break_token][line_break_token]We do not agree with your characterization of our contribution.	Reply	O	0
It is of course true that we could look at losses directly and it is indeed what we do -- we defined stiffness as the correlation between loss changes.	Reply	B-Reply	1
That, however, is not the main contribution of our paper.	Reply	I-Reply	1
We study how this concept depends on class membership, the stage of training, and the learning rate used for training.	Reply	I-Reply	1
Those results could certainly not be inferred from the total loss and (according to us) deserve a closer look	Reply	I-Reply	1

This paper builds a model of motivation-dependent learning.	Review	O	0
 A motivation channel is provided as an additional input to and RL-based learning system (essentially concatenated to state information), similar to goal-conditioned approaches (as the authors mention).	Review	O	0
 The motivational variables evolve according to their own rules, and are designed/interpreted as biological motivations such as water, food, sleep and work.	Review	O	0
 While the narrative is interesting, I lean towards reject as I believe it failed to deliver on what it promised.	Review	O	0
[line_break_token][line_break_token]In the first experiment, the satisfaction of these motivations are mapped onto a 4-room setting, where being in each room satisfies a motivation.	Review	O	0
 The choice to map the four rooms to biological drives is cute, but possibly confusing/misleading since this navigation problem really has nothing to do with these biological drives.	Review	O	0
A claim is that by providing the motivation as input to the policy, it is more robustly (across seeds) able to learn the "migration" (i.e. cycling) behavior among the rooms.	Review	O	0
 In a second example, a similar problem is solved involving navigation on a graph.	Review	O	0
[line_break_token][line_break_token]The final, most substantial example, is a policy trained to solve a simple, abstract version of a behavioral task.	Review	B-Review	2
In this setting, a motivation channel was again used.	Review	I-Review	2
 However, the motivation channel value is now fixed to one of two discrete values, essentially meaning it is simply a task-label variable, a paradigm that has already been applied in the context of simple models of neuroscience tasks, e.g. see Song et al.	Review	I-Review	2
2017 "Reward-based training of recurrent neural networks for cognitive and value-based tasks".	Review	I-Review	2
 [line_break_token][line_break_token]There is a bit of a mixed framing overall as to whether it is being claimed that the "motivation" being passed as an input is a fundamental contribution to AI/RL (I think it is not), versus the computational modeling of biological motivation.	Review	O	0
 I think the people qualified to judge whether the computational model is a worthwhile model of motivation specifically are probably a narrower set of computational neuroscientists.	Review	B-Review	4
 I do think there is value in the kind of computational modeling performed, involving establishing a relationship between training a neural network to solve a behavioral task and comparing this with real neural data.	Review	I-Review	4
 This paradigm already becoming increasingly popular within computational neuroscience.	Review	I-Review	4
 However, while I find the results slightly interesting, but not very significant, as someone interested in the biology of motivation, I question whether the nature of these contributions would be of broad interest at this venue.	Review	I-Review	4
 [line_break_token][line_break_token]More fundamentally, I don't believe there is a meaningful ML/AI/RL contribution, and I have some issues with the presentation of the first two examples.	Review	O	0
 While I do like the narrative inspiring these problems, I find the implementations of the problems too simplified to really be meaningfully related to their inspiration (in terms of motivated behaviors).	Review	B-Review	5
 Rather than really model motivation as part of the policy architecture, the authors have proposed a solution to modeling motivation that makes motivation a feature of the environment.	Review	I-Review	5
 Essentially, the reward provided by the environment depends on an extra latent variable and by hiding this (in the cases where the policy does not see motivation inputs), it is quite likely that it becomes too difficult for the value function to predict what is happening (the environment has become partially observed).	Review	I-Review	5
 This seems less a setting where motivation channels solve a problem, and more just an example of an environment that has more complex rules for generating rewards being more challenging to learn about, especially if latent variables are not available to the value function.	Review	I-Review	5
 Critically, it has not been shown that motivational systems are useful for artificial agents, rather the tasks themselves have been designed to attempt to be models of biological motivation.	Review	I-Review	5
 [line_break_token][line_break_token]Personally, I am interested in motivated behaviors and think that future AI developments should take note of this field, but again, the present work does not provide actionable insights into implementing an artificial motivation system.	Review	O	0
 At the same time, this work does not provide interesting enough neurobiological results for those to stand on their own either.	Review	B-Review	1
[line_break_token][line_break_token]Minor clarification:[line_break_token][line_break_token]"trained to perform in realistic tasks" -- the task is very simple.	Review	O	0
 I would consider this a fairly abstract model of the task.	Review	B-Review	3
 [line_break_token]	Review	I-Review	1
e thank the reviewer for careful reading of our paper at least twice and providing the thorough, meaningful, and in depth review.	Reply	O	0
We would like to debate, however, the assessment of value of this work for both neuroscience and machine learning communities and its relevance to the venue.	Reply	O	0
We agree with the reviewer that ‚Äúfuture AI developments should take a note‚Äù of motivated behaviors.	Reply	B-Reply	1
Our overall goal is to facilitate this exchange.	Reply	I-Reply	1
It is also clear that neuroscience community should take notice of many developments in AI.	Reply	I-Reply	1
One of such developments in the hierarchical RL (HRL) that has not been mapped on neural circuits yet.	Reply	I-Reply	1
Our paper proposes that motivational salience, which we call ‚Äòmotivation‚Äô for brevity, may have evolved from modulating simple feeding behaviors to solving more complex hierarchical cognitive tasks.	Reply	I-Reply	1
As such, our paper aims at bridging the gap between HRL community in ML and neuro communities interested in understanding motivated behaviors.	Reply	I-Reply	1
Clearly, building a motivated HRL model is not a task for a single paper.	Reply	I-Reply	1
Our goal was therefore to introduce the concept of motivational salience to the ML community.	Reply	I-Reply	1
In addition, we believe, we have made substantial contributions to computational neuroscience and to understanding of computational algorithms run by circuits in ventral pallidum (VP) as detailed below[line_break_token][line_break_token]1) Our paper presents the first example of neural network processing information about motivational salience.	Reply	O	0
Motivational salience has been described in RL framing before, but the networks processing motivation are missing.	Reply	B-Reply	4
The reviewer may not agree with how we frame the problem, but, perhaps, it is also important to formulate one solution in order to compel community to find alternatives.	Reply	I-Reply	4
Our solution is useful, however, because it helps solve complex computational tasks and allows to make sense of responses of neurons in basal ganglia.	Reply	I-Reply	4
[line_break_token][line_break_token]2) We explain the presence of two oppositely-tuned populations of neurons in VP as resulting from the need to solve temporal credit assignment problem via maintaining working memory about reward expectation between CS and US.	Reply	O	0
[line_break_token][line_break_token]3) Our general framework allows to derive clear experimentally testable predictions about network structure in VP.	Reply	O	0
We use a conventional machine learning algorithm (recurrent network training using backpropagation) to derive the structure of the network in VP from the first principles and show that it should contain inhibitory connections between two populations of neurons.	Reply	B-Reply	2
We agree with the reviewer that backpropagation has been used to train recurrent RL V-networks before, for example, in the neuroscience setting by Song et al. (	Reply	I-Reply	2
2017).	Reply	I-Reply	2
However, Song et al. (	Reply	I-Reply	2
2017) did not show that the network has a push-pull architecture.	Reply	I-Reply	2
Since this particular architecture is known to be important in neural systems, it is valuable to show that the same connectivity can be used in circuits implementing motivated behavior.	Reply	I-Reply	2
We argue that the presence of the push-pull circuit leads to the emergence of the two oppositely tuned populations of neurons.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Overall we suggest that our paper introduces motivational salience as a potential basis of HRL, uses the general machine learning framework based on motivational salience to explain existing experimental data (two populations of neurons), and generates clear experimentally testable predictions about the structure of network of real biological neurons in basal ganglia.	Reply	I-Reply	1
We thus humbly suggest that it makes a substantial contribution to the understanding of the circuit basis of computation involved in motivated behaviors	Reply	I-Reply	1

First, the authors propose to train a model for natural language inference (NLI) on multiple languages simultaneously.	Review	O	0
In particular, they translate English examples into all target languages and fine-tune a pretrained language model on all thereby obtained data at once.	Review	O	0
This is different from the previous state-of-the-art approach which consisted of, after translating from English into target languages, fine-tuning one NLI model for each language individually.	Review	O	0
The authors show that their approach is superior to training individual models for each language.	Review	O	0
For evaluation, XNLI is used.	Review	O	0
[line_break_token][line_break_token]Second, they introduce cross-lingual knowledge distillation (XD), where the same polyglot model is used both as teacher and student across languages to improve its sentence representations without using the target task labels.	Review	O	0
The main idea is that the same sentence in all languages should receive output representations as similar as possible.	Review	O	0
[line_break_token][line_break_token]The paper seems okay to me and the experiments seem solid.	Review	O	0
However, the results are not particularly surprising and the methods are not very innovative.	Review	B-Review	6
The writing could be improved.	Review	I-Review	6
[line_break_token][line_break_token]This paper could further be improved in the following ways:[line_break_token]- A more detailed investigation which combination of languages improve performance (and why?).	Review	O	0
[line_break_token]- Similarly: A combination of MTL and XD doesn't seem straightforward.	Review	O	0
Why?	Review	B-Review	2
What is learned?	Review	I-Review	2
[line_break_token][line_break_token]Smaller comments:[line_break_token]- Articles are missing frequently (e.g., "we substitute the word prediction head with classification layer" -&gt; "we substitute the word prediction head with a classification layer")[line_break_token]- Table 5: "w/0" -&gt; "w/o"?	Review	O	0
[line_break_token]- Have you run any significance tests?	Review	O	0
hank you for your review!	Reply	O	0
We will make sure to improve the writing and clarity of the paper, sorry for making you read a hurried submission.	Reply	O	0
We will definitely incorporate your smaller comments.	Reply	O	0
[line_break_token][line_break_token]We did not run any significance test for the submitted version; since it was suggested by several reviewers, we will do it via bootstrapping, as well as re-run the key models to estimate the variance of their results.	Reply	B-Reply	5
[line_break_token][line_break_token]We agree that a more detailed investigation of language combinations would be exciting, we did our best to explain the motivation for the choices we did in this paper.	Reply	I-Reply	1
We hope to provide a more thorough comparison in the next paper.	Reply	I-Reply	1
[line_break_token][line_break_token]As for ‚ÄúSimilarly: A combination of MTL and XD doesn't seem straightforward.	Reply	O	0
Why?	Reply	O	0
What is learned?‚Äù:[line_break_token]In the case of MTL, data from low-resource unrelated (to English) languages were used just as well as data for resource-rich high-translation-quality languages.	Reply	O	0
Our case studies with particular languages suggest that the quality of the parallel signal matters for XD.	Reply	B-Reply	2
By using XD with only a high-quality parallel signal from high-resource languages we are able to further improve the system learned with multilanguage finetuning that used data from all sources.	Reply	I-Reply	2

This paper looks at the idea of fusing multiple layers (typically a convolution and a LRN or pooling layer) into a single convolution via retraining of just that layer, and shows that simpler, faster models can be constructed that way at minimal loss in accuracy.	Review	O	0
This idea is fine.	Review	O	0
Several issues:[line_break_token]- The paper introduces the concept of a 'Deeprebirth layer', and for a while it seems like it's going to be some new architecture.	Review	O	0
Mid-way, we discover that 1) it's just a convolution 2) it's actually a different kind of convolution depending on whether one fuses serial or parallel pooling layers.	Review	B-Review	1
I understand the desire to give a name to the technique, but in this case naming the layer itself, when it's actually multiple things, non of which are new architecturally, confuses the argument a lot.	Review	I-Review	1
[line_break_token]- There are ways to perform this kind of operator fusion without retraining, and some deep learning framework such as Theano and the upcoming TensorFlow XLA implement them.	Review	O	0
It would have been nice to have a baseline that implements it, especially since most of the additional energy cost from non-fused operators comes from the extra intermediate memory writes that operator fusion removes.	Review	B-Review	2
[line_break_token]- Batchnorm can be folded into convolution layers without retraining by scaling the weights.	Review	O	0
Were they folded into the baseline figures reported in Table 7?	Review	B-Review	3
[line_break_token]- At the time of writing, the authors have not provided the details that would make this research reproducible, in particular how the depth of the fused layers relates to the depth of the original layers in each of the experiments.	Review	O	0
[line_break_token]- Retraining: how much time (epochs) does the retraining take?	Review	O	0
Did you consider using any form of distillation?	Review	B-Review	5
[line_break_token]Interesting set of experiments.	Review	I-Review	5
This paper needs a lot of improvements to be suitable for publication.	Review	I-Review	5
[line_break_token]- Open-sourcing: having the implementation be open-source always enhances the usefulness of such paper.	Review	O	0
Not a requirement obviously.	Review	B-Review	6
[line_break_token][line_break_token]	Review	O	0
(1) I understand the desire to give a name to the technique, but in this case naming the layer itself, when it's actually multiple things, non of which are new architecturally, confuses the argument a lot.	Reply	O	0
[line_break_token][line_break_token]Ans: Well, we name our approach as ‚Äúdeep-rebirth‚Äù because in our proposed speed optimization pipeline, we have replaced multiple deep network layers which run much slower compared to the newly generated and faster layer (e.g., convolution layer in our experiment) like a rebirth.	Reply	B-Reply	1
[line_break_token][line_break_token](2) There are ways to perform this kind of operator fusion without retraining, and some deep learning framework such as Theano and the upcoming TensorFlow XLA implement them.	Reply	O	0
It would have been nice to have a baseline that implements it, especially since most of the additional energy cost from non-fused operators comes from the extra intermediate memory writes that operator fusion removes.	Reply	O	0
[line_break_token][line_break_token]Ans: As far as we know, the operator fusion without retraining can only be applied to some specific structure, i.e.,  batch normalization or mean normalization after convolution.	Reply	B-Reply	2
This kind of operator fusion can‚Äôt be applied to other kinds of layers, such as pooling, LRN, etc.	Reply	I-Reply	2
Our pipeline is much more general.	Reply	I-Reply	2
[line_break_token][line_break_token]The deep learning framework such as Theano and XLA performs the operator fusion to reduce the memory.	Reply	I-Reply	2
However, the execution time of these models may not be accelerated due to the use of same architectures (i.e., performing exactly the same set of floating-point operations).	Reply	I-Reply	2
 If we view them as the baseline, their execution time would be much ‚Äúhigher‚Äù than deep-rebirth.	Reply	I-Reply	2
In contrast, our method re-trained the rebirth layers and significantly speeds up the execution time.	Reply	I-Reply	2
[line_break_token][line_break_token](3) Batchnorm can be folded into convolution layers without retraining by scaling the weights.	Reply	O	0
Were they folded into the baseline figures reported in Table 7?	Reply	O	0
[line_break_token][line_break_token]Ans: We agree that batchnorm can be folded into convolution layer without retraining by scaling the weights.	Reply	B-Reply	3
The results listed in Table 7 also include other layers‚Äô  optimization, e.g., pooling, not limited to batchnorm.	Reply	I-Reply	3
[line_break_token][line_break_token](4) At the time of writing, the authors have not provided the details that would make this research reproducible, in particular how the depth of the fused layers relates to the depth of the original layers in each of the experiments.	Reply	O	0
Open-sourcing: having the implementation be open-source always enhances the usefulness of such paper.	Reply	O	0
Not a requirement obviously.	Reply	O	0
[line_break_token][line_break_token]Ans:  We have listed the details in our revision.	Reply	B-Reply	4
We plan to release the code after final decision.	Reply	I-Reply	4
Our first step for open-source would be the release of the model architectures (in caffe‚Äôs prototxt format) used in our paper.	Reply	I-Reply	4
[line_break_token][line_break_token](5) Retraining: how much time (epochs) does the retraining take?	Reply	O	0
Did you consider using any form of distillation?	Reply	O	0
[line_break_token][line_break_token]Ans: Each step of our optimization pipeline takes around 2 epochs (in section 4.1.1).	Reply	B-Reply	5
For GoogleNet, it takes 9 steps and 18 epochs.	Reply	I-Reply	5
We regard this training time (or rebirth time) as a one-time cost and once trained it can be deployed to any mobile devices.	Reply	I-Reply	5
[line_break_token][line_break_token]Our ‚Äúrebirth‚Äù method can be considered as a special form of distillation that transfers the knowledge from the cumbersome substructure of multiple layers to the rebirthed accelerated substructure.	Reply	I-Reply	5
Different from traditional distillation method, our approach adopts layer-wise optimization and maintains the knowledge of the rest layers.	Reply	I-Reply	5
Also, our method utilizes a softmax at the end of our CNN to optimize classification accuracy.	Reply	I-Reply	5
[line_break_token][line_break_token](6) Interesting set of experiments.	Reply	O	0
This paper needs a lot of improvements to be suitable for publication.	Reply	O	0
[line_break_token][line_break_token]Ans: Thanks for your appreciation of our paper.	Reply	B-Reply	6
We are constantly improving the quality of our paper.	Reply	I-Reply	6

This paper studies knowledge transfer problem from small capacity network to bigger one.	Review	B-Review	3
This is a follow-up work of Net2Net (ICLR 2015) and NetMorph(ICML 2016).	Review	O	0
 [line_break_token]Comments[line_break_token]- 1) This paper studies macroscopic problem, with the morphing process composed by multiple atomic operations.	Review	O	0
While the atomic operations are proposed in Net2Net and NetMorph, there has not been study of the general modularized process principally.	Review	B-Review	1
Thus this paper asks a novel question.	Review	I-Review	1
[line_break_token]- 2) The solution by composing multiple atomic transformations seems to be quite reasonable.	Review	O	0
[line_break_token]- 3) In the ‚Äúrelated work‚Äù section, it is better to change ‚Äúnetwork morphism‚Äù to ‚Äúknowledge transfer‚Äù or in the subsection title, most of these works are known as knowledge transfer and it helps to connect to the existing works.	Review	O	0
[line_break_token]- 4) The author shows experiments on variants of ResNet.	Review	O	0
While the experiment shows that initializing from ResNet gives better error rate than the ones trained from scratch, it is unclear what the source This paper studies knowledge transfer problem from small capacity network to bigger one.	Review	B-Review	3
This is a follow-up work of Net2Net (ICLR 2015) and NetMorph(ICML 2016).	Review	O	0
 [line_break_token]Comments[line_break_token]- 1) This paper studies macroscopic problem, with the morphing process composed by multiple atomic operations.	Review	O	0
While the atomic operations are proposed in Net2Net and NetMorph, there has not been study of the general modularized process principally.	Review	B-Review	1
Thus this paper asks a novel question.	Review	I-Review	1
[line_break_token]- 2) The solution by composing multiple atomic transformations seems to be quite reasonable.	Review	O	0
[line_break_token]- 3) In the ‚Äúrelated work‚Äù section, it is better to change ‚Äúnetwork morphism‚Äù to ‚Äúknowledge transfer‚Äù or in the subsection title, most of these works are known as knowledge transfer and it helps to connect to the existing works.	Review	O	0
[line_break_token]- 4) The author shows experiments on variants of ResNet.	Review	O	0
While the experiment shows that initializing from ResNet gives better error rate than the ones trained from scratch, it is unclear what the source is.	Review	O	0
[line_break_token]- 5) One major advantage of this type of knowledge transfer (Net2Net, NetMorph) is to speedup training and model exploration.	Review	O	0
There seems to be no experiments demonstrate such advantage (possibly due to the lose initialization of BatchNorm).	Review	B-Review	4
This is the major drawback of this paper.	Review	I-Review	4
[line_break_token]-6)  The method proposed by the author can in principle do quite complicated transformation, e.g. transform  an entire resnet from a single conv layer, the experiment only consists of simple module transformations, which in some way can be covered by atomic operations.	Review	O	0
It would be more interesting to see what the results of more complicated transformations are (even if they are not as effective).	Review	O	0
[line_break_token][line_break_token]In summary, this paper studies a novel problem of knowledge transfer in a macroscopic level.	Review	O	0
The method could be of interest to the ICLR community.	Review	O	0
The experiments should be improved (comment 5) to make the results more convincing and practically useful and I strongly encourage the authors to do so.	Review	B-Review	4
[line_break_token]	Review	O	0
We appreciate the recognition and detailed comments from Reviewer #4, and have the following responses to address the concerns.	Reply	O	0
[line_break_token][line_break_token]3) In the ‚Äúrelated work‚Äù section, it is better to change ‚Äúnetwork morphism‚Äù to ‚Äúknowledge transfer‚Äù or in the subsection title, most of these works are known as knowledge transfer and it helps to connect to the existing works.	Reply	O	0
[line_break_token][line_break_token]We have made the change as suggested.	Reply	B-Reply	2
[line_break_token][line_break_token]4) The author shows experiments on variants of ResNet.	Reply	O	0
While the experiment shows that initializing from ResNet gives better error rate than the ones trained from scratch, it is unclear what the source is.	Reply	O	0
[line_break_token][line_break_token]When available, the results were cited from their original papers.	Reply	B-Reply	3
For example, the accuracies of ResNet on the CIFAR10 dataset in Table 1 were from [He2015]. For other ones that cannot be found in any existing paper, we trained the models by ourselves.	Reply	I-Reply	3
[line_break_token][line_break_token]5) One major advantage of this type of knowledge transfer (Net2Net, NetMorph) is to speedup training and model exploration.	Reply	O	0
There seems to be no experiments demonstrate such advantage (possibly due to the lose initialization of BatchNorm).	Reply	O	0
This is the major drawback of this paper.	Reply	O	0
[line_break_token][line_break_token]It has been verified in our previous work [Wei2016] that VGG16 could be easily morphed into a 19-layer network (NetMorph-VGG16), with a 15x speedup compared with training from scratch. (	Reply	B-Reply	4
NetMorh-VGG16 performed better than both VGG16 and VGG19.)	Reply	I-Reply	4
In this work, our focus is to study the macroscopic problem of network morphism, i.e., modularized morphing.	Reply	I-Reply	4
Thus we adopted a uniform training procedure for both of these two learning schemes.	Reply	I-Reply	4
Therefore, the training time for network morphism is the same as training from scratch in this research.	Reply	I-Reply	4
But the training can be greatly speeded up as in [Wei2016], which however is not our focus in this research.	Reply	I-Reply	4
[line_break_token][line_break_token]It is much cheaper to adopt network morphism to explore and design a new effective network architecture.	Reply	I-Reply	4
For example, for the network architectures illustrated in Fig.	Reply	I-Reply	4
4, we simply split the branches to compose new modules, which does not require domain-specific knowledge.	Reply	I-Reply	4
However, designing such a new network architecture via training from scratch requires significant insight to the network architectures, and it is also hard to tell whether the newly designed network will achieve a better performance until it is fully trained.	Reply	I-Reply	4
[line_break_token][line_break_token]Another advantage when exploring new network architectures with network morphism is that, one can quickly check whether a morphed architecture deserves further exploration by continuing to train the morphed network in a finer learning rate (e.g. 1e-5), to see if the performance is improved.	Reply	I-Reply	4
Hence, one does not have to wait for days or even months of training time to tell whether the new network architecture will achieve a better performance.	Reply	I-Reply	4
This could significantly save human time for deciding which network architecture is worth for exploring.	Reply	I-Reply	4
[line_break_token] [line_break_token]For BatchNorm, it is not a problem in our proposed algorithms.	Reply	I-Reply	4
While it will cause the morphed network not to exactly preserve the network function, this small perturbation introduced by BatchNorm actually will not affect the performance of the morphed network.	Reply	I-Reply	4
We observed almost identical accuracies for the original network and the morphed network before continual training.	Reply	I-Reply	4
This was stated in the last paragraph of Section 3.7.	Reply	I-Reply	4
[line_break_token][line_break_token]6) The method proposed by the author can in principle do quite complicated transformation, e.g. transform an entire resnet from a single conv layer, the experiment only consists of simple module transformations, which in some way can be covered by atomic operations.	Reply	O	0
It would be more interesting to see what the results of more complicated transformations are (even if they are not as effective).	Reply	O	0
[line_break_token][line_break_token]This is a very good suggestion.	Reply	B-Reply	5
Theoretically, an entire ResNet could be morphed from a single convolutional layer.	Reply	I-Reply	5
However, intuitively, this will not be that effective as the change to the network architecture is too large.	Reply	I-Reply	5
Instead, we proposed to grow the network depth in an exponential order by network morphism.	Reply	I-Reply	5
It was demonstrated to be very effective.	Reply	I-Reply	5
This is not trivial topic, and we have organized the findings in another paper which is under review.	Reply	I-Reply	5

Pros:[line_break_token]The paper is easy to read.	Review	O	0
Logic flows naturally within the paper.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]1.	Review	O	0
Experimental results are neither enough nor convincing.	Review	O	0
[line_break_token][line_break_token]Only one set of data is used throughout the paper: the Cifar10 dataset, and the architecture used is only a 100 layered MLP.	Review	B-Review	1
Even though LCW performs better than others in this circumstance, it does not prove its effectiveness in general or its elimination of the gradient vanishing problem.	Review	I-Review	1
For the 100 layer MLP, it's very hard to train a simple MLP and the training/testing accuracy is very low for all the methods.	Review	I-Review	2
More experiments with different number of layers and different architecture like ResNet should be tried to show better results.	Review	I-Review	3
[line_break_token][line_break_token]In Figure (7), LCW seems to avoid gradient vanishing but introduces gradient exploding problem.	Review	I-Review	4
[line_break_token][line_break_token]The proposed concept is only analyzed in MLP with Sigmoid activation function.	Review	I-Review	5
In the experimental parts, the authors claim they use both ReLU and Sigmoid function, but no comparisons are reflected in the figures.	Review	I-Review	5
[line_break_token][line_break_token]2.	Review	I-Review	10
The whole standpoint of the paper is quite vague and not very convincing.	Review	I-Review	6
[line_break_token]In section 2, the authors introduce angle bias and suggest its effect in MLPs that with random weights, showing that different samples may result in similar output in the second and deeper layers.	Review	I-Review	6
However, the connection between angle bias and the issue of gradient vanishing lacks a clear analytical connection.	Review	I-Review	6
The whole analysis of the connection is built solely on this one sentence "At the same time, the output does not change if we adjust the weight vectors in Layer 1", which is nowhere verified.	Review	I-Review	6
[line_break_token][line_break_token]Further, the phenomenon is only tested on random initialization.	Review	I-Review	7
When the network is trained for several iterations and becomes more settled, it is not clear how "angle affect" affects gradient vanishing problem.	Review	I-Review	7
[line_break_token][line_break_token][line_break_token]Minors:[line_break_token]1.	Review	O	0
Theorem 1,2,3 are direct conclusions from the definitions and are mis-stated as Theorems.	Review	O	0
[line_break_token][line_break_token]2. '	Review	O	0
patters' -> 'patterns'[line_break_token][line_break_token]3.	Review	O	0
In section 2.3, reasons 1 and 2 state the similar thing that output of MLP has relatively small change with different input data when angle bias occurs.	Review	B-Review	10
Only reason 1 mentions the gradient vanishing problem, even though the title of this section is "Relation to Vanishing Gradient Problem".	Review	I-Review	10
[line_break_token]	Review	O	0
We thank the reviewer for the insightful comments on our paper.	Reply	O	0
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 1: Only one set of data is used throughout the paper: the Cifar10 dataset, and[line_break_token]the architecture used is only a 100 layered MLP.	Reply	O	0
[line_break_token][line_break_token]Response 1: We did additional experiments with the SVHN dataset and the CIFAR-100 dataset[line_break_token]for each of which we trained 5 layered, 50 layered, and 100 layered MLPs.	Reply	O	0
[line_break_token]Results are shown in Figure 12, Figure 14, and Figure 15 in the revised manuscript.	Reply	B-Reply	1
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 2: For the 100 layer MLP, it's very hard to train a simple MLP and the[line_break_token]training/testing accuracy is very low for all the methods.	Reply	O	0
[line_break_token][line_break_token]Response 2: We do not agree to the comment.	Reply	O	0
The training accuracy for CIFAR-10 or SVHN dataset[line_break_token]is high for the 100 layer MLP, if we apply LCW (proposed method) or batch normalization,[line_break_token]as shown Figure 12 (a) and Figure 14 (a) in the revised manuscript.	Reply	B-Reply	2
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 3: More experiments with different number of layers and different architecture[line_break_token]like ResNet should be tried to show better results.	Reply	O	0
[line_break_token][line_break_token]Response 3: As mentioned in Response 1, we did experiments with several sizes of MLPs.	Reply	O	0
[line_break_token]We also tried ResNet, but it was unable to train ResNet with LCW.	Reply	B-Reply	3
This is mainly because[line_break_token]ReLU is used in ResNet, and the gradient explosion explained in Section 5.2 occurs.	Reply	I-Reply	3
[line_break_token]We are now developing methods that make LCW applicable to ReLU nets, including ResNet.	Reply	I-Reply	3
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 4: In Figure (7), LCW seems to avoid gradient vanishing but introduces gradient exploding problem.	Reply	O	0
[line_break_token][line_break_token]Response 4: We agree to the comment.	Reply	O	0
We have added an explanation on these points to the[line_break_token]second paragraph of Section 6 in the revised manuscript.	Reply	B-Reply	4
[line_break_token][line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 5: The proposed concept is only analyzed in MLP with Sigmoid activation function.	Reply	O	0
[line_break_token]In the experimental parts, the authors claim they use both ReLU and Sigmoid function,[line_break_token]but no comparisons are reflected in the figures.	Reply	O	0
[line_break_token][line_break_token]Response 5: We omitted results with ReLU in the figures, because MLPs with ReLU were not[line_break_token]trainable at all when LCW is applied, as mentioned in Section 5.2.	Reply	O	0
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 6: In section 2, the authors introduce angle bias and suggest its effect in MLPs that[line_break_token]with random weights, showing that different samples may result in similar output in the second[line_break_token]and deeper layers.	Reply	O	0
However, the connection between angle bias and the issue of gradient[line_break_token]vanishing lacks a clear analytical connection.	Reply	O	0
The whole analysis of the connection is built[line_break_token]solely on this one sentence "At the same time, the output does not change if we adjust the[line_break_token]weight vectors in Layer 1", which is nowhere verified.	Reply	O	0
[line_break_token][line_break_token]Response 6: We have enriched the explanation in Section 2.1 in the revised manuscript,[line_break_token]denoting that the shrinking of the distribution of the angle between the weight vector and the[line_break_token]activation vector is a reason for why the activation becomes almost constant in deep layers.	Reply	O	0
[line_break_token]Moreover, we have added analytical results in Section 2.3 that examine the relationship[line_break_token]between the constant activation in deeper layers and the vanishing gradient of weights.	Reply	B-Reply	6
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 7: The phenomenon is only tested on random initialization.	Reply	O	0
When the network is trained[line_break_token]for several iterations and becomes more settled, it is not clear how "angle affect" affects[line_break_token]gradient vanishing problem.	Reply	O	0
[line_break_token][line_break_token]Response 7: We have added Figures 8 and 9, which show the activation and the distribution of[line_break_token]angles in a MLP with sigmoid activation, respectively, after 10 epochs training.	Reply	O	0
[line_break_token]We have also added discussions on these figures to the third paragraph of Section 3.1.1 in[line_break_token]the revised manuscript.	Reply	B-Reply	7
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 8: Theorem 1,2,3 are direct conclusions from the definitions and are mis-stated as Theorems.	Reply	O	0
[line_break_token][line_break_token]Response 8: We have modified the manuscript to refer to these statements as propositions instead of theorems.	Reply	O	0
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 9: 'patters' -> 'patterns'[line_break_token][line_break_token]Response 9: In accordance with the comment, we have modified the expression.	Reply	O	0
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 10: In section 2.3, reasons 1 and 2 state the similar thing that output of MLP has relatively[line_break_token]small change with different input data when angle bias occurs.	Reply	O	0
Only reason 1 mentions the gradient[line_break_token]vanishing problem, even though the title of this section is "Relation to Vanishing Gradient Problem".	Reply	O	0
[line_break_token][line_break_token]Response 10: In accordance with the comment, we have deleted the second reason from the manuscript.	Reply	O	0
[line_break_token]Also, we have enriched the explanation related to reason 1, as mentioned in Response 6.	Reply	B-Reply	10

This paper discusses the problem of evaluating and diagnosing the representations learnt using a generative model.	Review	O	0
This is a very important and necessary problem.	Review	O	0
[line_break_token][line_break_token]However, this paper lacks in terms of experimental evaluation and has some technical flaws.	Review	O	0
[line_break_token]1.	Review	O	0
Morphological properties deals with only the "shape" properties of the image object.	Review	B-Review	1
However, when the entire image is subject to the generative model, it learns multiple properties from the image apart from shape too - such as texture and color.	Review	I-Review	1
Additionally, there are lot of low level pixel relations that the model learns to fit the distribution of the given images.	Review	I-Review	1
However, here the authors have assumed that the latent space of the generative models are influenced only by the morphological properties of the image - which is wrong.	Review	I-Review	1
Latent space features could be affected by the color or texture of the image as well.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
Extracting morphological properties of the image is straight-foward for MNIST kind of objects.	Review	B-Review	2
However, it becomes really difficult for other datasets such as CIFAR or some real world images.	Review	I-Review	2
Studying the properties of a generative model on such datasets is very challenging and the authors have not added a discussion around that.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
Now assuming that my GAN model has learnt good representation in Morpho-MNIST dataset, is it guaranteed to learn good representations in other datasets as well?	Review	B-Review	3
There is no guarantee on generalizability or extensibility of the work.	Review	I-Review	3
We thank the reviewer for acknowledging the importance of the problem we aimed to address, however, we very much disagree with the statements made regarding our assumptions.	Reply	O	0
[line_break_token][line_break_token]Regarding the reviewer‚Äôs first point, we believe there is a misunderstanding.	Reply	B-Reply	1
We absolutely agree that a generative model needs to learn about colour, texture, and low-level pixel relations to be able to extract its representations and to produce reasonable samples.	Reply	I-Reply	1
Regarding the reviewer‚Äôs statement that ‚Äúthe authors have assumed that the latent space of the generative models are influenced only by the morphological properties of the image‚Äù, we would like to stress that we never made such assumptions nor have we claimed that the latent space of models trained on MNIST capture exclusively shape variations.	Reply	I-Reply	1
What the Morpho-MNIST methodology aims to answer is: ‚Äúto what extent has my model learned to represent these specific factors of variation in the data?‚Äù If colour and texture are important factors for a given application or dataset, it suffices to design the relevant scalar metrics and include them in the very same framework.	Reply	I-Reply	1
[line_break_token][line_break_token]This brings us to the second point.	Reply	I-Reply	2
As far as we are aware, this is the first attempt in *any* context to quantitatively characterise inferential and generative behaviour of learned representations.	Reply	I-Reply	2
We propose to do it in terms of measurable features: here we exploit shape attributes, and in the conclusion we point to various possible extensions involving colours or object properties.	Reply	I-Reply	2
In our view, it just makes sense that the first step in that direction builds on a simple dataset with well understood and easily measurable factors of variation.	Reply	I-Reply	2
[line_break_token][line_break_token]Finally, although it is correct that there are no generalisability guarantees, that is the case for any model evaluated on MNIST, CIFAR-10, or even ImageNet (cf.	Reply	I-Reply	3
<a href="https://arxiv.org/abs/1806.00451," target="_blank" rel="nofollow">https://arxiv.org/abs/1806.00451,</a> for example).	Reply	O	0
As argued above, we are proposing a toolset to inspect and diagnose trained generative models that works with any collection of measurable attributes.	Reply	B-Reply	3
Evidently conclusions may not be transferable if the datasets have different relevant attributes	Reply	I-Reply	3

The authors find 2 issues with Adversarial Imitation Learning-style algorithms: I) implicit bias in the reward functions and II) despite abilities of coping with little data, high interaction with the environment is required.	Review	O	0
The authors suggest "Discriminator-Actor-Critic" - an off-policy Reinforcement Learning reducing complexity up to 10 and being unbiased, hence very flexible.	Review	O	0
[line_break_token][line_break_token]Several standard tasks, a robotic, and a VR task are used to show-case the effectiveness by a working implementation in TensorFlow Eager.	Review	O	0
[line_break_token][line_break_token]The paper is well written, and there is practically no criticism.	Review	O	0
[line_break_token][line_break_token]	Review	O	0
We thank the reviewer for the feedback and appreciate the strong recommendation.	Reply	O	0

The motivation of the paper is to be able to train low precision networks to a high-accuracy.	Review	O	0
Quantization is a useful tool in model compression, and doing it well for very low-precision models (2-3 bit precision specifically), is challenging.	Review	O	0
[line_break_token][line_break_token]The main contribution of the paper comes from:[line_break_token]a) Step Size Gradient: They propose a gradient which is sensitive to the distance between the value and the transition point.	Review	O	0
This is different from other methods which have gradients dependent only on the clip point.	Review	O	0
[line_break_token]b) Step Size Gradient Scale: This is an interesting contribution, where they try to match the ratio of average update of the step size ‚Äòs‚Äô and average magnitude of ‚Äòs‚Äô, with that of the network weights.	Review	O	0
This leads them to scale the gradient according to the precision and number of parameters.	Review	O	0
They demonstrate that this scaling actually helps improve the accuracy.	Review	O	0
[line_break_token][line_break_token]The results for 8-bit precision are not new.	Review	O	0
Several results (Quantization and Training of Neural Networks for Efficient[line_break_token]Integer-Arithmetic-Only Inference, Jacob et al.,	Review	O	0
Quantizing deep convolutional networks for[line_break_token]efficient inference: A whitepaper, Krishnamoorthi et al.),	Review	O	0
show 8-bit quantization results where the accuracy matches floating point accuracy, and in some case exceeds it (low precision quantization acting as a regularizer).	Review	O	0
However, the results for lower precision are impressive.	Review	O	0
[line_break_token][line_break_token]There are a few questions:[line_break_token]1.	Review	O	0
In sec 2.1, you mention that ‚Äòeach layer of weights and activations has a distinct step size, represented as an fp32 value, initialized to ‚Ä¶‚Äô.	Review	B-Review	1
Can you explain the intuition behind the initial value of the step size, and how is it a function of v?	Review	I-Review	1
[line_break_token]2. ‚	Review	O	0
ÄòModel Compression via Distillation and Quantization‚Äô (Polino et al.)	Review	B-Review	2
shows distillation actually helps significantly improve accuracy.	Review	I-Review	2
I wonder if the authors have tried different weight combinations for the distillation loss, and using bigger models as teacher models.	Review	I-Review	2
[line_break_token]3.	Review	O	0
I would like to get more details of the inference setup, specifically the size and inference latency improvements over full-precision networks.	Review	B-Review	3
The practical applicability of low-precision networks, specifically 2-bit and 3-bit networks, equally depends on the inference infrastructure, as it does on the training improvements.	Review	I-Review	3
[line_break_token]4.	Review	O	0
Have you evaluated your method for a non-Vision usecase?	Review	B-Review	4
[line_break_token][line_break_token]Overall this is a good work, I would tend towards accepting this.	Review	O	0
[line_break_token]	Review	O	0
Question 1:[line_break_token]We expect that a step size that provides a reasonable quantization of some data, "v", should scale with the magnitude of that data (captured by "&lt;|v|&gt;"), so that the values are reasonably spread across the bins of the quantizer.	Reply	O	0
 We also expect that as the number of quantized states increases, the step size itself should decrease, so that the data can be quantized more finely (captured by "1/sqrt(Q)").	Reply	B-Reply	1
 The particular heuristic we chose worked well in practice to give a reasonably good initial quantization that could then be further improved through training.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Question 2:[line_break_token]Knowledge distillation for quantized networks is certainly an interesting area for research, but we didn't want to expand the focus of our manuscript too far beyond the quantizer training method proposed, particularly as Polino et al.	Reply	O	0
and Mishra and Marr already have provided a good overview of knowledge distillation in this domain.	Reply	B-Reply	2
 Thus, we chose to show only the simplest knowledge distillation setup we are are aware of, distilling from a full precision teacher to a low precision student network with the same architecture.	Reply	I-Reply	2
 This approach offers has the benefit that the same trained high precision network used for weight initialization also serves as our teacher, and thus no additional networks are required, whereas distilling from a larger architecture would require training (or otherwise having access to) an additional network.	Reply	I-Reply	2
 However, we have since run an experiment to look at different weights on the distillation loss, and now note in section 3.7: "we used the distillation loss function of Hinton with temperature of 1 and equal weight given to the standard loss and the distillation loss (we found this gave comparable results to weighting the the distillation loss two times more or less than the standard loss on 2-bit ResNet-18)."	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]Question 3:[line_break_token]To show the reduction in model size offered by lower precision models, we have modified Figure 3 to include full precision model sizes.	Reply	O	0
[line_break_token][line_break_token]We did not measure latency or related performance metrics on actual hardware, as our approach was developed in advance of commercially available inference hardware optimized for low precision operations.	Reply	B-Reply	3
 Since algorithms are much cheaper to develop than new hardware, we believe it is the correct first step to demonstrate the ability of deep networks to achieve high accuracy at these extremely low precisions before hardware is created to optimize for these precisions.	Reply	I-Reply	3
 As new low precision inference chips become available, we look forward to benchmarking these low precision networks against full precision alternatives.	Reply	I-Reply	3
 [line_break_token][line_break_token][line_break_token]Question 4:[line_break_token]While we have not done so yet due to time constraints, we anticipate evaluating this approach for domains beyond vision as a next step in our research.	Reply	O	0

The motivation of the work is not clear but the novelty seems to be present.	Review	B-Review	1
[line_break_token][line_break_token]The paper is very hard to follow as the problem description and intuition of the D-GAN is not clearly written.	Review	I-Review	2
[line_break_token][line_break_token]Based on the experiments, the proposed method achieves marginal improvement in terms of F1 score but sometimes also slightly lower performance than other GAN based such as PGAN, so the impact of this work to solve positive unlabelled data problem is not evident.	Review	I-Review	3
[line_break_token][line_break_token]I am personally not as familiar with the PU problem and existing frameworks so my confidence in the assessment is low; my main experience is in the computer vision for autonomous driving and sparse coding.	Review	O	0
[line_break_token][line_break_token]But my feeling is this paper is marginally below the threshold of acceptance.	Review	O	0
Thanks for your review,[line_break_token][line_break_token]Firstly we apologize for not making the text clear enough.	Reply	O	0
[line_break_token]We hope the following answers to your respective points will clarify the proposed contributions.	Reply	O	0
[line_break_token][line_break_token][line_break_token]***[line_break_token][line_break_token]‚ÄúThe motivation of the work is not clear‚Äù[line_break_token][line_break_token]Motivations can be expressed as follow.	Reply	O	0
[line_break_token]1: Overcome the previous state of the art approaches disadvantages.	Reply	B-Reply	1
[line_break_token]      -[tab_token]GenPU architecture is more computational demanding (three discriminators and two generators) than standard GAN architectures (one discriminator and one generator).	Reply	I-Reply	1
Furthermore, GenPU requires prior knowledge and additional loss function hyper-parameters.	Reply	I-Reply	1
[line_break_token]      -[tab_token]The PGAN method has overfitting issues on simple datasets (see figure 6. (	Reply	I-Reply	1
b)) because its approach is based on GANs imperfections.	Reply	I-Reply	1
[line_break_token][line_break_token]2: A framework easily adaptable to GANs variants.	Reply	O	0
[line_break_token]      -[tab_token]A GAN PU framework similar to standard GAN could enable a better adaptability to last and potentially future GANs variants.	Reply	B-Reply	1
It is an important point because the state of the art is updated continuously but the architectures remain similar (one generator and one discriminator).	Reply	I-Reply	1
[line_break_token][line_break_token]3: Adversarial training of GAN-based approaches enables to learn automatically relevant high level feature metrics.	Reply	O	0
[line_break_token]      -[tab_token]GANs generate semantically realistic images.	Reply	B-Reply	1
The most interesting aspect is probably that the error computed to evaluate the generated images quality is estimated from a high level feature point of view: the discriminator output.	Reply	I-Reply	1
In this way, GANs enable relevant data augmentation.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]***[line_break_token][line_break_token]‚Äúthe novelty seems to be present‚Äù[line_break_token][line_break_token]The two article contributions can be highlighted as follow.	Reply	O	0
[line_break_token][line_break_token][line_break_token]Contribution 1: We propose to incorporate a PU risk inside the discriminator loss function.	Reply	B-Reply	1
[line_break_token][line_break_token]We show that a GAN can solve by itself a Positive Unlabeled learning task if the problem is well formulated: We combine a PU risk with the GAN discriminator loss function.	Reply	I-Reply	1
That enables the G convergence to the distribution of counter-examples included in the unlabeled dataset.	Reply	I-Reply	1
[line_break_token][line_break_token]Previous GAN-based PU approaches do not include the PU risk in the discriminator cost function.	Reply	I-Reply	1
GenPU and PGAN logics are as follow:[line_break_token]      -[tab_token]GenPU convergence is inspired by the original GAN convergence exposed by GoodFellow in 2014.	Reply	I-Reply	1
The main idea is in this sentence: ‚ÄúDu is aimed at separating the unlabelled training samples from the fake samples of both Gp and Gn‚Äù.	Reply	I-Reply	1
Thus the global system GenPU enables the convergence ‚Äúpi Pgp + (1-pi) Pgn -> Pu‚Äù, with Pgp the distribution of positive samples generated by Gp, Pgn the distribution of the negative samples generated by Gn, and Pu the distribution of unlabeled samples.	Reply	O	0
However, the same reasoning can be expressed using one single generator Gn if we replace the generated positive samples by the positive labeled samples that we have in a PU dataset.	Reply	B-Reply	1
Thus training five different models is not necessary to address standard PU learning challenge where we have enough positive samples.	Reply	I-Reply	1
This reasoning is different to the propose one.	Reply	I-Reply	1
[line_break_token]      -[tab_token]PGAN is trained to converge towards the unlabeled dataset distribution during the first step.	Reply	I-Reply	1
The PGAN exploits GANs imperfections such that the generated distribution at the adversarial equilibrium is still separable from the unlabeled samples distribution by a classifier.	Reply	I-Reply	1
The PGAN does not use a PU learning risk to train its GAN part.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]Contribution 2: Highlight of a critical normalization issue discussed in the context of the proposed framework[line_break_token][line_break_token]Batch-normalization (BN) technique cannot be used when several minibatches distributions (unlabeled, positive, and generated ones) are used to train a learning model.	Reply	I-Reply	1
[line_break_token][line_break_token]With BN, a classifier prediction for a given sample is critically influenced by the other samples of the same minibatch.	Reply	I-Reply	1
As presented in the article, the consequence with a PU learning risk is that BN does not allow a classifier to distinguish positive from negative samples (see figure 5(a) and subsections 2.3 and 3.1).	Reply	I-Reply	1
These sections include the analysis of this BN effect and alternative normalization solutions, such that this effect disappears.	Reply	I-Reply	1
[line_break_token][line_break_token]In practice, a D-GAN using BN converges towards the unlabeled samples distribution.	Reply	I-Reply	1
Without, it converges exclusively towards the negative samples distribution.	Reply	I-Reply	1
The normalization training impact is clearly highlighted in the figure 5.	Reply	I-Reply	1
[line_break_token]To the best of our knowledge, we are the first to highlight this critical phenomenon for the PU learning task.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]***[line_break_token][line_break_token]‚Äú intuition of the D-GAN is not clearly written.	Reply	O	0
‚Äù [line_break_token][line_break_token]The D-GAN intuition can be expressed as follow.	Reply	O	0
The discriminator D addresses to the generator G the riddle: [line_break_token]‚ÄúShow me what IS unlabeled AND NOT positive.	Reply	B-Reply	2
‚Äù[line_break_token]It turns out that negative samples included in the unlabeled dataset are both unlabeled and not positive.	Reply	I-Reply	2
Consequently G addresses this riddle by learning to show the negative samples distribution to D.	Reply	I-Reply	2

Motivated by a link between LSTMs and counter machines (suggested by recent work, e.g. Merrill, 2019 et al.),	Review	O	0
this paper studies the formal properties of counter machines (and LSTMs by extension) as grammars, in hopes of discovering why LSTMs perform particularly well in language tasks despite having no obvious hierarchical structure.	Review	O	0
[line_break_token][line_break_token]It makes the following contributions.	Review	O	0
It shows that: (1) many variants of counter machine converge to the same formal language, (2) the counter languages are closed under common set operations (e.g. intersection, union, and complement), (3) counter machines are incapable of evaluating boolean expressions, and (4) only a weak subclass of CLs are sublinear (and most are not).	Review	O	0
[line_break_token][line_break_token]While this paper gives thorough proofs, I would have liked to see more connection to practical NLP with some experiments.	Review	B-Review	1
Also, I would have liked to see more concrete takeaways from this paper: if correctly detecting surface patterns doesn't mean that LSTMs build correct semantic representations, what can ensure that LSTMS do have a correct semantic representation?	Review	I-Review	2
[line_break_token][line_break_token]As this paper is far from my area of expertise, I'm willing to change my score based on my co-reviewers.	Review	O	0
hank you for your review.	Reply	O	0
We agree that experiments would make the connection to modern NLP more concrete.	Reply	B-Reply	1
As an initial direction, we have conducted an experiment comparing the ability of LSTMs to 1) evaluate boolean expressions and 2) verify their well-formedness.	Reply	I-Reply	1
If accepted, we will include this in a revised version.	Reply	I-Reply	1
[line_break_token][line_break_token]Another experimental followup we have begun is evaluating pre-trained language models by assessing their ability to perform semantic evaluation of natural language.	Reply	I-Reply	3
However, we believe this larger effort is beyond the scope of this paper.	Reply	I-Reply	3
We think the community could benefit from our paper because it provides context for such future work, either by ourselves or others	Reply	I-Reply	3

This paper proposes an approach to building random forests that are[line_break_token]balanced in such a way as to facilitate domain adaptation.	Review	O	0
The authors[line_break_token]propose to split nodes not only based on the Information Gain, but[line_break_token]also so that the sizes of each set passed to left and right children[line_break_token]are equal.	Review	O	0
Another extension to the standard random forest training[line_break_token]procedure is the use of a collaborative term subtracted from the[line_break_token]information gain over the source domain.	Review	O	0
This term encourages[line_break_token]alignment of the source and target domains in the leaves of trees in[line_break_token]the forest.	Review	O	0
Experimental results are given on a range of standard[line_break_token]and open-set domain adaptation datasets.	Review	O	0
[line_break_token][line_break_token]The paper has a number of issues:[line_break_token][line_break_token]1.	Review	O	0
There are some problems with clarity, and the English is somewhat rough[line_break_token]   throughout.	Review	B-Review	1
These problems are not terribly distracting, but the[line_break_token]   manuscript could use more polish.	Review	I-Review	1
[line_break_token]2.	Review	O	0
I don't see a detailed discussion anywhere about the[line_break_token]   hyperparameters used for fitting the random forests.	Review	B-Review	2
How many trees[line_break_token]   are used?	Review	I-Review	2
What is the max depth?	Review	I-Review	2
These parameters should be[line_break_token]   discussed and included in the ablations in order to appreciate the[line_break_token]   complexity/performance tradeoffs.	Review	I-Review	2
[line_break_token][line_break_token]This paper has some interesting ideas in it, and the experimental[line_break_token]results are excellent.	Review	O	0
I would encourage the authors to move salient[line_break_token]material from the supplementary material to the main article and to[line_break_token]provide a more thorough discussion of the complexity of the models[line_break_token](the structural parameters of the trees/forests).	Review	B-Review	2
hank you for helpful comments on our paper.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
We will revise the paper to improve readability.	Reply	B-Reply	1
We will do our best to refine the rough expressions of the paper.	Reply	I-Reply	1
We are working on improving the paper, and we will make it better for the final version.	Reply	I-Reply	1
It would be greatly appreciated if more detailed comments could be provided.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	I-Reply	2
We added hyperparameter settings such as the number of trees, maximum depth, feature dimensionality of the SVM training, and the number of repeats in training a random forest to page 6.	Reply	I-Reply	2
We also supplemented the ablation study with regard to the number of trees and maximum depths in Table 3.	Reply	I-Reply	2
In the ablation study, the maximum depth is 8 with 100 decision trees to consider both accuracy and complexity.	Reply	I-Reply	2
[line_break_token][line_break_token]‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî--Revised paper ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-[line_break_token]To train the CoBRF, we use 100 trees with a maximum depth of 8.	Reply	I-Reply	2
[line_break_token]When there is no training data fallen on a node, we prune the tree at that node.	Reply	I-Reply	2
[line_break_token]The number of randomly selected feature dimension for the SVM training is set to 250.	Reply	I-Reply	2
[line_break_token]The input feature of SVM is normalized for the stable learning of the hyperplane.	Reply	I-Reply	2
[line_break_token]We repeat the SVM training 15 times to select the optimal split in each node.	Reply	I-Reply	2
[line_break_token][line_break_token]   Depth | The number of trees (T)[line_break_token]               |  5 | 10 | 50 | 100 |  [line_break_token]      6   | 62.2 | 65.4 | 67.5 | 67.7 |[line_break_token]      7   | 60.2 | 63.5 | 67.1 | 67.8 |[line_break_token]      8   | 58.9 | 63.3 | 67.5 | 68.0 |[line_break_token]      9   | 55.6 | 60.0 | 66.2 | 67.6 |[line_break_token]‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-‚Äî-‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-[line_break_token][line_break_token]Please refer to page 6, 7, and Table 3 for more information on the hyperparameters and ablation study.	Reply	I-Reply	2
  	Reply	I-Reply	2

The work proposes to use the geometry of data (that is considered to be known a priori) in order to have more consistent sparse coding.	Review	O	0
Namely, two data samples that are similar or neighbours, should have a sparse code that is similar (in terms of support).	Review	O	0
The general idea is not unique, but it is an interesting one (if one admits that the adjacency matrix A is known a priori), and the novelty mostly lies on the definition of the regularisation term that is an l1-norm (while other techniques would mostly use l2 regularisation).	Review	O	0
[line_break_token][line_break_token]Based on this idea, the authors develop a new SRSC algorithm, which is analysed in detail and shown to perform better than its competitors based on l2 sparse coding regularisation and other schemes in terms of clustering performance.	Review	O	0
[line_break_token][line_break_token]Inspired by LISTA, the authors then propose an approximate solution to the SRSC problem, called Deep-SRSC, that acts as a sort of fast encoder.	Review	O	0
Here too, the idea is interesting and seems to be quite efficient from experiments on USPS data, even if the framework seems to be strongly inspired from LISTA.	Review	O	0
That scheme should however be better motivated, by the limitations of SRSC that should be presented more clearly.	Review	B-Review	1
[line_break_token][line_break_token]Overall, the paper is well written, and pretty complete.	Review	O	0
It is not extremely original in its main ideas though, but the actual algorithm and implementation seem new and effective.	Review	O	0
Thank you for your comment!	Reply	O	0
[line_break_token][line_break_token]We have included a more clear motivation of Deep-SRSC in the beginning of Section 4 in the revised paper, namely ‚ÄúThe goal of Deep-SRSC is to approximate the sparse codes of the input data in a fast way by feeding the data through the Deep-SRSC network, instead of running the iterative optimization algorithm for SRSC in Section 2.1. ‚	Reply	B-Reply	1
Äù[line_break_token][line_break_token]In fact, SRSC is efficient from the perspective of the conventional optimization algorithms for the sparse coding methods.	Reply	I-Reply	1
Please refer to the complexity analysis of SRSC in the subsection ‚ÄúTime Complexity‚Äù in Section 2.1 of the revised paper.	Reply	I-Reply	1
Deep-SRSC is proposed as a fast approximation of SRSC with considerable (around 8.3 times) speedup for obtaining the approximate support regularized sparse codes of the new data or the test data (more details in Section 4.1 of the revised paper: Deep-SRSC As Fast Encoder).	Reply	I-Reply	1
[line_break_token][line_break_token]Moreover, we have presented the additional experiments in the revised paper on the MNIST and CIFAR-10 data for the clustering and semi-supervised learning tasks, which further demonstrate the effectiveness of SRSC and Deep-SRSC.	Reply	I-Reply	1

This paper proposes a new method of detecting in vs. out of distribution samples.	Review	O	0
Most existing approaches for this deal with detecting out of distributions at *test time* by augmenting input data and or temperature scaling the softmax and applying a simple classification rule based on the output.	Review	O	0
This paper proposes a different approach (with could be combined with these methods) based on a new training procedure.	Review	O	0
[line_break_token][line_break_token]The authors propose to train a generator network in combination with the classifier and an adversarial discriminator.	Review	O	0
The generator is trained to produce images that (1) fools a standard GAN discriminator and (2) has high entropy (as enforced with the pull-away term from the EBGAN).	Review	O	0
Classifier is trained to not only maximize classification accuracy on the real training data but also to output a uniform distribution for the generated samples.	Review	O	0
[line_break_token][line_break_token]The model is evaluated on CIFAR-10 and SVNH, where several out of distribution datasets are used in each case.	Review	O	0
Performance gains are clear with respect to the baseline methods.	Review	O	0
[line_break_token][line_break_token]This paper is clearly written, proposes a simple model and seems to outperform current methods.	Review	O	0
One thing missing is a discussion of how this approach is related to semi-supervised learning approaches using GANS where a generative model produces extra data points for the classifier/discriminator.	Review	B-Review	4
[line_break_token][line_break_token] I have some clarifying questions below:[line_break_token]- Figure 4 is unclear: does "Confidence loss with original GAN" refer to the method where the classifier is pretrained and then "Joint confidence loss" is with joint training?	Review	O	0
What does "Confidence loss (KL on SVHN/CIFAR-10)" refer to?	Review	B-Review	1
[line_break_token][line_break_token]- Why does the join training improve the ability of the model to generalize to out-of-distribution datasets not seen during training?	Review	O	0
[line_break_token][line_break_token]- Why is the pull away term necessary and how does the model perform without it?	Review	O	0
Most GAN models are able to stably train without such explicit terms such as the pull away or batch discrimination.	Review	B-Review	3
Is the proposed model unstable without the pull-away term?	Review	I-Review	3
[line_break_token][line_break_token]- How does this compare with a method whereby instead of pushing the fake sample's softmax distribution to be uniform, the model is simply a trained to classify them as an additional "out of distribution" class?	Review	O	0
This exact approach has been used to do semi supervised learning with GANS [1][2]. More generally, could the authors comment on how this approach is related to these semi-supervised approaches?	Review	B-Review	4
[line_break_token][line_break_token]- Did you try combining the classifier and discriminator into one model as in [1][2]?	Review	O	0
[line_break_token][line_break_token][1] Semi-Supervised Learning with Generative Adversarial Networks (<a href="https://arxiv.org/abs/1606.01583)" target="_blank" rel="nofollow">https://arxiv.org/abs/1606.01583)</a>[line_break_token][2] Good Semi-supervised Learning that Requires a Bad GAN (<a href="https://arxiv.org/abs/1705.09783)" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.09783)</a>	Review	O	0
We very much appreciate your valuable comments, efforts and times on our paper.	Reply	O	0
We provide our responses for all questions below.	Reply	O	0
Revised parts in the new draft are colored by blue.	Reply	O	0
[line_break_token][line_break_token]Q1: "Figure 4 is unclear."	Reply	O	0
[line_break_token][line_break_token]A1: First, "Confidence loss with original GAN" corresponds to a variant of confidence loss (1) which trains a classifier by optimizing the KL divergence term using samples from a pre-trained original/standard GAN, i.e., GAN generates in-distribution samples.	Reply	O	0
Next, "Joint confidence loss" is the proposed loss (4) optimized by Algorithm 1.	Reply	B-Reply	1
Here, we remark that only "Joint confidence loss" optimizes the KL divergence terms using implicit samples from the proposed GAN, i.e., GAN generates "boundary" samples in the low-density area of in-distribution.	Reply	I-Reply	1
Finally, "Confidence loss (KL on SVHN/CIFAR-10)" corresponds to the confidence loss (1) using explicit out-of-distribution samples (SVHN or CIFAR-10).	Reply	I-Reply	1
For example, "Confidence loss (KL on SVHN)" refers to the method where the KL divergence term in the confidence loss (1) is optimized using SVHN training data.	Reply	I-Reply	1
In the revision, we clarified the notations such that the KL divergence term is optimized on samples indicated in the parentheses, i.e., "Confidence loss with original GAN" and "Confidence loss (KL on SVHN/CIFAR-10)" were revised to "Confidence loss (samples from original GAN)" and "Confidence loss (SVHN/CIFAR-10)", respectively.	Reply	I-Reply	1
We updated Figure 2 and Figure 4 accordingly.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: "Why does the joint training improve the ability of the model to generalize to out-of-distribution datasets not seen during training?"	Reply	O	0
[line_break_token][line_break_token]A2: It is explained in Section 2.3.	Reply	O	0
In Section 2.1, we suggest to use out-of-distribution samples for training a confident classifier.	Reply	B-Reply	2
Conversely, in Section 2.2.,	Reply	I-Reply	2
we suggest to use a confident classifier for training a GAN generating out-of-distribution samples.	Reply	I-Reply	2
Namely, two models can be used for improving each other.	Reply	I-Reply	2
Hence, this naturally suggests a joint training scheme in Section 2.3 for confident classifier and the proposed GAN, where both improve as the training proceeds.	Reply	I-Reply	2
We emphasize the effect of joint training again in the revision.	Reply	I-Reply	2
Please see our revision of Section 2.3 for details.	Reply	I-Reply	2
[line_break_token][line_break_token]Q3: "Why is the pull away term necessary and how does the model perform without it?"	Reply	O	0
[line_break_token][line_break_token]A3: We really appreciate your valuable comments.	Reply	O	0
[line_break_token][line_break_token]The pull away term (PT) is not related to "stability."	Reply	B-Reply	3
Our intuition was that the entropy of out-of-distribution is expected to be much higher compared to that of in-distribution since the out-of-distribution is typically on a much larger space than the in-distribution.	Reply	I-Reply	3
Consequently, we expected that optimizing the PT term is useful for generating better out-of-distribution samples.	Reply	I-Reply	3
[line_break_token]We also note that the PT was recently used [2] for a similar purpose as ours.	Reply	I-Reply	3
[line_break_token][line_break_token]However, since we suggest to generate out-of-distribution samples nearby in-distribution (for efficient sampling purpose), its entropy might be not that high and the effect of PT is not clear.	Reply	I-Reply	3
After our submission, we actually verified that PT sometimes helps (but not always), and its gains are relatively marginal in overall.	Reply	I-Reply	3
Since PT increases the training complexity, we decided to remove the PT in the revision and have updated all experimental results without using PT.	Reply	I-Reply	3
Still, for interested readers, we also report the effects of PT in the Appendix D. We updated Section 2.2 and 2.3, Figure 3, 4 and 5, and Appendix D, accordingly.	Reply	I-Reply	3
[line_break_token][line_break_token]Q4: "How is this approach related to the semi-supervised approaches in [1][2]?	Reply	O	0
Did you try combining the classifier and discriminator into one model as in [1][2]?"	Reply	O	0
[line_break_token][line_break_token]A4: As briefly mentioned in Section 4, we expect that our proposed GAN might be useful for semi-supervised settings.	Reply	O	0
Also, we actually thought about combining the classifier and discriminator into one model, i.e., adding K+1 class.	Reply	B-Reply	4
However, we choose a more "conservative" way to design network architectures so that the original classification performance does not degrade.	Reply	I-Reply	4
Extension to semi-supervised learning should be an interesting future direction to explore.	Reply	I-Reply	4
[line_break_token][line_break_token][1] Odena, A. Semi-supervised learning with generative adversarial networks.	Reply	O	0
In NIPS, 2016. (	Reply	O	0
<a href="https://arxiv.org/abs/1606.01583)" target="_blank" rel="nofollow">https://arxiv.org/abs/1606.01583)</a>[line_break_token][2] Dai, Z., Yang, Z., Yang, F., Cohen, W.W. and Salakhutdinov, R. Good Semi-supervised Learning that Requires a Bad GAN.	Reply	O	0
In NIPS, 2017. (	Reply	O	0
<a href="https://arxiv.org/abs/1705.09783)" target="_blank" rel="nofollow">https://arxiv.org/abs/1705.09783)</a> [line_break_token][line_break_token]Thanks,[line_break_token]Author	Reply	O	0

This paper focuses on the problem of developing deep learning systems that can prove theorems in a mathematical formalism -- in this case, MetaMath.	Review	O	0
This has been a rapidly growing topic in the past few years, as evidenced by the numerous cited works.	Review	O	0
What sets this work apart from others is its focus on the instrumental task of generating data to train a prover, rather than directly training the prover on human theorems (via reinforcement learning) or human proofs (via imitation learning).	Review	O	0
[line_break_token][line_break_token]The paper proposer two approaches to generating theorems imitation learning (IL) and reinforcement learning (RL).	Review	O	0
The IL approach trains a neural policy to imitate the same steps taken in human proofs.	Review	O	0
The RL approach first trains a language model on human theorems (not proofs), and uses the likelihood under the model as a reward function for an RL agent which must take forward proof steps.	Review	O	0
[line_break_token][line_break_token]Both approaches result in a policy that can be used to take proof steps, with the goal of producing new theorems which are similar to the human ones.	Review	O	0
Since the proof steps are known for the generated theorems, a prover agent (which operates in backwards mode, working from the goal back to the hypotheses) can be trained to imitate the steps taken in the synthetic proofs (along with the human ones, if any are present).	Review	O	0
[line_break_token][line_break_token]At test time, the learned prover imitation policy is then used to guide an MCTS agent, as described in the Holophrasm paper.	Review	O	0
It is compared against the original Holophrasm algorithm, rerun on modern hardware.	Review	O	0
[line_break_token][line_break_token]This is to my knowledge a novel approach in the neural theorem proving domain, and in my opinion one that offers a potentially significant advantage over the existing fixed-dataset appraoches.	Review	O	0
[line_break_token][line_break_token]The main result of the paper is that an extra 35/2720 (1.2%) of the test theorems are proven, a 6% improvement over the Holophrasm baseline of 539.	Review	B-Review	1
It is difficult to judge how relevant of an improvement this is, and there is no analysis of the difficulty of the MetaMath problem set.	Review	I-Review	1
In addition, due to the 10-1-1 train-validation-test split, the neural agents are likely shown relatively similar problems during training as at test time, including potentially stronger versions of the same theorems.	Review	I-Review	2
There is also no comparison against non-neural approaches, such as Z3, Vampire, or similar theorem provers.	Review	I-Review	2
[line_break_token][line_break_token]To accept this paper, I would like to see stronger evidence that the introduced method produces significant improvements in prover ability.	Review	I-Review	3
For example, the same method could be applied to datasets such as HOList, Mizar, and CoqGym which have received more attention recently than MetaMath.	Review	I-Review	3
[line_break_token][line_break_token]Some additional questions and comments:[line_break_token]1.	Review	O	0
How big does the theorem graph G get?	Review	B-Review	4
Since the relevance policy is over all nodes of the graph, this could lead to a very large neural network that would be difficult to fit into memory.	Review	I-Review	4
Certainly not all 1M synthetic theorems could be generated in one graph.	Review	I-Review	4
[line_break_token]2.	Review	O	0
The paper claims that all theorems from set.mm are used as background theorems in algorithm 1, including the test ones -- this potentially sounds like training on the test set, or even worse, having access to the test theorems as "proven background knowledge" at test time.	Review	B-Review	5
[line_break_token]3.	Review	O	0
Please include some more details about the training of the Holophrasm baseline.	Review	B-Review	1
Does it simply do RL on the human theorems, or does it also do IL on human proofs?	Review	I-Review	1
hank you for your comments and your time for reviewing our submission.	Reply	O	0
We address your individual points below in a QA format.	Reply	O	0
[line_break_token][line_break_token]Q1: The main result of the paper is that an extra 35/2720 (1.2%) of the test theorems are proven, a 6% improvement over the Holophrasm baseline of 539.	Reply	O	0
It is difficult to judge how relevant of an improvement this is, and there is no analysis of the difficulty of the MetaMath problem set.	Reply	O	0
[line_break_token][line_break_token]A: In our experiments, the improvement from MetaGen over the Holophrasm baseline is significant because it is virtually impossible to prove a new theorem by random guessing.	Reply	O	0
The average proof length is 55 in set.mm, and the prover can find a proof only after taking a long sequence of correct proof steps.	Reply	B-Reply	1
In addition, a proof step can require composing a new expression, further increasing the search space.	Reply	I-Reply	1
This means that the probability of proving a new theorem through random guessing is close to zero, and proving a few dozens more theorems is a significant improvement.	Reply	I-Reply	1
As shown in Table 3, we achieve consistent improvement from MetaGen in different training settings.	Reply	I-Reply	1
When trained on all human proofs, our method with MetaGen-IL could find 21 extra proofs with five proof steps or more.	Reply	I-Reply	1
[line_break_token][line_break_token]Q2: The same method could be applied to datasets such as HOList, Mizar, and CoqGym which have received more attention recently than Metamath.	Reply	O	0
[line_break_token][line_break_token]A: Set.mm in Metamath is a good benchmark for automated theorem proving.	Reply	O	0
Mathmath only relies on substitution, the most general and fundamental inference rule of deductive reasoning, and therefore can serve as a meta-language to implement different logics, like first-order logic, higher-order logic, and set theory, while other systems are usually built on a particular logical foundation.	Reply	B-Reply	3
Such simplicity and generality offer a unique advantage for developing ML provers, because we can generate all potential theorems by handling substitution only.	Reply	I-Reply	3
[line_break_token][line_break_token]Set.mm is the largest corpus of math theorems in Metamath.	Reply	I-Reply	3
It contains 29,337 theorems and almost 1.5M proof steps.	Reply	I-Reply	3
It implements the Tarski-Grothendieck set theory and covers various math topics, including but not limited to first-order logic, real and complex analysis, linear algebra, graph theory, elementary geometry and topology.	Reply	I-Reply	3
It formalizes 71 of the ‚Äútop 100‚Äù math theorems, only behind HOL Light and Isabelle/HOL among all formal math databases [1] , and its coverage is still actively growing.	Reply	I-Reply	3
This makes set.mm a good benchmark to train and evaluate learning-based theorem provers.	Reply	I-Reply	3
[line_break_token][line_break_token]The idea of theorem generation can be applied to other systems beyond Metamath, but realizing it on another system is highly nontrivial.	Reply	I-Reply	3
It can even involve new research challenges.	Reply	I-Reply	3
In particular, due to large differences in logic foundations, grammar, inference rules, and benchmarking environments, the generation process, which is a key component of our approach, would be almost completely different for a new system.	Reply	I-Reply	3
And the entire pipeline essentially needs to be re-designed and re-coded from scratch for a new formal system, which can require an unreasonable amount of engineering.	Reply	I-Reply	3
Because of this, it is a standard practice in prior work to target a specific formal system and experiment only in this system [2,3,4,5,6,7,8]. [line_break_token][line_break_token]In addition, existing benchmarking environments for other systems have limitations that make it infeasible to implement our method.	Reply	I-Reply	3
HOList [2] and CoqGym [3] are built on tactic-based theorem provers.	Reply	I-Reply	3
Their environments only provide interfaces to call tactics implemented in backend provers.	Reply	I-Reply	3
Most tactics execute backward reasoning.	Reply	I-Reply	3
To generate new theorems, we need to be able to execute the corresponding reverse tactics, but this functionality is not provided in the current version of HOList and CoqGym.	Reply	I-Reply	3
[tab_token][line_break_token][line_break_token]Our approach cannot be directly applied to Mizar, because it does not provide human proofs in a format that can be understood by an automatic prover like the E prover (see [5]).	Reply	I-Reply	3
Prior works have used machine learning to improve the E prover [4,5,6] on Mizar, but they have only trained on proofs automatically found by the E prover, not those written by humans.	Reply	I-Reply	3
E expresses theorems as CNFs and proves by refutation at the level of CNF clauses.	Reply	I-Reply	3
The CNF representation of theorems and proofs are incomprehensible to humans.	Reply	I-Reply	3
Thus it is an open research question how to do forward reasoning to generate synthetic theorems in the CNF form that are similar to human theorems.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token][line_break_token]	Reply	O	0

I have read the authors' response.	Review	O	0
Their points regarding baseline comparisons are sensible in that there isn't a reason to expect the observations to *not* generalization to other datasets.	Review	O	0
It is odd that mLSTM is outperformed by LSTM in Table 3, but as the authors note in section 4.2 this may be due to instability of mLSTM during training.	Review	O	0
The results in the paper demonstrate significant improvement over LSTM, and while there are not as many baseline comparison to similar models as I would have liked to see, the quality of this work is sufficiently high that this is not a fatal flaw.	Review	O	0
In light of the author response and other reviews, I am revising my rating to 6: Weak Accept.	Review	O	0
[line_break_token][line_break_token]=====[line_break_token][line_break_token]This paper proposes a modification of LSTM networks in the context of language modeling called Mogrifier LSTM.	Review	O	0
Ordinary LSTMs are defined as recurrent operations on the current input, previous hidden state, and previous cell state.	Review	O	0
The proposed Mogrifier LSTM utilizes the same recurrent unit as the LSTM, but the input and previous hidden state are updated with several rounds of mutual gating.	Review	O	0
In each round, the input  is multiplied elementwise by a gate computed as a function of the hidden state (or vice versa).	Review	O	0
The authors experiment on word-level and character-level modeling and compare their Mogrifier LSTMs to several state-of-the-art approaches.	Review	O	0
They also conduct an ablation study to show the effect of various design choices and hyperparameters and experiments on a reverse copy task.	Review	O	0
[line_break_token][line_break_token]Specific contributions include:[line_break_token]* Proposal of a novel approach for modulating inputs to a recurrent unit by mutual gating.	Review	O	0
[line_break_token]* Experiments demonstrating strong performance on a number of language modeling tasks.	Review	O	0
[line_break_token]  [line_break_token]The paper in its current state is borderline, leaning towards weak reject.	Review	O	0
Points in favor of acceptance include the high clarity of writing, good experiments of the proposed model, and a discussion of possible reasons for why the mogrification operation works well.	Review	O	0
The main shortcoming of the paper is experimental comparison to baselines.	Review	O	0
[line_break_token][line_break_token]The authors were able to train baseline LSTMs to high levels of performance (presumably due to tuning of hyperparameters) and then demonstrate that Mogrifier LSTMs improve upon LSTMs significantly.	Review	B-Review	1
This is perhaps not entirely surprising, because the hyperparameter range of the Mogrifier LSTM includes zero rounds of updates, which would render it identical to the baseline LSTM.	Review	I-Review	1
Therefore, if the hyperparameters are tuned sufficiently well, the performance of the Mogrifier LSTM should be at least as good as the LSTM.	Review	I-Review	1
What the experiments do not show is that the proposed mogrification outperforms other forms of multiplicative interaction and/or gating.	Review	I-Review	2
The closest that the authors come to this is the single validation perplexity of the Multiplicative LSTM in Table 3.	Review	I-Review	2
If thorough hyperparameter tuning is applied to the Multiplicative LSTM or the approaches of Wu et al. (	Review	I-Review	2
2016) and/or Sutskever et al. (	Review	I-Review	2
2011), does the Mogrifier LSTM still outperform them?	Review	I-Review	2
[line_break_token][line_break_token]Other than this critical issue of baseline comparison, the experiments are quite informative.	Review	O	0
The ablation study showing the effect of different design decisions and the hyperparameter visualiztion in Appendix B are particularly useful.	Review	O	0
The mogrification operation is described precisely enough for other researchers to implement and the arguments made in 4.4 are compelling.	Review	O	0
[line_break_token][line_break_token]Question for the authors:[line_break_token]* Some qualitative analysis of the learned mogrification operation would be helpful for understanding the nature of the modulation.	Review	O	0
For example, how do the predictions change depending on the modulation?	Review	B-Review	3
If x is modulated by different hidden states, is there a noticeable effect on the output?	Review	I-Review	3
[line_break_token]* Did you experiment with other forms of modulation before arriving upon the mogrification formulation?	Review	O	0
There are some naive approaches such as concatenating the hidden state to the input and applying a nonlinear layer, or predicting affine parameters for the input as a function of the hidden state in the style of FiLM [1]. Are there obvious shortcomings in these naive approaches that mogrification handles gracefully?	Review	B-Review	4
[line_break_token][line_break_token][1] Perez, E., Strub, F., De Vries, H., Dumoulin, V. and Courville, A., 2018, April.	Review	O	0
Film: Visual reasoning with a general conditioning layer.	Review	O	0
In Thirty-Second AAAI Conference on Artificial Intelligence.	Review	O	0
e thank Reviewer #1 for the critical but thoughtful review.	Reply	O	0
We try to[line_break_token]address the issues brought up below.	Reply	O	0
[line_break_token][line_break_token]&gt; The authors were able to train baseline LSTMs to high levels of[line_break_token]&gt; performance (presumably due to tuning of hyperparameters) and then[line_break_token]&gt; demonstrate that Mogrifier LSTMs improve upon LSTMs significantly.	Reply	O	0
[line_break_token]&gt; This is perhaps not entirely surprising, because the hyperparameter[line_break_token]&gt; range of the Mogrifier LSTM includes zero rounds of updates, which[line_break_token]&gt; would render it identical to the baseline LSTM.	Reply	O	0
Therefore, if the[line_break_token]&gt; hyperparameters are tuned sufficiently well, the performance of the[line_break_token]&gt; Mogrifier LSTM should be at least as good as the LSTM[line_break_token][line_break_token]It is indeed unsurprising that the Mogrifier is not worse than the[line_break_token]LSTM since it includes the LSTM as a special case.	Reply	O	0
But in Figure 3[line_break_token]where perplexity is plotted as the function of rounds, the setting[line_break_token]that corresponds to the LSTM (rounds=0) is clearly the worst and the[line_break_token]gap is very significant.	Reply	B-Reply	1
[line_break_token][line_break_token]&gt; What the experiments do not show is that the proposed mogrification[line_break_token]&gt; outperforms other forms of multiplicative interaction and/or gating.	Reply	O	0
[line_break_token]&gt; The closest that the authors come to this is the single validation[line_break_token]&gt; perplexity of the Multiplicative LSTM in Table 3.	Reply	O	0
If thorough[line_break_token]&gt; hyperparameter tuning is applied to the Multiplicative LSTM or the[line_break_token]&gt; approaches of Wu et al. (	Reply	O	0
2016) and/or Sutskever et al. (	Reply	O	0
2011), does[line_break_token]&gt; the Mogrifier LSTM still outperform them?	Reply	O	0
[line_break_token][line_break_token]We agree that having these baselines would strengthen the contribution[line_break_token]and help position our work more precisely in their context.	Reply	B-Reply	2
Due to[line_break_token]time and resource constraints, we focussed on the most similar model,[line_break_token]the mLSTM, and evaluated it on PTB (which has been predictive of[line_break_token]performance on other tasks in our experience) using the same[line_break_token]hyperparameter tuning methodology as everywhere else in the paper, the[line_break_token]only exceptions being a shortened schedule and small BPTT window size.	Reply	I-Reply	2
[line_break_token]These concessions to practicality make results slightly worse (2-3[line_break_token]perplexity points), but there is little reason to believe they benefit[line_break_token]one model or the other.	Reply	I-Reply	2
And if the mLSTM were more similar to the[line_break_token]mogrifier than we'd like, we should see that in these experiments.	Reply	I-Reply	2
As[line_break_token]it is, what we found is that the mLSTM does not improve on the[line_break_token]baseline LSTM while the Mogrifier does.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; * Some qualitative analysis of the learned mogrification operation[line_break_token]&gt;   would be helpful for understanding the nature of the modulation.	Reply	O	0
For[line_break_token]&gt;   example, how do the predictions change depending on the modulation?	Reply	O	0
If[line_break_token]&gt;   x is modulated by different hidden states, is there a noticeable[line_break_token]&gt;   effect on the output?	Reply	O	0
[line_break_token][line_break_token]Obviously, in terms of perplexity there is a noticable effect.	Reply	B-Reply	3
In[line_break_token]terms of statistics of the modulated vs unmoodulated input vectors, we[line_break_token]do not have the data.	Reply	I-Reply	3
The closest we have in the paper is that "the[line_break_token]means of the standard LSTM gates in the Mogrifier were very close[line_break_token]between the two models but their variance was smaller in the[line_break_token]Mogrifier".	Reply	I-Reply	3
[line_break_token][line_break_token]&gt; * Did you experiment with other forms of modulation before arriving[line_break_token]&gt;   upon the mogrification formulation?	Reply	O	0
There are some naive[line_break_token]&gt;   approaches such as concatenating the hidden state to the input and[line_break_token]&gt;   applying a nonlinear layer, or predicting affine parameters for[line_break_token]&gt;   the input as a function of the hidden state in the style of FiLM[line_break_token]&gt;   [1]. Are there obvious shortcomings in these naive approaches that[line_break_token]&gt;   mogrification handles gracefully?	Reply	O	0
[line_break_token][line_break_token]We tried concatenation of hidden state and input and saw no benefit[line_break_token]compared to the Mogrifier to offset the significantly higher number of[line_break_token]parameters.	Reply	B-Reply	4
FiLM sounds similar to one round mogrifier without a[line_break_token]non-linearity.	Reply	I-Reply	4
As to obvious shortcomings to these methods, we do not[line_break_token]know of any.	Reply	I-Reply	4
Probably we would need to understand a mogrifier much[line_break_token]better to answer that question.	Reply	I-Reply	4

The work in this paper is focused on the task of knowledge base completion, dealing specifically with temporal relations, which is quite important in practice, and also not as well studied in literature.	Review	O	0
Specifically, the authors have 3 main contributions in this paper:[line_break_token]1.	Review	O	0
They present an order 4 tensor factorization for dealing with temporal data, which is a nice extension of the work in Lacroix 2018.	Review	O	0
The authors introduce different forms of regularization to extend to the order 4 tensors.	Review	O	0
Inspired by previous work, they produce different regularization strategies for order 4 tensor by unfolding the modes to reduce it ot an order 3 formulation.	Review	O	0
They also describe a regularization term for smoothing the temporal embeddings.	Review	O	0
[line_break_token]3.	Review	O	0
Finally, the authors mine wikidata for temporal relations and contribute a dataset based on wikidata that is much larger than existing datasets for this task.	Review	O	0
[line_break_token][line_break_token][line_break_token]Overall, I think this paper is  interesting as it provides an incremental extension of ComplEx to the temporal case, and the experiments to support the formulation show improvements in MRR.	Review	O	0
However, the experiments around standard benchmarks as well as the data produced by the authors do not always support the hypothesis that modeling temporal dimension in the proposed formulation is a win for the KB completion task.	Review	B-Review	1
 For example, the use of auxiliary losses  for enforcing temporal constraints makes the overall performance worse.	Review	I-Review	1
This is mentioned in a section, but I think it deserves a more thorough explanation.	Review	I-Review	1
Also, there is no mention about statistical significance of the results, and so it is hard to judge the claim of these being SOTA as made by the authors.	Review	I-Review	4
For example, on the wikidata dataset produced, the ComplEx model outperforms the proposed models.	Review	I-Review	4
[line_break_token][line_break_token][line_break_token][line_break_token]Strengths:[line_break_token]1.	Review	O	0
The work in this paper is quite well motivated and the modeling formulation is clear and easy to follow.	Review	O	0
The authors did a great job in citing relevant work and walking through the model formulation as well as the various regularization terms introduced.	Review	O	0
[line_break_token]2.	Review	B-Review	2
The authors compare their work to the previous SOTA - the ComplEx models for multiple datasets, including their own released datasets.	Review	O	0
They present a clear set of experiments to demonstrate the effectiveness of their approach both on non-temporal and temporal relations.	Review	O	0
[line_break_token]3.	Review	O	0
There is a dataset being released and also code, which should aid in reproducibility of the results (though I have not tested the code).	Review	O	0
[line_break_token][line_break_token]Areas to be addressed:[line_break_token]1.	Review	O	0
The work seems to assume that the time is discretized by year.	Review	B-Review	1
However, it is unclear how one would deal with a KB where the temporal relations can change on the order of weeks (example popular movies).	Review	I-Review	1
For that matter, how would the model be modified to deal with heterogenous time scales in the evolution of the relations in the KB?	Review	I-Review	1
Can the authors add some clarification as well as explanations for how this would be addressed in this formulation?	Review	I-Review	1
[line_break_token]2.	Review	I-Review	2
While there is a section devoted to different regularization, from Table 3, the impact of choosing the right regularizer seems minimal in terms of MRR.	Review	I-Review	2
Also, it seems that the results in Table 3 are comparable to the ‚Äúranks multiplied by 10‚Äù setting in Table 2.	Review	I-Review	2
What is the reason for this choice?	Review	I-Review	2
[line_break_token]3.	Review	O	0
For Table 4, why is there a performance difference between static and non-static relations?	Review	B-Review	3
It would help if the authors could provide some more error analyses to dive into this performance difference - is it just data imbalance or inherent difficulty in the task for temporal relations.	Review	I-Review	3
[line_break_token]4.	Review	I-Review	4
Section 6 talks about enforcing another auxiliary loss, however, these results are not part of the table.	Review	I-Review	4
I would urge the authors to add this to Table 4.	Review	I-Review	4
Also, the loss in MRR mentioned is it the average loss or does enforcing this auxiliary loss also influence performance on T-MRR as well?	Review	I-Review	4
If so, might it be that the auxiliary loss is too strong and might need to be penalized?	Review	I-Review	4
Did the authors try penalizing the auxiliary loss?	Review	I-Review	4
Finally, the graph in Figure 2 is hard to follow when printed in black and white.	Review	I-Review	4
What would the plot look like in comparison to a model that does not enforce the auxiliary function for the same example?	Review	I-Review	4
I would recommend re-working Section 6 to provide some more details about the performance of the models both across the various datasets as well as error analyses of a few examples compared across TNTComplex, TNTComplex + auxiliary loss + Baseline Complex.	Review	I-Review	4
Having some representative examples would make it easy to understand where these models differ in their performance.	Review	I-Review	4
[line_break_token]5.	Review	O	0
In the results, can the authors include metrics like filtered MRR as well as Hits@10, similar to the one suggested by Bordes 2013?	Review	B-Review	5
This would make it easier to compare against previous literature results which all seem to be reporting on these metrics.	Review	I-Review	5
[line_break_token]	Review	O	0
.	Reply	B-Reply	1
The work seems to assume that the time is discretized by year.	Reply	O	0
However, it is unclear how one would deal with a KB where the temporal relations can change on the order of weeks (example popular movies).	Reply	O	0
For that matter, how would the model be modified to deal with heterogenous time scales in the evolution of the relations in the KB?	Reply	O	0
Can the authors add some clarification as well as explanations for how this would be addressed in this formulation?	Reply	O	0
[line_break_token]‚Üí Changing the discretization of time is not an issue unless the number of timestamps to be considered becomes too large.	Reply	O	0
For the exemple of movies, with 52 weeks per year, this would lead to 5200 timestamps for 100 years worth of movies, which is completely manageable.	Reply	B-Reply	1
As mentioned in our answer to Reviewer #2 however, the temporal regularizer becomes more important when the granularity along time increases.	Reply	I-Reply	1
[line_break_token]Regarding heterogeneous timescales : in the temporal regularizer, we penalize the difference of embeddings of successive timestamps, irrespective of the actual timestamps.	Reply	I-Reply	1
In preliminary experiments, we also tried weighting by the time difference: ||T_i - T_{i+1}||_2^2 / (ts_{i+1} - ts_i), where T_i is the embedding corresponding to timestamp ts_i.	Reply	I-Reply	1
This reduces the temporal regularization for embeddings of timestamps that are far from their neighbors.	Reply	I-Reply	1
This did not lead to improvements on the datasets considered.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
While there is a section devoted to different regularization, from Table 3, the impact of choosing the right regularizer seems minimal in terms of MRR.	Reply	O	0
Also, it seems that the results in Table 3 are comparable to the ‚Äúranks multiplied by 10‚Äù setting in Table 2.	Reply	O	0
What is the reason for this choice?	Reply	O	0
[line_break_token]‚Üí Impact of regularizer: the impact is e.g., 2 points of MRR absolute on ICEWS-5, which is substantial.	Reply	O	0
 We consider our results with higher ranks as the new state-of-the-art (since performances are significantly better than previous methods), so we compare the regularizers in Table 3 in this most challenging and important setup.	Reply	B-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
For Table 4, why is there a performance difference between static and non-static relations?	Reply	O	0
It would help if the authors could provide some more error analyses to dive into this performance difference - is it just data imbalance or inherent difficulty in the task for temporal relations.	Reply	O	0
[line_break_token]‚Üí The difference in performance is due to a discrepancy in temporal vs non-temporal data.	Reply	O	0
Notably, 93% of temporal tuples (subject, predicate) have two or more valid objects.	Reply	B-Reply	3
This proportion is only 47% for non-temporal tuples.	Reply	I-Reply	3
 One-to-many relations lead to lower MRR than one-to-one relations (see table 3, Lacroix et al.	Reply	I-Reply	3
2018 Canonical Tensor Decomposition for Knowledge Base Completion)  [line_break_token][line_break_token]4.	Reply	O	0
Section 6 talks about enforcing another auxiliary loss, however, these results are not part of the table.	Reply	O	0
I would urge the authors to add this to Table 4.	Reply	O	0
Also, the loss in MRR mentioned is it the average loss or does enforcing this auxiliary loss also influence performance on T-MRR as well?	Reply	O	0
If so, might it be that the auxiliary loss is too strong and might need to be penalized?	Reply	O	0
Did the authors try penalizing the auxiliary loss?	Reply	O	0
[line_break_token][line_break_token]‚Üí The auxiliary loss has no influence on the T-MRR,  the point of MRR is lost over non-temporal triples.	Reply	O	0
We did not try reducing the weight of this loss in the overall loss to obtain the best (MRR, time AUC) operating point as this section is meant to be an example of new metrics that could be interesting on this dataset.	Reply	B-Reply	4
[line_break_token][line_break_token]Finally, the graph in Figure 2 is hard to follow when printed in black and white.	Reply	I-Reply	4
What would the plot look like in comparison to a model that does not enforce the auxiliary function for the same example?	Reply	I-Reply	4
[line_break_token][line_break_token]‚Üí We will add different strokes for each presidents in the final version of the paper.	Reply	O	0
 On this example, the plot for TNTComplEx trained without the auxiliary loss gives similar scores to the presidents over time.	Reply	B-Reply	4
[line_break_token][line_break_token]Having some representative examples would make it easy to understand where these models differ in their performance.	Reply	O	0
[line_break_token]‚Üí The breakdown we provide shows that the difference comes from non-temporal triples, which is expected when comparing a temporal and non-temporal model.	Reply	O	0
Since the non-temporal triples account for 90% of the link prediction loss, it is natural that adding a new loss will impact in majority the MRR of these triples and leave the MRR of temporal triples intact, which is what we observe.	Reply	B-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
In the results, can the authors include metrics like filtered MRR as well as Hits@10, similar to the one suggested by Bordes 2013?	Reply	O	0
This would make it easier to compare against previous literature results which all seem to be reporting on these metrics.	Reply	O	0
[line_break_token]‚Üí We report the filtered MRR similarly to previous state of the art on these datasets.	Reply	O	0
This is specified in the experimental set-up section.	Reply	B-Reply	5
To avoid clutter, we added hits@k in the supplementary materials (Appendix 8.5).	Reply	I-Reply	5

The paper studies the role of depth on incremental learning in several toy models for neural networks.	Review	O	0
In particular, they show that in these models, deep models require polynomially small initializations to exhibit incremental learning than shallow models.	Review	O	0
The paper is well written, and I think there are several interesting contributions.	Review	O	0
[line_break_token][line_break_token]The authors contribute analysis for non-asymptotically small initializations, and study an interesting role of depth in how small this initialization must be.	Review	O	0
Furthermore, they extend their results to several other models including matrix sensing, linear convnets, and classification.	Review	O	0
[line_break_token][line_break_token]I think nonetheless the paper suffers from a few issues.	Review	O	0
Some very important ones.	Review	O	0
[line_break_token][line_break_token]1) The authors study the role of depth on incremental learning, and exhibit how several models theoretically have this property.	Review	O	0
However, they do not study how incremental learning drives generalization.	Review	B-Review	1
In the entire paper, the gradient flow is with respect to the *expected* loss, rather than the empirical loss.	Review	I-Review	1
The research program of incremental learning for deep neural networks would show something like "Incremental learning exists when minimizing empirical loss", "Incremental learning and early stopping imply certain properties (like low capacity) on the resulting neural network" and "These properties imply low generalization error".	Review	I-Review	1
However, the fact that the authors' models minimize the expected loss altogether a priori rules out the direct applicability of this result to explaining generalization.	Review	I-Review	1
That is OK, in the sense that one could aim for these results to be modified and applied with empirical losses, and then a separate line of research could study how incremental learning bounds generalization error.	Review	I-Review	1
[line_break_token]In this sense, I think the authors should take out the "how incremental learning drives generalization" since there is no study on generalization whatsoever, just how depth plays a role in incremental learning.	Review	I-Review	1
An alternative title could be "How depth drives incremental learning."	Review	I-Review	1
or something like that.	Review	I-Review	1
[line_break_token][line_break_token]2) Another point is that all these models are very toy and mostly linear.	Review	O	0
That is OK again, but the introduction overclaims in this respect.	Review	B-Review	2
The sentences "we characterize the effect of the model's depth [...] showing how deeper models allow for incremental learning in larger (realistic) initialization scales."	Review	I-Review	2
and "Once incremental learning has been defined and characterized for the toy model, we generalize our results theoretically and empirically for larger models".	Review	I-Review	2
This makes it seem that results apply to realistic settings, which is really far from true.	Review	I-Review	2
I'm not expecting realistic results, this is a nascent theory, but I am expected the claims made to be validated and not misleading.	Review	I-Review	2
[line_break_token][line_break_token]3) In section 2.2, sigma(t) for N-&gt; \infty is undefined, and the proof for this result is missing (only for finite N appears).	Review	O	0
In particular, it is not clear if sigma(t) for N -&gt; \infty is obtained by a) taking limit N -&gt; \infty in the ODE of equation (8), and then finding the solution of this limiting ODE, or b) finding \sigma(t) for equation (8) on finite N and then taking limit N -&gt; \infty of the solution.	Review	O	0
I.e. there are two potentially different ways to define \sigma(t) for N -&gt; \infty which are solving the ODE and then taking limit or taking limit and then solving the limiting ODE.	Review	O	0
The definition of \sigma(t) for N -&gt; \infty is completely missing so I have no way to assess the validity of this result.	Review	O	0
[line_break_token][line_break_token]A small pet peeve: when writing math, try to avoid using symbols like \forall and \exists unless you're writing a logic paper.	Review	B-Review	4
Instead, try to write equation 2 like, which reads a lot nicer.	Review	I-Review	4
Also, avoid assigning equation numbers to equations you never reference.	Review	I-Review	4
hank you for the detailed review of our paper.	Reply	O	0
[line_break_token][line_break_token]As we understand it, the main issues are with us overclaiming our results, and we accept some of this criticism.	Reply	O	0
[line_break_token]Regarding our introduction where it can be interpreted that the models we analyze are "realistic", we see the models we analyze as non-trivial but concede that the wording could be interpreted as a claim for deep nonlinear networks, which our analysis by no means covers.	Reply	B-Reply	2
Our revision fixes this, clarifying which models we generalize to.	Reply	I-Reply	2
[line_break_token]Regarding the claim that our paper deals with generalization while the analysis is for the expected loss (meaning the theoretical study is about the path to the optimum and not the specific optimum chosen) - it is true that our theorems do not deal with empirical losses, but our experiments seen in figure 1 and the appendices strongly suggest that the dynamics we analyze for the expected loss are exhibited for different empirical losses and for small datasets.	Reply	I-Reply	1
The bias towards sparsity, which leads to generalization when the labeling function is itself sparse, appears to be caused by the combination of gradient descent and a deep parameterization which we analyze, and is consistent for many deep models.	Reply	I-Reply	1
[line_break_token][line_break_token]As for the third issue, the limit we take is for the ODE in equation (8), which leads to the equation, which is solvable like the ODEs for finite N. This result also appears in Saxe et al (2013).	Reply	I-Reply	3
Our revision treats this case more clearly in the proof of theorem 1	Reply	I-Reply	3

This paper studies a very simple and intuitive method to boost the training speed of deep neural networks.	Review	O	0
The authors first train some light weighted proxy models, using these models to rank the data according to its uncertainty, and then pick the most uncertain subset to train the final model.	Review	O	0
Experiments on CIFAR10/SVHN/Amazon Review Polarity demonstrates the effectiveness.	Review	O	0
[line_break_token][line_break_token]In general, I think the authors did a decent job in showing that such a simple idea could surprisingly work well to boost NN training.	Review	O	0
I believe it will inspire future works on speeding up NN training.	Review	O	0
However, to form a solid ICLR publication, plenty of future works need to be done.	Review	O	0
[line_break_token][line_break_token]1)[tab_token]I will not be fully convinced if an idea aiming to speed up, is only verified on small scale dataset (e.g., CIFAR10).	Review	O	0
It will be much better if there are large scale experiments conducted such as on ImageNet and WMT neural machine translation.	Review	B-Review	1
[line_break_token][line_break_token]2)[tab_token]Please well position some related works.	Review	O	0
First, it would be more interesting and informative if some baselines in section 2 (especially those in ‚ÄúOptimization and Importance Sampling‚Äô), are compared with.	Review	B-Review	2
Second, there are important related works omitted such as L2T [1], which also talks/shows the possibly of using partial training data to achieve speed up.	Review	I-Review	3
[line_break_token][line_break_token]3)[tab_token]Some writing issues: it would be better to *clearly* demonstrate the final accuracy of different models (i.e. ResNet 164 trained on whole data and selected subset), such as putting them into a table, but not merely showing them vaguely in the curves and text.	Review	O	0
I‚Äôm also note sure about the meaning of `epoch‚Äô in Table 1: does it mean how many epochs the proxy model is trained?	Review	B-Review	5
If so, I can hardly get the intuition of why smaller epochs works better.	Review	I-Review	5
I noted a conjecture raised by the authors in the last sentence of paragraph ‚Äúcomparing different proxies‚Äù.	Review	I-Review	5
However, I cannot catch the exact meaning.	Review	I-Review	5
[line_break_token][line_break_token][1] Fan, Y., Tian, F., Qin, T., Li, X. Y., & Liu, T. Y. Learning to Teach.	Review	O	0
ICLR 2018[line_break_token]	Review	O	0
Thank you for your thoughtful review and suggestions.	Reply	O	0
Here are our responses:[line_break_token][line_break_token]# large-scale experiments[line_break_token]We are currently running experiments on ImageNet, but the results will not be ready before the response deadline.	Reply	O	0
[line_break_token][line_break_token]# Comparison against baselines in section 2[line_break_token]We agree that more comparison against existing methods such as importance sampling would be valuable.	Reply	O	0
we aimed to compare against ‚ÄúNot All Samples Are Created Equal: Deep Learning with Importance Sampling‚Äù from Katharopoulos & Fleuret (2018) as it represents the most recent published work in the area.	Reply	O	0
Unfortunately, we were unable to complete the experiments before the response deadline.	Reply	B-Reply	2
[line_break_token][line_break_token]# Learning to teach (L2T)[line_break_token]We agree learning to teach is relevant and included it in the related work section.	Reply	O	0
[line_break_token][line_break_token]# Final accuracy of different models in a table[line_break_token]We believe Table 1 should address this concern, and we changed the structure to make it more clear.	Reply	O	0
The most important data from Figure 4 and 5 is captured in the table.	Reply	B-Reply	4
We could add the additional metrics from Figure 5, but the main point of that figure is to show that all of the metrics perform about the same, which would just add redundant rows to the table.	Reply	I-Reply	4
[line_break_token][line_break_token]# Smaller number of epochs[line_break_token]Great question.	Reply	O	0
Yes, "epoch" in Table 1 means how many epochs the proxy model is trained.	Reply	B-Reply	5
We have preliminary results that suggest the diversity of the subset is an important factor in maintaining quality.	Reply	I-Reply	5
Looking at the CDF of entropy on CIFAR10, for example, shows that only around 20% of points have relatively high entropy and that entropy quickly decays after the first 20%.	Reply	I-Reply	5
However, the target model is only able to match the same level of accuracy with a larger subset as shown in Table 1.	Reply	I-Reply	5
This suggests that the subset needs to be sufficiently representative in addition to containing the most difficult.	Reply	I-Reply	5
We hypothesize that the higher error of smaller architectures and partial training might result in increased randomness, which could improve the representativeness of the resulting subsets	Reply	I-Reply	5

This paper presents a reinforcement learning based approach to learn a search strategy to search for programs in the generic syntax-guided synthesis (SyGuS) formulation.	Review	O	0
Unlike previous neural program synthesis approaches, where the DSL grammar is fixed or the specification is in the form of input-output examples only, the SyGuS formulation considers different grammars for different synthesis problems and the specification format is also more general.	Review	O	0
The main idea of the approach is to first learn a joint representation of the specification and grammar using a graph neural network model, and then train a policy using reinforcement learning to guide the search with a grammar adaptive policy network that is conditioned on the joint representation.	Review	O	0
Since the specifications considered here are richer logical expressions, it uses a SAT solver for checking the validity of the proposed solution and to also obtain counterexamples for future rewards.	Review	O	0
The technique is evaluated on 210 SyGuS benchmarks coming from the cryptographic circuit synthesis domain, and shows significant improvements in terms of number of instances solved compared to CVC4 and ESymbolic baseline search techniques from the formal methods community.	Review	O	0
Moreover, the learnt policy is also showed to generalize beyond the benchmarks on which it is trained and the meta-solver performs reasonably well compared to the per-task out-of-box solver.	Review	O	0
[line_break_token][line_break_token]Overall, this paper tackles a more challenging synthesis problem than the ones typically considered in recent neural synthesis approaches.	Review	O	0
The previous synthesis approaches have mostly focused on learning programs in a fixed grammar (DSL) and with specifications that are typically based on either input-output examples or natural language descriptions.	Review	O	0
In the SyGuS formulation, each task has a different grammar and moreover, the specifications are much richer as they can be arbitrary logical expressions on program variables.	Review	O	0
The overall approach of using graph neural networks to learn a joint representation of grammars with the corresponding logical specifications, and then using reinforcement learning to learn a search policy over the grammar is quite interesting and novel.	Review	O	0
The empirical results on the cryptographic benchmarks compare favorably to state of the art CVC4 synthesis solver.	Review	O	0
[line_break_token][line_break_token]However, there were some details in the model description and evaluation that were not very clear in the current presentation.	Review	O	0
[line_break_token][line_break_token]First, the paper mentions that it uses the idea of Static Single Assignment (SSA) form for the graph representation.	Review	O	0
What is the SSA form of a grammar and of a specification?	Review	O	0
[line_break_token][line_break_token]It was also not very clear how the graphs are constructed from the grammar.	Review	O	0
For example, for the rule d1 -> X OR Y | d2 OR d2 in Figure 1, are there two d_OR nodes or a single node d_OR shared by both the rules?	Review	O	0
Similarly, what is the d_T node in the figure?	Review	O	0
It would be good to have a formal description of the nodes and edges in the graph constructed from the spec and grammar.	Review	O	0
[line_break_token][line_break_token]Since the embedding matrix H_d can be of variable size (different sizes of expansion rules), it wasn‚Äôt clear how the policy learns a conditional distribution over the variable number of actions.	Review	O	0
Is there some form of padding of the matrix and then masking being used?	Review	O	0
[line_break_token][line_break_token]For the reward design, the choice of using additional examples in the set B_\phi was quite interesting.	Review	O	0
But there was no discussion about how the interpolation technique works to generate more examples around a counterexample.	Review	O	0
Can you provide some more details on how the interpolation is being performed?	Review	O	0
[line_break_token][line_break_token]Also, how many examples were typically used in the experiments?	Review	O	0
It might be interesting to explore whether different number of examples lead to different results.	Review	O	0
How does the learning perform in the absence of these examples with the simple binary 0/1 reward?	Review	O	0
[line_break_token][line_break_token]From last year‚Äôs SyGuS competition, it seems that the EUSolver solves 152 problems from the set of 214 benchmarks (Table 4 in <a href="http://sygus.seas.upenn.edu/files/SyGuSComp2017.pdf)."	Review	O	0
target="_blank" rel="nofollow">http://sygus.seas.upenn.edu/files/SyGuSComp2017.pdf).</a> For the evaluation, is ESymbolic baseline solver different that the EUSolver?	Review	O	0
Would it be possible to evaluate the EUSolver on the same hardware and timeout to see how well it performs on the 210 benchmarks?	Review	O	0
[line_break_token][line_break_token]The current transfer results are only limited to the cryptographic benchmarks.	Review	O	0
Since SyGuS also has benchmarks in many other domains, would it be interesting to evaluate the policy transfer to some other non-cryptographic benchmark domain?	Review	O	0
[line_break_token]	Review	O	0
Reviewer 3, the authors of this paper have submitted a fairly detailed response to your own detailed review (thanks for that!).	Reply	O	0
It is important that there be some consideration of their reply, and if needed, discussion.	Reply	O	0
Please take the time to review and respond to their rebuttal, and either reconsider your assessment or explain why you stand by it in its current form	Reply	O	0

As mentioned in a previous comment I want to report back with[line_break_token]preliminary results from the hyperparameter search I am conducting.	Review	O	0
[line_break_token]Essentially I am optimizing over all notable parameters except the[line_break_token]number of units in each layer - in order to fix the model size [line_break_token](More specifically this includes: learning rate,[line_break_token]momentum, pooling shape, pooling stride, size of the convolutional[line_break_token]kernels).	Review	O	0
[line_break_token][line_break_token]My preliminary results suggest that on CIFAR-10 the best probout[line_break_token]network trained without data augmentation can achieve an error rate of <= 10.7% .	Review	O	0
[line_break_token]During the hyperparameter search I however also became aware that the[line_break_token]parameter search carried out for the original maxout paper was[line_break_token]probably  not very exhaustive, as improved performance can also[line_break_token]be achieved with a vanilla maxout model.	Review	B-Review	1
[line_break_token]While the difference in performance between probout and maxout appears[line_break_token]to be observable for all hyperparameter settings, the best maxout model [line_break_token]I obtained so far achieves 10.92% error on CIFAR-10 without data[line_break_token]augmentation.	Review	I-Review	1
[line_break_token][line_break_token]Interestingly, the best hyperparameter settings found so far[line_break_token]are much closer to the parameters that seem to be used in the 'Network[line_break_token]in Network' paper (also submitted to ICLR) than the original settings[line_break_token]used in the maxout paper (and maxout seems to perform on par[line_break_token]with 'Network in Network' when a fully connected layer is used after the convolutional[line_break_token]layers).	Review	I-Review	2
I will cross-link these results in the discussion to that paper.	Review	I-Review	2
[line_break_token][line_break_token]I will include the results into the paper as soon as the full[line_break_token]parameter search is finished and disclose the parameters found.	Review	I-Review	2
[line_break_token][line_break_token]It would be interesting if Ian could jump in with a short comment on[line_break_token]how exactly he fixed hyperparameters for his original work.	Review	I-Review	3
My co-author David Warde-Farley chose the final hyperparameters for CIFAR-10.	Reply	B-Reply	1
Our goal was simply to improve upon the state of the art with the limited computational resources that were available to us, so we did not run an exhaustive, automated search.	Reply	I-Reply	1
Instead, both David and I guessed a small number of hyperparameter settings by hand, and we stopped working on that particular task after we started to get diminishing marginal utility from our time spent on it.	Reply	I-Reply	1
The hyperparameters for the case with no data augmentation are probably particularly poor.	Reply	I-Reply	1
We just used the best hyperparameters from the data augmentation case.	Reply	I-Reply	1
[line_break_token][line_break_token]I think if you want to do an explicit comparison between two methods, like maxout and probabilistic maxout, it's best to do an automated search, like we did for our comparison between maxout and rectifiers.	Reply	I-Reply	2
Unfortunately, when we did this automated search, we had to do it for a small maxout model, since we wanted to compare maxout against a significantly larger rectifier model	Reply	I-Reply	2

* Overview*[line_break_token]The paper tackles instance segmentation for images of beef cattle.	Review	O	0
[line_break_token]Mostly the paper is badly written and important details of the proposed approach are missing.	Review	O	0
Overall the results are extremely underwhelming on the public benchmarks, and the gains on the in-house cattle dataset are very small.	Review	O	0
Most importantly, the novelty of the approach is non-existent.	Review	O	0
See below for clarifications.	Review	O	0
[line_break_token][line_break_token]* Details*[line_break_token]The authors build on FCN, a method designed for instance segmentation as they correctly mention in the intro.	Review	O	0
During the description of the approach, they mention that they predict blobs from the FCN output.	Review	B-Review	1
There is no mention of what that is, how they obtain it from the semantic mask predictions.	Review	I-Review	1
Unless I am missing this information, this is a crucial point.	Review	I-Review	1
Moving beyond that important detail, the authors propose two modules, which are essentially hard negative mining (similar to Training Region-based Object Detectors with Online Hard Example Mining, Shrivastava et al.,	Review	O	0
CVPR 2016) and another layer of classification.	Review	O	0
[line_break_token]If I were to ignore the extremely limited novelty of the proposed approach, the results (Table 1) are not compelling at all.	Review	O	0
The authors build on a shallow architecture and show underwhelming results on the public benchmarks.	Review	O	0
On top of that, the hyper-parameters used for computing published approaches are suboptimal (e.g. image size) which lead to lower performance than the ones reported by the original papers.	Review	O	0
[line_break_token][line_break_token]Last, while the above review sounds harsh I want to emphasize that it is quite legitimate to study a problem of particular interest (here image of beef cattle) and to care to obtain good results with low compute and at a low cost presumably.	Review	O	0
However, a publication is not necessarily justified based on the observations.	Review	O	0
I truly believe that there is people that will be interested in this approach (e.g. farmers, producers etc.)	Review	O	0
but a publication at an ICLR workshop is not the right venue for this paper.	Review	O	0
The network was not designed to compete against leaders in MS COCO/Pascal datasets, it is specific to this problem, like tumor segmentation or similar.	Reply	B-Reply	1
Results for MS COCO and Pascal were produced for reference, which is stated in the paper.	Reply	I-Reply	1
On our test data finetuned state-of-the-art algorithm Mask R-CNN produces 68.7% AP at 0.5 threshold and 27.7% mAP (at 50%:95% thresholds) vs FCN+MaskExtractor+BadOverlapsExtractor producing 69.4% AP at 0.5 threshold and 35.2% mAP (at 50%:95% thresholds).	Reply	I-Reply	1
Reported improvements in benchmark datasets are rarely larger.	Reply	I-Reply	1
[line_break_token][line_break_token]Giving all the details is simply intractable in a 3-page paper, it was intended to demonstrate the applicability and the potential of the idea of transforming (ignore pixels) and extracting additional information from the ground truth mask (count the number of 'bad' overlaps, e.g. 1 prediction/2+ cows or 2+ predictions/1 cow).	Reply	O	0
 There are two additional modules, one that learns good predictions and one that learns which ones are 'bad'.	Reply	O	0
They were intended to get the network to output single prediction (mask) per single observation (cow, in this case).	Reply	O	0
This solution is perfectly transferable to any object vs background problem with heavy partial occlusion.	Reply	O	0
I didn't use any negative hardmining: only positive blobs were segmented in the ground truth.	Reply	O	0
  [line_break_token][line_break_token]     	Reply	O	0

This paper suggests a quantization approach for neural networks, based on the Product Quantization (PQ) algorithm which has been successful in quantization for similarity search.	Review	O	0
The basic idea is to quantize the weights of a neuron/single layer with a variant of PQ, which is modified to optimize the quantization error of inner products of sample inputs with the weights, rather than the weights themselves.	Review	O	0
This is cast as a weighted variant of k-means.	Review	O	0
The inner product is more directly related to the network output (though still does not account for non-linear neuron activations) and thus is expected to yield better downstream performance, and only requires introducing unlabeled input samples into the quantization process.	Review	O	0
This approach is built into a pipeline that gradually quantizes the entire network.	Review	O	0
[line_break_token][line_break_token]Overall, I support the paper and recommend acceptance.	Review	O	0
PQ is known to be successful for quantization in other contexts, and the specialization suggested here for neural networks is natural and well-motivated.	Review	O	0
The method can be expected to perform well empirically, which the experiments verify, and to have potential impact.	Review	O	0
[line_break_token][line_break_token]Questions:[line_break_token]1.	Review	O	0
Can you comment on the quantization time of the suggested method?	Review	B-Review	1
Repeatedly solving the EM steps can add up to quite an overhead.	Review	I-Review	1
Does it pose a difficulty?	Review	I-Review	1
How does it compare to other methods?	Review	I-Review	1
[line_break_token]2.	Review	O	0
Can you elaborate on the issue of non-linearity?	Review	B-Review	2
It is mentioned only briefly in the conclusion.	Review	I-Review	2
What is the difficulty in incorporating it?	Review	I-Review	2
Is it in solving equation (4)?	Review	I-Review	2
And perhaps, how do you expect it to effect the results?	Review	I-Review	2
e thank Reviewer 2 for their support and questions.	Reply	O	0
We answer them below.	Reply	O	0
[line_break_token][line_break_token]Quantization time[line_break_token]As we state in our paper, quantizing a ResNet-50 (quantization + finetuning steps) takes about one day on one Volta V100 GPU.	Reply	O	0
The time of quantization is around 1 to 2 hours, the rest being dedicated to finetuning.	Reply	B-Reply	1
Thus, the time dedicated to quantization is relatively short, especially compared with the fine-tuning and even more with the initial network training.	Reply	I-Reply	1
This is because we optimized our EM implementation in at least two ways as detailed below.	Reply	I-Reply	1
[line_break_token]-[tab_token]The E-step is performed on the GPU (see file src/quantization/distance.py, lines 61-75) with automatic chunking.	Reply	I-Reply	1
This means that the code chunks the centroids and the weight matrices into blocks, performs the distance computation on those blocks and aggregates the results.	Reply	I-Reply	1
This falls within the map/reduce paradigm.	Reply	I-Reply	1
Note that the blocks are automatically calculated to be the largest that fit into the GPU, such that the utilization of the GPU is maximized, so as to minimize the compute time.	Reply	I-Reply	1
[line_break_token]-[tab_token]The M-step involves calculating a solution of a least squares problem (see footnote 2 in our paper).	Reply	O	0
The bottleneck for this is to calculate the pseudo-inverse of the activations x. However, we fix x when iterating our EM algorithm, therefore we can factor the computation of the pseudo inverse of x before alternating between the E and the M steps (see file src/quantization/solver.py and in particular the docstring).	Reply	B-Reply	1
[line_break_token][line_break_token]We provided pointers to the files in the code anonymously shared on OpenReview.	Reply	I-Reply	1
To our knowledge, these implementation strategies are novel in this context and were key in the development of our method to be able to iterate rapidly.	Reply	I-Reply	1
Both strategies are documented in the code so that they can benefit to the community.	Reply	I-Reply	1
[line_break_token][line_break_token]Incorporating the non-linearity[line_break_token]As the Reviewer rightfully stated, optimally we should take the non-linearity in Equation (4) into account.	Reply	O	0
One could hope for a higher compression ratio.	Reply	B-Reply	2
Indeed, the approximation constraint on the positive outputs would stay the same (they have to be close to the original outputs).	Reply	I-Reply	2
On the other hand, the only constraint lying on the negative outputs is that they should remain negative (with a possible margin), but not necessarily close to the original negative outputs.	Reply	I-Reply	2
 However, our early experiments with this method resulted in a rather unstable EM algorithm.	Reply	I-Reply	2
This direction may deserve further investigation.	Reply	I-Reply	2

Review: This paper deals with the issue of learning rotation invariant autoencoders and classifiers.	Review	O	0
 While this problem is well motivated, I found that this paper was fairly weak experimentally, and I also found it difficult to determine what the exact algorithm was.	Review	B-Review	7
 For example, how the optimization was done is not discussed at all.	Review	I-Review	7
 At the same time, I'm not an expert in group theory, so it's possible that the paper has technical novelty or significance which I did not appreciate.	Review	I-Review	7
 [line_break_token][line_break_token]Strengths: [line_break_token][line_break_token] -The challenge of learning rotation equivariant representations is well motivated and the idea of learning representations which transfer between different scales also seems useful.	Review	O	0
 [line_break_token][line_break_token]Weaknesses: [line_break_token]  [line_break_token]-I had a difficult time understanding how the preliminaries (section 2) were related to the experiments (section 3).	Review	O	0
 [line_break_token][line_break_token]-The reference (Kondor 2018) is used a lot but could refer to three different papers that are in the references.	Review	O	0
 [line_break_token][line_break_token]  -Only reported results are on rotated mnist, but the improvements seem reasonable, but unless I'm missing something are worse than the 1.62% error reported by harmonic nets (mentioned in the introduction of the paper).	Review	O	0
 In addition to rot-mnist, harmonic nets evaluated boundary detection on the berkeley segmentation dataset.	Review	B-Review	3
 [line_break_token][line_break_token]  -It's interesting that the model learns to be somewhat invariant across scales, but I think that the baselines for this could be better.	Review	O	0
 For example, using a convolution network with mean pooling at the end, one could estimate how well the normal classifier handles evaluation at a different scale from that used during training (I imagine the invariance would be somewhat bad but it's important to confirm).	Review	B-Review	4
 [line_break_token][line_break_token][line_break_token]Questions: [line_break_token][line_break_token]-Section 3.1 makes reference to "learning parameters".	Review	O	0
 I assume that this is done in the usual way with backpropagation and then SGD/Adam or something?	Review	B-Review	5
 [line_break_token][line_break_token]-How is it guaranteed that W is orthogonal in the learning procedure?	Review	O	0
 [line_break_token]	Review	B-Review	1
Thanks for the review comments.	Reply	O	0
[line_break_token]>Review: This paper deals with the issue of learning rotation invariant autoencoders and classifiers.	Reply	O	0
 While this problem is well motivated, I found that this paper was fairly weak experimentally, and I also found it difficult to determine what the exact algorithm was.	Reply	O	0
 For example, how the optimization was done is not discussed at all.	Reply	O	0
 At the same time, I'm not an expert in group theory, so it's possible that the paper has technical novelty or significance which I did not appreciate.	Reply	O	0
 [line_break_token][line_break_token][Reply] The algorithm for learning a CW basis is now stated explicitly in the appendix.	Reply	O	0
We have summarised our approach in the response to AnonReviewer3.	Reply	B-Reply	7
We have given it as comments titled "Summary 1 of 2" & "Summary 2 of 2".	Reply	O	0
[line_break_token][line_break_token]We discuss our Implementation now in Section 3.4.	Reply	B-Reply	7
The main technical novelty is that equivariance is easily learned in the CW basis.	Reply	I-Reply	7
As AnonReviewer1 points out, tensor product nonlinearity is perhaps more important than the basis itself.	Reply	I-Reply	7
[line_break_token]-----[line_break_token][line_break_token]>Strengths: [line_break_token][line_break_token]> -The challenge of learning rotation equivariant representations is well motivated and the idea of learning representations which transfer between different scales also seems useful.	Reply	O	0
 [line_break_token][line_break_token][Reply] Thanks for this encouragement.	Reply	O	0
[line_break_token]-----[line_break_token][line_break_token]>Weaknesses: [line_break_token]  [line_break_token]>-I had a difficult time understanding how the preliminaries (section 2) were related to the experiments (section 3).	Reply	O	0
 [line_break_token][line_break_token][Reply] Sorry about this.	Reply	O	0
Perhaps a reason for confusion is that whereas we use the phrase G-morphism[line_break_token]in Section 2, we use the phrase SO(2) equivariant maps in Section 3.	Reply	B-Reply	1
These are the same.	Reply	I-Reply	1
[line_break_token]-----[line_break_token][line_break_token]>-The reference (Kondor 2018) is used a lot but could refer to three different papers that are in the references.	Reply	O	0
 [line_break_token][line_break_token][Reply] Sorry about this.	Reply	O	0
This is now corrected.	Reply	B-Reply	2
[line_break_token]-----[line_break_token][line_break_token]>  -Only reported results are on rotated mnist, but the improvements seem reasonable, but unless I'm missing something are worse than the 1.62% error reported by harmonic nets (mentioned in the introduction of the paper).	Reply	O	0
 In addition to rot-mnist, harmonic nets evaluated boundary detection on the berkeley segmentation dataset.	Reply	O	0
 [line_break_token][line_break_token][Reply] Yes we get about 97%, less than what harmonic nets get but the architecture is very simple.	Reply	O	0
One aspect we did not emphasise much is the last column in table 1.	Reply	B-Reply	3
It is known that Harmonic nets (and many other equivariant networks) need a large amount of data augmentation to perform well on MNIST-rot when trained on upright MNIST.	Reply	I-Reply	3
We need no such augmentation once we have a reasonable W_{28}. In that sense our network is like spherical and FFS2CNN - truly rotation equivariant.	Reply	I-Reply	3
 [line_break_token][line_break_token]We will take a look at Berkeley segmentation data and see what harmonic nets do and see if we can conduct those experiments.	Reply	I-Reply	3
Thanks for this suggestion.	Reply	I-Reply	3
[line_break_token]-----[line_break_token][line_break_token]>  -It's interesting that the model learns to be somewhat invariant across scales, but I think that the baselines for this could be better.	Reply	O	0
 For example, using a convolution network with mean pooling at the end, one could estimate how well the normal classifier handles evaluation at a different scale from that used during training (I imagine the invariance would be somewhat bad but it's important to confirm).	Reply	O	0
 [line_break_token][line_break_token][Reply] Thanks for this suggestion.	Reply	O	0
We have run these experiments.	Reply	B-Reply	4
We trained a CNN with about 489K parameters on MNIST-rot 28x28 images, getting a 95.1 percent accuracy.	Reply	I-Reply	4
[line_break_token]When this was fed 14x14 images scaled up to 28x28, we get 90.5 percent accuracy.	Reply	I-Reply	4
Should we report this in the main paper?	Reply	I-Reply	4
[line_break_token]-----[line_break_token][line_break_token]>Questions: [line_break_token][line_break_token]>-Section 3.1 makes reference to "learning parameters".	Reply	O	0
 I assume that this is done in the usual way with backpropagation and then SGD/Adam or something?	Reply	O	0
 [line_break_token][line_break_token][Reply] Yes, backpropogation using ADAM optimiser.	Reply	O	0
We make this explicit in Section 3.4[line_break_token]-----[line_break_token][line_break_token]>-How is it guaranteed that W is orthogonal in the learning procedure?	Reply	O	0
[line_break_token][line_break_token][Reply] Sorry, we should have mentioned this -we do so now - we add a regularizer to the reconstruction loss.	Reply	O	0
[line_break_token]----	Reply	O	0

This paper tackles the problem of black-box hyperparameter optimization when multiple related optimization tasks are available simultaneously, performing transfer learning between tasks.	Review	O	0
Different tasks correspond to different datasets and/or metrics.	Review	O	0
Gaussian copulas are used to synchronize the different scales of the tasks.	Review	O	0
[line_break_token][line_break_token]I have several reservations with this paper.	Review	O	0
First and foremost, it seems to be lacking a fair and trivial baseline (I will describe it below) that justifies the apparently unnecessary complicated path followed in this paper.	Review	B-Review	2
Second, there are a few small incorrect or improperly justified technical details throughout the paper.	Review	O	0
[line_break_token][line_break_token][line_break_token]1) Mistaken/unjustified technical details:[line_break_token][line_break_token]- In equation 1, the last term seems to be constant.	Review	O	0
For each task, the function psi is not parametric, so its gradient is also not parametric and the input is the inverse of z, i.e., y, which is also fixed.	Review	B-Review	2
So why is it included in the cost function?	Review	I-Review	2
This sort of probabilistic renormalization is important in e.g. warped GPs because the transformation is parametric.	Review	I-Review	2
In this case, I don't see the point.	Review	I-Review	2
It can be treated as a normalization of the input data, prior to its probabilistic modeling.	Review	I-Review	2
[line_break_token][line_break_token]- Before equation 1, the text says "by minimizing the Gaussian negative log-likelihood on the available evaluations (x, z)" But then, equation 1 is not the NLL on z but on y.[line_break_token][line_break_token]- In section 4.2 the authors model the residuals of the previous model using a powerful Matern-5/2 GP.	Review	O	0
Why modeling the residuals this way and not the observations themselves?	Review	B-Review	4
The split of modeling between a parametric and non-parametric part is not justified.	Review	I-Review	4
[line_break_token][line_break_token]- One of the main points of the variable changes is to normalize the scales of the different tasks.	Review	O	0
However, equations 1 adds together the samples of the different tasks (which, as pointed out by the authors might have different sizes).	Review	B-Review	5
Even if the scales of the outputs are uniform, the different dataset sizes will bias the solutions towards larger datasets.	Review	I-Review	5
Why would that be a good thing?	Review	I-Review	5
This is not mentioned and doesn't seem correct: there should not be a connection between a dataset size and the prior influence of the corresponding task.	Review	I-Review	5
In fact, this will have the same effect as if the cost had different scales for different tasks, which is precisely the problem that the authors are trying to avoid.	Review	I-Review	5
[line_break_token][line_break_token][line_break_token]2) Trivial baseline[line_break_token][line_break_token]Given that the authors are trying to aggregate information about the optimal hyperparameters from several tasks, they should not compare with single-task approaches, but with the simplest way to combine all the tasks.	Review	O	0
For instance:[line_break_token]    a) Normalize the outputs of every task.	Review	B-Review	1
This can be accomplished in the usual way by dividing by the standard deviation, or even better, by computing the fixed transform z = psi(y), separately for each task.	Review	I-Review	1
[line_break_token]    b) Collect the z of all tasks and feed them into an existing GP black-box Bayesian optimizer.	Review	I-Review	1
[line_break_token][line_break_token]This is a very simple way to get "transfer learning" and it's unclear that the extra complexities of this paper (copulas, changes of variable with proper renormalization when the transformation is parameter free, etc) are buying much else.	Review	I-Review	1
[line_break_token][line_break_token][line_break_token]Minor improvements:[line_break_token][line_break_token]- Page 2: "is the output of a multi-layer perceptron (MLP) with d hidden nodes" Is d really the number of hidden nodes of the MLP?	Review	O	0
Or the number of outputs?	Review	B-Review	6
Given that d is also the size of w, it seems it's actually the latter.	Review	I-Review	6
[line_break_token][line_break_token]- Explain why the EI approach is used for the second model (with the GP), but not for the first model.	Review	O	0
[line_break_token][line_break_token]Edit after rebuttal:[line_break_token]‚ÄúThe term is not constant over z‚Äù -&gt; Sure, it‚Äôs not constant over z. But z is constant.	Review	O	0
So the term is constant.	Review	B-Review	2
[line_break_token][line_break_token]‚ÄúThe NLL is minimized in z and there is indeed no y in equation 1.‚Äù -&gt; Sure, there‚Äôs no y in the equation, that‚Äôs correct.	Review	O	0
But it is still the NLL of y, and not the NLL of z.[line_break_token][line_break_token]About the new baseline: Instead of simply renormalizing using mean and standard deviation, I suggested above using the same z=psi(y) that is used in the paper for the normalization.	Review	O	0
Is that where the advantage of the proposed method is coming from?	Review	B-Review	1
[line_break_token][line_break_token]"Note that this is orthogonal to the scale issues we focus on: larger tasks will have larger gradient contributions but the scaling we propose still allows us to learn tied parameters across tasks as their scales are made similar. "	Review	I-Review	5
Both issues affect the scaling of the task, so I don't see how they can be orthogonal.	Review	I-Review	5
Their scales are not made similar precisely because of the different sample sizes.	Review	I-Review	5
[line_break_token]	Review	O	0
 "In equation 1, the last term seems to be constant. [...]	Reply	O	0
So why is it included?"	Reply	O	0
[line_break_token][line_break_token]The term is not constant over and is needed when performing the change of variable.	Reply	B-Reply	2
It weights more the error (and gradients) occurring when the quantile function of is changing rapidly.	Reply	I-Reply	2
In other words, error in regions where the quantile function changes rapidly should cost more compared to flat regions.	Reply	I-Reply	2
[line_break_token][line_break_token]* "Before equation 1, the text says 'by minimizing the Gaussian negative log-likelihood on the available evaluations (x, z)' But then, equation 1 is not the NLL on z but on y."[line_break_token][line_break_token]The NLL is minimized in and there is indeed no in equation 1.	Reply	O	0
[line_break_token][line_break_token]* "Why modeling the residuals this way and not the observations themselves?	Reply	O	0
The split of modeling between a parametric and non-parametric part is not justified."	Reply	O	0
[line_break_token][line_break_token]This is in fact a key point of the paper.	Reply	B-Reply	4
Modeling the residuals allows us to set a parametric prior that can transfer well across tasks by avoiding the numerical issues caused by different task and metric scales.	Reply	I-Reply	4
Note that using a parametric prior also avoids the cubic complexity in the number of evaluations that makes it prohibitive to fit a GP on all task evaluations.	Reply	I-Reply	4
[line_break_token][line_break_token]* "Given that the authors are trying to aggregate information about the optimal hyperparameters from several tasks, they should not compare with single-task approaches, but with the simplest way to combine all the tasks.	Reply	O	0
For instance: a) Normalize the outputs of every task. [...]	Reply	O	0
b) Collect the z of all tasks and feed them into an existing GP black-box Bayesian optimizer.	Reply	O	0
This is a very simple way to get "transfer learning" and it's unclear that the extra complexities of this paper (copulas, changes of variable with proper renormalization when the transformation is parameter free, etc) are buying much else."	Reply	O	0
[line_break_token][line_break_token]a) We asked ourselves the same question when designing our approach.	Reply	B-Reply	1
For this reason a simple standardization to normalize tasks (where mean and std computed on each task separately) was evaluated in our ablation study in Section 5.2 and Table 3, where we probe the benefits of the Copulas and parametric priors against simpler alternatives.	Reply	I-Reply	1
The results shows that standard normalizations are not competitive with our proposal, and these baselines perform poorly due to the scale issues met across different tasks and metrics.	Reply	I-Reply	1
Given that this method was not seen in your first review, we renamed it and referenced it better in the ablation description to make it more visible.	Reply	I-Reply	1
[line_break_token][line_break_token]b) Following on the reviewer‚Äôs feedback, we ran additional experiments standardizing the outputs of every task and feeding these into warm-start GP.	Reply	I-Reply	1
While this approach scales cubically in the number of observations, which makes it prohibitive with a large number of observations per task, our proposal of learning a prior does not have this limitation.	Reply	I-Reply	1
Nonetheless, we applied this method by selecting the best hyperparameter evaluations from each related task for a total of 100 evaluations (so as to match the number of observations used in the warm-start GP baseline in the paper).	Reply	I-Reply	1
The results show that our approach significantly outperforms this variant of warm-start GP, confirming as in Table 3 that standardization is not sufficient to transfer information successfully across heterogeneous tasks.	Reply	I-Reply	1
We thank the reviewer for the suggestion and have incorporated this additional baseline into the paper.	Reply	I-Reply	1
[line_break_token][line_break_token]* "One of the main points of the variable changes is to normalize the scales of the different tasks.	Reply	O	0
However, equations 1 adds together the samples of the different tasks (which, as pointed out by the authors might have different sizes)... the different dataset sizes will bias the solutions towards larger datasets... In fact, this will have the same effect as if the cost had different scales for different tasks, which is precisely the problem that the authors are trying to avoid."	Reply	O	0
[line_break_token][line_break_token]It is true that we do not normalize by the dataset size.	Reply	B-Reply	5
Note that this is orthogonal to the scale issues we focus on: larger tasks will have larger gradient contributions but the scaling we propose still allows us to learn tied parameters across tasks as their scales are made similar.	Reply	I-Reply	5
We thank the reviewer for the observation and revised the manuscript to discuss this option.	Reply	I-Reply	5
[line_break_token][line_break_token]* "Is d really the number of hidden nodes of the MLP?	Reply	O	0
Or the number of outputs?	Reply	O	0
Given that d is also the size of w, it seems it's actually the latter."	Reply	O	0
[line_break_token][line_break_token]We clarified in the main text that the number of outputs and nodes coincide.	Reply	B-Reply	6
[line_break_token][line_break_token]* "Explain why the EI approach is used for the second model (with the GP), but not for the first model."	Reply	O	0
[line_break_token][line_break_token]As the first model is stateless, the same hyperparameter minimizing EI would be sampled at each step (as opposed to the GP-based model).	Reply	B-Reply	7
This is why we perform Thompson sampling instead	Reply	I-Reply	7

This paper compares two approaches to learn cross-lingual word embeddings: cross-lingual alignment (where separately trained embeddings in different languages are mapped into a shared space) and joint training (which combines the training data in all languages and jointly learns a cross-lingual space).	Review	O	0
The authors argue that each approach has its own advantages, and propose a "unified framework" that essentially applies them sequentially (first train jointly, and then further align them after the necessary vocabulary reallocation).	Review	O	0
[line_break_token][line_break_token]I have generally positive feelings about the paper.	Review	O	0
To be honest, I do not like the way the authors frame their work (e.g. the way the method is motivated in Section 2.3 or calling it a "unified framework"), but the actual method they propose does make sense, the experimental evaluation is solid, and the results are generally convincing.	Review	O	0
[line_break_token][line_break_token][line_break_token]Strengths:[line_break_token][line_break_token]- Good coverage of related work, including recent publications.	Review	O	0
[line_break_token][line_break_token]- Thorough evaluation in 3 different tasks, much better than what is common in the area (usually limited to BLI).	Review	O	0
[line_break_token][line_break_token]- The authors experiment with contextual embeddings in addition to conventional word embeddings.	Review	O	0
[line_break_token][line_break_token]- Generally convincing results with relevant ablations and reasonable baselines.	Review	O	0
[line_break_token][line_break_token][line_break_token]Weaknesses:[line_break_token][line_break_token]- I feel that framing this as a "unified framework" for cross-lingual alignment and joint training is going a bit too far.	Review	O	0
The proposed method is as simple as first doing the joint training and then the cross-lingual alignment (with a special treatment for vocabulary reallocation).	Review	B-Review	1
This is just a sequential application of two class of methods, and not what I would understand as a "unified framework" (which suggests some form of generalization or at least a closer interaction to me).	Review	I-Review	1
At the same time, the only "joint training" that the authors explore is training regular embeddings over concatenated monolingual corpora, which as far as I know has only been explored by Lample et al. (	Review	I-Review	1
2018), and I would not consider as a representative example of this family of methods.	Review	I-Review	1
[line_break_token][line_break_token]- It is not clear how the different vocabulary spaces are handled in BLI.	Review	O	0
My understanding is that if the query is in the source vocabulary subset the retrieval is done over the target subset, and if it is in the shared subset it is the same query word that is returned, but this is not clear at all.	Review	B-Review	2
[line_break_token][line_break_token]- I think that the issue of "oversharing" is magnified in the paper.	Review	O	0
I understand that this is directly connected to the reallocation step in the proposed method, and it of course makes sense to also map words that predominantly appear in a single language.	Review	B-Review	3
However, in relation to the downstream tasks themselves, oversharing only seems relevant for BLI, where one needs to delimit the retrieval space and avoid returning the query word (which is of course its own nearest neighbor) unless it actually exists in the target language.	Review	I-Review	3
This is connected to my previous point, and I think should be discussed in isolation.	Review	I-Review	3
[line_break_token][line_break_token][line_break_token]Other minor things to improve:[line_break_token][line_break_token]- Please make Figure 2c an actual table instead of an image.	Review	O	0
hank you for your comprehensive review and valuable feedback.	Reply	O	0
We address your comments one by one as following:[line_break_token][line_break_token][Terminology and joint training][line_break_token][line_break_token]While we meant to say this is a method that unifies two previously exclusive approaches by calling it a framework, we agree that it can be stated in a better way.	Reply	O	0
We will rephrase our terminology in an updated version.	Reply	B-Reply	1
[line_break_token][line_break_token]The joint training paradigm attracts the community‚Äôs growing attention recently, especially for the contextualized representations such as multilingual BERT.	Reply	I-Reply	1
There are still many open questions such as why joint training models work and how to further improve them.	Reply	I-Reply	1
In addition to the non-contextualized joint training explored by [1], we also conduct experiments for the contextualized representations and show that alignment can still improve pretrained models.	Reply	I-Reply	1
This is consistent with (very) recent results [2], which also suggest combining ideas from alignment as a future research direction.	Reply	I-Reply	1
[line_break_token][line_break_token][BLI evaluation][line_break_token][line_break_token]Your understanding of the evaluation protocol is correct.	Reply	O	0
We concatenate each language‚Äôs own subset with the shared subset and use the two concatenated parts for evaluation.	Reply	B-Reply	2
This is equivalent to your description since if the query is in the shared part it will automatically retrieve itself by the nature of CSLS.	Reply	I-Reply	2
We will make this clear in an updated version.	Reply	I-Reply	2
[line_break_token][line_break_token][Oversharing][line_break_token][line_break_token]The oversharing issue has three undesirable effects: (1) it results in a poor seed dictionary for the joint initialization (2) it prohibits the application of alignment refinement, and because of which, (3) it hinders performance on downstream tasks by making false assumptions on word translations.	Reply	O	0
While we agree that it is most relevant for BLI in our experiments, recent work [3] also shows less sharing (thus a larger vocab size &amp; more parameters) can be beneficial for contextualized representations on harder downstream tasks such as language understanding and question answering, and we hypothesize this is partly due to oversharing of tokens with different meanings in different languages.	Reply	O	0
[line_break_token][line_break_token][1] Phrase-Based &amp; Neural Unsupervised Machine Translation.	Reply	O	0
Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, Marc'Aurelio Ranzato.	Reply	O	0
EMNLP 2018[line_break_token][2] Emerging Cross-lingual Structure in Pretrained Language Models.	Reply	O	0
Shijie Wu, Alexis Conneau, Haoran Li, Luke Zettlemoyer, Veselin Stoyanov.	Reply	O	0
Preprint 2019 <a href="https://arxiv.org/abs/1911.01464" target="_blank" rel="nofollow">https://arxiv.org/abs/1911.01464</a>[line_break_token][3] On the Cross-lingual Transferability of Monolingual Representations.	Reply	O	0
Mikel Artetxe, Sebastian Ruder, Dani Yogatama.	Reply	O	0
Preprint 2019 <a href="https://arxiv.org/abs/1910.11856" target="_blank" rel="nofollow">https://arxiv.org/abs/1910.11856</a>	Reply	O	0

The authors propose to approximate the posterior over weights by minimizing KL(p||q) where p denotes the true posterior and q denotes a diagonal Gaussian approximation.	Review	O	0
The authors collect multiple samples from the posterior by running SGLD and learn the variational approximation by updating the mean and variance of the weights in an incremental fashion (which removes the need to store all previous samples).	Review	O	0
In practice, the authors use Adam + small gradient noise with fixed standard deviation instead of a properly tuned SGLD.	Review	O	0
Overall, it's a quite simple idea to learn a distribution over weights and   looks promising for outlier detection.	Review	O	0
It under-performs compared to explicit ensemble, however the proposed method is more memory efficient and requires just training 1 model.	Review	O	0
[line_break_token][line_break_token]Questions:[line_break_token]- Do you use all the samples or do you have some sort of "burn-in" phase where you ignore the first few samples as they could be quite bad?	Review	O	0
Did you try "thinning" the samples, i.e. use only every K-th sample or so?	Review	B-Review	1
[line_break_token]- how do you choose d_x in (4)?	Review	O	0
[line_break_token]- There has been some work on expectation propagation for Bayesian neural networks which also minimize KL(p||q).	Review	O	0
See "Stochastic expectation propagation" by Li et al.	Review	B-Review	3
2015 and "Distributed Bayesian learning with stochastic natural-gradient expectation propagation and the posterior server" by Hasenclever et al.	Review	I-Review	3
2015.	Review	I-Review	3
It would be nice to discuss connections to these works.	Review	I-Review	3
[line_break_token]- The snapshot ensemble code is available online at <a href="https://github.com/gaohuang/SnapshotEnsemble."	Review	O	0
target="_blank" rel="nofollow">https://github.com/gaohuang/SnapshotEnsemble.</a> It'd be worth understanding why/when it underperforms.	Review	O	0
Thanks for your remarks.	Reply	O	0
Answering each of the points  in the same order:[line_break_token]- We burn the first 100 iterations.	Reply	O	0
Since all the collected samples are used in the calculation of the Gaussian parameters, including the samples of low likelihood from the beginning of training did result in decreased performance.	Reply	B-Reply	1
We tried thinning (between 2 and 20 steps) and it did not yield a significant change in performance, in the cases that the number of samples collected were the same, i.e. collecting 100 samples from 100 steps yields similar performance to collection 100 samples from 200 steps with thinning factor of 2 (assuming the previous burn-in).	Reply	I-Reply	1
Given this, we chose to not use thinning and have a smaller number of gradient descent steps.	Reply	I-Reply	1
[line_break_token]- d_x is defined as the ensemble prediction disagreement for the input x, as per Lakshminarayanan[line_break_token]et al. (	Reply	O	0
2016).	Reply	B-Reply	2
[line_break_token]- Thanks for the suggestion, we were not aware of that line of work.	Reply	O	0
We are looking into it and will update the paper to include any similarities worth mentioning.	Reply	B-Reply	3
[line_break_token]- Yes, we are also suspicious about why we couldn't get snapshot ensembles to yield results in the same line of the original paper - we were a bit short on time and didn't manage to figure it out before the deadline.	Reply	O	0
We have looked into the implementation and ours seems to be aligned, but we will keep looking (it is possible that this is a matter of hyperparameter choice, since there are several additional hyperparameters at play in this model)	Reply	B-Reply	4

This paper proposes a method to address the interesting task, i.e. controllable human activity synthesis, by conditioning on the previous frames and the input control signal.	Review	O	0
To synthesis the next frame, a Pose2Pose network is proposed to first transfer the input information into the next frame body structure and object.	Review	O	0
Then, a Pose2Frame network is applied to generate the final result.	Review	O	0
The results on several video sequences look nice with more natural boundaries, object, and backgrounds compared to previous methods.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
The proposed Pose2Pose successfully transfer the pose conditioned on the past pose and the input control signal.	Review	O	0
The proposed conditioned residual block, occlusion augmentation and stopping criteria seem to help the Pose2Pose network work well.	Review	O	0
Besides, the object is also considered in this network, which makes the method generalized well to the videos where human holds some rigid object.	Review	O	0
[line_break_token]2.	Review	O	0
The Pose2Frame network is similar to previous works but learns to predict the soft mask to incorporate the complex background and to produce shallow.	Review	O	0
The mask term in Eq. (	Review	O	0
7) seems to work well for the foreground (body+object) and the shallow regions.	Review	O	0
[line_break_token]3.	Review	O	0
The paper is easy to follow.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
Since the method is only evaluated on several video sequences, I am not sure how the method will perform on other different scenes.	Review	B-Review	1
Results on more scenes will make the performance more convincing.	Review	I-Review	1
I also wonder if the video data will be released, which could be important for the following comparisons.	Review	I-Review	1
[line_break_token]2.	Review	O	0
As to the results of the Pose2Pose network, I wonder if there are some artifacts that will affect the performance of the Pose2Frame network.	Review	B-Review	2
Then, there will be another question: how the two networks are trained?	Review	I-Review	2
Are they trained separately or jointly?	Review	I-Review	2
I assume the authors first train the Pose2Pose network, then use the output to train the Pose2Frame network.	Review	I-Review	2
Otherwise, the artifacts from Pose2Pose will affect the testing performance of the Pose2Frame network.	Review	I-Review	2
[line_break_token]3.	Review	O	0
The mask term seems to work well for the shallow part.	Review	B-Review	3
I wonder how the straightforward regression term plus the smooth term will perform for the mask.	Review	I-Review	3
Here, the straightforward regression term means directly regress the output mask to the target densepose mask.	Review	I-Review	3
Will the proposed mask term perform better?	Review	I-Review	3
[line_break_token]	Review	O	0
1.	Reply	O	0
We aimed to provide a broad variety of example applications (playing tennis, walking, fencing, dancing), while mainly focusing on the most complicated (tennis) application, for a thorough analysis of our method.	Reply	B-Reply	1
Unfortunately, we cannot release the dataset, since we do not own the videos, but we will share our code.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
The Pose2Pose and Pose2Frame networks are trained separately.	Reply	B-Reply	2
Specifically, the P2F network is trained on the original data, and not on the output frames of the P2P network.	Reply	I-Reply	2
You are correct that some artifacts are added to the final P2F output at test time, yet they are minor due to the structural stability of the poses generated by the P2P network.	Reply	I-Reply	2
Furthermore, training the P2F network with the P2P outputs is problematic, since we do not have the ground-truth for the new pose generated by the P2P network.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
The mask loss proposed in the review is similar to our implementation, except that we make a distinction between an inner-mask control and an outer-mask control.	Reply	B-Reply	3
Our mask regression losses consist of a first loss penalizing the mask from being active outside the densepose mask, and a second loss penalizing the mask from being inactive inside the densepose mask.	Reply	I-Reply	3
Combining them both results in the suggested loss	Reply	I-Reply	3

The paper proposes to integrate sequential information into imitation learning techniques.	Review	O	0
 The assumption is that mostly all the IL techniques are learning a policy which depends on state at time t, while the information contained in this state may be not sufficient to choose the right action (actually, this is the POMDP setting, the notion of POMDP not appearing in the paper....).	Review	O	0
The authors thus propose to use a recurrent neural network to encode the state by aggregating past information, instead of just using the features of the state at time t. They thus instantiate this idea on different methods and show that, on some problems, this approach can increase the quality of the final policy.	Review	O	0
[line_break_token][line_break_token]Actually, the contribution of the paper is a simple extension of existing methods: using a RNN instead of a simple NN in imitation learning models.	Review	B-Review	5
First of all, when dealing with classical environments such as Atari, many papers propose to use the last N frames as a state encoding (instead of the last frame), following the same intuition.	Review	O	0
The studied setting thus corresponds to the PO-MDP case and using a RNN in POMDP is for example what is done in  [Merel etal.	Review	O	0
2017]. Moreover, the problem of imitation learning (and particularly inverse RL) in POMDP has been of the interest of many papers like [Choi et al.	Review	O	0
2008] for instance and many more, and it is unclear what is the positioning of this paper w.r.t existing works.	Review	B-Review	4
Since the paper proposes just to encode history with a RNN, the proposed solution lacks of originality, and the contribution of the paper in term of model is quite low.	Review	I-Review	1
 But the authors explain how this can be instantiated in three different settings (IRL, GAIL and BC) -- note that the section concerning the use of Adaboost is not clear and could be better described -- which can be of the interest of the community.	Review	I-Review	1
[line_break_token]Concerning the experiments, I don't understand what is the split between training and testing data.	Review	I-Review	2
Is it pairs of state-action coming from the experts ?	Review	I-Review	2
or trajectories ?	Review	I-Review	2
Moreover, I don't understand why these environments correspond to POMDP cases and the authors have to give details on that.	Review	I-Review	3
For instance, mountain-car is clearly not a POMDP problem in its classical shape, nor Acrobot.	Review	I-Review	3
As if, it makes the experiments very difficult to reproduce.	Review	I-Review	3
The interest of using the RNN to encode history does not seem clear for each of the cases since it often degrades the final performance, so I don't know exactly what insights I can extract from the paper.	Review	I-Review	3
[line_break_token][line_break_token]Pro:[line_break_token]* The approach is proposed for IRL, GAIL and BC[line_break_token][line_break_token]Cons:[line_break_token]* Lack of positionning w.r.t POMDP litterature[line_break_token]* Lack of details in the experiments, and lack of good experimental results[line_break_token]* Low contribution in term of model[line_break_token][line_break_token][line_break_token][Merel et al.	Review	O	0
2017]  Learning human behaviors from motion capture[line_break_token]by adversarial imitation[line_break_token][Choi et al.]	Review	O	0
Inverse Reinforcement Learning in Partially Observable[line_break_token]Environments	Review	O	0
We thank the reviewer for valuable comments.	Reply	B-Reply	5
While the idea is simple and the contribution in term of model seems small, we posed an important problem that sequential information is important in the RL-related approaches.	Reply	I-Reply	5
[line_break_token][line_break_token]We are sorry that we have missed the connection between this work and POMDPs.	Reply	I-Reply	3
The mentioned papers will be cited and discussed thoroughly.	Reply	I-Reply	3
We provide a simple solution to RL in POMDPs, which is the major contribution of this work.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding "lack of good experimental results", we achieved much better scores in most scenarios, and in some of them, we achieved better performance than human experts.	Reply	I-Reply	3
[line_break_token][line_break_token]Regarding experimental details, we can provide more in the revised version.	Reply	I-Reply	3
[line_break_token][line_break_token]Thanks again for helping us improve the quality of this paper	Reply	O	0

The paper develops a new method for adapting models trained on labeled data from some source domain to unlabeled data in a target domain.	Review	O	0
The authors accomplish this by adapting a technique from [1] and [2] enforcing that the deep features learned during training approximately follow a Gaussian mixture distribution.	Review	O	0
With the learned features in this form, the authors ensure domain adaptation by minimizing the discrepancy between the distributions arising from the source and target datasets.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token] + The paper's experiments show an improvement in the model's performance relative to past work, utilizing a large number of comparison models.	Review	O	0
[line_break_token] + The use of explicit distributional information within the learned representations seems like a good fit for the task at hand, and the authors' experiments back this up.	Review	O	0
[line_break_token][line_break_token]Weaknesses:[line_break_token] - The proposed method for unsupervised domain adaptation is very similar to the prototypical networks approach in [3], with the primary difference being a loss term incentivizing a Gaussian mixture distribution over features.	Review	O	0
[line_break_token] - While the authors achieve improved performance over [3], the gains in classification accuracy on the target dataset aren't especially huge (~1-3%).	Review	O	0
[line_break_token] - The paper is a bit hard to follow, and would be improved by giving a more explicit comparison of the methods used here to past work, especially [1] and [3].[line_break_token][line_break_token][line_break_token][1] Weitao Wan, Yuanyi Zhong, Tianpeng Li, and Jiansheng Chen.	Review	O	0
Rethinking feature distribution for loss functions in image classification.	Review	O	0
2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.	Review	O	0
9117‚Äì9126, 2018.	Review	O	0
[line_break_token][line_break_token][2] Hong-Ming Yang, Xu-Yao Zhang, Fangying Yin, and Chenglin Liu.	Review	O	0
Robust classification with convolutional prototype learning.	Review	O	0
2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.	Review	O	0
3474‚Äì3482, 2018.	Review	O	0
[line_break_token][line_break_token][3] Yingwei Pan, Ting Yao, Yehao Li, Yu Wang, Chong-Wah Ngo, and Tao Mei.	Review	O	0
Transferrable prototypical networks for unsupervised domain adaptation.	Review	O	0
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.	Review	O	0
2239‚Äì2247, 2019.	Review	O	0
hanks for reviewing our paper.	Reply	O	0
Here are some points that are not fair to our work based on the weaknesses you have mentioned and we want to argue about them:[line_break_token][line_break_token]1).	Reply	O	0
There is some connection between our work and the work in [1]. As we have stated in the Related Works section, in [2], "learning PN is equivalent to performing mixture density estimation on the deep features with an exponential density".	Reply	B-Reply	3
Thus, modeling the feature distribution as Gaussian Mixture, which is a type of exponential density, is equivalent to learn a Prototypical Network.	Reply	I-Reply	3
This statement induces some connection between our work and the work in [1]. However, this equivalence is only true when learning a model in a single domain.	Reply	I-Reply	3
Our work is way different from Pan et al.	Reply	I-Reply	3
's work in the setting of domain adaptation.	Reply	I-Reply	3
[line_break_token][line_break_token]First, we are based on different ideas.	Reply	I-Reply	3
While Pan et al.	Reply	I-Reply	3
propose a novel idea to remold PN for domain adaptation, as stated in their paper, our work is based on the idea that almost all existing domain adaptation methods are minimizing the feature distribution discrepancy for effective knowledge transfer from source domain to target domain, but none of them explicitly models the feature distribution though intuitively it facilitates the measuring of distribution discrepancy.	Reply	I-Reply	3
[line_break_token][line_break_token]Second, the two works propose different distribution discrepancy loss functions.	Reply	I-Reply	3
While Pan et al.	Reply	I-Reply	3
propose multi-granular distribution discrepancy loss functions at both class-level and sample-level, our work proposes two new distribution discrepancy loss functions based on probability, one is Gaussian Component Mean Matching (GCMM) and one is Pseudo Distribution Matching (PDM).	Reply	I-Reply	3
These two discrepancy loss functions work at different aspects and complement each other, where GCMM brings the two distributions closer, while PDM shapes the two distributions alike.	Reply	I-Reply	3
One central component of a domain adaptation method is the distribution discrepancy loss function, as most domain adaptation methods follow a similar framework to minimize the distribution discrepancy loss function together with a classification loss function for knowledge transfer.	Reply	I-Reply	3
Thus, you may think our work is very similar to Pan et al.	Reply	I-Reply	3
's.	Reply	I-Reply	3
This is because almost all domain adaptation methods follow this similar framework.	Reply	I-Reply	3
We do not agree with the claim that "the primary difference between our work and Pan et al.	Reply	I-Reply	3
's is a loss term incentivizing a Gaussian mixture distribution over features."	Reply	I-Reply	3
Due to the central role distribution discrepancy loss functions play in a domain adaptation method, devising new distribution discrepancy loss functions is an active research area in domain adaptation [3,4,5]. Please do not ignore the two novel discrepancy loss functions we propose based on our feature distribution modeling.	Reply	I-Reply	3
[line_break_token][line_break_token]Third, in terms of training algorithm, our method learns the distribution parameters automatically, while the Pan et al.	Reply	I-Reply	3
's work needs to manually calculate the prototypes for assigning pseudo labels.	Reply	I-Reply	3
[line_break_token][line_break_token]Finally, our proposed method fills the important gap in the area of domain adaptation, and to the best of our knowledge, no existing UDA methods have tried to model the feature distribution for domain adaptation.	Reply	I-Reply	3
[line_break_token][line_break_token]2).	Reply	O	0
For the digits image transfer tasks, state-of-the-art results are already quite high, all above 92%, thus a 1~3% of accuracy increase should be considered as significant.	Reply	B-Reply	2
There is not much room for a new method to make a huge improvement.	Reply	I-Reply	2
If we treat the "Train-on-target" accuracy as the upper bound, the difference of accuracy between the second best results and the upper bound is quite limited, being 5.2%, 2.6%, 6.3% for the transfer M-&gt;U, U-&gt;M, S-&gt;M respectively.	Reply	O	0
For VisDA-2017 dataset, our method improved from the second best by 1%, having a accuracy results of 81.4%.	Reply	B-Reply	2
[line_break_token]And it is 1.4% lower than [6], which won the first place in the VisDA-2017 competition.	Reply	I-Reply	2
Thus, although this improvement is not huge, but it should not be considered as marginal	Reply	I-Reply	2

This paper studies whether language composition may emerge by partially re-sampling new agents inside a pool of language agents.	Review	O	0
They set up a consistent experimental setting for assessing compositionality,  assess different agent architectures, e.g., memory vs. memoryless agents,  and explore how the language remains close to each other by re-sampling new agents.	Review	O	0
[line_break_token][line_break_token]The paper is well-motivated with substantial background literature on the cognitive science and emergent communication side.	Review	O	0
The claim is clear, the hypotheses are well-stated, and the experiments look solid (I particularly appreciated the paragraph on shortcoming evaluation).	Review	O	0
In the end, I enjoy reading the paper despite its density, and I could see that the authors made quite some effort in that direction.	Review	O	0
[line_break_token][line_break_token]Improvement direction, questions:[line_break_token] - The authors made were careful not to take ownership of Kottur et al.	Review	O	0
's works.	Review	B-Review	1
Yet, the writing sometimes gives the feeling that their work is solely an extension of Kottur's work, which is not the case.	Review	I-Review	1
It also gives the feeling that Kottur et al.	Review	I-Review	1
is the only valid experimental setting, which is not the case (at the authors pointed out in the related work section).	Review	I-Review	1
Thus, I would recommend to summarise at some point the similarity/difference between the two papers, or at least stop referring the paper every two lines!	Review	I-Review	1
[line_break_token] - Replacement strategy: the authors use simple replacement strategies, and conclude that it has little impact.	Review	O	0
Althought It sounds reasonable in the current setting, the conclusion may be a bit premature.	Review	B-Review	2
I would recommend to discuss further this result with complementary experiments could be the following: see the impact of epsilon, trying tournament strategies, why 8 populations (this sounds a bit arbitrary too).	Review	I-Review	2
I would also like to put those observations in perspective with the evolutionary literature [1], and even provide a full paragraph in the related work section.	Review	I-Review	2
[line_break_token] - Population dynamics: I am missing a key element in the paper: an analysis of the population dynamics.	Review	O	0
Although the paper deals with generational transmissions, there are no experiments that analyze the evolution of language generations after generations.	Review	B-Review	3
Most of the experiments deal with the final convergence state.	Review	I-Review	3
Again, I would recommend having a look at the evolutionary literature to see which protocol they use to analyze such behavior.	Review	I-Review	3
[line_break_token] - Literature side: The authors did an excellent job on the emergent communication and cognitive science side.	Review	O	0
I think that it is worth extending the comparison further.	Review	B-Review	4
For instance: [line_break_token]    * generational transmission can be studied in the light of game theory [2] where compositionality can be seen as a Nash Equilibrium between agent.	Review	I-Review	4
[line_break_token]    * generational transmission is a form of dynamic distillation [3][line_break_token]    * and evolutionary algorithms!	Review	I-Review	4
[line_break_token] - I had some difficulties in understanding Fig4, and the final-take away correctly.	Review	O	0
Would it be possible to give me one or two examples to correctly parse the table?	Review	B-Review	5
More generally, I would recommend to add a few lines with some concrete and cherry-picked examples from the experiments to help the reader to have more intuition).	Review	I-Review	5
[line_break_token] - In a similar spirit, it is hard to interpret the distance in Figure 3.	Review	O	0
What would correspond to an increase of 1pt of distance?	Review	B-Review	6
Having said that, the experiment is sound, and it is insightful.	Review	I-Review	6
[line_break_token] - reproducible: having a final table in the array in the appendix could be very helpful [line_break_token] - crazy experiment: even if I am also a DRL addict, I would be curious to train one of the models with evolutionary algorithms (CMA-ES over parameters, for instance) to assess whether RL has an impact on compositionality (or it is solely the experimental protocol that matters).	Review	O	0
[line_break_token] - I may have missed this point, but how many seeds did you use to run your experiments?	Review	O	0
[line_break_token] - I may have also missed this point, what is the average length of the dialogue.	Review	O	0
Can you upload (non-understandable) dialogue example?	Review	B-Review	10
[line_break_token][line_break_token]Last point... but it does not undermine the soundness of the experimental protocol!	Review	O	0
[line_break_token] - In the end, Is 25 accuracy points really compositionality?	Review	O	0
What would be the score of simple strategies with overcomplete tokens?	Review	B-Review	11
What is the score of the minimal vocab if we are only correct with one modality, two modalities?	Review	I-Review	11
[line_break_token][line_break_token][line_break_token][line_break_token]Remarks:[line_break_token] - in the introduction, you mention that previous old agents have grounded language, I am not sure whether we can speak of grounded language here, they have a predefined language, but it is not grounded.	Review	O	0
[line_break_token] - Please remove the bold sentence in the introduction :) The claim is clear!	Review	O	0
[line_break_token] - P11: Alg undefined[line_break_token] - P12: the legend cannot be read[line_break_token] [line_break_token][line_break_token]Conclusion[line_break_token]I am familiar with this type of experimental protocols, and I am well aware that they are never-ending works.	Review	O	0
There are always more experiments to do, more parameters to analyze.	Review	O	0
The final question is the following: is this paper have enough of these never-ending experiments?	Review	B-Review	16
I think that this paper is just above this threshold by a short margin, and I vouch for weak accept.	Review	O	0
[line_break_token][line_break_token]However, I am missing at least one dynamic figure (to see the impact of the population along time, which is one of the core concepts of the paper), and there are several links with other ML communities that still have to be highlighted (especially evolutionary algorithms).	Review	O	0
[line_break_token]Besides, I somehow feel that the authors pursue two different goals in this paper: they both analyze memory/memoryless complete/overcomplete agents, which is somehow orthogonal to the general transmission hypothesis.	Review	B-Review	8
Maybe, It would have made more sense to focus on one (or two) of the models and change the experimental setting on them (population size, training time, etc.)	Review	I-Review	8
[line_break_token][line_break_token]In the end, I would favor a weak accept.	Review	O	0
[line_break_token]I am open to discussion regarding this scoring.	Review	O	0
[line_break_token][line_break_token][1] B√§ck, Thomas, and Frank Hoffmeister. "	Review	O	0
Extended selection mechanisms in genetic algorithms." (	Review	O	0
1991).	Review	O	0
[line_break_token][2] Lanctot, Marc, et al. "	Review	O	0
A unified game-theoretic approach to multiagent reinforcement learning."	Review	O	0
Advances in Neural Information Processing Systems.	Review	O	0
2017.	Review	O	0
[line_break_token][3] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. "	Review	O	0
Distilling the knowledge in a neural network."	Review	O	0
arXiv preprint arXiv:1503.02531 (2015).	Review	O	0
hanks for the well balanced review and depth of feedback!	Reply	O	0
We generally agree with the comments and suggestions and add clarifications, additional information, and some rebuttal below.	Reply	O	0
[line_break_token][line_break_token]__Comment (referencing Kottur et al)__: ‚ÄúThe authors made were careful not to take ownership of Kottur et al.	Reply	O	0
's works.	Reply	O	0
Yet, the writing sometimes gives the feeling that their work is solely an extension of Kottur's work, which is not the case.	Reply	O	0
‚Äù[line_break_token]__Response__: Thanks!	Reply	O	0
This is something we struggled with, so it‚Äôs nice to get feedback.	Reply	B-Reply	1
We will try to better isolate references and clearly indicate the differences.	Reply	I-Reply	1
[line_break_token][line_break_token]__Comment (population dynamics)__: ‚ÄúPopulation dynamics: I am missing a key element in the paper: an analysis of the population dynamics.	Reply	O	0
Although the paper deals with generational transmissions, there are no experiments that analyze the evolution of language generations after generations.	Reply	O	0
Most of the experiments deal with the final convergence state.	Reply	O	0
‚Äù[line_break_token]__Response__: In initial experiments we measured D (the language dissimilarity metric from section 5.2) over training iterations.	Reply	O	0
We will compute this plot for our final experiments and report it in the appendix.	Reply	B-Reply	3
Initial experiments looked as expected: After some initial stabilization D looks like a typical learning curve for the 3 Multi Agent replacement methods, decreasing quickly at first then continuing to decrease slowly in later generations.	Reply	I-Reply	3
The No Replacement strategy converges immediately and then either stays fixed throughout training or sometimes (for Small Vocab models) actually increases over the course of training.	Reply	I-Reply	3
[line_break_token][line_break_token]__Comment (literature)__: ‚ÄúLiterature side: The authors did an excellent job [...] I think that it is worth extending[...]‚Äù[line_break_token]__Response__: Thanks for pointing out the relations to game theory and dynamic distillation.	Reply	O	0
Previous drafts did briefly discuss the relation to evolutionary algorithms, but we ended up cutting that discussion to help meet the page limit.	Reply	B-Reply	4
We will add these changes as space allows.	Reply	I-Reply	4
[line_break_token][line_break_token]__Commen (qualitative figure clarification)__: ‚ÄúI had some difficulties in understanding Fig4, and the final-take away correctly.	Reply	O	0
Would it be possible to give me one or two examples to correctly parse the table?	Reply	O	0
More generally, I would recommend[...]‚Äù[line_break_token]__Response__: Thanks for the suggestion.	Reply	O	0
We will add further explanation along the lines of what follows to the paper: Consider the top left example of Fig 4a.	Reply	B-Reply	5
In this case A-bot is presented with a dashed blue circle.	Reply	I-Reply	5
Due to space constraints, the figure leaves out what Q-bot says.	Reply	I-Reply	5
A-bot‚Äôs first response is the symbol ‚Äú2‚Äù and A-bot‚Äôs 2nd response is the symbol ‚Äú0‚Äù.	Reply	I-Reply	5
The checkmark indicates Q-bot guessed correctly.	Reply	I-Reply	5
The solid green star is a shape in the test set (because the text is in bold).	Reply	I-Reply	5
After the first generation (Fig 4a) Q-bot guessed some other shape.	Reply	I-Reply	5
After subsequent generations (Figs 4b and 4c) Q-bot guessed it correctly, qualitatively demonstrating the improvement in test accuracy we see after many generations.	Reply	I-Reply	5
We will clarify our explanation in the final version.	Reply	I-Reply	5
[line_break_token][line_break_token]__Comment (meaning of D)__: ‚ÄúIn a similar spirit, it is hard to interpret the distance in Figure 3.‚Äù[line_break_token]__Response__: We only intended this metric to be used to compare models and we find it hard to ground in an absolute sense.	Reply	O	0
The Single Agents Combined (roughly most different language) and Random Initialization (roughly most similar language) baselines can be compared to to get a sense of the range of performance for a particular model.	Reply	B-Reply	6
[line_break_token][line_break_token]__Comment (raw results table)__: ‚Äúreproducible: having a final table in the array in the appendix could be very helpful‚Äù[line_break_token]__Response__: We will add this.	Reply	O	0
[line_break_token][line_break_token]__Comment__: Number of seeds and average length.	Reply	O	0
[line_break_token]__Response__: Dialogs all take 2 rounds and we use 4 different random seeds.	Reply	O	0
This makes 16  runs per experiment because there are also 4 splits. (	Reply	B-Reply	10
As we mention in sections 2 and 4)[line_break_token][line_break_token]__Comment__: ‚ÄúLast point... but it does not undermine the soundness of the experimental protocol!	Reply	O	0
In the end, Is 25 accuracy points really compositionality?[...]‚Äù[line_break_token]__Response__: Our models are usually not completely compositional in the sense of 100% test accuracy, but we seem to agree that an intermediate sense of compositionality (between 0% and 100% test accuracy) is useful.	Reply	O	0
What simple strategies should we consider in addition those we already reported?	Reply	B-Reply	11
With respect to modalities, is the reviewer asking about single attribute accuracy (One as in the One vs Both accuracy from Kottur et al)?	Reply	I-Reply	11
[line_break_token][line_break_token]__Comment (grounding)__ ‚Äú[...]I am not sure whether we can speak of grounded language here[...]‚Äù[line_break_token]__Response__: The observations made by A-bot are of simple attribute tokens fed through a learned embedding.	Reply	O	0
They are not perceptual observations, so the language is not grounded in any perceptual environment in the normal sense.	Reply	B-Reply	12
We think it is reasonable to say the language is grounded in these tokens, but agree the perspective is more controversial than the normal sense of grounding.	Reply	I-Reply	12
We will make this discussion a bit more delicate	Reply	I-Reply	12

This paper proposes a method to train graph neural networks on dense hardware such as TPUs.	Review	O	0
The method is motivated by an observation that connections in graphs have locality in some datasets.	Review	O	0
 Experiments show significant improvements in training speed compared to single-GPU training.	Review	O	0
[line_break_token][line_break_token]The overall score of this paper is slightly positive.	Review	O	0
There is a certain demand to perform training on hardware targeted to dense computations.	Review	O	0
Even though the applications of the proposed method is limited to data with low-bandwidth, the paper shows there are real applications of the method.	Review	O	0
The effectiveness of the proposed method is well-supported by the experiments.	Review	O	0
[line_break_token][line_break_token]Major comments:[line_break_token]Comparisons with single-GPU training can be unfair.	Review	O	0
The method in Ma et al. (	Review	B-Review	1
2018) is indeed not easy to scale many GPUs because their target is processing extremely large graphs in parallel.	Review	I-Review	1
Since the experiments in the submitted paper use relatively small graphs that fit in a single GPU memory, it will not be so challenging to scale many GPUs.	Review	I-Review	1
At least, it is recommended to compare the results with training on several GPUs using data-parallel execution implemented in TensorFlow (or any other suitable frameworks).	Review	I-Review	1
If it is difficult, please provide more specific reasons why it is challenging to perform multi-GPU training.	Review	I-Review	1
hanks for your encouraging review!	Reply	O	0
[line_break_token][line_break_token]We don't claim that it is impossible to match our training speeds using a large number of GPUs, but we are not aware of any work that has successfully done so.	Reply	B-Reply	1
Our claim in this regard is simply that we have achieved training speeds that are far better than any existing results.	Reply	I-Reply	1
While we agree Ma et al. [	Reply	I-Reply	1
2018] focus on larger graphs, we do not think all the challenges they encounter could be totally avoided on the Allamanis et al. [	Reply	I-Reply	1
2018] dataset that we use.	Reply	I-Reply	1
For example, we believe the challenges related to shared PCIe interconnect [Ma et al.	Reply	I-Reply	1
2018, Sec.	Reply	I-Reply	1
6.3] would still persist.	Reply	I-Reply	1
[line_break_token][line_break_token]We reported single GPU training times to establish that training the model to state of the art accuracy takes a reasonable amount of time.	Reply	I-Reply	1
This helps contextualize the results we get on multi-TPU training.	Reply	I-Reply	1
[line_break_token][line_break_token]We'd like to reiterate that before this work, it was not clear that it would be possible to use dense hardware to train sparse GNNs in any reasonable timeframe at all, because the hardware is very specialized to fixed-size dense computation, and a naive densification of large graphs isn't feasible.	Reply	I-Reply	1
Our results showing that it's possible are valuable because this style of dense hardware is becoming increasingly prevalent as hardware becomes more specialized to matrix multiply-based workloads.	Reply	I-Reply	1
Since the presented techniques did allow us to train on TPUs, we exploited the ease of scaling up to 512 cores (with TPUs it is a matter of changing a single parameter) in order to report results from large-batch training of sparse GGNNs, and we also pointed out the fast training time one can achieve this way	Reply	I-Reply	1

This paper fits models to spike trains of retinal ganglion cells that are driven by natural images.	Review	O	0
I think the title should thus include the word ‚Äúactivity‚Äù at the end for otherwise it is actually formally incorrect.	Review	B-Review	1
[line_break_token][line_break_token]Anyhow, this paper proposes more specifically a recurrent network for this time series prediction and compares it to what seems to be the previous approach of a generalized linear model.	Review	O	0
Overall the stated paradigm is that when one can predict the spikes well then one can look into the model and learn how nature does it.	Review	O	0
[line_break_token][line_break_token]In general the paper sounds plausible, though I am not convinced that I learned a lot.	Review	O	0
The results in figure 2 show that the RNN model can predict the spikes a bit better.	Review	B-Review	2
So this is nice.	Review	I-Review	2
But now what?	Review	I-Review	2
You have shown that a more complicated model can produce better fits to the data, though there are of course still some variations to the real data.	Review	I-Review	2
Your initial outline was that a better predictive model helps you to better understand the neural processing in the retina.	Review	I-Review	2
So tell us what you learned.	Review	I-Review	2
I am not a specialist of the retina, but I know that there are several layers and recurrencies in the retina, so I am not so surprised that the new model is better than the GLM.	Review	I-Review	2
[line_break_token][line_break_token]It seems that more complicated recurrent models such as LSTM do not improve the performance according to a statement in the paper.	Review	I-Review	3
However, comparisons on this level are also difficult as a more complex models needs more data.	Review	I-Review	3
Hence, I would actually expect that more layers and even a more detailed model of the retina could eventually improve the prediction even further.	Review	I-Review	3
[line_break_token]I was also a bit puzzled that all the neurons in the network share all the same parameters (weights).	Review	I-Review	4
While the results show that these simplified models can capture a lot of the spike train characteristics, couldn‚Äôt a model with free parameters eventually outperform this one (with correspondingly more training data)?	Review	I-Review	4
[line_break_token]	Review	O	0
Thanks for taking the time to review our manuscript.	Reply	O	0
We will change the title as suggested.	Reply	B-Reply	1
We think, as other reviewers have mentioned, that this work is exciting because it introduces the idea that deep neural networks can be used in a neural modeling context with limited experimental data.	Reply	I-Reply	1
In particular, the framework we introduced for sharing information across neurons allows us to fit richer models given less data, and we believe this will be a powerful approach for modeling data from a number of other brain areas - most of which are much less studied / understood than the retina.	Reply	I-Reply	1
[line_break_token][line_break_token]Yes, a model with free parameters or more complicated structure could eventually outperform the shared model with enough training data but there are real biological and experimental limitations to the amount of data one can collect in these experiments and more broadly in most neuroscience experiments.	Reply	I-Reply	2
[line_break_token][line_break_token]We also believe we have taken important first steps to understanding the model improvement through model comparisons.	Reply	I-Reply	3
Whether the gap between linear-nonlinear model performance and optimal performance could be explained by a combination of  long-range spatial interactions and spatial and temporal nonlinearities might seem simple, but it is an important question in the field that has been difficult to address.	Reply	I-Reply	3
 We showed that the former is not true (at least up to the level of RNN performance) and that both spatial nonlinearities and nonlinear temporal processing are important.	Reply	I-Reply	3
These results can guide future research and experiments and further demonstrate the utility of our approach.	Reply	I-Reply	3
 This is a first step: in future work, we plan to further interrogate the RNN models to understand more specifically what information they are capturing.	Reply	I-Reply	3
As noted above, we also plan to apply this framework to non-retinal neurons where there are larger gaps between what current models capture and the optimal predictions.	Reply	I-Reply	4
In these systems, there is more room for improvement and more basic questions can be answered using our approach.	Reply	I-Reply	4

This paper studies multi-task learning (MTL) from the deep learning perspective where a number of layers are shared between tasks followed by specific heads for each task.	Review	O	0
One of the main challenges in this problem is to decide the best configuration among a large number of possible ones (e.g., the number of layers , number of neurons, when to stop the shared part of the network).	Review	O	0
In this paper, the authors fix the network architecture, and learn which filters (among the already learned ones) should be dedicated to (and hence fine-tuned for) a specific, and which ones should be shared between multiple tasks.	Review	O	0
[line_break_token][line_break_token]Instead of deciding on other hyper-parameters such as the number of layers, the authors chose to study how to efficiently share the capacity of the network: to decide which filters should be used for which tasks, and which filters should be shared between tasks.	Review	O	0
[line_break_token]Specifically, this is controlled by task specific binary vectors which get multiplied with feature activations for each task, hence blocking or allowing the signal to pass for a specific filter.	Review	O	0
In addition, they define a different set of binary vectors for the foreground and background passes.	Review	O	0
This allows simpler tasks to benefit from features learnt from more complicated tasks such as ImageNet classification while avoiding ‚Äòcatastrophic forgetting‚Äô at the same time.	Review	O	0
[line_break_token][line_break_token]Moreover, the authors develop a simple yet elegant strategy to reduce their parameter search space (by using the matrix P which controls the percentage of filters used per task + the percentage of filters shared between each pair of tasks) and quickly evaluate the performance of each configuration (using distillation).	Review	O	0
The advantages of these approaches are well discussed and validated quantitatively.	Review	O	0
[line_break_token][line_break_token]The paper is well written and the approach itself appears to be sound and it led to improvement over independent task estimator.	Review	O	0
 However, I am mostly concerned about the experimental setting: there are no comparisons with any other MTL algorithm.	Review	O	0
[line_break_token][line_break_token]The authors perform a search over the matrix P, which is similar to neural architecture search over the entire possible ways of sharing the capacity of a network.	Review	B-Review	2
This could potentially lead to improvement beyond multi-task learning.	Review	I-Review	2
Experimental comparison on this could be provided.	Review	I-Review	2
[line_break_token]I think the paper will make a strong case if it is compared with existing deep MTL algorithms including [Misra et al: Cross-stitch networks for multi-task learning]. In addition, the network seems to share a similar spirit with [Mallya et al: PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning], in that they also share the capacity of the network between tasks, and hence a comparison here seems reasonable.	Review	I-Review	1
[line_break_token][line_break_token]Overall, I think this paper makes a borderline case.	Review	O	0
[line_break_token][line_break_token]Other comments: [line_break_token]In the supplementary material, providing a detailed description of the algorithm (e.g., pseudo code and an accompanying discussion) that calculates the matrices M from P could help reproduce and build upon the experiments reported in the paper.	Review	O	0
I wonder if M is uniquely defined from M.	Review	B-Review	3
hank you for all of your comments and taking the time to review.	Reply	O	0
[line_break_token][line_break_token]Cross-stitch networks and PackNet would make for interesting comparisons.	Reply	B-Reply	1
While we do not have experiments to compare to these methods, it is worth noting some differences and advantages that our proposed method has to offer:[line_break_token]- Cross-stitch networks calculate a linear combination of activations across a parallel set of layers.	Reply	O	0
Thus, the full model is required to compute the activation for an individual task, and computation grows as a function of the number of tasks.	Reply	B-Reply	1
Our work allows pruning down to what is needed for an individual task.	Reply	I-Reply	1
[line_break_token]- PackNet also does pruning, but does so by iteratively pruning and retraining a model for each new task.	Reply	O	0
This raises challenges that do not occur in our work.	Reply	B-Reply	1
The amount of the network available to be retrained drops as each new task is added.	Reply	I-Reply	1
Furthermore, the order in which tasks are trained plays a significant role in final performance.	Reply	I-Reply	1
As seen in their paper, accuracy drops by a couple percentage points for a task if it is added second instead of first, and a couple more if added third instead of second.	Reply	I-Reply	1
It is unclear how well this would scale to a large number of tasks, and how much capacity remains in the network for each successive retraining step.	Reply	I-Reply	1
[line_break_token][line_break_token]For comparison to other MTL algorithms, here we report the test performance of our method which allows a comparison to two recent works that have evaluated on Visual Decathlon.	Reply	I-Reply	2
For context, these methods work by freezing an ImageNet model and adding additional layers for each task to augment intermediate activations.	Reply	I-Reply	2
We see that our performance is comparable to these methods despite using less computation and parameters per task.	Reply	I-Reply	2
Note, we use the ImageNet pretrained model provided by Rebuffi et al.	Reply	I-Reply	2
2018, so our base architecture is identical to theirs.	Reply	I-Reply	2
[line_break_token][line_break_token]Decathlon test set results:[line_break_token][line_break_token]      Airc,   C100, DPed, DTD,   GTSR, Flwr,  Oglt,   SVHN, UCF[line_break_token][1] 60.34, 82.12, 92.82, 55.53, 99.42, 81.41, 89.12, 96.55, 51.20[line_break_token][2] 64.11, 80.07, 91.29, 56.54, 98.46, 86.05, 89.67, 96.77, 49.38[line_break_token][3] 66.04, 81.86, 94.23, 57.82, 99.24, 85.74, 89.25, 96.62, 52.50[line_break_token][4] 69.31, 78.81, 91.13, 56.17, 99.14, 85.09, 89.85, 96.41, 51.52[line_break_token][line_break_token][1] separate networks finetuned for each task (as reported by Rebuffi et al.	Reply	O	0
2018)[line_break_token][2] Rosenfeld et al.	Reply	O	0
2017[line_break_token][3] Rebuffi et al.	Reply	O	0
2018[line_break_token][4] ours[line_break_token]	Reply	O	0

The paper presents a method to derive shaping rewards from a representation learnt with CPC.	Review	O	0
They propose learning a CPC representation from some random data and fix it.	Review	O	0
They assume exploration is not too difficult so that rewards are achievable without additional mechanisms.	Review	O	0
Once a reward is achieved they can compute the embedding of the corresponding state as a goal under the CPC learnt representation either directly ie.	Review	O	0
distance or via a clustering step.	Review	O	0
The paper is clearly written and presents a nice idea.	Review	O	0
The paper is correct and part of the approach seems novel.	Review	O	0
I find the analysis of the results well executed though I think that they should be improved for publication.	Review	O	0
[line_break_token][line_break_token]Major points: [line_break_token]* I think this is a valid contribution and it seems like something the RL audience might be interested in.	Review	O	0
[line_break_token]* I am very surprised that CPC does such a good job given that the main object for learning in CPC is the distribution of trajectories which should be quite different in random exploration and the optimal policy.	Review	O	0
I presume this is because the environments are quite simple.	Review	B-Review	1
This issue is of interest to the readers so an example of a simple failure case should make that point.	Review	I-Review	1
[line_break_token]* Secondly, as nice as those embeddings in figure 5 look I wonder what happens in larger mazes with more structure i.e. somewhere where random walk will not be a uniform distribution and thus CPC will (most likely) not work as intended.	Review	O	0
[line_break_token]* The clustering bonus how do you prevent it from staying at the edge of the goal region and deriving infinite rewards from that ?	Review	O	0
[line_break_token]* Since these are not potential functions how do you prevent the rewards from biasing learning ?	Review	O	0
Ng et al. --	Review	B-Review	4
Policy invariance under reward transformations.	Review	I-Review	4
This should be discussed in the paper because it is of practical importance.	Review	I-Review	4
[line_break_token]* Contrastive learning has been used to find goal embeddings before Warde-Farley et al.	Review	O	0
Unsupervised control through non-parametric discriminative rewards.	Review	B-Review	5
In that paper they don't need the CPC future state predictors but instead contrast the goal and the final state of the trajectory.	Review	I-Review	5
They use the resulting embedding to learn a reward function and ignore the extrinsic reward.	Review	I-Review	5
Interestingly, they show that the rewards can be learnt online (maybe ideas from that paper can be applied here).	Review	I-Review	5
[line_break_token]Minor points:[line_break_token]* please make legends on plots readable size.	Review	O	0
[line_break_token]	Review	O	0
hank you very much for your insightful review.	Reply	O	0
Below are our responses to some of your concerns:[line_break_token][line_break_token]* The clustering bonus how do you prevent it from staying at the edge of the goal region and deriving infinite rewards from that ?	Reply	O	0
[line_break_token][line_break_token]The cluster reward is one time only.	Reply	B-Reply	3
With the cluster reward, the MDP is no longer time-homogeneous, so we convert it to a time-homogeneous MDP by treating entering the cluster as the first goal, and entering the environment goal as the second goal.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]* Contrastive learning has been used to find goal embeddings before Warde-Farley et al.	Reply	O	0
Unsupervised control through non-parametric discriminative rewards.	Reply	O	0
In that paper they don't need the CPC future state predictors but instead contrast the goal and the final state of the trajectory.	Reply	O	0
They use the resulting embedding to learn a reward function and ignore the extrinsic reward.	Reply	O	0
Interestingly, they show that the rewards can be learnt online (maybe ideas from that paper can be applied here).	Reply	O	0
[line_break_token][line_break_token]Although our approach is currently off-line, we discussed near the end of our paper that converting the scheme to an online fashion is straightforward.	Reply	B-Reply	5
Our goal in this paper is to focus on the properties of predictive embedding, and how they may contain information useful for RL; our contribution is largely on the finding that the predictive embedding flattens out the original state space and provide straightforward paths to any goal in the environment.	Reply	I-Reply	5
We believe an online approach would work with our scheme, but that was not the focus of our paper.	Reply	I-Reply	5
[line_break_token][line_break_token][line_break_token]* I am very surprised that CPC does such a good job given that the main object for learning in CPC is the distribution of trajectories which should be quite different in random exploration and the optimal policy.	Reply	O	0
I presume this is because the environments are quite simple.	Reply	O	0
This issue is of interest to the readers so an example of a simple failure case should make that point.	Reply	O	0
[line_break_token]* Secondly, as nice as those embeddings in figure 5 look I wonder what happens in larger mazes with more structure i.e. somewhere where random walk will not be a uniform distribution and thus CPC will (most likely) not work as intended.	Reply	O	0
[line_break_token][line_break_token]With our scheme, having good exploration of the state space is key to training good predictive embedding.	Reply	B-Reply	1
This is more challenging for more difficult environments such as a large maze.	Reply	I-Reply	1
We believe that the need for good exploration is not unique to our approach; our focus of the paper is to provide a method to leverage good exploration data without reward signals, and this method is to train predictive embedding.	Reply	I-Reply	1
[line_break_token][line_break_token]For environments where random exploration is not enough (including the AntMaze environment), we overcame the issue by a) sampling from a robust distribution of initial states in the simulator b) training goal-conditioned policies for pure exploration strategies.	Reply	I-Reply	1
These two approaches allowed us to collect good exploration data and train high-quality predictive embedding in more difficult environments [line_break_token][line_break_token][line_break_token]* Since these are not potential functions how do you prevent the rewards from biasing learning ?	Reply	O	0
Ng et al. --	Reply	O	0
Policy invariance under reward transformations.	Reply	O	0
This should be discussed in the paper because it is of practical importance.	Reply	O	0
[line_break_token][line_break_token]A rigorous investigation of the mathematical properties of the latent space is out of the scope of this applicative paper.	Reply	B-Reply	4
From an empirical perspective, however, the ability for an agent to learn an optimal policy in various experimental settings with our scheme reflect that the negative distance scheme is likely a potential function.	Reply	I-Reply	4
Ultimately, this depends on whether the latent space induced by the encoder preserves the metric property of the original state space, and one could train an invertible map to enforce this.	Reply	I-Reply	4

This paper is technically sound.	Review	O	0
It highlights well the strengths and weaknesses of the proposed simplified model.	Review	O	0
[line_break_token][line_break_token]In terms of impact, its novelty is limited, in the sense that the authors did seemingly the right thing and obtained the expected outcomes.	Review	O	0
The idea of modeling deep learning computation is not in itself particularly novel.	Review	O	0
As a companion paper to an open source release of the model, it would meet my bar of acceptance in the same vein as a paper describing a novel dataset, which might not provide groundbreaking insights, yet be generally useful to the community.	Review	B-Review	1
[line_break_token][line_break_token]In the absence of released code, even if the authors promise to release it soon, I am more ambivalent, since that's where all the value lies.	Review	I-Review	2
It would also be a different story if the authors had been able to use this framework to make novel architectural decisions that improved training scalability in some way, and incorporated such new insights in the paper.	Review	I-Review	2
[line_break_token][line_break_token]UPDATED: code is now available.	Review	O	0
Revised review accordingly.	Review	O	0
As a follow-up to the previous response, we have release a live demo at <a href="https://talwalkarlab.github.io/paleo/." target="_blank" rel="nofollow">https://talwalkarlab.github.io/paleo/.</a>[line_break_token]Notably, we added a cost estimation feature that predicts dollar costs on AWS instances.	Reply	O	0
[line_break_token][line_break_token]The current interface provides a predefined set of configurations and works with data parallelism.	Reply	B-Reply	2
We will allow users to upload customized networks and model splits in the coming releases of the interface; although core implementations are already include in the open-sourced repository	Reply	I-Reply	2

The paper is well written and structured, presenting the problem clearly and accurately.	Review	O	0
It contains considerable relevant references and enough background knowledge.	Review	O	0
It nicely motivates the proposed approach, locates the contributions in the state-of-the-art and reviews related work.	Review	O	0
It is also very honest in terms of how it differs on the technical level from existing approaches.	Review	O	0
[line_break_token]The paper presents interesting and novel findings to further state-of-the-art‚Äôs understanding on how language concepts are represented in the intermediate layers of deep convolutional neural networks, showing that channels in convolutional representations are selectively sensitive to specific natural language concepts.	Review	O	0
It also nicely discusses how concepts granularity evolves with layers‚Äô deepness in the case of natural language tasks.	Review	O	0
[line_break_token]What I am missing, however, is an empirical study of concepts coverage over multiple layers, studying the multiple occurrences of single concepts at different layers, and a deeper dive on the rather noisy elements of natural language and the layers‚Äô activation dynamics towards such elements.	Review	O	0
[line_break_token]Overall, however, the ideas presented in the paper are interesting and original, and the experimental section is convincing.	Review	O	0
My recommendation is to accept this submission.	Review	O	0
[line_break_token]	Review	O	0
[line_break_token]We thank Reviewer 1 for positive and constructive review.	Reply	O	0
Please see our revisions in blue font to check how our paper is updated.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
Concepts coverage over multiple layers[line_break_token]===================================[line_break_token]We plot the number of unique concepts per layer in Figure 13.	Reply	O	0
In all datasets, the number of unique concepts increases with the layer depth, which implies that the units in a deeper layer represent more diverse concepts.	Reply	B-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	O	0
Multiple occurrences of each concept at different layers[line_break_token]===================================[line_break_token]We add Figure 16 to Appendix H to show how many layers each concept appears.	Reply	O	0
Although task and data specific concepts emerge at different layers, there is no strong pattern between the concepts and their occurrences at multiple layers.	Reply	B-Reply	2
[line_break_token][line_break_token][line_break_token]3.	Reply	I-Reply	1
The layers‚Äô activation dynamics towards noisy elements[line_break_token]===================================[line_break_token]It is an interesting suggestion to investigate how unit activations vary with noisy elements of natural language such as synthetic adversarial examples or natural noise (Belinkov et al.[1]) that could attack the model.	Reply	O	0
Since we discover some units that capture the abstract semantics rather than low-level text patterns in Section 4.2, we expect that those units will be not sensitive to such noisy transformation of the concepts.	Reply	B-Reply	3
More thorough analysis for this topic will be one of our emergent future works.	Reply	I-Reply	3
[line_break_token][line_break_token]References[line_break_token]===================================[line_break_token][1] Yonatan Belinkov et al.,	Reply	O	0
Synthetic and Natural Noise Both Break Neural Machine Translation (ICLR 2018)	Reply	O	0

This paper presents a new semi-supervised method for bilingual dictionary induction and proposes a new metric to measure isometry between embedding spaces.	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token]- The paper proposes to use a new metric, the Gromov-Hausdorff distance to measure how isometric two word embedding spaces are.	Review	O	0
[line_break_token]- The toy example is useful for motivating the use case of the method.	Review	O	0
[line_break_token]- The approach achieves convincing results on the dataset.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]- Beyond the isometry metric, the main innovation as far as I can see seems to be the hubness filtering, which is incremental and not ablated, so it is not clear how much improvement it yields.	Review	O	0
The weak orthogonality constraint has already been used in [2].[line_break_token]- It is not clear to me what the proposed metric adds beyond the eigenvector similarity metric proposed in [1]. The authors should compare to this metric at least.	Review	O	0
[line_break_token]- The authors might want to add the results of [3] for an up-to-date comparison.	Review	O	0
[line_break_token][line_break_token][1] S√∏gaard, A., Ruder, S., & Vuliƒá, I. (2018).	Review	O	0
On the Limitations of Unsupervised Bilingual Dictionary Induction.	Review	O	0
In Proceedings of ACL 2018.	Review	O	0
[line_break_token][2] Zhang, M., Liu, Y., Luan, H., & Sun, M. (2017).	Review	O	0
Adversarial Training for Unsupervised Bilingual Lexicon Induction.	Review	O	0
In Proceedings of ACL.	Review	O	0
[line_break_token][3] Artetxe, M., Labaka, G., & Agirre, E. (2018).	Review	O	0
A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings.	Review	O	0
In Proceedings of ACL 2018.	Review	O	0
Thank you for your feedback and insightful comments.	Reply	O	0
Below we try and address your comments individually:[line_break_token][line_break_token]> Beyond the isometry metric, the main innovation as far as I can see seems to be the hubness filtering, which is incremental and not ablated, so it is not clear how much improvement it yields.	Reply	O	0
The weak orthogonality constraint has already been used in [s 2].[line_break_token][line_break_token]In addition to the Gromov-Hausdorff metric, our joint framework is a novel contribution.	Reply	O	0
We show that it improves over both its corresponding supervised and unsupervised counterparts for two instantiations of our framework (BLISS(M) based on MUSE(S), and BLISS(R) based on RCSLS, incorporating reviewer feedback), which in turn illustrates its efficacy, with  BLISS(R) obtaining state-of-the-art results (to the best of our knowledge).	Reply	B-Reply	1
[line_break_token][line_break_token]> It is not clear to me what the proposed metric adds beyond the eigenvector similarity metric proposed in [1]. The authors should compare to this metric at least.\[line_break_token][line_break_token]Thank you for pointing this reference out; we have updated our paper to include the metric from [1] (Table 2).	Reply	O	0
From the Table, we observe that our method correlates better than the eigenvector similarity metric.	Reply	B-Reply	2
[line_break_token][line_break_token]> The authors might want to add the results of [3] for an up-to-date comparison.	Reply	O	0
[line_break_token][line_break_token]We have incorporated this baseline in our latest draft, along with an accompanying discussion (Section 4.2.4).	Reply	B-Reply	3

This paper studies the impact of angle bias on learning deep neural networks, where angle bias is defined to be the expected value of the inner product of a random vectors (e.g., an activation vector) and a given vector (e.g., a weight vector).	Review	O	0
 The angle bias is non-zero as long as the random vector is non-zero in expectation and the given vector is non-zero.	Review	O	0
 This suggests that the some of the units in a deep neural network have large values (either positive or negative) regardless of the input, which in turn suggests vanishing gradient.	Review	O	0
 The proposed solution to angle bias is to place a linear constraint such that the sum of the weight becomes zero.	Review	O	0
 Although this does not rule out angle bias in general, it does so for the very special case where the expected value of the random vector is a vector consisting of a common value.	Review	O	0
 Nevertheless, numerical experiments suggest that the proposed approach can effectively reduce angle bias and improves the accuracy for training data in the CIFAR-10 task.	Review	O	0
 Test accuracy is not improved, however.	Review	O	0
[line_break_token][line_break_token]Overall, this paper introduces an interesting phenomenon that is worth studying to gain insights into how to train deep neural networks, but the results are rather preliminary both on theory and experiments.	Review	O	0
[line_break_token][line_break_token]On the theoretical side, the linearly constrained weights are only shown to work for a very special case.	Review	O	0
 There can be many other approaches to mitigate the impact of angle bias.	Review	O	0
 For example, how about scaling each variable in a way that the mean becomes zero, instead of scaling it into [-1,+1] as is done in the experiments?	Review	O	0
 When the mean of input is zero, there is no angle bias in the first layer.	Review	B-Review	1
 Also, what about if we include the bias term so that b + w a is the preactivation value?	Review	O	0
[line_break_token][line_break_token]On the experimental side, it has been shown that linearly constrained weights can mitigate the impact of angle bias on vanishing gradient and can reduce the training error, but the test error is unfortunately increased for the particular task with the particular dataset in the experiments.	Review	B-Review	3
 It would be desirable to identify specific tasks and datasets for which the proposed approach outperforms baselines.	Review	I-Review	3
 It is intuitively expected that the proposed approach has some merit in some domains, but it is unclear exactly when and where it is.	Review	I-Review	3
[line_break_token][line_break_token]Minor comments:[line_break_token][line_break_token]In Section 2.2, is Layer 1 the input layer or the next?	Review	O	0
We thank the reviewer for the insightful comments on our paper.	Reply	O	0
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 1: How about scaling each variable in a way that the mean becomes zero, instead of[line_break_token]scaling it into [-1,+1] as is done in the experiments?	Reply	O	0
 When the mean of input is zero,[line_break_token]there is no angle bias in the first layer.	Reply	O	0
[line_break_token][line_break_token]Response 1: We did experiments with CIFAR-10, in which each variable was scaled to have[line_break_token]zero mean.	Reply	O	0
As the reviewer pointed out, we have no angle bias in the first layer (the layer[line_break_token]after the input layer) in this case.	Reply	B-Reply	1
[line_break_token]However, the training of MLPs then got harder and the test accuracy was very row, even if[line_break_token]we applied either LCW or batch-normalization.	Reply	I-Reply	1
We think this is because normalizing each pixel[line_break_token]of images in CIFAR-10 ruined the relationship between pixels.	Reply	I-Reply	1
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 2: What about if we include the bias term so that b + w a is the preactivation value?	Reply	O	0
[line_break_token][line_break_token]Response 2: We have already included the bias term in our original experiment, although[line_break_token]it was omitted in Equation 2 for simplicity.	Reply	O	0
We have modified Equation 2 to include[line_break_token]the bias term for clarity in the revised manuscript.	Reply	B-Reply	2
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 3: It would be desirable to identify specific tasks and datasets for which[line_break_token]the proposed approach outperforms baselines.	Reply	O	0
It is intuitively expected that the proposed[line_break_token]approach has some merit in some domains, but it is unclear exactly when and where it is.	Reply	O	0
[line_break_token][line_break_token]Response 3: We did additional experiments with the SVHN dataset and the CIFAR-100 dataset,[line_break_token]which are reported in the appendix B of the revised manuscript.	Reply	O	0
The peak value of the test[line_break_token]accuracy of the proposed method was comparable to that of batch-normalization when the MLP[line_break_token]has 5 layers or 50 layers, as shown in Figure 12 (f) and (i), Figure 14 (f) and (i), and[line_break_token]Figure 15 (f) and (i).	Reply	B-Reply	3
[line_break_token]An interesting point is that the peak of the test accuracy is around 20 epochs in the[line_break_token]proposed method.	Reply	I-Reply	3
However, we have no clear explanation for this finding.	Reply	I-Reply	3
We have added[line_break_token]a description on this point in the third paragraph of Section 5.1 in the revised manuscript.	Reply	I-Reply	3
[line_break_token][line_break_token]--[line_break_token][line_break_token]Comment 4: In Section 2.2, is Layer 1 the input layer or the next?	Reply	O	0
[line_break_token][line_break_token]Response 4: Layer 1 is the layer next to the input layer.	Reply	O	0
We have added an explanation of[line_break_token]these points to the first paragraph of Section 2.2.1 in the revised version.	Reply	B-Reply	4

This is an interesting application of DL in rhythm-based video games that learns two sub-tasks: step placement from raw audio, and step selection from ground truth placement.	Review	O	0
This seems to be a work in progress, as it doesn't address the complete end-to-end problem yet.	Review	B-Review	1
[line_break_token][line_break_token]Some key information is missing in the paper.	Review	I-Review	2
For example, the authors observed that data augmentation and inclusion of manual features (beta phase etc) significantly improved the performance but there is no comparison results given.	Review	I-Review	2
Have the authors tried to learn such manual features from data?	Review	I-Review	2
[line_break_token][line_break_token]Also there is a clear performance gap between Fraxtill and ITG, particularly on the step selection task under the best model LSTM64.	Review	I-Review	3
Also,  there is little difference between LSTM5 and LSTM64 on ITG while the improvement is more clear on Fraxtill.	Review	I-Review	3
What are the reasons behind these observations?	Review	I-Review	3
Dear reviewer, [line_break_token][line_break_token]Thank you for the thoughtful review.	Reply	O	0
We omitted some of these details to accommodate the extended abstract length.	Reply	O	0
[line_break_token][line_break_token]An unconditioned LSTM64 model trained on non-augmented Fraxtil data achieved a perplexity of 3.53 while the same unconditioned LSTM64 model trained on augmented data achieved a perplexity of 3.35.	Reply	B-Reply	3
These scores are significantly worse than the 3.01 perplexity achieved by the beat-conditioned LSTM64 model trained on augmented data.	Reply	O	0
[line_break_token][line_break_token]We believe the performance gap (on step selection) between the two datasets can be attributed to the fact that Fraxtil is a single-author dataset while ITG contains annotations from 9 choreographers.	Reply	B-Reply	2
Author style tends to be distinctive and thus the single-author sequences are more predictable.	Reply	I-Reply	2
[line_break_token][line_break_token]We have updated the workshop draft to address these points.	Reply	O	0

This paper applies the Gumbel-softmax to optimizing task-specific routing in deep multi-task learning.	Review	O	0
Experiments demonstrate improvements of the method over no sharing or full sharing, and it is used to achieve s-o-t-a results in the Omniglot MTL benchmark.	Review	O	0
[line_break_token][line_break_token]Although the end results are good, and the approach is well-motivated, I am leaning to reject, because the experiments have not made clear when the method works and how it behaves.	Review	O	0
The improvements over the full-sharing baselines appear fairly small, and in the analysis it appears the model is mainly discarding unneeded pooling layers.	Review	B-Review	3
Is there some real task-specific routing that the method is able to take advantage of?	Review	I-Review	1
Maybe an experiment where full-sharing is detrimental, i.e., because there are some highly unrelated tasks, would help to highlight how the approach selects appropriate module subsets for each task.	Review	I-Review	1
E.g., what are the routing patterns in Section 6.1 that are the same within each pair of MNIST tasks, but different across task pairs?	Review	I-Review	1
Is there a way to visualize differences between routing of different Omniglot tasks?	Review	I-Review	2
[line_break_token][line_break_token]Similarly, the experiment in Section 2 is interesting, but the conclusion that negative transfer exists is not novel.	Review	I-Review	4
Is there a way to include the Gumbel approach in these synthetic experiments to show that it addresses this issue?	Review	I-Review	4
E.g., something like the result in A.3 could be promoted to Section 2.	Review	I-Review	4
More compelling synthetic datasets could be generated by the method in A.1.	Review	I-Review	4
for the case where tasks are somewhat related, in which case we can actually see if how the sharing occurs.	Review	I-Review	4
Could Gumbel see a bigger boost in these synthetic experiments if training data were limited and generalization was tested instead of training loss?	Review	I-Review	4
[line_break_token]	Review	O	0
e thank the reviewer for the valuable comments.	Reply	O	0
We are open to any further suggestions for improving our paper.	Reply	O	0
Our responses to specific comments are provided below.	Reply	O	0
[line_break_token][line_break_token]1) Routing patterns for Omniglot[line_break_token][line_break_token]For the Omniglot experiment, it was indeed the case that discarding unwanted pooling layers was one of the clearest trends learned by our method.	Reply	O	0
However, as pointed out in the paper, there were still important differences in allocation patterns corresponding to different tasks.	Reply	B-Reply	2
Specifically, we grouped the tasks based on the pattern (i.e. the concatenation of all binary routing matrices), and we found around 10 groups on average, while the number of tasks was 20.	Reply	I-Reply	2
Notice that differences in patterns may result in arbitrarily large differences in outputs.	Reply	I-Reply	2
[line_break_token][line_break_token]2) Routing patterns for MNIST[line_break_token][line_break_token]In the case of no budget penalty, the routing commonly converged to the pattern of the following form: one pair of MNIST tasks would use all components (12 components, since there were 3 layers of 4 components each), while the other pair would use all but one component (11 components).	Reply	O	0
Since MNIST and MNIST-rot are still highly related, this shows that the model preferred almost full sharing, except for dropping a single connection to allow for processing the first pair of tasks differently than the second.	Reply	B-Reply	1
[line_break_token][line_break_token]With budget penalty enabled, each pair would usually use three out of four components in each layer, exactly matching the budget of 75% active connections.	Reply	I-Reply	1
Note that the resulting accuracy was the same with and without the budget penalty.	Reply	I-Reply	1
[line_break_token][line_break_token]3) Magnitude of gains on Omniglot over the full-sharing baseline[line_break_token][line_break_token]Even though the improvement on top of full sharing for Omniglot is not very large, full sharing is actually a pretty strong baseline; even stronger than previous SotA based on a sparse Mixture-of-Experts (P. Ramachandran et al, ICLR 2019).	Reply	O	0
Our interpretation of this result is that in the case of limited data (Omniglot has very few samples per class), it is hard to learn task-specific routing without incurring an accuracy drop due to optimization difficulties.	Reply	B-Reply	3
Since our routing method managed to learn task-conditioned routing and improve the accuracy, while the methods from previous works did not, we consider our Omniglot result to be a strong one.	Reply	I-Reply	3
[line_break_token][line_break_token]4) Other comments[line_break_token][line_break_token]We are happy to move the result from Appendix A.3 to Section 2, if that helps the paper.	Reply	O	0
[line_break_token][line_break_token]Also, the reviewer proposed considering the case of limited data and generalization.	Reply	B-Reply	4
However, note that Omniglot might already be seen as such a case, and our experiments show that Gumbel-Matrix routing does produce solutions that generalize well	Reply	I-Reply	4

This paper proposes to use TensorTrain representation to transform discrete tokens/symbols to its vector representation.	Review	O	0
[line_break_token]Since neural networks can only work with numerical numbers, in many NLP tasks, where the raw inputs are in the discrete token/symbol format, the popular technique is to use "embedding" matrices to find a vector representation of those inputs.	Review	O	0
[line_break_token][line_break_token]As the authors point out, the embedding matrices usually require huge number of parameters, since it assigns one vector for each input token for one embedding vector, but to attain a competitive performance in the real world applications, we need to use large number of embedding vectors, which results in a large number of parameters in the neural networks.	Review	O	0
[line_break_token][line_break_token]The paper assumes that those embedding matrices can be compressed by assuming that the low-rank property of embedding matrices.	Review	O	0
I think this is a valid assumption in many cases, and the paper shows the performance degradation according to this assumption is relatively small compared to the gain, a dramatically reduced size of parameters in the embedding stage, is substantial.	Review	O	0
[line_break_token][line_break_token]I think the paper is well written and proposes a new direction to find a memory efficient representation of symbols.	Review	O	0
I am not sure the current initialization techniques, nor the training method in the paper are the right way to train a tensor train "embedding" but I expect that the authors would perform the follow up work on those topics.	Review	B-Review	1
hank you for reviewing the paper and providing a positive feedback to our work!	Reply	O	0
[line_break_token][line_break_token]Our current initialization scheme was inspired by the common way to initialize token embeddings from the literature [1], which does not take into account the factorizative nature of our layers.	Reply	B-Reply	1
For the experiments, we simply implemented TT-embedding and TT-softmax layers to be easily optimized along with other parameters in autodiff framework (PyTorch in our case).	Reply	I-Reply	1
However, we are also aware of more advanced optimization algorithms particularly suitable for tensor decompositions (see [2] for a brief overview).	Reply	I-Reply	1
There is indeed a room for improvements to our current practices of initializing and optimizing TT-embeddings which require further investigation.	Reply	I-Reply	1
[line_break_token][line_break_token][1] T. Kocmi, O. Bojar.	Reply	O	0
An Exploration of Word Embedding Initialization in Deep-Learning Tasks.	Reply	O	0
In ICON, 2017.	Reply	O	0
[line_break_token][2] A. Novikov, P. Izmailov, V. Khrulkov, M. Figurnov, I. Oseledets.	Reply	O	0
Tensor Train decomposition on TensorFlow (T3F).	Reply	O	0
On arxiv, 2018	Reply	O	0

This paper provides new insights on what is captured contextualized word embeddings by compiling a set of ‚Äúedge probing‚Äù tasks.	Review	O	0
 This is not the first paper to attempt this type of analysis, but the results seem pretty thorough and cover a wider range of tasks than some similar previous works.	Review	O	0
 The findings in this paper are very timely and relevant given the increasing usage of these types of embeddings.	Review	O	0
 I imagine that the edge probing tasks could be extended towards looking for other linguistic attributes getting encoded in these embeddings.	Review	O	0
[line_break_token][line_break_token]Questions & other remarks:[line_break_token]-The discussion of the tables and graphs in the running text feels a bit condensed and at times unclear about which rows are being referred to.	Review	O	0
[line_break_token]-In figures 2 & 3: what are the tinted areas around the lines signifying here?	Review	O	0
Standard deviation?	Review	B-Review	2
 Standard error?	Review	I-Review	2
 Confidence intervals?	Review	I-Review	2
[line_break_token]-It seems the orthonormal encoder actually outperforms the full elmo model with the learned weights on the Winograd Schema.	Review	O	0
 Can the authors comment on this a bit more?	Review	B-Review	3
[line_break_token]	Review	O	0
Thank you for the review!	Reply	O	0
[line_break_token][line_break_token]We‚Äôre very interested in probing for other linguistic attributes - while we present a broad analysis in this paper, there‚Äôs certainly room to use edge probing to study more focused phenomena like PP attachment or ambiguities between specific semantic roles.	Reply	B-Reply	4
We use a standardized data format that makes it easy to add new tasks, and we hope that our code release will be a useful platform for this kind of analysis.	Reply	I-Reply	4
[line_break_token][line_break_token]We‚Äôll be sure to update the text to more clearly describe the tables.	Reply	I-Reply	1
[line_break_token][line_break_token]Whoops!	Reply	I-Reply	2
In Figure 2 and 3, the bars/bands are 95% confidence intervals calculated using the Normal approximation.	Reply	I-Reply	2
We wanted to emphasize that the SPR and Winograd datasets are quite small and that the differences between models are often not significant.	Reply	I-Reply	2
We‚Äôll add this to the caption in the final version	Reply	I-Reply	2

Summary: This paper attempts to better understand the notion of prototypes and in some sense create a taxonomy for characterizing various prototypicality metrics.	Review	O	0
While the idea of thinking about such a taxonomy is novel, I think the paper falls in clearly justifying certain design choices such as why are the properties outlined at the beginning of Section 2 desirable.	Review	B-Review	7
I also felt that the paper is resorting to rather informal ways of describing various properties and metrics without precisely quantifying them.	Review	I-Review	7
[line_break_token][line_break_token]Pros:[line_break_token]1.	Review	O	0
Novel attempt at understanding prototypes.	Review	O	0
Two specific contributions: a) outlining the properties desirable in prototypicality metrics b) proposing new prototypicality metrics and demonstrating the relevance of the various prototypicality metrics.	Review	O	0
[line_break_token]2.	Review	B-Review	3
Detailed experimental analysis along with some user studies[line_break_token][line_break_token]Cons:[line_break_token]1.	Review	O	0
An important drawback of this paper is that the notion of prototype is not very clearly contextualized and explained.	Review	B-Review	1
There is often a purpose associated with identifying prototypes - are we summarizing a dataset?	Review	I-Review	1
are we thinking about helping humans understand the behavior of a specific learning model?	Review	I-Review	1
Answers to these questions guide the process of choosing prototypes.	Review	I-Review	1
However, this paper seems to approach the problem of choosing prototypes via the "one approach fits all" strategy which I am not sure is even possible.	Review	I-Review	1
[line_break_token]2.	Review	I-Review	3
The choice of desirable properties is not clearly justified (Beginning of Section 2).	Review	I-Review	2
For instance, why should prototypes be independent of learning tasks?	Review	I-Review	2
[line_break_token]3.	Review	O	0
Lack of rigor in defining prototypicality metrics as well as properties in Section 2.	Review	B-Review	3
For example, wouldn't it be possible to theoretically prove that the metrics outlined in Section 2 satisfy the desired properties?	Review	I-Review	3
[line_break_token][line_break_token]Detailed Comments: [line_break_token]1.	Review	O	0
I would strongly encourage the authors to illustrate using examples in the introduction the significance of finding prototypes.	Review	B-Review	4
What are the end goals for which these prototypes would be used?	Review	I-Review	4
Why do you think the metric for chooosing prototypes should be independent of the learning task or model?	Review	I-Review	4
[line_break_token]2.	Review	I-Review	3
Along the same lines as the comment above, please provide detailed justifications for the list of properties provided in the beginning of Section 2.	Review	I-Review	5
It would be even better if you could formalize these a bit more.	Review	I-Review	5
[line_break_token]3.	Review	O	0
Would it be possible to theoretically show that the metrics defined in Section 2 satisfy any of the desirable properties highlighted in Section 2?	Review	B-Review	6
We thank the reviewer for their very knowledgeable review.	Reply	O	0
 It gave us new insights, and made us see how our paper could be read in a way that we did not anticipate.	Reply	O	0
[line_break_token][line_break_token]In particular, we see how our writing may give the impression that we are trying to create a taxonomy of ‚Äúprototype definitions.	Reply	B-Reply	7
‚Äù  That was not at all our intention, as we elaborate on below.	Reply	I-Reply	7
 Instead, inspired by the metric of Stock & Cisse (2018), we were interested in what were the differences between the examples contained in the dataset (both training and testing)---when evaluated by that metric, or the other four metrics we came up with---and how those differences might shed light on aspects such hard-to-learn and inherently-ambiguous submodes, memorized exceptions, and other concerns of example data corpus construction and curation.	Reply	O	0
[line_break_token][line_break_token]Below, we further respond to each of the reviewer‚Äôs comments:[line_break_token][line_break_token]> Summary: This paper attempts to better understand the notion of prototypes and in some sense create a taxonomy for characterizing various prototypicality metrics.	Reply	O	0
While the idea of thinking about such a taxonomy is novel, I think the paper falls in clearly justifying certain design choices such as why are the properties outlined at the beginning of Section 2 desirable.	Reply	O	0
I also felt that the paper is resorting to rather informal ways of describing various properties and metrics without precisely quantifying them.	Reply	O	0
[line_break_token][line_break_token]We agree with the reviewer that it feels less-than-satisfactory to give such informal definitions for prototypes.	Reply	B-Reply	7
 Indeed, this is how the list at the start of Section 2 came about: it is our own attempt at clarifying what we mean by ‚Äúprototypes.	Reply	I-Reply	7
‚Äù Before doing this work, we had no concrete definition for what ‚Äúprototypes‚Äù actually were, whether they generally existed in data corpora for ML tasks, or---if they did---whether they corresponded to human intuition.	Reply	I-Reply	7
Reading the existing literature on ‚Äúprototypes‚Äù in the ML literature didn‚Äôt surface any precise definition: we found only informal statements and rather subjective goals for each metric, whereas the mechanism of each metric was often clearly defined.	Reply	I-Reply	7
 Hence, for our own benefit, and that of the readers, we felt it was worth re-stating the common understanding from the prototype literature (even though it was vague); while doing this, we also added a few properties that seemed obvious, and were supported by our experiments, such as those of the last bullet in the list.	Reply	I-Reply	7
However, we do not see this list as a real contribution of our work, and its removal would not affect our results	Reply	I-Reply	7

This paper introduces a new type of Graph Neural Network (GNN) that incorporates Feature-wise Linear Modulation (FiLM) layers.	Review	O	0
Current GNNs update the target representations by aggregating information from neighbouring nodes without taking into the account the target node representation.	Review	O	0
As graph networks might benefit from such target-source interactions, the current work proposes to use FiLM layers to let the target node modulate the source node representations.	Review	O	0
The authors thoroughly evaluate this new architecture ‚Äî called GNN-FiLM‚Äî-on several graph benchmarks, including Citeseer, PPI, QM9, and VarMisuse.	Review	O	0
The proposed network outperforms the other methods on QM9 and is on par on the other benchmarks.	Review	O	0
[line_break_token][line_break_token]Strengths[line_break_token]- The literature review of existing work on GNN was a pleasure to read and provided a good motivation for the proposed GNN-FiLM architecture.	Review	O	0
[line_break_token]- The authors put significant effort into reproducing other GNN baselines.	Review	O	0
Perhaps the most surprising result of this work is that all GNNs perform remarkably similar (contrary to what previous work has reported)[line_break_token][line_break_token]Weaknesses[line_break_token]- There seems to be a much tighter relationship between GNN-FiLM and Gated GNNs than currently discussed.	Review	O	0
If you actually write down the equations of the recurrent cell in Eq 1), you‚Äôll notice that there are feature-wise interactions between the target node representations and the (sum of) source node representations.	Review	B-Review	1
The paper should discuss in more depth what the exact differences are.	Review	I-Review	1
Some visualizations would also help here.	Review	I-Review	1
[line_break_token]- Related to the previous point, I‚Äôd like to see a bit more discussion on *why* tight interactions between target and source nodes are helpful.	Review	O	0
For example, one could perhaps provide a toy example for which that‚Äôs obviously the case.	Review	B-Review	2
[line_break_token][line_break_token]All in all, I believe the ideas and results of this paper are promising but insufficient for publication in its current form.	Review	O	0
The paper tries to communicate two messages: 1) a model paper arguing for GNN-FiLM, 2) an unbiased evaluation of existing GNN models, showing that their performance is surprisingly similar on a number of benchmarks (with equal hyperparameter search).	Review	O	0
Both points are interesting but are not worked out sufficiently to pass the bar.	Review	O	0
For 1), I‚Äôd like to see an in-depth discussion on the benefits of target-source interactions, providing more insights into why this might be beneficial.	Review	B-Review	3
Your current experiments report very minimal gains for your proposed network, questioning why such interactions might be necessary in the first place.	Review	I-Review	3
For 2), I‚Äôd suggest to rewrite the paper from a slightly different angle and add more graph benchmarks if available (disclaimer: I‚Äôm not in the graph network community, so I can‚Äôt fully evaluate how significant these results are)[line_break_token][line_break_token][line_break_token]Typos[line_break_token]‚Äî‚Äî-[line_break_token]Last paragraph of intro: ‚Äútwo two‚Äù - &gt; two[line_break_token][line_break_token]*EDIT[line_break_token]After reading the rebuttal and revised paper, I've updated my score to "Weak Accept".	Review	O	0
The toy example and connection to GGNN are important additions which makes the paper more complete, though I believe there's room for further improvement here (see comments below).	Review	O	0
All in all, I weakly recommend to accept the paper.	Review	O	0
hank you for your kind (emergency?)	Reply	O	0
review and engaging with this submission.	Reply	O	0
[line_break_token][line_break_token]&gt; - There seems to be a much tighter relationship between GNN-FiLM and[line_break_token]&gt;   Gated GNNs than currently discussed.	Reply	O	0
If you actually write down the[line_break_token]&gt;   equations of the recurrent cell  in Eq 1), you‚Äôll notice that there[line_break_token]&gt;   are feature-wise interactions between the target node representations[line_break_token]&gt;   and the (sum of) source node representations.	Reply	O	0
[line_break_token][line_break_token]This is indeed true (for GRU/LSTM cells) and should maybe discussed in the paper in more depth, though it is a bit unclear where to best do this to not interrupt the flow of presentation.	Reply	B-Reply	1
[line_break_token]The differences arise from the application of the gated cell after summation of incoming messages.	Reply	I-Reply	1
Concretely, the "forgetting" of memories in a GRU/LSTM is similar to modulation of messages from the self-loop edges, and the gating of the cell input is similar to the modulation of incoming messages.	Reply	I-Reply	1
However, as GNN-FiLM uses _different_ values for different edge types, the modulation is additionally dependent on the kind of relationship between nodes.	Reply	I-Reply	1
In the case of a single edge type (+ a fresh self-loop edge type), GGNNs are indeed mathematically very similar to GNN-FiLM.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt; - Related to the previous point, I‚Äôd like to see a bit more discussion[line_break_token]&gt;   on *why* tight interactions between target and source nodes are[line_break_token]&gt;   helpful.	Reply	O	0
For example, one could perhaps provide a toy example for[line_break_token]&gt;   which that‚Äôs obviously the case.	Reply	O	0
[line_break_token][line_break_token]A simple toy example may be the following: Assume nodes are of type VA and type VB, and there are two edge types E1 and E2.	Reply	B-Reply	2
Our task is to count the number of E1-neighbours of VA nodes, and the number of E2-neighbours of VB nodes.	Reply	I-Reply	2
In FiLM, we can "filter" edges by using for VA nodes and for VB nodes.	Reply	I-Reply	2
Hence, GNN-FiLM can solve this task using a single layer.	Reply	I-Reply	2
Other models obviously can solve this task as well with more layers and feature dimensions by counting VA-E1, VA-E2, VB-E1, VB-E1 neighbours separately in a first message passing step, and then projecting to the desired dimension in a second layer.	Reply	I-Reply	2
[line_break_token][line_break_token]More generally, as the modulation of messages depends on the edge target representation and the edge type, GNN-FiLM can learn to (softly) select a subset of the graph edges for message passing, conditioned on the current representation of nodes, _per feature dimension_ (this is a substantial difference to the newly-introduced R-GAT setting; the original GAT model has no notion of edge types).	Reply	I-Reply	2
For example, in the Program Graph setting of the VarMisuse task, it may choose to emphasise "NextVariableUse" edges for some dimensions to gain information about how a variable is used later.	Reply	I-Reply	2
[line_break_token][line_break_token]You're right that this intuition is not provided clearly in the paper at the moment, and will be added in the next revision (but maybe only after feedback if these explanations make sense to a reader).	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; Your current experiments report very minimal gains for your proposed[line_break_token]&gt; network, questioning why such interactions might be necessary in the[line_break_token]&gt; first place.	Reply	O	0
[line_break_token][line_break_token]Note that the experimental gains over _standard_ baselines are quite substantial:[line_break_token]* For Tab.	Reply	B-Reply	3
1, the reported state of the art is a Micro-F1 of 0.973 +/- 0.002[line_break_token]* For Tab.	Reply	I-Reply	3
2, there is no clear state of the art as many papers use slightly different experiment design for this task (e.g., provide more features, ...); but the standard models are GGNN/R-GCN.	Reply	I-Reply	3
[line_break_token]* For Tab.	Reply	I-Reply	3
3, the reported state of the art is 84.0% (on SeenProjTest) and 74.1% (on UnseenProjTest) accuracy.	Reply	I-Reply	3
[line_break_token]While more graph tasks are studied, these 3 provide a good coverage of graph tasks (from small to large graph, classification and regression, node-level and graph-level).	Reply	I-Reply	3
The trends in these results are very likely to hold for the majority of tasks.	Reply	I-Reply	3
[line_break_token][line_break_token]Early feedback (and curiosity) led to more and more baselines in the experiments, and existing baselines were improved in a number of ways (e.g., the generalisations to the multi-relational setting, which are crucial for the performance in the reported experiments).	Reply	I-Reply	3
[line_break_token][line_break_token]Your review fits exactly to fear around submitting this paper: By doing a very thorough job on the experiments, the importance of the new method looks smaller; doing a worse job on the experiments (not including GNN-MLP*; not extending GAT/GIN to R-GAT/R-GIN) would have made it look better.	Reply	I-Reply	3
These nuances cannot be obvious to someone who's not active in the GNN research community (and so this rant is not meant as a "you did a bad job as a reviewer"), but this explanation may help to understand the context.	Reply	I-Reply	3
[line_break_token][line_break_token]However, the result that the differences between well-tuned, equally-well implemented models are small (and that the GNN-MLP baselines outperform other models) seems to be scientifically quite relevant, and of particular importance to the GNN research community.	Reply	I-Reply	3
Disseminating this result more widely should be a reason for acceptance for publication.	Reply	I-Reply	3

========== Edit following authors' response  ==========[line_break_token][line_break_token]Thank you for your detailed response and updated version.	Review	O	0
I think the new revision is significantly improved, mainly in more quantitative analyses and details in several places.	Review	O	0
I have updated my ev	Review	O	0
[line_break_token]We are deeply grateful to reviewer3 for thoughtful post-rebuttal suggestions.	Reply	O	0
We will clarify terminology, add more analyses and modify the figures accordingly.	Reply	O	0
For example, we will match the detected concepts with those in WordNet (ConceptNet) tree and update Fig 7 and Fig 14 to show which concepts are detected at each bin	Reply	O	0

This paper claims to propose a new approach to solve the computational problems of self-attention.	Review	O	0
However, the paper mainly focuses on adapting Transformer for image generation, which has far less applications.	Review	B-Review	1
The whole paper needs to be rewritten to make their target and contribution clearer.	Review	I-Review	1
[line_break_token][line_break_token]1.	Review	O	0
The authors overclaim that they provide a new approach for accelerating self-attention.	Review	B-Review	2
However, they only adapted Transformer for image generation.	Review	I-Review	2
In fact, Transformer does not equal to self-attention.	Review	I-Review	2
Currently, two directional self-attention like Bert has much wider applications compared with Transformer like sequential self-attention.	Review	I-Review	2
[line_break_token][line_break_token]2.	Review	O	0
For a paper claim to improve self-attention, they should show its effectiveness on a broad range of tasks, with comprehensive experimental evaluation.	Review	B-Review	3
However, authors mainly reported the image generation on several datasets.	Review	I-Review	3
[line_break_token][line_break_token]Overall, the authors need to rewrite the paper.	Review	O	0
They should either show more applications with the proposed self-attention approach or treat it as a new approach for image generation.	Review	O	0
hank you for remarks.	Reply	O	0
Since one of your major objections is at its core the same objection as that by reviewer #1, please see comment above.	Reply	O	0
We want to treat our paper as a new architecture for image (and video) generation and we are making this clear in the text	Reply	O	0

The paper proposes a class-conditional GAN model for video generation called DVD-GAN.	Review	O	0
The generator uses a single latent variable and uses ConvGRU modules and ResNet blocks to generate N frames.	Review	O	0
The model uses a dual discriminator, with one discriminator that discriminates individual frames, i.e. an image discriminator, and one that discriminates the whole video.	Review	O	0
This is similar to the MoCoGAN model, with the main difference being that the video discriminator operates on a smaller resolution video, thus reducing the dimensionality of the input to discriminate.	Review	O	0
The model is used to generate videos after being trained on the large-scale Kinetics-600 dataset, which contains multiple examples and has a lot of variability across videos.	Review	O	0
The main contribution of the paper is to successfully train this large GAN model on the very large-scale Kinetics dataset.	Review	O	0
The samples from the model are very visually appealing and are qualitatively  superior to any previous video prediction model.	Review	O	0
[line_break_token][line_break_token]While the paper mostly focuses on scaling up current models, it achieves significantly better qualitative results than previous models on a very challenging dataset, and therefore I believe it should be accepted as it is a significant advance in the field which probably will lead to follow-up work based on the model proposed here.	Review	O	0
[line_break_token][line_break_token]However, there are a number of things that could be improved/minor comments:[line_break_token][line_break_token]- Further details about the generator should be included in the main body of the paper, only having a figure to describe its architecture is not enough when the model and how to scale it up are key contributions.	Review	O	0
[line_break_token]- The authors introduce a FID score for video which is similar to FVD, but FID is only used to report results in one experiment, while FVD is used for the rest of the experiments.	Review	O	0
Since the community uses FVD and there is a publicly available implementation of this metric, I'd suggest that the authors also include FVD scores in Table 1 to help reproduce the results.	Review	B-Review	2
This is important since the FID metric is not explained thoroughly in the paper and small implementation details matter when using these metrics.	Review	I-Review	2
[line_break_token]- The related work section is missing many references to video prediction models, please add them to the paper.	Review	O	0
Some examples include:[line_break_token]Decomposing motion and content for natural video sequence prediction.	Review	B-Review	3
Villegas et al.	Review	I-Review	3
ICLR 2017[line_break_token]Unsupervised Learning of Disentangled Representations from Video.	Review	I-Review	3
Denton and Birodkar.	Review	I-Review	3
NIPS 2017[line_break_token]Predrnn: Recurrent neural networks for predictive learning using spatiotemporal lstms.	Review	I-Review	3
Wang et al.	Review	I-Review	3
NIPS 2017 [line_break_token]PredRNN++, ContextVP, ...[line_break_token]- Additional metrics for the BAIR experiment, including LPIPS and SSIM.	Review	O	0
While FVD correlates well with human judgement, LPIPS does so as well and provides another evaluation of the model.	Review	B-Review	4
Furthermore, metrics such as SSIM as used in SVG-LP can help better understand how well do the models cover the ground-truth sequence for given context frames.	Review	I-Review	4
[line_break_token]- Qualitative results for the BAIR experiment.	Review	O	0
Since most current models are not trained on Kinetics, qualitative samples for the BAIR dataset would help to qualitatively compare current methods to DVD-GAN.	Review	B-Review	5
[line_break_token]- In practice people have found that it is very difficult to train BigGAN-like models on images and videos.	Review	O	0
A common difficulty is that training diverges after a number of iterations, with the model starting to show mode collapse and big oscillations in terms of FID scores.	Review	B-Review	6
Since the models are trained for a big number of iterations, have you observed these kind of issues with different hyperparameter configurations?	Review	I-Review	6
If so, did you find any strategies to address it?	Review	I-Review	6
hanks for your review.	Reply	O	0
We‚Äôve detailed responses to your comments individually below.	Reply	O	0
[line_break_token][line_break_token]&gt; Further details about the generator should be included in the main body of the paper...[line_break_token]We give a detailed overview of the generator architecture in Appendix A.2 but were unable to fit all the details in the main body for length considerations.	Reply	O	0
If there are important details you feel are worth moving to the main text we would be happy to do so.	Reply	B-Reply	1
[line_break_token][line_break_token]&gt; ...I'd suggest that the authors also include FVD scores in Table 1 to help reproduce the results...[line_break_token]The revision just uploaded makes explicit that the FID metric we propose is identical to FVD except for using a different classifier for feature extraction -- one which has been trained on Kinetics-600 instead of Kinetics-400.	Reply	O	0
We also use hidden layer activations as features instead of the logits -- more in line with the FID metric used for images.	Reply	B-Reply	2
The new revision details in Appendix A.4 the (extremely minor) changes needed to be made to the publicly available FVD code to represent our metric.	Reply	I-Reply	2
Nevertheless, we agree with the reviewer in the value of providing both metrics and will update the paper with FVD metrics for the synthesis case in the next revision.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt; The related work section is missing many references to video prediction models...[line_break_token]Thank you for the references!	Reply	O	0
We‚Äôve added them and other relevant references in the new revision.	Reply	B-Reply	3
[line_break_token][line_break_token]&gt; Additional metrics for the BAIR experiment ...[line_break_token]The paper which introduced FVD reported a substantially weaker correlation between SSIM and human judgement, which was our motivation for focusing on FVD, but nevertheless we have just run an evaluation for SSIM on our best model.	Reply	O	0
We would like to include LPIPS results as well, however this will require more setup and will not be complete until a later revision.	Reply	B-Reply	4
[line_break_token][line_break_token]For 16 frames of BAIR with 1 conditioning frame, our per-frame SSIM scores are:[line_break_token][1.0, 0.92, 0.88, 0.87, 0.84, 0.84, 0.82, 0.82, 0.82, 0.81, 0.81, 0.80, 0.79, 0.79, 0.78, 0.78][line_break_token][line_break_token]VideoTransformer does not give explicit numbers (just a plot) so an exact numeric comparison is not possible.	Reply	I-Reply	4
Judging from Figure 2a in VideoTransformer, DVD-GAN‚Äôs SSIM frame-1 score of 0.92 is on par with VideoTransformer and slightly below VideoFlow‚Äôs 0.95.	Reply	I-Reply	4
Frames 2-6 of DVD-GAN are better than any other model, with the rest of the frames being roughly on par with VideoFlow and VideoTransformer.	Reply	I-Reply	4
The final value of 0.78 at frame 16 is slightly lower than VideoTransformer.	Reply	I-Reply	4
[line_break_token][line_break_token]&gt; Qualitative results for the BAIR experiment...[line_break_token]Agreed, the revision just uploaded includes samples from BAIR in the Appendix B as well as synthesis samples from UCF-101 in Appendix D.[line_break_token][line_break_token]&gt;... difficult to train BigGAN-like models on images and videos ... any strategies to address it?	Reply	O	0
[line_break_token]With an extremely small amount of initial hyperparameter tuning (settling on the results listed in the paper) our model was very stable on large datasets.	Reply	B-Reply	6
While DVD-GANs will eventually diverge on smaller datasets like UCF-101 and BAIR, at no point up to 1M iterations (the largest number of steps we have trained these models for) did a DVD-GAN diverge on the full Kinetics dataset, which we attribute to the dataset‚Äôs increased complexity and difficulty to be overfit.	Reply	I-Reply	6

[line_break_token]Summary[line_break_token]The authors propose training to optimize individual fairness using sensitive subspace robustness (SenSR) algorithm.	Review	O	0
[line_break_token][line_break_token]Decision[line_break_token]Overall, I recommend borderline as the paper seems legit in formulating the individual fairness problem into a minmax robust optimization problem.	Review	O	0
The authors show improvement in gender and racial biases compared to non-individual fair approaches.	Review	O	0
However, I think some sections are hard to follow for people not in the field.	Review	O	0
[line_break_token][line_break_token]Supporting argument:[line_break_token]1.	Review	O	0
End of P3, it is not clear to me why solving the worst case is better.	Review	B-Review	1
[line_break_token]2.	Review	I-Review	6
Though this paper studied individual fairness, can it also work for group fairness?	Review	I-Review	2
I am not sure whether this is the only work in this direction (baselines are not for individual fairness).	Review	I-Review	2
[line_break_token]3.	Review	O	0
Some of the metrics in the experiments are not precisely defined such as Race gap, Cuis.	Review	B-Review	3
gap, S-Con, GR-Con.	Review	I-Review	3
It is hard to follow from the text description.	Review	I-Review	3
[line_break_token]4.	Review	O	0
Some baseline models are not clearly defined such as ‚ÄúProject‚Äù in Table 1.	Review	B-Review	4
[line_break_token]5.	Review	O	0
Not sure how Section 3 connects with the rest of the paper.	Review	B-Review	5
[line_break_token][line_break_token][line_break_token]Additional feedback:[line_break_token]1.	Review	I-Review	6
Missing reference: <a href="https://arxiv.org/abs/1907.12059" target="_blank" rel="nofollow">https://arxiv.org/abs/1907.12059</a>[line_break_token]2.	Review	O	0
What‚Äôs TV distance in introduction?	Review	B-Review	6
[line_break_token]	Review	O	0
hank you for the feedback.	Reply	O	0
We address your concerns below.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
The objective that we minimize is the worst-case performance of a predictor on hypothetical training sets that are similar (only differ in irrelevant features) to the observed training set.	Reply	B-Reply	1
This leads to fairness because it penalizes predictors that perform well on the observed training set but poorly on similar hypothetical training sets.	Reply	I-Reply	1
For example, an unfair resume screening model may perform very well on a set of training resumes from mostly white men, but poorly on resumes from women or minorities.	Reply	I-Reply	1
By considering hypothetical sets of resumes from women or minorities during training, the objective we minimize penalizes models that only perform well on white men.	Reply	I-Reply	1
[line_break_token][line_break_token]2.	Reply	O	0
You can certainly encode group fairness by picking a metric that declares a pair of inputs similar whenever they are from the same group, but this is tangential to our goal of operationalizing individual fairness.	Reply	B-Reply	2
We have baselines and metrics for group fairness because group fairness is the prevalent notion in the literature.	Reply	I-Reply	2
[line_break_token][line_break_token]3.	Reply	O	0
Each of the experiments has a dedicated "Comparison metrics" paragraph.	Reply	B-Reply	3
We clarified the definitions of race and gender gaps in the corresponding paragraph.	Reply	I-Reply	3
They are the differences between average logits output by the classifier evaluated at Caucasian vs African-American names for the Race gap and Male vs Female names for the Gender gap.	Reply	I-Reply	3
Cuisine gap is the difference between logits of the embedded sentences: "Let‚Äôs go get Italian food" and "Let‚Äôs go get Mexican food".	Reply	I-Reply	3
Spouse Consistency (S-Con.)	Reply	I-Reply	3
and Gender and Race Consistency (GR-Con.)	Reply	I-Reply	3
quantify the individual fairness intuition, i.e. how often classifier prediction remains unchanged when we evaluate it on a hypothetical "counterfactual" example created by changing features such as gender and keeping all other features unchanged.	Reply	I-Reply	3
For these individual fairness metrics we did not write mathematical definition, but are happy to add one if the reviewer believes it would improve clarity.	Reply	I-Reply	3
[line_break_token][line_break_token]4.	Reply	O	0
In our experiments we discuss all baselines in the corresponding "Results" paragraphs.	Reply	B-Reply	4
Project is the pre-processing baseline where we project data onto the orthogonal complement of the sensitive subspace and then train regular classifier with the projected data.	Reply	I-Reply	4
SenSR outperforms this baseline suggesting that simply projecting out sensitive subspace is not sufficient and that robustness to unfair perturbations through SenSR gives better results in terms of fairness.	Reply	I-Reply	4
This is analogous to the observation made in the group fairness literature that simply excluding protected attribute is not sufficient to achieve fairness.	Reply	I-Reply	4
[line_break_token][line_break_token]5.	Reply	O	0
The main point of section 3 is to show that the fairness constraint generalizes; i.e. if you  train a model with SenSR, and it performs well on all hypothetical training sets that are similar to the observed training set (i.e. it seems fair on the training data), then it also performs well with high probability (WHP) on all hypothetical test sets that are similar to a test set (i.e. it is fair WHP at test time).	Reply	B-Reply	5
[line_break_token][line_break_token]We added the missing reference and clarified what is TV distance in the introduction	Reply	I-Reply	6

The authors propose two approaches to combine multiple weak generative models into a stronger one using principles from boosting.	Review	O	0
The approach is simple and elegant and basically creates an unnormalized product of experts model, where the individual experts are trained greedily to optimize the overall joint model.	Review	O	0
Unfortunately, this approach results in a joint model that has some undesirable properties: a unknown normalisation constant for the joint model and therefore an intractable log-likelihood on the test set; and it makes drawing exact samples from the joint model intractable.	Review	B-Review	1
These problems can unfortunately not be fixed by using different base learners, but are a direct result of the product of experts formulation of boosting.	Review	I-Review	1
[line_break_token]  [line_break_token]The experiments on 2 dimensional toy data illustrate that the proposed procedure works in principle and that the boosting formulation produces better results than individual weak learners and better results than e.g. bagging.	Review	O	0
But the experiments on MNIST are less convincing: Without an undisputable measure like e.g. log-likelihood it is hard to draw conclusions from the samples in Figure 2; and visually they look weak compared to even simple models like e.g. NADE.	Review	B-Review	2
[line_break_token][line_break_token]I think the paper could be improved significantly by adding a quantitative analysis: investigating the effect of combining undirected (e.g. RBM), undirected (e.g. VAE) and autoregressive (e.g. NADE) models and by measuring the improvement over the number of base learners.	Review	I-Review	3
But this would require a method to estimate the partition function Z or estimating some proxy.	Review	I-Review	3
[line_break_token]	Review	O	0
Thanks for your helpful comments.	Reply	O	0
Please refer to the common rebuttal posted for response to questions regarding MNIST experiments.	Reply	B-Reply	2
 Regarding the concerns with the unnormalized final density, we highlight that probabilistic models frequently make a trade-off between expressiveness and tractability.	Reply	I-Reply	2
Simple models such as NADE and mixture of Bernoullis make assumptions that lend tractability but are not very flexible in modeling complex structure in the data.	Reply	I-Reply	2
On the other hand, latent variable models such as VAEs and RBMs have great expressive power but need to approximate intractable integrals.	Reply	I-Reply	3
Boosted generative models also have a computationally intractable partition function  with the trade-off made in expressiveness just like VAEs, RBMs, GANs (where even the unnormalized log-likelihood cannot be directly computed), etc.	Reply	I-Reply	3
We argue that intractability is however not a deal-breaker since a).	Reply	I-Reply	3
many use cases of generative models (such as sampling, unsupervised feature learning) do not require the partition function, b).	Reply	I-Reply	3
wherever required, there are some generic techniques available for estimating the partition function	Reply	I-Reply	3

This paper presents a new method for fully- and semi-supervised few-shot classification that is based on learning a general embedding as usual, and then learning a sub-space of it for each class.	Review	O	0
A query point is then classified as the class whose sub-space is closest to it.	Review	O	0
[line_break_token][line_break_token]Pros: This is a neat idea and achieves competitive results.	Review	O	0
Learning a sub-space per class makes intuitive sense to me since it‚Äôs plausible that there is a lower-dimensional subspace of the overall embedding space that captures the properties that are common to only examples of a certain class.	Review	O	0
If this is indeed the case, it seems that indeed classifying query examples into classes based on their distances from the corresponding sub-spaces would lead to good discrimination.	Review	O	0
[line_break_token][line_break_token]Cons: First, an inherent limitation is that this approach is not applicable to one-shot learning, and I have doubts in its merit for very low shot learning (explained below).	Review	O	0
Second, I‚Äôm missing the justification behind a key point used to motivate the approach, which requires clarification (explained below).	Review	B-Review	2
Third, I feel that certain aspects of the approach were unclear (details to follow).	Review	I-Review	3
Finally, I feel more analysis is needed to better understand the differences of this method from previous work (concrete suggestions follow).	Review	I-Review	4
For semi-supervised learning, the novelty regarding how the unlabeled examples are incorporated is limited, as the approach used is previously-introduced in Ren et al, 2018.	Review	I-Review	5
[line_break_token][line_break_token]Overall, even though I like the idea and the results are good, there are a few points, mentioned in the above section that I feel require additional work before I can strongly recommend acceptance.	Review	O	0
Most importantly, relating to getting more intuition about why and when this works best, and tying it in better with previous approaches.	Review	O	0
[line_break_token][line_break_token]A key point requiring clarification.	Review	O	0
[line_break_token]There is a key fact that the authors used to motivate this approach which remains unclear to me: why is it the case that this approach is less sensitive to outliers than previous approaches?	Review	B-Review	2
In Figure 1, an outlier is pictured in each of subfigures (a) and (b) corresponding to Matching and Prototypical Networks, but not in subfigure (c) which corresponds to PSN.	Review	I-Review	2
No explanation is provided to justify this conjecture, other than empirical evaluation that is based on the overall accuracy only.	Review	I-Review	2
In particular, since SVD is used to obtain the sub-spaces, instead of an end-to-end learned projector that directly optimizes the query set accuracy, it‚Äôs not clear why if a support point is an outlier it would not affect the sub-space creation.	Review	I-Review	2
If I‚Äôm missing something, please clarify!	Review	I-Review	2
[line_break_token][line_break_token](A) Comments on the approach.	Review	O	0
[line_break_token](1) Why define X_k as the support set examples minus the class prototype instead of just the support examples themselves?	Review	O	0
The latter seems simpler, and should have all the required information for shaping the class‚Äô subspace.	Review	B-Review	6
[line_break_token](2) Note that if X_k is defined as [x_{k,1}, \dots, x_{k,K}] as proposed in the above point (ie.	Review	O	0
without subtracting the class mean from each support point) then this method would have been applicable to 1-shot too.	Review	B-Review	7
How would it then compare to a 1-shot Prototypical Network?	Review	I-Review	7
Notice that in this case the mean of the class is equal to this one example.	Review	I-Review	7
[line_break_token](3) In general, the truncated SVD decomposition for a class can be written using the matrices U, \Sigma and V^T with dimensions [D, n], [n, n] and [n, K] respectively, where D is the embedding dimensionality and K is the number of support points belonging to the given class.	Review	O	0
The middle matrix \Sigma in the non-truncated version would have dimensions [D, K]. Does this mean that when truncating, n is enforced to be smaller than each of D and K?	Review	B-Review	8
This would mean that the dimensionality n of the sub-space is limited by the number of the support examples, which in some cases may be very small in few-shot learning.	Review	I-Review	8
Can you comment on this?	Review	I-Review	8
[line_break_token](4) How to set n (the dimensionality of each subspace) is not obvious.	Review	O	0
What values were explored?	Review	B-Review	9
Is there a sweet spot in the trade-off between the observed complexity and the final accuracy?	Review	I-Review	9
[line_break_token][line_break_token](B) Comparison with Prototypical Networks.	Review	I-Review	4
[line_break_token](1) In what situations do we expect learning a sub-space per class to do better than learning a  prototype per class?	Review	I-Review	4
For example, Figure 4 shows the test-time performance as a function of the test ‚Äòway‚Äô.	Review	I-Review	4
A perhaps more interesting analysis would be to compare the models‚Äô performance as a function of the test *shot*: if more examples are available it may be less appropriate to create a prototype and more beneficial to create a sub-space?	Review	I-Review	4
[line_break_token](2) Can we recover Prototypical Networks as a special case of PSN?	Review	I-Review	4
If so, how?	Review	I-Review	4
It would be neat to show under which conditions these are equivalent.	Review	I-Review	4
[line_break_token][line_break_token](C) Clarifications regarding the semi-supervised setup.	Review	I-Review	5
[line_break_token](1) Are distractor classes sampled from a disjoint pool of classes, or is it that, for example, a class which is a distractor in an episode is a non-distractor in another episode.	Review	I-Review	5
[line_break_token](2) Similarly for labeled / unlabaled at training time.	Review	I-Review	5
Can the same example appear as labeled in one episode but unlabaled in another?	Review	I-Review	5
In Ren et al, 2018, this was prevented by creating an additional labeled/unlabeled split even for the training examples.	Review	I-Review	5
Therefore they use strictly less overall information at meta-training time than if that split weren‚Äôt used.	Review	I-Review	5
To be comparable with them, it‚Äôs important to apply this same setup.	Review	I-Review	5
[line_break_token][line_break_token](D) Additional minor comments.	Review	I-Review	10
[line_break_token](1) ‚ÄúTo work at the presence of distractors, we propose to use a fake class with zero mean‚Äù.	Review	I-Review	10
Note that this was already proposed in Ren et al, 2018.	Review	I-Review	10
They used a zero-mean, high-variance additional cluster whose aim was to ‚Äòsoak up‚Äô the distractor examples to prevent them for polluting legitimate clusters (this was the second model they proposed).	Review	I-Review	10
[line_break_token](2) In the introduction, regarding contribution iii.	Review	I-Review	10
A more appropriate way to describe this is as exploring generalization to different numbers of classes, or ‚Äòways‚Äô at test time than what was used at training time.	Review	I-Review	10
[line_break_token](3) Gidaris and Komodakis (2018) is described in the related work as using a more complicated pipeline.	Review	I-Review	10
Note however that their pipeline is in place for solving a more challenging problem than standard few-shot classification: they study how a model can maintain the ability to remember training classes while rapidly learning about new ‚Äòtest‚Äô classes.	Review	I-Review	10
[line_break_token](4) In the last line of section 5.3, use N-way instead of K-way since in the rest of the paper K was used to refer to the shot, not the way.	Review	I-Review	10
[line_break_token]	Review	O	0
[line_break_token]Q: ``Why is it the case that ... less sensitive to outliers ...''[line_break_token][line_break_token]A: A prototype in the Prototypical Networks (PN) is the average of a set and as such is sensitive to any perturbation of the set, outliers being one.	Reply	O	0
On the other hand, in PSN, a set is represented by a subspace.	Reply	B-Reply	2
To have a noticeable change in the orientation of the subspace, one needs to induce drastic changes to the set.	Reply	I-Reply	2
Having said this, we performed two extra-experiments to reinforce our conjecture here.	Reply	I-Reply	2
[line_break_token][line_break_token]In the first one, depicted in Fig.	Reply	I-Reply	2
2, we empirically studied the decision boundaries of PSN and PN.	Reply	I-Reply	2
The samples (triangle symbol) are drawn from the normal distribution for a two-class problem (column 1 and 2) and a problem with three classes (column 3 and 4).	Reply	I-Reply	2
The outliers (square symbol) are spread around initial samples.	Reply	I-Reply	2
The facecolors for outliers indicate to which class they have been assigned.	Reply	I-Reply	2
In the odd columns, we can see that the prototypes and subspaces discriminate the classes equally well.	Reply	I-Reply	2
[line_break_token]However, in the even columns, it is clearly shown that the outliers sway the prototypes and their decision boundaries while the subspace approach handles them more robustly.	Reply	I-Reply	2
  [line_break_token][line_break_token]In the second experiment, placed in appendix A, we provide the 5-way 5-shot and 5-way 10-shot results on the Mini-ImageNet by adding outliers and noise to support examples.	Reply	I-Reply	2
There are two setups conducted to examine the robustness of PSN to outliers and additive noise.	Reply	I-Reply	2
In the first experiment, the support set contains samples from classes absent in this set.	Reply	I-Reply	2
We did not split the dataset into disjoint inlier/outlier sets though, as the outliers were only presented at the test time, leading to more realistic experiments.	Reply	I-Reply	2
In the second experiment, perturbations were generated from a Gaussian distribution with random mean and predefined [line_break_token]variance.	Reply	I-Reply	2
The results shown in Fig.	Reply	I-Reply	2
4 demonstrate that on both tasks, PSN outperforms PN by a significant gap.	Reply	I-Reply	2
Note that, we utilized the same CNN architecture (4-convolutional layers) for both PSN and PN.	Reply	I-Reply	2
[line_break_token][line_break_token]Q: ``Why define as the support set examples minus the class prototype instead of just the support examples themselves?''	Reply	O	0
[line_break_token][line_break_token]A: Our idea here is to represent a class by an affine subspace which is indeed a generalization of [line_break_token]the concept of linear subspace (where the origin is a common point).	Reply	O	0
We indeed started by using linear-subspaces to model each class but empirically found that affine subspaces perform slightly better.	Reply	B-Reply	6
To address this comment, we have added a remark to Section 6.	Reply	I-Reply	6
[line_break_token][line_break_token]Q: ``How would it then compare to a 1-shot Prototypical Network?''	Reply	O	0
[line_break_token][line_break_token]A: We cannot build an affine subspace with only one example per class, as such we cannot use PSN to address 1-shot learning problems per se.	Reply	O	0
However, simply augmenting support images to obtain two or more samples per class alleviates such an issue straight away.	Reply	B-Reply	7
However, this simple issue is beyond the points we make in our paper (it is an orthogonal research direction in one- and few-shot learning).	Reply	I-Reply	7
We have reflected this in Section 6 of the revised draft to address the reviewer's comment.	Reply	I-Reply	7
[line_break_token][line_break_token]Q: ``Does this mean the dimensionality n of the sub-space is limited by the number of the support examples''[line_break_token][line_break_token]A: Affirmative.	Reply	O	0
Our idea is to construct a subspace representing the set.	Reply	B-Reply	8
The reviewer's comment raises an interesting point, whether parts of the orthogonal complement of each subspace can be used to make better decisions.	Reply	I-Reply	8
We believe that investigating the effect of orthogonal complements demands a dedicated study and goes beyond our work.	Reply	I-Reply	8
Having said this, we reflect this comment in Section 7.	Reply	I-Reply	8

This paper describes a new architecture for parallelizing off-policy reinforcement learning systems with a pool of independent learners trained on identical, but independent instances of the environment with a scheme for periodically synchronizing the the policy knowledge across the pool.	Review	O	0
The paper provides demonstrations in several continuous control domains.	Review	O	0
[line_break_token][line_break_token]I think this paper should be rejected because: 1) the approach is not well justified or placed within the large literature on parallel training architectures and population-based training methods, (2) the results are competitive with the best in each domain, but there are many missing details.	Review	O	0
Since the contribution is entirely support by empirical evidence, these issues need to be clarified.	Review	B-Review	2
I look forward to the author response, as I will pose several questions below and my final score will carefully take the answers into account.	Review	O	0
[line_break_token][line_break_token]Justification of decision.	Review	B-Review	1
There are numerous papers on parallel architectures for training deep RL systems [1,2, 6] and you cited a few, and while not all of them focus on continuous control there are design decisions and insights in those works must be relevant to your efforts.	Review	I-Review	1
You should make those connections clear in the paper.	Review	I-Review	1
One line of the paper is not nearly enough.	Review	I-Review	1
The stated focus of the paper is exploration-exploitation yet there is little to no discussion of other ideas including noisy networks, intrinsic motivation, or count-based exploration methods.	Review	I-Review	1
The paper is missing a lot of key connections to the literature.	Review	I-Review	1
[line_break_token][line_break_token]I am certainly not a fan of architectures that assume access to many instances of the environment.	Review	I-Review	3
In this case that assumption seems worse because of the target application: continuous control domains.	Review	I-Review	3
These domains are simulations of physical control systems; on a robot the agent receives only one stream of experience and thus these architectures would not work well.	Review	I-Review	3
Though there is some work on applying these multi-environment architectures to farms of robot arms; the reality of the real-world is that the arms end up being very different due to wear and tear, and engineers must constantly fix the hardware because these multi-environment architectures do not work when the environments are different.	Review	I-Review	3
We cannot loose sight of the goal here‚Äîmaximizing these simulation environments is not of interest itself, its a stepping stone‚Äîarchitectures that only work on simulations that afford multiple identical environments but fail in the real world have very limited application.	Review	I-Review	3
I think this paper needs to motivate why parallel training in this way in these robotics inspired domains is interesting and worthwhile.	Review	I-Review	3
   [line_break_token][line_break_token]The main area of concern with this paper is the experiment section.	Review	O	0
There are several issues/questions I would like the authors to address:[line_break_token]1) You built on top of TD3, however you just used the parameter settings of TD3 as published and didn‚Äôt tune them.	Review	O	0
This is a problem because it could just be that the existing parameter choices for TD3 were just better for the new approach.	Review	B-Review	4
You have to take additional effort in this case to ensure your method is actually better than just using TD3.	Review	I-Review	4
Additional parameter tuning of TD3 is required here.	Review	I-Review	4
[line_break_token]2) I think its an odd choice for TD3 to have an infinite buffer, as recent work has show at least for DQN that large buffers can hurt performance [7].  Can you justify this choice beyond ‚Äúthe authors of TD3 did it that way‚Äù?	Review	O	0
[line_break_token]3) Why is R_eval different for each method?	Review	O	0
[line_break_token]4) Why did you not compare to TD3 on the same set of domains as used in the TD3 paper?	Review	O	0
Why a subset?	Review	B-Review	7
Why these particular domains?	Review	I-Review	7
[line_break_token]5) In 2 of the 4 domains the proposed method ties or is worse than the baselines.	Review	O	0
In half-cheetah it looks close to significant, and in the ant domain the result is unlikely to be significant because the error-bars overlap and the error-bars of TD3 are wider than the other methods so a simple visual inspection is not enough.	Review	B-Review	8
There does not seem to be a strong case for the new method here.	Review	I-Review	8
I may be misunderstanding the results.	Review	I-Review	8
Help me see the significance.	Review	I-Review	8
[line_break_token]6) The paper claims improvement in variance, but this requires additional analysis in the form of an F-test of better.	Review	O	0
[line_break_token]7) Why these baselines (e.g., SAC) and not others?	Review	O	0
Why did you not include D4PG [6]?	Review	B-Review	10
Soft Q-learning?	Review	I-Review	10
A population-based training method [3,4,5,8] to name a few?	Review	I-Review	10
[line_break_token][line_break_token][1] GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning[line_break_token][2] IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures[line_break_token][3] Human-level performance in first-person multiplayer games with population-based deep reinforcement learning[line_break_token][4] Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents[line_break_token][5] Structured Evolution with Compact Architectures for Scalable Policy Optimization[line_break_token][6] Distributed Distributional Deterministic Policy Gradients[line_break_token][7] A Deeper Look at Experience Replay[line_break_token][8] Evolution Strategies as a Scalable Alternative to Reinforcement Learning[line_break_token] [line_break_token][line_break_token]Small things that did not impact the score:[line_break_token]1) references to ‚Äúsearch interval‚Äù in the abstract are confusing because the reader has not read the paper yet[line_break_token]2) Description of the method in abstract is too specific[line_break_token]3) P1 intro, not a topic sentence for what follows[line_break_token]4) ‚Äúperforms an action to its environment‚Äù > grammar[line_break_token]5) ‚ÄúOne way to parallel learning‚Ä¶‚Äù > grammar[line_break_token]6) ‚Äúthat the value parameter and‚Äù > grammar[line_break_token]7) ‚Äúpitfalls‚Äù > minima [line_break_token]8) Did you try combining you method with other base off-policy methods?	Review	O	0
how did it work?	Review	B-Review	11
[line_break_token]9) GAE undefined?	Review	I-Review	11
[line_break_token]10) ‚Äúamong the baseline and‚Äù>grammar‚Ä¶there are many grammar errors	Review	O	0
Response to Relation with Previous Works: We agree with the reviewer in that the proposed method is not properly placed in the literature in the original paper.	Reply	O	0
However, the proposed method has new ingredients in parallel learning, as mentioned by Reviewer 2.	Reply	B-Reply	1
In Section 4.3 of the revised paper, one can clearly see the impact of the new ingredients in the context of the previous works.	Reply	I-Reply	1
During the revision, we did extensive literature survey and framed our work in the context of the previous works including the references that the reviewer mentioned.	Reply	I-Reply	1
Please see Section 2 of the revised paper.	Reply	I-Reply	1
[line_break_token][line_break_token]Response to Missing Details: We agree with the reviewer in that there were many things missing in the original paper.	Reply	O	0
We included relevant new results in the revised paper.	Reply	B-Reply	2
Please see Section 2, Section 4.3 and Appendices.	Reply	I-Reply	2
Please see the response to all reviewers for what we have done during the revision.	Reply	I-Reply	2
[line_break_token][line_break_token]Response to Motivation in Parallel Learning in Continuous-Action RL: Please see the response to all reviewers.	Reply	O	0
Indeed, fast prototyping for development of large complex robot systems based on precise Newtonian-dynamics simulation platforms becomes more and more important to alleviate the difficulties that the reviewer mentioned.	Reply	B-Reply	3
Please visit <a href="https://cyberbotics.com/" target="_blank" rel="nofollow">https://cyberbotics.com/</a> .	Reply	O	0
 Furthermore, the proposed IPE method can be applied to off-policy RL algorithms with discrete actions such as DQN.	Reply	B-Reply	3
The constructed IPE-DQN algorithm is shown in Appendix E of the revised paper.	Reply	I-Reply	3
We tried IPE-DQN on several Atari games but could not obtain numerical result in this short revision time.	Reply	I-Reply	3
We have added a few sentences regarding this motivation in the conclusion of the revised paper.	Reply	I-Reply	3
[line_break_token][line_break_token]Response to Parameter Setting of TD3: Based on common sense, we believe that the authors of TD3 fine-tuned the parameters of their TD3.	Reply	O	0
As shown in Appendix D of the revised paper, IPE-SAC also performs better than SAC with the parameters in the SAC paper.	Reply	B-Reply	4
This is another evidence of generality of IPE.	Reply	I-Reply	4
[line_break_token][line_break_token]Response to The Infinite Buffer Size of TD3: The simulation is over 1 million environment steps, so the buffer size is actually 1 million.	Reply	O	0
For clarity in the revised paper we explicitly set the size of replay buffer as 1 million and obtained new performance plots in the revised paper.	Reply	B-Reply	5
[line_break_token][line_break_token]Response to R_eval: R_eval is the frequency of measuring the performance, and it does not affect training at all.	Reply	O	0
The reason for different R_eval is that the implementations of algorithms have different frequencies for writing logs.	Reply	B-Reply	6
This can be modified easily, so we set the R_eval = 4000 environment steps for all algorithms in the revised paper.	Reply	I-Reply	6
[line_break_token][line_break_token]Response to Other Environments for TD3: The environments (Reacher-v1, InvertedPendulum-v1, InvertedDoublePendulum-v1) were not considered because the performance of the previous algorithms on these environments already saturated, as seen in the original TD3 paper (Fujimoto et al.,	Reply	O	0
2018).	Reply	B-Reply	7
It seems that they achieved the optimal performance already.	Reply	I-Reply	7
IPE-TD3 will not provide improvement on these environments over other algorithms.	Reply	I-Reply	7
So, we did not feel the necessity for test of IPE-TD3 on these tests.	Reply	I-Reply	7
What we need is more challenging tasks.	Reply	I-Reply	7
[line_break_token][line_break_token]Response to Significance of IPE: The two of the four domains in the paper are easy tasks so that other algorithms already work well.	Reply	O	0
What we need is more challenging tasks to see the real gain of the method, as mentioned by Reviewers 2 and 3.	Reply	B-Reply	8
In more challenging Humanoid suggested by other reviewers, the constructed IPE-SAC outperforms SAC, as seen in Appendix D. Here, TD3 does not ever work.	Reply	I-Reply	8
[line_break_token][line_break_token]Response to F-test: F-test for variance is conducted with null hypothesis var_TD3 = var_IPE-TD3 and alternative hypothesis var_TD3 > var_IPE-TD3.	Reply	O	0
The F-statistics are 280.37, 0.69, 2.73, and 9.45 for Hopper-v1, Walker2d-v1, HalfCheetah-v1, and Ant-v1, respectively.	Reply	B-Reply	9
Thus, it seems that the variance of IPE-TD3 is smaller than that of TD3 in Hopper-v1 and Ant-v1 tasks.	Reply	I-Reply	9
[line_break_token][line_break_token]Response to Other Baselines: The revised paper includes more baselines (ACKTR and SQL).	Reply	O	0
As shown Figure 3, IPE-TD3 outperforms all baselines in the four MuJoCo tasks.	Reply	B-Reply	10
In ablation study of the revised paper, we considered other parallel enhancement methods.	Reply	I-Reply	10
Among them, the reloading method is based on the idea in PBT (Jaderberg et al.,	Reply	I-Reply	10
2017) and simply copies the best policy parameter to other learners.	Reply	I-Reply	10
As seen in Table 1 and the figures, IPE outperforms the reloading method.	Reply	I-Reply	10
So, it seems that the proposed way of fusing the best policy parameter is more effective than simply copying.	Reply	I-Reply	10
Note that simple copying means that the search area covered by all learners collapses to one point at the time of copying.	Reply	I-Reply	10
We don‚Äôt need to do this.	Reply	I-Reply	10
[line_break_token][line_break_token]Response to Minor Comments: Thanks for careful reading.	Reply	O	0
We checked the grammar.	Reply	B-Reply	11
Moreover IPE-enhanced algorithms do not use GAE	Reply	I-Reply	11

# Summary[line_break_token][line_break_token]This paper presents a BERT-inspired pretraining/finetuning setup for source code tasks.	Review	O	0
It collects a corpus of[line_break_token]unlabeled Python files for BERT pretraining, designs or adopts 5 tasks on established smaller-scale Python corpora, and[line_break_token]adjusts the BERT model to tokenize and encode source code snippets appropriately.	Review	O	0
[line_break_token][line_break_token]# Strengths[line_break_token][line_break_token]* The idea of applying the pretraining/finetuning paradigm to program analysis tasks makes sense, and has been[line_break_token]  informally attempted by multiple groups in the community in 2019.	Review	O	0
This is the first high-quality submission to a[line_break_token]  top-tier ML conference I've seen on the subject, though.	Review	O	0
[line_break_token]* The authors exercised commendable care and diligence in preparing the training data, adopting BERT to source code[line_break_token]  inputs, and ensuring correctness of the experimental setup.	Review	O	0
I appreciated all the provided details on tokenization[line_break_token]  (Section 3.3), deduplication (Sections 3.1-3.2), and task setup (Section 3.5).	Review	O	0
This should become a technical standard[line_break_token]  in the community.	Review	O	0
[line_break_token]* The paper is written clearly and concisely, and is generally a pleasure to read.	Review	O	0
[line_break_token][line_break_token]# Weaknesses[line_break_token][line_break_token]I have a gripe with the authors' choice to ignore program structure (e.g. abstract syntax trees) or features (e.g.[line_break_token]types) in their program representation.	Review	O	0
Without this extra information (easily available from a compiler/interpreter[line_break_token]API) the pipeline is not substantially different from the original NLP pipeline of BERT et al.	Review	B-Review	1
The main program-related[line_break_token]representation insight comes in tokenization (Section 3.3) and the definition of "sentences".	Review	I-Review	1
To repeat, I appreciate[line_break_token]the effort the authors put in making tokenization appropriate for BERT processing of source code, but this is a drop in[line_break_token]the bucket compared to the all the other program-related features the work is leaving off the table.	Review	I-Review	1
Programs are not[line_break_token]natural language.	Review	I-Review	1
[line_break_token]The argument that source code analysis would "pass on the burden ... to downstream tasks" (Page 3) is odd.	Review	I-Review	2
First, most[line_break_token]downstream tasks of interest occur in the settings where this analysis is already available: IDEs, code review[line_break_token]assistants, linters, etc.	Review	I-Review	2
Second, one often needs program analysis to even define downstream tasks in the first place --[line_break_token]for example, determining whether function arguments are swapped required detecting a function call and boundaries of its[line_break_token]arguments, thus parsing the program!	Review	I-Review	2
[line_break_token][line_break_token]This work obtains (and nicely analyzes) impressive results obtained by applying CuBERT.	Review	I-Review	3
However, it does not put the[line_break_token]results in context with prior work based on structured program representations.	Review	I-Review	3
Without this, it is difficult to say[line_break_token]whether the improvement comes from pretraining or from the language model simply learning a better "parsed"[line_break_token]representation of an input program from all the unlabeled corpus.	Review	I-Review	3
If it's the latter, one might argue that supplying the[line_break_token]model with structured program features explicitly might eliminate much of the need for the unlabeled corpus.	Review	I-Review	3
[line_break_token]I personally think that there will still be a gap between pretraining and finetuning even with structured program[line_break_token]features simply due to the sheer volume of available data, which, as the authors showed, is crucial for good[line_break_token]generalization of Transformer.	Review	I-Review	3
However, this still needs to be shown empirically.	Review	I-Review	3
[line_break_token][line_break_token]The "Function-Docstring Mismatch" task, as presented, seems too easy.	Review	I-Review	4
If the distractors (negative examples) are truly[line_break_token]chosen at random, most of them are going to use obviously different vocabulary from the original function signature (as[line_break_token]Figure 4 demonstrates).	Review	I-Review	4
A well designed task would somehow bias the sampling toward subtle distractors such as `get` vs.[line_break_token]`set` docstrings, but this seems challenging.	Review	I-Review	4
[line_break_token]This also explains why the task is not influenced as much by reduction of training data (Table 3).	Review	I-Review	4
[line_break_token][line_break_token]The Next Sentence Prediction pretraining task, as adapted for CuBERT, seems too difficult, in contrast.	Review	I-Review	5
If the paired[line_break_token]sentences (i.e. code lines) are chosen at random, the model would lack most of the context required to make a decision[line_break_token]about the logical relationship between them, such as which variables are defined and available in context, which[line_break_token]functionality is being implemented, etc.	Review	I-Review	5
I wonder, can the authors experiment with pretraining CuBERT only with the[line_break_token]Masked Language Model task?	Review	I-Review	5
Will it worsen the results substantially or at all?	Review	I-Review	5
[line_break_token][line_break_token]# Questions[line_break_token][line_break_token]Section 3.2: "similar files according to the same similarity metric..."[line_break_token]What are these metrics?	Review	O	0
[line_break_token][line_break_token]What is the fraction of positive/negative examples in the constructed finetuning datasets?	Review	B-Review	7
[line_break_token][line_break_token]What is the motivation for making Variable Misuse and Wrong Operator/Operand into a simple classification tasks instead[line_break_token]of the original (more useful) correction task?	Review	I-Review	8
[line_break_token]	Review	O	0
e thank the reviewer for the helpful comments and suggestions.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt; Choice to ignore program structure (e.g. abstract syntax trees) or features (e.g. types)[line_break_token][line_break_token]Natural languages are also endowed with structure (e.g., different types of parse trees, phrase structures, etc.).	Reply	O	0
However, the prevailing pre-training methods in NLP such as BERT do not make explicit use of such structure, and still attain state-of-the-art results.	Reply	B-Reply	1
The task of learning useful (structural) features is left to the self-attention mechanism of the Transformer model.	Reply	I-Reply	1
In this work, we apply the same approach to program-understanding tasks.	Reply	I-Reply	1
We recognize that it may be possible to extend CuBERT with explicitly provided structural information using approaches like relation-aware Transformers (see "Self-attention with relative position representations", <a href="https://www.aclweb.org/anthology/N18-2074.pdf)" target="_blank" rel="nofollow">https://www.aclweb.org/anthology/N18-2074.pdf)</a> in place of the usual Transformers based on sinusoidal positional encodings, and hope to try this in future work; this submission will provide a strong baseline to evaluate such future work.	Reply	O	0
We thank the reviewer for raising this point.	Reply	B-Reply	1
We now include this possibility as a future extension in Section 5, which we rename from ‚ÄúConclusions‚Äù to ‚ÄúConclusions and Future Work‚Äù.	Reply	I-Reply	1
[line_break_token][line_break_token]With regard to types, we do not assume that the source code is written in a statically typed language and hence, do not use types as features.	Reply	I-Reply	1
We train CuBERT for Python code, which is dynamically typed.	Reply	I-Reply	1
We leave exploring type information for statically-typed languages for future work.	Reply	I-Reply	1
[line_break_token][line_break_token]&gt;&gt; Burden of program analysis[line_break_token][line_break_token]The reviewer‚Äôs point is well taken.	Reply	O	0
We have reworded our relevant text in the paper.	Reply	B-Reply	2
To recap, our goal is to understand and evaluate a BERT-like pre-training approach (i.e., purely on lexical information) for program-understanding tasks, without exposing to the pre-training model additional information gleaned through program analysis.	Reply	I-Reply	2
[line_break_token][line_break_token]&gt;&gt; Simplicity of the Function-Docstring Mismatch task[line_break_token][line_break_token]We agree with the reviewer‚Äôs observation.	Reply	O	0
Nevertheless, the inherent ability of Transformer to relate every pair of tokens through self-attention plays a crucial role in CuBERT getting +7.5% improvement over the baseline model even on this relatively simple task.	Reply	B-Reply	4
[line_break_token][line_break_token]&gt;&gt; Utility of Next Sentence Prediction task[line_break_token][line_break_token]A recent work has argued that using only the Masked Language Model objective (coupled with more training on larger datasets) can improve the performance of BERT (see "RoBERTa: An optimized method for pretraining self-supervised NLP systems", <a href="https://arxiv.org/abs/1907.11692)."	Reply	O	0
target="_blank" rel="nofollow">https://arxiv.org/abs/1907.11692).</a> It will take more experimentation to check how inclusion/exclusion of next-sentence-prediction affects CuBERT.	Reply	O	0
[line_break_token][line_break_token]&gt;&gt; Explanation of similarity metric[line_break_token][line_break_token]Two files are considered similar to each other if the Jaccard similarity between the sets of tokens (identifiers and string literals) is above 0.8 and in addition, it is above 0.7 for multi-sets of tokens.	Reply	O	0
This is based on the criteria used in Allamanis (2018).	Reply	B-Reply	6
We have added this explanation in the revised version.	Reply	I-Reply	6
[line_break_token][line_break_token]&gt;&gt; Fraction of positive/negative examples in the finetuning tasks[line_break_token][line_break_token]We have provided these details in Appendix A now.	Reply	O	0
To summarize, all classification tasks except Exception Type classification, and the new pointer task (Section 4.7), have a 50-50 split of buggy/bug-free examples.	Reply	B-Reply	7
The per-class counts for the Exception Type classification task are shown in the (new) Table 6.	Reply	I-Reply	7
[line_break_token][line_break_token]&gt;&gt; Motivation for making Variable Misuse and Wrong Operator/Operand as classification tasks instead of correction tasks[line_break_token][line_break_token]We have now included experimentation for the joint task of classification, localization and repair of variable misuse errors from Vasic et al. (	Reply	O	0
2019).	Reply	B-Reply	8
Please see Section 4.7 for the results.	Reply	I-Reply	8
The original Wrong Operator and Swapped Operand tasks from (Pradel &amp; Sen 2018) are binary classification tasks similar to ours.	Reply	O	0
They were not error correction tasks.	Reply	B-Reply	8

This paper proposes analysis of regularization, weight Froebius-norm and feature L2 norm, showing that it is equivalent to another proposed regularization, gradient magnitude loss.	Review	O	0
They then argue that: 1) it is helpful to low-shot learning, 2) it is numerically stable, 3) it is a soft version of Batch Normalization.	Review	O	0
Finally, they demonstrate experimentally that such a regularization improves performance on low-shot tasks.	Review	O	0
[line_break_token][line_break_token]First, this is a nice analysis of some simple models, and proposes interesting insights in some optimization issues.	Review	B-Review	1
Unfortunately, the authors do not demonstrate, nor argue in a convincing manner, that such an analysis extends to deep non-linear computation structures.	Review	I-Review	1
I feel like the authors could write a full paper about "results can be derived for œÜ(x) with convex differentiable non-linear activation functions such as ReLU", both via analysis and experimentation to measure numerical stability.	Review	I-Review	1
[line_break_token][line_break_token]Second, the authors again show an interesting correspondance to batch normalization, but IMO fail to experimentally show its relevance.	Review	I-Review	2
[line_break_token][line_break_token]Finally, I understand the appeal of the proposed method from a numerical stability point of view, but am not convinced that it has any effect on low-shot learning in the high dimensional spaces that deep networks are used for.	Review	I-Review	3
[line_break_token][line_break_token]I commend the authors for contributing to the mathematical understanding of our field, but I think they have yet to demonstrate the large scale effectiveness of what they propose.	Review	O	0
At the same time, I feel like this paper does not have a clear and strong message.	Review	O	0
It makes various (interesting) claims about a number of things, but they seem more or less disparate, and only loosely related to low-shot learning.	Review	O	0
[line_break_token][line_break_token]notes:[line_break_token]- "an expectation taken with respect to the empirical distribution generated by the training set", generally the training set is viewed as a "montecarlo" sample of the underlying, unknown data distribution \mathcal{D}.[line_break_token]- "we can see that our model learns meaningful representations", it gets a 6.5% improvement on the baseline, but there is no analysis of the meaningfulness of the representations.	Review	B-Review	4
[line_break_token]- "Table 13.2" should be "Table 2".	Review	I-Review	4
[line_break_token]- please be mindful of formatting, some citations should be parenthesized and there are numerous extraneous and missing spacings between words and sentences.	Review	I-Review	4
[line_break_token]	Review	O	0
To AnonReview1:[line_break_token]We appreciate your valuable comments and suggestions.	Reply	O	0
We have modified our paper accordingly and submitted a revised version on Jan 11th.	Reply	O	0
Sorry for the long delay.	Reply	O	0
It takes us a while to carry out experiments on the large-scale ImageNet benchmark.	Reply	O	0
[line_break_token][line_break_token]* About Non-linear cases to derive similar results:[line_break_token]Great thanks.	Reply	O	0
More general idea could be derived for (1) non-linear ReLU and max-pooling as well as (2) deeper models with 3+ layers.	Reply	B-Reply	1
Many other popular forms such as tanh could also be used.	Reply	I-Reply	1
[line_break_token]We are working on this question and focus on ReLU case here.	Reply	I-Reply	1
The ReLU operator on a hidden "h" and changes the 1st order gradient of dE/dh.	Reply	I-Reply	1
A tricky problem is that ReLU is not 2nd-order differentiable with infinite Hessian.	Reply	I-Reply	1
If we substitute ReLU(x)=max{0,x} with a 2nd-order differentiable version CReLU(x)=ln(1+e^x), the revised Hessian of Eqn(11) is still convex and could be numerically more stable with regularizer added.	Reply	I-Reply	1
Also, for max-pooling case, the selected max-value among the max operation channels will dominate the computation and set the 1st and 2nd order derivatives of non-maximum elements to zero.	Reply	I-Reply	1
[line_break_token][line_break_token]These are our preliminary extension to the more common non-linear scenario and added in the revised version.	Reply	I-Reply	1
Though linear case is also non-trivial due to the non-convexity of the optimization problem as a whole, a more general analysis will make our conclusion more complete.	Reply	I-Reply	1
We are working on the extension now.	Reply	I-Reply	1
[line_break_token][line_break_token]* About comparison with batch-normalization[line_break_token]Great thanks for the very good suggestion.	Reply	O	0
This issue is raised by several reviewers and is of importance to evaluate the proposed model completely.	Reply	B-Reply	2
We add classification performance comparison between our feature penalty method (FP) and batch normalization (BN).	Reply	I-Reply	2
It is a little tricky to set up a fair comparison, since our model only includes regularization on the last hidden layer and BN modules are generally added on every layer.	Reply	I-Reply	2
For now we still keep BN layers in previous layers.	Reply	I-Reply	2
Our current comparison on supervised learning tasks indicates that the two methods achieves similar performance on MNIST, CIFAR-10 and Omniglot; on ImageNet, BN is slightly better than FP (75% v.s.	Reply	I-Reply	2
74%).	Reply	I-Reply	2
Both BN and FP outperforms baseline CNN, and the best classification performance can be achieved with both modules added.	Reply	I-Reply	2
[line_break_token]We include this part in our revised version.	Reply	I-Reply	2
We notice that FP can substitute BN in every layer rather than only the last layer.	Reply	I-Reply	2
We are working on a more complete comparison.	Reply	I-Reply	2
[line_break_token][line_break_token]* About why feature regularizer works in case of low-shot learning:[line_break_token]This is the central question we try to answer in our paper, and we are carefully rethinking about this problem from the angle of generalization ability.	Reply	O	0
[line_break_token][line_break_token]In the origin paper of SGM, the intuitive explanation is that a large gradient might be outlier.	Reply	B-Reply	3
[line_break_token][line_break_token]We observe that in the supervised learning the CNN model achieves almost 100% accuracy on training and lower accuracy on testing, especially the several low-shot scenarios experimentally.	Reply	I-Reply	3
We regard the performance discrepancy is actually from over-fitting, due to the complexity and parameter amount of neural network models.	Reply	I-Reply	3
The training/testing performance discrepancy could be reduced if a good regularizer (with both feature penalty and weight decay) is introduced.	Reply	I-Reply	3
The regularizer acts like a "max-margin" (an analogy to SVM, the distance from support vectors to the plane) to limit the selection of parameter space and thus further reduce the "VC-dimension".	Reply	I-Reply	3
[line_break_token][line_break_token]This is our preliminary guess and we have included some analysis in our revised version.	Reply	I-Reply	3
We are working on improving it.	Reply	I-Reply	3
[line_break_token][line_break_token]* Strict in presentation and reorganization of the paper:[line_break_token]Great thanks for the suggestions of presentation improvement.	Reply	O	0
We have already modified some of them accordingly in our revised version.	Reply	B-Reply	4
We will further proof-read to make it better.	Reply	I-Reply	4
[line_break_token]Also, current version is a little bit too dense.	Reply	I-Reply	4
We manage to include new experimental results and analysis in our revised paper.	Reply	I-Reply	4
We will trim it down within 9 pages, with some detailed derivations left in supplemental materials	Reply	I-Reply	4

Summary:[line_break_token]This paper proposes learning a pooling layer (not necessarily of a convolutional network) by using temporal coherence to learn the pools.	Review	O	0
Training is accomplished by minimizing a criterion that encourages the features to change slowly but have high entropy over all.	Review	O	0
[line_break_token]Detailed comments:[line_break_token]-The method demonstrates improvement over a spatial pooling baseline[line_break_token]-The experiments here don't allow comparison to prior work on learning pools, such as the paper by Jia and Huang.	Review	O	0
[line_break_token]- The method is not competitive with the state of the art[line_break_token][line_break_token]Suggestions to authors:[line_break_token][line_break_token]In future revisions of this paper, please be more specific about what your source of natural videos was.	Review	O	0
Just saying vimeo.com is not very specific.	Review	B-Review	3
vimeo.com has a lot of videos.	Review	I-Review	3
How many did you use?	Review	I-Review	3
Do they include the same kinds of objects as you need to classify on CIFAR-10?	Review	I-Review	3
[line_break_token]Comparing to Jia and Huang is very important, since they also study learning pooling structure.	Review	I-Review	3
Note that there are also new papers at ICLR on learning pooling structure you should consider in the future.	Review	I-Review	3
I think Y-Lan Boureau also wrote a paper on learning pools that might be relevant.	Review	I-Review	3
[line_break_token]Pros:[line_break_token]-The method demonstrates some improvement over baseline pooling systems applied to the same task.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token]-Doesn't compare to prior work on learning pools[line_break_token]-The method isn't competitive with the state of the art, despite having access to extra training data.	Review	O	0
First of all, thank you for reviewing our paper.	Reply	O	0
It was a valuable feedback.	Reply	O	0
We will try to include mentioned papers in the next revision.	Reply	O	0
[line_break_token][line_break_token]About the video dataset:[line_break_token]- We will include a detailed explanation in the next revision.	Reply	O	0
In short, 40 short (2-5 minutes in length) videos are used in our experiments.	Reply	B-Reply	3
We tried to collect videos containing the same objects as CIFAR10.	Reply	I-Reply	3
However, images extracted from the videos were very different from CIFAR10 images.	Reply	I-Reply	3
Many of them didn't include any object, and some only showed a small part of an object.	Reply	I-Reply	3
[line_break_token][line_break_token]Comparison to Jia and Huang's method:[line_break_token]- We didn't compare our method to Jia and Huang's method, because they are fundamentally different methods.	Reply	O	0
While Jia and Huang's method learns pooling regions in a supervised way, our method tries to learn pooling regions in an unsupervised way, which has many advantages.	Reply	B-Reply	1
[line_break_token]- Although our method uses additional data, the data used for learning pooling regions was not labeled.	Reply	O	0
On the other hand, Jia and Huang's method has an advantage of using labeled data, which produces pooling regions specialized for the classification task.	Reply	B-Reply	1
[line_break_token][line_break_token]Comparison to state-of-art methods:[line_break_token]- It is true that our result on CIFAR10 is below the state-of-art.	Reply	O	0
However, as shown by Adam Coates (ICML, 2011), classification results are largely influenced by the configuration of feature learning, especially by the number of features.	Reply	B-Reply	2
Since the feature learning was not our research focus, we did little tweaking and optimization in the feature learning step.	Reply	I-Reply	2
Also, restricted by the computation time, we didn't use large number of features (100 instead of 1600), which is likely the main reason of the low test accuracies.	Reply	I-Reply	2
[line_break_token][line_break_token]- In the end, let us restate the main contribution of our paper.	Reply	O	0
Our pooling method is novel because it learned pooling regions in an unsupervised way.	Reply	B-Reply	2
In addition, it does not use explicit spatial information and it can be used with any pre-learned features.	Reply	I-Reply	2
To the best our knowledge, there is no other pooling method that suffices those conditions	Reply	I-Reply	2

The paper describes a method for integrating scale equivariance into convolutional networks using steerable filters.	Review	O	0
 After developing the theory using continuous scale and translation space, a discretized implementation using a fixed set of steerable basis elements is described.	Review	O	0
 Experiments are performed measuring the error from true equivariance, varying number of layers, image scale and scales in scale interactions.	Review	O	0
 The method is evaluated using MNIST-scale and STL-10, with convincing results on MNIST-scale and bit less convincing but still good results on STL-10.	Review	O	0
[line_break_token][line_break_token]Overall, I think this is a nice paper with generally good explanations and experiments probing the behavior.	Review	O	0
 I would have liked to see more probing into the effects of number and distance between scales.	Review	B-Review	1
 Table 1 and corresponding text say that a significant advantage of the approach is that it can handle arbitrary scale values, but there was no explicit exploration of the effects of using this beyond one set of scales per experiment/dataset.	Review	I-Review	1
 What scale values can be sampled, which work best, and why?	Review	I-Review	1
[line_break_token][line_break_token]Also, while the MNIST-scale experiment seems convincing, I think the STL-10 is a bit less (but still OK):  Although the method outperforms other methods and appropriate baseline models, it's a little disappointing that pooling over scales (which I would would convert the equivariance to invariance) is best, and inter-scale interactions increase error.	Review	I-Review	2
 (Perhaps this is not too surprising in retrospect, as images may have limited scale variation from camera position in this dataset, but significant within-class viewpoint variation.)	Review	I-Review	2
[line_break_token][line_break_token]Even so, I still find the method concise and of interest, with the basics evaluated, even if some of its unique advantages may have been better explored.	Review	O	0
[line_break_token][line_break_token][line_break_token]Additional Questions:[line_break_token][line_break_token]* Inter-scale interaction could be elaborated a bit more.	Review	O	0
 End of sec 4 says, "use convHH for each scale sequentially and .. sum".	Review	B-Review	3
 I believe this is sequencing over scales in the kernel; explaining a bit better how this is implemented, including the shape of w in this case, would be helpful.	Review	I-Review	3
[line_break_token][line_break_token]* Which scales were chosen for the fixed basis?	Review	O	0
 How large in spatial extent are the kernels in the basis elements, at each scale?	Review	B-Review	4
[line_break_token][line_break_token]* In the implementation, what is the value of V (sampled 2d conv kernel size)?	Review	O	0
[line_break_token]	Review	O	0
hank you for your review.	Reply	O	0
[line_break_token][line_break_token]We compared our results on STL-10 to the current state-of-the-art model in the supervised learning setting known as Harm-WRN.	Reply	B-Reply	2
Our model SESN-B ourperformes it by more than 1% and achieves new state-of-the-art result on this dataset in the supervised learning setting.	Reply	I-Reply	2
We include Harm-WRN  in Table 3 for comparison.	Reply	I-Reply	2
[line_break_token][line_break_token]Q: Inter-scale interaction could be elaborated a bit more.	Reply	O	0
I believe this is sequencing over scales in the kernel.	Reply	O	0
[line_break_token] [line_break_token]A: Indeed.	Reply	O	0
You are right.	Reply	B-Reply	2
In the case of interscale interaction has shape.	Reply	I-Reply	2
We iterate over all scales in interaction, we shift for each scale and choose a corresponding part of and apply convHH.	Reply	I-Reply	2
We sum the obtained results afterwards.	Reply	I-Reply	2
Thank you for this comment.	Reply	I-Reply	2
We rephrased this section of our paper to make it easier for understanding.	Reply	I-Reply	2
[line_break_token][line_break_token]-------------------------[line_break_token][line_break_token]Q: Which scales were chosen for the fixed basis?	Reply	O	0
How large in spatial extent are the kernels in the basis elements, at each scale?	Reply	O	0
In the implementation, what is the value of V?	Reply	O	0
[line_break_token][line_break_token]A: The scales and therefore are the hyperparameters of the proposed method.	Reply	O	0
The set of values we choose from is tailored by the requirement of the completeness of the obtained basis on the smallest scale when it is projected to the pixel grid.	Reply	B-Reply	5
[line_break_token][line_break_token]For MNIST-scale experiment we used 4 scales with a step of.	Reply	I-Reply	5
We generate filters for and store them in an array of spatial extent of.	Reply	I-Reply	5
We choose by relying on prior knowledge about the dataset.	Reply	I-Reply	5
And the value of 1.5 is chosen from a set of with a step of 0.1 by using cross-validation.	Reply	I-Reply	5
We choose the value which gives the best accuracy on the validation set.	Reply	I-Reply	5
The variation of the accuracy during cross-validation is of 0.1% on the scale of about 2%.	Reply	I-Reply	5
[line_break_token][line_break_token]For STL-10 experiment, we sample 3 bases for and store them in an array of spatial extent of.	Reply	I-Reply	5
We chose the maximum number of scales we are able to use on our hardware.	Reply	I-Reply	5
Here we use value of as it generated the complete basis on the smallest scale.	Reply	I-Reply	5
And the value of is motivated by the assumption that in natural images of cats, cars, horses, etc.	Reply	I-Reply	5
the scale variations are usually of factor 2.	Reply	I-Reply	5
We did not run cross validation on this dataset	Reply	I-Reply	5

This paper proposes a new method for solving the metric constrained problem based on projections on cutting planes.	Review	O	0
Its main contribution comes from the "forgetting" part, where unnecessary constraints (that are inactive) are removed in order to keep the number of constraints manageable.	Review	O	0
[line_break_token][line_break_token]Pros: [line_break_token][line_break_token]The methods seem practically useful as verified in the experiments.	Review	O	0
[line_break_token][line_break_token]Cons: [line_break_token][line_break_token]Most importantly, the paper is out of format and there exist some critical typos that need to be fixed.	Review	O	0
[line_break_token]- The margin of the paper is wider than the official ICLR format.	Review	O	0
It needs to be reformatted and verified to be under 10 pages limit.	Review	B-Review	1
[line_break_token]- There seem to be multiple Latex bugs on referring the section numbers, e.g., "see appendix refsec:genealProblem" at bottom of page 5.	Review	O	0
[line_break_token][line_break_token]There is no theoretical guarantee on its improvement over existing methods, i.e., the forgotten constraints can reappear during optimization for multiple numbers of times.	Review	B-Review	3
However, I think this point is not crucial given the empirical usefulness of the algorithm.	Review	I-Review	3
[line_break_token][line_break_token]Minor questions: [line_break_token]- To my knowledge, cutting plane methods for the integer programming method (including Gurobi) already use an instance "project and forget" method, i.e., iteratively solving linear programs and then adding &amp; removing cutting planes.	Review	O	0
See [1] for an example.	Review	B-Review	4
Could the authors discuss the relationship between the two methods and highlight the relative difference &amp; contribution?	Review	O	0
[line_break_token][line_break_token][1] The cutting plane method is polynomial for perfect matchings, Chandrasekaran et al.,	Review	O	0
2012[line_break_token][line_break_token]========= [line_break_token][line_break_token]I have checked that the authors have re-formatted the paper into a correct form.	Review	O	0
I raise my score since I think the paper is interesting and provides a practically useful algorithm.	Review	O	0
he question about cutting planes is a great question.	Reply	B-Reply	4
As far as this author understands it, the cutting plane method in Gurobi is for mixed integer programming (MIP) and uses Gromov cuts.	Reply	I-Reply	4
[line_break_token][line_break_token]The difficulty of MIPs comes from the integrality constraints and not because they have a large number of constraints.	Reply	I-Reply	4
Hence using Gromov cuts lets us reduce the choices for the integral constraints until we can add the constraint.	Reply	I-Reply	4
Thus, reducing it to a linear program.	Reply	I-Reply	4
[line_break_token][line_break_token]However, in general, the cutting plane method highly depends on the choice of cuts.	Reply	I-Reply	4
 See [2,3] for in-depth discussions.	Reply	I-Reply	4
For other problems that are not MIPs, we have some success cases such as [1], but we have not had success in all problems.	Reply	I-Reply	4
[line_break_token][line_break_token]One of the key differences between the standard cutting plane method and Project and Forget is that in the standard cutting plane method, every time we introduce new constraints, we solve the whole optimization problem again.	Reply	I-Reply	4
In the case of Project and Forget, we do a round of projections.	Reply	I-Reply	4
 [line_break_token][line_break_token]Re-solving the LP again has potential issues.	Reply	I-Reply	4
In the case of metric constrained problems, we have a large number of constraints.	Reply	I-Reply	4
Thus, if we added a large portion of these constraints, we still cannot solve the LP using standard techniques.	Reply	I-Reply	4
 We could add in the constraints slowly so that this is not an issue.	Reply	I-Reply	4
However, then the intermediate solutions do not necessarily tell us anything about the final solution, and it is unclear whether progress is being made, and we may need too many rounds.	Reply	I-Reply	4
[line_break_token][line_break_token]The Project and Forget method addresses this issue.	Reply	I-Reply	4
If we added into many inactive constraints, then we only need to do one round of projections.	Reply	I-Reply	4
This is less computationally expensive than solving a whole LP.	Reply	I-Reply	4
Thus, we get to the forget step much faster.	Reply	I-Reply	4
Thus in practice, we add a large number of constraints initially, as seen in Figure 1.	Reply	I-Reply	4
However, we forget the inactive constraints quickly, and the projections done onto the active constraints constitute some progress towards finding the final solution. (	Reply	I-Reply	4
We may have projected onto inactive constraints, but experimentally, we tend to undo this relatively quickly.)	Reply	I-Reply	4
[line_break_token][line_break_token]Finally, we also have the generic version of our algorithm presented in the appendix.	Reply	I-Reply	4
For the general version of the algorithm, we have a subroutine that we dub the oracle.	Reply	I-Reply	4
Here the oracle is just the cutting plane selection method.	Reply	I-Reply	4
Here we show that under some weak assumptions (property 1) that our algorithm has a linear rate of convergence.	Reply	I-Reply	4
Additionally, we show that if we randomly sample constraints, then with probability 1, we have a linear rate of convergence.	Reply	I-Reply	4
[line_break_token][line_break_token][1]Karthekeyan Chandrasekaran, L√°szl√≥ A. V√©gh, and Santosh Vempala.	Reply	O	0
The cutting plane method is polynomial for perfect matchings.	Reply	O	0
In 2012 IEEE 53rd Annual Symposium on Foundations of Computer Science[line_break_token][2]Santanu S. Dey and Marco Molinaro.	Reply	O	0
Theoretical challenges towards cutting-plane selection.	Reply	O	0
Math.	Reply	O	0
Program.	Reply	O	0
[line_break_token][3]Laurent Poirrier and James Yu.	Reply	O	0
On the depth of cutting planes.	Reply	O	0
arXiv e-prints.	Reply	O	0

Summary[line_break_token]This paper propose an extention method of SGD, deep gradient boosting (DGB), which views the back-propagation procedure as a pseudo-residual targets of a gradient boosting problem.	Review	O	0
To apply DGB to the real CNNs, DGB is simplified to a input normalization layer, conditioned on the assumption that the convolution kernels should be small.	Review	O	0
After applying the input normalization layer to CNNs, the model could achieve comparable performance to the model with BN on CIFAR-10 and ImageNet recognition.	Review	O	0
[line_break_token][line_break_token]There are several concerns influencing my rating:[line_break_token]* I cannot catch the advantages of this input normalization layer compared to BN.	Review	O	0
For example, could this input normalization layer help to address the problem that BN performs bad when batch size is small?	Review	B-Review	1
The authors mention that this layer does not have additional parameters.	Review	I-Review	1
But as I know, the parameter size of BN is small, which downgrades the significance of the proposed method.	Review	I-Review	1
[line_break_token][line_break_token]* In the CIFAR-10 and ImageNet experiments, only the VGG model is adopted, which obviously limits the application scope.	Review	O	0
Could the proposed method work well on ResNet, DenseNet or other more recent deep architectures?	Review	B-Review	2
[line_break_token][line_break_token]* In the DGB experiments, the improvements of DGB compared with SGD in four datasets all seem marginal, in which DGB is slower than SGD.	Review	O	0
[line_break_token][line_break_token]Overall, I recognize the exploration of this method.	Review	O	0
But the advantages of DGB compared to SGD seem marginal.	Review	O	0
[line_break_token]	Review	O	0
hank you for carefully reading the paper.	Reply	O	0
[line_break_token][line_break_token]Though we mostly focus on INN(l), INN(l) is an alternative to batch norm and INN(r) is an alternative to layer norm.	Reply	B-Reply	1
This work shows how both formulations are equivalent and emerge from the dual solution to ridge regression.	Reply	I-Reply	1
INN also gives a specific meaning to alpha which can be treated as a hyper-parameter and adjusted according to the problem.	Reply	I-Reply	1
It is true that the parameter space of BN is small in comparison the the space of parameters of modern deep networks but could be significant in smaller applications.	Reply	I-Reply	1
In addition, without the extra parameters memory saving schemes could be employed where the intermediate outputs don't need to be saved during the forward pass and could be calculated on the fly during the backward pass.	Reply	I-Reply	1
[line_break_token][line_break_token]For ImageNet, we have added a couple of experiments performed using ResNet101 to the manuscript.	Reply	I-Reply	2
[line_break_token][line_break_token]We have added running times for the MNIST experiment and showed that for a batch size of 100 samples DGB(r) takes just 13% more time per iteration.	Reply	I-Reply	3
We'd also like to point out that the performance increase for Air and Higgs are significant given the standard deviations shown in Tables A1 and A4.	Reply	I-Reply	3

The authors propose TD-VAE to solve an important problem in agent learning, simulating the future by doing jumpy-rollouts in abstract states with uncertainty.	Review	O	0
The authors first formulate the sequential TD-VAE and then generalize it for jumpy rollouts.	Review	O	0
The proposed method is well evaluated for four tasks including high dimensional complex task.	Review	O	0
[line_break_token][line_break_token]Pros.	Review	O	0
[line_break_token]- Advancing a significant problem[line_break_token]- Principled and quite original modeling based on variational inference[line_break_token]- Rigorous experiments including complex high dimensional experiments[line_break_token]- Clear and intuitive explanation (but can be improved further)[line_break_token][line_break_token]Cons.	Review	O	0
[line_break_token]- Some details on the experiments are missing (due to page limit).	Review	O	0
It would be great to include these in the Appendix.	Review	B-Review	1
[line_break_token]- It is a complex model.	Review	O	0
For reproducibility, detail specification on the hyperparameters and architecture will be helpful.	Review	B-Review	2
[line_break_token][line_break_token]Minor comments[line_break_token]- Why q(z_{t-1}|z_t, b_{t-1}, b_t) depends both  b_{t-1}, b_t, not only b_t?	Review	O	0
[line_break_token]- The original model does not take the jump interval as input.	Review	O	0
Then, it is not clear how the jump interval is determined in p(z‚Äô|z)?	Review	B-Review	4
[line_break_token]	Review	O	0
Thank you for the review and comments.	Reply	O	0
[line_break_token]Thanks for the suggestion - we added missing experiment details, network specifications and hyperparameters in the appendix.	Reply	O	0
[line_break_token]You are correct that q(z_{t-1}|z_t, b_{t-1}, b_t) does not need to depend on b_{t-1}, but it does not hurt to do so; we chose to do so in order to further facilitate the learning of b_{t-1}, but it may not have affected experiments.	Reply	B-Reply	3
[line_break_token]If the model does not take the jump interval as input, the model has to represent the jump size by way of a multimodal distribution over possible future events.	Reply	I-Reply	4
One could imagine that one of the latent variables could be learned to correspond to dt.	Reply	I-Reply	4
[line_break_token]	Reply	O	0

This paper first theoretically demonstrates that a commonly used reinforcement learning method for neural sequence-to-sequence models (e.g. in NMT), contrastive minimum risk training (CMRT), is not guaranteed to converge to local (let alone global) optima of the reward function.	Review	O	0
The paper then empirically demonstrates that the REINFORCE algorithm, while not subject to the same theoretical flaws as CMRT, in practice fails to improve NMT models unless the baseline model is already "nearly correct" (i.e. the correct tokens were already within the few most probable tokens before the fine-tuning steps with REINFORCE).	Review	O	0
In fact, some of the performance gains of using REINFORCE/CMRT can be attributed to making the model's output probability distribution more peaked, and not necessarily from making the target tokens more probable as commonly assumed.	Review	O	0
[line_break_token][line_break_token]Overall, this is an excellent paper that offers significant contributions for the field.	Review	O	0
I have summarised the key strengths of the paper below, along with several suggestions and questions that I hope will be addressed by the authors.	Review	O	0
Based on my assessment, I am recommending a rating of "Accept" for this paper.	Review	O	0
[line_break_token][line_break_token]Strengths:[line_break_token]1.	Review	O	0
The paper is very well-written and well-structured.	Review	O	0
It starts off by pointing out the theoretical limitations of CMRT (and concisely recaps the key differences between CMRT and REINFORCE), and continues with an extensive set of experiments that clearly illustrates the limitations of REINFORCE in practice.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
I also like the use of both controlled simulations (including one where the reward is constant) and NMT experiments with real data.	Review	O	0
The controlled simulations are useful to abstract away from the full complexity of the model and investigate what happens under various control scenarios, while the NMT experiments demonstrate that the findings still hold under the realistic setup.	Review	O	0
[line_break_token][line_break_token]3.	Review	O	0
The findings are really interesting and clearly illustrate the limitations of existing REINFORCE/CMRT methods for neural sequence-to-sequence models.	Review	O	0
It is very interesting to see that REINFORCE fails to make the target token most probable when the initial model ranks the target token as the third or more probable tokens under the model (Figure 2), even under the simple controlled simulations, which highlights the prohibitively high sample complexity of the model.	Review	O	0
[line_break_token][line_break_token]4.	Review	B-Review	1
The peakiness effect hypothesis (i.e. attributing the gains of REINFORCE to making the output distribution more peaked, and not necessarily by making the target tokens more probable) is well-supported by the paper's empirical evidence.	Review	O	0
It is really illuminating that using a constant reward of 1 leads to the same BLEU score as actually optimising for BLEU in NMT (Section 5.2).	Review	O	0
[line_break_token][line_break_token]Suggestions and questions:[line_break_token]1.	Review	O	0
Section 4.2 (NMT Experiments) indicates that REINFORCE fine-tuning is done for 10 epochs, with 5,000 sentences per epoch, and k=1.	Review	B-Review	1
Considering the enormous discrete sample space, one could expect that using multi-sample REINFORCE (i.e. k &gt; 1) and training the model for many more epochs might mitigate the identified problems to some extent, and thus change the findings.	Review	O	0
Training for 5,000 sentences * 10 epochs may just not be enough for the RL fine-tuning to make a big difference.	Review	B-Review	1
[line_break_token][line_break_token]2.	Review	O	0
In Figure 1, the x-axis is the "Update Size" with a scale between -1.0 and 1.0.	Review	B-Review	2
This "Update Size" variable is not really explained in the paper, and why the scale is between -1.0 and 1.0.	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
In my understanding, the controlled simulations (Section 4.1) is done at the word-level (including word-level rewards, as opposed to the NMT experiments which are done at the sequence-level with sentence-level rewards).	Review	B-Review	3
If this is the case, this should be made clearer.	Review	I-Review	3
[line_break_token][line_break_token]4.	Review	I-Review	1
To make Figure 3 easier to understand, the caption should indicate that a lower cumulative percentage means a more peaked output distribution.	Review	I-Review	4
[line_break_token][line_break_token]5.	Review	O	0
Rather than breaking down the analysis by where the target token is ranked by the initial, pre-RL model (e.g. the target token is ranked second/third best in Figures 2 and 5), perhaps what really matters is the probability assigned to the target token.	Review	B-Review	5
For instance, even if the target token is ranked third best by the initial model, there will be a big difference whether it is assigned a probability of 0.1 or 0.01 (i.e. the latter case is much less likely to be sampled, which would exacerbate the problem).	Review	I-Review	5
Including this analysis might help strengthen the paper further.	Review	I-Review	5
[line_break_token]	Review	O	0
hank you for the positive review and for taking the time to thoroughly read and comment on our paper.	Reply	O	0
[line_break_token][line_break_token]We will, of course, address all your comments regarding changes in the last version of the paper (e.g. elaborating more on ‚Äúupdate size‚Äù).	Reply	O	0
[line_break_token][line_break_token]You mentioned the number of epochs run: it is possible to run more epochs, even though it is not a short process as it is (there are Monte Carlo roll-ups involved in the process too).	Reply	B-Reply	1
The experiments indeed suggest that if we want to use this method effectively, we need to run for much longer.	Reply	I-Reply	1
In practice, at this point of training, the patience already stops training and results drop.	Reply	I-Reply	1
Increasing the patience might work, and is worth exploring, but if it does end up helping (if no other changes are made), our results suggest it‚Äôll take much more than a few tens of epochs.	Reply	I-Reply	1
[line_break_token][line_break_token]Regarding the probabilities given to the third token, it is on average 0.04. (	Reply	I-Reply	5
Note that in our simulations we used those numbers so the on point 0 the frequencies mentions can be observed).	Reply	I-Reply	5

Update: I thank the authors for their comments!	Review	O	0
After reading them, I still think the paper is not novel enough so I'm leaving the rating untouched.	Review	O	0
[line_break_token][line_break_token]This paper proposes a domain adaptation technique for time series.	Review	O	0
The core of the approach is a combination of variational recurrent neural networks and adversarial domain adaptation (at the last time step).	Review	O	0
[line_break_token][line_break_token]Pros:[line_break_token][line_break_token]1.	Review	O	0
The authors consider a very important application of domain adaptation.	Review	O	0
[line_break_token][line_break_token]2.	Review	O	0
The paper is well-written and relatively easy to read.	Review	O	0
[line_break_token][line_break_token]3.	Review	O	0
Solid empirical evaluation.	Review	O	0
The authors compare their method against several recent domain adaptation techniques on a number of datasets.	Review	O	0
[line_break_token][line_break_token]Cons:[line_break_token][line_break_token]1.	Review	O	0
The novelty of the approach is relatively low: it‚Äôs just a straightforward fusion of the existing techniques.	Review	B-Review	1
[line_break_token][line_break_token]2.	Review	O	0
The paper lacks any motivation for use of the particular combination (VRNN and RevGrad).	Review	B-Review	2
I still believe comparable results can be obtained by polishing R-DANN (e.g. carefully penalizing domain discrepancy at every step)[line_break_token][line_break_token]Additional comments:[line_break_token][line_break_token]1.	Review	O	0
I‚Äôm not convinced by the discussion presented in Section 4.4.	Review	B-Review	3
I don‚Äôt think the visualization of firing patterns can be used to support the efficiency of the proposed method.	Review	I-Review	3
[line_break_token][line_break_token]2.	Review	O	0
Figure 1(c) looks very suspicious.	Review	B-Review	4
I can hardly believe t-SNE could produce this _very_ regular structure for non-degenerate (non-synthetic, real-world) data.	Review	I-Review	4
[line_break_token][line_break_token]Overall, it‚Äôs a solid paper but I‚Äôm not sure if it is up to the ICLR standard.	Review	O	0
Thank you for your comments and questions.	Reply	O	0
Below we provide more detailed comments to your questions.	Reply	O	0
[line_break_token][line_break_token]1.	Reply	O	0
The novelty of the approach is relatively low: it‚Äôs just a straightforward fusion of the existing techniques.	Reply	O	0
[line_break_token]A: We have clarified and highlighted our paper‚Äôs key novel contributions in the above 'Response to all reviewers' comment.	Reply	O	0
To briefly summarize - in this paper, we have focused on a very important problem in the healthcare application domain.	Reply	B-Reply	1
As far as we know, we are the first to propose unsupervised deep domain adaptation techniques to capture and transfer complex temporal dependencies present in healthcare multivariate time series data.	Reply	I-Reply	1
Our domain adaptation framework is general and is suitable for applications where dependencies are present in the multivariate time series data.	Reply	I-Reply	1
[line_break_token][line_break_token][line_break_token]2.	Reply	I-Reply	3
The paper lacks any motivation for use of the particular combination (VRNN and RevGrad).	Reply	O	0
I still believe comparable results can be obtained by polishing R-DANN (e.g. carefully penalizing domain discrepancy at every step)[line_break_token]A: We apologize for not being clear as to why we specifically used VRNN and reversal gradients.	Reply	O	0
Using a VRNN in VRADA, adds two capabilities: capture complex temporal dependencies present in the data and learns to create the data‚Äôs reconstruction.	Reply	B-Reply	2
 Both of these help our model learn more significant patterns within the data.	Reply	I-Reply	2
Using adversarial training via reversal gradients helps to learn domain-invariant representations.	Reply	I-Reply	2
We used this particular combination of VRNN with adversarial training since in healthcare applications matching the data distributions is more interesting than minimizing the distance between the data distribution means across domains (such as Mean Maximum Discrepancy (MMD)).	Reply	I-Reply	2
 Moreover, from a theoretical perspective, adversarial training idea [Ganin et.	Reply	I-Reply	2
al, JMLR 2016] is derived from the seminal works of [Ben-David et .	Reply	I-Reply	2
al, MLJ 2010]. [line_break_token]We would also like to inform that we have extensively fined tuned R-DANN to show the best results in our paper.	Reply	I-Reply	2
We have compared our approach fairly to Variational FAIR Autoencoder (denoted by VFAE) [Louizos C. et.	Reply	I-Reply	2
al, ICLR 2016], which uses MMD criterion.	Reply	I-Reply	2
We have empirically shown that VRADA outperforms both R-DANN and  VFAE on the healthcare datasets used in our paper.	Reply	I-Reply	2
[line_break_token][line_break_token]Additional comments:[line_break_token]Q 1.	Reply	O	0
I‚Äôm not convinced by the discussion presented in Section 4.4.	Reply	O	0
I don‚Äôt think the visualization of firing patterns can be used to support the efficiency of the proposed method.	Reply	O	0
[line_break_token]A: The discussion in section 4.4 is used to visualize and qualitatively compare the temporal dependencies captured by different domain adaptation approaches.	Reply	O	0
We used memory cell state activations for visualization.	Reply	B-Reply	3
In order to show that domain adaptation results in regular firing patterns, we have added plots to the appendix that show how firing patterns differ when domain adaptation isn‚Äôt applied.	Reply	I-Reply	3
You can then see a clear direction in the regularity of the firing patterns as (a) domain adaptation is applied, and (b) a better domain adaptation technique is applied.	Reply	I-Reply	3
We addressed the regularity found in Figure 4 in appendix section 6.2.3.	Reply	I-Reply	3
[line_break_token][line_break_token][line_break_token]Q 2.	Reply	O	0
Figure 1(c) looks very suspicious.	Reply	O	0
I can hardly believe t-SNE could produce this _very_ regular structure for non-degenerate (non-synthetic, real-world) data.	Reply	O	0
[line_break_token]A: Inspired by the feature representation visualization shown in [Ganin et.	Reply	O	0
al, JMLR 2016], we also use t-SNE plots to show the domain invariant feature representations learned by various domain adaptation approaches.	Reply	B-Reply	4
In Figure 1, we showed the t-SNE results which we consistently obtained for the source-target pairs from Adult-AHRF to Child-AHRF data.	Reply	I-Reply	4
It was surprising for us to see a regular t-SNE plot but that is the plot we obtained for the 3-1 source-target pair.	Reply	I-Reply	4
We also varied perplexity (from 5 to 100) and obtained similar t-SNE plots from our VRADA model.	Reply	I-Reply	4
We will release our codes to public for reproducibility.	Reply	I-Reply	4
[line_break_token][line_break_token][line_break_token]References:[line_break_token][Ganin et.	Reply	O	0
al, JMLR 2016] Ganin, Yaroslav, et al. "	Reply	O	0
Domain-adversarial training of neural networks."	Reply	O	0
Journal of Machine Learning Research 17.59 (2016): 1-35.	Reply	O	0
[line_break_token][Ben-David et.	Reply	O	0
al, MLJ 2010] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan.	Reply	O	0
A theory of learning from different domains.	Reply	O	0
Machine Learning, 9(1-2):151‚Äì175, 2010.	Reply	O	0
[line_break_token][Louizos C. et.	Reply	B-Reply	2
al, ICLR 2016] Louizos, Christos, et al. "	Reply	O	0
The variational fair autoencoder."	Reply	O	0
ICLR (2016)	Reply	O	0

This paper proposes an efficient algorithm to learn  neural embedding models with a dot-product structure over very large corpora.	Review	O	0
The main method is to reformulate the objective function in terms of generalized Gramiam matrices, and maintain estimates of those matrices in the training process.	Review	O	0
The algorithm uses less time and achieves significantly better quality than sampling based methods.	Review	O	0
[line_break_token][line_break_token]1.	Review	O	0
About the experiments, it seems the sample size for sampling based experiments is not discussed.	Review	B-Review	1
The number of noise samples have a large influence on the performance of the models.	Review	I-Review	1
In figure 2, different sampling strategies are discussed.	Review	I-Review	1
It would be cool if we can also see how the sampling size affects the estimation error.	Review	I-Review	1
[line_break_token][line_break_token]2.	Review	O	0
If we just look at the sampling based methods, in figure 2a, uniform sampling‚Äôs Gramian estimates is the worst.	Review	B-Review	2
But the MAP of uniform sampling on validation set for all three datasets are not the worst.	Review	I-Review	2
Do you have any comments?	Review	I-Review	2
[line_break_token][line_break_token]3.	Review	O	0
wheter an edge -> whether an edge.	Review	O	0
[line_break_token]	Review	O	0
Thank you for your review and your helpful suggestions.	Reply	O	0
[line_break_token][line_break_token]1) On the effect of sample size: we agree that the sample size directly affects the performance of these methods.	Reply	O	0
We investigated this effect in Appendix D.2 (which is now Appendix E.4 in the revision), where we ran the same experiment on Wikipedia English with batch sizes 128, 512 (Tables 3 and 4), and compared the results to batch size 1024 (Table 2).	Reply	B-Reply	1
We simultaneously varied the learning rate to understand its effect as well, but focusing on the effect of batch size only, we can observe that[line_break_token](i) the performance of all methods increases with the batch size (at least in the 128-1024 range).	Reply	I-Reply	1
[line_break_token](ii) the relative improvement of our methods (compared to the baseline) is larger for smaller batch sizes: the relative improvement is 19.5% for 1024, 26.7% for 512, and 29.1% for 128.	Reply	I-Reply	1
[line_break_token]Of course, one cannot increase the batch size indefinitely as there are hard limits on memory size, and the key advantage of our methods is in problems where sampling-based methods give poor estimates even with the largest feasible batch size.	Reply	I-Reply	1
[line_break_token]The effect of the batch size can also be seen to some extent in Figure 2.a, where we show the quality of the Gramian estimates for batch size 128 and 1024.	Reply	I-Reply	1
The figure suggests that the quality improves, for all methods, with larger batch sizes, and that SOGram with batch size 128 has a comparable estimation quality to the baseline with batch size 1024.	Reply	I-Reply	1
[line_break_token][line_break_token]2) The reviewer raises an interesting point.	Reply	O	0
We have observed in our experiments that for a fixed sampling distribution, improving the Gramian estimates generally leads to better MAP, but we cannot draw conclusions when the sampling distribution changes.	Reply	B-Reply	2
One possible explanation is that the sampling distribution affects both the quality of the Gramian estimates, and the frequency at which the item embeddings are updated.	Reply	I-Reply	2
In particular, tail items are sampled more often under uniform sampling than under the other distributions, and updating their embeddings more frequently may contribute to improving the MAP.	Reply	I-Reply	2
We added a comment (Appendix E.2 in the revision) to highlight this observation	Reply	I-Reply	2

This paper proposed another GAN-based PU learning method.	Review	O	0
The mathematics in this paper is not easy to follow, and there are many other critical issues.	Review	O	0
[line_break_token][line_break_token]*****[line_break_token][line_break_token]The clarity is really an issue.	Review	O	0
First of all, I cannot easily follow the meanings behind the equations.	Review	B-Review	1
I guess the authors first came up with some concrete implementation and then formalize it into an algorithm.	Review	I-Review	1
Given the current version of the paper, I am not sure whether this clarity of equations can be fixed without an additional round of review or not.	Review	I-Review	1
[line_break_token][line_break_token]Moreover, the logic in the story line is unclear to me, especially the 3rd paragraph that seems to be mostly important in the introduction.	Review	I-Review	2
There are two different binary classification problems, of separating the positive and negative classes, and of separating the given and generated data.	Review	I-Review	2
I cannot see why the generated data can serve as negative data.	Review	I-Review	2
This paragraph is discussing GenPU, PGAN and the proposed method, and consequently the motivation of the current paper does not make sense at least to me.	Review	I-Review	2
[line_break_token][line_break_token]*****[line_break_token][line_break_token]The paper classified PU learning methods into two categories, one-stage methods and two-stage methods.	Review	O	0
This is interesting.	Review	B-Review	3
However, before that, they should be classified into two categories, for censoring PU learning and for case-control PU learning.	Review	I-Review	3
The former problem setting was proposed very early and formalized in "learning classifiers from only positive and unlabeled data", KDD 2008; the latter problem setting was proposed in "presence-only data and the EM algorithm", Biometrics 2009 and formalized in "analysis of learning from positive and unlabeled data", NIPS 2014.	Review	O	0
Surprisingly, none of these 3 papers was cited.	Review	O	0
By definition, GAN-based PU learning belongs to the latter problem setting while Rank Prune can only be applied to the former but was included as a baseline method.	Review	O	0
[line_break_token][line_break_token]The huge difference between these two settings and their connections to learning with noisy labels are known for long time.	Review	O	0
To be short, class-conditional noise model corrupts P(Y|X) and covers censoring PU, mutual contamination distribution framework corrupts P(X|Y) and covers case-control PU, and mathematically mutual contamination distribution framework is more general than class-conditional noise model and so is case-control PU than censoring PU.	Review	O	0
See "learning from corrupted binary labels via class-probability estimation", ICML 2015 for more information where the above theoretical result has been proven.	Review	O	0
An arXiv paper entitled "on the minimal supervision for training any binary classifier from only unlabeled data" has some experimental results showing that methods for class-conditional noise model cannot handle mutual contamination distributions.	Review	O	0
The situation is similar when applying censoring PU methods to case-control PU problem setting.	Review	O	0
[line_break_token][line_break_token]Furthermore, the class-prior probability pi is well-defined and easy to estimate in censoring PU, see "learning classifiers from only positive and unlabeled data" mentioned above.	Review	O	0
However, it is not well-defined in case-control PU due to an identifiability issue described in "presence-only data and the EM algorithm" mentioned above.	Review	O	0
Thus, the target to be estimated is defined as the maximal theta such that theta*P(X|Y)<=P(X) following "estimating the class prior and posterior from noisy positives and unlabeled data", NIPS 2016.	Review	O	0
BTW, "mixture proportion estimation via kernel embedding of distributions" is SOTA in class-prior estimation; the previous NIPS paper was written earlier and accepted later.	Review	O	0
[line_break_token][line_break_token]In summary, as claimed in the paper and shown in Table 1 in the introduction, all discriminative PU methods and GenPU require to know pi for learning.	Review	O	0
This is true, but this is because they are designed for a more difficult problem setting---learning classifiers and estimating pi are both more difficult.	Review	O	0
Lacking some basic knowledge of PU learning is another big issue.	Review	O	0
[line_break_token][line_break_token]*****[line_break_token][line_break_token]The novelty is to be honest incremental and thus below the bar of ICLR.	Review	O	0
The significance is similarly poor, due to that the experiments mixed up methods for censoring PU and those for case-control PU.	Review	O	0
What is more, F1-score is a performance measure for information retrieval rather than binary classification.	Review	O	0
We all know GANs are pretty good at MNIST but not CIFAR-10.	Review	O	0
In fact, GenPU has a critical issue of mode collapse, and this is why GenPU reports 1-vs-1 rather than 5-vs-5 on MNIST.	Review	O	0
Even though, I still think GenPU makes much more sense than PGAN and D-GAN.	Review	O	0
Thanks for your constructive review,[line_break_token]Your comments indicate that the text and equations are not clear enough and that some previous state of the art methods were omitted.	Reply	O	0
We understand that the lack of clarity can be an issue.	Reply	O	0
We made during this rebuttal period a clarification effort.	Reply	O	0
[line_break_token]Moreover, please find as follow the answers to your comments.	Reply	O	0
[line_break_token][line_break_token][line_break_token]*****[line_break_token][line_break_token][line_break_token]‚ÄúI cannot easily follow the meanings behind the equations.	Reply	O	0
‚Äù[line_break_token][line_break_token]We have clarified the equations.	Reply	O	0
[line_break_token][line_break_token][line_break_token]‚ÄúI cannot see why the generated data can serve as negative data.	Reply	O	0
‚Äù ‚ÄúThis paragraph is discussing GenPU, PGAN and the proposed method, and consequently the motivation of the current paper does not make sense at least to me.	Reply	O	0
‚Äù [line_break_token][line_break_token]GANs are known to be relevant because of their ability of finding a boundary between real and generated samples: A GAN discriminator is trained to find autonomously the best metric to evaluate the generated samples quality.	Reply	O	0
This metric is considered as more relevant than previous ones such as the auto-encoders per-pixel reconstruction loss function.	Reply	B-Reply	2
[line_break_token]The GAN-based PU approaches main idea is to exploit this GAN benefit to address a PU learning problem: The initial goal of GANs is to imitate the unlabeled distribution.	Reply	I-Reply	2
In the context of the PU task, this goal is adapted to identify and imitate autonomously the distribution of relevant counter-examples hidden in the unlabeled dataset.	Reply	I-Reply	2
[line_break_token][line_break_token]The motivation in this paragraph is to discuss the previous GAN-based approaches following issues: [line_break_token]-[tab_token]GenPU issues: GenPU is not easily adaptable to the current GAN state of the art (fast) evolutions because of its untraditional adversarial framework.	Reply	I-Reply	2
Moreover, GenPU uses prior knowledge.	Reply	I-Reply	2
This is unpractical for example on some real application incremental datasets in which the fraction pi value can change continuously at each new training minibatch.	Reply	I-Reply	2
[line_break_token]-[tab_token]PGAN issue: It has a first stage overfitting problem when it is applied on relatively simple datasets as MNIST.	Reply	I-Reply	2
In fact, it is mentioned in their article: ‚ÄúIt is also known that a GAN is not perfect in its operation when it is applied to high dimensional data, ‚Ä¶ Thus it is possible to estimate the non-zero distance d computed into the cost function of Db‚Äù.	Reply	I-Reply	2
In other words, the PGAN exploits the GANs convergence defaults to address the PU learning problem.	Reply	I-Reply	2
[line_break_token][line_break_token]The proposed approach overcomes the above enumerated issues while keeping their respective advantages.	Reply	I-Reply	2
This is done by using a different technique: The D-GAN directly incorporates a PU learning risk into the discriminator loss function.	Reply	I-Reply	2
This guides naturally the generator to converge towards the distribution of the negative samples included in the unlabeled dataset.	Reply	I-Reply	2
[line_break_token][line_break_token][line_break_token]*****[line_break_token][line_break_token][line_break_token]‚ÄúThe paper classified PU learning methods into two categories, one-stage methods and two-stage methods.	Reply	O	0
This is interesting.	Reply	O	0
However, before that, they should be classified into two categories, for censoring PU learning and for case-control PU learning.	Reply	O	0
‚Äù[line_break_token][line_break_token]Previous relevant state of the art articles, like nnPU, classify PU learning methods in two-stage and one-stage categories.	Reply	O	0
The article nnPU (‚ÄúPositive-Unlabeled Learning with Non-Negative Risk Estimator‚Äù, NIPS 2017) says: ‚ÄúExisting PU methods can be divided into two categories based on how U data is handled.	Reply	B-Reply	3
The first category (e.g., [11, 12]) identifies possible negative (N) data in U data, and then performs ordinary supervised (PN) learning; the second (e.g., [13, 14]) regards U data as N data with smaller weights.	Reply	I-Reply	3
‚Äù.	Reply	I-Reply	2
[line_break_token][line_break_token]GAN-based approaches generate samples in the first step, and they perform ordinary PN learning during the second step by considering the generated samples as relevant counter-examples.	Reply	I-Reply	3
RP prepares a PN dataset from a PU dataset.	Reply	I-Reply	3
Thus it is relevant to classify into the same category (two-stage) RP, and GAN-based approaches (D-GAN, PGAN, GenPU).	Reply	I-Reply	3
[line_break_token][line_break_token]We introduce these categories (one-stage/two-stage) because our goal is to focus the attention on methods which aim at producing a relevant PN dataset from a PU dataset.	Reply	I-Reply	3
[line_break_token]	Reply	O	0

The problem is of increasing practical interest and importance.	Review	O	0
[line_break_token][line_break_token]The ablation study on the contribution and effects of each constituent  part is a strong part of the experiment section and the paper.	Review	O	0
[line_break_token][line_break_token]One major concern is about the novelty of the work.	Review	B-Review	1
There are many similar works under the umbrella of Neural Architecture search who are trying to connect different building blocks (modules) to build larger CNNs.	Review	I-Review	1
One example that explicitly makes sparse connections between them is [1]. Other examples of very similar works are [2,3,4].[line_break_token][line_break_token]The presentation of the paper can be improved a lot.	Review	O	0
In the current setup it‚Äôs very similar to a collection of ideas and tricks and techniques combined together.	Review	B-Review	3
[line_break_token][line_break_token]There are some typos and errors in the writing.	Review	I-Review	2
A thorough grammatical  proofreading is necessary.	Review	I-Review	2
[line_break_token][line_break_token]In conclusion there is a claim about tackling overfitting.	Review	I-Review	4
It‚Äôs not well supported or discussed in the experiments.	Review	I-Review	4
[line_break_token][line_break_token][1] Shazeer, Noam, et al. "	Review	O	0
Outrageously large neural networks: The sparsely-gated mixture-of-experts layer."	Review	O	0
arXiv preprint arXiv:1701.06538 (2017).	Review	O	0
[line_break_token][2] Xie, Lingxi, and Alan L. Yuille. "	Review	O	0
Genetic CNN."	Review	O	0
ICCV.	Review	O	0
2017.	Review	O	0
[line_break_token][3] Real, Esteban, et al. "	Review	O	0
Large-scale evolution of image classifiers."	Review	O	0
arXiv preprint arXiv:1703.01041 (2017).	Review	O	0
[line_break_token][4] Liu, Hanxiao, et al. "	Review	O	0
Hierarchical representations for efficient architecture search."	Review	O	0
arXiv preprint arXiv:1711.00436 (2017).	Review	O	0
[line_break_token]	Review	O	0
We are very excited about the positive and enthusiastic support of our core idea.	Reply	O	0
Thank you for your feedback about our strong part.	Reply	O	0
We totally agree with you that our strong part is Section 4.4.	Reply	O	0
[line_break_token] [line_break_token]About your main concerns:[line_break_token]We belive we have enough novelty for our work.	Reply	O	0
[line_break_token] [line_break_token]Paper [2] claimed that they use a genetic algorithm for searching network structures.	Reply	O	0
As I understand, their work mostly concentrates on searching skip connections of layers.	Reply	B-Reply	1
As it is shown in Fig.	Reply	I-Reply	1
2 in [2], the optimization object is only connections between layers, however, strictly speaking, they didn‚Äôt change the structure of the network.	Reply	I-Reply	1
 Our focus is combining the locally dense and externally sparse property of the human brain into the neural network.	Reply	I-Reply	1
Our optimization object is sparse connections between dense modules.	Reply	I-Reply	1
In our paper, we figure out a method to achieve local density and global sparsity and demonstrate it with our solid experiments.	Reply	I-Reply	1
 We have typical hierarchical structures, and our experiment figures out how different parts of the network will influence the final result.	Reply	I-Reply	1
Yes, many papers could use genetic algorithms, but they all have their own contributions.	Reply	I-Reply	1
Moreover, according to the experiment part in page 8 of [2], we acquire more solid experiment results.	Reply	I-Reply	1
  As these two papers have different core ideas, we believe that our paper have enough novelty.	Reply	I-Reply	1
[line_break_token] [line_break_token]Paper [3] focuses on minimizing human participation as much as possible.	Reply	I-Reply	1
They search all parameters including learning rate, identity, reset weights, insert & remove convolutions.	Reply	O	0
 We think paper [3] has the same motivation and idea as paper [2] that reduce human participation as much as possible.	Reply	B-Reply	1
We think paper [3] is even better than paper [2] as they are in the same direction.	Reply	I-Reply	1
[line_break_token]Our motivation is different from these two papers.	Reply	I-Reply	1
 Our focus is combining locally dense and globally sparse properties of network structures.	Reply	I-Reply	1
 We do analysis about how different parts of the network or the different types of connections will influence the final performance in Section 4.4.	Reply	I-Reply	1
[line_break_token] [line_break_token] [line_break_token]Paper [4] has a similar idea of hierarchical structures as our paper.	Reply	I-Reply	1
But our basic elements are modules which contain several dense layers.	Reply	I-Reply	1
We notice that in their paper, evolving algorithm could form cliques in the end.	Reply	I-Reply	1
We think it might have some interesting conclusions if they look into properties like density and which connections are important.	Reply	I-Reply	1
We think searching network structure is a big topic.	Reply	I-Reply	1
It worth many good papers on this topic.	Reply	I-Reply	1
But all of them have different contributions.	Reply	I-Reply	1
[line_break_token]Different from their work, we focus on the implement of human-like locally dense but externally sparse structures in our paper.	Reply	I-Reply	1
And we make a detailed analysis of how each long-distance connection will influence the final result.	Reply	I-Reply	1
[line_break_token] [line_break_token]Paper [1] is a good NLP paper with special layers and searching strategy.	Reply	I-Reply	1
This paper is also under the network search topic.	Reply	I-Reply	1
But we focus on totally different aspects.	Reply	I-Reply	1
[line_break_token] [line_break_token]Thank you for mentioning some typos and grammar mistakes.	Reply	O	0
We apologize for this.	Reply	B-Reply	2
We spend a lot of time doing several rounds of proofreading and revising.	Reply	I-Reply	2
We hope this version may make you feel better.	Reply	I-Reply	2
[line_break_token] [line_break_token]In all, although there are some papers having similar topics to our paper (network searching, hierarchical network structures, network pruning), we think a good topic worth many good papers to contribute to it.	Reply	O	0
Also, we think we have enough novelty as present above.	Reply	B-Reply	1
In that case, we think it worth to be accepted.	Reply	I-Reply	1
Thank you very much.	Reply	I-Reply	1
[line_break_token]	Reply	O	0

This paper introduces a method for generating training/test data for measuring the model's ability of "compositional generalization" in complex compositional tasks/domains such as natural language understanding, visual understanding and other domains.	Review	O	0
[line_break_token]The idea of the proposed method is to essentially keep the "atom" distribution unchanged between the training and test data, but maximize the divergence between the "compound" distributions between them.	Review	O	0
[line_break_token]The authors have conducted a thorough and systematic experimentation, comparing the proposed approach with a number of other heuristic approaches for train test splits (such as random and input/output length, etc.)	Review	O	0
and using both a new large data set they generated (CFQ) and existing data set (SCAN).	Review	O	0
[line_break_token]The experimental results verify that using their method they can obtain train test data sets with uniform atom distributions with large divergence in compound distributions, and they find that there is a surprisingly large negative correlation between the accuracy of existing state-of-the-art learning methods and the compound divergence.	Review	O	0
[line_break_token]The data generation mechanism is systematic and involved, consisting of different categories of rules (logical form, grammar, rule application DAG's, etc.)	Review	O	0
and it would seem that the generation method/system and the generated data would be useful as benchmark data for the community.	Review	O	0
[line_break_token]The paper lacks technical novelty other than the training and test data generation approach, but having one available to the community with these apparently desirable characteristics as benchmark data for measuring complex, compositional generalization capabilities, and that could be invaluable to the research community.	Review	B-Review	1
e thank the reviewer for reading our paper in detail and for providing a careful review of the paper along with a summary of the contributions.	Reply	O	0
We agree with the reviewer that some of the primary areas of technical novelty in the paper are related to the training and test data generation approach.	Reply	B-Reply	1
More specifically, we would suggest that the novelty consists of at least two aspects: one being the approach to generation of a structurally diverse dataset through maximization of the entropy of the compound distribution; the second (and in our opinion more fundamental) novel aspect being the DBCA approach to measuring compositional generalization capability through the creation of data splits of varied compound divergence (while keeping atom distribution similar).	Reply	I-Reply	1

This paper proposes the Layerwise Origin Target Synthesis (LOTS) method, which entails computing a difference in representation at a given layer in a neural network and then projecting that difference back to input space using backprop.	Review	O	0
Two types of differences are explored: linear scalings of a single input‚Äôs representation and difference vectors between representations of two inputs, where the inputs are of different classes.	Review	O	0
[line_break_token][line_break_token]In the former case, the LOTS method is used as a visualization of the representation of a specific input example, showing what it would mean, in input space, for the feature representation to be supressed or magnified.	Review	O	0
While it‚Äôs an interesting computation to perform, the value of the visualizations is not very clear.	Review	O	0
[line_break_token][line_break_token]In the latter case, LOTS is used to generate adversarial examples, moving from an origin image just far enough toward a target image to cause the classification to flip.	Review	O	0
As expected, the changes required are smaller when LOTS targets a higher layer (in the limit of targetting the last layer, results similar to the original adversarial image results would be obtained).	Review	O	0
[line_break_token][line_break_token]The paper is an interesting basic exploration and would probably be a great workshop paper.	Review	O	0
However, the results are probably not quite compelling enough to warrant a full ICLR paper.	Review	O	0
[line_break_token][line_break_token]A few suggestions for improvement:[line_break_token] - Several times it is claimed that LOTS can be used as a method for mining for diverse adversarial examples that could be used in training classifiers more robust to adversarial perturbation.	Review	O	0
But this simple experiment of training on LOTS generated examples isn‚Äôt tried.	Review	B-Review	1
Showing whether the LOTS method outperforms, say, FGS would go a long way toward making a strong paper.	Review	I-Review	1
[line_break_token] - How many layers are in the networks used in the paper, and what is their internal structure?	Review	O	0
This isn‚Äôt stated anywhere.	Review	B-Review	2
I was left wondering whether, say, in Fig 2 the CONV2_1 layer was immediately after the CONV1_1 layer and whether the FC8 layer was the last layer in the network.	Review	I-Review	2
[line_break_token] - In Fig 1, 2, 3, and 4, results of the application of LOTS are shown for many intermediate layers but miss for some reason applying it to the input (data) layer and the output/classification (softmax) layer.	Review	O	0
Showing the full range of possible results would reinforce the interpreatation (for example, in Fig 3, are even larger perturbations necessary in pixel space vs CONV1 space?	Review	B-Review	3
And does operating directly in softmax space result in smaller perturbations than IP2?)	Review	I-Review	3
[line_break_token] - The PASS score is mentioned a couple times but never explained at all.	Review	O	0
E.g. Fig 1 makes use of it but does not specify such basics as whether higher or lower PASS scores are associated with more or less severe perturbations.	Review	B-Review	4
A basic explanation would be great.	Review	I-Review	4
[line_break_token] - 4.2 states ‚ÄúIn summary, the visualized internal feature representations of the origin suggest that lower convolutional layers of the VGG Face model have managed to learn and capture features that provide semantically meaningful and interpretable representations to human observers.	Review	O	0
‚Äù I don‚Äôt see that this follows from any results.	Review	B-Review	5
If this is an important claim to the paper, it should be backed up by additional arguments or results.	Review	I-Review	5
[line_break_token][line_break_token][line_break_token][line_break_token]1/19/17 UPDATE AFTER REBUTTAL:[line_break_token]Given that experiments were added to the latest version of the paper, I'm increasing my review from 5 -> 6.	Review	O	0
I think the paper is now just on the accept side of the threshold.	Review	O	0
Thank you for your valuable suggestions for improvement!	Reply	O	0
[line_break_token][line_break_token]We believe that operating directly on softmax to produce adversarial examples, i.e., taking the difference of the captured probabilities, would not be different than using the logits as those probabilities are calculated directly from the logits. (	Reply	B-Reply	1
Also, considering that those probabilities add up to one, taking the difference would violate that.)	Reply	I-Reply	1
[line_break_token][line_break_token]We will upload a revised paper in a few days.	Reply	O	0
We try to address all suggestions/comments coming from reviewers including using them for improved learning.	Reply	O	0

This paper presents a general framework for sentence generation using a BERT-like model.	Review	O	0
The authors decompose the problem of sentence generation into two problems.	Review	O	0
One is selecting the positions at which changes should be made, and the other is actually replacing the current word with a new word.	Review	O	0
This framework enables them to represent many decoding strategies including that of Ghazvininejas et al. (	Review	O	0
2019) in a unified manner, and they propose a new decoding strategy that considers the prediction confidence of the current and the new word.	Review	O	0
The paper also presents a heuristic algorithm for beam search decoding to find the most likely generation path.	Review	O	0
Their experimental results on the WMT14 English-German dataset suggest that the proposed approach could achieve translation quality comparable to that of the standard autoregressive approach under a constant-time translation setting.	Review	O	0
[line_break_token][line_break_token]It is nice to see existing decoding strategies represented in a generalized framework, but I was a bit disappointed that the authors do not seem to address the most critical problem in using a BERT-like model for sentence generation, namely, how to find the most likely sentence in a probabilistically sound way.	Review	B-Review	1
It seems to me that the authors rely on at least two approximations.	Review	I-Review	2
One is using pseudo-likelihood and the other is using the most likely generation path instead of performing marginalization.	Review	I-Review	2
It is fine that the authors focus on empirical results of translation quality but then I would like to see more strong and extensive evidence that supports the use of such approximation.	Review	I-Review	2
[line_break_token]	Review	O	0
e believe that our framework is a probabilistically sound way of generating from masked language models, and language models generally.	Reply	B-Reply	1
Our methodology does require some approximations to tractably generate sentences, but the overall generative story we offer is still valid.	Reply	I-Reply	1
Moreover, even generating in traditional left-to-right autoregressive models requires approximations (e.g. greedy decoding or beam search) due to the exponential hypothesis space.	Reply	I-Reply	1
[line_break_token][line_break_token]We believe our approximations are theoretically sensible, but they are difficult to verify how good they are due to the fact that what we‚Äôre trying to approximate in the first place is highly intractable to compute.	Reply	I-Reply	2
One piece of evidence we‚Äôve looked at and included in the paper (Fig 3 in appendix in revision) is the probability of the intermediate sequences over the generation process.	Reply	I-Reply	2
The energy (in the sense of energy-based models, see <a href="https://arxiv.org/abs/1902.04094)" target="_blank" rel="nofollow">https://arxiv.org/abs/1902.04094)</a> of the target sequence decreases (equivalently, the probability increases) throughout the generation process.	Reply	O	0
The figure also shows that more sophisticated decoding schemes such as left2right, easy-first, and least2most converge to lower energy (higher probability) target sequences faster compared to uniformly picking positions.	Reply	B-Reply	2
Overall, we believe that this is evidence that even with the approximations involved, our framework is able to find target sequences in a probabilistically sound manner and points to the value of further research in developing better coordinate selection mechanisms.	Reply	I-Reply	2
If the reviewer has any thoughts on further experiments or evidence to explore, we‚Äôd be happy to hear it.	Reply	I-Reply	2

